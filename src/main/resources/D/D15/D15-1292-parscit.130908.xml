<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.997252">
Navigating the Semantic Horizon
using Relative Neighborhood Graphs
</title>
<note confidence="0.87429925">
Amaru Cuba Gyllensten and Magnus Sahlgren
Gavagai
Bondegatan 21
116 33 Stockholm
</note>
<address confidence="0.581414">
Sweden
</address>
<email confidence="0.97687">
{amaru|mange}@gavagai.se
</email>
<sectionHeader confidence="0.997" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999985230769231">
This paper introduces a novel way to nav-
igate neighborhoods in distributional se-
mantic models. The approach is based
on relative neighborhood graphs, which
uncover the topological structure of local
neighborhoods in semantic space. This
has the potential to overcome both the
problem with selecting a proper k in k-NN
search, and the problem that a ranked list
of neighbors may conflate several different
senses. We provide both qualitative and
quantitative results that support the viabil-
ity of the proposed method.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999934333333334">
Nearest neighbor search is a fundamental opera-
tion in data mining, in which we are interested in
finding the closest points to some given reference
point. Formally, if we have a reference point r
and a set of other points P in a metric space M
with some distance function d, the nearest neigh-
bor search task is to find the point p E P that min-
imizes d(p, r). In k-Nearest Neighbor search (k-
NN), we want to find the k closest points to some
given reference point. Nearest neighbor search
is a well-studied task, and in particular the com-
plexity of the task (a linear search has a running
time of O(Ni) where N is the cardinality of P
and i the complexity of the distance function d)
has generated a lot of research; suggestions for re-
ducing the complexity of linear nearest neighbor
searches include using various types of space par-
titioning techniques like k-d trees (Bentley, 1975),
or various techniques for doing approximate near-
est neighbor search (Arya et al., 1998), of which
one of the most well-known is locality-sensitive
hashing (Indyk and Motwani, 1998).
The problem we are concerned with in this
paper is not the complexity of nearest neighbor
search, but the question of how to identify the in-
ternal structure of neighborhoods defined by the
nearest neighbors. The problem with a normal k-
NN is that the result — a sorted list of the k nearest
neighbors — does not say anything about the inter-
nal structure of the neighborhood. It is quite pos-
sible for two neighborhoods with widely different
internal structures to produce identical k-NN re-
sults. In the context of Distributional Semantic
Models (DSMs), which collect and represent co-
occurrence statistics in high-dimensional vector
spaces, such structural differences may carry sig-
nificant semantic information, e.g. about the dif-
ferent senses of terms. We argue that the inability
of standard k-NN to account for structural prop-
erties has been misinterpreted as a shortcoming
of the distributional representation (Erk and Pad´o,
2010).
We will demonstrate in this paper that this is
not a shortcoming of the distributional represen-
tation, but of the mode of querying the DSM. We
argue that information about the different usages
(i.e. senses) of a term is encoded in the structural
properties of the nearest neighborhoods, and we
propose the use of relative neighborhood graphs
for identifying these structural properties. Relative
neighborhood graphs may also be used for finding
a relevant k for a given reference point, which we
refer to as the horizon with respect to the reference
point.
</bodyText>
<sectionHeader confidence="0.842848" genericHeader="method">
2 Distributional Semantics and Nearest
Neighbor Search
</sectionHeader>
<bodyText confidence="0.999593">
Collecting and comparing co-occurrence statis-
tics for terms in language has become a stan-
dard approach for computational semantics, and
is now commonly referred to as distributional se-
mantics. There are many different types of mod-
els that can be used for this purpose, but their
common objective is to represent terms as vec-
tors that record (some function of) their distri-
</bodyText>
<page confidence="0.909375">
2451
</page>
<note confidence="0.984397">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2451–2460,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.998023204081633">
butional properties. The standard approach for
generating such vectors is to collect distributional
statistics in a co-occurrence matrix that records
co-occurrence counts between terms and contexts.
The co-occurrence matrix is then subject to var-
ious types of transformations, ranging from the
application of simple frequency filters or associ-
ation measures to matrix factorization or regres-
sion models. The resulting representations are re-
ferred to as distributional vectors (or word embed-
dings), which are used to compute similarity be-
tween terms.
Given a similarity — or distance — measure on
such distributional vectors, we can perform a near-
est neighbor search. This is a particularly impor-
tant operation in distributional semantics, since it
answers the question “which other terms are sim-
ilar to this one?” and this is a central question in
semantics; lexica and thesauri are built with the
main purpose of answering this question. Conse-
quently, nearest neighbor search in a DSM could
be seen as a compilation step in a distributional
lexicon.
The result of a nearest neighbor search in a
DSM is often presented as a list of (the top k)
neighbors, sorted by descending similarity with
the target term. Table 1 illustrates typical sorted
nearest neighbor lists produced with three dif-
ferent DSMs: a standard model based on Point-
wise Mutual Information (PMI)1 that has been re-
duced to 2,000 dimensions by applying a Gaus-
sian random projection; GloVe, which uses regres-
sion to find distributional vectors such that their
dot product approximates their log probability of
co-occurring (Pennington et al., 2014); and the
Skipgram model, which uses stochastic gradient
descent and hierarchical softmax combined with
negative sampling and subsampling to find dis-
tributional vectors that maximize the probability
of observed co-occurrence events (Mikolov et al.,
2013). We refer to the respective papers for de-
tails regarding the various models. The similarity
measure used is the cosine similarity: s(a, b) =
a·b
llallllbll
Table 1 lists the 10 nearest neighbors to suit
in these three different DSMs using the entire
Wikipedia as data. As can be expected, there
are both similarities and dissimilarities between
</bodyText>
<footnote confidence="0.8982725">
1For observations a and b, PMI(a, b)= log p(a,b)
p(a)p(b). The
</footnote>
<note confidence="0.643491">
probabilities are often replaced in DSMs by co-occurrence
counts of a and b and their respective frequency counts.
</note>
<tableCaption confidence="0.957509">
Table 1: Sorted list of the nearest neighbors to
“suit” in three different distributional models.
</tableCaption>
<figureCaption confidence="0.636174818181818">
PMI GloVe Skipgram
suits suits suits
dress lawsuit lawsuit
jacket filed countersuit
wearing case classaction
hat wearing doublebreasted
trousers laiming skintight
costume lawsuits necktie
shirt alleging wetsuit
pants alleges crossbone
lawsuit classaction lawsuits
</figureCaption>
<bodyText confidence="0.999765">
these neighborhoods; “suits” and “lawsuit” oc-
cur among the 10 nearest neighbors to “suit” in
all three models, whereas other terms are spe-
cific for one particular model. What is com-
mon between the three models is that they all
feature neighbors that represent two different us-
ages of “suit”: the law-sense (“lawsuit”) and
the clothes-sense (“dress”, “wearing”, “double-
breasted”).2 However, these distinction are not
discernible by merely looking at the list of near-
est neighbors; the only information it provides is
the ranking of the nearest neighbors in descending
order of similarity.
It has been argued that DSMs that represent
terms by a single vector cannot adequately handle
polysemy, since they conflate several different us-
age patterns in one and the same vector (V´eronis,
2004; Erk and Pad´o, 2010). Examples like the one
above is often cited as evidence. We argue that
this critique is unfounded and misinformed, and
that it is the mode of querying the DSM that can
be susceptible to problems with polysemy. As the
above example demonstrates, querying DSMs by
k-NN conflates different usages of terms. The rea-
son for this seems quite obvious: simply ranking
the nearest neighbors by similarity (or distance)
ignores any local structures of the neighborhood.
If “suit” has as neighbors both “dress” and “law-
suit”, which represent two distinct types of usages
of “suit”, there will be a structural distinction in
the neighborhood of “suit” between these differ-
ent neighbors, since they will be mutually unre-
lated (i.e. there is a similarity between “suit” and
</bodyText>
<footnote confidence="0.986029333333333">
2The Skipgram model also features a manga-related sense
of “suit” in the neighbor “crossbone,” which refers to the
mange series “Mobile Suit Crossbone Gundam.”
</footnote>
<page confidence="0.995645">
2452
</page>
<bodyText confidence="0.999908230769231">
“dress” and between “suit” and “lawsuit”, but not
between “dress” and “lawsuit”).
k-NN also gives rise to another problem re-
lated to polysemy in DSMs. The problem is that
the most frequent senses will populate the top
of the nearest neighbor list, while the less fre-
quent senses will not appear until further down
the list, and if we set a too restrictive k, we will
only see neighbors relating to the most frequent
sense. As an example, consider the two differ-
ent senses of “suit” above. The distributional vec-
tor for “suit” can be thought of as a sum vsuit =
fsuit|lawvsuit|law + fsuit|clothesvsuit|clothes, where
vsuit|law is an idealized notion of the true dis-
tributional vector of “suit” in the law-sense, and
fsuit|law is the relative frequency of this sense.3
From there one can easily argue that a similar-
ity such as s(vsuit, vclothes) is actually a weighted
composite of the similarities s(vsuit|law, vclothes)
and s(vsuit|clothes, vclothes).4 If “suit” occurs pre-
dominantly in the law-sense in our corpus, the k-
NN neighborhood of “suit” will be dominated by
words pertaining to its law-sense, while the less
frequent senses might not be present at all. A
misguided k may thus obscure any other, less fre-
quent, senses of a term.
</bodyText>
<sectionHeader confidence="0.998852" genericHeader="method">
3 Word-Sense Induction
</sectionHeader>
<bodyText confidence="0.999790789473684">
Selecting a relevant k for a given term and group-
ing the neighbors according to which senses they
represent is an example of Word-Sense Induction
(WSI). DSMs are well suited for this task, and
there have been a number of different approaches
suggested in the literature. One of the earliest ap-
proaches is distributional clustering (Pereira et al.,
1993), which is based on a probabilistic decompo-
sition model that uses maximum likelihood esti-
mation to fit the model to observed data. Another
example is Clustering By Committee (CBC) (Pan-
tel and Lin, 2002), which first uses average-link
clustering to recursively cluster the nearest neigh-
bors of a term into committees, which are then
used to define clusters by iteratively adding com-
mittees whose similarity to the term exceeds a cer-
tain threshold, and that is not too similar to any
other added committee. For each added commit-
tee, its features are also removed from the distri-
</bodyText>
<footnote confidence="0.832311333333334">
3Weighting schemes muddles this notion quite a bit, but
we think the general intuition still holds.
4In the case of cosine similarity this follows nicely from
the distributive property of dot products: v = av1 + bv2,
s (v, w\ —_ v·w = a(v1·w)+b(v2·w)
/ kvkkwk kvkkwk
</footnote>
<bodyText confidence="0.999544392156863">
butional representation of the term. This last step
ensures that the clusters do not become too similar,
and that clusters representing less frequent senses
can be discovered.
The idea of iteratively removing features from
the distributional vector when a sense cluster as
been formed is also present in Dorow and Wid-
dows (2003), who use a graph-based clustering
method. Another graph-based approach is the
HyperLex algorithm (V´eronis, 2004), which con-
structs a graph connecting all pairs of terms that
co-occur in the context of an ambiguous term. The
resulting graph contains highly connected compo-
nents, which represent the different senses of the
term. Agirre et al. (2006) compare HyperLex to
PageRank (Brin and Page, 1998) and demonstrates
that the two methods perform similarly.
There have also been several attempts to use
various types of matrix factorization for WSI. The
idea is that the factorization uncovers a set of
global senses in the form of the latent factors,
and that the sense distribution for a given term
can be described as a distribution over these la-
tent factors. Examples of factorization methods
that have been used include different versions of
Latent Dirichlet Allocation ((Brody and Lapata,
2009; S´eaghdha and Korhonen, 2011; Yao and
Van Durme, 2011; Lau et al., 2012) and non-
negative matrix factorization (Dinu and Lapata,
2010; Van de Cruys and Apidianaki, 2011).
Tomuro et al. (2007) argue that clustering ap-
proaches like distributional clustering or CBC may
produce clusters that are themselves polysemous,
which may not be a desirable property of a WSI
algorithm, and suggests using feature domain sim-
ilarity to solve this problem. The idea is to incor-
porate similarities between the features of items
rather than the similarity between the items them-
selves in a modified version of CBC that enables
the algorithm to utilize feature similarities, which
inhibit the formation of polysemous clusters.
Koptjevskaja Tamm and Sahlgren (2014) also
leverage on the idea of using feature similarity
as the basis of sense clustering. The approach,
called syntagmatically labeled partitioning, relies
on a DSM that encodes sequential as well as sub-
stitutable relations. The method essentially sorts
the k nearest (substitutable) neighbors according
to which sequential connections they share. The
resulting partitioning of the nearest distributional
neighbors does not only constitute a WSI, but it
</bodyText>
<page confidence="0.963452">
2453
</page>
<bodyText confidence="0.999889">
also provides labels for the induced senses in the
form of the sequential connections the neighbors
share.
</bodyText>
<sectionHeader confidence="0.987011" genericHeader="method">
4 Neighborhood Graphs
</sectionHeader>
<bodyText confidence="0.999957702702703">
Many of the previous WSI approaches operate at
a global level, utilizing global structural proper-
ties of the semantic spaces, e.g. by matrix fac-
torization techniques. We believe this is as ill-
advised as setting a global k or radius for the near-
est neighbor search, since it is the local structures
that are important when analyzing nearest neigh-
bors. Other WSI approaches use various forms
of clustering techniques. However, previous stud-
ies of the intrinsic dimensionality of distributional
semantic spaces using fractal dimensions indicate
that neighborhoods in semantic space have a fila-
mentary rather than clustered structure (Karlgren
et al., 2008).
We therefore propose the use of topological
models that take the local structure of neighbor-
hoods in semantic space into account. The ap-
proach discovers different word senses from the
local structure of neighborhoods, given nothing
but similarities between points. As such it is easy
to test on widely different vector models, as long
as there exists a well behaved similarity function.
The proposed approach not only answers the ques-
tion which other terms are similar to a given term,
but also how are they similar.
Relative neighborhoods, first proposed in (Tou-
ssaint, 1980), are examples of empty region graphs
(Cardinal et al., 2009), where points are neighbors
if some region between them is empty. For Rela-
tive Neighborhood Graphs (RNG) this region be-
tween two points a and c is defined as the inter-
section of the two spheres with centers in a and c
with radius d(a, c). In other words, a point b lies
between points a and c if it is closer to both a and
c than a and c are to each other. If no such point b
exists, a and c are neighbors. Illustrations of this
can be seen in Figure 1.
</bodyText>
<figureCaption confidence="0.8438275">
Figure 1: Example of when point b is between
point a and c (left), and when it is not (right).
</figureCaption>
<bodyText confidence="0.999957176470588">
Such neighborhoods have been argued to better
preserve local topology (Bremer et al., 2014), and
be more robust to deformations of the data than k-
NN neighborhoods (Correa and Lindstrom, 2012)
as they in some sense contain information about
direction whereas k-NN neighborhoods only con-
tain information about distance. Going back to the
“suit” example, we can see that if “suit” in the law-
sense is more similar to the composite “suit” than
to its clothes-sense, and vice versa, then the com-
posite vsuit lies between vsuitjlaw and vsuitjclothes.
This in turn means that out of those two points,
both are relative neighbors to “suit”, and neither
of them lies between the other and “suit”.
Formally, the set of points between two points
a, c ∈ V can be characterized and computed in the
following way:
</bodyText>
<equation confidence="0.637642333333333">
btw(V, a, c) = {b|b ∈ V, b is between a and c}
rng-nbh(V, a) = {c|c ∈ V, btw(V, a, c) = ∅}
Erng(V ) = {(a, b)|a ∈ V, b ∈ rng-nbh(V, a)}
</equation>
<bodyText confidence="0.9993716">
where Erng is the undirected edge set of the RNG.
The function btw(V, a, c) can be straightforwardly
translated to an algorithm taking O(|V |) time,
making the rng-nbh(V, a) function take O(|V |2)
time, which in turn makes the computation of the
complete graph take O(|V |3) time.5 Clearly un-
feasible, but we have not found any alternatives
that perform better in the high-dimensional case.6
Correa and Lindstrom (2012) note that the inter-
section of the RNG and the k-NN graph is a more
feasible alternative:
k-rng-nbh(V, a) = rng-nbh(V &apos;, a)
where V &apos; = k nearest neighbors of a.
Given a precompiled k-NN lookup, the above
takes O(k2) time, so using a heap-based
O(|V  |lg k) k-NN algorithm results in an algo-
rithm taking O(k2 + |V  |lg k) time.
The same idea can be used to build a tree struc-
ture rooted in a reference word a in the following
way:
</bodyText>
<equation confidence="0.57152">
rnbh-tree(V, a) = {(c, arg min d(b,c))|c ∈ V }
bEB�
</equation>
<bodyText confidence="0.991871">
where Bc = {a} ∪ btw(V, a, c)
</bodyText>
<footnote confidence="0.984140333333333">
5Assuming a constant time distance function.
6It should be noted that there are more efficient algorithms
for lower-dimensional situations.
</footnote>
<page confidence="0.993013">
2454
</page>
<bodyText confidence="0.999848866666667">
which can easily be restricted to the k-nearest
neighbors of a in much the same way as above,
with the same monotonic behavior.
Computing this for a point a produces a tree
where the direct children of a are its relative neigh-
bors, and the parent of a point c further down the
tree is the point between a and c that is closest
to c. This structure, while similar to a minimum
spanning tree, differs in some crucial regards: the
rnbh-tree(V, a) is rooted in a word a. The differ-
ence between rnbh-tree(V, a) and rnbh-tree(V, b)
is often quite significant. Furthermore, the re-
stricted k-rnbh-tree is monotonic in k. That prop-
erty does not hold for a minimum spanning tree of
a local neighborhood.
</bodyText>
<sectionHeader confidence="0.931326" genericHeader="method">
5 Examples of RNGs
</sectionHeader>
<bodyText confidence="0.997693346938775">
To get an intuition of what these neighborhoods
look like we present a few examples. The words
have been chosen either because they are com-
mon examples in similar work — e.g. “heart” and
“suit” from Pantel and Lin (2002) — or because
they represent different parts-of-speech (“above”
is a preposition, “bad” is an adjective, and “ser-
vice” is a noun) and disparate kinds of ambiguity
(“orange” can be both a fruit and a color).
Figure 2 (next page) illustrates what an RNG
looks like for the term “heart” and its 100 near-
est neighbors in the PMI model. Note that the
root “heart” (at the mid-left in the graph) only
has two relative neighbors: “cardiac” and “soul,”
arguably representing a body-sense and a soul-
sense of the term. One advantage of using this
type of structure for the neighborhood is that
it enables us to examine various depths of the
tree. Depth one includes only the direct neigh-
bors (“cardiac” and “soul”), while depth two in-
cludes all neighbors two steps away in the graph:
“disease,” “coronary,” “pulmonary,” “cardiovascu-
lar,” “ventricular,” and “failure,” which are all chil-
dren to “cardiac.” This tree structure can be used
to identify neighbors that are themselves polyse-
mous (c.f. the critique mentioned in Section 3 of
clustering-based approaches to word-sense induc-
tion that they may produce polysemous clusters ).
One example is the neighbor “disease” at depth
two, which has six children that refer to different
aspects of disease.
We argue that the RNG can be quite useful
for WSI, since the branching structure indicates
different usages, and the depth factor enables us
to calibrate the granularity of the induced word
senses. If we only consider direct neighbors
(i.e. depth one), and set k = V (i.e. we do an
exhaustive nearest neighbor search), we will ex-
tract all terms that have a direct connection to the
reference term. We refer to this neighborhood as
the semantic horizon. At the most coarse level of
analysis, this is the neighborhood that represents
the main induced senses of a term. Tables 2 and
3 provide examples of 1,000-RNG neighborhoods
of depth one.
Table 2: RNG for k = 1, 000 of the words “suit,”
“orange,” and “heart” in three different semantic
models. The numbers in parenthesis indicate the
k-NN ranks of the neighbors.
</bodyText>
<figureCaption confidence="0.973966294117647">
PMI GloVe Skipgram
suit
suits (1) suits (1) suits (1)
dress (2) lawsuit (2) lawsuit (2)
lawsuit (10) mobile (33)
dinosaur (53) gundam (34)
costly (60) trump (55)
option (76) zoot (133)
counterparts (99) rebid (423)
predator (107) serenaders
trump (109) (458)
... hev (987)
orange
yellow (1) yellow (1) redorange (1)
lemon (16) ktype (12)
lemon (14)
citrus (17)
jersey (21)
cherry (24)
county (26)
peel (42)
jumpsuits (57)
...
heart
cardiac (1) my (1) congestive (1)
soul (22) blood (2) hearts (2)
hearts (183) throbs (3)
ashtray(641) suffering (4)
rags(771) brain (6)
cardiac (8)
hearts (11)
throb (17)
lungs (22)
...
</figureCaption>
<bodyText confidence="0.999738666666667">
These examples demonstrate some interesting
similarities and differences between the three
models. First of all, there are some direct neigh-
bors that are present in all three models: “suit”
has “suits” and “lawsuit” as direct neighbors in
all three models, “heart” has “hearts,” “service”
</bodyText>
<page confidence="0.98694">
2455
</page>
<figureCaption confidence="0.998894">
Figure 2: RNG for “heart” in the PMI model, restricted to the 100 nearest neighbors.
</figureCaption>
<bodyText confidence="0.99982014">
has “services,” and “above” has “below”. Plu-
ral forms are of course reasonable neighbors of
their singular counterparts in a semantic model,
but their usefulness for WSI can perhaps be ques-
tioned. Taking “suits” to indicate the clothes-sense
of “suit,” all three models produce both a clothes-
sense and a law-sense. For “orange,” the Skipgram
model only represents the color-sense, while the
PMI and GloVe models also feature a fruit-sense.
For “heart,” all three models have a disease-sense
(represented by the neighbors “cardiac” in the PMI
and GloVe models, and the neighbor “congestive”
in the Skipgram model), and an organ-sense (rep-
resented by the plural form “hearts”). “Service”
is a comparably vague term that has a number of
different senses in the PMI and GloVe models,
but only one in the Skipgram model. “Bad” pro-
duces both a negativity-sense and a German spa
town-sense in all three models, but only the GloVe
and Skipgram models have a separate antonym-
sense (“good” is not a direct neighbor in the PMI
model). “Above” has both the antonym and direct
neighbors relating to measurements in all three
models.
It is interesting to note that GloVe produces a
significant amount of sequential relations; “mo-
bile suit gundam”, “cheap suit serenaders”, “or-
ange peel”, and “orange jumpsuit” are just some
of many examples of sequential relations found in
the relative neighborhood of terms in the GloVe
model.
The PMI and GloVe models produce the struc-
turally most similar RNGs in these examples, with
on average a handful of direct neighbors, of which
some can be very distant. The Skipgram model
on the other hand produces very few direct neigh-
bors. This led us to look further into the struc-
tural properties of neighborhoods in the Skipgram
model. An interesting observation — and possi-
ble complication — is that the neighborhoods in
the Skipgram model are highly asymmetric: the
first neighbor of “information” is “informations”,
whereas “information” is the 1,829th neighbor of
“informations.” While such asymmetry occurs in
all models, it seems much more prevalent in the
Skipgram model. Figure 3 confirms this suspi-
cion: each point corresponds to a random word
pair (a, b) with x corresponding to where b is in
the ordered list of a’s neighbor, and y to where a
is in the ordered list of b’s neighbors. The figure
</bodyText>
<page confidence="0.91766">
2456
</page>
<table confidence="0.953185078740157">
PMI GloVe skipgram
● ● ● ● ● ● ●
● ● ● ●
●
● ● ●● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ●● ● ●● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ●● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ●
● ●● ● ● ●● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ●● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ●●
● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ●
● ●
● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●
● ● ● ● ●● ● ● ● ● ● ● ● ● ● ●● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●
● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ●● ● ● ● ● ●
● ● ● ● ● ● ● ● ●● ● ● ●
● ● ● ● ● ●
● ● ● ● ● ●
● ●● ● ● ●
● ● ● ●
● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ●● ● ● ●●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●●
● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ●
● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ●●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ●● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ●
● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ●● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ●
● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ●
● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ●●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ●●
● ●
● ●
● ● ● ●
● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ●● ● ● ● ● ●● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ●● ● ●● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ●
● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ●● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●
● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ●●
● ● ● ● ● ● ● ● ● ●● ● ●
● ● ● ● ● ● ●
● ● ● ● ●
● ● ● ● ● ●
● ● ● ●
● ● ● ●●
●
● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●● ● ● ●● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ●● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ●● ● ●
● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ●●
● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ●● ● ● ●
● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ●● ●
● ● ● ● ● ● ● ● ● ● ●● ●
● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ●
● ● ● ●
● ● ●
● ● ● ● ●
● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ●● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ●● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ●
● ● ● ● ● ● ● ● ● ● ●
● ● ● ● ●● ● ● ●
● ● ● ● ● ● ●●
● ● ●●
● ● ● ●
● ● ● ● ●●
</table>
<figure confidence="0.7309">
0 50000 100000 150000 0 50000 100000 150000 0 50000 100000 150000
</figure>
<figureCaption confidence="0.998249">
Figure 3: Neighborhood reciprocity in the different models; PMI to the left, GloVe in the middle, and
Skipgram to the right.
</figureCaption>
<figure confidence="0.99922">
150000
100000
50000
0
</figure>
<figureCaption confidence="0.732413">
Table 3: k-RNG for k = 1, 000 of the words “ser-
vice,” “bad,” and “above” in three different seman-
tic models. The numbers in parenthesis indicate
the k-NN ranks of the neighbors.
</figureCaption>
<table confidence="0.980041875">
PMI GloVe Skipgram
service
services (1) services (1) services (1)
network (2) operated (3)
operates (8) serving (6)
launched (18) military (17)
served (22) duty (20)
intercity(34) passenger (21)
dialaride (644)
aftersales (759)
limitedstop
(802)
bad
terrible (1) good (1) nauheim (1)
that (2) kissingen (2) good (2)
luck (39) ugly (45) dreadful (5)
unfortunate (70) nasty (48)
stalling (276) dirty (106)
donnersbergkreis omen (328)
(860) conkers (360)
rancid (980) karma (952)
above
below (1) below (1) below (1)
around (2) level (2) 500ft (2)
feet (5) height (3)
measuring (29) just (4)
beneath (36) stands (10)
columns (62) lower (11)
atop (102) beneath (12)
rise (21)
sea (30)
...
</table>
<bodyText confidence="0.999663571428571">
shows that the local densities vary much more in
the Skipgram model than in the others. This is not
in itself undesirable, but wild differences in neigh-
borhood reciprocity complicates the choice of k in
the k-RNG algorithm, as observed by the particu-
larly sparse neighborhoods of the Skipgram model
above.
</bodyText>
<sectionHeader confidence="0.996417" genericHeader="method">
6 WSI Evaluation
</sectionHeader>
<bodyText confidence="0.989263347826087">
The standard way to evaluate WSI algorithms is to
use one the SemEval WSI test collections (Agirre
and Soroa, 2007; Manandhar et al., 2010; Nav-
igli and Vannella, 2013; Jurgens and Klapaftis,
2013), which are all designed similarly: systems
are expected to first perform WSI and then to as-
sign texts to the induced senses (i.e. in effect do-
ing a word-sense disambiguation step). We con-
sider this type of evaluation to be a less useful
for our purposes, since the required disambigua-
tion step is a highly non-trivial task in itself. The
RNG method proposed in this paper is a pure
WSI algorithm, and as such does not offer a solu-
tion to the disambiguation problem. We therefore
opted to focus solely on the hypothesis that rel-
ative neighborhoods cover senses that k-NNs do
not. In essence, we investigate whether k-RNG
retrieval does a better job at covering different
senses than k-NN retrieval. This was done using
pseudowords.
Pseudowords are artificially ambiguous words,
created by regarding different words as identi-
cal. We can, for example, say that the pseu-
</bodyText>
<page confidence="0.98391">
2457
</page>
<figure confidence="0.959719705128205">
RNG1000
0.75
0.50
0.25
0.00
●
● ● ●
● ● ●●
●
● ●
● ● ● ●
● ● ● ● ●
● ●
● ●
● ● ● ●
●
● ●
● ●
● ● ● ●
●
●
● ●
●
●
● ●
●
●
● ● ●
● ● ●
● ●
● ●
●
● ● ●
●
●
● ● ●
● ●
●
●
● ● ● ●
● ● ● ●
● ● ●
● ● ●
● ● ●
● ● ●
● ●
● ●
● ● ● ●
● ●
● ●
●
●
● ●
PMI GloVe
●
●
●
●
●
●
●
● ●
●
●
●
●
●
● ● ●
● ● ●
● ●
● ●
● ● ● ●
● ● ●
● ●
● ● ●
●
●
● ●
</figure>
<equation confidence="0.962412652631579">
● ● ●
● ● ● ● ● ●●
● ● ● ● ● ●
● ● ●
● ●
● ● ● ●
● ● ● ●
● ● ●
● ● ●
● ● ●
● ● ● ● ●●
● ● ●
● ● ● ● ●
● ●
● ●
● ● ● ● ● ●
● ●
● ● ●
● ●
● ● ● ●
● ● ● ●
● ● ●
● ● ● ●
● ●
● ● ● ● ● ● ● ●
● ● ●
● ● ●
● ● ●
● ● ● ● ●
● ● ● ●
● ●
●
● ● ●
● ● ● ● ●
● ●
● ● ●
● ● ● ●●
● ●● ●
● ● ● ●
● ● ● ● ●
● ● ●
● ● ● ●
● ● ● ●
● ●
● ●
● ● ● ● ● ● ●
● ● ●
● ● ● ● ● ● ●
● ●
● ● ● ●
● ● ● ● ●
● ● ●
● ● ●
● ● ● ●
● ● ● ● ●
● ● ●●
● ● ● ● ●
● ● ●
● ● ●
● ● ● ● ● ● ●
● ● ● ●
● ● ●●
● ● ● ● ● ●
● ●
● ● ● ●
● ● ●
● ● ●
● ● ● ●
● ●
●
●
● ● ● ● ● ● ●
● ● ● ● ●
● ● ●
● ● ● ● ●
● ● ●
● ● ●
● ● ● ●
● ● ●
● ●
● ● ● ●
● ● ● ● ●
● ● ● ● ● ● ●
● ● ● ●
● ● ● ●
● ●
● ●
● ●
● ● ● ●
● ● ● ●
● ● ● ● ●
● ● ● ● ●
● ● ●
● ●
● ● ● ● ●
</equation>
<figure confidence="0.995580814516129">
●
● ● ●
● ●
● ● ●
● ● ●●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
●
● ●
●
●
●
● ●
● ● ● ●
●
●
●
●
● ●
●
●
●
●
Ile. -
● ● ● ● ●
● ● ●
● ●
● ●
● ● ● ● ● ●
● ● ● ● ● ● ●●
● ● ● ● ● ●
●
●
● ● ● ●●
● ● ● ● ● ●
● ●
● ● ●
● ● ● ● ● ● ●
● ● ● ● ●
● ● ● ●
● ● ● ●
● ● ●●
● ● ● ● ● ● ● ●
● ● ●
● ●
● ● ● ● ● ● ● ● ● ●
● ●
● ● ● ● ●
● ● ● ● ● ● ● ●
● ●
● ●
● ● ● ● ● ●
●
● ● ● ● ●
● ● ● ●
● ● ● ●
● ●
● ●
● ●
● ● ●
● ● ● ● ●
● ●
● ● ● ●
● ●
● ● ● ● ●
● ● ● ● ● ●
● ● ● ●
● ●
● ●
● ●
● ● ● ● ● ● ● ● ● ● ● ●
● ●
● ● ● ● ●
● ● ● ● ●
● ● ●
● ●
●
● ● ● ● ● ● ● ● ●
● ● ● ● ● ●
● ● ● ●
● ● ●
● ● ● ●
●
● ● ● ● ● ●
● ● ● ● ●
● ● ● ● ●
● ● ● ● ●
● ● ● ●● ● ● ● ● ● ●
● ●
● ● ● ● ●
● ● ● ●●
● ● ● ●
● ● ●
● ●
● ● ● ● ●
● ● ●
● ● ●
● ● ●
● ●
● ● ● ●
●
●
●
●
●
●
Skipgram
●
0.00 0.25 0.50 0.75 0.00 0.25 0.50 0.75 0.00 0.25 0.50 0.75
KNN10
</figure>
<figureCaption confidence="0.9880815">
Figure 4: Comparison of minmax pseudosense score for k-RNGs and k-NNs for k = 1, 000 and k = 10
respectively; PMI to the left, GloVe in the middle, and Skipgram to the right.
</figureCaption>
<bodyText confidence="0.999488777777778">
doword &lt;deadeye&gt; is a composite of the two
words marksman and loudspeaker. A corpus with
the artificially ambiguous word &lt;deadeye&gt; in it
can then be created by replacing all occurrences
of the words marksman and loudspeaker with
&lt;deadeye&gt;.
Using the pseudowords provided by Pilehvar
and Navigli (2013) a corpus with 689 non-
overlapping pseudowords was created, based on
the BNC corpus.7 Two models were then trained,
one on the altered corpus, and one on the unal-
tered one. To check whether the neighborhood of a
pseudoword contains information about its under-
lying senses we compared each underlying sense
to the words in the neighborhood, taking the mini-
mum of all senses’ maximum similarity as a score,
as demonstrated in Table 4. The similarities were
calculated using the model trained on the unaltered
corpus, as the one based on the altered corpus will
not contain the underlying senses of pseudowords.
Working through the example in Table 4, the
neighborhood of the pseudoword &lt;deadeye &gt;
consists of the three words shooter, stereo, and
sport. The pseudoword in itself is made up of
the two underlying senses marksman and loud-
speaker. The similarities between the words in
the neighborhood of the model trained on the unal-
</bodyText>
<footnote confidence="0.782188">
7www.natcorp.ox.ac.uk
</footnote>
<bodyText confidence="0.999592833333333">
tered data and the words of the underlying senses
are as presented in Table 4. The closest word to
marksman is shooter, with a similarity score of
0.7. The closest word to loudspeaker is stereo,
with a score of 0.3. So the scoring would, in total,
be 0.3. It should be noted that the upper bound for
this score is oftentimes significantly lower than 1:
The neighborhood could not possibly contain the
words marksman or loudspeaker, as those words
are not present in the corpus. This means that the
scores are bounded by the similarity of the least
similar closest neighbor to the underlying senses.
</bodyText>
<tableCaption confidence="0.691518">
Table 4: Example scoring of a neighborhood of
the word &lt;deadeye&gt;.
</tableCaption>
<table confidence="0.770335">
&lt;deadeye&gt; shooter stereo sport max
marksman 0.7 0.04 0.4 0.7
loudspeaker 0.01 0.3 0.05 0.3
min: 0.3
</table>
<bodyText confidence="0.997942375">
This score was chosen because of its simplic-
ity and intuitive interpretation: a low score im-
plies that at least one word sense was not repre-
sented in the neighborhood whereas a high score
means that all senses are represented in the neigh-
borhood. One can then plot these scores for both
relative neighborhoods and k-NN neighborhoods
for each pseudoword as is done in Figure 4. Each
</bodyText>
<page confidence="0.959163">
2458
</page>
<bodyText confidence="0.9726714">
point (x, y) represents a pseudoword, with x and
y being the score of the k-NN neighborhood and
the k-RNG neighborhood respectively.
Figure 5 shows an aggregate of Figure 4, plot-
ting the distribution of y−x, i.e. the difference be-
tween the scores achieved by the k-RNG and the
k-NN. As seen in Figure 4, a lot of points lie on
the line y = x, meaning both methods achieved
the same score. However, when this is not the
case, there is a clear bias for the k-RNG to out-
perform the k-NN, as demonstrated in Figure 5.
Here, using the BNC instead of Wikipedia as train-
ing data, the GloVe and Skipgram models yielded
sparse relative neighborhoods — both with an av-
erage of about 8 neighbors — but the PMI model
produced quite dense neighborhoods averaging 63
neighbors. Since the scoring function does not pe-
nalize neighborhood size there is good reason to
be skeptical of its viability, and specifically the
performance of the PMI-model based on these fig-
ures.
Figure 5: Distribution of difference between
scores for k-RNGs and k-NNs. Positive scores
means that the k-RNG scored higher than the k-
NN
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999989230769231">
This paper has discussed the question how to
query semantic models, which is a question that
has been long neglected in research on computa-
tional semantics. Nearest neighbor search (or k-
NN) is often treated as the only available option,
which leads to misunderstandings regarding how
semantic models represent and handle vagueness
and polysemy. We have argued that the structure
— or topology — of the local neighborhoods in se-
mantic models carry useful semantic information
regarding the different usages — or senses — of
a term, and that such topological properties there-
fore can be used to analyze polysemy and do WSI.
We have introduced relative neighborhood
graphs (RNG) as an alternative to standard k-NN,
and we have exemplified k-RNG in three differ-
ent well-known semantic models. The examples
demonstrate that k-RNG manages to retrieve dis-
parate and relevant neighbors in all three models,
yet the kind of neighbors returned and the nature
of the neighborhoods differ. Quantitatively, The k-
RNG method consistently outperformed k-NN on
underlying sense retrieval.
We have also illustrated how k-RNG can be
used as a tool to gain insight into the topological
properties of different models. The GloVe model,
for example, makes no difference between sequen-
tial and substitutable relations, leading to neigh-
borhoods that contain n-grams instead of senses.
This can clearly be seen in for example Table 2.
Skipgram uses more sophisticated tokenization,
which alleviates this issue.
Another interesting result of the paper is that the
RNG uncovers otherwise unseen differences be-
tween the models, which manifest not as scoring
differences but as properties of the word represen-
tations themselves. One example is the differences
in neighborhood reciprocity observed between the
different models.
</bodyText>
<sectionHeader confidence="0.999468" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998889125">
Eneko Agirre and Aitor Soroa. 2007. Semeval-2007
task 02: Evaluating word sense induction and dis-
crimination systems. In Proceedings of SemEval,
pages 7–12.
Eneko Agirre, David Martinez, Oier L´opez de Lacalle,
and Aitor Soroa. 2006. Two graph-based algo-
rithms for state-of-the-art WSD. In Proceedings of
EMNLP, pages 585–593.
Sunil Arya, David M. Mount, Nathan S. Netanyahu,
Ruth Silverman, and Angela Y. Wu. 1998. An
optimal algorithm for approximate nearest neighbor
searching fixed dimensions. Journal of the ACM,
45(6):891–923.
Jon Louis Bentley. 1975. Multidimensional binary
search trees used for associative searching. Com-
munications of the ACM, 18(9):509–517.
</reference>
<figure confidence="0.998385466666667">
●
●
●●
0.75
0.50
−0.25
RNG1000 − KNN10
0.25
0.00
PMI GloVe Upg—
id
id
PMI
GloVe
sipg.m
</figure>
<page confidence="0.977742">
2459
</page>
<reference confidence="0.999654032967033">
Peer-Timo Bremer, Ingrid Hotz, Valerio Pascucci, and
Ronald Peikert. 2014. Topological Methods in Data
Analysis and Visualization III. Springer.
Sergey Brin and Larry Page. 1998. The anatomy of a
large-scale hypertextual web search engine. In Pro-
ceedings of WWW, pages 107–117.
Samuel Brody and Mirella Lapata. 2009. Bayesian
word sense induction. In Proceedings of EACL,
pages 103–111.
Jean Cardinal, S´ebastien Collette, and Stefan Langer-
man. 2009. Empty region graphs. Computational
geometry, 42(3):183–195.
Carlos D Correa and Peter Lindstrom. 2012.
Locally-scaled spectral clustering using empty re-
gion graphs. In Proceedings of KDD, pages 1330–
1338.
Georgiana Dinu and Mirella Lapata. 2010. Measuring
distributional similarity in context. In Proceedings
of EMNLP, pages 1162–1172.
Beate Dorow and Dominic Widdows. 2003. Discover-
ing corpus-specific word senses. In Proceedings of
EACL, pages 79–82.
Katrin Erk and Sebastian Pad´o. 2010. Exemplar-based
models for word meaning in context. In Proceedings
of ACL, pages 92–97.
Piotr Indyk and Rajeev Motwani. 1998. Approximate
nearest neighbors: towards removing the curse of di-
mensionality. In Proceedings of STOC, pages 604–
613.
David Jurgens and Ioannis Klapaftis. 2013. Semeval-
2013 task 13: Word sense induction for graded and
non-graded senses. In Proceedings of SemEval,
pages 290–299.
Jussi Karlgren, Anders Holst, and Magnus Sahlgren.
2008. Filaments of meaning in word space. In Pro-
ceedings of ECIR, pages 531–538.
Maria Koptjevskaja Tamm and Magnus Sahlgren.
2014. Temperature in word space. In Benedikt
Szmrecsanyi and Bernhard W¨alchli, editors, Aggre-
gating dialectology, typology, and register analysis,
pages 231–267. De Gruyter.
Jey Han Lau, Paul Cook, Diana McCarthy, David New-
man, and Timothy Baldwin. 2012. Word sense in-
duction for novel sense detection. In Proceedings of
EACL, pages 591–601.
Suresh Manandhar, Ioannis P. Klapaftis, Dmitriy Dli-
gach, and Sameer S. Pradhan. 2010. Semeval-2010
task 14: Word sense induction &amp; disambiguation. In
Proceedings of SemEval, pages 63–68.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Proceedings of NIPS, pages 3111–3119.
Roberto Navigli and Daniele Vannella. 2013.
Semeval-2013 task 11: Word sense induction and
disambiguation within an end-user application. In
Proceedings of SemEval, pages 193–201.
Patrick Pantel and Dekang Lin. 2002. Discovering
word senses from text. In Proceedings of KDD,
pages 613–619.
Jeffrey Pennington, Richard Socher, and Christo-
pher D. Manning. 2014. GloVe: Global vectors
for word representation. In Proceedings of EMNLP,
pages 1532–1543.
Fernando Pereira, Naftali Tishby, and Lillian Lee.
1993. Distributional clustering of english words. In
Proceedings ofACL, pages 183–190.
Mohammad Taher Pilehvar and Roberto Navigli. 2013.
Paving the way to a large-scale pseudosense-
annotated dataset. In Proceedings of NAACL-HLT,
pages 1100–1109.
Diarmuid O´ S´eaghdha and Anna Korhonen. 2011.
Probabilistic models of similarity in syntactic con-
text. In Proceedings of EMNLP, pages 1047–1057.
Noriko Tomuro, Steven L. Lytinen, Kyoko Kanzaki,
and Hitoshi Isahara. 2007. Clustering using fea-
ture domain similarity to discover word senses for
adjectives. In Proceedings of ICSC, pages 370–377.
Godfried T. Toussaint. 1980. The relative neighbour-
hood graph of a finite planar set. Pattern Recogni-
tion, 12(4):261 – 268.
Tim Van de Cruys and Marianna Apidianaki. 2011.
Latent semantic word sense induction and disam-
biguation. In Proceedings of HLT, pages 1476–
1485.
Jean V´eronis. 2004. HyperLex: lexical cartography
for information retrieval. Computer Speech &amp; Lan-
guage, 18(3):223–252.
Xuchen Yao and Benjamin Van Durme. 2011. Non-
parametric bayesian word sense induction. In Pro-
ceedings of TextGraphs, pages 10–14.
</reference>
<page confidence="0.985525">
2460
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.556954">
<title confidence="0.983123666666667">Navigating the Semantic using Relative Neighborhood Graphs Amaru Cuba Gyllensten and Magnus</title>
<author confidence="0.695986">Bondegatan</author>
<phone confidence="0.816932">116 33</phone>
<abstract confidence="0.998745928571429">This paper introduces a novel way to navigate neighborhoods in distributional semantic models. The approach is based neighborhood which uncover the topological structure of local neighborhoods in semantic space. This has the potential to overcome both the problem with selecting a proper k in k-NN search, and the problem that a ranked list of neighbors may conflate several different senses. We provide both qualitative and quantitative results that support the viability of the proposed method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Semeval-2007 task 02: Evaluating word sense induction and discrimination systems.</title>
<date>2007</date>
<booktitle>In Proceedings of SemEval,</booktitle>
<pages>7--12</pages>
<contexts>
<context position="29711" citStr="Agirre and Soroa, 2007" startWordPosition="6408" endWordPosition="6411">(1) below (1) around (2) level (2) 500ft (2) feet (5) height (3) measuring (29) just (4) beneath (36) stands (10) columns (62) lower (11) atop (102) beneath (12) rise (21) sea (30) ... shows that the local densities vary much more in the Skipgram model than in the others. This is not in itself undesirable, but wild differences in neighborhood reciprocity complicates the choice of k in the k-RNG algorithm, as observed by the particularly sparse neighborhoods of the Skipgram model above. 6 WSI Evaluation The standard way to evaluate WSI algorithms is to use one the SemEval WSI test collections (Agirre and Soroa, 2007; Manandhar et al., 2010; Navigli and Vannella, 2013; Jurgens and Klapaftis, 2013), which are all designed similarly: systems are expected to first perform WSI and then to assign texts to the induced senses (i.e. in effect doing a word-sense disambiguation step). We consider this type of evaluation to be a less useful for our purposes, since the required disambiguation step is a highly non-trivial task in itself. The RNG method proposed in this paper is a pure WSI algorithm, and as such does not offer a solution to the disambiguation problem. We therefore opted to focus solely on the hypothesi</context>
</contexts>
<marker>Agirre, Soroa, 2007</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2007. Semeval-2007 task 02: Evaluating word sense induction and discrimination systems. In Proceedings of SemEval, pages 7–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>David Martinez</author>
<author>Oier L´opez de Lacalle</author>
<author>Aitor Soroa</author>
</authors>
<title>Two graph-based algorithms for state-of-the-art WSD.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>585--593</pages>
<marker>Agirre, Martinez, de Lacalle, Soroa, 2006</marker>
<rawString>Eneko Agirre, David Martinez, Oier L´opez de Lacalle, and Aitor Soroa. 2006. Two graph-based algorithms for state-of-the-art WSD. In Proceedings of EMNLP, pages 585–593.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunil Arya</author>
<author>David M Mount</author>
<author>Nathan S Netanyahu</author>
<author>Ruth Silverman</author>
<author>Angela Y Wu</author>
</authors>
<title>An optimal algorithm for approximate nearest neighbor searching fixed dimensions.</title>
<date>1998</date>
<journal>Journal of the ACM,</journal>
<volume>45</volume>
<issue>6</issue>
<contexts>
<context position="1692" citStr="Arya et al., 1998" startWordPosition="277" endWordPosition="280">, r). In k-Nearest Neighbor search (kNN), we want to find the k closest points to some given reference point. Nearest neighbor search is a well-studied task, and in particular the complexity of the task (a linear search has a running time of O(Ni) where N is the cardinality of P and i the complexity of the distance function d) has generated a lot of research; suggestions for reducing the complexity of linear nearest neighbor searches include using various types of space partitioning techniques like k-d trees (Bentley, 1975), or various techniques for doing approximate nearest neighbor search (Arya et al., 1998), of which one of the most well-known is locality-sensitive hashing (Indyk and Motwani, 1998). The problem we are concerned with in this paper is not the complexity of nearest neighbor search, but the question of how to identify the internal structure of neighborhoods defined by the nearest neighbors. The problem with a normal kNN is that the result — a sorted list of the k nearest neighbors — does not say anything about the internal structure of the neighborhood. It is quite possible for two neighborhoods with widely different internal structures to produce identical k-NN results. In the cont</context>
</contexts>
<marker>Arya, Mount, Netanyahu, Silverman, Wu, 1998</marker>
<rawString>Sunil Arya, David M. Mount, Nathan S. Netanyahu, Ruth Silverman, and Angela Y. Wu. 1998. An optimal algorithm for approximate nearest neighbor searching fixed dimensions. Journal of the ACM, 45(6):891–923.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Louis Bentley</author>
</authors>
<title>Multidimensional binary search trees used for associative searching.</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<issue>9</issue>
<contexts>
<context position="1603" citStr="Bentley, 1975" startWordPosition="265" endWordPosition="266">ion d, the nearest neighbor search task is to find the point p E P that minimizes d(p, r). In k-Nearest Neighbor search (kNN), we want to find the k closest points to some given reference point. Nearest neighbor search is a well-studied task, and in particular the complexity of the task (a linear search has a running time of O(Ni) where N is the cardinality of P and i the complexity of the distance function d) has generated a lot of research; suggestions for reducing the complexity of linear nearest neighbor searches include using various types of space partitioning techniques like k-d trees (Bentley, 1975), or various techniques for doing approximate nearest neighbor search (Arya et al., 1998), of which one of the most well-known is locality-sensitive hashing (Indyk and Motwani, 1998). The problem we are concerned with in this paper is not the complexity of nearest neighbor search, but the question of how to identify the internal structure of neighborhoods defined by the nearest neighbors. The problem with a normal kNN is that the result — a sorted list of the k nearest neighbors — does not say anything about the internal structure of the neighborhood. It is quite possible for two neighborhoods</context>
</contexts>
<marker>Bentley, 1975</marker>
<rawString>Jon Louis Bentley. 1975. Multidimensional binary search trees used for associative searching. Communications of the ACM, 18(9):509–517.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peer-Timo Bremer</author>
<author>Ingrid Hotz</author>
<author>Valerio Pascucci</author>
<author>Ronald Peikert</author>
</authors>
<date>2014</date>
<booktitle>Topological Methods in Data Analysis and Visualization III.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="15346" citStr="Bremer et al., 2014" startWordPosition="2485" endWordPosition="2488">ighbors if some region between them is empty. For Relative Neighborhood Graphs (RNG) this region between two points a and c is defined as the intersection of the two spheres with centers in a and c with radius d(a, c). In other words, a point b lies between points a and c if it is closer to both a and c than a and c are to each other. If no such point b exists, a and c are neighbors. Illustrations of this can be seen in Figure 1. Figure 1: Example of when point b is between point a and c (left), and when it is not (right). Such neighborhoods have been argued to better preserve local topology (Bremer et al., 2014), and be more robust to deformations of the data than kNN neighborhoods (Correa and Lindstrom, 2012) as they in some sense contain information about direction whereas k-NN neighborhoods only contain information about distance. Going back to the “suit” example, we can see that if “suit” in the lawsense is more similar to the composite “suit” than to its clothes-sense, and vice versa, then the composite vsuit lies between vsuitjlaw and vsuitjclothes. This in turn means that out of those two points, both are relative neighbors to “suit”, and neither of them lies between the other and “suit”. Form</context>
</contexts>
<marker>Bremer, Hotz, Pascucci, Peikert, 2014</marker>
<rawString>Peer-Timo Bremer, Ingrid Hotz, Valerio Pascucci, and Ronald Peikert. 2014. Topological Methods in Data Analysis and Visualization III. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Larry Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual web search engine.</title>
<date>1998</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>107--117</pages>
<contexts>
<context position="11580" citStr="Brin and Page, 1998" startWordPosition="1864" endWordPosition="1867">that clusters representing less frequent senses can be discovered. The idea of iteratively removing features from the distributional vector when a sense cluster as been formed is also present in Dorow and Widdows (2003), who use a graph-based clustering method. Another graph-based approach is the HyperLex algorithm (V´eronis, 2004), which constructs a graph connecting all pairs of terms that co-occur in the context of an ambiguous term. The resulting graph contains highly connected components, which represent the different senses of the term. Agirre et al. (2006) compare HyperLex to PageRank (Brin and Page, 1998) and demonstrates that the two methods perform similarly. There have also been several attempts to use various types of matrix factorization for WSI. The idea is that the factorization uncovers a set of global senses in the form of the latent factors, and that the sense distribution for a given term can be described as a distribution over these latent factors. Examples of factorization methods that have been used include different versions of Latent Dirichlet Allocation ((Brody and Lapata, 2009; S´eaghdha and Korhonen, 2011; Yao and Van Durme, 2011; Lau et al., 2012) and nonnegative matrix fac</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Larry Page. 1998. The anatomy of a large-scale hypertextual web search engine. In Proceedings of WWW, pages 107–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Mirella Lapata</author>
</authors>
<title>Bayesian word sense induction.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>103--111</pages>
<contexts>
<context position="12079" citStr="Brody and Lapata, 2009" startWordPosition="1945" endWordPosition="1948">, which represent the different senses of the term. Agirre et al. (2006) compare HyperLex to PageRank (Brin and Page, 1998) and demonstrates that the two methods perform similarly. There have also been several attempts to use various types of matrix factorization for WSI. The idea is that the factorization uncovers a set of global senses in the form of the latent factors, and that the sense distribution for a given term can be described as a distribution over these latent factors. Examples of factorization methods that have been used include different versions of Latent Dirichlet Allocation ((Brody and Lapata, 2009; S´eaghdha and Korhonen, 2011; Yao and Van Durme, 2011; Lau et al., 2012) and nonnegative matrix factorization (Dinu and Lapata, 2010; Van de Cruys and Apidianaki, 2011). Tomuro et al. (2007) argue that clustering approaches like distributional clustering or CBC may produce clusters that are themselves polysemous, which may not be a desirable property of a WSI algorithm, and suggests using feature domain similarity to solve this problem. The idea is to incorporate similarities between the features of items rather than the similarity between the items themselves in a modified version of CBC th</context>
</contexts>
<marker>Brody, Lapata, 2009</marker>
<rawString>Samuel Brody and Mirella Lapata. 2009. Bayesian word sense induction. In Proceedings of EACL, pages 103–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean Cardinal</author>
<author>S´ebastien Collette</author>
<author>Stefan Langerman</author>
</authors>
<title>Empty region graphs.</title>
<date>2009</date>
<booktitle>Computational geometry,</booktitle>
<pages>42--3</pages>
<contexts>
<context position="14705" citStr="Cardinal et al., 2009" startWordPosition="2356" endWordPosition="2359">opose the use of topological models that take the local structure of neighborhoods in semantic space into account. The approach discovers different word senses from the local structure of neighborhoods, given nothing but similarities between points. As such it is easy to test on widely different vector models, as long as there exists a well behaved similarity function. The proposed approach not only answers the question which other terms are similar to a given term, but also how are they similar. Relative neighborhoods, first proposed in (Toussaint, 1980), are examples of empty region graphs (Cardinal et al., 2009), where points are neighbors if some region between them is empty. For Relative Neighborhood Graphs (RNG) this region between two points a and c is defined as the intersection of the two spheres with centers in a and c with radius d(a, c). In other words, a point b lies between points a and c if it is closer to both a and c than a and c are to each other. If no such point b exists, a and c are neighbors. Illustrations of this can be seen in Figure 1. Figure 1: Example of when point b is between point a and c (left), and when it is not (right). Such neighborhoods have been argued to better pres</context>
</contexts>
<marker>Cardinal, Collette, Langerman, 2009</marker>
<rawString>Jean Cardinal, S´ebastien Collette, and Stefan Langerman. 2009. Empty region graphs. Computational geometry, 42(3):183–195.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos D Correa</author>
<author>Peter Lindstrom</author>
</authors>
<title>Locally-scaled spectral clustering using empty region graphs.</title>
<date>2012</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>1330--1338</pages>
<contexts>
<context position="15446" citStr="Correa and Lindstrom, 2012" startWordPosition="2502" endWordPosition="2505">ion between two points a and c is defined as the intersection of the two spheres with centers in a and c with radius d(a, c). In other words, a point b lies between points a and c if it is closer to both a and c than a and c are to each other. If no such point b exists, a and c are neighbors. Illustrations of this can be seen in Figure 1. Figure 1: Example of when point b is between point a and c (left), and when it is not (right). Such neighborhoods have been argued to better preserve local topology (Bremer et al., 2014), and be more robust to deformations of the data than kNN neighborhoods (Correa and Lindstrom, 2012) as they in some sense contain information about direction whereas k-NN neighborhoods only contain information about distance. Going back to the “suit” example, we can see that if “suit” in the lawsense is more similar to the composite “suit” than to its clothes-sense, and vice versa, then the composite vsuit lies between vsuitjlaw and vsuitjclothes. This in turn means that out of those two points, both are relative neighbors to “suit”, and neither of them lies between the other and “suit”. Formally, the set of points between two points a, c ∈ V can be characterized and computed in the followi</context>
</contexts>
<marker>Correa, Lindstrom, 2012</marker>
<rawString>Carlos D Correa and Peter Lindstrom. 2012. Locally-scaled spectral clustering using empty region graphs. In Proceedings of KDD, pages 1330– 1338.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgiana Dinu</author>
<author>Mirella Lapata</author>
</authors>
<title>Measuring distributional similarity in context.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1162--1172</pages>
<contexts>
<context position="12213" citStr="Dinu and Lapata, 2010" startWordPosition="1967" endWordPosition="1970">rates that the two methods perform similarly. There have also been several attempts to use various types of matrix factorization for WSI. The idea is that the factorization uncovers a set of global senses in the form of the latent factors, and that the sense distribution for a given term can be described as a distribution over these latent factors. Examples of factorization methods that have been used include different versions of Latent Dirichlet Allocation ((Brody and Lapata, 2009; S´eaghdha and Korhonen, 2011; Yao and Van Durme, 2011; Lau et al., 2012) and nonnegative matrix factorization (Dinu and Lapata, 2010; Van de Cruys and Apidianaki, 2011). Tomuro et al. (2007) argue that clustering approaches like distributional clustering or CBC may produce clusters that are themselves polysemous, which may not be a desirable property of a WSI algorithm, and suggests using feature domain similarity to solve this problem. The idea is to incorporate similarities between the features of items rather than the similarity between the items themselves in a modified version of CBC that enables the algorithm to utilize feature similarities, which inhibit the formation of polysemous clusters. Koptjevskaja Tamm and Sa</context>
</contexts>
<marker>Dinu, Lapata, 2010</marker>
<rawString>Georgiana Dinu and Mirella Lapata. 2010. Measuring distributional similarity in context. In Proceedings of EMNLP, pages 1162–1172.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beate Dorow</author>
<author>Dominic Widdows</author>
</authors>
<title>Discovering corpus-specific word senses.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>79--82</pages>
<contexts>
<context position="11179" citStr="Dorow and Widdows (2003)" startWordPosition="1801" endWordPosition="1805"> also removed from the distri3Weighting schemes muddles this notion quite a bit, but we think the general intuition still holds. 4In the case of cosine similarity this follows nicely from the distributive property of dot products: v = av1 + bv2, s (v, w\ —_ v·w = a(v1·w)+b(v2·w) / kvkkwk kvkkwk butional representation of the term. This last step ensures that the clusters do not become too similar, and that clusters representing less frequent senses can be discovered. The idea of iteratively removing features from the distributional vector when a sense cluster as been formed is also present in Dorow and Widdows (2003), who use a graph-based clustering method. Another graph-based approach is the HyperLex algorithm (V´eronis, 2004), which constructs a graph connecting all pairs of terms that co-occur in the context of an ambiguous term. The resulting graph contains highly connected components, which represent the different senses of the term. Agirre et al. (2006) compare HyperLex to PageRank (Brin and Page, 1998) and demonstrates that the two methods perform similarly. There have also been several attempts to use various types of matrix factorization for WSI. The idea is that the factorization uncovers a set</context>
</contexts>
<marker>Dorow, Widdows, 2003</marker>
<rawString>Beate Dorow and Dominic Widdows. 2003. Discovering corpus-specific word senses. In Proceedings of EACL, pages 79–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Exemplar-based models for word meaning in context.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>92--97</pages>
<marker>Erk, Pad´o, 2010</marker>
<rawString>Katrin Erk and Sebastian Pad´o. 2010. Exemplar-based models for word meaning in context. In Proceedings of ACL, pages 92–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Piotr Indyk</author>
<author>Rajeev Motwani</author>
</authors>
<title>Approximate nearest neighbors: towards removing the curse of dimensionality.</title>
<date>1998</date>
<booktitle>In Proceedings of STOC,</booktitle>
<pages>604--613</pages>
<contexts>
<context position="1785" citStr="Indyk and Motwani, 1998" startWordPosition="291" endWordPosition="294">given reference point. Nearest neighbor search is a well-studied task, and in particular the complexity of the task (a linear search has a running time of O(Ni) where N is the cardinality of P and i the complexity of the distance function d) has generated a lot of research; suggestions for reducing the complexity of linear nearest neighbor searches include using various types of space partitioning techniques like k-d trees (Bentley, 1975), or various techniques for doing approximate nearest neighbor search (Arya et al., 1998), of which one of the most well-known is locality-sensitive hashing (Indyk and Motwani, 1998). The problem we are concerned with in this paper is not the complexity of nearest neighbor search, but the question of how to identify the internal structure of neighborhoods defined by the nearest neighbors. The problem with a normal kNN is that the result — a sorted list of the k nearest neighbors — does not say anything about the internal structure of the neighborhood. It is quite possible for two neighborhoods with widely different internal structures to produce identical k-NN results. In the context of Distributional Semantic Models (DSMs), which collect and represent cooccurrence statis</context>
</contexts>
<marker>Indyk, Motwani, 1998</marker>
<rawString>Piotr Indyk and Rajeev Motwani. 1998. Approximate nearest neighbors: towards removing the curse of dimensionality. In Proceedings of STOC, pages 604– 613.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Jurgens</author>
<author>Ioannis Klapaftis</author>
</authors>
<title>Semeval2013 task 13: Word sense induction for graded and non-graded senses.</title>
<date>2013</date>
<booktitle>In Proceedings of SemEval,</booktitle>
<pages>290--299</pages>
<contexts>
<context position="29793" citStr="Jurgens and Klapaftis, 2013" startWordPosition="6421" endWordPosition="6424">29) just (4) beneath (36) stands (10) columns (62) lower (11) atop (102) beneath (12) rise (21) sea (30) ... shows that the local densities vary much more in the Skipgram model than in the others. This is not in itself undesirable, but wild differences in neighborhood reciprocity complicates the choice of k in the k-RNG algorithm, as observed by the particularly sparse neighborhoods of the Skipgram model above. 6 WSI Evaluation The standard way to evaluate WSI algorithms is to use one the SemEval WSI test collections (Agirre and Soroa, 2007; Manandhar et al., 2010; Navigli and Vannella, 2013; Jurgens and Klapaftis, 2013), which are all designed similarly: systems are expected to first perform WSI and then to assign texts to the induced senses (i.e. in effect doing a word-sense disambiguation step). We consider this type of evaluation to be a less useful for our purposes, since the required disambiguation step is a highly non-trivial task in itself. The RNG method proposed in this paper is a pure WSI algorithm, and as such does not offer a solution to the disambiguation problem. We therefore opted to focus solely on the hypothesis that relative neighborhoods cover senses that k-NNs do not. In essence, we inves</context>
</contexts>
<marker>Jurgens, Klapaftis, 2013</marker>
<rawString>David Jurgens and Ioannis Klapaftis. 2013. Semeval2013 task 13: Word sense induction for graded and non-graded senses. In Proceedings of SemEval, pages 290–299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jussi Karlgren</author>
<author>Anders Holst</author>
<author>Magnus Sahlgren</author>
</authors>
<title>Filaments of meaning in word space.</title>
<date>2008</date>
<booktitle>In Proceedings of ECIR,</booktitle>
<pages>531--538</pages>
<contexts>
<context position="14066" citStr="Karlgren et al., 2008" startWordPosition="2252" endWordPosition="2255">ches operate at a global level, utilizing global structural properties of the semantic spaces, e.g. by matrix factorization techniques. We believe this is as illadvised as setting a global k or radius for the nearest neighbor search, since it is the local structures that are important when analyzing nearest neighbors. Other WSI approaches use various forms of clustering techniques. However, previous studies of the intrinsic dimensionality of distributional semantic spaces using fractal dimensions indicate that neighborhoods in semantic space have a filamentary rather than clustered structure (Karlgren et al., 2008). We therefore propose the use of topological models that take the local structure of neighborhoods in semantic space into account. The approach discovers different word senses from the local structure of neighborhoods, given nothing but similarities between points. As such it is easy to test on widely different vector models, as long as there exists a well behaved similarity function. The proposed approach not only answers the question which other terms are similar to a given term, but also how are they similar. Relative neighborhoods, first proposed in (Toussaint, 1980), are examples of empt</context>
</contexts>
<marker>Karlgren, Holst, Sahlgren, 2008</marker>
<rawString>Jussi Karlgren, Anders Holst, and Magnus Sahlgren. 2008. Filaments of meaning in word space. In Proceedings of ECIR, pages 531–538.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Koptjevskaja Tamm</author>
<author>Magnus Sahlgren</author>
</authors>
<title>Temperature in word space.</title>
<date>2014</date>
<booktitle>In Benedikt Szmrecsanyi and</booktitle>
<pages>231--267</pages>
<editor>Bernhard W¨alchli, editors, Aggregating dialectology, typology, and register analysis,</editor>
<note>De Gruyter.</note>
<contexts>
<context position="12826" citStr="Tamm and Sahlgren (2014)" startWordPosition="2063" endWordPosition="2066">apata, 2010; Van de Cruys and Apidianaki, 2011). Tomuro et al. (2007) argue that clustering approaches like distributional clustering or CBC may produce clusters that are themselves polysemous, which may not be a desirable property of a WSI algorithm, and suggests using feature domain similarity to solve this problem. The idea is to incorporate similarities between the features of items rather than the similarity between the items themselves in a modified version of CBC that enables the algorithm to utilize feature similarities, which inhibit the formation of polysemous clusters. Koptjevskaja Tamm and Sahlgren (2014) also leverage on the idea of using feature similarity as the basis of sense clustering. The approach, called syntagmatically labeled partitioning, relies on a DSM that encodes sequential as well as substitutable relations. The method essentially sorts the k nearest (substitutable) neighbors according to which sequential connections they share. The resulting partitioning of the nearest distributional neighbors does not only constitute a WSI, but it 2453 also provides labels for the induced senses in the form of the sequential connections the neighbors share. 4 Neighborhood Graphs Many of the p</context>
</contexts>
<marker>Tamm, Sahlgren, 2014</marker>
<rawString>Maria Koptjevskaja Tamm and Magnus Sahlgren. 2014. Temperature in word space. In Benedikt Szmrecsanyi and Bernhard W¨alchli, editors, Aggregating dialectology, typology, and register analysis, pages 231–267. De Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jey Han Lau</author>
<author>Paul Cook</author>
<author>Diana McCarthy</author>
<author>David Newman</author>
<author>Timothy Baldwin</author>
</authors>
<title>Word sense induction for novel sense detection.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>591--601</pages>
<contexts>
<context position="12153" citStr="Lau et al., 2012" startWordPosition="1958" endWordPosition="1961">e HyperLex to PageRank (Brin and Page, 1998) and demonstrates that the two methods perform similarly. There have also been several attempts to use various types of matrix factorization for WSI. The idea is that the factorization uncovers a set of global senses in the form of the latent factors, and that the sense distribution for a given term can be described as a distribution over these latent factors. Examples of factorization methods that have been used include different versions of Latent Dirichlet Allocation ((Brody and Lapata, 2009; S´eaghdha and Korhonen, 2011; Yao and Van Durme, 2011; Lau et al., 2012) and nonnegative matrix factorization (Dinu and Lapata, 2010; Van de Cruys and Apidianaki, 2011). Tomuro et al. (2007) argue that clustering approaches like distributional clustering or CBC may produce clusters that are themselves polysemous, which may not be a desirable property of a WSI algorithm, and suggests using feature domain similarity to solve this problem. The idea is to incorporate similarities between the features of items rather than the similarity between the items themselves in a modified version of CBC that enables the algorithm to utilize feature similarities, which inhibit th</context>
</contexts>
<marker>Lau, Cook, McCarthy, Newman, Baldwin, 2012</marker>
<rawString>Jey Han Lau, Paul Cook, Diana McCarthy, David Newman, and Timothy Baldwin. 2012. Word sense induction for novel sense detection. In Proceedings of EACL, pages 591–601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suresh Manandhar</author>
<author>Ioannis P Klapaftis</author>
<author>Dmitriy Dligach</author>
<author>Sameer S Pradhan</author>
</authors>
<date>2010</date>
<booktitle>Semeval-2010 task 14: Word sense induction &amp; disambiguation. In Proceedings of SemEval,</booktitle>
<pages>63--68</pages>
<contexts>
<context position="29735" citStr="Manandhar et al., 2010" startWordPosition="6412" endWordPosition="6415"> level (2) 500ft (2) feet (5) height (3) measuring (29) just (4) beneath (36) stands (10) columns (62) lower (11) atop (102) beneath (12) rise (21) sea (30) ... shows that the local densities vary much more in the Skipgram model than in the others. This is not in itself undesirable, but wild differences in neighborhood reciprocity complicates the choice of k in the k-RNG algorithm, as observed by the particularly sparse neighborhoods of the Skipgram model above. 6 WSI Evaluation The standard way to evaluate WSI algorithms is to use one the SemEval WSI test collections (Agirre and Soroa, 2007; Manandhar et al., 2010; Navigli and Vannella, 2013; Jurgens and Klapaftis, 2013), which are all designed similarly: systems are expected to first perform WSI and then to assign texts to the induced senses (i.e. in effect doing a word-sense disambiguation step). We consider this type of evaluation to be a less useful for our purposes, since the required disambiguation step is a highly non-trivial task in itself. The RNG method proposed in this paper is a pure WSI algorithm, and as such does not offer a solution to the disambiguation problem. We therefore opted to focus solely on the hypothesis that relative neighbor</context>
</contexts>
<marker>Manandhar, Klapaftis, Dligach, Pradhan, 2010</marker>
<rawString>Suresh Manandhar, Ioannis P. Klapaftis, Dmitriy Dligach, and Sameer S. Pradhan. 2010. Semeval-2010 task 14: Word sense induction &amp; disambiguation. In Proceedings of SemEval, pages 63–68.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Proceedings of NIPS,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="5773" citStr="Mikolov et al., 2013" startWordPosition="919" endWordPosition="922">arest neighbor lists produced with three different DSMs: a standard model based on Pointwise Mutual Information (PMI)1 that has been reduced to 2,000 dimensions by applying a Gaussian random projection; GloVe, which uses regression to find distributional vectors such that their dot product approximates their log probability of co-occurring (Pennington et al., 2014); and the Skipgram model, which uses stochastic gradient descent and hierarchical softmax combined with negative sampling and subsampling to find distributional vectors that maximize the probability of observed co-occurrence events (Mikolov et al., 2013). We refer to the respective papers for details regarding the various models. The similarity measure used is the cosine similarity: s(a, b) = a·b llallllbll Table 1 lists the 10 nearest neighbors to suit in these three different DSMs using the entire Wikipedia as data. As can be expected, there are both similarities and dissimilarities between 1For observations a and b, PMI(a, b)= log p(a,b) p(a)p(b). The probabilities are often replaced in DSMs by co-occurrence counts of a and b and their respective frequency counts. Table 1: Sorted list of the nearest neighbors to “suit” in three different d</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S. Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Proceedings of NIPS, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Daniele Vannella</author>
</authors>
<title>Semeval-2013 task 11: Word sense induction and disambiguation within an end-user application.</title>
<date>2013</date>
<booktitle>In Proceedings of SemEval,</booktitle>
<pages>193--201</pages>
<contexts>
<context position="29763" citStr="Navigli and Vannella, 2013" startWordPosition="6416" endWordPosition="6420">t (5) height (3) measuring (29) just (4) beneath (36) stands (10) columns (62) lower (11) atop (102) beneath (12) rise (21) sea (30) ... shows that the local densities vary much more in the Skipgram model than in the others. This is not in itself undesirable, but wild differences in neighborhood reciprocity complicates the choice of k in the k-RNG algorithm, as observed by the particularly sparse neighborhoods of the Skipgram model above. 6 WSI Evaluation The standard way to evaluate WSI algorithms is to use one the SemEval WSI test collections (Agirre and Soroa, 2007; Manandhar et al., 2010; Navigli and Vannella, 2013; Jurgens and Klapaftis, 2013), which are all designed similarly: systems are expected to first perform WSI and then to assign texts to the induced senses (i.e. in effect doing a word-sense disambiguation step). We consider this type of evaluation to be a less useful for our purposes, since the required disambiguation step is a highly non-trivial task in itself. The RNG method proposed in this paper is a pure WSI algorithm, and as such does not offer a solution to the disambiguation problem. We therefore opted to focus solely on the hypothesis that relative neighborhoods cover senses that k-NN</context>
</contexts>
<marker>Navigli, Vannella, 2013</marker>
<rawString>Roberto Navigli and Daniele Vannella. 2013. Semeval-2013 task 11: Word sense induction and disambiguation within an end-user application. In Proceedings of SemEval, pages 193–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>613--619</pages>
<contexts>
<context position="10210" citStr="Pantel and Lin, 2002" startWordPosition="1638" endWordPosition="1642">ny other, less frequent, senses of a term. 3 Word-Sense Induction Selecting a relevant k for a given term and grouping the neighbors according to which senses they represent is an example of Word-Sense Induction (WSI). DSMs are well suited for this task, and there have been a number of different approaches suggested in the literature. One of the earliest approaches is distributional clustering (Pereira et al., 1993), which is based on a probabilistic decomposition model that uses maximum likelihood estimation to fit the model to observed data. Another example is Clustering By Committee (CBC) (Pantel and Lin, 2002), which first uses average-link clustering to recursively cluster the nearest neighbors of a term into committees, which are then used to define clusters by iteratively adding committees whose similarity to the term exceeds a certain threshold, and that is not too similar to any other added committee. For each added committee, its features are also removed from the distri3Weighting schemes muddles this notion quite a bit, but we think the general intuition still holds. 4In the case of cosine similarity this follows nicely from the distributive property of dot products: v = av1 + bv2, s (v, w\ </context>
<context position="18198" citStr="Pantel and Lin (2002)" startWordPosition="3006" endWordPosition="3009">hat is closest to c. This structure, while similar to a minimum spanning tree, differs in some crucial regards: the rnbh-tree(V, a) is rooted in a word a. The difference between rnbh-tree(V, a) and rnbh-tree(V, b) is often quite significant. Furthermore, the restricted k-rnbh-tree is monotonic in k. That property does not hold for a minimum spanning tree of a local neighborhood. 5 Examples of RNGs To get an intuition of what these neighborhoods look like we present a few examples. The words have been chosen either because they are common examples in similar work — e.g. “heart” and “suit” from Pantel and Lin (2002) — or because they represent different parts-of-speech (“above” is a preposition, “bad” is an adjective, and “service” is a noun) and disparate kinds of ambiguity (“orange” can be both a fruit and a color). Figure 2 (next page) illustrates what an RNG looks like for the term “heart” and its 100 nearest neighbors in the PMI model. Note that the root “heart” (at the mid-left in the graph) only has two relative neighbors: “cardiac” and “soul,” arguably representing a body-sense and a soulsense of the term. One advantage of using this type of structure for the neighborhood is that it enables us to</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel and Dekang Lin. 2002. Discovering word senses from text. In Proceedings of KDD, pages 613–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Pennington</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>GloVe: Global vectors for word representation.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1532--1543</pages>
<contexts>
<context position="5519" citStr="Pennington et al., 2014" startWordPosition="884" endWordPosition="887">ld be seen as a compilation step in a distributional lexicon. The result of a nearest neighbor search in a DSM is often presented as a list of (the top k) neighbors, sorted by descending similarity with the target term. Table 1 illustrates typical sorted nearest neighbor lists produced with three different DSMs: a standard model based on Pointwise Mutual Information (PMI)1 that has been reduced to 2,000 dimensions by applying a Gaussian random projection; GloVe, which uses regression to find distributional vectors such that their dot product approximates their log probability of co-occurring (Pennington et al., 2014); and the Skipgram model, which uses stochastic gradient descent and hierarchical softmax combined with negative sampling and subsampling to find distributional vectors that maximize the probability of observed co-occurrence events (Mikolov et al., 2013). We refer to the respective papers for details regarding the various models. The similarity measure used is the cosine similarity: s(a, b) = a·b llallllbll Table 1 lists the 10 nearest neighbors to suit in these three different DSMs using the entire Wikipedia as data. As can be expected, there are both similarities and dissimilarities between </context>
</contexts>
<marker>Pennington, Socher, Manning, 2014</marker>
<rawString>Jeffrey Pennington, Richard Socher, and Christopher D. Manning. 2014. GloVe: Global vectors for word representation. In Proceedings of EMNLP, pages 1532–1543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional clustering of english words.</title>
<date>1993</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>183--190</pages>
<contexts>
<context position="10008" citStr="Pereira et al., 1993" startWordPosition="1605" endWordPosition="1608">w-sense in our corpus, the kNN neighborhood of “suit” will be dominated by words pertaining to its law-sense, while the less frequent senses might not be present at all. A misguided k may thus obscure any other, less frequent, senses of a term. 3 Word-Sense Induction Selecting a relevant k for a given term and grouping the neighbors according to which senses they represent is an example of Word-Sense Induction (WSI). DSMs are well suited for this task, and there have been a number of different approaches suggested in the literature. One of the earliest approaches is distributional clustering (Pereira et al., 1993), which is based on a probabilistic decomposition model that uses maximum likelihood estimation to fit the model to observed data. Another example is Clustering By Committee (CBC) (Pantel and Lin, 2002), which first uses average-link clustering to recursively cluster the nearest neighbors of a term into committees, which are then used to define clusters by iteratively adding committees whose similarity to the term exceeds a certain threshold, and that is not too similar to any other added committee. For each added committee, its features are also removed from the distri3Weighting schemes muddl</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando Pereira, Naftali Tishby, and Lillian Lee. 1993. Distributional clustering of english words. In Proceedings ofACL, pages 183–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohammad Taher Pilehvar</author>
<author>Roberto Navigli</author>
</authors>
<title>Paving the way to a large-scale pseudosenseannotated dataset.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>1100--1109</pages>
<contexts>
<context position="32980" citStr="Pilehvar and Navigli (2013)" startWordPosition="7526" endWordPosition="7529"> ●● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● ● Skipgram ● 0.00 0.25 0.50 0.75 0.00 0.25 0.50 0.75 0.00 0.25 0.50 0.75 KNN10 Figure 4: Comparison of minmax pseudosense score for k-RNGs and k-NNs for k = 1, 000 and k = 10 respectively; PMI to the left, GloVe in the middle, and Skipgram to the right. doword &lt;deadeye&gt; is a composite of the two words marksman and loudspeaker. A corpus with the artificially ambiguous word &lt;deadeye&gt; in it can then be created by replacing all occurrences of the words marksman and loudspeaker with &lt;deadeye&gt;. Using the pseudowords provided by Pilehvar and Navigli (2013) a corpus with 689 nonoverlapping pseudowords was created, based on the BNC corpus.7 Two models were then trained, one on the altered corpus, and one on the unaltered one. To check whether the neighborhood of a pseudoword contains information about its underlying senses we compared each underlying sense to the words in the neighborhood, taking the minimum of all senses’ maximum similarity as a score, as demonstrated in Table 4. The similarities were calculated using the model trained on the unaltered corpus, as the one based on the altered corpus will not contain the underlying senses of pseud</context>
</contexts>
<marker>Pilehvar, Navigli, 2013</marker>
<rawString>Mohammad Taher Pilehvar and Roberto Navigli. 2013. Paving the way to a large-scale pseudosenseannotated dataset. In Proceedings of NAACL-HLT, pages 1100–1109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
<author>Anna Korhonen</author>
</authors>
<title>Probabilistic models of similarity in syntactic context.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1047--1057</pages>
<marker>S´eaghdha, Korhonen, 2011</marker>
<rawString>Diarmuid O´ S´eaghdha and Anna Korhonen. 2011. Probabilistic models of similarity in syntactic context. In Proceedings of EMNLP, pages 1047–1057.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noriko Tomuro</author>
<author>Steven L Lytinen</author>
<author>Kyoko Kanzaki</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Clustering using feature domain similarity to discover word senses for adjectives.</title>
<date>2007</date>
<booktitle>In Proceedings of ICSC,</booktitle>
<pages>370--377</pages>
<contexts>
<context position="12271" citStr="Tomuro et al. (2007)" startWordPosition="1977" endWordPosition="1980">so been several attempts to use various types of matrix factorization for WSI. The idea is that the factorization uncovers a set of global senses in the form of the latent factors, and that the sense distribution for a given term can be described as a distribution over these latent factors. Examples of factorization methods that have been used include different versions of Latent Dirichlet Allocation ((Brody and Lapata, 2009; S´eaghdha and Korhonen, 2011; Yao and Van Durme, 2011; Lau et al., 2012) and nonnegative matrix factorization (Dinu and Lapata, 2010; Van de Cruys and Apidianaki, 2011). Tomuro et al. (2007) argue that clustering approaches like distributional clustering or CBC may produce clusters that are themselves polysemous, which may not be a desirable property of a WSI algorithm, and suggests using feature domain similarity to solve this problem. The idea is to incorporate similarities between the features of items rather than the similarity between the items themselves in a modified version of CBC that enables the algorithm to utilize feature similarities, which inhibit the formation of polysemous clusters. Koptjevskaja Tamm and Sahlgren (2014) also leverage on the idea of using feature s</context>
</contexts>
<marker>Tomuro, Lytinen, Kanzaki, Isahara, 2007</marker>
<rawString>Noriko Tomuro, Steven L. Lytinen, Kyoko Kanzaki, and Hitoshi Isahara. 2007. Clustering using feature domain similarity to discover word senses for adjectives. In Proceedings of ICSC, pages 370–377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Godfried T Toussaint</author>
</authors>
<title>The relative neighbourhood graph of a finite planar set.</title>
<date>1980</date>
<journal>Pattern Recognition,</journal>
<volume>12</volume>
<issue>4</issue>
<pages>268</pages>
<contexts>
<context position="14644" citStr="Toussaint, 1980" startWordPosition="2347" endWordPosition="2349">ered structure (Karlgren et al., 2008). We therefore propose the use of topological models that take the local structure of neighborhoods in semantic space into account. The approach discovers different word senses from the local structure of neighborhoods, given nothing but similarities between points. As such it is easy to test on widely different vector models, as long as there exists a well behaved similarity function. The proposed approach not only answers the question which other terms are similar to a given term, but also how are they similar. Relative neighborhoods, first proposed in (Toussaint, 1980), are examples of empty region graphs (Cardinal et al., 2009), where points are neighbors if some region between them is empty. For Relative Neighborhood Graphs (RNG) this region between two points a and c is defined as the intersection of the two spheres with centers in a and c with radius d(a, c). In other words, a point b lies between points a and c if it is closer to both a and c than a and c are to each other. If no such point b exists, a and c are neighbors. Illustrations of this can be seen in Figure 1. Figure 1: Example of when point b is between point a and c (left), and when it is no</context>
</contexts>
<marker>Toussaint, 1980</marker>
<rawString>Godfried T. Toussaint. 1980. The relative neighbourhood graph of a finite planar set. Pattern Recognition, 12(4):261 – 268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Van de Cruys</author>
<author>Marianna Apidianaki</author>
</authors>
<title>Latent semantic word sense induction and disambiguation.</title>
<date>2011</date>
<booktitle>In Proceedings of HLT,</booktitle>
<pages>1476--1485</pages>
<marker>Van de Cruys, Apidianaki, 2011</marker>
<rawString>Tim Van de Cruys and Marianna Apidianaki. 2011. Latent semantic word sense induction and disambiguation. In Proceedings of HLT, pages 1476– 1485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean V´eronis</author>
</authors>
<title>HyperLex: lexical cartography for information retrieval.</title>
<date>2004</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>18</volume>
<issue>3</issue>
<marker>V´eronis, 2004</marker>
<rawString>Jean V´eronis. 2004. HyperLex: lexical cartography for information retrieval. Computer Speech &amp; Language, 18(3):223–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuchen Yao</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Nonparametric bayesian word sense induction.</title>
<date>2011</date>
<booktitle>In Proceedings of TextGraphs,</booktitle>
<pages>10--14</pages>
<marker>Yao, Van Durme, 2011</marker>
<rawString>Xuchen Yao and Benjamin Van Durme. 2011. Nonparametric bayesian word sense induction. In Proceedings of TextGraphs, pages 10–14.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>