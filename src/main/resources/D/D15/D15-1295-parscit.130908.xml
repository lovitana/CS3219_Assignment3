<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003158">
<title confidence="0.993043">
Distributed Representations for Unsupervised Semantic Role Labeling
</title>
<author confidence="0.994324">
Kristian Woodsend and Mirella Lapata
</author>
<affiliation confidence="0.9994545">
Institute for Language, Cognition and Computation
School of Informatics, University of Edinburgh
</affiliation>
<address confidence="0.991851">
10 Crichton Street, Edinburgh EH8 9AB
</address>
<email confidence="0.998662">
k.woodsend@ed.ac.uk,mlap@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.994797" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999381388888889">
We present a new approach for unsuper-
vised semantic role labeling that lever-
ages distributed representations. We in-
duce embeddings to represent a predi-
cate, its arguments and their complex in-
terdependence. Argument embeddings are
learned from surrounding contexts involv-
ing the predicate and neighboring argu-
ments, while predicate embeddings are
learned from argument contexts. The in-
duced representations are clustered into
roles using a linear programming formu-
lation of hierarchical clustering, where
we can model task-specific knowledge.
Experiments show improved performance
over previous unsupervised semantic role
labeling approaches and other distributed
word representation models.
</bodyText>
<sectionHeader confidence="0.998791" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999333904761905">
In recent years, an increasing body of work has
been devoted to learning distributed word repre-
sentations and their successful usage in numerous
tasks and real-world applications. Examples in-
clude language modeling (Collobert et al., 2011;
Mikolov et al., 2013c; Mnih and Kavukcuoglu,
2013), paraphrase detection (Socher et al., 2011a),
sentiment analysis (Socher et al., 2011b; Kalch-
brenner et al., 2014), and most notably machine
translation (Kalchbrenner and Blunsom, 2013;
Cho et al., 2014; Auli et al., 2013). Distributed
word representations (also known as word embed-
dings) are trained by predicting the contexts in
which the words or phrases occur.
In this paper, we present a new approach for
unsupervised semantic role labeling that leverages
distributed representations. The goal of semantic
role labeling is to discover the relations that hold
between a predicate and its arguments in a given
input sentence (e.g., “who” did “what” to “whom”,
“when”, “where”, and “how”).
</bodyText>
<listItem confidence="0.994151">
1. [The burglar]A0 [broke]V [the window]A1.
2. [The window]A1 [broke]V.
</listItem>
<bodyText confidence="0.999978944444444">
In sentence (1), A0 represents the Agent of the
breaking event, A1 represents the Patient (i.e., the
physical object affected by the breaking event)
and V determines the boundaries of the predicate.
The semantic roles in the example are labeled
in the style of PropBank (Palmer et al., 2005),
a broad-coverage human-annotated corpus of se-
mantic roles and their syntactic realizations. In the
unsupervised case, the model must induce such la-
bels from data without access to a predefined set of
semantic roles.
Role induction is commonly treated as a cluster-
ing problem (Titov and Klementiev, 2012; Lang
and Lapata, 2014). The input to the model are
instances of arguments (e.g., window, the burglar
in sentence (1)) and the output is a grouping of
these instances into clusters such that each cluster
contains arguments corresponding to a specific se-
mantic role and each role corresponds to exactly
one cluster. In other words, the syntactic repre-
sentations of verbal predicates, and argument po-
sitions are observable, whereas the associated se-
mantic roles are latent and need to be inferred.
The task is challenging due to its unsupervised
nature — it is difficult to define a learning objec-
tive function whose optimization will yield an ac-
curate model — but also because each predicate
can allow several alternate mappings or linkings
between its semantic roles and their syntactic real-
ization. Despite occupying different syntactic po-
sitions (subject in sentence (1) and object in sen-
tence (2)), the noun phrase the window expresses
the same role in both sentences. To learn such
linkings, previous work has made use of syntac-
tic and semantic features (e.g., whether two argu-
ments are in the same position in the parse tree,
</bodyText>
<page confidence="0.938432">
2482
</page>
<note confidence="0.9846665">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2482–2491,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999924413793103">
whether they have the same POS-tags, whether
they are lexically similar). These features are typ-
ically defined on argument instances, without tak-
ing the predicate into account, and do not interact
but instead are sequentially applied.
In this work we propose to learn these features
and their complex interactions (e.g., selectional
restrictions) automatically from data. Specifi-
cally, we induce embeddings to represent a pred-
icate and its arguments. Argument embeddings
are learned from surrounding contexts involving
the predicate and neighboring arguments. Anal-
ogously, predicate embeddings are learned from
contexts representing their arguments. Our model
learns a rich feature space which can serve as input
to any clustering algorithm. We use a linear pro-
gramming formulation of hierarchical clustering
which is advantageous for two reasons. Firstly, ex-
pressing clustering as a global optimization prob-
lem with an explicit objective function can po-
tentially yield higher quality output compared to
greedy algorithms (such as agglomerative cluster-
ing). Secondly, through the use of constraints, we
can model task-specific knowledge (e.g., seman-
tic roles are unique within a frame). Experimen-
tal results show improved performance over both
previous unsupervised semantic role labeling ap-
proaches and other distributed word representation
models.
</bodyText>
<sectionHeader confidence="0.999796" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999780478873239">
Our model is inspired by recent work in learning
distributed representations of words (Bengio et al.,
2006; Mnih and Hinton, 2008; Collobert et al.,
2011; Turian et al., 2010; Mikolov et al., 2013a).
In this framework, a neural network is used to pre-
dict a word taking into account its context. Words
are represented by vectors which are concatenated
or averaged in order to form a representation of the
context. We induce vector representations to rep-
resent each predicate and its argument. As a learn-
ing objective, vectors are required to contribute
to a prediction task about the target argument in
the sentence, given the predicate and a small win-
dow of surrounding arguments. Similarly, predi-
cate vectors are learned from the contexts of pre-
ceding arguments, and are required to contribute
to the prediction of upcoming arguments. Our
vectors encode the semantics of arguments, predi-
cates, and their interdependence.
Approaches to unsupervised semantic role la-
beling follow two main modeling paradigms. Un-
der the the first variant, semantic roles are mod-
eled as latent variables in a (directed) graphical
model that relates a verb, its semantic roles, and
their possible syntactic realizations (Grenager and
Manning, 2006; Lang and Lapata, 2010; Garg
and Henderson, 2012). Role induction here corre-
sponds to inferring the state of the latent variables
representing the semantic roles of arguments. The
second approach is similarity-driven and based
on clustering. For instance, Lang and Lapata
(2014) induce semantic roles via graph partition-
ing: each vertex in a graph corresponds to an ar-
gument instance of a predicate and edges repre-
sent features expressing syntactic or semantic sim-
ilarity. The graph partitioning problem is solved
using task-specific adaptations of label propaga-
tion and agglomerative clustering. Titov and Kle-
mentiev (2012) propose a Bayesian clustering al-
gorithm based on the Chinese Restaurant Pro-
cess. Their model encourages similar verbs to
have similar linking preferences using a distance-
dependent Chinese Restaurant Process prior.
More recently, Titov and Khoddam (2015) pro-
pose a reconstruction-error minimization framer-
work for unsupervised semantic role induction.
Their model consists of two componenets: the
encoder (implemented as a log-linear model)
predicts roles given syntactic and lexical fea-
tures, whereas the reconstruction component (im-
plemented as a probabilistic tensor factorization
model) recovers argument fillers based on the role
predictions, the predicate and other arguments.
The two components are estimated jointly to min-
imize errors in argument reconstruction.
Our work follows the similarity-driven model-
ing paradigm. Rather than engineering relevant
features, we learn them using a neural network and
a task-appropriate training objective. We are thus
able to model complex interactions between argu-
ments and their predicates without making simpli-
fying assumptions (e.g., that arguments are condi-
tionally independent of each other given the pred-
icate). Our embeddings are largely independent of
the clustering algorithm used to induce the seman-
tic roles. We advocate the use of linear program-
ming, which supports the incorporation of linguis-
tic and structural constraints during cluster forma-
tion. ILP techniques have been previously applied
to several supervised NLP tasks, including seman-
tic role labeling (Punyakanok et al., 2008), how-
</bodyText>
<page confidence="0.992048">
2483
</page>
<figureCaption confidence="0.998804">
Figure 1: Symmetric context window from the list of arguments
</figureCaption>
<figure confidence="0.631674833333333">
START Yesterday Kristina hit Scott with a baseball END
a1 a2 a3 predicate a4 a5 a6 Identification
argt−1 argt argt+1 Window 1
argt−1 argt argt+1 Window 2
argt−1 argt argt+1 Window 3
argt−1 argt argt+1 Window 4
</figure>
<bodyText confidence="0.88885">
ever their application to unsupervised role induc-
tion is novel to our knowledge.
</bodyText>
<sectionHeader confidence="0.994645" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.999574882352941">
Unsupervised role induction is commonly mod-
eled after supervised semantic role labeling
(M`arquez et al., 2008) and follows a two-stage ap-
proach. Given a sentence and a designated verb,
the goal is to identify the arguments of the verbal
predicate (argument identification) and label them
with semantic roles (role induction). The model
is first given a syntactically analyzed sentence
(e.g., in the form of a dependency parse) with the
aim of determining all constitutents that fill a se-
mantic role. Argument identification is performed
heuristically using a small number of rules which
take into account syntactic relations encountered
when traversing the dependency tree from predi-
cate to argument (Lang and Lapata, 2014; Titov
and Klementiev, 2012). An alternative which we
follow here is to use a supervised classifier trained
on a small amount of data using non-lexicalized
features.
As mentioned earlier, we treat role induction
as a type-level clustering problem: argument in-
stances are assigned to clusters such that these rep-
resent semantic roles. We induce a separate set of
clusters for each verb, and each cluster thus repre-
sents a verb-specific role. Clustering algorithms
commonly take a matrix of pairwise similarity
scores between instances as input and produce a
set of output clusters, often satisfying some op-
timality criterion. In our case, instances are type-
level arguments represented by embeddings whose
similarity is quantified using a distance measure
such as cosine (see Section 3.1) and clusters are
formed using a linear programming formulation of
hierarchical clustering (see Section 3.2).
</bodyText>
<subsectionHeader confidence="0.998396">
3.1 Predicate and Argument Embeddings
</subsectionHeader>
<bodyText confidence="0.999930333333333">
Our approach for learning predicate and argu-
ment vectors is inspired by recent methods aimed
at learning high-quality vector representations of
words from large amounts of unstructured text
data (Mikolov et al., 2013a). In this framework,
vectors of the surrounding words within a fixed-
sized window (the context) are summed into a sin-
gle vector vc, which is useful in predicting the
output vector v0 representing the current or target
word. Longer-range context information can also
be captured (Le and Mikolov, 2014), specifically
words within the current paragraph but outside of
the target word context window.
In contrast to previous word-based approaches,
our model induces vector representations for each
predicate and its semantic arguments. As a learn-
ing objective, vectors are required to contribute
to a prediction task about the target argument in
the sentence, given the predicate and a small win-
dow of surrounding arguments. So despite the fact
that the argument vectors and weightings are ini-
tialized randomly, they can eventually capture se-
mantics as an indirect result of the prediction task.
Similarly, predicate vectors are learned from the
many contexts sampled from sentences involving
that predicate, and are required to contribute to the
prediction task of the next argument. One way to
consider the role of the predicate token is as an-
other argument. It acts as a memory (similar to
the paragraph memory of Le and Mikolov, 2014)
that remembers what is missing from the current
context, and so captures something of the core na-
ture of the predicate.
Figure 1 illustrates our approach for building
the context, for the example sentence Yesterday,
Kristina hit Scott with a baseball. As a prepro-
cessing step, (verbal) predicates and arguments are
identified based on a dependency parse, to give a
full list of arguments for the sentence. Boxes show
</bodyText>
<page confidence="0.950272">
2484
</page>
<bodyText confidence="0.999991153846154">
the span of each argument. In our model, contexts
are symmetric and of fixed length (c = 1 in the
Figure), sampled from a sliding window over the
argument list. To enable the first and last argu-
ments within the sentence to be predicted from the
context, we augment the argument list with START
and END arguments. Meanwhile, the predicate
is associated with all contexts generated from the
sliding window approach.
More formally, given a training set compris-
ing a predicate b and a sequence of its semantic
arguments a1, a2, a3,..., aT, the objective of the
model is to maximize the average log probability:
</bodyText>
<equation confidence="0.932003">
log p(at|b, at+j, −c ≤ j ≤ c, j =6 0) (1)
</equation>
<bodyText confidence="0.999836333333333">
where c is the size of the training context around
the center argument at. We define probability us-
ing the softmax function:
</bodyText>
<equation confidence="0.9972765">
T
P (at b, acontext) °` eXP (vc v0) (2)
</equation>
<bodyText confidence="0.999982064516129">
where v0 is the target argument vector and vc the
context vector formed from predicate and con-
text arguments vectors. Vectors are trained using
stochastic gradient descent where the gradient is
obtained via back-propagation. After the training
converges, predicates and arguments with similar
meaning are mapped to a similar position in the
vector space.
Every predicate is mapped to a unique vec-
tor vpred, with the vocabulary of vectors shared
across the data set. For the arguments, we generate
feature vectors f−1 and f+1 from syntactic infor-
mation (dependency relations and POS-tags), con-
catenated with a distributional vector to represent
the head word token in each argument. The repre-
sentation vectors v−1 and v+1 are calculated from
the feature vectors using vj = Wcontextfj, where
the matrix Wcontext is also updated as part of the
learning process. Wcontext is common for all ar-
guments. In a similar manner, the representation
vector v0 for the target argument is calculated us-
ing v0 = Wargumentf0. The predicate and argument
vectors are concatenated to predict the middle ar-
gument in a context. Other ways of dividing the
argument window between context and predicted
argument, and of combining context vectors, are
possible. As the full list of arguments in a sentence
is known, we use a symmetric window. The ad-
vantage of concatenating the vectors is that infor-
mation on the sequence of arguments is preserved.
An illustration of our model is given in Figure 2.
</bodyText>
<figure confidence="0.363504">
argt−1 argt argt+1 predicate
</figure>
<figureCaption confidence="0.8347055">
Figure 2: Distributional model for learning repre-
sentations of predicates and semantic arguments.
</figureCaption>
<bodyText confidence="0.99998475">
Through a context window of arguments rather
than neighboring tokens, our model captures a
semantic representation of each verbal predicate.
Furthermore, the arguments themselves are posi-
tioned in vector space as a result of the selectional
preferences of the predicates. In the next section,
we use the induced semantic space to cluster argu-
ments into semantic roles.
</bodyText>
<subsectionHeader confidence="0.999773">
3.2 Argument Clustering
</subsectionHeader>
<bodyText confidence="0.999961956521739">
Hierarchical clustering is a method of clustering
which seeks to build a hierarchy of clusters, often
presented in a dendrogram. In such a represen-
tation, all possible pairs of clusters are merged at
some level. It is typically implemented as a greedy
heuristic algorithm with no explicit objective func-
tion. Instead, it requires a measure of dissimilar-
ity between sets of observations, typically through
a measure of distance between pairs of observa-
tions. An example is the agglomerative clustering
technique used in Lang and Lapata (2014). Their
algorithm starts from seed clusters based on shared
syntactic information, and then repeatedly merges
pairs of clusters “bottom up” to form a hierarchy.
It is possible to formalize hierarchical clustering
as an integer linear programming (ILP) problem
with the dendrogram properties enforced as linear
constraints (Gilpin et al., 2013). Although exact
solvers exists for ILP, their performance is highly
dependent on the number of variables involved,
and we found it necessary to develop a linear pro-
gramming (LP) relaxation to provide approximate
solutions faster. Dynamic programming is an al-
</bodyText>
<figure confidence="0.99543012">
Context
features
×Wcontext
×Wcontext
Context
representation
v−1
Concatentation
v0
Target
representation
×Wargument
Target
features
f0
v+1
vpred
vc
f−1
f+1
1
T
T
∑
t=1
</figure>
<page confidence="0.977074">
2485
</page>
<bodyText confidence="0.999662956521739">
ternative approximation technique that could be
explored; it has recently been used successfully
in the context of supervised semantic role labeling
(T¨ackstr¨om et al., 2015).
But first, we consider the exact formalization
of agglomerative clustering as an ILP. In order to
generate a legal dendrogram, it is necessary for the
model to enforce the following partition proper-
ties:
Reflexivity A seed cluster is always in the same
merged cluster as itself.
Symmetry If seed cluster a is merged into the
same cluster as seed cluster b, then b is also
in the same cluster as a.
Transitivity If a and b are merged at a certain
level, and b and c are also merged at the same
level, then a is in the same cluster as c at that
level.
To model hierarchical clustering as an ILP prob-
lem, we consider all pairs of clusters a and b,
and introduce variables Mab to represent the merge
level between clusters a and b. Reflexivity is en-
forced by the constraint:
</bodyText>
<equation confidence="0.950944">
Maa = 0, (3)
</equation>
<bodyText confidence="0.739119">
Meanwhile the symmetry requirement is captured
by the constraint:
</bodyText>
<equation confidence="0.959368">
Mab = Mba. (4)
</equation>
<bodyText confidence="0.999977">
The transitivity requirement and the objective to
find the hierarchy that minimizes pair-wise dis-
tances are modeled in the objective of the ILP
using auxiliary variables Oabc that represent the
merge order of pairs (a,b) and (a,c), and coeffi-
cients wabc that are set equal to the difference be-
tween distance metrics D between those pairs:
</bodyText>
<equation confidence="0.955344111111111">
argmax E wabcOabc
M , O a,b,c∈Instances
subject to:
Mab is a merge function
�
1 if Mab &lt; Mac
Oabc =
0 otherwise
wabc = D(a,c) −D(a,b).
</equation>
<bodyText confidence="0.999924692307692">
Although exact solutions can be found using ILP
solvers, for the problems we consider there are
typically over 100 seed clusters. This generates
in the order of 106 transitivity constraints, and it is
this in particular that results in combinatorial com-
plexity from off-the-shelf ILP solvers.
An LP relaxation provides approximate solu-
tions faster. A maximum merge level L is first de-
fined as a parameter, although as this is not an inte-
ger problem and fractional levels are possible, this
does not represent the number of levels. Auxiliary
variables Zab≥ac capture the merge hierarchy, and
Tabc rewards transitivity by a factor a:
</bodyText>
<equation confidence="0.982811181818182">
arg max E wabcOabc + aTabc
M , O,Za b,c∈Instances
subject to:
0 ≤ T ≤ 1
0 ≤ O ≤ 1
0 ≤ Z ≤ 1 (5)
0 ≤ M ≤ L
−L ≤ Mac −Mab − (L+ 1)Oabc ≤ 0
−L ≤ Mab −Mac −(L+1)Zab≥ac +1 ≤ 0
−L ≤ Mbc −Mac −(L+1)Zbc≥ac +1 ≤ 0
Zab≥ac + Zbc≥ac ≥ Tabc
</equation>
<bodyText confidence="0.999911454545454">
To capture the linguistic principles involved in
semantic role labeling (Lang and Lapata, 2014),
our formulation includes additional constraints.
These are expressed explicitly through the con-
struction of the linear programme:
Role Uniqueness Semantic roles are unique
within a particular frame. This principle is cap-
tured by constraining the merge level of two seed
clusters a and b to be at the top level L of the hi-
erarchy, where a and b are roles that occur within
the same frame, with the constraint:
</bodyText>
<equation confidence="0.986174">
Mab = L ∀(a,b) in frame. (6)
</equation>
<bodyText confidence="0.997310416666667">
Syntactic Position Arguments occurring in a
specific syntactic position within a specific link-
ing all bear the same semantic role. This is han-
dled by construction of the problem, where all ar-
guments of a particular predicate occurring in a
specific syntactic position are collected into a seed
cluster at the beginning of the merging problem.
Argument Head Distribution The distribution
over argument heads is the same for two clusters
that represent the same semantic role. The distri-
bution of arguments is captured in vector space by
the model described in Section 3.1. We calculate
</bodyText>
<page confidence="0.941664">
2486
</page>
<bodyText confidence="0.999296">
centroid vectors from the instances in each clus-
ter. To measure similarity between clusters a and
b, we use cosine similarity between centroids:
</bodyText>
<equation confidence="0.8816695">
vTa vb
D(a,b) = (7)
IvaIIvbI
Equations (3)–(7) comprise the LP model.
</equation>
<sectionHeader confidence="0.99888" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9999756">
In this section we present our experimental setup
for assessing the performance of the model pre-
sented above. We explain how it was trained and
tested, and also briefly introduce the models used
for comparison with our approach.
</bodyText>
<subsectionHeader confidence="0.956826">
4.1 Training
</subsectionHeader>
<bodyText confidence="0.999990333333333">
To obtain distributed representations, we used text
from a subset of the English Gigaword corpus
(Parker et al., 2011), comprising almost 64 mil-
lion tokens (2.7 million sentences). The training
corpus was pre-processed using MATE (Bj¨orkelund
et al., 2009) to lemmatize the words, provide
POS-tags and a dependency parse, identify verbal
predicates and the position of arguments.
The neural network model described in Sec-
tion 3.1 was trained using Matlab. We restricted
the predicate vocabulary to use the 5,000 most fre-
quent verbs in the training corpus, and the verbal
predicates found in the CoNLL-2008 shared task
data set (Surdeanu et al., 2008). Predicates were
represented as vectors of size 80, while vectors
of length 50 were used for arguments. We used
a symmetric context window of size c = 1. As
the mechanism to prevent all vectors from hav-
ing the same value, we used “negative-sampling”
(Mikolov et al., 2013b), where there are k = 5 ran-
domly sampled negative examples of (context, tar-
get) pairs for each data sample. This technique
has the advantage that we do not need to provide
numerical probabilities for the noise distribution.
Model parameters were updated during training
using stochastic gradient descent over 5 epochs,
decreasing the update step size at each epoch.
</bodyText>
<subsectionHeader confidence="0.995632">
4.2 Argument clustering
</subsectionHeader>
<bodyText confidence="0.9999763">
Following common practice in unsupervised role
induction (Titov and Klementiev, 2012; Lang and
Lapata, 2014), we evaluated our model on the
complete CoNLL-2008 shared task data set. We
used the clustering metrics of purity, collocation
and their harmonic mean F1. In addition, we used
V-measure (Rosenberg and Hirschberg, 2007), an
entropy-based measure which explicitly evaluates
how successfully the criteria of homogeneity and
completeness have been satisfied.
In previous work on unsupervised role induc-
tion, the results for each predicate were weighted
in proportion to the number of times the predicate
appeared in the CoNLL-2008 test set. In addi-
tion to this measure, we evaluate clustering where
predicates are uniformly weighted. In a data set
where the top 10 predicates account for almost
20% of the samples, these metrics give a view
of performance on the other 3,000-plus predicates
where less predicate-specific data is available.
</bodyText>
<subsectionHeader confidence="0.989227">
4.3 Comparison Models
</subsectionHeader>
<bodyText confidence="0.999952875">
We compared our model against a baseline that
assigns arguments to clusters based on their syn-
tactic functions (SYNTF; Lang and Lapata, 2014).
Specifically, the baseline forms clusters from the
syntactic position of an argument using four cues:
the verb’s voice, the argument’s position relative
to the predicate, its syntactic relation, and any re-
alizing preposition.1
To assess whether our argument-based model
has any advantages over other word-based dis-
tributed representations we compared the follow-
ing variants: (a) the arg2vec model presented in
Section 3.1 trained on the subset of Gigaword;
(b) the continuous bag-of-words model trained
using word2vec on the same Gigaword corpus;
and (c) 300–dimensional vectors pre-trained on
part of the Google News dataset2 (about 100
billion words), again using word2vec. In all
three instances, we performed argument cluster-
ing using the LP of Section 3.2. We also com-
pare against Agglomerative-cosine (AGGLOM),
the best performing model of Lang and Lapata
(2014).3 Where applicable, we also refer to the
models presented in Titov and Klementiev (2012).
</bodyText>
<sectionHeader confidence="0.999918" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.715897714285714">
Our results on the semantic role induction task are
summarized in Tables 1 and 2. Table 1 presents
results using the gold standard parses and argu-
1Differences in the results compared to Lang and Lapata
(2014) are due to our re-implementation of the predicate la-
beling stage, to be consistent with the preprocessing we used
for the other comparison systems.
</bodyText>
<footnote confidence="0.985292">
2http://code.google.com/p/word2vec/
3Differences from published results are again due to
changes at the predicate labeling stage.
</footnote>
<page confidence="0.970134">
2487
</page>
<table confidence="0.996655142857143">
Weighted Unweighted Weighted Unweighted
PU CO F1 PU CO F1 HO CO V1 HO CO V1
SYNTF 81.6 78.1 79.8 90.0 86.8 87.8 71.7 66.2 68.8 85.5 81.7 82.1
AGGLOM 87.4 75.3 80.9 95.1 80.7 86.5 79.2 65.5 71.7 93.1 78.1 84.0
word2vec-GIGAWORD 82.8 77.9 80.3 91.4 86.3 88.2 78.8 63.7 70.4 90.2 81.1 84.4
word2vec-GOOGLENEWS 83.4 76.2 79.7 91.6 85.7 87.9 78.7 63.7 70.4 90.2 80.7 84.1
arg2vec-GIGAWORD 87.9 74.7 80.8 94.2 85.4 88.9 86.1 64.6 73.8 94.6 80.9 86.2
</table>
<tableCaption confidence="0.9722885">
Table 1: Purity, collocation and F1 measures (left), and homogeneity, completeness and V1 measures
(right) for CoNLL-2008 data set, using gold syntax information.
</tableCaption>
<table confidence="0.9998405">
Weighted Unweighted Weighted Unweighted
PU CO F1 PU CO F1 HO CO V1 HO CO V1
SYNTF 68.3 72.1 70.1 80.6 81.3 80.3 55.2 54.9 55.0 74.4 74.3 73.2
AGGLOM 75.5 69.5 72.4 89.3 77.9 82.4 64.9 55.7 60.0 86.1 74.6 78.8
DEPREL+MATE 81.4 77.7 79.5 88.7 84.8 86.2 71.5 65.7 68.5 83.7 79.2 80.3
word2vec-GIGAWORD 83.3 76.1 79.5 91.3 85.7 87.8 78.4 63.4 70.1 89.9 80.3 83.9
word2vec-GOOGLENEWS 82.9 77.4 80.1 91.3 86.0 88.0 78.3 63.6 70.2 89.9 80.9 84.2
arg2vec-GIGAWORD 87.7 74.6 80.6 93.9 85.3 88.8 85.7 64.4 73.5 94.4 80.8 86.1
</table>
<tableCaption confidence="0.9955695">
Table 2: Purity, collocation and F1 measures, and homogeneity, completeness and V1 measures for
CoNLL-2008 data set using automatic parse syntax information.
</tableCaption>
<bodyText confidence="0.99972940625">
ments available in the CoNLL 2008 data set. No-
tice that our embeddings are still learned using au-
tomatically identified arguments. Table 2 uses au-
tomatic parses with automatically identified argu-
ments which is a more realistic evaluation setting.
As can be seen in Table 1, when gold standard
information is used the syntactic function baseline
(SYNTF) is very effective. When considering F1
(weighted by the number of instances), arg2vec
performs on the same par with graph-based ag-
glomerative clustering (AGGLOM). Interestingly,
word2vec performs worse when trained either
on Gigaword or the Google News corpora. Ac-
cording to (weighted) V1, arg2vec outperforms
all other comparison models. When predicates
are weighted uniformly, arg2vec is the best per-
forming model using F1 or the more information-
centric V-measure. This suggests that our model
performs well on the the less-frequent predicates
and rarer semantic roles. The results also show
that our model captures semantic information use-
ful for this task more successfully than the word-
based distributional models. Both word2vec mod-
els have similar performance, despite significant
differences in the size of their training data.
Table 2 shows similar trends. The poorer per-
formance of SYNTF and AGGLOM can partly be
ascribed to the heuristics used for argument iden-
tification: DEPREL+MATE gives the baseline per-
formance of our dependency parser and argu-
ment identification. Nevertheless, when compar-
ing systems that have access to the same prepro-
cessing, our arg2vec model gives the best per-
formance particularly in the information-centric
V-measures. Also note, that it seems robust to
noise incurred by the automatic parsing and argu-
ment identification procedures.
Titov and Klementiev (2012) report a
(weighted) F1 of 83.0 on the gold standard
CoNLL-2008 dataset, using a coupled model
where parameters are shared across verbs and
a form of smoothing which replaces argument
fillers by lexical cluster ids stemming from
Brown et al.’s (1992) algorithm (trained on the
RCV1 corpus, about 63 millions words). Our
model would presumably benefit from a similar
coupling mechanism which we could enforce as
a constraint in the ILP. However, we leave this to
future work. When tested on automatic parses and
gold arguments, their model yields a weighted
F1 of 78.8. For comparison, arg2vec obtains an
F1 of 80.6 on automatic parses and arguments.
Figure 4 shows visualizations of the argument
semantic space as captured by the arg2vec-
GIGAWORD model, for the predicates eat and
win. Dimensionality reduction was performed by
the t-SNE library.4 The visualization suggests
that the model learns similarities beyond simple
word contexts.
The evaluation presented so far assesses the
quality of the argument representations learned
by our model. We also wanted to see whether
the predicate embeddings capture meaningful se-
mantic content. Figure 3 shows a visualization
</bodyText>
<footnote confidence="0.968604">
4http://lvdmaaten.github.io/tsne/
</footnote>
<page confidence="0.991736">
2488
</page>
<figure confidence="0.999911">
reflect
cause
mean
require
acquire
help
seek
offer buy
receive
−15
file
sell
pay
lead
need
propose
follow
try
win
give
trade
agree
plan
ask
want
put
bring
yield
price
close
do
change
meet
tell
find
work
go
call
end
gain
get
expect
hold
move
run
add
see
turn
note
have
leave
announce
decline
rise
come
drop
fall
become
remain
appear
show
seem
continue
increase
grow
believe
think
begin
start
$
youth
effect
other
mushroom
ketchup
lunch
overtime
cash
sales
one
profit
sandwich
pizza
bread sugar
bowl
market
debt
american
rat
the things
art jurisprudence
apple
character
chunk
somebody
people e
animal it
nterprise
program
anyone
she
pentagon
cheerio
cost
diabetic
we
they
i you
husband
giant
him
series
we congress
candidate
they
i industry
support
one
board
election
battle
$ concession
right
account
endorsement
contract
seat
can
group
license
party
majority
confidence
four
race
order
0 business prize
100 confirmation
150
approvalverdict clearance
union
company ibm recently
issue
share
month
victory
case
pennant
%
back he
finally
taylor
them
it official
fujitsu plc
team
administration
archrival
then
</figure>
<figureCaption confidence="0.9850782">
Figure 4: 2-D representation of the induced argu-
ment space for the predicates eat (top) and win
(bottom). In both representations, A0 arguments
are clustered bottom left, while A1 arguments are
found top right.
</figureCaption>
<figure confidence="0.999763037037037">
use
build
develop
operate
name
involve
create
produce
provide
represent
allow
own
look set lose
reach
make
know
raise
spend
estimate
say
consider
take
keep
cut
reduce
include
base
</figure>
<figureCaption confidence="0.998436">
Figure 3: 2-D representation of the induced predi-
</figureCaption>
<bodyText confidence="0.98953952173913">
200 00
cate space for the 100 most frequent predicates in
CoNLL-2008.
of the predicate semantic space as captured by
arg2vec when it is trained on the Gigaword cor-
pus. It shows a projection of the 100 most frequent
verbs in CoNLL-2008, with dimensionality reduc-
tion again performed by t-SNE. The visualization
suggests that the model captures non-trivial predi-
cate similarities. Verbs relating to buying and sell-
ing lie close together (e.g., offer, buy, receive, pay,
sell). Verbs denoting growth or decrease are also
grouped together (drop, fall, increase, grow, re-
duce, cut). Interestingly, verbs with similar argu-
ment structure share regions of the space (e.g., say,
estimate, or believe, think or seem, appear). Use-
fully, verbs are represented in a continuous space
rather than discrete clusters (e.g., acquire is some-
where between buy and own).
In order to quantitatively evaluate the qual-
ity of the predicate representations induced by
our model, we compared the cosine distances
between vectors to the hierarchy of VerbNet
(Schuler, 2005). VerbNet is a hierarchical domain-
independent broad-coverage verb lexicon for En-
glish, organizing verbs into classes. The evalua-
tion task was, for all pairs of predicates, to predict
whether they would be in the same cluster at the
0 0
top layer of the hierarchy of VerbNet. To form
the top layer of VerbNet, we took the first inte-
ger of each VerbNet class number. As an exam-
ple, the verbs believe (VN class conjecture-29.5),
think (consider-29.9), expect (conjecture-29.5-1),
and adopt (appoint-29.1) would all be in the same
class 29. According to this reduction of VerbNet,
there are 101 classes. The prediction was based
on whether the cosine distance between the pair
of vectors was above a threshold value. We mea-
sured area under the precision-recall curve (AUC)
which captures performance at all thresholds, and
F1-score at the best threshold. arg2vec does bet-
ter in both measures than a baseline of random
vectors of the same dimension, scoring 0.637 for
AUC compared to a baseline of 0.505, and 29.5
against 22.9 for F1.
</bodyText>
<sectionHeader confidence="0.999336" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9982785">
In this paper we presented a new approach for
learning distributed representations for predicates
and their arguments which we show is useful for
unsupervised semantic role labeling. Rather than
creating a task-specific algorithm for role induc-
tion, we learn a task-specific representation. We
</bodyText>
<page confidence="0.973137">
2489
</page>
<bodyText confidence="0.9994495">
thus decouple feature learning from clustering in-
ference, which results in a conceptually simpler
model. Through a formulation of the clustering
problem as a linear programme, we are able to per-
form clustering efficiently and incorporate task-
specific constraints. In the future, we would like
to investigate how our approach generalizes across
languages and tasks.
Acknowledgements We would like to thank
Miguel Forte and members of the ILCC at the
School of Informatics for their valuable feed-
back. We acknowledge the support of EPSRC
(EP/K017845/1) in the framework of the CHIST-
ERA READERS project.
</bodyText>
<sectionHeader confidence="0.998275" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999819731182796">
Michael Auli, Michel Galley, Chris Quirk, and Geof-
frey Zweig. 2013. Joint language and translation
modeling with recurrent neural networks. In Pro-
ceedings of the 2013 Conference on Empirical Meth-
ods in Natural Language Processing, pages 1044–
1054, Seattle, Washington.
Yoshua Bengio, Holger Schwenk, Jean-S´ebastien
Morin, and Jean-Luc Gauvain, 2006. Neural Proba-
bilistic Language Models, pages 137–186. Springer.
Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues.
2009. Multilingual Semantic Role Labeling. In Pro-
ceedings of the Thirteenth Conference on Computa-
tional Natural Language Learning (CoNLL 2009):
Shared Task, pages 43–48, Boulder, Colorado, June.
Association for Computational Linguistics.
P. F. Brown, V. J. Della Pietra, P. V. deSouza, J. C. Lai,
and R. L. Mercer. 1992. Class-based n-gram mod-
els of natural language. Computational Linguistics,
18(4):283–298.
Kyunghyun Cho, Bart van Merrienboer, Dzmitry Bah-
danau, and Yoshua Bengio. 2014. On the properties
of neural machine translation: Encoder–decoder ap-
proaches. In Proceedings of SSST-8, Eighth Work-
shop on Syntax, Semantics and Structure in Statisti-
cal Translation, pages 103–111, Doha, Qatar, Octo-
ber. Association for Computational Linguistics.
Ronan Collobert, Jason Weston, Leon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. The Journal of Machine Learning Re-
search, 12:2493–2537, March.
Nikhil Garg and James Henderson. 2012. Unsuper-
vised Semantic Role Induction with Global Role Or-
dering. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics (Volume 2: Short Papers), pages 145–149, Jeju
Island, Korea.
Sean Gilpin, Siegried Nijssen, and Ian Davidson. 2013.
Formalizing Hierarchical Clustering as Integer Lin-
ear Programming. In In Proceedings of the 27th
AAAI Conference on Artificial Intelligence, pages
372–378, Bellevue, Washington.
Trond Grenager and Christopher D. Manning. 2006.
Unsupervised discovery of a statistical verb lexicon.
In Proceedings of the 2006 Conference on Empirical
Methods in Natural Language Processing, pages 1–
8, Sydney, Australia.
Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent
continuous translation models. In Proceedings of
the 2013 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1700–1709, Seattle,
Washington.
Nal Kalchbrenner, Edward Grefenstette, and Phil Blun-
som. 2014. A Convolutional Neural Network for
Modelling Sentences. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics (Volume 1: Long Papers), pages
655–665, Baltimore, Maryland.
Joel Lang and Mirella Lapata. 2010. Unsuper-
vised induction of semantic roles. In Human Lan-
guage Technologies: The 2010 Annual Conference
of the North American Chapter of the Association
for Computational Linguistics, pages 939–947, Los
Angeles, California.
Joel Lang and Mirella Lapata. 2014. Similarity-
driven semantic role induction via graph partition-
ing. Computational Linguistics, 40(3):133–164.
Quoc V. Le and Tomas Mikolov. 2014. Distributed
representations of sentences and documents. In Pro-
ceedings of the 31th International Conference on
Machine Learning, ICML 2014, Beijing, China, 21-
26 June 2014, pages 1188–1196.
Llu´ıs M`arquez, Xavier Carreras, Kenneth C.
Litkowski, and Suzanne Stevenson. 2008. Semantic
Role Labeling: An Introduction to the Special Issue.
Computational Linguistics, 34(2):145–159, June.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013a. Efficient Estimation of Word Repre-
sentations in Vector Space, January.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeffrey Dean. 2013b. Distributed Repre-
sentations of Words and Phrases and their Composi-
tionality. In C. J. C. Burges, L. Bottou, M. Welling,
Z. Ghahramani, and K. Q. Weinberger, editors, Ad-
vances in Neural Information Processing Systems
26, pages 3111–3119. Curran Associates, Inc., Oc-
tober.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013c. Linguistic regularities in continuous space
word representations. In Proceedings of the 2013
Conference of the North American Chapter of the
Association for Computational Linguistics: Human
Language Technologies, pages 746–751, Atlanta,
</reference>
<page confidence="0.656727">
2490
</page>
<reference confidence="0.999694581081081">
Georgia, June. Association for Computational Lin-
guistics.
Andriy Mnih and Geoffrey E. Hinton. 2008. A scal-
able hierarchical distributed language model. In Ad-
vances in Neural Information Processing Systems,
pages 1081–1088.
Andriy Mnih and Koray Kavukcuoglu. 2013. Learning
word embeddings efficiently with noise-contrastive
estimation. In Advances in Neural Information Pro-
cessing Systems 26, pages 2265–2273.
Martha Palmer, Daniel Gildea, and Paul Kingsbury.
2005. The Proposition Bank: An Annotated Cor-
pus of Semantic Roles. Computational Linguistics,
31(1):71–106, March.
Robert Parker, David Graff, Junbo Kong, Ke Chen, and
Kazuaki Maeda. 2011. English Gigaword Fifth Edi-
tion. LDC2011T07. Linguistic Data Consortium.
Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008.
The importance of syntactic parsing and inference in
semantic role labeling. Computational Linguistics,
34(2):257–287, June.
Andrew Rosenberg and Julia Hirschberg. 2007. V-
Measure: A Conditional Entropy-Based External
Cluster Evaluation Measure. In Proceedings of the
2007 Joint Conference on Empirical Methods in
Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL).
Karin Kipper Schuler. 2005. VerbNet: A broad-
coverage, comprehensive verb lexicon. Ph.D. thesis,
University of Pennsylvania.
Richard Socher, Eric H. Huang, Jeffrey Pennin, An-
drew Y. Ng, and Christopher D. Manning. 2011a.
Dynamic pooling and unfolding recursive autoen-
coders for paraphrase detection. In J. Shawe-Taylor,
R.S. Zemel, P. Bartlett, F.C.N. Pereira, and K.Q.
Weinberger, editors, Advances in Neural Informa-
tion Processing Systems 24, pages 801–809.
Richard Socher, Jeffrey Pennington, Eric H. Huang,
Andrew Y. Ng, and Christopher D. Manning. 2011b.
Semi-Supervised Recursive Autoencoders for Pre-
dicting Sentiment Distributions. In Proceedings of
the 2011 Conference on Empirical Methods in Nat-
ural Language Processing, pages 151–161, Edin-
burgh, Scotland, UK.
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Llu´ıs M`arquez, and Joakim Nivre. 2008. The
CoNLL 2008 Shared Task on Joint Parsing of Syn-
tactic and Semantic Dependencies. In CoNLL 2008:
Proceedings of the Twelfth Conference on Computa-
tional Natural Language Learning, pages 159–177,
Manchester, England, August. Coling 2008 Orga-
nizing Committee.
Oscar T¨ackstr¨om, Kuzman Ganchev, and Dipanjan
Das. 2015. Efficient inference and structured learn-
ing for semantic role labeling. Transactions of the
Association for Computational Linguistics, 3:29–41.
Ivan Titov and Ehsan Khoddam. 2015. Unsupervised
induction of semantic roles within a reconstruction-
error minimization framework. In Proceedings of
the 2015 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 1–10, Den-
ver, Colorado.
Ivan Titov and Alexandre Klementiev. 2012. A
Bayesian approach to unsupervised semantic role in-
duction. In Proceedings of the 13th Conference of
the European Chapter of the Association for Compu-
tational Linguistics, pages 12–22, Avignon, France.
Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio.
2010. Word representations: A simple and general
method for semi-supervised learning. In Proceed-
ings of the 48th Annual Meeting of the Association
for Computational Linguistics, pages 384–394, Up-
psala, Sweden.
</reference>
<page confidence="0.990139">
2491
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.549002">
<title confidence="0.988128">Distributed Representations for Unsupervised Semantic Role Labeling</title>
<author confidence="0.597632">Woodsend</author>
<affiliation confidence="0.9503305">Institute for Language, Cognition and School of Informatics, University of</affiliation>
<address confidence="0.90247">10 Crichton Street, Edinburgh EH8</address>
<abstract confidence="0.999164421052632">We present a new approach for unsupervised semantic role labeling that leverages distributed representations. We induce embeddings to represent a predicate, its arguments and their complex interdependence. Argument embeddings are learned from surrounding contexts involving the predicate and neighboring arguments, while predicate embeddings are learned from argument contexts. The induced representations are clustered into roles using a linear programming formulation of hierarchical clustering, where we can model task-specific knowledge. Experiments show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michael Auli</author>
<author>Michel Galley</author>
<author>Chris Quirk</author>
<author>Geoffrey Zweig</author>
</authors>
<title>Joint language and translation modeling with recurrent neural networks.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1044--1054</pages>
<location>Seattle, Washington.</location>
<contexts>
<context position="1506" citStr="Auli et al., 2013" startWordPosition="203" endWordPosition="206">vised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold between a predicate and its arguments in a given input sentence (e.g., “who” did “what” to “whom”, “when”, “where”, and “how”). 1. [The burglar]A0 [broke]V [the window]A1. 2. [The window]A1 [broke]V. In sentence (1), A0 represents the Agent of the breaking e</context>
</contexts>
<marker>Auli, Galley, Quirk, Zweig, 2013</marker>
<rawString>Michael Auli, Michel Galley, Chris Quirk, and Geoffrey Zweig. 2013. Joint language and translation modeling with recurrent neural networks. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1044– 1054, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>Holger Schwenk</author>
<author>Jean-S´ebastien Morin</author>
<author>Jean-Luc Gauvain</author>
</authors>
<title>Neural Probabilistic Language Models,</title>
<date>2006</date>
<pages>137--186</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5446" citStr="Bengio et al., 2006" startWordPosition="812" endWordPosition="815">tly, expressing clustering as a global optimization problem with an explicit objective function can potentially yield higher quality output compared to greedy algorithms (such as agglomerative clustering). Secondly, through the use of constraints, we can model task-specific knowledge (e.g., semantic roles are unique within a frame). Experimental results show improved performance over both previous unsupervised semantic role labeling approaches and other distributed word representation models. 2 Related Work Our model is inspired by recent work in learning distributed representations of words (Bengio et al., 2006; Mnih and Hinton, 2008; Collobert et al., 2011; Turian et al., 2010; Mikolov et al., 2013a). In this framework, a neural network is used to predict a word taking into account its context. Words are represented by vectors which are concatenated or averaged in order to form a representation of the context. We induce vector representations to represent each predicate and its argument. As a learning objective, vectors are required to contribute to a prediction task about the target argument in the sentence, given the predicate and a small window of surrounding arguments. Similarly, predicate vect</context>
</contexts>
<marker>Bengio, Schwenk, Morin, Gauvain, 2006</marker>
<rawString>Yoshua Bengio, Holger Schwenk, Jean-S´ebastien Morin, and Jean-Luc Gauvain, 2006. Neural Probabilistic Language Models, pages 137–186. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Love Hafdell</author>
<author>Pierre Nugues</author>
</authors>
<title>Multilingual Semantic Role Labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task,</booktitle>
<pages>43--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<marker>Bj¨orkelund, Hafdell, Nugues, 2009</marker>
<rawString>Anders Bj¨orkelund, Love Hafdell, and Pierre Nugues. 2009. Multilingual Semantic Role Labeling. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL 2009): Shared Task, pages 43–48, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>V J Della Pietra</author>
<author>P V deSouza</author>
<author>J C Lai</author>
<author>R L Mercer</author>
</authors>
<title>Class-based n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<volume>18</volume>
<issue>4</issue>
<marker>Brown, Pietra, deSouza, Lai, Mercer, 1992</marker>
<rawString>P. F. Brown, V. J. Della Pietra, P. V. deSouza, J. C. Lai, and R. L. Mercer. 1992. Class-based n-gram models of natural language. Computational Linguistics, 18(4):283–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyunghyun Cho</author>
<author>Bart van Merrienboer</author>
<author>Dzmitry Bahdanau</author>
<author>Yoshua Bengio</author>
</authors>
<title>On the properties of neural machine translation: Encoder–decoder approaches.</title>
<date>2014</date>
<booktitle>In Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation,</booktitle>
<pages>103--111</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Doha, Qatar,</location>
<marker>Cho, van Merrienboer, Bahdanau, Bengio, 2014</marker>
<rawString>Kyunghyun Cho, Bart van Merrienboer, Dzmitry Bahdanau, and Yoshua Bengio. 2014. On the properties of neural machine translation: Encoder–decoder approaches. In Proceedings of SSST-8, Eighth Workshop on Syntax, Semantics and Structure in Statistical Translation, pages 103–111, Doha, Qatar, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>Leon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="1231" citStr="Collobert et al., 2011" startWordPosition="161" endWordPosition="164">redicate embeddings are learned from argument contexts. The induced representations are clustered into roles using a linear programming formulation of hierarchical clustering, where we can model task-specific knowledge. Experiments show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the rel</context>
<context position="5493" citStr="Collobert et al., 2011" startWordPosition="820" endWordPosition="823">ization problem with an explicit objective function can potentially yield higher quality output compared to greedy algorithms (such as agglomerative clustering). Secondly, through the use of constraints, we can model task-specific knowledge (e.g., semantic roles are unique within a frame). Experimental results show improved performance over both previous unsupervised semantic role labeling approaches and other distributed word representation models. 2 Related Work Our model is inspired by recent work in learning distributed representations of words (Bengio et al., 2006; Mnih and Hinton, 2008; Collobert et al., 2011; Turian et al., 2010; Mikolov et al., 2013a). In this framework, a neural network is used to predict a word taking into account its context. Words are represented by vectors which are concatenated or averaged in order to form a representation of the context. We induce vector representations to represent each predicate and its argument. As a learning objective, vectors are required to contribute to a prediction task about the target argument in the sentence, given the predicate and a small window of surrounding arguments. Similarly, predicate vectors are learned from the contexts of preceding </context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, Leon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. The Journal of Machine Learning Research, 12:2493–2537, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikhil Garg</author>
<author>James Henderson</author>
</authors>
<title>Unsupervised Semantic Role Induction with Global Role Ordering.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>145--149</pages>
<location>Jeju Island,</location>
<contexts>
<context position="6616" citStr="Garg and Henderson, 2012" startWordPosition="1000" endWordPosition="1003">dow of surrounding arguments. Similarly, predicate vectors are learned from the contexts of preceding arguments, and are required to contribute to the prediction of upcoming arguments. Our vectors encode the semantics of arguments, predicates, and their interdependence. Approaches to unsupervised semantic role labeling follow two main modeling paradigms. Under the the first variant, semantic roles are modeled as latent variables in a (directed) graphical model that relates a verb, its semantic roles, and their possible syntactic realizations (Grenager and Manning, 2006; Lang and Lapata, 2010; Garg and Henderson, 2012). Role induction here corresponds to inferring the state of the latent variables representing the semantic roles of arguments. The second approach is similarity-driven and based on clustering. For instance, Lang and Lapata (2014) induce semantic roles via graph partitioning: each vertex in a graph corresponds to an argument instance of a predicate and edges represent features expressing syntactic or semantic similarity. The graph partitioning problem is solved using task-specific adaptations of label propagation and agglomerative clustering. Titov and Klementiev (2012) propose a Bayesian clust</context>
</contexts>
<marker>Garg, Henderson, 2012</marker>
<rawString>Nikhil Garg and James Henderson. 2012. Unsupervised Semantic Role Induction with Global Role Ordering. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 145–149, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Gilpin</author>
<author>Siegried Nijssen</author>
<author>Ian Davidson</author>
</authors>
<title>Formalizing Hierarchical Clustering as Integer Linear Programming. In</title>
<date>2013</date>
<booktitle>In Proceedings of the 27th AAAI Conference on Artificial Intelligence,</booktitle>
<pages>372--378</pages>
<location>Bellevue, Washington.</location>
<contexts>
<context position="16332" citStr="Gilpin et al., 2013" startWordPosition="2536" endWordPosition="2539">gorithm with no explicit objective function. Instead, it requires a measure of dissimilarity between sets of observations, typically through a measure of distance between pairs of observations. An example is the agglomerative clustering technique used in Lang and Lapata (2014). Their algorithm starts from seed clusters based on shared syntactic information, and then repeatedly merges pairs of clusters “bottom up” to form a hierarchy. It is possible to formalize hierarchical clustering as an integer linear programming (ILP) problem with the dendrogram properties enforced as linear constraints (Gilpin et al., 2013). Although exact solvers exists for ILP, their performance is highly dependent on the number of variables involved, and we found it necessary to develop a linear programming (LP) relaxation to provide approximate solutions faster. Dynamic programming is an alContext features ×Wcontext ×Wcontext Context representation v−1 Concatentation v0 Target representation ×Wargument Target features f0 v+1 vpred vc f−1 f+1 1 T T ∑ t=1 2485 ternative approximation technique that could be explored; it has recently been used successfully in the context of supervised semantic role labeling (T¨ackstr¨om et al.,</context>
</contexts>
<marker>Gilpin, Nijssen, Davidson, 2013</marker>
<rawString>Sean Gilpin, Siegried Nijssen, and Ian Davidson. 2013. Formalizing Hierarchical Clustering as Integer Linear Programming. In In Proceedings of the 27th AAAI Conference on Artificial Intelligence, pages 372–378, Bellevue, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trond Grenager</author>
<author>Christopher D Manning</author>
</authors>
<title>Unsupervised discovery of a statistical verb lexicon.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<volume>1</volume>
<pages>pages</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="6566" citStr="Grenager and Manning, 2006" startWordPosition="992" endWordPosition="995">n the sentence, given the predicate and a small window of surrounding arguments. Similarly, predicate vectors are learned from the contexts of preceding arguments, and are required to contribute to the prediction of upcoming arguments. Our vectors encode the semantics of arguments, predicates, and their interdependence. Approaches to unsupervised semantic role labeling follow two main modeling paradigms. Under the the first variant, semantic roles are modeled as latent variables in a (directed) graphical model that relates a verb, its semantic roles, and their possible syntactic realizations (Grenager and Manning, 2006; Lang and Lapata, 2010; Garg and Henderson, 2012). Role induction here corresponds to inferring the state of the latent variables representing the semantic roles of arguments. The second approach is similarity-driven and based on clustering. For instance, Lang and Lapata (2014) induce semantic roles via graph partitioning: each vertex in a graph corresponds to an argument instance of a predicate and edges represent features expressing syntactic or semantic similarity. The graph partitioning problem is solved using task-specific adaptations of label propagation and agglomerative clustering. Ti</context>
</contexts>
<marker>Grenager, Manning, 2006</marker>
<rawString>Trond Grenager and Christopher D. Manning. 2006. Unsupervised discovery of a statistical verb lexicon. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 1– 8, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nal Kalchbrenner</author>
<author>Phil Blunsom</author>
</authors>
<title>Recurrent continuous translation models.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1700--1709</pages>
<location>Seattle, Washington.</location>
<contexts>
<context position="1468" citStr="Kalchbrenner and Blunsom, 2013" startWordPosition="195" endWordPosition="198">ts show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold between a predicate and its arguments in a given input sentence (e.g., “who” did “what” to “whom”, “when”, “where”, and “how”). 1. [The burglar]A0 [broke]V [the window]A1. 2. [The window]A1 [broke]V. In sentence (1), A0 </context>
</contexts>
<marker>Kalchbrenner, Blunsom, 2013</marker>
<rawString>Nal Kalchbrenner and Phil Blunsom. 2013. Recurrent continuous translation models. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1700–1709, Seattle, Washington.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nal Kalchbrenner</author>
<author>Edward Grefenstette</author>
<author>Phil Blunsom</author>
</authors>
<title>A Convolutional Neural Network for Modelling Sentences.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>655--665</pages>
<location>Baltimore, Maryland.</location>
<contexts>
<context position="1398" citStr="Kalchbrenner et al., 2014" startWordPosition="185" endWordPosition="189"> clustering, where we can model task-specific knowledge. Experiments show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold between a predicate and its arguments in a given input sentence (e.g., “who” did “what” to “whom”, “when”, “where”, and “how”). 1. [The burglar]A0 [br</context>
</contexts>
<marker>Kalchbrenner, Grefenstette, Blunsom, 2014</marker>
<rawString>Nal Kalchbrenner, Edward Grefenstette, and Phil Blunsom. 2014. A Convolutional Neural Network for Modelling Sentences. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 655–665, Baltimore, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Lang</author>
<author>Mirella Lapata</author>
</authors>
<title>Unsupervised induction of semantic roles.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>939--947</pages>
<location>Los Angeles, California.</location>
<contexts>
<context position="6589" citStr="Lang and Lapata, 2010" startWordPosition="996" endWordPosition="999">edicate and a small window of surrounding arguments. Similarly, predicate vectors are learned from the contexts of preceding arguments, and are required to contribute to the prediction of upcoming arguments. Our vectors encode the semantics of arguments, predicates, and their interdependence. Approaches to unsupervised semantic role labeling follow two main modeling paradigms. Under the the first variant, semantic roles are modeled as latent variables in a (directed) graphical model that relates a verb, its semantic roles, and their possible syntactic realizations (Grenager and Manning, 2006; Lang and Lapata, 2010; Garg and Henderson, 2012). Role induction here corresponds to inferring the state of the latent variables representing the semantic roles of arguments. The second approach is similarity-driven and based on clustering. For instance, Lang and Lapata (2014) induce semantic roles via graph partitioning: each vertex in a graph corresponds to an argument instance of a predicate and edges represent features expressing syntactic or semantic similarity. The graph partitioning problem is solved using task-specific adaptations of label propagation and agglomerative clustering. Titov and Klementiev (201</context>
</contexts>
<marker>Lang, Lapata, 2010</marker>
<rawString>Joel Lang and Mirella Lapata. 2010. Unsupervised induction of semantic roles. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 939–947, Los Angeles, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Lang</author>
<author>Mirella Lapata</author>
</authors>
<title>Similaritydriven semantic role induction via graph partitioning.</title>
<date>2014</date>
<journal>Computational Linguistics,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="2667" citStr="Lang and Lapata, 2014" startWordPosition="387" endWordPosition="390">V. In sentence (1), A0 represents the Agent of the breaking event, A1 represents the Patient (i.e., the physical object affected by the breaking event) and V determines the boundaries of the predicate. The semantic roles in the example are labeled in the style of PropBank (Palmer et al., 2005), a broad-coverage human-annotated corpus of semantic roles and their syntactic realizations. In the unsupervised case, the model must induce such labels from data without access to a predefined set of semantic roles. Role induction is commonly treated as a clustering problem (Titov and Klementiev, 2012; Lang and Lapata, 2014). The input to the model are instances of arguments (e.g., window, the burglar in sentence (1)) and the output is a grouping of these instances into clusters such that each cluster contains arguments corresponding to a specific semantic role and each role corresponds to exactly one cluster. In other words, the syntactic representations of verbal predicates, and argument positions are observable, whereas the associated semantic roles are latent and need to be inferred. The task is challenging due to its unsupervised nature — it is difficult to define a learning objective function whose optimiza</context>
<context position="6845" citStr="Lang and Lapata (2014)" startWordPosition="1034" endWordPosition="1037">predicates, and their interdependence. Approaches to unsupervised semantic role labeling follow two main modeling paradigms. Under the the first variant, semantic roles are modeled as latent variables in a (directed) graphical model that relates a verb, its semantic roles, and their possible syntactic realizations (Grenager and Manning, 2006; Lang and Lapata, 2010; Garg and Henderson, 2012). Role induction here corresponds to inferring the state of the latent variables representing the semantic roles of arguments. The second approach is similarity-driven and based on clustering. For instance, Lang and Lapata (2014) induce semantic roles via graph partitioning: each vertex in a graph corresponds to an argument instance of a predicate and edges represent features expressing syntactic or semantic similarity. The graph partitioning problem is solved using task-specific adaptations of label propagation and agglomerative clustering. Titov and Klementiev (2012) propose a Bayesian clustering algorithm based on the Chinese Restaurant Process. Their model encourages similar verbs to have similar linking preferences using a distancedependent Chinese Restaurant Process prior. More recently, Titov and Khoddam (2015)</context>
<context position="9830" citStr="Lang and Lapata, 2014" startWordPosition="1487" endWordPosition="1490">l., 2008) and follows a two-stage approach. Given a sentence and a designated verb, the goal is to identify the arguments of the verbal predicate (argument identification) and label them with semantic roles (role induction). The model is first given a syntactically analyzed sentence (e.g., in the form of a dependency parse) with the aim of determining all constitutents that fill a semantic role. Argument identification is performed heuristically using a small number of rules which take into account syntactic relations encountered when traversing the dependency tree from predicate to argument (Lang and Lapata, 2014; Titov and Klementiev, 2012). An alternative which we follow here is to use a supervised classifier trained on a small amount of data using non-lexicalized features. As mentioned earlier, we treat role induction as a type-level clustering problem: argument instances are assigned to clusters such that these represent semantic roles. We induce a separate set of clusters for each verb, and each cluster thus represents a verb-specific role. Clustering algorithms commonly take a matrix of pairwise similarity scores between instances as input and produce a set of output clusters, often satisfying s</context>
<context position="15989" citStr="Lang and Lapata (2014)" startWordPosition="2486" endWordPosition="2489">semantic space to cluster arguments into semantic roles. 3.2 Argument Clustering Hierarchical clustering is a method of clustering which seeks to build a hierarchy of clusters, often presented in a dendrogram. In such a representation, all possible pairs of clusters are merged at some level. It is typically implemented as a greedy heuristic algorithm with no explicit objective function. Instead, it requires a measure of dissimilarity between sets of observations, typically through a measure of distance between pairs of observations. An example is the agglomerative clustering technique used in Lang and Lapata (2014). Their algorithm starts from seed clusters based on shared syntactic information, and then repeatedly merges pairs of clusters “bottom up” to form a hierarchy. It is possible to formalize hierarchical clustering as an integer linear programming (ILP) problem with the dendrogram properties enforced as linear constraints (Gilpin et al., 2013). Although exact solvers exists for ILP, their performance is highly dependent on the number of variables involved, and we found it necessary to develop a linear programming (LP) relaxation to provide approximate solutions faster. Dynamic programming is an </context>
<context position="19234" citStr="Lang and Lapata, 2014" startWordPosition="3052" endWordPosition="3055">lutions faster. A maximum merge level L is first defined as a parameter, although as this is not an integer problem and fractional levels are possible, this does not represent the number of levels. Auxiliary variables Zab≥ac capture the merge hierarchy, and Tabc rewards transitivity by a factor a: arg max E wabcOabc + aTabc M , O,Za b,c∈Instances subject to: 0 ≤ T ≤ 1 0 ≤ O ≤ 1 0 ≤ Z ≤ 1 (5) 0 ≤ M ≤ L −L ≤ Mac −Mab − (L+ 1)Oabc ≤ 0 −L ≤ Mab −Mac −(L+1)Zab≥ac +1 ≤ 0 −L ≤ Mbc −Mac −(L+1)Zbc≥ac +1 ≤ 0 Zab≥ac + Zbc≥ac ≥ Tabc To capture the linguistic principles involved in semantic role labeling (Lang and Lapata, 2014), our formulation includes additional constraints. These are expressed explicitly through the construction of the linear programme: Role Uniqueness Semantic roles are unique within a particular frame. This principle is captured by constraining the merge level of two seed clusters a and b to be at the top level L of the hierarchy, where a and b are roles that occur within the same frame, with the constraint: Mab = L ∀(a,b) in frame. (6) Syntactic Position Arguments occurring in a specific syntactic position within a specific linking all bear the same semantic role. This is handled by constructi</context>
<context position="22164" citStr="Lang and Lapata, 2014" startWordPosition="3531" endWordPosition="3534">= 1. As the mechanism to prevent all vectors from having the same value, we used “negative-sampling” (Mikolov et al., 2013b), where there are k = 5 randomly sampled negative examples of (context, target) pairs for each data sample. This technique has the advantage that we do not need to provide numerical probabilities for the noise distribution. Model parameters were updated during training using stochastic gradient descent over 5 epochs, decreasing the update step size at each epoch. 4.2 Argument clustering Following common practice in unsupervised role induction (Titov and Klementiev, 2012; Lang and Lapata, 2014), we evaluated our model on the complete CoNLL-2008 shared task data set. We used the clustering metrics of purity, collocation and their harmonic mean F1. In addition, we used V-measure (Rosenberg and Hirschberg, 2007), an entropy-based measure which explicitly evaluates how successfully the criteria of homogeneity and completeness have been satisfied. In previous work on unsupervised role induction, the results for each predicate were weighted in proportion to the number of times the predicate appeared in the CoNLL-2008 test set. In addition to this measure, we evaluate clustering where pred</context>
<context position="24034" citStr="Lang and Lapata (2014)" startWordPosition="3817" endWordPosition="3820">ur argument-based model has any advantages over other word-based distributed representations we compared the following variants: (a) the arg2vec model presented in Section 3.1 trained on the subset of Gigaword; (b) the continuous bag-of-words model trained using word2vec on the same Gigaword corpus; and (c) 300–dimensional vectors pre-trained on part of the Google News dataset2 (about 100 billion words), again using word2vec. In all three instances, we performed argument clustering using the LP of Section 3.2. We also compare against Agglomerative-cosine (AGGLOM), the best performing model of Lang and Lapata (2014).3 Where applicable, we also refer to the models presented in Titov and Klementiev (2012). 5 Results Our results on the semantic role induction task are summarized in Tables 1 and 2. Table 1 presents results using the gold standard parses and argu1Differences in the results compared to Lang and Lapata (2014) are due to our re-implementation of the predicate labeling stage, to be consistent with the preprocessing we used for the other comparison systems. 2http://code.google.com/p/word2vec/ 3Differences from published results are again due to changes at the predicate labeling stage. 2487 Weighte</context>
</contexts>
<marker>Lang, Lapata, 2014</marker>
<rawString>Joel Lang and Mirella Lapata. 2014. Similaritydriven semantic role induction via graph partitioning. Computational Linguistics, 40(3):133–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quoc V Le and Tomas Mikolov</author>
</authors>
<title>Distributed representations of sentences and documents.</title>
<date>2014</date>
<booktitle>In Proceedings of the 31th International Conference on Machine Learning, ICML 2014,</booktitle>
<pages>1188--1196</pages>
<location>Beijing,</location>
<contexts>
<context position="11282" citStr="Mikolov, 2014" startWordPosition="1714" endWordPosition="1715"> formulation of hierarchical clustering (see Section 3.2). 3.1 Predicate and Argument Embeddings Our approach for learning predicate and argument vectors is inspired by recent methods aimed at learning high-quality vector representations of words from large amounts of unstructured text data (Mikolov et al., 2013a). In this framework, vectors of the surrounding words within a fixedsized window (the context) are summed into a single vector vc, which is useful in predicting the output vector v0 representing the current or target word. Longer-range context information can also be captured (Le and Mikolov, 2014), specifically words within the current paragraph but outside of the target word context window. In contrast to previous word-based approaches, our model induces vector representations for each predicate and its semantic arguments. As a learning objective, vectors are required to contribute to a prediction task about the target argument in the sentence, given the predicate and a small window of surrounding arguments. So despite the fact that the argument vectors and weightings are initialized randomly, they can eventually capture semantics as an indirect result of the prediction task. Similarl</context>
</contexts>
<marker>Mikolov, 2014</marker>
<rawString>Quoc V. Le and Tomas Mikolov. 2014. Distributed representations of sentences and documents. In Proceedings of the 31th International Conference on Machine Learning, ICML 2014, Beijing, China, 21-26 June 2014, pages 1188–1196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu´ıs M`arquez</author>
<author>Xavier Carreras</author>
<author>Kenneth C Litkowski</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Semantic Role Labeling: An Introduction to the Special Issue.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<marker>M`arquez, Carreras, Litkowski, Stevenson, 2008</marker>
<rawString>Llu´ıs M`arquez, Xavier Carreras, Kenneth C. Litkowski, and Suzanne Stevenson. 2008. Semantic Role Labeling: An Introduction to the Special Issue. Computational Linguistics, 34(2):145–159, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<date></date>
<booktitle>2013a. Efficient Estimation of Word Representations in Vector Space,</booktitle>
<marker>Mikolov, Chen, Corrado, Dean, </marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013a. Efficient Estimation of Word Representations in Vector Space, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Distributed Representations of Words and Phrases and their Compositionality. In</title>
<date>2013</date>
<booktitle>Advances in Neural Information Processing Systems 26,</booktitle>
<pages>3111--3119</pages>
<editor>C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors,</editor>
<publisher>Curran Associates, Inc.,</publisher>
<contexts>
<context position="1253" citStr="Mikolov et al., 2013" startWordPosition="165" endWordPosition="168">learned from argument contexts. The induced representations are clustered into roles using a linear programming formulation of hierarchical clustering, where we can model task-specific knowledge. Experiments show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold betwe</context>
<context position="5536" citStr="Mikolov et al., 2013" startWordPosition="828" endWordPosition="831">nction can potentially yield higher quality output compared to greedy algorithms (such as agglomerative clustering). Secondly, through the use of constraints, we can model task-specific knowledge (e.g., semantic roles are unique within a frame). Experimental results show improved performance over both previous unsupervised semantic role labeling approaches and other distributed word representation models. 2 Related Work Our model is inspired by recent work in learning distributed representations of words (Bengio et al., 2006; Mnih and Hinton, 2008; Collobert et al., 2011; Turian et al., 2010; Mikolov et al., 2013a). In this framework, a neural network is used to predict a word taking into account its context. Words are represented by vectors which are concatenated or averaged in order to form a representation of the context. We induce vector representations to represent each predicate and its argument. As a learning objective, vectors are required to contribute to a prediction task about the target argument in the sentence, given the predicate and a small window of surrounding arguments. Similarly, predicate vectors are learned from the contexts of preceding arguments, and are required to contribute t</context>
<context position="10981" citStr="Mikolov et al., 2013" startWordPosition="1663" endWordPosition="1666">ces as input and produce a set of output clusters, often satisfying some optimality criterion. In our case, instances are typelevel arguments represented by embeddings whose similarity is quantified using a distance measure such as cosine (see Section 3.1) and clusters are formed using a linear programming formulation of hierarchical clustering (see Section 3.2). 3.1 Predicate and Argument Embeddings Our approach for learning predicate and argument vectors is inspired by recent methods aimed at learning high-quality vector representations of words from large amounts of unstructured text data (Mikolov et al., 2013a). In this framework, vectors of the surrounding words within a fixedsized window (the context) are summed into a single vector vc, which is useful in predicting the output vector v0 representing the current or target word. Longer-range context information can also be captured (Le and Mikolov, 2014), specifically words within the current paragraph but outside of the target word context window. In contrast to previous word-based approaches, our model induces vector representations for each predicate and its semantic arguments. As a learning objective, vectors are required to contribute to a pr</context>
<context position="21664" citStr="Mikolov et al., 2013" startWordPosition="3454" endWordPosition="3457">a dependency parse, identify verbal predicates and the position of arguments. The neural network model described in Section 3.1 was trained using Matlab. We restricted the predicate vocabulary to use the 5,000 most frequent verbs in the training corpus, and the verbal predicates found in the CoNLL-2008 shared task data set (Surdeanu et al., 2008). Predicates were represented as vectors of size 80, while vectors of length 50 were used for arguments. We used a symmetric context window of size c = 1. As the mechanism to prevent all vectors from having the same value, we used “negative-sampling” (Mikolov et al., 2013b), where there are k = 5 randomly sampled negative examples of (context, target) pairs for each data sample. This technique has the advantage that we do not need to provide numerical probabilities for the noise distribution. Model parameters were updated during training using stochastic gradient descent over 5 epochs, decreasing the update step size at each epoch. 4.2 Argument clustering Following common practice in unsupervised role induction (Titov and Klementiev, 2012; Lang and Lapata, 2014), we evaluated our model on the complete CoNLL-2008 shared task data set. We used the clustering met</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeffrey Dean. 2013b. Distributed Representations of Words and Phrases and their Compositionality. In C. J. C. Burges, L. Bottou, M. Welling, Z. Ghahramani, and K. Q. Weinberger, editors, Advances in Neural Information Processing Systems 26, pages 3111–3119. Curran Associates, Inc., October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Wen-tau Yih</author>
<author>Geoffrey Zweig</author>
</authors>
<title>Linguistic regularities in continuous space word representations.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>746--751</pages>
<location>Atlanta,</location>
<contexts>
<context position="1253" citStr="Mikolov et al., 2013" startWordPosition="165" endWordPosition="168">learned from argument contexts. The induced representations are clustered into roles using a linear programming formulation of hierarchical clustering, where we can model task-specific knowledge. Experiments show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold betwe</context>
<context position="5536" citStr="Mikolov et al., 2013" startWordPosition="828" endWordPosition="831">nction can potentially yield higher quality output compared to greedy algorithms (such as agglomerative clustering). Secondly, through the use of constraints, we can model task-specific knowledge (e.g., semantic roles are unique within a frame). Experimental results show improved performance over both previous unsupervised semantic role labeling approaches and other distributed word representation models. 2 Related Work Our model is inspired by recent work in learning distributed representations of words (Bengio et al., 2006; Mnih and Hinton, 2008; Collobert et al., 2011; Turian et al., 2010; Mikolov et al., 2013a). In this framework, a neural network is used to predict a word taking into account its context. Words are represented by vectors which are concatenated or averaged in order to form a representation of the context. We induce vector representations to represent each predicate and its argument. As a learning objective, vectors are required to contribute to a prediction task about the target argument in the sentence, given the predicate and a small window of surrounding arguments. Similarly, predicate vectors are learned from the contexts of preceding arguments, and are required to contribute t</context>
<context position="10981" citStr="Mikolov et al., 2013" startWordPosition="1663" endWordPosition="1666">ces as input and produce a set of output clusters, often satisfying some optimality criterion. In our case, instances are typelevel arguments represented by embeddings whose similarity is quantified using a distance measure such as cosine (see Section 3.1) and clusters are formed using a linear programming formulation of hierarchical clustering (see Section 3.2). 3.1 Predicate and Argument Embeddings Our approach for learning predicate and argument vectors is inspired by recent methods aimed at learning high-quality vector representations of words from large amounts of unstructured text data (Mikolov et al., 2013a). In this framework, vectors of the surrounding words within a fixedsized window (the context) are summed into a single vector vc, which is useful in predicting the output vector v0 representing the current or target word. Longer-range context information can also be captured (Le and Mikolov, 2014), specifically words within the current paragraph but outside of the target word context window. In contrast to previous word-based approaches, our model induces vector representations for each predicate and its semantic arguments. As a learning objective, vectors are required to contribute to a pr</context>
<context position="21664" citStr="Mikolov et al., 2013" startWordPosition="3454" endWordPosition="3457">a dependency parse, identify verbal predicates and the position of arguments. The neural network model described in Section 3.1 was trained using Matlab. We restricted the predicate vocabulary to use the 5,000 most frequent verbs in the training corpus, and the verbal predicates found in the CoNLL-2008 shared task data set (Surdeanu et al., 2008). Predicates were represented as vectors of size 80, while vectors of length 50 were used for arguments. We used a symmetric context window of size c = 1. As the mechanism to prevent all vectors from having the same value, we used “negative-sampling” (Mikolov et al., 2013b), where there are k = 5 randomly sampled negative examples of (context, target) pairs for each data sample. This technique has the advantage that we do not need to provide numerical probabilities for the noise distribution. Model parameters were updated during training using stochastic gradient descent over 5 epochs, decreasing the update step size at each epoch. 4.2 Argument clustering Following common practice in unsupervised role induction (Titov and Klementiev, 2012; Lang and Lapata, 2014), we evaluated our model on the complete CoNLL-2008 shared task data set. We used the clustering met</context>
</contexts>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013c. Linguistic regularities in continuous space word representations. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 746–751, Atlanta,</rawString>
</citation>
<citation valid="false">
<authors>
<author>June Georgia</author>
</authors>
<title>Association for Computational Linguistics.</title>
<marker>Georgia, </marker>
<rawString>Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andriy Mnih</author>
<author>Geoffrey E Hinton</author>
</authors>
<title>A scalable hierarchical distributed language model.</title>
<date>2008</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>1081--1088</pages>
<contexts>
<context position="5469" citStr="Mnih and Hinton, 2008" startWordPosition="816" endWordPosition="819">ering as a global optimization problem with an explicit objective function can potentially yield higher quality output compared to greedy algorithms (such as agglomerative clustering). Secondly, through the use of constraints, we can model task-specific knowledge (e.g., semantic roles are unique within a frame). Experimental results show improved performance over both previous unsupervised semantic role labeling approaches and other distributed word representation models. 2 Related Work Our model is inspired by recent work in learning distributed representations of words (Bengio et al., 2006; Mnih and Hinton, 2008; Collobert et al., 2011; Turian et al., 2010; Mikolov et al., 2013a). In this framework, a neural network is used to predict a word taking into account its context. Words are represented by vectors which are concatenated or averaged in order to form a representation of the context. We induce vector representations to represent each predicate and its argument. As a learning objective, vectors are required to contribute to a prediction task about the target argument in the sentence, given the predicate and a small window of surrounding arguments. Similarly, predicate vectors are learned from th</context>
</contexts>
<marker>Mnih, Hinton, 2008</marker>
<rawString>Andriy Mnih and Geoffrey E. Hinton. 2008. A scalable hierarchical distributed language model. In Advances in Neural Information Processing Systems, pages 1081–1088.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andriy Mnih</author>
<author>Koray Kavukcuoglu</author>
</authors>
<title>Learning word embeddings efficiently with noise-contrastive estimation.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems 26,</booktitle>
<pages>2265--2273</pages>
<contexts>
<context position="1283" citStr="Mnih and Kavukcuoglu, 2013" startWordPosition="169" endWordPosition="172">ontexts. The induced representations are clustered into roles using a linear programming formulation of hierarchical clustering, where we can model task-specific knowledge. Experiments show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold between a predicate and its argumen</context>
</contexts>
<marker>Mnih, Kavukcuoglu, 2013</marker>
<rawString>Andriy Mnih and Koray Kavukcuoglu. 2013. Learning word embeddings efficiently with noise-contrastive estimation. In Advances in Neural Information Processing Systems 26, pages 2265–2273.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An Annotated Corpus of Semantic Roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="2339" citStr="Palmer et al., 2005" startWordPosition="335" endWordPosition="338">e labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold between a predicate and its arguments in a given input sentence (e.g., “who” did “what” to “whom”, “when”, “where”, and “how”). 1. [The burglar]A0 [broke]V [the window]A1. 2. [The window]A1 [broke]V. In sentence (1), A0 represents the Agent of the breaking event, A1 represents the Patient (i.e., the physical object affected by the breaking event) and V determines the boundaries of the predicate. The semantic roles in the example are labeled in the style of PropBank (Palmer et al., 2005), a broad-coverage human-annotated corpus of semantic roles and their syntactic realizations. In the unsupervised case, the model must induce such labels from data without access to a predefined set of semantic roles. Role induction is commonly treated as a clustering problem (Titov and Klementiev, 2012; Lang and Lapata, 2014). The input to the model are instances of arguments (e.g., window, the burglar in sentence (1)) and the output is a grouping of these instances into clusters such that each cluster contains arguments corresponding to a specific semantic role and each role corresponds to e</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An Annotated Corpus of Semantic Roles. Computational Linguistics, 31(1):71–106, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Parker</author>
<author>David Graff</author>
<author>Junbo Kong</author>
<author>Ke Chen</author>
<author>Kazuaki Maeda</author>
</authors>
<date>2011</date>
<booktitle>English Gigaword Fifth Edition. LDC2011T07. Linguistic Data Consortium.</booktitle>
<contexts>
<context position="20860" citStr="Parker et al., 2011" startWordPosition="3322" endWordPosition="3325"> 3.1. We calculate 2486 centroid vectors from the instances in each cluster. To measure similarity between clusters a and b, we use cosine similarity between centroids: vTa vb D(a,b) = (7) IvaIIvbI Equations (3)–(7) comprise the LP model. 4 Experimental Setup In this section we present our experimental setup for assessing the performance of the model presented above. We explain how it was trained and tested, and also briefly introduce the models used for comparison with our approach. 4.1 Training To obtain distributed representations, we used text from a subset of the English Gigaword corpus (Parker et al., 2011), comprising almost 64 million tokens (2.7 million sentences). The training corpus was pre-processed using MATE (Bj¨orkelund et al., 2009) to lemmatize the words, provide POS-tags and a dependency parse, identify verbal predicates and the position of arguments. The neural network model described in Section 3.1 was trained using Matlab. We restricted the predicate vocabulary to use the 5,000 most frequent verbs in the training corpus, and the verbal predicates found in the CoNLL-2008 shared task data set (Surdeanu et al., 2008). Predicates were represented as vectors of size 80, while vectors o</context>
</contexts>
<marker>Parker, Graff, Kong, Chen, Maeda, 2011</marker>
<rawString>Robert Parker, David Graff, Junbo Kong, Ke Chen, and Kazuaki Maeda. 2011. English Gigaword Fifth Edition. LDC2011T07. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>The importance of syntactic parsing and inference in semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="8736" citStr="Punyakanok et al., 2008" startWordPosition="1311" endWordPosition="1314">ppropriate training objective. We are thus able to model complex interactions between arguments and their predicates without making simplifying assumptions (e.g., that arguments are conditionally independent of each other given the predicate). Our embeddings are largely independent of the clustering algorithm used to induce the semantic roles. We advocate the use of linear programming, which supports the incorporation of linguistic and structural constraints during cluster formation. ILP techniques have been previously applied to several supervised NLP tasks, including semantic role labeling (Punyakanok et al., 2008), how2483 Figure 1: Symmetric context window from the list of arguments START Yesterday Kristina hit Scott with a baseball END a1 a2 a3 predicate a4 a5 a6 Identification argt−1 argt argt+1 Window 1 argt−1 argt argt+1 Window 2 argt−1 argt argt+1 Window 3 argt−1 argt argt+1 Window 4 ever their application to unsupervised role induction is novel to our knowledge. 3 Model Unsupervised role induction is commonly modeled after supervised semantic role labeling (M`arquez et al., 2008) and follows a two-stage approach. Given a sentence and a designated verb, the goal is to identify the arguments of th</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2008</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008. The importance of syntactic parsing and inference in semantic role labeling. Computational Linguistics, 34(2):257–287, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Rosenberg</author>
<author>Julia Hirschberg</author>
</authors>
<title>VMeasure: A Conditional Entropy-Based External Cluster Evaluation Measure.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</booktitle>
<contexts>
<context position="22383" citStr="Rosenberg and Hirschberg, 2007" startWordPosition="3565" endWordPosition="3568">for each data sample. This technique has the advantage that we do not need to provide numerical probabilities for the noise distribution. Model parameters were updated during training using stochastic gradient descent over 5 epochs, decreasing the update step size at each epoch. 4.2 Argument clustering Following common practice in unsupervised role induction (Titov and Klementiev, 2012; Lang and Lapata, 2014), we evaluated our model on the complete CoNLL-2008 shared task data set. We used the clustering metrics of purity, collocation and their harmonic mean F1. In addition, we used V-measure (Rosenberg and Hirschberg, 2007), an entropy-based measure which explicitly evaluates how successfully the criteria of homogeneity and completeness have been satisfied. In previous work on unsupervised role induction, the results for each predicate were weighted in proportion to the number of times the predicate appeared in the CoNLL-2008 test set. In addition to this measure, we evaluate clustering where predicates are uniformly weighted. In a data set where the top 10 predicates account for almost 20% of the samples, these metrics give a view of performance on the other 3,000-plus predicates where less predicate-specific d</context>
</contexts>
<marker>Rosenberg, Hirschberg, 2007</marker>
<rawString>Andrew Rosenberg and Julia Hirschberg. 2007. VMeasure: A Conditional Entropy-Based External Cluster Evaluation Measure. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper Schuler</author>
</authors>
<title>VerbNet: A broadcoverage, comprehensive verb lexicon.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="31458" citStr="Schuler, 2005" startWordPosition="5001" endWordPosition="5002">her (e.g., offer, buy, receive, pay, sell). Verbs denoting growth or decrease are also grouped together (drop, fall, increase, grow, reduce, cut). Interestingly, verbs with similar argument structure share regions of the space (e.g., say, estimate, or believe, think or seem, appear). Usefully, verbs are represented in a continuous space rather than discrete clusters (e.g., acquire is somewhere between buy and own). In order to quantitatively evaluate the quality of the predicate representations induced by our model, we compared the cosine distances between vectors to the hierarchy of VerbNet (Schuler, 2005). VerbNet is a hierarchical domainindependent broad-coverage verb lexicon for English, organizing verbs into classes. The evaluation task was, for all pairs of predicates, to predict whether they would be in the same cluster at the 0 0 top layer of the hierarchy of VerbNet. To form the top layer of VerbNet, we took the first integer of each VerbNet class number. As an example, the verbs believe (VN class conjecture-29.5), think (consider-29.9), expect (conjecture-29.5-1), and adopt (appoint-29.1) would all be in the same class 29. According to this reduction of VerbNet, there are 101 classes. </context>
</contexts>
<marker>Schuler, 2005</marker>
<rawString>Karin Kipper Schuler. 2005. VerbNet: A broadcoverage, comprehensive verb lexicon. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Eric H Huang</author>
<author>Jeffrey Pennin</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Dynamic pooling and unfolding recursive autoencoders for paraphrase detection.</title>
<date>2011</date>
<booktitle>Advances in Neural Information Processing Systems 24,</booktitle>
<pages>801--809</pages>
<editor>In J. Shawe-Taylor, R.S. Zemel, P. Bartlett, F.C.N. Pereira, and K.Q. Weinberger, editors,</editor>
<contexts>
<context position="1326" citStr="Socher et al., 2011" startWordPosition="175" endWordPosition="178">into roles using a linear programming formulation of hierarchical clustering, where we can model task-specific knowledge. Experiments show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold between a predicate and its arguments in a given input sentence (e.g., “who” d</context>
</contexts>
<marker>Socher, Huang, Pennin, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Eric H. Huang, Jeffrey Pennin, Andrew Y. Ng, and Christopher D. Manning. 2011a. Dynamic pooling and unfolding recursive autoencoders for paraphrase detection. In J. Shawe-Taylor, R.S. Zemel, P. Bartlett, F.C.N. Pereira, and K.Q. Weinberger, editors, Advances in Neural Information Processing Systems 24, pages 801–809.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Jeffrey Pennington</author>
<author>Eric H Huang</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>151--161</pages>
<location>Edinburgh, Scotland, UK.</location>
<contexts>
<context position="1326" citStr="Socher et al., 2011" startWordPosition="175" endWordPosition="178">into roles using a linear programming formulation of hierarchical clustering, where we can model task-specific knowledge. Experiments show improved performance over previous unsupervised semantic role labeling approaches and other distributed word representation models. 1 Introduction In recent years, an increasing body of work has been devoted to learning distributed word representations and their successful usage in numerous tasks and real-world applications. Examples include language modeling (Collobert et al., 2011; Mikolov et al., 2013c; Mnih and Kavukcuoglu, 2013), paraphrase detection (Socher et al., 2011a), sentiment analysis (Socher et al., 2011b; Kalchbrenner et al., 2014), and most notably machine translation (Kalchbrenner and Blunsom, 2013; Cho et al., 2014; Auli et al., 2013). Distributed word representations (also known as word embeddings) are trained by predicting the contexts in which the words or phrases occur. In this paper, we present a new approach for unsupervised semantic role labeling that leverages distributed representations. The goal of semantic role labeling is to discover the relations that hold between a predicate and its arguments in a given input sentence (e.g., “who” d</context>
</contexts>
<marker>Socher, Pennington, Huang, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Jeffrey Pennington, Eric H. Huang, Andrew Y. Ng, and Christopher D. Manning. 2011b. Semi-Supervised Recursive Autoencoders for Predicting Sentiment Distributions. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 151–161, Edinburgh, Scotland, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Llu´ıs M`arquez</author>
<author>Joakim Nivre</author>
</authors>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>The CoNLL 2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning,</booktitle>
<pages>159--177</pages>
<location>Manchester, England,</location>
<marker>Surdeanu, Johansson, Meyers, M`arquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Llu´ıs M`arquez, and Joakim Nivre. 2008. The CoNLL 2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In CoNLL 2008: Proceedings of the Twelfth Conference on Computational Natural Language Learning, pages 159–177, Manchester, England, August. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Kuzman Ganchev</author>
<author>Dipanjan Das</author>
</authors>
<title>Efficient inference and structured learning for semantic role labeling.</title>
<date>2015</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>3--29</pages>
<marker>T¨ackstr¨om, Ganchev, Das, 2015</marker>
<rawString>Oscar T¨ackstr¨om, Kuzman Ganchev, and Dipanjan Das. 2015. Efficient inference and structured learning for semantic role labeling. Transactions of the Association for Computational Linguistics, 3:29–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ehsan Khoddam</author>
</authors>
<title>Unsupervised induction of semantic roles within a reconstructionerror minimization framework.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1--10</pages>
<location>Denver, Colorado.</location>
<contexts>
<context position="7445" citStr="Titov and Khoddam (2015)" startWordPosition="1124" endWordPosition="1127">, Lang and Lapata (2014) induce semantic roles via graph partitioning: each vertex in a graph corresponds to an argument instance of a predicate and edges represent features expressing syntactic or semantic similarity. The graph partitioning problem is solved using task-specific adaptations of label propagation and agglomerative clustering. Titov and Klementiev (2012) propose a Bayesian clustering algorithm based on the Chinese Restaurant Process. Their model encourages similar verbs to have similar linking preferences using a distancedependent Chinese Restaurant Process prior. More recently, Titov and Khoddam (2015) propose a reconstruction-error minimization framerwork for unsupervised semantic role induction. Their model consists of two componenets: the encoder (implemented as a log-linear model) predicts roles given syntactic and lexical features, whereas the reconstruction component (implemented as a probabilistic tensor factorization model) recovers argument fillers based on the role predictions, the predicate and other arguments. The two components are estimated jointly to minimize errors in argument reconstruction. Our work follows the similarity-driven modeling paradigm. Rather than engineering r</context>
</contexts>
<marker>Titov, Khoddam, 2015</marker>
<rawString>Ivan Titov and Ehsan Khoddam. 2015. Unsupervised induction of semantic roles within a reconstructionerror minimization framework. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1–10, Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Alexandre Klementiev</author>
</authors>
<title>A Bayesian approach to unsupervised semantic role induction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>12--22</pages>
<location>Avignon, France.</location>
<contexts>
<context position="2643" citStr="Titov and Klementiev, 2012" startWordPosition="383" endWordPosition="386">1. 2. [The window]A1 [broke]V. In sentence (1), A0 represents the Agent of the breaking event, A1 represents the Patient (i.e., the physical object affected by the breaking event) and V determines the boundaries of the predicate. The semantic roles in the example are labeled in the style of PropBank (Palmer et al., 2005), a broad-coverage human-annotated corpus of semantic roles and their syntactic realizations. In the unsupervised case, the model must induce such labels from data without access to a predefined set of semantic roles. Role induction is commonly treated as a clustering problem (Titov and Klementiev, 2012; Lang and Lapata, 2014). The input to the model are instances of arguments (e.g., window, the burglar in sentence (1)) and the output is a grouping of these instances into clusters such that each cluster contains arguments corresponding to a specific semantic role and each role corresponds to exactly one cluster. In other words, the syntactic representations of verbal predicates, and argument positions are observable, whereas the associated semantic roles are latent and need to be inferred. The task is challenging due to its unsupervised nature — it is difficult to define a learning objective</context>
<context position="7191" citStr="Titov and Klementiev (2012)" startWordPosition="1086" endWordPosition="1090">06; Lang and Lapata, 2010; Garg and Henderson, 2012). Role induction here corresponds to inferring the state of the latent variables representing the semantic roles of arguments. The second approach is similarity-driven and based on clustering. For instance, Lang and Lapata (2014) induce semantic roles via graph partitioning: each vertex in a graph corresponds to an argument instance of a predicate and edges represent features expressing syntactic or semantic similarity. The graph partitioning problem is solved using task-specific adaptations of label propagation and agglomerative clustering. Titov and Klementiev (2012) propose a Bayesian clustering algorithm based on the Chinese Restaurant Process. Their model encourages similar verbs to have similar linking preferences using a distancedependent Chinese Restaurant Process prior. More recently, Titov and Khoddam (2015) propose a reconstruction-error minimization framerwork for unsupervised semantic role induction. Their model consists of two componenets: the encoder (implemented as a log-linear model) predicts roles given syntactic and lexical features, whereas the reconstruction component (implemented as a probabilistic tensor factorization model) recovers </context>
<context position="9859" citStr="Titov and Klementiev, 2012" startWordPosition="1491" endWordPosition="1494"> two-stage approach. Given a sentence and a designated verb, the goal is to identify the arguments of the verbal predicate (argument identification) and label them with semantic roles (role induction). The model is first given a syntactically analyzed sentence (e.g., in the form of a dependency parse) with the aim of determining all constitutents that fill a semantic role. Argument identification is performed heuristically using a small number of rules which take into account syntactic relations encountered when traversing the dependency tree from predicate to argument (Lang and Lapata, 2014; Titov and Klementiev, 2012). An alternative which we follow here is to use a supervised classifier trained on a small amount of data using non-lexicalized features. As mentioned earlier, we treat role induction as a type-level clustering problem: argument instances are assigned to clusters such that these represent semantic roles. We induce a separate set of clusters for each verb, and each cluster thus represents a verb-specific role. Clustering algorithms commonly take a matrix of pairwise similarity scores between instances as input and produce a set of output clusters, often satisfying some optimality criterion. In </context>
<context position="22140" citStr="Titov and Klementiev, 2012" startWordPosition="3527" endWordPosition="3530">ic context window of size c = 1. As the mechanism to prevent all vectors from having the same value, we used “negative-sampling” (Mikolov et al., 2013b), where there are k = 5 randomly sampled negative examples of (context, target) pairs for each data sample. This technique has the advantage that we do not need to provide numerical probabilities for the noise distribution. Model parameters were updated during training using stochastic gradient descent over 5 epochs, decreasing the update step size at each epoch. 4.2 Argument clustering Following common practice in unsupervised role induction (Titov and Klementiev, 2012; Lang and Lapata, 2014), we evaluated our model on the complete CoNLL-2008 shared task data set. We used the clustering metrics of purity, collocation and their harmonic mean F1. In addition, we used V-measure (Rosenberg and Hirschberg, 2007), an entropy-based measure which explicitly evaluates how successfully the criteria of homogeneity and completeness have been satisfied. In previous work on unsupervised role induction, the results for each predicate were weighted in proportion to the number of times the predicate appeared in the CoNLL-2008 test set. In addition to this measure, we evalua</context>
<context position="24123" citStr="Titov and Klementiev (2012)" startWordPosition="3831" endWordPosition="3834">ntations we compared the following variants: (a) the arg2vec model presented in Section 3.1 trained on the subset of Gigaword; (b) the continuous bag-of-words model trained using word2vec on the same Gigaword corpus; and (c) 300–dimensional vectors pre-trained on part of the Google News dataset2 (about 100 billion words), again using word2vec. In all three instances, we performed argument clustering using the LP of Section 3.2. We also compare against Agglomerative-cosine (AGGLOM), the best performing model of Lang and Lapata (2014).3 Where applicable, we also refer to the models presented in Titov and Klementiev (2012). 5 Results Our results on the semantic role induction task are summarized in Tables 1 and 2. Table 1 presents results using the gold standard parses and argu1Differences in the results compared to Lang and Lapata (2014) are due to our re-implementation of the predicate labeling stage, to be consistent with the preprocessing we used for the other comparison systems. 2http://code.google.com/p/word2vec/ 3Differences from published results are again due to changes at the predicate labeling stage. 2487 Weighted Unweighted Weighted Unweighted PU CO F1 PU CO F1 HO CO V1 HO CO V1 SYNTF 81.6 78.1 79.8</context>
<context position="27661" citStr="Titov and Klementiev (2012)" startWordPosition="4398" endWordPosition="4401">e significant differences in the size of their training data. Table 2 shows similar trends. The poorer performance of SYNTF and AGGLOM can partly be ascribed to the heuristics used for argument identification: DEPREL+MATE gives the baseline performance of our dependency parser and argument identification. Nevertheless, when comparing systems that have access to the same preprocessing, our arg2vec model gives the best performance particularly in the information-centric V-measures. Also note, that it seems robust to noise incurred by the automatic parsing and argument identification procedures. Titov and Klementiev (2012) report a (weighted) F1 of 83.0 on the gold standard CoNLL-2008 dataset, using a coupled model where parameters are shared across verbs and a form of smoothing which replaces argument fillers by lexical cluster ids stemming from Brown et al.’s (1992) algorithm (trained on the RCV1 corpus, about 63 millions words). Our model would presumably benefit from a similar coupling mechanism which we could enforce as a constraint in the ILP. However, we leave this to future work. When tested on automatic parses and gold arguments, their model yields a weighted F1 of 78.8. For comparison, arg2vec obtains</context>
</contexts>
<marker>Titov, Klementiev, 2012</marker>
<rawString>Ivan Titov and Alexandre Klementiev. 2012. A Bayesian approach to unsupervised semantic role induction. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, pages 12–22, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev-Arie Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: A simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>384--394</pages>
<location>Uppsala,</location>
<contexts>
<context position="5514" citStr="Turian et al., 2010" startWordPosition="824" endWordPosition="827">explicit objective function can potentially yield higher quality output compared to greedy algorithms (such as agglomerative clustering). Secondly, through the use of constraints, we can model task-specific knowledge (e.g., semantic roles are unique within a frame). Experimental results show improved performance over both previous unsupervised semantic role labeling approaches and other distributed word representation models. 2 Related Work Our model is inspired by recent work in learning distributed representations of words (Bengio et al., 2006; Mnih and Hinton, 2008; Collobert et al., 2011; Turian et al., 2010; Mikolov et al., 2013a). In this framework, a neural network is used to predict a word taking into account its context. Words are represented by vectors which are concatenated or averaged in order to form a representation of the context. We induce vector representations to represent each predicate and its argument. As a learning objective, vectors are required to contribute to a prediction task about the target argument in the sentence, given the predicate and a small window of surrounding arguments. Similarly, predicate vectors are learned from the contexts of preceding arguments, and are re</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev-Arie Ratinov, and Yoshua Bengio. 2010. Word representations: A simple and general method for semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 384–394, Uppsala, Sweden.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>