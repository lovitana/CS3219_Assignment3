<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001132">
<title confidence="0.980304">
Distant Supervision for Relation Extraction via Piecewise
Convolutional Neural Networks
</title>
<author confidence="0.988768">
Daojian Zeng, Kang Liu, Yubo Chen and Jun Zhao
</author>
<affiliation confidence="0.9837835">
National Laboratory of Pattern Recognition
Institute of Automation, Chinese Academy of Sciences, Beijing, 100190, China
</affiliation>
<email confidence="0.996885">
{djzeng,kliu,yubo.chen,jzhao}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.994744" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999929321428571">
Two problems arise when using distant su-
pervision for relation extraction. First, in
this method, an already existing knowl-
edge base is heuristically aligned to texts,
and the alignment results are treated as la-
beled data. However, the heuristic align-
ment can fail, resulting in wrong label
problem. In addition, in previous ap-
proaches, statistical models have typically
been applied to ad hoc features. The noise
that originates from the feature extraction
process can cause poor performance.
In this paper, we propose a novel
model dubbed the Piecewise Convolu-
tional Neural Networks (PCNNs) with
multi-instance learning to address these
two problems. To solve the first prob-
lem, distant supervised relation extraction
is treated as a multi-instance problem in
which the uncertainty of instance labels
is taken into account. To address the lat-
ter problem, we avoid feature engineering
and instead adopt convolutional architec-
ture with piecewise max pooling to auto-
matically learn relevant features. Exper-
iments show that our method is effective
and outperforms several competitive base-
line methods.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999707666666667">
In relation extraction, one challenge that is faced
when building a machine learning system is the
generation of training examples. One common
technique for coping with this difficulty is distant
supervision (Mintz et al., 2009) which assumes
that if two entities have a relationship in a known
knowledge base, then all sentences that mention
these two entities will express that relationship in
some way. Figure 1 shows an example of the auto-
</bodyText>
<figureCaption confidence="0.985972666666667">
Figure 1: Training instances generated through
distant supervision. Upper sentence: correct la-
beling; lower sentence: incorrect labeling.
</figureCaption>
<bodyText confidence="0.999826413793104">
matic labeling of data through distant supervision.
In this example, Apple and Steve Jobs are two re-
lated entities in Freebase1. All sentences that con-
tain these two entities are selected as training in-
stances. The distant supervision strategy is an ef-
fective method of automatically labeling training
data. However, it has two major shortcomings
when used for relation extraction.
First, the distant supervision assumption is too
strong and causes the wrong label problem. A sen-
tence that mentions two entities does not necessar-
ily express their relation in a knowledge base. It is
possible that these two entities may simply share
the same topic. For instance, the upper sentence
indeed expresses the “company/founders” relation
in Figure 1. The lower sentence, however, does not
express this relation but is still selected as a train-
ing instance. This will hinder the performance of
a model trained on such noisy data.
Second, previous methods (Mintz et al., 2009;
Riedel et al., 2010; Hoffmann et al., 2011) have
typically applied supervised models to elaborately
designed features when obtained the labeled data
through distant supervision. These features are
often derived from preexisting Natural Language
Processing (NLP) tools. Since errors inevitably
exist in NLP tools, the use of traditional features
leads to error propagation or accumulation. Dis-
tant supervised relation extraction generally ad-
</bodyText>
<footnote confidence="0.988171">
1http://www.freebase.com/
</footnote>
<page confidence="0.640195">
1753
</page>
<note confidence="0.992008">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1753–1762,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figure confidence="0.982272428571428">
8000
6000
Number af sentence 4000
2000
0
0 20 40 60 80 100
Sentence Length
</figure>
<figureCaption confidence="0.9938345">
Figure 2: The sentence length distribution of
Riedel’s dataset.
</figureCaption>
<bodyText confidence="0.999421742424243">
dresses corpora from the Web, including many
informal texts. Figure 2 shows the sentence
length distribution of a benchmark distant super-
vision dataset that was developed by Riedel et
al. (2010). Approximately half of the sentences
are longer than 40 words. McDonald and Nivre
(2007) showed that the accuracy of syntactic pars-
ing decreases significantly with increasing sen-
tence length. Therefore, when using traditional
features, the problem of error propagation or ac-
cumulation will not only exist, it will grow more
serious.
In this paper, we propose a novel model dubbed
Piecewise Convolutional Neural Networks (PC-
NNs) with multi-instance learning to address the
two problems described above. To address the first
problem, distant supervised relation extraction is
treated as a multi-instance problem similar to pre-
vious studies (Riedel et al., 2010; Hoffmann et al.,
2011; Surdeanu et al., 2012). In multi-instance
problem, the training set consists of many bags,
and each contains many instances. The labels of
the bags are known; however, the labels of the in-
stances in the bags are unknown. We design an
objective function at the bag level. In the learning
process, the uncertainty of instance labels can be
taken into account; this alleviates the wrong label
problem.
To address the second problem, we adopt con-
volutional architecture to automatically learn rel-
evant features without complicated NLP prepro-
cessing inspired by Zeng et al. (2014). Our pro-
posal is an extension of Zeng et al. (2014), in
which a single max pooling operation is utilized
to determine the most significant features. Al-
though this operation has been shown to be effec-
tive for textual feature representation (Collobert et
al., 2011; Kim, 2014), it reduces the size of the
hidden layers too rapidly and cannot capture the
structural information between two entities (Gra-
ham, 2014). For example, to identify the relation
between Steve Jobs and Apple in Figure 1, we need
to specify the entities and extract the structural
features between them. Several approaches have
employed manually crafted features that attempt
to model such structural information. These ap-
proaches usually consider both internal and exter-
nal contexts. A sentence is inherently divided into
three segments according to the two given entities.
The internal context includes the characters inside
the two entities, and the external context involves
the characters around the two entities (Zhang et
al., 2006). Clearly, single max pooling is not suf-
ficient to capture such structural information. To
capture structural and other latent information, we
divide the convolution results into three segments
based on the positions of the two given entities and
devise a piecewise max pooling layer instead of
the single max pooling layer. The piecewise max
pooling procedure returns the maximum value in
each segment instead of a single maximum value
over the entire sentence. Thus, it is expected to
exhibit superior performance compared with tra-
ditional methods.
The contributions of this paper can be summa-
rized as follows.
</bodyText>
<listItem confidence="0.963190615384615">
• We explore the feasibility of performing dis-
tant supervised relation extraction without
hand-designed features. PCNNS are pro-
posed to automatically learn features without
complicated NLP preprocessing.
• To address the wrong label problem, we de-
velop innovative solutions that incorporate
multi-instance learning into the PCNNS for
distant supervised relation extraction.
• In the proposed network, we devise a piece-
wise max pooling layer, which aims to cap-
ture structural information between two enti-
ties.
</listItem>
<sectionHeader confidence="0.999215" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998626333333333">
Relation extraction is one of the most important
topics in NLP. Many approaches to relation ex-
traction have been developed, such as bootstrap-
ping, unsupervised relation discovery and super-
vised classification. Supervised approaches are
the most commonly used methods for relation
</bodyText>
<page confidence="0.989884">
1754
</page>
<bodyText confidence="0.999985">
extraction and yield relatively high performance
(Bunescu and Mooney, 2006; Zelenko et al., 2003;
Zhou et al., 2005). In the supervised paradigm, re-
lation extraction is considered to be a multi-class
classification problem and may suffer from a lack
of labeled data for training. To address this prob-
lem, Mintz et al. (2009) adopted Freebase to per-
form distant supervision. As described in Sec-
tion 1, the algorithm for training data generation
is sometimes faced with the wrong label problem.
To address this shortcoming, (Riedel et al., 2010;
Hoffmann et al., 2011; Surdeanu et al., 2012) de-
veloped the relaxed distant supervision assump-
tion for multi-instance learning. The term ‘multi-
instance learning was coined by (Dietterich et al.,
1997) while investigating the problem of predict-
ing drug activity. In multi-instance learning, the
uncertainty of instance labels can be taken into ac-
count. The focus of multi-instance learning is to
discriminate among the bags.
These methods have been shown to be effec-
tive for relation extraction. However, their per-
formance depends strongly on the quality of the
designed features. Most existing studies have con-
centrated on extracting features to identify the
relations between two entities. Previous meth-
ods can be generally categorized into two types:
feature-based methods and kernel-based methods.
In feature-based methods, a diverse set of strate-
gies is exploited to convert classification clues
(e.g., sequences, parse trees) into feature vec-
tors (Kambhatla, 2004; Suchanek et al., 2006).
Feature-based methods suffer from the necessity
of selecting a suitable feature set when convert-
ing structured representations into feature vectors.
Kernel-based methods provide a natural alterna-
tive to exploit rich representations of input classifi-
cation clues, such as syntactic parse trees. Kernel-
based methods enable the use of a large set of fea-
tures without needing to extract them explicitly.
Several kernels have been proposed, such as the
convolution tree kernel (Qian et al., 2008), the sub-
sequence kernel (Bunescu and Mooney, 2006) and
the dependency tree kernel (Bunescu and Mooney,
2005).
Nevertheless, as mentioned in Section 1, it is
difficult to design high-quality features using ex-
isting NLP tools. With the recent revival of in-
terest in neural networks, many researchers have
investigated the possibility of using neural net-
works to automatically learn features (Socher et
al., 2012; Zeng et al., 2014). Inspired by Zeng
et al. (2014), we propose the use of PCNNs with
multi-instance learning to automatically learn fea-
tures for distant supervised relation extraction. Di-
etterich et al. (1997) suggested that the design
of multi-instance modifications for neural net-
works is a particularly interesting topic. Zhang
and Zhou (2006) successfully incorporated multi-
instance learning into traditional Backpropagation
(BP) and Radial Basis Function (RBF) networks
and optimized these networks by minimizing a
sum-of-squares error function. In contrast to their
method, we define the objective function based on
the cross-entropy principle.
</bodyText>
<sectionHeader confidence="0.998578" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.9560575">
Distant supervised relation extraction is formu-
lated as multi-instance problem. In this section,
we present innovative solutions that incorporate
multi-instance learning into a convolutional neu-
ral network to fulfill this task. PCNNs are pro-
posed for the automatic learning of features with-
out complicated NLP preprocessing. Figure 3
shows our neural network architecture for distant
supervised relation extraction. It illustrates the
procedure that handles one instance of a bag. This
procedure includes four main parts: Vector Rep-
resentation, Convolution, Piecewise Max Pooling
and Softmax Output. We describe these parts in
detail below.
</bodyText>
<subsectionHeader confidence="0.997155">
3.1 Vector Representation
</subsectionHeader>
<bodyText confidence="0.999901">
The inputs of our network are raw word tokens.
When using neural networks, we typically trans-
form word tokens into low-dimensional vectors.
In our method, each input word token is trans-
formed into a vector by looking up pre-trained
word embeddings. Moreover, we use position fea-
tures (PFs) to specify entity pairs, which are also
transformed into vectors by looking up position
embeddings.
</bodyText>
<subsectionHeader confidence="0.912809">
3.1.1 Word Embeddings
</subsectionHeader>
<bodyText confidence="0.999963727272727">
Word embeddings are distributed representations
of words that map each word in a text to a ‘k&apos;-
dimensional
k&apos;-
dimensional real-valued vector. They have re-
cently been shown to capture both semantic and
syntactic information about words very well, set-
ting performance records in several word similar-
ity tasks (Mikolov et al., 2013; Pennington et al.,
2014). Using word embeddings that have been
trained a priori has become common practice for
</bodyText>
<page confidence="0.988446">
1755
</page>
<figureCaption confidence="0.981755">
Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extrac-
tion, illustrating the procedure for handling one instance of a bag and predicting the relation between
Kojo Annan and Kofi Annan.
</figureCaption>
<figure confidence="0.995517545454546">
...
hired
,
the
son
of
...
,
in
...
word position
</figure>
<bodyText confidence="0.957330375">
enhancing many other NLP tasks (Parikh et al.,
2014; Huang et al., 2014).
A common method of training a neural network
is to randomly initialize all parameters and then
optimize them using an optimization algorithm.
Recent research (Erhan et al., 2010) has shown
that neural networks can converge to better local
minima when they are initialized with word em-
beddings. Word embeddings are typically learned
in an entirely unsupervised manner by exploiting
the co-occurrence structure of words in unlabeled
text. Researchers have proposed several methods
of training word embeddings (Bengio et al., 2003;
Collobert et al., 2011; N ikolov et al., 2013). In
this paper, we use the Skip-gram model (N ikolov
et al., 2013) to train word embeddings.
</bodyText>
<subsectionHeader confidence="0.712943">
3.1.2 Position Embeddings
</subsectionHeader>
<bodyText confidence="0.994441523809524">
In relation extraction, we focus on assigning labels
to entity pairs. Similar to Zeng et al. (2014), we
use PFs to specify entity pairs. A PF is defined
as the combination of the relative distances from
the current word to e1 and e2. For instance, in the
following example, the relative distances from son
to e1 (Kojo Annan) and e2 (Kofi Annan) are 3 and
-2, respectively.
... hired Kojo Annan , the son of Kofi Annan , in ...
Two position embedding matrixes (PF1 and
PF2) are randomly initialized. We then transform
the relative distances into real valued vectors by
looking up the position embedding matrixes. In
the example shown in Figure 3, it is assumed that
the size of the word embedding is dw = 4 and that
the size of the position embedding is dp = 1. In
combined word embeddings and position embed-
dings, the vector representation part transforms an
instance into a matrix S E Rsxd, where s is the
sentence length and d = dw + dp * 2. The matrix
S is subsequently fed into the convolution part.
</bodyText>
<subsectionHeader confidence="0.999016">
3.2 Convolution
</subsectionHeader>
<bodyText confidence="0.99930735">
In relation extraction, an input sentence that is
marked as containing the target entities corre-
sponds only to a relation type; it does not predict
labels for each word. Thus, it might be necessary
to utilize all local features and perform this predic-
tion globally. When using a neural network, the
convolution approach is a natural means of merg-
ing all these features (Collobert et al., 2011).
Convolution is an operation between a vector of
weights, w, and a vector of inputs that is treated as
a sequence q. The weights matrix w is regarded
as the filter for the convolution. In the example
shown in Figure 3, we assume that the length of
the filter is w (w = 3); thus, w E Rm (m = w*d).
We consider S to be a sequence {q1, q2, , qs},
where qi E Rd. In general, let qi:j refer to the
concatenation of qi to qj. The convolution op-
eration involves taking the dot product of w with
each w-gram in the sequence q to obtain another
sequence c E Rs+w−1:
</bodyText>
<equation confidence="0.959951">
cj = wqj−w+1:j (1)
</equation>
<bodyText confidence="0.9992765">
where the index j ranges from 1 to s+w −1. Out-
of-range input values qi, where i &lt; 1 or i &gt; s, are
</bodyText>
<page confidence="0.96173">
1756
</page>
<bodyText confidence="0.997948714285714">
taken to be zero.
The ability to capture different features typi-
cally requires the use of multiple filters (or feature
maps) in the convolution. Under the assumption
that we use n filters (W = {w1, w2,··· , wn}),
the convolution operation can be expressed as fol-
lows:
</bodyText>
<equation confidence="0.898097">
cij = wiqj−w+1:j 1 ≤ i ≤ n (2)
</equation>
<bodyText confidence="0.98917075">
The convolution result is a matrix C =
{c1, c2, · · · , cn} ∈ Rn×(s+w−1). Figure 3 shows
an example in which we use 3 different filters in
the convolution procedure.
</bodyText>
<subsectionHeader confidence="0.995599">
3.3 Piecewise Max Pooling
</subsectionHeader>
<bodyText confidence="0.999981709677419">
The size of the convolution output matrix C ∈
Rn×(s+w−1) depends on the number of tokens s
in the sentence that is fed into the network. To
apply subsequent layers, the features that are ex-
tracted by the convolution layer must be com-
bined such that they are independent of the sen-
tence length. In traditional Convolution Neural
Networks (CNNs), max pooling operations are of-
ten applied for this purpose (Collobert et al., 2011;
Zeng et al., 2014). This type of pooling scheme
naturally addresses variable sentence lengths. The
idea is to capture the most significant features
(with the highest values) in each feature map.
However, despite the widespread use of single
max pooling, this approach is insufficient for rela-
tion extraction. As described in the first section,
single max pooling reduces the size of the hidden
layers too rapidly and is too coarse to capture fine-
grained features for relation extraction. In addi-
tion, single max pooling is not sufficient to cap-
ture the structural information between two enti-
ties. In relation extraction, an input sentence can
be divided into three segments based on the two
selected entities. Therefore, we propose a piece-
wise max pooling procedure that returns the max-
imum value in each segment instead of a single
maximum value. As shown in Figure 3, the output
of each convolutional filter ci is divided into three
segments {ci1, ci2, ci3} by Kojo Annan and Kofi
Annan. The piecewise max pooling procedure can
be expressed as follows:
</bodyText>
<equation confidence="0.9217">
pij = max(cij) 1 ≤ i ≤ n, 1 ≤ j ≤ 3 (3)
</equation>
<bodyText confidence="0.999747">
For the output of each convolutional filter,
we can obtain a 3-dimensional vector pi =
{pi1, pi2, pi3}. We then concatenate all vectors
p1:n and apply a non-linear function, such as the
hyperbolic tangent. Finally, the piecewise max
pooling procedure outputs a vector:
</bodyText>
<equation confidence="0.999503">
g = tanh(p1:n) (4)
</equation>
<bodyText confidence="0.9999605">
where g ∈ R3n. The size of g is fixed and is no
longer related to the sentence length.
</bodyText>
<subsectionHeader confidence="0.989284">
3.4 Softmax Output
</subsectionHeader>
<bodyText confidence="0.999949">
To compute the confidence of each relation, the
feature vector g is fed into a softmax classifier.
</bodyText>
<equation confidence="0.996064">
o = W1g + b (5)
W1 ∈ Rn1×3n is the transformation matrix, and
</equation>
<bodyText confidence="0.994652454545454">
o ∈ Rn1 is the final output of the network, where
n1 is equal to the number of possible relation types
for the relation extraction system.
We employ dropout (Hinton et al., 2012) on the
penultimate layer for regularization. Dropout pre-
vents the co-adaptation of hidden units by ran-
domly dropping out a proportion p of the hidden
units during forward computing. We first apply a
“masking” operation (g◦r) on g, where r is a vec-
tor of Bernoulli random variables with probability
p of being 1. Eq.(5) becomes:
</bodyText>
<equation confidence="0.945349">
o = W1(g ◦ r) + b (6)
</equation>
<bodyText confidence="0.999254857142857">
Each output can then be interpreted as the con-
fidence score of the corresponding relation. This
score can be interpreted as a conditional probabil-
ity by applying a softmax operation (see Section
3.5). In the test procedure, the learned weight vec-
tors are scaled by p such that W1 = pW1 and are
used (without dropout) to score unseen instances.
</bodyText>
<subsectionHeader confidence="0.953191">
3.5 Multi-instance Learning
</subsectionHeader>
<bodyText confidence="0.997683214285714">
In order to alleviate the wrong label problem,
we use multi-instance learning for PCNNs. The
PCNNs-based relation extraction can be stated as a
quintuple 0 = (E, PF1, PF2, W, W1)2. The in-
put to the network is a bag. Suppose that there are
T bags {M1, M2, · · · , MT} and that the i-th bag
contains qi instances Mi = {m1i, m2i, · · · , m?&apos;
i }.
The objective of multi-instance learning is to pre-
dict the labels of the unseen bags. In this paper, all
instances in a bag are considered independently.
Given an input instance mji , the network with the
parameter 0 outputs a vector o, where the r-th
component or corresponds to the score associated
</bodyText>
<footnote confidence="0.825032">
2� represents the word embeddings.
</footnote>
<page confidence="0.982906">
1757
</page>
<construct confidence="0.501314">
Algorithm 1 Multi-instance learning
</construct>
<listItem confidence="0.949225">
1: Initialize 0. Partition the bags into mini-
batches of size bs.
2: Randomly choose a mini-batch, and feed the
bags into the network one by one.
3: Find the j-th instance mji (1 ≤ i ≤ bs) in each
bag according to Eq. (9).
4: Update 0 based on the gradients of mji (1 ≤
i ≤ bs) via Adadelta.
5: Repeat steps 2-4 until either convergence or
the maximum number of epochs is reached.
</listItem>
<bodyText confidence="0.994950333333333">
with relation r. To obtain the conditional probabil-
ity p(r|m, 0), we apply a softmax operation over
all relation types:
</bodyText>
<equation confidence="0.999660333333333">
p(r |mji; 0) = nl eor (7)
E eok
k=1
</equation>
<bodyText confidence="0.999948833333333">
The objective of multi-instance learning is to dis-
criminate bags rather than instances. To do so,
we must define the objective function on the bags.
Given all (T) training bags (Mi, yi), we can define
the objective function using cross-entropy at the
bag level as follows:
</bodyText>
<equation confidence="0.998699333333333">
T
J (0) = log p(yi|mji; 0) (8)
i=1
</equation>
<bodyText confidence="0.878957">
where j is constrained as follows:
</bodyText>
<equation confidence="0.8595795">
j* = arg maxp(yi|mji; 0) 1 ≤ j ≤ qi (9)
j
</equation>
<bodyText confidence="0.999974588235295">
Using this defined objective function, we max-
imize J(0) through stochastic gradient descent
over shuffled mini-batches with the Adadelta
(Zeiler, 2012) update rule. The entire training pro-
cedure is described in Algorithm 1.
From the introduction presented above, we
know that the traditional backpropagation algo-
rithm modifies a network in accordance with all
training instances, whereas backpropagation with
multi-instance learning modifies a network based
on bags. Thus, our method captures the nature
of distant supervised relation extraction, in which
some training instances will inevitably be incor-
rectly labeled. When a trained PCNN is used for
prediction, a bag is positively labeled if and only
if the output of the network on at least one of its
instances is assigned a positive label.
</bodyText>
<sectionHeader confidence="0.999015" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999922166666667">
Our experiments are intended to provide evidence
that supports the following hypothesis: automat-
ically learning features using PCNNs with multi-
instance learning can lead to an increase in perfor-
mance. To this end, we first introduce the dataset
and evaluation metrics used. Next, we test several
variants via cross-validation to determine the pa-
rameters to be used in our experiments. We then
compare the performance of our method to those
of several traditional methods. Finally, we evalu-
ate the effects of piecewise max pooling and multi-
instance learning3.
</bodyText>
<subsectionHeader confidence="0.970708">
4.1 Dataset and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999982823529412">
We evaluate our method on a widely used dataset4
that was developed by (Riedel et al., 2010) and
has also been used by (Hoffmann et al., 2011; Sur-
deanu et al., 2012). This dataset was generated by
aligning Freebase relations with the NYT corpus,
with sentences from the years 2005-2006 used as
the training corpus and sentences from 2007 used
as the testing corpus.
Following previous work (Mintz et al., 2009),
we evaluate our method in two ways: the held-out
evaluation and the manual evaluation. The held-
out evaluation only compares the extracted rela-
tion instances against Freebase relation data and
reports the precision/recall curves of the experi-
ments. In the manual evaluation, we manually
check the newly discovered relation instances that
are not in Freebase.
</bodyText>
<subsectionHeader confidence="0.885235">
4.2 Experimental Settings
4.2.1 Pre-trained Word Embeddings
</subsectionHeader>
<bodyText confidence="0.999959333333333">
In this paper, we use the Skip-gram model
(word2vec)5 to train the word embeddings on the
NYT corpus. Word2vec first constructs a vocab-
ulary from the training text data and then learns
vector representations of the words. To obtain the
embeddings of the entities, we concatenate the to-
kens of a entity using the ## operator when the
entity has multiple word tokens. Since a compar-
ison of the word embeddings is beyond the scope
</bodyText>
<footnote confidence="0.719762">
3With regard to the position feature, our experiments yield
the same positive results described in Zeng et al. (2014). Be-
cause the position feature is not the main contribution of this
paper, we do not present the results without the position fea-
ture.
4http://iesl.cs.umass.edu/riedel/ecml/
5https://code.google.com/p/word2vec/
</footnote>
<page confidence="0.975336">
1758
</page>
<table confidence="0.722415666666667">
Window Feature Word Position Batch Adadelta parameter Dropout
size maps dimension dimension size probability
w = 3 n = 230 d,,,=50 dp = 5 b3=50 p = 0.95,E = 1e−6 p = 0.5
</table>
<tableCaption confidence="0.998828">
Table 1: Parameters used in our experiments.
</tableCaption>
<bodyText confidence="0.989802">
of this paper, our experiments directly utilize 50-
dimensional vectors.
</bodyText>
<subsubsectionHeader confidence="0.67971">
4.2.2 Parameter Settings
</subsubsectionHeader>
<bodyText confidence="0.9999875">
In this section, we experimentally study the ef-
fects of two parameters on our models: the win-
dow size, w, and the number of feature maps, n.
Following (Surdeanu et al., 2012), we tune all of
the models using three-fold validation on the train-
ing set. We use a grid search to determine the op-
timal parameters and manually specify subsets of
the parameter spaces: w E 11, 2, 3, · · · , 71 and
n E 150,60,··· , 3001. Table 1 shows all parame-
ters used in the experiments. Because the position
dimension has little effect on the result, we heuris-
tically choose dp = 5. The batch size is fixed
to 50. We use Adadelta (Zeiler, 2012) in the up-
date procedure; it relies on two main parameters,
p and E, which do not significantly affect the per-
formance (Zeiler, 2012). Following (Zeiler, 2012),
we choose 0.95 and 1e−6, respectively, as the val-
ues of these parameters. In the dropout operation,
we randomly set the hidden unit activities to zero
with a probability of 0.5 during training.
</bodyText>
<subsectionHeader confidence="0.986005">
4.3 Comparison with Traditional Approaches
4.3.1 Held-out Evaluation
</subsectionHeader>
<bodyText confidence="0.995940210526316">
The held-out evaluation provides an approximate
measure of precision without requiring costly hu-
man evaluation. Half of the Freebase relations are
used for testing. The relation instances discovered
from the test articles are automatically compared
with those in Freebase.
To evaluate the proposed method, we select
the following three traditional methods for com-
parison. Mintz represents a traditional distant-
supervision-based model that was proposed by
(Mintz et al., 2009). MultiR is a multi-instance
learning method that was proposed by (Hoffmann
et al., 2011). MIML is a multi-instance multi-
label model that was proposed by (Surdeanu et al.,
2012). Figure 4 shows the precision-recall curves
for each method, where PCNNs+MIL denotes
our method, and demonstrates that PCNNs+MIL
achieves higher precision over the entire range of
recall. PCNNs+MIL enhances the recall to ap-
</bodyText>
<figureCaption confidence="0.989419">
Figure 4: Performance comparison of the pro-
posed method with traditional approaches.
</figureCaption>
<table confidence="0.9980706">
Top N Mintz MultiR MIML PCNNs+MIL
Top 100 0.77 0.83 0.85 0.86
Top 200 0.71 0.74 0.75 0.80
Top 500 0.55 0.59 0.61 0.69
Average 0.676 0.720 0.737 0.783
</table>
<tableCaption confidence="0.99519">
Table 2: Precision values for the top 100, top 200,
</tableCaption>
<bodyText confidence="0.988409588235294">
and top 500 extracted relation instances upon man-
ual evaluation.
proximately 34% without any loss of precision. In
terms of both precision and recall, PCNNs+MIL
outperforms all other evaluated approaches. No-
tably, the results of the methods evaluated for com-
parison were obtained using manually crafted fea-
tures. By contrast, our result is obtained by au-
tomatically learning features from original words.
The results demonstrate that the proposed method
is an effective technique for distant supervised re-
lation extraction. Automatically learning features
via PCNNs can alleviate the error propagation that
occurs in traditional feature extraction. Incorpo-
rating multi-instance learning into a convolutional
neural network is an effective means of addressing
the wrong label problem.
</bodyText>
<subsectionHeader confidence="0.665314">
4.3.2 Manual Evaluation
</subsectionHeader>
<bodyText confidence="0.9983982">
It is worth emphasizing that there is a sharp de-
cline in the held-out precision-recall curves of PC-
NNs+MIL at very low recall (Figure 4). A manual
check of the misclassified examples that were pro-
duced with high confidence reveals that the ma-
</bodyText>
<page confidence="0.983923">
1759
</page>
<bodyText confidence="0.99995412">
jorities of these examples are false negatives and
are actually true relation instances that were mis-
classified due to the incomplete nature of Free-
base.
Thus, the held-out evaluation suffers from false
negatives in Freebase. We perform a manual eval-
uation to eliminate these problems. For the manual
evaluation, we choose the entity pairs for which
at least one participating entity is not present in
Freebase as a candidate. This means that there is
no overlap between the held-out and manual can-
didates. Because the number of relation instances
that are expressed in the test data is unknown, we
cannot calculate the recall in this case. Instead, we
calculate the precision of the top N extracted rela-
tion instances. Table 2 presents the manually eval-
uated precisions for the top 100, top 200, and top
500 extracted instances. The results show that PC-
NNs+MIL achieves the best performance; more-
over, the precision is higher than in the held-out
evaluation. This finding indicates that many of the
false negatives that we predict are, in fact, true re-
lational facts. The sharp decline observed in the
held-out precision-recall curves is therefore rea-
sonable.
</bodyText>
<subsectionHeader confidence="0.9966485">
4.4 Effect of Piecewise Max Pooling and
Multi-instance Learning
</subsectionHeader>
<bodyText confidence="0.999479652173913">
In this paper, we develop a method of piecewise
max pooling and incorporate multi-instance learn-
ing into convolutional neural networks for distant
supervised relation extraction. To demonstrate the
effects of these two techniques, we empirically
study the performance of systems in which these
techniques are not implemented through held-out
evaluations (Figure 5). CNNs represents convolu-
tional neural networks to which single max pool-
ing is applied. Figure 5 shows that when piecewise
max pooling is used (PCNNs), better results are
produced than those achieved using CNNs. More-
over, compared with CNNs+MIL, PCNNs achieve
slightly higher precision when the recall is greater
than 0.08. Since the parameters for all the model
are determined by grid search, we can observe that
CNNs cannot achieve competitive results com-
pared to PCNNs when increasing the size of the
hidden layer of convolutional neural networks. It
means that we cannot capture more useful infor-
mation by simply increasing the network param-
eter. These results demonstrate that the proposed
piecewise max pooling technique is beneficial and
</bodyText>
<figureCaption confidence="0.964215">
Figure 5: Effect of piecewise max pooling and
multi-instance learning.
</figureCaption>
<bodyText confidence="0.991058">
can effectively capture structural information for
relation extraction. A similar phenomenon is also
observed when multi-instance learning is added to
the network. Both CNNs+MIL and PCNNs+MIL
outperform their counterparts CNNs and PCNNs,
respectively, thereby demonstrating that incorpo-
ration of multi-instance learning into our neural
network was successful in solving the wrong label
problem. As expected, PCNNs+MIL obtains the
best results because the advantages of both tech-
niques are achieved simultaneously.
</bodyText>
<sectionHeader confidence="0.998924" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999960363636364">
In this paper, we exploit Piecewise Convolutional
Neural Networks (PCNNs) with multi-instance
learning for distant supervised relation extraction.
In our method, features are automatically learned
without complicated NLP preprocessing. We also
successfully devise a piecewise max pooling layer
in the proposed network to capture structural in-
formation and incorporate multi-instance learning
to address the wrong label problem. Experimental
results show that the proposed approach offers sig-
nificant improvements over comparable methods.
</bodyText>
<sectionHeader confidence="0.998027" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999868666666667">
This work was sponsored by the National Basic
Research Program of China (no. 2014CB340503)
and the National Natural Science Foundation of
China (no. 61272332 and no. 61202329). We
thank the anonymous reviewers for their insight-
ful comments.
</bodyText>
<page confidence="0.986669">
1760
</page>
<sectionHeader confidence="0.983126" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999909203883495">
Yoshua Bengio, Rjean Ducharme, Pascal Vincent, and
Christian Jauvin. 2003. A neural probabilistic lan-
guage model. Journal of Machine Learning Re-
search, 3:1137–1155.
Razvan C. Bunescu and Raymond J. Mooney. 2005. A
shortest path dependency kernel for relation extrac-
tion. In Proceedings of HLT/EMNLP, pages 724–
731.
Razvan Bunescu and Raymond Mooney. 2006. Subse-
quence kernels for relation extraction. Proceedings
of NIPS, 18:171–178.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12:2493–2537.
Thomas G Dietterich, Richard H Lathrop, and Tom´as
Lozano-P´erez. 1997. Solving the multiple instance
problem with axis-parallel rectangles. Journal of
Artificial intelligence, 89(1):31–71.
Dumitru Erhan, Aaron Courville, Yoshua Bengio, and
Pascal Vincent. 2010. Why does unsupervised pre-
training help deep learning? Journal of Machine
Learning Research, 11:625–660.
Benjamin Graham. 2014. Fractional max-pooling.
arXiv preprint arXiv:1412.6071.
Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky,
Ilya Sutskever, and Ruslan R Salakhutdinov. 2012.
Improving neural networks by preventing co-
adaptation of feature detectors. arXiv preprint
arXiv:1207.0580.
Raphael Hoffmann, Congle Zhang, Xiao Ling,
Luke Zettlemoyer, and Daniel S. Weld. 2011.
Knowledge-based weak supervision for information
extraction of overlapping relations. In Proceedings
of ACL, pages 541–550.
Fei Huang, Arun Ahuja, Doug Downey, Yi Yang,
Yuhong Guo, and Alexander Yates. 2014. Learning
representations for weakly supervised natural lan-
guage processing tasks. Journal of Computational
Linguistics, 40(1):85–120, March.
Nanda Kambhatla. 2004. Combining lexical, syntac-
tic, and semantic features with maximum entropy
models for extracting relations. In Proceedings of
ACLdemo.
Yoon Kim. 2014. Convolutional neural networks for
sentence classification. In Proceedings of EMNLP,
pages 1746–1751.
Ryan T McDonald and Joakim Nivre. 2007. Charac-
terizing the errors of data-driven dependency parsing
models. In Proceedings of EMNLP-CoNLL, pages
122–131.
Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey
Dean. 2013. Efficient estimation of word represen-
tations in vector space. In Proceedings of Workshop
at ICLR.
Mike Mintz, Steven Bills, Rion Snow, and Dan Juraf-
sky. 2009. Distant supervision for relation extrac-
tion without labeled data. In Proceedings of ACL-
AFNLP, pages 1003–1011.
Ankur P Parikh, Shay B Cohen, and Eric P Xing.
2014. Spectral unsupervised parsing with additive
tree metrics. In Proceedings of ACL, pages 1062–
1072.
Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for word
representation. In Proceedings of EMNLP 2014,
pages 1746–1751.
Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming
Zhu, and Peide Qian. 2008. Exploiting constituent
dependencies for tree kernel-based semantic relation
extraction. In Proceedings of COLING, pages 697–
704.
Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Proceedings of ECML PKDD,
pages 148–163.
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic composi-
tionality through recursive matrix-vector spaces. In
Proceedings of EMNLP-CoNLL, pages 1201–1211.
Fabian M. Suchanek, Georgiana Ifrim, and Gerhard
Weikum. 2006. Combining linguistic and statistical
analysis to extract relations from web documents. In
Proceedings of KDD, pages 712–717.
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,
and Christopher D. Manning. 2012. Multi-instance
multi-label learning for relation extraction. In Pro-
ceedings of EMNLP-CoNLL, pages 455–465.
Matthew D. Zeiler. 2012. Adadelta: An adaptive learn-
ing rate method. arXiv preprint arXiv:1212.5701,
abs/1212.5701.
Dmitry Zelenko, Chinatsu Aone, and Anthony
Richardella. 2003. Kernel methods for relation ex-
traction. Journal of Machine Learning Research,
3:1083–1106.
Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou,
and Jun Zhao. 2014. Relation classification via con-
volutional deep neural network. In Proceedings of
COLING, pages 2335–2344.
Minling Zhang and Zhihua Zhou. 2006. Adapting rbf
neural networks to multi-instance learning. Neural
Processing Letters, 23(1):1–26.
</reference>
<page confidence="0.812567">
1761
</page>
<reference confidence="0.999128571428572">
Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou.
2006. A composite kernel to extract relations be-
tween entities with both flat and structured features.
In Proceedings of ACL, pages 825–832.
Guodong Zhou, Jian Su, Jie Zhang, and Min Zhang.
2005. Exploring various knowledge in relation ex-
traction. In Proceedings of ACL, pages 427–434.
</reference>
<page confidence="0.994235">
1762
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.457247">
<title confidence="0.9969765">Distant Supervision for Relation Extraction via Convolutional Neural Networks</title>
<author confidence="0.988912">Daojian Zeng</author>
<author confidence="0.988912">Kang Liu</author>
<author confidence="0.988912">Yubo Chen</author>
<author confidence="0.988912">Jun</author>
<affiliation confidence="0.991765">National Laboratory of Pattern</affiliation>
<address confidence="0.493753">Institute of Automation, Chinese Academy of Sciences, Beijing, 100190,</address>
<abstract confidence="0.997894517241379">Two problems arise when using distant supervision for relation extraction. First, in this method, an already existing knowledge base is heuristically aligned to texts, and the alignment results are treated as labeled data. However, the heuristic alignment can fail, resulting in wrong label problem. In addition, in previous approaches, statistical models have typically been applied to ad hoc features. The noise that originates from the feature extraction process can cause poor performance. In this paper, we propose a novel model dubbed the Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address these two problems. To solve the first problem, distant supervised relation extraction is treated as a multi-instance problem in which the uncertainty of instance labels is taken into account. To address the latter problem, we avoid feature engineering and instead adopt convolutional architecture with piecewise max pooling to automatically learn relevant features. Experiments show that our method is effective and outperforms several competitive baseline methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>Rjean Ducharme</author>
<author>Pascal Vincent</author>
<author>Christian Jauvin</author>
</authors>
<title>A neural probabilistic language model.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--1137</pages>
<contexts>
<context position="13180" citStr="Bengio et al., 2003" startWordPosition="2015" endWordPosition="2018">... word position enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings. Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; N ikolov et al., 2013). In this paper, we use the Skip-gram model (N ikolov et al., 2013) to train word embeddings. 3.1.2 Position Embeddings In relation extraction, we focus on assigning labels to entity pairs. Similar to Zeng et al. (2014), we use PFs to specify entity pairs. A PF is defined as the combination of the relative distances from the current word to e1 and e2. For instance, in the following example, the relative distances from son to e1 (Kojo Annan) and e2 (Kofi Annan) are 3 and -2, respectively. ... hired Kojo Annan , the son of Kofi Annan , in ... Two p</context>
</contexts>
<marker>Bengio, Ducharme, Vincent, Jauvin, 2003</marker>
<rawString>Yoshua Bengio, Rjean Ducharme, Pascal Vincent, and Christian Jauvin. 2003. A neural probabilistic language model. Journal of Machine Learning Research, 3:1137–1155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT/EMNLP,</booktitle>
<pages>724--731</pages>
<contexts>
<context position="9799" citStr="Bunescu and Mooney, 2005" startWordPosition="1497" endWordPosition="1500"> Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Dietterich et al. (1997) suggested that the design of multi-instance modifications for neural networks is a part</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of HLT/EMNLP, pages 724– 731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Raymond Mooney</author>
</authors>
<title>Subsequence kernels for relation extraction.</title>
<date>2006</date>
<booktitle>Proceedings of NIPS,</booktitle>
<pages>18--171</pages>
<contexts>
<context position="7735" citStr="Bunescu and Mooney, 2006" startWordPosition="1177" endWordPosition="1180">tive solutions that incorporate multi-instance learning into the PCNNS for distant supervised relation extraction. • In the proposed network, we devise a piecewise max pooling layer, which aims to capture structural information between two entities. 2 Related Work Relation extraction is one of the most important topics in NLP. Many approaches to relation extraction have been developed, such as bootstrapping, unsupervised relation discovery and supervised classification. Supervised approaches are the most commonly used methods for relation 1754 extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm, relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning. Th</context>
<context position="9741" citStr="Bunescu and Mooney, 2006" startWordPosition="1488" endWordPosition="1491">ences, parse trees) into feature vectors (Kambhatla, 2004; Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Dietterich et al. (1997) suggested that the design of </context>
</contexts>
<marker>Bunescu, Mooney, 2006</marker>
<rawString>Razvan Bunescu and Raymond Mooney. 2006. Subsequence kernels for relation extraction. Proceedings of NIPS, 18:171–178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="5493" citStr="Collobert et al., 2011" startWordPosition="835" endWordPosition="838">own. We design an objective function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (2014), in which a single max pooling operation is utilized to determine the most significant features. Although this operation has been shown to be effective for textual feature representation (Collobert et al., 2011; Kim, 2014), it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities (Graham, 2014). For example, to identify the relation between Steve Jobs and Apple in Figure 1, we need to specify the entities and extract the structural features between them. Several approaches have employed manually crafted features that attempt to model such structural information. These approaches usually consider both internal and external contexts. A sentence is inherently divided into three segments according to the two given entities. The internal cont</context>
<context position="13204" citStr="Collobert et al., 2011" startWordPosition="2019" endWordPosition="2022">ancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings. Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; N ikolov et al., 2013). In this paper, we use the Skip-gram model (N ikolov et al., 2013) to train word embeddings. 3.1.2 Position Embeddings In relation extraction, we focus on assigning labels to entity pairs. Similar to Zeng et al. (2014), we use PFs to specify entity pairs. A PF is defined as the combination of the relative distances from the current word to e1 and e2. For instance, in the following example, the relative distances from son to e1 (Kojo Annan) and e2 (Kofi Annan) are 3 and -2, respectively. ... hired Kojo Annan , the son of Kofi Annan , in ... Two position embedding matrix</context>
<context position="14761" citStr="Collobert et al., 2011" startWordPosition="2298" endWordPosition="2301">nd position embeddings, the vector representation part transforms an instance into a matrix S E Rsxd, where s is the sentence length and d = dw + dp * 2. The matrix S is subsequently fed into the convolution part. 3.2 Convolution In relation extraction, an input sentence that is marked as containing the target entities corresponds only to a relation type; it does not predict labels for each word. Thus, it might be necessary to utilize all local features and perform this prediction globally. When using a neural network, the convolution approach is a natural means of merging all these features (Collobert et al., 2011). Convolution is an operation between a vector of weights, w, and a vector of inputs that is treated as a sequence q. The weights matrix w is regarded as the filter for the convolution. In the example shown in Figure 3, we assume that the length of the filter is w (w = 3); thus, w E Rm (m = w*d). We consider S to be a sequence {q1, q2, , qs}, where qi E Rd. In general, let qi:j refer to the concatenation of qi to qj. The convolution operation involves taking the dot product of w with each w-gram in the sequence q to obtain another sequence c E Rs+w−1: cj = wqj−w+1:j (1) where the index j range</context>
<context position="16358" citStr="Collobert et al., 2011" startWordPosition="2607" endWordPosition="2610">(2) The convolution result is a matrix C = {c1, c2, · · · , cn} ∈ Rn×(s+w−1). Figure 3 shows an example in which we use 3 different filters in the convolution procedure. 3.3 Piecewise Max Pooling The size of the convolution output matrix C ∈ Rn×(s+w−1) depends on the number of tokens s in the sentence that is fed into the network. To apply subsequent layers, the features that are extracted by the convolution layer must be combined such that they are independent of the sentence length. In traditional Convolution Neural Networks (CNNs), max pooling operations are often applied for this purpose (Collobert et al., 2011; Zeng et al., 2014). This type of pooling scheme naturally addresses variable sentence lengths. The idea is to capture the most significant features (with the highest values) in each feature map. However, despite the widespread use of single max pooling, this approach is insufficient for relation extraction. As described in the first section, single max pooling reduces the size of the hidden layers too rapidly and is too coarse to capture finegrained features for relation extraction. In addition, single max pooling is not sufficient to capture the structural information between two entities. </context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
<author>Richard H Lathrop</author>
<author>Tom´as Lozano-P´erez</author>
</authors>
<title>Solving the multiple instance problem with axis-parallel rectangles.</title>
<date>1997</date>
<journal>Journal of Artificial intelligence,</journal>
<volume>89</volume>
<issue>1</issue>
<marker>Dietterich, Lathrop, Lozano-P´erez, 1997</marker>
<rawString>Thomas G Dietterich, Richard H Lathrop, and Tom´as Lozano-P´erez. 1997. Solving the multiple instance problem with axis-parallel rectangles. Journal of Artificial intelligence, 89(1):31–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dumitru Erhan</author>
<author>Aaron Courville</author>
<author>Yoshua Bengio</author>
<author>Pascal Vincent</author>
</authors>
<title>Why does unsupervised pretraining help deep learning?</title>
<date>2010</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>11--625</pages>
<contexts>
<context position="12831" citStr="Erhan et al., 2010" startWordPosition="1963" endWordPosition="1966">rd embeddings that have been trained a priori has become common practice for 1755 Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extraction, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. ... hired , the son of ... , in ... word position enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings. Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; N ikolov et al., 2013). In this paper, we use the Skip-gram model (N ikolov et al., 2013) to train word embeddings. 3.1.2 Position Embeddings In relation extraction, we focus on assigning labels to entity pairs. Similar to Ze</context>
</contexts>
<marker>Erhan, Courville, Bengio, Vincent, 2010</marker>
<rawString>Dumitru Erhan, Aaron Courville, Yoshua Bengio, and Pascal Vincent. 2010. Why does unsupervised pretraining help deep learning? Journal of Machine Learning Research, 11:625–660.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Graham</author>
</authors>
<title>Fractional max-pooling. arXiv preprint arXiv:1412.6071.</title>
<date>2014</date>
<contexts>
<context position="5641" citStr="Graham, 2014" startWordPosition="860" endWordPosition="862"> the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (2014), in which a single max pooling operation is utilized to determine the most significant features. Although this operation has been shown to be effective for textual feature representation (Collobert et al., 2011; Kim, 2014), it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities (Graham, 2014). For example, to identify the relation between Steve Jobs and Apple in Figure 1, we need to specify the entities and extract the structural features between them. Several approaches have employed manually crafted features that attempt to model such structural information. These approaches usually consider both internal and external contexts. A sentence is inherently divided into three segments according to the two given entities. The internal context includes the characters inside the two entities, and the external context involves the characters around the two entities (Zhang et al., 2006). </context>
</contexts>
<marker>Graham, 2014</marker>
<rawString>Benjamin Graham. 2014. Fractional max-pooling. arXiv preprint arXiv:1412.6071.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey E Hinton</author>
<author>Nitish Srivastava</author>
<author>Alex Krizhevsky</author>
<author>Ilya Sutskever</author>
<author>Ruslan R Salakhutdinov</author>
</authors>
<title>Improving neural networks by preventing coadaptation of feature detectors. arXiv preprint arXiv:1207.0580.</title>
<date>2012</date>
<contexts>
<context position="18189" citStr="Hinton et al., 2012" startWordPosition="2929" endWordPosition="2932">oncatenate all vectors p1:n and apply a non-linear function, such as the hyperbolic tangent. Finally, the piecewise max pooling procedure outputs a vector: g = tanh(p1:n) (4) where g ∈ R3n. The size of g is fixed and is no longer related to the sentence length. 3.4 Softmax Output To compute the confidence of each relation, the feature vector g is fed into a softmax classifier. o = W1g + b (5) W1 ∈ Rn1×3n is the transformation matrix, and o ∈ Rn1 is the final output of the network, where n1 is equal to the number of possible relation types for the relation extraction system. We employ dropout (Hinton et al., 2012) on the penultimate layer for regularization. Dropout prevents the co-adaptation of hidden units by randomly dropping out a proportion p of the hidden units during forward computing. We first apply a “masking” operation (g◦r) on g, where r is a vector of Bernoulli random variables with probability p of being 1. Eq.(5) becomes: o = W1(g ◦ r) + b (6) Each output can then be interpreted as the confidence score of the corresponding relation. This score can be interpreted as a conditional probability by applying a softmax operation (see Section 3.5). In the test procedure, the learned weight vector</context>
</contexts>
<marker>Hinton, Srivastava, Krizhevsky, Sutskever, Salakhutdinov, 2012</marker>
<rawString>Geoffrey E Hinton, Nitish Srivastava, Alex Krizhevsky, Ilya Sutskever, and Ruslan R Salakhutdinov. 2012. Improving neural networks by preventing coadaptation of feature detectors. arXiv preprint arXiv:1207.0580.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledge-based weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>541--550</pages>
<contexts>
<context position="3015" citStr="Hoffmann et al., 2011" startWordPosition="456" endWordPosition="459">the distant supervision assumption is too strong and causes the wrong label problem. A sentence that mentions two entities does not necessarily express their relation in a knowledge base. It is possible that these two entities may simply share the same topic. For instance, the upper sentence indeed expresses the “company/founders” relation in Figure 1. The lower sentence, however, does not express this relation but is still selected as a training instance. This will hinder the performance of a model trained on such noisy data. Second, previous methods (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011) have typically applied supervised models to elaborately designed features when obtained the labeled data through distant supervision. These features are often derived from preexisting Natural Language Processing (NLP) tools. Since errors inevitably exist in NLP tools, the use of traditional features leads to error propagation or accumulation. Distant supervised relation extraction generally ad1http://www.freebase.com/ 1753 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1753–1762, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Comp</context>
<context position="4653" citStr="Hoffmann et al., 2011" startWordPosition="696" endWordPosition="699">s. McDonald and Nivre (2007) showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length. Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious. In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above. To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). In multi-instance problem, the training set consists of many bags, and each contains many instances. The labels of the bags are known; however, the labels of the instances in the bags are unknown. We design an objective function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an ex</context>
<context position="8226" citStr="Hoffmann et al., 2011" startWordPosition="1259" endWordPosition="1262">es are the most commonly used methods for relation 1754 extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm, relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning. The term ‘multiinstance learning was coined by (Dietterich et al., 1997) while investigating the problem of predicting drug activity. In multi-instance learning, the uncertainty of instance labels can be taken into account. The focus of multi-instance learning is to discriminate among the bags. These methods have been shown to be effective for relation extraction. However, their performance depends strongly on the quality of the designed features. Most existing studies have concentrated o</context>
<context position="22099" citStr="Hoffmann et al., 2011" startWordPosition="3613" endWordPosition="3616">atures using PCNNs with multiinstance learning can lead to an increase in performance. To this end, we first introduce the dataset and evaluation metrics used. Next, we test several variants via cross-validation to determine the parameters to be used in our experiments. We then compare the performance of our method to those of several traditional methods. Finally, we evaluate the effects of piecewise max pooling and multiinstance learning3. 4.1 Dataset and Evaluation Metrics We evaluate our method on a widely used dataset4 that was developed by (Riedel et al., 2010) and has also been used by (Hoffmann et al., 2011; Surdeanu et al., 2012). This dataset was generated by aligning Freebase relations with the NYT corpus, with sentences from the years 2005-2006 used as the training corpus and sentences from 2007 used as the testing corpus. Following previous work (Mintz et al., 2009), we evaluate our method in two ways: the held-out evaluation and the manual evaluation. The heldout evaluation only compares the extracted relation instances against Freebase relation data and reports the precision/recall curves of the experiments. In the manual evaluation, we manually check the newly discovered relation instanc</context>
<context position="25475" citStr="Hoffmann et al., 2011" startWordPosition="4164" endWordPosition="4167">son with Traditional Approaches 4.3.1 Held-out Evaluation The held-out evaluation provides an approximate measure of precision without requiring costly human evaluation. Half of the Freebase relations are used for testing. The relation instances discovered from the test articles are automatically compared with those in Freebase. To evaluate the proposed method, we select the following three traditional methods for comparison. Mintz represents a traditional distantsupervision-based model that was proposed by (Mintz et al., 2009). MultiR is a multi-instance learning method that was proposed by (Hoffmann et al., 2011). MIML is a multi-instance multilabel model that was proposed by (Surdeanu et al., 2012). Figure 4 shows the precision-recall curves for each method, where PCNNs+MIL denotes our method, and demonstrates that PCNNs+MIL achieves higher precision over the entire range of recall. PCNNs+MIL enhances the recall to apFigure 4: Performance comparison of the proposed method with traditional approaches. Top N Mintz MultiR MIML PCNNs+MIL Top 100 0.77 0.83 0.85 0.86 Top 200 0.71 0.74 0.75 0.80 Top 500 0.55 0.59 0.61 0.69 Average 0.676 0.720 0.737 0.783 Table 2: Precision values for the top 100, top 200, a</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S. Weld. 2011. Knowledge-based weak supervision for information extraction of overlapping relations. In Proceedings of ACL, pages 541–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
<author>Arun Ahuja</author>
<author>Doug Downey</author>
<author>Yi Yang</author>
<author>Yuhong Guo</author>
<author>Alexander Yates</author>
</authors>
<title>Learning representations for weakly supervised natural language processing tasks.</title>
<date>2014</date>
<journal>Journal of Computational Linguistics,</journal>
<volume>40</volume>
<issue>1</issue>
<contexts>
<context position="12651" citStr="Huang et al., 2014" startWordPosition="1935" endWordPosition="1938">oth semantic and syntactic information about words very well, setting performance records in several word similarity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori has become common practice for 1755 Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extraction, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. ... hired , the son of ... , in ... word position enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings. Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; N ikolov et al., 2013). In this paper, we use</context>
</contexts>
<marker>Huang, Ahuja, Downey, Yang, Guo, Yates, 2014</marker>
<rawString>Fei Huang, Arun Ahuja, Doug Downey, Yi Yang, Yuhong Guo, and Alexander Yates. 2014. Learning representations for weakly supervised natural language processing tasks. Journal of Computational Linguistics, 40(1):85–120, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nanda Kambhatla</author>
</authors>
<title>Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations.</title>
<date>2004</date>
<booktitle>In Proceedings of ACLdemo.</booktitle>
<contexts>
<context position="9173" citStr="Kambhatla, 2004" startWordPosition="1403" endWordPosition="1404">he focus of multi-instance learning is to discriminate among the bags. These methods have been shown to be effective for relation extraction. However, their performance depends strongly on the quality of the designed features. Most existing studies have concentrated on extracting features to identify the relations between two entities. Previous methods can be generally categorized into two types: feature-based methods and kernel-based methods. In feature-based methods, a diverse set of strategies is exploited to convert classification clues (e.g., sequences, parse trees) into feature vectors (Kambhatla, 2004; Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel </context>
</contexts>
<marker>Kambhatla, 2004</marker>
<rawString>Nanda Kambhatla. 2004. Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations. In Proceedings of ACLdemo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoon Kim</author>
</authors>
<title>Convolutional neural networks for sentence classification.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1746--1751</pages>
<contexts>
<context position="5505" citStr="Kim, 2014" startWordPosition="839" endWordPosition="840">ive function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (2014), in which a single max pooling operation is utilized to determine the most significant features. Although this operation has been shown to be effective for textual feature representation (Collobert et al., 2011; Kim, 2014), it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities (Graham, 2014). For example, to identify the relation between Steve Jobs and Apple in Figure 1, we need to specify the entities and extract the structural features between them. Several approaches have employed manually crafted features that attempt to model such structural information. These approaches usually consider both internal and external contexts. A sentence is inherently divided into three segments according to the two given entities. The internal context includes</context>
</contexts>
<marker>Kim, 2014</marker>
<rawString>Yoon Kim. 2014. Convolutional neural networks for sentence classification. In Proceedings of EMNLP, pages 1746–1751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>122--131</pages>
<contexts>
<context position="4060" citStr="McDonald and Nivre (2007)" startWordPosition="606" endWordPosition="609">m/ 1753 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1753–1762, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. 8000 6000 Number af sentence 4000 2000 0 0 20 40 60 80 100 Sentence Length Figure 2: The sentence length distribution of Riedel’s dataset. dresses corpora from the Web, including many informal texts. Figure 2 shows the sentence length distribution of a benchmark distant supervision dataset that was developed by Riedel et al. (2010). Approximately half of the sentences are longer than 40 words. McDonald and Nivre (2007) showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length. Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious. In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above. To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies (Riedel et al., 2010; Hoffmann et al., 2011; Surde</context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>Ryan T McDonald and Joakim Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proceedings of EMNLP-CoNLL, pages 122–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Kai Chen</author>
<author>Greg Corrado</author>
<author>Jeffrey Dean</author>
</authors>
<title>Efficient estimation of word representations in vector space.</title>
<date>2013</date>
<booktitle>In Proceedings of Workshop at ICLR.</booktitle>
<contexts>
<context position="12176" citStr="Mikolov et al., 2013" startWordPosition="1854" endWordPosition="1857">ensional vectors. In our method, each input word token is transformed into a vector by looking up pre-trained word embeddings. Moreover, we use position features (PFs) to specify entity pairs, which are also transformed into vectors by looking up position embeddings. 3.1.1 Word Embeddings Word embeddings are distributed representations of words that map each word in a text to a ‘k&apos;- dimensional k&apos;- dimensional real-valued vector. They have recently been shown to capture both semantic and syntactic information about words very well, setting performance records in several word similarity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori has become common practice for 1755 Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extraction, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. ... hired , the son of ... , in ... word position enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optim</context>
</contexts>
<marker>Mikolov, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Kai Chen, Greg Corrado, and Jeffrey Dean. 2013. Efficient estimation of word representations in vector space. In Proceedings of Workshop at ICLR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of ACLAFNLP,</booktitle>
<pages>1003--1011</pages>
<contexts>
<context position="1651" citStr="Mintz et al., 2009" startWordPosition="238" endWordPosition="241">reated as a multi-instance problem in which the uncertainty of instance labels is taken into account. To address the latter problem, we avoid feature engineering and instead adopt convolutional architecture with piecewise max pooling to automatically learn relevant features. Experiments show that our method is effective and outperforms several competitive baseline methods. 1 Introduction In relation extraction, one challenge that is faced when building a machine learning system is the generation of training examples. One common technique for coping with this difficulty is distant supervision (Mintz et al., 2009) which assumes that if two entities have a relationship in a known knowledge base, then all sentences that mention these two entities will express that relationship in some way. Figure 1 shows an example of the autoFigure 1: Training instances generated through distant supervision. Upper sentence: correct labeling; lower sentence: incorrect labeling. matic labeling of data through distant supervision. In this example, Apple and Steve Jobs are two related entities in Freebase1. All sentences that contain these two entities are selected as training instances. The distant supervision strategy is </context>
<context position="2970" citStr="Mintz et al., 2009" startWordPosition="448" endWordPosition="451">hen used for relation extraction. First, the distant supervision assumption is too strong and causes the wrong label problem. A sentence that mentions two entities does not necessarily express their relation in a knowledge base. It is possible that these two entities may simply share the same topic. For instance, the upper sentence indeed expresses the “company/founders” relation in Figure 1. The lower sentence, however, does not express this relation but is still selected as a training instance. This will hinder the performance of a model trained on such noisy data. Second, previous methods (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011) have typically applied supervised models to elaborately designed features when obtained the labeled data through distant supervision. These features are often derived from preexisting Natural Language Processing (NLP) tools. Since errors inevitably exist in NLP tools, the use of traditional features leads to error propagation or accumulation. Distant supervised relation extraction generally ad1http://www.freebase.com/ 1753 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1753–1762, Lisbon, Portugal, 17-2</context>
<context position="7985" citStr="Mintz et al. (2009)" startWordPosition="1220" endWordPosition="1223">ated Work Relation extraction is one of the most important topics in NLP. Many approaches to relation extraction have been developed, such as bootstrapping, unsupervised relation discovery and supervised classification. Supervised approaches are the most commonly used methods for relation 1754 extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm, relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning. The term ‘multiinstance learning was coined by (Dietterich et al., 1997) while investigating the problem of predicting drug activity. In multi-instance learning, the uncertainty of instance labels can be taken into account. The focus of multi-instance </context>
<context position="22368" citStr="Mintz et al., 2009" startWordPosition="3657" endWordPosition="3660">We then compare the performance of our method to those of several traditional methods. Finally, we evaluate the effects of piecewise max pooling and multiinstance learning3. 4.1 Dataset and Evaluation Metrics We evaluate our method on a widely used dataset4 that was developed by (Riedel et al., 2010) and has also been used by (Hoffmann et al., 2011; Surdeanu et al., 2012). This dataset was generated by aligning Freebase relations with the NYT corpus, with sentences from the years 2005-2006 used as the training corpus and sentences from 2007 used as the testing corpus. Following previous work (Mintz et al., 2009), we evaluate our method in two ways: the held-out evaluation and the manual evaluation. The heldout evaluation only compares the extracted relation instances against Freebase relation data and reports the precision/recall curves of the experiments. In the manual evaluation, we manually check the newly discovered relation instances that are not in Freebase. 4.2 Experimental Settings 4.2.1 Pre-trained Word Embeddings In this paper, we use the Skip-gram model (word2vec)5 to train the word embeddings on the NYT corpus. Word2vec first constructs a vocabulary from the training text data and then le</context>
<context position="25386" citStr="Mintz et al., 2009" startWordPosition="4150" endWordPosition="4153"> hidden unit activities to zero with a probability of 0.5 during training. 4.3 Comparison with Traditional Approaches 4.3.1 Held-out Evaluation The held-out evaluation provides an approximate measure of precision without requiring costly human evaluation. Half of the Freebase relations are used for testing. The relation instances discovered from the test articles are automatically compared with those in Freebase. To evaluate the proposed method, we select the following three traditional methods for comparison. Mintz represents a traditional distantsupervision-based model that was proposed by (Mintz et al., 2009). MultiR is a multi-instance learning method that was proposed by (Hoffmann et al., 2011). MIML is a multi-instance multilabel model that was proposed by (Surdeanu et al., 2012). Figure 4 shows the precision-recall curves for each method, where PCNNs+MIL denotes our method, and demonstrates that PCNNs+MIL achieves higher precision over the entire range of recall. PCNNs+MIL enhances the recall to apFigure 4: Performance comparison of the proposed method with traditional approaches. Top N Mintz MultiR MIML PCNNs+MIL Top 100 0.77 0.83 0.85 0.86 Top 200 0.71 0.74 0.75 0.80 Top 500 0.55 0.59 0.61 0</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of ACLAFNLP, pages 1003–1011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ankur P Parikh</author>
<author>Shay B Cohen</author>
<author>Eric P Xing</author>
</authors>
<title>Spectral unsupervised parsing with additive tree metrics.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1062--1072</pages>
<contexts>
<context position="12630" citStr="Parikh et al., 2014" startWordPosition="1931" endWordPosition="1934">en shown to capture both semantic and syntactic information about words very well, setting performance records in several word similarity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori has become common practice for 1755 Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extraction, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. ... hired , the son of ... , in ... word position enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent research (Erhan et al., 2010) has shown that neural networks can converge to better local minima when they are initialized with word embeddings. Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; N ikolov et al., 2013). </context>
</contexts>
<marker>Parikh, Cohen, Xing, 2014</marker>
<rawString>Ankur P Parikh, Shay B Cohen, and Eric P Xing. 2014. Spectral unsupervised parsing with additive tree metrics. In Proceedings of ACL, pages 1062– 1072.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Pennington</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>Glove: Global vectors for word representation.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP 2014,</booktitle>
<pages>1746--1751</pages>
<contexts>
<context position="12202" citStr="Pennington et al., 2014" startWordPosition="1858" endWordPosition="1861">ur method, each input word token is transformed into a vector by looking up pre-trained word embeddings. Moreover, we use position features (PFs) to specify entity pairs, which are also transformed into vectors by looking up position embeddings. 3.1.1 Word Embeddings Word embeddings are distributed representations of words that map each word in a text to a ‘k&apos;- dimensional k&apos;- dimensional real-valued vector. They have recently been shown to capture both semantic and syntactic information about words very well, setting performance records in several word similarity tasks (Mikolov et al., 2013; Pennington et al., 2014). Using word embeddings that have been trained a priori has become common practice for 1755 Figure 3: The architecture of PCNNs (better viewed in color) used for distant supervised relation extraction, illustrating the procedure for handling one instance of a bag and predicting the relation between Kojo Annan and Kofi Annan. ... hired , the son of ... , in ... word position enhancing many other NLP tasks (Parikh et al., 2014; Huang et al., 2014). A common method of training a neural network is to randomly initialize all parameters and then optimize them using an optimization algorithm. Recent </context>
</contexts>
<marker>Pennington, Socher, Manning, 2014</marker>
<rawString>Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. In Proceedings of EMNLP 2014, pages 1746–1751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longhua Qian</author>
<author>Guodong Zhou</author>
<author>Fang Kong</author>
<author>Qiaoming Zhu</author>
<author>Peide Qian</author>
</authors>
<title>Exploiting constituent dependencies for tree kernel-based semantic relation extraction.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>697--704</pages>
<contexts>
<context position="9690" citStr="Qian et al., 2008" startWordPosition="1480" endWordPosition="1483"> to convert classification clues (e.g., sequences, parse trees) into feature vectors (Kambhatla, 2004; Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Die</context>
</contexts>
<marker>Qian, Zhou, Kong, Zhu, Qian, 2008</marker>
<rawString>Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming Zhu, and Peide Qian. 2008. Exploiting constituent dependencies for tree kernel-based semantic relation extraction. In Proceedings of COLING, pages 697– 704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Proceedings of ECML PKDD,</booktitle>
<pages>148--163</pages>
<contexts>
<context position="2991" citStr="Riedel et al., 2010" startWordPosition="452" endWordPosition="455">n extraction. First, the distant supervision assumption is too strong and causes the wrong label problem. A sentence that mentions two entities does not necessarily express their relation in a knowledge base. It is possible that these two entities may simply share the same topic. For instance, the upper sentence indeed expresses the “company/founders” relation in Figure 1. The lower sentence, however, does not express this relation but is still selected as a training instance. This will hinder the performance of a model trained on such noisy data. Second, previous methods (Mintz et al., 2009; Riedel et al., 2010; Hoffmann et al., 2011) have typically applied supervised models to elaborately designed features when obtained the labeled data through distant supervision. These features are often derived from preexisting Natural Language Processing (NLP) tools. Since errors inevitably exist in NLP tools, the use of traditional features leads to error propagation or accumulation. Distant supervised relation extraction generally ad1http://www.freebase.com/ 1753 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1753–1762, Lisbon, Portugal, 17-21 September 2015. c�2</context>
<context position="4630" citStr="Riedel et al., 2010" startWordPosition="692" endWordPosition="695">e longer than 40 words. McDonald and Nivre (2007) showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length. Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious. In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above. To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). In multi-instance problem, the training set consists of many bags, and each contains many instances. The labels of the bags are known; however, the labels of the instances in the bags are unknown. We design an objective function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014)</context>
<context position="8203" citStr="Riedel et al., 2010" startWordPosition="1255" endWordPosition="1258">. Supervised approaches are the most commonly used methods for relation 1754 extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm, relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning. The term ‘multiinstance learning was coined by (Dietterich et al., 1997) while investigating the problem of predicting drug activity. In multi-instance learning, the uncertainty of instance labels can be taken into account. The focus of multi-instance learning is to discriminate among the bags. These methods have been shown to be effective for relation extraction. However, their performance depends strongly on the quality of the designed features. Most existing stud</context>
<context position="22050" citStr="Riedel et al., 2010" startWordPosition="3603" endWordPosition="3606"> following hypothesis: automatically learning features using PCNNs with multiinstance learning can lead to an increase in performance. To this end, we first introduce the dataset and evaluation metrics used. Next, we test several variants via cross-validation to determine the parameters to be used in our experiments. We then compare the performance of our method to those of several traditional methods. Finally, we evaluate the effects of piecewise max pooling and multiinstance learning3. 4.1 Dataset and Evaluation Metrics We evaluate our method on a widely used dataset4 that was developed by (Riedel et al., 2010) and has also been used by (Hoffmann et al., 2011; Surdeanu et al., 2012). This dataset was generated by aligning Freebase relations with the NYT corpus, with sentences from the years 2005-2006 used as the training corpus and sentences from 2007 used as the testing corpus. Following previous work (Mintz et al., 2009), we evaluate our method in two ways: the held-out evaluation and the manual evaluation. The heldout evaluation only compares the extracted relation instances against Freebase relation data and reports the precision/recall curves of the experiments. In the manual evaluation, we man</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Proceedings of ECML PKDD, pages 148–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>1201--1211</pages>
<contexts>
<context position="10100" citStr="Socher et al., 2012" startWordPosition="1544" endWordPosition="1547">arse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Dietterich et al. (1997) suggested that the design of multi-instance modifications for neural networks is a particularly interesting topic. Zhang and Zhou (2006) successfully incorporated multiinstance learning into traditional Backpropagation (BP) and Radial Basis Function (RBF) networks and optimized these networks by minimizing a sum-of-squares error function. In contrast to their method, we define the obje</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of EMNLP-CoNLL, pages 1201–1211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Georgiana Ifrim</author>
<author>Gerhard Weikum</author>
</authors>
<title>Combining linguistic and statistical analysis to extract relations from web documents.</title>
<date>2006</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>712--717</pages>
<contexts>
<context position="9197" citStr="Suchanek et al., 2006" startWordPosition="1405" endWordPosition="1408">-instance learning is to discriminate among the bags. These methods have been shown to be effective for relation extraction. However, their performance depends strongly on the quality of the designed features. Most existing studies have concentrated on extracting features to identify the relations between two entities. Previous methods can be generally categorized into two types: feature-based methods and kernel-based methods. In feature-based methods, a diverse set of strategies is exploited to convert classification clues (e.g., sequences, parse trees) into feature vectors (Kambhatla, 2004; Suchanek et al., 2006). Feature-based methods suffer from the necessity of selecting a suitable feature set when converting structured representations into feature vectors. Kernel-based methods provide a natural alternative to exploit rich representations of input classification clues, such as syntactic parse trees. Kernelbased methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 200</context>
</contexts>
<marker>Suchanek, Ifrim, Weikum, 2006</marker>
<rawString>Fabian M. Suchanek, Georgiana Ifrim, and Gerhard Weikum. 2006. Combining linguistic and statistical analysis to extract relations from web documents. In Proceedings of KDD, pages 712–717.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multi-instance multi-label learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>455--465</pages>
<contexts>
<context position="4677" citStr="Surdeanu et al., 2012" startWordPosition="700" endWordPosition="703">2007) showed that the accuracy of syntactic parsing decreases significantly with increasing sentence length. Therefore, when using traditional features, the problem of error propagation or accumulation will not only exist, it will grow more serious. In this paper, we propose a novel model dubbed Piecewise Convolutional Neural Networks (PCNNs) with multi-instance learning to address the two problems described above. To address the first problem, distant supervised relation extraction is treated as a multi-instance problem similar to previous studies (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). In multi-instance problem, the training set consists of many bags, and each contains many instances. The labels of the bags are known; however, the labels of the instances in the bags are unknown. We design an objective function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (</context>
<context position="8250" citStr="Surdeanu et al., 2012" startWordPosition="1263" endWordPosition="1266">y used methods for relation 1754 extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm, relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning. The term ‘multiinstance learning was coined by (Dietterich et al., 1997) while investigating the problem of predicting drug activity. In multi-instance learning, the uncertainty of instance labels can be taken into account. The focus of multi-instance learning is to discriminate among the bags. These methods have been shown to be effective for relation extraction. However, their performance depends strongly on the quality of the designed features. Most existing studies have concentrated on extracting features to</context>
<context position="22123" citStr="Surdeanu et al., 2012" startWordPosition="3617" endWordPosition="3621"> multiinstance learning can lead to an increase in performance. To this end, we first introduce the dataset and evaluation metrics used. Next, we test several variants via cross-validation to determine the parameters to be used in our experiments. We then compare the performance of our method to those of several traditional methods. Finally, we evaluate the effects of piecewise max pooling and multiinstance learning3. 4.1 Dataset and Evaluation Metrics We evaluate our method on a widely used dataset4 that was developed by (Riedel et al., 2010) and has also been used by (Hoffmann et al., 2011; Surdeanu et al., 2012). This dataset was generated by aligning Freebase relations with the NYT corpus, with sentences from the years 2005-2006 used as the training corpus and sentences from 2007 used as the testing corpus. Following previous work (Mintz et al., 2009), we evaluate our method in two ways: the held-out evaluation and the manual evaluation. The heldout evaluation only compares the extracted relation instances against Freebase relation data and reports the precision/recall curves of the experiments. In the manual evaluation, we manually check the newly discovered relation instances that are not in Freeb</context>
<context position="24036" citStr="Surdeanu et al., 2012" startWordPosition="3925" endWordPosition="3928">not present the results without the position feature. 4http://iesl.cs.umass.edu/riedel/ecml/ 5https://code.google.com/p/word2vec/ 1758 Window Feature Word Position Batch Adadelta parameter Dropout size maps dimension dimension size probability w = 3 n = 230 d,,,=50 dp = 5 b3=50 p = 0.95,E = 1e−6 p = 0.5 Table 1: Parameters used in our experiments. of this paper, our experiments directly utilize 50- dimensional vectors. 4.2.2 Parameter Settings In this section, we experimentally study the effects of two parameters on our models: the window size, w, and the number of feature maps, n. Following (Surdeanu et al., 2012), we tune all of the models using three-fold validation on the training set. We use a grid search to determine the optimal parameters and manually specify subsets of the parameter spaces: w E 11, 2, 3, · · · , 71 and n E 150,60,··· , 3001. Table 1 shows all parameters used in the experiments. Because the position dimension has little effect on the result, we heuristically choose dp = 5. The batch size is fixed to 50. We use Adadelta (Zeiler, 2012) in the update procedure; it relies on two main parameters, p and E, which do not significantly affect the performance (Zeiler, 2012). Following (Zei</context>
<context position="25563" citStr="Surdeanu et al., 2012" startWordPosition="4179" endWordPosition="4182">es an approximate measure of precision without requiring costly human evaluation. Half of the Freebase relations are used for testing. The relation instances discovered from the test articles are automatically compared with those in Freebase. To evaluate the proposed method, we select the following three traditional methods for comparison. Mintz represents a traditional distantsupervision-based model that was proposed by (Mintz et al., 2009). MultiR is a multi-instance learning method that was proposed by (Hoffmann et al., 2011). MIML is a multi-instance multilabel model that was proposed by (Surdeanu et al., 2012). Figure 4 shows the precision-recall curves for each method, where PCNNs+MIL denotes our method, and demonstrates that PCNNs+MIL achieves higher precision over the entire range of recall. PCNNs+MIL enhances the recall to apFigure 4: Performance comparison of the proposed method with traditional approaches. Top N Mintz MultiR MIML PCNNs+MIL Top 100 0.77 0.83 0.85 0.86 Top 200 0.71 0.74 0.75 0.80 Top 500 0.55 0.59 0.61 0.69 Average 0.676 0.720 0.737 0.783 Table 2: Precision values for the top 100, top 200, and top 500 extracted relation instances upon manual evaluation. proximately 34% without </context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D. Manning. 2012. Multi-instance multi-label learning for relation extraction. In Proceedings of EMNLP-CoNLL, pages 455–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew D Zeiler</author>
</authors>
<title>Adadelta: An adaptive learning rate method. arXiv preprint arXiv:1212.5701,</title>
<date>2012</date>
<pages>1212--5701</pages>
<contexts>
<context position="20705" citStr="Zeiler, 2012" startWordPosition="3392" endWordPosition="3393">ftmax operation over all relation types: p(r |mji; 0) = nl eor (7) E eok k=1 The objective of multi-instance learning is to discriminate bags rather than instances. To do so, we must define the objective function on the bags. Given all (T) training bags (Mi, yi), we can define the objective function using cross-entropy at the bag level as follows: T J (0) = log p(yi|mji; 0) (8) i=1 where j is constrained as follows: j* = arg maxp(yi|mji; 0) 1 ≤ j ≤ qi (9) j Using this defined objective function, we maximize J(0) through stochastic gradient descent over shuffled mini-batches with the Adadelta (Zeiler, 2012) update rule. The entire training procedure is described in Algorithm 1. From the introduction presented above, we know that the traditional backpropagation algorithm modifies a network in accordance with all training instances, whereas backpropagation with multi-instance learning modifies a network based on bags. Thus, our method captures the nature of distant supervised relation extraction, in which some training instances will inevitably be incorrectly labeled. When a trained PCNN is used for prediction, a bag is positively labeled if and only if the output of the network on at least one of</context>
<context position="24487" citStr="Zeiler, 2012" startWordPosition="4015" endWordPosition="4016">ion, we experimentally study the effects of two parameters on our models: the window size, w, and the number of feature maps, n. Following (Surdeanu et al., 2012), we tune all of the models using three-fold validation on the training set. We use a grid search to determine the optimal parameters and manually specify subsets of the parameter spaces: w E 11, 2, 3, · · · , 71 and n E 150,60,··· , 3001. Table 1 shows all parameters used in the experiments. Because the position dimension has little effect on the result, we heuristically choose dp = 5. The batch size is fixed to 50. We use Adadelta (Zeiler, 2012) in the update procedure; it relies on two main parameters, p and E, which do not significantly affect the performance (Zeiler, 2012). Following (Zeiler, 2012), we choose 0.95 and 1e−6, respectively, as the values of these parameters. In the dropout operation, we randomly set the hidden unit activities to zero with a probability of 0.5 during training. 4.3 Comparison with Traditional Approaches 4.3.1 Held-out Evaluation The held-out evaluation provides an approximate measure of precision without requiring costly human evaluation. Half of the Freebase relations are used for testing. The relatio</context>
</contexts>
<marker>Zeiler, 2012</marker>
<rawString>Matthew D. Zeiler. 2012. Adadelta: An adaptive learning rate method. arXiv preprint arXiv:1212.5701, abs/1212.5701.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
<author>Anthony Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--1083</pages>
<contexts>
<context position="7757" citStr="Zelenko et al., 2003" startWordPosition="1181" endWordPosition="1184">orate multi-instance learning into the PCNNS for distant supervised relation extraction. • In the proposed network, we devise a piecewise max pooling layer, which aims to capture structural information between two entities. 2 Related Work Relation extraction is one of the most important topics in NLP. Many approaches to relation extraction have been developed, such as bootstrapping, unsupervised relation discovery and supervised classification. Supervised approaches are the most commonly used methods for relation 1754 extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm, relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning. The term ‘multiinstance </context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2003</marker>
<rawString>Dmitry Zelenko, Chinatsu Aone, and Anthony Richardella. 2003. Kernel methods for relation extraction. Journal of Machine Learning Research, 3:1083–1106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daojian Zeng</author>
<author>Kang Liu</author>
<author>Siwei Lai</author>
<author>Guangyou Zhou</author>
<author>Jun Zhao</author>
</authors>
<title>Relation classification via convolutional deep neural network.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>2335--2344</pages>
<contexts>
<context position="5230" citStr="Zeng et al. (2014)" startWordPosition="790" endWordPosition="793">iedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). In multi-instance problem, the training set consists of many bags, and each contains many instances. The labels of the bags are known; however, the labels of the instances in the bags are unknown. We design an objective function at the bag level. In the learning process, the uncertainty of instance labels can be taken into account; this alleviates the wrong label problem. To address the second problem, we adopt convolutional architecture to automatically learn relevant features without complicated NLP preprocessing inspired by Zeng et al. (2014). Our proposal is an extension of Zeng et al. (2014), in which a single max pooling operation is utilized to determine the most significant features. Although this operation has been shown to be effective for textual feature representation (Collobert et al., 2011; Kim, 2014), it reduces the size of the hidden layers too rapidly and cannot capture the structural information between two entities (Graham, 2014). For example, to identify the relation between Steve Jobs and Apple in Figure 1, we need to specify the entities and extract the structural features between them. Several approaches have e</context>
<context position="10120" citStr="Zeng et al., 2014" startWordPosition="1548" endWordPosition="1551">ed methods enable the use of a large set of features without needing to extract them explicitly. Several kernels have been proposed, such as the convolution tree kernel (Qian et al., 2008), the subsequence kernel (Bunescu and Mooney, 2006) and the dependency tree kernel (Bunescu and Mooney, 2005). Nevertheless, as mentioned in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Dietterich et al. (1997) suggested that the design of multi-instance modifications for neural networks is a particularly interesting topic. Zhang and Zhou (2006) successfully incorporated multiinstance learning into traditional Backpropagation (BP) and Radial Basis Function (RBF) networks and optimized these networks by minimizing a sum-of-squares error function. In contrast to their method, we define the objective function based</context>
<context position="13447" citStr="Zeng et al. (2014)" startWordPosition="2061" endWordPosition="2064">0) has shown that neural networks can converge to better local minima when they are initialized with word embeddings. Word embeddings are typically learned in an entirely unsupervised manner by exploiting the co-occurrence structure of words in unlabeled text. Researchers have proposed several methods of training word embeddings (Bengio et al., 2003; Collobert et al., 2011; N ikolov et al., 2013). In this paper, we use the Skip-gram model (N ikolov et al., 2013) to train word embeddings. 3.1.2 Position Embeddings In relation extraction, we focus on assigning labels to entity pairs. Similar to Zeng et al. (2014), we use PFs to specify entity pairs. A PF is defined as the combination of the relative distances from the current word to e1 and e2. For instance, in the following example, the relative distances from son to e1 (Kojo Annan) and e2 (Kofi Annan) are 3 and -2, respectively. ... hired Kojo Annan , the son of Kofi Annan , in ... Two position embedding matrixes (PF1 and PF2) are randomly initialized. We then transform the relative distances into real valued vectors by looking up the position embedding matrixes. In the example shown in Figure 3, it is assumed that the size of the word embedding is </context>
<context position="16378" citStr="Zeng et al., 2014" startWordPosition="2611" endWordPosition="2614">lt is a matrix C = {c1, c2, · · · , cn} ∈ Rn×(s+w−1). Figure 3 shows an example in which we use 3 different filters in the convolution procedure. 3.3 Piecewise Max Pooling The size of the convolution output matrix C ∈ Rn×(s+w−1) depends on the number of tokens s in the sentence that is fed into the network. To apply subsequent layers, the features that are extracted by the convolution layer must be combined such that they are independent of the sentence length. In traditional Convolution Neural Networks (CNNs), max pooling operations are often applied for this purpose (Collobert et al., 2011; Zeng et al., 2014). This type of pooling scheme naturally addresses variable sentence lengths. The idea is to capture the most significant features (with the highest values) in each feature map. However, despite the widespread use of single max pooling, this approach is insufficient for relation extraction. As described in the first section, single max pooling reduces the size of the hidden layers too rapidly and is too coarse to capture finegrained features for relation extraction. In addition, single max pooling is not sufficient to capture the structural information between two entities. In relation extracti</context>
<context position="23333" citStr="Zeng et al. (2014)" startWordPosition="3813" endWordPosition="3816">in Freebase. 4.2 Experimental Settings 4.2.1 Pre-trained Word Embeddings In this paper, we use the Skip-gram model (word2vec)5 to train the word embeddings on the NYT corpus. Word2vec first constructs a vocabulary from the training text data and then learns vector representations of the words. To obtain the embeddings of the entities, we concatenate the tokens of a entity using the ## operator when the entity has multiple word tokens. Since a comparison of the word embeddings is beyond the scope 3With regard to the position feature, our experiments yield the same positive results described in Zeng et al. (2014). Because the position feature is not the main contribution of this paper, we do not present the results without the position feature. 4http://iesl.cs.umass.edu/riedel/ecml/ 5https://code.google.com/p/word2vec/ 1758 Window Feature Word Position Batch Adadelta parameter Dropout size maps dimension dimension size probability w = 3 n = 230 d,,,=50 dp = 5 b3=50 p = 0.95,E = 1e−6 p = 0.5 Table 1: Parameters used in our experiments. of this paper, our experiments directly utilize 50- dimensional vectors. 4.2.2 Parameter Settings In this section, we experimentally study the effects of two parameters </context>
</contexts>
<marker>Zeng, Liu, Lai, Zhou, Zhao, 2014</marker>
<rawString>Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via convolutional deep neural network. In Proceedings of COLING, pages 2335–2344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minling Zhang</author>
<author>Zhihua Zhou</author>
</authors>
<title>Adapting rbf neural networks to multi-instance learning.</title>
<date>2006</date>
<journal>Neural Processing Letters,</journal>
<volume>23</volume>
<issue>1</issue>
<contexts>
<context position="10448" citStr="Zhang and Zhou (2006)" startWordPosition="1598" endWordPosition="1601"> in Section 1, it is difficult to design high-quality features using existing NLP tools. With the recent revival of interest in neural networks, many researchers have investigated the possibility of using neural networks to automatically learn features (Socher et al., 2012; Zeng et al., 2014). Inspired by Zeng et al. (2014), we propose the use of PCNNs with multi-instance learning to automatically learn features for distant supervised relation extraction. Dietterich et al. (1997) suggested that the design of multi-instance modifications for neural networks is a particularly interesting topic. Zhang and Zhou (2006) successfully incorporated multiinstance learning into traditional Backpropagation (BP) and Radial Basis Function (RBF) networks and optimized these networks by minimizing a sum-of-squares error function. In contrast to their method, we define the objective function based on the cross-entropy principle. 3 Methodology Distant supervised relation extraction is formulated as multi-instance problem. In this section, we present innovative solutions that incorporate multi-instance learning into a convolutional neural network to fulfill this task. PCNNs are proposed for the automatic learning of feat</context>
</contexts>
<marker>Zhang, Zhou, 2006</marker>
<rawString>Minling Zhang and Zhihua Zhou. 2006. Adapting rbf neural networks to multi-instance learning. Neural Processing Letters, 23(1):1–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Zhang</author>
<author>Jie Zhang</author>
<author>Jian Su</author>
<author>Guodong Zhou</author>
</authors>
<title>A composite kernel to extract relations between entities with both flat and structured features.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>825--832</pages>
<contexts>
<context position="6239" citStr="Zhang et al., 2006" startWordPosition="950" endWordPosition="953">tities (Graham, 2014). For example, to identify the relation between Steve Jobs and Apple in Figure 1, we need to specify the entities and extract the structural features between them. Several approaches have employed manually crafted features that attempt to model such structural information. These approaches usually consider both internal and external contexts. A sentence is inherently divided into three segments according to the two given entities. The internal context includes the characters inside the two entities, and the external context involves the characters around the two entities (Zhang et al., 2006). Clearly, single max pooling is not sufficient to capture such structural information. To capture structural and other latent information, we divide the convolution results into three segments based on the positions of the two given entities and devise a piecewise max pooling layer instead of the single max pooling layer. The piecewise max pooling procedure returns the maximum value in each segment instead of a single maximum value over the entire sentence. Thus, it is expected to exhibit superior performance compared with traditional methods. The contributions of this paper can be summarized</context>
</contexts>
<marker>Zhang, Zhang, Su, Zhou, 2006</marker>
<rawString>Min Zhang, Jie Zhang, Jian Su, and Guodong Zhou. 2006. A composite kernel to extract relations between entities with both flat and structured features. In Proceedings of ACL, pages 825–832.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guodong Zhou</author>
<author>Jian Su</author>
<author>Jie Zhang</author>
<author>Min Zhang</author>
</authors>
<title>Exploring various knowledge in relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>427--434</pages>
<contexts>
<context position="7777" citStr="Zhou et al., 2005" startWordPosition="1185" endWordPosition="1188">earning into the PCNNS for distant supervised relation extraction. • In the proposed network, we devise a piecewise max pooling layer, which aims to capture structural information between two entities. 2 Related Work Relation extraction is one of the most important topics in NLP. Many approaches to relation extraction have been developed, such as bootstrapping, unsupervised relation discovery and supervised classification. Supervised approaches are the most commonly used methods for relation 1754 extraction and yield relatively high performance (Bunescu and Mooney, 2006; Zelenko et al., 2003; Zhou et al., 2005). In the supervised paradigm, relation extraction is considered to be a multi-class classification problem and may suffer from a lack of labeled data for training. To address this problem, Mintz et al. (2009) adopted Freebase to perform distant supervision. As described in Section 1, the algorithm for training data generation is sometimes faced with the wrong label problem. To address this shortcoming, (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012) developed the relaxed distant supervision assumption for multi-instance learning. The term ‘multiinstance learning was coined </context>
</contexts>
<marker>Zhou, Su, Zhang, Zhang, 2005</marker>
<rawString>Guodong Zhou, Jian Su, Jie Zhang, and Min Zhang. 2005. Exploring various knowledge in relation extraction. In Proceedings of ACL, pages 427–434.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>