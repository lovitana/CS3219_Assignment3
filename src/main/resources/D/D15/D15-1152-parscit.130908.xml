<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007728">
<title confidence="0.4647738">
Improving Arabic Diacritization through Syntactic Analysis
Anas Shahrour, Salam Khalifa and Nizar Habash
Computational Approaches to Modeling Language Lab
New York University Abu Dhabi
United Arab Emirates
</title>
<email confidence="0.994073">
{anas.shahrour,salamkhalifa,nizar.habash}@nyu.edu
</email>
<sectionHeader confidence="0.993785" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999866">
We present an approach to Arabic auto-
matic diacritization that integrates syntac-
tic analysis with morphological tagging
through improving the prediction of case
and state features. Our best system in-
creases the accuracy of word diacritization
by 2.5% absolute on all words, and 5.2%
absolute on nominals over a state-of-the-
art baseline. Similar increases are shown
on the full morphological analysis choice.
</bodyText>
<sectionHeader confidence="0.999229" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999508117647059">
Modern Standard Arabic (MSA) orthography
generally omits diacritical marks which encode
lexical as well as syntactic (case) information. The
task of Arabic automatic diacritization is about
the automatic restoration of the missing diacritics.
Diacritization improvement in Arabic has impor-
tant implications for downstream processing for
Arabic natural language processing, e.g. speech
recognition (Ananthakrishnan et al., 2005; Biadsy
et al., 2009), speech synthesis (Elshafei et al.,
2002), and machine translation (Diab et al., 2007;
Zbib et al., 2010).
Previous efforts on diacritization utilized mor-
phological tagging techniques to disambiguate
word forms. Habash et al. (2007a) observe that
while such techniques work relatively well on lex-
ical diacritics (located on word stems), they are
much worse for syntactic case diacritics (typically
word final). They suggest that syntactic anal-
ysis may help with automatic diacrtization, but
stop short of testing the idea, and instead demon-
strate that complex linguistic features and rules are
needed to model complex Arabic case using gold
syntactic analyses. In this paper, we develop an
approach for improving the quality of automatic
Arabic diacritization through the use of automatic
syntactic analysis. Our approach combines hand-
written rules for case assignment and agreement
with machine learning of case and state adjustment
on the output of a state-of-the-art morphological
tagger. Our best system increases the accuracy of
word diacrtization by 2.5% absolute overall, and
5.2% absolute on nominals over a state-of-the-art
baseline.
</bodyText>
<sectionHeader confidence="0.979071" genericHeader="introduction">
2 Linguistic Background
</sectionHeader>
<bodyText confidence="0.999403909090909">
Arabic automatic processing, and specifically dia-
critization is hard for a number of reasons.
First, Arabic words are morphologically rich.
The morphological analyzer we use represents
Arabic words with 15 features (Pasha et al.,
2014).1 We focus on case and state in this paper.
In our data set, case has five values: nominative
(n), accusative (a), genitive (g), undefined (u) and
not applicable (na). Cases n, a and g are usually
expressed with an overt morpheme. Case u is used
to mark words without an overt morpheme expres-
sion of case (e.g., invariable nouns such as jY_Z1
šakwaý ‘complaint’), or those not assigned a case
in the manual annotations. Most of the missing
assignments are for foreign proper nouns, which
often do not receive case markers. However, this
is not done consistently in the training data we use.
Case na is used for non-nominals. State is a nom-
inal feature that has four values: definite (d), in-
definite (i), construct (c) and not applicable (na).
State generally reflects the definiteness in nomi-
nals (d vs i) and whether a nominal is the head of
genitive construction (aka Idafa) (c). State na is
used for non-nominals.2 For the most part, case
and state realize as a single word-final morpheme,
�
e.g., the suffix I Aã in U�Er� kitAbAã3 is a morpheme
indicating the word is (cas:a, stt:i).
Second, undiacritized Arabic words are highly
ambiguous: in our training data, words had an av-
erage of 12.8 analyses per word, most of which
are associated with different diacritizations. Some
diacritization differences reflect different analysis
</bodyText>
<footnote confidence="0.99739">
1Lemma (lex), Part-of-Speech (pos), Gender (gen), Num-
ber (num), Case (cas), State (stt), Person (per), Aspect (asp),
Voice (vox), Mood (mod), four proclitics (prcn), and one en-
clitic (enc0).
2For a detailed discussion of Arabic case and state, see
(Smrž, 2007; Habash et al., 2007a).
3Arabic transliteration is presented in the Habash-Soudi-
Buckwalter scheme (Habash et al., 2007b).
</footnote>
<page confidence="0.91244">
1309
</page>
<note confidence="0.6741335">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1309–1315,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.998240352941177">
lemmas; while others are due to morpho-syntactic
differences. For example, the undiacritized ver-
sion of the word we used above (l��l��r ktAbA)
has two other diacritizations and analyses: l���l�����r
kut∼AbAã (cas:a stt:i) ‘writers’ (different lemma)
and l���l���r� kitAbA (cas:n stt:c num:d) ‘two books of
[...]’ (different features).
Third, Arabic has complex case/state assign-
ment and agreement patterns that interact with the
sentence’s syntax. For example, a noun may get
its case by being subject of a verb and its state by
being the head of an idafa construction; while ad-
jectives modifying this noun agree with it in its
case, their state is determined by the state of the
last element in the idafa chain the noun heads.
For more information on Arabic orthography,
morphology, and syntax, see Habash (2010).
</bodyText>
<sectionHeader confidence="0.999965" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999946321428572">
Much work has been done on Arabic diacritization
(Vergyri and Kirchhoff, 2004; Nelken and Shieber,
2005; Zitouni et al., 2006; Habash and Rambow,
2007; Alghamdi and Muzafar, 2007; Rashwan et
al., 2009; Bebah et al., 2014; Hadj Ameur et al.,
2015; Abandah et al., 2015; Bouamor et al., 2015).
We refer the reader to the extensive literature re-
view by Abandah et al. (2015), and focus on sys-
tems we compare with.
Most of the previous approaches cited above
utilize different sequence modeling techniques
that use varying degrees of knowledge from shal-
low letter and word forms to deeper morphologi-
cal information; none to our knowledge make use
of syntax. Habash and Rambow (2007) approach
diacritization as a part of the morphological dis-
ambiguation problem, where they select the opti-
mal full morphological tag for Arabic in context
and use it to select from a list of possible analyses
produced by a morphological analyzer. They use
independent taggers for all features; and language
models for lemmas and diacritized surface forms.
Their work is part of the state-of-the-art Ara-
bic morphological tagger MADAMIRA (Pasha et
al., 2014). Our paper is most closely related
to Habash and Rambow (2007) and Pasha et al.
(2014). We extend their work using additional
syntactic features to improve morphological dis-
ambiguation accuracy. We demonstrate improve-
ments in terms of both full morphological analysis
choice (lemmatization, tokenization, all features)
as well as word diacritization.
Most recently, Abandah et al. (2015) presented
a recurrent neural network approach to diacritize
full sentences with impressive results. We do not
compare to their effort here but we note that they
use an order of magnitude more diacritized data
than we do, and they focus on diacritization only
as opposed to full morphological analysis.
In related work on modeling Arabic case and
syntax, Habash et al. (2007a) compared rule-based
and machine learning approaches to capture the
complexity of Arabic case assignment and agree-
ment. They demonstrated their results on gold
syntactic analyses showing that given good syn-
tactic representations, case prediction can be done
at a high degree of accuracy. Alkuhlani et al.
(2013) later extended this work to cover all mor-
phological features, including state. Additionally,
Marton et al. (2013) demonstrated that in the con-
text of syntactic dependency parsing, case is the
best feature to use in gold settings and is the worst
feature to use in predicted settings. In this paper
we use automatic (i.e. not gold) syntactic features
to improve case prediction, which improves mor-
phological analysis and word diacrtization.
</bodyText>
<sectionHeader confidence="0.995047" genericHeader="method">
4 Approach
</sectionHeader>
<bodyText confidence="0.999858230769231">
Motivation We are motivated by an error
analysis we conducted of 1,200 words of the
MADAMIRA system output. We found a large
number of surprising syntactically impossible case
errors such as genitive nouns following verbs or
construct nouns followed by non-genitives. We
explain these errors by MADAMIRA’s contextual
models being limited to a small window of neigh-
boring words and with no modeling of syntax,
which leads to a much worse performance on case
and diacritization compared to lemmas and POS
(almost 10% absolute drop from 96% to 86%).
Proposed Solution Our approach is to provide
better prediction of case and state using models
with access to additional information, in partic-
ular syntactic analysis and rules. The predicted
case and state values are then used to re-tag the
MADAMIRA output by selecting the best match
in its ranked morphological analyses. We limit our
retagging to nominals. Since what we are learning
to predict is how to correct MADAMIRA’s base-
line choice (as opposed to a generative model of
case-state), we also re-apply the model on its out-
put to fix primarily propagated agreement errors in
a manner similar to Habash et al. (2007a)’s agree-
ment classifier.4
</bodyText>
<footnote confidence="0.815951">
4We optimized for a re-application limit, which we found
invariably to be +1 time or +2 times in our DevTest experi-
</footnote>
<page confidence="0.990113">
1310
</page>
<sectionHeader confidence="0.996727" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.9999724">
We present next our experimental results and com-
pare five case-state prediction techniques. The
results for these techniques are compared to our
state-of-the-art baseline system, which has been
compared to a number of other approaches.
</bodyText>
<subsectionHeader confidence="0.984393">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999782346153846">
Data We used the Penn Arabic Treebank (PATB,
parts 1, 2 and 3) (Maamouri et al., 2004;
Maamouri et al., 2006; Maamouri et al., 2009)
split into Train, Dev and (blind) Test along the rec-
ommendations of Diab et al. (2013) which were
also used in the baseline system. The morpho-
logical feature representations we use are derived
from the PATB analyses following the approach
used in the MADA and later MADAMIRA sys-
tems (Habash and Rambow, 2005; Habash and
Rambow, 2007; Pasha et al., 2014). We further
divide Dev into two parts with equal number of
sentences: DevTrain (30K words) for training our
case-state classifiers, and DevTest (33K words) for
development testing. The Test set has 63K words.5
Evaluation Metrics We report our accuracy in
terms of two metrics: a. Diac, the percentage
of correctly fully diacrtized words; and b. All,
the percentage of words for which a full morpho-
logical analysis (lemma, POS, all inflectional and
clitic features, and diacritization) is correctly pre-
dicted. We report the results on all words (All
Words) as well as on nominals6 with no u case
in the gold (henceforth, Nominals). We do not re-
port on case and state prediction accuracy, nor on
the character-level diacritization.
</bodyText>
<subsectionHeader confidence="0.679873">
Morphological Analysis, Baseline and Topline
</subsectionHeader>
<bodyText confidence="0.995524235294118">
For our baseline, we use the morphological analy-
sis and disambiguation tool MADAMIRA (Pasha
et al., 2014), which produces a contextually
ranked list of analyses for each word. We com-
puted an oracular topline using the PATB gold case
and state values in the retagging process.
ments. We do not report more on this due to space limitations.
Because of the need to have the same of number of parse
tree tokens for reapplication in the models using syntax, we
constrain the retagging to maintain the same clitic signature
(number of clitics) in the MADAMIRA baseline top analysis.
5To address the concern that we are using more &amp;quot;train-
ing&amp;quot; data than our baseline, we compared the performance
of MADAMIRA’s release (baseline) to a version that was
trained on Train + DevTrain. The small increase in training
data made no significant difference from the baseline system
in terms of our metrics.
</bodyText>
<footnote confidence="0.6468385">
6Nominals consists of nouns (including noun_quant and
noun_num), adjectives, proper nouns, adverbs, and pronouns.
</footnote>
<table confidence="0.999815222222222">
All Words Nominals
System Diac All Diac All
Oracle Topline 96.2 94.2 98.0 95.7
Baseline 87.4 85.0 81.9 78.2
Morphology Rules 88.0 85.5 83.1 79.4
Morphology Classifier 88.4 85.9 83.7 80.1
Syntax Rules 87.4 84.6 86.4 82.2
Syntax Classifier 89.1 86.6 85.2 81.4
Syntax Rules+Classifier 89.7 87.1 86.4 82.5
</table>
<tableCaption confidence="0.999924">
Table 1: Results on DevTest.
</tableCaption>
<bodyText confidence="0.993410785714286">
Syntactic Analysis For syntactic features, we
trained an Arabic dependency parser using Malt-
Parser (Nivre et al., 2007) on the Columbia Arabic
Treebank (CATiB) version of the PATB (Habash
and Roth, 2009). The Train data followed the
same splits mentioned above. The Nivre &amp;quot;eager&amp;quot;
algorithm was used in all experiments. The CATiB
dependency tree has six simple POS tags and
eight relations (Habash and Roth, 2009; Habash
et al., 2009). The PATB tokenization as well as
the CATiB POS tags were produced by the base-
line system MADAMIRA and used as input to
the parser. We also used the well performing
yet simple CATiBex expansion of the CATiB tags
as implemented in the publicly available parsing
pipeline from Marton et al. (2013). Our parser’s
performance on the PATB Dev set is comparable
to Marton et al. (2013): 84.2% labeled attachment,
86.6% unlabeled attachment, and 93.6% label ac-
curacy.
Machine Learning Technique Given the small
size of DevTrain, we opted to train unlexical-
ized models that we expect to capture morpho-
syntactic abstractions. We tried a number of ma-
chine learning techniques and settled on using the
J48 Decision tree classifier with its default settings
in WEKA (Hall et al., 2009; Quinlan, 1993) for all
of the classification experiments in this paper.
</bodyText>
<subsectionHeader confidence="0.998477">
5.2 Case and State Classification Techniques
</subsectionHeader>
<bodyText confidence="0.999882777777778">
We detail and report on five case-state classifica-
tion techniques we experimented with. All results
on the DevTest are presented in Table 1.
Morphology Rules We created a simple man-
ual word-morphology based classifier that handled
the most salient case errors seen in our pilot study
(Section 4) and whose correction has a high preci-
sion. The scope of the rules was limited to word
bigrams and included three conditions: (i) post-
</bodyText>
<page confidence="0.961947">
1311
</page>
<bodyText confidence="0.994539103448276">
verbal genitive nouns are changed to the first non-
genitive analysis available from MADAMIRA; (ii)
post-construct state non-genitive nouns should be-
come genitive; and (iii) adjectives agreeing with
the nouns they follow in gender, number, and def-
initeness, but not in case should match the nouns’
case. The collective improvement of all the rules
applied in the order presented above adds up to
0.6% absolute on All Word Diac, and 1.2% abso-
lute on Nominal Diac.
Morphology-based Classifier We trained a
classifier to predict a correction of the baseline
case and state of a word using the DevTrain
data set. For features, we included all the non-
lexical morphological features (all features men-
tioned in footnote 1 except for lemma). Clitic fea-
ture values were binarized to indicate if a clitic is
present or not. We used Nil values for all out-
of-vocabulary words in MADAMIRA. BOS and
EOS placeholders were used for sentence bound-
aries. We excluded all DevTrain words whose
predicted POS switches from nominal to non-
nominal or vice versa, but kept them as part of
other words’ context. This minimizes noise and
sparsity in the training data, especially given its
small size and the rarity of such examples. We ex-
perimented with adding features from neighboring
words within a window size of +/- 2 words. The
best performing setup was with window size +/- 1.
This classifier makes around 0.5% absolute gain
over the simple word morphology rules.
Syntax Rules Inspired by Habash et al.
(2007a)’s simple set of rules for determining case
on gold dependency trees, we re-implemented
these rules to work with our different dependency
representation and extended them to include state
assignment in a manner similar to Alkuhlani et al.
(2013).7 These rules improve over the baseline
by 4.5% absolute in Nominal Diac accuracy,
but produce no gains in All Words setting. An
investigation of the error patterns reveals the main
7For nominal case assignment, our rules are: (i) default
case is a; (ii) children of root are n; (iii) object of prepo-
sition and idafa children are assigned g; (iv) predicates not
headed by verbs are assigned n; and (v) subjects and top-
ics not headed (or grand-headed) by a class of words called
Ân∼a and her sisters are assigned n. After case assign-
ment, we apply two case agreement rules: (i) for all nom-
inals modifying case-assigned nominals (i.e., with tree rela-
tion mod), copy the case of the modified nominal; and (ii) for
all nominals conjoined to case-assigned nominals (i.e., with
tree chain nominal-conjunction-nominal), copy the case
of the heading nominal. For state, we assign d to words with
the definite article proclitic, and c to words heading an idafa
construction. All other nominals are assigned state i.
reason to be the rules’ inability to predict the
problematic u case.
Syntax-based Classifier We trained a classifier
to predict a correction of the case and state of a
word on a parsed version of the DevTrain data set.
Since the syntactic parse separates most clitics in
the PATB tokenization, we align the tree tokens
with the word morphology before extracting clas-
sifier features. The features we used are the to-
ken’s morphological features (same as those used
for words in the morphology-based classifier), the
parent and grandparent’s features, the relations be-
tween token and parent, and between parent and
grandparent, and the features of the neighboring
+/- n tokens. The tokenized clitics are only used
as context features (tree and surface). We tested
all combinations of values of n as 0, 1, 2, and 3
and of including parent and grandparent features.
The best performing setting was with including
the parent and grandparent as well as a window of
+/- 1 tokens. The syntax-based classifier improves
over the morphology-based classifier but it trails
behind syntax rules in terms of Nominal Diac. Its
All Word Diac accuracy is the highest so far.
Combination of Syntax Rules and Classifier
We combine the last two approaches to exploit
their complementary performance by including
the syntax rule predictions as features in the
syntax-based classifier. The resulting system is
our best performer achieving DevTest accuracy
improvements of 2.3% absolute (All Word Diac),
and 4.5% absolute (Nominal Diac).
</bodyText>
<subsectionHeader confidence="0.994653">
5.3 Blind Test Results
</subsectionHeader>
<bodyText confidence="0.9995913">
The results of applying the best approach and set-
tings on our blind Test set are presented in Ta-
ble 2. While the baseline on Test is slightly higher
than DevTest, the performance on all metrics are
comparable. The increase in Diac accuracy on All
Words is 2.5% absolute and on Nominals is 5.2%
absolute. The corresponding relative reductions in
error to the oracle toplines are 30% and 34%. Sim-
ilar increases are shown on the full morphological
analysis choice.
</bodyText>
<table confidence="0.9960412">
All Words Nominals
System Diac All Diac All
Oracle Topline 96.3 94.4 97.9 95.6
Baseline 88.1 86.0 82.4 79.4
Syntax Rules+Classifier 90.6 88.5 87.6 84.5
</table>
<tableCaption confidence="0.999603">
Table 2: Results on the blind Test set.
</tableCaption>
<page confidence="0.935443">
1312
</page>
<table confidence="0.948377972972973">
���
�
YJ~~
� k. àA�JJ.Ë j �B@ v@ �,...Aƒ B@ XÊª7 tSlyqy AlÂsAsy Ân AlÂmn fy lbnAn jay—id˜u
My main comment is that security in Lebanon is good
Word Dependency Gold Baseline Best System
YJ�k. jyd PRD of Ân ‘that’ jay—id˜u [NOM] jay—idi[GEN] jay—id˜u [NOM]
j;,41 o�Y; � Ai vAg. 0A¿kAn jAn -yAnm ydh Alymný
Ghanem was his right
hand
Jean
Word Dependency Gold Baseline Best System
èYK� ydh PRD of kAn ‘was’ yadahu [ACC] yadihi [GEN] yadahu [ACC]
Ë@ Alymný MOD of yd ‘hand’ Alyum.naý [U] Alyamaniy—i [GEN] Alyum.naý [U]
ú æÒJ
AK.ðPð@ AlAqtSAdy¯� mS ÂwrwbA
�����
©Ó éK��X�A �’�J��¯B���
@ ~H~ A�ªË@ P �QªJ�ƒsySzz AlSlAqAt
¯C~
with Europe
It will reinforce the economic relations
Word Dependency Gold Baseline Best System
4.DL;CªË@ OBJ of AlSalAqAti AlSalAqAti AlSalAqAti
AlSlAqAt ySzz ‘reinforce’ [ACC] [GEN] [ACC]
é�K�XA’�J�¯B@ ~MOD AlAiqtiSAdiy—a¯�a AlAiqtiSAdiy—a¯�i AlAiqtiSAdiy—a¯�a
AlAqtSAdy¯� of [ACC] [GEN] [ACC]
AlSlAqAt ‘relations’
��
... †A�®�K@ ��@ ø� QK�QmÌ @�‡J��¯P Z@P �PñË@ ~•~
K~ P~ •Ó@ é�KA�®Ë Q�K@� 0AjJ�Ê; ÉƒAK. XA’�J�¯B@ QK� Pð Y»@
Âkd wzyr AlAqtSAd bAsl flyHAn ˇABr lqAˆyh Âms rˆyys AlwzrA’ rfyq AlHryry Ân AtfAq ...
Following his meeting with the Prime Minister Rafiq Alhariri,
the Minister of Economy Basil Flaihan has confirmed that the agreement ...
Word Dependency Gold Baseline Best System
•~ SBJ of Âkd ‘confirmed’ raˆyiysa [ACC] raˆyiysa [ACC] raˆyiysu [NOM]
KP rˆyys
</table>
<figureCaption confidence="0.99805">
Figure 1: Examples of corrections from our best performing system.
</figureCaption>
<subsectionHeader confidence="0.995757">
5.4 Error Analysis and Examples
</subsectionHeader>
<bodyText confidence="0.999969740740741">
We manually investigated the types of errors in
the first 100 errors in the DevTest in our best
system’s output. In about a quarter of the cases
(23%), all of which proper nouns, the gold refer-
ence was not fully diacritized, making it impossi-
ble to evaluate. In an additional 7%, typographi-
cal errors in the input including missing sentence
breaks led to bad parses which are the likely cause
of error. The rest of the errors are system fail-
ures: 31% are connected with syntactic tree errors
(although a third of these are due to agreement-
propagated errors over correct trees); 28% are due
to other morphological analysis issues (half are
out-of-vocabulary and 4% are no-analysis cases);
and 11% are other case selection errors unrelated
to the above-mentioned issues.
Figure 1 shows four examples from the DevTest
where the analysis of our best system for the un-
derlined words is different from baseline. Exam-
ples (a), (b), and (c) are cases where our best sys-
tem’s analysis matched the gold. The dependency
relation also matched the gold and was the likely
cause of correction. In example (d), our best sys-
tem incorrectly changed the correct baseline anal-
ysis in agreement with the wrong dependency re-
lation provided by the parser, which is the likely
cause of error.
</bodyText>
<sectionHeader confidence="0.981649" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999958578947369">
We have demonstrated the value of using auto-
matic syntactic analysis as part of the task of au-
tomatic diacritization and morphological tagging
of Arabic. Our best solution is a hybrid approach
that combines statistical parsing and manual syn-
tactic rules as part of a machine learning model for
correcting case and state features.
In the future, we plan to investigate the develop-
ment of joint morphological disambiguation and
syntactic parsing models. We will also work on
improving the quality of Arabic parsing which is
behind many of the errors according to our er-
ror analysis. Other possible directions include
using more sophisticated machine learning tech-
niques and richer lexical features. We also plan
to host a demo and make our system available
through the website of the Computational Ap-
proaches to Modeling Language (CAMeL) Lab:
www.camel-lab.com.
</bodyText>
<sectionHeader confidence="0.989778" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999809">
We would like to thank Arfath Pasha for his help-
ful support overall, and especially for retraining
the special version of MADAMIRA we discuss in
footnote 5.
</bodyText>
<page confidence="0.988127">
1313
</page>
<sectionHeader confidence="0.961447" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999140452991454">
Gheith A Abandah, Alex Graves, Balkees Al-Shagoor,
Alaa Arabiyat, Fuad Jamour, and Majid Al-Taee.
2015. Automatic diacritization of Arabic text us-
ing recurrent neural networks. International Journal
on Document Analysis and Recognition (IJDAR),
18(2):183–197.
Mansour Alghamdi and Zeeshan Muzafar. 2007.
KACST Arabic diacritizer. In First International
Symposium on Computers and Arabic Language,
pages 25–28.
Sarah Alkuhlani, Nizar Habash, and Ryan Roth. 2013.
Automatic morphological enrichment of a morpho-
logically underspecified treebank. In HLT-NAACL,
pages 460–470.
S. Ananthakrishnan, S. Narayanan, and S. Bangalore.
2005. Automatic diacritization of Arabic transcripts
for ASR. In Proceedings of ICON, Kanpur, India,
December.
Mohamed Bebah, Chennoufi Amine, Mazroui Azzed-
dine, and Lakhouaja Abdelhak. 2014. Hybrid ap-
proaches for automatic vowelization of Arabic texts.
arXiv preprint arXiv:1410.2646.
Fadi Biadsy, Nizar Habash, and Julia Hirschberg.
2009. Improving the Arabic Pronunciation Dic-
tionary for Phone and Word Recognition with
Linguistically-Based Pronunciation Rules. In Pro-
ceedings of Human Language Technologies: The
2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 397–405, Boulder, Colorado.
Houda Bouamor, Wajdi Zaghouani, Mona Diab, Os-
sama Obeid, Kemal Oflazer, Mahmoud Ghoneim,
and Abdelati Hawwari. 2015. A pilot study on
Arabic multi-genre corpus diacritization. In Pro-
ceedings of the Second Workshop on Arabic Natural
Language Processing, pages 80–88, Beijing, China,
July. Association for Computational Linguistics.
Mona Diab, Mahmoud Ghoneim, and Nizar Habash.
2007. Arabic Diacritization in the Context of Sta-
tistical Machine Translation. In Proceedings of
Machine Translation Summit (MT-Summit), Copen-
hagen, Denmark.
Mona Diab, Nizar Habash, Owen Rambow, and Ryan
Roth. 2013. LDC Arabic treebanks and associ-
ated corpora: Data divisions manual. arXiv preprint
arXiv:1309.5652.
Moustafa Elshafei, Husni Al-Muhtaseb, and Mansour
Al-Ghamdi. 2002. Techniques for high qual-
ity Arabic speech synthesis. Information sciences,
140(3):255–267.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphologi-
cal Disambiguation in One Fell Swoop. In Proceed-
ings of the 43rd Annual Meeting of the Association
for Computational Linguistics (ACL’05), pages 573–
580, Ann Arbor, Michigan.
Nizar Habash and Owen Rambow. 2007. Arabic Dia-
critization through Full Morphological Tagging. In
Proceedings of the 8th Meeting of the North Amer-
ican Chapter of the Association for Computational
Linguistics/Human Language Technologies Confer-
ence (HLT-NAACL07).
Nizar Habash and Ryan M Roth. 2009. CATiB: The
Columbia Arabic Treebank. In Proceedings of the
ACL-IJCNLP 2009 Conference Short Papers, pages
221–224. Association for Computational Linguis-
tics.
Nizar Habash, Ryan Gabbard, Owen Rambow, Seth
Kulick, and Mitchell P Marcus. 2007a. Deter-
mining case in Arabic: Learning complex linguis-
tic behavior requires complex linguistic features. In
EMNLP-CoNLL, pages 1084–1092.
Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007b. On Arabic Transliteration. In A. van den
Bosch and A. Soudi, editors, Arabic Computa-
tional Morphology: Knowledge-based and Empiri-
cal Methods. Springer.
Nizar Habash, Reem Faraj, and Ryan Roth. 2009. Syn-
tactic Annotation in the Columbia Arabic Treebank.
In Proceedings of MEDAR International Conference
on Arabic Language Resources and Tools, Cairo,
Egypt.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan &amp; Claypool Publish-
ers.
Mohamed Seghir Hadj Ameur, Youcef Moulahoum,
and Ahmed Guessoum. 2015. Restoration of Ara-
bic diacritics using a multilevel statistical model. In
Computer Science and Its Applications, volume 456
of IFIP Advances in Information and Communica-
tion Technology, pages 181–192. Springer Interna-
tional Publishing.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H Witten.
2009. The WEKA data mining software: an update.
ACM SIGKDD explorations newsletter, 11(1):10–
18.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, and
Wigdan Mekki. 2004. The Penn Arabic Treebank:
Building a Large-Scale Annotated Arabic Corpus.
In NEMLAR Conference on Arabic Language Re-
sources and Tools, pages 102–109, Cairo, Egypt.
Mohamed Maamouri, Ann Bies, and Seth Kulick.
2006. Diacritization: A challenge to Arabic tree-
bank annotation and parsing. In Proceedings of the
Conference of the Machine Translation SIG of the
British Computer Society.
Mohamed Maamouri, Ann Bies, and Seth Kulick.
2009. Creating a Methodology for Large-Scale Cor-
rection of Treebank Annotation: The Case of the
Arabic Treebank. In Proceedings of MEDAR Inter-
national Conference on Arabic Language Resources
and Tools, Cairo, Egypt.
Yuval Marton, Nizar Habash, and Owen Rambow.
2013. Dependency parsing of modern standard Ara-
bic with lexical and inflectional features. Computa-
tional Linguistics, 39(1):161–194.
</reference>
<page confidence="0.863438">
1314
</page>
<reference confidence="0.999719944444445">
Rani Nelken and Stuart Shieber. 2005. Arabic Di-
acritization Using Weighted Finite-State Transduc-
ers. In Proceedings of the Workshop on Compu-
tational Approaches to Semitic Languages at 43rd
Meeting of the Association for Computational Lin-
guistics (ACL’05), pages 79–86, Ann Arbor, Michi-
gan.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, Gülsen Eryigit, Sandra Kübler, Svetoslav
Marinov, and Erwin Marsi. 2007. MaltParser:
a language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13(02):95–135.
Arfath Pasha, Mohamed Al-Badrashiny, Ahmed El
Kholy, Ramy Eskander, Mona Diab, Nizar Habash,
Manoj Pooleery, Owen Rambow, and Ryan Roth.
2014. MADAMIRA: A Fast, Comprehensive Tool
for Morphological Analysis and Disambiguation of
Arabic. In In Proceedings of LREC, Reykjavik, Ice-
land.
Ross Quinlan. 1993. C4.5: Programs for Machine
Learning. Morgan Kaufmann Publishers, San Ma-
teo, CA.
Mohsen Rashwan, Mohammad Al-Badrashiny, Mo-
hamed Attia, and S Abdou. 2009. A hybrid sys-
tem for automatic Arabic diacritization. In The 2nd
International Conference on Arabic Language Re-
sources and Tools. Citeseer.
Otakar Smrž. 2007. Functional Arabic Morphology.
Formal System and Implementation. Ph.D. thesis,
Charles University in Prague, Prague, Czech Repub-
lic.
Dimitra Vergyri and Katrin Kirchhoff. 2004. Auto-
matic Diacritization of Arabic for Acoustic Mod-
eling in Speech Recognition. In Ali Farghaly
and Karine Megerdoomian, editors, COLING 2004
Workshop on Computational Approaches to Ara-
bic Script-based Languages, pages 66–73, Geneva,
Switzerland.
Rabih Zbib, Spyros Matsoukas, Richard Schwartz, and
John Makhoul. 2010. Decision trees for lexical
smoothing in statistical machine translation. In Pro-
ceedings of the Joint Fifth Workshop on Statistical
Machine Translation and MetricsMATR, pages 428–
437, Uppsala, Sweden, July. Association for Com-
putational Linguistics.
Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya.
2006. Maximum entropy based restoration of Ara-
bic diacritics. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Compu-
tational Linguistics, pages 577–584, Sydney, Aus-
tralia, July. Association for Computational Linguis-
tics.
</reference>
<page confidence="0.992778">
1315
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.717279">
<title confidence="0.934403">Improving Arabic Diacritization through Syntactic Analysis Anas Shahrour, Salam Khalifa and Nizar Computational Approaches to Modeling Language</title>
<author confidence="0.745398">New York University Abu</author>
<affiliation confidence="0.965909">United Arab</affiliation>
<email confidence="0.999727">anas.shahrour@nyu.edu</email>
<email confidence="0.999727">salamkhalifa@nyu.edu</email>
<email confidence="0.999727">nizar.habash@nyu.edu</email>
<abstract confidence="0.999713090909091">We present an approach to Arabic automatic diacritization that integrates syntactic analysis with morphological tagging through improving the prediction of case and state features. Our best system increases the accuracy of word diacritization by 2.5% absolute on all words, and 5.2% absolute on nominals over a state-of-theart baseline. Similar increases are shown on the full morphological analysis choice.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gheith A Abandah</author>
</authors>
<title>Alex Graves, Balkees Al-Shagoor, Alaa Arabiyat, Fuad Jamour, and Majid Al-Taee.</title>
<date>2015</date>
<booktitle>International Journal on Document Analysis and Recognition (IJDAR),</booktitle>
<pages>18--2</pages>
<marker>Abandah, 2015</marker>
<rawString>Gheith A Abandah, Alex Graves, Balkees Al-Shagoor, Alaa Arabiyat, Fuad Jamour, and Majid Al-Taee. 2015. Automatic diacritization of Arabic text using recurrent neural networks. International Journal on Document Analysis and Recognition (IJDAR), 18(2):183–197.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mansour Alghamdi</author>
<author>Zeeshan Muzafar</author>
</authors>
<title>KACST Arabic diacritizer.</title>
<date>2007</date>
<booktitle>In First International Symposium on Computers and Arabic Language,</booktitle>
<pages>25--28</pages>
<contexts>
<context position="5465" citStr="Alghamdi and Muzafar, 2007" startWordPosition="828" endWordPosition="831"> and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morphological disambiguation problem, where they select th</context>
</contexts>
<marker>Alghamdi, Muzafar, 2007</marker>
<rawString>Mansour Alghamdi and Zeeshan Muzafar. 2007. KACST Arabic diacritizer. In First International Symposium on Computers and Arabic Language, pages 25–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarah Alkuhlani</author>
<author>Nizar Habash</author>
<author>Ryan Roth</author>
</authors>
<title>Automatic morphological enrichment of a morphologically underspecified treebank.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>460--470</pages>
<contexts>
<context position="7496" citStr="Alkuhlani et al. (2013)" startWordPosition="1152" endWordPosition="1155">l sentences with impressive results. We do not compare to their effort here but we note that they use an order of magnitude more diacritized data than we do, and they focus on diacritization only as opposed to full morphological analysis. In related work on modeling Arabic case and syntax, Habash et al. (2007a) compared rule-based and machine learning approaches to capture the complexity of Arabic case assignment and agreement. They demonstrated their results on gold syntactic analyses showing that given good syntactic representations, case prediction can be done at a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features, including state. Additionally, Marton et al. (2013) demonstrated that in the context of syntactic dependency parsing, case is the best feature to use in gold settings and is the worst feature to use in predicted settings. In this paper we use automatic (i.e. not gold) syntactic features to improve case prediction, which improves morphological analysis and word diacrtization. 4 Approach Motivation We are motivated by an error analysis we conducted of 1,200 words of the MADAMIRA system output. We found a large number of surprising sy</context>
<context position="15633" citStr="Alkuhlani et al. (2013)" startWordPosition="2489" endWordPosition="2492">arsity in the training data, especially given its small size and the rarity of such examples. We experimented with adding features from neighboring words within a window size of +/- 2 words. The best performing setup was with window size +/- 1. This classifier makes around 0.5% absolute gain over the simple word morphology rules. Syntax Rules Inspired by Habash et al. (2007a)’s simple set of rules for determining case on gold dependency trees, we re-implemented these rules to work with our different dependency representation and extended them to include state assignment in a manner similar to Alkuhlani et al. (2013).7 These rules improve over the baseline by 4.5% absolute in Nominal Diac accuracy, but produce no gains in All Words setting. An investigation of the error patterns reveals the main 7For nominal case assignment, our rules are: (i) default case is a; (ii) children of root are n; (iii) object of preposition and idafa children are assigned g; (iv) predicates not headed by verbs are assigned n; and (v) subjects and topics not headed (or grand-headed) by a class of words called Ân∼a and her sisters are assigned n. After case assignment, we apply two case agreement rules: (i) for all nominals modif</context>
</contexts>
<marker>Alkuhlani, Habash, Roth, 2013</marker>
<rawString>Sarah Alkuhlani, Nizar Habash, and Ryan Roth. 2013. Automatic morphological enrichment of a morphologically underspecified treebank. In HLT-NAACL, pages 460–470.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ananthakrishnan</author>
<author>S Narayanan</author>
<author>S Bangalore</author>
</authors>
<title>Automatic diacritization of Arabic transcripts for ASR.</title>
<date>2005</date>
<booktitle>In Proceedings of ICON,</booktitle>
<location>Kanpur, India,</location>
<contexts>
<context position="1114" citStr="Ananthakrishnan et al., 2005" startWordPosition="145" endWordPosition="148">f word diacritization by 2.5% absolute on all words, and 5.2% absolute on nominals over a state-of-theart baseline. Similar increases are shown on the full morphological analysis choice. 1 Introduction Modern Standard Arabic (MSA) orthography generally omits diacritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic featur</context>
</contexts>
<marker>Ananthakrishnan, Narayanan, Bangalore, 2005</marker>
<rawString>S. Ananthakrishnan, S. Narayanan, and S. Bangalore. 2005. Automatic diacritization of Arabic transcripts for ASR. In Proceedings of ICON, Kanpur, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Bebah</author>
</authors>
<title>Chennoufi Amine, Mazroui Azzeddine, and Lakhouaja Abdelhak.</title>
<date>2014</date>
<marker>Bebah, 2014</marker>
<rawString>Mohamed Bebah, Chennoufi Amine, Mazroui Azzeddine, and Lakhouaja Abdelhak. 2014. Hybrid approaches for automatic vowelization of Arabic texts. arXiv preprint arXiv:1410.2646.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fadi Biadsy</author>
<author>Nizar Habash</author>
<author>Julia Hirschberg</author>
</authors>
<title>Improving the Arabic Pronunciation Dictionary for Phone and Word Recognition with Linguistically-Based Pronunciation Rules.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>397--405</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="1136" citStr="Biadsy et al., 2009" startWordPosition="149" endWordPosition="152">absolute on all words, and 5.2% absolute on nominals over a state-of-theart baseline. Similar increases are shown on the full morphological analysis choice. 1 Introduction Modern Standard Arabic (MSA) orthography generally omits diacritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are neede</context>
</contexts>
<marker>Biadsy, Habash, Hirschberg, 2009</marker>
<rawString>Fadi Biadsy, Nizar Habash, and Julia Hirschberg. 2009. Improving the Arabic Pronunciation Dictionary for Phone and Word Recognition with Linguistically-Based Pronunciation Rules. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 397–405, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Houda Bouamor</author>
<author>Wajdi Zaghouani</author>
<author>Mona Diab</author>
<author>Ossama Obeid</author>
<author>Kemal Oflazer</author>
<author>Mahmoud Ghoneim</author>
<author>Abdelati Hawwari</author>
</authors>
<title>A pilot study on Arabic multi-genre corpus diacritization.</title>
<date>2015</date>
<booktitle>In Proceedings of the Second Workshop on Arabic Natural Language Processing,</booktitle>
<pages>80--88</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Beijing, China,</location>
<contexts>
<context position="5577" citStr="Bouamor et al., 2015" startWordPosition="849" endWordPosition="852">ct of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morphological disambiguation problem, where they select the optimal full morphological tag for Arabic in context and use it to select from a list of possible analyses pro</context>
</contexts>
<marker>Bouamor, Zaghouani, Diab, Obeid, Oflazer, Ghoneim, Hawwari, 2015</marker>
<rawString>Houda Bouamor, Wajdi Zaghouani, Mona Diab, Ossama Obeid, Kemal Oflazer, Mahmoud Ghoneim, and Abdelati Hawwari. 2015. A pilot study on Arabic multi-genre corpus diacritization. In Proceedings of the Second Workshop on Arabic Natural Language Processing, pages 80–88, Beijing, China, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Mahmoud Ghoneim</author>
<author>Nizar Habash</author>
</authors>
<title>Arabic Diacritization in the Context of Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings of Machine Translation Summit (MT-Summit),</booktitle>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="1222" citStr="Diab et al., 2007" startWordPosition="162" endWordPosition="165">ilar increases are shown on the full morphological analysis choice. 1 Introduction Modern Standard Arabic (MSA) orthography generally omits diacritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold syntactic analyses. In this paper, we develo</context>
</contexts>
<marker>Diab, Ghoneim, Habash, 2007</marker>
<rawString>Mona Diab, Mahmoud Ghoneim, and Nizar Habash. 2007. Arabic Diacritization in the Context of Statistical Machine Translation. In Proceedings of Machine Translation Summit (MT-Summit), Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>LDC Arabic treebanks and associated corpora: Data divisions manual. arXiv preprint arXiv:1309.5652.</title>
<date>2013</date>
<contexts>
<context position="9764" citStr="Diab et al. (2013)" startWordPosition="1524" endWordPosition="1527"> optimized for a re-application limit, which we found invariably to be +1 time or +2 times in our DevTest experi1310 5 Experimental Results We present next our experimental results and compare five case-state prediction techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Test along the recommendations of Diab et al. (2013) which were also used in the baseline system. The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems (Habash and Rambow, 2005; Habash and Rambow, 2007; Pasha et al., 2014). We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing. The Test set has 63K words.5 Evaluation Metrics We report our accuracy in terms of two metrics: a. Diac, the percentage of correctly fully diacrtized w</context>
</contexts>
<marker>Diab, Habash, Rambow, Roth, 2013</marker>
<rawString>Mona Diab, Nizar Habash, Owen Rambow, and Ryan Roth. 2013. LDC Arabic treebanks and associated corpora: Data divisions manual. arXiv preprint arXiv:1309.5652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moustafa Elshafei</author>
<author>Husni Al-Muhtaseb</author>
<author>Mansour Al-Ghamdi</author>
</authors>
<title>Techniques for high quality Arabic speech synthesis. Information sciences,</title>
<date>2002</date>
<pages>140--3</pages>
<contexts>
<context position="1178" citStr="Elshafei et al., 2002" startWordPosition="155" endWordPosition="158"> on nominals over a state-of-theart baseline. Similar increases are shown on the full morphological analysis choice. 1 Introduction Modern Standard Arabic (MSA) orthography generally omits diacritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold </context>
</contexts>
<marker>Elshafei, Al-Muhtaseb, Al-Ghamdi, 2002</marker>
<rawString>Moustafa Elshafei, Husni Al-Muhtaseb, and Mansour Al-Ghamdi. 2002. Techniques for high quality Arabic speech synthesis. Information sciences, 140(3):255–267.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>573--580</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="9985" citStr="Habash and Rambow, 2005" startWordPosition="1561" endWordPosition="1564">ion techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Test along the recommendations of Diab et al. (2013) which were also used in the baseline system. The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems (Habash and Rambow, 2005; Habash and Rambow, 2007; Pasha et al., 2014). We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing. The Test set has 63K words.5 Evaluation Metrics We report our accuracy in terms of two metrics: a. Diac, the percentage of correctly fully diacrtized words; and b. All, the percentage of words for which a full morphological analysis (lemma, POS, all inflectional and clitic features, and diacritization) is correctly predicted. We report the results on all words (All Word</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 573– 580, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Diacritization through Full Morphological Tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of the 8th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL07).</booktitle>
<contexts>
<context position="5437" citStr="Habash and Rambow, 2007" startWordPosition="824" endWordPosition="827">lex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morphological disambiguation p</context>
<context position="10010" citStr="Habash and Rambow, 2007" startWordPosition="1565" endWordPosition="1568">ts for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Test along the recommendations of Diab et al. (2013) which were also used in the baseline system. The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems (Habash and Rambow, 2005; Habash and Rambow, 2007; Pasha et al., 2014). We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing. The Test set has 63K words.5 Evaluation Metrics We report our accuracy in terms of two metrics: a. Diac, the percentage of correctly fully diacrtized words; and b. All, the percentage of words for which a full morphological analysis (lemma, POS, all inflectional and clitic features, and diacritization) is correctly predicted. We report the results on all words (All Words) as well as on nominals</context>
</contexts>
<marker>Habash, Rambow, 2007</marker>
<rawString>Nizar Habash and Owen Rambow. 2007. Arabic Diacritization through Full Morphological Tagging. In Proceedings of the 8th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL07).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan M Roth</author>
</authors>
<title>CATiB: The Columbia Arabic Treebank.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>221--224</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12343" citStr="Habash and Roth, 2009" startWordPosition="1943" endWordPosition="1946">s (including noun_quant and noun_num), adjectives, proper nouns, adverbs, and pronouns. All Words Nominals System Diac All Diac All Oracle Topline 96.2 94.2 98.0 95.7 Baseline 87.4 85.0 81.9 78.2 Morphology Rules 88.0 85.5 83.1 79.4 Morphology Classifier 88.4 85.9 83.7 80.1 Syntax Rules 87.4 84.6 86.4 82.2 Syntax Classifier 89.1 86.6 85.2 81.4 Syntax Rules+Classifier 89.7 87.1 86.4 82.5 Table 1: Results on DevTest. Syntactic Analysis For syntactic features, we trained an Arabic dependency parser using MaltParser (Nivre et al., 2007) on the Columbia Arabic Treebank (CATiB) version of the PATB (Habash and Roth, 2009). The Train data followed the same splits mentioned above. The Nivre &amp;quot;eager&amp;quot; algorithm was used in all experiments. The CATiB dependency tree has six simple POS tags and eight relations (Habash and Roth, 2009; Habash et al., 2009). The PATB tokenization as well as the CATiB POS tags were produced by the baseline system MADAMIRA and used as input to the parser. We also used the well performing yet simple CATiBex expansion of the CATiB tags as implemented in the publicly available parsing pipeline from Marton et al. (2013). Our parser’s performance on the PATB Dev set is comparable to Marton et </context>
</contexts>
<marker>Habash, Roth, 2009</marker>
<rawString>Nizar Habash and Ryan M Roth. 2009. CATiB: The Columbia Arabic Treebank. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 221–224. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ryan Gabbard</author>
<author>Owen Rambow</author>
<author>Seth Kulick</author>
<author>Mitchell P Marcus</author>
</authors>
<title>Determining case in Arabic: Learning complex linguistic behavior requires complex linguistic features. In EMNLP-CoNLL,</title>
<date>2007</date>
<pages>1084--1092</pages>
<contexts>
<context position="1368" citStr="Habash et al. (2007" startWordPosition="183" endWordPosition="186">ritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold syntactic analyses. In this paper, we develop an approach for improving the quality of automatic Arabic diacritization through the use of automatic syntactic analysis. Our approach combines </context>
<context position="4155" citStr="Habash et al., 2007" startWordPosition="629" endWordPosition="632">.g., the suffix I Aã in U�Er� kitAbAã3 is a morpheme indicating the word is (cas:a, stt:i). Second, undiacritized Arabic words are highly ambiguous: in our training data, words had an average of 12.8 analyses per word, most of which are associated with different diacritizations. Some diacritization differences reflect different analysis 1Lemma (lex), Part-of-Speech (pos), Gender (gen), Number (num), Case (cas), State (stt), Person (per), Aspect (asp), Voice (vox), Mood (mod), four proclitics (prcn), and one enclitic (enc0). 2For a detailed discussion of Arabic case and state, see (Smrž, 2007; Habash et al., 2007a). 3Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007b). 1309 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1309–1315, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. lemmas; while others are due to morpho-syntactic differences. For example, the undiacritized version of the word we used above (l��l��r ktAbA) has two other diacritizations and analyses: l���l�����r kut∼AbAã (cas:a stt:i) ‘writers’ (different lemma) and l���l���r� kitAbA (cas:n stt:c num:d) ‘two b</context>
<context position="7183" citStr="Habash et al. (2007" startWordPosition="1105" endWordPosition="1108">es to improve morphological disambiguation accuracy. We demonstrate improvements in terms of both full morphological analysis choice (lemmatization, tokenization, all features) as well as word diacritization. Most recently, Abandah et al. (2015) presented a recurrent neural network approach to diacritize full sentences with impressive results. We do not compare to their effort here but we note that they use an order of magnitude more diacritized data than we do, and they focus on diacritization only as opposed to full morphological analysis. In related work on modeling Arabic case and syntax, Habash et al. (2007a) compared rule-based and machine learning approaches to capture the complexity of Arabic case assignment and agreement. They demonstrated their results on gold syntactic analyses showing that given good syntactic representations, case prediction can be done at a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features, including state. Additionally, Marton et al. (2013) demonstrated that in the context of syntactic dependency parsing, case is the best feature to use in gold settings and is the worst feature to use in predicted settings. In</context>
<context position="9115" citStr="Habash et al. (2007" startWordPosition="1417" endWordPosition="1420">roposed Solution Our approach is to provide better prediction of case and state using models with access to additional information, in particular syntactic analysis and rules. The predicted case and state values are then used to re-tag the MADAMIRA output by selecting the best match in its ranked morphological analyses. We limit our retagging to nominals. Since what we are learning to predict is how to correct MADAMIRA’s baseline choice (as opposed to a generative model of case-state), we also re-apply the model on its output to fix primarily propagated agreement errors in a manner similar to Habash et al. (2007a)’s agreement classifier.4 4We optimized for a re-application limit, which we found invariably to be +1 time or +2 times in our DevTest experi1310 5 Experimental Results We present next our experimental results and compare five case-state prediction techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Tes</context>
<context position="15386" citStr="Habash et al. (2007" startWordPosition="2451" endWordPosition="2454">AMIRA. BOS and EOS placeholders were used for sentence boundaries. We excluded all DevTrain words whose predicted POS switches from nominal to nonnominal or vice versa, but kept them as part of other words’ context. This minimizes noise and sparsity in the training data, especially given its small size and the rarity of such examples. We experimented with adding features from neighboring words within a window size of +/- 2 words. The best performing setup was with window size +/- 1. This classifier makes around 0.5% absolute gain over the simple word morphology rules. Syntax Rules Inspired by Habash et al. (2007a)’s simple set of rules for determining case on gold dependency trees, we re-implemented these rules to work with our different dependency representation and extended them to include state assignment in a manner similar to Alkuhlani et al. (2013).7 These rules improve over the baseline by 4.5% absolute in Nominal Diac accuracy, but produce no gains in All Words setting. An investigation of the error patterns reveals the main 7For nominal case assignment, our rules are: (i) default case is a; (ii) children of root are n; (iii) object of preposition and idafa children are assigned g; (iv) predi</context>
</contexts>
<marker>Habash, Gabbard, Rambow, Kulick, Marcus, 2007</marker>
<rawString>Nizar Habash, Ryan Gabbard, Owen Rambow, Seth Kulick, and Mitchell P Marcus. 2007a. Determining case in Arabic: Learning complex linguistic behavior requires complex linguistic features. In EMNLP-CoNLL, pages 1084–1092.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Abdelhadi Soudi</author>
<author>Tim Buckwalter</author>
</authors>
<title>On Arabic Transliteration.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="1368" citStr="Habash et al. (2007" startWordPosition="183" endWordPosition="186">ritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold syntactic analyses. In this paper, we develop an approach for improving the quality of automatic Arabic diacritization through the use of automatic syntactic analysis. Our approach combines </context>
<context position="4155" citStr="Habash et al., 2007" startWordPosition="629" endWordPosition="632">.g., the suffix I Aã in U�Er� kitAbAã3 is a morpheme indicating the word is (cas:a, stt:i). Second, undiacritized Arabic words are highly ambiguous: in our training data, words had an average of 12.8 analyses per word, most of which are associated with different diacritizations. Some diacritization differences reflect different analysis 1Lemma (lex), Part-of-Speech (pos), Gender (gen), Number (num), Case (cas), State (stt), Person (per), Aspect (asp), Voice (vox), Mood (mod), four proclitics (prcn), and one enclitic (enc0). 2For a detailed discussion of Arabic case and state, see (Smrž, 2007; Habash et al., 2007a). 3Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007b). 1309 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1309–1315, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. lemmas; while others are due to morpho-syntactic differences. For example, the undiacritized version of the word we used above (l��l��r ktAbA) has two other diacritizations and analyses: l���l�����r kut∼AbAã (cas:a stt:i) ‘writers’ (different lemma) and l���l���r� kitAbA (cas:n stt:c num:d) ‘two b</context>
<context position="7183" citStr="Habash et al. (2007" startWordPosition="1105" endWordPosition="1108">es to improve morphological disambiguation accuracy. We demonstrate improvements in terms of both full morphological analysis choice (lemmatization, tokenization, all features) as well as word diacritization. Most recently, Abandah et al. (2015) presented a recurrent neural network approach to diacritize full sentences with impressive results. We do not compare to their effort here but we note that they use an order of magnitude more diacritized data than we do, and they focus on diacritization only as opposed to full morphological analysis. In related work on modeling Arabic case and syntax, Habash et al. (2007a) compared rule-based and machine learning approaches to capture the complexity of Arabic case assignment and agreement. They demonstrated their results on gold syntactic analyses showing that given good syntactic representations, case prediction can be done at a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features, including state. Additionally, Marton et al. (2013) demonstrated that in the context of syntactic dependency parsing, case is the best feature to use in gold settings and is the worst feature to use in predicted settings. In</context>
<context position="9115" citStr="Habash et al. (2007" startWordPosition="1417" endWordPosition="1420">roposed Solution Our approach is to provide better prediction of case and state using models with access to additional information, in particular syntactic analysis and rules. The predicted case and state values are then used to re-tag the MADAMIRA output by selecting the best match in its ranked morphological analyses. We limit our retagging to nominals. Since what we are learning to predict is how to correct MADAMIRA’s baseline choice (as opposed to a generative model of case-state), we also re-apply the model on its output to fix primarily propagated agreement errors in a manner similar to Habash et al. (2007a)’s agreement classifier.4 4We optimized for a re-application limit, which we found invariably to be +1 time or +2 times in our DevTest experi1310 5 Experimental Results We present next our experimental results and compare five case-state prediction techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Tes</context>
<context position="15386" citStr="Habash et al. (2007" startWordPosition="2451" endWordPosition="2454">AMIRA. BOS and EOS placeholders were used for sentence boundaries. We excluded all DevTrain words whose predicted POS switches from nominal to nonnominal or vice versa, but kept them as part of other words’ context. This minimizes noise and sparsity in the training data, especially given its small size and the rarity of such examples. We experimented with adding features from neighboring words within a window size of +/- 2 words. The best performing setup was with window size +/- 1. This classifier makes around 0.5% absolute gain over the simple word morphology rules. Syntax Rules Inspired by Habash et al. (2007a)’s simple set of rules for determining case on gold dependency trees, we re-implemented these rules to work with our different dependency representation and extended them to include state assignment in a manner similar to Alkuhlani et al. (2013).7 These rules improve over the baseline by 4.5% absolute in Nominal Diac accuracy, but produce no gains in All Words setting. An investigation of the error patterns reveals the main 7For nominal case assignment, our rules are: (i) default case is a; (ii) children of root are n; (iii) object of preposition and idafa children are assigned g; (iv) predi</context>
</contexts>
<marker>Habash, Soudi, Buckwalter, 2007</marker>
<rawString>Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007b. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Reem Faraj</author>
<author>Ryan Roth</author>
</authors>
<title>Syntactic Annotation in the Columbia Arabic Treebank.</title>
<date>2009</date>
<booktitle>In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools,</booktitle>
<location>Cairo, Egypt.</location>
<contexts>
<context position="12573" citStr="Habash et al., 2009" startWordPosition="1981" endWordPosition="1984"> Morphology Classifier 88.4 85.9 83.7 80.1 Syntax Rules 87.4 84.6 86.4 82.2 Syntax Classifier 89.1 86.6 85.2 81.4 Syntax Rules+Classifier 89.7 87.1 86.4 82.5 Table 1: Results on DevTest. Syntactic Analysis For syntactic features, we trained an Arabic dependency parser using MaltParser (Nivre et al., 2007) on the Columbia Arabic Treebank (CATiB) version of the PATB (Habash and Roth, 2009). The Train data followed the same splits mentioned above. The Nivre &amp;quot;eager&amp;quot; algorithm was used in all experiments. The CATiB dependency tree has six simple POS tags and eight relations (Habash and Roth, 2009; Habash et al., 2009). The PATB tokenization as well as the CATiB POS tags were produced by the baseline system MADAMIRA and used as input to the parser. We also used the well performing yet simple CATiBex expansion of the CATiB tags as implemented in the publicly available parsing pipeline from Marton et al. (2013). Our parser’s performance on the PATB Dev set is comparable to Marton et al. (2013): 84.2% labeled attachment, 86.6% unlabeled attachment, and 93.6% label accuracy. Machine Learning Technique Given the small size of DevTrain, we opted to train unlexicalized models that we expect to capture morphosyntac</context>
</contexts>
<marker>Habash, Faraj, Roth, 2009</marker>
<rawString>Nizar Habash, Reem Faraj, and Ryan Roth. 2009. Syntactic Annotation in the Columbia Arabic Treebank. In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="5270" citStr="Habash (2010)" startWordPosition="799" endWordPosition="800">ut∼AbAã (cas:a stt:i) ‘writers’ (different lemma) and l���l���r� kitAbA (cas:n stt:c num:d) ‘two books of [...]’ (different features). Third, Arabic has complex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deepe</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Seghir Hadj Ameur</author>
<author>Youcef Moulahoum</author>
<author>Ahmed Guessoum</author>
</authors>
<title>Restoration of Arabic diacritics using a multilevel statistical model.</title>
<date>2015</date>
<booktitle>In Computer Science and Its Applications,</booktitle>
<volume>456</volume>
<pages>181--192</pages>
<publisher>Springer International Publishing.</publisher>
<contexts>
<context position="5532" citStr="Ameur et al., 2015" startWordPosition="841" endWordPosition="844">le, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morphological disambiguation problem, where they select the optimal full morphological tag for Arabic in context and use it t</context>
</contexts>
<marker>Ameur, Moulahoum, Guessoum, 2015</marker>
<rawString>Mohamed Seghir Hadj Ameur, Youcef Moulahoum, and Ahmed Guessoum. 2015. Restoration of Arabic diacritics using a multilevel statistical model. In Computer Science and Its Applications, volume 456 of IFIP Advances in Information and Communication Technology, pages 181–192. Springer International Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: an update.</title>
<date>2009</date>
<journal>ACM SIGKDD explorations newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<pages>18</pages>
<contexts>
<context position="13346" citStr="Hall et al., 2009" startWordPosition="2111" endWordPosition="2114">erforming yet simple CATiBex expansion of the CATiB tags as implemented in the publicly available parsing pipeline from Marton et al. (2013). Our parser’s performance on the PATB Dev set is comparable to Marton et al. (2013): 84.2% labeled attachment, 86.6% unlabeled attachment, and 93.6% label accuracy. Machine Learning Technique Given the small size of DevTrain, we opted to train unlexicalized models that we expect to capture morphosyntactic abstractions. We tried a number of machine learning techniques and settled on using the J48 Decision tree classifier with its default settings in WEKA (Hall et al., 2009; Quinlan, 1993) for all of the classification experiments in this paper. 5.2 Case and State Classification Techniques We detail and report on five case-state classification techniques we experimented with. All results on the DevTest are presented in Table 1. Morphology Rules We created a simple manual word-morphology based classifier that handled the most salient case errors seen in our pilot study (Section 4) and whose correction has a high precision. The scope of the rules was limited to word bigrams and included three conditions: (i) post1311 verbal genitive nouns are changed to the first </context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The WEKA data mining software: an update. ACM SIGKDD explorations newsletter, 11(1):10– 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Wigdan Mekki</author>
</authors>
<title>The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus.</title>
<date>2004</date>
<booktitle>In NEMLAR Conference on Arabic Language Resources and Tools,</booktitle>
<pages>102--109</pages>
<location>Cairo, Egypt.</location>
<contexts>
<context position="9630" citStr="Maamouri et al., 2004" startWordPosition="1500" endWordPosition="1503">odel on its output to fix primarily propagated agreement errors in a manner similar to Habash et al. (2007a)’s agreement classifier.4 4We optimized for a re-application limit, which we found invariably to be +1 time or +2 times in our DevTest experi1310 5 Experimental Results We present next our experimental results and compare five case-state prediction techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Test along the recommendations of Diab et al. (2013) which were also used in the baseline system. The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems (Habash and Rambow, 2005; Habash and Rambow, 2007; Pasha et al., 2014). We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing. The Test set has </context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic Treebank: Building a Large-Scale Annotated Arabic Corpus. In NEMLAR Conference on Arabic Language Resources and Tools, pages 102–109, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
</authors>
<title>Diacritization: A challenge to Arabic treebank annotation and parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference of the Machine Translation SIG of the British Computer Society.</booktitle>
<contexts>
<context position="9653" citStr="Maamouri et al., 2006" startWordPosition="1504" endWordPosition="1507">ix primarily propagated agreement errors in a manner similar to Habash et al. (2007a)’s agreement classifier.4 4We optimized for a re-application limit, which we found invariably to be +1 time or +2 times in our DevTest experi1310 5 Experimental Results We present next our experimental results and compare five case-state prediction techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Test along the recommendations of Diab et al. (2013) which were also used in the baseline system. The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems (Habash and Rambow, 2005; Habash and Rambow, 2007; Pasha et al., 2014). We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing. The Test set has 63K words.5 Evaluation </context>
</contexts>
<marker>Maamouri, Bies, Kulick, 2006</marker>
<rawString>Mohamed Maamouri, Ann Bies, and Seth Kulick. 2006. Diacritization: A challenge to Arabic treebank annotation and parsing. In Proceedings of the Conference of the Machine Translation SIG of the British Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
</authors>
<title>Creating a Methodology for Large-Scale Correction of Treebank Annotation: The Case of the Arabic Treebank.</title>
<date>2009</date>
<booktitle>In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools,</booktitle>
<location>Cairo, Egypt.</location>
<contexts>
<context position="9677" citStr="Maamouri et al., 2009" startWordPosition="1508" endWordPosition="1511"> agreement errors in a manner similar to Habash et al. (2007a)’s agreement classifier.4 4We optimized for a re-application limit, which we found invariably to be +1 time or +2 times in our DevTest experi1310 5 Experimental Results We present next our experimental results and compare five case-state prediction techniques. The results for these techniques are compared to our state-of-the-art baseline system, which has been compared to a number of other approaches. 5.1 Experimental Setup Data We used the Penn Arabic Treebank (PATB, parts 1, 2 and 3) (Maamouri et al., 2004; Maamouri et al., 2006; Maamouri et al., 2009) split into Train, Dev and (blind) Test along the recommendations of Diab et al. (2013) which were also used in the baseline system. The morphological feature representations we use are derived from the PATB analyses following the approach used in the MADA and later MADAMIRA systems (Habash and Rambow, 2005; Habash and Rambow, 2007; Pasha et al., 2014). We further divide Dev into two parts with equal number of sentences: DevTrain (30K words) for training our case-state classifiers, and DevTest (33K words) for development testing. The Test set has 63K words.5 Evaluation Metrics We report our ac</context>
</contexts>
<marker>Maamouri, Bies, Kulick, 2009</marker>
<rawString>Mohamed Maamouri, Ann Bies, and Seth Kulick. 2009. Creating a Methodology for Large-Scale Correction of Treebank Annotation: The Case of the Arabic Treebank. In Proceedings of MEDAR International Conference on Arabic Language Resources and Tools, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Dependency parsing of modern standard Arabic with lexical and inflectional features.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>1</issue>
<contexts>
<context position="7610" citStr="Marton et al. (2013)" startWordPosition="1169" endWordPosition="1172">nitude more diacritized data than we do, and they focus on diacritization only as opposed to full morphological analysis. In related work on modeling Arabic case and syntax, Habash et al. (2007a) compared rule-based and machine learning approaches to capture the complexity of Arabic case assignment and agreement. They demonstrated their results on gold syntactic analyses showing that given good syntactic representations, case prediction can be done at a high degree of accuracy. Alkuhlani et al. (2013) later extended this work to cover all morphological features, including state. Additionally, Marton et al. (2013) demonstrated that in the context of syntactic dependency parsing, case is the best feature to use in gold settings and is the worst feature to use in predicted settings. In this paper we use automatic (i.e. not gold) syntactic features to improve case prediction, which improves morphological analysis and word diacrtization. 4 Approach Motivation We are motivated by an error analysis we conducted of 1,200 words of the MADAMIRA system output. We found a large number of surprising syntactically impossible case errors such as genitive nouns following verbs or construct nouns followed by non-genit</context>
<context position="12869" citStr="Marton et al. (2013)" startWordPosition="2033" endWordPosition="2036">al., 2007) on the Columbia Arabic Treebank (CATiB) version of the PATB (Habash and Roth, 2009). The Train data followed the same splits mentioned above. The Nivre &amp;quot;eager&amp;quot; algorithm was used in all experiments. The CATiB dependency tree has six simple POS tags and eight relations (Habash and Roth, 2009; Habash et al., 2009). The PATB tokenization as well as the CATiB POS tags were produced by the baseline system MADAMIRA and used as input to the parser. We also used the well performing yet simple CATiBex expansion of the CATiB tags as implemented in the publicly available parsing pipeline from Marton et al. (2013). Our parser’s performance on the PATB Dev set is comparable to Marton et al. (2013): 84.2% labeled attachment, 86.6% unlabeled attachment, and 93.6% label accuracy. Machine Learning Technique Given the small size of DevTrain, we opted to train unlexicalized models that we expect to capture morphosyntactic abstractions. We tried a number of machine learning techniques and settled on using the J48 Decision tree classifier with its default settings in WEKA (Hall et al., 2009; Quinlan, 1993) for all of the classification experiments in this paper. 5.2 Case and State Classification Techniques We d</context>
</contexts>
<marker>Marton, Habash, Rambow, 2013</marker>
<rawString>Yuval Marton, Nizar Habash, and Owen Rambow. 2013. Dependency parsing of modern standard Arabic with lexical and inflectional features. Computational Linguistics, 39(1):161–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Stuart Shieber</author>
</authors>
<title>Arabic Diacritization Using Weighted Finite-State Transducers.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Computational Approaches to Semitic Languages at 43rd Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>79--86</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="5390" citStr="Nelken and Shieber, 2005" startWordPosition="816" endWordPosition="819">.]’ (different features). Third, Arabic has complex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization </context>
</contexts>
<marker>Nelken, Shieber, 2005</marker>
<rawString>Rani Nelken and Stuart Shieber. 2005. Arabic Diacritization Using Weighted Finite-State Transducers. In Proceedings of the Workshop on Computational Approaches to Semitic Languages at 43rd Meeting of the Association for Computational Linguistics (ACL’05), pages 79–86, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Atanas Chanev, Gülsen Eryigit, Sandra Kübler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>02</issue>
<contexts>
<context position="12259" citStr="Nivre et al., 2007" startWordPosition="1929" endWordPosition="1932">ence from the baseline system in terms of our metrics. 6Nominals consists of nouns (including noun_quant and noun_num), adjectives, proper nouns, adverbs, and pronouns. All Words Nominals System Diac All Diac All Oracle Topline 96.2 94.2 98.0 95.7 Baseline 87.4 85.0 81.9 78.2 Morphology Rules 88.0 85.5 83.1 79.4 Morphology Classifier 88.4 85.9 83.7 80.1 Syntax Rules 87.4 84.6 86.4 82.2 Syntax Classifier 89.1 86.6 85.2 81.4 Syntax Rules+Classifier 89.7 87.1 86.4 82.5 Table 1: Results on DevTest. Syntactic Analysis For syntactic features, we trained an Arabic dependency parser using MaltParser (Nivre et al., 2007) on the Columbia Arabic Treebank (CATiB) version of the PATB (Habash and Roth, 2009). The Train data followed the same splits mentioned above. The Nivre &amp;quot;eager&amp;quot; algorithm was used in all experiments. The CATiB dependency tree has six simple POS tags and eight relations (Habash and Roth, 2009; Habash et al., 2009). The PATB tokenization as well as the CATiB POS tags were produced by the baseline system MADAMIRA and used as input to the parser. We also used the well performing yet simple CATiBex expansion of the CATiB tags as implemented in the publicly available parsing pipeline from Marton et </context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, Gülsen Eryigit, Sandra Kübler, Svetoslav Marinov, and Erwin Marsi. 2007. MaltParser: a language-independent system for data-driven dependency parsing. Natural Language Engineering, 13(02):95–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arfath Pasha</author>
<author>Mohamed Al-Badrashiny</author>
<author>Ahmed El Kholy</author>
<author>Ramy Eskander</author>
<author>Mona Diab</author>
<author>Nizar Habash</author>
<author>Manoj Pooleery</author>
<author>Owen Rambow</author>
<author>Ryan Roth</author>
</authors>
<title>MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic. In</title>
<date>2014</date>
<booktitle>In Proceedings of LREC, Reykjavik,</booktitle>
<marker>Pasha, Al-Badrashiny, El Kholy, Eskander, Diab, Habash, Pooleery, Rambow, Roth, 2014</marker>
<rawString>Arfath Pasha, Mohamed Al-Badrashiny, Ahmed El Kholy, Ramy Eskander, Mona Diab, Nizar Habash, Manoj Pooleery, Owen Rambow, and Ryan Roth. 2014. MADAMIRA: A Fast, Comprehensive Tool for Morphological Analysis and Disambiguation of Arabic. In In Proceedings of LREC, Reykjavik, Iceland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann Publishers,</publisher>
<location>San Mateo, CA.</location>
<contexts>
<context position="13362" citStr="Quinlan, 1993" startWordPosition="2115" endWordPosition="2116">e CATiBex expansion of the CATiB tags as implemented in the publicly available parsing pipeline from Marton et al. (2013). Our parser’s performance on the PATB Dev set is comparable to Marton et al. (2013): 84.2% labeled attachment, 86.6% unlabeled attachment, and 93.6% label accuracy. Machine Learning Technique Given the small size of DevTrain, we opted to train unlexicalized models that we expect to capture morphosyntactic abstractions. We tried a number of machine learning techniques and settled on using the J48 Decision tree classifier with its default settings in WEKA (Hall et al., 2009; Quinlan, 1993) for all of the classification experiments in this paper. 5.2 Case and State Classification Techniques We detail and report on five case-state classification techniques we experimented with. All results on the DevTest are presented in Table 1. Morphology Rules We created a simple manual word-morphology based classifier that handled the most salient case errors seen in our pilot study (Section 4) and whose correction has a high precision. The scope of the rules was limited to word bigrams and included three conditions: (i) post1311 verbal genitive nouns are changed to the first nongenitive anal</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>Ross Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann Publishers, San Mateo, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohsen Rashwan</author>
<author>Mohammad Al-Badrashiny</author>
<author>Mohamed Attia</author>
<author>S Abdou</author>
</authors>
<title>A hybrid system for automatic Arabic diacritization.</title>
<date>2009</date>
<booktitle>In The 2nd International Conference on Arabic Language Resources</booktitle>
<contexts>
<context position="5487" citStr="Rashwan et al., 2009" startWordPosition="832" endWordPosition="835"> interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morphological disambiguation problem, where they select the optimal full morphol</context>
</contexts>
<marker>Rashwan, Al-Badrashiny, Attia, Abdou, 2009</marker>
<rawString>Mohsen Rashwan, Mohammad Al-Badrashiny, Mohamed Attia, and S Abdou. 2009. A hybrid system for automatic Arabic diacritization. In The 2nd International Conference on Arabic Language Resources and Tools. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Otakar Smrž</author>
</authors>
<title>Functional Arabic Morphology. Formal System and Implementation.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>Charles University in Prague,</institution>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="4134" citStr="Smrž, 2007" startWordPosition="627" endWordPosition="628">orpheme, � e.g., the suffix I Aã in U�Er� kitAbAã3 is a morpheme indicating the word is (cas:a, stt:i). Second, undiacritized Arabic words are highly ambiguous: in our training data, words had an average of 12.8 analyses per word, most of which are associated with different diacritizations. Some diacritization differences reflect different analysis 1Lemma (lex), Part-of-Speech (pos), Gender (gen), Number (num), Case (cas), State (stt), Person (per), Aspect (asp), Voice (vox), Mood (mod), four proclitics (prcn), and one enclitic (enc0). 2For a detailed discussion of Arabic case and state, see (Smrž, 2007; Habash et al., 2007a). 3Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007b). 1309 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1309–1315, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. lemmas; while others are due to morpho-syntactic differences. For example, the undiacritized version of the word we used above (l��l��r ktAbA) has two other diacritizations and analyses: l���l�����r kut∼AbAã (cas:a stt:i) ‘writers’ (different lemma) and l���l���r� kitAbA (cas:</context>
</contexts>
<marker>Smrž, 2007</marker>
<rawString>Otakar Smrž. 2007. Functional Arabic Morphology. Formal System and Implementation. Ph.D. thesis, Charles University in Prague, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitra Vergyri</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Automatic Diacritization of Arabic for Acoustic Modeling in Speech Recognition.</title>
<date>2004</date>
<booktitle>In Ali Farghaly and Karine Megerdoomian, editors, COLING 2004 Workshop on Computational Approaches to Arabic Script-based Languages,</booktitle>
<pages>66--73</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="5364" citStr="Vergyri and Kirchhoff, 2004" startWordPosition="812" endWordPosition="815">tt:c num:d) ‘two books of [...]’ (different features). Third, Arabic has complex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007</context>
</contexts>
<marker>Vergyri, Kirchhoff, 2004</marker>
<rawString>Dimitra Vergyri and Katrin Kirchhoff. 2004. Automatic Diacritization of Arabic for Acoustic Modeling in Speech Recognition. In Ali Farghaly and Karine Megerdoomian, editors, COLING 2004 Workshop on Computational Approaches to Arabic Script-based Languages, pages 66–73, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rabih Zbib</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>John Makhoul</author>
</authors>
<title>Decision trees for lexical smoothing in statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>428--437</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="1242" citStr="Zbib et al., 2010" startWordPosition="166" endWordPosition="169">shown on the full morphological analysis choice. 1 Introduction Modern Standard Arabic (MSA) orthography generally omits diacritical marks which encode lexical as well as syntactic (case) information. The task of Arabic automatic diacritization is about the automatic restoration of the missing diacritics. Diacritization improvement in Arabic has important implications for downstream processing for Arabic natural language processing, e.g. speech recognition (Ananthakrishnan et al., 2005; Biadsy et al., 2009), speech synthesis (Elshafei et al., 2002), and machine translation (Diab et al., 2007; Zbib et al., 2010). Previous efforts on diacritization utilized morphological tagging techniques to disambiguate word forms. Habash et al. (2007a) observe that while such techniques work relatively well on lexical diacritics (located on word stems), they are much worse for syntactic case diacritics (typically word final). They suggest that syntactic analysis may help with automatic diacrtization, but stop short of testing the idea, and instead demonstrate that complex linguistic features and rules are needed to model complex Arabic case using gold syntactic analyses. In this paper, we develop an approach for im</context>
</contexts>
<marker>Zbib, Matsoukas, Schwartz, Makhoul, 2010</marker>
<rawString>Rabih Zbib, Spyros Matsoukas, Richard Schwartz, and John Makhoul. 2010. Decision trees for lexical smoothing in statistical machine translation. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 428– 437, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Imed Zitouni</author>
<author>Jeffrey S Sorensen</author>
<author>Ruhi Sarikaya</author>
</authors>
<title>Maximum entropy based restoration of Arabic diacritics.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>577--584</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="5412" citStr="Zitouni et al., 2006" startWordPosition="820" endWordPosition="823">Third, Arabic has complex case/state assignment and agreement patterns that interact with the sentence’s syntax. For example, a noun may get its case by being subject of a verb and its state by being the head of an idafa construction; while adjectives modifying this noun agree with it in its case, their state is determined by the state of the last element in the idafa chain the noun heads. For more information on Arabic orthography, morphology, and syntax, see Habash (2010). 3 Related Work Much work has been done on Arabic diacritization (Vergyri and Kirchhoff, 2004; Nelken and Shieber, 2005; Zitouni et al., 2006; Habash and Rambow, 2007; Alghamdi and Muzafar, 2007; Rashwan et al., 2009; Bebah et al., 2014; Hadj Ameur et al., 2015; Abandah et al., 2015; Bouamor et al., 2015). We refer the reader to the extensive literature review by Abandah et al. (2015), and focus on systems we compare with. Most of the previous approaches cited above utilize different sequence modeling techniques that use varying degrees of knowledge from shallow letter and word forms to deeper morphological information; none to our knowledge make use of syntax. Habash and Rambow (2007) approach diacritization as a part of the morph</context>
</contexts>
<marker>Zitouni, Sorensen, Sarikaya, 2006</marker>
<rawString>Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya. 2006. Maximum entropy based restoration of Arabic diacritics. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 577–584, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>