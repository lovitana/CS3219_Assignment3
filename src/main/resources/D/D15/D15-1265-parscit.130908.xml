<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000251">
<title confidence="0.9990225">
Wikification of Concept Mentions within Spoken Dialogues
Using Domain Constraints from Wikipedia
</title>
<author confidence="0.987026">
Seokhwan Kim, Rafael E. Banchs, Haizhou Li
</author>
<affiliation confidence="0.9758775">
Human Language Technology Department
Institute for Infocomm Research
</affiliation>
<address confidence="0.979335">
Singapore 138632
</address>
<email confidence="0.999299">
{kims,rembanchs,hli}@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.997393" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999808142857143">
While most previous work on Wikification
has focused on written texts, this paper
presents a Wikification approach for spo-
ken dialogues. A set of analyzers are pro-
posed to learn dialogue-specific properties
along with domain knowledge of conver-
sations from Wikipedia. Then, the an-
alyzed properties are used as constraints
for generating candidates, and the candi-
dates are ranked to find the appropriate
links. The experimental results show that
our proposed approach can significantly
improve the performances of the task in
human-human dialogues.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999836">
Linking mentions in natural language to the
relevant concepts in knowledge-bases plays a
key role in better understanding the meanings
of expressions as well as further populating
knowledge-bases with less human effort. Espe-
cially, Wikipedia has been widely used as a major
target resource for linking. Most previous work
on this Wikipedia-based linking task called Wiki-
fication (Mihalcea and Csomai, 2007) has focused
on resolving ambiguities and variabilities of the
expressions in written texts including newswire
collections (McNamee and Dang, 2009; Ji et al.,
2010; Ji et al., 2014) or microblog posts (Genc et
al., 2011; Cassidy et al., 2012; Guo et al., 2013;
Huang et al., 2014).
But writing and reading are not the only ways
for exchange of information, since many commu-
nications between people in real life are performed
through spoken dialogues also. Thus, we could
expect to improve the understanding capabilities
of applications based on Wikification and broaden
the coverage of the contents in knowledge-bases,
if Wikification is successfully performed also for
human-human spoken conversations.
In this work, we focus on the following differ-
ences between spoken dialogues and written texts
as sources for Wikification. Firstly, at least two
speakers are engaged in a dialogue session, while
the texts in newswire or microblogs are mostly
written by a single author. Thus, the viewpoint of
each speaker should be considered separately or
jointly depending on the situation. Secondly, the
correspondence between mentions and concepts in
spoken dialogues tends to be dependent not only
on the contexts explicitly mentioned in a given di-
alogue, but also on other information inferred by
speakers based on their background knowledge.
The other difference is that spoken utterances are
more likely to be informal and noisy than writ-
ten sentences, which makes expressions more am-
biguous and variable.
To solve these issues, we propose a three step
approach for Wikification on spoken dialogues. At
the first step, a set of classifiers are used for an-
alyzing the dialogue-specific aspects of a given
mention. According to the analyzed results, the
criteria in selecting concept candidates is deter-
mined, and then a ranking is performed on the fil-
tered candidates to identify the concept that is the
most relevant to the mention.
While many researchers have worked on link-
ing named-entities (Bunescu and Pasca, 2006;
Cucerzan, 2007; McNamee and Dang, 2009; Han
and Sun, 2011; Han et al., 2011; Ji et al., 2014)
or other types of concept mentions (Mihalcea and
Csomai, 2007; Milne and Witten, 2008; Ferragina
and Scaiella, 2010; Ratinov et al., 2011; Mendes
et al., 2011; Cheng and Roth, 2013) to the relevant
articles in Wikipedia, all the noun phrases includ-
ing not only named entities or base noun phrases,
but also complex or recursive noun phrases in a di-
alogue are considered as instances to be linked in
this work. For the concept candidates, we divide
every article into sub-sections and consider each
section as a unit along with article-level concepts.
</bodyText>
<page confidence="0.903458">
2225
</page>
<note confidence="0.865635">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figure confidence="0.995973563380282">
Guide: In the morning I suggest to you to go to Botanical Garden.
LV ID
+ - + +
DR SRG SRT
-
+
LV ID
DR SRG
SRT
- -
- -
Input Mention
mi
Tourist: Oh, we also have Botanical Garden.
LV
ID
DR
SRG
SRT
+
-
-
-
+
Step 1
Tourist: That is actually one of my favourite places here.
Linking
Validity
Analysis
In-dialogue
Reference
Analysis
Domain
Relevance
Analysis
Speaker
Relatedness
Analysis
Guide: If so, you might like this place also.
LV
+
ID
+
DR
-
SRG
-
SRT
+
LV ID
+
- - -
DR SRG SRT
+
LV
ID
DR
SRG
SRT
+
+
+
+
-
Step 2
Candidate
Generation
Wikipedia
Concepts
History
&lt;mj, f(mj)&gt;j=0..(i-1)
</figure>
<figureCaption confidence="0.997218666666667">
Figure 2: Examples of annotations for mention
analysis: SRG and SRT denote guide and tourist
relatedness, respectively.
</figureCaption>
<figure confidence="0.9947714">
Step 3
Candidate
Ranking
Output Concept
f(mi)
</figure>
<bodyText confidence="0.990519454545455">
lated to the topic or the profile of a speaker. Then,
all the articles listed on these seed pages are col-
lected and considered as the related concepts in the
corresponding sets.
Since every property has a positive or a negative
value as a result, each analysis can be considered
as a binary classification problem. In this work,
we train support vector machines (SVM) (Cortes
and Vapnik, 1995) from the dialogues annotated
with the corresponding labels as shown in Figure 2
based on the features listed in Table 1.
</bodyText>
<subsectionHeader confidence="0.999617">
2.2 Candidate Generation
</subsectionHeader>
<bodyText confidence="0.999993208333333">
After analyzing the above property values of a
given mention, a set of concepts to be disam-
biguated are selected from Wikipedia. These can-
didates are retrieved from a Lucene 1 index on the
whole Wikipedia collection with the fields of ar-
ticle title, section title, redirection, category, and
body texts. Each query to the search engine is pre-
pared with the combination of the mention phrase
and its analyzed properties as constraints for fil-
tering. If the value for in-dialogue reference is
positive, the searching is restricted to the set of
concepts linked with the previous mentions in the
same session. Similarly, the domain relevance
and speaker relatedness values provide the filter-
ing condition within the corresponding subsets in-
troduced in Section 2.1.
One practical issue on this candidate generation
step is how to combine the multiple constraints
when we have more than one positive proper-
ties for a given mention. The simplest way is
taking the intersection of the corresponding con-
straints. However, we should consider the fact
that the properties assigned automatically can be
erroneous, since none of the analyzer is perfect.
</bodyText>
<footnote confidence="0.981652">
1http://lucene.apache.org/
</footnote>
<figureCaption confidence="0.981357">
Figure 1: Overall architecture of three-step ap-
proach for Wikification on spoken dialogues
</figureCaption>
<sectionHeader confidence="0.779861" genericHeader="introduction">
2 Method
</sectionHeader>
<subsectionHeader confidence="0.957123">
2.1 Mention Analysis
</subsectionHeader>
<bodyText confidence="0.999854896551724">
The first step in our proposed approach (Figure 1)
is analyzing the following four types of binary
properties of a given mention: linking validity
(LV ), in-dialogue reference (ID), domain rele-
vance (DR), and speaker relatedness (SR).
Linking validity of the mention is determined
by the decision whether it is matched with any
Wikipedia concept or not. Since only the men-
tions assigned with positive validity values are
proceeded to the further processes, this classifi-
cation can be considered as a joint task for target
mention identification and NIL detection.
Another type of analysis focuses on the refer-
ences between the mention and the linking his-
tory. If the mention is matched with one in the set
of concepts for the previous mentions in the same
session, it has a positive value for the in-dialogue
reference property.
The other two types of properties are defined
for indicating the relevances of the mention to the
contents that are specific to the target domain or
the profiles of each speaker in the conversation.
For these analyses, the whole Wikipedia collection
is partitioned into subsets according to the domain
or speaker-relevances. In this work, the concepts
in these subsets are automatically collected with
no manual effort by utilizing the domain knowl-
edge also from Wikipedia. First, we retrieve the
‘List’ or ‘Index’ pages in Wikipedia that are re-
</bodyText>
<page confidence="0.964684">
2226
</page>
<table confidence="0.949254733333333">
Level Name Description
Mention SP the speaker who spoke that mention
WM word n-grams within the mention
LM lemma n-grams within the mention
PM POS n-grams within the mention
NE named entities within the mention
NP base noun phrases within the men-
tion
Utterance BW the words before the mention
AW the words after the mention
BL the lemmas before the mention
AL the lemmas after the mention
BP the POS tags before the mention
AP the POS tags after the mention
IU whether the mention previously oc-
</table>
<bodyText confidence="0.957524785714286">
curs in the same utterance
Dialogue EO whether the phrase is previously
mentioned in the dialogue history
EOS whether the phrase is previously
mentioned by the same speaker in
the history
Wikipedia IW whether the phrase is a title of an
entry in Wikipedia
IWD whether the phrase is a title of an
entry in the set of domain-relevant
concepts
IWSk whether the phrase is a title of an
entry in the set of k-th speaker-
relevant concepts
</bodyText>
<tableCaption confidence="0.6859395">
Table 1: List of features for training the models for
mention analysis
</tableCaption>
<bodyText confidence="0.9998625">
For the noisy cases, the intersection-based filtering
could be risky, because the errors are also jointly
accumulated. To circumvent the impact of errors
from the previous step, we also try to use the union
of the constraints and compare it with the intersec-
tion case later in Section 3.
</bodyText>
<subsectionHeader confidence="0.999213">
2.3 Candidate Ranking
</subsectionHeader>
<bodyText confidence="0.62710672972973">
In this work, linking a given mention to its
most relevant concept is determined by ranking
SVM (Joachims, 2002) which is a pairwise rank-
ing algorithm learned from the ranked lists. For
each pair of a mention m in the training data and
its candidate concept c, the ranking score s(m, c)
is assigned as follows:
s(m, c) = { 4 if c is the exactly same as f(m),
3 if c is the parent article of f(m),
2 if c belongs to the same article
but different section of f(m),
1 otherwise.
where f(m) is the annotation of m in the train-
ing dataset. The list of candidates assigned with
their scores provides the relative orders for a given
mention, and it can be converted into a set of
Name Description
SP the speaker who spoke that mention
WM word n-grams within the surface of m
WT word n-grams within the title of c
EMT whether the surface of m is same as the title of c
EMR whether the surface of m is same as one of re-
directions to c
MIT whether the surface of m is a sub-string of the
title of c
TIM whether the title of c is a sub-string of the m’s
surface form
MIR whether the surface of m is a sub-string of a re-
directed title to c
RIM whether a re-directed title to c is a sub-string of
the m’s surface form
PMT similarity score based on edit distance between
the surface of m and the title of c
PMR maximum similarity score between the surface of
m and the redirected titles to c
OC whether c previously occurred in the full dialogue
history
</bodyText>
<equation confidence="0.391493">
OCw whether c occurred within w previous turns with
w ∈ {1, 3, 5, 10}
</equation>
<tableCaption confidence="0.895134">
Table 2: List of features for training the ranking
SVM model
</tableCaption>
<bodyText confidence="0.983979">
pairwise constraints which are trained by ranking
SVM with the features in Table 2.
</bodyText>
<sectionHeader confidence="0.99857" genericHeader="method">
3 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.991678">
3.1 Data
</subsectionHeader>
<bodyText confidence="0.999952333333333">
To demonstrate the effectiveness of our approach
to Wikification on spoken dialogues, we per-
formed experiments on a dialogue corpus which
consists of 35 sessions collected from human-
human conversations in English about tourism
in Singapore between actual tour guides in Sin-
gapore and tourists from the Philippines. All
the recorded dialogues with the total length of
21 hours were manually transcribed, then the
31,034 utterance were pre-processed by Stanford
CoreNLP toolkit 2. Each noun phrase in the con-
stituent trees provided by the parser is consid-
ered as an instance for Wikification and manu-
ally annotated with the corresponding concept in
Wikipedia. 34,949 mentions have been linked to
the concepts in Wikipedia.
As a pool for candidate generation, we built a
Lucene index based on Wikipedia database dump
as of January 2015 which has 4,797,927 articles
and 25,577,464 sections in total. From this collec-
tion, 11,128 and 27,186 articles have been consid-
ered as Singapore-related and Philippines-related
concepts, respectively, for the filtering based on
domain and speaker relevances.
</bodyText>
<footnote confidence="0.963791">
2http://nlp.stanford.edu/software/corenlp.shtml
</footnote>
<page confidence="0.961608">
2227
</page>
<table confidence="0.999699125">
Features LV ID SRG SRT
M 86.29 69.15 71.10 72.94
M+U 86.90 70.43 70.43 68.85
M+D 86.17 71.09 70.56 71.52
M+W 86.21 68.96 70.66 71.86
M+U+D 86.82 72.37 70.12 68.30
M+U+W 86.84 70.13 70.19 68.78
M+U+D+W 86.77 72.20 69.94 68.10
</table>
<tableCaption confidence="0.999221">
Table 3: Comparisons of the performances in
</tableCaption>
<bodyText confidence="0.5700965">
F-measure of mention analyzers with different
combinations of features: M,U,D,W denotes
mention-level, utterance-level, dialogue-level, and
Wikipedia features, respectively
</bodyText>
<subsectionHeader confidence="0.999941">
3.2 Mention Analysis
</subsectionHeader>
<bodyText confidence="0.999659380952381">
Based on the annotated dialogues, we built four
mention analyzers for LV , ID, SRG, and SRT,
where SRG is for the guides and SRT is for the
tourists in the conversations. In this work, only the
information where each speaker is from was con-
sidered as a profile to analyze the speaker-related
properties. Since all the guides participated in the
data collection are from Singapore and the main
topic of the conversations is also about Singapore,
we omitted DR which should have the same re-
sults as SRG in the experiments.
For each analyzer, we trained the SVM models
using SVMlight 3 with the features in Table 1. All
the evaluations were performed in five-fold cross
validation to the manual annotations with preci-
sion, recall, and F-measure.
Table 3 compares the performances of the seven
combinations of feature sets for each analyzer.
Based on these results, we selected the model that
achieved the best performance for each analyzer to
process the mentions for the further steps.
</bodyText>
<table confidence="0.516499">
Method P R F
</table>
<tableCaption confidence="0.880164">
Table 4: Comparisons of the performances of
Wikification on spoken dialogues
</tableCaption>
<bodyText confidence="0.997324428571429">
considered as the correct constraints, which is in-
tended for comparing with the others to investigate
the influence of errors in mention analysis. For ev-
ery set, we retrieved top 100 candidates satisfying
the given constraints from the Lucene index with
Wikipedia collection and added one more special
candidate for NIL detection.
</bodyText>
<subsectionHeader confidence="0.997334">
3.4 Candidate Ranking
</subsectionHeader>
<bodyText confidence="0.99994085">
For each set of candidates, we trained a ranking
function using SVMrank4 with the features in Ta-
ble 2. Both training and testing the ranking models
were performed also based on five-fold cross vali-
dation with the same divisions as the former eval-
uation. After getting the ranking results, we took
the top-ranked candidate for each list and consid-
ered it as a result of Wikification for the corre-
sponding mention.
Table 4 compares the final performances of
Wikification obtained by ranking on the candi-
dates generated with different sets of constraints.
Both approaches, intersection and union, outper-
formed the baseline by 12.60 and 13.50 in F-
measure, respectively. While the intersection strat-
egy contributed to produce more precise outputs
than the others even including the case with man-
ual filtering, the other proposed approach with
union achieved more gain in recall with slightly
better F-measure than the former one.
</bodyText>
<table confidence="0.949376">
No filtering 26.85 22.52 21.24
Intersection 44.37 27.35 33.84
Union 38.04 31.97 34.74
Manual (Oracle) 39.90 34.72 37.13
</table>
<subsectionHeader confidence="0.998378">
3.3 Candidate Generation
</subsectionHeader>
<bodyText confidence="0.9996148">
For each mention in the corpus, we prepared four
sets of candidates with different filtering con-
straints. While the first baseline set was retrieved
with no filtering, the others were generated ac-
cording to the procedure described in Section 2.2.
When more than one positive values were pro-
vided from mention analyzers, intersection and
union operators were applied for combining mul-
tiple constraints. In the last set, the property val-
ues manually annotated in the training data were
</bodyText>
<footnote confidence="0.845143">
3http://svmlight.joachims.org/
</footnote>
<sectionHeader confidence="0.99953" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999879777777778">
This paper presented a Wikification approach
for spoken dialogues. In this approach, a set
of dialogue-specific properties were analyzed for
generating concept candidates. Then, supervised
ranking was performed on these candidates to
identify the relevant concepts. Experimental re-
sults show that the proposed constraints help to
improve the performances of the task on spoken
dialogues.
</bodyText>
<footnote confidence="0.997284">
4http://www.cs.cornell.edu/people/tj/svm light/svm rank.html
</footnote>
<page confidence="0.994532">
2228
</page>
<sectionHeader confidence="0.995516" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999737457831325">
Razvan C. Bunescu and Marius Pasca. 2006. Using
Encyclopedic Knowledge for Named entity Disam-
biguation. In EACL, volume 6, pages 9–16.
Taylor Cassidy, Heng Ji, Lev-Arie Ratinov, Arkaitz Zu-
biaga, and Hongzhao Huang. 2012. Analysis and
Enhancement of Wikification for Microblogs with
Context Expansion. In COLING, volume 12, pages
441–456.
Xiao Cheng and Dan Roth. 2013. Relational inference
for wikification. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1787–1796.
Corinna Cortes and Vladimir Vapnik. 1995. Support-
vector networks. Machine learning, 20(3):273–297.
Silviu Cucerzan. 2007. Large-Scale Named En-
tity Disambiguation Based on Wikipedia Data. In
EMNLP-CoNLL, volume 7, pages 708–716.
Paolo Ferragina and Ugo Scaiella. 2010. Tagme:
on-the-fly annotation of short text fragments (by
wikipedia entities). In Proceedings of the 19th ACM
international conference on Information and knowl-
edge management, pages 1625–1628.
Yegin Genc, Yasuaki Sakamoto, and Jeffrey V Nicker-
son. 2011. Discovering context: Classifying tweets
through a semantic transform based on wikipedia.
Foundations of Augmented Cognition, page 484.
Stephen Guo, Ming-Wei Chang, and Emre Kiciman.
2013. To Link or Not to Link? A Study on End-to-
End Tweet Entity Linking. In HLT-NAACL, pages
1020–1030.
Xianpei Han and Le Sun. 2011. A generative entity-
mention model for linking entities with knowledge
base. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies-Volume 1, pages 945–
954. Association for Computational Linguistics.
Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective
entity linking in web text: a graph-based method. In
Proceedings of the 34th international ACM SIGIR
conference on Research and development in Infor-
mation Retrieval, pages 765–774.
Hongzhao Huang, Yunbo Cao, Xiaojiang Huang, Heng
Ji, and Chin-Yew Lin. 2014. Collective tweet wiki-
fication based on semi-supervised graph regulariza-
tion. Proceedings of the ACL, Baltimore, Maryland.
Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2010. Overview of the tac 2010
knowledge base population track. In Third Text
Analysis Conference (TAC 2010).
Heng Ji, H. T. Dang, J. Nothman, and B. Hachey.
2014. Overview of tac-kbp2014 entity discovery
and linking tasks. In Proc. Text Analysis Conference
(TAC2014).
Thorsten Joachims. 2002. Optimizing search en-
gines using clickthrough data. In Proceedings of the
eighth ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 133–
142.
Paul McNamee and Hoa Trang Dang. 2009. Overview
of the tac 2009 knowledge base population track. In
Text Analysis Conference (TAC), volume 17, pages
111–113.
Pablo N Mendes, Max Jakob, Andr´es Garc´ıa-Silva, and
Christian Bizer. 2011. Dbpedia spotlight: shedding
light on the web of documents. In Proceedings of
the 7th International Conference on Semantic Sys-
tems, pages 1–8.
Rada Mihalcea and Andras Csomai. 2007. Wikify!:
linking documents to encyclopedic knowledge. In
Proceedings of the sixteenth ACM conference on
Conference on information and knowledge manage-
ment, pages 233–242.
David Milne and Ian H. Witten. 2008. Learning to link
with wikipedia. In Proceedings of the 17th ACM
conference on Information and knowledge manage-
ment, pages 509–518.
Lev Ratinov, Dan Roth, Doug Downey, and Mike
Anderson. 2011. Local and global algorithms
for disambiguation to wikipedia. In Proceedings
of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies-Volume 1, pages 1375–1384. Associ-
ation for Computational Linguistics.
</reference>
<page confidence="0.995152">
2229
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.632744">
<title confidence="0.998104">Wikification of Concept Mentions within Spoken Using Domain Constraints from Wikipedia</title>
<author confidence="0.924132">Seokhwan Kim</author>
<author confidence="0.924132">Rafael E Banchs</author>
<author confidence="0.924132">Haizhou</author>
<affiliation confidence="0.8749595">Human Language Technology Institute for Infocomm</affiliation>
<address confidence="0.857959">Singapore</address>
<abstract confidence="0.998931">While most previous work on Wikification has focused on written texts, this paper presents a Wikification approach for spoken dialogues. A set of analyzers are proposed to learn dialogue-specific properties along with domain knowledge of conversations from Wikipedia. Then, the analyzed properties are used as constraints for generating candidates, and the candidates are ranked to find the appropriate links. The experimental results show that our proposed approach can significantly improve the performances of the task in human-human dialogues.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Marius Pasca</author>
</authors>
<title>Using Encyclopedic Knowledge for Named entity Disambiguation.</title>
<date>2006</date>
<booktitle>In EACL,</booktitle>
<volume>6</volume>
<pages>9--16</pages>
<contexts>
<context position="3258" citStr="Bunescu and Pasca, 2006" startWordPosition="493" endWordPosition="496">e likely to be informal and noisy than written sentences, which makes expressions more ambiguous and variable. To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each sectio</context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>Razvan C. Bunescu and Marius Pasca. 2006. Using Encyclopedic Knowledge for Named entity Disambiguation. In EACL, volume 6, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Cassidy</author>
<author>Heng Ji</author>
<author>Lev-Arie Ratinov</author>
<author>Arkaitz Zubiaga</author>
<author>Hongzhao Huang</author>
</authors>
<title>Analysis and Enhancement of Wikification for Microblogs with Context Expansion.</title>
<date>2012</date>
<booktitle>In COLING,</booktitle>
<volume>12</volume>
<pages>441--456</pages>
<contexts>
<context position="1484" citStr="Cassidy et al., 2012" startWordPosition="212" endWordPosition="215"> language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at l</context>
</contexts>
<marker>Cassidy, Ji, Ratinov, Zubiaga, Huang, 2012</marker>
<rawString>Taylor Cassidy, Heng Ji, Lev-Arie Ratinov, Arkaitz Zubiaga, and Hongzhao Huang. 2012. Analysis and Enhancement of Wikification for Microblogs with Context Expansion. In COLING, volume 12, pages 441–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Cheng</author>
<author>Dan Roth</author>
</authors>
<title>Relational inference for wikification.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1787--1796</pages>
<contexts>
<context position="3535" citStr="Cheng and Roth, 2013" startWordPosition="541" endWordPosition="544">e-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Guide: In the morning I sugges</context>
</contexts>
<marker>Cheng, Roth, 2013</marker>
<rawString>Xiao Cheng and Dan Roth. 2013. Relational inference for wikification. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1787–1796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Supportvector networks.</title>
<date>1995</date>
<booktitle>Machine learning,</booktitle>
<pages>20--3</pages>
<contexts>
<context position="5254" citStr="Cortes and Vapnik, 1995" startWordPosition="845" endWordPosition="848">date Generation Wikipedia Concepts History &lt;mj, f(mj)&gt;j=0..(i-1) Figure 2: Examples of annotations for mention analysis: SRG and SRT denote guide and tourist relatedness, respectively. Step 3 Candidate Ranking Output Concept f(mi) lated to the topic or the profile of a speaker. Then, all the articles listed on these seed pages are collected and considered as the related concepts in the corresponding sets. Since every property has a positive or a negative value as a result, each analysis can be considered as a binary classification problem. In this work, we train support vector machines (SVM) (Cortes and Vapnik, 1995) from the dialogues annotated with the corresponding labels as shown in Figure 2 based on the features listed in Table 1. 2.2 Candidate Generation After analyzing the above property values of a given mention, a set of concepts to be disambiguated are selected from Wikipedia. These candidates are retrieved from a Lucene 1 index on the whole Wikipedia collection with the fields of article title, section title, redirection, category, and body texts. Each query to the search engine is prepared with the combination of the mention phrase and its analyzed properties as constraints for filtering. If t</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Supportvector networks. Machine learning, 20(3):273–297.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-Scale Named Entity Disambiguation Based on Wikipedia Data.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<volume>7</volume>
<pages>708--716</pages>
<contexts>
<context position="3274" citStr="Cucerzan, 2007" startWordPosition="497" endWordPosition="498">nd noisy than written sentences, which makes expressions more ambiguous and variable. To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit alon</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-Scale Named Entity Disambiguation Based on Wikipedia Data. In EMNLP-CoNLL, volume 7, pages 708–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Ferragina</author>
<author>Ugo Scaiella</author>
</authors>
<title>Tagme: on-the-fly annotation of short text fragments (by wikipedia entities).</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international conference on Information and knowledge management,</booktitle>
<pages>1625--1628</pages>
<contexts>
<context position="3469" citStr="Ferragina and Scaiella, 2010" startWordPosition="529" endWordPosition="532">t the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, Lisbon, Portugal, 17-21 September 2015. c�2015 Associa</context>
</contexts>
<marker>Ferragina, Scaiella, 2010</marker>
<rawString>Paolo Ferragina and Ugo Scaiella. 2010. Tagme: on-the-fly annotation of short text fragments (by wikipedia entities). In Proceedings of the 19th ACM international conference on Information and knowledge management, pages 1625–1628.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yegin Genc</author>
<author>Yasuaki Sakamoto</author>
<author>Jeffrey V Nickerson</author>
</authors>
<title>Discovering context: Classifying tweets through a semantic transform based on wikipedia. Foundations of Augmented Cognition,</title>
<date>2011</date>
<pages>484</pages>
<contexts>
<context position="1462" citStr="Genc et al., 2011" startWordPosition="208" endWordPosition="211">mentions in natural language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikif</context>
</contexts>
<marker>Genc, Sakamoto, Nickerson, 2011</marker>
<rawString>Yegin Genc, Yasuaki Sakamoto, and Jeffrey V Nickerson. 2011. Discovering context: Classifying tweets through a semantic transform based on wikipedia. Foundations of Augmented Cognition, page 484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Guo</author>
<author>Ming-Wei Chang</author>
<author>Emre Kiciman</author>
</authors>
<title>To Link or Not to Link? A Study on End-toEnd Tweet Entity Linking. In</title>
<date>2013</date>
<booktitle>HLT-NAACL,</booktitle>
<pages>1020--1030</pages>
<contexts>
<context position="1502" citStr="Guo et al., 2013" startWordPosition="216" endWordPosition="219">ant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at least two speakers </context>
</contexts>
<marker>Guo, Chang, Kiciman, 2013</marker>
<rawString>Stephen Guo, Ming-Wei Chang, and Emre Kiciman. 2013. To Link or Not to Link? A Study on End-toEnd Tweet Entity Linking. In HLT-NAACL, pages 1020–1030.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
</authors>
<title>A generative entitymention model for linking entities with knowledge base.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>945--954</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Han, Le Sun, 2011</marker>
<rawString>Xianpei Han and Le Sun. 2011. A generative entitymention model for linking entities with knowledge base. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 945– 954. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
<author>Jun Zhao</author>
</authors>
<title>Collective entity linking in web text: a graph-based method.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,</booktitle>
<pages>765--774</pages>
<marker>Han, Le Sun, Zhao, 2011</marker>
<rawString>Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective entity linking in web text: a graph-based method. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 765–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongzhao Huang</author>
<author>Yunbo Cao</author>
<author>Xiaojiang Huang</author>
<author>Heng Ji</author>
<author>Chin-Yew Lin</author>
</authors>
<title>Collective tweet wikification based on semi-supervised graph regularization.</title>
<date>2014</date>
<booktitle>Proceedings of the ACL,</booktitle>
<location>Baltimore, Maryland.</location>
<contexts>
<context position="1523" citStr="Huang et al., 2014" startWordPosition="220" endWordPosition="223">owledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues and written texts as sources for Wikification. Firstly, at least two speakers are engaged in a dial</context>
</contexts>
<marker>Huang, Cao, Huang, Ji, Lin, 2014</marker>
<rawString>Hongzhao Huang, Yunbo Cao, Xiaojiang Huang, Heng Ji, and Chin-Yew Lin. 2014. Collective tweet wikification based on semi-supervised graph regularization. Proceedings of the ACL, Baltimore, Maryland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
<author>Kira Griffitt</author>
<author>Joe Ellis</author>
</authors>
<title>Overview of the tac 2010 knowledge base population track.</title>
<date>2010</date>
<booktitle>In Third Text Analysis Conference (TAC</booktitle>
<contexts>
<context position="1406" citStr="Ji et al., 2010" startWordPosition="197" endWordPosition="200">task in human-human dialogues. 1 Introduction Linking mentions in natural language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between</context>
</contexts>
<marker>Ji, Grishman, Dang, Griffitt, Ellis, 2010</marker>
<rawString>Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Griffitt, and Joe Ellis. 2010. Overview of the tac 2010 knowledge base population track. In Third Text Analysis Conference (TAC 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>H T Dang</author>
<author>J Nothman</author>
<author>B Hachey</author>
</authors>
<title>Overview of tac-kbp2014 entity discovery and linking tasks.</title>
<date>2014</date>
<booktitle>In Proc. Text Analysis Conference (TAC2014).</booktitle>
<contexts>
<context position="1424" citStr="Ji et al., 2014" startWordPosition="201" endWordPosition="204">an dialogues. 1 Introduction Linking mentions in natural language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following differences between spoken dialogues </context>
<context position="3353" citStr="Ji et al., 2014" startWordPosition="511" endWordPosition="514">ariable. To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empir</context>
</contexts>
<marker>Ji, Dang, Nothman, Hachey, 2014</marker>
<rawString>Heng Ji, H. T. Dang, J. Nothman, and B. Hachey. 2014. Overview of tac-kbp2014 entity discovery and linking tasks. In Proc. Text Analysis Conference (TAC2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Optimizing search engines using clickthrough data.</title>
<date>2002</date>
<booktitle>In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>133--142</pages>
<contexts>
<context position="9489" citStr="Joachims, 2002" startWordPosition="1550" endWordPosition="1551">et of domain-relevant concepts IWSk whether the phrase is a title of an entry in the set of k-th speakerrelevant concepts Table 1: List of features for training the models for mention analysis For the noisy cases, the intersection-based filtering could be risky, because the errors are also jointly accumulated. To circumvent the impact of errors from the previous step, we also try to use the union of the constraints and compare it with the intersection case later in Section 3. 2.3 Candidate Ranking In this work, linking a given mention to its most relevant concept is determined by ranking SVM (Joachims, 2002) which is a pairwise ranking algorithm learned from the ranked lists. For each pair of a mention m in the training data and its candidate concept c, the ranking score s(m, c) is assigned as follows: s(m, c) = { 4 if c is the exactly same as f(m), 3 if c is the parent article of f(m), 2 if c belongs to the same article but different section of f(m), 1 otherwise. where f(m) is the annotation of m in the training dataset. The list of candidates assigned with their scores provides the relative orders for a given mention, and it can be converted into a set of Name Description SP the speaker who spo</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 133– 142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of the tac 2009 knowledge base population track.</title>
<date>2009</date>
<booktitle>In Text Analysis Conference (TAC),</booktitle>
<volume>17</volume>
<pages>111--113</pages>
<contexts>
<context position="1389" citStr="McNamee and Dang, 2009" startWordPosition="193" endWordPosition="196">the performances of the task in human-human dialogues. 1 Introduction Linking mentions in natural language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents in knowledge-bases, if Wikification is successfully performed also for human-human spoken conversations. In this work, we focus on the following di</context>
<context position="3298" citStr="McNamee and Dang, 2009" startWordPosition="499" endWordPosition="502">itten sentences, which makes expressions more ambiguous and variable. To solve these issues, we propose a three step approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level con</context>
</contexts>
<marker>McNamee, Dang, 2009</marker>
<rawString>Paul McNamee and Hoa Trang Dang. 2009. Overview of the tac 2009 knowledge base population track. In Text Analysis Conference (TAC), volume 17, pages 111–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo N Mendes</author>
<author>Max Jakob</author>
<author>Andr´es Garc´ıa-Silva</author>
<author>Christian Bizer</author>
</authors>
<title>Dbpedia spotlight: shedding light on the web of documents.</title>
<date>2011</date>
<booktitle>In Proceedings of the 7th International Conference on Semantic Systems,</booktitle>
<pages>1--8</pages>
<marker>Mendes, Jakob, Garc´ıa-Silva, Bizer, 2011</marker>
<rawString>Pablo N Mendes, Max Jakob, Andr´es Garc´ıa-Silva, and Christian Bizer. 2011. Dbpedia spotlight: shedding light on the web of documents. In Proceedings of the 7th International Conference on Semantic Systems, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Andras Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,</booktitle>
<pages>233--242</pages>
<contexts>
<context position="1243" citStr="Mihalcea and Csomai, 2007" startWordPosition="173" endWordPosition="176">ates, and the candidates are ranked to find the appropriate links. The experimental results show that our proposed approach can significantly improve the performances of the task in human-human dialogues. 1 Introduction Linking mentions in natural language to the relevant concepts in knowledge-bases plays a key role in better understanding the meanings of expressions as well as further populating knowledge-bases with less human effort. Especially, Wikipedia has been widely used as a major target resource for linking. Most previous work on this Wikipedia-based linking task called Wikification (Mihalcea and Csomai, 2007) has focused on resolving ambiguities and variabilities of the expressions in written texts including newswire collections (McNamee and Dang, 2009; Ji et al., 2010; Ji et al., 2014) or microblog posts (Genc et al., 2011; Cassidy et al., 2012; Guo et al., 2013; Huang et al., 2014). But writing and reading are not the only ways for exchange of information, since many communications between people in real life are performed through spoken dialogues also. Thus, we could expect to improve the understanding capabilities of applications based on Wikification and broaden the coverage of the contents i</context>
<context position="3415" citStr="Mihalcea and Csomai, 2007" startWordPosition="521" endWordPosition="524">ep approach for Wikification on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, </context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>Rada Mihalcea and Andras Csomai. 2007. Wikify!: linking documents to encyclopedic knowledge. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pages 233–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>509--518</pages>
<contexts>
<context position="3439" citStr="Milne and Witten, 2008" startWordPosition="525" endWordPosition="528">n on spoken dialogues. At the first step, a set of classifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, Lisbon, Portugal, 17-21 </context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H. Witten. 2008. Learning to link with wikipedia. In Proceedings of the 17th ACM conference on Information and knowledge management, pages 509–518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>1375--1384</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3491" citStr="Ratinov et al., 2011" startWordPosition="533" endWordPosition="536">ssifiers are used for analyzing the dialogue-specific aspects of a given mention. According to the analyzed results, the criteria in selecting concept candidates is determined, and then a ranking is performed on the filtered candidates to identify the concept that is the most relevant to the mention. While many researchers have worked on linking named-entities (Bunescu and Pasca, 2006; Cucerzan, 2007; McNamee and Dang, 2009; Han and Sun, 2011; Han et al., 2011; Ji et al., 2014) or other types of concept mentions (Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011; Mendes et al., 2011; Cheng and Roth, 2013) to the relevant articles in Wikipedia, all the noun phrases including not only named entities or base noun phrases, but also complex or recursive noun phrases in a dialogue are considered as instances to be linked in this work. For the concept candidates, we divide every article into sub-sections and consider each section as a unit along with article-level concepts. 2225 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2225–2229, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 1375–1384. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>