<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000584">
<title confidence="0.989315">
Inferring Binary Relation Schemas for Open Information Extraction
</title>
<author confidence="0.995153">
Kangqi Luo1 and Xusheng Luo2 and Kenny Q. Zhu3
</author>
<affiliation confidence="0.996254">
Department of Computer Science &amp; Engineering
Shanghai Jiao Tong University, Shanghai, China
</affiliation>
<email confidence="0.878561">
1luokangqi@sjtu.edu.cn 2freefish 6174@sjtu.edu.cn 3kzhu@cs.sjtu.edu.cn
</email>
<sectionHeader confidence="0.990341" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999981714285714">
This paper presents a framework to model
the semantic representation of binary re-
lations produced by open information ex-
traction systems. For each binary relation,
we infer a set of preferred types on the
two arguments simultaneously, and gen-
erate a ranked list of type pairs which
we call schemas. All inferred types are
drawn from the Freebase type taxonomy,
which are human readable. Our system
collects 171,168 binary relations from Re-
Verb, and is able to produce top-ranking
relation schemas with a mean reciprocal
rank of 0.337.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.981153523809524">
Open information extraction (or Open IE) is a task
of extracting all sorts of relations between named
entities or concepts from open-domain text cor-
pora, without restraining itself to specific rela-
tions or patterns. State-of-the-art Open IE sys-
tems (Carlson et al., 2010; Fader et al., 2011;
Schmitz et al., 2012; Nakashole et al., 2012) ex-
tract millions of binary relations with high preci-
sion from the web corpus. Each extracted relation
instance is a triple of the form (arg1, rel, arg2),
where the relation rel is a lexical or syntactic pat-
tern, and both arguments are multi-word expres-
sions representing the argument entities or con-
cepts.
Whereas Open IE provides concrete relation in-
stances, we are interested in generalizing these
instances into more abstract semantic representa-
tions. In this paper, we focus on inferring the
schemas of binary relations.
For example, given the binary relation “play in”,
an Open IE system extracts many triples of the
form (X, play in, Y ). The following relation
triples are extracted in ReVerb:
(Goel Grey, played in, Cabaret)
(Tom Brady, play in, National Football League)
Informally, the goal of our system is to
automatically infer a set of schemas such as
(t1, play in, t2), where t1 and t2 are two seman-
tic types drawn from a standard knowledge base
such as WordNet (Miller, 1995), Yago (Suchanek
et al., 2007), Freebase (Bollacker et al., 2008), and
Probase (Wu et al., 2012), and each such schema
can be used to represent a set of “play in” relation
instances. For the above example, two possible
schemas for “play in” are:
(film actor, play in, film)
(athlete, play in, sports league)
The schema of a binary relation is useful in-
formation in NLP tasks, such as context-oriented
entity recognition and open domain question an-
swering. Suppose we are to recognize the enti-
ties in the sentence “Granger played in the IBA”.
“Granger” is a highly ambiguous term, while “the
IBA” is probably a sports league. Then with the
the above relation schemas for “play in”, the entity
recognizer knows that “Granger” is more likely to
be an athlete, which results in the correct linking
to “Danny Granger”, who is an NBA player, even
though the Open IE has never extracted such fact
before.
One relevant technique to achieve our goal is
selectional preference (SP) (Resnik, 1996; Erk,
2007; Ritter et al., 2010), which computes the
most appropriate types for a specific argument of
a predicate. SP is based on the idea of mutual in-
formation (Erk, 2007), which tends to select types
which are unique to the relation. In other words,
common types which can be used for many differ-
ent relations are less preferred. However, in Open
IE, many relations are related or even similar, e.g.,
play in, take part in and be involved in. There’s
no reason for these relations not to share schemas.
Therefore in this paper, our problem is, given a re-
</bodyText>
<page confidence="0.994164">
555
</page>
<note confidence="0.659333">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 555–560,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999925545454545">
lation and its instances, identify the smallest types
that can cover as many instances as possible. Our
approach first attempts to link the arguments in the
relation instances to a set of possible entities in a
knowledge base, hence generate a set of (e1, e2)
entity pairs. Then we select a pair of types (t1, t2)
that covers maximum number of entity pairs. We
resolve ties by selecting the smaller (more spe-
cific) types according to a type taxonomy inferred
from knowledge base.
This paper makes the following contributions:
i) we defined the schema inference problem for
binary relations from Open IE; ii) we developed
a prototype system based on Freebase and entity
linking (Lin et al., 2012; Ratinov et al., 2011;
Hoffart et al., 2011; Rao et al., 2013; Cai et al.,
2013), which simultaneously models the type dis-
tributions of two arguments for each binary rela-
tion; iii) our experiment on ReVerb triples showed
that the top inferred schemas receive decent mean
reciprocal rank (MRR) of 0.337, with respect to
the human labeled ground truth.
</bodyText>
<sectionHeader confidence="0.967239" genericHeader="method">
2 Problem Definition
</sectionHeader>
<bodyText confidence="0.958877833333333">
A knowledge base K is a 5-tuple (E, Alist, T,
P, IsA), where:
- E is a finite set of entities e E E,
- Alist(e) = {n1, n2, ...} is a function which
returns a set of names (or aliases) of an entity,
- T is a finite set of types t E T,
- P is a finite set of relation instances p(e1, e2),
where p is a predicate in K.
- IsA is a finite set entity-type pairs (e, t),
representing the isA relation between entities
and types. An entity belongs to at least one
type.
An Open IE triple set 5 contains all relation in-
stances extracted by the IE system, of the form
(a1, rel, a2), where a1 and a2 are the arguments
of extracted relation pattern rel. The set of argu-
ment pairs sharing the same relation pattern rel is
denoted by 5rel.
The problem is, for each 5rel, return a set of
type pairs (or schemas) from T, (t1, t2), ordered
by the number of argument pairs covered in 5rel.
If two schemas cover the same number of argu-
ment pairs from 5rel, the schema covering small-
est number of entities wins.
</bodyText>
<sectionHeader confidence="0.993098" genericHeader="method">
3 System
</sectionHeader>
<bodyText confidence="0.9834134">
The workflow of our system is shown in Figure
Figure 1. The system takes Open IE relation tu-
ples as the input, then performs entity linking, re-
lation grouping and schema ranking to translate
them into final ranked list of schemas.
</bodyText>
<listItem confidence="0.9358914">
(1) Entity Linking: Relation arguments are
linked to entities in the knowledge base by fuzzy
string matching. Each entity in the knowledge
base has a unique identifier.
(2) Relation Grouping: Linked tuples shar-
ing similar relation patterns are grouped together.
Besides, each group has a representative relation
pattern, which is generated from all the patterns
within the group.
(3) Schema Ranking: For each linked tuple
</listItem>
<bodyText confidence="0.7437724">
in one relation group, argument entities are trans-
formed into types drawn from the knowledge base.
Then this procedure ranks type pairs (schemas) in
terms of how much Open IE tuples a type pair can
cover and how specific a type concept is.
</bodyText>
<subsectionHeader confidence="0.998946">
3.1 Entity Linking
</subsectionHeader>
<bodyText confidence="0.999870846153846">
In the entity linking step, by matching arguments
to entities in the knowledge base, each relation
tuple is transformed into linked tuples, ltup =
(e1, rel, e2), with linking scores.
We aim to support fuzzy matching between ar-
guments and entity aliases, so we take all the
aliases into consideration, and build an inverted in-
dex from words to aliases. Different words in one
alias cannot be treated equally. Intuitively, a word
is more important if it occurs in fewer aliases (n),
and vice versa. Based on the inverted index, we
use inverted document frequency score to approx-
imately model the weight of a word w:
</bodyText>
<equation confidence="0.988111">
idf(w) = 1 /log(j{n : w E n}j) (1)
</equation>
<bodyText confidence="0.9558068">
Besides, stop words are removed from aliases,
treating their idf scores as 0. In order to measure
the probability of fuzzy matching from an argu-
ment (a) to an alias (n), we introduce the weighted
overlap score:
</bodyText>
<equation confidence="0.994831">
idf(w)
idf(w) (2)
</equation>
<bodyText confidence="0.999753">
We merge all the aliases of an entity together
to producing a similarity score of fuzzy matching
between an entity and an argument:
</bodyText>
<equation confidence="0.585076571428571">
sim(e, a) = max
n∈Alist(e)
overlap(a,n) = E
w∈a∩n
�
w∈a∪n
overlap(a,n) (3)
</equation>
<page confidence="0.571906">
556
</page>
<figure confidence="0.999857454545454">
Open IE
Knowledge Base
entity
names
type
taxonomy
type
pairs
Relation
Schema
Schema
Ranking
relation
tuples
Entity
Linking
linked
tuples
Relation
Grouping
relation
groups
</figure>
<figureCaption confidence="0.999995">
Figure 1: System Architecture
</figureCaption>
<bodyText confidence="0.999962923076923">
In order to control the quality of candidate en-
tities, for an argument having m words (with stop
words removed), we only keep entities that have
at least one alias matching m − 1 words in the ar-
gument, and have a similarity score larger than a
threshold, τ. With similarity score computed, we
generate 10 best entity candidates respectively for
both the subject and the object of rel.
Next, we model the joint similarity score (F)
of the relation tuple (a1, rel, a2) with each entity
pair combination (e1, e2) in two ways. One is a
naive method which only considers the similarity
between arguments and corresponding entities:
</bodyText>
<equation confidence="0.998445">
F(a1, e1,a2, e2, rel) = (4)
sim(e1, a1) x sim(e2, a2).
</equation>
<bodyText confidence="0.977385473684211">
The other method takes predicate paths between
e1 and e2 into consideration. Let w~ be the word
vector of rel, and p~ be a path of predicates con-
necting e1 and e2 in at most 2 hops. Here we say
two entities e1 and e2 are connected in 1 hop, if
there exists a predicate p, such that p(e1, e2) (or
p(e2, e1)) is in the knowledge base.
Similarly, e1 and e2 are connected in 2 hops,
if there exists two predicates p1, p2 and a transi-
tion entity e′, such that p1(e1,e′) (or p1(e′,e1))
and p2(e′, e2) (or p2(e2, e′)) are in the knowledge
base.
We hence define the relatedness between p~ and
and we follow the IBM alignment Model 1 (Yao
and Van Durme, 2014) to calculate the conditional
probability between predicates and relation words
P(~p  |~w). Based on the information above, we de-
fine a richer joint similarity score, considering all
valid paths between e1 and e2:
</bodyText>
<equation confidence="0.999451">
F(a1, e1, a2,e2, rel) = sim(e1, a1)x
F- sim(e2, a2) x p� P(~p |~w). (6)
</equation>
<bodyText confidence="0.999961714285714">
Due to the multiplications, the value of P(~p |~w)
varies a lot among different entity pair candidates.
The large deviation makes P(~p |~w) the most im-
portant term in Eq. (6), especially in the case when
none of predicate paths are similar enough to the
relation words. Therefore, we trust the factor of
P(~p |~w) only when there exists a similar predicate
path. In practice, we use a threshold ρ to control
whether to use Eq. (6) or Eq. (4). We call this an
ensemble method. For each case of entity link-
ing, if there exists one candidate entity pair satis-
fying P(~p  |~w) &gt; ρ, we use the ensemble method,
otherwise we fall back to the naive method for the
current case.
</bodyText>
<subsectionHeader confidence="0.998588">
3.2 Relation Grouping
</subsectionHeader>
<bodyText confidence="0.97532080952381">
In the step of relation grouping, linked tuples with
similar relation patterns form a group. Each linked
tuple belongs to one unique group.
The idea is to simplify relation patterns by syn-
tactic transformations. If two patterns share the
same simplified pattern, we treat them as being
equivalent and put them into one group. First,
since adjectives, adverbs and modal verbs can
hardly change the type distribution of arguments
in a relation, we remove these words from a pat-
tern. Second, many relations from Open IE con-
tain verbs, which come in different tenses. We
transform all tenses into present tense. In addi-
tion, passive voice in a pattern, if any, is kept in
the transformed pattern. A simple example below
shows a group of relations:
(X, resign from, Y)
(X, had resigned from, Y)
(X, finally resigned from, Y)
w~ in the form of a conditional probability accord-
ing to the Naive Bayes model:
</bodyText>
<figure confidence="0.9646534">
fl
P(~p  |~w) ^ p P(p  |~w)
(5)
fl fl
a p P(p) . P(w  |p),
</figure>
<page confidence="0.990652">
557
</page>
<bodyText confidence="0.999977">
All linked tuples with the same simplified pat-
tern form a group. This pattern is selected as
the representative pattern, like the pattern “resign
from” in the above example.
</bodyText>
<subsectionHeader confidence="0.999095">
3.3 Schema Ranking
</subsectionHeader>
<bodyText confidence="0.999361076923077">
Given a relation group, the step of schema rank-
ing produces a ranked list of relation schemas with
two constraints. Take “play in” as an example, the
ideal schemas will contain the pair (actor, film)
and (athlete, sports league)
Each linked tuple (e1, rel, e2) supports the
type pair (t1, t2) where (e1, t1), (e2, t2) E IsA in
the knowledge base. We treat these pairs equally,
since it’s not trivial to tell which type is more re-
lated to the argument given the relation tuple as
context. Combining all tuples in one group, we de-
fine the support of a type pair tp in a group (using
the representative pattern r to stand for the group):
</bodyText>
<equation confidence="0.9998605">
supr((t1,t2)) = (7)
{(e1, t1) E IsA, (e2, t2) E IsA}
</equation>
<bodyText confidence="0.999972722222222">
A simple intuition is to rank schemas by the size
of the support. Since one entity belongs to mul-
tiple types, relation schemas with general types
will be ranked higher. However, two different
schemas may share the same support. For in-
stance, given the relation “X die in Y”, suppose
Open IE extractions and entity linking step returns
correct results, the schema (person, location)
and (deceased person, location) have identical
supports. The latter one shows a more concrete
representation of the relation, because deceased
person covers small entities than person in the
knowledge base.
Therefore, the schemas cannot be ranked by us-
ing the support alone. Next, we aim to extract the
subsumption relations between types in the knowl-
edge base, building the taxonomy of types.
We first define all entities in t as
</bodyText>
<equation confidence="0.995244">
cover(t) = {e  |(e, t) E IsA}. (8)
</equation>
<bodyText confidence="0.999917388888889">
Intuitively, type t1 is subsumed in t2, if all enti-
ties in t1 also belong to t2, that is, cover(t1) C_
cover(t2). This uses the idea of strict set inclu-
sion. For example, we can learn that the type per-
son subsumes types such as actor, politician and
deceased person.
However, strict set inclusion doesn’t always
hold in the knowledge base. For example, enti-
ties in type award winner are mostly person, but
there still has some organizations in it. The strict
method fails to find the subsumption relation be-
tween award winner and person, while this sub-
sumption actually holds with a large confidence.
To resolve this problem, we use a relaxed set
inclusion, where the set cover(t1) can be a subset
of another set cover(t2) to a certain degree. We
define the degree of the subsumption as the ratio
between the number of entities in the two sets:
</bodyText>
<equation confidence="0.9997995">
deg(t1 C_ t2) = |cover(t1) � cover(t2)|
|cover(t1) |. (9)
</equation>
<bodyText confidence="0.9974703125">
If deg(t1 C_ t2) &gt; ǫ, then t1 is subsumed by
t2, and ǫ is a confidence parameter determined by
weight tuning. By scanning all types in the knowl-
edge base, all subsumption relations with enough
confidence are extracted, forming our type taxon-
omy.
With a type hierarchy computed by above re-
laxed set inclusion, we can define a schema
(t1, t2) subsumes another schema (t3, t4) if i) t1
subsumes t3 and t2 subsumes t4; ii) t1 subsumes
t3 and t2 = t4; or iii) t2 subsumes t4 and t1 = t3.
If a schema (type pair) tp1 subsumes another
schema tp2, and their supports (|supr(tp)|) are
approximately equal, we give the more specific
schema tp2 a higher rank in the output list. Here
two supports are roughly equal if:
</bodyText>
<equation confidence="0.9968125">
|supr(tp1) |− |supr(tp2) |&lt; λ (10)
max(|supr(tp1) |,  |supr(tp2) |)
</equation>
<bodyText confidence="0.969779">
Where λ is a threshold determined in the experi-
ments.
</bodyText>
<sectionHeader confidence="0.996695" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999924083333333">
Freebase (Bollacker et al., 2008) is a collabora-
tively generated knowledge base, which contains
more than 40 million entities, and more than 1,700
real types 1. In our experiment, We use the 16 Feb.
2014 dump of Freebase as the knowledge base.
ReVerb (Fader et al., 2011) is an Open IE sys-
tem which aims to extract verb based relation in-
stances from web corpora. The release ReVerb
dataset contains more than 14 millions of relation
tuples with high quality. We observed that in Re-
Verb, some argument is unlikely to be an entity in
Freebase, for example:
</bodyText>
<footnote confidence="0.836166666666667">
(Metro Manila, consists of, 12 cities),
1Freebase types are identified by type id, for example,
sports.pro athlete stands for “professional athlete”.
</footnote>
<page confidence="0.993726">
558
</page>
<bodyText confidence="0.99820836">
where the object argument is not an entity but a
type. Since types are usually represented by low-
ercase common words, we remove the tuple if one
argument is lowercase, or if it is made up com-
pletely of common words in WordNet. In addition,
because date/time such as “Jan. 16th, 1981” often
occurs in the object argument while Freebase does
not have any such specific dates as entities, we use
SUTime (Chang and Manning, 2012) to recognize
dates as an virtual entity. After cleaning, the sys-
tem collects 3,234,208 tuples and 171,168 relation
groups.
The following parameters are tuned using a de-
velopment set: τ = 0.667, ǫ = 0.6, λ = 5% and
ρ = e−50. For relation grouping, we use Stanford
Parser (Klein and Manning, 2003) to perform POS
tagging, lemmatizing and parsing on relations.
We first evaluate the results of entity linking.
We randomly pick 200 relation instances from Re-
Verb, and manually labeled arguments with Free-
base entities. For both naive and ensemble strat-
egy, we evaluate the precision, recall, F1 and MRR
score on the labeled set. An output entity pair is
correct, if and only if both arguments are correctly
linked. Experimental results are listed in Table 1.
</bodyText>
<tableCaption confidence="0.996964">
Table 1: Entity Linking Result
</tableCaption>
<table confidence="0.959671333333333">
Strategy P R F1 MRR
Naive 0.371 0.327 0.348 0.377
Ensemble 0.386 0.340 0.361 0.381
</table>
<bodyText confidence="0.999593176470588">
For the evaluation of relation schema, we first
randomly pick 50 binary relations with support
larger than 500 from the system. For each relation,
we selected top 100 type pairs with the largest sup-
port, as what we evaluated. We assigned 3 human
annotators to label the fitness score of type pair
for the relation. The labeled score ranges from 0
to 3. Then we merge these 3 label sets, forming 50
gold standard rankings. When evaluating a rela-
tion schema list from our system, we calculate the
MRR score (Liu, 2009) by the top schemas in the
gold rankings.
For comparison, we use Pointwise Mutual In-
formation (Church and Hanks, 1990) as our base-
line model, which is used in other selectional pref-
erence tasks (Resnik, 1996). We define the associ-
ation score between relation and type pair as:
</bodyText>
<equation confidence="0.8881155">
PMI(r, tp) = p(r, tp) log p(r, tp)
p(r, ∗)p(∗, tp) (11)
</equation>
<bodyText confidence="0.991714">
Where p(r, tp) is the joint probability of relation
and type pair in the whole linked tuple set, and ∗
stands for any relations or type pairs.
Table 2 shows the MRR scores by using both
baseline model (PMI) and our approach. As the re-
sult shows, our approach improves the MRR score
by 10.1%.
</bodyText>
<tableCaption confidence="0.983883">
Table 2: End-to-end Schema Inference Results
</tableCaption>
<table confidence="0.996897333333333">
Approach MRR Score
PMI Baseline 0.306
Our Approach 0.337
</table>
<bodyText confidence="0.999310833333333">
Finally, Table 3 shows some example binary re-
lations, and their schemas inferred by our system.
We can see that with a well-defined type hierarchy,
our system is able to extract both coarse-grained
and fine-grained type information from entities,
resulting in a informative type lists.
</bodyText>
<tableCaption confidence="0.992266">
Table 3: Sample Relation Schemas
</tableCaption>
<table confidence="0.9261976">
Relation Top Schemas
be find at (location, location)
(employer, location)
(organization, location)
appear on (person, tv program)
(person, nominated work)
(person, winning work)
be the writer of (person, nominated work)
(person, film)
(person, book subject)
</table>
<sectionHeader confidence="0.997981" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999621">
In summary, our work describes a data driven ap-
proach of relation schema inference. By max-
imizing the support of both arguments simulta-
neously, our system is able to generate human-
readable type pairs for a binary relation from Open
IE systems. Our experiments shows that the top
ranked relation schemas for each relation are ac-
curate according to human judges. The proposed
framework can be integrated with future Open IE
systems.
</bodyText>
<sectionHeader confidence="0.995366" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<copyright confidence="0.928117">
Kenny Q. Zhu is the contact author and was sup-
ported by NSFC grant 61373031 and NSFC-NRF
Joint Research Program No. 61411140247.
</copyright>
<sectionHeader confidence="0.997323" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.59928">
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a col-
laboratively created graph database for structuring
</reference>
<page confidence="0.995135">
559
</page>
<reference confidence="0.999627394736842">
human knowledge. In ACM SIGMOD, pages 1247–
1250. ACM.
Zhiyuan Cai, Kaiqi Zhao, Kenny Q. Zhu, and Haixun
Wang. 2013. Wikification via link co-occurrence.
In ACM CIKM’13, pages 1087–1096.
Andrew Carlson, Justin Betteridge, Bryan Kisiel,
Burr Settles, Estevam R Hruschka Jr, and Tom M
Mitchell. 2010. Toward an architecture for never-
ending language learning. In AAAI, volume 5,
page 3.
Angel X Chang and Christopher D Manning. 2012.
Sutime: A library for recognizing and normalizing
time expressions. In LREC, pages 3735–3740.
Kenneth Ward Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicog-
raphy. Computational linguistics, 16(1):22–29.
Katrin Erk. 2007. A simple, similarity-based
model for selectional preferences. In AI-
IUAL MEETIIG-ASSOCIATIOI FOR COMPU-
TATIOIAL LIIGUISTICS, page 216.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In EMILP, pages 1535–1545.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-
dino, Hagen F¨urstenau, Manfred Pinkal, Marc Span-
iol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum. 2011. Robust disambiguation of named
entities in text. In Proceedings of EMILP, pages
782–792.
Dan Klein and Christopher D Manning. 2003. Accu-
rate unlexicalized parsing. In ACL, pages 423–430.
Thomas Lin, Oren Etzioni, et al. 2012. Entity link-
ing at web scale. In Proceedings of the Joint Work-
shop on Automatic Knowledge Base Construction
and Web-scale Knowledge Extraction, pages 84–88.
Tie-Yan Liu. 2009. Learning to rank for information
retrieval. Foundations and Trends in Information
Retrieval, 3(3):225–331.
George A Miller. 1995. Wordnet: a lexical
database for english. Communications of the ACM,
38(11):39–41.
Ndapandula Nakashole, Gerhard Weikum, and Fabian
Suchanek. 2012. Patty: a taxonomy of relational
patterns with semantic types. In EMILP, pages
1135–1145.
Delip Rao, Paul McNamee, and Mark Dredze. 2013.
Entity linking: Finding extracted entities in a knowl-
edge base. In Multi-source, multilingual informa-
tion extraction and summarization, pages 93–115.
Springer.
Lev Ratinov, Dan Roth, Doug Downey, and Mike An-
derson. 2011. Local and global algorithms for
disambiguation to wikipedia. In Proceedings of
ACL:HLT, pages 1375–1384.
Philip Resnik. 1996. Selectional constraints: An
information-theoretic model and its computational
realization. Cognition, 61(1):127–159.
Alan Ritter, Oren Etzioni, et al. 2010. A latent dirich-
let allocation method for selectional preferences. In
ACL, pages 424–434.
Michael Schmitz, Robert Bart, Stephen Soderland,
Oren Etzioni, et al. 2012. Open language learning
for information extraction. In EMILP, pages 523–
534.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. 2007. Yago: A Core of Semantic Knowl-
edge. In 16th international World Wide Web con-
ference (WWW 2007), New York, NY, USA. ACM
Press.
Wentao Wu, Hongsong Li, Haixun Wang, and
Kenny Q. Zhu. 2012. Probase: a probabilistic tax-
onomy for text understanding. In SIGMOD Confer-
ence, pages 481–492.
Xuchen Yao and Benjamin Van Durme. 2014. Infor-
mation extraction over structured data: Question an-
swering with freebase. In Proceedings ofACL.
</reference>
<page confidence="0.997024">
560
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.354491">
<title confidence="0.992582">Inferring Binary Relation Schemas for Open Information Extraction</title>
<author confidence="0.612211">Q</author>
<affiliation confidence="0.985358">Department of Computer Science &amp;</affiliation>
<address confidence="0.729294">Shanghai Jiao Tong University, Shanghai, China</address>
<email confidence="0.803081">6174@sjtu.edu.cn</email>
<abstract confidence="0.9966216">This paper presents a framework to model the semantic representation of binary relations produced by open information extraction systems. For each binary relation, we infer a set of preferred types on the two arguments simultaneously, and generate a ranked list of type pairs which we call schemas. All inferred types are drawn from the Freebase type taxonomy, which are human readable. Our system collects 171,168 binary relations from Re- Verb, and is able to produce top-ranking relation schemas with a mean reciprocal rank of 0.337.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: a collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In ACM SIGMOD,</booktitle>
<pages>1247--1250</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2229" citStr="Bollacker et al., 2008" startWordPosition="353" endWordPosition="356">ntic representations. In this paper, we focus on inferring the schemas of binary relations. For example, given the binary relation “play in”, an Open IE system extracts many triples of the form (X, play in, Y ). The following relation triples are extracted in ReVerb: (Goel Grey, played in, Cabaret) (Tom Brady, play in, National Football League) Informally, the goal of our system is to automatically infer a set of schemas such as (t1, play in, t2), where t1 and t2 are two semantic types drawn from a standard knowledge base such as WordNet (Miller, 1995), Yago (Suchanek et al., 2007), Freebase (Bollacker et al., 2008), and Probase (Wu et al., 2012), and each such schema can be used to represent a set of “play in” relation instances. For the above example, two possible schemas for “play in” are: (film actor, play in, film) (athlete, play in, sports league) The schema of a binary relation is useful information in NLP tasks, such as context-oriented entity recognition and open domain question answering. Suppose we are to recognize the entities in the sentence “Granger played in the IBA”. “Granger” is a highly ambiguous term, while “the IBA” is probably a sports league. Then with the the above relation schemas</context>
<context position="14949" citStr="Bollacker et al., 2008" startWordPosition="2602" endWordPosition="2605"> type hierarchy computed by above relaxed set inclusion, we can define a schema (t1, t2) subsumes another schema (t3, t4) if i) t1 subsumes t3 and t2 subsumes t4; ii) t1 subsumes t3 and t2 = t4; or iii) t2 subsumes t4 and t1 = t3. If a schema (type pair) tp1 subsumes another schema tp2, and their supports (|supr(tp)|) are approximately equal, we give the more specific schema tp2 a higher rank in the output list. Here two supports are roughly equal if: |supr(tp1) |− |supr(tp2) |&lt; λ (10) max(|supr(tp1) |, |supr(tp2) |) Where λ is a threshold determined in the experiments. 4 Evaluation Freebase (Bollacker et al., 2008) is a collaboratively generated knowledge base, which contains more than 40 million entities, and more than 1,700 real types 1. In our experiment, We use the 16 Feb. 2014 dump of Freebase as the knowledge base. ReVerb (Fader et al., 2011) is an Open IE system which aims to extract verb based relation instances from web corpora. The release ReVerb dataset contains more than 14 millions of relation tuples with high quality. We observed that in ReVerb, some argument is unlikely to be an entity in Freebase, for example: (Metro Manila, consists of, 12 cities), 1Freebase types are identified by type</context>
</contexts>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In ACM SIGMOD, pages 1247– 1250. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Cai</author>
<author>Kaiqi Zhao</author>
<author>Kenny Q Zhu</author>
<author>Haixun Wang</author>
</authors>
<title>Wikification via link co-occurrence.</title>
<date>2013</date>
<booktitle>In ACM CIKM’13,</booktitle>
<pages>1087--1096</pages>
<contexts>
<context position="4679" citStr="Cai et al., 2013" startWordPosition="770" endWordPosition="773">elation instances to a set of possible entities in a knowledge base, hence generate a set of (e1, e2) entity pairs. Then we select a pair of types (t1, t2) that covers maximum number of entity pairs. We resolve ties by selecting the smaller (more specific) types according to a type taxonomy inferred from knowledge base. This paper makes the following contributions: i) we defined the schema inference problem for binary relations from Open IE; ii) we developed a prototype system based on Freebase and entity linking (Lin et al., 2012; Ratinov et al., 2011; Hoffart et al., 2011; Rao et al., 2013; Cai et al., 2013), which simultaneously models the type distributions of two arguments for each binary relation; iii) our experiment on ReVerb triples showed that the top inferred schemas receive decent mean reciprocal rank (MRR) of 0.337, with respect to the human labeled ground truth. 2 Problem Definition A knowledge base K is a 5-tuple (E, Alist, T, P, IsA), where: - E is a finite set of entities e E E, - Alist(e) = {n1, n2, ...} is a function which returns a set of names (or aliases) of an entity, - T is a finite set of types t E T, - P is a finite set of relation instances p(e1, e2), where p is a predicat</context>
</contexts>
<marker>Cai, Zhao, Zhu, Wang, 2013</marker>
<rawString>Zhiyuan Cai, Kaiqi Zhao, Kenny Q. Zhu, and Haixun Wang. 2013. Wikification via link co-occurrence. In ACM CIKM’13, pages 1087–1096.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Bryan Kisiel</author>
<author>Burr Settles</author>
<author>Estevam R Hruschka Jr</author>
<author>Tom M Mitchell</author>
</authors>
<title>Toward an architecture for neverending language learning.</title>
<date>2010</date>
<booktitle>In AAAI,</booktitle>
<volume>5</volume>
<pages>3</pages>
<contexts>
<context position="1105" citStr="Carlson et al., 2010" startWordPosition="163" endWordPosition="166"> the two arguments simultaneously, and generate a ranked list of type pairs which we call schemas. All inferred types are drawn from the Freebase type taxonomy, which are human readable. Our system collects 171,168 binary relations from ReVerb, and is able to produce top-ranking relation schemas with a mean reciprocal rank of 0.337. 1 Introduction Open information extraction (or Open IE) is a task of extracting all sorts of relations between named entities or concepts from open-domain text corpora, without restraining itself to specific relations or patterns. State-of-the-art Open IE systems (Carlson et al., 2010; Fader et al., 2011; Schmitz et al., 2012; Nakashole et al., 2012) extract millions of binary relations with high precision from the web corpus. Each extracted relation instance is a triple of the form (arg1, rel, arg2), where the relation rel is a lexical or syntactic pattern, and both arguments are multi-word expressions representing the argument entities or concepts. Whereas Open IE provides concrete relation instances, we are interested in generalizing these instances into more abstract semantic representations. In this paper, we focus on inferring the schemas of binary relations. For exa</context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Jr, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R Hruschka Jr, and Tom M Mitchell. 2010. Toward an architecture for neverending language learning. In AAAI, volume 5, page 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angel X Chang</author>
<author>Christopher D Manning</author>
</authors>
<title>Sutime: A library for recognizing and normalizing time expressions.</title>
<date>2012</date>
<booktitle>In LREC,</booktitle>
<pages>3735--3740</pages>
<contexts>
<context position="16050" citStr="Chang and Manning, 2012" startWordPosition="2793" endWordPosition="2796">ly to be an entity in Freebase, for example: (Metro Manila, consists of, 12 cities), 1Freebase types are identified by type id, for example, sports.pro athlete stands for “professional athlete”. 558 where the object argument is not an entity but a type. Since types are usually represented by lowercase common words, we remove the tuple if one argument is lowercase, or if it is made up completely of common words in WordNet. In addition, because date/time such as “Jan. 16th, 1981” often occurs in the object argument while Freebase does not have any such specific dates as entities, we use SUTime (Chang and Manning, 2012) to recognize dates as an virtual entity. After cleaning, the system collects 3,234,208 tuples and 171,168 relation groups. The following parameters are tuned using a development set: τ = 0.667, ǫ = 0.6, λ = 5% and ρ = e−50. For relation grouping, we use Stanford Parser (Klein and Manning, 2003) to perform POS tagging, lemmatizing and parsing on relations. We first evaluate the results of entity linking. We randomly pick 200 relation instances from ReVerb, and manually labeled arguments with Freebase entities. For both naive and ensemble strategy, we evaluate the precision, recall, F1 and MRR </context>
</contexts>
<marker>Chang, Manning, 2012</marker>
<rawString>Angel X Chang and Christopher D Manning. 2012. Sutime: A library for recognizing and normalizing time expressions. In LREC, pages 3735–3740.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Ward Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<booktitle>Computational linguistics,</booktitle>
<pages>16--1</pages>
<contexts>
<context position="17554" citStr="Church and Hanks, 1990" startWordPosition="3054" endWordPosition="3057">luation of relation schema, we first randomly pick 50 binary relations with support larger than 500 from the system. For each relation, we selected top 100 type pairs with the largest support, as what we evaluated. We assigned 3 human annotators to label the fitness score of type pair for the relation. The labeled score ranges from 0 to 3. Then we merge these 3 label sets, forming 50 gold standard rankings. When evaluating a relation schema list from our system, we calculate the MRR score (Liu, 2009) by the top schemas in the gold rankings. For comparison, we use Pointwise Mutual Information (Church and Hanks, 1990) as our baseline model, which is used in other selectional preference tasks (Resnik, 1996). We define the association score between relation and type pair as: PMI(r, tp) = p(r, tp) log p(r, tp) p(r, ∗)p(∗, tp) (11) Where p(r, tp) is the joint probability of relation and type pair in the whole linked tuple set, and ∗ stands for any relations or type pairs. Table 2 shows the MRR scores by using both baseline model (PMI) and our approach. As the result shows, our approach improves the MRR score by 10.1%. Table 2: End-to-end Schema Inference Results Approach MRR Score PMI Baseline 0.306 Our Approa</context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth Ward Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational linguistics, 16(1):22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Erk</author>
</authors>
<title>A simple, similarity-based model for selectional preferences.</title>
<date>2007</date>
<booktitle>In AIIUAL MEETIIG-ASSOCIATIOI FOR COMPUTATIOIAL LIIGUISTICS,</booktitle>
<pages>216</pages>
<contexts>
<context position="3160" citStr="Erk, 2007" startWordPosition="515" endWordPosition="516">text-oriented entity recognition and open domain question answering. Suppose we are to recognize the entities in the sentence “Granger played in the IBA”. “Granger” is a highly ambiguous term, while “the IBA” is probably a sports league. Then with the the above relation schemas for “play in”, the entity recognizer knows that “Granger” is more likely to be an athlete, which results in the correct linking to “Danny Granger”, who is an NBA player, even though the Open IE has never extracted such fact before. One relevant technique to achieve our goal is selectional preference (SP) (Resnik, 1996; Erk, 2007; Ritter et al., 2010), which computes the most appropriate types for a specific argument of a predicate. SP is based on the idea of mutual information (Erk, 2007), which tends to select types which are unique to the relation. In other words, common types which can be used for many different relations are less preferred. However, in Open IE, many relations are related or even similar, e.g., play in, take part in and be involved in. There’s no reason for these relations not to share schemas. Therefore in this paper, our problem is, given a re555 Proceedings of the 2015 Conference on Empirical M</context>
</contexts>
<marker>Erk, 2007</marker>
<rawString>Katrin Erk. 2007. A simple, similarity-based model for selectional preferences. In AIIUAL MEETIIG-ASSOCIATIOI FOR COMPUTATIOIAL LIIGUISTICS, page 216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In EMILP,</booktitle>
<pages>1535--1545</pages>
<contexts>
<context position="1125" citStr="Fader et al., 2011" startWordPosition="167" endWordPosition="170">ultaneously, and generate a ranked list of type pairs which we call schemas. All inferred types are drawn from the Freebase type taxonomy, which are human readable. Our system collects 171,168 binary relations from ReVerb, and is able to produce top-ranking relation schemas with a mean reciprocal rank of 0.337. 1 Introduction Open information extraction (or Open IE) is a task of extracting all sorts of relations between named entities or concepts from open-domain text corpora, without restraining itself to specific relations or patterns. State-of-the-art Open IE systems (Carlson et al., 2010; Fader et al., 2011; Schmitz et al., 2012; Nakashole et al., 2012) extract millions of binary relations with high precision from the web corpus. Each extracted relation instance is a triple of the form (arg1, rel, arg2), where the relation rel is a lexical or syntactic pattern, and both arguments are multi-word expressions representing the argument entities or concepts. Whereas Open IE provides concrete relation instances, we are interested in generalizing these instances into more abstract semantic representations. In this paper, we focus on inferring the schemas of binary relations. For example, given the bina</context>
<context position="15187" citStr="Fader et al., 2011" startWordPosition="2644" endWordPosition="2647"> (type pair) tp1 subsumes another schema tp2, and their supports (|supr(tp)|) are approximately equal, we give the more specific schema tp2 a higher rank in the output list. Here two supports are roughly equal if: |supr(tp1) |− |supr(tp2) |&lt; λ (10) max(|supr(tp1) |, |supr(tp2) |) Where λ is a threshold determined in the experiments. 4 Evaluation Freebase (Bollacker et al., 2008) is a collaboratively generated knowledge base, which contains more than 40 million entities, and more than 1,700 real types 1. In our experiment, We use the 16 Feb. 2014 dump of Freebase as the knowledge base. ReVerb (Fader et al., 2011) is an Open IE system which aims to extract verb based relation instances from web corpora. The release ReVerb dataset contains more than 14 millions of relation tuples with high quality. We observed that in ReVerb, some argument is unlikely to be an entity in Freebase, for example: (Metro Manila, consists of, 12 cities), 1Freebase types are identified by type id, for example, sports.pro athlete stands for “professional athlete”. 558 where the object argument is not an entity but a type. Since types are usually represented by lowercase common words, we remove the tuple if one argument is lower</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In EMILP, pages 1535–1545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed Amir Yosef</author>
<author>Ilaria Bordino</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
<author>Marc Spaniol</author>
<author>Bilyana Taneva</author>
<author>Stefan Thater</author>
<author>Gerhard Weikum</author>
</authors>
<title>Robust disambiguation of named entities in text.</title>
<date>2011</date>
<booktitle>In Proceedings of EMILP,</booktitle>
<pages>782--792</pages>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. 2011. Robust disambiguation of named entities in text. In Proceedings of EMILP, pages 782–792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In ACL,</booktitle>
<pages>423--430</pages>
<contexts>
<context position="16346" citStr="Klein and Manning, 2003" startWordPosition="2846" endWordPosition="2849">ercase common words, we remove the tuple if one argument is lowercase, or if it is made up completely of common words in WordNet. In addition, because date/time such as “Jan. 16th, 1981” often occurs in the object argument while Freebase does not have any such specific dates as entities, we use SUTime (Chang and Manning, 2012) to recognize dates as an virtual entity. After cleaning, the system collects 3,234,208 tuples and 171,168 relation groups. The following parameters are tuned using a development set: τ = 0.667, ǫ = 0.6, λ = 5% and ρ = e−50. For relation grouping, we use Stanford Parser (Klein and Manning, 2003) to perform POS tagging, lemmatizing and parsing on relations. We first evaluate the results of entity linking. We randomly pick 200 relation instances from ReVerb, and manually labeled arguments with Freebase entities. For both naive and ensemble strategy, we evaluate the precision, recall, F1 and MRR score on the labeled set. An output entity pair is correct, if and only if both arguments are correctly linked. Experimental results are listed in Table 1. Table 1: Entity Linking Result Strategy P R F1 MRR Naive 0.371 0.327 0.348 0.377 Ensemble 0.386 0.340 0.361 0.381 For the evaluation of rela</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D Manning. 2003. Accurate unlexicalized parsing. In ACL, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lin</author>
<author>Oren Etzioni</author>
</authors>
<title>Entity linking at web scale.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction,</booktitle>
<pages>84--88</pages>
<marker>Lin, Etzioni, 2012</marker>
<rawString>Thomas Lin, Oren Etzioni, et al. 2012. Entity linking at web scale. In Proceedings of the Joint Workshop on Automatic Knowledge Base Construction and Web-scale Knowledge Extraction, pages 84–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tie-Yan Liu</author>
</authors>
<title>Learning to rank for information retrieval.</title>
<date>2009</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<volume>3</volume>
<issue>3</issue>
<contexts>
<context position="17436" citStr="Liu, 2009" startWordPosition="3036" endWordPosition="3037">ing Result Strategy P R F1 MRR Naive 0.371 0.327 0.348 0.377 Ensemble 0.386 0.340 0.361 0.381 For the evaluation of relation schema, we first randomly pick 50 binary relations with support larger than 500 from the system. For each relation, we selected top 100 type pairs with the largest support, as what we evaluated. We assigned 3 human annotators to label the fitness score of type pair for the relation. The labeled score ranges from 0 to 3. Then we merge these 3 label sets, forming 50 gold standard rankings. When evaluating a relation schema list from our system, we calculate the MRR score (Liu, 2009) by the top schemas in the gold rankings. For comparison, we use Pointwise Mutual Information (Church and Hanks, 1990) as our baseline model, which is used in other selectional preference tasks (Resnik, 1996). We define the association score between relation and type pair as: PMI(r, tp) = p(r, tp) log p(r, tp) p(r, ∗)p(∗, tp) (11) Where p(r, tp) is the joint probability of relation and type pair in the whole linked tuple set, and ∗ stands for any relations or type pairs. Table 2 shows the MRR scores by using both baseline model (PMI) and our approach. As the result shows, our approach improves</context>
</contexts>
<marker>Liu, 2009</marker>
<rawString>Tie-Yan Liu. 2009. Learning to rank for information retrieval. Foundations and Trends in Information Retrieval, 3(3):225–331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: a lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="2164" citStr="Miller, 1995" startWordPosition="345" endWordPosition="346">in generalizing these instances into more abstract semantic representations. In this paper, we focus on inferring the schemas of binary relations. For example, given the binary relation “play in”, an Open IE system extracts many triples of the form (X, play in, Y ). The following relation triples are extracted in ReVerb: (Goel Grey, played in, Cabaret) (Tom Brady, play in, National Football League) Informally, the goal of our system is to automatically infer a set of schemas such as (t1, play in, t2), where t1 and t2 are two semantic types drawn from a standard knowledge base such as WordNet (Miller, 1995), Yago (Suchanek et al., 2007), Freebase (Bollacker et al., 2008), and Probase (Wu et al., 2012), and each such schema can be used to represent a set of “play in” relation instances. For the above example, two possible schemas for “play in” are: (film actor, play in, film) (athlete, play in, sports league) The schema of a binary relation is useful information in NLP tasks, such as context-oriented entity recognition and open domain question answering. Suppose we are to recognize the entities in the sentence “Granger played in the IBA”. “Granger” is a highly ambiguous term, while “the IBA” is p</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ndapandula Nakashole</author>
<author>Gerhard Weikum</author>
<author>Fabian Suchanek</author>
</authors>
<title>Patty: a taxonomy of relational patterns with semantic types.</title>
<date>2012</date>
<booktitle>In EMILP,</booktitle>
<pages>1135--1145</pages>
<contexts>
<context position="1172" citStr="Nakashole et al., 2012" startWordPosition="175" endWordPosition="178"> type pairs which we call schemas. All inferred types are drawn from the Freebase type taxonomy, which are human readable. Our system collects 171,168 binary relations from ReVerb, and is able to produce top-ranking relation schemas with a mean reciprocal rank of 0.337. 1 Introduction Open information extraction (or Open IE) is a task of extracting all sorts of relations between named entities or concepts from open-domain text corpora, without restraining itself to specific relations or patterns. State-of-the-art Open IE systems (Carlson et al., 2010; Fader et al., 2011; Schmitz et al., 2012; Nakashole et al., 2012) extract millions of binary relations with high precision from the web corpus. Each extracted relation instance is a triple of the form (arg1, rel, arg2), where the relation rel is a lexical or syntactic pattern, and both arguments are multi-word expressions representing the argument entities or concepts. Whereas Open IE provides concrete relation instances, we are interested in generalizing these instances into more abstract semantic representations. In this paper, we focus on inferring the schemas of binary relations. For example, given the binary relation “play in”, an Open IE system extrac</context>
</contexts>
<marker>Nakashole, Weikum, Suchanek, 2012</marker>
<rawString>Ndapandula Nakashole, Gerhard Weikum, and Fabian Suchanek. 2012. Patty: a taxonomy of relational patterns with semantic types. In EMILP, pages 1135–1145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Paul McNamee</author>
<author>Mark Dredze</author>
</authors>
<title>Entity linking: Finding extracted entities in a knowledge base. In Multi-source, multilingual information extraction and summarization,</title>
<date>2013</date>
<pages>93--115</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="4660" citStr="Rao et al., 2013" startWordPosition="766" endWordPosition="769">arguments in the relation instances to a set of possible entities in a knowledge base, hence generate a set of (e1, e2) entity pairs. Then we select a pair of types (t1, t2) that covers maximum number of entity pairs. We resolve ties by selecting the smaller (more specific) types according to a type taxonomy inferred from knowledge base. This paper makes the following contributions: i) we defined the schema inference problem for binary relations from Open IE; ii) we developed a prototype system based on Freebase and entity linking (Lin et al., 2012; Ratinov et al., 2011; Hoffart et al., 2011; Rao et al., 2013; Cai et al., 2013), which simultaneously models the type distributions of two arguments for each binary relation; iii) our experiment on ReVerb triples showed that the top inferred schemas receive decent mean reciprocal rank (MRR) of 0.337, with respect to the human labeled ground truth. 2 Problem Definition A knowledge base K is a 5-tuple (E, Alist, T, P, IsA), where: - E is a finite set of entities e E E, - Alist(e) = {n1, n2, ...} is a function which returns a set of names (or aliases) of an entity, - T is a finite set of types t E T, - P is a finite set of relation instances p(e1, e2), wh</context>
</contexts>
<marker>Rao, McNamee, Dredze, 2013</marker>
<rawString>Delip Rao, Paul McNamee, and Mark Dredze. 2013. Entity linking: Finding extracted entities in a knowledge base. In Multi-source, multilingual information extraction and summarization, pages 93–115. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL:HLT,</booktitle>
<pages>1375--1384</pages>
<contexts>
<context position="4620" citStr="Ratinov et al., 2011" startWordPosition="758" endWordPosition="761">le. Our approach first attempts to link the arguments in the relation instances to a set of possible entities in a knowledge base, hence generate a set of (e1, e2) entity pairs. Then we select a pair of types (t1, t2) that covers maximum number of entity pairs. We resolve ties by selecting the smaller (more specific) types according to a type taxonomy inferred from knowledge base. This paper makes the following contributions: i) we defined the schema inference problem for binary relations from Open IE; ii) we developed a prototype system based on Freebase and entity linking (Lin et al., 2012; Ratinov et al., 2011; Hoffart et al., 2011; Rao et al., 2013; Cai et al., 2013), which simultaneously models the type distributions of two arguments for each binary relation; iii) our experiment on ReVerb triples showed that the top inferred schemas receive decent mean reciprocal rank (MRR) of 0.337, with respect to the human labeled ground truth. 2 Problem Definition A knowledge base K is a 5-tuple (E, Alist, T, P, IsA), where: - E is a finite set of entities e E E, - Alist(e) = {n1, n2, ...} is a function which returns a set of names (or aliases) of an entity, - T is a finite set of types t E T, - P is a finite</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In Proceedings of ACL:HLT, pages 1375–1384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selectional constraints: An information-theoretic model and its computational realization.</title>
<date>1996</date>
<journal>Cognition,</journal>
<volume>61</volume>
<issue>1</issue>
<contexts>
<context position="3149" citStr="Resnik, 1996" startWordPosition="513" endWordPosition="514">s, such as context-oriented entity recognition and open domain question answering. Suppose we are to recognize the entities in the sentence “Granger played in the IBA”. “Granger” is a highly ambiguous term, while “the IBA” is probably a sports league. Then with the the above relation schemas for “play in”, the entity recognizer knows that “Granger” is more likely to be an athlete, which results in the correct linking to “Danny Granger”, who is an NBA player, even though the Open IE has never extracted such fact before. One relevant technique to achieve our goal is selectional preference (SP) (Resnik, 1996; Erk, 2007; Ritter et al., 2010), which computes the most appropriate types for a specific argument of a predicate. SP is based on the idea of mutual information (Erk, 2007), which tends to select types which are unique to the relation. In other words, common types which can be used for many different relations are less preferred. However, in Open IE, many relations are related or even similar, e.g., play in, take part in and be involved in. There’s no reason for these relations not to share schemas. Therefore in this paper, our problem is, given a re555 Proceedings of the 2015 Conference on </context>
<context position="17644" citStr="Resnik, 1996" startWordPosition="3072" endWordPosition="3073">from the system. For each relation, we selected top 100 type pairs with the largest support, as what we evaluated. We assigned 3 human annotators to label the fitness score of type pair for the relation. The labeled score ranges from 0 to 3. Then we merge these 3 label sets, forming 50 gold standard rankings. When evaluating a relation schema list from our system, we calculate the MRR score (Liu, 2009) by the top schemas in the gold rankings. For comparison, we use Pointwise Mutual Information (Church and Hanks, 1990) as our baseline model, which is used in other selectional preference tasks (Resnik, 1996). We define the association score between relation and type pair as: PMI(r, tp) = p(r, tp) log p(r, tp) p(r, ∗)p(∗, tp) (11) Where p(r, tp) is the joint probability of relation and type pair in the whole linked tuple set, and ∗ stands for any relations or type pairs. Table 2 shows the MRR scores by using both baseline model (PMI) and our approach. As the result shows, our approach improves the MRR score by 10.1%. Table 2: End-to-end Schema Inference Results Approach MRR Score PMI Baseline 0.306 Our Approach 0.337 Finally, Table 3 shows some example binary relations, and their schemas inferred </context>
</contexts>
<marker>Resnik, 1996</marker>
<rawString>Philip Resnik. 1996. Selectional constraints: An information-theoretic model and its computational realization. Cognition, 61(1):127–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Oren Etzioni</author>
</authors>
<title>A latent dirichlet allocation method for selectional preferences. In</title>
<date>2010</date>
<booktitle>ACL,</booktitle>
<pages>424--434</pages>
<marker>Ritter, Etzioni, 2010</marker>
<rawString>Alan Ritter, Oren Etzioni, et al. 2010. A latent dirichlet allocation method for selectional preferences. In ACL, pages 424–434.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Schmitz</author>
<author>Robert Bart</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Open language learning for information extraction.</title>
<date>2012</date>
<booktitle>In EMILP,</booktitle>
<pages>523--534</pages>
<contexts>
<context position="1147" citStr="Schmitz et al., 2012" startWordPosition="171" endWordPosition="174">erate a ranked list of type pairs which we call schemas. All inferred types are drawn from the Freebase type taxonomy, which are human readable. Our system collects 171,168 binary relations from ReVerb, and is able to produce top-ranking relation schemas with a mean reciprocal rank of 0.337. 1 Introduction Open information extraction (or Open IE) is a task of extracting all sorts of relations between named entities or concepts from open-domain text corpora, without restraining itself to specific relations or patterns. State-of-the-art Open IE systems (Carlson et al., 2010; Fader et al., 2011; Schmitz et al., 2012; Nakashole et al., 2012) extract millions of binary relations with high precision from the web corpus. Each extracted relation instance is a triple of the form (arg1, rel, arg2), where the relation rel is a lexical or syntactic pattern, and both arguments are multi-word expressions representing the argument entities or concepts. Whereas Open IE provides concrete relation instances, we are interested in generalizing these instances into more abstract semantic representations. In this paper, we focus on inferring the schemas of binary relations. For example, given the binary relation “play in”,</context>
</contexts>
<marker>Schmitz, Bart, Soderland, Etzioni, 2012</marker>
<rawString>Michael Schmitz, Robert Bart, Stephen Soderland, Oren Etzioni, et al. 2012. Open language learning for information extraction. In EMILP, pages 523– 534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>Yago: A Core of Semantic Knowledge.</title>
<date>2007</date>
<booktitle>In 16th international World Wide Web conference (WWW</booktitle>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2194" citStr="Suchanek et al., 2007" startWordPosition="348" endWordPosition="351"> instances into more abstract semantic representations. In this paper, we focus on inferring the schemas of binary relations. For example, given the binary relation “play in”, an Open IE system extracts many triples of the form (X, play in, Y ). The following relation triples are extracted in ReVerb: (Goel Grey, played in, Cabaret) (Tom Brady, play in, National Football League) Informally, the goal of our system is to automatically infer a set of schemas such as (t1, play in, t2), where t1 and t2 are two semantic types drawn from a standard knowledge base such as WordNet (Miller, 1995), Yago (Suchanek et al., 2007), Freebase (Bollacker et al., 2008), and Probase (Wu et al., 2012), and each such schema can be used to represent a set of “play in” relation instances. For the above example, two possible schemas for “play in” are: (film actor, play in, film) (athlete, play in, sports league) The schema of a binary relation is useful information in NLP tasks, such as context-oriented entity recognition and open domain question answering. Suppose we are to recognize the entities in the sentence “Granger played in the IBA”. “Granger” is a highly ambiguous term, while “the IBA” is probably a sports league. Then </context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. 2007. Yago: A Core of Semantic Knowledge. In 16th international World Wide Web conference (WWW 2007), New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wentao Wu</author>
<author>Hongsong Li</author>
<author>Haixun Wang</author>
<author>Kenny Q Zhu</author>
</authors>
<title>Probase: a probabilistic taxonomy for text understanding.</title>
<date>2012</date>
<booktitle>In SIGMOD Conference,</booktitle>
<pages>481--492</pages>
<contexts>
<context position="2260" citStr="Wu et al., 2012" startWordPosition="359" endWordPosition="362">e focus on inferring the schemas of binary relations. For example, given the binary relation “play in”, an Open IE system extracts many triples of the form (X, play in, Y ). The following relation triples are extracted in ReVerb: (Goel Grey, played in, Cabaret) (Tom Brady, play in, National Football League) Informally, the goal of our system is to automatically infer a set of schemas such as (t1, play in, t2), where t1 and t2 are two semantic types drawn from a standard knowledge base such as WordNet (Miller, 1995), Yago (Suchanek et al., 2007), Freebase (Bollacker et al., 2008), and Probase (Wu et al., 2012), and each such schema can be used to represent a set of “play in” relation instances. For the above example, two possible schemas for “play in” are: (film actor, play in, film) (athlete, play in, sports league) The schema of a binary relation is useful information in NLP tasks, such as context-oriented entity recognition and open domain question answering. Suppose we are to recognize the entities in the sentence “Granger played in the IBA”. “Granger” is a highly ambiguous term, while “the IBA” is probably a sports league. Then with the the above relation schemas for “play in”, the entity reco</context>
</contexts>
<marker>Wu, Li, Wang, Zhu, 2012</marker>
<rawString>Wentao Wu, Hongsong Li, Haixun Wang, and Kenny Q. Zhu. 2012. Probase: a probabilistic taxonomy for text understanding. In SIGMOD Conference, pages 481–492.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuchen Yao</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Information extraction over structured data: Question answering with freebase.</title>
<date>2014</date>
<booktitle>In Proceedings ofACL.</booktitle>
<marker>Yao, Van Durme, 2014</marker>
<rawString>Xuchen Yao and Benjamin Van Durme. 2014. Information extraction over structured data: Question answering with freebase. In Proceedings ofACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>