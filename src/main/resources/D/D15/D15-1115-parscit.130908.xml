<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000089">
<title confidence="0.995868">
Semantic Framework for Comparison Structures in Natural Language
</title>
<author confidence="0.995184">
Omid Bakhshandeh James F. Allen
</author>
<affiliation confidence="0.9253975">
University of Rochester University of Rochester
omidb@cs.rochester.edu Institute for Human and Machine Cognition
</affiliation>
<email confidence="0.995531">
james@cs.rochester.edu
</email>
<sectionHeader confidence="0.993805" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999812473684211">
Comparison is one of the most impor-
tant phenomena in language for express-
ing objective and subjective facts about
various entities. Systems that can under-
stand and reason over comparative struc-
ture can play a major role in the applica-
tions which require deeper understanding
of language. In this paper we present a
novel semantic framework for represent-
ing the meaning of comparative structures
in natural language, which models com-
parisons as predicate-argument pairs inter-
connected with semantic roles. Our frame-
work supports not only adjectival, but also
adverbial, nominal, and verbal compara-
tives. With this paper, we provide a novel
dataset of gold-standard comparison struc-
tures annotated according to our semantic
framework.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994359375">
Representing the meaning of text has long been
a focus in linguistics and deriving computational
models of meaning has been pursued by various
semantic tasks such as semantic parsing. Deep
semantic parsing (as opposed to shallow seman-
tic parsing, such as semantic role labeling) aims
to map a sentence in natural language into its cor-
responding formal meaning representation (Zelle
and Mooney, 1996; Berant and Liang, 2014).
There has been a renewed interest in deeper se-
mantic representations of natural language (Ba-
narescu et al., 2013) in NLP community. Open-
domain semantic representations enable inference
and reasoning, which is required for many lan-
guage understanding tasks such as reading com-
prehension tests and open-domain question an-
swering. Comparison is a common way for ex-
pressing differences in sentiment and other prop-
erties towards some entity. Comparison can hap-
pen in very simple structures such as ‘John is
taller than Sam’, or more complicated construc-
tions such as ‘The table is longer than the sofa is
wide’. So far the computational semantics of com-
paratives and how they affect the meaning of text
has not been studied effectively. That is, the dif-
ference between the existing semantic and syntac-
tic representation of comparatives is not distinc-
tive enough for enabling deeper understanding of
a sentence. For instance, the general logical form
representation of the sentence ‘John is taller than
Susan’ using the Boxer system (Bos, 2008) is the
following:
</bodyText>
<equation confidence="0.919015333333333">
named(x0, john, per)
&amp; named(x1, susan, nam)
&amp;than(taller(x0), x1) (1)
</equation>
<bodyText confidence="0.999962476190476">
The above meaning representation does not
fully capture the underlying semantics of the ad-
jective ‘tall’ and what it means to be ‘taller’. A hu-
man reader can easily infer that actually the height
of John is greater than the height of Susan. An-
other example to consider is the sentence ‘John is
tall’, which basically has the typical logical form
tall(john) –which is a very superficial represen-
tation for the meaning of the predicate ‘tall’. Like-
wise, a human reader can infer that defining some-
one as ‘tall’ in some domain of discourse entails
that this person is somehow ‘taller’ than some
other population (say their average), however, the
earlier typical logical form representation does not
enable such inferences.
In this paper we introduce a novel framework
for semantic representation and computational
analysis of the structure of comparison in natural
language. This framework enables deeper repre-
sentation of semantics of comparatives, including
all different types of comparison within compara-
</bodyText>
<page confidence="0.982148">
993
</page>
<note confidence="0.9854825">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 993–1002,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.997153578947368">
tives, superlatives, equatives, excessives, and as-
setives, and the way they are related to their cor-
responding semantic roles. Together with this pa-
per, we provide a dataset of gold-annotated com-
parative structures using our meaning representa-
tion, which enables training models on compar-
ison constructions. We propose a new approach
for automatic extraction of comparison structures
from a given text. A semantic representation of the
comparison expressed by the sentence ‘The equip-
ment is too old to be much of use to us.’ aug-
mented under our representation would be the fol-
lowing:
Throughout this paper we define a comparison
to be any statement comparing two or more enti-
ties, expressing some kind of measurement on a
scale, or indicating some degree of having a mea-
surable property. The details of these variations
will be discussed in Section 3.
</bodyText>
<sectionHeader confidence="0.98112" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.9995425">
In this section we provide a linguistic background
on comparison constructions in language, which
provides the basis of our semantic framework (to
be presented in Section 3).
</bodyText>
<subsectionHeader confidence="0.98978">
2.1 Comparative Structures in Language
</subsectionHeader>
<bodyText confidence="0.997629">
Measurement in natural language is mainly ex-
pressed in sentences having comparative mor-
phemes such as more, less, -er, as, too, enough,
-est, etc1. Comparatives can be either adjectival,
adverbial, nominal, or verbal, i.e., the main com-
ponent of the sentence carrying out the measure-
ment can have either of these parts of speech.
Adjectival Comparatives: Canonical exam-
ples of comparative sentences contain adjectives,
e.g., ‘tall’ or ‘pretty’. Even within adjectival com-
paratives, there is a good deal of structural variety.
Consider the following examples:
</bodyText>
<listItem confidence="0.982841">
(1) a. Mary is taller than Susan.
b. Mary is 3 inches taller than Susan.
c. Mary is taller than 5 feet.
</listItem>
<footnote confidence="0.9931414">
1These morphemes are counted as the main comparison
operators. For easier representation, throughout this paper
we specify the smallest constituent containing any of these
morphemes as the comparison operator, which is italicized in
the sentences.
</footnote>
<bodyText confidence="0.931467227272727">
The comparative form of the adjective ‘tall’ in
sentence 1a is viewed as an expression denoting a
greater than (&gt;-) relation between two individuals,
‘Mary’ and ‘Susan’, on the scale of ‘tallness’. The
degree-theoretic analysis of such adjectives brings
up the notion of Gradable Adjectives: many adjec-
tives describe qualities that can be measured ac-
cording to degrees on scales, such as the scale of
‘size’, ‘beauty’, ‘age’, etc. These adjectives can be
used with comparative morphemes, indicating less
or more of a particular quality on a scale. Gradable
adjectives can express specific relations between
individuals on a scale, e.g., in sentence 1b Mary is
taller than Susan by a measure of 3 inches.
Comparison on the scale does not always in-
volve two individuals. For example consider sen-
tence 1c which denotes a comparison being made
between an individual and a specific point on the
scale of ‘tallness’. All the earlier examples are
among the simplest types of comparative struc-
tures using adjectives. Consider the following ex-
ample:
</bodyText>
<listItem confidence="0.713384">
(2) Mary is taller than the bed is long.
</listItem>
<bodyText confidence="0.999919083333333">
In sentence 2 we have a case of subcompara-
tives, where we compare ‘Mary’ and ‘bed’ accord-
ing to two different dimensions: height and length.
Each dimension provides a degree, and the degrees
are ultimately related by the greater than (&gt;-) re-
lation. Scalability is known to be universal in lan-
guage and a wide variety of linguistic phenomena
can be explained in terms of degrees and scales
(Solt, 2015).
The Semantics of Scales: A fairly common
view (Kennedy, 2007) is that a scale 5 is a triple
of the following form:
</bodyText>
<equation confidence="0.776683">
5 = (D, &gt;-, DIM) (2)
</equation>
<bodyText confidence="0.99953">
where D is a set of degrees, &gt;- is an ordering re-
lation on D, and DIM is the dimension of mea-
surement.2
Individuals are linked to degrees by measure
functions. A measure function µS is the func-
tion that maps an individual x to the degree on the
scale 5 that represents x’s measure with respect to
the dimension DIM. For example, the µHEIGHT
measure function is a function that maps individ-
uals to their respective heights. Under this model,
we represent the comparative structure of the sen-
tences 1a-1c as follows:
</bodyText>
<footnote confidence="0.9381915">
2To know more about the theory of scales and restrictions
on dimensions and degrees refer to (Solt, 2015).
</footnote>
<page confidence="0.987496">
994
</page>
<equation confidence="0.398295666666667">
(3) a. µHEIGHT (Mary) &gt;- µHEIGHT (Susan)
b. µHEIGHT (Mary) &gt;- µHEIGHT (Susan) + 3”
c. µHEIGHT (Mary) &gt;- 5 feet
</equation>
<bodyText confidence="0.943568">
A generic comparative interpretation of some
degree of tallness under HEIGHT scale is as fol-
lows:
</bodyText>
<equation confidence="0.951627">
Qtallj = AdAx.µHEIGHT(x) &gt;- d (3)
</equation>
<bodyText confidence="0.999634266666667">
where d is the degree argument which is sup-
plied by some form of degree morpheme: a degree
modifier (e.g., too, very), a measure phrase (e.g.
1.7 inches), or simply comparative or superlative
morphology. Under this model, we can also rep-
resent the comparative structure of the sentence
‘Mary is tall’3, where there is no explicit degree
argument. A common assumption is that the de-
gree role is played by a phonologically null degree
morpheme called pos, which denotes a context-
dependent threshold or standard of comparison
(Kennedy, 2007; Heim, 2007). For instance, in
a specific context of adult men in north America
being ‘tall’ could be interpreted as being over 6
feet.
</bodyText>
<listItem confidence="0.82562">
Non-canonical Comparatives: Comparative
structures can also be verbal, nominal, and adver-
bial. Consider the following verbal comparatives:
(4) a. The women ate more than men did.
b. The lake cooled more than 4 degrees.
</listItem>
<bodyText confidence="0.999778666666667">
It has been proposed (Wellwood et al., 2012)
that measure functions (µ) can be applied both to
individuals and to events, in the latter case mea-
suring either the event or an entity related to the
event. The comparative interpretation for the two
sentences 4a and 4b is as follows:
</bodyText>
<equation confidence="0.616835">
(5) a. µvolume(eat(women)) &gt;_ µvolume(eat(men))
b. Ae.µcoolness(e)(lake) &gt;- 4 degrees
</equation>
<bodyText confidence="0.998112111111111">
where cool is a function that takes an event e and
an object x (here ‘lake’) and returns a degree rep-
resenting the amount to which x changes in cool-
ness as a result of participating in e. The underly-
ing scale of verbal comparatives is sometimes am-
biguous, e.g., in sentence 5a it is not clear whether
the women ate more in volume or in quantity.
Comparative structures can also be nominal.
Consider the following sentences:
</bodyText>
<footnote confidence="0.856339666666667">
3Such cases are called positive usage of the adjective.
The negative (also called antonym) usage would be ‘Mary
is short’.
</footnote>
<bodyText confidence="0.95309625">
(6) a. More juniors than seniors came to the
ceremony.
b. We bought more milk than wine.
The meaning of sentences presented above must
be stated with reference to degrees as well (Solt,
2015). Hence, the scale for the comparison sen-
tence 6a is the numerical counting by integers and
the scale for sentence 6b is something correspond-
ing to a mass dimension, here perhaps liquid vol-
ume. Adverbial comparatives share many of their
characteristics with the adjectival and verbal class,
which we do not develop further for brevity. For
example the sentence ‘Mary ran faster than Sam’
is an example of adverbial comparison, where the
implicit ‘speed’ attribute of the ‘running’ event as-
sociated with Mary and Sam is being compared.
</bodyText>
<subsectionHeader confidence="0.999712">
2.2 Categories of Comparison
</subsectionHeader>
<bodyText confidence="0.9979482">
There are various ways for making comparisons,
each indicating different degrees of difference or
similarity. Following are the major categories for
degrees of comparison together with example sen-
tences4:
</bodyText>
<listItem confidence="0.999086411764706">
(7) Comparative
a. Mary is taller than Susan.
b. Dogs are more intelligent than rabbits.
(8) Superlative
a. Mary is the tallest girl in her class.
b. Dogs are the most intelligent among
pets.
(9) Equative
a. Mary is as tall as Bill.
b. Dogs are as intelligent as cats.
(10) Excessive
a. Mary is too short for basketball.
b. Dogs are too intelligent to be fooled.
(11) Assetive
a. Mary is tall enough to reach the shelf.
b. Dogs are intelligent enough to find
their way home.
</listItem>
<sectionHeader confidence="0.983263" genericHeader="method">
3 Semantic Framework of Comparison
</sectionHeader>
<bodyText confidence="0.9994435">
As discussed earlier, having a deep meaning rep-
resentation of comparison structures can help us
</bodyText>
<footnote confidence="0.913358333333333">
4As shown in example sentences of Table 1, there can
be non-adjectival comparisons in each of these categories as
well.
</footnote>
<page confidence="0.997282">
995
</page>
<bodyText confidence="0.999915202898551">
build computational models of comparison in nat-
ural language and perform inferential tasks in var-
ious domains. Here we introduce a novel seman-
tic framework of comparison. This framework is
based on the linguistic interpretations presented in
Section 2, but formalized and adapted to suit our
semantic computational framework.
We model comparatives as inter-connected
predicate-argument structures, where predicates
are the main comparison operators (implicit and
explicit comparison morphemes), and arguments
are connected to the predicates via semantic roles
(relations). Our framework includes not only ex-
plicit comparisons, but also implicit ones in the
form of an evaluation or a measurement on a scale,
which will be explained throughout this section.
More detailed and complete list of the predicates,
semantic roles, and arguments can be found in the
supplementary material.
Predicates: Table 1 lists all the predicate oper-
ators under our framework. As the table shows,
there are four main types of predicates: compara-
tives, extremes, bases, and measurements. Most
of these types can be associated with operators
from any of our parts of speech: Adjective (JJ),
Adverb (RB), Noun (NN), and Verb (VB). The
predicate operator in each of the examples is ital-
icized. The comparatives type also includes the
operators &lt; and =&lt;, which are the opposite of the
operators &gt; and &gt;= presented in the table. It is
important to note that the ‘base positive’ predi-
cate is actually the implicit pos operator (as men-
tioned in Section 2.1; however, for easier repre-
sentation we specify it by marking its correspond-
ing adjective or adverb. The same thing happens
for measurement predicates. Also, our framework
captures the subtle difference between the mean-
ing of ‘Mary is [tall]positive’ and ‘Mary is 5 feet
[tall]measurement−explicit’. The earlier means that
Mary is tall according to some standard of tallness
in a context, while the latter means that Mary’s
height equals the degree of 5 feet.
Semantic Roles: Each predicate is character-
ized by its arguments and each argument is con-
nected to the predicates by a relation (semantic
role) type. Table 2 shows the possible semantic
role types for a predicate. Figure is the core role
for a comparison structure, i.e., any comparison
should have a role indicating the main entity which
is being evaluated/measured/compared on a scale.
The simplest form of comparative predicate, e.g.,
‘John is taller than Sam’, involves two main roles:
Figure (John) and Ground (Sam). The non-core
roles are mainly associated with non-comparative
comparisons
Arguments: Last but not least, each role points
to an argument, which can have various types, as
listed in Table 3. The most frequent argument type
is individual, as in ’John is taller than Sam’. The
other notable role is Phrase-value, which repre-
sents an interesting comparison phenomena. In the
corresponding example in the table, the speed of
John’s driving is explicitly being compared with
some point on the scale of speed to which ‘he
was allowed’. Such ground roles are classified as
phrase-value, where a verb phrase signifies a point
of comparison on scale, not an individual entity.
Figure 1 shows an example of predicate-argument
structure under the described semantic framework.
</bodyText>
<sectionHeader confidence="0.989949" genericHeader="method">
4 Predicting Comparison Structures
</sectionHeader>
<bodyText confidence="0.99788625">
Given an input sentence, we want to predict the
predicate operators, their semantic roles, and ar-
guments. We decompose this problem into three
sub-problems:
</bodyText>
<listItem confidence="0.99906825">
• Labeling predicate candidates using a multi-
class classifier
• For each predicate, considering the set of all
possible argument spans:
</listItem>
<bodyText confidence="0.933855714285714">
– Use a classifier for predicting the role
type label
– Use a classifier for predicting the argu-
ment type label
Our overall approach, to be described in this
section, is similar to the works on joint inference
with global constraints for learning event relations
and process structures (Do et al., 2012; Berant et
al., 2014).
Predicting Predicates: The first step in com-
parison structure prediction is to identify and la-
bel the predicates. For this purpose we train a
multi-class classifier that labels all one-word con-
stituents in the sentence with any of predicate
types in Table 1 or None (indicating that the con-
stituent is not a predicate). The set of all possible
predicate labels is named P.
We used various features for training the predi-
cate classifier: we extract the lemma and POS tag
of the word, POS tag of children, siblings, par-
ent and root of the sentence in the dependency
</bodyText>
<page confidence="0.989847">
996
</page>
<table confidence="0.474041">
Predicate Type Subtype Examples
Comparatives:
Comparing against one or more entities.
&gt;
</table>
<listItem confidence="0.974567638888889">
• JJ: The car was more modern than I had imagined.
• RB: John ran faster than Susan.
• NN: More cookies than cakes were purchased.
• VB: Coffee is less consumed than tea.
&gt;= • JJ: Pizza is as expensive as pasta.
• RB: The men ran as fast as the women did.
• NN: That college hires as much professors as we do.
• VB: Athletes drink as much as others.
Superlative • JJ: Mary is the tallest among her colleagues.
• RB: Mike talked the most loudly of the group.
• NN: The juniors found the most rock of all.
• VB: The fire fighters ran the most among others.
Extreme: Excessive • JJ: Mary is too tall to fit in the chair.
Indicating having enough or too much of • RB: Sam ran too fast to get caught.
a quality or quantity. • NN: There are too many students at the party.
• VB: The kid screamed too much.
Assetive • JJ: Mary is smart enough to accept the offer.
• RB: The machine works steadily enough.
• NN: There are enough professors at the party.
• VB: Jack passed enough interviews to prove himself.
Polarity:
Base form expression of +/- quality.
• JJ: Mary is tall.
Positive
• RB:John talks beautifully.
• JJ: Susan is short.
Negative
• RB: Philip walks slowly.
Measurement:
Indicating a measurement on a scale.
• JJ: Mary is 5 feet tall.
Explicit
• RB: Philip is driving 60mph fast.
• JJ: Mary is 5 feet.
Implicit
• RB: Philip is driving 60mph.
</listItem>
<tableCaption confidence="0.987549">
Table 1: The predicate types defined under our framework.
</tableCaption>
<figureCaption confidence="0.992741">
Figure 1: A full annotation of a sample predicate-argument structure under the described semantic frame-
work.
</figureCaption>
<bodyText confidence="0.998546928571429">
tree, POS tag and lemma of two adjacent words,
similarity features from WordNet (Miller, 1995),
word polarity features, and most importantly ‘at-
tribute concepts’ for words which are adjectives
(Bakhshandeh and Allen, 2015). The ‘attribute
concepts’ are the different properties that an adjec-
tive can describe, for instance ‘height’ and ‘thick-
ness’ are the attributes of the adjective ‘gangling’.
Last but not least, we include the conjunction of
all these features.
Predicting Roles and Arguments: Given
the predicates, one should label the predicate-
argument role and predict the argument type. Here
we take an approach used for semantic role label-
ing (Punyakanok et al., 2008): given a predicate,
we collect all constituents in the sentence to build
a set of plausible candidate arguments. As a re-
sult, each predicate has a set of candidate argu-
ments which should be labeled with their argu-
ment types and be assigned with a semantic role
edge. Here we jointly train two logistic regres-
sion classifiers for predicting semantic role type
and argument type of a predicate-argument pair,
using argument identification features from (Pun-
yakanok et al., 2008) and using the structured av-
eraged Perceptron algorithm (Collins, 2002). The
role types can be any of the roles from table 2 or
None (set R), and the argument types can be any
</bodyText>
<page confidence="0.985706">
997
</page>
<table confidence="0.993124285714286">
Relation Type Description Example
Figure The main role being compared to something - [Lara] is taller than the tree.
else.
Ground The main role against which the figure is com- - Lara is taller than the [tree].
pared.
Differencedegree The ‘plus’ and ‘times’ roles, signifying an - Sam is [twice] taller than Jim.
amount of difference on a degree.
Domain The explicit expression of the domain/popula- - Mary is the most intelligent among
tion in which the comparison takes place [her classmates].
Reason The reason associated with the excessive and - John is too lazy [to wake up].
assetive predicates
Measurementdegree The main indication of a measurement - Henry is [5 feet] tall.
Scale The scale on which the comparison takes place - The [height] of the chair equals the
[length] of the sofa.
</table>
<tableCaption confidence="0.993382">
Table 2: The role types under our framework.
</tableCaption>
<table confidence="0.997751045454546">
Argument Type Subtype Example
Individual: - - [John] is a better performer than Susie.
An entity being compared against others.
Reference: - - John is 2&amp;quot; taller than [that].
A referring entity, the actual antecedent of
which would be resolved in discourse-level.
Phrase: Value - John was driving faster than [he was
Introduces a degree on scale. allowed].
Amount: Value - Mary is [5 feet] tall.
The expression of the amount in a measurement. Very Low-Low - Mary is [twice] taller than Bill.
High-Very High - Mary is [a little bit] taller than John.
- Mary is [a lot] taller than Bill.
Bound: Exact - Mary is [exactly] 5 feet tall.
A bound/approximation being set on the amount Approximate - Sam was [about] three times faster
that is expressed. Lower than others.
Higher - John walks [at least] twice faster than
you.
- Mary is [at most] twice as smart as the
others.
Scale: Explicit - The [height] of the bridge is too low
The scale on which the measurement is done. Implicit for the van.
- Sam is more [available] than John is.
</table>
<tableCaption confidence="0.99993">
Table 3: The argument types under our framework.
</tableCaption>
<bodyText confidence="0.932172571428571">
of the ones from table 3 or None (set G). At the
end of this stage we have two scores: scp,j,r =
log Prp,j,r where p E P is a predicate type, j is
a candidate argument, r E R is a role type; and
scp,j,g = log Prp,j,g where g E G.
Joint Inference: Given a sentence with its ex-
tracted predicates5, for each predicate labeled as
p, the goal is the following: find the best assign-
ment for the indicators y = {yp,j,r I p E P,1 &lt;
j &lt; n,r E R} and x = {xp,j,g I p E P,1 &lt;
j &lt; n, g E G}. Here n is the number of candidate
arguments for the given predicate. We model the
problem as an Integer Linear Programming (ILP).
We formulate the problem as follows:
</bodyText>
<footnote confidence="0.9112495">
5A constituent is a predicate if it is labeled with any p ∈ P
and p =� None.
</footnote>
<equation confidence="0.996558444444444">
s.t. X yp,j,r = 1 (4b)
r∈R,r6=None
X yp,j,g = 1 (4c)
g∈G
X yp,j,r = 1 (4d)
1&lt;j≤n
yp,j,None = xp,j,None (4e)
X yp,j,Figure = 1. (4f)
1&lt;j≤n
</equation>
<bodyText confidence="0.999095333333333">
The hard constraints 4b − 4c each indicate a re-
striction on the structure of the predicate-argument
relation and labels: each argument can have only
</bodyText>
<figure confidence="0.688676">
Xarg max
y,x
Xscp,j,r yp,j,r +
1&lt;j≤n
g∈G
scp,j,g xp,j,g (4a)
1&lt;j≤n
r∈R
</figure>
<page confidence="0.991147">
998
</page>
<bodyText confidence="0.99981925">
one role and argument type (4b − 4c), each pred-
icate can only have one of each role type (4d), a
‘None’ role type should be matched with a ‘None’
argument type (4e), and each predicate should
have exactly one ‘Figure’ role (4f). There are also
some other specific constraints such as the fact that
a predicate labeled with ‘comparative’ cannot have
a ‘Domain’ role type and vice verse.
</bodyText>
<sectionHeader confidence="0.99697" genericHeader="method">
5 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.937004">
5.1 Dataset Creation
</subsectionHeader>
<bodyText confidence="0.999995784313725">
In order to make our gold-annotated dataset we
used OntoNotes (Pradhan et al., 2007) release
5.0 corpus. OntoNotes covers various genres
such as conversations, news-wire, and Weblogs,
which provides distinctive variations of compari-
son structures in natural language. Furtheremore,
we think our annotations can potentially provide
augmentations on OntoNotes, so using the origi-
nal OntoNotes sentences can be beneficial.
One approach for pinpointing comparison sen-
tences is to mine for some known patterns and
train a classifier for distinguishing comparison
and non-comparison sentences (Jindal and Liu,
2006b). However, as demonstrated earlier, the va-
riety of comparison structures is so vast that be-
ing limited to some specific patterns or syntactic
structures will not serve our purpose. In order
to address this issue, we randomly selected 2000
sentences from OntoNotes which contained an ad-
jective, an adverb, or any of the comparison mor-
phemes. This set contained some non-comparison
sentences, such as ‘John admitted to the crime
too’.
In order to make the final set of comparison sen-
tences we performed the following task: we define
a comparative sentence as a sentence that contains
at least one predicate operator as defined in Sec-
tion 3. Hence, we provided three human experts
with a full predicate operator types table and asked
each of them to annotate any predicate operator
found in the given sentences. Then we retained
any sentences with at least one predicate operator
which was annotated by at least two of the three
judges. We further refined the set to include equal
number of predicate types. This resulted in 531
sentences.
After collecting the comparison sentences, we
asked the annotators to provide gold-standard an-
notation of predicate-argument structure of the
sentences. This involves the annotator to read
the annotation guideline and basically understand
the semantic framework for comparison structures
that we introduced in Section 3. Initially, we
ran a pilot study on a set of 50 sentences where
each sentence was annotated by two of the ex-
perts. We used pilot results for iterating over the
annotation schema and guideline and resolving is-
sues regarding low agreement predicates and ar-
gument types6, until getting to average agreement
κ = 0.80. We split the dataset into 30% and 70%
for testing and training respectively.
</bodyText>
<subsectionHeader confidence="0.997029">
5.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999990333333333">
Here we evaluate the performance of our pro-
posed predicate-argument structure prediction.
We present the following two methods:
</bodyText>
<listItem confidence="0.9573208">
• ILP Method: Our full approach as described
in Section 4. Here we used the Gurobi7 op-
timization package for finding an exact solu-
tion for our ILP formalization.
• Baseline: A simple pattern-based method
</listItem>
<bodyText confidence="0.974535538461539">
which uses lexical patterns for predicting
predicate type and argument types. This
method uses the generic comparative mor-
phemes such as ‘er’, ‘est’, ‘more’ and ‘less’
for detecting any specific type of predicate.
For identifying predicate arguments it relies
on rules which use syntactic structure, e.g.,
for a ‘greater’ predicate identified by ‘er’
morpheme, the ‘left’ argument is always the
main subject of the sentence. This method
annotates anything not recognized by pat-
terns as ‘None’.
Here with compare their predictions on test
set to the gold standard annotations and compute
micro-averaged precision, recall and F1 score. For
this analysis we remove the ‘equative’ predicate
type, given its very low frequency in our training
set. Moreover, here we do not include the positive
and negative predicate types, as these take only
one role argument which is ‘figure’, making the
prediction task trivial.
Table 4 shows the results of predicate type pre-
diction. The final reported average in this table ex-
cludes the type ‘None’. The best performing cate-
gory in both methods is ‘superlative’, which is be-
cause of its more typical structure which makes it
</bodyText>
<footnote confidence="0.99986075">
6The disagreements were mainly on fine-grained predi-
cate types, which were resolved by collapsing some of the
types together.
7www.gurobi.com
</footnote>
<page confidence="0.9973">
999
</page>
<bodyText confidence="0.99971590625">
easier to be predicted. In general, the precision of
predicate prediction is very high in ILP method,
which is due to the fact that our predicates are
the comparison operators indicated by the com-
parison morphemes. The baseline performs con-
siderably weaker than ILP method for predicting
less and greater predicates. This is because pre-
dicting these types requires a more complicated
analysis where simple morphological and syntac-
tic patterns can result in many false positives.
Table 5 depicts the results of the role type pre-
diction. The weighted average in this table is
based on frequency, excluding the type ‘None’.
The precision on role prediction varies across
different types. Overall, the baseline performs
weakly on predicting role types, which is dues to
the complicated structure of roles.
The best prediction of ILP method is on scales,
which has benefited from the attribute concept fea-
ture. The weaker performing types have been
affected by the low-frequency occurrence in the
training set. There are many cases of very long
and complex sentences in our dataset. One major
reason behind some of the false predictions is in-
correct dependency parse for long sentences. One
notable issue here is that for easier prediction and
analysis, we had asked our annotators to mark only
the head words for phrasal arguments. This had of-
ten caused lower agreement among annotators and
hence worse predictions on the system trained on
the dataset. In future, we are going to switch to
span-based argument identification.
</bodyText>
<table confidence="0.999827142857143">
Assetive 100 46 63 100 26 41
Greater 90 82 86 54 68 60
Superlative 96 79 87 89 73 80
Excessive 100 43 60 100 24 38
Less 100 86 92 45 71 55
None 96 99 99 78 80 79
Average 97 67 79 77 52 68
</table>
<tableCaption confidence="0.9430035">
Table 4: The evaluation results on predicate type
prediction.
</tableCaption>
<sectionHeader confidence="0.99972" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.9999175">
The syntax and semantics of comparison in lan-
guage have been studied in linguistics for a long
time (Bresnan, 1973; Cresswell, 1976; Von Ste-
chow, 1984). However, so far, computational
modeling of the semantics of comparison com-
ponents of natural language has not been devel-
</bodyText>
<table confidence="0.999735818181818">
Role Type ILP Method Baseline
P R F1 P R F1
Plus 67 31 42 11 17 13
Ground 34 56 42 6 23 9
Scale 81 28 41 63 20 30
Figure 25 44 32 3 29 5
Reason 50 12 20 33 7 11
Domain 50 25 33 26 24 25
Times 14 50 22 30 12 17
None 97 96 96 81 78 79
Weighted Average 76 42 54 24 18 20
</table>
<tableCaption confidence="0.863274">
Table 5: The evaluation result on role type predic-
tion.
</tableCaption>
<bodyText confidence="0.999932358974359">
oped as elaborately as needed. The main efforts
on computational aspects of comparatives have
been in the context of sentiment analysis. Jindal
and Liu (2006b) introduced the first approach for
the identification of sentences containing compar-
isons. Their system trains a Naive Bayes classi-
fier for labeling sentences as comparative or non-
comparative.
Later works progressed into identifying the
components of the comparisons: comparative
predicates and arguments. For example for the
sentence “Canon’s optics is better than those of
Sony and Nikon.”, the extracted relation should be:
(better, {optics}, {Canon}, {Sony, Nikon}). Jindal
and Liu (2006a) detect such arguments by labeling
sequential rules. Xu et al. (2011) use Conditional
Random Fields (Lafferty et al., 2001) to extract
relations between two entities, an attribute and a
predicate phrase. These works all provide a rudi-
mentary basis for computational analysis of com-
paratives, however, they lack depth and breadth as
they are limited to the limited comparison struc-
ture (Entity1, Entity2, aspect) expressed within
some sequential patterns. It is evident that the
framework of comparison proposed in this paper
goes beyond simple triplet annotation of compari-
son structures and is more representative of the lin-
guistics literature on comparatives and measure-
ments.
The most recent related work on comparatives
(Kessler, 2014) focuses on argument identification
task: given a comparative predicate, they find the
arguments corresponding to it. They train a classi-
fier for this task emphasizing on syntax informa-
tion. Most of the entities in their training data
are products (cameras, cars, and phones). An-
other recent work (Kessler and Kuhn, 2014) con-
centrates on the annotation of what they call multi-
word predicates (such as ‘more powerful’, where
</bodyText>
<figure confidence="0.943403">
ILP Method
Baseline
Predicate Type P R F1
P R F1
</figure>
<page confidence="0.846694">
1000
</page>
<bodyText confidence="0.999468">
the comparison is not one-word such as ‘calmer’).
They show that annotating the modifier of com-
paratives (i.e., the adjectives) gives better results
in classification. Both these works share the major
shortcoming of the earlier works, as they are very
limited to their specific patterns and fail to enable
deeper representation and analysis of various com-
plex comparative structures.
</bodyText>
<sectionHeader confidence="0.998371" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999973351351351">
Systems that can understand and reason over com-
paratives are crucial for various NLP applications
ranging from open-domain question answering to
product review analysis. Understanding compar-
atives requires a semantic framework which can
represent their underlying meaning. In this pa-
per we presented a novel semantic framework for
representing the meaning of various comparison
constructions in natural language. We mainly
modeled comparisons as predicate-argument pairs
which are connected via semantic roles. Our
framework supports all possible parts of speech
and variety of measurements and comparisons,
hence providing a unique computational represen-
tation of the underlying semantics of comparison.
Furthermore, we introduced an ILP-based method
for predicting the predicate-argument structure of
comparison sentences.
With this paper, we provide a novel dataset of
gold-standard annotations based on our seman-
tic framework. We are planning on expanding
our gold-standard annotations under this frame-
work for having more training data. Our semantic
framework on comparison constructions enables
us to do logical reasoning and inference over com-
paratives. In the future, we are planning to de-
sign a reading comprehension task where we use
this framework for answering comparison ques-
tions from a paragraph containing various inter-
related comparisons.
Last but not least, the works on broad-coverage
semantic parsing (Allen et al., 2008; Bos, 2008)
can all benefit from our semantic framework. We
will be extending the TRIPS logical form (Allen
et al., 2008) according to this framework and will
modify the grammar to generate the deeper repre-
sentations.
</bodyText>
<sectionHeader confidence="0.998295" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999860428571428">
We would like to thank Alexis Welwood for her
invaluable comments and guidelines on this work.
Moreover, we thank Ritwik Bose for his help on
annotations. This work was funded by the Office
of Naval Research (grant N000141110417) and
the DARPA Big Mechanism program under ARO
contract W911NF-14-1-0391.
</bodyText>
<sectionHeader confidence="0.990131" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999766680851064">
James F. Allen, Mary Swift, and Will de Beaumont.
2008. Deep semantic analysis of text. In Proceed-
ings of the 2008 Conference on Semantics in Text
Processing, STEP ’08, pages 343–354, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Omid Bakhshandeh and James F. Allen. 2015. From
adjective glosses to attribute concepts: Learning dif-
ferent aspects that an adjective can describe. In Pro-
ceedings of 11th International Conference on Com-
putational Semantics (IWCS).
Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract meaning representation
for sembanking. In Proceedings of the 7th Linguis-
tic Annotation Workshop and Interoperability with
Discourse, pages 178–186, Sofia, Bulgaria, August.
Association for Computational Linguistics.
Jonathan Berant and Percy Liang. 2014. Semantic
parsing via paraphrasing. In Association for Com-
putational Linguistics (ACL).
Jonathan Berant, Vivek Srikumar, Pei-Chun Chen,
Brad Huang, Christopher D. Manning, Abby V. Lin-
den, and Brittany Harding. 2014. Modeling bi-
ological processes for reading comprehension. In
Proceedings of the 2014 Conference on Empirical
Methods in Natural Language Processing (EMNLP
2014).
Johan Bos. 2008. Wide-coverage semantic analy-
sis with boxer. In Johan Bos and Rodolfo Del-
monte, editors, Semantics in Text Processing. STEP
2008 Conference Proceedings, Research in Compu-
tational Semantics, pages 277–286. College Publi-
cations.
Joan Bresnan. 1973. Syntax of the comparative
clause construction in english. Linguistic Inquiry,
4(3):275–343.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and exper-
iments with perceptron algorithms. In Proceedings
of the ACL-02 Conference on Empirical Methods in
Natural Language Processing - Volume 10, EMNLP
’02, pages 1–8, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Max Cresswell. 1976. The semantics of degree. Bar-
bara Hall Partee (ed.), pages 261–292.
</reference>
<page confidence="0.694365">
1001
</page>
<reference confidence="0.999818736111111">
Quang Do, Wei Lu, and Dan Roth. 2012. Joint infer-
ence for event timeline construction. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, EMNLP-CoNLL 2012,
July 12-14, 2012, Jeju Island, Korea, pages 677–
687.
Irene Heim. 2007. Little. In In Proceedings of 16th
Semantics and Linguistic Theory Conference, Cor-
nell University, Ithaca.
Nitin Jindal and Bing Liu. 2006a. Identifying com-
parative sentences in text documents. In Proceed-
ings of the 29th Annual International ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval, SIGIR ’06, pages 244–251, New
York, NY, USA. ACM.
Nitin Jindal and Bing Liu. 2006b. Mining comparative
sentences and relations. In Proceedings of the 21st
National Conference on Artificial Intelligence - Vol-
ume 2, AAAI’06, pages 1331–1336. AAAI Press.
Christopher Kennedy. 2007. Vagueness and grammar:
the semantics of relative and absolute gradable ad-
jectives. Linguistics and Philosophy, 30(1):1–45,
February.
Wiltrud Kessler and Jonas Kuhn. 2014. Detecting
comparative sentiment expressions – a case study
in annotation design decisions. In Proceedings of
KONVENS, Hildesheim, Germany.
Wiltrud Kessler. 2014. Improving the detection of
comparison arguments in product reviews. In Pro-
ceedings of 44th Jahrestagung der Gesellschaft fur
Informatik e.V. (INFORMATIK2014), pages 22–26,
Stuttgart, Germany, September.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth Inter-
national Conference on Machine Learning, ICML
’01, pages 282–289, San Francisco, CA, USA. Mor-
gan Kaufmann Publishers Inc.
George A. Miller. 1995. Wordnet: A lexical database
for english. Commun. ACM, 38(11):39–41, Novem-
ber.
Sameer Pradhan, Eduard Hovy, Mitch Marcus, Martha
Palmer, Lance Ramshaw, and Ralph Weischedel.
2007. Ontonotes: A unified relational seman-
tic representation. In Proceedings of the Interna-
tional Conference on Semantic Computing, ICSC
’07, pages 517–526, Washington, DC, USA. IEEE
Computer Society.
Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008.
The importance of syntactic parsing and infer-
ence in semantic role labeling. Comput. Linguist.,
34(2):257–287, June.
Stephanie Solt. 2015. Measurement scales in natu-
ral language. Language and Linguistics Compass,
9(1):14–32.
Arnim Von Stechow. 1984. Comparing semantic the-
ories of comparison. Journal of Semantics, 3(1):1–
77.
Alexis Wellwood, V. Hacquard, , and R. Pancheva.
2012. Measuring and comparing individuals and
events. Journal of Semantics, 29(2):207–228.
Kaiquan Xu, Stephen Shaoyi Liao, Jiexun Li, and
Yuxia Song. 2011. Mining comparative opinions
from customer reviews for competitive intelligence.
Decision Support Systems, 50(4):743–754.
John M. Zelle and Raymond J. Mooney. 1996. Learn-
ing to parse database queries using inductive logic
programming. In Proceedings of the Thirteenth Na-
tional Conference on Artificial Intelligence - Volume
2, AAAI’96, pages 1050–1055. AAAI Press.
</reference>
<page confidence="0.995278">
1002
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.399519">
<title confidence="0.999464">Semantic Framework for Comparison Structures in Natural Language</title>
<author confidence="0.99441">Omid Bakhshandeh James F Allen</author>
<affiliation confidence="0.7360965">University of Rochester University of for Human and Machine Cognition</affiliation>
<email confidence="0.996297">james@cs.rochester.edu</email>
<abstract confidence="0.9914372">Comparison is one of the most important phenomena in language for expressing objective and subjective facts about various entities. Systems that can understand and reason over comparative structure can play a major role in the applications which require deeper understanding of language. In this paper we present a novel semantic framework for representing the meaning of comparative structures in natural language, which models comparisons as predicate-argument pairs interconnected with semantic roles. Our framework supports not only adjectival, but also adverbial, nominal, and verbal comparatives. With this paper, we provide a novel dataset of gold-standard comparison structures annotated according to our semantic framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>Mary Swift</author>
<author>Will de Beaumont</author>
</authors>
<title>Deep semantic analysis of text.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Semantics in Text Processing, STEP ’08,</booktitle>
<pages>343--354</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Allen, Swift, de Beaumont, 2008</marker>
<rawString>James F. Allen, Mary Swift, and Will de Beaumont. 2008. Deep semantic analysis of text. In Proceedings of the 2008 Conference on Semantics in Text Processing, STEP ’08, pages 343–354, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omid Bakhshandeh</author>
<author>James F Allen</author>
</authors>
<title>From adjective glosses to attribute concepts: Learning different aspects that an adjective can describe.</title>
<date>2015</date>
<booktitle>In Proceedings of 11th International Conference on Computational Semantics (IWCS).</booktitle>
<contexts>
<context position="18044" citStr="Bakhshandeh and Allen, 2015" startWordPosition="2963" endWordPosition="2966">J: Susan is short. Negative • RB: Philip walks slowly. Measurement: Indicating a measurement on a scale. • JJ: Mary is 5 feet tall. Explicit • RB: Philip is driving 60mph fast. • JJ: Mary is 5 feet. Implicit • RB: Philip is driving 60mph. Table 1: The predicate types defined under our framework. Figure 1: A full annotation of a sample predicate-argument structure under the described semantic framework. tree, POS tag and lemma of two adjacent words, similarity features from WordNet (Miller, 1995), word polarity features, and most importantly ‘attribute concepts’ for words which are adjectives (Bakhshandeh and Allen, 2015). The ‘attribute concepts’ are the different properties that an adjective can describe, for instance ‘height’ and ‘thickness’ are the attributes of the adjective ‘gangling’. Last but not least, we include the conjunction of all these features. Predicting Roles and Arguments: Given the predicates, one should label the predicateargument role and predict the argument type. Here we take an approach used for semantic role labeling (Punyakanok et al., 2008): given a predicate, we collect all constituents in the sentence to build a set of plausible candidate arguments. As a result, each predicate has</context>
</contexts>
<marker>Bakhshandeh, Allen, 2015</marker>
<rawString>Omid Bakhshandeh and James F. Allen. 2015. From adjective glosses to attribute concepts: Learning different aspects that an adjective can describe. In Proceedings of 11th International Conference on Computational Semantics (IWCS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Banarescu</author>
<author>Claire Bonial</author>
<author>Shu Cai</author>
<author>Madalina Georgescu</author>
<author>Kira Griffitt</author>
<author>Ulf Hermjakob</author>
<author>Kevin Knight</author>
<author>Philipp Koehn</author>
<author>Martha Palmer</author>
<author>Nathan Schneider</author>
</authors>
<title>Abstract meaning representation for sembanking.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,</booktitle>
<pages>178--186</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="1528" citStr="Banarescu et al., 2013" startWordPosition="224" endWordPosition="228"> comparison structures annotated according to our semantic framework. 1 Introduction Representing the meaning of text has long been a focus in linguistics and deriving computational models of meaning has been pursued by various semantic tasks such as semantic parsing. Deep semantic parsing (as opposed to shallow semantic parsing, such as semantic role labeling) aims to map a sentence in natural language into its corresponding formal meaning representation (Zelle and Mooney, 1996; Berant and Liang, 2014). There has been a renewed interest in deeper semantic representations of natural language (Banarescu et al., 2013) in NLP community. Opendomain semantic representations enable inference and reasoning, which is required for many language understanding tasks such as reading comprehension tests and open-domain question answering. Comparison is a common way for expressing differences in sentiment and other properties towards some entity. Comparison can happen in very simple structures such as ‘John is taller than Sam’, or more complicated constructions such as ‘The table is longer than the sofa is wide’. So far the computational semantics of comparatives and how they affect the meaning of text has not been st</context>
</contexts>
<marker>Banarescu, Bonial, Cai, Georgescu, Griffitt, Hermjakob, Knight, Koehn, Palmer, Schneider, 2013</marker>
<rawString>Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider. 2013. Abstract meaning representation for sembanking. In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse, pages 178–186, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Percy Liang</author>
</authors>
<title>Semantic parsing via paraphrasing.</title>
<date>2014</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="1413" citStr="Berant and Liang, 2014" startWordPosition="206" endWordPosition="209"> but also adverbial, nominal, and verbal comparatives. With this paper, we provide a novel dataset of gold-standard comparison structures annotated according to our semantic framework. 1 Introduction Representing the meaning of text has long been a focus in linguistics and deriving computational models of meaning has been pursued by various semantic tasks such as semantic parsing. Deep semantic parsing (as opposed to shallow semantic parsing, such as semantic role labeling) aims to map a sentence in natural language into its corresponding formal meaning representation (Zelle and Mooney, 1996; Berant and Liang, 2014). There has been a renewed interest in deeper semantic representations of natural language (Banarescu et al., 2013) in NLP community. Opendomain semantic representations enable inference and reasoning, which is required for many language understanding tasks such as reading comprehension tests and open-domain question answering. Comparison is a common way for expressing differences in sentiment and other properties towards some entity. Comparison can happen in very simple structures such as ‘John is taller than Sam’, or more complicated constructions such as ‘The table is longer than the sofa i</context>
</contexts>
<marker>Berant, Liang, 2014</marker>
<rawString>Jonathan Berant and Percy Liang. 2014. Semantic parsing via paraphrasing. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Vivek Srikumar</author>
<author>Pei-Chun Chen</author>
<author>Brad Huang</author>
<author>Christopher D Manning</author>
<author>Abby V Linden</author>
<author>Brittany Harding</author>
</authors>
<title>Modeling biological processes for reading comprehension.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<contexts>
<context position="15650" citStr="Berant et al., 2014" startWordPosition="2531" endWordPosition="2534">es Given an input sentence, we want to predict the predicate operators, their semantic roles, and arguments. We decompose this problem into three sub-problems: • Labeling predicate candidates using a multiclass classifier • For each predicate, considering the set of all possible argument spans: – Use a classifier for predicting the role type label – Use a classifier for predicting the argument type label Our overall approach, to be described in this section, is similar to the works on joint inference with global constraints for learning event relations and process structures (Do et al., 2012; Berant et al., 2014). Predicting Predicates: The first step in comparison structure prediction is to identify and label the predicates. For this purpose we train a multi-class classifier that labels all one-word constituents in the sentence with any of predicate types in Table 1 or None (indicating that the constituent is not a predicate). The set of all possible predicate labels is named P. We used various features for training the predicate classifier: we extract the lemma and POS tag of the word, POS tag of children, siblings, parent and root of the sentence in the dependency 996 Predicate Type Subtype Example</context>
</contexts>
<marker>Berant, Srikumar, Chen, Huang, Manning, Linden, Harding, 2014</marker>
<rawString>Jonathan Berant, Vivek Srikumar, Pei-Chun Chen, Brad Huang, Christopher D. Manning, Abby V. Linden, and Brittany Harding. 2014. Modeling biological processes for reading comprehension. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP 2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Wide-coverage semantic analysis with boxer.</title>
<date>2008</date>
<booktitle>Semantics in Text Processing. STEP 2008 Conference Proceedings, Research in Computational Semantics,</booktitle>
<pages>277--286</pages>
<editor>In Johan Bos and Rodolfo Delmonte, editors,</editor>
<publisher>College Publications.</publisher>
<contexts>
<context position="2453" citStr="Bos, 2008" startWordPosition="376" endWordPosition="377"> entity. Comparison can happen in very simple structures such as ‘John is taller than Sam’, or more complicated constructions such as ‘The table is longer than the sofa is wide’. So far the computational semantics of comparatives and how they affect the meaning of text has not been studied effectively. That is, the difference between the existing semantic and syntactic representation of comparatives is not distinctive enough for enabling deeper understanding of a sentence. For instance, the general logical form representation of the sentence ‘John is taller than Susan’ using the Boxer system (Bos, 2008) is the following: named(x0, john, per) &amp; named(x1, susan, nam) &amp;than(taller(x0), x1) (1) The above meaning representation does not fully capture the underlying semantics of the adjective ‘tall’ and what it means to be ‘taller’. A human reader can easily infer that actually the height of John is greater than the height of Susan. Another example to consider is the sentence ‘John is tall’, which basically has the typical logical form tall(john) –which is a very superficial representation for the meaning of the predicate ‘tall’. Likewise, a human reader can infer that defining someone as ‘tall’ i</context>
</contexts>
<marker>Bos, 2008</marker>
<rawString>Johan Bos. 2008. Wide-coverage semantic analysis with boxer. In Johan Bos and Rodolfo Delmonte, editors, Semantics in Text Processing. STEP 2008 Conference Proceedings, Research in Computational Semantics, pages 277–286. College Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan Bresnan</author>
</authors>
<title>Syntax of the comparative clause construction in english.</title>
<date>1973</date>
<journal>Linguistic Inquiry,</journal>
<volume>4</volume>
<issue>3</issue>
<contexts>
<context position="28500" citStr="Bresnan, 1973" startWordPosition="4746" endWordPosition="4747">y the head words for phrasal arguments. This had often caused lower agreement among annotators and hence worse predictions on the system trained on the dataset. In future, we are going to switch to span-based argument identification. Assetive 100 46 63 100 26 41 Greater 90 82 86 54 68 60 Superlative 96 79 87 89 73 80 Excessive 100 43 60 100 24 38 Less 100 86 92 45 71 55 None 96 99 99 78 80 79 Average 97 67 79 77 52 68 Table 4: The evaluation results on predicate type prediction. 6 Related Work The syntax and semantics of comparison in language have been studied in linguistics for a long time (Bresnan, 1973; Cresswell, 1976; Von Stechow, 1984). However, so far, computational modeling of the semantics of comparison components of natural language has not been develRole Type ILP Method Baseline P R F1 P R F1 Plus 67 31 42 11 17 13 Ground 34 56 42 6 23 9 Scale 81 28 41 63 20 30 Figure 25 44 32 3 29 5 Reason 50 12 20 33 7 11 Domain 50 25 33 26 24 25 Times 14 50 22 30 12 17 None 97 96 96 81 78 79 Weighted Average 76 42 54 24 18 20 Table 5: The evaluation result on role type prediction. oped as elaborately as needed. The main efforts on computational aspects of comparatives have been in the context of </context>
</contexts>
<marker>Bresnan, 1973</marker>
<rawString>Joan Bresnan. 1973. Syntax of the comparative clause construction in english. Linguistic Inquiry, 4(3):275–343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP ’02,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="19047" citStr="Collins, 2002" startWordPosition="3126" endWordPosition="3127">approach used for semantic role labeling (Punyakanok et al., 2008): given a predicate, we collect all constituents in the sentence to build a set of plausible candidate arguments. As a result, each predicate has a set of candidate arguments which should be labeled with their argument types and be assigned with a semantic role edge. Here we jointly train two logistic regression classifiers for predicting semantic role type and argument type of a predicate-argument pair, using argument identification features from (Punyakanok et al., 2008) and using the structured averaged Perceptron algorithm (Collins, 2002). The role types can be any of the roles from table 2 or None (set R), and the argument types can be any 997 Relation Type Description Example Figure The main role being compared to something - [Lara] is taller than the tree. else. Ground The main role against which the figure is com- - Lara is taller than the [tree]. pared. Differencedegree The ‘plus’ and ‘times’ roles, signifying an - Sam is [twice] taller than Jim. amount of difference on a degree. Domain The explicit expression of the domain/popula- - Mary is the most intelligent among tion in which the comparison takes place [her classmat</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP ’02, pages 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Cresswell</author>
</authors>
<title>The semantics of degree.</title>
<date>1976</date>
<pages>261--292</pages>
<editor>Partee (ed.),</editor>
<publisher>Barbara Hall</publisher>
<contexts>
<context position="28517" citStr="Cresswell, 1976" startWordPosition="4748" endWordPosition="4749">s for phrasal arguments. This had often caused lower agreement among annotators and hence worse predictions on the system trained on the dataset. In future, we are going to switch to span-based argument identification. Assetive 100 46 63 100 26 41 Greater 90 82 86 54 68 60 Superlative 96 79 87 89 73 80 Excessive 100 43 60 100 24 38 Less 100 86 92 45 71 55 None 96 99 99 78 80 79 Average 97 67 79 77 52 68 Table 4: The evaluation results on predicate type prediction. 6 Related Work The syntax and semantics of comparison in language have been studied in linguistics for a long time (Bresnan, 1973; Cresswell, 1976; Von Stechow, 1984). However, so far, computational modeling of the semantics of comparison components of natural language has not been develRole Type ILP Method Baseline P R F1 P R F1 Plus 67 31 42 11 17 13 Ground 34 56 42 6 23 9 Scale 81 28 41 63 20 30 Figure 25 44 32 3 29 5 Reason 50 12 20 33 7 11 Domain 50 25 33 26 24 25 Times 14 50 22 30 12 17 None 97 96 96 81 78 79 Weighted Average 76 42 54 24 18 20 Table 5: The evaluation result on role type prediction. oped as elaborately as needed. The main efforts on computational aspects of comparatives have been in the context of sentiment analysi</context>
</contexts>
<marker>Cresswell, 1976</marker>
<rawString>Max Cresswell. 1976. The semantics of degree. Barbara Hall Partee (ed.), pages 261–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Do</author>
<author>Wei Lu</author>
<author>Dan Roth</author>
</authors>
<title>Joint inference for event timeline construction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL 2012,</booktitle>
<pages>677--687</pages>
<location>Jeju Island,</location>
<contexts>
<context position="15628" citStr="Do et al., 2012" startWordPosition="2527" endWordPosition="2530">mparison Structures Given an input sentence, we want to predict the predicate operators, their semantic roles, and arguments. We decompose this problem into three sub-problems: • Labeling predicate candidates using a multiclass classifier • For each predicate, considering the set of all possible argument spans: – Use a classifier for predicting the role type label – Use a classifier for predicting the argument type label Our overall approach, to be described in this section, is similar to the works on joint inference with global constraints for learning event relations and process structures (Do et al., 2012; Berant et al., 2014). Predicting Predicates: The first step in comparison structure prediction is to identify and label the predicates. For this purpose we train a multi-class classifier that labels all one-word constituents in the sentence with any of predicate types in Table 1 or None (indicating that the constituent is not a predicate). The set of all possible predicate labels is named P. We used various features for training the predicate classifier: we extract the lemma and POS tag of the word, POS tag of children, siblings, parent and root of the sentence in the dependency 996 Predicat</context>
</contexts>
<marker>Do, Lu, Roth, 2012</marker>
<rawString>Quang Do, Wei Lu, and Dan Roth. 2012. Joint inference for event timeline construction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL 2012, July 12-14, 2012, Jeju Island, Korea, pages 677– 687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Heim</author>
</authors>
<title>Little. In</title>
<date>2007</date>
<booktitle>In Proceedings of 16th Semantics and Linguistic Theory Conference,</booktitle>
<institution>Cornell University,</institution>
<location>Ithaca.</location>
<contexts>
<context position="8776" citStr="Heim, 2007" startWordPosition="1412" endWordPosition="1413">EIGHT scale is as follows: Qtallj = AdAx.µHEIGHT(x) &gt;- d (3) where d is the degree argument which is supplied by some form of degree morpheme: a degree modifier (e.g., too, very), a measure phrase (e.g. 1.7 inches), or simply comparative or superlative morphology. Under this model, we can also represent the comparative structure of the sentence ‘Mary is tall’3, where there is no explicit degree argument. A common assumption is that the degree role is played by a phonologically null degree morpheme called pos, which denotes a contextdependent threshold or standard of comparison (Kennedy, 2007; Heim, 2007). For instance, in a specific context of adult men in north America being ‘tall’ could be interpreted as being over 6 feet. Non-canonical Comparatives: Comparative structures can also be verbal, nominal, and adverbial. Consider the following verbal comparatives: (4) a. The women ate more than men did. b. The lake cooled more than 4 degrees. It has been proposed (Wellwood et al., 2012) that measure functions (µ) can be applied both to individuals and to events, in the latter case measuring either the event or an entity related to the event. The comparative interpretation for the two sentences 4</context>
</contexts>
<marker>Heim, 2007</marker>
<rawString>Irene Heim. 2007. Little. In In Proceedings of 16th Semantics and Linguistic Theory Conference, Cornell University, Ithaca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Identifying comparative sentences in text documents.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’06,</booktitle>
<pages>244--251</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="23197" citStr="Jindal and Liu, 2006" startWordPosition="3868" endWordPosition="3871">et Creation In order to make our gold-annotated dataset we used OntoNotes (Pradhan et al., 2007) release 5.0 corpus. OntoNotes covers various genres such as conversations, news-wire, and Weblogs, which provides distinctive variations of comparison structures in natural language. Furtheremore, we think our annotations can potentially provide augmentations on OntoNotes, so using the original OntoNotes sentences can be beneficial. One approach for pinpointing comparison sentences is to mine for some known patterns and train a classifier for distinguishing comparison and non-comparison sentences (Jindal and Liu, 2006b). However, as demonstrated earlier, the variety of comparison structures is so vast that being limited to some specific patterns or syntactic structures will not serve our purpose. In order to address this issue, we randomly selected 2000 sentences from OntoNotes which contained an adjective, an adverb, or any of the comparison morphemes. This set contained some non-comparison sentences, such as ‘John admitted to the crime too’. In order to make the final set of comparison sentences we performed the following task: we define a comparative sentence as a sentence that contains at least one pre</context>
<context position="29140" citStr="Jindal and Liu (2006" startWordPosition="4879" endWordPosition="4882">on Stechow, 1984). However, so far, computational modeling of the semantics of comparison components of natural language has not been develRole Type ILP Method Baseline P R F1 P R F1 Plus 67 31 42 11 17 13 Ground 34 56 42 6 23 9 Scale 81 28 41 63 20 30 Figure 25 44 32 3 29 5 Reason 50 12 20 33 7 11 Domain 50 25 33 26 24 25 Times 14 50 22 30 12 17 None 97 96 96 81 78 79 Weighted Average 76 42 54 24 18 20 Table 5: The evaluation result on role type prediction. oped as elaborately as needed. The main efforts on computational aspects of comparatives have been in the context of sentiment analysis. Jindal and Liu (2006b) introduced the first approach for the identification of sentences containing comparisons. Their system trains a Naive Bayes classifier for labeling sentences as comparative or noncomparative. Later works progressed into identifying the components of the comparisons: comparative predicates and arguments. For example for the sentence “Canon’s optics is better than those of Sony and Nikon.”, the extracted relation should be: (better, {optics}, {Canon}, {Sony, Nikon}). Jindal and Liu (2006a) detect such arguments by labeling sequential rules. Xu et al. (2011) use Conditional Random Fields (Laff</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006a. Identifying comparative sentences in text documents. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’06, pages 244–251, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Mining comparative sentences and relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st National Conference on Artificial Intelligence - Volume 2, AAAI’06,</booktitle>
<pages>1331--1336</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="23197" citStr="Jindal and Liu, 2006" startWordPosition="3868" endWordPosition="3871">et Creation In order to make our gold-annotated dataset we used OntoNotes (Pradhan et al., 2007) release 5.0 corpus. OntoNotes covers various genres such as conversations, news-wire, and Weblogs, which provides distinctive variations of comparison structures in natural language. Furtheremore, we think our annotations can potentially provide augmentations on OntoNotes, so using the original OntoNotes sentences can be beneficial. One approach for pinpointing comparison sentences is to mine for some known patterns and train a classifier for distinguishing comparison and non-comparison sentences (Jindal and Liu, 2006b). However, as demonstrated earlier, the variety of comparison structures is so vast that being limited to some specific patterns or syntactic structures will not serve our purpose. In order to address this issue, we randomly selected 2000 sentences from OntoNotes which contained an adjective, an adverb, or any of the comparison morphemes. This set contained some non-comparison sentences, such as ‘John admitted to the crime too’. In order to make the final set of comparison sentences we performed the following task: we define a comparative sentence as a sentence that contains at least one pre</context>
<context position="29140" citStr="Jindal and Liu (2006" startWordPosition="4879" endWordPosition="4882">on Stechow, 1984). However, so far, computational modeling of the semantics of comparison components of natural language has not been develRole Type ILP Method Baseline P R F1 P R F1 Plus 67 31 42 11 17 13 Ground 34 56 42 6 23 9 Scale 81 28 41 63 20 30 Figure 25 44 32 3 29 5 Reason 50 12 20 33 7 11 Domain 50 25 33 26 24 25 Times 14 50 22 30 12 17 None 97 96 96 81 78 79 Weighted Average 76 42 54 24 18 20 Table 5: The evaluation result on role type prediction. oped as elaborately as needed. The main efforts on computational aspects of comparatives have been in the context of sentiment analysis. Jindal and Liu (2006b) introduced the first approach for the identification of sentences containing comparisons. Their system trains a Naive Bayes classifier for labeling sentences as comparative or noncomparative. Later works progressed into identifying the components of the comparisons: comparative predicates and arguments. For example for the sentence “Canon’s optics is better than those of Sony and Nikon.”, the extracted relation should be: (better, {optics}, {Canon}, {Sony, Nikon}). Jindal and Liu (2006a) detect such arguments by labeling sequential rules. Xu et al. (2011) use Conditional Random Fields (Laff</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006b. Mining comparative sentences and relations. In Proceedings of the 21st National Conference on Artificial Intelligence - Volume 2, AAAI’06, pages 1331–1336. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
</authors>
<title>Vagueness and grammar: the semantics of relative and absolute gradable adjectives.</title>
<date>2007</date>
<journal>Linguistics and Philosophy,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="7282" citStr="Kennedy, 2007" startWordPosition="1148" endWordPosition="1149">les are among the simplest types of comparative structures using adjectives. Consider the following example: (2) Mary is taller than the bed is long. In sentence 2 we have a case of subcomparatives, where we compare ‘Mary’ and ‘bed’ according to two different dimensions: height and length. Each dimension provides a degree, and the degrees are ultimately related by the greater than (&gt;-) relation. Scalability is known to be universal in language and a wide variety of linguistic phenomena can be explained in terms of degrees and scales (Solt, 2015). The Semantics of Scales: A fairly common view (Kennedy, 2007) is that a scale 5 is a triple of the following form: 5 = (D, &gt;-, DIM) (2) where D is a set of degrees, &gt;- is an ordering relation on D, and DIM is the dimension of measurement.2 Individuals are linked to degrees by measure functions. A measure function µS is the function that maps an individual x to the degree on the scale 5 that represents x’s measure with respect to the dimension DIM. For example, the µHEIGHT measure function is a function that maps individuals to their respective heights. Under this model, we represent the comparative structure of the sentences 1a-1c as follows: 2To know m</context>
<context position="8763" citStr="Kennedy, 2007" startWordPosition="1410" endWordPosition="1411">allness under HEIGHT scale is as follows: Qtallj = AdAx.µHEIGHT(x) &gt;- d (3) where d is the degree argument which is supplied by some form of degree morpheme: a degree modifier (e.g., too, very), a measure phrase (e.g. 1.7 inches), or simply comparative or superlative morphology. Under this model, we can also represent the comparative structure of the sentence ‘Mary is tall’3, where there is no explicit degree argument. A common assumption is that the degree role is played by a phonologically null degree morpheme called pos, which denotes a contextdependent threshold or standard of comparison (Kennedy, 2007; Heim, 2007). For instance, in a specific context of adult men in north America being ‘tall’ could be interpreted as being over 6 feet. Non-canonical Comparatives: Comparative structures can also be verbal, nominal, and adverbial. Consider the following verbal comparatives: (4) a. The women ate more than men did. b. The lake cooled more than 4 degrees. It has been proposed (Wellwood et al., 2012) that measure functions (µ) can be applied both to individuals and to events, in the latter case measuring either the event or an entity related to the event. The comparative interpretation for the tw</context>
</contexts>
<marker>Kennedy, 2007</marker>
<rawString>Christopher Kennedy. 2007. Vagueness and grammar: the semantics of relative and absolute gradable adjectives. Linguistics and Philosophy, 30(1):1–45, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wiltrud Kessler</author>
<author>Jonas Kuhn</author>
</authors>
<title>Detecting comparative sentiment expressions – a case study in annotation design decisions.</title>
<date>2014</date>
<booktitle>In Proceedings of KONVENS,</booktitle>
<location>Hildesheim, Germany.</location>
<contexts>
<context position="30695" citStr="Kessler and Kuhn, 2014" startWordPosition="5114" endWordPosition="5117">uential patterns. It is evident that the framework of comparison proposed in this paper goes beyond simple triplet annotation of comparison structures and is more representative of the linguistics literature on comparatives and measurements. The most recent related work on comparatives (Kessler, 2014) focuses on argument identification task: given a comparative predicate, they find the arguments corresponding to it. They train a classifier for this task emphasizing on syntax information. Most of the entities in their training data are products (cameras, cars, and phones). Another recent work (Kessler and Kuhn, 2014) concentrates on the annotation of what they call multiword predicates (such as ‘more powerful’, where ILP Method Baseline Predicate Type P R F1 P R F1 1000 the comparison is not one-word such as ‘calmer’). They show that annotating the modifier of comparatives (i.e., the adjectives) gives better results in classification. Both these works share the major shortcoming of the earlier works, as they are very limited to their specific patterns and fail to enable deeper representation and analysis of various complex comparative structures. 7 Conclusion Systems that can understand and reason over co</context>
</contexts>
<marker>Kessler, Kuhn, 2014</marker>
<rawString>Wiltrud Kessler and Jonas Kuhn. 2014. Detecting comparative sentiment expressions – a case study in annotation design decisions. In Proceedings of KONVENS, Hildesheim, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wiltrud Kessler</author>
</authors>
<title>Improving the detection of comparison arguments in product reviews.</title>
<date>2014</date>
<booktitle>In Proceedings of 44th Jahrestagung der Gesellschaft fur Informatik e.V. (INFORMATIK2014),</booktitle>
<pages>22--26</pages>
<location>Stuttgart, Germany,</location>
<contexts>
<context position="30374" citStr="Kessler, 2014" startWordPosition="5065" endWordPosition="5066">o extract relations between two entities, an attribute and a predicate phrase. These works all provide a rudimentary basis for computational analysis of comparatives, however, they lack depth and breadth as they are limited to the limited comparison structure (Entity1, Entity2, aspect) expressed within some sequential patterns. It is evident that the framework of comparison proposed in this paper goes beyond simple triplet annotation of comparison structures and is more representative of the linguistics literature on comparatives and measurements. The most recent related work on comparatives (Kessler, 2014) focuses on argument identification task: given a comparative predicate, they find the arguments corresponding to it. They train a classifier for this task emphasizing on syntax information. Most of the entities in their training data are products (cameras, cars, and phones). Another recent work (Kessler and Kuhn, 2014) concentrates on the annotation of what they call multiword predicates (such as ‘more powerful’, where ILP Method Baseline Predicate Type P R F1 P R F1 1000 the comparison is not one-word such as ‘calmer’). They show that annotating the modifier of comparatives (i.e., the adject</context>
</contexts>
<marker>Kessler, 2014</marker>
<rawString>Wiltrud Kessler. 2014. Improving the detection of comparison arguments in product reviews. In Proceedings of 44th Jahrestagung der Gesellschaft fur Informatik e.V. (INFORMATIK2014), pages 22–26, Stuttgart, Germany, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="29758" citStr="Lafferty et al., 2001" startWordPosition="4969" endWordPosition="4972">2006b) introduced the first approach for the identification of sentences containing comparisons. Their system trains a Naive Bayes classifier for labeling sentences as comparative or noncomparative. Later works progressed into identifying the components of the comparisons: comparative predicates and arguments. For example for the sentence “Canon’s optics is better than those of Sony and Nikon.”, the extracted relation should be: (better, {optics}, {Canon}, {Sony, Nikon}). Jindal and Liu (2006a) detect such arguments by labeling sequential rules. Xu et al. (2011) use Conditional Random Fields (Lafferty et al., 2001) to extract relations between two entities, an attribute and a predicate phrase. These works all provide a rudimentary basis for computational analysis of comparatives, however, they lack depth and breadth as they are limited to the limited comparison structure (Entity1, Entity2, aspect) expressed within some sequential patterns. It is evident that the framework of comparison proposed in this paper goes beyond simple triplet annotation of comparison structures and is more representative of the linguistics literature on comparatives and measurements. The most recent related work on comparatives</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01, pages 282–289, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: A lexical database for english.</title>
<date>1995</date>
<journal>Commun. ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="17916" citStr="Miller, 1995" startWordPosition="2947" endWordPosition="2948">elf. Polarity: Base form expression of +/- quality. • JJ: Mary is tall. Positive • RB:John talks beautifully. • JJ: Susan is short. Negative • RB: Philip walks slowly. Measurement: Indicating a measurement on a scale. • JJ: Mary is 5 feet tall. Explicit • RB: Philip is driving 60mph fast. • JJ: Mary is 5 feet. Implicit • RB: Philip is driving 60mph. Table 1: The predicate types defined under our framework. Figure 1: A full annotation of a sample predicate-argument structure under the described semantic framework. tree, POS tag and lemma of two adjacent words, similarity features from WordNet (Miller, 1995), word polarity features, and most importantly ‘attribute concepts’ for words which are adjectives (Bakhshandeh and Allen, 2015). The ‘attribute concepts’ are the different properties that an adjective can describe, for instance ‘height’ and ‘thickness’ are the attributes of the adjective ‘gangling’. Last but not least, we include the conjunction of all these features. Predicting Roles and Arguments: Given the predicates, one should label the predicateargument role and predict the argument type. Here we take an approach used for semantic role labeling (Punyakanok et al., 2008): given a predica</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: A lexical database for english. Commun. ACM, 38(11):39–41, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Pradhan</author>
<author>Eduard Hovy</author>
<author>Mitch Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>Ontonotes: A unified relational semantic representation.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Semantic Computing, ICSC ’07,</booktitle>
<pages>517--526</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="22673" citStr="Pradhan et al., 2007" startWordPosition="3795" endWordPosition="3798">bels: each argument can have only Xarg max y,x Xscp,j,r yp,j,r + 1&lt;j≤n g∈G scp,j,g xp,j,g (4a) 1&lt;j≤n r∈R 998 one role and argument type (4b − 4c), each predicate can only have one of each role type (4d), a ‘None’ role type should be matched with a ‘None’ argument type (4e), and each predicate should have exactly one ‘Figure’ role (4f). There are also some other specific constraints such as the fact that a predicate labeled with ‘comparative’ cannot have a ‘Domain’ role type and vice verse. 5 Experimental Setup 5.1 Dataset Creation In order to make our gold-annotated dataset we used OntoNotes (Pradhan et al., 2007) release 5.0 corpus. OntoNotes covers various genres such as conversations, news-wire, and Weblogs, which provides distinctive variations of comparison structures in natural language. Furtheremore, we think our annotations can potentially provide augmentations on OntoNotes, so using the original OntoNotes sentences can be beneficial. One approach for pinpointing comparison sentences is to mine for some known patterns and train a classifier for distinguishing comparison and non-comparison sentences (Jindal and Liu, 2006b). However, as demonstrated earlier, the variety of comparison structures i</context>
</contexts>
<marker>Pradhan, Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2007</marker>
<rawString>Sameer Pradhan, Eduard Hovy, Mitch Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2007. Ontonotes: A unified relational semantic representation. In Proceedings of the International Conference on Semantic Computing, ICSC ’07, pages 517–526, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>The importance of syntactic parsing and inference in semantic role labeling.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="18499" citStr="Punyakanok et al., 2008" startWordPosition="3035" endWordPosition="3038">rity features from WordNet (Miller, 1995), word polarity features, and most importantly ‘attribute concepts’ for words which are adjectives (Bakhshandeh and Allen, 2015). The ‘attribute concepts’ are the different properties that an adjective can describe, for instance ‘height’ and ‘thickness’ are the attributes of the adjective ‘gangling’. Last but not least, we include the conjunction of all these features. Predicting Roles and Arguments: Given the predicates, one should label the predicateargument role and predict the argument type. Here we take an approach used for semantic role labeling (Punyakanok et al., 2008): given a predicate, we collect all constituents in the sentence to build a set of plausible candidate arguments. As a result, each predicate has a set of candidate arguments which should be labeled with their argument types and be assigned with a semantic role edge. Here we jointly train two logistic regression classifiers for predicting semantic role type and argument type of a predicate-argument pair, using argument identification features from (Punyakanok et al., 2008) and using the structured averaged Perceptron algorithm (Collins, 2002). The role types can be any of the roles from table </context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2008</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008. The importance of syntactic parsing and inference in semantic role labeling. Comput. Linguist., 34(2):257–287, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Solt</author>
</authors>
<title>Measurement scales in natural language.</title>
<date>2015</date>
<journal>Language and Linguistics Compass,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="7219" citStr="Solt, 2015" startWordPosition="1138" endWordPosition="1139">ific point on the scale of ‘tallness’. All the earlier examples are among the simplest types of comparative structures using adjectives. Consider the following example: (2) Mary is taller than the bed is long. In sentence 2 we have a case of subcomparatives, where we compare ‘Mary’ and ‘bed’ according to two different dimensions: height and length. Each dimension provides a degree, and the degrees are ultimately related by the greater than (&gt;-) relation. Scalability is known to be universal in language and a wide variety of linguistic phenomena can be explained in terms of degrees and scales (Solt, 2015). The Semantics of Scales: A fairly common view (Kennedy, 2007) is that a scale 5 is a triple of the following form: 5 = (D, &gt;-, DIM) (2) where D is a set of degrees, &gt;- is an ordering relation on D, and DIM is the dimension of measurement.2 Individuals are linked to degrees by measure functions. A measure function µS is the function that maps an individual x to the degree on the scale 5 that represents x’s measure with respect to the dimension DIM. For example, the µHEIGHT measure function is a function that maps individuals to their respective heights. Under this model, we represent the comp</context>
<context position="10224" citStr="Solt, 2015" startWordPosition="1659" endWordPosition="1660">ich x changes in coolness as a result of participating in e. The underlying scale of verbal comparatives is sometimes ambiguous, e.g., in sentence 5a it is not clear whether the women ate more in volume or in quantity. Comparative structures can also be nominal. Consider the following sentences: 3Such cases are called positive usage of the adjective. The negative (also called antonym) usage would be ‘Mary is short’. (6) a. More juniors than seniors came to the ceremony. b. We bought more milk than wine. The meaning of sentences presented above must be stated with reference to degrees as well (Solt, 2015). Hence, the scale for the comparison sentence 6a is the numerical counting by integers and the scale for sentence 6b is something corresponding to a mass dimension, here perhaps liquid volume. Adverbial comparatives share many of their characteristics with the adjectival and verbal class, which we do not develop further for brevity. For example the sentence ‘Mary ran faster than Sam’ is an example of adverbial comparison, where the implicit ‘speed’ attribute of the ‘running’ event associated with Mary and Sam is being compared. 2.2 Categories of Comparison There are various ways for making co</context>
</contexts>
<marker>Solt, 2015</marker>
<rawString>Stephanie Solt. 2015. Measurement scales in natural language. Language and Linguistics Compass, 9(1):14–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arnim Von Stechow</author>
</authors>
<title>Comparing semantic theories of comparison.</title>
<date>1984</date>
<journal>Journal of Semantics,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>77</pages>
<marker>Von Stechow, 1984</marker>
<rawString>Arnim Von Stechow. 1984. Comparing semantic theories of comparison. Journal of Semantics, 3(1):1– 77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexis Wellwood</author>
<author>V Hacquard</author>
</authors>
<title>Measuring and comparing individuals and events.</title>
<date>2012</date>
<journal>Journal of Semantics,</journal>
<volume>29</volume>
<issue>2</issue>
<marker>Wellwood, Hacquard, 2012</marker>
<rawString>Alexis Wellwood, V. Hacquard, , and R. Pancheva. 2012. Measuring and comparing individuals and events. Journal of Semantics, 29(2):207–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kaiquan Xu</author>
<author>Stephen Shaoyi Liao</author>
<author>Jiexun Li</author>
<author>Yuxia Song</author>
</authors>
<title>Mining comparative opinions from customer reviews for competitive intelligence. Decision Support Systems,</title>
<date>2011</date>
<pages>50--4</pages>
<contexts>
<context position="29704" citStr="Xu et al. (2011)" startWordPosition="4961" endWordPosition="4964"> context of sentiment analysis. Jindal and Liu (2006b) introduced the first approach for the identification of sentences containing comparisons. Their system trains a Naive Bayes classifier for labeling sentences as comparative or noncomparative. Later works progressed into identifying the components of the comparisons: comparative predicates and arguments. For example for the sentence “Canon’s optics is better than those of Sony and Nikon.”, the extracted relation should be: (better, {optics}, {Canon}, {Sony, Nikon}). Jindal and Liu (2006a) detect such arguments by labeling sequential rules. Xu et al. (2011) use Conditional Random Fields (Lafferty et al., 2001) to extract relations between two entities, an attribute and a predicate phrase. These works all provide a rudimentary basis for computational analysis of comparatives, however, they lack depth and breadth as they are limited to the limited comparison structure (Entity1, Entity2, aspect) expressed within some sequential patterns. It is evident that the framework of comparison proposed in this paper goes beyond simple triplet annotation of comparison structures and is more representative of the linguistics literature on comparatives and meas</context>
</contexts>
<marker>Xu, Liao, Li, Song, 2011</marker>
<rawString>Kaiquan Xu, Stephen Shaoyi Liao, Jiexun Li, and Yuxia Song. 2011. Mining comparative opinions from customer reviews for competitive intelligence. Decision Support Systems, 50(4):743–754.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Zelle</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to parse database queries using inductive logic programming.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirteenth National Conference on Artificial Intelligence - Volume 2, AAAI’96,</booktitle>
<pages>1050--1055</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="1388" citStr="Zelle and Mooney, 1996" startWordPosition="202" endWordPosition="205">rts not only adjectival, but also adverbial, nominal, and verbal comparatives. With this paper, we provide a novel dataset of gold-standard comparison structures annotated according to our semantic framework. 1 Introduction Representing the meaning of text has long been a focus in linguistics and deriving computational models of meaning has been pursued by various semantic tasks such as semantic parsing. Deep semantic parsing (as opposed to shallow semantic parsing, such as semantic role labeling) aims to map a sentence in natural language into its corresponding formal meaning representation (Zelle and Mooney, 1996; Berant and Liang, 2014). There has been a renewed interest in deeper semantic representations of natural language (Banarescu et al., 2013) in NLP community. Opendomain semantic representations enable inference and reasoning, which is required for many language understanding tasks such as reading comprehension tests and open-domain question answering. Comparison is a common way for expressing differences in sentiment and other properties towards some entity. Comparison can happen in very simple structures such as ‘John is taller than Sam’, or more complicated constructions such as ‘The table </context>
</contexts>
<marker>Zelle, Mooney, 1996</marker>
<rawString>John M. Zelle and Raymond J. Mooney. 1996. Learning to parse database queries using inductive logic programming. In Proceedings of the Thirteenth National Conference on Artificial Intelligence - Volume 2, AAAI’96, pages 1050–1055. AAAI Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>