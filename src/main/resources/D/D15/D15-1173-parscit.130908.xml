<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001870">
<title confidence="0.996558">
Efficient and Expressive Knowledge Base Completion
Using Subgraph Feature Extraction
</title>
<author confidence="0.988667">
Matt Gardner and Tom Mitchell
</author>
<affiliation confidence="0.988292">
Carnegie Mellon University
</affiliation>
<email confidence="0.993487">
mg1@cs.cmu.edu, tom.mitchell@cmu.edu
</email>
<sectionHeader confidence="0.997329" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999993869565217">
We explore some of the practicalities
of using random walk inference meth-
ods, such as the Path Ranking Algorithm
(PRA), for the task of knowledge base
completion. We show that the random
walk probabilities computed (at great ex-
pense) by PRA provide no discernible
benefit to performance on this task, so they
can safely be dropped. This allows us
to define a simpler algorithm for gener-
ating feature matrices from graphs, which
we call subgraph feature extraction (SFE).
In addition to being conceptually simpler
than PRA, SFE is much more efficient, re-
ducing computation by an order of mag-
nitude, and more expressive, allowing for
much richer features than paths between
two nodes in a graph. We show experi-
mentally that this technique gives substan-
tially better performance than PRA and its
variants, improving mean average preci-
sion from .432 to .528 on a knowledge
base completion task using the NELL KB.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999912054545455">
Knowledge bases (KBs), such as Freebase (Bol-
lacker et al., 2008), NELL (Mitchell et al., 2015),
and DBPedia (Mendes et al., 2012) contain large
collections of facts about things, people, and
places in the world. These knowledge bases are
useful for various tasks, including training rela-
tion extractors and semantic parsers (Hoffmann et
al., 2011; Krishnamurthy and Mitchell, 2012), and
question answering (Berant et al., 2013). While
these knowledge bases may be very large, they are
still quite incomplete, missing large percentages
of facts about common or popular entities (West et
al., 2014; Choi et al., 2015). The task of knowl-
edge base completion—filling in missing facts by
examining the facts already in the KB, or by look-
ing in a corpus—is one attempt to mitigate the
problems of this knowledge sparsity.
In this work we examine one method for
performing knowledge base completion that is
currently in use: the Path Ranking Algorithm
(PRA) (Lao et al., 2011; Dong et al., 2014). PRA
is a method for performing link prediction in a
graph with labeled edges by computing feature
matrices over node pairs in the graph. The method
has a strong connection to logical inference (Gard-
ner et al., 2015), as the feature space considered by
PRA consists of a restricted class of horn clauses
found in the graph. While PRA can be applied
to any link prediction task in a graph, its primary
use has been in KB completion (Lao et al., 2012;
Gardner et al., 2013; Gardner et al., 2014).
PRA is a two-step process, where the first step
finds potential path types between node pairs to
use as features in a statistical model, and the sec-
ond step computes random walk probabilities as-
sociated with each path type and node pair (these
are the values in a feature matrix). This second
step is very computationally intensive, requiring
time proportional to the average out-degree of the
graph to the power of the path length for each cell
in the computed feature matrix. In this paper we
consider whether this computational effort is well-
spent, or whether we might more profitably spend
computation in other ways. We propose a new way
of generating feature matrices over node pairs in a
graph that aims to improve both the efficiency and
the expressivity of the model relative to PRA.
Our technique, which we call subgraph fea-
ture extraction (SFE), is similar to only doing the
first step of PRA. Given a set of node pairs in a
graph, we first do a local search to characterize
the graph around each node. We then run a set
of feature extractors over these local subgraphs to
obtain feature vectors for each node pair. In the
simplest case, where the feature extractors only
</bodyText>
<page confidence="0.94397">
1488
</page>
<note confidence="0.9847785">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1488–1498,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999721133333333">
look for paths connecting the two nodes, the fea-
ture space is equivalent to PRA’s, and this is the
same as running PRA and binarizing the resultant
feature vectors. However, because we do not have
to compute random walk probabilities associated
with each path type in the feature matrix, we can
extract much more expressive features, including
features which are not representable as paths in the
graph at all. In addition, we can do a more exhaus-
tive search to characterize the local graph, using a
breadth-first search instead of random walks. SFE
is a much simpler method than PRA for obtaining
feature matrices over node pairs in a graph. De-
spite its simplicity, however, we show experimen-
tally that it substantially outperforms PRA, both in
terms of running time and prediction performance.
SFE decreases running time over PRA by an order
of magnitude, it improves mean average precision
from .432 to .528 on the NELL KB, and it im-
proves mean reciprocal rank from .850 to .933.
In the remainder of this paper, we first describe
PRA in more detail. We then situate our meth-
ods in the context of related work, and provide ad-
ditional experimental motivation for the improve-
ments described in this paper. We then formally
define SFE and the feature extractors we used,
and finally we present an experimental compari-
son between PRA and SFE on the NELL KB. The
code and data used in this paper is available at
http://rtw.ml.cmu.edu/emnlp2015 sfe/.
</bodyText>
<sectionHeader confidence="0.98695" genericHeader="introduction">
2 The Path Ranking Algorithm
</sectionHeader>
<bodyText confidence="0.999943806451614">
The path ranking algorithm was introduced by Lao
and Cohen (2010). It is a two-step process for gen-
erating a feature matrix over node pairs in a graph.
The first step finds a set of potentially useful path
types that connect the node pairs, which become
the columns of the feature matrix. The second step
then computes the values in the feature matrix by
finding random walk probabilities as described be-
low. Once the feature matrix has been computed,
it can be used with whatever classification model
is desired (or even incorporated as one of many
factors in a structured prediction model), though
almost all prior work with PRA simply uses logis-
tic regression.
More formally, consider a graph G with nodes
N, edges E, and edge labels R, and a set of node
pairs (sj, tj) E D that are instances of some rela-
tionship of interest. PRA will generate a feature
vector for each (sj, tj) pair, where each feature is
some sequence of edge labels -e1-e2-...-el-. If the
edge sequence, or path type, corresponding to the
feature exists between the source and target nodes
in the graph, the value of that feature in the feature
vector will be non-zero.
Because the feature space considered by PRA
is so large,1 and because computing the feature
values is so computationally intensive, the first
step PRA must perform is feature selection, which
is done using random walks over the graph. In
this step of PRA, we find path types 7r that are
likely to be useful in predicting new instances of
the relation represented by the input node pairs.
These path types are found by performing random
walks on the graph G starting at the source and
target nodes in D and recording which paths con-
nect some source node with its target.2 Note that
these are two-sided, unconstrained random walks:
the walks from sources and targets can be joined
on intermediate nodes to get a larger set of paths
that connect the source and target nodes. Once
connectivity statistics have been computed in this
way, k path types are selected as features. Lao et
al. (2011) use measures of the precision and recall
of each feature in this selection, while Gardner et
al. (2014) simply pick those most frequently seen.
Once a set of path features has been selected,
the second step of PRA is to compute values for
each cell in the feature matrix. Recall that rows
in this matrix correspond to node pairs, and the
columns correspond to the path types found in the
first step. The cell value assigned by PRA is the
probability of arriving at the target node of a node
pair, given that a random walk began at the source
node and was constrained to follow the path type:
p(t|s, 7r). There are several ways of computing
this probability. The most straightforward method
is to use a path-constrained breadth-first search to
exhaustively enumerate all possible targets given a
source node and a path type, count how frequently
each target is seen, and normalize the distribution.
This calculates the desired probability exactly, but
at the cost of doing a breadth-first search (with
</bodyText>
<footnote confidence="0.9995658">
1The feature space consists of the set of all possible edge
label sequences, with cardinality El&apos;=1 |R|&apos;, assuming a
bound l on the maximum path length.
2A deterministic algorithm, such as a breadth-first search,
could obviously be used here instead of random walks, and
indeed Lao’s original work did use a more exhaustive search.
However, when moving to the larger graphs corresponding
to the NELL and Freebase KBs, Lao (2011) (and all future
work) switched to using random walks, because the graph
was too large.
</footnote>
<page confidence="0.997166">
1489
</page>
<bodyText confidence="0.999984488888889">
complexity proportional to the average per-edge-
label out-degree to the power of the path length)
per source node per path type.
There are three methods that can potentially re-
duce the computational complexity of this proba-
bility calculation. The first is to use random walks
to approximate the probability via rejection sam-
pling: for each path type and source node, a num-
ber of random walks are performed, attempting
to follow the edge sequence corresponding to the
path type. If a node is reached where it is no
longer possible to follow the path type, the ran-
dom walk is restarted. This does not reduce the
time necessary to get an arbitrarily good approxi-
mation, but it does allow us to decrease computa-
tion time, even getting a fixed complexity, at the
cost of accepting some error in our probability es-
timates. Second, Lao (2012) showed that when the
target node of a query is known, the exponent can
be cut in half by using a two-sided BFS. In this
method, some careful bookkeeping is done with
dynamic programming such that the probability
can be computed correctly when the two-sided
search meets at an intermediate node. Lao’s dy-
namic programming technique is only applicable
when the target node is known, however, and only
cuts the exponent in half—this is still quite compu-
tationally intensive. Lastly, we could replace the
BFS with a multiplication of adjacency matrices,
which performs the same computation. The effi-
ciency gain comes from the fact that we can just
do the multiplication once per path type, instead of
once per path type per source node. However, to
correctly compute the probabilities for a (source,
target) pair, we need to exclude from the graph the
edge connecting that training instance. This means
that the matrix computed for each path type should
be different for each training instance, and so we
either lose our efficiency gain or we accept incor-
rect probability estimates. In this work we use the
rejection sampling technique.
As mentioned above, once the feature matrix
has been computed in the second step of PRA, one
can use any kind of classifier desired to learn a
model and make predictions on test data.
</bodyText>
<sectionHeader confidence="0.999974" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999879290909091">
The task of knowledge base completion has seen
a lot of attention in recent years, with entire work-
shops devoted to it (Suchanek et al., 2013). We
will touch on three broad categories related to KB
completion: the task of relation extraction, embed-
ding methods for KB completion, and graph meth-
ods for KB completion.
Relation extraction. Relation extraction and
knowledge base completion have the same goal:
to predict new instances of relations in a formal
knowledge base such as Freebase or NELL. The
difference is that relation extraction focuses on de-
termining what relationship is expressed by a par-
ticular sentence, while knowledge base comple-
tion tries to predict which relationships hold be-
tween which entities. A relation extraction system
can be used for knowledge base completion, but
typical KB completion methods do not make pre-
dictions on single sentences. This is easily seen
in the line of work known as distantly-supervised
relation extraction (Mintz et al., 2009; Hoffmann
et al., 2011; Surdeanu et al., 2012); these models
use the relation instances in a knowledge base as
their only supervision, performing some heuristic
mapping of the entities in text to the knowledge
base, then using that mapping to train extractors
for each relation in the KB. The cost of using these
methods is that is it generally difficult to incorpo-
rate richer features from the knowledge base when
predicting whether a particular sentence expresses
a relation, and so techniques that make fuller use
of the KB can perform better on the KB comple-
tion task (Weston et al., 2013; Riedel et al., 2013).
Embedding methods for KB completion.
There has been much recent work that attempts
to perform KB completion by learning an embed-
ded representation of entities and relations in the
KB and then using these representations to infer
missing relationships. Some of earliest work along
these lines were the RESCAL model (Nickel et al.,
2011) and Structured Embeddings (Bordes et al.,
2011). These were soon followed by TransE (Bor-
des et al., 2013), Neural Tensor Networks (Socher
et al., 2013), and many variants on all of these
algorithms (Chang et al., 2014; Garcia-Dur´an et
al., 2014; Wang et al., 2014). These methods
perform well when there is structural redundancy
in the knowledge base tensor, but when the ten-
sor (or individual relations in the tensor) has high
rank, learning good embeddings can be challeng-
ing. The ARE model (Nickel et al., 2014) at-
tempted to address this by only making the em-
beddings capture the residual of the tensor that
cannot be readily predicted from the graph-based
techniques mentioned below.
</bodyText>
<page confidence="0.959638">
1490
</page>
<table confidence="0.9968386">
Dataset Method MAP
Freebase Probabilities .337
Binarized .344
NELL Probabilities .303
Binarized .319
</table>
<tableCaption confidence="0.998683">
Table 1: Using binary feature values instead of
</tableCaption>
<bodyText confidence="0.97898075">
random walk probabilities gives statistically in-
distinguishable performance. The p-value on the
Freebase data is .55, while it is .25 for NELL.
Graph-based methods for KB completion. A
separate line of research into KB completion can
be broadly construed as performing some kind of
inference over graphs in order to predict missing
instances in a knowledge base. Markov logic net-
works (Richardson and Domingos, 2006) fall into
this category, as does ProPPR (Wang et al., 2013)
and many other logic-based systems. PRA, the
main subject of this paper, also fits in this line
of work. Work specifically with PRA has ranged
from incorporating a parsed corpus as additional
evidence when doing random walk inference (Lao
et al., 2012), to introducing better representations
of the text corpus (Gardner et al., 2013; Gardner
et al., 2014), and using PRA in a broader context
as part of Google’s Knowledge Vault (Dong et al.,
2014). An interesting piece of work that combines
embedding methods with graph-based methods is
that of Neelakantan et al. (2015), which uses a re-
cursive neural network to create embedded repre-
sentations of PRA-style paths.
</bodyText>
<sectionHeader confidence="0.995383" genericHeader="method">
4 Motivation
</sectionHeader>
<bodyText confidence="0.983344854545455">
We motivate our modifications to PRA with three
observations. First, it appears that binarizing the
feature matrix produced by PRA, removing most
of the information gained in PRA’s second step,
has no significant impact on prediction perfor-
mance in knowledge base completion tasks. We
show this on the NELL KB and the Freebase KB in
Table 1.3 The fact that random walk probabilities
carry no additional information for this task over
binary features is surprising, and it shows that the
second step of PRA spends a lot of its computation
for no discernible gain in performance.
Second, Neelakantan et al. (2015) presented ex-
3The NELL data and experimental protocol is described
in Section 6.1. The Freebase data consists of 24 relations
from the Freebase KB; we used the same data used by Gard-
ner et al. (2014).
periments showing a substantial increase in perfor-
mance from using a much larger set of features in
a PRA-like model.4 All of their experiments used
binary features, so this is not a direct comparison
of random walk probabilities versus binarized fea-
tures, but it shows that increasing the feature size
beyond the point that is computationally feasible
with random walk probabilities seems useful. Ad-
ditionally, they showed that using path bigram fea-
tures, where each sequential pair of edges types in
each path was added as an additional feature to the
model, gave a significant increase in performance.
These kind of features are not representable in the
traditional formulation of PRA.
Lastly, the method used to compute the random
walk probabilities—rejection sampling—makes
the inclusion of more expressive features problem-
atic. Consider the path bigrams mentioned above;
one could conceivably compute a probability for a
path type that only specifies that the last edge type
in the path must be r, but it would be incredibly
inefficient with rejection sampling, as most of the
samples would end up rejected (leaving aside the
additional issues of an unspecified path length). In
contrast, if the features simply signify whether a
particular path type exists in the graph, without
any associated probability, these kinds of features
are very easy to compute.
Given this motivation, our work attempts to im-
prove both the efficiency and the expressivity of
PRA by removing the second step of the algo-
rithm. Efficiency is improved because the sec-
ond step is the most computationally expensive,
and expressivity is improved by allowing features
that cannot be reasonably computed with rejec-
tion sampling. We show experimentally that the
techniques we introduce do indeed improve per-
formance quite substantially.
</bodyText>
<sectionHeader confidence="0.956937" genericHeader="method">
5 Subgraph Feature Extraction
</sectionHeader>
<bodyText confidence="0.982096666666667">
In this section we discuss how SFE constructs fea-
ture matrices over node pairs in a graph using
just a single search over the graph for each node
(which is comparable to only using the first step
of PRA). As outlined in Section 2, the first step
of PRA does a series of random walks from each
source and target node (sj, tj) in a dataset D. In
4Note that while Neelakantan et al. called the baseline
they were comparing to “PRA&apos;, they only used the first step
of the algorithm to produce path types, and thus did not really
compare against PRA per se. It is their version of “PRA&apos; that
we formalize and expand as SFE in this work.
</bodyText>
<page confidence="0.953887">
1491
</page>
<bodyText confidence="0.999969">
PRA these random walks are used to find a rela-
tively small set of potentially useful path types for
which more specific random walk probabilities are
then computed, at great expense. In our method,
subgraph feature extraction (SFE), we stop after
this first set of random walks and instead construct
a binary feature matrix.
More formally, for each node n in the data
(where n could be either a source node or a target
node), SFE constructs a subgraph centered around
that node using k random walks. Each random
walk that leaves n follows some path type 7r and
ends at some intermediate node i. We keep all
of these (7r, i) pairs as the characterization of the
subgraph around n, and we will refer to this sub-
graph as Gn. To construct a feature vector for
a source-target pair (sj, tj), SFE takes the sub-
graphs G,, and Gtr and merges them on the in-
termediate nodes i. That is, if an intermediate
node i is present in both G,, and Gtr, SFE takes
the path types 7r corresponding to i and combines
them (reversing the path type coming from the tar-
get node tj). If some intermediate node for the
source sj happens to be tj, no combination of path
types is necessary (and similarly if an intermediate
node for the target tj is sj—the path only needs to
be reversed in this case). This creates a feature
space that is exactly the same as that constructed
by PRA: sequences of edge types that connect a
source node to a target node. To construct the fea-
ture vector SFE just takes all of these combined
path types as binary features for (sj, tj). Note,
however, that we need not restrict ourselves to
only using the same feature space as PRA; Sec-
tion 5.1 will examine extracting more expressive
features from these subgraphs.
This method for generating a feature matrix
over node pairs in a graph is much simpler and less
computationally expensive than PRA, and from
looking at Table 1 we would expect that it would
perform on par with PRA with drastically reduced
computation costs. Some experimentation shows
that it is not that simple. Table 2 shows a com-
parison between PRA and SFE on 10 NELL rela-
tions.5 SFE has a higher mean average precision,
but the difference is not statistically significant.
There is a large variance in SFE’s performance,
and on some relations PRA performs better.
We examined the feature matrices computed
</bodyText>
<tableCaption confidence="0.456296">
5The data and evaluation methods are described more
fully in Section 6.1. These experiments were conducted on
a different development split of the same data.
</tableCaption>
<table confidence="0.947434">
Method MAP Ave. Features
PRA .3704 835
SFE .4007 8275
</table>
<tableCaption confidence="0.736273">
Table 2: Comparison of PRA and SFE on 10
NELL relations. The difference shown is not sta-
tistically significant.
</tableCaption>
<bodyText confidence="0.999833930232559">
by these methods and discovered that the reason
for the inconsistency of SFE’s improvement is
because its random walks are all unconstrained.
Consider the case of a node with a very high de-
gree, say 1000. If we only do 200 random walks
from this node, we cannot possibly get a complete
characterization of the graph even one step away
from the node. If a particularly informative path is
&lt;CITYINSTATE, STATEINCOUNTRY&gt;, and both
the city from which a random walk starts and the
intermediate state node have very high degree, the
probability of actually finding this path type using
unconstrained random walks is quite low. This is
the benefit gained by the path-constrained random
walks performed by PRA; PRA leverages training
instances with relatively low degree and aggrega-
tion across a large number of instances to find path
types that are potentially useful. Once they are
found, significant computational effort goes into
discovering whether each path type exists for all
(s, t) pairs. It is this computational effort that
allows the path type &lt;CITYINSTATE, STATEIN-
COUNTRY&gt; to have a non-zero value even for
very highly connected nodes.
How do we mitigate this issue, so that SFE can
consistently find these path types? It seems the
only option without resorting to a similar two-step
process to what PRA uses is to do a more exhaus-
tive search. PRA uses random walks to improve
scalability on very large graphs, particularly be-
cause the second step of the algorithm is so ex-
pensive. However, if we are only doing a single
search, and the graph fits in memory, a few steps of
a breadth-first search (BFS) per node is not infea-
sible. We can make the BFS more tractable by ex-
cluding edge types whose fan out is too high. For
example, at a type node in Freebase, there could be
thousands of edges of type /TYPE/OBJECT/TYPE;
if there are a large number of edges of the same
type leaving a node, we do not include those edges
in the BFS. Note that because the type node will
still be counted as an intermediate node in the sub-
graph, we can still find paths that go through that
</bodyText>
<page confidence="0.928588">
1492
</page>
<table confidence="0.984678125">
ALIAS
ALIAS
Method MAP Ave. Features Time
PRA .3704 835 44 min.
SFE-RW .4007 8275 6 min.
SFE-BFS .4799 237853 5 min.
“is married to”
“Barack Obama” “Michelle Obama”
</table>
<tableCaption confidence="0.998598">
Table 3: Comparison of PRA and SFE (with PRA-
</tableCaption>
<bodyText confidence="0.994736833333333">
style features) on 10 NELL relations. SFE-RW is
not statistically better than PRA, but SFE-BFS is
(p &lt; 0.05).
node; we just do not continue searching if the out-
degree of a particular edge type is too high.
When using a BFS instead of random walks to
obtain the subgraphs G3� and Gtr for each node
pair, we saw a dramatic increase in the number of
path type features found and a substantial increase
in performance.6 These results are shown in Ta-
ble 3; SFE-RW is our SFE implementation using
random walks, and SFE-BFS uses a BFS.
</bodyText>
<subsectionHeader confidence="0.993394">
5.1 More expressive features
</subsectionHeader>
<bodyText confidence="0.999621035714286">
The description above shows how to recreate the
feature space used by PRA using our simpler sub-
graph feature extraction technique. As we have
mentioned, however, we need not restrict our-
selves to merely recreating PRA’s feature space.
Eliminating random walk probabilities allows us
to extract a much richer set of features from the
subgraphs around each node, and here we present
the feature extractors we have experimented with.
Figure 1 contains an example graph that we will
refer to when describing these features.
PRA-style features. We explained these fea-
tures in Section 5, but we repeat them here for con-
sistency, and use the example to make the feature
extraction process more clear. Relying on the no-
tation introduced earlier, these features are gener-
ated by intersecting the subgraphs G3 and Gt on
the intermediate nodes. That is, when the sub-
graphs share an intermediate node, we combine
the path types found from the source and target to
that node. In the example in Figure 1, there are two
common intermediate nodes (“Barack Obama”
and “Michelle Obama”), and combining the path
types corresponding to those nodes gives the same
path type: -ALIAS-“is married to”-ALIAS-1-.
Path bigram features. In Section 4, we
mentioned that Neelakantan et al. (2015) experi-
mented with using path bigrams as features. We
</bodyText>
<footnote confidence="0.880525">
6One should not read too much into the decrease in run-
ning time between SFE-RW and SFE-BFS, however, as it was
mostly an implementation detail.
</footnote>
<table confidence="0.890136076923077">
/m/Barack Obama /m/Michelle Obama
GENDER
/m/Male /m/Female
Subgraph for /m/Barack Obama
7r i
-ALIAS- “Barack Obama”
-GENDER- /m/Male
-ALIAS-“is married to”- “Michelle Obama”
Subgraph for /m/Michelle Obama
7r i
-ALIAS- “Michelle Obama”
-GENDER- /m/Female
-ALIAS-“is married to”-1- “Barack Obama”
</table>
<figureCaption confidence="0.975835">
Figure 1: An example graph, with subgraphs ex-
tracted for two nodes.
</figureCaption>
<bodyText confidence="0.997725758620689">
include those features here as well. For any path
7r between a source node s and a target node t, we
create a feature for each relation bigram in the path
type. In the example in Figure 1, this would result
in the features “BIGRAM:@START@-ALIAS”,
“BIGRAM:ALIAS-is married to”, “BIGRAM:is
married to-ALIAS”, and “BIGRAM:ALIAS-
@END@”.
One-sided features. We use one-sided path to
describe a sequence of edges that starts at a source
or target node in the data, but does not necessarily
terminate at a corresponding target or source node,
as PRA features do. Following the notation intro-
duced in Section 5, we use as features each (7r,
i) pair in the subgraph characterizations G3 and
Gt, along with whether the feature came from the
source node or the target node. The motivation
for these one-sided path types is to better model
which sources and targets are good candidates for
participating in a particular relation. For example,
not all cities participate in the relation CITYCAPI-
TALOFCOUNTRY, even though the domain of the
relation is all cities. A city that has a large number
of sports teams may be more likely to be a capi-
tal city, and these one-sided features could easily
capture that kind of information.
Example one-sided features from the ex-
ample in Figure 1 would be “SOURCE:-
GENDER-:male”, “TARGET:-GENDER-:female”,
</bodyText>
<equation confidence="0.346665">
GENDER
</equation>
<page confidence="0.922683">
1493
</page>
<bodyText confidence="0.999288963855422">
“SOURCE:-ALIAS-:Barack Obama”, and
“SOURCE:-ALIAS-is married to-:Michelle
Obama”.
One-sided feature comparisons. We can ex-
pand on the one-sided features introduced above
by allowing for comparisons of these features in
certain circumstances. For example, if both the
source and target nodes have an age or gender en-
coded in the graph, we might profitably use com-
parisons of these values to make better predictions.
Drawing again on the notation from Section 5,
we can formalize these features as analogous to
the pairwise PRA features. To get the PRA
features, we intersect the intermediate nodes i
from the subgraphs Gs and Gt, and combine the
path types π when we find common intermediate
nodes. To get these comparison features, we in-
stead intersect the subgraphs on the path types,
and combine the intermediate nodes when there
are common path types. That is, if we see a com-
mon path type, such as -GENDER-, we will con-
struct a feature representing a comparison between
the intermediate node for the source and the target.
If the values are the same, this information can be
captured with a PRA feature, but it cannot be eas-
ily captured by PRA when the values are different.
In the example in Figure 1, there are two
common path types: -ALIAS-, and-GENDER-
. The feature generated from the path type -
GENDER- would be “COMPARISON:-GENDER-
:/m/Male:/m/Female”.
Vector space similarity features. Gardner et
al. (2014) introduced a modification of PRA’s ran-
dom walks to incorporate vector space similarity
between the relations in the graph. On the data
they were using, a graph that combined a formal
knowledge base with textual relations extracted
from text, they found that this technique gave a
substantial performance improvement. The vector
space random walks only affected the second step
of PRA, however, and we have removed that step
in SFE. While it is not as conceptually clean as
the vector space random walks, we can obtain a
similar effect with a simple feature transformation
using the vectors for each relation. We obtain vec-
tor representations of relations through factoriza-
tion of the knowledge base tensor as did Gardner
et al., and replace each edge type in a PRA-style
path with edges that are similar to it in the vec-
tor space. We also introduce a special “any edge”
symbol, and say that all other edge types are simi-
lar to this edge type.
To reduce the combinatorial explosion of the
feature space that this feature extractor cre-
ates, we only allow replacing one relation at
a time with a similar relation. In the ex-
ample graph in Figure 1, and assuming that
“spouse of” is found to be similar to “is mar-
ried to”, some of the features extracted would be
the following: “VECSIM:-ALIAS-is married to-
ALIAS-”, “VECSIM:-ALIAS-spouse of-ALIAS-”,
“VECSIM:-ALIAS-@ANY REL@-ALIAS-”, and
“VECSIM:-@ANY REL@-is married to-ALIAS-
”. Note that the first of those features, “VECSIM:-
ALIAS-is married to-ALIAS-”, is necessary even
though it just duplicates the original PRA-style
feature. This allows path types with different but
similar relations to generate the same features.
Any-Relation features. It turns out that
much of the benefit gained from Gardner et
al.’s vector space similarity features came from
allowing any path type that used a surface edge
to match any other surface edge with non-zero
probability.7 To test whether the vector space
similarity features give us any benefit over just
replacing relations with dummy symbols, we
add a feature extractor that is identical to the
one above, assuming an empty vector similarity
mapping. The features extracted from Figure 1
would thus be “ANYREL:-@ANY REL@-
is married to-ALIAS”, “ANYREL:-ALIAS-
@ANY REL@-ALIAS”, “ANYREL:-ALIAS-is
married to-@ANY REL@”.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999955285714286">
Here we present experimental results evaluating
the feature extractors we presented, and a com-
parison between SFE and PRA. As we showed in
Section 5 that using a breadth-first search to ob-
tain subgraphs is superior to using random walks,
all of the experiments presented here use the BFS
implementation of SFE.
</bodyText>
<subsectionHeader confidence="0.997597">
6.1 Data
</subsectionHeader>
<bodyText confidence="0.9999344">
To evaluate SFE and the feature extractors we in-
troduced, we learned models for 10 relations in
the NELL KB. We used the same data as Gardner
et al. (2014), using both the formal KB relations
and the surface relations extracted from text in our
</bodyText>
<footnote confidence="0.974193">
7Replacing all surface edges with a single dummy rela-
tion gives performance close to vector space PRA. The vec-
tor space walks do statistically outperform this, but the extra
gain is small.
</footnote>
<page confidence="0.994849">
1494
</page>
<bodyText confidence="0.9999285">
graph. We used logistic regression with elastic net
(L1 and L2) regularization. We tuned the L1 and
L2 parameters for each method on a random de-
velopment split of the data, then used a new split
of the data to run the final tests presented here.
The evaluation metrics we use are mean aver-
age precision (MAP) and mean reciprocal rank
(MRR). We judge statistical significance using a
paired permutation test, where the average preci-
sion8 on each relation is used as paired data.
</bodyText>
<subsectionHeader confidence="0.999663">
6.2 On Obtaining Negative Evidence
</subsectionHeader>
<bodyText confidence="0.999986459459459">
One important practical issue for most uses of
PRA is the selection of negative examples for
training a model. Typically a knowledge base only
contains positive examples of a relation, and it is
not clear a priori what the best method is for ob-
taining negative evidence. Prior work with PRA
makes a closed world assumption, treating any (s,
t) pair not seen in the knowledge base as a negative
example. Negative instances are selected when
performing the second step of PRA—if a random
walk from a source ends at a target that is not a
known correct target for that source, that source-
target pair is used as a negative example.
SFE only scores (source, target) pairs; it has no
mechanism similar to PRA’s that will find poten-
tial targets given a source node. We thus need
a new way of finding negative examples, both at
training time and at test time. We used a simple
technique to find negative examples from a graph
given a set of positive examples, and we used
this to obtain the training and testing data used in
the experiments below. Our technique takes each
source and target node in the given positive exam-
ples and finds other nodes in the same category
that are close in terms of personalized page rank
(PPR). We then sample new (source, target) pairs
from these lists of similar nodes, weighted by their
PPR score (while also allowing the original source
and target to be sampled). These become our neg-
ative examples, both at training and at testing time.
Because this is changing the negative evidence
available to PRA at training time, we wanted to be
sure we were not unfairly hindering PRA in our
comparisons. If it is in fact better to let PRA find
its own negative examples at training time, instead
of the ones sampled based on personalized page
rank, then we should let PRA get its own nega-
</bodyText>
<footnote confidence="0.97873">
8Average precision is equivalent to the area under a preci-
sion/recall curve.
</footnote>
<table confidence="0.990065">
Method MAP
PRA’s random walks .359
PPR-based sampling .363
</table>
<tableCaption confidence="0.994069">
Table 4: Comparing methods for obtaining nega-
</tableCaption>
<bodyText confidence="0.940718764705882">
tive evidence available at training time. The differ-
ence seen is not statistically significant (p = .77).
tive evidence. We thus ran an experiment to see
under which training regime PRA performs bet-
ter. We created a test set with both positive and
negative examples as described in the paragraph
above, and at training time we compared two tech-
niques: (1) letting PRA find its own negative ex-
amples through its random walks, and (2) only
using the negative examples selected by PPR. As
can be seen in Table 4, the difference between the
two training conditions is very small, and it is not
statistically significant. Because there is no sig-
nificant difference between the two conditions, in
the experiments that follow we give both PRA and
SFE the same training data, created through the
PPR-based sampling technique described above.
</bodyText>
<subsectionHeader confidence="0.896334">
6.3 Results
</subsectionHeader>
<bodyText confidence="0.999985904761905">
We first examine the effect of each of the fea-
ture types introduced in Section 5.1. The results
are shown in Table 5. We can see that, for this
data, the comparisons and one-sided features did
not improve performance (and the decreases are
not statistically significant). Bigram features do
appear to improve performance, though the im-
provement was not consistent enough across rela-
tions to achieve statistical significance. The vector
similarity features do improve performance, with
p-values hovering right at 0.05 when comparing
against only PRA features and PRA + bigram fea-
tures. The any rel features, however, do statisti-
cally improve over all other methods (p &lt;= 0.01)
except the PRA + vec sim result (p = .21).
Finally, we present a comparison between PRA,
PRA with vector space random walks, and the best
SFE result from the ablation study. This is shown
in Table 6. SFE significantly outperforms PRA,
both with and without the vector space random
walks presented by Gardner et al. (2014).
</bodyText>
<subsectionHeader confidence="0.952734">
6.4 Discussion
</subsectionHeader>
<bodyText confidence="0.999579">
When using only PRA-style features with SFE,
the highest weighted features were almost always
those of the form -ALIAS-[some textual relation]-
ALIAS-1-. For example, for the relation WRITER-
</bodyText>
<page confidence="0.962407">
1495
</page>
<table confidence="0.998846111111111">
Feature Types MAP MRR Features
PRA-style features .431 .806 240k
+ Comparisons .405 .833 558k
+ One-sided .389 .800 1,227k
+ One-sided + Comps. .387 .817 1,544k
+ Bigrams .483 1.00 320k
+ Vector similarity .514 .910 3,993k
+ Bigrams + vec sim. .490 .950 4,073k
+ Any Rel .528 .933 649k
</table>
<tableCaption confidence="0.9705165">
Table 5: SFE feature ablation study. All rows use
PRA features. PRA + any rel is statistically better
than all other methods except PRA + vec sim, and
most of the other differences are not significant.
</tableCaption>
<table confidence="0.999455">
Method MAP MRR
PRA .362 .717
Vector space PRA .432 .850
SFE (PRA + any rel features) .528 .933
</table>
<tableCaption confidence="0.967421">
Table 6: Results of final comparison between SFE
</tableCaption>
<bodyText confidence="0.976411351851852">
and PRA, with and without vector space similarity
features. SFE is statistically better than both PRA
methods (p &lt; 0.005).
WROTEBOOK, the textual relations used in this
feature might be “wrote”, “describes in”, “writes
in”, and “expresses in”. These are the same fea-
ture types that PRA itself finds to have the high-
est weight, also, though SFE finds many more of
them than PRA does, as PRA has to do aggres-
sive feature selection. For this particular dataset,
where the graph consists of edges from a formal
KB mixed with edges from extracted textual rela-
tions, these kinds of features are by far the most
useful, and most of the improvements seen by the
additional feature types we used with SFE come
from more compactly encoding these features.
For example, the path bigram features can en-
code the fact that there exists a path from the
source to the target that begins or ends with an
ALIAS edge. This captures in just two features
all path types of the form -ALIAS-[some textual
relation]-ALIAS-1-, and those two bigram features
are almost always the highest weighted features in
models where they are used.
However, the bigram features do not capture
those path types exactly. The Any-Rel features
were designed in part specifically for this path
type, and they capture it exactly with a single fea-
ture. For all 10 relations, the feature “ANYREL:-
ALIAS-@ANY REL@-ALIAS-1” is the highest
weighted feature. This is because, for the relations
we experimented with, knowing that some rela-
tionship is expressed in text between a particular
pair of KB entities is a very strong indication of a
single KB relation. There are only so many possi-
ble relationships between cities and countries, for
instance. These features are much less informative
between entity types where more than one relation
is possible, such as between people.
While the bigram and any-rel features capture
succintly whether textual relations are present be-
tween two entities, the one-sided features are more
useful for determining whether an entity fits into
the domain or range of a particular relation. We
saw a few features that did this, capturing fine-
grained entity types. Most of the features, how-
ever, tended towards memorizing (and thus over-
fitting) the training data, as these features con-
tained the names of the training entities. We be-
lieve this overfitting to be the main reason these
features did not improve performance, along with
the fact that the relations we tested do not need
much domain or range modeling (as opposed to,
e.g., SPOUSEOF or CITYCAPITALOFCOUNTRY).
</bodyText>
<sectionHeader confidence="0.99901" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999854222222222">
We have explored several practical issues that
arise when using the path ranking algorithm for
knowledge base completion. An analysis of sev-
eral of these issues led us to propose a sim-
pler algorithm, which we called subgraph fea-
ture extraction, which characterizes the subgraph
around node pairs and extracts features from that
subgraph. SFE is both significantly faster and
performs better than PRA on this task. We
showed experimentally that we can reduce run-
ning time by an order of magnitude, while at
the same time improving mean average preci-
sion from .432 to .528 and mean reciprocal rank
from .850 to .933. This thus constitutes the
best published results for knowledge base com-
pletion on NELL data. The code and data used
in the experiments in this paper are available at
http://rtw.ml.cmu.edu/emnlp2015 sfe/.
</bodyText>
<sectionHeader confidence="0.997785" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.977215">
This work was supported in part by NSF
grant IIS1247489, in part by support as a Ya-
hoo! Fellow, and in part by DARPA contract
FA87501320005.
</bodyText>
<page confidence="0.991055">
1496
</page>
<sectionHeader confidence="0.996285" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999909339449542">
Jonathan Berant, Andrew Chou, Roy Frostig, and Percy
Liang. 2013. Semantic parsing on freebase from
question-answer pairs. In EMNLP, pages 1533–
1544.
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a col-
laboratively created graph database for structuring
human knowledge. In Proceedings of SIGMOD.
Antoine Bordes, Jason Weston, Ronan Collobert,
Yoshua Bengio, et al. 2011. Learning structured
embeddings of knowledge bases. In AAAI.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-
Duran, Jason Weston, and Oksana Yakhnenko.
2013. Translating embeddings for modeling multi-
relational data. In Advances in Neural Information
Processing Systems, pages 2787–2795.
Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and
Christopher Meek. 2014. Typed tensor decom-
position of knowledge bases for relation extrac-
tion. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1568–1579.
Eunsol Choi, Tom Kwiatkowski, and Luke Zettle-
moyer. 2015. Scalable semantic parsing with partial
ontologies. In Proceedings of ACL.
Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko
Horn, Ni Lao, Kevin Murphy, Thomas Strohmann,
Shaohua Sun, and Wei Zhang. 2014. Knowl-
edge vault: A web-scale approach to probabilis-
tic knowledge fusion. In Proceedings of the 20th
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 601–610.
ACM.
Alberto Garc´ıa-Dur´an, Antoine Bordes, and Nicolas
Usunier. 2014. Effective blending of two and three-
way interactions for modeling multi-relational data.
In Machine Learning and Knowledge Discovery in
Databases, pages 434–449. Springer.
Matt Gardner, Partha Talukdar, Bryan Kisiel, and Tom
Mitchell. 2013. Improving learning and infer-
ence in a large knowledge-base using latent syntac-
tic cues. In Proceedings of EMNLP. Association for
Computational Linguistics.
Matt Gardner, Partha Talukdar, Jayant Krishnamurthy,
and Tom Mitchell. 2014. Incorporating vector space
similarity in random walk inference over knowledge
bases. In Proceedings of EMNLP. Association for
Computational Linguistics.
Matt Gardner, Partha Talukdar, and Tom Mitchell.
2015. Combining vector space embeddings with
symbolic logical inference over open-domain text.
In 2015 AAAI Spring Symposium Series.
Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction
of overlapping relations. In Proceedings of the 49th
Annual Meeting of the Association for Computa-
tional Linguistics: Human Language Technologies-
Volume 1, pages 541–550. Association for Compu-
tational Linguistics.
Jayant Krishnamurthy and Tom M Mitchell. 2012.
Weakly supervised training of semantic parsers. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
754–765. Association for Computational Linguis-
tics.
Ni Lao and William W Cohen. 2010. Relational re-
trieval using a combination of path-constrained ran-
dom walks. Machine learning, 81(1):53–67.
Ni Lao, Tom Mitchell, and William W Cohen. 2011.
Random walk inference and learning in a large scale
knowledge base. In Proceedings of EMNLP. Asso-
ciation for Computational Linguistics.
Ni Lao, Amarnag Subramanya, Fernando Pereira, and
William W Cohen. 2012. Reading the web with
learned syntactic-semantic inference rules. In Pro-
ceedings of EMNLP-CoNLL.
Ni Lao. 2012. Efficient Random Walk Inference with
Knowledge Bases. Ph.D. thesis, Carnegie Mellon
University.
Pablo N. Mendes, Max Jakob, and Christian Bizer.
2012. Dbpedia for nlp: A multilingual cross-domain
knowledge base. In Proceedings of the Eighth In-
ternational Conference on Language Resources and
Evaluation (LREC’12).
Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP, pages
1003–1011. Association for Computational Linguis-
tics.
Tom M. Mitchell, William Cohen, Estevam Hruschka,
Partha Talukdar, Justin Betteridge, Andrew Carl-
son, Bhavana Dalvi, Matthew Gardner, Bryan
Kisiel, Jayant Krishnamurthy, Ni Lao, Kathryn
Mazaitis, Thahir Mohamed, Ndapa Nakashole, Em-
manouil Antonios Platanios, Alan Ritter, Mehdi
Samadi, Burr Settles, Richard Wang, Derry Wijaya,
Abhinav Gupta, Xinlei Chen, Abulhair Saparov,
Malcolm Greaves, and Joel Welling. 2015. Never-
ending learning. In AAAI 2015. Association for the
Advancement of Artificial Intelligence.
Arvind Neelakantan, Benjamin Roth, and Andrew Mc-
Callum. 2015. Compositional vector space models
for knowledge base completion. In ACL 2015. As-
sociation for Computational Linguistics.
</reference>
<page confidence="0.844752">
1497
</page>
<reference confidence="0.999683851851852">
Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In Proceedings of
the 28th international conference on machine learn-
ing (ICML-11), pages 809–816.
Maximilian Nickel, Xueyan Jiang, and Volker Tresp.
2014. Reducing the rank in relational factorization
models by including observable patterns. In Ad-
vances in Neural Information Processing Systems,
pages 1179–1187.
Matthew Richardson and Pedro Domingos. 2006.
Markov logic networks. Machine learning, 62(1-
2):107–136.
Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M Marlin. 2013. Relation extraction with
matrix factorization and universal schemas. In Pro-
ceedings of NAACL-HLT.
Richard Socher, Danqi Chen, Christopher D Manning,
and Andrew Ng. 2013. Reasoning with neural ten-
sor networks for knowledge base completion. In Ad-
vances in Neural Information Processing Systems,
pages 926–934.
Fabian Suchanek, James Fan, Raphael Hoffmann, Se-
bastian Riedel, and Partha Pratim Talukdar. 2013.
Advances in automated knowledge base construc-
tion. SIGMOD Records journal, March.
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati,
and Christopher D Manning. 2012. Multi-instance
multi-label learning for relation extraction. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 455–
465. Association for Computational Linguistics.
William Yang Wang, Kathryn Mazaitis, and
William W. Cohen. 2013. Programming with
personalized pagerank: A locally groundable
first-order probabilistic logic. In Proceedings of the
22Nd ACM International Conference on Conference
on Information &amp; Knowledge Management,
CIKM ’13, pages 2129–2138, New York, NY, USA.
ACM.
Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng
Chen. 2014. Knowledge graph embedding by trans-
lating on hyperplanes. In Proceedings of the Twenty-
Eighth AAAI Conference on Artificial Intelligence,
pages 1112–1119.
Robert West, Evgeniy Gabrilovich, Kevin Murphy,
Shaohua Sun, Rahul Gupta, and Dekang Lin. 2014.
Knowledge base completion via search-based ques-
tion answering. In WWW.
Jason Weston, Antoine Bordes, Oksana Yakhnenko,
and Nicolas Usunier. 2013. Connecting language
and knowledge bases with embedding models for re-
lation extraction. In Proceedings of EMNLP.
</reference>
<page confidence="0.994244">
1498
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.854548">
<title confidence="0.9994775">Efficient and Expressive Knowledge Base Using Subgraph Feature Extraction</title>
<author confidence="0.999623">Matt Gardner</author>
<author confidence="0.999623">Tom</author>
<affiliation confidence="0.99972">Carnegie Mellon University</affiliation>
<email confidence="0.996365">mg1@cs.cmu.edu,tom.mitchell@cmu.edu</email>
<abstract confidence="0.99364525">We explore some of the practicalities of using random walk inference methods, such as the Path Ranking Algorithm (PRA), for the task of knowledge base completion. We show that the random walk probabilities computed (at great expense) by PRA provide no discernible benefit to performance on this task, so they can safely be dropped. This allows us to define a simpler algorithm for generating feature matrices from graphs, which we call subgraph feature extraction (SFE). In addition to being conceptually simpler than PRA, SFE is much more efficient, reducing computation by an order of magnitude, and more expressive, allowing for much richer features than paths between two nodes in a graph. We show experimentally that this technique gives substantially better performance than PRA and its variants, improving mean average precision from .432 to .528 on a knowledge base completion task using the NELL KB.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Andrew Chou</author>
<author>Roy Frostig</author>
<author>Percy Liang</author>
</authors>
<title>Semantic parsing on freebase from question-answer pairs.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<pages>1533--1544</pages>
<contexts>
<context position="1539" citStr="Berant et al., 2013" startWordPosition="237" endWordPosition="240">nique gives substantially better performance than PRA and its variants, improving mean average precision from .432 to .528 on a knowledge base completion task using the NELL KB. 1 Introduction Knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) contain large collections of facts about things, people, and places in the world. These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers (Hoffmann et al., 2011; Krishnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by looking in a corpus—is one attempt to mitigate the problems of this knowledge sparsity. In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link p</context>
</contexts>
<marker>Berant, Chou, Frostig, Liang, 2013</marker>
<rawString>Jonathan Berant, Andrew Chou, Roy Frostig, and Percy Liang. 2013. Semantic parsing on freebase from question-answer pairs. In EMNLP, pages 1533– 1544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: a collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of SIGMOD.</booktitle>
<contexts>
<context position="1176" citStr="Bollacker et al., 2008" startWordPosition="181" endWordPosition="185">r algorithm for generating feature matrices from graphs, which we call subgraph feature extraction (SFE). In addition to being conceptually simpler than PRA, SFE is much more efficient, reducing computation by an order of magnitude, and more expressive, allowing for much richer features than paths between two nodes in a graph. We show experimentally that this technique gives substantially better performance than PRA and its variants, improving mean average precision from .432 to .528 on a knowledge base completion task using the NELL KB. 1 Introduction Knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) contain large collections of facts about things, people, and places in the world. These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers (Hoffmann et al., 2011; Krishnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling i</context>
</contexts>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of SIGMOD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Jason Weston</author>
<author>Ronan Collobert</author>
<author>Yoshua Bengio</author>
</authors>
<title>Learning structured embeddings of knowledge bases.</title>
<date>2011</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="13157" citStr="Bordes et al., 2011" startWordPosition="2217" endWordPosition="2220">atures from the knowledge base when predicting whether a particular sentence expresses a relation, and so techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedding methods for KB completion. There has been much recent work that attempts to perform KB completion by learning an embedded representation of entities and relations in the KB and then using these representations to infer missing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al., 2014; Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge base tensor, but when the tensor (or individual relations in the tensor) has high rank, learning good embeddings can be challenging. The ARE model (Nickel et al., 2014) attempted to address this by only making the embeddings capture the residual of the tensor that cannot be readily predicted from th</context>
</contexts>
<marker>Bordes, Weston, Collobert, Bengio, 2011</marker>
<rawString>Antoine Bordes, Jason Weston, Ronan Collobert, Yoshua Bengio, et al. 2011. Learning structured embeddings of knowledge bases. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Nicolas Usunier</author>
<author>Alberto GarciaDuran</author>
<author>Jason Weston</author>
<author>Oksana Yakhnenko</author>
</authors>
<title>Translating embeddings for modeling multirelational data.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>2787--2795</pages>
<contexts>
<context position="13215" citStr="Bordes et al., 2013" startWordPosition="2227" endWordPosition="2231">articular sentence expresses a relation, and so techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedding methods for KB completion. There has been much recent work that attempts to perform KB completion by learning an embedded representation of entities and relations in the KB and then using these representations to infer missing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al., 2014; Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge base tensor, but when the tensor (or individual relations in the tensor) has high rank, learning good embeddings can be challenging. The ARE model (Nickel et al., 2014) attempted to address this by only making the embeddings capture the residual of the tensor that cannot be readily predicted from the graph-based techniques mentioned below. 1490 Dataset Met</context>
</contexts>
<marker>Bordes, Usunier, GarciaDuran, Weston, Yakhnenko, 2013</marker>
<rawString>Antoine Bordes, Nicolas Usunier, Alberto GarciaDuran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multirelational data. In Advances in Neural Information Processing Systems, pages 2787–2795.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai-Wei Chang</author>
<author>Wen-tau Yih</author>
<author>Bishan Yang</author>
<author>Christopher Meek</author>
</authors>
<title>Typed tensor decomposition of knowledge bases for relation extraction.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1568--1579</pages>
<contexts>
<context position="13327" citStr="Chang et al., 2014" startWordPosition="2247" endWordPosition="2250">e KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedding methods for KB completion. There has been much recent work that attempts to perform KB completion by learning an embedded representation of entities and relations in the KB and then using these representations to infer missing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al., 2014; Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge base tensor, but when the tensor (or individual relations in the tensor) has high rank, learning good embeddings can be challenging. The ARE model (Nickel et al., 2014) attempted to address this by only making the embeddings capture the residual of the tensor that cannot be readily predicted from the graph-based techniques mentioned below. 1490 Dataset Method MAP Freebase Probabilities .337 Binarized .344 NELL Probabilities .303 Binarized .319 Table 1: Using binary </context>
</contexts>
<marker>Chang, Yih, Yang, Meek, 2014</marker>
<rawString>Kai-Wei Chang, Wen-tau Yih, Bishan Yang, and Christopher Meek. 2014. Typed tensor decomposition of knowledge bases for relation extraction. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1568–1579.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eunsol Choi</author>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Scalable semantic parsing with partial ontologies.</title>
<date>2015</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1727" citStr="Choi et al., 2015" startWordPosition="268" endWordPosition="271">on Knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) contain large collections of facts about things, people, and places in the world. These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers (Hoffmann et al., 2011; Krishnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by looking in a corpus—is one attempt to mitigate the problems of this knowledge sparsity. In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference (Gardner et al., 2015), as the f</context>
</contexts>
<marker>Choi, Kwiatkowski, Zettlemoyer, 2015</marker>
<rawString>Eunsol Choi, Tom Kwiatkowski, and Luke Zettlemoyer. 2015. Scalable semantic parsing with partial ontologies. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Dong</author>
<author>Evgeniy Gabrilovich</author>
<author>Geremy Heitz</author>
<author>Wilko Horn</author>
<author>Ni Lao</author>
<author>Kevin Murphy</author>
<author>Thomas Strohmann</author>
<author>Shaohua Sun</author>
<author>Wei Zhang</author>
</authors>
<title>Knowledge vault: A web-scale approach to probabilistic knowledge fusion.</title>
<date>2014</date>
<booktitle>In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>601--610</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2100" citStr="Dong et al., 2014" startWordPosition="333" endWordPosition="336">hell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by looking in a corpus—is one attempt to mitigate the problems of this knowledge sparsity. In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference (Gardner et al., 2015), as the feature space considered by PRA consists of a restricted class of horn clauses found in the graph. While PRA can be applied to any link prediction task in a graph, its primary use has been in KB completion (Lao et al., 2012; Gardner et al., 2013; Gardner et al., 2014). PRA is a two-step process, where the first step finds potential path types between node pairs to use as </context>
<context position="14877" citStr="Dong et al., 2014" startWordPosition="2498" endWordPosition="2501"> order to predict missing instances in a knowledge base. Markov logic networks (Richardson and Domingos, 2006) fall into this category, as does ProPPR (Wang et al., 2013) and many other logic-based systems. PRA, the main subject of this paper, also fits in this line of work. Work specifically with PRA has ranged from incorporating a parsed corpus as additional evidence when doing random walk inference (Lao et al., 2012), to introducing better representations of the text corpus (Gardner et al., 2013; Gardner et al., 2014), and using PRA in a broader context as part of Google’s Knowledge Vault (Dong et al., 2014). An interesting piece of work that combines embedding methods with graph-based methods is that of Neelakantan et al. (2015), which uses a recursive neural network to create embedded representations of PRA-style paths. 4 Motivation We motivate our modifications to PRA with three observations. First, it appears that binarizing the feature matrix produced by PRA, removing most of the information gained in PRA’s second step, has no significant impact on prediction performance in knowledge base completion tasks. We show this on the NELL KB and the Freebase KB in Table 1.3 The fact that random walk</context>
</contexts>
<marker>Dong, Gabrilovich, Heitz, Horn, Lao, Murphy, Strohmann, Sun, Zhang, 2014</marker>
<rawString>Xin Dong, Evgeniy Gabrilovich, Geremy Heitz, Wilko Horn, Ni Lao, Kevin Murphy, Thomas Strohmann, Shaohua Sun, and Wei Zhang. 2014. Knowledge vault: A web-scale approach to probabilistic knowledge fusion. In Proceedings of the 20th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 601–610. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alberto Garc´ıa-Dur´an</author>
<author>Antoine Bordes</author>
<author>Nicolas Usunier</author>
</authors>
<title>Effective blending of two and threeway interactions for modeling multi-relational data.</title>
<date>2014</date>
<booktitle>In Machine Learning and Knowledge Discovery in Databases,</booktitle>
<pages>434--449</pages>
<publisher>Springer.</publisher>
<marker>Garc´ıa-Dur´an, Bordes, Usunier, 2014</marker>
<rawString>Alberto Garc´ıa-Dur´an, Antoine Bordes, and Nicolas Usunier. 2014. Effective blending of two and threeway interactions for modeling multi-relational data. In Machine Learning and Knowledge Discovery in Databases, pages 434–449. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gardner</author>
<author>Partha Talukdar</author>
<author>Bryan Kisiel</author>
<author>Tom Mitchell</author>
</authors>
<title>Improving learning and inference in a large knowledge-base using latent syntactic cues.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2571" citStr="Gardner et al., 2013" startWordPosition="419" endWordPosition="422"> one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference (Gardner et al., 2015), as the feature space considered by PRA consists of a restricted class of horn clauses found in the graph. While PRA can be applied to any link prediction task in a graph, its primary use has been in KB completion (Lao et al., 2012; Gardner et al., 2013; Gardner et al., 2014). PRA is a two-step process, where the first step finds potential path types between node pairs to use as features in a statistical model, and the second step computes random walk probabilities associated with each path type and node pair (these are the values in a feature matrix). This second step is very computationally intensive, requiring time proportional to the average out-degree of the graph to the power of the path length for each cell in the computed feature matrix. In this paper we consider whether this computational effort is wellspent, or whether we might mor</context>
<context position="14762" citStr="Gardner et al., 2013" startWordPosition="2477" endWordPosition="2480">rate line of research into KB completion can be broadly construed as performing some kind of inference over graphs in order to predict missing instances in a knowledge base. Markov logic networks (Richardson and Domingos, 2006) fall into this category, as does ProPPR (Wang et al., 2013) and many other logic-based systems. PRA, the main subject of this paper, also fits in this line of work. Work specifically with PRA has ranged from incorporating a parsed corpus as additional evidence when doing random walk inference (Lao et al., 2012), to introducing better representations of the text corpus (Gardner et al., 2013; Gardner et al., 2014), and using PRA in a broader context as part of Google’s Knowledge Vault (Dong et al., 2014). An interesting piece of work that combines embedding methods with graph-based methods is that of Neelakantan et al. (2015), which uses a recursive neural network to create embedded representations of PRA-style paths. 4 Motivation We motivate our modifications to PRA with three observations. First, it appears that binarizing the feature matrix produced by PRA, removing most of the information gained in PRA’s second step, has no significant impact on prediction performance in know</context>
</contexts>
<marker>Gardner, Talukdar, Kisiel, Mitchell, 2013</marker>
<rawString>Matt Gardner, Partha Talukdar, Bryan Kisiel, and Tom Mitchell. 2013. Improving learning and inference in a large knowledge-base using latent syntactic cues. In Proceedings of EMNLP. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gardner</author>
<author>Partha Talukdar</author>
<author>Jayant Krishnamurthy</author>
<author>Tom Mitchell</author>
</authors>
<title>Incorporating vector space similarity in random walk inference over knowledge bases.</title>
<date>2014</date>
<booktitle>In Proceedings of EMNLP. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2594" citStr="Gardner et al., 2014" startWordPosition="423" endWordPosition="426">ming knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference (Gardner et al., 2015), as the feature space considered by PRA consists of a restricted class of horn clauses found in the graph. While PRA can be applied to any link prediction task in a graph, its primary use has been in KB completion (Lao et al., 2012; Gardner et al., 2013; Gardner et al., 2014). PRA is a two-step process, where the first step finds potential path types between node pairs to use as features in a statistical model, and the second step computes random walk probabilities associated with each path type and node pair (these are the values in a feature matrix). This second step is very computationally intensive, requiring time proportional to the average out-degree of the graph to the power of the path length for each cell in the computed feature matrix. In this paper we consider whether this computational effort is wellspent, or whether we might more profitably spend comp</context>
<context position="7591" citStr="Gardner et al. (2014)" startWordPosition="1282" endWordPosition="1285">put node pairs. These path types are found by performing random walks on the graph G starting at the source and target nodes in D and recording which paths connect some source node with its target.2 Note that these are two-sided, unconstrained random walks: the walks from sources and targets can be joined on intermediate nodes to get a larger set of paths that connect the source and target nodes. Once connectivity statistics have been computed in this way, k path types are selected as features. Lao et al. (2011) use measures of the precision and recall of each feature in this selection, while Gardner et al. (2014) simply pick those most frequently seen. Once a set of path features has been selected, the second step of PRA is to compute values for each cell in the feature matrix. Recall that rows in this matrix correspond to node pairs, and the columns correspond to the path types found in the first step. The cell value assigned by PRA is the probability of arriving at the target node of a node pair, given that a random walk began at the source node and was constrained to follow the path type: p(t|s, 7r). There are several ways of computing this probability. The most straightforward method is to use a p</context>
<context position="14785" citStr="Gardner et al., 2014" startWordPosition="2481" endWordPosition="2484">into KB completion can be broadly construed as performing some kind of inference over graphs in order to predict missing instances in a knowledge base. Markov logic networks (Richardson and Domingos, 2006) fall into this category, as does ProPPR (Wang et al., 2013) and many other logic-based systems. PRA, the main subject of this paper, also fits in this line of work. Work specifically with PRA has ranged from incorporating a parsed corpus as additional evidence when doing random walk inference (Lao et al., 2012), to introducing better representations of the text corpus (Gardner et al., 2013; Gardner et al., 2014), and using PRA in a broader context as part of Google’s Knowledge Vault (Dong et al., 2014). An interesting piece of work that combines embedding methods with graph-based methods is that of Neelakantan et al. (2015), which uses a recursive neural network to create embedded representations of PRA-style paths. 4 Motivation We motivate our modifications to PRA with three observations. First, it appears that binarizing the feature matrix produced by PRA, removing most of the information gained in PRA’s second step, has no significant impact on prediction performance in knowledge base completion t</context>
<context position="28485" citStr="Gardner et al. (2014)" startWordPosition="4810" endWordPosition="4813">ne the intermediate nodes when there are common path types. That is, if we see a common path type, such as -GENDER-, we will construct a feature representing a comparison between the intermediate node for the source and the target. If the values are the same, this information can be captured with a PRA feature, but it cannot be easily captured by PRA when the values are different. In the example in Figure 1, there are two common path types: -ALIAS-, and-GENDER. The feature generated from the path type - GENDER- would be “COMPARISON:-GENDER:/m/Male:/m/Female”. Vector space similarity features. Gardner et al. (2014) introduced a modification of PRA’s random walks to incorporate vector space similarity between the relations in the graph. On the data they were using, a graph that combined a formal knowledge base with textual relations extracted from text, they found that this technique gave a substantial performance improvement. The vector space random walks only affected the second step of PRA, however, and we have removed that step in SFE. While it is not as conceptually clean as the vector space random walks, we can obtain a similar effect with a simple feature transformation using the vectors for each </context>
<context position="31281" citStr="Gardner et al. (2014)" startWordPosition="5266" endWordPosition="5269"> 1 would thus be “ANYREL:-@ANY REL@- is married to-ALIAS”, “ANYREL:-ALIAS@ANY REL@-ALIAS”, “ANYREL:-ALIAS-is married to-@ANY REL@”. 6 Experiments Here we present experimental results evaluating the feature extractors we presented, and a comparison between SFE and PRA. As we showed in Section 5 that using a breadth-first search to obtain subgraphs is superior to using random walks, all of the experiments presented here use the BFS implementation of SFE. 6.1 Data To evaluate SFE and the feature extractors we introduced, we learned models for 10 relations in the NELL KB. We used the same data as Gardner et al. (2014), using both the formal KB relations and the surface relations extracted from text in our 7Replacing all surface edges with a single dummy relation gives performance close to vector space PRA. The vector space walks do statistically outperform this, but the extra gain is small. 1494 graph. We used logistic regression with elastic net (L1 and L2) regularization. We tuned the L1 and L2 parameters for each method on a random development split of the data, then used a new split of the data to run the final tests presented here. The evaluation metrics we use are mean average precision (MAP) and mea</context>
<context position="35910" citStr="Gardner et al. (2014)" startWordPosition="6063" endWordPosition="6066">s relations to achieve statistical significance. The vector similarity features do improve performance, with p-values hovering right at 0.05 when comparing against only PRA features and PRA + bigram features. The any rel features, however, do statistically improve over all other methods (p &lt;= 0.01) except the PRA + vec sim result (p = .21). Finally, we present a comparison between PRA, PRA with vector space random walks, and the best SFE result from the ablation study. This is shown in Table 6. SFE significantly outperforms PRA, both with and without the vector space random walks presented by Gardner et al. (2014). 6.4 Discussion When using only PRA-style features with SFE, the highest weighted features were almost always those of the form -ALIAS-[some textual relation]- ALIAS-1-. For example, for the relation WRITER1495 Feature Types MAP MRR Features PRA-style features .431 .806 240k + Comparisons .405 .833 558k + One-sided .389 .800 1,227k + One-sided + Comps. .387 .817 1,544k + Bigrams .483 1.00 320k + Vector similarity .514 .910 3,993k + Bigrams + vec sim. .490 .950 4,073k + Any Rel .528 .933 649k Table 5: SFE feature ablation study. All rows use PRA features. PRA + any rel is statistically better </context>
</contexts>
<marker>Gardner, Talukdar, Krishnamurthy, Mitchell, 2014</marker>
<rawString>Matt Gardner, Partha Talukdar, Jayant Krishnamurthy, and Tom Mitchell. 2014. Incorporating vector space similarity in random walk inference over knowledge bases. In Proceedings of EMNLP. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Gardner</author>
<author>Partha Talukdar</author>
<author>Tom Mitchell</author>
</authors>
<title>Combining vector space embeddings with symbolic logical inference over open-domain text. In</title>
<date>2015</date>
<publisher>AAAI Spring Symposium Series.</publisher>
<contexts>
<context position="2317" citStr="Gardner et al., 2015" startWordPosition="370" endWordPosition="374">t al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by looking in a corpus—is one attempt to mitigate the problems of this knowledge sparsity. In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference (Gardner et al., 2015), as the feature space considered by PRA consists of a restricted class of horn clauses found in the graph. While PRA can be applied to any link prediction task in a graph, its primary use has been in KB completion (Lao et al., 2012; Gardner et al., 2013; Gardner et al., 2014). PRA is a two-step process, where the first step finds potential path types between node pairs to use as features in a statistical model, and the second step computes random walk probabilities associated with each path type and node pair (these are the values in a feature matrix). This second step is very computationally</context>
</contexts>
<marker>Gardner, Talukdar, Mitchell, 2015</marker>
<rawString>Matt Gardner, Partha Talukdar, and Tom Mitchell. 2015. Combining vector space embeddings with symbolic logical inference over open-domain text. In 2015 AAAI Spring Symposium Series.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledgebased weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesVolume 1,</booktitle>
<pages>541--550</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1458" citStr="Hoffmann et al., 2011" startWordPosition="226" endWordPosition="229">res than paths between two nodes in a graph. We show experimentally that this technique gives substantially better performance than PRA and its variants, improving mean average precision from .432 to .528 on a knowledge base completion task using the NELL KB. 1 Introduction Knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) contain large collections of facts about things, people, and places in the world. These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers (Hoffmann et al., 2011; Krishnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by looking in a corpus—is one attempt to mitigate the problems of this knowledge sparsity. In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (</context>
<context position="12180" citStr="Hoffmann et al., 2011" startWordPosition="2055" endWordPosition="2058">etion have the same goal: to predict new instances of relations in a formal knowledge base such as Freebase or NELL. The difference is that relation extraction focuses on determining what relationship is expressed by a particular sentence, while knowledge base completion tries to predict which relationships hold between which entities. A relation extraction system can be used for knowledge base completion, but typical KB completion methods do not make predictions on single sentences. This is easily seen in the line of work known as distantly-supervised relation extraction (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012); these models use the relation instances in a knowledge base as their only supervision, performing some heuristic mapping of the entities in text to the knowledge base, then using that mapping to train extractors for each relation in the KB. The cost of using these methods is that is it generally difficult to incorporate richer features from the knowledge base when predicting whether a particular sentence expresses a relation, and so techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedd</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language TechnologiesVolume 1, pages 541–550. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jayant Krishnamurthy</author>
<author>Tom M Mitchell</author>
</authors>
<title>Weakly supervised training of semantic parsers.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>754--765</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1493" citStr="Krishnamurthy and Mitchell, 2012" startWordPosition="230" endWordPosition="233">two nodes in a graph. We show experimentally that this technique gives substantially better performance than PRA and its variants, improving mean average precision from .432 to .528 on a knowledge base completion task using the NELL KB. 1 Introduction Knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) contain large collections of facts about things, people, and places in the world. These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers (Hoffmann et al., 2011; Krishnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by looking in a corpus—is one attempt to mitigate the problems of this knowledge sparsity. In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al.</context>
</contexts>
<marker>Krishnamurthy, Mitchell, 2012</marker>
<rawString>Jayant Krishnamurthy and Tom M Mitchell. 2012. Weakly supervised training of semantic parsers. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 754–765. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ni Lao</author>
<author>William W Cohen</author>
</authors>
<title>Relational retrieval using a combination of path-constrained random walks.</title>
<date>2010</date>
<booktitle>Machine learning,</booktitle>
<pages>81--1</pages>
<contexts>
<context position="5519" citStr="Lao and Cohen (2010)" startWordPosition="918" endWordPosition="921">L KB, and it improves mean reciprocal rank from .850 to .933. In the remainder of this paper, we first describe PRA in more detail. We then situate our methods in the context of related work, and provide additional experimental motivation for the improvements described in this paper. We then formally define SFE and the feature extractors we used, and finally we present an experimental comparison between PRA and SFE on the NELL KB. The code and data used in this paper is available at http://rtw.ml.cmu.edu/emnlp2015 sfe/. 2 The Path Ranking Algorithm The path ranking algorithm was introduced by Lao and Cohen (2010). It is a two-step process for generating a feature matrix over node pairs in a graph. The first step finds a set of potentially useful path types that connect the node pairs, which become the columns of the feature matrix. The second step then computes the values in the feature matrix by finding random walk probabilities as described below. Once the feature matrix has been computed, it can be used with whatever classification model is desired (or even incorporated as one of many factors in a structured prediction model), though almost all prior work with PRA simply uses logistic regression. M</context>
</contexts>
<marker>Lao, Cohen, 2010</marker>
<rawString>Ni Lao and William W Cohen. 2010. Relational retrieval using a combination of path-constrained random walks. Machine learning, 81(1):53–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ni Lao</author>
<author>Tom Mitchell</author>
<author>William W Cohen</author>
</authors>
<title>Random walk inference and learning in a large scale knowledge base.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2080" citStr="Lao et al., 2011" startWordPosition="329" endWordPosition="332">hnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by looking in a corpus—is one attempt to mitigate the problems of this knowledge sparsity. In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference (Gardner et al., 2015), as the feature space considered by PRA consists of a restricted class of horn clauses found in the graph. While PRA can be applied to any link prediction task in a graph, its primary use has been in KB completion (Lao et al., 2012; Gardner et al., 2013; Gardner et al., 2014). PRA is a two-step process, where the first step finds potential path types between n</context>
<context position="7487" citStr="Lao et al. (2011)" startWordPosition="1264" endWordPosition="1267">es 7r that are likely to be useful in predicting new instances of the relation represented by the input node pairs. These path types are found by performing random walks on the graph G starting at the source and target nodes in D and recording which paths connect some source node with its target.2 Note that these are two-sided, unconstrained random walks: the walks from sources and targets can be joined on intermediate nodes to get a larger set of paths that connect the source and target nodes. Once connectivity statistics have been computed in this way, k path types are selected as features. Lao et al. (2011) use measures of the precision and recall of each feature in this selection, while Gardner et al. (2014) simply pick those most frequently seen. Once a set of path features has been selected, the second step of PRA is to compute values for each cell in the feature matrix. Recall that rows in this matrix correspond to node pairs, and the columns correspond to the path types found in the first step. The cell value assigned by PRA is the probability of arriving at the target node of a node pair, given that a random walk began at the source node and was constrained to follow the path type: p(t|s, </context>
</contexts>
<marker>Lao, Mitchell, Cohen, 2011</marker>
<rawString>Ni Lao, Tom Mitchell, and William W Cohen. 2011. Random walk inference and learning in a large scale knowledge base. In Proceedings of EMNLP. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ni Lao</author>
<author>Amarnag Subramanya</author>
<author>Fernando Pereira</author>
<author>William W Cohen</author>
</authors>
<title>Reading the web with learned syntactic-semantic inference rules.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="2549" citStr="Lao et al., 2012" startWordPosition="415" endWordPosition="418">is work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference (Gardner et al., 2015), as the feature space considered by PRA consists of a restricted class of horn clauses found in the graph. While PRA can be applied to any link prediction task in a graph, its primary use has been in KB completion (Lao et al., 2012; Gardner et al., 2013; Gardner et al., 2014). PRA is a two-step process, where the first step finds potential path types between node pairs to use as features in a statistical model, and the second step computes random walk probabilities associated with each path type and node pair (these are the values in a feature matrix). This second step is very computationally intensive, requiring time proportional to the average out-degree of the graph to the power of the path length for each cell in the computed feature matrix. In this paper we consider whether this computational effort is wellspent, o</context>
<context position="14682" citStr="Lao et al., 2012" startWordPosition="2465" endWordPosition="2468"> .55, while it is .25 for NELL. Graph-based methods for KB completion. A separate line of research into KB completion can be broadly construed as performing some kind of inference over graphs in order to predict missing instances in a knowledge base. Markov logic networks (Richardson and Domingos, 2006) fall into this category, as does ProPPR (Wang et al., 2013) and many other logic-based systems. PRA, the main subject of this paper, also fits in this line of work. Work specifically with PRA has ranged from incorporating a parsed corpus as additional evidence when doing random walk inference (Lao et al., 2012), to introducing better representations of the text corpus (Gardner et al., 2013; Gardner et al., 2014), and using PRA in a broader context as part of Google’s Knowledge Vault (Dong et al., 2014). An interesting piece of work that combines embedding methods with graph-based methods is that of Neelakantan et al. (2015), which uses a recursive neural network to create embedded representations of PRA-style paths. 4 Motivation We motivate our modifications to PRA with three observations. First, it appears that binarizing the feature matrix produced by PRA, removing most of the information gained i</context>
</contexts>
<marker>Lao, Subramanya, Pereira, Cohen, 2012</marker>
<rawString>Ni Lao, Amarnag Subramanya, Fernando Pereira, and William W Cohen. 2012. Reading the web with learned syntactic-semantic inference rules. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ni Lao</author>
</authors>
<title>Efficient Random Walk Inference with Knowledge Bases.</title>
<date>2012</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University.</institution>
<contexts>
<context position="9844" citStr="Lao (2012)" startWordPosition="1668" endWordPosition="1669">lity calculation. The first is to use random walks to approximate the probability via rejection sampling: for each path type and source node, a number of random walks are performed, attempting to follow the edge sequence corresponding to the path type. If a node is reached where it is no longer possible to follow the path type, the random walk is restarted. This does not reduce the time necessary to get an arbitrarily good approximation, but it does allow us to decrease computation time, even getting a fixed complexity, at the cost of accepting some error in our probability estimates. Second, Lao (2012) showed that when the target node of a query is known, the exponent can be cut in half by using a two-sided BFS. In this method, some careful bookkeeping is done with dynamic programming such that the probability can be computed correctly when the two-sided search meets at an intermediate node. Lao’s dynamic programming technique is only applicable when the target node is known, however, and only cuts the exponent in half—this is still quite computationally intensive. Lastly, we could replace the BFS with a multiplication of adjacency matrices, which performs the same computation. The efficien</context>
</contexts>
<marker>Lao, 2012</marker>
<rawString>Ni Lao. 2012. Efficient Random Walk Inference with Knowledge Bases. Ph.D. thesis, Carnegie Mellon University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo N Mendes</author>
<author>Max Jakob</author>
<author>Christian Bizer</author>
</authors>
<title>Dbpedia for nlp: A multilingual cross-domain knowledge base.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC’12).</booktitle>
<contexts>
<context position="1241" citStr="Mendes et al., 2012" startWordPosition="193" endWordPosition="196">ll subgraph feature extraction (SFE). In addition to being conceptually simpler than PRA, SFE is much more efficient, reducing computation by an order of magnitude, and more expressive, allowing for much richer features than paths between two nodes in a graph. We show experimentally that this technique gives substantially better performance than PRA and its variants, improving mean average precision from .432 to .528 on a knowledge base completion task using the NELL KB. 1 Introduction Knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) contain large collections of facts about things, people, and places in the world. These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers (Hoffmann et al., 2011; Krishnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by l</context>
</contexts>
<marker>Mendes, Jakob, Bizer, 2012</marker>
<rawString>Pablo N. Mendes, Max Jakob, and Christian Bizer. 2012. Dbpedia for nlp: A multilingual cross-domain knowledge base. In Proceedings of the Eighth International Conference on Language Resources and Evaluation (LREC’12).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12157" citStr="Mintz et al., 2009" startWordPosition="2051" endWordPosition="2054">knowledge base completion have the same goal: to predict new instances of relations in a formal knowledge base such as Freebase or NELL. The difference is that relation extraction focuses on determining what relationship is expressed by a particular sentence, while knowledge base completion tries to predict which relationships hold between which entities. A relation extraction system can be used for knowledge base completion, but typical KB completion methods do not make predictions on single sentences. This is easily seen in the line of work known as distantly-supervised relation extraction (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012); these models use the relation instances in a knowledge base as their only supervision, performing some heuristic mapping of the entities in text to the knowledge base, then using that mapping to train extractors for each relation in the KB. The cost of using these methods is that is it generally difficult to incorporate richer features from the knowledge base when predicting whether a particular sentence expresses a relation, and so techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riede</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 1003–1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Tom M Mitchell</author>
<author>William Cohen</author>
<author>Estevam Hruschka</author>
<author>Partha Talukdar</author>
<author>Justin Betteridge</author>
<author>Andrew Carlson</author>
<author>Bhavana Dalvi</author>
<author>Matthew Gardner</author>
<author>Bryan Kisiel</author>
<author>Jayant Krishnamurthy</author>
<author>Ni Lao</author>
</authors>
<title>Kathryn Mazaitis, Thahir Mohamed, Ndapa Nakashole, Emmanouil Antonios Platanios,</title>
<date>2015</date>
<booktitle>In AAAI 2015. Association for the Advancement of Artificial Intelligence.</booktitle>
<location>Alan Ritter, Mehdi Samadi, Burr Settles, Richard Wang, Derry Wijaya, Abhinav Gupta, Xinlei</location>
<contexts>
<context position="1206" citStr="Mitchell et al., 2015" startWordPosition="187" endWordPosition="190">ure matrices from graphs, which we call subgraph feature extraction (SFE). In addition to being conceptually simpler than PRA, SFE is much more efficient, reducing computation by an order of magnitude, and more expressive, allowing for much richer features than paths between two nodes in a graph. We show experimentally that this technique gives substantially better performance than PRA and its variants, improving mean average precision from .432 to .528 on a knowledge base completion task using the NELL KB. 1 Introduction Knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) contain large collections of facts about things, people, and places in the world. These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers (Hoffmann et al., 2011; Krishnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining t</context>
</contexts>
<marker>Mitchell, Cohen, Hruschka, Talukdar, Betteridge, Carlson, Dalvi, Gardner, Kisiel, Krishnamurthy, Lao, 2015</marker>
<rawString>Tom M. Mitchell, William Cohen, Estevam Hruschka, Partha Talukdar, Justin Betteridge, Andrew Carlson, Bhavana Dalvi, Matthew Gardner, Bryan Kisiel, Jayant Krishnamurthy, Ni Lao, Kathryn Mazaitis, Thahir Mohamed, Ndapa Nakashole, Emmanouil Antonios Platanios, Alan Ritter, Mehdi Samadi, Burr Settles, Richard Wang, Derry Wijaya, Abhinav Gupta, Xinlei Chen, Abulhair Saparov, Malcolm Greaves, and Joel Welling. 2015. Neverending learning. In AAAI 2015. Association for the Advancement of Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arvind Neelakantan</author>
<author>Benjamin Roth</author>
<author>Andrew McCallum</author>
</authors>
<title>Compositional vector space models for knowledge base completion.</title>
<date>2015</date>
<booktitle>In ACL 2015. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="15001" citStr="Neelakantan et al. (2015)" startWordPosition="2517" endWordPosition="2520">nto this category, as does ProPPR (Wang et al., 2013) and many other logic-based systems. PRA, the main subject of this paper, also fits in this line of work. Work specifically with PRA has ranged from incorporating a parsed corpus as additional evidence when doing random walk inference (Lao et al., 2012), to introducing better representations of the text corpus (Gardner et al., 2013; Gardner et al., 2014), and using PRA in a broader context as part of Google’s Knowledge Vault (Dong et al., 2014). An interesting piece of work that combines embedding methods with graph-based methods is that of Neelakantan et al. (2015), which uses a recursive neural network to create embedded representations of PRA-style paths. 4 Motivation We motivate our modifications to PRA with three observations. First, it appears that binarizing the feature matrix produced by PRA, removing most of the information gained in PRA’s second step, has no significant impact on prediction performance in knowledge base completion tasks. We show this on the NELL KB and the Freebase KB in Table 1.3 The fact that random walk probabilities carry no additional information for this task over binary features is surprising, and it shows that the secon</context>
<context position="25167" citStr="Neelakantan et al. (2015)" startWordPosition="4268" endWordPosition="4271">e to make the feature extraction process more clear. Relying on the notation introduced earlier, these features are generated by intersecting the subgraphs G3 and Gt on the intermediate nodes. That is, when the subgraphs share an intermediate node, we combine the path types found from the source and target to that node. In the example in Figure 1, there are two common intermediate nodes (“Barack Obama” and “Michelle Obama”), and combining the path types corresponding to those nodes gives the same path type: -ALIAS-“is married to”-ALIAS-1-. Path bigram features. In Section 4, we mentioned that Neelakantan et al. (2015) experimented with using path bigrams as features. We 6One should not read too much into the decrease in running time between SFE-RW and SFE-BFS, however, as it was mostly an implementation detail. /m/Barack Obama /m/Michelle Obama GENDER /m/Male /m/Female Subgraph for /m/Barack Obama 7r i -ALIAS- “Barack Obama” -GENDER- /m/Male -ALIAS-“is married to”- “Michelle Obama” Subgraph for /m/Michelle Obama 7r i -ALIAS- “Michelle Obama” -GENDER- /m/Female -ALIAS-“is married to”-1- “Barack Obama” Figure 1: An example graph, with subgraphs extracted for two nodes. include those features here as well. Fo</context>
</contexts>
<marker>Neelakantan, Roth, McCallum, 2015</marker>
<rawString>Arvind Neelakantan, Benjamin Roth, and Andrew McCallum. 2015. Compositional vector space models for knowledge base completion. In ACL 2015. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Nickel</author>
<author>Volker Tresp</author>
<author>Hans-Peter Kriegel</author>
</authors>
<title>A three-way model for collective learning on multi-relational data.</title>
<date>2011</date>
<booktitle>In Proceedings of the 28th international conference on machine learning (ICML-11),</booktitle>
<pages>809--816</pages>
<contexts>
<context position="13109" citStr="Nickel et al., 2011" startWordPosition="2210" endWordPosition="2213"> it generally difficult to incorporate richer features from the knowledge base when predicting whether a particular sentence expresses a relation, and so techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedding methods for KB completion. There has been much recent work that attempts to perform KB completion by learning an embedded representation of entities and relations in the KB and then using these representations to infer missing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al., 2014; Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge base tensor, but when the tensor (or individual relations in the tensor) has high rank, learning good embeddings can be challenging. The ARE model (Nickel et al., 2014) attempted to address this by only making the embeddings capture the residual of the</context>
</contexts>
<marker>Nickel, Tresp, Kriegel, 2011</marker>
<rawString>Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th international conference on machine learning (ICML-11), pages 809–816.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Nickel</author>
<author>Xueyan Jiang</author>
<author>Volker Tresp</author>
</authors>
<title>Reducing the rank in relational factorization models by including observable patterns.</title>
<date>2014</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>1179--1187</pages>
<contexts>
<context position="13625" citStr="Nickel et al., 2014" startWordPosition="2297" endWordPosition="2300">ssing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al., 2014; Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge base tensor, but when the tensor (or individual relations in the tensor) has high rank, learning good embeddings can be challenging. The ARE model (Nickel et al., 2014) attempted to address this by only making the embeddings capture the residual of the tensor that cannot be readily predicted from the graph-based techniques mentioned below. 1490 Dataset Method MAP Freebase Probabilities .337 Binarized .344 NELL Probabilities .303 Binarized .319 Table 1: Using binary feature values instead of random walk probabilities gives statistically indistinguishable performance. The p-value on the Freebase data is .55, while it is .25 for NELL. Graph-based methods for KB completion. A separate line of research into KB completion can be broadly construed as performing som</context>
</contexts>
<marker>Nickel, Jiang, Tresp, 2014</marker>
<rawString>Maximilian Nickel, Xueyan Jiang, and Volker Tresp. 2014. Reducing the rank in relational factorization models by including observable patterns. In Advances in Neural Information Processing Systems, pages 1179–1187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Richardson</author>
<author>Pedro Domingos</author>
</authors>
<title>Markov logic networks.</title>
<date>2006</date>
<booktitle>Machine learning,</booktitle>
<pages>62--1</pages>
<contexts>
<context position="14369" citStr="Richardson and Domingos, 2006" startWordPosition="2412" endWordPosition="2415"> predicted from the graph-based techniques mentioned below. 1490 Dataset Method MAP Freebase Probabilities .337 Binarized .344 NELL Probabilities .303 Binarized .319 Table 1: Using binary feature values instead of random walk probabilities gives statistically indistinguishable performance. The p-value on the Freebase data is .55, while it is .25 for NELL. Graph-based methods for KB completion. A separate line of research into KB completion can be broadly construed as performing some kind of inference over graphs in order to predict missing instances in a knowledge base. Markov logic networks (Richardson and Domingos, 2006) fall into this category, as does ProPPR (Wang et al., 2013) and many other logic-based systems. PRA, the main subject of this paper, also fits in this line of work. Work specifically with PRA has ranged from incorporating a parsed corpus as additional evidence when doing random walk inference (Lao et al., 2012), to introducing better representations of the text corpus (Gardner et al., 2013; Gardner et al., 2014), and using PRA in a broader context as part of Google’s Knowledge Vault (Dong et al., 2014). An interesting piece of work that combines embedding methods with graph-based methods is t</context>
</contexts>
<marker>Richardson, Domingos, 2006</marker>
<rawString>Matthew Richardson and Pedro Domingos. 2006. Markov logic networks. Machine learning, 62(1-2):107–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
<author>Benjamin M Marlin</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT.</booktitle>
<contexts>
<context position="12772" citStr="Riedel et al., 2013" startWordPosition="2156" endWordPosition="2159"> 2009; Hoffmann et al., 2011; Surdeanu et al., 2012); these models use the relation instances in a knowledge base as their only supervision, performing some heuristic mapping of the entities in text to the knowledge base, then using that mapping to train extractors for each relation in the KB. The cost of using these methods is that is it generally difficult to incorporate richer features from the knowledge base when predicting whether a particular sentence expresses a relation, and so techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedding methods for KB completion. There has been much recent work that attempts to perform KB completion by learning an embedded representation of entities and relations in the KB and then using these representations to infer missing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al., 2014; Wang et al., 20</context>
</contexts>
<marker>Riedel, Yao, McCallum, Marlin, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. In Proceedings of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Danqi Chen</author>
<author>Christopher D Manning</author>
<author>Andrew Ng</author>
</authors>
<title>Reasoning with neural tensor networks for knowledge base completion.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>926--934</pages>
<contexts>
<context position="13261" citStr="Socher et al., 2013" startWordPosition="2235" endWordPosition="2238">o techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedding methods for KB completion. There has been much recent work that attempts to perform KB completion by learning an embedded representation of entities and relations in the KB and then using these representations to infer missing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al., 2014; Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge base tensor, but when the tensor (or individual relations in the tensor) has high rank, learning good embeddings can be challenging. The ARE model (Nickel et al., 2014) attempted to address this by only making the embeddings capture the residual of the tensor that cannot be readily predicted from the graph-based techniques mentioned below. 1490 Dataset Method MAP Freebase Probabilities .337 Binarized </context>
</contexts>
<marker>Socher, Chen, Manning, Ng, 2013</marker>
<rawString>Richard Socher, Danqi Chen, Christopher D Manning, and Andrew Ng. 2013. Reasoning with neural tensor networks for knowledge base completion. In Advances in Neural Information Processing Systems, pages 926–934.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian Suchanek</author>
<author>James Fan</author>
<author>Raphael Hoffmann</author>
<author>Sebastian Riedel</author>
</authors>
<title>and Partha Pratim Talukdar.</title>
<date>2013</date>
<contexts>
<context position="11319" citStr="Suchanek et al., 2013" startWordPosition="1918" endWordPosition="1921"> connecting that training instance. This means that the matrix computed for each path type should be different for each training instance, and so we either lose our efficiency gain or we accept incorrect probability estimates. In this work we use the rejection sampling technique. As mentioned above, once the feature matrix has been computed in the second step of PRA, one can use any kind of classifier desired to learn a model and make predictions on test data. 3 Related Work The task of knowledge base completion has seen a lot of attention in recent years, with entire workshops devoted to it (Suchanek et al., 2013). We will touch on three broad categories related to KB completion: the task of relation extraction, embedding methods for KB completion, and graph methods for KB completion. Relation extraction. Relation extraction and knowledge base completion have the same goal: to predict new instances of relations in a formal knowledge base such as Freebase or NELL. The difference is that relation extraction focuses on determining what relationship is expressed by a particular sentence, while knowledge base completion tries to predict which relationships hold between which entities. A relation extraction </context>
</contexts>
<marker>Suchanek, Fan, Hoffmann, Riedel, 2013</marker>
<rawString>Fabian Suchanek, James Fan, Raphael Hoffmann, Sebastian Riedel, and Partha Pratim Talukdar. 2013. Advances in automated knowledge base construction. SIGMOD Records journal, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multi-instance multi-label learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>455--465</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="12204" citStr="Surdeanu et al., 2012" startWordPosition="2059" endWordPosition="2062">l: to predict new instances of relations in a formal knowledge base such as Freebase or NELL. The difference is that relation extraction focuses on determining what relationship is expressed by a particular sentence, while knowledge base completion tries to predict which relationships hold between which entities. A relation extraction system can be used for knowledge base completion, but typical KB completion methods do not make predictions on single sentences. This is easily seen in the line of work known as distantly-supervised relation extraction (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012); these models use the relation instances in a knowledge base as their only supervision, performing some heuristic mapping of the entities in text to the knowledge base, then using that mapping to train extractors for each relation in the KB. The cost of using these methods is that is it generally difficult to incorporate richer features from the knowledge base when predicting whether a particular sentence expresses a relation, and so techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedding methods for KB compl</context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multi-label learning for relation extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 455– 465. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Yang Wang</author>
<author>Kathryn Mazaitis</author>
<author>William W Cohen</author>
</authors>
<title>Programming with personalized pagerank: A locally groundable first-order probabilistic logic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22Nd ACM International Conference on Conference on Information &amp;#38; Knowledge Management, CIKM ’13,</booktitle>
<pages>2129--2138</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="14429" citStr="Wang et al., 2013" startWordPosition="2423" endWordPosition="2426"> Method MAP Freebase Probabilities .337 Binarized .344 NELL Probabilities .303 Binarized .319 Table 1: Using binary feature values instead of random walk probabilities gives statistically indistinguishable performance. The p-value on the Freebase data is .55, while it is .25 for NELL. Graph-based methods for KB completion. A separate line of research into KB completion can be broadly construed as performing some kind of inference over graphs in order to predict missing instances in a knowledge base. Markov logic networks (Richardson and Domingos, 2006) fall into this category, as does ProPPR (Wang et al., 2013) and many other logic-based systems. PRA, the main subject of this paper, also fits in this line of work. Work specifically with PRA has ranged from incorporating a parsed corpus as additional evidence when doing random walk inference (Lao et al., 2012), to introducing better representations of the text corpus (Gardner et al., 2013; Gardner et al., 2014), and using PRA in a broader context as part of Google’s Knowledge Vault (Dong et al., 2014). An interesting piece of work that combines embedding methods with graph-based methods is that of Neelakantan et al. (2015), which uses a recursive neu</context>
</contexts>
<marker>Wang, Mazaitis, Cohen, 2013</marker>
<rawString>William Yang Wang, Kathryn Mazaitis, and William W. Cohen. 2013. Programming with personalized pagerank: A locally groundable first-order probabilistic logic. In Proceedings of the 22Nd ACM International Conference on Conference on Information &amp;#38; Knowledge Management, CIKM ’13, pages 2129–2138, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhen Wang</author>
<author>Jianwen Zhang</author>
<author>Jianlin Feng</author>
<author>Zheng Chen</author>
</authors>
<title>Knowledge graph embedding by translating on hyperplanes.</title>
<date>2014</date>
<booktitle>In Proceedings of the TwentyEighth AAAI Conference on Artificial Intelligence,</booktitle>
<pages>1112--1119</pages>
<contexts>
<context position="13375" citStr="Wang et al., 2014" startWordPosition="2255" endWordPosition="2258">l et al., 2013). Embedding methods for KB completion. There has been much recent work that attempts to perform KB completion by learning an embedded representation of entities and relations in the KB and then using these representations to infer missing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al., 2014; Wang et al., 2014). These methods perform well when there is structural redundancy in the knowledge base tensor, but when the tensor (or individual relations in the tensor) has high rank, learning good embeddings can be challenging. The ARE model (Nickel et al., 2014) attempted to address this by only making the embeddings capture the residual of the tensor that cannot be readily predicted from the graph-based techniques mentioned below. 1490 Dataset Method MAP Freebase Probabilities .337 Binarized .344 NELL Probabilities .303 Binarized .319 Table 1: Using binary feature values instead of random walk probabilit</context>
</contexts>
<marker>Wang, Zhang, Feng, Chen, 2014</marker>
<rawString>Zhen Wang, Jianwen Zhang, Jianlin Feng, and Zheng Chen. 2014. Knowledge graph embedding by translating on hyperplanes. In Proceedings of the TwentyEighth AAAI Conference on Artificial Intelligence, pages 1112–1119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert West</author>
<author>Evgeniy Gabrilovich</author>
<author>Kevin Murphy</author>
<author>Shaohua Sun</author>
<author>Rahul Gupta</author>
<author>Dekang Lin</author>
</authors>
<title>Knowledge base completion via search-based question answering.</title>
<date>2014</date>
<booktitle>In WWW.</booktitle>
<contexts>
<context position="1707" citStr="West et al., 2014" startWordPosition="264" endWordPosition="267">LL KB. 1 Introduction Knowledge bases (KBs), such as Freebase (Bollacker et al., 2008), NELL (Mitchell et al., 2015), and DBPedia (Mendes et al., 2012) contain large collections of facts about things, people, and places in the world. These knowledge bases are useful for various tasks, including training relation extractors and semantic parsers (Hoffmann et al., 2011; Krishnamurthy and Mitchell, 2012), and question answering (Berant et al., 2013). While these knowledge bases may be very large, they are still quite incomplete, missing large percentages of facts about common or popular entities (West et al., 2014; Choi et al., 2015). The task of knowledge base completion—filling in missing facts by examining the facts already in the KB, or by looking in a corpus—is one attempt to mitigate the problems of this knowledge sparsity. In this work we examine one method for performing knowledge base completion that is currently in use: the Path Ranking Algorithm (PRA) (Lao et al., 2011; Dong et al., 2014). PRA is a method for performing link prediction in a graph with labeled edges by computing feature matrices over node pairs in the graph. The method has a strong connection to logical inference (Gardner et </context>
</contexts>
<marker>West, Gabrilovich, Murphy, Sun, Gupta, Lin, 2014</marker>
<rawString>Robert West, Evgeniy Gabrilovich, Kevin Murphy, Shaohua Sun, Rahul Gupta, and Dekang Lin. 2014. Knowledge base completion via search-based question answering. In WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston</author>
<author>Antoine Bordes</author>
<author>Oksana Yakhnenko</author>
<author>Nicolas Usunier</author>
</authors>
<title>Connecting language and knowledge bases with embedding models for relation extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="12750" citStr="Weston et al., 2013" startWordPosition="2152" endWordPosition="2155">action (Mintz et al., 2009; Hoffmann et al., 2011; Surdeanu et al., 2012); these models use the relation instances in a knowledge base as their only supervision, performing some heuristic mapping of the entities in text to the knowledge base, then using that mapping to train extractors for each relation in the KB. The cost of using these methods is that is it generally difficult to incorporate richer features from the knowledge base when predicting whether a particular sentence expresses a relation, and so techniques that make fuller use of the KB can perform better on the KB completion task (Weston et al., 2013; Riedel et al., 2013). Embedding methods for KB completion. There has been much recent work that attempts to perform KB completion by learning an embedded representation of entities and relations in the KB and then using these representations to infer missing relationships. Some of earliest work along these lines were the RESCAL model (Nickel et al., 2011) and Structured Embeddings (Bordes et al., 2011). These were soon followed by TransE (Bordes et al., 2013), Neural Tensor Networks (Socher et al., 2013), and many variants on all of these algorithms (Chang et al., 2014; Garcia-Dur´an et al.,</context>
</contexts>
<marker>Weston, Bordes, Yakhnenko, Usunier, 2013</marker>
<rawString>Jason Weston, Antoine Bordes, Oksana Yakhnenko, and Nicolas Usunier. 2013. Connecting language and knowledge bases with embedding models for relation extraction. In Proceedings of EMNLP.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>