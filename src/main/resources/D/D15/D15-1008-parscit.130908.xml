<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.677535">
Open Extraction of Fine-Grained Political Statements
</title>
<author confidence="0.991953">
David Bamman
</author>
<affiliation confidence="0.9992005">
School of Information
University of California, Berkeley
</affiliation>
<address confidence="0.6102">
Berkeley, CA 94720, USA
</address>
<email confidence="0.999117">
dbamman@berkeley.edu
</email>
<sectionHeader confidence="0.994802" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999696375">
Text data has recently been used as evi-
dence in estimating the political ideologies
of individuals, including political elites
and social media users. While inferences
about people are often the intrinsic quan-
tity of interest, we draw inspiration from
open information extraction to identify a
new task: inferring the political import of
propositions like OBAMA IS A SOCIAL-
IST. We present several models that ex-
ploit the structure that exists between peo-
ple and the assertions they make to learn
latent positions of people and propositions
at the same time, and we evaluate them on
a novel dataset of propositions judged on a
political spectrum.
</bodyText>
<sectionHeader confidence="0.998784" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997235666666667">
Over the past few years, much work has fo-
cussed on inferring political preferences of peo-
ple from their behavior, both in unsupervised and
supervised settings. Classical ideal point models
(Poole and Rosenthal, 1985; Martin and Quinn,
2002) estimate the political ideologies of legisla-
tors through their observed voting behavior, pos-
sibly paired with the textual content of bills (Ger-
rish and Blei, 2012) and debate text (Nguyen et al.,
2015); other unsupervised models estimate ideolo-
gies of politicians from their speeches alone (Sim
et al., 2013). Twitter users have also been mod-
eled in a similar framework, using their observed
following behavior of political elites as evidence
to be explained (Barber´a, 2015). Supervised mod-
els, likewise, have not only been used for assessing
the political stance of sentences (Iyyer et al., 2014)
but are also very popular for predicting the holis-
tic ideologies of everyday users on Twitter (Rao
et al., 2010; Pennacchiotti and Popescu, 2011;
Al Zamal et al., 2012; Cohen and Ruths, 2013;
</bodyText>
<author confidence="0.431409">
Noah A. Smith
</author>
<affiliation confidence="0.8073545">
Computer Science &amp; Engineering
University of Washington
</affiliation>
<address confidence="0.471978">
Seattle, WA 98195, USA
</address>
<email confidence="0.989182">
nasmith@cs.washington.edu
</email>
<bodyText confidence="0.999701585365853">
Volkova et al., 2014), Facebook (Bond and Mess-
ing, 2015) and blogs (Jiang and Argamon, 2008),
where training data is relatively easy to obtain—
either from user self-declarations, political follow-
ing behavior, or third-party categorizations.
Aside from their intrinsic value, estimates of
users’ political ideologies have been useful for
quantifying the orientation of news media sources
(Park et al., 2011; Zhou et al., 2011). We con-
sider in this work a different task: estimating the
political import of propositions like OBAMA IS A
SOCIALIST.
In focusing on propositional statements, we
draw on a parallel, but largely independent, strand
of research in open information extraction. IE sys-
tems, from early slot-filling models with predeter-
mined ontologies (Hobbs et al., 1993) to the large-
scale open-vocabulary systems in use today (Fader
et al., 2011; Mitchell et al., 2015) have worked
toward learning type-level propositional informa-
tion from text, such as BARACK OBAMA IS PRES-
IDENT. To a large extent, the ability to learn these
facts from text is dependent on having data sources
that are either relatively factual in their presenta-
tion (e.g., news articles and Wikipedia) or are suf-
ficiently diverse to average over conflicting opin-
ions (e.g., broad, random samples of the web).
Many of the propositional statements that in-
dividuals make online are, of course, not objec-
tive descriptions of reality at all, but rather reflect
their own beliefs, opinions and other private men-
tal states (Wiebe et al., 2005). While much work
has investigated methods for establishing the truth
content of individual sentences — whether from
the perspective of veridicality (de Marneffe et al.,
2012), fact assessment (Nakashole and Mitchell,
2014), or subjectivity analysis (Wiebe et al., 2003;
Wilson, 2008) — the structure that exists between
users and their assertions gives us an opportunity
to situate them both in the same political space:
in this work we operate at the level of subject-
</bodyText>
<page confidence="0.872879">
76
</page>
<note confidence="0.9843255">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 76–85,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.7594766">
predicate propositions, and present models that
capture not only the variation in what subjects
(e.g., OBAMA, ABORTION, GUN CONTROL) that
individual communities are more likely to discuss,
but also the variation in what predicates differ-
ent communities assert of the same subject (e.g.,
GLOBAL WARMING IS A HOAX vs. IS A FACT).
The contributions of this work are as follows:
• We present a new evaluation dataset of 766
propositions judged according to their positions
in a political spectrum.
• We present and evaluate several models for es-
timating the ideal points of subject-predicate
propositions, and find that unsupervised meth-
ods perform best (on sufficiently partisan data).
</bodyText>
<sectionHeader confidence="0.891467" genericHeader="introduction">
2 Task and Data
</sectionHeader>
<bodyText confidence="0.999934461538462">
The task that we propose in this work is assessing
the political import of type-level propositions; on
average, are liberals or conservatives more likely
to claim that GLOBAL WARMING IS A HOAX? To
support this task, we create a benchmark of po-
litical propositions, extracted from politically par-
tisan data, paired with human judgments (details
in §2.3). We define a proposition to be a tuple
comprised of a subject and predicate, each consist-
ing of one or more words, such as (global warm-
ing, is a hoax).1 We adopt an open vocabulary
approach where each unique predicate defines a
unary relation.
</bodyText>
<subsectionHeader confidence="0.982311">
2.1 Data
</subsectionHeader>
<bodyText confidence="0.997635090909091">
In order to extract propositions that are likely to be
political in nature and exhibit variability accord-
ing to ideology, we collect data from a politically
volatile source: comments on partisan blogs.
We draw data from NPR,2 Mother Jones3 and
Politico4, all listed by Pew Research (Mitchell
et al., 2014) as news sources most trusted by
those with consistently liberal views; Breitbart,5
most trusted by those with consistently conser-
vative views; and the Daily Caller,6 Young Con-
servatives7 and the Independent Journal Review,8
</bodyText>
<footnote confidence="0.998635222222222">
1We use these typographical conventions throughout:
Subjects are in sans serif, predicates in italics.
2http://www.npr.org
3http://www.motherjones.com
4http://www.politico.com
5http://www.breitbart.com
6http://dailycaller.com
7http://www.youngcons.com
8https://www.ijreview.com
</footnote>
<bodyText confidence="0.9499505">
all popular among conservatives (Kaufman, 2014).
All data comes from articles published between
2012–2015 and is centered on the US political
landscape.
</bodyText>
<table confidence="0.993748333333333">
Source Articles Posts Tokens Users
Politico 10,305 9.8M 348.4M 173,519
Breitbart 46,068 8.8M 336.4M 165,607
Daily Caller 46,114 5.4M 240.4M 228,696
Mother Jones 16,830 1.9M 119.2M 138,995
NPR 14993 1.6M 82.6M 62,600
IJ Review 3,396 278K 13.1M 51,589
Young Cons. 4,948 222K 10.6M 34,434
Total 142,654 28.0M 1.15B 621,231
</table>
<tableCaption confidence="0.999763">
Table 1: Data.
</tableCaption>
<bodyText confidence="0.999330125">
We gather comments using the Disqus API;9 as
a comment hosting service, Disqus allows users to
post to different blogs using a single identity. Ta-
ble 1 lists the total number of articles, user com-
ments, unique users and tokens extracted from
each blog source. In total, we extract 28 million
comments (1.2 billion tokens) posted by 621,231
unique users.10
</bodyText>
<subsectionHeader confidence="0.99966">
2.2 Extracting Propositions
</subsectionHeader>
<bodyText confidence="0.99412975">
The blog comments in table 1 provide raw data
from which to mine propositional assertions. In
order to extract structured (subject, predicate)
propositions from text, we first parse all com-
ments using the collapsed dependencies (de Marn-
effe and Manning, 2008) of the Stanford parser
(Manning et al., 2014), and identify all subjects as
those that hold an nsubj or nsubjpass relation
to their head. In order to balance the tradeoff be-
tween generality and specificity in the representa-
tion of assertions, we extract three representations
of each predicate.
</bodyText>
<listItem confidence="0.993689909090909">
1. Exact strings, which capture verbatim the
specific nuance of the assertion. This in-
cludes all subjects paired with their heads and
all descendants of that head. Tense and num-
ber are preserved.
Example: (Reagan, gave amnesty to 3 mil-
lion undocumented immigrants)
2. Reduced syntactic tuples, which provide
a level of abstraction by lemmatizing word
forms and including only specific syntactic
relationships. This includes propositions de-
</listItem>
<footnote confidence="0.99771">
9https://disqus.com/api/
10While terms of service prohibit our release of this data,
we will make available tools to allow others to collect similar
data from Disqus for these blogs.
</footnote>
<page confidence="0.999351">
77
</page>
<bodyText confidence="0.999917142857143">
fined as nominal subjects paired with their
heads and children of that head that are
negators, modal auxiliaries (can, may, might,
shall, could, would), particles and direct ob-
jects. All word forms are lemmatized, remov-
ing tense information on verbs and number
on nouns.
</bodyText>
<listItem confidence="0.791990666666667">
Example: (Reagan, give amnesty)
3. Subject-verb tuples, which provide a more
general layer of abstraction by only encod-
</listItem>
<bodyText confidence="0.935309074074074">
ing the relationship between a subject and its
main action. In this case, a proposition is de-
fined as the nominal subject and its lemma-
tized head.
Example: (Reagan, give)
The human benchmark defined in §2.3 below
considers only verbatim predicates, while all mod-
els proposed in §3 and all baselines in §4 include
the union of all three representations as data.
Here, syntactic structure not only provides in-
formation in the representation of propositions,
but also allows us to define criteria by which to
exclude predicates — since we are looking to ex-
tract propositions that are directly asserted by an
author of a blog comment (and not second-order
reporting), we exclude all propositions dominated
by an attitude predicate (Republicans think that
Obama should be impeached) and all those con-
tained within a conditional clause (If Obama were
impeached... ). We also exclude all assertions
drawn from questions (i.e., sentences containing
a question mark) and all assertions extracted from
quoted text (i.e., surrounded by quotation marks).
In total, from all 28 million comments across
all seven blogs, we extract all propositions defined
by the criteria above, yielding a total of 61 million
propositions (45 million unique).
</bodyText>
<subsectionHeader confidence="0.999469">
2.3 Human Benchmark
</subsectionHeader>
<bodyText confidence="0.999478519230769">
From all propositions with a verbatim predicate
extracted from the entire dataset, we rank the
most frequent subjects and manually filter out non-
content terms (like that, one, someone, anyone,
etc.) to yield a set of 138 target topics, the most
frequent of which are obama, democrats, bush,
hillary, and america.
For each proposition containing one of these
topics as its subject and mentioned by at least
5 different people across all blogs, we randomly
sampled 1,000 in proportion to their frequency of
use (so that sentences that appear more frequently
in the data are more likely to be sampled); the sen-
tences selected in this random way contain a va-
riety of politically charged viewpoints. We then
presented them to workers on Amazon Mechanical
Turk for judgments on the extent to which they re-
flect a US liberal vs. conservative political world-
view.
For each sentence, we paid 7 annotators in the
United States to a.) confirm that the extracted
sentence was a well-formed assertion and b.) to
rate “the most likely political belief of the per-
son who would say it” on a five-point scale: very
conservative/Republican (−2), slightly conserva-
tive/Republican (−1), neutral (0), slightly lib-
eral/Democrat (1), and very liberal/Democrat (2).
We keep all sentences that at least six annotators
have marked as meaningful (those excluded by
this criterion include sentence fragments like bush
wasn’t and those that are difficult to understand
without context, such as romney is obama) and
where the standard deviation of the responses is
under 1 (which excludes sentences with flat distri-
butions such as government does nothing well and
those with bimodal distributions, such as christie
is done). After this quality control, we average
the responses to create a dataset of 766 proposi-
tions paired with their political judgments. Table
2 presents a random sample of annotations from
this dataset.
proposition mean s.d.
obama lied and people died -2.000 0.000
gay marriage is not a civil right -1.857 0.350
obama can’t be trusted -1.714 0.452
hillary lied -0.857 0.990
hillary won’t run -0.714 0.452
bush was just as bad 0.857 0.639
obama would win 1.429 0.495
rand paul is a phony 1.429 0.495
abortion is not murder 1.571 0.495
hillary will win in 2016 1.857 0.350
</bodyText>
<tableCaption confidence="0.962369">
Table 2: Random sample of AMT annotations.
</tableCaption>
<sectionHeader confidence="0.990261" genericHeader="method">
3 Models
</sectionHeader>
<bodyText confidence="0.99995525">
The models we introduce to assess the political
import of propositions are based on two funda-
mental ideas. First, users’ latent political pref-
erences, while unobserved, can provide an orga-
nizing principle for inference about propositions
in an unsupervised setting. Second, by decou-
pling the variation in subjects discussed by dif-
ferent communities (e.g., liberals may talk more
</bodyText>
<page confidence="0.989401">
78
</page>
<bodyText confidence="0.999976722222222">
about global warming while conservatives may
talk more about gun rights) from variation in what
statements are predicated of those subjects (e.g.,
liberals may assert that (global warming, is a
fact) while conservatives may be more likely to
assert that it is a hoax), we are able to have a more
flexible and interpretable parameterization of ob-
served textual behavior that allows us to directly
measure both.
We present two models below: one that repre-
sents users and propositions as real-valued points,
and another that represents each as categorical
variables. For both models, the input is a set of
users paired with a list of (subject, predicate) tu-
ples they author; the variables of interest we seek
are representations of those users, subjects, and
predicates that explain the coupling between users
and propositions we see.
</bodyText>
<subsectionHeader confidence="0.967782">
3.1 Additive Model
</subsectionHeader>
<bodyText confidence="0.999826">
The first model we present (fig. 1) represents each
user, subject, and predicate as a real-valued point
in K-dimensional space. In the experiments that
follow, we consider the simple case where K = 1
but present the model in more general terms below.
In this model, we parameterize the generative
probability of a subject (like Obama) as used by
an individual u as the exponentiated sum of a
background log frequency of that subject in the
corpus overall (msbj) and K additive effects, nor-
malized over the space of S possible subjects, as a
real-valued analogue to the SAGE model of Eisen-
stein et al. (2011). While the background term
controls the overall frequency of a subject in the
corpus, β E RK×S mediates the relative increase
or decrease in probability of a subject for each la-
tent dimension. Intuitively, when both ηu,k and
βk,sbj (for a given user u, dimension k, and sub-
ject sbj) are the same sign (either both positive
or both negative), the probability of that subject
under that user increases; when they differ, it de-
creases. β·,sbj is a K-dimensional representation
of subject sbj, and ηu,· is a K-dimensional repre-
sentation of user u.
</bodyText>
<equation confidence="0.999600714285714">
P(sbj  |u, η, β, msbj) =
K
exp (�
msbj + Pk=1 ηu,kβk,sbj
K
Psbj0 exp (�
msbj0 + Pk=1 ηu,kβk,sbj0
</equation>
<bodyText confidence="0.999695875">
Likewise, we parameterize the generative proba-
bility of a predicate (conditioned on a subject) in
the same way; for S subjects, each of which con-
tains (up to) P predicates, ψ E RS×K×P captures
the relative increase or decrease in probability for
a given predicate conditioned on its subject, rel-
ative to its background frequency in the corpus
overall, mpred|sbj.
</bodyText>
<equation confidence="0.986547">
P(pred  |sbj, u, η, ψ, mpred|sbj) =
� �
exp mpred|sbj + PK k=1 ηu,kψsbj,k,pred
P � �
mpred0|sbj + PK
pred0 exp
k=1 ηu,kψsbj,k,pred0
(2)
</equation>
<figureCaption confidence="0.765911">
Figure 1: Additive model with decoupled subjects
</figureCaption>
<bodyText confidence="0.907639142857143">
and predicates. η contains a K-dimensional repre-
sentation of each user; β captures the variation in
observed subjects, and ψ captures the variation in
predicates for a fixed subject.
The full generative story for this model runs as
follows. For a vocabulary of subjects of size S,
where each subject s has P predicates:
</bodyText>
<listItem confidence="0.870013416666667">
– For each dimension k, draw subject coefficients
βk E RS — Norm(µs, σsI)
– For each subject s:
– For each dimension k, draw subject-specific
predicate coefficients ψs,k E RP —
Norm(µp, σpI)
– For each user u:
– Draw user representation η E RK —
Norm(µ, σI)
– For each proposition (sbj, pred) made by u:
– Draw sbj according to eq. 1
– Draw pred according to eq. 2
</listItem>
<bodyText confidence="0.998403">
The unobserved quantities of interest in this
model are η, β and ψ. In the experiments reported
</bodyText>
<figure confidence="0.995280866666667">
µs
R
6s
msbj mpred
sbj
µ 6
pred
Tl
W
U
K
µp
6p
V
(1)
</figure>
<page confidence="0.9898">
79
</page>
<bodyText confidence="0.999618923076923">
below, we set the prior distributions on η, β and
ψ to be standard normals (µ = 0, σ = 1) and per-
form maximum a posteriori inference with respect
to η, β and ψ in turn for a total of 25 iterations.
While β and ψ provide scores for the polit-
ical import of subjects and of predicates condi-
tioned on fixed subjects, respectively, we can re-
cover a single ideological score for both a subject
and its predicate by adding their effects together.
In the evaluation given in §5, let the PREDICATE
SCORE for (subject, predicate) be that given by
ψsubject,·,predicate, and let the PROPOSITION SCORE
be β·,subject + ψsubject,·,predicate.
</bodyText>
<subsectionHeader confidence="0.994358">
3.2 Single Membership Model
</subsectionHeader>
<bodyText confidence="0.990665555555555">
While the additive model above represents each
user and proposition as a real-valued point in K-
dimensional space, we can also represent those
values as categorical variables in an unsupervised
naive Bayes parameterization; in this case, a user
is not defined as a mixture of different effects, but
rather belongs to a single unique community. The
generative story for this model (shown in fig. 2) is
as follows:
</bodyText>
<listItem confidence="0.844697">
– Draw population distribution over categories
θ — Dir(α)
– For each category k, draw distribution over sub-
jects φk — Dir(γ)
– For each category k and subject s:
– Draw distribution over subject-specific predi-
cates ξk,s — Dir(γs)
– For each user u:
– Draw user type index z — Cat(θ)
– For each proposition (sbj, pred) made by u:
– Draw subject sbj — Cat(φz)
– Draw predicate pred — Cat(ξz,sbj)
</listItem>
<bodyText confidence="0.897189894736842">
We set K = 2 in an attempt to recover a dis-
tinction between liberal and conservative users.
For the experiments reported below, we run in-
ference using collapsed Gibbs sampling (Griffiths
and Steyvers, 2004) for 100 iterations, perform-
ing hyperparameter optimization on α, γ and γs
(all asymmetric) every 10 using the fixed-point
method of Minka (2003).
In order to compare the subject-specific predi-
cate distributions across categories, we first calcu-
late the posterior predictive distribution by taking
a single sample of all latent variables z to estimate
Figure 2: Single membership model with decou-
pled subjects and predicates. z is the latent cate-
gory identity of a user (e.g., liberal or conserva-
tive); φ is a distribution over subjects for each cat-
egory; and ξ is a distribution of predicates given
subject s.
the following (Asuncion et al., 2009):
</bodyText>
<equation confidence="0.999298666666667">
c(z v) + γv
ζz,v = E (3)
v&apos; c(z, vt) + γv&apos;
</equation>
<bodyText confidence="0.9994684">
Where ˆζz,v is the vth element of the zth multino-
mial being estimated, c(z, v) is the count of ele-
ment v associated with category z and γv is the
associated Dirichlet hyperparameter for that ele-
ment. Given this smoothed distribution, for each
proposition we assign it a real valued score, the
log-likelihood ratio between its value in these two
distributions. In the evaluation that follows, let the
PREDICATE SCORE for a given (subject, predi-
cate) under this model be:
</bodyText>
<equation confidence="0.955735857142857">
log �
ˆξ0,subject,predicate (4)
ˆξ1,subject,predicate
Let the PROPOSITION SCORE be:
�
ˆξ0,subject,predicate (5)
ˆφ1,subject X ˆξ1,subject,predicate
</equation>
<sectionHeader confidence="0.996251" genericHeader="method">
4 Comparison
</sectionHeader>
<bodyText confidence="0.999973571428571">
The two models described in §3 are unsupervised
methods for estimating the latent political posi-
tions of users along with propositional assertions.
We compare with three other models, a mixture
of unsupervised, supervised, and semi-supervised
methods. Unlike our models, these were not de-
signed for the task described in §2.
</bodyText>
<figure confidence="0.9905841">
�
Y z Ys
sbj
a 0
pred
Wa
U
4
log
ˆφ0,subject X
</figure>
<page confidence="0.943584">
80
</page>
<subsectionHeader confidence="0.981221">
4.1 Principal Component Analysis
</subsectionHeader>
<bodyText confidence="0.99999064">
To compare against another purely unsupervised
model, we evaluate against principal component
analysis (PCA), a latent linear model that min-
imizes the average reconstruction error between
an original data matrix X E Rn&amp;quot;p and a low-
dimensional approximation ZWT, where Z E
Rn&amp;quot;K can be thought of as a K-dimensional la-
tent representation of the input and W E Rp&amp;quot;K
contains the eigenvectors of the K largest eigen-
values of the covariance matrix XXT, providing
a K-dimensional representation for each feature.
We perform PCA with K = 1 on two representa-
tions of our data: a.) counts, where the input data
matrix contains the counts for each proposition for
each user, and b.) frequencies, where we normal-
ize those counts for each user to unit length. While
the input data is sparse, we must center each col-
umn to have a 0 mean (resulting in a dense ma-
trix) and perform PCA through a singular value
decomposition of that column-centered data using
the method of Halko (2011); in using SVD for
PCA, the right singular vectors correspond to the
principal directions; from these we directly read
off a K = 1 dimensional score for each proposi-
tion in our data.
</bodyText>
<subsectionHeader confidence="0.969057">
4.2 E2-Regularized Logistic Regression
</subsectionHeader>
<bodyText confidence="0.999905585365854">
While unsupervised methods potentially allow us
to learn interesting structure in data, they are of-
ten eclipsed in prediction tasks by the addition of
any form of supervision. While purely supervised
models give more control over the exact decision
boundary being learned, they can suffer by learn-
ing from a much smaller training set than unsu-
pervised methods have access to. To evaluate this
tradeoff, we compare against a supervised model
trained using naturally occurring data – users who
self-declare themselves in their profiles to be lib-
eral, conservative, democrat, or republican. We
randomly sampled 150 users who self-identify as
liberals and 150 who identify as conservatives. We
do not expect these users to be a truly random sam-
ple of the population — those who self-declare
their political affiliation are more likely to engage
with political content differently from those who
do not (Sandvig, 2015; Hargittai, 2015) — but is a
method that has been used for political prediction
tasks in the past (Cohen and Ruths, 2013).
We build a predictive model using two classes
of features: a.) binary indicators of the most
frequent 25,000 unigrams and multiword expres-
sions11 in the corpus overall; and b.) features de-
rived from user posting activity to the seven blogs
shown in table 1 (binary indicators of the blogs
posted to, and the identity of the most frequent
blog). In a tenfold cross-validation (using E2-
regularized logistic regression), this classifier at-
tains an accuracy rate of 76.7% (with a standard
error of f1.7 across the ten folds).
In order to establish real-valued scores for
propositions, we follow the same method as for
the single membership model described above, us-
ing the log likelihood ratio of the probability of
the proposition under each condition, where that
probability is given as the count of the proposi-
tion among users classified as (e.g.) liberals (plus
some small smoothing factor) divided by the total
number of propositions used by them overall.
</bodyText>
<equation confidence="0.99668475">
P(prop  |z = conservative)
score(prop) = log
P(prop  |z = liberal)
(6)
</equation>
<subsectionHeader confidence="0.974551">
4.3 Co-Training
</subsectionHeader>
<bodyText confidence="0.9999845">
Since the features we use for the supervised model
provide two roughly independent views of the
data, we also evaluate against the semi-supervised
method of co-training (Blum and Mitchell, 1998).
Here, we train two different logistic regression
classifiers, each with access to only the unigrams
and multiword expressions employed by the user
(hwords) or to binary indicators of the blogs posted
to and the identity of the most frequent blog
(hbloys). For ten iterations, we pick a random sam-
ple U&apos; of 1,000 data points from the full dataset
U and classify each using the two classifiers;
each classifier then adds up to 100 of the highest-
confidence predictions to the training set, retaining
the class distribution balance of the initial training
set; after training, the final predictive probability
for an item is the product of the two trained clas-
sifiers. In a tenfold cross-validation, co-training
yielded a slightly higher (but not statistically sig-
nificant) accuracy over pure supervision (77.0%
f1.8). We calculate scores for propositions in the
same way as for the fully supervised case above.
</bodyText>
<sectionHeader confidence="0.998581" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.78708575">
For the experiments that follow, we limit the input
data available to all models to only those propo-
11Multiword expressions were found using the method of
Justeson and Katz (1995).
</bodyText>
<page confidence="0.997923">
81
</page>
<bodyText confidence="0.999930166666667">
sitions whose subject falls within the evaluation
benchmark; and include only propositions used by
at least five different users, and only users who
make at least five different assertions, yielding a
total dataset of 40,803 users and 1.9 million propo-
sitions (81,728 unique), containing the union of all
three kinds of extracted propositions from §2.2.
Each of the automatic methods that we discuss
above assigns a real-valued score to propositions
like OBAMA IS A SOCIALIST. Our goal in evalu-
ation is to judge how well those model scores re-
cover those assigned by humans in our benchmark.
Since each method may make different assump-
tions about the distribution of scores (and normal-
izing them may be sensitive to outliers), we do not
attempt to model them directly, but rather use two
nonparametric tests: Spearman’s rank correlation
coefficient and cluster purity.
</bodyText>
<equation confidence="0.853956666666667">
their model counterparts.12
Purity = N (max |g1 n cj  |+ max |g2 n cj  |�
(7)
</equation>
<bodyText confidence="0.997400666666667">
A perfect purity score (in which all items from
each cluster in C are matched to the same cluster
in !g) is 1.0; given that all clusters are identically
sized (being defined as the set falling on each half
of a midpoint), a random assignment would yield
a score of 0.50 in expectation.
</bodyText>
<table confidence="0.999772">
Model Purity Spearman’s p
Additive (PROP.) 0.757 ±0.020 0.648 ±0.017
Single mem. (PROP.) 0.754 ±0.019 0.628 ±0.017
Single mem. (PRED.) 0.702 ±0.018 0.555 ±0.015
Additive (PRED.) 0.705 ±0.018 0.490 ±0.013
Co-training 0.695 ±0.018 0.450 ±0.013
LR 0.619 ±0.016 0.278 ±0.010
PCA (frequency) 0.518 ±0.014 0.098 ±0.009
PCA (counts) 0.514 ±0.014 0.066 ±0.008
</table>
<tableCaption confidence="0.999707">
Table 3: Evaluation. Higher is better.
</tableCaption>
<bodyText confidence="0.9599543">
Spearman’s rank correlation coefficient. The
set of scores in the human benchmark and as out-
put by a model each defines a ranked list of propo-
sitions; Spearman’s rank correlation coefficient
(p) is a nonparametric test of the Pearson correla-
tion coefficient measured over the ranks of items
in two lists (rather than their values). We use
the absolute value of p to compare the degree to
which the ranked propositions of two lists are lin-
early correlated; a perfect correlation would have
p = 1.0; no correlation would have p = 0.0.
Purity. While Spearman’s rank correlation co-
efficient gives us a nonparametric estimate of the
degree to which the exact order of two sequences
are the same, we can also soften the exact order-
ing assumption and evaluate the degree to which a
ranked proposition falls on the correct side of the
political continuum (i.e., not considering whether
OBAMA IS A SOCIALIST is more or less conserva-
tive than OBAMA IS A DICTATOR but rather that it
is more conservative than liberal). For each ranked
list, we form two clusters of propositions, split at
the midpoint: all scores below the midpoint de-
fine one cluster, and all scores above or equal de-
fine a second. For N = 766 propositions, given
gold clusters !g = {g1, g21 and model clusters
Cn = {c1, c21 (each containing 383 propositions),
we calculate purity as the average overlap for the
best alignment between the two gold clusters and
Table 3 presents the results of this evaluation.
For both of the models described in §3, we present
results for scoring a proposition like OBAMA IS
A SOCIALIST based only on the conditional pred-
icate score (PRED.) and on a score that includes
variation in the subject as well (PROP.). Since both
models are fit using approximate inference with a
non-convex objective function, we run five models
with different random initializations and present
the average across all five.
We estimate confidence intervals using the
block jackknife (Quenouille, 1956; Efron and
Stein, 1981), calculating purity and Spearman’s
p over 76 resampled subsets of the full 766 ele-
ments, each leaving out 10.13 For both metrics,
the two best performing models show statistically
significant improvement over all other models, but
are not significantly different from each other.
We draw two messages from these results:
For heavily partisan data, unsupervised meth-
ods are sufficient. In drawing on comments on
politically partisan blogs, we are able to match hu-
man judgments of the political import of proposi-
tions quite well (both of the unsupervised models
12In this case, with two clusters on each side, the best
alignment in maximal in that gn,i → cn,j ⇒ gn,¬i → cn,¬j.
13As a clustering metric, purity has no closed-form expres-
sion for confidence sets, and since its evaluation requires its
elements to be unique (in order to be matched across clus-
ters), we cannot use common resampling-with-replacement
techniques such as the bootstrap (Efron, 1979).
</bodyText>
<page confidence="0.997617">
82
</page>
<bodyText confidence="0.999965206896552">
described in §3 outperform their supervised and
semi-supervised counterparts by a large margin),
which suggests that the easiest structure to find in
this particular data is the affiliation of users with
their political ideologies. Both unsupervised mod-
els are able to exploit the natural structure with-
out being constrained by a small amount of train-
ing data that may be more biased (e.g., in its class
balance) than helpful. The two generative models
also widely outperform PCA, which may reflect a
mismatch between its underlying assumptions and
the textual data we observe; PCA treats data spar-
sity as structural zeros (not simply missing data)
and so must model not only the variation that ex-
ists between users, but also the variation that exists
in their frequency of use; other latent component
models may be a better fit for this kind of data.
Joint information is important. For both mod-
els, including information about the full joint
probability of a subject and predicate together
yields substantial improvements for both purity
and the Spearman correlation coefficient com-
pared to scores calculated from variation in the
conditional predicate alone. While we might have
considered variation in the predicate to be suffi-
cient in distinguishing between political parties,
we see that this is simply not the case; variation
in the subject may help anchor propositions in the
spectrum relative to each other.
</bodyText>
<sectionHeader confidence="0.899147" genericHeader="method">
6 Convergent Validity
</sectionHeader>
<bodyText confidence="0.999961583333333">
The primary quantity of interest that we are trying
to estimate in the models described above is the
political position of an assertion; a user’s latent
political affiliation is only a helpful auxiliary vari-
able in reaching this goal. We can, however, also
measure the correlation of those variables them-
selves with other variables of interest, such as
users’ self-declarations of political affiliation and
audience participation on the different blogs. Both
provide measures of convergent validity that con-
firm the distinction being made in our models is
indeed one of political ideology.
</bodyText>
<subsectionHeader confidence="0.999806">
6.1 Correlation with Self-declarations
</subsectionHeader>
<bodyText confidence="0.999864681818182">
One form of data not exploited by the unsu-
pervised models described above are users’ self-
declarations; we omit these above in order to make
the models as general as possible (requiring only
text and not metadata), but they can provide an
independent measure of the distinctions our un-
supervised models are learning. (The supervised
baselines in contrast are able to draw on this pro-
file information for training data.)
Approximately 12% of the users in the data in-
put to our models (4,718 of 40,804) have affiliated
self-declared profile information; the most fre-
quent of these include retired, businessman, stu-
dent, and patriot. For all of these users, we regress
binary indicators of the top 25,000 unigrams in
their profiles against the MAP estimate of their po-
litical affiliation in the single-membership model.
Across all 5 folds, the features with the highest
predictive weights for one class were patriot, con-
servative, obama, and god while the highest pre-
dictive weights for the other are progressive, voter,
liberal, and science.
</bodyText>
<subsectionHeader confidence="0.994636">
6.2 Estimating Media Audience
</subsectionHeader>
<bodyText confidence="0.998786375">
We can also use users’ latent political ideologies to
estimate the overall ideological makeup of a blog’s
active audience. If we assign each post to our es-
timate of the political ideology of its author, we
find that Mother Jones has the highest fraction of
comments by estimated liberals at 80.4%, while
Breitbart has the highest percentage of comments
by conservatives (79.5%).
</bodyText>
<table confidence="0.999564625">
Blog % Liberal by post
Mother Jones 80.4%
NPR 67.4%
Politico 51.6%
Young Conservatives 38.0%
Daily Caller 28.4%
IJ Review 28.0%
Breitbart 20.5%
</table>
<tableCaption confidence="0.999706">
Table 4: Media audience.
</tableCaption>
<bodyText confidence="0.999923">
This broadly accords with Mitchell et al. (2014),
which finds that among the blogs in our dataset,
consistently liberal respondents trust NPR and
Mother Jones most, while consistent conservatives
trust Breitbart most and NPR and Mother Jones
the least.
</bodyText>
<sectionHeader confidence="0.998773" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999915">
We introduce the task of estimating the political
import of propositions such as OBAMA IS A SO-
CIALIST; while much work in open information
extraction has focused on learning facts such as
OBAMA IS PRESIDENT from text, we are able to
exploit structure in the users and communities who
make such assertions in order to align them all
</bodyText>
<page confidence="0.996044">
83
</page>
<bodyText confidence="0.999427166666667">
within the same political space. Given sufficiently
partisan data (here, comments on political blogs),
we find that the unsupervised generative models
presented here are able to outperform other mod-
els, including those given access to supervision.
One natural downstream application of this
work is fine-grained opinion polling; while ex-
isting work has leveraged social media data on
Twitter for uncovering correlations with con-
sumer confidence, political polls (O’Connor et al.,
2010), and flu trends (Paul and Dredze, 2011),
our work points the way toward identifying fine-
grained, interpretable propositions in public dis-
course and estimating latent aspects (such as po-
litical affiliation) of the communities who as-
sert them. Data and code to support this work
can be found at http://people.ischool.
berkeley.edu/˜dbamman/emnlp2015/.
</bodyText>
<sectionHeader confidence="0.998754" genericHeader="acknowledgments">
8 Acknowledgments
</sectionHeader>
<bodyText confidence="0.999591222222222">
We thank Jacob Eisenstein and our anonymous re-
viewers for their helpful comments. The research
reported in this article was largely performed
while both authors were at Carnegie Mellon Uni-
versity, and was supported by NSF grant IIS-
1211277. This work was made possible through
the use of computing resources made available by
the Open Science Data Cloud (OSDC), an Open
Cloud Consortium (OCC)-sponsored project.
</bodyText>
<sectionHeader confidence="0.997463" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99894276056338">
Faiyaz Al Zamal, Wendy Liu, and Derek Ruths. 2012.
Homophily and latent attribute inference: Inferring
latent attributes of Twitter users from neighbors. In
Proc. of ICWSM.
Arthur U. Asuncion, Max Welling, Padhraic Smyth,
and Yee Whye Teh. 2009. On smoothing and in-
ference for topic models. In Proc. of UAI.
Pablo Barber´a. 2015. Birds of the same feather
tweet together: Bayesian ideal point estimation us-
ing Twitter data. Political Analysis, 23(1):76–91.
Avrim Blum and Tom Mitchell. 1998. Combining
labeled and unlabeled data with co-training. In
Proc. of COLT.
Robert Bond and Solomon Messing. 2015. Quan-
tifying social media’s political space: Estimat-
ing ideology from publicly revealed preferences
on Facebook. American Political Science Review,
109(01):62–78.
Raviv Cohen and Derek Ruths. 2013. Classifying
political orientation on Twitter: It’s not easy! In
Proc. of ICWSM.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. Stanford typed dependencies manual.
Technical report, Stanford University.
Marie-Catherine de Marneffe, Christopher D. Man-
ning, and Christopher Potts. 2012. Did it happen?
the pragmatic complexity of veridicality assessment.
Computational Linguistics, 38(2):301–333.
Bradley Efron and Charles Stein. 1981. The jack-
knife estimate of variance. The Annals of Statistics,
9(3):586–596.
Bradley Efron. 1979. Bootstrap methods: another look
at the jackknife. The Annals of Statistics, 7(1):1–26.
Jacob Eisenstein, Amr Ahmed, and Eric P. Xing.
2011. Sparse additive generative models of text. In
Proc. of ICML.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proc. of EMNLP.
Sean Gerrish and David M. Blei. 2012. How they
vote: Issue-adjusted models of legislative behavior.
In NIPS.
Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
Academy of Sciences of the United States of Amer-
ica, 101(Suppl. 1):5228–5235.
Nathan Halko, Per-Gunnar Martinsson, Yoel Shkol-
nisky, and Mark Tygert. 2011. An algorithm for
the principal component analysis of large data sets.
SIAM Journal on Scientific Computing, 33(5):2580–
2594.
Eszter Hargittai. 2015. Why doesn’t Science publish
important methods info prominently? http://
goo.gl/wXUtys, May.
Jerry R. Hobbs, Douglas Appelt, John Bear, David Is-
rael, Megumi Kameyama, and Mabry Tyson. 1993.
Fastus: A system for extracting information from
text. In Proc. of HLT.
Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, and
Philip Resnik. 2014. Political ideology detection
using recursive neural networks. In Proc. of ACL.
Maojin Jiang and Shlomo Argamon. 2008. Exploit-
ing subjectivity analysis in blogs to improve political
leaning categorization. In Proc. of SIGIR.
John S. Justeson and Slava M. Katz. 1995. Technical
terminology: some linguistic properties and an al-
gorithm for identification in text. Natural language
engineering, 1(1):9–27.
Leslie Kaufman. 2014. Independent Journal Review
website becomes a draw for conservatives. New
York Times, Nov. 2, 2014.
</reference>
<page confidence="0.983412">
84
</page>
<reference confidence="0.999630481927711">
Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In Proc. of ACL.
Andrew D. Martin and Kevin M. Quinn. 2002. Dy-
namic ideal point estimation via Markov Chain
Monte Carlo for the U.S. Supreme Court, 1953–
1999. Political Analysis, 10(2):134–153.
Thomas P. Minka. 2003. Estimating a Dirichlet
distribution. http://research.microsoft.
com/en-us/um/people/minka/papers/
dirichlet/.
Amy Mitchell, Jeffrey Gottfried, Jocelyn Kiley, and
Katerina Eva Matsa. 2014. Political polarization
and media habits: From Fox News to Facebook,
how liberals and conservatives keep up with politics.
Technical report, Pew Research Center.
T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, J. Bet-
teridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel,
J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed,
N. Nakashole, E. Platanios, A. Ritter, M. Samadi,
B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen,
A. Saparov, M. Greaves, and J. Welling. 2015.
Never-ending learning. In Proc. of AAAI.
Ndapandula Nakashole and Tom M. Mitchell. 2014.
Language-aware truth assessment of fact candidates.
In ACL.
Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik,
and Kristina Miler. 2015. Tea party in the house: A
hierarchical ideal point topic model and its applica-
tion to Republican legislators in the 112th Congress.
In Proc. of ACL.
Brendan O’Connor, Ramnath Balasubramanyan,
Bryan R. Routledge, and Noah A. Smith. 2010.
From tweets to polls: Linking text sentiment to
public opinion time series. In Proc. of ICWSM.
Souneil Park, Minsam Ko, Jungwoo Kim, Ying Liu,
and Junehwa Song. 2011. The politics of com-
ments: Predicting political orientation of news
stories with commenters’ sentiment patterns. In
Proc. of CSCW.
Michael J Paul and Mark Dredze. 2011. You are what
you Tweet: Analyzing twitter for public health. In
Proc. of ICWSM.
Marco Pennacchiotti and Ana-Maria Popescu. 2011.
Democrats, Republicans and Starbucks afficionados:
User classification in Twitter. In Proc. of KDD.
Keith T. Poole and Howard Rosenthal. 1985. A spa-
tial model for legislative roll call analysis. American
Journal of Political Science, 29(2):357–384.
Maurice H. Quenouille. 1956. Notes on bias in esti-
mation. Biometrika, 43(3/4):353–360.
Delip Rao, David Yarowsky, Abhishek Shreevats, and
Manaswi Gupta. 2010. Classifying latent user at-
tributes in Twitter. In Proc. of SMUC.
Christian Sandvig. 2015. The Facebook “it’s not our
fault” study. http://blogs.law.harvard.
edu/niftyc/archives/1062, May.
Yanchuan Sim, Brice D. L. Acree, Justin H. Gross, and
Noah A. Smith. 2013. Measuring ideological pro-
portions in political speeches. In Proc. of EMNLP.
Svitlana Volkova, Glen Coppersmith, and Benjamin
Van Durme. 2014. Inferring user political prefer-
ences from streaming communications. In Proc. of
ACL.
Janyce Wiebe, Eric Breck, Chris Buckley, Claire
Cardie, Paul Davis, Bruce Fraser, Diane J. Litman,
David R. Pierce, Ellen Riloff, and Theresa Wilson.
2003. Recognizing and organizing opinions ex-
pressed in the world press. In Proceedings of the
2003 AAAI Spring Symposium on New Directions in
Question Answering.
Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language. Language Resources and Evalu-
ation, 39(2-3):165–210.
Theresa Ann Wilson. 2008. Fine-grained subjectiv-
ity and sentiment analysis: recognizing the intensity,
polarity, and attitudes ofprivate states. Ph.D. thesis,
University of Pittsburgh.
Daniel Xiaodan Zhou, Paul Resnick, and Qiaozhu Mei.
2011. Classifying the political leaning of news arti-
cles and users from user votes. In Proc. of ICWSM.
</reference>
<page confidence="0.999696">
85
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.964639">
<title confidence="0.999962">Open Extraction of Fine-Grained Political Statements</title>
<author confidence="0.994062">David</author>
<affiliation confidence="0.999675">School of University of California,</affiliation>
<address confidence="0.999514">Berkeley, CA 94720,</address>
<email confidence="0.999731">dbamman@berkeley.edu</email>
<abstract confidence="0.998316588235294">Text data has recently been used as evidence in estimating the political ideologies of individuals, including political elites and social media users. While inferences about people are often the intrinsic quantity of interest, we draw inspiration from open information extraction to identify a new task: inferring the political import of like IS A We present several models that exploit the structure that exists between people and the assertions they make to learn latent positions of people and propositions at the same time, and we evaluate them on a novel dataset of propositions judged on a political spectrum.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Faiyaz Al Zamal</author>
<author>Wendy Liu</author>
<author>Derek Ruths</author>
</authors>
<title>Homophily and latent attribute inference: Inferring latent attributes of Twitter users from neighbors.</title>
<date>2012</date>
<booktitle>In Proc. of ICWSM.</booktitle>
<contexts>
<context position="1845" citStr="Zamal et al., 2012" startWordPosition="286" endWordPosition="289">and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a d</context>
</contexts>
<marker>Zamal, Liu, Ruths, 2012</marker>
<rawString>Faiyaz Al Zamal, Wendy Liu, and Derek Ruths. 2012. Homophily and latent attribute inference: Inferring latent attributes of Twitter users from neighbors. In Proc. of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arthur U Asuncion</author>
<author>Max Welling</author>
<author>Padhraic Smyth</author>
<author>Yee Whye Teh</author>
</authors>
<title>On smoothing and inference for topic models.</title>
<date>2009</date>
<booktitle>In Proc. of UAI.</booktitle>
<contexts>
<context position="18466" citStr="Asuncion et al., 2009" startWordPosition="3000" endWordPosition="3003">rming hyperparameter optimization on α, γ and γs (all asymmetric) every 10 using the fixed-point method of Minka (2003). In order to compare the subject-specific predicate distributions across categories, we first calculate the posterior predictive distribution by taking a single sample of all latent variables z to estimate Figure 2: Single membership model with decoupled subjects and predicates. z is the latent category identity of a user (e.g., liberal or conservative); φ is a distribution over subjects for each category; and ξ is a distribution of predicates given subject s. the following (Asuncion et al., 2009): c(z v) + γv ζz,v = E (3) v&apos; c(z, vt) + γv&apos; Where ˆζz,v is the vth element of the zth multinomial being estimated, c(z, v) is the count of element v associated with category z and γv is the associated Dirichlet hyperparameter for that element. Given this smoothed distribution, for each proposition we assign it a real valued score, the log-likelihood ratio between its value in these two distributions. In the evaluation that follows, let the PREDICATE SCORE for a given (subject, predicate) under this model be: log � ˆξ0,subject,predicate (4) ˆξ1,subject,predicate Let the PROPOSITION SCORE be: �</context>
</contexts>
<marker>Asuncion, Welling, Smyth, Teh, 2009</marker>
<rawString>Arthur U. Asuncion, Max Welling, Padhraic Smyth, and Yee Whye Teh. 2009. On smoothing and inference for topic models. In Proc. of UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pablo Barber´a</author>
</authors>
<title>Birds of the same feather tweet together: Bayesian ideal point estimation using Twitter data. Political Analysis,</title>
<date>2015</date>
<marker>Barber´a, 2015</marker>
<rawString>Pablo Barber´a. 2015. Birds of the same feather tweet together: Bayesian ideal point estimation using Twitter data. Political Analysis, 23(1):76–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Avrim Blum</author>
<author>Tom Mitchell</author>
</authors>
<title>Combining labeled and unlabeled data with co-training.</title>
<date>1998</date>
<booktitle>In Proc. of COLT.</booktitle>
<contexts>
<context position="23014" citStr="Blum and Mitchell, 1998" startWordPosition="3753" endWordPosition="3756">r the single membership model described above, using the log likelihood ratio of the probability of the proposition under each condition, where that probability is given as the count of the proposition among users classified as (e.g.) liberals (plus some small smoothing factor) divided by the total number of propositions used by them overall. P(prop |z = conservative) score(prop) = log P(prop |z = liberal) (6) 4.3 Co-Training Since the features we use for the supervised model provide two roughly independent views of the data, we also evaluate against the semi-supervised method of co-training (Blum and Mitchell, 1998). Here, we train two different logistic regression classifiers, each with access to only the unigrams and multiword expressions employed by the user (hwords) or to binary indicators of the blogs posted to and the identity of the most frequent blog (hbloys). For ten iterations, we pick a random sample U&apos; of 1,000 data points from the full dataset U and classify each using the two classifiers; each classifier then adds up to 100 of the highestconfidence predictions to the training set, retaining the class distribution balance of the initial training set; after training, the final predictive prob</context>
</contexts>
<marker>Blum, Mitchell, 1998</marker>
<rawString>Avrim Blum and Tom Mitchell. 1998. Combining labeled and unlabeled data with co-training. In Proc. of COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Bond</author>
<author>Solomon Messing</author>
</authors>
<title>Quantifying social media’s political space: Estimating ideology from publicly revealed preferences on Facebook.</title>
<date>2015</date>
<journal>American Political Science Review,</journal>
<volume>109</volume>
<issue>01</issue>
<contexts>
<context position="2045" citStr="Bond and Messing, 2015" startWordPosition="314" endWordPosition="318">led in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a different task: estimating the political import of propositions like OBAMA IS A SOCIALIST. In focusing on propositional statements, we draw on a parallel, but largely independent, strand of research in</context>
</contexts>
<marker>Bond, Messing, 2015</marker>
<rawString>Robert Bond and Solomon Messing. 2015. Quantifying social media’s political space: Estimating ideology from publicly revealed preferences on Facebook. American Political Science Review, 109(01):62–78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raviv Cohen</author>
<author>Derek Ruths</author>
</authors>
<title>Classifying political orientation on Twitter: It’s not easy!</title>
<date>2013</date>
<booktitle>In Proc. of ICWSM.</booktitle>
<contexts>
<context position="1868" citStr="Cohen and Ruths, 2013" startWordPosition="290" endWordPosition="293">debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a different task: estimati</context>
<context position="21774" citStr="Cohen and Ruths, 2013" startWordPosition="3552" endWordPosition="3555">e against a supervised model trained using naturally occurring data – users who self-declare themselves in their profiles to be liberal, conservative, democrat, or republican. We randomly sampled 150 users who self-identify as liberals and 150 who identify as conservatives. We do not expect these users to be a truly random sample of the population — those who self-declare their political affiliation are more likely to engage with political content differently from those who do not (Sandvig, 2015; Hargittai, 2015) — but is a method that has been used for political prediction tasks in the past (Cohen and Ruths, 2013). We build a predictive model using two classes of features: a.) binary indicators of the most frequent 25,000 unigrams and multiword expressions11 in the corpus overall; and b.) features derived from user posting activity to the seven blogs shown in table 1 (binary indicators of the blogs posted to, and the identity of the most frequent blog). In a tenfold cross-validation (using E2- regularized logistic regression), this classifier attains an accuracy rate of 76.7% (with a standard error of f1.7 across the ten folds). In order to establish real-valued scores for propositions, we follow the s</context>
</contexts>
<marker>Cohen, Ruths, 2013</marker>
<rawString>Raviv Cohen and Derek Ruths. 2013. Classifying political orientation on Twitter: It’s not easy! In Proc. of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>Stanford typed dependencies manual.</title>
<date>2008</date>
<tech>Technical report,</tech>
<institution>Stanford University.</institution>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. Stanford typed dependencies manual. Technical report, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
<author>Christopher Potts</author>
</authors>
<title>Did it happen? the pragmatic complexity of veridicality assessment.</title>
<date>2012</date>
<journal>Computational Linguistics,</journal>
<volume>38</volume>
<issue>2</issue>
<marker>de Marneffe, Manning, Potts, 2012</marker>
<rawString>Marie-Catherine de Marneffe, Christopher D. Manning, and Christopher Potts. 2012. Did it happen? the pragmatic complexity of veridicality assessment. Computational Linguistics, 38(2):301–333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley Efron</author>
<author>Charles Stein</author>
</authors>
<title>The jackknife estimate of variance.</title>
<date>1981</date>
<journal>The Annals of Statistics,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="27734" citStr="Efron and Stein, 1981" startWordPosition="4540" endWordPosition="4543">st alignment between the two gold clusters and Table 3 presents the results of this evaluation. For both of the models described in §3, we present results for scoring a proposition like OBAMA IS A SOCIALIST based only on the conditional predicate score (PRED.) and on a score that includes variation in the subject as well (PROP.). Since both models are fit using approximate inference with a non-convex objective function, we run five models with different random initializations and present the average across all five. We estimate confidence intervals using the block jackknife (Quenouille, 1956; Efron and Stein, 1981), calculating purity and Spearman’s p over 76 resampled subsets of the full 766 elements, each leaving out 10.13 For both metrics, the two best performing models show statistically significant improvement over all other models, but are not significantly different from each other. We draw two messages from these results: For heavily partisan data, unsupervised methods are sufficient. In drawing on comments on politically partisan blogs, we are able to match human judgments of the political import of propositions quite well (both of the unsupervised models 12In this case, with two clusters on ea</context>
</contexts>
<marker>Efron, Stein, 1981</marker>
<rawString>Bradley Efron and Charles Stein. 1981. The jackknife estimate of variance. The Annals of Statistics, 9(3):586–596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bradley Efron</author>
</authors>
<title>Bootstrap methods: another look at the jackknife.</title>
<date>1979</date>
<journal>The Annals of Statistics,</journal>
<volume>7</volume>
<issue>1</issue>
<contexts>
<context position="28691" citStr="Efron, 1979" startWordPosition="4697" endWordPosition="4698">ta, unsupervised methods are sufficient. In drawing on comments on politically partisan blogs, we are able to match human judgments of the political import of propositions quite well (both of the unsupervised models 12In this case, with two clusters on each side, the best alignment in maximal in that gn,i → cn,j ⇒ gn,¬i → cn,¬j. 13As a clustering metric, purity has no closed-form expression for confidence sets, and since its evaluation requires its elements to be unique (in order to be matched across clusters), we cannot use common resampling-with-replacement techniques such as the bootstrap (Efron, 1979). 82 described in §3 outperform their supervised and semi-supervised counterparts by a large margin), which suggests that the easiest structure to find in this particular data is the affiliation of users with their political ideologies. Both unsupervised models are able to exploit the natural structure without being constrained by a small amount of training data that may be more biased (e.g., in its class balance) than helpful. The two generative models also widely outperform PCA, which may reflect a mismatch between its underlying assumptions and the textual data we observe; PCA treats data s</context>
</contexts>
<marker>Efron, 1979</marker>
<rawString>Bradley Efron. 1979. Bootstrap methods: another look at the jackknife. The Annals of Statistics, 7(1):1–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Eisenstein</author>
<author>Amr Ahmed</author>
<author>Eric P Xing</author>
</authors>
<title>Sparse additive generative models of text.</title>
<date>2011</date>
<booktitle>In Proc. of ICML.</booktitle>
<contexts>
<context position="14126" citStr="Eisenstein et al. (2011)" startWordPosition="2232" endWordPosition="2236">1 Additive Model The first model we present (fig. 1) represents each user, subject, and predicate as a real-valued point in K-dimensional space. In the experiments that follow, we consider the simple case where K = 1 but present the model in more general terms below. In this model, we parameterize the generative probability of a subject (like Obama) as used by an individual u as the exponentiated sum of a background log frequency of that subject in the corpus overall (msbj) and K additive effects, normalized over the space of S possible subjects, as a real-valued analogue to the SAGE model of Eisenstein et al. (2011). While the background term controls the overall frequency of a subject in the corpus, β E RK×S mediates the relative increase or decrease in probability of a subject for each latent dimension. Intuitively, when both ηu,k and βk,sbj (for a given user u, dimension k, and subject sbj) are the same sign (either both positive or both negative), the probability of that subject under that user increases; when they differ, it decreases. β·,sbj is a K-dimensional representation of subject sbj, and ηu,· is a K-dimensional representation of user u. P(sbj |u, η, β, msbj) = K exp (� msbj + Pk=1 ηu,kβk,sbj</context>
</contexts>
<marker>Eisenstein, Ahmed, Xing, 2011</marker>
<rawString>Jacob Eisenstein, Amr Ahmed, and Eric P. Xing. 2011. Sparse additive generative models of text. In Proc. of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="2843" citStr="Fader et al., 2011" startWordPosition="437" endWordPosition="440">ions. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a different task: estimating the political import of propositions like OBAMA IS A SOCIALIST. In focusing on propositional statements, we draw on a parallel, but largely independent, strand of research in open information extraction. IE systems, from early slot-filling models with predetermined ontologies (Hobbs et al., 1993) to the largescale open-vocabulary systems in use today (Fader et al., 2011; Mitchell et al., 2015) have worked toward learning type-level propositional information from text, such as BARACK OBAMA IS PRESIDENT. To a large extent, the ability to learn these facts from text is dependent on having data sources that are either relatively factual in their presentation (e.g., news articles and Wikipedia) or are sufficiently diverse to average over conflicting opinions (e.g., broad, random samples of the web). Many of the propositional statements that individuals make online are, of course, not objective descriptions of reality at all, but rather reflect their own beliefs, </context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Gerrish</author>
<author>David M Blei</author>
</authors>
<title>How they vote: Issue-adjusted models of legislative behavior.</title>
<date>2012</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="1242" citStr="Gerrish and Blei, 2012" startWordPosition="187" endWordPosition="191"> between people and the assertions they make to learn latent positions of people and propositions at the same time, and we evaluate them on a novel dataset of propositions judged on a political spectrum. 1 Introduction Over the past few years, much work has focussed on inferring political preferences of people from their behavior, both in unsupervised and supervised settings. Classical ideal point models (Poole and Rosenthal, 1985; Martin and Quinn, 2002) estimate the political ideologies of legislators through their observed voting behavior, possibly paired with the textual content of bills (Gerrish and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2</context>
</contexts>
<marker>Gerrish, Blei, 2012</marker>
<rawString>Sean Gerrish and David M. Blei. 2012. How they vote: Issue-adjusted models of legislative behavior. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>Proceedings of the National Academy of Sciences of the United States of America,</booktitle>
<volume>101</volume>
<pages>1--5228</pages>
<contexts>
<context position="17818" citStr="Griffiths and Steyvers, 2004" startWordPosition="2894" endWordPosition="2897">wn in fig. 2) is as follows: – Draw population distribution over categories θ — Dir(α) – For each category k, draw distribution over subjects φk — Dir(γ) – For each category k and subject s: – Draw distribution over subject-specific predicates ξk,s — Dir(γs) – For each user u: – Draw user type index z — Cat(θ) – For each proposition (sbj, pred) made by u: – Draw subject sbj — Cat(φz) – Draw predicate pred — Cat(ξz,sbj) We set K = 2 in an attempt to recover a distinction between liberal and conservative users. For the experiments reported below, we run inference using collapsed Gibbs sampling (Griffiths and Steyvers, 2004) for 100 iterations, performing hyperparameter optimization on α, γ and γs (all asymmetric) every 10 using the fixed-point method of Minka (2003). In order to compare the subject-specific predicate distributions across categories, we first calculate the posterior predictive distribution by taking a single sample of all latent variables z to estimate Figure 2: Single membership model with decoupled subjects and predicates. z is the latent category identity of a user (e.g., liberal or conservative); φ is a distribution over subjects for each category; and ξ is a distribution of predicates given </context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences of the United States of America, 101(Suppl. 1):5228–5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathan Halko</author>
<author>Per-Gunnar Martinsson</author>
<author>Yoel Shkolnisky</author>
<author>Mark Tygert</author>
</authors>
<title>An algorithm for the principal component analysis of large data sets.</title>
<date>2011</date>
<journal>SIAM Journal on Scientific Computing,</journal>
<volume>33</volume>
<issue>5</issue>
<pages>2594</pages>
<marker>Halko, Martinsson, Shkolnisky, Tygert, 2011</marker>
<rawString>Nathan Halko, Per-Gunnar Martinsson, Yoel Shkolnisky, and Mark Tygert. 2011. An algorithm for the principal component analysis of large data sets. SIAM Journal on Scientific Computing, 33(5):2580– 2594.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eszter Hargittai</author>
</authors>
<title>Why doesn’t Science publish important methods info prominently? http:// goo.gl/wXUtys,</title>
<date>2015</date>
<contexts>
<context position="21670" citStr="Hargittai, 2015" startWordPosition="3534" endWordPosition="3535">maller training set than unsupervised methods have access to. To evaluate this tradeoff, we compare against a supervised model trained using naturally occurring data – users who self-declare themselves in their profiles to be liberal, conservative, democrat, or republican. We randomly sampled 150 users who self-identify as liberals and 150 who identify as conservatives. We do not expect these users to be a truly random sample of the population — those who self-declare their political affiliation are more likely to engage with political content differently from those who do not (Sandvig, 2015; Hargittai, 2015) — but is a method that has been used for political prediction tasks in the past (Cohen and Ruths, 2013). We build a predictive model using two classes of features: a.) binary indicators of the most frequent 25,000 unigrams and multiword expressions11 in the corpus overall; and b.) features derived from user posting activity to the seven blogs shown in table 1 (binary indicators of the blogs posted to, and the identity of the most frequent blog). In a tenfold cross-validation (using E2- regularized logistic regression), this classifier attains an accuracy rate of 76.7% (with a standard error o</context>
</contexts>
<marker>Hargittai, 2015</marker>
<rawString>Eszter Hargittai. 2015. Why doesn’t Science publish important methods info prominently? http:// goo.gl/wXUtys, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
<author>Douglas Appelt</author>
<author>John Bear</author>
<author>David Israel</author>
<author>Megumi Kameyama</author>
<author>Mabry Tyson</author>
</authors>
<title>Fastus: A system for extracting information from text.</title>
<date>1993</date>
<booktitle>In Proc. of HLT.</booktitle>
<contexts>
<context position="2768" citStr="Hobbs et al., 1993" startWordPosition="424" endWordPosition="427"> self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a different task: estimating the political import of propositions like OBAMA IS A SOCIALIST. In focusing on propositional statements, we draw on a parallel, but largely independent, strand of research in open information extraction. IE systems, from early slot-filling models with predetermined ontologies (Hobbs et al., 1993) to the largescale open-vocabulary systems in use today (Fader et al., 2011; Mitchell et al., 2015) have worked toward learning type-level propositional information from text, such as BARACK OBAMA IS PRESIDENT. To a large extent, the ability to learn these facts from text is dependent on having data sources that are either relatively factual in their presentation (e.g., news articles and Wikipedia) or are sufficiently diverse to average over conflicting opinions (e.g., broad, random samples of the web). Many of the propositional statements that individuals make online are, of course, not objec</context>
</contexts>
<marker>Hobbs, Appelt, Bear, Israel, Kameyama, Tyson, 1993</marker>
<rawString>Jerry R. Hobbs, Douglas Appelt, John Bear, David Israel, Megumi Kameyama, and Mabry Tyson. 1993. Fastus: A system for extracting information from text. In Proc. of HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohit Iyyer</author>
<author>Peter Enns</author>
<author>Jordan Boyd-Graber</author>
<author>Philip Resnik</author>
</authors>
<title>Political ideology detection using recursive neural networks.</title>
<date>2014</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1677" citStr="Iyyer et al., 2014" startWordPosition="257" endWordPosition="260">tin and Quinn, 2002) estimate the political ideologies of legislators through their observed voting behavior, possibly paired with the textual content of bills (Gerrish and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of</context>
</contexts>
<marker>Iyyer, Enns, Boyd-Graber, Resnik, 2014</marker>
<rawString>Mohit Iyyer, Peter Enns, Jordan Boyd-Graber, and Philip Resnik. 2014. Political ideology detection using recursive neural networks. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maojin Jiang</author>
<author>Shlomo Argamon</author>
</authors>
<title>Exploiting subjectivity analysis in blogs to improve political leaning categorization.</title>
<date>2008</date>
<booktitle>In Proc. of SIGIR.</booktitle>
<contexts>
<context position="2081" citStr="Jiang and Argamon, 2008" startWordPosition="321" endWordPosition="324">heir observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a different task: estimating the political import of propositions like OBAMA IS A SOCIALIST. In focusing on propositional statements, we draw on a parallel, but largely independent, strand of research in open information extraction. IE sys</context>
</contexts>
<marker>Jiang, Argamon, 2008</marker>
<rawString>Maojin Jiang and Shlomo Argamon. 2008. Exploiting subjectivity analysis in blogs to improve political leaning categorization. In Proc. of SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Technical terminology: some linguistic properties and an algorithm for identification in text. Natural language engineering,</title>
<date>1995</date>
<pages>1--1</pages>
<contexts>
<context position="24116" citStr="Justeson and Katz (1995)" startWordPosition="3932" endWordPosition="3935">ining set, retaining the class distribution balance of the initial training set; after training, the final predictive probability for an item is the product of the two trained classifiers. In a tenfold cross-validation, co-training yielded a slightly higher (but not statistically significant) accuracy over pure supervision (77.0% f1.8). We calculate scores for propositions in the same way as for the fully supervised case above. 5 Evaluation For the experiments that follow, we limit the input data available to all models to only those propo11Multiword expressions were found using the method of Justeson and Katz (1995). 81 sitions whose subject falls within the evaluation benchmark; and include only propositions used by at least five different users, and only users who make at least five different assertions, yielding a total dataset of 40,803 users and 1.9 million propositions (81,728 unique), containing the union of all three kinds of extracted propositions from §2.2. Each of the automatic methods that we discuss above assigns a real-valued score to propositions like OBAMA IS A SOCIALIST. Our goal in evaluation is to judge how well those model scores recover those assigned by humans in our benchmark. Sinc</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>John S. Justeson and Slava M. Katz. 1995. Technical terminology: some linguistic properties and an algorithm for identification in text. Natural language engineering, 1(1):9–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leslie Kaufman</author>
</authors>
<title>Independent Journal Review website becomes a draw for conservatives.</title>
<date>2014</date>
<volume>2</volume>
<location>New York Times,</location>
<contexts>
<context position="6327" citStr="Kaufman, 2014" startWordPosition="971" endWordPosition="972">nd Politico4, all listed by Pew Research (Mitchell et al., 2014) as news sources most trusted by those with consistently liberal views; Breitbart,5 most trusted by those with consistently conservative views; and the Daily Caller,6 Young Conservatives7 and the Independent Journal Review,8 1We use these typographical conventions throughout: Subjects are in sans serif, predicates in italics. 2http://www.npr.org 3http://www.motherjones.com 4http://www.politico.com 5http://www.breitbart.com 6http://dailycaller.com 7http://www.youngcons.com 8https://www.ijreview.com all popular among conservatives (Kaufman, 2014). All data comes from articles published between 2012–2015 and is centered on the US political landscape. Source Articles Posts Tokens Users Politico 10,305 9.8M 348.4M 173,519 Breitbart 46,068 8.8M 336.4M 165,607 Daily Caller 46,114 5.4M 240.4M 228,696 Mother Jones 16,830 1.9M 119.2M 138,995 NPR 14993 1.6M 82.6M 62,600 IJ Review 3,396 278K 13.1M 51,589 Young Cons. 4,948 222K 10.6M 34,434 Total 142,654 28.0M 1.15B 621,231 Table 1: Data. We gather comments using the Disqus API;9 as a comment hosting service, Disqus allows users to post to different blogs using a single identity. Table 1 lists t</context>
</contexts>
<marker>Kaufman, 2014</marker>
<rawString>Leslie Kaufman. 2014. Independent Journal Review website becomes a draw for conservatives. New York Times, Nov. 2, 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Mihai Surdeanu</author>
<author>John Bauer</author>
<author>Jenny Finkel</author>
<author>Steven J Bethard</author>
<author>David McClosky</author>
</authors>
<title>The Stanford CoreNLP natural language processing toolkit.</title>
<date>2014</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="7457" citStr="Manning et al., 2014" startWordPosition="1149" endWordPosition="1152">ce, Disqus allows users to post to different blogs using a single identity. Table 1 lists the total number of articles, user comments, unique users and tokens extracted from each blog source. In total, we extract 28 million comments (1.2 billion tokens) posted by 621,231 unique users.10 2.2 Extracting Propositions The blog comments in table 1 provide raw data from which to mine propositional assertions. In order to extract structured (subject, predicate) propositions from text, we first parse all comments using the collapsed dependencies (de Marneffe and Manning, 2008) of the Stanford parser (Manning et al., 2014), and identify all subjects as those that hold an nsubj or nsubjpass relation to their head. In order to balance the tradeoff between generality and specificity in the representation of assertions, we extract three representations of each predicate. 1. Exact strings, which capture verbatim the specific nuance of the assertion. This includes all subjects paired with their heads and all descendants of that head. Tense and number are preserved. Example: (Reagan, gave amnesty to 3 million undocumented immigrants) 2. Reduced syntactic tuples, which provide a level of abstraction by lemmatizing word</context>
</contexts>
<marker>Manning, Surdeanu, Bauer, Finkel, Bethard, McClosky, 2014</marker>
<rawString>Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. 2014. The Stanford CoreNLP natural language processing toolkit. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew D Martin</author>
<author>Kevin M Quinn</author>
</authors>
<title>Dynamic ideal point estimation via Markov Chain Monte Carlo for the U.S. Supreme Court,</title>
<date>2002</date>
<journal>Political Analysis,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="1078" citStr="Martin and Quinn, 2002" startWordPosition="162" endWordPosition="165">n to identify a new task: inferring the political import of propositions like OBAMA IS A SOCIALIST. We present several models that exploit the structure that exists between people and the assertions they make to learn latent positions of people and propositions at the same time, and we evaluate them on a novel dataset of propositions judged on a political spectrum. 1 Introduction Over the past few years, much work has focussed on inferring political preferences of people from their behavior, both in unsupervised and supervised settings. Classical ideal point models (Poole and Rosenthal, 1985; Martin and Quinn, 2002) estimate the political ideologies of legislators through their observed voting behavior, possibly paired with the textual content of bills (Gerrish and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) </context>
</contexts>
<marker>Martin, Quinn, 2002</marker>
<rawString>Andrew D. Martin and Kevin M. Quinn. 2002. Dynamic ideal point estimation via Markov Chain Monte Carlo for the U.S. Supreme Court, 1953– 1999. Political Analysis, 10(2):134–153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas P Minka</author>
</authors>
<title>Estimating a Dirichlet distribution.</title>
<date>2003</date>
<note>http://research.microsoft. com/en-us/um/people/minka/papers/ dirichlet/.</note>
<contexts>
<context position="17963" citStr="Minka (2003)" startWordPosition="2919" endWordPosition="2920">ch category k and subject s: – Draw distribution over subject-specific predicates ξk,s — Dir(γs) – For each user u: – Draw user type index z — Cat(θ) – For each proposition (sbj, pred) made by u: – Draw subject sbj — Cat(φz) – Draw predicate pred — Cat(ξz,sbj) We set K = 2 in an attempt to recover a distinction between liberal and conservative users. For the experiments reported below, we run inference using collapsed Gibbs sampling (Griffiths and Steyvers, 2004) for 100 iterations, performing hyperparameter optimization on α, γ and γs (all asymmetric) every 10 using the fixed-point method of Minka (2003). In order to compare the subject-specific predicate distributions across categories, we first calculate the posterior predictive distribution by taking a single sample of all latent variables z to estimate Figure 2: Single membership model with decoupled subjects and predicates. z is the latent category identity of a user (e.g., liberal or conservative); φ is a distribution over subjects for each category; and ξ is a distribution of predicates given subject s. the following (Asuncion et al., 2009): c(z v) + γv ζz,v = E (3) v&apos; c(z, vt) + γv&apos; Where ˆζz,v is the vth element of the zth multinomia</context>
</contexts>
<marker>Minka, 2003</marker>
<rawString>Thomas P. Minka. 2003. Estimating a Dirichlet distribution. http://research.microsoft. com/en-us/um/people/minka/papers/ dirichlet/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Mitchell</author>
<author>Jeffrey Gottfried</author>
<author>Jocelyn Kiley</author>
<author>Katerina Eva Matsa</author>
</authors>
<title>Political polarization and media habits: From Fox News to Facebook, how liberals and conservatives keep up with politics.</title>
<date>2014</date>
<tech>Technical report,</tech>
<institution>Pew Research Center.</institution>
<contexts>
<context position="5777" citStr="Mitchell et al., 2014" startWordPosition="909" endWordPosition="912">ly partisan data, paired with human judgments (details in §2.3). We define a proposition to be a tuple comprised of a subject and predicate, each consisting of one or more words, such as (global warming, is a hoax).1 We adopt an open vocabulary approach where each unique predicate defines a unary relation. 2.1 Data In order to extract propositions that are likely to be political in nature and exhibit variability according to ideology, we collect data from a politically volatile source: comments on partisan blogs. We draw data from NPR,2 Mother Jones3 and Politico4, all listed by Pew Research (Mitchell et al., 2014) as news sources most trusted by those with consistently liberal views; Breitbart,5 most trusted by those with consistently conservative views; and the Daily Caller,6 Young Conservatives7 and the Independent Journal Review,8 1We use these typographical conventions throughout: Subjects are in sans serif, predicates in italics. 2http://www.npr.org 3http://www.motherjones.com 4http://www.politico.com 5http://www.breitbart.com 6http://dailycaller.com 7http://www.youngcons.com 8https://www.ijreview.com all popular among conservatives (Kaufman, 2014). All data comes from articles published between 2</context>
<context position="32429" citStr="Mitchell et al. (2014)" startWordPosition="5294" endWordPosition="5297">Estimating Media Audience We can also use users’ latent political ideologies to estimate the overall ideological makeup of a blog’s active audience. If we assign each post to our estimate of the political ideology of its author, we find that Mother Jones has the highest fraction of comments by estimated liberals at 80.4%, while Breitbart has the highest percentage of comments by conservatives (79.5%). Blog % Liberal by post Mother Jones 80.4% NPR 67.4% Politico 51.6% Young Conservatives 38.0% Daily Caller 28.4% IJ Review 28.0% Breitbart 20.5% Table 4: Media audience. This broadly accords with Mitchell et al. (2014), which finds that among the blogs in our dataset, consistently liberal respondents trust NPR and Mother Jones most, while consistent conservatives trust Breitbart most and NPR and Mother Jones the least. 7 Conclusion We introduce the task of estimating the political import of propositions such as OBAMA IS A SOCIALIST; while much work in open information extraction has focused on learning facts such as OBAMA IS PRESIDENT from text, we are able to exploit structure in the users and communities who make such assertions in order to align them all 83 within the same political space. Given sufficie</context>
</contexts>
<marker>Mitchell, Gottfried, Kiley, Matsa, 2014</marker>
<rawString>Amy Mitchell, Jeffrey Gottfried, Jocelyn Kiley, and Katerina Eva Matsa. 2014. Political polarization and media habits: From Fox News to Facebook, how liberals and conservatives keep up with politics. Technical report, Pew Research Center.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Mitchell</author>
<author>W Cohen</author>
<author>E Hruschka</author>
<author>P Talukdar</author>
<author>J Betteridge</author>
<author>A Carlson</author>
<author>B Dalvi</author>
<author>M Gardner</author>
<author>B Kisiel</author>
<author>J Krishnamurthy</author>
<author>N Lao</author>
<author>K Mazaitis</author>
<author>T Mohamed</author>
<author>N Nakashole</author>
<author>E Platanios</author>
<author>A Ritter</author>
<author>M Samadi</author>
<author>B Settles</author>
<author>R Wang</author>
<author>D Wijaya</author>
<author>A Gupta</author>
<author>X Chen</author>
<author>A Saparov</author>
<author>M Greaves</author>
<author>J Welling</author>
</authors>
<title>Never-ending learning.</title>
<date>2015</date>
<booktitle>In Proc. of AAAI.</booktitle>
<contexts>
<context position="2867" citStr="Mitchell et al., 2015" startWordPosition="441" endWordPosition="444">ir intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a different task: estimating the political import of propositions like OBAMA IS A SOCIALIST. In focusing on propositional statements, we draw on a parallel, but largely independent, strand of research in open information extraction. IE systems, from early slot-filling models with predetermined ontologies (Hobbs et al., 1993) to the largescale open-vocabulary systems in use today (Fader et al., 2011; Mitchell et al., 2015) have worked toward learning type-level propositional information from text, such as BARACK OBAMA IS PRESIDENT. To a large extent, the ability to learn these facts from text is dependent on having data sources that are either relatively factual in their presentation (e.g., news articles and Wikipedia) or are sufficiently diverse to average over conflicting opinions (e.g., broad, random samples of the web). Many of the propositional statements that individuals make online are, of course, not objective descriptions of reality at all, but rather reflect their own beliefs, opinions and other priva</context>
</contexts>
<marker>Mitchell, Cohen, Hruschka, Talukdar, Betteridge, Carlson, Dalvi, Gardner, Kisiel, Krishnamurthy, Lao, Mazaitis, Mohamed, Nakashole, Platanios, Ritter, Samadi, Settles, Wang, Wijaya, Gupta, Chen, Saparov, Greaves, Welling, 2015</marker>
<rawString>T. Mitchell, W. Cohen, E. Hruschka, P. Talukdar, J. Betteridge, A. Carlson, B. Dalvi, M. Gardner, B. Kisiel, J. Krishnamurthy, N. Lao, K. Mazaitis, T. Mohamed, N. Nakashole, E. Platanios, A. Ritter, M. Samadi, B. Settles, R. Wang, D. Wijaya, A. Gupta, X. Chen, A. Saparov, M. Greaves, and J. Welling. 2015. Never-ending learning. In Proc. of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ndapandula Nakashole</author>
<author>Tom M Mitchell</author>
</authors>
<title>Language-aware truth assessment of fact candidates.</title>
<date>2014</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="3727" citStr="Nakashole and Mitchell, 2014" startWordPosition="578" endWordPosition="581">ively factual in their presentation (e.g., news articles and Wikipedia) or are sufficiently diverse to average over conflicting opinions (e.g., broad, random samples of the web). Many of the propositional statements that individuals make online are, of course, not objective descriptions of reality at all, but rather reflect their own beliefs, opinions and other private mental states (Wiebe et al., 2005). While much work has investigated methods for establishing the truth content of individual sentences — whether from the perspective of veridicality (de Marneffe et al., 2012), fact assessment (Nakashole and Mitchell, 2014), or subjectivity analysis (Wiebe et al., 2003; Wilson, 2008) — the structure that exists between users and their assertions gives us an opportunity to situate them both in the same political space: in this work we operate at the level of subject76 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 76–85, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. predicate propositions, and present models that capture not only the variation in what subjects (e.g., OBAMA, ABORTION, GUN CONTROL) that individual communities</context>
</contexts>
<marker>Nakashole, Mitchell, 2014</marker>
<rawString>Ndapandula Nakashole and Tom M. Mitchell. 2014. Language-aware truth assessment of fact candidates. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet-An Nguyen</author>
<author>Jordan Boyd-Graber</author>
<author>Philip Resnik</author>
<author>Kristina Miler</author>
</authors>
<title>Tea party in the house: A hierarchical ideal point topic model and its application to Republican legislators in the 112th Congress.</title>
<date>2015</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1280" citStr="Nguyen et al., 2015" startWordPosition="195" endWordPosition="198">ake to learn latent positions of people and propositions at the same time, and we evaluate them on a novel dataset of propositions judged on a political spectrum. 1 Introduction Over the past few years, much work has focussed on inferring political preferences of people from their behavior, both in unsupervised and supervised settings. Classical ideal point models (Poole and Rosenthal, 1985; Martin and Quinn, 2002) estimate the political ideologies of legislators through their observed voting behavior, possibly paired with the textual content of bills (Gerrish and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Sm</context>
</contexts>
<marker>Nguyen, Boyd-Graber, Resnik, Miler, 2015</marker>
<rawString>Viet-An Nguyen, Jordan Boyd-Graber, Philip Resnik, and Kristina Miler. 2015. Tea party in the house: A hierarchical ideal point topic model and its application to Republican legislators in the 112th Congress. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan O’Connor</author>
<author>Ramnath Balasubramanyan</author>
<author>Bryan R Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>From tweets to polls: Linking text sentiment to public opinion time series.</title>
<date>2010</date>
<booktitle>In Proc. of ICWSM.</booktitle>
<marker>O’Connor, Balasubramanyan, Routledge, Smith, 2010</marker>
<rawString>Brendan O’Connor, Ramnath Balasubramanyan, Bryan R. Routledge, and Noah A. Smith. 2010. From tweets to polls: Linking text sentiment to public opinion time series. In Proc. of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Souneil Park</author>
<author>Minsam Ko</author>
<author>Jungwoo Kim</author>
<author>Ying Liu</author>
<author>Junehwa Song</author>
</authors>
<title>The politics of comments: Predicting political orientation of news stories with commenters’ sentiment patterns.</title>
<date>2011</date>
<booktitle>In Proc. of CSCW.</booktitle>
<contexts>
<context position="2395" citStr="Park et al., 2011" startWordPosition="365" endWordPosition="368">t al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a different task: estimating the political import of propositions like OBAMA IS A SOCIALIST. In focusing on propositional statements, we draw on a parallel, but largely independent, strand of research in open information extraction. IE systems, from early slot-filling models with predetermined ontologies (Hobbs et al., 1993) to the largescale open-vocabulary systems in use today (Fader et al., 2011; Mitchell et al., 2015) have worked toward learning type-level propositional information from text, such as BARACK OBAMA IS PRESIDENT. To a large exten</context>
</contexts>
<marker>Park, Ko, Kim, Liu, Song, 2011</marker>
<rawString>Souneil Park, Minsam Ko, Jungwoo Kim, Ying Liu, and Junehwa Song. 2011. The politics of comments: Predicting political orientation of news stories with commenters’ sentiment patterns. In Proc. of CSCW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Paul</author>
<author>Mark Dredze</author>
</authors>
<title>You are what you Tweet: Analyzing twitter for public health.</title>
<date>2011</date>
<booktitle>In Proc. of ICWSM.</booktitle>
<contexts>
<context position="33507" citStr="Paul and Dredze, 2011" startWordPosition="5464" endWordPosition="5467">it structure in the users and communities who make such assertions in order to align them all 83 within the same political space. Given sufficiently partisan data (here, comments on political blogs), we find that the unsupervised generative models presented here are able to outperform other models, including those given access to supervision. One natural downstream application of this work is fine-grained opinion polling; while existing work has leveraged social media data on Twitter for uncovering correlations with consumer confidence, political polls (O’Connor et al., 2010), and flu trends (Paul and Dredze, 2011), our work points the way toward identifying finegrained, interpretable propositions in public discourse and estimating latent aspects (such as political affiliation) of the communities who assert them. Data and code to support this work can be found at http://people.ischool. berkeley.edu/˜dbamman/emnlp2015/. 8 Acknowledgments We thank Jacob Eisenstein and our anonymous reviewers for their helpful comments. The research reported in this article was largely performed while both authors were at Carnegie Mellon University, and was supported by NSF grant IIS1211277. This work was made possible thr</context>
</contexts>
<marker>Paul, Dredze, 2011</marker>
<rawString>Michael J Paul and Mark Dredze. 2011. You are what you Tweet: Analyzing twitter for public health. In Proc. of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Ana-Maria Popescu</author>
</authors>
<title>Democrats, Republicans and Starbucks afficionados: User classification in Twitter.</title>
<date>2011</date>
<booktitle>In Proc. of KDD.</booktitle>
<contexts>
<context position="1822" citStr="Pennacchiotti and Popescu, 2011" startWordPosition="281" endWordPosition="284">e textual content of bills (Gerrish and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We co</context>
</contexts>
<marker>Pennacchiotti, Popescu, 2011</marker>
<rawString>Marco Pennacchiotti and Ana-Maria Popescu. 2011. Democrats, Republicans and Starbucks afficionados: User classification in Twitter. In Proc. of KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith T Poole</author>
<author>Howard Rosenthal</author>
</authors>
<title>A spatial model for legislative roll call analysis.</title>
<date>1985</date>
<journal>American Journal of Political Science,</journal>
<volume>29</volume>
<issue>2</issue>
<contexts>
<context position="1053" citStr="Poole and Rosenthal, 1985" startWordPosition="158" endWordPosition="161"> open information extraction to identify a new task: inferring the political import of propositions like OBAMA IS A SOCIALIST. We present several models that exploit the structure that exists between people and the assertions they make to learn latent positions of people and propositions at the same time, and we evaluate them on a novel dataset of propositions judged on a political spectrum. 1 Introduction Over the past few years, much work has focussed on inferring political preferences of people from their behavior, both in unsupervised and supervised settings. Classical ideal point models (Poole and Rosenthal, 1985; Martin and Quinn, 2002) estimate the political ideologies of legislators through their observed voting behavior, possibly paired with the textual content of bills (Gerrish and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of senten</context>
</contexts>
<marker>Poole, Rosenthal, 1985</marker>
<rawString>Keith T. Poole and Howard Rosenthal. 1985. A spatial model for legislative roll call analysis. American Journal of Political Science, 29(2):357–384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice H Quenouille</author>
</authors>
<title>Notes on bias in estimation.</title>
<date>1956</date>
<journal>Biometrika,</journal>
<pages>43--3</pages>
<contexts>
<context position="27710" citStr="Quenouille, 1956" startWordPosition="4538" endWordPosition="4539">overlap for the best alignment between the two gold clusters and Table 3 presents the results of this evaluation. For both of the models described in §3, we present results for scoring a proposition like OBAMA IS A SOCIALIST based only on the conditional predicate score (PRED.) and on a score that includes variation in the subject as well (PROP.). Since both models are fit using approximate inference with a non-convex objective function, we run five models with different random initializations and present the average across all five. We estimate confidence intervals using the block jackknife (Quenouille, 1956; Efron and Stein, 1981), calculating purity and Spearman’s p over 76 resampled subsets of the full 766 elements, each leaving out 10.13 For both metrics, the two best performing models show statistically significant improvement over all other models, but are not significantly different from each other. We draw two messages from these results: For heavily partisan data, unsupervised methods are sufficient. In drawing on comments on politically partisan blogs, we are able to match human judgments of the political import of propositions quite well (both of the unsupervised models 12In this case,</context>
</contexts>
<marker>Quenouille, 1956</marker>
<rawString>Maurice H. Quenouille. 1956. Notes on bias in estimation. Biometrika, 43(3/4):353–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>David Yarowsky</author>
<author>Abhishek Shreevats</author>
<author>Manaswi Gupta</author>
</authors>
<title>Classifying latent user attributes in Twitter.</title>
<date>2010</date>
<booktitle>In Proc. of SMUC.</booktitle>
<contexts>
<context position="1789" citStr="Rao et al., 2010" startWordPosition="277" endWordPosition="280">bly paired with the textual content of bills (Gerrish and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al.</context>
</contexts>
<marker>Rao, Yarowsky, Shreevats, Gupta, 2010</marker>
<rawString>Delip Rao, David Yarowsky, Abhishek Shreevats, and Manaswi Gupta. 2010. Classifying latent user attributes in Twitter. In Proc. of SMUC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Sandvig</author>
</authors>
<title>The Facebook “it’s not our fault” study.</title>
<date>2015</date>
<tech>http://blogs.law.harvard. edu/niftyc/archives/1062,</tech>
<contexts>
<context position="21652" citStr="Sandvig, 2015" startWordPosition="3532" endWordPosition="3533">g from a much smaller training set than unsupervised methods have access to. To evaluate this tradeoff, we compare against a supervised model trained using naturally occurring data – users who self-declare themselves in their profiles to be liberal, conservative, democrat, or republican. We randomly sampled 150 users who self-identify as liberals and 150 who identify as conservatives. We do not expect these users to be a truly random sample of the population — those who self-declare their political affiliation are more likely to engage with political content differently from those who do not (Sandvig, 2015; Hargittai, 2015) — but is a method that has been used for political prediction tasks in the past (Cohen and Ruths, 2013). We build a predictive model using two classes of features: a.) binary indicators of the most frequent 25,000 unigrams and multiword expressions11 in the corpus overall; and b.) features derived from user posting activity to the seven blogs shown in table 1 (binary indicators of the blogs posted to, and the identity of the most frequent blog). In a tenfold cross-validation (using E2- regularized logistic regression), this classifier attains an accuracy rate of 76.7% (with </context>
</contexts>
<marker>Sandvig, 2015</marker>
<rawString>Christian Sandvig. 2015. The Facebook “it’s not our fault” study. http://blogs.law.harvard. edu/niftyc/archives/1062, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanchuan Sim</author>
<author>Brice D L Acree</author>
<author>Justin H Gross</author>
<author>Noah A Smith</author>
</authors>
<title>Measuring ideological proportions in political speeches.</title>
<date>2013</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="1387" citStr="Sim et al., 2013" startWordPosition="211" endWordPosition="214">aset of propositions judged on a political spectrum. 1 Introduction Over the past few years, much work has focussed on inferring political preferences of people from their behavior, both in unsupervised and supervised settings. Classical ideal point models (Poole and Rosenthal, 1985; Martin and Quinn, 2002) estimate the political ideologies of legislators through their observed voting behavior, possibly paired with the textual content of bills (Gerrish and Blei, 2012) and debate text (Nguyen et al., 2015); other unsupervised models estimate ideologies of politicians from their speeches alone (Sim et al., 2013). Twitter users have also been modeled in a similar framework, using their observed following behavior of political elites as evidence to be explained (Barber´a, 2015). Supervised models, likewise, have not only been used for assessing the political stance of sentences (Iyyer et al., 2014) but are also very popular for predicting the holistic ideologies of everyday users on Twitter (Rao et al., 2010; Pennacchiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.ed</context>
</contexts>
<marker>Sim, Acree, Gross, Smith, 2013</marker>
<rawString>Yanchuan Sim, Brice D. L. Acree, Justin H. Gross, and Noah A. Smith. 2013. Measuring ideological proportions in political speeches. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Svitlana Volkova</author>
<author>Glen Coppersmith</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Inferring user political preferences from streaming communications.</title>
<date>2014</date>
<booktitle>In Proc. of ACL.</booktitle>
<marker>Volkova, Coppersmith, Van Durme, 2014</marker>
<rawString>Svitlana Volkova, Glen Coppersmith, and Benjamin Van Durme. 2014. Inferring user political preferences from streaming communications. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Eric Breck</author>
<author>Chris Buckley</author>
<author>Claire Cardie</author>
<author>Paul Davis</author>
<author>Bruce Fraser</author>
<author>Diane J Litman</author>
<author>David R Pierce</author>
<author>Ellen Riloff</author>
<author>Theresa Wilson</author>
</authors>
<title>Recognizing and organizing opinions expressed in the world press.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 AAAI Spring Symposium on New Directions in Question Answering.</booktitle>
<contexts>
<context position="3773" citStr="Wiebe et al., 2003" startWordPosition="585" endWordPosition="588">and Wikipedia) or are sufficiently diverse to average over conflicting opinions (e.g., broad, random samples of the web). Many of the propositional statements that individuals make online are, of course, not objective descriptions of reality at all, but rather reflect their own beliefs, opinions and other private mental states (Wiebe et al., 2005). While much work has investigated methods for establishing the truth content of individual sentences — whether from the perspective of veridicality (de Marneffe et al., 2012), fact assessment (Nakashole and Mitchell, 2014), or subjectivity analysis (Wiebe et al., 2003; Wilson, 2008) — the structure that exists between users and their assertions gives us an opportunity to situate them both in the same political space: in this work we operate at the level of subject76 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 76–85, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. predicate propositions, and present models that capture not only the variation in what subjects (e.g., OBAMA, ABORTION, GUN CONTROL) that individual communities are more likely to discuss, but also the vari</context>
</contexts>
<marker>Wiebe, Breck, Buckley, Cardie, Davis, Fraser, Litman, Pierce, Riloff, Wilson, 2003</marker>
<rawString>Janyce Wiebe, Eric Breck, Chris Buckley, Claire Cardie, Paul Davis, Bruce Fraser, Diane J. Litman, David R. Pierce, Ellen Riloff, and Theresa Wilson. 2003. Recognizing and organizing opinions expressed in the world press. In Proceedings of the 2003 AAAI Spring Symposium on New Directions in Question Answering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language. Language Resources and Evaluation,</title>
<date>2005</date>
<pages>39--2</pages>
<contexts>
<context position="3504" citStr="Wiebe et al., 2005" startWordPosition="546" endWordPosition="549">d learning type-level propositional information from text, such as BARACK OBAMA IS PRESIDENT. To a large extent, the ability to learn these facts from text is dependent on having data sources that are either relatively factual in their presentation (e.g., news articles and Wikipedia) or are sufficiently diverse to average over conflicting opinions (e.g., broad, random samples of the web). Many of the propositional statements that individuals make online are, of course, not objective descriptions of reality at all, but rather reflect their own beliefs, opinions and other private mental states (Wiebe et al., 2005). While much work has investigated methods for establishing the truth content of individual sentences — whether from the perspective of veridicality (de Marneffe et al., 2012), fact assessment (Nakashole and Mitchell, 2014), or subjectivity analysis (Wiebe et al., 2003; Wilson, 2008) — the structure that exists between users and their assertions gives us an opportunity to situate them both in the same political space: in this work we operate at the level of subject76 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 76–85, Lisbon, Portugal, 17-21 Sep</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, 39(2-3):165–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Ann Wilson</author>
</authors>
<title>Fine-grained subjectivity and sentiment analysis: recognizing the intensity, polarity, and attitudes ofprivate states.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pittsburgh.</institution>
<contexts>
<context position="3788" citStr="Wilson, 2008" startWordPosition="589" endWordPosition="590">e sufficiently diverse to average over conflicting opinions (e.g., broad, random samples of the web). Many of the propositional statements that individuals make online are, of course, not objective descriptions of reality at all, but rather reflect their own beliefs, opinions and other private mental states (Wiebe et al., 2005). While much work has investigated methods for establishing the truth content of individual sentences — whether from the perspective of veridicality (de Marneffe et al., 2012), fact assessment (Nakashole and Mitchell, 2014), or subjectivity analysis (Wiebe et al., 2003; Wilson, 2008) — the structure that exists between users and their assertions gives us an opportunity to situate them both in the same political space: in this work we operate at the level of subject76 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 76–85, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. predicate propositions, and present models that capture not only the variation in what subjects (e.g., OBAMA, ABORTION, GUN CONTROL) that individual communities are more likely to discuss, but also the variation in what p</context>
</contexts>
<marker>Wilson, 2008</marker>
<rawString>Theresa Ann Wilson. 2008. Fine-grained subjectivity and sentiment analysis: recognizing the intensity, polarity, and attitudes ofprivate states. Ph.D. thesis, University of Pittsburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Xiaodan Zhou</author>
<author>Paul Resnick</author>
<author>Qiaozhu Mei</author>
</authors>
<title>Classifying the political leaning of news articles and users from user votes.</title>
<date>2011</date>
<booktitle>In Proc. of ICWSM.</booktitle>
<contexts>
<context position="2415" citStr="Zhou et al., 2011" startWordPosition="369" endWordPosition="372">chiotti and Popescu, 2011; Al Zamal et al., 2012; Cohen and Ruths, 2013; Noah A. Smith Computer Science &amp; Engineering University of Washington Seattle, WA 98195, USA nasmith@cs.washington.edu Volkova et al., 2014), Facebook (Bond and Messing, 2015) and blogs (Jiang and Argamon, 2008), where training data is relatively easy to obtain— either from user self-declarations, political following behavior, or third-party categorizations. Aside from their intrinsic value, estimates of users’ political ideologies have been useful for quantifying the orientation of news media sources (Park et al., 2011; Zhou et al., 2011). We consider in this work a different task: estimating the political import of propositions like OBAMA IS A SOCIALIST. In focusing on propositional statements, we draw on a parallel, but largely independent, strand of research in open information extraction. IE systems, from early slot-filling models with predetermined ontologies (Hobbs et al., 1993) to the largescale open-vocabulary systems in use today (Fader et al., 2011; Mitchell et al., 2015) have worked toward learning type-level propositional information from text, such as BARACK OBAMA IS PRESIDENT. To a large extent, the ability to le</context>
</contexts>
<marker>Zhou, Resnick, Mei, 2011</marker>
<rawString>Daniel Xiaodan Zhou, Paul Resnick, and Qiaozhu Mei. 2011. Classifying the political leaning of news articles and users from user votes. In Proc. of ICWSM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>