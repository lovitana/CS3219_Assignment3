<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000441">
<title confidence="0.9127485">
Language and Domain Independent Entity Linking
with Quantified Collective Validation
</title>
<author confidence="0.998209">
Han Wang∗,1, Jin Guang Zheng∗,2, Xiaogang Ma1, Peter Fox1, and Heng Ji2
</author>
<affiliation confidence="0.9930685">
{Tetherless World Constellation1, Computer Science Department2}
Rensselaer Polytechnic Institute
</affiliation>
<address confidence="0.779782">
Troy, NY, USA
</address>
<email confidence="0.981522">
{wangh17, zhengj6, max7, pfox, jih}@rpi.edu
</email>
<sectionHeader confidence="0.99427" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998812678571429">
Linking named mentions detected in a
source document to an existing knowl-
edge base provides disambiguated entity
referents for the mentions. This al-
lows better document analysis, knowl-
edge extraction and knowledge base pop-
ulation. Most of the previous research
extensively exploited the linguistic fea-
tures of the source documents in a su-
pervised or semi-supervised way. These
systems therefore cannot be easily ap-
plied to a new language or domain. In
this paper, we present a novel unsuper-
vised algorithm named Quantified Col-
lective Validation that avoids excessive
linguistic analysis on the source docu-
ments and fully leverages the knowledge
base structure for the entity linking task.
We show our approach achieves state-
of-the-art English entity linking perfor-
mance and demonstrate successful de-
ployment in a new language (Chinese)
and two new domains (Biomedical and
Earth Science). Experiment datasets
and system demonstration are available
at http://tw.rpi.edu/web/doc/
hanwang_emnlp_2015 for research
purpose.
</bodyText>
<sectionHeader confidence="0.989288" genericHeader="categories and subject descriptors">
1 Introduction and Motivation
</sectionHeader>
<bodyText confidence="0.964878625">
The entity linking (EL) task aims at analyzing
each named entity mention in a source document
and linking it to its referent in a knowledge base
(KB). Consider the following example: “One day
after released by the Patriots, Florida born Cald-
well visited the Jets. The New York Jets
have six receivers on the roster: Cotchery, Coles,
...”. Here “Caldwell” is an ambiguous mention
</bodyText>
<note confidence="0.59827">
∗These authors contributed equally to this work.
</note>
<bodyText confidence="0.999712352941176">
because not only are there thousands of people
with different professions named “Caldwell”, but
even if as an American football player, as most
people would recognize it from the context, there
are several “Caldwell”s who are/were associated
with either “the Patriots” or “the Jets”. An EL
system should be able to disambiguate the men-
tion by carefully examining the context and then
identify the correct KB referent, which is Reche
Caldwell in this case.
Although EL has attracted a lot of community
attention in the recent years, most research efforts
have been focused on developing systems only ef-
fective for generic English corpora. When these
systems are migrated to a new language or do-
main, their performance will usually suffer from
a noticeable decline due to the following reasons:
</bodyText>
<listItem confidence="0.625895">
1) State-of-the-art EL systems have developed
comprehensive linguistic features from the source
</listItem>
<bodyText confidence="0.993283">
documents to generate advanced representations
of the mentions and their context. While this
methodology has been proved rewarding for a
resource-rich language such as English, it prevents
the systems from being adopted to a new language,
especially to one with limited linguistic resources.
One can imagine that it would be very difficult,
if not impossible, for an English EL system that
benefits from the part-of-speech tagging, depen-
dency parsing, and named entity recognition to be
deployed to a new language such as Chinese that
has quite different linguistic characteristics.
</bodyText>
<listItem confidence="0.6800382">
2) The current EL approaches mostly target at
people, organizations, and geo-political entities
which are widely present in a general KB such
as Wikipedia. However, domain-specific EL tends
to pay more attention to entities beyond the above
three types. For instance, in the biomedical sci-
ence domain, protein is a major class of entities
that greatly interest scientists. Conventional EL
systems are very likely to fail in linking protein
mentions in the text due to the lack of labeled
</listItem>
<page confidence="0.982751">
695
</page>
<note confidence="0.985054">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 695–704,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999965375">
training data. Moreover, their reliance on general
reference KBs seems insufficient for a specific do-
main. Take “A20”, a type of protein as an example.
Wikipedia has more than a few items listed un-
der the name of “A20” and their types range from
aircrafts to roads. This diversified information in-
evitably introduces noise for a biomedical EL ap-
plication.
One potential solution to tackle these limita-
tions is, instead of concentrating on the source
documents, to conduct more deliberate study on
the KB. Structured KBs such as DBpedia1 typi-
cally offer detailed descriptions about entities, a
large collection of named relations between enti-
ties, and a growing number of multi-lingual en-
tity surface forms. By embracing these ready-
for-use information and linked structures, we will
be able to obtain sufficient contextual information
for disambiguation without generating a full list
of linguistic features from the source documents,
and therefore eliminate the language dependency.
Moreover, currently there exist numerous pub-
licly available domain ontology repositories such
as BioPortal2 and OBO Foundry3 which provide
significantly more domain knowledge than general
KBs for EL to leverage. By incorporating these
domain ontologies, we can easily increase the en-
tity coverage and reduce noise for deploying EL in
various new domains.
In order to make the most of the KB structure,
the mention context should be matched against
the KB such that the relevant KB information
can be extracted. A collective way of aligning
co-occurred mentions to the KB graph has been
proved to be a successful strategy to better rep-
resent the source context (Pennacchiotti and Pan-
tel, 2009; Fern´andez et al., 2010; Cucerzan, 2011;
Han et al., 2011; Ratinov et al., 2011; Dalton and
Dietz, 2013; Zheng et al., 2014; Pan et al., 2015).
We take a further step to consider quantitatively
differentiating entity relations in the KB in or-
der to evaluate entity candidates more precisely.
Meanwhile, we jointly validate these candidates
by aligning them back to the source context and in-
tegrating multiple ranking results. This novel EL
framework deeply exploits the KB structure with a
light weight representation of the source context,
and thus enables a smooth migration to new lan-
</bodyText>
<footnote confidence="0.999965">
1http://wiki.dbpedia.org
2http://bioportal.bioontology.org
3http://www.obofoundry.org
</footnote>
<bodyText confidence="0.9950642">
guages and domains.
The main novel contributions of this paper are
summarized as follows: 1) We design an unsuper-
vised EL algorithm, namely, Quantified Collec-
tive Validation (QCV) that builds KB entity can-
didate graphs with quantified relations for the pur-
pose of collective disambiguation and inference.
2) We develop a procedure of building language
and domain independent EL systems by incorpo-
rating various ontologies into the QCV compo-
nent. 3) We demonstrate that our system is able
to achieve state-of-the-art performance in English
EL, and it can also produce promising results for
Chinese EL as well as EL in Biomedical Science
and Earth Science.
</bodyText>
<sectionHeader confidence="0.971065" genericHeader="general terms">
2 Baseline Collective EL
</sectionHeader>
<bodyText confidence="0.999061066666667">
As a baseline, we adopt a competitive unsuper-
vised collective EL system (Zheng et al., 2014)
utilizing structured KBs. It defines entropy based
weights for the KB relations, and embeds them in
a two-step candidate ranking process to produce
the EL results.
Structured KB Terminologies: In a structured
KB, a fact is usually expressed in the form of a
triple: (eh, r, et) where eh, et are called the head
entity and the tail entity, respectively, and r is the
relation between eh and et.
Entropy Based KB Relation Weights: The goal
is to leverage various levels of granularity of KB
relations. The calculation of the relation weight
H(r) is given in Equation (1):
</bodyText>
<equation confidence="0.997693">
H(r) = − � P(et) log(P(et)) (1)
et∈Et(r)
</equation>
<bodyText confidence="0.9939985">
where Et(r) is the tail entity set for r in the KB,
and P(et) is the probability of et appearing as the
tail entity for r in the KB.
Salience Ranking: As the first ranking step, we
examine the candidates without the context and
prefers those with higher importance in the KB.
Equation (2) computes the salience score Sa(c) for
a candidate c:
</bodyText>
<equation confidence="0.99715075">
� H(r)Sa(et)
Sa(c) = (2)
L(et)
r∈R(c),et∈Et(r)
</equation>
<bodyText confidence="0.99684975">
where R(c) is the relation set for c in the KB; H(r)
is given by Equation (1); Et(r) is the tail entity
set with c being the head entity and r being the
connecting relation in the KB; L(et) denotes the
</bodyText>
<page confidence="0.997372">
696
</page>
<listItem confidence="0.6826205">
cardinality of the tail entity set with et being the
head entity in the KB. Sa(c) is recursively com-
puted until convergence.
Collective Ranking: The similarity Sim&apos; (m, c)
between a candidate c and its mention m is defined
using Equation (3) as the final ranking score:
</listItem>
<equation confidence="0.99983">
Sim&apos; (m, c) = α · JS(m, c) · Sa(c)
+ Q · 1: H(r) · 1: Sa(n) (3)
r∈R(c) n∈Et(r)∩C(m)
</equation>
<bodyText confidence="0.999904">
where JS(m, c) is the Jaccard similarity between
the string surface forms of m and c; Sa(c) and
Sa(n) are both evaluated by Equation (2); C(m)
denotes the candidate set for mention m; α and Q
are hyperparameters.
</bodyText>
<sectionHeader confidence="0.983215" genericHeader="keywords">
3 Quantified Collective Validation
</sectionHeader>
<bodyText confidence="0.999971333333333">
Incorporating the KB relation weighing mecha-
nism of the baseline system, our QCV algorithm
constructs a number of candidate graphs for a
given set of collaborative mentions, and then per-
forms a two-level ranking followed by a collective
validation on those candidate graphs to acquire the
linking results. Because this procedure minimally
relies on linguistic analysis of the source docu-
ments while mainly uses the KB structure which
by nature keeps detached from any specific lan-
guage or domain, we claim that QCV comes with
language and domain independence.
</bodyText>
<subsectionHeader confidence="0.999528">
3.1 Candidate Graph Construction
</subsectionHeader>
<bodyText confidence="0.998743944444444">
The KB entity candidate graphs are constructed
based on a mention context graph and a KB graph.
We will introduce them in order as follows.
Mention Context Graph: To avoid abusing lin-
guistic knowledge from the source documents, we
construct a mention context graph Gm simply in-
volving mention co-occurrence. Figure 1 depicts
a constructed Gm for the Caldwell example at
the beginning of Section 1. In this figure, men-
tions “New York Jets”, “Cotchery” and “Coles”
are brought into Gm through the coreference be-
tween “Jets” and “New York Jets” since the three
of them are outside the context window of “Cald-
well”, “Florida”, “Patriots”, and “Jets”. Gm con-
tains a set of vertices representing the mentions
extracted from the source document and a set of
undirected edges. There will be an edge between
two mention vertices if both of them fall into a
context window with width wm in the source doc-
ument. Ideally, wm should cover a single dis-
course according to the one sense per discourse
assumption (Gale et al., 1992), but for simplic-
ity we heuristically set wm to be 7-sentence wide
as a hyperparameter. Two mention vertices will
be connected via a dashed edge if they are coref-
erential but are not located in the same context
window. Here we determine the coreference by
performing substring matching and abbreviation
expansion. The dashed edge indicates the out-
of-context coreferential mention together with its
neighbors will be indirectly included in Gm as
extended context to later facilitate the candidate
graph collective validation. Note that all of these
loose settings comply with our intention of gener-
ating a light-weight source context representation
born with domain and language independence.
</bodyText>
<figureCaption confidence="0.912912">
Figure 1: Mention context graph for the Caldwell
example.
</figureCaption>
<bodyText confidence="0.9577618">
KB Graph: A structured KB such as DBpedia
can be represented as a weighted graph Gk that
consists of a set of vertices representing the en-
tities and a set of directed edges labeled with re-
lations between entities. The weights of relations
are computed using Equation (1). In order to fur-
ther enrich the KB relations, we add a type of re-
lation named “wiki link” between two entities if
one of them appears in the Wikipedia article of the
other. Figure 2 presents a subgraph of the DBpe-
dia KB graph containing the relevant entities in the
Caldwell example.
Candidate Graph: The candidate graph is a
set of graphs Gic (i = 1, 2, ...) used for com-
puting ranking scores for the KB entity candi-
dates. For each of the mentions extracted from
the source context, we first select a list of entity
candidates from Gk with heuristic rules such as
fuzzy string matching, synonyms, Wikipedia redi-
rect, etc. Then we pick one candidate for each of
the mentions to constitute the vertices of a Gic. In
each Gic, we add an edge between two vertices if
they are connected in Gk by some relation r and
their mentions are connected in Gm. The edge la-
bel r from Gk is transferred to Gic. Upon comple-
</bodyText>
<figure confidence="0.9980114">
Patriots
Caldwell
Florida
Jets
New York Jets
Cotchery
Coles
697
Patriot Act
Patriots
(American Revolution)
...
Florida City, Florida
Florida, Ohio
Florida
... ...
birth place
0.93
wiki link
0.21
former team
0.61
birth place
0.93
New England Patriots
Reche Caldwell
birth place
0.93
wiki link
wiki link
0.21
0.21
wiki link
0.21
wiki link
wiki link
0.21
0.21
New York Jets
Newcastle Jets FC
Jet aircraft
former team
0.61
Jerricho Cotchery
Laveranues Coles
former team
0.61
...
Andre Caldwell
James Caldwell
(clergyman)
Jim Caldwell
(American Football)
Danny Coles
...
</figure>
<figureCaption confidence="0.999807">
Figure 2: KB graph for the Caldwell example.
</figureCaption>
<bodyText confidence="0.999518818181818">
tion, every Gic represents a collective linking solu-
tion to the given mention set. Figure 3 shows three
of the constructed candidate graphs for the Cald-
well example. One can see that the first two graphs
are very likely to be good solutions since they in-
herit many of the relation edges from GK, while
the third one is probably a poor collection as the
candidates barely connect to one another. In the
next section, we will more formally reveal how to
rank these candidate graphs to obtain the optimal
linking results.
</bodyText>
<figure confidence="0.933511">
Newcastle Jets FC
James Caldwell
(clergyman) wiki link
Florida City, Florida (American Revolution)
Patriots
C
</figure>
<figureCaption confidence="0.9887295">
Figure 3: Candidate graphs for the Caldwell ex-
ample.
</figureCaption>
<subsectionHeader confidence="0.999701">
3.2 Candidate Ranking
</subsectionHeader>
<bodyText confidence="0.99773564516129">
With the constructed candidate graphs, QCV per-
forms two levels of ranking. First, it uses Equa-
tion (2) to compute the candidates’ salience scores
as a priori ranking. Then it compares each can-
didate graph with the mention context graph, and
evaluates their vertex set similarity for context
similarity ranking. Finally, by considering the re-
lation weights in the candidate graphs as well as
previous ranking scores, QCV collectively vali-
dates all the candidates and assembles the linking
results. Below we will focus on introducing the
context similarity ranking and the collective vali-
dation since the salience ranking resembles that of
our baseline system.
Context Similarity Ranking: As shown in Fig-
ure 3, among the constructed candidate graphs,
some of them contain many connected vertices
while some are otherwise quite disconnected. In-
tuitively we would like to measure this structure
difference by comparing each candidate graph Gic
with its mention context graph Gm. Granted, we
can only assert co-occurrence between two con-
nected mentions in Gm, but it should be of great
probability that two co-occurring mentions have
their entity referents connected by some relation
in the KB. In other words, the more a Gic is struc-
turally similar to its Gm, the better the candidates
in this Gic represent their mentions in Gm. There-
fore, we define the context similarity Sm(mc, c)
between a candidate c and its mention mc using
Jaccard similarity in Equation (4):
</bodyText>
<equation confidence="0.4550605">
Sm(mc, c) = |pGm(mc) n pGic(c) |(4)
pGm (mc) U pGi (c)
</equation>
<figure confidence="0.997631954545455">
Jerricho Cotchery
Laveranues Coles
former team former team
wiki link
Reche Caldwell
birth place former team
Florida
New England Patriots
A
Jerricho Cotchery
Laveranues Coles
former team former team
wiki link
Andre Caldwell
birth place wiki link
Florida
New England Patriots
B
Jerricho Cotchery
Danny Coles
New York Jets
New York Jets
</figure>
<page confidence="0.983309">
698
</page>
<bodyText confidence="0.999633477272727">
where ΘGm(mc) and ΘGic(c) denote mc’s neigh-
bor set in Gm and c’s neighbor set in Gic, re-
spectively. The intersection takes the candidates
of those mentions in ΘGm(mc) that appear in
ΘGic(c), and the union is equivalent to ΘGm(mc)
due to the way we construct Gic. We rank Gicusing
the summation of the context similarity of every c
in Gic. Note that our baseline system uses Jaccard
similarity to achieve approximate string match be-
tween the surface forms of a mention and a can-
didate, while we alternatively use it to capture the
graph’s structural similarity. After ranking with
the context similarity, those Gic with more con-
nected vertices such as Figure 3A and Figure 3B
will get closer to the top of the ranked candidate
graph list.
Candidate Graph Collective Validation: Be-
sides the salience, the context similarity provides
another ranking score for each candidate c in Gic,
and it promotes those candidates remaining con-
nected in Gic. However, it fails to differenti-
ate how two candidates are connected. In Fig-
ure 3A, Reche Caldwell is a former player
of New England Patriots, and in Fig-
ure 3B, Andre Caldwell’s Wikipedia article
includes a hyperlink pointing to New England
Patriots. The former seems a “tighter” rela-
tion than the latter. Although these two distinct
relations imply that these two candidate pairs are
related with different relation types, the context
similarity rankings for these two candidate graphs
are identical. Based on this observation, assuming
that a “tighter” relation between two candidates is
more likely to be an appropriate representation of
the relation between their co-occurring mentions
in the source context, we propose a novel valida-
tion step that not only considers the two previous
ranking scores of each candidate but also quantita-
tively examines the relations between candidates.
We transfer the calculated relation weights from
Gk to Gic as positive indicators of how tightly two
candidates are related, and then define the com-
posite graph weight W (Gic) for each Gic in Equa-
tion (5) as the final ranking metric:
</bodyText>
<equation confidence="0.999095">
W(Gic) = � Sa(c)Sm(mc, c) + � H(r) (5)
</equation>
<bodyText confidence="0.99998425">
weight, since the relation “former team” has a
greater weight than “wiki link”, the candidate
graph in Figure 3A outweighs that in Figure 3B,
and therefore is ranked to the top.
</bodyText>
<sectionHeader confidence="0.999228" genericHeader="introduction">
4 Experiments
</sectionHeader>
<bodyText confidence="0.99962">
In this section, we first show QCV’s performance
on generic English corpora and compare it with
our baseline together with other state-of-the-art
EL systems. Then we move to a new language
(Chinese) and two new domains (Biomedical Sci-
ence and Earth Science) to demonstrate the lan-
guage and domain independent nature of our algo-
rithm.
</bodyText>
<subsectionHeader confidence="0.9726">
4.1 EL on Generic English Corpora
</subsectionHeader>
<bodyText confidence="0.999847866666667">
For this evaluation, we used the TAC-KBP2013
EL dataset1, which contains 2,190 mentions ex-
tracted from English newswire, web blogs, and
discussion forums. We selected a subset of 1,090
linkable mentions that have entity referents in the
KB for our experiment. DBpedia 3.9, which was
generated from the Wikipedia dump in early 2013
and includes more than 4 million entities and more
than 470 million facts2, was used as our KB. We
followed the KBP EL track using B-Cubed+ (Ji
et al., 2011) as the evaluation metric. Table 1
presents the results of QCV, our baseline system,
as well as the top 3 supervised participant sys-
tems3and the top 3 unsupervised participant sys-
tems3 of the TAC-KBP2013 EL track.
</bodyText>
<table confidence="0.999701888888889">
System B3+ Fs
Supervised 1st 0.7244
Supervised 2nd 0.7214
Supervised 3rd 0.7184
Unsupervised 1st 0.6324
Unsupervised 2nd 0.5764
Unsupervised 3rd 0.5734
Baseline (unsupervised) 0.697
QCV (unsupervised) 0.749
</table>
<tableCaption confidence="0.9480525">
Table 1: Performance on the TAC-KBP2013 EL
Dataset (1,090 linkable mentions).
</tableCaption>
<table confidence="0.387156">
c∈V (Gic) r∈E(Gic)
</table>
<bodyText confidence="0.9992045">
where V (Gic) and E(Gic) are the vertex set and the
edge set of Gic; Sa(c), Sm(mc, c), and H(r) are
given by Equation (2), Equation (4), and Equa-
tion (1), respectively. With this composite graph
</bodyText>
<footnote confidence="0.996328166666667">
1http://www.nist.gov/tac/2013/KBP/data.html
2http://wiki.dbpedia.org/services-resources/datasets/data-
set-39
3Due to NIST policy, the names of the TAC-KBP2013
participant systems are not revealed.
4http://www.nist.gov/tac/publications/2013/papers.html
</footnote>
<page confidence="0.998727">
699
</page>
<bodyText confidence="0.999607875">
As shown in Table 1, QCV not only substan-
tially outperforms the best unsupervised systems
but also beats the best supervised systems from
the KBP participants. In order to understand this
notable advancement, we broke down our system
into components and evaluated them accumula-
tively using the same dataset as above. The ex-
periment results are summarized in Table 2.
</bodyText>
<table confidence="0.99939975">
Components B3+ P B3+ R B3+ F1
SR 0.680 0.598 0.636
SR + CS 0.699 0.624 0.659
SR + CS + CV 0.789 0.712 0.749
</table>
<tableCaption confidence="0.999425">
Table 2: QCV Performance by Component.
</tableCaption>
<bodyText confidence="0.999967517857143">
In Table 2, SR, CS, and CV correspond to the
Salience Ranking, the Context Similarity Rank-
ing, and the Collective Validation in our QCV
algorithm, respectively. It can be seen that SR
already outperforms the best KBP unsupervised
systems from Table 1. This is mainly attributed
to the engagement of the entropy based relation
weights which injects the impact of different re-
lations into the entity salience. Notwithstanding
being somewhat effective, SR solely depends on
the KB and plays its role without the source con-
text. It should be straightforward that the sys-
tem performance gets improved after enabling CS
since the source context has been incorporated.
However, it was a little puzzling that the perfor-
mance boost by enabling CS turned out to be rel-
atively small. We took a careful look at the in-
termediate experiment results and discovered that
although CS did not produce a lot more correct
linking results than SR did, it did promote a great
number of good candidates to the top of the rank-
ing list. For example, in the Caldwell case, CS
successfully raised the rankings of the context-
related candidates such as Reche Caldwell,
Andre Caldwell, and Jim Caldwell, de-
spite the fact that it delivered Andre Caldwell
instead of Reche Caldwell as the final linking
result. This convincingly implies that CS is able to
well capture the context of the target mentions, but
meanwhile it is deficient in recognizing the subtle
contextual difference among similar candidates.
In Table 2 there is a significant performance gain
after enabling CV. As described in Section 3.2, CV
collectively validates the candidates of the target
mention “Caldwell” and the mentions in its con-
text such as “Florida”, “Patriots”, and “Jets” by
integrating their SR and CS scores as well as the
weights of the KB relations between them. There-
fore this improvement is reasonably substantial.
By investigating the remaining errors, we iden-
tified several potential causes: 1) Our system occa-
sionally could not capture enough context for the
target mention. This happened more frequently
for web blogs and discussion forums, where the
language was informal and casual. Without any
linguistic analysis on the source documents, it
was difficult for us to extract additional context
words. 2) Our simple coreference rules some-
times failed to work correctly and introduced false
candidates, which, without clear context to dis-
ambiguate, could lead to linking errors. 3) Our
KB had limited knowledge about some entities in
a way that certain relations were missing. This
kept us from creating necessary links in the can-
didate graphs and further effectively validating the
graphs.
</bodyText>
<subsectionHeader confidence="0.971808">
4.2 EL on Generic Chinese Corpora
</subsectionHeader>
<bodyText confidence="0.999646470588235">
Using Chinese as a case study, we evaluate the lan-
guage portability of our approach. We used the
TAC-KBP2012 Chinese EL dataset1, and selected
a subset of 1,240 linkable mentions out of the total
2,122 mentions extracted from Chinese newswire,
web blogs, and discussion forums. For KB, we
still used DBpedia because it contains multilingual
surface forms for its entities. For instance, the en-
tity Barack Obama has surface forms in over 30
languages including the Chinese one: “贝拉克·奥
巴马”. This cross-lingual surface form mapping
naturally provides us with a convenient translation
tool. Table 3 shows the linking performance com-
parison among QCV, our baseline system, and the
top 3 participant systems of the KBP Chinese EL
track. Again, we employed the B-Cubed+ met-
ric.
</bodyText>
<table confidence="0.998799166666667">
System B3+ F1
Clarke et al. (2012) (supervised) 0.493
Monahan and Carpenter (2012) (supervised) 0.660
Fahrni et al. (2012) (supervised) 0.736
Baseline (unsupervised) 0.648
QCV (unsupervised) 0.671
</table>
<tableCaption confidence="0.940289">
Table 3: Performance on the TAC-KBP2012 Chi-
nese EL Dataset (1240 linkable mentions).
</tableCaption>
<bodyText confidence="0.759653">
As shown in Table 3, the best performance is
</bodyText>
<footnote confidence="0.983368">
1http://www.nist.gov/tac/2012/KBP/data.html
</footnote>
<page confidence="0.995355">
700
</page>
<bodyText confidence="0.999440756756757">
achieved by Fahrni et al. (2012), a supervised sys-
tem using over 20 fine-tuned features and many
linguistic resources. In contrast, our QCV is an
unsupervised approach without using any labeled
data or linguistic resources. During the error anal-
ysis, we found that in this dataset multiple men-
tions are often the variants of the surface form of
a single KB entity. For example, “奥C4” and
“欧C4”, being just different Chinese transliter-
ations, both refer to “Obama”. This fact tends to
result in a low recall for our system because one
or more of the mention variants may not exist in
the KB. We decided to heuristically apply a sub-
string matching in addition to the Wikipedia redi-
rection mapping to boost the recall. However, as
one can imagine, this simple strategy will impair
the system precision due to the introduced noise.
Take “奥C4” again for example. If we only
match its second and third characters, “欧C4”
will be correctly picked, but “C4镇” (a small
town in China) will also be falsely included. For-
tunately, our QCV algorithm was able to select and
rank candidates complying with the source con-
text. Consequently most of this kind of noise got
filtered out, and we thus could produce balanced
precision and recall.
We acknowledge that, without performing
deeper linguistic analysis on the source docu-
ments, the cross-language surface form mapping
of the KB plays a crucial role in our approach. One
can replace it with any machine translation prod-
uct which, however, is not always available espe-
cially for a low-resource language. We should take
advantage of the existing KBs where such cross-
lingual mapping has already been widely created.
The latest DBpedia provides localized versions in
125 languages1, for instance.
</bodyText>
<subsectionHeader confidence="0.997409">
4.3 EL in Biomedical Science
</subsectionHeader>
<bodyText confidence="0.999471181818182">
To demonstrate the domain portability of our ap-
proach, we first take the biomedical science do-
main as a case study. We conducted our ex-
periment using the evaluation dataset created by
Zheng et al. (2014) which contains 208 linkable
mentions extracted from several biomedical pub-
lications. We built our KB with over 300 domain
ontologies downloaded from BioPortal. Table 4
compares the linking accuracy of QCV and our
baseline system.
As shown in Table 4, our approach achieves
</bodyText>
<footnote confidence="0.979279">
1http://wiki.dbpedia.org/about
</footnote>
<table confidence="0.991283333333333">
System Correct Total Accuracy
Baseline 173 208 83.17%
QCV 177 208 85.10%
</table>
<tableCaption confidence="0.997524">
Table 4: Biomedical Science EL Performance.
</tableCaption>
<bodyText confidence="0.999973238095238">
similar performance to our baseline system which
is the state-of-the-art to our knowledge. However,
we were curious why QCV did not improve the
baseline system in the biomedical domain as much
as it did in the general domain. After some in-
depth analysis of the experiment results, we dis-
covered that in this dataset the candidates of the
related mentions (i.e. those mentions within the
same context window) mostly have similar rela-
tions in the KB. In other words, for each men-
tion, the candidate entity types are not as diverse
as those in the general domain. As a consequence,
the collective validation step in QCV does not take
much effect since the weights of the involved re-
lations are quite close to one another. On such a
dataset, the context similarity ranking will play a
major part for the disambiguation, and QCV will
not be able to function at its full power. Nonethe-
less, from the results we can see that our approach
can be efficiently and effectively adapted to this
new domain.
</bodyText>
<subsectionHeader confidence="0.988708">
4.4 EL in Earth Science
</subsectionHeader>
<bodyText confidence="0.998461583333333">
Now we move to another new domain, Earth Sci-
ence. As far as we know, we are the first to study
EL in this domain. In order to create an evaluation
dataset, our domain expert selected three scientific
papers about Early Triassic discovery, Global Stra-
totype Section, and Triassic crisis, which are three
different aspects of Earth Science related discov-
ery, and then identified 296 mentions that can be
linked to DBpedia entities. Table 5 presents the
linking accuracy comparison between QCV and
our baseline system. We can see that QCV pro-
vided significant gains.
</bodyText>
<table confidence="0.995453666666667">
System Correct Total Accuracy
Baseline 221 296 74.66%
QCV 236 296 79.73%
</table>
<tableCaption confidence="0.999024">
Table 5: Earth Science EL Performance.
</tableCaption>
<bodyText confidence="0.999350333333333">
The linking errors were mainly caused by the
following reasons: 1) As a general KB, DBpe-
dia has introduced certain noise for our domain-
</bodyText>
<page confidence="0.994672">
701
</page>
<bodyText confidence="0.99997648">
specific EL. For example, in Geology, the term
“Beds” mostly refers to “Geology Bed”, which is
a division of a geologic formation. But in general,
“Beds” usually means the beds people sleep on.
Much more common in the KB, the latter had such
a significantly higher salience score than the for-
mer that the final ranking score of our system got
biased. 2) Some relations between Earth Science
related entities are not clearly defined in DBpe-
dia. For instance, in geology time scale, the period
“Chattian” is immediately preceded by the period
“Rupelian”. An explicit relation such as “preceded
by” should be inserted between these two period
entities. Instead, only a vague “wiki link” relation
is present in our KB. This directly diminishes the
differentiating power of our system on the KB re-
lations.
It is worth mentioning that there exists a large
number of well established ontologies for different
sub-domains of Earth Science. SWEET ontolo-
gies1, for example, widely capture Earth and En-
vironmental terminologies. By adopting these on-
tologies, we will be able to considerably improve
our domain EL performance, and the benefits of
EL in the domain will further get revealed.
</bodyText>
<subsectionHeader confidence="0.99781">
4.5 System Complexity
</subsectionHeader>
<bodyText confidence="0.999325882352941">
We indexed our KB and ontologies in the format of
triples using Apache Lucene2 such that retrieving
entity candidates of a mention is O(1). We pre-
computed all the entropy-based relation weights
and entity salience scores with complexities of
O(nr · ne) and O(ne · k), respectively, where nr
is the number of KB relations, ne is the number
of KB entities, and k is the number of iterations it
took for the salience score to get converged. For
the final QCV score computation, the upper bound
of the computing time to link all the mentions in a
document is O(nm · n, · nn, · nn.), where nm is
the number of linkable mentions in the document,
n, is the number of candidates for each mention,
and nn, is the number of neighbor nodes of a can-
didate, and nn. is the number of neighbors of a
mention.
</bodyText>
<sectionHeader confidence="0.999877" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999857">
In recent years, collective inference methods for
EL have become increasingly popular. Many ef-
forts have been devoted to encoding linguistic fea-
</bodyText>
<footnote confidence="0.999882">
1http://sweet.jpl.nasa.gov
2https://lucene.apache.org/
</footnote>
<bodyText confidence="0.999937980392157">
tures from the source documents in order to pre-
cisely select collaborator mentions for collective
inference. These features include topic model-
ing (Xu et al., 2012; Cassidy et al., 2012), re-
lation constraint (Cheng and Roth, 2013), coref-
erential chaining (Nguyen et al., 2012; Huang et
al., 2014), and dependency restriction (Ling et al.,
2014). Some recent work utilized multi-layer lin-
guistic analysis integration to capture contextual
properties for better mention collection (Pan et al.,
2015). While many of these approaches have been
proved to be effective, the dependency on deep
linguistic knowledge makes it difficult to migrate
them to a new language or domain. In contrast to
these methods, we establish a very loose setting
for the mention selection, and rely on the quanti-
fied information computed from the structured KB
to collectively evaluate and validate the entity can-
didates. Since the KB is relatively universal to
languages and domains, our approach inherently
is language and domain independent.
Recent cross-lingual EL approaches can be di-
vided into two types. The first type (McNamee et
al., 2011; Cassidy et al., 2011; McNamee et al.,
2012; Guo et al., 2012; Miao et al., 2013) trans-
lated entity mentions and source documents from
the new language into English and then ran En-
glish mono-lingual EL to link to English KB. The
second type (Monahan et al., 2011; Fahrni et al.,
2011; Fahrni et al., 2012; Monahan and Carpenter,
2012; Clarke et al., 2012; Fahrni et al., 2013) de-
veloped EL systems on the new language and used
cross-lingual KB links to map the link results back
to English KB. While the bottleneck of the former
method usually is on translation errors, the latter
approach heavily relies on the linguistic resources
and the KB of the new language. In comparison,
our system mainly uses the English KB and a men-
tion surface form mapping that can either come
from translation or cross-lingual KB links, and re-
quires minimal linguistic resources from the new
language.
There is a limited amount of research work
in the literature that focused solely on domain-
specific EL (Zheng et al., 2014). In the biomed-
ical domain, a few studies have been found on
EL-related tasks such as scientific name discov-
ery (Akella et al., 2012), gene name normaliza-
tion (Hirschman et al., 2005; Fang et al., 2006;
Dai et al., 2010), biomedical named entity recog-
nition (Usami et al., 2011; Van Landeghem et al.,
</bodyText>
<page confidence="0.991343">
702
</page>
<bodyText confidence="0.9998585">
2012) and concept mention extraction (Tsai et al.,
2013). The baseline system (Zheng et al., 2014)
in this paper is the work most similar to ours in
a sense of collectively aligning mentions to struc-
tured KBs. However, our system differs by inte-
grating a context similarity ranking and a candi-
date validation to conduct a two-way collective in-
ference with better performance.
</bodyText>
<sectionHeader confidence="0.997909" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99996">
Language and domain independence is a new re-
quirement to EL systems and this capability is par-
ticularly welcome by low-resource language re-
lated applications and domain scientists. In this
paper we demonstrated a high-performance EL
approach that can be easily migrated to new lan-
guages and domains due to the minimal reliance
on linguistic analysis and the deep utilization of
structured KBs. In the future, we plan to improve
the source document processing such that the sys-
tem can better extract the mention context without
involving extensive linguistic knowledge. We are
also experimenting with our collective validation
algorithm to incorporate the impact of more dis-
tant KB entities other than just the neighbors.
</bodyText>
<sectionHeader confidence="0.996238" genericHeader="acknowledgments">
7 Acknowledgement
</sectionHeader>
<bodyText confidence="0.999368769230769">
This work was supported by the U.S. DARPA
DEFT Program No. FA8750-13-2-0041, ARL
NS-CTA No. W911NF-09-2-0053, NSF CA-
REER Award IIS-1523198, DARPA LORELEI,
AFRL DREAM project, gift awards from IBM,
Google, Disney and Bosch. The views and con-
clusions contained in this document are those of
the authors and should not be interpreted as rep-
resenting the official policies, either expressed or
implied, of the U.S. Government. The U.S. Gov-
ernment is authorized to reproduce and distribute
reprints for Government purposes notwithstanding
any copyright notation here on.
</bodyText>
<sectionHeader confidence="0.998463" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999634553846154">
Lakshmi Manohar Akella, Catherine N. Norton, and
Holly Miller. 2012. NetiNeti: Discovery of Sci-
entific Names from Text Using Machine Learning
Methods. BMC Bioinformatics, 13:211.
Taylor Cassidy, Zheng Chen, Javier Artiles, Heng Ji,
Hongbo Deng, Lev-Arie Ratinov, Jing Zheng, Ji-
awei Han, and Dan Roth. 2011. CUNY-UIUC-SRI
TAC-KBP2011 Entity Linking System Description.
In Proceedings of Text Analysis Conference 2011.
Taylor Cassidy, Heng Ji, Lev-Arie Ratinov, Arkaitz Zu-
biaga, and Hongzhao Huang. 2012. Analysis and
Enhancement of Wikification for Microblogs with
Context Expansion. In Proceedings of the 25th In-
ternational Conference on Computational Linguis-
tics.
Xiao Cheng and Dan Roth. 2013. Relational Inference
for Wikification. In Proceedings of the 2013 Con-
ference on Empirical Methods in Natural Language
Processing.
James Clarke, Yuval Merhav, Ghalib Suleiman, Shuai
Zheng, and David Murgatroyd. 2012. Basis Tech-
nology at TAC 2012 Entity Linking. In Proceedings
of Text Analysis Conference 2012.
Silviu Cucerzan. 2011. TAC Entity Linking by Per-
forming Full-Document Entity Extraction and Dis-
ambiguation. In Proceedings of Text Analysis Con-
ference 2011.
Hong-Jie Dai, Po-Ting Lai, and Richard Tzong-Han
Tsai. 2010. Multistage Gene Normalization and
SVM-Based Ranking for Protein Interactor Extrac-
tion in Full-Text Articles. IEEE/ACM Transac-
tions on Computational Biology and Bioinformatics,
7(3):412–420.
Jeffrey Dalton and Laura Dietz. 2013. A Neighbor-
hood Relevance Model for Entity Linking. In Pro-
ceedings of the 10th Conference on Open Research
Areas in Information Retrieval.
Angela Fahrni, Vivi Nastase, and Michael Strube.
2011. HITS’ Cross-lingual Entity Linking System
at TAC2011: One Model for All Languages. In Pro-
ceedings of Text Analysis Conference 2011.
Angela Fahrni, Thierry G¨ockel, and Michael Strube.
2012. HITS’ Monolingual and Cross-lingual Entity
Linking System at TAC 2012: A Joint Approach. In
Proceedings of the Text Analysis Conference 2012.
Angela Fahrni, Benjamin Heinzerling, Thierry G¨ockel,
and Michael Strube. 2013. HITS’ Monolingual and
Cross-lingual Entity Linking System at TAC 2013.
In Proceedings of Text Analysis Conference 2013.
Haw-ren Fang, Kevin Murphy, Yang Jin, Jessica S.
Kim, and Peter S. White. 2006. Human Gene Name
Normalization Using Text Matching with Automati-
cally Extracted Synonym Dictionaries. In Proceed-
ings of the Workshop on Linking Natural Language
Processing and Biology: Towards Deeper Biologi-
cal Literature Analysis, pages 41–48.
Norberto Fern´andez, Jesus A. Fisteus, Luis S´anchez,
and Eduardo Martin. 2010. WebTLab: A
Cooccurence-Based Approach to KBP 2010 Entity-
Linking Task. In Proceedings of Text Analysis Con-
ference 2010.
William A. Gale, Kenneth W. Church, and David
Yarowsky. 1992. One Sense per Discourse. In
Proceedings of the Fifth DARPA Speech and Natu-
ral Language Workshop.
</reference>
<page confidence="0.98614">
703
</page>
<reference confidence="0.999837652173913">
Filipe Guo, Ying Xu, Filipe Mesquita, Denilson Bar-
bosa, and Grzegorz Kondrak. 2012. ualberta at
TAC-KBP 2012: English and Cross-Lingual Entity
Linking. In Proceedings of Text Analysis Confer-
ence 2012.
Xianpei Han, Le Sun, and Jun Zhao. 2011. Collec-
tive Entity Linking in Web Text: A Graph-Based
Method. In Proceedings of the 34th Annual ACM
SIGIR Conference.
Lynette Hirschman, Marc Colosimo, Alexander Mor-
gan, and Alexander Yeh. 2005. Overview of
BioCreAtIvE Task 1B: Normalized Gene Lists.
BMC Bioinformatics, 6.
Hongzhao Huang, Yunbo Cao, Xiaojiang Huang, Heng
Ji, and Chin-Yew Lin. 2014. Collective Tweet Wik-
ification based on Semi-supervised Graph Regular-
ization. In Proceedings of the 52nd Annual Meeting
of the Association for Computational Linguistics.
Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011.
Overview of the TAC 2011 Knowledge Base Popu-
lation Track. In Proceedings of Text Analysis Con-
ference 2011.
Xiao Ling, Sameer Singh, and Daniel S. Weld. 2014.
Context Representation for Named Entity Linking.
In Proceedings of the 3rd Pacific Northwest Re-
gional NLP Workshop.
Paul McNamee, James Mayfield, Dawn Lawrie, Dou-
glas W. Oard, and David Doermann. 2011. Cross-
Language Entity Linking. In Proceedings of the
5th International Joint Conference on Natural Lan-
guage Processing.
Paul McNamee, Veselin Stoyanov, James Mayfield,
Tim Finin, Tim Oates, Tan Xu, Douglas W. Oard,
and Dawn Lawrie. 2012. HLTCOE Participation at
TAC 2012: Entity Linking and Cold Start Knowl-
edge Base Construction. In Proceedings of Text
Analysis Conference 2012.
Qingliang Miao, Ruiyu Fang, Yao Meng, and Shu
Zhang. 2013. FRDC’s Cross-lingual Entity Link-
ing System at TAC 2013. In Proceedings of Text
Analysis Conference 2013.
Sean Monahan and Dean Carpenter. 2012. Lorify: A
Knowledge Base from Scratch. In Proceedings of
Text Analysis Conference 2012.
Sean Monahan, John Lehmann, Timothy Nyberg, Jesse
Plymale, and Arnold Jung. 2011. Cross-Lingual
Cross-Document Coreference with Entity Linking.
In Proceedings of Text Analysis Conference 2011.
Hien T. Nguyen, Huy H. Minha, Tru H. Cao, and
Trong T. Nguyen. 2012. JVN-TDT Entity Linking
Systems at TAC-KBP2012. In Proceedings of Text
Analysis Conference 2012.
Xiaoman Pan, Taylor Cassidy, Ulf Hermjakob, Heng Ji,
and Kevin Knight. 2015. Unsupervised Entity Link-
ing with Abstract Meaning Representation. In Pro-
ceedings of the 2015 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics – Human Language Technologies.
Marco Pennacchiotti and Patrick Pantel. 2009. En-
tity Extraction via Ensemble Semantics. In Proceed-
ings of the 2009 Conference on Empirical Methods
in Natural Language Processing EMNLP2009.
Lev-Arie Ratinov, Dan Roth, Doug Downey, and Mike
Anderson. 2011. Local and Global Algorithms for
Disambiguation to Wikipedia. In Proceedings of the
49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies.
Chen-Tse Tsai, Gourab Kundu, and Dan Roth. 2013.
Concept-Based Analysis of Scientific Literature. In
Proceedings of 22nd ACM International Conference
on Information and Knowledge Management (CIKM
2013).
Yu Usami, Han-Cheol Cho, Naoaki Okazaki, and
Jun’ichi Tsujii. 2011. Automatic Acquisition of
Huge Training Data for Bio-medical Named Entity
Recognition. In Proceedings of BioNLP 2011 Work-
shop.
Sofie Van Landeghem, Jari Bj¨orne, Thomas Abeel,
Bernard De Baets, Tapio Salakoski, and Yves Van de
Peer. 2012. Semantically Linking Molecular Enti-
ties in Literature through Entity Relationships. BMC
Bioinformatics, 13.
Jian Xu, Qin Lu, Jie Liu, and Ruifeng Xu. 2012. NLP-
Comp in TAC 2012 Entity Linking and Slot-Filling.
In Proceedings of Text Analysis Conference 2012.
Jin Guang Zheng, Daniel Howsmon, Boliang Zhang,
Juergen Hahn, Deborah McGuinness, James
Hendler, and Heng Ji. 2014. Entity Linking for
Biomedical Literature. In Proceedings of the ACM
8th International Workshop on Data and Text
Mining in Bioinformatics.
</reference>
<page confidence="0.998529">
704
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.702827">
<title confidence="0.999726">Language and Domain Independent Entity with Quantified Collective Validation</title>
<author confidence="0.996507">Jin Guang Xiaogang Peter</author>
<author confidence="0.996507">Heng</author>
<affiliation confidence="0.9949295">World Computer Science Rensselaer Polytechnic</affiliation>
<address confidence="0.888335">Troy, NY,</address>
<email confidence="0.852161">zhengj6,max7,pfox,</email>
<abstract confidence="0.997835857142857">Linking named mentions detected in a source document to an existing knowledge base provides disambiguated entity for the mentions. This lows better document analysis, knowledge extraction and knowledge base population. Most of the previous research extensively exploited the linguistic features of the source documents in a supervised or semi-supervised way. These systems therefore cannot be easily applied to a new language or domain. In this paper, we present a novel unsupervised algorithm named Quantified Collective Validation that avoids excessive linguistic analysis on the source documents and fully leverages the knowledge base structure for the entity linking task. We show our approach achieves stateof-the-art English entity linking performance and demonstrate successful deployment in a new language (Chinese) and two new domains (Biomedical and Earth Science). Experiment and system demonstration are available research purpose.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lakshmi Manohar Akella</author>
<author>Catherine N Norton</author>
<author>Holly Miller</author>
</authors>
<title>NetiNeti: Discovery of Scientific Names from Text Using Machine Learning Methods.</title>
<date>2012</date>
<journal>BMC Bioinformatics,</journal>
<pages>13--211</pages>
<contexts>
<context position="32745" citStr="Akella et al., 2012" startWordPosition="5358" endWordPosition="5361">the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the literature that focused solely on domainspecific EL (Zheng et al., 2014). In the biomedical domain, a few studies have been found on EL-related tasks such as scientific name discovery (Akella et al., 2012), gene name normalization (Hirschman et al., 2005; Fang et al., 2006; Dai et al., 2010), biomedical named entity recognition (Usami et al., 2011; Van Landeghem et al., 702 2012) and concept mention extraction (Tsai et al., 2013). The baseline system (Zheng et al., 2014) in this paper is the work most similar to ours in a sense of collectively aligning mentions to structured KBs. However, our system differs by integrating a context similarity ranking and a candidate validation to conduct a two-way collective inference with better performance. 6 Conclusions and Future Work Language and domain in</context>
</contexts>
<marker>Akella, Norton, Miller, 2012</marker>
<rawString>Lakshmi Manohar Akella, Catherine N. Norton, and Holly Miller. 2012. NetiNeti: Discovery of Scientific Names from Text Using Machine Learning Methods. BMC Bioinformatics, 13:211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Cassidy</author>
<author>Zheng Chen</author>
<author>Javier Artiles</author>
<author>Heng Ji</author>
<author>Hongbo Deng</author>
<author>Lev-Arie Ratinov</author>
<author>Jing Zheng</author>
<author>Jiawei Han</author>
<author>Dan Roth</author>
</authors>
<title>CUNY-UIUC-SRI TAC-KBP2011 Entity Linking System Description.</title>
<date>2011</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="31628" citStr="Cassidy et al., 2011" startWordPosition="5162" endWordPosition="5165">roaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguisti</context>
</contexts>
<marker>Cassidy, Chen, Artiles, Ji, Deng, Ratinov, Zheng, Han, Roth, 2011</marker>
<rawString>Taylor Cassidy, Zheng Chen, Javier Artiles, Heng Ji, Hongbo Deng, Lev-Arie Ratinov, Jing Zheng, Jiawei Han, and Dan Roth. 2011. CUNY-UIUC-SRI TAC-KBP2011 Entity Linking System Description. In Proceedings of Text Analysis Conference 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Cassidy</author>
<author>Heng Ji</author>
<author>Lev-Arie Ratinov</author>
<author>Arkaitz Zubiaga</author>
<author>Hongzhao Huang</author>
</authors>
<title>Analysis and Enhancement of Wikification for Microblogs with Context Expansion.</title>
<date>2012</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="30672" citStr="Cassidy et al., 2012" startWordPosition="5011" endWordPosition="5014">nn.), where nm is the number of linkable mentions in the document, n, is the number of candidates for each mention, and nn, is the number of neighbor nodes of a candidate, and nn. is the number of neighbors of a mention. 5 Related Work In recent years, collective inference methods for EL have become increasingly popular. Many efforts have been devoted to encoding linguistic fea1http://sweet.jpl.nasa.gov 2https://lucene.apache.org/ tures from the source documents in order to precisely select collaborator mentions for collective inference. These features include topic modeling (Xu et al., 2012; Cassidy et al., 2012), relation constraint (Cheng and Roth, 2013), coreferential chaining (Nguyen et al., 2012; Huang et al., 2014), and dependency restriction (Ling et al., 2014). Some recent work utilized multi-layer linguistic analysis integration to capture contextual properties for better mention collection (Pan et al., 2015). While many of these approaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantif</context>
</contexts>
<marker>Cassidy, Ji, Ratinov, Zubiaga, Huang, 2012</marker>
<rawString>Taylor Cassidy, Heng Ji, Lev-Arie Ratinov, Arkaitz Zubiaga, and Hongzhao Huang. 2012. Analysis and Enhancement of Wikification for Microblogs with Context Expansion. In Proceedings of the 25th International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Cheng</author>
<author>Dan Roth</author>
</authors>
<title>Relational Inference for Wikification.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="30716" citStr="Cheng and Roth, 2013" startWordPosition="5018" endWordPosition="5021">tions in the document, n, is the number of candidates for each mention, and nn, is the number of neighbor nodes of a candidate, and nn. is the number of neighbors of a mention. 5 Related Work In recent years, collective inference methods for EL have become increasingly popular. Many efforts have been devoted to encoding linguistic fea1http://sweet.jpl.nasa.gov 2https://lucene.apache.org/ tures from the source documents in order to precisely select collaborator mentions for collective inference. These features include topic modeling (Xu et al., 2012; Cassidy et al., 2012), relation constraint (Cheng and Roth, 2013), coreferential chaining (Nguyen et al., 2012; Huang et al., 2014), and dependency restriction (Ling et al., 2014). Some recent work utilized multi-layer linguistic analysis integration to capture contextual properties for better mention collection (Pan et al., 2015). While many of these approaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured</context>
</contexts>
<marker>Cheng, Roth, 2013</marker>
<rawString>Xiao Cheng and Dan Roth. 2013. Relational Inference for Wikification. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Yuval Merhav</author>
<author>Ghalib Suleiman</author>
<author>Shuai Zheng</author>
<author>David Murgatroyd</author>
</authors>
<date>2012</date>
<booktitle>Basis Technology at TAC 2012 Entity Linking. In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="23718" citStr="Clarke et al. (2012)" startWordPosition="3855" endWordPosition="3858"> the total 2,122 mentions extracted from Chinese newswire, web blogs, and discussion forums. For KB, we still used DBpedia because it contains multilingual surface forms for its entities. For instance, the entity Barack Obama has surface forms in over 30 languages including the Chinese one: “贝拉克·奥 巴马”. This cross-lingual surface form mapping naturally provides us with a convenient translation tool. Table 3 shows the linking performance comparison among QCV, our baseline system, and the top 3 participant systems of the KBP Chinese EL track. Again, we employed the B-Cubed+ metric. System B3+ F1 Clarke et al. (2012) (supervised) 0.493 Monahan and Carpenter (2012) (supervised) 0.660 Fahrni et al. (2012) (supervised) 0.736 Baseline (unsupervised) 0.648 QCV (unsupervised) 0.671 Table 3: Performance on the TAC-KBP2012 Chinese EL Dataset (1240 linkable mentions). As shown in Table 3, the best performance is 1http://www.nist.gov/tac/2012/KBP/data.html 700 achieved by Fahrni et al. (2012), a supervised system using over 20 fine-tuned features and many linguistic resources. In contrast, our QCV is an unsupervised approach without using any labeled data or linguistic resources. During the error analysis, we found</context>
<context position="31961" citStr="Clarke et al., 2012" startWordPosition="5222" endWordPosition="5225">te and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the literature that focus</context>
</contexts>
<marker>Clarke, Merhav, Suleiman, Zheng, Murgatroyd, 2012</marker>
<rawString>James Clarke, Yuval Merhav, Ghalib Suleiman, Shuai Zheng, and David Murgatroyd. 2012. Basis Technology at TAC 2012 Entity Linking. In Proceedings of Text Analysis Conference 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>TAC Entity Linking by Performing Full-Document Entity Extraction and Disambiguation.</title>
<date>2011</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="5669" citStr="Cucerzan, 2011" startWordPosition="869" endWordPosition="870">undry3 which provide significantly more domain knowledge than general KBs for EL to leverage. By incorporating these domain ontologies, we can easily increase the entity coverage and reduce noise for deploying EL in various new domains. In order to make the most of the KB structure, the mention context should be matched against the KB such that the relevant KB information can be extracted. A collective way of aligning co-occurred mentions to the KB graph has been proved to be a successful strategy to better represent the source context (Pennacchiotti and Pantel, 2009; Fern´andez et al., 2010; Cucerzan, 2011; Han et al., 2011; Ratinov et al., 2011; Dalton and Dietz, 2013; Zheng et al., 2014; Pan et al., 2015). We take a further step to consider quantitatively differentiating entity relations in the KB in order to evaluate entity candidates more precisely. Meanwhile, we jointly validate these candidates by aligning them back to the source context and integrating multiple ranking results. This novel EL framework deeply exploits the KB structure with a light weight representation of the source context, and thus enables a smooth migration to new lan1http://wiki.dbpedia.org 2http://bioportal.bioontolo</context>
</contexts>
<marker>Cucerzan, 2011</marker>
<rawString>Silviu Cucerzan. 2011. TAC Entity Linking by Performing Full-Document Entity Extraction and Disambiguation. In Proceedings of Text Analysis Conference 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong-Jie Dai</author>
<author>Po-Ting Lai</author>
<author>Richard Tzong-Han Tsai</author>
</authors>
<title>Multistage Gene Normalization and SVM-Based Ranking for Protein Interactor Extraction in Full-Text Articles.</title>
<date>2010</date>
<journal>IEEE/ACM Transactions on Computational Biology and Bioinformatics,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="32832" citStr="Dai et al., 2010" startWordPosition="5374" endWordPosition="5377">the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the literature that focused solely on domainspecific EL (Zheng et al., 2014). In the biomedical domain, a few studies have been found on EL-related tasks such as scientific name discovery (Akella et al., 2012), gene name normalization (Hirschman et al., 2005; Fang et al., 2006; Dai et al., 2010), biomedical named entity recognition (Usami et al., 2011; Van Landeghem et al., 702 2012) and concept mention extraction (Tsai et al., 2013). The baseline system (Zheng et al., 2014) in this paper is the work most similar to ours in a sense of collectively aligning mentions to structured KBs. However, our system differs by integrating a context similarity ranking and a candidate validation to conduct a two-way collective inference with better performance. 6 Conclusions and Future Work Language and domain independence is a new requirement to EL systems and this capability is particularly welco</context>
</contexts>
<marker>Dai, Lai, Tsai, 2010</marker>
<rawString>Hong-Jie Dai, Po-Ting Lai, and Richard Tzong-Han Tsai. 2010. Multistage Gene Normalization and SVM-Based Ranking for Protein Interactor Extraction in Full-Text Articles. IEEE/ACM Transactions on Computational Biology and Bioinformatics, 7(3):412–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Dalton</author>
<author>Laura Dietz</author>
</authors>
<title>A Neighborhood Relevance Model for Entity Linking.</title>
<date>2013</date>
<booktitle>In Proceedings of the 10th Conference on Open Research Areas in Information Retrieval.</booktitle>
<contexts>
<context position="5733" citStr="Dalton and Dietz, 2013" startWordPosition="879" endWordPosition="882"> than general KBs for EL to leverage. By incorporating these domain ontologies, we can easily increase the entity coverage and reduce noise for deploying EL in various new domains. In order to make the most of the KB structure, the mention context should be matched against the KB such that the relevant KB information can be extracted. A collective way of aligning co-occurred mentions to the KB graph has been proved to be a successful strategy to better represent the source context (Pennacchiotti and Pantel, 2009; Fern´andez et al., 2010; Cucerzan, 2011; Han et al., 2011; Ratinov et al., 2011; Dalton and Dietz, 2013; Zheng et al., 2014; Pan et al., 2015). We take a further step to consider quantitatively differentiating entity relations in the KB in order to evaluate entity candidates more precisely. Meanwhile, we jointly validate these candidates by aligning them back to the source context and integrating multiple ranking results. This novel EL framework deeply exploits the KB structure with a light weight representation of the source context, and thus enables a smooth migration to new lan1http://wiki.dbpedia.org 2http://bioportal.bioontology.org 3http://www.obofoundry.org guages and domains. The main n</context>
</contexts>
<marker>Dalton, Dietz, 2013</marker>
<rawString>Jeffrey Dalton and Laura Dietz. 2013. A Neighborhood Relevance Model for Entity Linking. In Proceedings of the 10th Conference on Open Research Areas in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
</authors>
<title>HITS’ Cross-lingual Entity Linking System at TAC2011: One Model for All Languages.</title>
<date>2011</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="31890" citStr="Fahrni et al., 2011" startWordPosition="5210" endWordPosition="5213">fied information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. </context>
</contexts>
<marker>Fahrni, Nastase, Strube, 2011</marker>
<rawString>Angela Fahrni, Vivi Nastase, and Michael Strube. 2011. HITS’ Cross-lingual Entity Linking System at TAC2011: One Model for All Languages. In Proceedings of Text Analysis Conference 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Thierry G¨ockel</author>
<author>Michael Strube</author>
</authors>
<title>HITS’ Monolingual and Cross-lingual Entity Linking System at TAC 2012: A Joint Approach.</title>
<date>2012</date>
<booktitle>In Proceedings of the Text Analysis Conference</booktitle>
<marker>Fahrni, G¨ockel, Strube, 2012</marker>
<rawString>Angela Fahrni, Thierry G¨ockel, and Michael Strube. 2012. HITS’ Monolingual and Cross-lingual Entity Linking System at TAC 2012: A Joint Approach. In Proceedings of the Text Analysis Conference 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angela Fahrni</author>
<author>Benjamin Heinzerling</author>
<author>Thierry G¨ockel</author>
<author>Michael Strube</author>
</authors>
<date>2013</date>
<booktitle>HITS’ Monolingual and Cross-lingual Entity Linking System at TAC 2013. In Proceedings of Text Analysis Conference</booktitle>
<marker>Fahrni, Heinzerling, G¨ockel, Strube, 2013</marker>
<rawString>Angela Fahrni, Benjamin Heinzerling, Thierry G¨ockel, and Michael Strube. 2013. HITS’ Monolingual and Cross-lingual Entity Linking System at TAC 2013. In Proceedings of Text Analysis Conference 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haw-ren Fang</author>
<author>Kevin Murphy</author>
<author>Yang Jin</author>
<author>Jessica S Kim</author>
<author>Peter S White</author>
</authors>
<title>Human Gene Name Normalization Using Text Matching with Automatically Extracted Synonym Dictionaries.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Linking Natural Language Processing and Biology: Towards Deeper Biological Literature Analysis,</booktitle>
<pages>41--48</pages>
<contexts>
<context position="32813" citStr="Fang et al., 2006" startWordPosition="5370" endWordPosition="5373"> heavily relies on the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the literature that focused solely on domainspecific EL (Zheng et al., 2014). In the biomedical domain, a few studies have been found on EL-related tasks such as scientific name discovery (Akella et al., 2012), gene name normalization (Hirschman et al., 2005; Fang et al., 2006; Dai et al., 2010), biomedical named entity recognition (Usami et al., 2011; Van Landeghem et al., 702 2012) and concept mention extraction (Tsai et al., 2013). The baseline system (Zheng et al., 2014) in this paper is the work most similar to ours in a sense of collectively aligning mentions to structured KBs. However, our system differs by integrating a context similarity ranking and a candidate validation to conduct a two-way collective inference with better performance. 6 Conclusions and Future Work Language and domain independence is a new requirement to EL systems and this capability is</context>
</contexts>
<marker>Fang, Murphy, Jin, Kim, White, 2006</marker>
<rawString>Haw-ren Fang, Kevin Murphy, Yang Jin, Jessica S. Kim, and Peter S. White. 2006. Human Gene Name Normalization Using Text Matching with Automatically Extracted Synonym Dictionaries. In Proceedings of the Workshop on Linking Natural Language Processing and Biology: Towards Deeper Biological Literature Analysis, pages 41–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norberto Fern´andez</author>
<author>Jesus A Fisteus</author>
<author>Luis S´anchez</author>
<author>Eduardo Martin</author>
</authors>
<title>WebTLab: A Cooccurence-Based Approach to KBP</title>
<date>2010</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<marker>Fern´andez, Fisteus, S´anchez, Martin, 2010</marker>
<rawString>Norberto Fern´andez, Jesus A. Fisteus, Luis S´anchez, and Eduardo Martin. 2010. WebTLab: A Cooccurence-Based Approach to KBP 2010 EntityLinking Task. In Proceedings of Text Analysis Conference 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Gale</author>
<author>Kenneth W Church</author>
<author>David Yarowsky</author>
</authors>
<title>One Sense per Discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fifth DARPA Speech and Natural Language Workshop.</booktitle>
<contexts>
<context position="10493" citStr="Gale et al., 1992" startWordPosition="1681" endWordPosition="1684">In this figure, mentions “New York Jets”, “Cotchery” and “Coles” are brought into Gm through the coreference between “Jets” and “New York Jets” since the three of them are outside the context window of “Caldwell”, “Florida”, “Patriots”, and “Jets”. Gm contains a set of vertices representing the mentions extracted from the source document and a set of undirected edges. There will be an edge between two mention vertices if both of them fall into a context window with width wm in the source document. Ideally, wm should cover a single discourse according to the one sense per discourse assumption (Gale et al., 1992), but for simplicity we heuristically set wm to be 7-sentence wide as a hyperparameter. Two mention vertices will be connected via a dashed edge if they are coreferential but are not located in the same context window. Here we determine the coreference by performing substring matching and abbreviation expansion. The dashed edge indicates the outof-context coreferential mention together with its neighbors will be indirectly included in Gm as extended context to later facilitate the candidate graph collective validation. Note that all of these loose settings comply with our intention of generati</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>William A. Gale, Kenneth W. Church, and David Yarowsky. 1992. One Sense per Discourse. In Proceedings of the Fifth DARPA Speech and Natural Language Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Filipe Guo</author>
<author>Ying Xu</author>
<author>Filipe Mesquita</author>
<author>Denilson Barbosa</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>ualberta at TAC-KBP 2012: English and Cross-Lingual Entity Linking.</title>
<date>2012</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="31668" citStr="Guo et al., 2012" startWordPosition="5170" endWordPosition="5173">e dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB of the new langua</context>
</contexts>
<marker>Guo, Xu, Mesquita, Barbosa, Kondrak, 2012</marker>
<rawString>Filipe Guo, Ying Xu, Filipe Mesquita, Denilson Barbosa, and Grzegorz Kondrak. 2012. ualberta at TAC-KBP 2012: English and Cross-Lingual Entity Linking. In Proceedings of Text Analysis Conference 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
<author>Jun Zhao</author>
</authors>
<title>Collective Entity Linking in Web Text: A Graph-Based Method.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th Annual ACM SIGIR Conference.</booktitle>
<marker>Han, Le Sun, Zhao, 2011</marker>
<rawString>Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective Entity Linking in Web Text: A Graph-Based Method. In Proceedings of the 34th Annual ACM SIGIR Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynette Hirschman</author>
<author>Marc Colosimo</author>
<author>Alexander Morgan</author>
<author>Alexander Yeh</author>
</authors>
<title>Overview of BioCreAtIvE Task 1B: Normalized Gene Lists.</title>
<date>2005</date>
<journal>BMC Bioinformatics,</journal>
<volume>6</volume>
<contexts>
<context position="32794" citStr="Hirschman et al., 2005" startWordPosition="5366" endWordPosition="5369">ors, the latter approach heavily relies on the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the literature that focused solely on domainspecific EL (Zheng et al., 2014). In the biomedical domain, a few studies have been found on EL-related tasks such as scientific name discovery (Akella et al., 2012), gene name normalization (Hirschman et al., 2005; Fang et al., 2006; Dai et al., 2010), biomedical named entity recognition (Usami et al., 2011; Van Landeghem et al., 702 2012) and concept mention extraction (Tsai et al., 2013). The baseline system (Zheng et al., 2014) in this paper is the work most similar to ours in a sense of collectively aligning mentions to structured KBs. However, our system differs by integrating a context similarity ranking and a candidate validation to conduct a two-way collective inference with better performance. 6 Conclusions and Future Work Language and domain independence is a new requirement to EL systems and</context>
</contexts>
<marker>Hirschman, Colosimo, Morgan, Yeh, 2005</marker>
<rawString>Lynette Hirschman, Marc Colosimo, Alexander Morgan, and Alexander Yeh. 2005. Overview of BioCreAtIvE Task 1B: Normalized Gene Lists. BMC Bioinformatics, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongzhao Huang</author>
<author>Yunbo Cao</author>
<author>Xiaojiang Huang</author>
<author>Heng Ji</author>
<author>Chin-Yew Lin</author>
</authors>
<title>Collective Tweet Wikification based on Semi-supervised Graph Regularization.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="30782" citStr="Huang et al., 2014" startWordPosition="5029" endWordPosition="5032">on, and nn, is the number of neighbor nodes of a candidate, and nn. is the number of neighbors of a mention. 5 Related Work In recent years, collective inference methods for EL have become increasingly popular. Many efforts have been devoted to encoding linguistic fea1http://sweet.jpl.nasa.gov 2https://lucene.apache.org/ tures from the source documents in order to precisely select collaborator mentions for collective inference. These features include topic modeling (Xu et al., 2012; Cassidy et al., 2012), relation constraint (Cheng and Roth, 2013), coreferential chaining (Nguyen et al., 2012; Huang et al., 2014), and dependency restriction (Ling et al., 2014). Some recent work utilized multi-layer linguistic analysis integration to capture contextual properties for better mention collection (Pan et al., 2015). While many of these approaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. S</context>
</contexts>
<marker>Huang, Cao, Huang, Ji, Lin, 2014</marker>
<rawString>Hongzhao Huang, Yunbo Cao, Xiaojiang Huang, Heng Ji, and Chin-Yew Lin. 2014. Collective Tweet Wikification based on Semi-supervised Graph Regularization. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Knowledge Base Population Track.</title>
<date>2011</date>
<journal>Overview of the TAC</journal>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="18744" citStr="Ji et al., 2011" startWordPosition="3061" endWordPosition="3064">nd Earth Science) to demonstrate the language and domain independent nature of our algorithm. 4.1 EL on Generic English Corpora For this evaluation, we used the TAC-KBP2013 EL dataset1, which contains 2,190 mentions extracted from English newswire, web blogs, and discussion forums. We selected a subset of 1,090 linkable mentions that have entity referents in the KB for our experiment. DBpedia 3.9, which was generated from the Wikipedia dump in early 2013 and includes more than 4 million entities and more than 470 million facts2, was used as our KB. We followed the KBP EL track using B-Cubed+ (Ji et al., 2011) as the evaluation metric. Table 1 presents the results of QCV, our baseline system, as well as the top 3 supervised participant systems3and the top 3 unsupervised participant systems3 of the TAC-KBP2013 EL track. System B3+ Fs Supervised 1st 0.7244 Supervised 2nd 0.7214 Supervised 3rd 0.7184 Unsupervised 1st 0.6324 Unsupervised 2nd 0.5764 Unsupervised 3rd 0.5734 Baseline (unsupervised) 0.697 QCV (unsupervised) 0.749 Table 1: Performance on the TAC-KBP2013 EL Dataset (1,090 linkable mentions). c∈V (Gic) r∈E(Gic) where V (Gic) and E(Gic) are the vertex set and the edge set of Gic; Sa(c), Sm(mc,</context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011. Overview of the TAC 2011 Knowledge Base Population Track. In Proceedings of Text Analysis Conference 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Sameer Singh</author>
<author>Daniel S Weld</author>
</authors>
<title>Context Representation for Named Entity Linking.</title>
<date>2014</date>
<booktitle>In Proceedings of the 3rd Pacific Northwest Regional NLP Workshop.</booktitle>
<contexts>
<context position="30830" citStr="Ling et al., 2014" startWordPosition="5036" endWordPosition="5039">candidate, and nn. is the number of neighbors of a mention. 5 Related Work In recent years, collective inference methods for EL have become increasingly popular. Many efforts have been devoted to encoding linguistic fea1http://sweet.jpl.nasa.gov 2https://lucene.apache.org/ tures from the source documents in order to precisely select collaborator mentions for collective inference. These features include topic modeling (Xu et al., 2012; Cassidy et al., 2012), relation constraint (Cheng and Roth, 2013), coreferential chaining (Nguyen et al., 2012; Huang et al., 2014), and dependency restriction (Ling et al., 2014). Some recent work utilized multi-layer linguistic analysis integration to capture contextual properties for better mention collection (Pan et al., 2015). While many of these approaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages</context>
</contexts>
<marker>Ling, Singh, Weld, 2014</marker>
<rawString>Xiao Ling, Sameer Singh, and Daniel S. Weld. 2014. Context Representation for Named Entity Linking. In Proceedings of the 3rd Pacific Northwest Regional NLP Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>James Mayfield</author>
<author>Dawn Lawrie</author>
<author>Douglas W Oard</author>
<author>David Doermann</author>
</authors>
<title>CrossLanguage Entity Linking.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="31606" citStr="McNamee et al., 2011" startWordPosition="5158" endWordPosition="5161">hile many of these approaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily r</context>
</contexts>
<marker>McNamee, Mayfield, Lawrie, Oard, Doermann, 2011</marker>
<rawString>Paul McNamee, James Mayfield, Dawn Lawrie, Douglas W. Oard, and David Doermann. 2011. CrossLanguage Entity Linking. In Proceedings of the 5th International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>Veselin Stoyanov</author>
<author>James Mayfield</author>
<author>Tim Finin</author>
<author>Tim Oates</author>
<author>Tan Xu</author>
<author>Douglas W Oard</author>
<author>Dawn Lawrie</author>
</authors>
<title>HLTCOE Participation at TAC 2012: Entity Linking and Cold Start Knowledge Base Construction.</title>
<date>2012</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="31650" citStr="McNamee et al., 2012" startWordPosition="5166" endWordPosition="5169">ed to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB</context>
</contexts>
<marker>McNamee, Stoyanov, Mayfield, Finin, Oates, Xu, Oard, Lawrie, 2012</marker>
<rawString>Paul McNamee, Veselin Stoyanov, James Mayfield, Tim Finin, Tim Oates, Tan Xu, Douglas W. Oard, and Dawn Lawrie. 2012. HLTCOE Participation at TAC 2012: Entity Linking and Cold Start Knowledge Base Construction. In Proceedings of Text Analysis Conference 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qingliang Miao</author>
<author>Ruiyu Fang</author>
<author>Yao Meng</author>
<author>Shu Zhang</author>
</authors>
<title>FRDC’s Cross-lingual Entity Linking System at TAC</title>
<date>2013</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="31688" citStr="Miao et al., 2013" startWordPosition="5174" endWordPosition="5177">ep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB of the new language. In comparison, o</context>
</contexts>
<marker>Miao, Fang, Meng, Zhang, 2013</marker>
<rawString>Qingliang Miao, Ruiyu Fang, Yao Meng, and Shu Zhang. 2013. FRDC’s Cross-lingual Entity Linking System at TAC 2013. In Proceedings of Text Analysis Conference 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Monahan</author>
<author>Dean Carpenter</author>
</authors>
<title>Lorify: A Knowledge Base from Scratch.</title>
<date>2012</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="23766" citStr="Monahan and Carpenter (2012)" startWordPosition="3861" endWordPosition="3864"> Chinese newswire, web blogs, and discussion forums. For KB, we still used DBpedia because it contains multilingual surface forms for its entities. For instance, the entity Barack Obama has surface forms in over 30 languages including the Chinese one: “贝拉克·奥 巴马”. This cross-lingual surface form mapping naturally provides us with a convenient translation tool. Table 3 shows the linking performance comparison among QCV, our baseline system, and the top 3 participant systems of the KBP Chinese EL track. Again, we employed the B-Cubed+ metric. System B3+ F1 Clarke et al. (2012) (supervised) 0.493 Monahan and Carpenter (2012) (supervised) 0.660 Fahrni et al. (2012) (supervised) 0.736 Baseline (unsupervised) 0.648 QCV (unsupervised) 0.671 Table 3: Performance on the TAC-KBP2012 Chinese EL Dataset (1240 linkable mentions). As shown in Table 3, the best performance is 1http://www.nist.gov/tac/2012/KBP/data.html 700 achieved by Fahrni et al. (2012), a supervised system using over 20 fine-tuned features and many linguistic resources. In contrast, our QCV is an unsupervised approach without using any labeled data or linguistic resources. During the error analysis, we found that in this dataset multiple mentions are ofte</context>
<context position="31940" citStr="Monahan and Carpenter, 2012" startWordPosition="5218" endWordPosition="5221">red KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the </context>
</contexts>
<marker>Monahan, Carpenter, 2012</marker>
<rawString>Sean Monahan and Dean Carpenter. 2012. Lorify: A Knowledge Base from Scratch. In Proceedings of Text Analysis Conference 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Monahan</author>
<author>John Lehmann</author>
<author>Timothy Nyberg</author>
<author>Jesse Plymale</author>
<author>Arnold Jung</author>
</authors>
<title>Cross-Lingual Cross-Document Coreference with Entity Linking.</title>
<date>2011</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="31869" citStr="Monahan et al., 2011" startWordPosition="5206" endWordPosition="5209">and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first type (McNamee et al., 2011; Cassidy et al., 2011; McNamee et al., 2012; Guo et al., 2012; Miao et al., 2013) translated entity mentions and source documents from the new language into English and then ran English mono-lingual EL to link to English KB. The second type (Monahan et al., 2011; Fahrni et al., 2011; Fahrni et al., 2012; Monahan and Carpenter, 2012; Clarke et al., 2012; Fahrni et al., 2013) developed EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources fr</context>
</contexts>
<marker>Monahan, Lehmann, Nyberg, Plymale, Jung, 2011</marker>
<rawString>Sean Monahan, John Lehmann, Timothy Nyberg, Jesse Plymale, and Arnold Jung. 2011. Cross-Lingual Cross-Document Coreference with Entity Linking. In Proceedings of Text Analysis Conference 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hien T Nguyen</author>
<author>Huy H Minha</author>
<author>Tru H Cao</author>
<author>Trong T Nguyen</author>
</authors>
<title>JVN-TDT Entity Linking Systems at TAC-KBP2012.</title>
<date>2012</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="30761" citStr="Nguyen et al., 2012" startWordPosition="5025" endWordPosition="5028">idates for each mention, and nn, is the number of neighbor nodes of a candidate, and nn. is the number of neighbors of a mention. 5 Related Work In recent years, collective inference methods for EL have become increasingly popular. Many efforts have been devoted to encoding linguistic fea1http://sweet.jpl.nasa.gov 2https://lucene.apache.org/ tures from the source documents in order to precisely select collaborator mentions for collective inference. These features include topic modeling (Xu et al., 2012; Cassidy et al., 2012), relation constraint (Cheng and Roth, 2013), coreferential chaining (Nguyen et al., 2012; Huang et al., 2014), and dependency restriction (Ling et al., 2014). Some recent work utilized multi-layer linguistic analysis integration to capture contextual properties for better mention collection (Pan et al., 2015). While many of these approaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the</context>
</contexts>
<marker>Nguyen, Minha, Cao, Nguyen, 2012</marker>
<rawString>Hien T. Nguyen, Huy H. Minha, Tru H. Cao, and Trong T. Nguyen. 2012. JVN-TDT Entity Linking Systems at TAC-KBP2012. In Proceedings of Text Analysis Conference 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoman Pan</author>
<author>Taylor Cassidy</author>
<author>Ulf Hermjakob</author>
<author>Heng Ji</author>
<author>Kevin Knight</author>
</authors>
<title>Unsupervised Entity Linking with Abstract Meaning Representation.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics – Human Language Technologies.</booktitle>
<contexts>
<context position="5772" citStr="Pan et al., 2015" startWordPosition="887" endWordPosition="890">orporating these domain ontologies, we can easily increase the entity coverage and reduce noise for deploying EL in various new domains. In order to make the most of the KB structure, the mention context should be matched against the KB such that the relevant KB information can be extracted. A collective way of aligning co-occurred mentions to the KB graph has been proved to be a successful strategy to better represent the source context (Pennacchiotti and Pantel, 2009; Fern´andez et al., 2010; Cucerzan, 2011; Han et al., 2011; Ratinov et al., 2011; Dalton and Dietz, 2013; Zheng et al., 2014; Pan et al., 2015). We take a further step to consider quantitatively differentiating entity relations in the KB in order to evaluate entity candidates more precisely. Meanwhile, we jointly validate these candidates by aligning them back to the source context and integrating multiple ranking results. This novel EL framework deeply exploits the KB structure with a light weight representation of the source context, and thus enables a smooth migration to new lan1http://wiki.dbpedia.org 2http://bioportal.bioontology.org 3http://www.obofoundry.org guages and domains. The main novel contributions of this paper are su</context>
<context position="30983" citStr="Pan et al., 2015" startWordPosition="5057" endWordPosition="5060">opular. Many efforts have been devoted to encoding linguistic fea1http://sweet.jpl.nasa.gov 2https://lucene.apache.org/ tures from the source documents in order to precisely select collaborator mentions for collective inference. These features include topic modeling (Xu et al., 2012; Cassidy et al., 2012), relation constraint (Cheng and Roth, 2013), coreferential chaining (Nguyen et al., 2012; Huang et al., 2014), and dependency restriction (Ling et al., 2014). Some recent work utilized multi-layer linguistic analysis integration to capture contextual properties for better mention collection (Pan et al., 2015). While many of these approaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, and rely on the quantified information computed from the structured KB to collectively evaluate and validate the entity candidates. Since the KB is relatively universal to languages and domains, our approach inherently is language and domain independent. Recent cross-lingual EL approaches can be divided into two types. The first typ</context>
</contexts>
<marker>Pan, Cassidy, Hermjakob, Ji, Knight, 2015</marker>
<rawString>Xiaoman Pan, Taylor Cassidy, Ulf Hermjakob, Heng Ji, and Kevin Knight. 2015. Unsupervised Entity Linking with Abstract Meaning Representation. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics – Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Patrick Pantel</author>
</authors>
<title>Entity Extraction via Ensemble Semantics.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing EMNLP2009.</booktitle>
<contexts>
<context position="5628" citStr="Pennacchiotti and Pantel, 2009" startWordPosition="860" endWordPosition="864">omain ontology repositories such as BioPortal2 and OBO Foundry3 which provide significantly more domain knowledge than general KBs for EL to leverage. By incorporating these domain ontologies, we can easily increase the entity coverage and reduce noise for deploying EL in various new domains. In order to make the most of the KB structure, the mention context should be matched against the KB such that the relevant KB information can be extracted. A collective way of aligning co-occurred mentions to the KB graph has been proved to be a successful strategy to better represent the source context (Pennacchiotti and Pantel, 2009; Fern´andez et al., 2010; Cucerzan, 2011; Han et al., 2011; Ratinov et al., 2011; Dalton and Dietz, 2013; Zheng et al., 2014; Pan et al., 2015). We take a further step to consider quantitatively differentiating entity relations in the KB in order to evaluate entity candidates more precisely. Meanwhile, we jointly validate these candidates by aligning them back to the source context and integrating multiple ranking results. This novel EL framework deeply exploits the KB structure with a light weight representation of the source context, and thus enables a smooth migration to new lan1http://wik</context>
</contexts>
<marker>Pennacchiotti, Pantel, 2009</marker>
<rawString>Marco Pennacchiotti and Patrick Pantel. 2009. Entity Extraction via Ensemble Semantics. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing EMNLP2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev-Arie Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and Global Algorithms for Disambiguation to Wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<contexts>
<context position="5709" citStr="Ratinov et al., 2011" startWordPosition="875" endWordPosition="878"> more domain knowledge than general KBs for EL to leverage. By incorporating these domain ontologies, we can easily increase the entity coverage and reduce noise for deploying EL in various new domains. In order to make the most of the KB structure, the mention context should be matched against the KB such that the relevant KB information can be extracted. A collective way of aligning co-occurred mentions to the KB graph has been proved to be a successful strategy to better represent the source context (Pennacchiotti and Pantel, 2009; Fern´andez et al., 2010; Cucerzan, 2011; Han et al., 2011; Ratinov et al., 2011; Dalton and Dietz, 2013; Zheng et al., 2014; Pan et al., 2015). We take a further step to consider quantitatively differentiating entity relations in the KB in order to evaluate entity candidates more precisely. Meanwhile, we jointly validate these candidates by aligning them back to the source context and integrating multiple ranking results. This novel EL framework deeply exploits the KB structure with a light weight representation of the source context, and thus enables a smooth migration to new lan1http://wiki.dbpedia.org 2http://bioportal.bioontology.org 3http://www.obofoundry.org guages</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev-Arie Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and Global Algorithms for Disambiguation to Wikipedia. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen-Tse Tsai</author>
<author>Gourab Kundu</author>
<author>Dan Roth</author>
</authors>
<title>Concept-Based Analysis of Scientific Literature.</title>
<date>2013</date>
<booktitle>In Proceedings of 22nd ACM International Conference on Information and Knowledge Management (CIKM</booktitle>
<contexts>
<context position="32973" citStr="Tsai et al., 2013" startWordPosition="5397" endWordPosition="5400">ping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the literature that focused solely on domainspecific EL (Zheng et al., 2014). In the biomedical domain, a few studies have been found on EL-related tasks such as scientific name discovery (Akella et al., 2012), gene name normalization (Hirschman et al., 2005; Fang et al., 2006; Dai et al., 2010), biomedical named entity recognition (Usami et al., 2011; Van Landeghem et al., 702 2012) and concept mention extraction (Tsai et al., 2013). The baseline system (Zheng et al., 2014) in this paper is the work most similar to ours in a sense of collectively aligning mentions to structured KBs. However, our system differs by integrating a context similarity ranking and a candidate validation to conduct a two-way collective inference with better performance. 6 Conclusions and Future Work Language and domain independence is a new requirement to EL systems and this capability is particularly welcome by low-resource language related applications and domain scientists. In this paper we demonstrated a high-performance EL approach that can</context>
</contexts>
<marker>Tsai, Kundu, Roth, 2013</marker>
<rawString>Chen-Tse Tsai, Gourab Kundu, and Dan Roth. 2013. Concept-Based Analysis of Scientific Literature. In Proceedings of 22nd ACM International Conference on Information and Knowledge Management (CIKM 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Usami</author>
<author>Han-Cheol Cho</author>
<author>Naoaki Okazaki</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Automatic Acquisition of Huge Training Data for Bio-medical Named Entity Recognition.</title>
<date>2011</date>
<booktitle>In Proceedings of BioNLP 2011 Workshop.</booktitle>
<contexts>
<context position="32889" citStr="Usami et al., 2011" startWordPosition="5383" endWordPosition="5386"> In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the literature that focused solely on domainspecific EL (Zheng et al., 2014). In the biomedical domain, a few studies have been found on EL-related tasks such as scientific name discovery (Akella et al., 2012), gene name normalization (Hirschman et al., 2005; Fang et al., 2006; Dai et al., 2010), biomedical named entity recognition (Usami et al., 2011; Van Landeghem et al., 702 2012) and concept mention extraction (Tsai et al., 2013). The baseline system (Zheng et al., 2014) in this paper is the work most similar to ours in a sense of collectively aligning mentions to structured KBs. However, our system differs by integrating a context similarity ranking and a candidate validation to conduct a two-way collective inference with better performance. 6 Conclusions and Future Work Language and domain independence is a new requirement to EL systems and this capability is particularly welcome by low-resource language related applications and doma</context>
</contexts>
<marker>Usami, Cho, Okazaki, Tsujii, 2011</marker>
<rawString>Yu Usami, Han-Cheol Cho, Naoaki Okazaki, and Jun’ichi Tsujii. 2011. Automatic Acquisition of Huge Training Data for Bio-medical Named Entity Recognition. In Proceedings of BioNLP 2011 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sofie Van Landeghem</author>
<author>Jari Bj¨orne</author>
<author>Thomas Abeel</author>
<author>Bernard De Baets</author>
<author>Tapio Salakoski</author>
<author>Yves Van de Peer</author>
</authors>
<title>Semantically Linking Molecular Entities in Literature through Entity Relationships.</title>
<date>2012</date>
<journal>BMC Bioinformatics,</journal>
<volume>13</volume>
<marker>Van Landeghem, Bj¨orne, Abeel, De Baets, Salakoski, Van de Peer, 2012</marker>
<rawString>Sofie Van Landeghem, Jari Bj¨orne, Thomas Abeel, Bernard De Baets, Tapio Salakoski, and Yves Van de Peer. 2012. Semantically Linking Molecular Entities in Literature through Entity Relationships. BMC Bioinformatics, 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian Xu</author>
<author>Qin Lu</author>
<author>Jie Liu</author>
<author>Ruifeng Xu</author>
</authors>
<title>NLPComp in TAC</title>
<date>2012</date>
<booktitle>In Proceedings of Text Analysis Conference</booktitle>
<contexts>
<context position="30649" citStr="Xu et al., 2012" startWordPosition="5007" endWordPosition="5010">(nm · n, · nn, · nn.), where nm is the number of linkable mentions in the document, n, is the number of candidates for each mention, and nn, is the number of neighbor nodes of a candidate, and nn. is the number of neighbors of a mention. 5 Related Work In recent years, collective inference methods for EL have become increasingly popular. Many efforts have been devoted to encoding linguistic fea1http://sweet.jpl.nasa.gov 2https://lucene.apache.org/ tures from the source documents in order to precisely select collaborator mentions for collective inference. These features include topic modeling (Xu et al., 2012; Cassidy et al., 2012), relation constraint (Cheng and Roth, 2013), coreferential chaining (Nguyen et al., 2012; Huang et al., 2014), and dependency restriction (Ling et al., 2014). Some recent work utilized multi-layer linguistic analysis integration to capture contextual properties for better mention collection (Pan et al., 2015). While many of these approaches have been proved to be effective, the dependency on deep linguistic knowledge makes it difficult to migrate them to a new language or domain. In contrast to these methods, we establish a very loose setting for the mention selection, </context>
</contexts>
<marker>Xu, Lu, Liu, Xu, 2012</marker>
<rawString>Jian Xu, Qin Lu, Jie Liu, and Ruifeng Xu. 2012. NLPComp in TAC 2012 Entity Linking and Slot-Filling. In Proceedings of Text Analysis Conference 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin Guang Zheng</author>
<author>Daniel Howsmon</author>
<author>Boliang Zhang</author>
<author>Juergen Hahn</author>
<author>Deborah McGuinness</author>
<author>James Hendler</author>
<author>Heng Ji</author>
</authors>
<title>Entity Linking for Biomedical Literature.</title>
<date>2014</date>
<booktitle>In Proceedings of the ACM 8th International Workshop on Data and Text Mining in Bioinformatics.</booktitle>
<contexts>
<context position="5753" citStr="Zheng et al., 2014" startWordPosition="883" endWordPosition="886"> to leverage. By incorporating these domain ontologies, we can easily increase the entity coverage and reduce noise for deploying EL in various new domains. In order to make the most of the KB structure, the mention context should be matched against the KB such that the relevant KB information can be extracted. A collective way of aligning co-occurred mentions to the KB graph has been proved to be a successful strategy to better represent the source context (Pennacchiotti and Pantel, 2009; Fern´andez et al., 2010; Cucerzan, 2011; Han et al., 2011; Ratinov et al., 2011; Dalton and Dietz, 2013; Zheng et al., 2014; Pan et al., 2015). We take a further step to consider quantitatively differentiating entity relations in the KB in order to evaluate entity candidates more precisely. Meanwhile, we jointly validate these candidates by aligning them back to the source context and integrating multiple ranking results. This novel EL framework deeply exploits the KB structure with a light weight representation of the source context, and thus enables a smooth migration to new lan1http://wiki.dbpedia.org 2http://bioportal.bioontology.org 3http://www.obofoundry.org guages and domains. The main novel contributions o</context>
<context position="7075" citStr="Zheng et al., 2014" startWordPosition="1085" endWordPosition="1088">ollective Validation (QCV) that builds KB entity candidate graphs with quantified relations for the purpose of collective disambiguation and inference. 2) We develop a procedure of building language and domain independent EL systems by incorporating various ontologies into the QCV component. 3) We demonstrate that our system is able to achieve state-of-the-art performance in English EL, and it can also produce promising results for Chinese EL as well as EL in Biomedical Science and Earth Science. 2 Baseline Collective EL As a baseline, we adopt a competitive unsupervised collective EL system (Zheng et al., 2014) utilizing structured KBs. It defines entropy based weights for the KB relations, and embeds them in a two-step candidate ranking process to produce the EL results. Structured KB Terminologies: In a structured KB, a fact is usually expressed in the form of a triple: (eh, r, et) where eh, et are called the head entity and the tail entity, respectively, and r is the relation between eh and et. Entropy Based KB Relation Weights: The goal is to leverage various levels of granularity of KB relations. The calculation of the relation weight H(r) is given in Equation (1): H(r) = − � P(et) log(P(et)) (</context>
<context position="26022" citStr="Zheng et al. (2014)" startWordPosition="4229" endWordPosition="4232">form mapping of the KB plays a crucial role in our approach. One can replace it with any machine translation product which, however, is not always available especially for a low-resource language. We should take advantage of the existing KBs where such crosslingual mapping has already been widely created. The latest DBpedia provides localized versions in 125 languages1, for instance. 4.3 EL in Biomedical Science To demonstrate the domain portability of our approach, we first take the biomedical science domain as a case study. We conducted our experiment using the evaluation dataset created by Zheng et al. (2014) which contains 208 linkable mentions extracted from several biomedical publications. We built our KB with over 300 domain ontologies downloaded from BioPortal. Table 4 compares the linking accuracy of QCV and our baseline system. As shown in Table 4, our approach achieves 1http://wiki.dbpedia.org/about System Correct Total Accuracy Baseline 173 208 83.17% QCV 177 208 85.10% Table 4: Biomedical Science EL Performance. similar performance to our baseline system which is the state-of-the-art to our knowledge. However, we were curious why QCV did not improve the baseline system in the biomedical </context>
<context position="32612" citStr="Zheng et al., 2014" startWordPosition="5334" endWordPosition="5337"> EL systems on the new language and used cross-lingual KB links to map the link results back to English KB. While the bottleneck of the former method usually is on translation errors, the latter approach heavily relies on the linguistic resources and the KB of the new language. In comparison, our system mainly uses the English KB and a mention surface form mapping that can either come from translation or cross-lingual KB links, and requires minimal linguistic resources from the new language. There is a limited amount of research work in the literature that focused solely on domainspecific EL (Zheng et al., 2014). In the biomedical domain, a few studies have been found on EL-related tasks such as scientific name discovery (Akella et al., 2012), gene name normalization (Hirschman et al., 2005; Fang et al., 2006; Dai et al., 2010), biomedical named entity recognition (Usami et al., 2011; Van Landeghem et al., 702 2012) and concept mention extraction (Tsai et al., 2013). The baseline system (Zheng et al., 2014) in this paper is the work most similar to ours in a sense of collectively aligning mentions to structured KBs. However, our system differs by integrating a context similarity ranking and a candida</context>
</contexts>
<marker>Zheng, Howsmon, Zhang, Hahn, McGuinness, Hendler, Ji, 2014</marker>
<rawString>Jin Guang Zheng, Daniel Howsmon, Boliang Zhang, Juergen Hahn, Deborah McGuinness, James Hendler, and Heng Ji. 2014. Entity Linking for Biomedical Literature. In Proceedings of the ACM 8th International Workshop on Data and Text Mining in Bioinformatics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>