<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000021">
<title confidence="0.96673">
Higher-order logical inference with compositional semantics
</title>
<author confidence="0.977233">
Koji Mineshima1,3 Pascual Martinez-G´omez1,2,3
</author>
<email confidence="0.97642">
mineshima.koji@ocha.ac.jp pascual@nii.ac.jp
</email>
<author confidence="0.881164">
Yusuke Miyao2 Daisuke Bekki1,2,3
</author>
<email confidence="0.871468">
yusuke@nii.ac.jp bekki@is.ocha.ac.jp
</email>
<affiliation confidence="0.989918">
1Ochanomizu University 2National Institute of Informatics 3CREST, JST
Tokyo, Japan Tokyo, Japan Saitama, Japan
</affiliation>
<sectionHeader confidence="0.978801" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999911235294118">
We present a higher-order inference sys-
tem based on a formal compositional
semantics and the wide-coverage CCG
parser. We develop an improved method
to bridge between the parser and seman-
tic composition. The system is evaluated
on the FraCaS test suite. In contrast to the
widely held view that higher-order logic is
unsuitable for efficient logical inferences,
the results show that a system based on
a reasonably-sized semantic lexicon and a
manageable number of non-first-order ax-
ioms enables efficient logical inferences,
including those concerned with general-
ized quantifiers and intensional operators,
and outperforms the state-of-the-art first-
order inference system.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999961945454546">
Entailment relations are of central importance in
the enterprise of both formal and computational
semantics. Traditionally, formal semanticists have
concentrated on a relatively small set of linguis-
tic inferences. However, since the emergence of
statistical parsers based on sophisticated syntac-
tic theories (Clark and Curran, 2007), an open do-
main system has been developed that supports cer-
tain degree of robust semantic interpretation with
wide coverage (Bos et al., 2004). It is then rea-
sonable to expect that a state-of-the-art formal se-
mantics provides an accurate computational basis
of natural language inferences.
However, there are still obstacles in the way
of achieving this goal. One is that the statistical
parsers on which semantic interpretations rely do
not necessarily reflect the best syntactic analysis as
assumed in the formal semantics literature (Honni-
bal et al., 2010). Another persistent problem is the
gap between the logics employed in the two com-
munities; while it is generally assumed among for-
mal semanticists that adequate semantic represen-
tations for natural language demand higher-order
logic or type theory (Carpenter, 1997), the domi-
nant view in computational linguistics is that infer-
ences based on higher-order logic are hopelessly
inefficient for practical applications (Bos, 2009a).
Accordingly, it is claimed that some approxima-
tion of higher-order representations in terms of
first-order logic (Hobbs, 1985), or a more efficient
“natural logic” system based on surface structures
is needed. However, it is often not a trivial task
to give an approximation of rich higher-order in-
formation within a first-order language (Pulman,
2007). Moreover, the coverage of existing natu-
ral logic systems is limited to single-premise in-
ferences (MacCartney and Manning, 2008).
In this paper, we first present an improved com-
positional semantics that fills the gap between the
parser syntax and a composition derivation. We
then develop an inference system that is capable of
higher-order inferences in natural languages. We
combine a state-of-the-art higher-order proof sys-
tem (Coq) with a wide-coverage parser based on
a modern syntactic theory (Combinatory Catego-
rial Grammar, CCG). The system is designed to
handle multi-premise inferences as well as single-
premise ones.
We test our system on the FraCaS test suite
(Cooper et al., 1994), which is suitable for eval-
uating the linguistic coverage of an inference sys-
tem. The experiments show that our higher-order
system outperforms the state-of-the-art first-order
system with respect to the speed and accuracy of
making logical inferences.
</bodyText>
<sectionHeader confidence="0.977447" genericHeader="introduction">
2 CCG and Compositional Semantics
</sectionHeader>
<bodyText confidence="0.998975">
As an initial step of compositional semantics, we
use the C&amp;C parser (Clark and Curran, 2007),
a statistical CCG parser trained on CCGbank
(Hockenmaier and Steedman, 2007). Parser out-
</bodyText>
<page confidence="0.922037">
2055
</page>
<note confidence="0.833923">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2055–2061,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figure confidence="0.725984">
category: S\NP
semantics: AQ.Q(Ax.True)(Ax.E(x))
</figure>
<figureCaption confidence="0.636061714285714">
Figure 1: Schematic lexical entry (semantic tem-
plate) for intransitive verbs. E is a position in
which a particular lexical item appears.
category: NP/N
semantics: AFAGAH.bx(Fx ∧ Gx Hx)
surf : every
Figure 2: The lexical entry for determiner every
</figureCaption>
<bodyText confidence="0.999498459459459">
puts are mapped onto semantic representations in
a standard way (Bos, 2008), using A-calculus as an
interface between syntax and semantics.
The strategy we use to build a semantic lexicon
is similar to that of Bos et al. (2004). A lexical en-
try for each open word class consists of a syntac-
tic category in CCG (possibly with syntactic fea-
tures) and a semantic representation encoded as a
A-term. Fig. 1 gives an example.1 For a limited
number of closed words such as logical or func-
tional expressions, a A-term is directly assigned to
a surface form (see Fig. 2). The output formula is
obtained by combining each A-term in accordance
with meaning composition rules and then by ap-
plying 0-conversion.
There is a non-trivial gap between the parser
output and the standard CCG-syntax as presented
in Steedman (2000). Due to this gap, it is not
straightforward to obtain desirable semantic repre-
sentations for a wide range of constructions. One
major difference from the standard CCG-syntax is
the treatment of post-NP modifiers; for instance,
the relative clause who works is assigned not the
category N\N, but the category NP\NP, which
applies to the whole NP. To derive correct truth-
conditions for quantificational sentences, we as-
sign to determiners a semantic term having an ex-
tra predicate variable as shown in Fig. 2, namely,
AFAGAH.bx(Fx ∧ Gx Hx), in a similar way
to the continuation semantics for event predicates
(Bos, 2009b; Champollion, 2015). The extra pred-
icate variable G can be filled by the semantically
empty predicate Ax.True in a verb phrase (see
Fig. 1). Fig. 3 gives an example derivation.
Note that the changes in the lexical entries as il-
lustrated in Fig. 1 and Fig. 2 are made for the cor-
rect semantic parsing, namely, the compositional
</bodyText>
<footnote confidence="0.9205015">
1Here we use a non-standard semantics for intransitive
verbs. We will explain it in the next paragraph.
</footnote>
<table confidence="0.773235833333333">
Examples Semantic Types
most (E Prop) (E Prop) Prop
might Prop Prop
true Prop Prop
manage Prop E Prop
believe Prop E Prop
</table>
<tableCaption confidence="0.868437">
Table 1: A classification of key linguistic elements
having higher-order denotations.
</tableCaption>
<bodyText confidence="0.997163470588235">
derivation of semantic representations. Usually,
inferences are conducted on those output seman-
tic representations in which additional complexi-
ties, such as lambda operators and extra predicate
variables, disappear. Accordingly, the changes in
the lexical entries do not affect the efficiency of
inferences.
The present analysis of post NP-modifiers can
also handle non-restrictive relative clauses such as
“the president, who ...”. In this case, the modi-
fier “who...” can be taken to apply to the whole
NP the president, thus its syntactic category can
be regarded as NP\NP, not as N\N. Thus, al-
though the NP\NP analysis of relative clauses is
a non-standard one, it has an advantage in that it
provides a unified treatment of restrictive and non-
restrictive relative clauses.
</bodyText>
<sectionHeader confidence="0.944336" genericHeader="method">
3 Representation and Inference in HOL
</sectionHeader>
<bodyText confidence="0.999947666666667">
We present a higher-order representation language
and describe apparently higher-order phenomena
that have received attention in formal semantics.
</bodyText>
<subsectionHeader confidence="0.999785">
3.1 Semantic representations in HOL
</subsectionHeader>
<bodyText confidence="0.879022444444444">
We use the language of higher-order logic (HOL)
with two basic types, E for entities and Prop for
propositions. Here we distinguish between propo-
sitions and truth-values, as is standard in modern
type theory (Ranta, 1994; Luo, 2012). Key higher-
order constructs are summarized in Table 1.2 A
first-order language can be taken as a fragment of
this language. Thus, adopting a higher-order lan-
guage does not lead to the loss of the expressive
power of the first-order language.
Apart from sub-sentential utterances such as
short answers to wh-questions (Ginzburg, 2005),
there are important constructions that are naturally
2We write a function from objects of type A to objects of
type B as A --+ B. Here --+ is right-associative: A --+ B --+ C
means A--+(B --+C). We use the symbol --+ both for logical
implication and function-type constructor, following the so-
called Curry-Howard isomorphism (Carpenter, 1997).
</bodyText>
<page confidence="0.959777">
2056
</page>
<figure confidence="0.962114545454546">
Every student who works
NP/N N (NP\NP)/(S\NP) S\NP
λFGH.∀x(Fx ∧ Gx → Hx) λx.student(x) λV QF.Q(λx.(V (λGH.Hx) ∧ Fx)) λQ.Q(λx.True)(λx.work(x))
&gt; &gt;
NP NP\NP
λGH.∀x(student(x) ∧ Gx → Hx) λQF.Q(λx.(work(x) ∧ Fx)) &lt; comes
NP S\NP
λFH.∀x(student(x) ∧ work(x) ∧ Fx → Hx) λQ.Q(λx.True)(λx.come(x))
&lt;
S
∀x(student(x) ∧ work(x) ∧ True → come(x))
</figure>
<figureCaption confidence="0.953644">
Figure 3: A CCG derivation of the semantic representation for the sentence Every student who works
comes. AFGH.X is an abbreviation for AFAGAH.X. “True” denotes the tautology, hence the final
formula is equivalent to bx(student(x) n work(x) — come(x)).
</figureCaption>
<bodyText confidence="0.993008111111111">
represented in higher-order languages.3
Generalized quantifiers A classical example of
non-first-orderizable expressions is a proportional
generalized quantifier like most and half of (Bar-
wise and Cooper, 1981). Model-theoretically, they
denote relations between sets. We represent them
as a two-place higher-order predicate taking first-
order predicates as arguments. For instance, Most
students work is represented as follows.
</bodyText>
<equation confidence="0.727871">
(1) most(Ax.student(x), Ax.work(x))
</equation>
<bodyText confidence="0.998469125">
Here, most is a higher-order predicate in the sense
that it takes first-order predicates Ax.student(x)
and Ax.work(x) as arguments. We take the entail-
ment patterns governing most as axioms, along the
same lines of natural logic and monotonicity cal-
culus (Icard and Moss, 2014), where determiners
are taken as primitive two-place operators.
Standard quantifiers like every and some could
also be treated as binary operators in the same way
as the binary most in (1). But we choose to adopt
the first-order decomposition in such cases (see
Fig. 2 for the lexical entry of every).
Modals Modal auxiliary expressions like might,
must and can are represented as unary sentential
operators. For instance, the sentence Some student
might come is represented as:
</bodyText>
<listItem confidence="0.661292">
(2) lx(student(x) n might(come(x))).
</listItem>
<bodyText confidence="0.998680444444445">
An important inference role of such a modal op-
erator is to distinguish modal contexts from actual
contexts and thus block an inference from one con-
text to another (might A does not entail A).
Alternatives to the higher-order approach in-
clude the first-order decomposition of modal op-
erators using world variables (Blackburn et al.,
2001) and the first-order modal semantic represen-
tations implemented in Boxer (Bos, 2005). We
</bodyText>
<footnote confidence="0.87793">
3See also Blackburn and Bos (2005) for some discussion
on inferences that go beyond first-order logic.
</footnote>
<bodyText confidence="0.9996115">
prefer the higher-order approach, because the first-
order approaches introduce additional quantifiers
and variables at the level of the semantic represen-
tations on which one makes inferences.
Veridical and anti-veridical predicates A sen-
tential operator O is veridical if O(A) entails A,
and anti-veridical if O(A) entails -,A. While
modal auxiliary verbs like might are neither veridi-
cal nor anti-veridical, there is a class of ex-
pressions licensing these patterns of inference.
Typical examples are adjectives taking an em-
bedded proposition, such as true/correct and
false/incorrect. Note that sentences like Every-
thing/what he said is false involve a quantifica-
tion over propositions, which is problematic for
the first-order approach.
The so-called implicative verbs like manage and
fail (Nairn et al., 2006) are also an instance of
this class. For example, Some student manages to
come is formalized as
</bodyText>
<listItem confidence="0.876763">
(3) lx(student(x) n manage(x, come(x)))
</listItem>
<bodyText confidence="0.983900909090909">
where manage is a veridical predicate taking a
proposition as the second argument; it licenses an
inference to lx(student(x) n come(x)).
Attitude verbs A wide range of propositional at-
titude verbs such as believe and hope are similar
to modals in that they do not license an inference
from attitude contexts to actual contexts. But fac-
tives like know and remember are an exception;
they are veridical.4
A first-order translation can be given along the
lines of Hintikka (1962). (4) is translated as (5).
</bodyText>
<listItem confidence="0.764904666666667">
(4) know(�ohn, lx(student(x) n come(x)))
(5) bw1(Rjohnw0 wi —
lx(student(wi, x) n come(wi, x)))
</listItem>
<footnote confidence="0.905312333333333">
4Factive predicates show the important inference patterns
known as presupposition projection (van der Sandt, 1992),
which are beyond the scope of this paper.
</footnote>
<page confidence="0.96733">
2057
</page>
<table confidence="0.438180769230769">
Inference pattern Axiom
Existential import VFVG (most(F, G)
→ 3x(Fx h Gx))
Conservativity VFVG (most(F, G)
→ most(F, Ax.(Fx h Gx)))
Monotonicity VFVGVH(most(F,G)
(right-upward) → (Vx(Gx → Hx)
→ most(F, H)))
Veridicality VP(true(P) → P)
VxVP(manage(x, P) → P)
VxVP(know(x, P) → P)
Anti-veridicality VP(false(P) → -P)
VxVP(fail(x, P) → -P)
</table>
<tableCaption confidence="0.783066">
Table 2: Axioms for non-first-order constructions.
</tableCaption>
<bodyText confidence="0.977516666666667">
However, one drawback is that the compositional
semantics becomes complicated, so we prefer the
non-decomposition approach for attitude verbs.
</bodyText>
<subsectionHeader confidence="0.979798">
3.2 Inferences in HOL
</subsectionHeader>
<bodyText confidence="0.999921473684211">
Following Chatzikyriakidis and Luo (2014), we
use a proof-assistant Coq (Cast´eran and Bertot,
2004) to implement a specialized prover for
higher-order features in natural languages, and
combine it with efficient first-order inferences. We
use Coq’s built-in tactics for first-order inferences.
Coq also has a language called Ltac for user-
defined automated tactics (Delahaye, 2000). The
additional axioms and tactics specialized for natu-
ral language constructions are written in Ltac. We
ran Coq fully automated, by feeding to its inter-
active mode a set of predefined tactics combined
with user-defined proof-search tactics.
Table 2 shows the axioms we implemented.
Modals and non-veridical predicates (by which we
mean predicates that are neither veridical nor anti-
veridical) do not have particular axioms, with the
consequence that actual and hypothetical contexts
are correctly distinguished.
</bodyText>
<sectionHeader confidence="0.999643" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999905888888889">
We evaluated our system on the FraCaS test suite
(Cooper et al., 1994), a set of entailment prob-
lems that is designed to evaluate theories of for-
mal semantics.5 We used the version provided by
MacCartney and Manning (2007). The whole data
set is divided into nine sections, each devoted to
linguistically challenging problems. Of these, we
used six sections, excluding three sections (nomi-
nal anaphora, ellipsis and temporal reference) that
</bodyText>
<footnote confidence="0.997913">
5Our system will be publicly available at
https://github.com/mynlp/ccg2lambda.
</footnote>
<table confidence="0.999879375">
Section # Ours Nut L&amp;S 13 Tian 14
Quantifiers 74 .77 .53 .62 .80
Plurals 33 .67 .52 − −
Adjectives 22 .68 .32 − −
Comparatives 31 .48 .45 − −
Verbs 8 .62 .62 − −
Attitudes 13 .77 .46 − −
Total 181 .69 .50 − −
</table>
<tableCaption confidence="0.999623">
Table 3: Accuracy on the FraCaS test suite. The
</tableCaption>
<bodyText confidence="0.998811738095238">
first column shows the number of problems. Of
the total 188 problems, we excluded seven prob-
lems that lack a well-defined answer.
involve a task of resolving context-dependency, a
task beyond the scope of this paper. Each prob-
lem consists of one or more premises, followed
by a hypothesis. There are three types of answer:
yes (the premise set entails the hypothesis), no (the
premise set entails the negation of the hypothesis),
and unknown (the premise set entails neither the
hypothesis nor its negation). Fig.4 shows some
examples.
Currently, our system has 57 templates for gen-
eral syntactic categories and 80 lexical entries for
closed words. In a similar way to Bos et al. (2004),
closed words are confined to a limited range of
logical and functional expressions such as quanti-
fiers and connectives. These templates and lexical
entries are not specific with respect to the FraCaS
test suite. We use WordNet (Miller, 1995) as the
knowledge base for antonymy; logical axioms rel-
evant to given inferences are extracted from this
knowledge base.
We compared our system with the state-of-
the-art CCG-based first-order system Boxer (Bos,
2008), which is one of the most well-known logic-
based approaches to textual entailment. We used
the Nutcracker system based on Boxer that utilizes
a first-order prover (Bliksem) and a model builder
(Mace) with the option enabling access to Word-
Net. We did not use the option enabling modal
semantics, since it did not improve the results. All
experiments were run on a 4-core@1.8Ghz, 8GB
RAM and SSD machine with Ubuntu.
Experimental results are shown in Table 3. Our
system improved on Nutcracker. We set a time-
out of 30 seconds, after which we output the label
“unknown”. Nutcracker timed-out in one third of
the problems (57 out of 181), whereas there was
no time-out in our system.
Table 4 shows parse times and inference times
for the FraCaS test suite. The inference speed
</bodyText>
<page confidence="0.985269">
2058
</page>
<table confidence="0.817741888888889">
fracas-067
Premise 1 All residents of the North American continent can travel freely within Europe.
Premise 2 Every Canadian resident is a resident of the North American continent.
Hypothesis All Canadian residents can travel freely within Europe.
Answer Yes
fracas-074
Premise 1 Most Europeans can travel freely within Europe.
Hypothesis Most Europeans who are resident outside Europe can travel freely within Europe.
Answer Unknown
</table>
<figureCaption confidence="0.848761">
Figure 4: Examples of entailment problems from the FraCaS test suite
</figureCaption>
<table confidence="0.987274">
Parsing and inference sec
/problem
CCG Parsing (C&amp;C parser) 3.76
Our system with higher-order inference 3.72
Our system with higher-order rules ablated 3.46
Nutcracker with first-order inference 11.23
(first-order prover + model builder)
</table>
<tableCaption confidence="0.601544333333333">
Table 4: Comparison of inference time on the Fra-
CaS test suite. CCG parsing is common to both
our system and Nutcracker.
</tableCaption>
<bodyText confidence="0.999875153846154">
of our system is significantly higher than that
of Nutcracker. Our system’s total accuracy with
higher-order rules is 69%, and drops to 59% when
ablating the higher-order rules.
We are aware of two other systems tested on
FraCaS that are capable of multiple-premise infer-
ences: the CCG-based first-order system of Lewis
and Steedman (2013) and the dependency-based
compositional semantics of Tian et al. (2014).
These systems were only evaluated on the Quan-
tifier section of FraCaS. As shown in Table 3, our
results improve on the former and are comparable
with the latter.
Other important studies on FraCaS are those
based on natural logic (MacCartney and Manning,
2008; Angeli and Manning, 2014). These sys-
tems are designed solely for single-premise in-
ferences and hence are incapable of handling the
general case of multiple-premise problems (which
cover about 45% of the problems in FraCaS). Our
system improves on these natural-logic-based sys-
tems by making multiple-premise inferences as
well.
Main errors we found are due to various parse
errors caused by the CCG parser, including the
failure to handle multiwords like a lot of. The per-
formance of our system will be further improved
with correct syntactic analyses. Our experiments
on FraCaS problems do not constitute an evalua-
tion on real texts nor on unseen test data. Note,
however, that a benefit of using a linguistically
controlled set of entailment problems is that one
can check not only whether, but also how each se-
mantic phenomenon is handled by the system. In
contrast to the widely held view that higher-order
logic is less useful in computational linguistics,
our results demonstrate the logical capacity of a
higher-order inference system integrated with the
CCG-based compositional semantics.
</bodyText>
<sectionHeader confidence="0.998834" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999923727272727">
We have presented a framework for a composi-
tional semantics based on the wide-coverage CCG
parser, combined with a higher-order inference
system. The experimental results on the FraCaS
test suite have shown that a reasonable number of
lexical entries and non-first-order axioms enable
various logical inferences in an efficient way and
outperform the state-of-the-art first-order system.
Future work will focus on incorporating a robust
model of lexical knowledge (Lewis and Steedman,
2013; Tian et al., 2014) to our framework.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998870571428571">
We are grateful to Chris Worth, Ribeka Tanaka,
and the three anonymous reviewers for their help-
ful comments and suggestions. This research
has been supported by the JST CREST program
(Establishment of Knowledge-Intensive Structural
Natural Language Processing and Construction of
Knowledge Infrastructure).
</bodyText>
<page confidence="0.9951">
2059
</page>
<sectionHeader confidence="0.990007" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999677442307692">
Gabor Angeli and Christopher D. Manning. 2014.
NaturalLI: Natural logic inference for common
sense reasoning. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP-2014), pages 534–545.
Jon Barwise and Robin Cooper. 1981. Generalized
quantifiers and natural language. Linguistics and
Philosophy, 4(2):159–219.
Patrick Blackburn and Johan Bos. 2005. Represen-
tation and Inference for Natural Language: A First
Course in Computational Semantics. CSLI.
Patrick Blackburn, Maarten de Rijke, and Yde Venema.
2001. Modal Logic. Cambridge University Press.
Johan Bos, Stephen Clark, Mark Steedman, James R.
Curran, and Julia Hockenmaier. 2004. Wide-
coverage semantic representations from a CCG
parser. In Proceedings of the 20th Interna-
tional Conference on Computational Linguistics
(COLING-2004), pages 104–111.
Johan Bos. 2005. Towards wide-coverage semantic in-
terpretation. In Proceedings of Sixth International
Workshop on Computational Semantics (IWCS-6),
pages 42–53.
Johan Bos. 2008. Wide-coverage semantic analysis
with Boxer. In Proceedings of the 2008 Conference
on Semantics in Text Processing, pages 277–286.
Johan Bos. 2009a. Applying automated deduction to
natural language understanding. Journal of Applied
Logic, 7(1):100–112.
Johan Bos. 2009b. Towards a large-scale formal se-
mantic lexicon for text processing. In Proceed-
ings of the Biennal GSCL Conference From Form
to Meaning: Processing Texts Automatically, pages
3–14.
Bob Carpenter. 1997. Type-Logical Semantics. MIT
Press.
Pierre Cast´eran and Yves Bertot. 2004. Interac-
tive Theorem Proving and Program Development.
Coq’Art: The Calculus of Inductive Constructions.
Springer.
Lucas Champollion. 2015. The interaction of compo-
sitional semantics and event semantics. Linguistics
and Philosophy, 38(1):31–66.
Stergios Chatzikyriakidis and Zhaohui Luo. 2014.
Natural language inference in Coq. Journal of
Logic, Language and Information, 23(4):441–480.
Stephen Clark and James R Curran. 2007. Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguistics,
33(4):493–552.
Robin Cooper, Richard Crouch, Jan van Eijck, Chris
Fox, Josef van Genabith, Jan Jaspers, Hans Kamp,
Manfred Pinkal, Massimo Poesio, Stephen Pulman,
et al. 1994. FraCaS: A Framework for Computa-
tional Semantics. Deliverable, D6.
David Delahaye. 2000. A Tactic Language for the Sys-
tem Coq. In Logic for Programming and Automated
Reasoning (LPAR), volume 1955 of Lecture Notes in
Computer Science, pages 85–95. Springer.
Jonathan Ginzburg. 2005. Abstraction and ontology:
Questions as propositional abstracts in type theory
with records. Journal of Logic and Computation,
15(2):113–130.
Jaakko Hintikka. 1962. Knowledge and Belief. Cor-
nell University Press.
Jerry R. Hobbs. 1985. Ontological promiscuity. In
Proceedings of the 23rd annual meeting on Asso-
ciation for Computational Linguistics (ACL-1985),
pages 60–69.
Julia Hockenmaier and Mark Steedman. 2007. CCG-
bank: a corpus of CCG derivations and dependency
structures extracted from the Penn Treebank. Com-
putational Linguistics, 33(3):355–396.
Matthew Honnibal, James R. Curran, and Johan Bos.
2010. Rebanking CCGbank for improved NP inter-
pretation. In Proceedings of the 48th Annual Meet-
ing of the Association for Computational Linguistics
(ACL-2010), pages 207–215.
Thomas Icard and Lawrence Moss. 2014. Recent
progress in monotonicity. Linguistic Issues in Lan-
guage Technology (LiLT), 9.
Mike Lewis and Mark Steedman. 2013. Combin-
ing distributional and logical semantics. Transac-
tions of the Association for Computational Linguis-
tics, 1:179–192.
Zhaohui Luo. 2012. Formal semantics in modern type
theories with coercive subtyping. Linguistics and
Philosophy, 35(6):491–513.
Bill MacCartney and Christopher D. Manning. 2007.
Natural logic for textual inference. In Proceedings
of the ACL-PASCAL Workshop on Textual Entail-
ment and Paraphrasing, pages 193–200.
Bill MacCartney and Christopher D. Manning. 2008.
Modeling semantic containment and exclusion in
natural language inference. In Proceedings of the
22nd International Conference on Computational
Linguistics, pages 521–528.
George A Miller. 1995. WordNet: a lexical
database for English. Communications of the ACM,
38(11):39–41.
Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen.
2006. Computing relative polarity for textual infer-
ence. Inference in Computational Semantics (ICoS-
5), pages 67–76.
</reference>
<page confidence="0.751984">
2060
</page>
<reference confidence="0.999331875">
Stephen Pulman. 2007. Formal and computational se-
mantics: a case study. In Proceedings of the Seventh
International Workshop on Computational Seman-
tics (IWCS-7), pages 181–196.
Aarne Ranta. 1994. Type-Theoretical Grammar. Ox-
ford University Press.
Mark Steedman. 2000. The Syntactic Process. MIT
Press.
Ran Tian, Yusuke Miyao, and Takuya Matsuzaki.
2014. Logical inference on dependency-based com-
positional semantics. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics (ACL-2014), pages 79–89.
Rob van der Sandt. 1992. Presupposition projec-
tion as anaphora resolution. Journal of Semantics,
9(4):333–377.
</reference>
<page confidence="0.993662">
2061
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.337117">
<title confidence="0.687577">Higher-order logical inference with compositional semantics</title>
<abstract confidence="0.7353825">mineshima.koji@ocha.ac.jp pascual@nii.ac.jp yusuke@nii.ac.jp bekki@is.ocha.ac.jp</abstract>
<affiliation confidence="0.99965">University Institute of Informatics JST</affiliation>
<address confidence="0.808126">Tokyo, Japan Tokyo, Japan Saitama, Japan</address>
<abstract confidence="0.998853944444444">We present a higher-order inference system based on a formal compositional semantics and the wide-coverage CCG parser. We develop an improved method to bridge between the parser and semantic composition. The system is evaluated on the FraCaS test suite. In contrast to the widely held view that higher-order logic is unsuitable for efficient logical inferences, the results show that a system based on a reasonably-sized semantic lexicon and a manageable number of non-first-order axioms enables efficient logical inferences, including those concerned with generalized quantifiers and intensional operators, and outperforms the state-of-the-art firstorder inference system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Gabor Angeli</author>
<author>Christopher D Manning</author>
</authors>
<title>NaturalLI: Natural logic inference for common sense reasoning.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2014),</booktitle>
<pages>534--545</pages>
<contexts>
<context position="18159" citStr="Angeli and Manning, 2014" startWordPosition="2817" endWordPosition="2820">m’s total accuracy with higher-order rules is 69%, and drops to 59% when ablating the higher-order rules. We are aware of two other systems tested on FraCaS that are capable of multiple-premise inferences: the CCG-based first-order system of Lewis and Steedman (2013) and the dependency-based compositional semantics of Tian et al. (2014). These systems were only evaluated on the Quantifier section of FraCaS. As shown in Table 3, our results improve on the former and are comparable with the latter. Other important studies on FraCaS are those based on natural logic (MacCartney and Manning, 2008; Angeli and Manning, 2014). These systems are designed solely for single-premise inferences and hence are incapable of handling the general case of multiple-premise problems (which cover about 45% of the problems in FraCaS). Our system improves on these natural-logic-based systems by making multiple-premise inferences as well. Main errors we found are due to various parse errors caused by the CCG parser, including the failure to handle multiwords like a lot of. The performance of our system will be further improved with correct syntactic analyses. Our experiments on FraCaS problems do not constitute an evaluation on re</context>
</contexts>
<marker>Angeli, Manning, 2014</marker>
<rawString>Gabor Angeli and Christopher D. Manning. 2014. NaturalLI: Natural logic inference for common sense reasoning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2014), pages 534–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Barwise</author>
<author>Robin Cooper</author>
</authors>
<title>Generalized quantifiers and natural language.</title>
<date>1981</date>
<journal>Linguistics and Philosophy,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="9151" citStr="Barwise and Cooper, 1981" startWordPosition="1396" endWordPosition="1400"> Gx → Hx) λQF.Q(λx.(work(x) ∧ Fx)) &lt; comes NP S\NP λFH.∀x(student(x) ∧ work(x) ∧ Fx → Hx) λQ.Q(λx.True)(λx.come(x)) &lt; S ∀x(student(x) ∧ work(x) ∧ True → come(x)) Figure 3: A CCG derivation of the semantic representation for the sentence Every student who works comes. AFGH.X is an abbreviation for AFAGAH.X. “True” denotes the tautology, hence the final formula is equivalent to bx(student(x) n work(x) — come(x)). represented in higher-order languages.3 Generalized quantifiers A classical example of non-first-orderizable expressions is a proportional generalized quantifier like most and half of (Barwise and Cooper, 1981). Model-theoretically, they denote relations between sets. We represent them as a two-place higher-order predicate taking firstorder predicates as arguments. For instance, Most students work is represented as follows. (1) most(Ax.student(x), Ax.work(x)) Here, most is a higher-order predicate in the sense that it takes first-order predicates Ax.student(x) and Ax.work(x) as arguments. We take the entailment patterns governing most as axioms, along the same lines of natural logic and monotonicity calculus (Icard and Moss, 2014), where determiners are taken as primitive two-place operators. Standa</context>
</contexts>
<marker>Barwise, Cooper, 1981</marker>
<rawString>Jon Barwise and Robin Cooper. 1981. Generalized quantifiers and natural language. Linguistics and Philosophy, 4(2):159–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Blackburn</author>
<author>Johan Bos</author>
</authors>
<title>Representation and Inference for Natural Language: A First Course in Computational Semantics.</title>
<date>2005</date>
<publisher>CSLI.</publisher>
<contexts>
<context position="10657" citStr="Blackburn and Bos (2005)" startWordPosition="1629" endWordPosition="1632">t and can are represented as unary sentential operators. For instance, the sentence Some student might come is represented as: (2) lx(student(x) n might(come(x))). An important inference role of such a modal operator is to distinguish modal contexts from actual contexts and thus block an inference from one context to another (might A does not entail A). Alternatives to the higher-order approach include the first-order decomposition of modal operators using world variables (Blackburn et al., 2001) and the first-order modal semantic representations implemented in Boxer (Bos, 2005). We 3See also Blackburn and Bos (2005) for some discussion on inferences that go beyond first-order logic. prefer the higher-order approach, because the firstorder approaches introduce additional quantifiers and variables at the level of the semantic representations on which one makes inferences. Veridical and anti-veridical predicates A sentential operator O is veridical if O(A) entails A, and anti-veridical if O(A) entails -,A. While modal auxiliary verbs like might are neither veridical nor anti-veridical, there is a class of expressions licensing these patterns of inference. Typical examples are adjectives taking an embedded p</context>
</contexts>
<marker>Blackburn, Bos, 2005</marker>
<rawString>Patrick Blackburn and Johan Bos. 2005. Representation and Inference for Natural Language: A First Course in Computational Semantics. CSLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Blackburn</author>
<author>Maarten de Rijke</author>
<author>Yde Venema</author>
</authors>
<title>Modal Logic.</title>
<date>2001</date>
<publisher>Cambridge University Press.</publisher>
<marker>Blackburn, de Rijke, Venema, 2001</marker>
<rawString>Patrick Blackburn, Maarten de Rijke, and Yde Venema. 2001. Modal Logic. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Stephen Clark</author>
<author>Mark Steedman</author>
<author>James R Curran</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Widecoverage semantic representations from a CCG parser.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING-2004),</booktitle>
<pages>104--111</pages>
<contexts>
<context position="1505" citStr="Bos et al., 2004" startWordPosition="200" endWordPosition="203">rned with generalized quantifiers and intensional operators, and outperforms the state-of-the-art firstorder inference system. 1 Introduction Entailment relations are of central importance in the enterprise of both formal and computational semantics. Traditionally, formal semanticists have concentrated on a relatively small set of linguistic inferences. However, since the emergence of statistical parsers based on sophisticated syntactic theories (Clark and Curran, 2007), an open domain system has been developed that supports certain degree of robust semantic interpretation with wide coverage (Bos et al., 2004). It is then reasonable to expect that a state-of-the-art formal semantics provides an accurate computational basis of natural language inferences. However, there are still obstacles in the way of achieving this goal. One is that the statistical parsers on which semantic interpretations rely do not necessarily reflect the best syntactic analysis as assumed in the formal semantics literature (Honnibal et al., 2010). Another persistent problem is the gap between the logics employed in the two communities; while it is generally assumed among formal semanticists that adequate semantic representati</context>
<context position="4592" citStr="Bos et al. (2004)" startWordPosition="669" endWordPosition="672">1, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. category: S\NP semantics: AQ.Q(Ax.True)(Ax.E(x)) Figure 1: Schematic lexical entry (semantic template) for intransitive verbs. E is a position in which a particular lexical item appears. category: NP/N semantics: AFAGAH.bx(Fx ∧ Gx Hx) surf : every Figure 2: The lexical entry for determiner every puts are mapped onto semantic representations in a standard way (Bos, 2008), using A-calculus as an interface between syntax and semantics. The strategy we use to build a semantic lexicon is similar to that of Bos et al. (2004). A lexical entry for each open word class consists of a syntactic category in CCG (possibly with syntactic features) and a semantic representation encoded as a A-term. Fig. 1 gives an example.1 For a limited number of closed words such as logical or functional expressions, a A-term is directly assigned to a surface form (see Fig. 2). The output formula is obtained by combining each A-term in accordance with meaning composition rules and then by applying 0-conversion. There is a non-trivial gap between the parser output and the standard CCG-syntax as presented in Steedman (2000). Due to this g</context>
<context position="15363" citStr="Bos et al. (2004)" startWordPosition="2369" endWordPosition="2372"> we excluded seven problems that lack a well-defined answer. involve a task of resolving context-dependency, a task beyond the scope of this paper. Each problem consists of one or more premises, followed by a hypothesis. There are three types of answer: yes (the premise set entails the hypothesis), no (the premise set entails the negation of the hypothesis), and unknown (the premise set entails neither the hypothesis nor its negation). Fig.4 shows some examples. Currently, our system has 57 templates for general syntactic categories and 80 lexical entries for closed words. In a similar way to Bos et al. (2004), closed words are confined to a limited range of logical and functional expressions such as quantifiers and connectives. These templates and lexical entries are not specific with respect to the FraCaS test suite. We use WordNet (Miller, 1995) as the knowledge base for antonymy; logical axioms relevant to given inferences are extracted from this knowledge base. We compared our system with the state-ofthe-art CCG-based first-order system Boxer (Bos, 2008), which is one of the most well-known logicbased approaches to textual entailment. We used the Nutcracker system based on Boxer that utilizes </context>
</contexts>
<marker>Bos, Clark, Steedman, Curran, Hockenmaier, 2004</marker>
<rawString>Johan Bos, Stephen Clark, Mark Steedman, James R. Curran, and Julia Hockenmaier. 2004. Widecoverage semantic representations from a CCG parser. In Proceedings of the 20th International Conference on Computational Linguistics (COLING-2004), pages 104–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Towards wide-coverage semantic interpretation.</title>
<date>2005</date>
<booktitle>In Proceedings of Sixth International Workshop on Computational Semantics (IWCS-6),</booktitle>
<pages>42--53</pages>
<contexts>
<context position="10618" citStr="Bos, 2005" startWordPosition="1624" endWordPosition="1625">pressions like might, must and can are represented as unary sentential operators. For instance, the sentence Some student might come is represented as: (2) lx(student(x) n might(come(x))). An important inference role of such a modal operator is to distinguish modal contexts from actual contexts and thus block an inference from one context to another (might A does not entail A). Alternatives to the higher-order approach include the first-order decomposition of modal operators using world variables (Blackburn et al., 2001) and the first-order modal semantic representations implemented in Boxer (Bos, 2005). We 3See also Blackburn and Bos (2005) for some discussion on inferences that go beyond first-order logic. prefer the higher-order approach, because the firstorder approaches introduce additional quantifiers and variables at the level of the semantic representations on which one makes inferences. Veridical and anti-veridical predicates A sentential operator O is veridical if O(A) entails A, and anti-veridical if O(A) entails -,A. While modal auxiliary verbs like might are neither veridical nor anti-veridical, there is a class of expressions licensing these patterns of inference. Typical examp</context>
</contexts>
<marker>Bos, 2005</marker>
<rawString>Johan Bos. 2005. Towards wide-coverage semantic interpretation. In Proceedings of Sixth International Workshop on Computational Semantics (IWCS-6), pages 42–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Wide-coverage semantic analysis with Boxer.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Semantics in Text Processing,</booktitle>
<pages>277--286</pages>
<contexts>
<context position="4440" citStr="Bos, 2008" startWordPosition="644" endWordPosition="645">nmaier and Steedman, 2007). Parser out2055 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2055–2061, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. category: S\NP semantics: AQ.Q(Ax.True)(Ax.E(x)) Figure 1: Schematic lexical entry (semantic template) for intransitive verbs. E is a position in which a particular lexical item appears. category: NP/N semantics: AFAGAH.bx(Fx ∧ Gx Hx) surf : every Figure 2: The lexical entry for determiner every puts are mapped onto semantic representations in a standard way (Bos, 2008), using A-calculus as an interface between syntax and semantics. The strategy we use to build a semantic lexicon is similar to that of Bos et al. (2004). A lexical entry for each open word class consists of a syntactic category in CCG (possibly with syntactic features) and a semantic representation encoded as a A-term. Fig. 1 gives an example.1 For a limited number of closed words such as logical or functional expressions, a A-term is directly assigned to a surface form (see Fig. 2). The output formula is obtained by combining each A-term in accordance with meaning composition rules and then b</context>
<context position="15821" citStr="Bos, 2008" startWordPosition="2443" endWordPosition="2444">. Currently, our system has 57 templates for general syntactic categories and 80 lexical entries for closed words. In a similar way to Bos et al. (2004), closed words are confined to a limited range of logical and functional expressions such as quantifiers and connectives. These templates and lexical entries are not specific with respect to the FraCaS test suite. We use WordNet (Miller, 1995) as the knowledge base for antonymy; logical axioms relevant to given inferences are extracted from this knowledge base. We compared our system with the state-ofthe-art CCG-based first-order system Boxer (Bos, 2008), which is one of the most well-known logicbased approaches to textual entailment. We used the Nutcracker system based on Boxer that utilizes a first-order prover (Bliksem) and a model builder (Mace) with the option enabling access to WordNet. We did not use the option enabling modal semantics, since it did not improve the results. All experiments were run on a 4-core@1.8Ghz, 8GB RAM and SSD machine with Ubuntu. Experimental results are shown in Table 3. Our system improved on Nutcracker. We set a timeout of 30 seconds, after which we output the label “unknown”. Nutcracker timed-out in one thi</context>
</contexts>
<marker>Bos, 2008</marker>
<rawString>Johan Bos. 2008. Wide-coverage semantic analysis with Boxer. In Proceedings of the 2008 Conference on Semantics in Text Processing, pages 277–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Applying automated deduction to natural language understanding.</title>
<date>2009</date>
<journal>Journal of Applied Logic,</journal>
<volume>7</volume>
<issue>1</issue>
<contexts>
<context position="2348" citStr="Bos, 2009" startWordPosition="330" endWordPosition="331">statistical parsers on which semantic interpretations rely do not necessarily reflect the best syntactic analysis as assumed in the formal semantics literature (Honnibal et al., 2010). Another persistent problem is the gap between the logics employed in the two communities; while it is generally assumed among formal semanticists that adequate semantic representations for natural language demand higher-order logic or type theory (Carpenter, 1997), the dominant view in computational linguistics is that inferences based on higher-order logic are hopelessly inefficient for practical applications (Bos, 2009a). Accordingly, it is claimed that some approximation of higher-order representations in terms of first-order logic (Hobbs, 1985), or a more efficient “natural logic” system based on surface structures is needed. However, it is often not a trivial task to give an approximation of rich higher-order information within a first-order language (Pulman, 2007). Moreover, the coverage of existing natural logic systems is limited to single-premise inferences (MacCartney and Manning, 2008). In this paper, we first present an improved compositional semantics that fills the gap between the parser syntax </context>
<context position="5795" citStr="Bos, 2009" startWordPosition="872" endWordPosition="873">this gap, it is not straightforward to obtain desirable semantic representations for a wide range of constructions. One major difference from the standard CCG-syntax is the treatment of post-NP modifiers; for instance, the relative clause who works is assigned not the category N\N, but the category NP\NP, which applies to the whole NP. To derive correct truthconditions for quantificational sentences, we assign to determiners a semantic term having an extra predicate variable as shown in Fig. 2, namely, AFAGAH.bx(Fx ∧ Gx Hx), in a similar way to the continuation semantics for event predicates (Bos, 2009b; Champollion, 2015). The extra predicate variable G can be filled by the semantically empty predicate Ax.True in a verb phrase (see Fig. 1). Fig. 3 gives an example derivation. Note that the changes in the lexical entries as illustrated in Fig. 1 and Fig. 2 are made for the correct semantic parsing, namely, the compositional 1Here we use a non-standard semantics for intransitive verbs. We will explain it in the next paragraph. Examples Semantic Types most (E Prop) (E Prop) Prop might Prop Prop true Prop Prop manage Prop E Prop believe Prop E Prop Table 1: A classification of key linguistic e</context>
</contexts>
<marker>Bos, 2009</marker>
<rawString>Johan Bos. 2009a. Applying automated deduction to natural language understanding. Journal of Applied Logic, 7(1):100–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Towards a large-scale formal semantic lexicon for text processing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Biennal GSCL Conference From Form to Meaning: Processing Texts Automatically,</booktitle>
<pages>3--14</pages>
<contexts>
<context position="2348" citStr="Bos, 2009" startWordPosition="330" endWordPosition="331">statistical parsers on which semantic interpretations rely do not necessarily reflect the best syntactic analysis as assumed in the formal semantics literature (Honnibal et al., 2010). Another persistent problem is the gap between the logics employed in the two communities; while it is generally assumed among formal semanticists that adequate semantic representations for natural language demand higher-order logic or type theory (Carpenter, 1997), the dominant view in computational linguistics is that inferences based on higher-order logic are hopelessly inefficient for practical applications (Bos, 2009a). Accordingly, it is claimed that some approximation of higher-order representations in terms of first-order logic (Hobbs, 1985), or a more efficient “natural logic” system based on surface structures is needed. However, it is often not a trivial task to give an approximation of rich higher-order information within a first-order language (Pulman, 2007). Moreover, the coverage of existing natural logic systems is limited to single-premise inferences (MacCartney and Manning, 2008). In this paper, we first present an improved compositional semantics that fills the gap between the parser syntax </context>
<context position="5795" citStr="Bos, 2009" startWordPosition="872" endWordPosition="873">this gap, it is not straightforward to obtain desirable semantic representations for a wide range of constructions. One major difference from the standard CCG-syntax is the treatment of post-NP modifiers; for instance, the relative clause who works is assigned not the category N\N, but the category NP\NP, which applies to the whole NP. To derive correct truthconditions for quantificational sentences, we assign to determiners a semantic term having an extra predicate variable as shown in Fig. 2, namely, AFAGAH.bx(Fx ∧ Gx Hx), in a similar way to the continuation semantics for event predicates (Bos, 2009b; Champollion, 2015). The extra predicate variable G can be filled by the semantically empty predicate Ax.True in a verb phrase (see Fig. 1). Fig. 3 gives an example derivation. Note that the changes in the lexical entries as illustrated in Fig. 1 and Fig. 2 are made for the correct semantic parsing, namely, the compositional 1Here we use a non-standard semantics for intransitive verbs. We will explain it in the next paragraph. Examples Semantic Types most (E Prop) (E Prop) Prop might Prop Prop true Prop Prop manage Prop E Prop believe Prop E Prop Table 1: A classification of key linguistic e</context>
</contexts>
<marker>Bos, 2009</marker>
<rawString>Johan Bos. 2009b. Towards a large-scale formal semantic lexicon for text processing. In Proceedings of the Biennal GSCL Conference From Form to Meaning: Processing Texts Automatically, pages 3–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Carpenter</author>
</authors>
<title>Type-Logical Semantics.</title>
<date>1997</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2188" citStr="Carpenter, 1997" startWordPosition="307" endWordPosition="308">mantics provides an accurate computational basis of natural language inferences. However, there are still obstacles in the way of achieving this goal. One is that the statistical parsers on which semantic interpretations rely do not necessarily reflect the best syntactic analysis as assumed in the formal semantics literature (Honnibal et al., 2010). Another persistent problem is the gap between the logics employed in the two communities; while it is generally assumed among formal semanticists that adequate semantic representations for natural language demand higher-order logic or type theory (Carpenter, 1997), the dominant view in computational linguistics is that inferences based on higher-order logic are hopelessly inefficient for practical applications (Bos, 2009a). Accordingly, it is claimed that some approximation of higher-order representations in terms of first-order logic (Hobbs, 1985), or a more efficient “natural logic” system based on surface structures is needed. However, it is often not a trivial task to give an approximation of rich higher-order information within a first-order language (Pulman, 2007). Moreover, the coverage of existing natural logic systems is limited to single-prem</context>
<context position="8344" citStr="Carpenter, 1997" startWordPosition="1279" endWordPosition="1280">st-order language can be taken as a fragment of this language. Thus, adopting a higher-order language does not lead to the loss of the expressive power of the first-order language. Apart from sub-sentential utterances such as short answers to wh-questions (Ginzburg, 2005), there are important constructions that are naturally 2We write a function from objects of type A to objects of type B as A --+ B. Here --+ is right-associative: A --+ B --+ C means A--+(B --+C). We use the symbol --+ both for logical implication and function-type constructor, following the socalled Curry-Howard isomorphism (Carpenter, 1997). 2056 Every student who works NP/N N (NP\NP)/(S\NP) S\NP λFGH.∀x(Fx ∧ Gx → Hx) λx.student(x) λV QF.Q(λx.(V (λGH.Hx) ∧ Fx)) λQ.Q(λx.True)(λx.work(x)) &gt; &gt; NP NP\NP λGH.∀x(student(x) ∧ Gx → Hx) λQF.Q(λx.(work(x) ∧ Fx)) &lt; comes NP S\NP λFH.∀x(student(x) ∧ work(x) ∧ Fx → Hx) λQ.Q(λx.True)(λx.come(x)) &lt; S ∀x(student(x) ∧ work(x) ∧ True → come(x)) Figure 3: A CCG derivation of the semantic representation for the sentence Every student who works comes. AFGH.X is an abbreviation for AFAGAH.X. “True” denotes the tautology, hence the final formula is equivalent to bx(student(x) n work(x) — come(x)). rep</context>
</contexts>
<marker>Carpenter, 1997</marker>
<rawString>Bob Carpenter. 1997. Type-Logical Semantics. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Cast´eran</author>
<author>Yves Bertot</author>
</authors>
<title>Interactive Theorem Proving and Program Development. Coq’Art: The Calculus of Inductive Constructions.</title>
<date>2004</date>
<publisher>Springer.</publisher>
<marker>Cast´eran, Bertot, 2004</marker>
<rawString>Pierre Cast´eran and Yves Bertot. 2004. Interactive Theorem Proving and Program Development. Coq’Art: The Calculus of Inductive Constructions. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lucas Champollion</author>
</authors>
<title>The interaction of compositional semantics and event semantics.</title>
<date>2015</date>
<journal>Linguistics and Philosophy,</journal>
<volume>38</volume>
<issue>1</issue>
<contexts>
<context position="5816" citStr="Champollion, 2015" startWordPosition="874" endWordPosition="875"> is not straightforward to obtain desirable semantic representations for a wide range of constructions. One major difference from the standard CCG-syntax is the treatment of post-NP modifiers; for instance, the relative clause who works is assigned not the category N\N, but the category NP\NP, which applies to the whole NP. To derive correct truthconditions for quantificational sentences, we assign to determiners a semantic term having an extra predicate variable as shown in Fig. 2, namely, AFAGAH.bx(Fx ∧ Gx Hx), in a similar way to the continuation semantics for event predicates (Bos, 2009b; Champollion, 2015). The extra predicate variable G can be filled by the semantically empty predicate Ax.True in a verb phrase (see Fig. 1). Fig. 3 gives an example derivation. Note that the changes in the lexical entries as illustrated in Fig. 1 and Fig. 2 are made for the correct semantic parsing, namely, the compositional 1Here we use a non-standard semantics for intransitive verbs. We will explain it in the next paragraph. Examples Semantic Types most (E Prop) (E Prop) Prop might Prop Prop true Prop Prop manage Prop E Prop believe Prop E Prop Table 1: A classification of key linguistic elements having higher</context>
</contexts>
<marker>Champollion, 2015</marker>
<rawString>Lucas Champollion. 2015. The interaction of compositional semantics and event semantics. Linguistics and Philosophy, 38(1):31–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stergios Chatzikyriakidis</author>
<author>Zhaohui Luo</author>
</authors>
<title>Natural language inference in Coq.</title>
<date>2014</date>
<journal>Journal of Logic, Language and Information,</journal>
<volume>23</volume>
<issue>4</issue>
<contexts>
<context position="13031" citStr="Chatzikyriakidis and Luo (2014)" startWordPosition="1989" endWordPosition="1992">eyond the scope of this paper. 2057 Inference pattern Axiom Existential import VFVG (most(F, G) → 3x(Fx h Gx)) Conservativity VFVG (most(F, G) → most(F, Ax.(Fx h Gx))) Monotonicity VFVGVH(most(F,G) (right-upward) → (Vx(Gx → Hx) → most(F, H))) Veridicality VP(true(P) → P) VxVP(manage(x, P) → P) VxVP(know(x, P) → P) Anti-veridicality VP(false(P) → -P) VxVP(fail(x, P) → -P) Table 2: Axioms for non-first-order constructions. However, one drawback is that the compositional semantics becomes complicated, so we prefer the non-decomposition approach for attitude verbs. 3.2 Inferences in HOL Following Chatzikyriakidis and Luo (2014), we use a proof-assistant Coq (Cast´eran and Bertot, 2004) to implement a specialized prover for higher-order features in natural languages, and combine it with efficient first-order inferences. We use Coq’s built-in tactics for first-order inferences. Coq also has a language called Ltac for userdefined automated tactics (Delahaye, 2000). The additional axioms and tactics specialized for natural language constructions are written in Ltac. We ran Coq fully automated, by feeding to its interactive mode a set of predefined tactics combined with user-defined proof-search tactics. Table 2 shows th</context>
</contexts>
<marker>Chatzikyriakidis, Luo, 2014</marker>
<rawString>Stergios Chatzikyriakidis and Zhaohui Luo. 2014. Natural language inference in Coq. Journal of Logic, Language and Information, 23(4):441–480.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Widecoverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="1362" citStr="Clark and Curran, 2007" startWordPosition="176" endWordPosition="179"> on a reasonably-sized semantic lexicon and a manageable number of non-first-order axioms enables efficient logical inferences, including those concerned with generalized quantifiers and intensional operators, and outperforms the state-of-the-art firstorder inference system. 1 Introduction Entailment relations are of central importance in the enterprise of both formal and computational semantics. Traditionally, formal semanticists have concentrated on a relatively small set of linguistic inferences. However, since the emergence of statistical parsers based on sophisticated syntactic theories (Clark and Curran, 2007), an open domain system has been developed that supports certain degree of robust semantic interpretation with wide coverage (Bos et al., 2004). It is then reasonable to expect that a state-of-the-art formal semantics provides an accurate computational basis of natural language inferences. However, there are still obstacles in the way of achieving this goal. One is that the statistical parsers on which semantic interpretations rely do not necessarily reflect the best syntactic analysis as assumed in the formal semantics literature (Honnibal et al., 2010). Another persistent problem is the gap </context>
<context position="3778" citStr="Clark and Curran, 2007" startWordPosition="548" endWordPosition="551">verage parser based on a modern syntactic theory (Combinatory Categorial Grammar, CCG). The system is designed to handle multi-premise inferences as well as singlepremise ones. We test our system on the FraCaS test suite (Cooper et al., 1994), which is suitable for evaluating the linguistic coverage of an inference system. The experiments show that our higher-order system outperforms the state-of-the-art first-order system with respect to the speed and accuracy of making logical inferences. 2 CCG and Compositional Semantics As an initial step of compositional semantics, we use the C&amp;C parser (Clark and Curran, 2007), a statistical CCG parser trained on CCGbank (Hockenmaier and Steedman, 2007). Parser out2055 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2055–2061, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. category: S\NP semantics: AQ.Q(Ax.True)(Ax.E(x)) Figure 1: Schematic lexical entry (semantic template) for intransitive verbs. E is a position in which a particular lexical item appears. category: NP/N semantics: AFAGAH.bx(Fx ∧ Gx Hx) surf : every Figure 2: The lexical entry for determiner every puts are mapp</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James R Curran. 2007. Widecoverage efficient statistical parsing with CCG and log-linear models. Computational Linguistics, 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robin Cooper</author>
<author>Richard Crouch</author>
<author>Jan van Eijck</author>
<author>Chris Fox</author>
<author>Josef van Genabith</author>
<author>Jan Jaspers</author>
<author>Hans Kamp</author>
<author>Manfred Pinkal</author>
<author>Massimo Poesio</author>
<author>Stephen Pulman</author>
</authors>
<title>FraCaS: A Framework for Computational Semantics. Deliverable,</title>
<date>1994</date>
<marker>Cooper, Crouch, van Eijck, Fox, van Genabith, Jaspers, Kamp, Pinkal, Poesio, Pulman, 1994</marker>
<rawString>Robin Cooper, Richard Crouch, Jan van Eijck, Chris Fox, Josef van Genabith, Jan Jaspers, Hans Kamp, Manfred Pinkal, Massimo Poesio, Stephen Pulman, et al. 1994. FraCaS: A Framework for Computational Semantics. Deliverable, D6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Delahaye</author>
</authors>
<title>A Tactic Language for the System Coq.</title>
<date>2000</date>
<booktitle>In Logic for Programming and Automated Reasoning (LPAR), volume 1955 of Lecture Notes in Computer Science,</booktitle>
<pages>85--95</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="13371" citStr="Delahaye, 2000" startWordPosition="2040" endWordPosition="2041">(fail(x, P) → -P) Table 2: Axioms for non-first-order constructions. However, one drawback is that the compositional semantics becomes complicated, so we prefer the non-decomposition approach for attitude verbs. 3.2 Inferences in HOL Following Chatzikyriakidis and Luo (2014), we use a proof-assistant Coq (Cast´eran and Bertot, 2004) to implement a specialized prover for higher-order features in natural languages, and combine it with efficient first-order inferences. We use Coq’s built-in tactics for first-order inferences. Coq also has a language called Ltac for userdefined automated tactics (Delahaye, 2000). The additional axioms and tactics specialized for natural language constructions are written in Ltac. We ran Coq fully automated, by feeding to its interactive mode a set of predefined tactics combined with user-defined proof-search tactics. Table 2 shows the axioms we implemented. Modals and non-veridical predicates (by which we mean predicates that are neither veridical nor antiveridical) do not have particular axioms, with the consequence that actual and hypothetical contexts are correctly distinguished. 4 Experiments We evaluated our system on the FraCaS test suite (Cooper et al., 1994),</context>
</contexts>
<marker>Delahaye, 2000</marker>
<rawString>David Delahaye. 2000. A Tactic Language for the System Coq. In Logic for Programming and Automated Reasoning (LPAR), volume 1955 of Lecture Notes in Computer Science, pages 85–95. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Ginzburg</author>
</authors>
<title>Abstraction and ontology: Questions as propositional abstracts in type theory with records.</title>
<date>2005</date>
<journal>Journal of Logic and Computation,</journal>
<volume>15</volume>
<issue>2</issue>
<contexts>
<context position="8000" citStr="Ginzburg, 2005" startWordPosition="1222" endWordPosition="1223">l semantics. 3.1 Semantic representations in HOL We use the language of higher-order logic (HOL) with two basic types, E for entities and Prop for propositions. Here we distinguish between propositions and truth-values, as is standard in modern type theory (Ranta, 1994; Luo, 2012). Key higherorder constructs are summarized in Table 1.2 A first-order language can be taken as a fragment of this language. Thus, adopting a higher-order language does not lead to the loss of the expressive power of the first-order language. Apart from sub-sentential utterances such as short answers to wh-questions (Ginzburg, 2005), there are important constructions that are naturally 2We write a function from objects of type A to objects of type B as A --+ B. Here --+ is right-associative: A --+ B --+ C means A--+(B --+C). We use the symbol --+ both for logical implication and function-type constructor, following the socalled Curry-Howard isomorphism (Carpenter, 1997). 2056 Every student who works NP/N N (NP\NP)/(S\NP) S\NP λFGH.∀x(Fx ∧ Gx → Hx) λx.student(x) λV QF.Q(λx.(V (λGH.Hx) ∧ Fx)) λQ.Q(λx.True)(λx.work(x)) &gt; &gt; NP NP\NP λGH.∀x(student(x) ∧ Gx → Hx) λQF.Q(λx.(work(x) ∧ Fx)) &lt; comes NP S\NP λFH.∀x(student(x) ∧ wor</context>
</contexts>
<marker>Ginzburg, 2005</marker>
<rawString>Jonathan Ginzburg. 2005. Abstraction and ontology: Questions as propositional abstracts in type theory with records. Journal of Logic and Computation, 15(2):113–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaakko Hintikka</author>
</authors>
<title>Knowledge and Belief.</title>
<date>1962</date>
<publisher>Cornell University Press.</publisher>
<contexts>
<context position="12149" citStr="Hintikka (1962)" startWordPosition="1863" endWordPosition="1864">06) are also an instance of this class. For example, Some student manages to come is formalized as (3) lx(student(x) n manage(x, come(x))) where manage is a veridical predicate taking a proposition as the second argument; it licenses an inference to lx(student(x) n come(x)). Attitude verbs A wide range of propositional attitude verbs such as believe and hope are similar to modals in that they do not license an inference from attitude contexts to actual contexts. But factives like know and remember are an exception; they are veridical.4 A first-order translation can be given along the lines of Hintikka (1962). (4) is translated as (5). (4) know(�ohn, lx(student(x) n come(x))) (5) bw1(Rjohnw0 wi — lx(student(wi, x) n come(wi, x))) 4Factive predicates show the important inference patterns known as presupposition projection (van der Sandt, 1992), which are beyond the scope of this paper. 2057 Inference pattern Axiom Existential import VFVG (most(F, G) → 3x(Fx h Gx)) Conservativity VFVG (most(F, G) → most(F, Ax.(Fx h Gx))) Monotonicity VFVGVH(most(F,G) (right-upward) → (Vx(Gx → Hx) → most(F, H))) Veridicality VP(true(P) → P) VxVP(manage(x, P) → P) VxVP(know(x, P) → P) Anti-veridicality VP(false(P) → -</context>
</contexts>
<marker>Hintikka, 1962</marker>
<rawString>Jaakko Hintikka. 1962. Knowledge and Belief. Cornell University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry R Hobbs</author>
</authors>
<title>Ontological promiscuity.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd annual meeting on Association for Computational Linguistics (ACL-1985),</booktitle>
<pages>60--69</pages>
<contexts>
<context position="2478" citStr="Hobbs, 1985" startWordPosition="348" endWordPosition="349"> the formal semantics literature (Honnibal et al., 2010). Another persistent problem is the gap between the logics employed in the two communities; while it is generally assumed among formal semanticists that adequate semantic representations for natural language demand higher-order logic or type theory (Carpenter, 1997), the dominant view in computational linguistics is that inferences based on higher-order logic are hopelessly inefficient for practical applications (Bos, 2009a). Accordingly, it is claimed that some approximation of higher-order representations in terms of first-order logic (Hobbs, 1985), or a more efficient “natural logic” system based on surface structures is needed. However, it is often not a trivial task to give an approximation of rich higher-order information within a first-order language (Pulman, 2007). Moreover, the coverage of existing natural logic systems is limited to single-premise inferences (MacCartney and Manning, 2008). In this paper, we first present an improved compositional semantics that fills the gap between the parser syntax and a composition derivation. We then develop an inference system that is capable of higher-order inferences in natural languages.</context>
</contexts>
<marker>Hobbs, 1985</marker>
<rawString>Jerry R. Hobbs. 1985. Ontological promiscuity. In Proceedings of the 23rd annual meeting on Association for Computational Linguistics (ACL-1985), pages 60–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="3856" citStr="Hockenmaier and Steedman, 2007" startWordPosition="559" endWordPosition="562">al Grammar, CCG). The system is designed to handle multi-premise inferences as well as singlepremise ones. We test our system on the FraCaS test suite (Cooper et al., 1994), which is suitable for evaluating the linguistic coverage of an inference system. The experiments show that our higher-order system outperforms the state-of-the-art first-order system with respect to the speed and accuracy of making logical inferences. 2 CCG and Compositional Semantics As an initial step of compositional semantics, we use the C&amp;C parser (Clark and Curran, 2007), a statistical CCG parser trained on CCGbank (Hockenmaier and Steedman, 2007). Parser out2055 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2055–2061, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. category: S\NP semantics: AQ.Q(Ax.True)(Ax.E(x)) Figure 1: Schematic lexical entry (semantic template) for intransitive verbs. E is a position in which a particular lexical item appears. category: NP/N semantics: AFAGAH.bx(Fx ∧ Gx Hx) surf : every Figure 2: The lexical entry for determiner every puts are mapped onto semantic representations in a standard way (Bos, 2008), using A-calcul</context>
</contexts>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2007. CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank. Computational Linguistics, 33(3):355–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Honnibal</author>
<author>James R Curran</author>
<author>Johan Bos</author>
</authors>
<title>Rebanking CCGbank for improved NP interpretation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL-2010),</booktitle>
<pages>207--215</pages>
<contexts>
<context position="1922" citStr="Honnibal et al., 2010" startWordPosition="264" endWordPosition="268">d on sophisticated syntactic theories (Clark and Curran, 2007), an open domain system has been developed that supports certain degree of robust semantic interpretation with wide coverage (Bos et al., 2004). It is then reasonable to expect that a state-of-the-art formal semantics provides an accurate computational basis of natural language inferences. However, there are still obstacles in the way of achieving this goal. One is that the statistical parsers on which semantic interpretations rely do not necessarily reflect the best syntactic analysis as assumed in the formal semantics literature (Honnibal et al., 2010). Another persistent problem is the gap between the logics employed in the two communities; while it is generally assumed among formal semanticists that adequate semantic representations for natural language demand higher-order logic or type theory (Carpenter, 1997), the dominant view in computational linguistics is that inferences based on higher-order logic are hopelessly inefficient for practical applications (Bos, 2009a). Accordingly, it is claimed that some approximation of higher-order representations in terms of first-order logic (Hobbs, 1985), or a more efficient “natural logic” system</context>
</contexts>
<marker>Honnibal, Curran, Bos, 2010</marker>
<rawString>Matthew Honnibal, James R. Curran, and Johan Bos. 2010. Rebanking CCGbank for improved NP interpretation. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL-2010), pages 207–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Icard</author>
<author>Lawrence Moss</author>
</authors>
<title>Recent progress in monotonicity.</title>
<date>2014</date>
<journal>Linguistic Issues in Language Technology (LiLT),</journal>
<volume>9</volume>
<contexts>
<context position="9681" citStr="Icard and Moss, 2014" startWordPosition="1473" endWordPosition="1476">s is a proportional generalized quantifier like most and half of (Barwise and Cooper, 1981). Model-theoretically, they denote relations between sets. We represent them as a two-place higher-order predicate taking firstorder predicates as arguments. For instance, Most students work is represented as follows. (1) most(Ax.student(x), Ax.work(x)) Here, most is a higher-order predicate in the sense that it takes first-order predicates Ax.student(x) and Ax.work(x) as arguments. We take the entailment patterns governing most as axioms, along the same lines of natural logic and monotonicity calculus (Icard and Moss, 2014), where determiners are taken as primitive two-place operators. Standard quantifiers like every and some could also be treated as binary operators in the same way as the binary most in (1). But we choose to adopt the first-order decomposition in such cases (see Fig. 2 for the lexical entry of every). Modals Modal auxiliary expressions like might, must and can are represented as unary sentential operators. For instance, the sentence Some student might come is represented as: (2) lx(student(x) n might(come(x))). An important inference role of such a modal operator is to distinguish modal context</context>
</contexts>
<marker>Icard, Moss, 2014</marker>
<rawString>Thomas Icard and Lawrence Moss. 2014. Recent progress in monotonicity. Linguistic Issues in Language Technology (LiLT), 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>Combining distributional and logical semantics.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--179</pages>
<contexts>
<context position="17801" citStr="Lewis and Steedman (2013)" startWordPosition="2759" endWordPosition="2762">em with higher-order inference 3.72 Our system with higher-order rules ablated 3.46 Nutcracker with first-order inference 11.23 (first-order prover + model builder) Table 4: Comparison of inference time on the FraCaS test suite. CCG parsing is common to both our system and Nutcracker. of our system is significantly higher than that of Nutcracker. Our system’s total accuracy with higher-order rules is 69%, and drops to 59% when ablating the higher-order rules. We are aware of two other systems tested on FraCaS that are capable of multiple-premise inferences: the CCG-based first-order system of Lewis and Steedman (2013) and the dependency-based compositional semantics of Tian et al. (2014). These systems were only evaluated on the Quantifier section of FraCaS. As shown in Table 3, our results improve on the former and are comparable with the latter. Other important studies on FraCaS are those based on natural logic (MacCartney and Manning, 2008; Angeli and Manning, 2014). These systems are designed solely for single-premise inferences and hence are incapable of handling the general case of multiple-premise problems (which cover about 45% of the problems in FraCaS). Our system improves on these natural-logic-</context>
</contexts>
<marker>Lewis, Steedman, 2013</marker>
<rawString>Mike Lewis and Mark Steedman. 2013. Combining distributional and logical semantics. Transactions of the Association for Computational Linguistics, 1:179–192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhaohui Luo</author>
</authors>
<title>Formal semantics in modern type theories with coercive subtyping.</title>
<date>2012</date>
<journal>Linguistics and Philosophy,</journal>
<volume>35</volume>
<issue>6</issue>
<contexts>
<context position="7666" citStr="Luo, 2012" startWordPosition="1169" endWordPosition="1170">s of relative clauses is a non-standard one, it has an advantage in that it provides a unified treatment of restrictive and nonrestrictive relative clauses. 3 Representation and Inference in HOL We present a higher-order representation language and describe apparently higher-order phenomena that have received attention in formal semantics. 3.1 Semantic representations in HOL We use the language of higher-order logic (HOL) with two basic types, E for entities and Prop for propositions. Here we distinguish between propositions and truth-values, as is standard in modern type theory (Ranta, 1994; Luo, 2012). Key higherorder constructs are summarized in Table 1.2 A first-order language can be taken as a fragment of this language. Thus, adopting a higher-order language does not lead to the loss of the expressive power of the first-order language. Apart from sub-sentential utterances such as short answers to wh-questions (Ginzburg, 2005), there are important constructions that are naturally 2We write a function from objects of type A to objects of type B as A --+ B. Here --+ is right-associative: A --+ B --+ C means A--+(B --+C). We use the symbol --+ both for logical implication and function-type </context>
</contexts>
<marker>Luo, 2012</marker>
<rawString>Zhaohui Luo. 2012. Formal semantics in modern type theories with coercive subtyping. Linguistics and Philosophy, 35(6):491–513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Natural logic for textual inference.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>193--200</pages>
<contexts>
<context position="14122" citStr="MacCartney and Manning (2007)" startWordPosition="2155" endWordPosition="2158">utomated, by feeding to its interactive mode a set of predefined tactics combined with user-defined proof-search tactics. Table 2 shows the axioms we implemented. Modals and non-veridical predicates (by which we mean predicates that are neither veridical nor antiveridical) do not have particular axioms, with the consequence that actual and hypothetical contexts are correctly distinguished. 4 Experiments We evaluated our system on the FraCaS test suite (Cooper et al., 1994), a set of entailment problems that is designed to evaluate theories of formal semantics.5 We used the version provided by MacCartney and Manning (2007). The whole data set is divided into nine sections, each devoted to linguistically challenging problems. Of these, we used six sections, excluding three sections (nominal anaphora, ellipsis and temporal reference) that 5Our system will be publicly available at https://github.com/mynlp/ccg2lambda. Section # Ours Nut L&amp;S 13 Tian 14 Quantifiers 74 .77 .53 .62 .80 Plurals 33 .67 .52 − − Adjectives 22 .68 .32 − − Comparatives 31 .48 .45 − − Verbs 8 .62 .62 − − Attitudes 13 .77 .46 − − Total 181 .69 .50 − − Table 3: Accuracy on the FraCaS test suite. The first column shows the number of problems. Of</context>
</contexts>
<marker>MacCartney, Manning, 2007</marker>
<rawString>Bill MacCartney and Christopher D. Manning. 2007. Natural logic for textual inference. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, pages 193–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Modeling semantic containment and exclusion in natural language inference.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics,</booktitle>
<pages>521--528</pages>
<contexts>
<context position="2833" citStr="MacCartney and Manning, 2008" startWordPosition="401" endWordPosition="404">iew in computational linguistics is that inferences based on higher-order logic are hopelessly inefficient for practical applications (Bos, 2009a). Accordingly, it is claimed that some approximation of higher-order representations in terms of first-order logic (Hobbs, 1985), or a more efficient “natural logic” system based on surface structures is needed. However, it is often not a trivial task to give an approximation of rich higher-order information within a first-order language (Pulman, 2007). Moreover, the coverage of existing natural logic systems is limited to single-premise inferences (MacCartney and Manning, 2008). In this paper, we first present an improved compositional semantics that fills the gap between the parser syntax and a composition derivation. We then develop an inference system that is capable of higher-order inferences in natural languages. We combine a state-of-the-art higher-order proof system (Coq) with a wide-coverage parser based on a modern syntactic theory (Combinatory Categorial Grammar, CCG). The system is designed to handle multi-premise inferences as well as singlepremise ones. We test our system on the FraCaS test suite (Cooper et al., 1994), which is suitable for evaluating t</context>
<context position="18132" citStr="MacCartney and Manning, 2008" startWordPosition="2813" endWordPosition="2816"> that of Nutcracker. Our system’s total accuracy with higher-order rules is 69%, and drops to 59% when ablating the higher-order rules. We are aware of two other systems tested on FraCaS that are capable of multiple-premise inferences: the CCG-based first-order system of Lewis and Steedman (2013) and the dependency-based compositional semantics of Tian et al. (2014). These systems were only evaluated on the Quantifier section of FraCaS. As shown in Table 3, our results improve on the former and are comparable with the latter. Other important studies on FraCaS are those based on natural logic (MacCartney and Manning, 2008; Angeli and Manning, 2014). These systems are designed solely for single-premise inferences and hence are incapable of handling the general case of multiple-premise problems (which cover about 45% of the problems in FraCaS). Our system improves on these natural-logic-based systems by making multiple-premise inferences as well. Main errors we found are due to various parse errors caused by the CCG parser, including the failure to handle multiwords like a lot of. The performance of our system will be further improved with correct syntactic analyses. Our experiments on FraCaS problems do not con</context>
</contexts>
<marker>MacCartney, Manning, 2008</marker>
<rawString>Bill MacCartney and Christopher D. Manning. 2008. Modeling semantic containment and exclusion in natural language inference. In Proceedings of the 22nd International Conference on Computational Linguistics, pages 521–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: a lexical database for English.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="15606" citStr="Miller, 1995" startWordPosition="2410" endWordPosition="2411">nswer: yes (the premise set entails the hypothesis), no (the premise set entails the negation of the hypothesis), and unknown (the premise set entails neither the hypothesis nor its negation). Fig.4 shows some examples. Currently, our system has 57 templates for general syntactic categories and 80 lexical entries for closed words. In a similar way to Bos et al. (2004), closed words are confined to a limited range of logical and functional expressions such as quantifiers and connectives. These templates and lexical entries are not specific with respect to the FraCaS test suite. We use WordNet (Miller, 1995) as the knowledge base for antonymy; logical axioms relevant to given inferences are extracted from this knowledge base. We compared our system with the state-ofthe-art CCG-based first-order system Boxer (Bos, 2008), which is one of the most well-known logicbased approaches to textual entailment. We used the Nutcracker system based on Boxer that utilizes a first-order prover (Bliksem) and a model builder (Mace) with the option enabling access to WordNet. We did not use the option enabling modal semantics, since it did not improve the results. All experiments were run on a 4-core@1.8Ghz, 8GB RA</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A Miller. 1995. WordNet: a lexical database for English. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rowan Nairn</author>
<author>Cleo Condoravdi</author>
<author>Lauri Karttunen</author>
</authors>
<title>Computing relative polarity for textual inference.</title>
<date>2006</date>
<booktitle>Inference in Computational Semantics (ICoS5),</booktitle>
<pages>67--76</pages>
<contexts>
<context position="11537" citStr="Nairn et al., 2006" startWordPosition="1760" endWordPosition="1763">eridical and anti-veridical predicates A sentential operator O is veridical if O(A) entails A, and anti-veridical if O(A) entails -,A. While modal auxiliary verbs like might are neither veridical nor anti-veridical, there is a class of expressions licensing these patterns of inference. Typical examples are adjectives taking an embedded proposition, such as true/correct and false/incorrect. Note that sentences like Everything/what he said is false involve a quantification over propositions, which is problematic for the first-order approach. The so-called implicative verbs like manage and fail (Nairn et al., 2006) are also an instance of this class. For example, Some student manages to come is formalized as (3) lx(student(x) n manage(x, come(x))) where manage is a veridical predicate taking a proposition as the second argument; it licenses an inference to lx(student(x) n come(x)). Attitude verbs A wide range of propositional attitude verbs such as believe and hope are similar to modals in that they do not license an inference from attitude contexts to actual contexts. But factives like know and remember are an exception; they are veridical.4 A first-order translation can be given along the lines of Hin</context>
</contexts>
<marker>Nairn, Condoravdi, Karttunen, 2006</marker>
<rawString>Rowan Nairn, Cleo Condoravdi, and Lauri Karttunen. 2006. Computing relative polarity for textual inference. Inference in Computational Semantics (ICoS5), pages 67–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Pulman</author>
</authors>
<title>Formal and computational semantics: a case study.</title>
<date>2007</date>
<booktitle>In Proceedings of the Seventh International Workshop on Computational Semantics (IWCS-7),</booktitle>
<pages>181--196</pages>
<contexts>
<context position="2704" citStr="Pulman, 2007" startWordPosition="384" endWordPosition="385">c representations for natural language demand higher-order logic or type theory (Carpenter, 1997), the dominant view in computational linguistics is that inferences based on higher-order logic are hopelessly inefficient for practical applications (Bos, 2009a). Accordingly, it is claimed that some approximation of higher-order representations in terms of first-order logic (Hobbs, 1985), or a more efficient “natural logic” system based on surface structures is needed. However, it is often not a trivial task to give an approximation of rich higher-order information within a first-order language (Pulman, 2007). Moreover, the coverage of existing natural logic systems is limited to single-premise inferences (MacCartney and Manning, 2008). In this paper, we first present an improved compositional semantics that fills the gap between the parser syntax and a composition derivation. We then develop an inference system that is capable of higher-order inferences in natural languages. We combine a state-of-the-art higher-order proof system (Coq) with a wide-coverage parser based on a modern syntactic theory (Combinatory Categorial Grammar, CCG). The system is designed to handle multi-premise inferences as </context>
</contexts>
<marker>Pulman, 2007</marker>
<rawString>Stephen Pulman. 2007. Formal and computational semantics: a case study. In Proceedings of the Seventh International Workshop on Computational Semantics (IWCS-7), pages 181–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aarne Ranta</author>
</authors>
<title>Type-Theoretical Grammar.</title>
<date>1994</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="7654" citStr="Ranta, 1994" startWordPosition="1167" endWordPosition="1168">NP\NP analysis of relative clauses is a non-standard one, it has an advantage in that it provides a unified treatment of restrictive and nonrestrictive relative clauses. 3 Representation and Inference in HOL We present a higher-order representation language and describe apparently higher-order phenomena that have received attention in formal semantics. 3.1 Semantic representations in HOL We use the language of higher-order logic (HOL) with two basic types, E for entities and Prop for propositions. Here we distinguish between propositions and truth-values, as is standard in modern type theory (Ranta, 1994; Luo, 2012). Key higherorder constructs are summarized in Table 1.2 A first-order language can be taken as a fragment of this language. Thus, adopting a higher-order language does not lead to the loss of the expressive power of the first-order language. Apart from sub-sentential utterances such as short answers to wh-questions (Ginzburg, 2005), there are important constructions that are naturally 2We write a function from objects of type A to objects of type B as A --+ B. Here --+ is right-associative: A --+ B --+ C means A--+(B --+C). We use the symbol --+ both for logical implication and fu</context>
</contexts>
<marker>Ranta, 1994</marker>
<rawString>Aarne Ranta. 1994. Type-Theoretical Grammar. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="5177" citStr="Steedman (2000)" startWordPosition="771" endWordPosition="772">r to that of Bos et al. (2004). A lexical entry for each open word class consists of a syntactic category in CCG (possibly with syntactic features) and a semantic representation encoded as a A-term. Fig. 1 gives an example.1 For a limited number of closed words such as logical or functional expressions, a A-term is directly assigned to a surface form (see Fig. 2). The output formula is obtained by combining each A-term in accordance with meaning composition rules and then by applying 0-conversion. There is a non-trivial gap between the parser output and the standard CCG-syntax as presented in Steedman (2000). Due to this gap, it is not straightforward to obtain desirable semantic representations for a wide range of constructions. One major difference from the standard CCG-syntax is the treatment of post-NP modifiers; for instance, the relative clause who works is assigned not the category N\N, but the category NP\NP, which applies to the whole NP. To derive correct truthconditions for quantificational sentences, we assign to determiners a semantic term having an extra predicate variable as shown in Fig. 2, namely, AFAGAH.bx(Fx ∧ Gx Hx), in a similar way to the continuation semantics for event pre</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ran Tian</author>
<author>Yusuke Miyao</author>
<author>Takuya Matsuzaki</author>
</authors>
<title>Logical inference on dependency-based compositional semantics.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-2014),</booktitle>
<pages>79--89</pages>
<contexts>
<context position="17872" citStr="Tian et al. (2014)" startWordPosition="2769" endWordPosition="2772"> 3.46 Nutcracker with first-order inference 11.23 (first-order prover + model builder) Table 4: Comparison of inference time on the FraCaS test suite. CCG parsing is common to both our system and Nutcracker. of our system is significantly higher than that of Nutcracker. Our system’s total accuracy with higher-order rules is 69%, and drops to 59% when ablating the higher-order rules. We are aware of two other systems tested on FraCaS that are capable of multiple-premise inferences: the CCG-based first-order system of Lewis and Steedman (2013) and the dependency-based compositional semantics of Tian et al. (2014). These systems were only evaluated on the Quantifier section of FraCaS. As shown in Table 3, our results improve on the former and are comparable with the latter. Other important studies on FraCaS are those based on natural logic (MacCartney and Manning, 2008; Angeli and Manning, 2014). These systems are designed solely for single-premise inferences and hence are incapable of handling the general case of multiple-premise problems (which cover about 45% of the problems in FraCaS). Our system improves on these natural-logic-based systems by making multiple-premise inferences as well. Main error</context>
</contexts>
<marker>Tian, Miyao, Matsuzaki, 2014</marker>
<rawString>Ran Tian, Yusuke Miyao, and Takuya Matsuzaki. 2014. Logical inference on dependency-based compositional semantics. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (ACL-2014), pages 79–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rob van der Sandt</author>
</authors>
<title>Presupposition projection as anaphora resolution.</title>
<date>1992</date>
<journal>Journal of Semantics,</journal>
<volume>9</volume>
<issue>4</issue>
<marker>van der Sandt, 1992</marker>
<rawString>Rob van der Sandt. 1992. Presupposition projection as anaphora resolution. Journal of Semantics, 9(4):333–377.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>