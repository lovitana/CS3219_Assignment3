<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000029">
<title confidence="0.866162">
Multilingual discriminative lexicalized phrase structure parsing
</title>
<author confidence="0.725574">
Benoit Crabb´e
</author>
<bodyText confidence="0.245516">
Alpage – Universit´e Paris Diderot – Inria – IUF
Place Paul Ricoeur 75013 Paris
benoit.crabbe@univ-paris-diderot.fr
</bodyText>
<sectionHeader confidence="0.975396" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997649">
We provide a generalization of discrimina-
tive lexicalized shift reduce parsing tech-
niques for phrase structure grammar to a
wide range of morphologically rich lan-
guages. The model is efficient and outper-
forms recent strong baselines on almost all
languages considered. It takes advantage
of a dependency based modelling of mor-
phology and a shallow modelling of con-
stituency boundaries.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998715">
Lexicalized phrase structure parsing techniques
were first introduced by Charniak (2000) and
Collins (2003) as generative probabilistic models.
Nowadays most statistical models used in natu-
ral language processing are discriminative: dis-
criminative models provide more flexibility for
modelling a large number of variables and conve-
niently expressing their interactions. This trend is
particularly striking if we consider the literature in
dependency parsing. Most state of the art multi-
lingual parsers are actually weighted by discrimi-
native models (Nivre and Scholz, 2004; McDon-
ald et al., 2005; Fern´andez-Gonz´alez and Martins,
2015).
With respect to multilingual phrase structure
parsing, the situation is quite different. Most
parsers focus on fixed word order languages like
English or Chinese as exemplified by Zhu et al.
(2013). Despite a few exceptions (Collins et al.,
1999), multilingual state of the art results are gen-
erally derived from the generative model of Petrov
et al. (2006). Although more recently Hall et
al. (2014) introduced a conditional random field
parser that clearly improved the state of the art in
the multilingual setting.
Both Petrov et al. (2006) and Hall et al. (2014)
frame their parsing model to model in priority
regular surfacic patterns and word order: Petrov
et al. (2006) crucially infers category refinements
(called category ‘splits‘) in order to specialize
the grammar on recurrent informative patterns ob-
served on input spans. Hall et al. (2014) re-
lies on a similar intuition : the model essentially
aims to capture regularities on the spans of con-
stituents and their immediate neighbourhood, fol-
lowing earlier intuitions of Klein and Manning
(2004). This modelling strategy has two main mo-
tivations. First it reduces the burden of feature en-
gineering, making it easier to generalize to multi-
ple languages. Second it avoids modeling explic-
itly bilexical dependencies for which parameters
are notoriously hard to estimate from small data
sets such as existing treebanks.
On the other hand this strategy becomes less in-
tuitive when it comes to modeling free word or-
der languages where word order and constituency
should in principle be less informative. As such,
the good results reported by Hall et al. (2014)
are surprising. It suggests that word order and
constituency might be more relevant than often
thought for modelling free word order languages.
Nevertheless, free word order languages also
tend to be morphologically rich languages. This
paper shows that a parsing model that can effec-
tively take morphology into account is key for
parsing these languages. More specifically, we
show that an efficient lexicalized phrase structure
parser - modelling both dependencies and mor-
phology - already significantly improves parsing
accuracy. But we also show that an additional
modelling of spans and constituency provides ad-
ditional robustness that contributes to yield state
of the art results on almost all languages consid-
ered, while remaining quite efficient. Moreover,
given the availability of existing multi-view tree-
banks (Bhatt et al., 2009; Seddah et al., 2013; Qiu
et al., 2014), our proposed solution only requires
a lightweight infrastructure to achieve multilin-
</bodyText>
<page confidence="0.950008">
1847
</page>
<note confidence="0.9848655">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1847–1856,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999820411764706">
gual parsing without requiring costly language-
dependent modifications such as feature engineer-
ing.
The paper is organized as follows. We first re-
view the properties of multiview treebanks (Sec-
tion 2). As these treebanks typically do not pro-
vide directly head annotation, an information re-
quired for lexicalized parsing, we provide an au-
tomated multilingual head annotation procedure
(Section 3). We then describe in section 4 a vari-
ant of lexicalized shift reduce parsing that we use
for the multilingual setting. It provides a way to
integrate morphology in the model. Section 5 fi-
nally describes a set of experiments designed to
test our main hypothesis and to point out the im-
provements over state of the art in multilingual
parsing.
</bodyText>
<sectionHeader confidence="0.995037" genericHeader="method">
2 Multi-view treebanks
</sectionHeader>
<bodyText confidence="0.999853185185185">
Multi-view treebanks are treebanks annotated both
for constituents and dependencies that have the
property to be token-wise aligned (Bhatt et al.,
2009; Seddah et al., 2013; Qiu et al., 2014) . These
double annotations are typically obtained by con-
verting a constituency or dependency annotation
into the other annotation type. This method was
used for the construction of the dataset for the
SPMRL 2013 shared task (Seddah et al., 2013),
which contains multi-view treebanks for a num-
ber of morphologically rich languages, for which
either constituency or dependency treebanks were
available. The same kind of process was applied
to the Penn TreeBank using the Stanford conver-
sion system to produce dependency annotations
(de Marneffe et al., 2006). In this paper, we use
both of these datasets.
Although in multi-view treebanks each sentence
is annotated both for constituency and depen-
dency, they are not normalized for categories nor
lexical features accross languages such as depen-
dencies in the Google Universal Treebank (Mc-
Donald et al., 2013). What is more, the depen-
dency and constituency structures may sometimes
strongly differ. For some languages, like Hungar-
ian, the conversion has involved some manual re-
annotation (Vincze et al., 2010).
</bodyText>
<sectionHeader confidence="0.973372" genericHeader="method">
3 Head annotation procedure
</sectionHeader>
<bodyText confidence="0.996561047619048">
Lexicalized phrase structure parsers traditionally
use hand-crafted heuristics for head annotation
(Collins, 2003). Although these heuristics are
available for some languages, for others they are
non existent or non explicit and typically hidden
in conversion procedures. In order to leverage the
burden of managing language specific heuristics,
we first automate head annotation by taking ad-
vantage of the multi-view annotation.
We begin by introducing some notation. As-
suming a sentence W = wi ... wn, the depen-
dency annotation of this sentence is assumed to be
a dependency forest (Kuhlmann and Nivre, 2006).
A dependency graph G = (V, E) where V =
{1 ... n} is the set of word indexes or vertices and
E C_ V x V is a set of dependency links. By
convention, a dependency (i, j) means that i gov-
erns j. A dependency forest is a dependency graph
such that a node has at most a single incoming
edge and where there is no cycle. A node with no
incoming edge is a root of the dependency forest
and a dependency tree is a dependency forest with
a single root. For some languages, such as Ger-
man or Basque, the dependency structures found
in the data set are actually dependency forests.
Lexicalized parsing relies on head annotation,
in other words each node in a constituency tree is
associated with the word index of its head. More
formally, let A be the set of nodes in the c-tree,
head annotation can be represented as a function
h : A H {1... n} which maps each node a E A
to the index of its head in the input sentence. h
is obtained by leveraging head-related information
associated with each rule in the grammar. More
precisely, each rule T —* -y, with -y = al ... ak,
is associated with a head index i (1 &lt; i &lt; k) that
states that the head h(T) of any node labeled T in a
constituency tree that is built using this rule is the
same as the head of the right-hand side symbol ai.
A Naive h function is straightforwardly defined
as the annotation of each local rule part of the tree
in a bottom-up fashion:1
</bodyText>
<equation confidence="0.9766258">
Base: h(wi) = i ∀wi E W
Recurrence:
{ h(ai) if ∀aj:aj∈γ,i�=j (h(ai)r h(aj)) E E
h(T) = ⊥
otherwise
</equation>
<bodyText confidence="0.953484">
When ]a E A such that h(a) = L we say that the
annotation has failed.
However the naive procedure fails in a large
number of cases. Failures fall into the four pat-
terns that are illustrated in Figure 1. For each of
</bodyText>
<footnote confidence="0.997259">
1The additional case of unary rules is straightforward and
left to the reader.
</footnote>
<page confidence="0.991685">
1848
</page>
<figure confidence="0.99560927027027">
X
X
X
a
b
c
a b c d e
X
X
X
X
e
d
X
c
X
X
X
X
a
a
a
b
b
b
c a
a b
c a b c
X
X
X
X
X
X
X
X
Local restructuration I Local restructuration II Forest effect Non projectivity
</figure>
<figureCaption confidence="0.999835">
Figure 1: Patterns of the causes of problems taking place during head annotation
</figureCaption>
<bodyText confidence="0.946009058823529">
� h(ai) if ∀aj:ajEγ,i#j (h(ai), h(aj)) ∈ E+
h(τ) = h(aKNN(τ—γ)) otherwise
the patterns we have highlighted in bold the sym-
bols for which the Naive procedure currently fails.
Local Restructuration I is where the c-structure is
flatter than the d-structure. Here the Naive pro-
cedure fails because (a, c) E� E. Local Restruc-
turation II is where the d-structure is flatter than
the c-structure. The procedure fails because nei-
ther (a, b) E E nor (b, a) E E. Forest Effect is
where the d-structure is a dependency forest (here
E = 0). And finally Non Projectivity is where the
d-tree is non projective.
We can easily correct the naive procedure for
Local Restructuration I by taking advantage of
E+, the non reflexive transitive closure of E, thus
yielding the following Corrected procedure:
</bodyText>
<equation confidence="0.97865175">
Base: h(wi) = i ∀wi ∈ W
Recurrence:
� h(ai) if ∀a..a.Eγ,i0j (h(ai), h(aj)) ∈ E+
h(τ) = otherwise
</equation>
<bodyText confidence="0.986292">
The three other cases are more problematic, since
their correction would somehow require altering
the structure of either the c-tree or the d-tree.
Refraining from altering the constituency data set
we instead use a catch-all procedure that essen-
tially creates the problematic head annotation by
analogy with the rest of the data, yielding a fully
Robust procedure that is guaranteed to succeed in
any case:
Base: h(wi) = i ∀wi ∈ W
</bodyText>
<subsectionHeader confidence="0.570646">
Recurrence:
</subsectionHeader>
<bodyText confidence="0.986849">
where KNN(T —* &apos;y) is a function returning a
guess for the position of the head in &apos;y, the right
hand side of the rule, based on similarity to suc-
cessfully head annotated rules.
The details are as follows. KNN(T —* &apos;y) sup-
poses a dataset D = (Ri, Hi)N i=1 of successfully
head annotated rules. In this dataset, each rule
Ri = T —* &apos;y is associated with Hi the posi-
tion of the head in &apos;y. We define the similarity
between two rules R1 = T(1) —* a(1)
</bodyText>
<equation confidence="0.937044857142857">
1 ... a(1)
k
and R2 = T(2) —* a(2) ... ak2) to be the Lev-
1enshtein distance between T(1), a(1)
1 ... a(1) kand
T(2), a(2)
1 ... a(2)
</equation>
<bodyText confidence="0.9975371">
k� . In practice for a given rule R
the function returns the most frequent H among
the 5 most similar rules in the data set.
The full head annotated data set D is built by
reading off the rules from the trees successfully
annotated in the treebank by the Corrected proce-
dure in a first pass. A second pass yields the final
annotation by running the Robust procedure.
Analysis of the conversion We report in Table 1
an overall quantification of the conversion proce-
dure: % Success (Corrected) reports the number
of trees succesfully annotated by the Corrected
procedure and Silver UAS reports an UAS score
obtained by comparing the reference dependency
trees to the conversion of those obtained from the
Robust conversion of the head-annotated phrase
structure trees back to dependency structures. The
conversion works well apart from four languages
(Arabic, Basque, German and Hungarian) which
cause more difficulties.
</bodyText>
<table confidence="0.973688363636364">
% Success (Corrected) Silver UAS
61.7 92.0
54.2 82.7
99.9 98.8
99.9 99.3
98.4 72.1
98.2 99.0
85.9 80.1
100.0 100.0
98.6 98.8
99.6 98.8
</table>
<tableCaption confidence="0.99938">
Table 1: Quantification of the conversion
</tableCaption>
<bodyText confidence="0.999835666666667">
In order to better understand the problems faced
by the conversion procedure, we manually in-
spected the errors returned by the Corrected pro-
</bodyText>
<figure confidence="0.997704090909091">
Language
ARABIC
BASQUE
ENGLISH
FRENCH
GERMAN
HEBREW
HUNGARIAN
KOREAN
POLISH
SWEDISH
</figure>
<page confidence="0.988271">
1849
</page>
<bodyText confidence="0.9999885">
cedure. For each language, we sampled 20 ex-
amples of failures encountered and we manually
categorized the errors using the four patterns illus-
trated in Figure 1. Across languages, 49.9% of the
errors come from the pattern Local Restructura-
tion II and 50% from the pattern Forest effect and
more suprisingly, we found only one example in
our sample from the pattern Non projectivity in the
Hungarian treebank. This overall average hides
however an important variation across treebanks.
The Forest effect is indeed massively found in the
Basque2 (100%) and German treebanks and more
marginally in the Hungarian data set. Most of the
time, these are cases of short word sequences (2 to
5 tokens) where all nodes are annoted as roots of
the dependency trees. The Local restructuration II
is mostly found in the Arabic, Hebrew and Polish
treebanks and less frequently in Hungarian. Ara-
bic and Hebrew tend to follow a binary annotation
scheme partially inspired by X-Bar, hence creat-
ing additional constituent structures that are not di-
rectly inferrable from the dependency annotation.
Polish uses this restructuration in patterns involv-
ing coordination. More surprisingly, non projec-
tive patterns, which we expected to be a signifi-
cant feature of these languages, remain marginal
in comparison to annotation related idiosyncrasic
problems.
</bodyText>
<sectionHeader confidence="0.935152" genericHeader="method">
4 Parsing algorithm
</sectionHeader>
<bodyText confidence="0.999978555555556">
This section provides an overview of the design of
the constituent parsing system. There are three re-
cent proposals for beam-based discriminative shift
reduce parsing for phrase structure grammar with
a structured perceptron and beam search (Zhu et
al., 2013; Crabb´e, 2014; Mi and Huang, 2015). All
three proposals point out that for weighted phrase
structure parsing, the shift reduce algorithm re-
quires a special treatment of unary rules in order to
compare derivations of the same length. They all
provide different management schemes for these
unaries.
The work described here draws on the LR algo-
rithm introduced by Crabb´e (2014), but provides a
simpler algorithm, it precisely describes the man-
agement of unary rules and clarifies how spans and
morphological information is represented (see sec-
tion 5 ).
</bodyText>
<footnote confidence="0.945290666666667">
2The constituency conversion of the Basque treebank also
contains a recurrent attachment error of the punctuations
which we ignored when computing this statistic.
</footnote>
<bodyText confidence="0.99568675">
For each language, the grammar is induced
from a treebank using the following preprocessing
steps. The corpus is first head-annotated with the
Robust head annotation procedure. Second, the
treebank is head-markovized (order 0) and unary
productions that do not emit tokens3 are collapsed
into unique symbols. Once this has been done
we assume that tokens to be parsed are a list of
couples (tag, wordform). The preprocessing steps
ensure the binarized treebank implicitly encodes
a binary lexicalized grammar whose rules are ei-
ther in Chomsky Normal Form (CNF) like in (a)
</bodyText>
<equation confidence="0.473023">
X[h] —* A[x] B[h], X[h] —* A[h] B[x], X[t] —* t
or are also of the form (b) X[h] —* A[h] t, X[t] —*
A[h] t, X[h] —* t B[h], X[t] —* t B[h] where
A, B, X are delexicalized non-terminals, h, x, t
</equation>
<bodyText confidence="0.999313838709677">
are tokens (terminals) and A[h], A[x] ... X[t] are
lexicalized non-terminals. Given a grammar in
CNF, we can prove that for a sentence of length
n, the number of derivation steps for a shift reduce
parser is 3n − 1. However our tagset-preserving
transformation also introduces rules of the form
(b), which explains why the number of derivation
steps may vary from 2n − 1 to 3n − 1.
To ensure that a derivation is of length 3n − 1,
the parser forces each shift to be followed by either
a unary reduction or an alternative dummy Ghost
Reduction (GR). Given the pre-processed treebank
we infer the set A of actions used by the parser.
Let E be the set of non-terminal symbols (includ-
ing temporary symbols) read off from the binary
treebank. The set of actions contains one Shift (S),
one Ghost Reduction (GR) a set of |E |unary re-
ductions (RU-X), one for each symbol, a set of |E|
binary left reductions (RL-X) and a set of |E |bi-
nary right reductions (RR-X) (see also Sagae and
Lavie (2006) and Figure 3 for details).
The parser itself is organized around two data
structures: a stack of symbols, S = ... |s2|s1|s0,
whose topmost element is s0. Symbols are lexi-
calized non terminals or tokens of the form A[x].
The second structure is a queue statically filled
with tokens T = t1 ... tn. Parsing is performed
by sequentially generating configurations C of the
form (j, S, ·) where S is a stack and j is the index
of the first element of the queue. Given an ini-
tial configuration C0 = (1, c, 1), a derivation step
</bodyText>
<equation confidence="0.909621">
at−1
Ct−1 � Ct generates a new configuration Ct by
</equation>
<bodyText confidence="0.9251445">
applying an action at−1 E A as defined in Fig-
ure 3. The derivation is complete and successful
</bodyText>
<footnote confidence="0.981641">
3In order not to alter the tagset of the treebank.
</footnote>
<page confidence="0.959248">
1850
</page>
<figure confidence="0.755555142857143">
Language gen num case mood aspect other
s2.ct[s2.wt] s1.ct[s1.wt] s0.ct[s0.wt]
s1.cl[s1.wl] s1.cr[s1.wr] s0.cl[s0.wl] s0.cr[s0.wr]
� �� �
stack
ARABIC gender number case mood aspect -
BASQUE - NUM KAS MDN ASP DADUDIO,ERL,NOR(I|K)?
ENGLISH - - - - - -
FRENCH g n - m - mwe
GERMAN gender number case mood - -
HEBREW gen num - - - tense
HUNGARIAN - Num Cas Mood - SubPOS
KOREAN - - case-type - - verb-type
POLISH gender number case - aspect post-prepositionality
SWEDISH gender number case verbform - perfectform
s1.lc
s1.rc
s0.lc
s0.rc q1 ... qj
� �� �
queue
</figure>
<figureCaption confidence="0.9067614">
Figure 2: Features available for scoring. sx denote a position in the stack. Stack positions are local trees of depth 1, features
can access its top, left and right nodes. The suffixes cp, wp, lc, rc denote respectively the delexicalized category, the head
token, the left corner token, the right corner token of a stack position. For tokens elements accessible from the stack (sx.wx)
and from the queue (qx), features can access the word form, pos tag or any morphological feature m available for that language
as described in the table at the right
</figureCaption>
<equation confidence="0.99783425">
INIT (1, c, +) : 0
GOAL (n + 1, T, +) : w
SHIFT hj,S,⊥i : w
hj+1,S  |tj.tag[tj.word]),&gt;i : w+F(S,hj,Si)
RL(X) hj,S�  |c1[t1]c0[t0],⊥i : w
hj,S�  |X[t1],⊥i : w+F(RL(X),hj,Si)
RR(X) hj,S�  |c1[t1]c0[t0],⊥i : w
hj,S�  |X[t0],⊥i : w+F(RR(X),hj,Si)
RU(X) hj,S�  |c0[t0],&gt;i : w
hj,Se  |X[t0],⊥i : w+F(RU(X),hj,Si)
GR(X) hj,S�  |c0[t0],&gt;i : w
hj,S�  |c0[t0],⊥i : w+F(GR,hj,Si)
</equation>
<figureCaption confidence="0.99793">
Figure 3: Weighted inference rules
</figureCaption>
<bodyText confidence="0.764887">
once the action C3n−1 is generated. A derivation
</bodyText>
<equation confidence="0.494209333333333">
sequence C0⇒τ is a sequence of derivation steps
Co. . . a�1C
0 r
</equation>
<bodyText confidence="0.990234">
Weighted prediction The choice of the action
a E A at each derivation step is naturally non-
deterministic. Determinism is provided by a
weighting function based on a linear model of the
form:
</bodyText>
<equation confidence="0.9990545">
W (C0⇒τ) = τ−1� w · Φ(ai, Ci) = τ−1� F(ai, Ci)
i=0 i=0
</equation>
<bodyText confidence="0.999542333333333">
where w E Rd is a weight vector and Φ(ai, Ci) E
{0,1}d is a feature vector. The best parse is then
the successful derivation with the maximum score:
</bodyText>
<equation confidence="0.984497">
ˆC0⇒3n−1 = argmax W (C0⇒3n−1)
C0⇒3n−1∈GEN3n−1
</equation>
<bodyText confidence="0.9997535">
In practice, we use a beam of size K at each time
step and lossy feature hashing, which makes the
inference approximative.
For the purpose of computing weights, we ex-
tend the representation of the stack and queue el-
ements such that the feature functions have ac-
cess to a richer context than just simple lexical-
ized symbols of the form A[x]. As described in
Figure 2 (left), features can also access the imme-
diate left and right children of s0 and s1 as well as
their left and right corner tokens. This allows us
to encode the span models described in Section 5.
We also use tuple-structured tokens encoding not
only the word-form and the tag but also additional
custom lexical features such as those enumerated
in Figure 2 (right). This allows us to express the
morphological models described in Section 5.
Finally, the parameters w are estimated with a
parallel averaged structured perceptron designed
to cope with inexact inference (beam search):
we specifically rely on max-violation updates of
Huang et al. (2012) and on minibatches to acceler-
ate and parallelize training (Shalev-Shwartz et al.,
2007; Zhao and Huang, 2013).
</bodyText>
<sectionHeader confidence="0.999424" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999984125">
The experiments aim to compare the contribution
of span based features approximating some intu-
itions of Hall et al. (2014) for shift reduce parsing
and morphological features for parsing free word
order languages. We start by describing the evalu-
ation protocol and by defining the models used.
We use the standard SPMRL data set (Seddah et
al., 2013). Part of speech tags are generated with
Marmot (M¨uller et al., 2013), a CRF tagger specif-
ically designed to provide tuple-structured tags.
The training and development sets are tagged by
10-fold jackknifing. Head annotation is supplied
by the Robust procedure described in Section 3.
The parser is systematically trained for 25 epochs
with a max violation update perceptron, a beam of
size 8 and a minibatch size of 24.
</bodyText>
<page confidence="0.983589">
1851
</page>
<bodyText confidence="0.991670262295083">
To enable a comparison with other published re-
sults, the evaluation is performed with a version of
evalb provided by the SPMRL organizers (Sed-
dah et al., 2013) which takes punctuation into ac-
count.
Baseline model (B) The baseline model uses a
set of templates identical to those of Zhu et al.
(2013) for parsing English and Chinese except that
we have no specific templates for unary reduc-
tions.
Span-based model (B+S) This model extends
the B model by modeling spans. The span model
approximates an intuition underlying Hall et al.
(2014): constituent boundaries contain very infor-
mative tokens (typically function words). These
tokens together with the pattern of their neighbor-
hood provide key clues for detecting and (sub-
)typing constituents. Moreover, parameter esti-
mation for frequent functional words should suf-
fer less from data sparseness issues than the esti-
mation of bilexical dependencies on lexical head
words. The model includes conjunctions of non-
terminal symbols on the stack with their left and
right corners (words or tags) and also their imme-
diately adjacent tokens across constituents. Using
the notation given in Figure 2 we specifically in-
cluded the following matrix templates :
s0.ct&amp;s0.lc.word&amp;s0.rc.word
s1.ct&amp;s1.lc.word&amp;s1.rc.word
s0.ct&amp;s0.lc.word&amp;s1.rc.word
q1.word&amp;s0.lc.word&amp;s0.rc.word
qa.word&amp;s0.lc.word&amp;s0.rc.word
from which we derived additional backoff tem-
plates where only a single corner condition is ex-
pressed and/or words are replaced by tags.
Morphological model (B+M) This model ex-
tends the B model by adding morphological fea-
tures. This model aims to approximate the intu-
ition that morphological features such as case are
key for identifying the structure of free word order
languages. As feature engineering may become in
principle quite complex once it comes to morphol-
ogy, we targeted fairly crude models with the goal
of providing a proof of concept. Therefore the
morphologically informed models use as input a
rich set of morphological features specified in Fig-
ure 2 (right) predicted by the CRF tagger (M¨uller
et al., 2013) with the same jackkniffing as before.
The content of Figure 2 provides an explicit indi-
cation of the actual features defined in the original
treebanks (see Seddah et al. (2013) and references
therein for details), while the columns are indica-
tive normalized names. For Basque most of the
additional morphological features further encode
case and verbal subcategorization. For French the
mwe field abbreviates IOB predicted tags derived
from multi-word expression annotations found in
the original dataset.
Now let M be the set of values enumerated for
a language in Figure 2 (right), we systematically
added the following templates to model B:
</bodyText>
<equation confidence="0.9956445">
s0.wt.m&amp;s1.wt.m&amp;q1.tag ∀m ∈ M
s0.wt.m&amp;s1.ct&amp;q1.m ∀m ∈ M
s0.ct.m&amp;s1.wt.m&amp;q1.m ∀m ∈ M
s0.wt.m&amp;q1.m&amp;qa.tag ∀m ∈ M
s0.wt.m&amp;q1.tag&amp;qa.m ∀m ∈ M
s0.ct&amp;q1.m&amp;qa.m ∀m ∈ M
</equation>
<bodyText confidence="0.999816730769231">
Essentially the model expresses interactions be-
tween morphological features from the constituent
heads on the top of the stack and the morphologi-
cal features from the tokens at the beginning of the
queue.
Mixed model (B+S+M) Our last model is the
union of the span model (B+S) and the morpho-
logical model (B+M).
Results (development) We measured the im-
pact of the model variations on the development
set for c-parsing on the SPMRL data sets (Table
2). We immediately observe that modelling spans
tends to improve the results, in particular for lan-
guages where the head annotation is more prob-
lematic: Arabic4, Basque, German and Hungar-
ian and also Swedish however. So the span-based
model seems to improve the parser’s robustness in
cases when dependencies lack precision. For this
model, the average behaviour is similar to that of
Hall et al. (2014) although the variance is high.
On the other hand, the morphological model
tends to be most important for languages where
head annotation is easier: French, Korean, Polish
and Swedish. It is key for very richly inflected lan-
guages such as Basque and Hungarian even though
our head annotation is more approximative5. A
</bodyText>
<footnote confidence="0.911681272727273">
4Although not detailed in the paper, we also observe that
for Arabic, the morphological features are generally pre-
dicted with a lower accurracy by the tagger than for other
languages.
5As annotation schemes are not normalized across lan-
guages, it is important to stress that these observations are
very unlikely to be representative of the linguistic properties
of these languages.They are more likely to be a result of an-
notation choices. For example Korean is a strongly aggluti-
native language for which much of the morphology is already
encoded in the tag set.
</footnote>
<page confidence="0.947853">
1852
</page>
<table confidence="0.998877833333333">
Model Arabic Basque French German Hebrew Hungarian Korean Polish Swedish Avg
1 Base 79.46 74.67 79.66 82.61 90.43 84.34 81.96 91.68 75.60 82.26
2 Base+S 80.59 76.39 80.15 83.63 90.63 85.62 82.21 91.75 77.49 83.16
3 Base+M 80.17 83.69 81.05 83.66 90.40 87.75 82.79 92.72 77.50 84.41
4 Base+S+M 81.25 84.01 80.87 84.08 90.69 88.27 83.09 92.78 77.87 84.77
5 Hall-Klein 14 78.89 83.74 79.40 83.28 88.06 87.44 81.85 91.10 75.95 83.30
</table>
<tableCaption confidence="0.809625">
F1-scores provided by evalb-spmrl (Seddah et al., 2013). Takes punctuation into account and penalizes unparsed sentences.
Table 2: Development F-scores
</tableCaption>
<bodyText confidence="0.984087294117647">
comparison with Hall et al. (2014) also reveals
that for Basque, Hungarian and Swedish, taking
into account morphological information largely
explains our improved results.
Results (test) We observe in Table 3 that our
joint B+S+M model yields a state of the art c-
parser on almost all languages considered6. It is
quite clear that both our span and morphology en-
hanced models could be dramatically improved,
but it shows that with reasonable feature engi-
neering, these two sub-models are largely suffi-
cient to improve the state of the art in c-parsing
for these languages over strong baselines. Al-
though in principle the Berkeley parsers (Petrov
et al., 2006; Hall et al., 2014) are designed to be
language-generic with an underlying design that
is surprisingly accurate for free word order lan-
guages end up suffering from a lack of sensitiv-
ity to morphological information. Finally we also
observe that our phrase structure parser clearly
outperforms the TurboParser setup described by
Fern´andez-Gonz´alez and Martins (2015) in which
an elaborate output conversion procedure gener-
ates c-parses from d-parses.
Comparison with related work We conclude
with a few comparisons with related work. This
will enable us to show that our approach is not
only accurate but also efficient. A comparison
with dependency parsers will also allow us to bet-
ter identify the properties of our proposal.
In order to test efficiency, we compared our
parser to c-parsers trained on Penn Treebank
(PTB) for which we have running times reported
6For Basque, our problem comes from a recurrent incon-
sistency in the SPMRL data set. As annotated in the c-trees,
the punctuation induces a modification of the d-structure: c-
trees encode a different governor for punctuation marks than
d-trees. This not only causes problem to our head annotation
procedure but also for the parser to solving these attachments.
A simple correction results in a significant improvement of
these parsing results. However we decided to leave the data
untouched in order to preserve fair comparisons with other
systems.
by Fern´andez-Gonz´alez and Martins (2015). This
required first assigning heads, for which we used
the Stanford tool for converting PTB to Basic De-
pendencies, and then used our Robust conversion
method. We performed a simple test using the
PTB standard split with the same experimental set-
ting as before, except that we use the standard
evalb scorer (Table 5). Although the time com-
</bodyText>
<table confidence="0.999397666666667">
System (single parsers) F1 (EVALB) (Toks/sec)
Hall-Klein 14 88.6 12
StanfordSR 89.1 655
Charniak 00 89.5 -
This paper (B+S) 89.7 2150 °
This paper (B+S) [Collins] 90.0 2150 °
Petrov 06 90.1 169
Fernandez-Martins 15 90.2 957
Zhu et al. 13 90.4 1290
</table>
<tableCaption confidence="0.864042">
Alls scores and times except o are measured by Fern´andez-
Gonz´alez and Martins (2015) on an intel Xeon 2.3Ghz. o de-
notes the use of a different architecture (2.4Ghz intel).
Table 5: Penn treebank test (WSJ 23)
</tableCaption>
<bodyText confidence="0.999509823529412">
parison remains indicative, it is clear that the pars-
ing framework described in this paper is not only
reasonably accurate on a fixed word order lan-
guage such as English but it is also quite efficient.
Parsing accuracies might be different with other
head annotation schemes (See e.g. Elming et al.
(2013) for illustrations). In our case, we compare
the (B+S) model with automated head annotation
to the Collins head annotation as implemented in
the Standord CORE NLP library (Manning et al.,
2014), where we can see that the Collins hand-
crafted head annotation yields better results than
the automated one on English7.
The question is now to which extend c-trees en-
code meaningful dependencies? As lexicalized
c-trees encode unlabeled dependency trees, our
parser also directly outputs unlabeled d-trees by
</bodyText>
<footnote confidence="0.99834225">
7This pattern does not seem to be systematic: on French
we could also compare with head annotations described in
(Arun and Keller, 2005) and we observed a slight improve-
ment when using the automated procedure.
</footnote>
<page confidence="0.854049">
1853
</page>
<table confidence="0.948195222222222">
Parser (single) Arabic Basque French German Hebrew Hungarian Korean Polish Swedish Avg
Petrov 06 79.19 70.50 80.38 78.30 86.96 81.62 71.42 79.23 79.19 78.45
Petrov 06 + tags 78.66 74.74 79.76 78.28 85.42 85.22 78.56 86.75 80.64 81.17
Hall-Klein 14 78.75 83.39 79.70 78.43 87.18 88.25 80.18 90.66 82.00 83.72
Fernandez-Martins 15 - 85.90 78.75 78.66 88.97 88.16 79.28 91.20 82.80 84.22
This paper (B+S+M) 81.31 84.94 80.84 79.26 89.65 90.14 82.65 92.66 83.24 85.42
Best semi/ensemble 81.32 88.24 82.53 81.66 89.80 91.72 83.81 90.50 85.50 86.72
F-scores provided by evalb-spmrl (Seddah et al., 2013). It takes punctuation into account and penalizes unparsed sentences. The average ignores Arabic
for comparison with TurboParser. Petrov 06 + tags is the Berkeley parser with externally predicted pos tags (Seddah et al., 2013)
</table>
<tableCaption confidence="0.999387">
Table 3: Multilingual test (F-scores, phrase structure parsing)
</tableCaption>
<table confidence="0.997457833333333">
System English French Korean Hebrew Polish Swedish Arabic Basque German Hungarian
This paper (B+S+M) 91.75 86.68 87.22 85.28 88.61 86.22 80.64 73.68 67.20 74.46
Best d-parser (single) 91.95 85.80 85.84 81.05 88.12 84.54 84.57 84.33 87.65 83.71
Best semi/ensemble - 89.19 89.10 87.41 91.75 88.48 88.32 89.96 91.64 89.81
Unlabeled Accuracy Scores. Best other is the best single parser UAS result reported either in SPMRL 13 or SPMRL 14 shared tasks.
Best ensemble is the best semi-supervised or ensemble system from either SPMRL 13 or SPMRL 14 (Bj¨orkelund et al., 2013; Bj¨orkelund et al., 2014).
</table>
<tableCaption confidence="0.999941">
Table 4: Multilingual test (UAS, dependency parsing)
</tableCaption>
<bodyText confidence="0.9999186">
simply reading them off from the lexicalized c-
structure. We report in Table 4 the UAS evalua-
tion of those dependencies and we compare them
to the best results obtained by dependency parsers
in both SPMRL13 and SPMRL14 shared tasks.
For each language, the comparison is made with
the best single dependency parsing system8. For
English we compare against Standard TurboParser
- which seems to be the most similar to our
system- when parsing to Basic Stanford dependen-
cies. The comparison with semi-supervised and
ensemble parsers still provides a reasonable upper-
line (Bj¨orkelund et al., 2013).
As can be seen in Table 4, our results partly
generalize the observation summarized by Cer et
al. (2010) and Kong and Smith (2014) that phrase
structure parsers tend to provide better dependen-
cies than genuine dependency parsers for parsing
to Stanford Dependencies. For English, our UAS
is similar to that of TurboParser, but in a broader
multilingual framework, the left side of the table
shows that the unlabeled dependencies are clearly
better than those of genuine dependency parsers.
On the right side of the table are languages for
which our dependencies are actually worse. This
is not a surprise, since these are also the languages
for which head annotation was more problematic
in the first place. This last observation suggests
that a lexicalized c-parser can also provide very
accurate dependencies. A way to further gen-
</bodyText>
<footnote confidence="0.730698">
8In practice it turns out that these are either DYALOG-
SR (de La Clergerie, 2013) or sometimes MALTOPTIMIZER
(Ballesteros and Nivre, 2012)
</footnote>
<bodyText confidence="0.999348">
eralize this observation to problematic languages
would be either to design a less immediate post-
processing conversion scheme or to further nor-
malize the data set to obtain the correct heads from
the outset.
</bodyText>
<sectionHeader confidence="0.999231" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999922576923077">
Lexicalized phrase structure parsing of morpho-
logically rich languages used to be difficult since
existing implementations targeting essentially En-
glish or Chinese do not allow a straightforward
integration of morphology. Given multi-view
treebanks, we achieve multilingual parsing with
a language-agnostic head annotation procedure.
Once this procedure has created the required data
representation for lexicalized parsing, only mod-
est and weakly language dependent feature engi-
neering is required to achieve state-of-the-art ac-
curacies on all languages considered: a minimal
interface with morphology already contributes to
improving accuracy, and this is specifically the
case when heads are accurately identified. When
heads are only approximatively identified, span-
based configurational modelling tends to correct
the approximation.
Leaving aside details concerning conversion
and data normalization, we generally found that
the unlabeled dependencies modelled by the lex-
icalized c-parser also tend to be highly accu-
rate. For languages where c-annotations and d-
annotations are less compatible, additional lan-
guage renormalizations would help to get better
comparisons.
</bodyText>
<page confidence="0.984603">
1854
</page>
<bodyText confidence="0.999985166666667">
As suggested in this paper, future work for pars-
ing morphologically rich languages will require to
focus both on feature selection and on the interface
between syntax and morphology, which means in
our case the interface between the segmenter, the
tagger and the parser.
</bodyText>
<sectionHeader confidence="0.997385" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9990975">
The author wishes to thank Djam´e Seddah for in-
sigthful discussions regarding the work reported in
this paper as well as R. Bawden, M. Coavoux and
B. Sagot for their careful proofreading.
</bodyText>
<sectionHeader confidence="0.998869" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999334144444444">
Abhishek Arun and Frank Keller. 2005. Lexicalization
in crosslinguistic probabilistic parsing: The case of
french. In Association for Computational Linguis-
tics.
Miguel Ballesteros and Joakim Nivre. 2012. Maltopti-
mizer: An optimization tool for maltparser. In 13th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics (EACL).
Rajesh Bhatt, Bhuvana Narasimhan, Martha Palmer,
Owen Rambow, Dipti Sharma, and Fei Xia. 2009.
A multi-representational and multi-layered treebank
for hindi/urdu. In Proceedings of the Third Linguis-
tic Annotation Workshop (LAW III).
Anders Bj¨orkelund, Ozlem Cetinoglu, Rich´ard Farkas,
Thomas Mueller, and Wolfgang Seeker. 2013.
(re)ranking meets morphosyntax: State-of-the-art
results from the SPMRL 2013 shared task. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages.
Anders Bj¨orkelund, ¨Ozlem Cetinoˇglu, Agnieszka
Fale´nska, Rich´ard Farkas, Thomas M¨uller, Wolf-
gang Seeker, and Zsolt Sz´ant´o. 2014. The ims-
wrocaw-szeged-cis entry at the spmrl 2014 shared
task: Reranking and morphosyntax meet unlabeled
data. In Fifth Workshop on Statistical Parsing of
Morphologically-Rich Languages.
Daniel M. Cer, Marie-Catherine de Marneffe, Daniel
Jurafsky, and Christopher D. Manning. 2010. Pars-
ing to stanford dependencies: Trade-offs between
speed and accuracy. In Proceedings of the Language
Ressources and Evaluation Conference (LREC).
Eugene Charniak. 2000. A maximum-entropy-
inspired parser. In ANLP, pages 132–139.
Michael Collins, Jan Hajic, Lance A. Ramshaw, and
Christoph Tillmann. 1999. A statistical parser for
Czech. In 27th Annual Meeting of the Association
for Computational Linguistics (ACL).
Michael Collins. 2003. Head-driven statistical models
for natural language parsing. Computational Lin-
guistics, 29(4):589–637.
Benoit Crabb´e. 2014. An LR-inspired generalized
lexicalized phrase structure parser. In 25th Inter-
national Conference on Computational Linguistics
(COLING).
Eric Villemonte de La Clergerie. 2013. Exploring
beam-based shift-reduce dependency parsing with
dyalog: Results from the spmrl 2013 shared task.
In 4th Workshop on Statistical Parsing of Morpho-
logically Rich Languages (SPMRL2013).
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. 2006. Generat-
ing typed dependency parses from phrase structure
parses. In Language Ressources and Evaluation
Conference (LREC).
Jakob Elming, Anders Johannsen, Sigrid Klerke,
Emanuele Lapponi, Hector Martinez, and Anders
Sogaard. 2013. Down-stream effects of tree-
to-dependency conversions. In Proceedings of
NAACL-HLT.
Daniel Fern´andez-Gonz´alez and Andr´e F. T. Martins.
2015. Parsing as reduction. In Proceeding of the As-
sociation of Computational Linguistics (ACL), 2015.
David Hall, Greg Durrett, and Dan Klein. 2014. Less
grammar, more features. In Proceedings of the 52nd
Annual Meeting of the Association for Computa-
tional Linguistics, ACL 2014, pages 228–237.
Liang Huang, Suphan Fayong, and Yang Guo. 2012.
Structured perceptron with inexact search. In Hu-
man Language Technologies: Conference of the
North American Chapter of the Association of Com-
putational Linguistics (NAACL-HLT).
Dan Klein and Christopher D. Manning. 2004.
Corpus-based induction of syntactic structure: Mod-
els of dependency and constituency. In Proceedings
of the 42nd Annual Meeting of the Association for
Computational Linguistics, pages 478–485.
Lingpeng Kong and Noah A. Smith. 2014. An em-
pirical comparison of parsing methods for stanford
dependencies. CoRR, abs/1404.4314.
Marco Kuhlmann and Joakim Nivre. 2006. Mildly
non-projective dependency structures. In 21st In-
ternational Conference on Computational Linguis-
tics and 44th Annual Meeting of the Association for
Computational Linguistics (ACL/COLING).
Christopher D. Manning, Mihai Surdeanu, John Bauer,
Jenny Finkel, Steven J. Bethard, and David Mc-
Closky. 2014. The Stanford CoreNLP natural lan-
guage processing toolkit. In Proceedings of 52nd
Annual Meeting of the Association for Computa-
tional Linguistics: System Demonstrations.
</reference>
<page confidence="0.828549">
1855
</page>
<reference confidence="0.999873118421053">
Ryan T. McDonald, Fernando Pereira, Kiril Ribarov,
and Jan Hajic. 2005. Non-projective dependency
parsing using spanning tree algorithms. In Human
Language Technology Conference and Conference
on Empirical Methods in Natural Language Pro-
cessing (HLT/EMNLP).
Ryan McDonald, J. Nivre, Y. Quirmbach-Brundage,
Y. Goldberg, D. Das, K. Ganchev, K. Hall, S. Petrov,
H. Zhang, O. Tackstrom, C. Bedini, N. Bertomeu
Castello, and J. Lee. 2013. Universal dependency
annotation for multilingual parsing. In Proceed-
ing of the Association of Computational Linguistics
(ACL).
Haitao Mi and Liang Huang. 2015. Shift-reduce con-
stituency parsing with dynamic programming and
pos tag lattice. In Proceedings of the Conference of
the North American Chapter of the Association for
Computational Linguistics (NAACL-HLT).
Thomas M¨uller, Helmut Schmid, and Hinrich Sch¨utze.
2013. Efficient higher-order crfs for morphological
tagging. In Proceedings of the 2013 Conference on
Empirical Methods in Natural Language Processing
(EMNLP).
Joakim Nivre and Mario Scholz. 2004. Determinis-
tic dependency parsing of english text. In COLING
2004, 20th International Conference on Computa-
tional Linguistics.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and in-
terpretable tree annotation. In 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computa-
tional Linguistics, Proceedings of the Conference
(ACL/COLING).
Likun Qiu, Yue Zhang, Peng Jin, and Houfeng Wang.
2014. Multi-view chinese treebanking. In 25th In-
ternational Conference on Computational Linguis-
tics (COLING).
Kenji Sagae and Alon Lavie. 2006. A best-first prob-
abilistic shift-reduce parser. In 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computa-
tional Linguistics (ACL/COLING).
Djam´e Seddah, Reut Tsarfaty, Sandra Kubler, Marie
Candito, Jinho D. Choi, Rich´ard Farkas, Jennifer
Foster, Iakes Goenaga, Koldo Gojenola Gallete-
beitia, Yoav Goldberg, Spence Green, Nizar Habash,
Marco Kuhlmann, Wolfgang Maier, Yuval Mar-
ton, Joakim Nivre, Adam Przepi´orkowski, Ryan
Roth, Wolfgang Seeker, Yannick Versley, Veronika
Vincze, Marcin Woliski, Alina Wr´oblewska, and
Eric Villemonte de la Clergerie. 2013. Overview
of the spmrl 2013 shared task: A cross-framework
evaluation of parsing morphologically rich lan-
guages. In Proceedings of the Fourth SPMRL Work-
shop, Seattle, USA.
Shai Shalev-Shwartz, Yoram Singer, and Nathan Sre-
bro. 2007. Pegasos: Primal estimated sub-gradient
solver for SVM. In Machine Learning, Proceed-
ings of the Twenty-Fourth International Conference
(ICML).
Veronika Vincze, Dora Szauter, Attila Almasi, Gy-
orgy Mora, Zoltan Alexin, and Janos Csirik. 2010.
Hungarian dependency treebank. In Proceedings of
Language Ressources and Evalutation Conference
(LREC).
Kai Zhao and Liang Huang. 2013. Minibatch and par-
allelization for online large margin structured learn-
ing. In Human Language Technologies: Conference
of the North American Chapter of the Association of
Computational Linguistics (NAACL-HLT).
Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang,
and Jingbo Zhu. 2013. Fast and accurate shift-
reduce constituent parsing. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics, (ACL).
</reference>
<page confidence="0.993344">
1856
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.783254">
<title confidence="0.999684">Multilingual discriminative lexicalized phrase structure parsing</title>
<author confidence="0.972352">Benoit</author>
<affiliation confidence="0.870119">Alpage – Universit´e Paris Diderot – Inria –</affiliation>
<address confidence="0.919028">Place Paul Ricoeur 75013</address>
<email confidence="0.990511">benoit.crabbe@univ-paris-diderot.fr</email>
<abstract confidence="0.993728909090909">We provide a generalization of discriminative lexicalized shift reduce parsing techniques for phrase structure grammar to a wide range of morphologically rich languages. The model is efficient and outperforms recent strong baselines on almost all languages considered. It takes advantage of a dependency based modelling of morphology and a shallow modelling of constituency boundaries.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Abhishek Arun</author>
<author>Frank Keller</author>
</authors>
<title>Lexicalization in crosslinguistic probabilistic parsing: The case of french.</title>
<date>2005</date>
<booktitle>In Association for Computational Linguistics.</booktitle>
<contexts>
<context position="29804" citStr="Arun and Keller, 2005" startWordPosition="4960" endWordPosition="4963">s). In our case, we compare the (B+S) model with automated head annotation to the Collins head annotation as implemented in the Standord CORE NLP library (Manning et al., 2014), where we can see that the Collins handcrafted head annotation yields better results than the automated one on English7. The question is now to which extend c-trees encode meaningful dependencies? As lexicalized c-trees encode unlabeled dependency trees, our parser also directly outputs unlabeled d-trees by 7This pattern does not seem to be systematic: on French we could also compare with head annotations described in (Arun and Keller, 2005) and we observed a slight improvement when using the automated procedure. 1853 Parser (single) Arabic Basque French German Hebrew Hungarian Korean Polish Swedish Avg Petrov 06 79.19 70.50 80.38 78.30 86.96 81.62 71.42 79.23 79.19 78.45 Petrov 06 + tags 78.66 74.74 79.76 78.28 85.42 85.22 78.56 86.75 80.64 81.17 Hall-Klein 14 78.75 83.39 79.70 78.43 87.18 88.25 80.18 90.66 82.00 83.72 Fernandez-Martins 15 - 85.90 78.75 78.66 88.97 88.16 79.28 91.20 82.80 84.22 This paper (B+S+M) 81.31 84.94 80.84 79.26 89.65 90.14 82.65 92.66 83.24 85.42 Best semi/ensemble 81.32 88.24 82.53 81.66 89.80 91.72 83</context>
</contexts>
<marker>Arun, Keller, 2005</marker>
<rawString>Abhishek Arun and Frank Keller. 2005. Lexicalization in crosslinguistic probabilistic parsing: The case of french. In Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miguel Ballesteros</author>
<author>Joakim Nivre</author>
</authors>
<title>Maltoptimizer: An optimization tool for maltparser.</title>
<date>2012</date>
<booktitle>In 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL).</booktitle>
<contexts>
<context position="32984" citStr="Ballesteros and Nivre, 2012" startWordPosition="5466" endWordPosition="5469">ultilingual framework, the left side of the table shows that the unlabeled dependencies are clearly better than those of genuine dependency parsers. On the right side of the table are languages for which our dependencies are actually worse. This is not a surprise, since these are also the languages for which head annotation was more problematic in the first place. This last observation suggests that a lexicalized c-parser can also provide very accurate dependencies. A way to further gen8In practice it turns out that these are either DYALOGSR (de La Clergerie, 2013) or sometimes MALTOPTIMIZER (Ballesteros and Nivre, 2012) eralize this observation to problematic languages would be either to design a less immediate postprocessing conversion scheme or to further normalize the data set to obtain the correct heads from the outset. 6 Conclusion Lexicalized phrase structure parsing of morphologically rich languages used to be difficult since existing implementations targeting essentially English or Chinese do not allow a straightforward integration of morphology. Given multi-view treebanks, we achieve multilingual parsing with a language-agnostic head annotation procedure. Once this procedure has created the required</context>
</contexts>
<marker>Ballesteros, Nivre, 2012</marker>
<rawString>Miguel Ballesteros and Joakim Nivre. 2012. Maltoptimizer: An optimization tool for maltparser. In 13th Conference of the European Chapter of the Association for Computational Linguistics (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rajesh Bhatt</author>
<author>Bhuvana Narasimhan</author>
<author>Martha Palmer</author>
<author>Owen Rambow</author>
<author>Dipti Sharma</author>
<author>Fei Xia</author>
</authors>
<title>A multi-representational and multi-layered treebank for hindi/urdu.</title>
<date>2009</date>
<booktitle>In Proceedings of the Third Linguistic Annotation Workshop (LAW III).</booktitle>
<contexts>
<context position="3703" citStr="Bhatt et al., 2009" startWordPosition="561" endWordPosition="564">nguages. This paper shows that a parsing model that can effectively take morphology into account is key for parsing these languages. More specifically, we show that an efficient lexicalized phrase structure parser - modelling both dependencies and morphology - already significantly improves parsing accuracy. But we also show that an additional modelling of spans and constituency provides additional robustness that contributes to yield state of the art results on almost all languages considered, while remaining quite efficient. Moreover, given the availability of existing multi-view treebanks (Bhatt et al., 2009; Seddah et al., 2013; Qiu et al., 2014), our proposed solution only requires a lightweight infrastructure to achieve multilin1847 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1847–1856, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. gual parsing without requiring costly languagedependent modifications such as feature engineering. The paper is organized as follows. We first review the properties of multiview treebanks (Section 2). As these treebanks typically do not provide directly head annotation, an </context>
<context position="4940" citStr="Bhatt et al., 2009" startWordPosition="751" endWordPosition="754">d for lexicalized parsing, we provide an automated multilingual head annotation procedure (Section 3). We then describe in section 4 a variant of lexicalized shift reduce parsing that we use for the multilingual setting. It provides a way to integrate morphology in the model. Section 5 finally describes a set of experiments designed to test our main hypothesis and to point out the improvements over state of the art in multilingual parsing. 2 Multi-view treebanks Multi-view treebanks are treebanks annotated both for constituents and dependencies that have the property to be token-wise aligned (Bhatt et al., 2009; Seddah et al., 2013; Qiu et al., 2014) . These double annotations are typically obtained by converting a constituency or dependency annotation into the other annotation type. This method was used for the construction of the dataset for the SPMRL 2013 shared task (Seddah et al., 2013), which contains multi-view treebanks for a number of morphologically rich languages, for which either constituency or dependency treebanks were available. The same kind of process was applied to the Penn TreeBank using the Stanford conversion system to produce dependency annotations (de Marneffe et al., 2006). I</context>
</contexts>
<marker>Bhatt, Narasimhan, Palmer, Rambow, Sharma, Xia, 2009</marker>
<rawString>Rajesh Bhatt, Bhuvana Narasimhan, Martha Palmer, Owen Rambow, Dipti Sharma, and Fei Xia. 2009. A multi-representational and multi-layered treebank for hindi/urdu. In Proceedings of the Third Linguistic Annotation Workshop (LAW III).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>Ozlem Cetinoglu</author>
<author>Rich´ard Farkas</author>
<author>Thomas Mueller</author>
<author>Wolfgang Seeker</author>
</authors>
<title>(re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages.</booktitle>
<marker>Bj¨orkelund, Cetinoglu, Farkas, Mueller, Seeker, 2013</marker>
<rawString>Anders Bj¨orkelund, Ozlem Cetinoglu, Rich´ard Farkas, Thomas Mueller, and Wolfgang Seeker. 2013. (re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Bj¨orkelund</author>
<author>¨Ozlem Cetinoˇglu</author>
<author>Agnieszka Fale´nska</author>
<author>Rich´ard Farkas</author>
<author>Thomas M¨uller</author>
<author>Wolfgang Seeker</author>
<author>Zsolt Sz´ant´o</author>
</authors>
<title>The imswrocaw-szeged-cis entry at the spmrl 2014 shared task: Reranking and morphosyntax meet unlabeled data. In Fifth Workshop on Statistical Parsing of Morphologically-Rich Languages.</title>
<date>2014</date>
<marker>Bj¨orkelund, Cetinoˇglu, Fale´nska, Farkas, M¨uller, Seeker, Sz´ant´o, 2014</marker>
<rawString>Anders Bj¨orkelund, ¨Ozlem Cetinoˇglu, Agnieszka Fale´nska, Rich´ard Farkas, Thomas M¨uller, Wolfgang Seeker, and Zsolt Sz´ant´o. 2014. The imswrocaw-szeged-cis entry at the spmrl 2014 shared task: Reranking and morphosyntax meet unlabeled data. In Fifth Workshop on Statistical Parsing of Morphologically-Rich Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Cer</author>
<author>Marie-Catherine de Marneffe</author>
<author>Daniel Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing to stanford dependencies: Trade-offs between speed and accuracy.</title>
<date>2010</date>
<booktitle>In Proceedings of the Language Ressources and Evaluation Conference (LREC).</booktitle>
<marker>Cer, de Marneffe, Jurafsky, Manning, 2010</marker>
<rawString>Daniel M. Cer, Marie-Catherine de Marneffe, Daniel Jurafsky, and Christopher D. Manning. 2010. Parsing to stanford dependencies: Trade-offs between speed and accuracy. In Proceedings of the Language Ressources and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropyinspired parser.</title>
<date>2000</date>
<booktitle>In ANLP,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="694" citStr="Charniak (2000)" startWordPosition="95" endWordPosition="96"> Alpage – Universit´e Paris Diderot – Inria – IUF Place Paul Ricoeur 75013 Paris benoit.crabbe@univ-paris-diderot.fr Abstract We provide a generalization of discriminative lexicalized shift reduce parsing techniques for phrase structure grammar to a wide range of morphologically rich languages. The model is efficient and outperforms recent strong baselines on almost all languages considered. It takes advantage of a dependency based modelling of morphology and a shallow modelling of constituency boundaries. 1 Introduction Lexicalized phrase structure parsing techniques were first introduced by Charniak (2000) and Collins (2003) as generative probabilistic models. Nowadays most statistical models used in natural language processing are discriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure pars</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropyinspired parser. In ANLP, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Jan Hajic</author>
<author>Lance A Ramshaw</author>
<author>Christoph Tillmann</author>
</authors>
<title>A statistical parser for Czech.</title>
<date>1999</date>
<booktitle>In 27th Annual Meeting of the Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="1490" citStr="Collins et al., 1999" startWordPosition="211" endWordPosition="214">more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informative patterns observed on input spans. Hall et al</context>
</contexts>
<marker>Collins, Hajic, Ramshaw, Tillmann, 1999</marker>
<rawString>Michael Collins, Jan Hajic, Lance A. Ramshaw, and Christoph Tillmann. 1999. A statistical parser for Czech. In 27th Annual Meeting of the Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-driven statistical models for natural language parsing.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="713" citStr="Collins (2003)" startWordPosition="98" endWordPosition="99">e Paris Diderot – Inria – IUF Place Paul Ricoeur 75013 Paris benoit.crabbe@univ-paris-diderot.fr Abstract We provide a generalization of discriminative lexicalized shift reduce parsing techniques for phrase structure grammar to a wide range of morphologically rich languages. The model is efficient and outperforms recent strong baselines on almost all languages considered. It takes advantage of a dependency based modelling of morphology and a shallow modelling of constituency boundaries. 1 Introduction Lexicalized phrase structure parsing techniques were first introduced by Charniak (2000) and Collins (2003) as generative probabilistic models. Nowadays most statistical models used in natural language processing are discriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation </context>
<context position="6182" citStr="Collins, 2003" startWordPosition="944" endWordPosition="945"> these datasets. Although in multi-view treebanks each sentence is annotated both for constituency and dependency, they are not normalized for categories nor lexical features accross languages such as dependencies in the Google Universal Treebank (McDonald et al., 2013). What is more, the dependency and constituency structures may sometimes strongly differ. For some languages, like Hungarian, the conversion has involved some manual reannotation (Vincze et al., 2010). 3 Head annotation procedure Lexicalized phrase structure parsers traditionally use hand-crafted heuristics for head annotation (Collins, 2003). Although these heuristics are available for some languages, for others they are non existent or non explicit and typically hidden in conversion procedures. In order to leverage the burden of managing language specific heuristics, we first automate head annotation by taking advantage of the multi-view annotation. We begin by introducing some notation. Assuming a sentence W = wi ... wn, the dependency annotation of this sentence is assumed to be a dependency forest (Kuhlmann and Nivre, 2006). A dependency graph G = (V, E) where V = {1 ... n} is the set of word indexes or vertices and E C_ V x </context>
</contexts>
<marker>Collins, 2003</marker>
<rawString>Michael Collins. 2003. Head-driven statistical models for natural language parsing. Computational Linguistics, 29(4):589–637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoit Crabb´e</author>
</authors>
<title>An LR-inspired generalized lexicalized phrase structure parser.</title>
<date>2014</date>
<booktitle>In 25th International Conference on Computational Linguistics (COLING).</booktitle>
<marker>Crabb´e, 2014</marker>
<rawString>Benoit Crabb´e. 2014. An LR-inspired generalized lexicalized phrase structure parser. In 25th International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<title>Eric Villemonte de La Clergerie.</title>
<date>2013</date>
<booktitle>In 4th Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL2013).</booktitle>
<contexts>
<context position="1441" citStr="(2013)" startWordPosition="206" endWordPosition="206">ve: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informa</context>
<context position="21050" citStr="(2013)" startWordPosition="3563" endWordPosition="3563">ple-structured tags. The training and development sets are tagged by 10-fold jackknifing. Head annotation is supplied by the Robust procedure described in Section 3. The parser is systematically trained for 25 epochs with a max violation update perceptron, a beam of size 8 and a minibatch size of 24. 1851 To enable a comparison with other published results, the evaluation is performed with a version of evalb provided by the SPMRL organizers (Seddah et al., 2013) which takes punctuation into account. Baseline model (B) The baseline model uses a set of templates identical to those of Zhu et al. (2013) for parsing English and Chinese except that we have no specific templates for unary reductions. Span-based model (B+S) This model extends the B model by modeling spans. The span model approximates an intuition underlying Hall et al. (2014): constituent boundaries contain very informative tokens (typically function words). These tokens together with the pattern of their neighborhood provide key clues for detecting and (sub)typing constituents. Moreover, parameter estimation for frequent functional words should suffer less from data sparseness issues than the estimation of bilexical dependencie</context>
<context position="22999" citStr="(2013)" startWordPosition="3859" endWordPosition="3859">es such as case are key for identifying the structure of free word order languages. As feature engineering may become in principle quite complex once it comes to morphology, we targeted fairly crude models with the goal of providing a proof of concept. Therefore the morphologically informed models use as input a rich set of morphological features specified in Figure 2 (right) predicted by the CRF tagger (M¨uller et al., 2013) with the same jackkniffing as before. The content of Figure 2 provides an explicit indication of the actual features defined in the original treebanks (see Seddah et al. (2013) and references therein for details), while the columns are indicative normalized names. For Basque most of the additional morphological features further encode case and verbal subcategorization. For French the mwe field abbreviates IOB predicted tags derived from multi-word expression annotations found in the original dataset. Now let M be the set of values enumerated for a language in Figure 2 (right), we systematically added the following templates to model B: s0.wt.m&amp;s1.wt.m&amp;q1.tag ∀m ∈ M s0.wt.m&amp;s1.ct&amp;q1.m ∀m ∈ M s0.ct.m&amp;s1.wt.m&amp;q1.m ∀m ∈ M s0.wt.m&amp;q1.m&amp;qa.tag ∀m ∈ M s0.wt.m&amp;q1.tag&amp;qa.m ∀</context>
<context position="29165" citStr="(2013)" startWordPosition="4862" endWordPosition="4862">lins] 90.0 2150 ° Petrov 06 90.1 169 Fernandez-Martins 15 90.2 957 Zhu et al. 13 90.4 1290 Alls scores and times except o are measured by Fern´andezGonz´alez and Martins (2015) on an intel Xeon 2.3Ghz. o denotes the use of a different architecture (2.4Ghz intel). Table 5: Penn treebank test (WSJ 23) parison remains indicative, it is clear that the parsing framework described in this paper is not only reasonably accurate on a fixed word order language such as English but it is also quite efficient. Parsing accuracies might be different with other head annotation schemes (See e.g. Elming et al. (2013) for illustrations). In our case, we compare the (B+S) model with automated head annotation to the Collins head annotation as implemented in the Standord CORE NLP library (Manning et al., 2014), where we can see that the Collins handcrafted head annotation yields better results than the automated one on English7. The question is now to which extend c-trees encode meaningful dependencies? As lexicalized c-trees encode unlabeled dependency trees, our parser also directly outputs unlabeled d-trees by 7This pattern does not seem to be systematic: on French we could also compare with head annotatio</context>
</contexts>
<marker>2013</marker>
<rawString>Eric Villemonte de La Clergerie. 2013. Exploring beam-based shift-reduce dependency parsing with dyalog: Results from the spmrl 2013 shared task. In 4th Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Language Ressources and Evaluation Conference (LREC).</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. 2006. Generating typed dependency parses from phrase structure parses. In Language Ressources and Evaluation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jakob Elming</author>
<author>Anders Johannsen</author>
<author>Sigrid Klerke</author>
<author>Emanuele Lapponi</author>
<author>Hector Martinez</author>
<author>Anders Sogaard</author>
</authors>
<title>Down-stream effects of treeto-dependency conversions.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT.</booktitle>
<contexts>
<context position="29165" citStr="Elming et al. (2013)" startWordPosition="4859" endWordPosition="4862">per (B+S) [Collins] 90.0 2150 ° Petrov 06 90.1 169 Fernandez-Martins 15 90.2 957 Zhu et al. 13 90.4 1290 Alls scores and times except o are measured by Fern´andezGonz´alez and Martins (2015) on an intel Xeon 2.3Ghz. o denotes the use of a different architecture (2.4Ghz intel). Table 5: Penn treebank test (WSJ 23) parison remains indicative, it is clear that the parsing framework described in this paper is not only reasonably accurate on a fixed word order language such as English but it is also quite efficient. Parsing accuracies might be different with other head annotation schemes (See e.g. Elming et al. (2013) for illustrations). In our case, we compare the (B+S) model with automated head annotation to the Collins head annotation as implemented in the Standord CORE NLP library (Manning et al., 2014), where we can see that the Collins handcrafted head annotation yields better results than the automated one on English7. The question is now to which extend c-trees encode meaningful dependencies? As lexicalized c-trees encode unlabeled dependency trees, our parser also directly outputs unlabeled d-trees by 7This pattern does not seem to be systematic: on French we could also compare with head annotatio</context>
</contexts>
<marker>Elming, Johannsen, Klerke, Lapponi, Martinez, Sogaard, 2013</marker>
<rawString>Jakob Elming, Anders Johannsen, Sigrid Klerke, Emanuele Lapponi, Hector Martinez, and Anders Sogaard. 2013. Down-stream effects of treeto-dependency conversions. In Proceedings of NAACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Fern´andez-Gonz´alez</author>
<author>Andr´e F T Martins</author>
</authors>
<title>Parsing as reduction.</title>
<date>2015</date>
<booktitle>In Proceeding of the Association of Computational Linguistics (ACL),</booktitle>
<marker>Fern´andez-Gonz´alez, Martins, 2015</marker>
<rawString>Daniel Fern´andez-Gonz´alez and Andr´e F. T. Martins. 2015. Parsing as reduction. In Proceeding of the Association of Computational Linguistics (ACL), 2015.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hall</author>
<author>Greg Durrett</author>
<author>Dan Klein</author>
</authors>
<title>Less grammar, more features.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL</booktitle>
<pages>228--237</pages>
<contexts>
<context position="1644" citStr="Hall et al. (2014)" startWordPosition="237" endWordPosition="240"> the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informative patterns observed on input spans. Hall et al. (2014) relies on a similar intuition : the model essentially aims to capture regularities on the spans of constituents and their immediate neighbourhood</context>
<context position="20096" citStr="Hall et al. (2014)" startWordPosition="3399" endWordPosition="3402">lso additional custom lexical features such as those enumerated in Figure 2 (right). This allows us to express the morphological models described in Section 5. Finally, the parameters w are estimated with a parallel averaged structured perceptron designed to cope with inexact inference (beam search): we specifically rely on max-violation updates of Huang et al. (2012) and on minibatches to accelerate and parallelize training (Shalev-Shwartz et al., 2007; Zhao and Huang, 2013). 5 Experiments The experiments aim to compare the contribution of span based features approximating some intuitions of Hall et al. (2014) for shift reduce parsing and morphological features for parsing free word order languages. We start by describing the evaluation protocol and by defining the models used. We use the standard SPMRL data set (Seddah et al., 2013). Part of speech tags are generated with Marmot (M¨uller et al., 2013), a CRF tagger specifically designed to provide tuple-structured tags. The training and development sets are tagged by 10-fold jackknifing. Head annotation is supplied by the Robust procedure described in Section 3. The parser is systematically trained for 25 epochs with a max violation update percept</context>
<context position="24479" citStr="Hall et al. (2014)" startWordPosition="4093" endWordPosition="4096"> model is the union of the span model (B+S) and the morphological model (B+M). Results (development) We measured the impact of the model variations on the development set for c-parsing on the SPMRL data sets (Table 2). We immediately observe that modelling spans tends to improve the results, in particular for languages where the head annotation is more problematic: Arabic4, Basque, German and Hungarian and also Swedish however. So the span-based model seems to improve the parser’s robustness in cases when dependencies lack precision. For this model, the average behaviour is similar to that of Hall et al. (2014) although the variance is high. On the other hand, the morphological model tends to be most important for languages where head annotation is easier: French, Korean, Polish and Swedish. It is key for very richly inflected languages such as Basque and Hungarian even though our head annotation is more approximative5. A 4Although not detailed in the paper, we also observe that for Arabic, the morphological features are generally predicted with a lower accurracy by the tagger than for other languages. 5As annotation schemes are not normalized across languages, it is important to stress that these o</context>
<context position="25981" citStr="Hall et al. (2014)" startWordPosition="4337" endWordPosition="4340">52 Model Arabic Basque French German Hebrew Hungarian Korean Polish Swedish Avg 1 Base 79.46 74.67 79.66 82.61 90.43 84.34 81.96 91.68 75.60 82.26 2 Base+S 80.59 76.39 80.15 83.63 90.63 85.62 82.21 91.75 77.49 83.16 3 Base+M 80.17 83.69 81.05 83.66 90.40 87.75 82.79 92.72 77.50 84.41 4 Base+S+M 81.25 84.01 80.87 84.08 90.69 88.27 83.09 92.78 77.87 84.77 5 Hall-Klein 14 78.89 83.74 79.40 83.28 88.06 87.44 81.85 91.10 75.95 83.30 F1-scores provided by evalb-spmrl (Seddah et al., 2013). Takes punctuation into account and penalizes unparsed sentences. Table 2: Development F-scores comparison with Hall et al. (2014) also reveals that for Basque, Hungarian and Swedish, taking into account morphological information largely explains our improved results. Results (test) We observe in Table 3 that our joint B+S+M model yields a state of the art cparser on almost all languages considered6. It is quite clear that both our span and morphology enhanced models could be dramatically improved, but it shows that with reasonable feature engineering, these two sub-models are largely sufficient to improve the state of the art in c-parsing for these languages over strong baselines. Although in principle the Berkeley pars</context>
</contexts>
<marker>Hall, Durrett, Klein, 2014</marker>
<rawString>David Hall, Greg Durrett, and Dan Klein. 2014. Less grammar, more features. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014, pages 228–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Suphan Fayong</author>
<author>Yang Guo</author>
</authors>
<title>Structured perceptron with inexact search.</title>
<date>2012</date>
<booktitle>In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics (NAACL-HLT).</booktitle>
<contexts>
<context position="19848" citStr="Huang et al. (2012)" startWordPosition="3360" endWordPosition="3363"> the immediate left and right children of s0 and s1 as well as their left and right corner tokens. This allows us to encode the span models described in Section 5. We also use tuple-structured tokens encoding not only the word-form and the tag but also additional custom lexical features such as those enumerated in Figure 2 (right). This allows us to express the morphological models described in Section 5. Finally, the parameters w are estimated with a parallel averaged structured perceptron designed to cope with inexact inference (beam search): we specifically rely on max-violation updates of Huang et al. (2012) and on minibatches to accelerate and parallelize training (Shalev-Shwartz et al., 2007; Zhao and Huang, 2013). 5 Experiments The experiments aim to compare the contribution of span based features approximating some intuitions of Hall et al. (2014) for shift reduce parsing and morphological features for parsing free word order languages. We start by describing the evaluation protocol and by defining the models used. We use the standard SPMRL data set (Seddah et al., 2013). Part of speech tags are generated with Marmot (M¨uller et al., 2013), a CRF tagger specifically designed to provide tuple-</context>
</contexts>
<marker>Huang, Fayong, Guo, 2012</marker>
<rawString>Liang Huang, Suphan Fayong, and Yang Guo. 2012. Structured perceptron with inexact search. In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>478--485</pages>
<contexts>
<context position="2302" citStr="Klein and Manning (2004)" startWordPosition="342" endWordPosition="345">ield parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informative patterns observed on input spans. Hall et al. (2014) relies on a similar intuition : the model essentially aims to capture regularities on the spans of constituents and their immediate neighbourhood, following earlier intuitions of Klein and Manning (2004). This modelling strategy has two main motivations. First it reduces the burden of feature engineering, making it easier to generalize to multiple languages. Second it avoids modeling explicitly bilexical dependencies for which parameters are notoriously hard to estimate from small data sets such as existing treebanks. On the other hand this strategy becomes less intuitive when it comes to modeling free word order languages where word order and constituency should in principle be less informative. As such, the good results reported by Hall et al. (2014) are surprising. It suggests that word or</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Christopher D. Manning. 2004. Corpus-based induction of syntactic structure: Models of dependency and constituency. In Proceedings of the 42nd Annual Meeting of the Association for Computational Linguistics, pages 478–485.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lingpeng Kong</author>
<author>Noah A Smith</author>
</authors>
<title>An empirical comparison of parsing methods for stanford dependencies.</title>
<date>2014</date>
<location>CoRR, abs/1404.4314.</location>
<contexts>
<context position="32145" citStr="Kong and Smith (2014)" startWordPosition="5332" endWordPosition="5335">e dependencies and we compare them to the best results obtained by dependency parsers in both SPMRL13 and SPMRL14 shared tasks. For each language, the comparison is made with the best single dependency parsing system8. For English we compare against Standard TurboParser - which seems to be the most similar to our system- when parsing to Basic Stanford dependencies. The comparison with semi-supervised and ensemble parsers still provides a reasonable upperline (Bj¨orkelund et al., 2013). As can be seen in Table 4, our results partly generalize the observation summarized by Cer et al. (2010) and Kong and Smith (2014) that phrase structure parsers tend to provide better dependencies than genuine dependency parsers for parsing to Stanford Dependencies. For English, our UAS is similar to that of TurboParser, but in a broader multilingual framework, the left side of the table shows that the unlabeled dependencies are clearly better than those of genuine dependency parsers. On the right side of the table are languages for which our dependencies are actually worse. This is not a surprise, since these are also the languages for which head annotation was more problematic in the first place. This last observation </context>
</contexts>
<marker>Kong, Smith, 2014</marker>
<rawString>Lingpeng Kong and Noah A. Smith. 2014. An empirical comparison of parsing methods for stanford dependencies. CoRR, abs/1404.4314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Joakim Nivre</author>
</authors>
<title>Mildly non-projective dependency structures.</title>
<date>2006</date>
<booktitle>In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL/COLING).</booktitle>
<contexts>
<context position="6678" citStr="Kuhlmann and Nivre, 2006" startWordPosition="1022" endWordPosition="1025">tion procedure Lexicalized phrase structure parsers traditionally use hand-crafted heuristics for head annotation (Collins, 2003). Although these heuristics are available for some languages, for others they are non existent or non explicit and typically hidden in conversion procedures. In order to leverage the burden of managing language specific heuristics, we first automate head annotation by taking advantage of the multi-view annotation. We begin by introducing some notation. Assuming a sentence W = wi ... wn, the dependency annotation of this sentence is assumed to be a dependency forest (Kuhlmann and Nivre, 2006). A dependency graph G = (V, E) where V = {1 ... n} is the set of word indexes or vertices and E C_ V x V is a set of dependency links. By convention, a dependency (i, j) means that i governs j. A dependency forest is a dependency graph such that a node has at most a single incoming edge and where there is no cycle. A node with no incoming edge is a root of the dependency forest and a dependency tree is a dependency forest with a single root. For some languages, such as German or Basque, the dependency structures found in the data set are actually dependency forests. Lexicalized parsing relies</context>
</contexts>
<marker>Kuhlmann, Nivre, 2006</marker>
<rawString>Marco Kuhlmann and Joakim Nivre. 2006. Mildly non-projective dependency structures. In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL/COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Mihai Surdeanu</author>
<author>John Bauer</author>
<author>Jenny Finkel</author>
<author>Steven J Bethard</author>
<author>David McClosky</author>
</authors>
<title>The Stanford CoreNLP natural language processing toolkit.</title>
<date>2014</date>
<booktitle>In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations.</booktitle>
<contexts>
<context position="29358" citStr="Manning et al., 2014" startWordPosition="4890" endWordPosition="4893">n an intel Xeon 2.3Ghz. o denotes the use of a different architecture (2.4Ghz intel). Table 5: Penn treebank test (WSJ 23) parison remains indicative, it is clear that the parsing framework described in this paper is not only reasonably accurate on a fixed word order language such as English but it is also quite efficient. Parsing accuracies might be different with other head annotation schemes (See e.g. Elming et al. (2013) for illustrations). In our case, we compare the (B+S) model with automated head annotation to the Collins head annotation as implemented in the Standord CORE NLP library (Manning et al., 2014), where we can see that the Collins handcrafted head annotation yields better results than the automated one on English7. The question is now to which extend c-trees encode meaningful dependencies? As lexicalized c-trees encode unlabeled dependency trees, our parser also directly outputs unlabeled d-trees by 7This pattern does not seem to be systematic: on French we could also compare with head annotations described in (Arun and Keller, 2005) and we observed a slight improvement when using the automated procedure. 1853 Parser (single) Arabic Basque French German Hebrew Hungarian Korean Polish </context>
</contexts>
<marker>Manning, Surdeanu, Bauer, Finkel, Bethard, McClosky, 2014</marker>
<rawString>Christopher D. Manning, Mihai Surdeanu, John Bauer, Jenny Finkel, Steven J. Bethard, and David McClosky. 2014. The Stanford CoreNLP natural language processing toolkit. In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP).</booktitle>
<contexts>
<context position="1201" citStr="McDonald et al., 2005" startWordPosition="167" endWordPosition="171">oundaries. 1 Introduction Lexicalized phrase structure parsing techniques were first introduced by Charniak (2000) and Collins (2003) as generative probabilistic models. Nowadays most statistical models used in natural language processing are discriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et a</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan T. McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. In Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>J Nivre</author>
<author>Y Quirmbach-Brundage</author>
<author>Y Goldberg</author>
<author>D Das</author>
<author>K Ganchev</author>
<author>K Hall</author>
<author>S Petrov</author>
<author>H Zhang</author>
<author>O Tackstrom</author>
<author>C Bedini</author>
<author>N Bertomeu Castello</author>
<author>J Lee</author>
</authors>
<title>Universal dependency annotation for multilingual parsing.</title>
<date>2013</date>
<booktitle>In Proceeding of the Association of Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="5838" citStr="McDonald et al., 2013" startWordPosition="893" endWordPosition="897">al., 2013), which contains multi-view treebanks for a number of morphologically rich languages, for which either constituency or dependency treebanks were available. The same kind of process was applied to the Penn TreeBank using the Stanford conversion system to produce dependency annotations (de Marneffe et al., 2006). In this paper, we use both of these datasets. Although in multi-view treebanks each sentence is annotated both for constituency and dependency, they are not normalized for categories nor lexical features accross languages such as dependencies in the Google Universal Treebank (McDonald et al., 2013). What is more, the dependency and constituency structures may sometimes strongly differ. For some languages, like Hungarian, the conversion has involved some manual reannotation (Vincze et al., 2010). 3 Head annotation procedure Lexicalized phrase structure parsers traditionally use hand-crafted heuristics for head annotation (Collins, 2003). Although these heuristics are available for some languages, for others they are non existent or non explicit and typically hidden in conversion procedures. In order to leverage the burden of managing language specific heuristics, we first automate head a</context>
</contexts>
<marker>McDonald, Nivre, Quirmbach-Brundage, Goldberg, Das, Ganchev, Hall, Petrov, Zhang, Tackstrom, Bedini, Castello, Lee, 2013</marker>
<rawString>Ryan McDonald, J. Nivre, Y. Quirmbach-Brundage, Y. Goldberg, D. Das, K. Ganchev, K. Hall, S. Petrov, H. Zhang, O. Tackstrom, C. Bedini, N. Bertomeu Castello, and J. Lee. 2013. Universal dependency annotation for multilingual parsing. In Proceeding of the Association of Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
</authors>
<title>Shift-reduce constituency parsing with dynamic programming and pos tag lattice.</title>
<date>2015</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT).</booktitle>
<contexts>
<context position="13612" citStr="Mi and Huang, 2015" startWordPosition="2267" endWordPosition="2270">rectly inferrable from the dependency annotation. Polish uses this restructuration in patterns involving coordination. More surprisingly, non projective patterns, which we expected to be a significant feature of these languages, remain marginal in comparison to annotation related idiosyncrasic problems. 4 Parsing algorithm This section provides an overview of the design of the constituent parsing system. There are three recent proposals for beam-based discriminative shift reduce parsing for phrase structure grammar with a structured perceptron and beam search (Zhu et al., 2013; Crabb´e, 2014; Mi and Huang, 2015). All three proposals point out that for weighted phrase structure parsing, the shift reduce algorithm requires a special treatment of unary rules in order to compare derivations of the same length. They all provide different management schemes for these unaries. The work described here draws on the LR algorithm introduced by Crabb´e (2014), but provides a simpler algorithm, it precisely describes the management of unary rules and clarifies how spans and morphological information is represented (see section 5 ). 2The constituency conversion of the Basque treebank also contains a recurrent atta</context>
</contexts>
<marker>Mi, Huang, 2015</marker>
<rawString>Haitao Mi and Liang Huang. 2015. Shift-reduce constituency parsing with dynamic programming and pos tag lattice. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M¨uller</author>
<author>Helmut Schmid</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Efficient higher-order crfs for morphological tagging.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<marker>M¨uller, Schmid, Sch¨utze, 2013</marker>
<rawString>Thomas M¨uller, Helmut Schmid, and Hinrich Sch¨utze. 2013. Efficient higher-order crfs for morphological tagging. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Mario Scholz</author>
</authors>
<title>Deterministic dependency parsing of english text.</title>
<date>2004</date>
<booktitle>In COLING 2004, 20th International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="1178" citStr="Nivre and Scholz, 2004" startWordPosition="163" endWordPosition="166">elling of constituency boundaries. 1 Introduction Lexicalized phrase structure parsing techniques were first introduced by Charniak (2000) and Collins (2003) as generative probabilistic models. Nowadays most statistical models used in natural language processing are discriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et a</context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>Joakim Nivre and Mario Scholz. 2004. Deterministic dependency parsing of english text. In COLING 2004, 20th International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (ACL/COLING).</booktitle>
<contexts>
<context position="1601" citStr="Petrov et al. (2006)" startWordPosition="230" endWordPosition="233">trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informative patterns observed on input spans. Hall et al. (2014) relies on a similar intuition : the model essentially aims to capture regularities on the spans of con</context>
<context position="26605" citStr="Petrov et al., 2006" startWordPosition="4439" endWordPosition="4442"> reveals that for Basque, Hungarian and Swedish, taking into account morphological information largely explains our improved results. Results (test) We observe in Table 3 that our joint B+S+M model yields a state of the art cparser on almost all languages considered6. It is quite clear that both our span and morphology enhanced models could be dramatically improved, but it shows that with reasonable feature engineering, these two sub-models are largely sufficient to improve the state of the art in c-parsing for these languages over strong baselines. Although in principle the Berkeley parsers (Petrov et al., 2006; Hall et al., 2014) are designed to be language-generic with an underlying design that is surprisingly accurate for free word order languages end up suffering from a lack of sensitivity to morphological information. Finally we also observe that our phrase structure parser clearly outperforms the TurboParser setup described by Fern´andez-Gonz´alez and Martins (2015) in which an elaborate output conversion procedure generates c-parses from d-parses. Comparison with related work We conclude with a few comparisons with related work. This will enable us to show that our approach is not only accura</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, Proceedings of the Conference (ACL/COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Likun Qiu</author>
<author>Yue Zhang</author>
<author>Peng Jin</author>
<author>Houfeng Wang</author>
</authors>
<title>Multi-view chinese treebanking.</title>
<date>2014</date>
<booktitle>In 25th International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="3743" citStr="Qiu et al., 2014" startWordPosition="569" endWordPosition="572">model that can effectively take morphology into account is key for parsing these languages. More specifically, we show that an efficient lexicalized phrase structure parser - modelling both dependencies and morphology - already significantly improves parsing accuracy. But we also show that an additional modelling of spans and constituency provides additional robustness that contributes to yield state of the art results on almost all languages considered, while remaining quite efficient. Moreover, given the availability of existing multi-view treebanks (Bhatt et al., 2009; Seddah et al., 2013; Qiu et al., 2014), our proposed solution only requires a lightweight infrastructure to achieve multilin1847 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1847–1856, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. gual parsing without requiring costly languagedependent modifications such as feature engineering. The paper is organized as follows. We first review the properties of multiview treebanks (Section 2). As these treebanks typically do not provide directly head annotation, an information required for lexicalized par</context>
<context position="4980" citStr="Qiu et al., 2014" startWordPosition="759" endWordPosition="762">automated multilingual head annotation procedure (Section 3). We then describe in section 4 a variant of lexicalized shift reduce parsing that we use for the multilingual setting. It provides a way to integrate morphology in the model. Section 5 finally describes a set of experiments designed to test our main hypothesis and to point out the improvements over state of the art in multilingual parsing. 2 Multi-view treebanks Multi-view treebanks are treebanks annotated both for constituents and dependencies that have the property to be token-wise aligned (Bhatt et al., 2009; Seddah et al., 2013; Qiu et al., 2014) . These double annotations are typically obtained by converting a constituency or dependency annotation into the other annotation type. This method was used for the construction of the dataset for the SPMRL 2013 shared task (Seddah et al., 2013), which contains multi-view treebanks for a number of morphologically rich languages, for which either constituency or dependency treebanks were available. The same kind of process was applied to the Penn TreeBank using the Stanford conversion system to produce dependency annotations (de Marneffe et al., 2006). In this paper, we use both of these datas</context>
</contexts>
<marker>Qiu, Zhang, Jin, Wang, 2014</marker>
<rawString>Likun Qiu, Yue Zhang, Peng Jin, and Houfeng Wang. 2014. Multi-view chinese treebanking. In 25th International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<title>A best-first probabilistic shift-reduce parser.</title>
<date>2006</date>
<booktitle>In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL/COLING).</booktitle>
<contexts>
<context position="16048" citStr="Sagae and Lavie (2006)" startWordPosition="2689" endWordPosition="2692"> − 1 to 3n − 1. To ensure that a derivation is of length 3n − 1, the parser forces each shift to be followed by either a unary reduction or an alternative dummy Ghost Reduction (GR). Given the pre-processed treebank we infer the set A of actions used by the parser. Let E be the set of non-terminal symbols (including temporary symbols) read off from the binary treebank. The set of actions contains one Shift (S), one Ghost Reduction (GR) a set of |E |unary reductions (RU-X), one for each symbol, a set of |E| binary left reductions (RL-X) and a set of |E |binary right reductions (RR-X) (see also Sagae and Lavie (2006) and Figure 3 for details). The parser itself is organized around two data structures: a stack of symbols, S = ... |s2|s1|s0, whose topmost element is s0. Symbols are lexicalized non terminals or tokens of the form A[x]. The second structure is a queue statically filled with tokens T = t1 ... tn. Parsing is performed by sequentially generating configurations C of the form (j, S, ·) where S is a stack and j is the index of the first element of the queue. Given an initial configuration C0 = (1, c, 1), a derivation step at−1 Ct−1 � Ct generates a new configuration Ct by applying an action at−1 E </context>
</contexts>
<marker>Sagae, Lavie, 2006</marker>
<rawString>Kenji Sagae and Alon Lavie. 2006. A best-first probabilistic shift-reduce parser. In 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL/COLING).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Djam´e Seddah</author>
<author>Reut Tsarfaty</author>
<author>Sandra Kubler</author>
<author>Marie Candito</author>
<author>Jinho D Choi</author>
<author>Rich´ard Farkas</author>
<author>Jennifer Foster</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Yuval Marton, Joakim Nivre, Adam Przepi´orkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woliski, Alina Wr´oblewska, and Eric Villemonte de la Clergerie.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth SPMRL Workshop,</booktitle>
<location>Seattle, USA.</location>
<contexts>
<context position="3724" citStr="Seddah et al., 2013" startWordPosition="565" endWordPosition="568">shows that a parsing model that can effectively take morphology into account is key for parsing these languages. More specifically, we show that an efficient lexicalized phrase structure parser - modelling both dependencies and morphology - already significantly improves parsing accuracy. But we also show that an additional modelling of spans and constituency provides additional robustness that contributes to yield state of the art results on almost all languages considered, while remaining quite efficient. Moreover, given the availability of existing multi-view treebanks (Bhatt et al., 2009; Seddah et al., 2013; Qiu et al., 2014), our proposed solution only requires a lightweight infrastructure to achieve multilin1847 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1847–1856, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. gual parsing without requiring costly languagedependent modifications such as feature engineering. The paper is organized as follows. We first review the properties of multiview treebanks (Section 2). As these treebanks typically do not provide directly head annotation, an information required </context>
<context position="4961" citStr="Seddah et al., 2013" startWordPosition="755" endWordPosition="758">rsing, we provide an automated multilingual head annotation procedure (Section 3). We then describe in section 4 a variant of lexicalized shift reduce parsing that we use for the multilingual setting. It provides a way to integrate morphology in the model. Section 5 finally describes a set of experiments designed to test our main hypothesis and to point out the improvements over state of the art in multilingual parsing. 2 Multi-view treebanks Multi-view treebanks are treebanks annotated both for constituents and dependencies that have the property to be token-wise aligned (Bhatt et al., 2009; Seddah et al., 2013; Qiu et al., 2014) . These double annotations are typically obtained by converting a constituency or dependency annotation into the other annotation type. This method was used for the construction of the dataset for the SPMRL 2013 shared task (Seddah et al., 2013), which contains multi-view treebanks for a number of morphologically rich languages, for which either constituency or dependency treebanks were available. The same kind of process was applied to the Penn TreeBank using the Stanford conversion system to produce dependency annotations (de Marneffe et al., 2006). In this paper, we use </context>
<context position="20324" citStr="Seddah et al., 2013" startWordPosition="3437" endWordPosition="3440">tructured perceptron designed to cope with inexact inference (beam search): we specifically rely on max-violation updates of Huang et al. (2012) and on minibatches to accelerate and parallelize training (Shalev-Shwartz et al., 2007; Zhao and Huang, 2013). 5 Experiments The experiments aim to compare the contribution of span based features approximating some intuitions of Hall et al. (2014) for shift reduce parsing and morphological features for parsing free word order languages. We start by describing the evaluation protocol and by defining the models used. We use the standard SPMRL data set (Seddah et al., 2013). Part of speech tags are generated with Marmot (M¨uller et al., 2013), a CRF tagger specifically designed to provide tuple-structured tags. The training and development sets are tagged by 10-fold jackknifing. Head annotation is supplied by the Robust procedure described in Section 3. The parser is systematically trained for 25 epochs with a max violation update perceptron, a beam of size 8 and a minibatch size of 24. 1851 To enable a comparison with other published results, the evaluation is performed with a version of evalb provided by the SPMRL organizers (Seddah et al., 2013) which takes p</context>
<context position="22999" citStr="Seddah et al. (2013)" startWordPosition="3856" endWordPosition="3859">logical features such as case are key for identifying the structure of free word order languages. As feature engineering may become in principle quite complex once it comes to morphology, we targeted fairly crude models with the goal of providing a proof of concept. Therefore the morphologically informed models use as input a rich set of morphological features specified in Figure 2 (right) predicted by the CRF tagger (M¨uller et al., 2013) with the same jackkniffing as before. The content of Figure 2 provides an explicit indication of the actual features defined in the original treebanks (see Seddah et al. (2013) and references therein for details), while the columns are indicative normalized names. For Basque most of the additional morphological features further encode case and verbal subcategorization. For French the mwe field abbreviates IOB predicted tags derived from multi-word expression annotations found in the original dataset. Now let M be the set of values enumerated for a language in Figure 2 (right), we systematically added the following templates to model B: s0.wt.m&amp;s1.wt.m&amp;q1.tag ∀m ∈ M s0.wt.m&amp;s1.ct&amp;q1.m ∀m ∈ M s0.ct.m&amp;s1.wt.m&amp;q1.m ∀m ∈ M s0.wt.m&amp;q1.m&amp;qa.tag ∀m ∈ M s0.wt.m&amp;q1.tag&amp;qa.m ∀</context>
<context position="25850" citStr="Seddah et al., 2013" startWordPosition="4319" endWordPosition="4322">oices. For example Korean is a strongly agglutinative language for which much of the morphology is already encoded in the tag set. 1852 Model Arabic Basque French German Hebrew Hungarian Korean Polish Swedish Avg 1 Base 79.46 74.67 79.66 82.61 90.43 84.34 81.96 91.68 75.60 82.26 2 Base+S 80.59 76.39 80.15 83.63 90.63 85.62 82.21 91.75 77.49 83.16 3 Base+M 80.17 83.69 81.05 83.66 90.40 87.75 82.79 92.72 77.50 84.41 4 Base+S+M 81.25 84.01 80.87 84.08 90.69 88.27 83.09 92.78 77.87 84.77 5 Hall-Klein 14 78.89 83.74 79.40 83.28 88.06 87.44 81.85 91.10 75.95 83.30 F1-scores provided by evalb-spmrl (Seddah et al., 2013). Takes punctuation into account and penalizes unparsed sentences. Table 2: Development F-scores comparison with Hall et al. (2014) also reveals that for Basque, Hungarian and Swedish, taking into account morphological information largely explains our improved results. Results (test) We observe in Table 3 that our joint B+S+M model yields a state of the art cparser on almost all languages considered6. It is quite clear that both our span and morphology enhanced models could be dramatically improved, but it shows that with reasonable feature engineering, these two sub-models are largely suffici</context>
<context position="30480" citStr="Seddah et al., 2013" startWordPosition="5068" endWordPosition="5071">omated procedure. 1853 Parser (single) Arabic Basque French German Hebrew Hungarian Korean Polish Swedish Avg Petrov 06 79.19 70.50 80.38 78.30 86.96 81.62 71.42 79.23 79.19 78.45 Petrov 06 + tags 78.66 74.74 79.76 78.28 85.42 85.22 78.56 86.75 80.64 81.17 Hall-Klein 14 78.75 83.39 79.70 78.43 87.18 88.25 80.18 90.66 82.00 83.72 Fernandez-Martins 15 - 85.90 78.75 78.66 88.97 88.16 79.28 91.20 82.80 84.22 This paper (B+S+M) 81.31 84.94 80.84 79.26 89.65 90.14 82.65 92.66 83.24 85.42 Best semi/ensemble 81.32 88.24 82.53 81.66 89.80 91.72 83.81 90.50 85.50 86.72 F-scores provided by evalb-spmrl (Seddah et al., 2013). It takes punctuation into account and penalizes unparsed sentences. The average ignores Arabic for comparison with TurboParser. Petrov 06 + tags is the Berkeley parser with externally predicted pos tags (Seddah et al., 2013) Table 3: Multilingual test (F-scores, phrase structure parsing) System English French Korean Hebrew Polish Swedish Arabic Basque German Hungarian This paper (B+S+M) 91.75 86.68 87.22 85.28 88.61 86.22 80.64 73.68 67.20 74.46 Best d-parser (single) 91.95 85.80 85.84 81.05 88.12 84.54 84.57 84.33 87.65 83.71 Best semi/ensemble - 89.19 89.10 87.41 91.75 88.48 88.32 89.96 91</context>
</contexts>
<marker>Seddah, Tsarfaty, Kubler, Candito, Choi, Farkas, Foster, 2013</marker>
<rawString>Djam´e Seddah, Reut Tsarfaty, Sandra Kubler, Marie Candito, Jinho D. Choi, Rich´ard Farkas, Jennifer Foster, Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Yuval Marton, Joakim Nivre, Adam Przepi´orkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woliski, Alina Wr´oblewska, and Eric Villemonte de la Clergerie. 2013. Overview of the spmrl 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages. In Proceedings of the Fourth SPMRL Workshop, Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
<author>Nathan Srebro</author>
</authors>
<title>Pegasos: Primal estimated sub-gradient solver for SVM.</title>
<date>2007</date>
<booktitle>In Machine Learning, Proceedings of the Twenty-Fourth International Conference (ICML).</booktitle>
<contexts>
<context position="19935" citStr="Shalev-Shwartz et al., 2007" startWordPosition="3373" endWordPosition="3376">ight corner tokens. This allows us to encode the span models described in Section 5. We also use tuple-structured tokens encoding not only the word-form and the tag but also additional custom lexical features such as those enumerated in Figure 2 (right). This allows us to express the morphological models described in Section 5. Finally, the parameters w are estimated with a parallel averaged structured perceptron designed to cope with inexact inference (beam search): we specifically rely on max-violation updates of Huang et al. (2012) and on minibatches to accelerate and parallelize training (Shalev-Shwartz et al., 2007; Zhao and Huang, 2013). 5 Experiments The experiments aim to compare the contribution of span based features approximating some intuitions of Hall et al. (2014) for shift reduce parsing and morphological features for parsing free word order languages. We start by describing the evaluation protocol and by defining the models used. We use the standard SPMRL data set (Seddah et al., 2013). Part of speech tags are generated with Marmot (M¨uller et al., 2013), a CRF tagger specifically designed to provide tuple-structured tags. The training and development sets are tagged by 10-fold jackknifing. H</context>
</contexts>
<marker>Shalev-Shwartz, Singer, Srebro, 2007</marker>
<rawString>Shai Shalev-Shwartz, Yoram Singer, and Nathan Srebro. 2007. Pegasos: Primal estimated sub-gradient solver for SVM. In Machine Learning, Proceedings of the Twenty-Fourth International Conference (ICML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
<author>Dora Szauter</author>
<author>Attila Almasi</author>
<author>Gyorgy Mora</author>
<author>Zoltan Alexin</author>
<author>Janos Csirik</author>
</authors>
<title>Hungarian dependency treebank.</title>
<date>2010</date>
<booktitle>In Proceedings of Language Ressources and Evalutation Conference (LREC).</booktitle>
<contexts>
<context position="6038" citStr="Vincze et al., 2010" startWordPosition="925" endWordPosition="928"> to the Penn TreeBank using the Stanford conversion system to produce dependency annotations (de Marneffe et al., 2006). In this paper, we use both of these datasets. Although in multi-view treebanks each sentence is annotated both for constituency and dependency, they are not normalized for categories nor lexical features accross languages such as dependencies in the Google Universal Treebank (McDonald et al., 2013). What is more, the dependency and constituency structures may sometimes strongly differ. For some languages, like Hungarian, the conversion has involved some manual reannotation (Vincze et al., 2010). 3 Head annotation procedure Lexicalized phrase structure parsers traditionally use hand-crafted heuristics for head annotation (Collins, 2003). Although these heuristics are available for some languages, for others they are non existent or non explicit and typically hidden in conversion procedures. In order to leverage the burden of managing language specific heuristics, we first automate head annotation by taking advantage of the multi-view annotation. We begin by introducing some notation. Assuming a sentence W = wi ... wn, the dependency annotation of this sentence is assumed to be a depe</context>
</contexts>
<marker>Vincze, Szauter, Almasi, Mora, Alexin, Csirik, 2010</marker>
<rawString>Veronika Vincze, Dora Szauter, Attila Almasi, Gyorgy Mora, Zoltan Alexin, and Janos Csirik. 2010. Hungarian dependency treebank. In Proceedings of Language Ressources and Evalutation Conference (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Zhao</author>
<author>Liang Huang</author>
</authors>
<title>Minibatch and parallelization for online large margin structured learning.</title>
<date>2013</date>
<booktitle>In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics (NAACL-HLT).</booktitle>
<contexts>
<context position="19958" citStr="Zhao and Huang, 2013" startWordPosition="3377" endWordPosition="3380">ws us to encode the span models described in Section 5. We also use tuple-structured tokens encoding not only the word-form and the tag but also additional custom lexical features such as those enumerated in Figure 2 (right). This allows us to express the morphological models described in Section 5. Finally, the parameters w are estimated with a parallel averaged structured perceptron designed to cope with inexact inference (beam search): we specifically rely on max-violation updates of Huang et al. (2012) and on minibatches to accelerate and parallelize training (Shalev-Shwartz et al., 2007; Zhao and Huang, 2013). 5 Experiments The experiments aim to compare the contribution of span based features approximating some intuitions of Hall et al. (2014) for shift reduce parsing and morphological features for parsing free word order languages. We start by describing the evaluation protocol and by defining the models used. We use the standard SPMRL data set (Seddah et al., 2013). Part of speech tags are generated with Marmot (M¨uller et al., 2013), a CRF tagger specifically designed to provide tuple-structured tags. The training and development sets are tagged by 10-fold jackknifing. Head annotation is suppl</context>
</contexts>
<marker>Zhao, Huang, 2013</marker>
<rawString>Kai Zhao and Liang Huang. 2013. Minibatch and parallelization for online large margin structured learning. In Human Language Technologies: Conference of the North American Chapter of the Association of Computational Linguistics (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Muhua Zhu</author>
<author>Yue Zhang</author>
<author>Wenliang Chen</author>
<author>Min Zhang</author>
<author>Jingbo Zhu</author>
</authors>
<title>Fast and accurate shiftreduce constituent parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>(ACL).</location>
<contexts>
<context position="1441" citStr="Zhu et al. (2013)" startWordPosition="203" endWordPosition="206">iscriminative: discriminative models provide more flexibility for modelling a large number of variables and conveniently expressing their interactions. This trend is particularly striking if we consider the literature in dependency parsing. Most state of the art multilingual parsers are actually weighted by discriminative models (Nivre and Scholz, 2004; McDonald et al., 2005; Fern´andez-Gonz´alez and Martins, 2015). With respect to multilingual phrase structure parsing, the situation is quite different. Most parsers focus on fixed word order languages like English or Chinese as exemplified by Zhu et al. (2013). Despite a few exceptions (Collins et al., 1999), multilingual state of the art results are generally derived from the generative model of Petrov et al. (2006). Although more recently Hall et al. (2014) introduced a conditional random field parser that clearly improved the state of the art in the multilingual setting. Both Petrov et al. (2006) and Hall et al. (2014) frame their parsing model to model in priority regular surfacic patterns and word order: Petrov et al. (2006) crucially infers category refinements (called category ‘splits‘) in order to specialize the grammar on recurrent informa</context>
<context position="13576" citStr="Zhu et al., 2013" startWordPosition="2261" endWordPosition="2264">ituent structures that are not directly inferrable from the dependency annotation. Polish uses this restructuration in patterns involving coordination. More surprisingly, non projective patterns, which we expected to be a significant feature of these languages, remain marginal in comparison to annotation related idiosyncrasic problems. 4 Parsing algorithm This section provides an overview of the design of the constituent parsing system. There are three recent proposals for beam-based discriminative shift reduce parsing for phrase structure grammar with a structured perceptron and beam search (Zhu et al., 2013; Crabb´e, 2014; Mi and Huang, 2015). All three proposals point out that for weighted phrase structure parsing, the shift reduce algorithm requires a special treatment of unary rules in order to compare derivations of the same length. They all provide different management schemes for these unaries. The work described here draws on the LR algorithm introduced by Crabb´e (2014), but provides a simpler algorithm, it precisely describes the management of unary rules and clarifies how spans and morphological information is represented (see section 5 ). 2The constituency conversion of the Basque tre</context>
<context position="21050" citStr="Zhu et al. (2013)" startWordPosition="3560" endWordPosition="3563"> provide tuple-structured tags. The training and development sets are tagged by 10-fold jackknifing. Head annotation is supplied by the Robust procedure described in Section 3. The parser is systematically trained for 25 epochs with a max violation update perceptron, a beam of size 8 and a minibatch size of 24. 1851 To enable a comparison with other published results, the evaluation is performed with a version of evalb provided by the SPMRL organizers (Seddah et al., 2013) which takes punctuation into account. Baseline model (B) The baseline model uses a set of templates identical to those of Zhu et al. (2013) for parsing English and Chinese except that we have no specific templates for unary reductions. Span-based model (B+S) This model extends the B model by modeling spans. The span model approximates an intuition underlying Hall et al. (2014): constituent boundaries contain very informative tokens (typically function words). These tokens together with the pattern of their neighborhood provide key clues for detecting and (sub)typing constituents. Moreover, parameter estimation for frequent functional words should suffer less from data sparseness issues than the estimation of bilexical dependencie</context>
</contexts>
<marker>Zhu, Zhang, Chen, Zhang, Zhu, 2013</marker>
<rawString>Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. 2013. Fast and accurate shiftreduce constituent parsing. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, (ACL).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>