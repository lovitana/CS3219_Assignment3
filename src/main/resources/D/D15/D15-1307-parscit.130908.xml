<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003527">
<title confidence="0.988609">
Detection of Steganographic Techniques on Twitter
</title>
<author confidence="0.994555">
Alex Wilson and Phil Blunsom and Andrew D. Ker
</author>
<affiliation confidence="0.997772">
Department of Computer Science
University of Oxford
</affiliation>
<address confidence="0.996977">
Oxford, OX1 3QD, UK
</address>
<email confidence="0.999766">
{alex.wilson,phil.blunsom,andrew.ker}@cs.ox.ac.uk
</email>
<sectionHeader confidence="0.997402" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999740666666667">
We propose a method to detect hidden data
in English text. We target a system pre-
viously thought secure, which hides mes-
sages in tweets. The method brings ideas
from image steganalysis into the linguis-
tic domain, including the training of a
feature-rich model for detection. To iden-
tify Twitter users guilty of steganography,
we aggregate evidence; a first, in any do-
main. We test our system on a set of 1M
steganographic tweets, and show it to be
effective.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999914428571429">
Consider this: two isolated prisoners, communi-
cating by letters scrutinised by the prison warden.
They cannot write openly about escape plots, and
the warden destroys any written in code. They
must hide the true message within the letter, us-
ing steganography: the art of hiding information.
In cover modification1steganography, a cover
object is tweaked so that it carries a hidden mes-
sage: this is called embedding, the tweaked ver-
sion is the stego object, and the message is the pay-
load (Fridrich, 2009). The message should not be
detectable to any observer (the standard terminol-
ogy for this is the warden, taken from the prisoner
metaphor) who knows the system is deployed, but
does not know the original cover.
We are concerned here with linguistic steganog-
raphy, in which the cover is a piece of text, and
the message is embedded using textual transfor-
mations intended to preserve the meaning of the
original: synonym substitutions, syntactical trans-
formations, etc. Note that we are not concerned
</bodyText>
<footnote confidence="0.626235">
1There are other steganographic paradigms, not in scope.
Translation based methods hide information in the automatic
translation of the cover (e.g. Meng et al. (2011)). Cover gen-
eration methods automatically produce text containing the
payload (e.g. Chapman et al. (2001)).
</footnote>
<bodyText confidence="0.999811771428571">
with the subset of linguistic steganography that
hides in file formatting (e.g. white space, as in
Por et al. (2008)), which has no security against an
informed warden (in the case of hiding informa-
tion by adding extraneous white space, the warden
simply has to look for consistent irregular use of
spaces to spot an active steganographer).
The field suffers from a number of issues: com-
pared to images, text covers have low capac-
ity (Chang and Clark, 2010); certain methods
are weak against human attackers (Grosvald and
Orgun, 2011) (most paraphrase systems cannot
guarantee perfectly fluent stego objects); finally,
authors are generally concerned with the perfor-
mance of the transformation (whether they pro-
duce grammatically/semantically correct transfor-
mations), rather than whether the generated stego
objects are detectable or not (e.g. Chang and Clark
(2010)).
However, there is a new challenger in the field.
We proposed a new linguistic stegosystem (Wilson
et al., 2014) and verified its security against hu-
man judges, who were unable to distinguish gen-
uine covers from manipulated stego objects.
This paper aims to attack CoverTweet statisti-
cally. We are in the shoes of the warden, attempt-
ing to classify stego objects from innocent2cover
objects. We propose techniques new to linguis-
tic steganalysis, including a large set of features
that detect unusual and inconsistent use of lan-
guage and the aggregation of evidence from mul-
tiple sentences. This last development, known in
the steganographic literature as pooled steganaly-
sis (Ker, 2007), represents a first in both linguistic
and image steganalysis.
</bodyText>
<footnote confidence="0.9999088">
2It is usual to call steganographers and their output
‘guilty’ (with non-steganographers and unchanged cover ob-
jects being ‘innocent’). This has the possibility of seeming
politically charged, so we will use the term ‘active’ instead:
be aware that this is not the usual terminology.
</footnote>
<page confidence="0.836911">
2564
</page>
<note confidence="0.864282">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2564–2569,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<sectionHeader confidence="0.957831" genericHeader="introduction">
2 Linguistic Stegosystems
</sectionHeader>
<bodyText confidence="0.999984431818182">
T-Lex (Winstein, 1998) is the oldest available
cover-modification based linguistic stegosystem.
It uses a dictionary containing a small number
of disjoint synonym sets extracted from Word-
Net (Miller, 1995). Each set is unambiguously or-
dered (e.g. alphabetically), then values are embed-
ded by changing cover words for their synonyms.
Due to the the small dictionary, the capacity of
covers is only ∼ 0.1 bits per sentence.
CoverTweet is a modern evolution of T-Lex.
It hides information in tweets by applying para-
phrase rules taken from the Paraphrase Database
(PPDB) (Ganitkevitch et al., 2013), a set of 169M
rules. The system applies suitable rules to a given
cover, generating a set of possible stego objects.
These are ranked by a distortion measure (derived
from the probabilities of applied rules and from
sentence probabilities given by a language model),
and assigned a keyed hash. A human operator fil-
ters the options for fluency, and chooses the best
stego object with the desired hash.
CoverTweet uses a subset of the PPDB, re-
stricted to lexical and phrasal substitutions. Even
with the reduced set of rules, 4 bits can be embed-
ded per tweet, and it was proven secure against
human judges (Wilson et al., 2014).
Twitter is a realistic setting for steganography.
There is precedent for information hiding and
mass monitoring on micro-blogging sites, such as
the use of code words and government censorship
on the Chinese website Sina Weibo (Chen et al.,
2013). For this reason, we are attacking this set-
ting.
There are many other linguistic stegosystems,
using an array of different hiding methods (e.g.
adjective deletion, word order, anaphora reso-
lution: (Chang and Clark, 2012a), (Chang and
Clark, 2012b), (Vybornova and Macq, 2007)).
Approximately 1 bit of payload per cover sentence
is usual, making CoverTweet the exception. Un-
fortunately for steganalysis literature, the vast ma-
jority of these require data that is unavailable (and
too expensive to reproduce); beyond CoverTweet,
the only system that can be evaluated is T-Lex.
</bodyText>
<sectionHeader confidence="0.999974" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.999989571428572">
To our knowledge, there have been only five prior
attempts at linguistic steganalysis on cover mod-
ification based systems; of these, four attack T-
Lex, the other attacks an equivalent proprietary
system. Taskiran et al. (2006) was the first, us-
ing n-gram language models to extract features
from stego text, before training a support vector
machine (SVM) on the features. We will adopt
some of these features for our attack.
Subsequent work (Xin-guang et al. (2006); Yu
et al. (2009); Chen et al. (2011); Xiang et al.
(2014)) has used smaller models: they have all de-
signed a single feature to exploit a weakness, and
used this (or the mean and variance of it) to train a
classifier for attack. Analysis of results, especially
the effect of embedding rate on detection, has been
lacking or non-existent. This focus on individual
features echoes the early work on image steganal-
ysis, which has since shifted towards feature-rich
models. We will be utilising the latter here, in ad-
dition to the pooled steganalysis paradigm.
</bodyText>
<sectionHeader confidence="0.992944" genericHeader="method">
4 Proposed features
</sectionHeader>
<bodyText confidence="0.999969966666667">
Below we describe four classes of proposed fea-
tures for individual tweets. Each class will be eval-
uated individually, and in combination.
Basic features Including: word count (includ-
ing tokenised punctuation); the mean and variance
of the number of characters in each word; the total
stop word count3; and the counts for each individ-
ual stop word. (131 features)
n-gram features Using a 5-gram model, for n
from 1 to 5, the mean, variance and total log like-
lihood of the n-grams in the tweet. (15 features)
Word length Equivalent to the n-gram features,
using a 10-gram model of word length. We expect
the PPDB to replace common words with uncom-
mon longer words, or multiple shorter words. (30
features)
PPDB features Kerckhoffs’ principle (Fridrich,
2009), which states that a stegosystem must be se-
cure even when the attacker (us) knows how the
system works, introduces an interesting opportu-
nity for linguistic steganalysis. As all linguistic
stegosystems rely on automatic paraphrasing, and
generally require a source of data, it is conserva-
tive to assume that the attacker has access to this
data source. As the attacker, we can derive fea-
tures from this data.
Applying this, we extracted features using the
same subset of the PPDB that CoverTweet uses.
To our knowledge, this is the first work to ex-
plicitly apply Kerckhoffs’ principle to linguistic
</bodyText>
<footnote confidence="0.5106335">
3We use the Natural Language Toolkit (Bird, 2006) for
the list of 127 stop words.
</footnote>
<page confidence="0.943388">
2565
</page>
<bodyText confidence="0.999978">
steganalysis. This set includes: a repeat of the
n-gram features, but only taking into account
n-grams that contain at least one word in4 the
PPDB; the mean and variance of character count
for words in the PPDB; for phrase lengths j from
1 to 5, the proportion of j-grams in the tweet that
are in the PPDB; likelihood of the most proba-
ble paraphrased sentence, extracted by generating
sentences in the same way as CoverTweet. Finally,
a substitution score: each word or phrase in the
PPDB is replaced by its most likely substitute, ac-
cording to the language model. The max, min,
mean and variance of the log likelihoods for the
resulting sentences are used. (27 features)
</bodyText>
<subsectionHeader confidence="0.997523">
4.1 Pooling the features
</subsectionHeader>
<bodyText confidence="0.999948388888889">
Individual linguistic stego objects carry a tiny pay-
load, making detection an incredibly difficult task.
In some cases, the stego tweet will be identical to
the cover, making the task impossible. Although
we do not hope to reliably identify stego tweets
individually, the warden can still try to catch the
active steganographers: through pooled steganal-
ysis (Ker, 2007). Here, the warden considers all
the evidence for each user, and aims to identify
those actively using steganography. We combine
features from batches of tweets, by the same user:
taking the max, min, mean and variance of each
feature. If performing steganography causes small
consistent changes to a feature, this will be appar-
ent in the mean. If it causes inconsistent changes,
it may be apparent in the variance. If it occasion-
ally produces an extreme result, the max and min
will capture this. (812 features)
</bodyText>
<sectionHeader confidence="0.966869" genericHeader="method">
5 Method and Results
</sectionHeader>
<bodyText confidence="0.999961">
Here we take the role of an automatic censor, at-
tempting to identify users on Twitter who are send-
ing secret messages. We imagine a scenario where
CoverTweet is openly available, and so can as-
sume this is the system utilised by the active users.
</bodyText>
<subsectionHeader confidence="0.907159">
5.1 Data and Embedding
</subsectionHeader>
<bodyText confidence="0.7689128">
From the Harvard TweetMap (Mostak, 2013),
we gathered 72M English language tweets, from
1.2M users. Each tweet was canonicalised as fol-
lows: tokenised; made lowercase; usernames re-
placed by a uniform token; URLs replaced by a
</bodyText>
<footnote confidence="0.98322">
4Where we say a word or phrase is ‘in’ the PPDB, we
mean it features in one or more paraphrase rules that could
have been applied to the original tweet.
</footnote>
<bodyText confidence="0.999740098039216">
uniform token. We randomly selected 1000 users
with 1000-2000 tweets to train and test a classifier.
On the remaining tweets, we trained a 10-gram
word length model, and a 5-gram language model,
using SRILM (Stolcke, 2002) with Kneyser-Ney
smoothing. For vocabulary, the language model
was given every word in the PPDB, and every
word in the set of tweets, including the removed
tweets. We do not expect this to provide an unre-
alistic advantage to the censor: any word not in the
PPDB cannot hide information.
We randomly took 10 users from the set of
1000, and produced 100 stego tweets for each, for
three payload sizes: 1, 2 and 4 bits. The stego
tweets were generated using CoverTweet, with a
human operator selecting the most fluent option
containing a desired (randomly generated) pay-
load. If there were no fluent options, the tweet was
skipped. If the tweet already contained the desired
payload (if the hash value of the tweet already
matched the message), it was left unchanged. We
refer to this data as Manual CoverTweet (M-CT).
Due to the expensive nature of generating data
with a human judge, and to assess the value of
the human in-the-loop, we also automatically gen-
erated 1M stego tweets, by embedding data in
1000 tweets for each of the 1000 users. The same
three payload sizes were used. Here, the tweet
with the highest probability (provided by the lan-
guage model and the PPDB) was selected. Again,
the tweet was left unchanged if the tweet already
contained the desired payload. Tweets were only
skipped if there were no options with the correct
payload. We refer to this as Automatic Cover-
Tweet (A-CT). Finally, we embedded 1 bit in the
same tweets using T-Lex, rejecting any that con-
tained no words in the T-Lex dictionary; the result
was approximately 100 tweets on average per user.
We split the users in half, training a linear
ensemble classifier (Kodovsk`y et al., 2012) (de-
signed to work with large feature sets for steganal-
ysis) on feature instances from one half, testing it
on the other. We only classified tweets by users for
whom the classifier had no prior knowledge. All
error rates are averaged over 10 different random
user splits. For the M-CT data, where we have a
much smaller set of data, we performed 10-fold
cross validation, leaving one user out for testing
each fold.
In each experiment we matched training and
testing data: the training data was produced by the
</bodyText>
<page confidence="0.994268">
2566
</page>
<figureCaption confidence="0.993448">
Figure 1: ROCs for each embedding method, for
individual tweets or batches containing 1 bit.
</figureCaption>
<table confidence="0.9858706">
Batch size AUC
A-CT 1 0.551
M-CT 1 0.509
T-Lex 1 0.667
A-CT 100 0.9631
</table>
<tableCaption confidence="0.8742975">
Table 1: AUC values for the ROCs shown in Fig-
ure 1
</tableCaption>
<bodyText confidence="0.999810666666667">
same method as the testing data. For M-CT we
tried an alternative scheme, by training on A-CT
data, but testing on M-CT; this did not work reli-
ably, and the accuracy of the resulting model went
down as pooled batch size increased. The explo-
ration of this phenomenon is left for later work.
</bodyText>
<subsectionHeader confidence="0.999082">
5.2 A note on unchangeable covers
</subsectionHeader>
<bodyText confidence="0.996339384615385">
Some tweets cannot hide the payload, either when
there are no paraphrase options for that hash, or
when the human (for M-CT) vetoes all the op-
tions. This is the non-shared selection channel
problem in steganography. Methods such as syn-
drome trellis codes (Filler et al., 2011) allow the
unchangeable cover elements to be sent without
compromising the message. These have not been
applied to linguistic steganography, but we simu-
late their use: we remove the unchangeable tweets
from the cover and stego sets, essentially giving
the steganographer and detector the ability to ig-
nore such tweets.
</bodyText>
<figureCaption confidence="0.862701666666667">
Figure 2: The effect of batch size on error rate.
Batches of 100 are the maximum for M-CT and
T-Lex, but we go up to 1000 with A-CT.
</figureCaption>
<sectionHeader confidence="0.527444" genericHeader="evaluation">
5.3 Results
</sectionHeader>
<bodyText confidence="0.999647064516129">
As expected, the performance of the classifiers
trained on individual tweets is poor (see Figure 1).
In particular, the models trained on A-CT and M-
CT data have very low accuracy on data with 1 bit
payload, performing only slightly better than ran-
dom guessing. T-Lex tweets prove slightly easier
to detect. This does not mean that the systems are
secure however. Though we cannot identify in-
dividual stego tweets, when we pool evidence we
find we are able to train a model that can identify
active users with high accuracy, for all data sets.
Figure 2 shows the change in error rate as the
batch size (the number of tweets we pool) is in-
creased. We can clearly see that increasing batch
size improves accuracy. We also see that in-
creasing payload size makes active users easier to
spot. This is unsurprising: CoverTweet is forced
to choose from fewer options when payload in-
creases.
The experiment showed us that M-CT is the
most secure stegosystem, though not immune to
the effects of pooling. When combining features
from 100 tweets, the classifier had an error rate
of 0.21 on 4 bit M-CT data; data generated in the
same way, with the same payload, was previously
shown to be secure against human judges. With
large batches, detection of A-CT is almost perfect.
To establish which class of features had the
biggest effect on detection, we trained models on
each combination of features described in Sec-
tion 4. A subset of these combinations are shown
</bodyText>
<figure confidence="0.998013892857143">
0.0 0.2 0.4 0.6 0.8 1.0
False positive rate
True positive rate
0.8
0.6
0.4
0.0
0.2
1.0
A-CT
M-CT
T-Lex
Individual
Batch of 100
0.5
A-CT
M-CT
T-Lex
1 bit
2 bits
4 bits
0.3
0.2
0.1
0.0100 101 102 103
Batch size
Error rate
0.4
</figure>
<page confidence="0.64094">
2567
</page>
<table confidence="0.701575">
b n p w b+n n+p p+w b+n+p p+n+c all
A-CT (2 bits) 0.345 0.311 0.217 0.376 0.266 0.204 0.203 0.180 0.191 0.169
T-Lex (1 bit) 0.448 0.226 0.273 0.317 0.226 0.202 0.218 0.198 0.168 0.168
</table>
<tableCaption confidence="0.94904">
Table 2: Error rates for models trained on different combinations of feature class, for a batch of 10. The
</tableCaption>
<bodyText confidence="0.985323814814815">
feature sets are as follows: basic (b), n-gram (n), PPDB (p) and word length (w).
in Table 2, for A-CT and T-Lex.We can see that for
A-CT, the PPDB features easily outperform oth-
ers, with an error rate of 0.217 when used alone;
the warden’s knowledge of the system is power-
ful. The second best is the n-gram set, though it
performs better on T-Lex than on A-CT. This is
most likely due to CoverTweet’s use of the lan-
guage model in the embedding stage: the system
is attempting to minimise the distortion that these
features are looking for. T-Lex has no such distor-
tion measure, leaving it open to this sort of attack.
Basic and PPDB feature sets fare worse on T-
Lex. The basic features are aimed at changes in
word count and stop word usage: neither of these
are affected by T-Lex substitutions. The PPDB
features are at a disadvantage with T-Lex, as they
are designed for CoverTweet. If T-Lex’s data
source were used instead of CoverTweet’s, the per-
formance would likely improve significantly.
The combination of PPDB and n-gram features
on T-Lex gives us some interesting insight: despite
the mismatch of substitution source, we still see
an improvement over the n-gram features used on
their own. This suggests that the warden does not
need the exact data source as the steganographer
for these features to be useful.
</bodyText>
<sectionHeader confidence="0.996904" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.998809342857143">
It was believed that linguistic steganography was
weak against humans, but CoverTweet disproved
it. We have shown that individual stego objects are
seemingly also strong against statistical attacks.
However, by pooling multiple pieces of evidence
against a user, the warden can drastically improve
detection rate. With each steganographic tweet
sent, the user creeps closer to being caught. This
is the first steganalytic classifier, in any domain,
that successfully exploits pooled evidence. The
design of steganographic systems must now take
this type of attacker into account. It would inter-
esting to determine whether human judges are ca-
pable of pooling large amounts of scant evidence:
we conjecture not.
Results suggest that detection is improved by
utilising rich-feature models; we only scratched
the surface with regards to this. There are many
avenues to explore, such as using multiple lan-
guage models from which to extract features (this
is the analogue of filter banks used in contempo-
rary image steganalysis (Fridrich and Kodovsk`y,
2012)).
The security of a system should first be mea-
sured against a powerful (informed) attacker. We
played this role by using features extracted using
exact knowledge of the CoverTweet system (the
PPDB features); this class of features was partic-
ularly effective against CoverTweet. The system
should now be evaluated against a weaker attacker.
We have seen that detection is still reliable when
the warden knows the wrong system (T-Lex), but
further experiments are required to determine ex-
actly how detection rate is affected by mismatches
in paraphrase sources, or language model.
</bodyText>
<sectionHeader confidence="0.99913" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999015875">
Steven Bird. 2006. NLTK: the natural language
toolkit. In Proceedings of the COLING/ACL on In-
teractive presentation sessions, pages 69–72. Asso-
ciation for Computational Linguistics.
Ching-Yun Chang and Stephen Clark. 2010. Lin-
guistic steganography using automatically generated
paraphrases. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 591–599. Association for Computa-
tional Linguistics.
Ching-Yun Chang and Stephen Clark. 2012a. Adjec-
tive deletion for linguistic steganography and secret
sharing. In COLING, pages 493–510.
Ching-Yun Chang and Stephen Clark. 2012b. The se-
cret’s in the word order: Text-to-text generation for
linguistic steganography. In COLING, pages 511–
528.
Mark Chapman, George I Davida, and Marc Rennhard.
2001. A practical and effective approach to large-
scale automated linguistic steganography. In Infor-
mation Security, pages 156–165. Springer.
Zhili Chen, Liusheng Huang, Haibo Miao, Wei Yang,
and Peng Meng. 2011. Steganalysis against
</reference>
<page confidence="0.993879">
2568
</page>
<bodyText confidence="0.925287">
substitution-based linguistic steganography based
on context clusters. Computers &amp; Electrical Engi-
neering, 37(6):1071–1081.
Le Chen, Chi Zhang, and Christo Wilson. 2013.
Tweeting under pressure: analyzing trending topics
and evolving word choice on sina weibo. In Pro-
ceedings of the first ACM conference on Online so-
cial networks, pages 89–100. ACM.
</bodyText>
<reference confidence="0.993881246575343">
Tom´aˇs Filler, Jan Judas, and Jessica Fridrich. 2011.
Minimizing additive distortion in steganography us-
ing syndrome-trellis codes. Information Forensics
and Security, IEEE Transactions on, 6(3):920–935.
Jessica Fridrich and Jan Kodovsk`y. 2012. Rich mod-
els for steganalysis of digital images. Informa-
tion Forensics and Security, IEEE Transactions on,
7(3):868–882.
Jessica Fridrich. 2009. Steganography in digital me-
dia: principles, algorithms, and applications. Cam-
bridge University Press.
Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In HLT-NAACL, pages 758–764.
Michael Grosvald and C Orhan Orgun. 2011. Free
from the cover text: a human-generated natural lan-
guage approach to text-based steganography. Jour-
nal of Information Hiding and Multimedia Signal
Processing, 2(2):133–141.
Andrew D Ker. 2007. Batch steganography and pooled
steganalysis. In Information Hiding, pages 265–
281. Springer.
Jan Kodovsk`y, Jessica Fridrich, and Vojtˇech Holub.
2012. Ensemble classifiers for steganalysis of digi-
tal media. Information Forensics and Security, IEEE
Transactions on, 7(2):432–444.
Peng Meng, Yun-Qing Shi, Liusheng Huang, Zhili
Chen, Wei Yang, and Abdelrahman Desoky. 2011.
Linl: Lost in n-best list. In Information Hiding,
pages 329–341. Springer.
George A. Miller. 1995. Wordnet: A lexical database
for english. COMMUNICATIONS OF THE ACM,
38:39–41.
Todd Mostak. 2013. Harvard TweetMap. accessed Oc-
tober 2013. https://worldmap.harvard.
edu/.
Lip Y Por, TF Ang, and B Delina. 2008. Whitesteg:
a new scheme in information hiding using text
steganography. WSEAS Transactions on Computers,
7(6):735–745.
Andreas Stolcke. 2002. SRILM - an extensible lan-
guage modeling toolkit. pages 901–904.
Cuneyt M Taskiran, Umut Topkara, Mercan Topkara,
and Edward J Delp. 2006. Attacks on lexical natu-
ral language steganography systems. In IS&amp;T/SPIE
Electronic Imaging, pages 120–129. International
Society for Optics and Photonics.
Olga Vybornova and Benoit Macq. 2007. Natural
language watermarking and robust hashing based
on presuppositional analysis. In Information Reuse
and Integration, 2007. IRI 2007. IEEE International
Conference on, pages 177–182. IEEE.
Alex Wilson, Phil Blunsom, and Andrew D Ker. 2014.
Linguistic steganography on twitter: hierarchical
language modeling with manual interaction. In
IS&amp;T/SPIE Electronic Imaging, pages 201–217. In-
ternational Society for Optics and Photonics.
Keith Winstein. 1998. Lexical steganography through
adaptive modulation of the word choice hash.
http://www.imsa.edu/˜keithw/tlex.
Unpublished.
Lingyun Xiang, Xingming Sun, Gang Luo, and Bin
Xia. 2014. Linguistic steganalysis using the fea-
tures derived from synonym frequency. Multimedia
tools and applications, 71(3):1893–1911.
Sui Xin-guang, Luo Hui, and Zhu Zhong-liang. 2006.
A steganalysis method based on the distribution of
characters. In Signal Processing, 2006 8th Interna-
tional Conference on, volume 4, pages 54–56. IEEE.
Zhenshan Yu, Liusheng Huang, Zhili Chen, Lingjun Li,
Xinxin Zhao, and Youwen Zhu. 2009. Steganalysis
of synonym-substitution based natural language wa-
termarking.
</reference>
<page confidence="0.993675">
2569
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.635395">
<title confidence="0.990534">Detection of Steganographic Techniques on Twitter</title>
<author confidence="0.957863">Wilson Blunsom D</author>
<affiliation confidence="0.9982155">Department of Computer University of</affiliation>
<address confidence="0.719613">Oxford, OX1 3QD,</address>
<abstract confidence="0.994054461538462">We propose a method to detect hidden data in English text. We target a system previously thought secure, which hides messages in tweets. The method brings ideas from image steganalysis into the linguistic domain, including the training of a feature-rich model for detection. To identify Twitter users guilty of steganography, we aggregate evidence; a first, in any domain. We test our system on a set of 1M steganographic tweets, and show it to be effective.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bird</author>
</authors>
<title>NLTK: the natural language toolkit.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Interactive presentation sessions,</booktitle>
<pages>69--72</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8616" citStr="Bird, 2006" startWordPosition="1378" endWordPosition="1379"> be secure even when the attacker (us) knows how the system works, introduces an interesting opportunity for linguistic steganalysis. As all linguistic stegosystems rely on automatic paraphrasing, and generally require a source of data, it is conservative to assume that the attacker has access to this data source. As the attacker, we can derive features from this data. Applying this, we extracted features using the same subset of the PPDB that CoverTweet uses. To our knowledge, this is the first work to explicitly apply Kerckhoffs’ principle to linguistic 3We use the Natural Language Toolkit (Bird, 2006) for the list of 127 stop words. 2565 steganalysis. This set includes: a repeat of the n-gram features, but only taking into account n-grams that contain at least one word in4 the PPDB; the mean and variance of character count for words in the PPDB; for phrase lengths j from 1 to 5, the proportion of j-grams in the tweet that are in the PPDB; likelihood of the most probable paraphrased sentence, extracted by generating sentences in the same way as CoverTweet. Finally, a substitution score: each word or phrase in the PPDB is replaced by its most likely substitute, according to the language mode</context>
</contexts>
<marker>Bird, 2006</marker>
<rawString>Steven Bird. 2006. NLTK: the natural language toolkit. In Proceedings of the COLING/ACL on Interactive presentation sessions, pages 69–72. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ching-Yun Chang</author>
<author>Stephen Clark</author>
</authors>
<title>Linguistic steganography using automatically generated paraphrases.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>591--599</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2437" citStr="Chang and Clark, 2010" startWordPosition="390" endWordPosition="393">tomatic translation of the cover (e.g. Meng et al. (2011)). Cover generation methods automatically produce text containing the payload (e.g. Chapman et al. (2001)). with the subset of linguistic steganography that hides in file formatting (e.g. white space, as in Por et al. (2008)), which has no security against an informed warden (in the case of hiding information by adding extraneous white space, the warden simply has to look for consistent irregular use of spaces to spot an active steganographer). The field suffers from a number of issues: compared to images, text covers have low capacity (Chang and Clark, 2010); certain methods are weak against human attackers (Grosvald and Orgun, 2011) (most paraphrase systems cannot guarantee perfectly fluent stego objects); finally, authors are generally concerned with the performance of the transformation (whether they produce grammatically/semantically correct transformations), rather than whether the generated stego objects are detectable or not (e.g. Chang and Clark (2010)). However, there is a new challenger in the field. We proposed a new linguistic stegosystem (Wilson et al., 2014) and verified its security against human judges, who were unable to distingu</context>
</contexts>
<marker>Chang, Clark, 2010</marker>
<rawString>Ching-Yun Chang and Stephen Clark. 2010. Linguistic steganography using automatically generated paraphrases. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 591–599. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ching-Yun Chang</author>
<author>Stephen Clark</author>
</authors>
<title>Adjective deletion for linguistic steganography and secret sharing.</title>
<date>2012</date>
<booktitle>In COLING,</booktitle>
<pages>493--510</pages>
<contexts>
<context position="5798" citStr="Chang and Clark, 2012" startWordPosition="912" endWordPosition="915"> substitutions. Even with the reduced set of rules, 4 bits can be embedded per tweet, and it was proven secure against human judges (Wilson et al., 2014). Twitter is a realistic setting for steganography. There is precedent for information hiding and mass monitoring on micro-blogging sites, such as the use of code words and government censorship on the Chinese website Sina Weibo (Chen et al., 2013). For this reason, we are attacking this setting. There are many other linguistic stegosystems, using an array of different hiding methods (e.g. adjective deletion, word order, anaphora resolution: (Chang and Clark, 2012a), (Chang and Clark, 2012b), (Vybornova and Macq, 2007)). Approximately 1 bit of payload per cover sentence is usual, making CoverTweet the exception. Unfortunately for steganalysis literature, the vast majority of these require data that is unavailable (and too expensive to reproduce); beyond CoverTweet, the only system that can be evaluated is T-Lex. 3 Related Work To our knowledge, there have been only five prior attempts at linguistic steganalysis on cover modification based systems; of these, four attack TLex, the other attacks an equivalent proprietary system. Taskiran et al. (2006) was</context>
</contexts>
<marker>Chang, Clark, 2012</marker>
<rawString>Ching-Yun Chang and Stephen Clark. 2012a. Adjective deletion for linguistic steganography and secret sharing. In COLING, pages 493–510.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ching-Yun Chang</author>
<author>Stephen Clark</author>
</authors>
<title>The secret’s in the word order: Text-to-text generation for linguistic steganography. In</title>
<date>2012</date>
<booktitle>COLING,</booktitle>
<pages>511--528</pages>
<contexts>
<context position="5798" citStr="Chang and Clark, 2012" startWordPosition="912" endWordPosition="915"> substitutions. Even with the reduced set of rules, 4 bits can be embedded per tweet, and it was proven secure against human judges (Wilson et al., 2014). Twitter is a realistic setting for steganography. There is precedent for information hiding and mass monitoring on micro-blogging sites, such as the use of code words and government censorship on the Chinese website Sina Weibo (Chen et al., 2013). For this reason, we are attacking this setting. There are many other linguistic stegosystems, using an array of different hiding methods (e.g. adjective deletion, word order, anaphora resolution: (Chang and Clark, 2012a), (Chang and Clark, 2012b), (Vybornova and Macq, 2007)). Approximately 1 bit of payload per cover sentence is usual, making CoverTweet the exception. Unfortunately for steganalysis literature, the vast majority of these require data that is unavailable (and too expensive to reproduce); beyond CoverTweet, the only system that can be evaluated is T-Lex. 3 Related Work To our knowledge, there have been only five prior attempts at linguistic steganalysis on cover modification based systems; of these, four attack TLex, the other attacks an equivalent proprietary system. Taskiran et al. (2006) was</context>
</contexts>
<marker>Chang, Clark, 2012</marker>
<rawString>Ching-Yun Chang and Stephen Clark. 2012b. The secret’s in the word order: Text-to-text generation for linguistic steganography. In COLING, pages 511– 528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Chapman</author>
<author>George I Davida</author>
<author>Marc Rennhard</author>
</authors>
<title>A practical and effective approach to largescale automated linguistic steganography.</title>
<date>2001</date>
<booktitle>In Information Security,</booktitle>
<pages>156--165</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1977" citStr="Chapman et al. (2001)" startWordPosition="311" endWordPosition="314">the system is deployed, but does not know the original cover. We are concerned here with linguistic steganography, in which the cover is a piece of text, and the message is embedded using textual transformations intended to preserve the meaning of the original: synonym substitutions, syntactical transformations, etc. Note that we are not concerned 1There are other steganographic paradigms, not in scope. Translation based methods hide information in the automatic translation of the cover (e.g. Meng et al. (2011)). Cover generation methods automatically produce text containing the payload (e.g. Chapman et al. (2001)). with the subset of linguistic steganography that hides in file formatting (e.g. white space, as in Por et al. (2008)), which has no security against an informed warden (in the case of hiding information by adding extraneous white space, the warden simply has to look for consistent irregular use of spaces to spot an active steganographer). The field suffers from a number of issues: compared to images, text covers have low capacity (Chang and Clark, 2010); certain methods are weak against human attackers (Grosvald and Orgun, 2011) (most paraphrase systems cannot guarantee perfectly fluent ste</context>
</contexts>
<marker>Chapman, Davida, Rennhard, 2001</marker>
<rawString>Mark Chapman, George I Davida, and Marc Rennhard. 2001. A practical and effective approach to largescale automated linguistic steganography. In Information Security, pages 156–165. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhili Chen</author>
<author>Liusheng Huang</author>
<author>Haibo Miao</author>
<author>Wei Yang</author>
<author>Peng Meng</author>
</authors>
<date>2011</date>
<note>Steganalysis against</note>
<contexts>
<context position="6671" citStr="Chen et al. (2011)" startWordPosition="1053" endWordPosition="1056">(and too expensive to reproduce); beyond CoverTweet, the only system that can be evaluated is T-Lex. 3 Related Work To our knowledge, there have been only five prior attempts at linguistic steganalysis on cover modification based systems; of these, four attack TLex, the other attacks an equivalent proprietary system. Taskiran et al. (2006) was the first, using n-gram language models to extract features from stego text, before training a support vector machine (SVM) on the features. We will adopt some of these features for our attack. Subsequent work (Xin-guang et al. (2006); Yu et al. (2009); Chen et al. (2011); Xiang et al. (2014)) has used smaller models: they have all designed a single feature to exploit a weakness, and used this (or the mean and variance of it) to train a classifier for attack. Analysis of results, especially the effect of embedding rate on detection, has been lacking or non-existent. This focus on individual features echoes the early work on image steganalysis, which has since shifted towards feature-rich models. We will be utilising the latter here, in addition to the pooled steganalysis paradigm. 4 Proposed features Below we describe four classes of proposed features for indi</context>
</contexts>
<marker>Chen, Huang, Miao, Yang, Meng, 2011</marker>
<rawString>Zhili Chen, Liusheng Huang, Haibo Miao, Wei Yang, and Peng Meng. 2011. Steganalysis against</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom´aˇs Filler</author>
<author>Jan Judas</author>
<author>Jessica Fridrich</author>
</authors>
<title>Minimizing additive distortion in steganography using syndrome-trellis codes. Information Forensics and Security,</title>
<date>2011</date>
<journal>IEEE Transactions on,</journal>
<volume>6</volume>
<issue>3</issue>
<contexts>
<context position="14130" citStr="Filler et al., 2011" startWordPosition="2332" endWordPosition="2335">s shown in Figure 1 same method as the testing data. For M-CT we tried an alternative scheme, by training on A-CT data, but testing on M-CT; this did not work reliably, and the accuracy of the resulting model went down as pooled batch size increased. The exploration of this phenomenon is left for later work. 5.2 A note on unchangeable covers Some tweets cannot hide the payload, either when there are no paraphrase options for that hash, or when the human (for M-CT) vetoes all the options. This is the non-shared selection channel problem in steganography. Methods such as syndrome trellis codes (Filler et al., 2011) allow the unchangeable cover elements to be sent without compromising the message. These have not been applied to linguistic steganography, but we simulate their use: we remove the unchangeable tweets from the cover and stego sets, essentially giving the steganographer and detector the ability to ignore such tweets. Figure 2: The effect of batch size on error rate. Batches of 100 are the maximum for M-CT and T-Lex, but we go up to 1000 with A-CT. 5.3 Results As expected, the performance of the classifiers trained on individual tweets is poor (see Figure 1). In particular, the models trained o</context>
</contexts>
<marker>Filler, Judas, Fridrich, 2011</marker>
<rawString>Tom´aˇs Filler, Jan Judas, and Jessica Fridrich. 2011. Minimizing additive distortion in steganography using syndrome-trellis codes. Information Forensics and Security, IEEE Transactions on, 6(3):920–935.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jessica Fridrich</author>
<author>Jan Kodovsk`y</author>
</authors>
<title>Rich models for steganalysis of digital images. Information Forensics and Security,</title>
<date>2012</date>
<journal>IEEE Transactions on,</journal>
<volume>7</volume>
<issue>3</issue>
<marker>Fridrich, Kodovsk`y, 2012</marker>
<rawString>Jessica Fridrich and Jan Kodovsk`y. 2012. Rich models for steganalysis of digital images. Information Forensics and Security, IEEE Transactions on, 7(3):868–882.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jessica Fridrich</author>
</authors>
<title>Steganography in digital media: principles, algorithms, and applications.</title>
<date>2009</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1207" citStr="Fridrich, 2009" startWordPosition="191" endWordPosition="192"> domain. We test our system on a set of 1M steganographic tweets, and show it to be effective. 1 Introduction Consider this: two isolated prisoners, communicating by letters scrutinised by the prison warden. They cannot write openly about escape plots, and the warden destroys any written in code. They must hide the true message within the letter, using steganography: the art of hiding information. In cover modification1steganography, a cover object is tweaked so that it carries a hidden message: this is called embedding, the tweaked version is the stego object, and the message is the payload (Fridrich, 2009). The message should not be detectable to any observer (the standard terminology for this is the warden, taken from the prisoner metaphor) who knows the system is deployed, but does not know the original cover. We are concerned here with linguistic steganography, in which the cover is a piece of text, and the message is embedded using textual transformations intended to preserve the meaning of the original: synonym substitutions, syntactical transformations, etc. Note that we are not concerned 1There are other steganographic paradigms, not in scope. Translation based methods hide information i</context>
<context position="7967" citStr="Fridrich, 2009" startWordPosition="1271" endWordPosition="1272">ic features Including: word count (including tokenised punctuation); the mean and variance of the number of characters in each word; the total stop word count3; and the counts for each individual stop word. (131 features) n-gram features Using a 5-gram model, for n from 1 to 5, the mean, variance and total log likelihood of the n-grams in the tweet. (15 features) Word length Equivalent to the n-gram features, using a 10-gram model of word length. We expect the PPDB to replace common words with uncommon longer words, or multiple shorter words. (30 features) PPDB features Kerckhoffs’ principle (Fridrich, 2009), which states that a stegosystem must be secure even when the attacker (us) knows how the system works, introduces an interesting opportunity for linguistic steganalysis. As all linguistic stegosystems rely on automatic paraphrasing, and generally require a source of data, it is conservative to assume that the attacker has access to this data source. As the attacker, we can derive features from this data. Applying this, we extracted features using the same subset of the PPDB that CoverTweet uses. To our knowledge, this is the first work to explicitly apply Kerckhoffs’ principle to linguistic </context>
</contexts>
<marker>Fridrich, 2009</marker>
<rawString>Jessica Fridrich. 2009. Steganography in digital media: principles, algorithms, and applications. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Benjamin Van Durme</author>
<author>Chris Callison-Burch</author>
</authors>
<title>PPDB: The paraphrase database.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>758--764</pages>
<marker>Ganitkevitch, Van Durme, Callison-Burch, 2013</marker>
<rawString>Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch. 2013. PPDB: The paraphrase database. In HLT-NAACL, pages 758–764.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Grosvald</author>
<author>C Orhan Orgun</author>
</authors>
<title>Free from the cover text: a human-generated natural language approach to text-based steganography.</title>
<date>2011</date>
<journal>Journal of Information Hiding and Multimedia Signal Processing,</journal>
<volume>2</volume>
<issue>2</issue>
<contexts>
<context position="2514" citStr="Grosvald and Orgun, 2011" startWordPosition="401" endWordPosition="404">on methods automatically produce text containing the payload (e.g. Chapman et al. (2001)). with the subset of linguistic steganography that hides in file formatting (e.g. white space, as in Por et al. (2008)), which has no security against an informed warden (in the case of hiding information by adding extraneous white space, the warden simply has to look for consistent irregular use of spaces to spot an active steganographer). The field suffers from a number of issues: compared to images, text covers have low capacity (Chang and Clark, 2010); certain methods are weak against human attackers (Grosvald and Orgun, 2011) (most paraphrase systems cannot guarantee perfectly fluent stego objects); finally, authors are generally concerned with the performance of the transformation (whether they produce grammatically/semantically correct transformations), rather than whether the generated stego objects are detectable or not (e.g. Chang and Clark (2010)). However, there is a new challenger in the field. We proposed a new linguistic stegosystem (Wilson et al., 2014) and verified its security against human judges, who were unable to distinguish genuine covers from manipulated stego objects. This paper aims to attack </context>
</contexts>
<marker>Grosvald, Orgun, 2011</marker>
<rawString>Michael Grosvald and C Orhan Orgun. 2011. Free from the cover text: a human-generated natural language approach to text-based steganography. Journal of Information Hiding and Multimedia Signal Processing, 2(2):133–141.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew D Ker</author>
</authors>
<title>Batch steganography and pooled steganalysis.</title>
<date>2007</date>
<booktitle>In Information Hiding,</booktitle>
<pages>265--281</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="3535" citStr="Ker, 2007" startWordPosition="558" endWordPosition="559">ic stegosystem (Wilson et al., 2014) and verified its security against human judges, who were unable to distinguish genuine covers from manipulated stego objects. This paper aims to attack CoverTweet statistically. We are in the shoes of the warden, attempting to classify stego objects from innocent2cover objects. We propose techniques new to linguistic steganalysis, including a large set of features that detect unusual and inconsistent use of language and the aggregation of evidence from multiple sentences. This last development, known in the steganographic literature as pooled steganalysis (Ker, 2007), represents a first in both linguistic and image steganalysis. 2It is usual to call steganographers and their output ‘guilty’ (with non-steganographers and unchanged cover objects being ‘innocent’). This has the possibility of seeming politically charged, so we will use the term ‘active’ instead: be aware that this is not the usual terminology. 2564 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2564–2569, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. 2 Linguistic Stegosystems T-Lex (Winstein, 1998) is </context>
<context position="9720" citStr="Ker, 2007" startWordPosition="1565" endWordPosition="1566"> each word or phrase in the PPDB is replaced by its most likely substitute, according to the language model. The max, min, mean and variance of the log likelihoods for the resulting sentences are used. (27 features) 4.1 Pooling the features Individual linguistic stego objects carry a tiny payload, making detection an incredibly difficult task. In some cases, the stego tweet will be identical to the cover, making the task impossible. Although we do not hope to reliably identify stego tweets individually, the warden can still try to catch the active steganographers: through pooled steganalysis (Ker, 2007). Here, the warden considers all the evidence for each user, and aims to identify those actively using steganography. We combine features from batches of tweets, by the same user: taking the max, min, mean and variance of each feature. If performing steganography causes small consistent changes to a feature, this will be apparent in the mean. If it causes inconsistent changes, it may be apparent in the variance. If it occasionally produces an extreme result, the max and min will capture this. (812 features) 5 Method and Results Here we take the role of an automatic censor, attempting to identi</context>
</contexts>
<marker>Ker, 2007</marker>
<rawString>Andrew D Ker. 2007. Batch steganography and pooled steganalysis. In Information Hiding, pages 265– 281. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Kodovsk`y</author>
<author>Jessica Fridrich</author>
<author>Vojtˇech Holub</author>
</authors>
<title>Ensemble classifiers for steganalysis of digital media. Information Forensics and Security,</title>
<date>2012</date>
<journal>IEEE Transactions on,</journal>
<volume>7</volume>
<issue>2</issue>
<marker>Kodovsk`y, Fridrich, Holub, 2012</marker>
<rawString>Jan Kodovsk`y, Jessica Fridrich, and Vojtˇech Holub. 2012. Ensemble classifiers for steganalysis of digital media. Information Forensics and Security, IEEE Transactions on, 7(2):432–444.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Meng</author>
<author>Yun-Qing Shi</author>
<author>Liusheng Huang</author>
<author>Zhili Chen</author>
<author>Wei Yang</author>
<author>Abdelrahman Desoky</author>
</authors>
<title>Linl: Lost in n-best list.</title>
<date>2011</date>
<booktitle>In Information Hiding,</booktitle>
<pages>329--341</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1872" citStr="Meng et al. (2011)" startWordPosition="296" endWordPosition="299">bserver (the standard terminology for this is the warden, taken from the prisoner metaphor) who knows the system is deployed, but does not know the original cover. We are concerned here with linguistic steganography, in which the cover is a piece of text, and the message is embedded using textual transformations intended to preserve the meaning of the original: synonym substitutions, syntactical transformations, etc. Note that we are not concerned 1There are other steganographic paradigms, not in scope. Translation based methods hide information in the automatic translation of the cover (e.g. Meng et al. (2011)). Cover generation methods automatically produce text containing the payload (e.g. Chapman et al. (2001)). with the subset of linguistic steganography that hides in file formatting (e.g. white space, as in Por et al. (2008)), which has no security against an informed warden (in the case of hiding information by adding extraneous white space, the warden simply has to look for consistent irregular use of spaces to spot an active steganographer). The field suffers from a number of issues: compared to images, text covers have low capacity (Chang and Clark, 2010); certain methods are weak against </context>
</contexts>
<marker>Meng, Shi, Huang, Chen, Yang, Desoky, 2011</marker>
<rawString>Peng Meng, Yun-Qing Shi, Liusheng Huang, Zhili Chen, Wei Yang, and Abdelrahman Desoky. 2011. Linl: Lost in n-best list. In Information Hiding, pages 329–341. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: A lexical database for english.</title>
<date>1995</date>
<journal>COMMUNICATIONS OF THE ACM,</journal>
<pages>38--39</pages>
<contexts>
<context position="4314" citStr="Miller, 1995" startWordPosition="668" endWordPosition="669"> cover objects being ‘innocent’). This has the possibility of seeming politically charged, so we will use the term ‘active’ instead: be aware that this is not the usual terminology. 2564 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2564–2569, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. 2 Linguistic Stegosystems T-Lex (Winstein, 1998) is the oldest available cover-modification based linguistic stegosystem. It uses a dictionary containing a small number of disjoint synonym sets extracted from WordNet (Miller, 1995). Each set is unambiguously ordered (e.g. alphabetically), then values are embedded by changing cover words for their synonyms. Due to the the small dictionary, the capacity of covers is only ∼ 0.1 bits per sentence. CoverTweet is a modern evolution of T-Lex. It hides information in tweets by applying paraphrase rules taken from the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013), a set of 169M rules. The system applies suitable rules to a given cover, generating a set of possible stego objects. These are ranked by a distortion measure (derived from the probabilities of applied rules an</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: A lexical database for english. COMMUNICATIONS OF THE ACM, 38:39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Todd Mostak</author>
</authors>
<title>Harvard TweetMap. accessed</title>
<date>2013</date>
<note>https://worldmap.harvard. edu/.</note>
<contexts>
<context position="10563" citStr="Mostak, 2013" startWordPosition="1710" endWordPosition="1711">ture. If performing steganography causes small consistent changes to a feature, this will be apparent in the mean. If it causes inconsistent changes, it may be apparent in the variance. If it occasionally produces an extreme result, the max and min will capture this. (812 features) 5 Method and Results Here we take the role of an automatic censor, attempting to identify users on Twitter who are sending secret messages. We imagine a scenario where CoverTweet is openly available, and so can assume this is the system utilised by the active users. 5.1 Data and Embedding From the Harvard TweetMap (Mostak, 2013), we gathered 72M English language tweets, from 1.2M users. Each tweet was canonicalised as follows: tokenised; made lowercase; usernames replaced by a uniform token; URLs replaced by a 4Where we say a word or phrase is ‘in’ the PPDB, we mean it features in one or more paraphrase rules that could have been applied to the original tweet. uniform token. We randomly selected 1000 users with 1000-2000 tweets to train and test a classifier. On the remaining tweets, we trained a 10-gram word length model, and a 5-gram language model, using SRILM (Stolcke, 2002) with Kneyser-Ney smoothing. For vocabu</context>
</contexts>
<marker>Mostak, 2013</marker>
<rawString>Todd Mostak. 2013. Harvard TweetMap. accessed October 2013. https://worldmap.harvard. edu/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lip Y Por</author>
<author>TF Ang</author>
<author>B Delina</author>
</authors>
<title>Whitesteg: a new scheme in information hiding using text steganography.</title>
<date>2008</date>
<journal>WSEAS Transactions on Computers,</journal>
<volume>7</volume>
<issue>6</issue>
<contexts>
<context position="2096" citStr="Por et al. (2008)" startWordPosition="331" endWordPosition="334"> the cover is a piece of text, and the message is embedded using textual transformations intended to preserve the meaning of the original: synonym substitutions, syntactical transformations, etc. Note that we are not concerned 1There are other steganographic paradigms, not in scope. Translation based methods hide information in the automatic translation of the cover (e.g. Meng et al. (2011)). Cover generation methods automatically produce text containing the payload (e.g. Chapman et al. (2001)). with the subset of linguistic steganography that hides in file formatting (e.g. white space, as in Por et al. (2008)), which has no security against an informed warden (in the case of hiding information by adding extraneous white space, the warden simply has to look for consistent irregular use of spaces to spot an active steganographer). The field suffers from a number of issues: compared to images, text covers have low capacity (Chang and Clark, 2010); certain methods are weak against human attackers (Grosvald and Orgun, 2011) (most paraphrase systems cannot guarantee perfectly fluent stego objects); finally, authors are generally concerned with the performance of the transformation (whether they produce </context>
</contexts>
<marker>Por, Ang, Delina, 2008</marker>
<rawString>Lip Y Por, TF Ang, and B Delina. 2008. Whitesteg: a new scheme in information hiding using text steganography. WSEAS Transactions on Computers, 7(6):735–745.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<pages>901--904</pages>
<contexts>
<context position="11124" citStr="Stolcke, 2002" startWordPosition="1806" endWordPosition="1807">nd Embedding From the Harvard TweetMap (Mostak, 2013), we gathered 72M English language tweets, from 1.2M users. Each tweet was canonicalised as follows: tokenised; made lowercase; usernames replaced by a uniform token; URLs replaced by a 4Where we say a word or phrase is ‘in’ the PPDB, we mean it features in one or more paraphrase rules that could have been applied to the original tweet. uniform token. We randomly selected 1000 users with 1000-2000 tweets to train and test a classifier. On the remaining tweets, we trained a 10-gram word length model, and a 5-gram language model, using SRILM (Stolcke, 2002) with Kneyser-Ney smoothing. For vocabulary, the language model was given every word in the PPDB, and every word in the set of tweets, including the removed tweets. We do not expect this to provide an unrealistic advantage to the censor: any word not in the PPDB cannot hide information. We randomly took 10 users from the set of 1000, and produced 100 stego tweets for each, for three payload sizes: 1, 2 and 4 bits. The stego tweets were generated using CoverTweet, with a human operator selecting the most fluent option containing a desired (randomly generated) payload. If there were no fluent op</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cuneyt M Taskiran</author>
<author>Umut Topkara</author>
<author>Mercan Topkara</author>
<author>Edward J Delp</author>
</authors>
<title>Attacks on lexical natural language steganography systems.</title>
<date>2006</date>
<booktitle>In IS&amp;T/SPIE Electronic Imaging,</booktitle>
<pages>120--129</pages>
<institution>International Society for Optics and Photonics.</institution>
<contexts>
<context position="6394" citStr="Taskiran et al. (2006)" startWordPosition="1005" endWordPosition="1008">on: (Chang and Clark, 2012a), (Chang and Clark, 2012b), (Vybornova and Macq, 2007)). Approximately 1 bit of payload per cover sentence is usual, making CoverTweet the exception. Unfortunately for steganalysis literature, the vast majority of these require data that is unavailable (and too expensive to reproduce); beyond CoverTweet, the only system that can be evaluated is T-Lex. 3 Related Work To our knowledge, there have been only five prior attempts at linguistic steganalysis on cover modification based systems; of these, four attack TLex, the other attacks an equivalent proprietary system. Taskiran et al. (2006) was the first, using n-gram language models to extract features from stego text, before training a support vector machine (SVM) on the features. We will adopt some of these features for our attack. Subsequent work (Xin-guang et al. (2006); Yu et al. (2009); Chen et al. (2011); Xiang et al. (2014)) has used smaller models: they have all designed a single feature to exploit a weakness, and used this (or the mean and variance of it) to train a classifier for attack. Analysis of results, especially the effect of embedding rate on detection, has been lacking or non-existent. This focus on individu</context>
</contexts>
<marker>Taskiran, Topkara, Topkara, Delp, 2006</marker>
<rawString>Cuneyt M Taskiran, Umut Topkara, Mercan Topkara, and Edward J Delp. 2006. Attacks on lexical natural language steganography systems. In IS&amp;T/SPIE Electronic Imaging, pages 120–129. International Society for Optics and Photonics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olga Vybornova</author>
<author>Benoit Macq</author>
</authors>
<title>Natural language watermarking and robust hashing based on presuppositional analysis.</title>
<date>2007</date>
<booktitle>In Information Reuse and Integration,</booktitle>
<pages>177--182</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="5854" citStr="Vybornova and Macq, 2007" startWordPosition="920" endWordPosition="923">4 bits can be embedded per tweet, and it was proven secure against human judges (Wilson et al., 2014). Twitter is a realistic setting for steganography. There is precedent for information hiding and mass monitoring on micro-blogging sites, such as the use of code words and government censorship on the Chinese website Sina Weibo (Chen et al., 2013). For this reason, we are attacking this setting. There are many other linguistic stegosystems, using an array of different hiding methods (e.g. adjective deletion, word order, anaphora resolution: (Chang and Clark, 2012a), (Chang and Clark, 2012b), (Vybornova and Macq, 2007)). Approximately 1 bit of payload per cover sentence is usual, making CoverTweet the exception. Unfortunately for steganalysis literature, the vast majority of these require data that is unavailable (and too expensive to reproduce); beyond CoverTweet, the only system that can be evaluated is T-Lex. 3 Related Work To our knowledge, there have been only five prior attempts at linguistic steganalysis on cover modification based systems; of these, four attack TLex, the other attacks an equivalent proprietary system. Taskiran et al. (2006) was the first, using n-gram language models to extract feat</context>
</contexts>
<marker>Vybornova, Macq, 2007</marker>
<rawString>Olga Vybornova and Benoit Macq. 2007. Natural language watermarking and robust hashing based on presuppositional analysis. In Information Reuse and Integration, 2007. IRI 2007. IEEE International Conference on, pages 177–182. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Wilson</author>
<author>Phil Blunsom</author>
<author>Andrew D Ker</author>
</authors>
<title>Linguistic steganography on twitter: hierarchical language modeling with manual interaction.</title>
<date>2014</date>
<booktitle>In IS&amp;T/SPIE Electronic Imaging,</booktitle>
<pages>201--217</pages>
<institution>International Society for Optics and Photonics.</institution>
<contexts>
<context position="2961" citStr="Wilson et al., 2014" startWordPosition="465" endWordPosition="468">om a number of issues: compared to images, text covers have low capacity (Chang and Clark, 2010); certain methods are weak against human attackers (Grosvald and Orgun, 2011) (most paraphrase systems cannot guarantee perfectly fluent stego objects); finally, authors are generally concerned with the performance of the transformation (whether they produce grammatically/semantically correct transformations), rather than whether the generated stego objects are detectable or not (e.g. Chang and Clark (2010)). However, there is a new challenger in the field. We proposed a new linguistic stegosystem (Wilson et al., 2014) and verified its security against human judges, who were unable to distinguish genuine covers from manipulated stego objects. This paper aims to attack CoverTweet statistically. We are in the shoes of the warden, attempting to classify stego objects from innocent2cover objects. We propose techniques new to linguistic steganalysis, including a large set of features that detect unusual and inconsistent use of language and the aggregation of evidence from multiple sentences. This last development, known in the steganographic literature as pooled steganalysis (Ker, 2007), represents a first in bo</context>
<context position="5330" citStr="Wilson et al., 2014" startWordPosition="839" endWordPosition="842"> of 169M rules. The system applies suitable rules to a given cover, generating a set of possible stego objects. These are ranked by a distortion measure (derived from the probabilities of applied rules and from sentence probabilities given by a language model), and assigned a keyed hash. A human operator filters the options for fluency, and chooses the best stego object with the desired hash. CoverTweet uses a subset of the PPDB, restricted to lexical and phrasal substitutions. Even with the reduced set of rules, 4 bits can be embedded per tweet, and it was proven secure against human judges (Wilson et al., 2014). Twitter is a realistic setting for steganography. There is precedent for information hiding and mass monitoring on micro-blogging sites, such as the use of code words and government censorship on the Chinese website Sina Weibo (Chen et al., 2013). For this reason, we are attacking this setting. There are many other linguistic stegosystems, using an array of different hiding methods (e.g. adjective deletion, word order, anaphora resolution: (Chang and Clark, 2012a), (Chang and Clark, 2012b), (Vybornova and Macq, 2007)). Approximately 1 bit of payload per cover sentence is usual, making CoverT</context>
</contexts>
<marker>Wilson, Blunsom, Ker, 2014</marker>
<rawString>Alex Wilson, Phil Blunsom, and Andrew D Ker. 2014. Linguistic steganography on twitter: hierarchical language modeling with manual interaction. In IS&amp;T/SPIE Electronic Imaging, pages 201–217. International Society for Optics and Photonics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Winstein</author>
</authors>
<title>Lexical steganography through adaptive modulation of the word choice hash.</title>
<date>1998</date>
<note>http://www.imsa.edu/˜keithw/tlex. Unpublished.</note>
<contexts>
<context position="4131" citStr="Winstein, 1998" startWordPosition="642" endWordPosition="643">nalysis (Ker, 2007), represents a first in both linguistic and image steganalysis. 2It is usual to call steganographers and their output ‘guilty’ (with non-steganographers and unchanged cover objects being ‘innocent’). This has the possibility of seeming politically charged, so we will use the term ‘active’ instead: be aware that this is not the usual terminology. 2564 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2564–2569, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. 2 Linguistic Stegosystems T-Lex (Winstein, 1998) is the oldest available cover-modification based linguistic stegosystem. It uses a dictionary containing a small number of disjoint synonym sets extracted from WordNet (Miller, 1995). Each set is unambiguously ordered (e.g. alphabetically), then values are embedded by changing cover words for their synonyms. Due to the the small dictionary, the capacity of covers is only ∼ 0.1 bits per sentence. CoverTweet is a modern evolution of T-Lex. It hides information in tweets by applying paraphrase rules taken from the Paraphrase Database (PPDB) (Ganitkevitch et al., 2013), a set of 169M rules. The s</context>
</contexts>
<marker>Winstein, 1998</marker>
<rawString>Keith Winstein. 1998. Lexical steganography through adaptive modulation of the word choice hash. http://www.imsa.edu/˜keithw/tlex. Unpublished.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lingyun Xiang</author>
<author>Xingming Sun</author>
<author>Gang Luo</author>
<author>Bin Xia</author>
</authors>
<title>Linguistic steganalysis using the features derived from synonym frequency. Multimedia tools and applications,</title>
<date>2014</date>
<pages>71--3</pages>
<contexts>
<context position="6692" citStr="Xiang et al. (2014)" startWordPosition="1057" endWordPosition="1060">o reproduce); beyond CoverTweet, the only system that can be evaluated is T-Lex. 3 Related Work To our knowledge, there have been only five prior attempts at linguistic steganalysis on cover modification based systems; of these, four attack TLex, the other attacks an equivalent proprietary system. Taskiran et al. (2006) was the first, using n-gram language models to extract features from stego text, before training a support vector machine (SVM) on the features. We will adopt some of these features for our attack. Subsequent work (Xin-guang et al. (2006); Yu et al. (2009); Chen et al. (2011); Xiang et al. (2014)) has used smaller models: they have all designed a single feature to exploit a weakness, and used this (or the mean and variance of it) to train a classifier for attack. Analysis of results, especially the effect of embedding rate on detection, has been lacking or non-existent. This focus on individual features echoes the early work on image steganalysis, which has since shifted towards feature-rich models. We will be utilising the latter here, in addition to the pooled steganalysis paradigm. 4 Proposed features Below we describe four classes of proposed features for individual tweets. Each c</context>
</contexts>
<marker>Xiang, Sun, Luo, Xia, 2014</marker>
<rawString>Lingyun Xiang, Xingming Sun, Gang Luo, and Bin Xia. 2014. Linguistic steganalysis using the features derived from synonym frequency. Multimedia tools and applications, 71(3):1893–1911.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sui Xin-guang</author>
<author>Luo Hui</author>
<author>Zhu Zhong-liang</author>
</authors>
<title>A steganalysis method based on the distribution of characters.</title>
<date>2006</date>
<booktitle>In Signal Processing, 2006 8th International Conference on,</booktitle>
<volume>4</volume>
<pages>54--56</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="6633" citStr="Xin-guang et al. (2006)" startWordPosition="1045" endWordPosition="1048"> of these require data that is unavailable (and too expensive to reproduce); beyond CoverTweet, the only system that can be evaluated is T-Lex. 3 Related Work To our knowledge, there have been only five prior attempts at linguistic steganalysis on cover modification based systems; of these, four attack TLex, the other attacks an equivalent proprietary system. Taskiran et al. (2006) was the first, using n-gram language models to extract features from stego text, before training a support vector machine (SVM) on the features. We will adopt some of these features for our attack. Subsequent work (Xin-guang et al. (2006); Yu et al. (2009); Chen et al. (2011); Xiang et al. (2014)) has used smaller models: they have all designed a single feature to exploit a weakness, and used this (or the mean and variance of it) to train a classifier for attack. Analysis of results, especially the effect of embedding rate on detection, has been lacking or non-existent. This focus on individual features echoes the early work on image steganalysis, which has since shifted towards feature-rich models. We will be utilising the latter here, in addition to the pooled steganalysis paradigm. 4 Proposed features Below we describe four</context>
</contexts>
<marker>Xin-guang, Hui, Zhong-liang, 2006</marker>
<rawString>Sui Xin-guang, Luo Hui, and Zhu Zhong-liang. 2006. A steganalysis method based on the distribution of characters. In Signal Processing, 2006 8th International Conference on, volume 4, pages 54–56. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhenshan Yu</author>
<author>Liusheng Huang</author>
<author>Zhili Chen</author>
<author>Lingjun Li</author>
<author>Xinxin Zhao</author>
<author>Youwen Zhu</author>
</authors>
<title>Steganalysis of synonym-substitution based natural language watermarking.</title>
<date>2009</date>
<contexts>
<context position="6651" citStr="Yu et al. (2009)" startWordPosition="1049" endWordPosition="1052">at is unavailable (and too expensive to reproduce); beyond CoverTweet, the only system that can be evaluated is T-Lex. 3 Related Work To our knowledge, there have been only five prior attempts at linguistic steganalysis on cover modification based systems; of these, four attack TLex, the other attacks an equivalent proprietary system. Taskiran et al. (2006) was the first, using n-gram language models to extract features from stego text, before training a support vector machine (SVM) on the features. We will adopt some of these features for our attack. Subsequent work (Xin-guang et al. (2006); Yu et al. (2009); Chen et al. (2011); Xiang et al. (2014)) has used smaller models: they have all designed a single feature to exploit a weakness, and used this (or the mean and variance of it) to train a classifier for attack. Analysis of results, especially the effect of embedding rate on detection, has been lacking or non-existent. This focus on individual features echoes the early work on image steganalysis, which has since shifted towards feature-rich models. We will be utilising the latter here, in addition to the pooled steganalysis paradigm. 4 Proposed features Below we describe four classes of propos</context>
</contexts>
<marker>Yu, Huang, Chen, Li, Zhao, Zhu, 2009</marker>
<rawString>Zhenshan Yu, Liusheng Huang, Zhili Chen, Lingjun Li, Xinxin Zhao, and Youwen Zhu. 2009. Steganalysis of synonym-substitution based natural language watermarking.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>