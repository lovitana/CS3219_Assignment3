<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003757">
<title confidence="0.923138">
Classifying Tweet Level Judgements of Rumours in Social Media
</title>
<author confidence="0.984475">
Michal Lukasik,1 Trevor Cohn2 and Kalina Bontcheva1
</author>
<affiliation confidence="0.650516">
1Computer Science 2Computing and Information Systems
The University of Sheffield The University of Melbourne
</affiliation>
<email confidence="0.990164">
{m.lukasik,k.bontcheva}@shef.ac.uk t.cohn@unimelb.edu.au
</email>
<sectionHeader confidence="0.993709" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999926846153846">
Social media is a rich source of rumours
and corresponding community reactions.
Rumours reflect different characteristics,
some shared and some individual. We for-
mulate the problem of classifying tweet
level judgements of rumours as a super-
vised learning task. Both supervised and
unsupervised domain adaptation are con-
sidered, in which tweets from a rumour are
classified on the basis of other annotated
rumours. We demonstrate how multi-task
learning helps achieve good results on ru-
mours from the 2011 England riots.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993624138888889">
There is an increasing need to interpret and act
upon rumours spreading quickly through social
media, especially in circumstances where their ve-
racity is hard to establish. For instance, during an
earthquake in Chile rumours spread through Twit-
ter that a volcano had become active and that there
was a tsunami warning in Valparaiso (Mendoza et
al., 2010). Other examples, from the riots in Eng-
land in 2011, were that rioters were going to attack
Birmingham’s children hospital and that animals
had escaped from the zoo (Procter et al., 2013).
Social scientists (Procter et al., 2013) analysed
manually a sample of tweets expressing different
judgements towards rumours and categorised them
manually in supporting, denying or questioning.
The goal here is to carry out tweet-level judge-
ment classification automatically, in order to assist
in (near) real-time rumour monitoring by journal-
ists and authorities (Procter et al., 2013). In ad-
dition, information about tweet-level judgements
has been used as a first step for early rumour de-
tection by (Zhao et al., 2015).
The focus here is on tweet-level judgement clas-
sification on unseen rumours, based on a training
text position
Birmingham Children’s hospital has support
been attacked. F***ing morons.
#UKRiots
Girlfriend has just called her ward deny
in Birmingham Children’s Hospital &amp;
there’s no sign of any trouble #Birm-
inghamriots
Birmingham children’s hospital question
guarded by police? Really? Who
would target a childrens hospital
#disgusting #Birminghamriots
</bodyText>
<tableCaption confidence="0.557255">
Table 1: Tweets on a rumour about hospital being
attacked during 2011 England Riots.
</tableCaption>
<bodyText confidence="0.9993176">
set of other already annotated rumours. Previous
work on this problem either considered unrealis-
tic settings ignoring temporal ordering and rumour
identities (Qazvinian et al., 2011) or proposed reg-
ular expressions as a solution (Zhao et al., 2015).
We expect posts expressing similar opinions to ex-
hibit many similar characteristics across different
rumours. Based on the assumption of a common
underlying linguistic signal, we build a transfer
learning system that labels newly emerging ru-
mours for which we have little or no annotated
data. Results demonstrate that Gaussian Process-
based multi task learning allows for significantly
improved performance.
The novel contributions of this paper are:
1. Formulating the problem of classifying judge-
ments of rumours in both supervised and unsuper-
vised domain adaptation settings. 2. Showing how
a multi-task learning approach outperforms single-
task methods.
</bodyText>
<sectionHeader confidence="0.999588" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.9953955">
In the context of rumour spread in social media,
researchers have studied differences in informa-
</bodyText>
<page confidence="0.832844">
2590
</page>
<note confidence="0.6311855">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2590–2595,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999983980392157">
tion flows between content of varying credibility.
For instance, Procter et al. (2013) grouped source
tweets and re-tweets into information flows (Lotan
et al., 2011), then ranked these by flow size, as
a proxy of significance. Information flows were
then categorised manually. Along similar vein,
Mendoza et al. (2010) found that users deal with
true and false rumours differently: the former are
affirmed more than 90% of the time, whereas the
latter are challenged (questioned or denied) 50%
of the time. Friggeri et al. (2014) analyzed a set
rumours from the Snopes.com website that have
been matched to Facebook public conversations.
They concluded that false rumours are more likely
to receive a comment with link to Snopes.com
website. However, none of the above attempted
to automatically classify rumours.
With respect to automatic methods for detect-
ing misinformation and disinformation in social
media, Ratkiewicz et al. (2011) detect political
abuse (a kind of disinformation) spread through
Twitter. The task is defined in purely information
diffusion settings and is not necessarily related
with the truthfulness of the piece of information.
Castillo et al. (2013) proposed methods for identi-
fying newsworthy information cascades on Twitter
and then classifying these cascades as credible and
not credible. The main difference from our task is
that credibility classification is carried out over the
entire information cascade, classified objects are
not necessarily rumours and no explicit judgement
classification was performed in their approach.
Early rumour identification is the focus of Zhao
et al. (2015), where regular expressions are used
for finding questioning and denying tweets as a
key pre-requisite step for rumour detection. Un-
fortunately, when we applied these regular expres-
sions on our dataset, they yielded only 16% recall
for questioning and 14% recall for denying tweets.
Consequently, this motivated us to seek a better
approach to tweet-level classification.
The work most relevant to ours is due
to Qazvinian et al. (2011). Their method first
carries out rumour retrieval, whereby tweets are
classified into rumour related and non-rumour re-
lated. Next, rumour-related tweets are classified
into supporting and not-supporting. The classi-
fier is trained by ignoring rumour identities, i.e.,
pooling together tweets from all rumours, and ig-
noring the temporal dependencies between tweets.
In contrast, we formulate the rumour classifica-
</bodyText>
<table confidence="0.998956">
Rumour Supporting Denying Questioning
army bank 62 42 73
hospital 796 487 132
London Eye 177 295 160
McDonald’s 177 0 13
Miss Selfridge’s 3150 0 7
police beat girl 783 4 95
zoo 616 129 99
</table>
<tableCaption confidence="0.988399">
Table 2: Counts of tweets with supporting, deny-
</tableCaption>
<bodyText confidence="0.9381664">
ing or questioning labels in each rumour collec-
tion.
tion problem as transfer learning, where unseen
rumours (or rumours with few initial tweets ob-
served) are classified using already known ru-
mours – a much harder and more practical setting.
Moreover, unlike Qazvinian et al. (2011), we con-
sider the multi-class classification problem and do
not collaps questioning and denying tweets into a
single class, since they differ significantly.
</bodyText>
<sectionHeader confidence="0.996927" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.9999672">
We evaluate our work on several rumours circu-
lating on Twitter during the England riots in 2011
(see Table 2). The dataset was analysed and an-
notated manually as supporting, questioning, or
denying a rumour, by a team of social scientists
studying the role of social media during the riots
(Procter et al., 2013). The original dataset also
included commenting tweets, but these have been
removed from our experiments due to their small
number (they constituted only 5% of the corpus).
As can be seen from the dataset overview in
Table 2, different rumours exhibit varying pro-
portions of supporting, denying and questioning
tweets, which was also observed in other studies of
rumours (Mendoza et al., 2010; Qazvinian et al.,
2011). These variations in majority classes across
rumours underscores the modeling challenge in
tweet-level classification of rumour attitudes.
With respect to veracity, one rumour has been
confirmed as true (Miss Selfridge’s being on fire),
one is unsubstantiated (police beat girl), and the
remaining five are known to be false. Note, how-
ever, that the focus here is not on classifying truth-
fulness, but instead on identifying the attitude ex-
pressed in each tweet towards the rumour.
</bodyText>
<page confidence="0.965274">
2591
</page>
<sectionHeader confidence="0.983194" genericHeader="method">
4 Problem formulation
</sectionHeader>
<bodyText confidence="0.999986611111111">
Let R be a set of rumours, each of which consists
of tweets discussing it, ∀rER Tr = {tr1, · · · , trrn}.
T = ∪rERTr is the complete set of tweets from all
rumours. Each tweet is classified as supporting,
denying or questioning with respect to its rumour:
y(t) ∈ {0, 1, 2}, where 0 denotes supporting, 1
means denying and 2 denotes questioning.
First, we consider the Leave One Out (LOO)
setting, which means that for each rumour r ∈ R,
we construct the test set equal to Tr and the train-
ing set equal to T \ Tr. Therefore this is a very
challenging and realistic scenario, where the test
set contains an entirely unseen rumour, from those
in the training set.
The second setting is Leave Part Out (LPO).
In this formulation, a very small number of ini-
tial tweets from the target rumour is added to the
training set {tr1, · · · , trrk}. This scenario becomes
applicable typically soon after a rumour breaks
out and journalists have started monitoring and
analysing the related tweet stream. The experi-
ments section investigates how the number of ini-
tial training tweets influences classification perfor-
mance on a fixed test set, namely: {trrl, · · · , trrn},
l &gt; k.
The tweet-level classification problem here as-
sumes that tweets from the training set are already
labelled with the rumour discussed and the atti-
tude expressed towards that. This information can
be acquired either via manual annotation as part
of expert analysis, as is the case with our dataset,
or automatically, e.g. using pattern-based rumour
detection (Zhao et al., 2015). Afterwards, our
method can be used to classify the attitudes ex-
pressed in each new tweet from outside the train-
ing set.
</bodyText>
<sectionHeader confidence="0.991321" genericHeader="method">
5 Gaussian Processes for Classification
</sectionHeader>
<bodyText confidence="0.999914333333333">
Gaussian Processes are a Bayesian non-parametric
machine learning framework that has been shown
to work well for a range of NLP problems, of-
ten beating other state-of-the-art methods (Cohn
and Specia, 2013; Lampos et al., 2014; Beck et
al., 2014; Preotiuc-Pietro et al., 2015). We use
Gaussian Processes as this probabilistic kernelised
framework avoids the need for expensive cross-
validation for hyperparameter selection.1
</bodyText>
<footnote confidence="0.528575">
1There exist frequentist kernel methods, like SVMs,
which additionally require extensive heldout parameter tun-
ing.
</footnote>
<bodyText confidence="0.996567166666667">
The central concept of Gaussian Process
Classification (GPC; (Rasmussen and Williams,
2005)) is a latent function f over inputs
x: f(x) ∼ GP(m(x), k(x, x&apos;)), where m is the
mean function, assumed to be 0 and k is the kernel
function, specifying the degree to which the out-
puts covary as a function of the inputs. We use a
linear kernel, k(x, x&apos;) = σ2xTx&apos;. The latent func-
tion is then mapped by the probit function Φ(f)
into the range [0, 1], such that the resulting value
can be interpreted as p(y = 1|x).
The GPC posterior
</bodyText>
<equation confidence="0.872030833333333">
is calculated as
� p(f*|X, x*,p(f*|X,y,x*) = |y|X p(f)df,
)
n
where p(y|f) = H Φ(fj)yj(1−Φ(fj))1−yj is the
j=1
</equation>
<bodyText confidence="0.99174334375">
Bernoulli likelihood of class y. After calculating
the above posterior from the training data, this is
used in prediction, i.e.,
�p(y* =1|X, y, x*)= Φ (f*) p (f*|X, y, x*) df* .
The above integrals are intractable and approx-
imation techniques are required to solve them.
There exist various methods to deal with calculat-
ing the posterior; here we use Expectation Prop-
agation (EP; (Minka and Lafferty, 2002)). In EP,
the posterior is approximated by a fully factorised
distribution, where each component is assumed to
be an unnormalised Gaussian.
In order to conduct multi-class classification,
we perform a one-vs-all classification for each la-
bel and then assign the one with the highest like-
lihood, amongst the three (supporting, denying,
questioning). We choose this method due to inter-
pretability of results, similar to recent work on oc-
cupational class classification (Preotiuc-Pietro et
al., 2015).
Intrinsic Coregionalization Model In the LPO
setting initial labelled tweets from the target ru-
mour are observed as well. In this case, we pro-
pose to weight the importance of tweets from the
reference rumours depending on how similar their
characteristics are to the tweets from the target ru-
mour available for training. To handle this with
GPC, we use a multiple output model based on the
Intrinsic Coregionalisation Model (ICM; ( ´Alvarez
et al., 2012)). It has already been applied suc-
cessfully to NLP regression problems (Beck et al.,
2014) and it can also be applied to classification
</bodyText>
<page confidence="0.977558">
2592
</page>
<bodyText confidence="0.999021666666667">
ones. ICM parametrizes the kernel by a matrix
which represents the extent of covariance between
pairs of tasks. The complete kernel takes form of
</bodyText>
<equation confidence="0.958599">
k((x, d), (x&apos;, d&apos;)) = kdata(x, x&apos;)Bd,d&apos;
,
</equation>
<bodyText confidence="0.98643085">
where B is a square coregionalization matrix, d
and d&apos; denote the tasks of the two inputs and kdata
is a kernel for comparing inputs x and x&apos; (here, lin-
ear). We parametrize the coregionalization matrix
B = κI + vvT, where v specifies the correlation
between tasks and the vector κ controls extent of
task independence.
Hyperparameter selection We tune hyperpa-
rameters v, κ and Q2 by maximizing evidence of
the model p(yIX), thus having no need for a vali-
dation set.
Methods We consider GPs in three different set-
tings, varying in what data the model is trained on
and what kernel it uses. The first setting (denoted
GP) considers only target rumour data for train-
ing. The second (GPPooled) additionally consid-
ers tweets from reference rumours (i.e. other than
the target rumour). The third setting is GPICM,
where an ICM kernel is used to weight influence
from tweets from reference rumours.
</bodyText>
<sectionHeader confidence="0.999598" genericHeader="method">
6 Features
</sectionHeader>
<bodyText confidence="0.997778714285714">
We conducted a series of preprocessing steps in or-
der to address data sparsity. All words were low-
ercased; stopwords removed; all emoticons were
replaced with words2; and stemming was per-
formed. In addition, multiple occurrences of a
character were replaced with a double occurrence
(Agarwal et al., 2011), to correct for misspellings
and lengthenings, e.g., looool. All punctuation
was also removed, except for ., ! and ?, which we
hypothesize to be important for expressing emo-
tion. Lastly, usernames were removed as they tend
to be rumour-specific, i.e., very few users com-
ment on more than one rumour.
After preprocessing the text data, we use either
the resulting bag of words (BOW) feature repre-
sentation or replace all words with their Brown
cluster ids (Brown), using 1000 clusters acquired
from a large scale Twitter corpus (Owoputi et al.,
2013). In all cases, simple re-tweets are removed
from the training set to prevent bias (Llewellyn et
al., 2014).
</bodyText>
<footnote confidence="0.999532">
2We used the dictionary from: http://bit.ly/
1rX1Hdk and extended it with: :o, : 1, =/, :s, :S, :p.
</footnote>
<table confidence="0.99741775">
method acc
Majority 0.68
GPPooled Brown 0.72
GPPooled BOW 0.69
</table>
<tableCaption confidence="0.9874595">
Table 3: Accuracy taken across all rumours in the
LOO setting.
</tableCaption>
<sectionHeader confidence="0.98467" genericHeader="evaluation">
7 Experiments and Discussion
</sectionHeader>
<bodyText confidence="0.999834390243903">
Table 3 shows the mean accuracy in the LOO
scenario following the GPPooled method, which
pools all reference rumours together ignoring their
task identities. ICM can not use correlations to tar-
get rumour in this case and so can not be used. The
majority baseline simply assigns the most frequent
class from the training set.
We can observe that methods perform on a level
similar to majority vote, outperforming it only
slightly. This indicates how difficult the LOO task
is, when no annotated target rumour tweets are
available.
Figure 1 shows accuracy for a range of methods
as the number of tweets about the target rumour
used for training increases. Most notably, perfor-
mance increases from 70% to around 80%, after
only 10 annotated tweets from the target rumour
become available, as compared to the results on
unseen rumours from Table 3. However, as the
amount of target rumour increases, performance
does not increase further, which suggests that even
only 10 human-annotated tweets are enough to
achieve significant performance benefits. Note
also how the use of reference rumours is very im-
portant, as methods using only the target rumour
obtain accuracy similar to the Majority vote clas-
sifier (GP Brown and GP BOW).
The top performing methods are GPCIM and
GPPooled, where use of Brown clusters consis-
tently improves results for both methods over
BOW, irrespective of the number of tweets about
the target rumour annotated for training. More-
over, GPICM is better than GPPooled both with
Brown and BOW features and GPCIM with
Brown is ultimately the best performing of all.
In order to analyse the importance of Brown
clusters, Automatic Relevance Determination
(ARD) is used (Rasmussen and Williams, 2005)
for the best performing GPICM Brown in the LPO
scenario. Only the case where the first 10 tweets
are used for training is considered, since it already
</bodyText>
<page confidence="0.986028">
2593
</page>
<figureCaption confidence="0.997792">
Figure 1: Accuracy measures for different methods versus the size of the target rumour used for training
in the LPO setting. The test set is fixed to all but the first 50 tweets of the target rumour.
</figureCaption>
<figure confidence="0.955409454545455">
supporting denying questioning
? fake ?
10001101 11111000001 10001101
! not !
10001100 001000 10001100
not ? hope
001000 10001101 01000111110
fake ! true
11111000001 10001100 111110010110
true bullshit searching
111110010110 11110101011111 01111000010
</figure>
<tableCaption confidence="0.956308">
Table 4: Top 5 Brown clusters, each shown
</tableCaption>
<bodyText confidence="0.995036">
with a representative word. For further
details please see the cluster definitions
at http://www.ark.cs.cmu.edu/
TweetNLP/cluster_viewer.html.
performs very well. Using ARD, we learn a sepa-
rate length-scale for each feature, thus establishing
their importance. The weights learnt for differ-
ent clusters are averaged over the 7 rumours and
the top 5 Brown clusters for each label are shown
in Table 4. We can see that clusters around the
words fake and bullshit turn out to be important
for the denying class, and true for both supporting
and questioning classes. This reinforces our hy-
pothesis that common linguistic cues can be found
across multiple rumours. Note how punctuation
proves important as well, since clusters ? and !
are also very prominent.
</bodyText>
<sectionHeader confidence="0.999251" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999975846153846">
This paper investigated the problem of classifying
judgements expressed in tweets about rumours.
First, we considered a setting where no training
data from target rumour is available (LOO). With-
out access to annotated examples of the target ru-
mour the learning problem becomes very difficult.
We showed that in the supervised domain adapta-
tion setting (LPO) even annotating a small number
of tweets helps to achieve better results. More-
over, we demonstrated the benefits of a multi task
learning approach, as well as that Brown cluster
features are more useful for the task than simple
bag of words.
Judgement estimation is undoubtedly of great
value e.g. for marketing, politics and journalism,
helping to target widely believed topics. Although
the focus here is on classifying community reac-
tions, Castillo et al. (2013) showed that commu-
nity reaction is correlated with actual rumour ve-
racity. Consequently our classification methods
may prove useful in the broader and more chal-
lenging task of annotating veracity.
An interesting direction for future work would
be adding non-textual features. For example, the
rumour diffusion pattern (Lukasik et al., 2015)
may be a useful cue for judgement classification.
</bodyText>
<sectionHeader confidence="0.997488" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99991475">
Work partially supported by the European Union
under grant agreement No. 611233 PHEME. The
work was implemented using the GPy toolkit
(GPy authors, 2015).
</bodyText>
<sectionHeader confidence="0.9984" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9667104">
Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Ram-
bow, and Rebecca Passonneau. 2011. Sentiment
analysis of twitter data. In Proceedings of the Work-
shop on Languages in Social Media, LSM ’11, pages
30–38.
</reference>
<page confidence="0.9096">
2594
</page>
<reference confidence="0.9995563125">
Mauricio A. ´Alvarez, Lorenzo Rosasco, and Neil D.
Lawrence. 2012. Kernels for vector-valued func-
tions: A review. Found. Trends Mach. Learn.,
4(3):195–266.
Daniel Beck, Trevor Cohn, and Lucia Specia. 2014.
Joint emotion analysis via multi-task Gaussian pro-
cesses. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
EMNLP ’14, pages 1798–1803.
Carlos Castillo, Marcelo Mendoza, and Barbara
Poblete. 2013. Predicting information credibility
in time-sensitive social media. Internet Research,
23(5):560–588.
Trevor Cohn and Lucia Specia. 2013. Modelling an-
notator bias with multi-task Gaussian processes: An
application to machine translation quality estima-
tion. In 51st Annual Meeting of the Association for
Computational Linguistics, ACL ’13, pages 32–42.
Adrien Friggeri, Lada Adamic, Dean Eckles, and Justin
Cheng. 2014. Rumor cascades. In International
AAAI Conference on Weblogs and Social Media.
The GPy authors. 2015. GPy: A Gaussian process
framework in Python. http://github.com/
SheffieldML/GPy.
Vasileios Lampos, Nikolaos Aletras, Daniel Preotiuc-
Pietro, and Trevor Cohn. 2014. Predicting and
characterising user impact on twitter. In Proceed-
ings of the 14th Conference of the European Chap-
ter of the Association for Computational Linguistics,
EACL’14, pages 405–413.
Clare Llewellyn, Claire Grover, Jon Oberlander, and
Ewan Klein. 2014. Re-using an argument corpus
to aid in the curation of social media collections. In
Proceedings of the Ninth International Conference
on Language Resources and Evaluation, LREC’14,
pages 462–468.
Gilad Lotan, Erhardt Graeff, Mike Ananny, Devin
Gaffney, Ian Pearce, and danah boyd. 2011. The
Arab spring— the revolutions were tweeted: Infor-
mation flows during the 2011 Tunisian and Egyptian
revolutions. International Journal of Communica-
tion, 5(0).
Michal Lukasik, Trevor Cohn, and Kalina Bontcheva.
2015. Point process modelling of rumour dynamics
in social media. In Proceedings of the 53rd Annual
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference
on Natural Language Processing of the Asian Fed-
eration of Natural Language Processing, ACL 2015,
pages 518–523.
Marcelo Mendoza, Barbara Poblete, and Carlos
Castillo. 2010. Twitter under crisis: Can we trust
what we RT? In 1st Workshop on Social Media An-
alytics, SOMA’10, pages 71–79.
Thomas Minka and John Lafferty. 2002. Expectation-
propagation for the generative aspect model. In Pro-
ceedings of the Eighteenth Conference on Uncer-
tainty in Artificial Intelligence, UAI’02, pages 352–
359.
Olutobi Owoputi, Chris Dyer, Kevin Gimpel, Nathan
Schneider, and Noah A. Smith. 2013. Improved
part-of-speech tagging for online conversational text
with word clusters. In Proceedings of NAACL, pages
380–390.
Daniel Preotiuc-Pietro, Vasileios Lampos, and Niko-
laos Aletras. 2015. An analysis of the user occupa-
tional class through twitter content. In Proceedings
of the 53rd Annual Meeting of the Association for
Computational Linguistics and the 7th International
Joint Conference on Natural Language Processing
of the Asian Federation of Natural Language Pro-
cessing, ACL 2015, pages 1754–1764.
Rob Procter, Jeremy Crump, Susanne Karstedt, Alex
Voss, and Marta Cantijoch. 2013. Reading the riots:
What were the police doing on twitter? Policing and
society, 23(4):413–436.
Vahed Qazvinian, Emily Rosengren, Dragomir R.
Radev, and Qiaozhu Mei. 2011. Rumor has it:
Identifying misinformation in microblogs. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, EMNLP ’11, pages
1589–1599.
Carl Edward Rasmussen and Christopher K. I.
Williams. 2005. Gaussian Processes for Ma-
chine Learning (Adaptive Computation and Ma-
chine Learning). The MIT Press.
Jacob Ratkiewicz, Michael Conover, Mark Meiss,
Bruno Gonalves, Alessandro Flammini, and Fil-
ippo Menczer. 2011. Detecting and tracking po-
litical abuse in social media. In 5th International
AAAI Conference on Weblogs and Social Media,
ICWSM’11.
Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015.
Early detection of rumors in social media from en-
quiry posts. In International World Wide Web Con-
ference Committee (IW3C2).
</reference>
<page confidence="0.988428">
2595
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.517737">
<title confidence="0.998966">Classifying Tweet Level Judgements of Rumours in Social Media</title>
<author confidence="0.856748">Trevor</author>
<affiliation confidence="0.8164495">Science and Information Systems The University of Sheffield The University of</affiliation>
<email confidence="0.971998">t.cohn@unimelb.edu.au</email>
<abstract confidence="0.982155">Social media is a rich source of rumours and corresponding community reactions. Rumours reflect different characteristics, some shared and some individual. We formulate the problem of classifying tweet level judgements of rumours as a supervised learning task. Both supervised and unsupervised domain adaptation are considered, in which tweets from a rumour are classified on the basis of other annotated rumours. We demonstrate how multi-task learning helps achieve good results on rumours from the 2011 England riots.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Boyi Xie</author>
<author>Ilia Vovsha</author>
<author>Owen Rambow</author>
<author>Rebecca Passonneau</author>
</authors>
<title>Sentiment analysis of twitter data.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Languages in Social Media, LSM ’11,</booktitle>
<pages>30--38</pages>
<contexts>
<context position="13812" citStr="Agarwal et al., 2011" startWordPosition="2202" endWordPosition="2205">. The first setting (denoted GP) considers only target rumour data for training. The second (GPPooled) additionally considers tweets from reference rumours (i.e. other than the target rumour). The third setting is GPICM, where an ICM kernel is used to weight influence from tweets from reference rumours. 6 Features We conducted a series of preprocessing steps in order to address data sparsity. All words were lowercased; stopwords removed; all emoticons were replaced with words2; and stemming was performed. In addition, multiple occurrences of a character were replaced with a double occurrence (Agarwal et al., 2011), to correct for misspellings and lengthenings, e.g., looool. All punctuation was also removed, except for ., ! and ?, which we hypothesize to be important for expressing emotion. Lastly, usernames were removed as they tend to be rumour-specific, i.e., very few users comment on more than one rumour. After preprocessing the text data, we use either the resulting bag of words (BOW) feature representation or replace all words with their Brown cluster ids (Brown), using 1000 clusters acquired from a large scale Twitter corpus (Owoputi et al., 2013). In all cases, simple re-tweets are removed from </context>
</contexts>
<marker>Agarwal, Xie, Vovsha, Rambow, Passonneau, 2011</marker>
<rawString>Apoorv Agarwal, Boyi Xie, Ilia Vovsha, Owen Rambow, and Rebecca Passonneau. 2011. Sentiment analysis of twitter data. In Proceedings of the Workshop on Languages in Social Media, LSM ’11, pages 30–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauricio A ´Alvarez</author>
<author>Lorenzo Rosasco</author>
<author>Neil D Lawrence</author>
</authors>
<title>Kernels for vector-valued functions: A review.</title>
<date>2012</date>
<journal>Found. Trends Mach. Learn.,</journal>
<volume>4</volume>
<issue>3</issue>
<marker>´Alvarez, Rosasco, Lawrence, 2012</marker>
<rawString>Mauricio A. ´Alvarez, Lorenzo Rosasco, and Neil D. Lawrence. 2012. Kernels for vector-valued functions: A review. Found. Trends Mach. Learn., 4(3):195–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Beck</author>
<author>Trevor Cohn</author>
<author>Lucia Specia</author>
</authors>
<title>Joint emotion analysis via multi-task Gaussian processes.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’14,</booktitle>
<pages>1798--1803</pages>
<contexts>
<context position="9987" citStr="Beck et al., 2014" startWordPosition="1568" endWordPosition="1571">s that. This information can be acquired either via manual annotation as part of expert analysis, as is the case with our dataset, or automatically, e.g. using pattern-based rumour detection (Zhao et al., 2015). Afterwards, our method can be used to classify the attitudes expressed in each new tweet from outside the training set. 5 Gaussian Processes for Classification Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015). We use Gaussian Processes as this probabilistic kernelised framework avoids the need for expensive crossvalidation for hyperparameter selection.1 1There exist frequentist kernel methods, like SVMs, which additionally require extensive heldout parameter tuning. The central concept of Gaussian Process Classification (GPC; (Rasmussen and Williams, 2005)) is a latent function f over inputs x: f(x) ∼ GP(m(x), k(x, x&apos;)), where m is the mean function, assumed to be 0 and k is the kernel function, specifying the degree to which the outputs covary as a function of the i</context>
<context position="12365" citStr="Beck et al., 2014" startWordPosition="1956" endWordPosition="1959">work on occupational class classification (Preotiuc-Pietro et al., 2015). Intrinsic Coregionalization Model In the LPO setting initial labelled tweets from the target rumour are observed as well. In this case, we propose to weight the importance of tweets from the reference rumours depending on how similar their characteristics are to the tweets from the target rumour available for training. To handle this with GPC, we use a multiple output model based on the Intrinsic Coregionalisation Model (ICM; ( ´Alvarez et al., 2012)). It has already been applied successfully to NLP regression problems (Beck et al., 2014) and it can also be applied to classification 2592 ones. ICM parametrizes the kernel by a matrix which represents the extent of covariance between pairs of tasks. The complete kernel takes form of k((x, d), (x&apos;, d&apos;)) = kdata(x, x&apos;)Bd,d&apos; , where B is a square coregionalization matrix, d and d&apos; denote the tasks of the two inputs and kdata is a kernel for comparing inputs x and x&apos; (here, linear). We parametrize the coregionalization matrix B = κI + vvT, where v specifies the correlation between tasks and the vector κ controls extent of task independence. Hyperparameter selection We tune hyperpara</context>
</contexts>
<marker>Beck, Cohn, Specia, 2014</marker>
<rawString>Daniel Beck, Trevor Cohn, and Lucia Specia. 2014. Joint emotion analysis via multi-task Gaussian processes. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’14, pages 1798–1803.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos Castillo</author>
<author>Marcelo Mendoza</author>
<author>Barbara Poblete</author>
</authors>
<title>Predicting information credibility in time-sensitive social media.</title>
<date>2013</date>
<journal>Internet Research,</journal>
<volume>23</volume>
<issue>5</issue>
<contexts>
<context position="4825" citStr="Castillo et al. (2013)" startWordPosition="719" endWordPosition="722">om the Snopes.com website that have been matched to Facebook public conversations. They concluded that false rumours are more likely to receive a comment with link to Snopes.com website. However, none of the above attempted to automatically classify rumours. With respect to automatic methods for detecting misinformation and disinformation in social media, Ratkiewicz et al. (2011) detect political abuse (a kind of disinformation) spread through Twitter. The task is defined in purely information diffusion settings and is not necessarily related with the truthfulness of the piece of information. Castillo et al. (2013) proposed methods for identifying newsworthy information cascades on Twitter and then classifying these cascades as credible and not credible. The main difference from our task is that credibility classification is carried out over the entire information cascade, classified objects are not necessarily rumours and no explicit judgement classification was performed in their approach. Early rumour identification is the focus of Zhao et al. (2015), where regular expressions are used for finding questioning and denying tweets as a key pre-requisite step for rumour detection. Unfortunately, when we </context>
</contexts>
<marker>Castillo, Mendoza, Poblete, 2013</marker>
<rawString>Carlos Castillo, Marcelo Mendoza, and Barbara Poblete. 2013. Predicting information credibility in time-sensitive social media. Internet Research, 23(5):560–588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Lucia Specia</author>
</authors>
<title>Modelling annotator bias with multi-task Gaussian processes: An application to machine translation quality estimation.</title>
<date>2013</date>
<booktitle>In 51st Annual Meeting of the Association for Computational Linguistics, ACL ’13,</booktitle>
<pages>32--42</pages>
<contexts>
<context position="9947" citStr="Cohn and Specia, 2013" startWordPosition="1560" endWordPosition="1563"> discussed and the attitude expressed towards that. This information can be acquired either via manual annotation as part of expert analysis, as is the case with our dataset, or automatically, e.g. using pattern-based rumour detection (Zhao et al., 2015). Afterwards, our method can be used to classify the attitudes expressed in each new tweet from outside the training set. 5 Gaussian Processes for Classification Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015). We use Gaussian Processes as this probabilistic kernelised framework avoids the need for expensive crossvalidation for hyperparameter selection.1 1There exist frequentist kernel methods, like SVMs, which additionally require extensive heldout parameter tuning. The central concept of Gaussian Process Classification (GPC; (Rasmussen and Williams, 2005)) is a latent function f over inputs x: f(x) ∼ GP(m(x), k(x, x&apos;)), where m is the mean function, assumed to be 0 and k is the kernel function, specifying the degree to which t</context>
</contexts>
<marker>Cohn, Specia, 2013</marker>
<rawString>Trevor Cohn and Lucia Specia. 2013. Modelling annotator bias with multi-task Gaussian processes: An application to machine translation quality estimation. In 51st Annual Meeting of the Association for Computational Linguistics, ACL ’13, pages 32–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adrien Friggeri</author>
<author>Lada Adamic</author>
<author>Dean Eckles</author>
<author>Justin Cheng</author>
</authors>
<title>Rumor cascades.</title>
<date>2014</date>
<booktitle>In International AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="4177" citStr="Friggeri et al. (2014)" startWordPosition="622" endWordPosition="625">, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. tion flows between content of varying credibility. For instance, Procter et al. (2013) grouped source tweets and re-tweets into information flows (Lotan et al., 2011), then ranked these by flow size, as a proxy of significance. Information flows were then categorised manually. Along similar vein, Mendoza et al. (2010) found that users deal with true and false rumours differently: the former are affirmed more than 90% of the time, whereas the latter are challenged (questioned or denied) 50% of the time. Friggeri et al. (2014) analyzed a set rumours from the Snopes.com website that have been matched to Facebook public conversations. They concluded that false rumours are more likely to receive a comment with link to Snopes.com website. However, none of the above attempted to automatically classify rumours. With respect to automatic methods for detecting misinformation and disinformation in social media, Ratkiewicz et al. (2011) detect political abuse (a kind of disinformation) spread through Twitter. The task is defined in purely information diffusion settings and is not necessarily related with the truthfulness of </context>
</contexts>
<marker>Friggeri, Adamic, Eckles, Cheng, 2014</marker>
<rawString>Adrien Friggeri, Lada Adamic, Dean Eckles, and Justin Cheng. 2014. Rumor cascades. In International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<title>The GPy authors.</title>
<date>2015</date>
<note>http://github.com/ SheffieldML/GPy.</note>
<contexts>
<context position="5272" citStr="(2015)" startWordPosition="787" endWordPosition="787">sk is defined in purely information diffusion settings and is not necessarily related with the truthfulness of the piece of information. Castillo et al. (2013) proposed methods for identifying newsworthy information cascades on Twitter and then classifying these cascades as credible and not credible. The main difference from our task is that credibility classification is carried out over the entire information cascade, classified objects are not necessarily rumours and no explicit judgement classification was performed in their approach. Early rumour identification is the focus of Zhao et al. (2015), where regular expressions are used for finding questioning and denying tweets as a key pre-requisite step for rumour detection. Unfortunately, when we applied these regular expressions on our dataset, they yielded only 16% recall for questioning and 14% recall for denying tweets. Consequently, this motivated us to seek a better approach to tweet-level classification. The work most relevant to ours is due to Qazvinian et al. (2011). Their method first carries out rumour retrieval, whereby tweets are classified into rumour related and non-rumour related. Next, rumour-related tweets are classif</context>
</contexts>
<marker>2015</marker>
<rawString>The GPy authors. 2015. GPy: A Gaussian process framework in Python. http://github.com/ SheffieldML/GPy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Lampos</author>
<author>Nikolaos Aletras</author>
<author>Daniel PreotiucPietro</author>
<author>Trevor Cohn</author>
</authors>
<title>Predicting and characterising user impact on twitter.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, EACL’14,</booktitle>
<pages>405--413</pages>
<contexts>
<context position="9968" citStr="Lampos et al., 2014" startWordPosition="1564" endWordPosition="1567">tude expressed towards that. This information can be acquired either via manual annotation as part of expert analysis, as is the case with our dataset, or automatically, e.g. using pattern-based rumour detection (Zhao et al., 2015). Afterwards, our method can be used to classify the attitudes expressed in each new tweet from outside the training set. 5 Gaussian Processes for Classification Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015). We use Gaussian Processes as this probabilistic kernelised framework avoids the need for expensive crossvalidation for hyperparameter selection.1 1There exist frequentist kernel methods, like SVMs, which additionally require extensive heldout parameter tuning. The central concept of Gaussian Process Classification (GPC; (Rasmussen and Williams, 2005)) is a latent function f over inputs x: f(x) ∼ GP(m(x), k(x, x&apos;)), where m is the mean function, assumed to be 0 and k is the kernel function, specifying the degree to which the outputs covary as </context>
</contexts>
<marker>Lampos, Aletras, PreotiucPietro, Cohn, 2014</marker>
<rawString>Vasileios Lampos, Nikolaos Aletras, Daniel PreotiucPietro, and Trevor Cohn. 2014. Predicting and characterising user impact on twitter. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, EACL’14, pages 405–413.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clare Llewellyn</author>
<author>Claire Grover</author>
<author>Jon Oberlander</author>
<author>Ewan Klein</author>
</authors>
<title>Re-using an argument corpus to aid in the curation of social media collections.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation, LREC’14,</booktitle>
<pages>462--468</pages>
<contexts>
<context position="14469" citStr="Llewellyn et al., 2014" startWordPosition="2311" endWordPosition="2314">lengthenings, e.g., looool. All punctuation was also removed, except for ., ! and ?, which we hypothesize to be important for expressing emotion. Lastly, usernames were removed as they tend to be rumour-specific, i.e., very few users comment on more than one rumour. After preprocessing the text data, we use either the resulting bag of words (BOW) feature representation or replace all words with their Brown cluster ids (Brown), using 1000 clusters acquired from a large scale Twitter corpus (Owoputi et al., 2013). In all cases, simple re-tweets are removed from the training set to prevent bias (Llewellyn et al., 2014). 2We used the dictionary from: http://bit.ly/ 1rX1Hdk and extended it with: :o, : 1, =/, :s, :S, :p. method acc Majority 0.68 GPPooled Brown 0.72 GPPooled BOW 0.69 Table 3: Accuracy taken across all rumours in the LOO setting. 7 Experiments and Discussion Table 3 shows the mean accuracy in the LOO scenario following the GPPooled method, which pools all reference rumours together ignoring their task identities. ICM can not use correlations to target rumour in this case and so can not be used. The majority baseline simply assigns the most frequent class from the training set. We can observe tha</context>
</contexts>
<marker>Llewellyn, Grover, Oberlander, Klein, 2014</marker>
<rawString>Clare Llewellyn, Claire Grover, Jon Oberlander, and Ewan Klein. 2014. Re-using an argument corpus to aid in the curation of social media collections. In Proceedings of the Ninth International Conference on Language Resources and Evaluation, LREC’14, pages 462–468.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gilad Lotan</author>
<author>Erhardt Graeff</author>
<author>Mike Ananny</author>
<author>Devin Gaffney</author>
<author>Ian Pearce</author>
<author>danah boyd</author>
</authors>
<title>The Arab spring— the revolutions were tweeted: Information flows during the 2011 Tunisian and Egyptian revolutions.</title>
<date>2011</date>
<journal>International Journal of Communication,</journal>
<volume>5</volume>
<issue>0</issue>
<contexts>
<context position="3813" citStr="Lotan et al., 2011" startWordPosition="562" endWordPosition="565">in both supervised and unsupervised domain adaptation settings. 2. Showing how a multi-task learning approach outperforms singletask methods. 2 Related work In the context of rumour spread in social media, researchers have studied differences in informa2590 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2590–2595, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. tion flows between content of varying credibility. For instance, Procter et al. (2013) grouped source tweets and re-tweets into information flows (Lotan et al., 2011), then ranked these by flow size, as a proxy of significance. Information flows were then categorised manually. Along similar vein, Mendoza et al. (2010) found that users deal with true and false rumours differently: the former are affirmed more than 90% of the time, whereas the latter are challenged (questioned or denied) 50% of the time. Friggeri et al. (2014) analyzed a set rumours from the Snopes.com website that have been matched to Facebook public conversations. They concluded that false rumours are more likely to receive a comment with link to Snopes.com website. However, none of the ab</context>
</contexts>
<marker>Lotan, Graeff, Ananny, Gaffney, Pearce, boyd, 2011</marker>
<rawString>Gilad Lotan, Erhardt Graeff, Mike Ananny, Devin Gaffney, Ian Pearce, and danah boyd. 2011. The Arab spring— the revolutions were tweeted: Information flows during the 2011 Tunisian and Egyptian revolutions. International Journal of Communication, 5(0).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Lukasik</author>
<author>Trevor Cohn</author>
<author>Kalina Bontcheva</author>
</authors>
<title>Point process modelling of rumour dynamics in social media.</title>
<date>2015</date>
<booktitle>In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL</booktitle>
<pages>518--523</pages>
<marker>Lukasik, Cohn, Bontcheva, 2015</marker>
<rawString>Michal Lukasik, Trevor Cohn, and Kalina Bontcheva. 2015. Point process modelling of rumour dynamics in social media. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, pages 518–523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcelo Mendoza</author>
<author>Barbara Poblete</author>
<author>Carlos Castillo</author>
</authors>
<title>Twitter under crisis: Can we trust what we RT?</title>
<date>2010</date>
<booktitle>In 1st Workshop on Social Media Analytics, SOMA’10,</booktitle>
<pages>71--79</pages>
<contexts>
<context position="1178" citStr="Mendoza et al., 2010" startWordPosition="169" endWordPosition="172">pervised and unsupervised domain adaptation are considered, in which tweets from a rumour are classified on the basis of other annotated rumours. We demonstrate how multi-task learning helps achieve good results on rumours from the 2011 England riots. 1 Introduction There is an increasing need to interpret and act upon rumours spreading quickly through social media, especially in circumstances where their veracity is hard to establish. For instance, during an earthquake in Chile rumours spread through Twitter that a volcano had become active and that there was a tsunami warning in Valparaiso (Mendoza et al., 2010). Other examples, from the riots in England in 2011, were that rioters were going to attack Birmingham’s children hospital and that animals had escaped from the zoo (Procter et al., 2013). Social scientists (Procter et al., 2013) analysed manually a sample of tweets expressing different judgements towards rumours and categorised them manually in supporting, denying or questioning. The goal here is to carry out tweet-level judgement classification automatically, in order to assist in (near) real-time rumour monitoring by journalists and authorities (Procter et al., 2013). In addition, informati</context>
<context position="3966" citStr="Mendoza et al. (2010)" startWordPosition="586" endWordPosition="589"> work In the context of rumour spread in social media, researchers have studied differences in informa2590 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2590–2595, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. tion flows between content of varying credibility. For instance, Procter et al. (2013) grouped source tweets and re-tweets into information flows (Lotan et al., 2011), then ranked these by flow size, as a proxy of significance. Information flows were then categorised manually. Along similar vein, Mendoza et al. (2010) found that users deal with true and false rumours differently: the former are affirmed more than 90% of the time, whereas the latter are challenged (questioned or denied) 50% of the time. Friggeri et al. (2014) analyzed a set rumours from the Snopes.com website that have been matched to Facebook public conversations. They concluded that false rumours are more likely to receive a comment with link to Snopes.com website. However, none of the above attempted to automatically classify rumours. With respect to automatic methods for detecting misinformation and disinformation in social media, Ratki</context>
<context position="7504" citStr="Mendoza et al., 2010" startWordPosition="1144" endWordPosition="1147">ots in 2011 (see Table 2). The dataset was analysed and annotated manually as supporting, questioning, or denying a rumour, by a team of social scientists studying the role of social media during the riots (Procter et al., 2013). The original dataset also included commenting tweets, but these have been removed from our experiments due to their small number (they constituted only 5% of the corpus). As can be seen from the dataset overview in Table 2, different rumours exhibit varying proportions of supporting, denying and questioning tweets, which was also observed in other studies of rumours (Mendoza et al., 2010; Qazvinian et al., 2011). These variations in majority classes across rumours underscores the modeling challenge in tweet-level classification of rumour attitudes. With respect to veracity, one rumour has been confirmed as true (Miss Selfridge’s being on fire), one is unsubstantiated (police beat girl), and the remaining five are known to be false. Note, however, that the focus here is not on classifying truthfulness, but instead on identifying the attitude expressed in each tweet towards the rumour. 2591 4 Problem formulation Let R be a set of rumours, each of which consists of tweets discus</context>
</contexts>
<marker>Mendoza, Poblete, Castillo, 2010</marker>
<rawString>Marcelo Mendoza, Barbara Poblete, and Carlos Castillo. 2010. Twitter under crisis: Can we trust what we RT? In 1st Workshop on Social Media Analytics, SOMA’10, pages 71–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Minka</author>
<author>John Lafferty</author>
</authors>
<title>Expectationpropagation for the generative aspect model.</title>
<date>2002</date>
<booktitle>In Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence, UAI’02,</booktitle>
<pages>352--359</pages>
<contexts>
<context position="11322" citStr="Minka and Lafferty, 2002" startWordPosition="1790" endWordPosition="1793">f) into the range [0, 1], such that the resulting value can be interpreted as p(y = 1|x). The GPC posterior is calculated as � p(f*|X, x*,p(f*|X,y,x*) = |y|X p(f)df, ) n where p(y|f) = H Φ(fj)yj(1−Φ(fj))1−yj is the j=1 Bernoulli likelihood of class y. After calculating the above posterior from the training data, this is used in prediction, i.e., �p(y* =1|X, y, x*)= Φ (f*) p (f*|X, y, x*) df* . The above integrals are intractable and approximation techniques are required to solve them. There exist various methods to deal with calculating the posterior; here we use Expectation Propagation (EP; (Minka and Lafferty, 2002)). In EP, the posterior is approximated by a fully factorised distribution, where each component is assumed to be an unnormalised Gaussian. In order to conduct multi-class classification, we perform a one-vs-all classification for each label and then assign the one with the highest likelihood, amongst the three (supporting, denying, questioning). We choose this method due to interpretability of results, similar to recent work on occupational class classification (Preotiuc-Pietro et al., 2015). Intrinsic Coregionalization Model In the LPO setting initial labelled tweets from the target rumour a</context>
</contexts>
<marker>Minka, Lafferty, 2002</marker>
<rawString>Thomas Minka and John Lafferty. 2002. Expectationpropagation for the generative aspect model. In Proceedings of the Eighteenth Conference on Uncertainty in Artificial Intelligence, UAI’02, pages 352– 359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olutobi Owoputi</author>
<author>Chris Dyer</author>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Noah A Smith</author>
</authors>
<title>Improved part-of-speech tagging for online conversational text with word clusters.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>380--390</pages>
<contexts>
<context position="14362" citStr="Owoputi et al., 2013" startWordPosition="2293" endWordPosition="2296">character were replaced with a double occurrence (Agarwal et al., 2011), to correct for misspellings and lengthenings, e.g., looool. All punctuation was also removed, except for ., ! and ?, which we hypothesize to be important for expressing emotion. Lastly, usernames were removed as they tend to be rumour-specific, i.e., very few users comment on more than one rumour. After preprocessing the text data, we use either the resulting bag of words (BOW) feature representation or replace all words with their Brown cluster ids (Brown), using 1000 clusters acquired from a large scale Twitter corpus (Owoputi et al., 2013). In all cases, simple re-tweets are removed from the training set to prevent bias (Llewellyn et al., 2014). 2We used the dictionary from: http://bit.ly/ 1rX1Hdk and extended it with: :o, : 1, =/, :s, :S, :p. method acc Majority 0.68 GPPooled Brown 0.72 GPPooled BOW 0.69 Table 3: Accuracy taken across all rumours in the LOO setting. 7 Experiments and Discussion Table 3 shows the mean accuracy in the LOO scenario following the GPPooled method, which pools all reference rumours together ignoring their task identities. ICM can not use correlations to target rumour in this case and so can not be u</context>
</contexts>
<marker>Owoputi, Dyer, Gimpel, Schneider, Smith, 2013</marker>
<rawString>Olutobi Owoputi, Chris Dyer, Kevin Gimpel, Nathan Schneider, and Noah A. Smith. 2013. Improved part-of-speech tagging for online conversational text with word clusters. In Proceedings of NAACL, pages 380–390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Preotiuc-Pietro</author>
<author>Vasileios Lampos</author>
<author>Nikolaos Aletras</author>
</authors>
<title>An analysis of the user occupational class through twitter content.</title>
<date>2015</date>
<booktitle>In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL</booktitle>
<pages>1754--1764</pages>
<contexts>
<context position="10018" citStr="Preotiuc-Pietro et al., 2015" startWordPosition="1572" endWordPosition="1575">ation can be acquired either via manual annotation as part of expert analysis, as is the case with our dataset, or automatically, e.g. using pattern-based rumour detection (Zhao et al., 2015). Afterwards, our method can be used to classify the attitudes expressed in each new tweet from outside the training set. 5 Gaussian Processes for Classification Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015). We use Gaussian Processes as this probabilistic kernelised framework avoids the need for expensive crossvalidation for hyperparameter selection.1 1There exist frequentist kernel methods, like SVMs, which additionally require extensive heldout parameter tuning. The central concept of Gaussian Process Classification (GPC; (Rasmussen and Williams, 2005)) is a latent function f over inputs x: f(x) ∼ GP(m(x), k(x, x&apos;)), where m is the mean function, assumed to be 0 and k is the kernel function, specifying the degree to which the outputs covary as a function of the inputs. We use a linear kernel, </context>
<context position="11819" citStr="Preotiuc-Pietro et al., 2015" startWordPosition="1865" endWordPosition="1868">re exist various methods to deal with calculating the posterior; here we use Expectation Propagation (EP; (Minka and Lafferty, 2002)). In EP, the posterior is approximated by a fully factorised distribution, where each component is assumed to be an unnormalised Gaussian. In order to conduct multi-class classification, we perform a one-vs-all classification for each label and then assign the one with the highest likelihood, amongst the three (supporting, denying, questioning). We choose this method due to interpretability of results, similar to recent work on occupational class classification (Preotiuc-Pietro et al., 2015). Intrinsic Coregionalization Model In the LPO setting initial labelled tweets from the target rumour are observed as well. In this case, we propose to weight the importance of tweets from the reference rumours depending on how similar their characteristics are to the tweets from the target rumour available for training. To handle this with GPC, we use a multiple output model based on the Intrinsic Coregionalisation Model (ICM; ( ´Alvarez et al., 2012)). It has already been applied successfully to NLP regression problems (Beck et al., 2014) and it can also be applied to classification 2592 one</context>
</contexts>
<marker>Preotiuc-Pietro, Lampos, Aletras, 2015</marker>
<rawString>Daniel Preotiuc-Pietro, Vasileios Lampos, and Nikolaos Aletras. 2015. An analysis of the user occupational class through twitter content. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, pages 1754–1764.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rob Procter</author>
<author>Jeremy Crump</author>
<author>Susanne Karstedt</author>
<author>Alex Voss</author>
<author>Marta Cantijoch</author>
</authors>
<title>Reading the riots: What were the police doing on twitter? Policing and society,</title>
<date>2013</date>
<pages>23--4</pages>
<contexts>
<context position="1365" citStr="Procter et al., 2013" startWordPosition="201" endWordPosition="204">lps achieve good results on rumours from the 2011 England riots. 1 Introduction There is an increasing need to interpret and act upon rumours spreading quickly through social media, especially in circumstances where their veracity is hard to establish. For instance, during an earthquake in Chile rumours spread through Twitter that a volcano had become active and that there was a tsunami warning in Valparaiso (Mendoza et al., 2010). Other examples, from the riots in England in 2011, were that rioters were going to attack Birmingham’s children hospital and that animals had escaped from the zoo (Procter et al., 2013). Social scientists (Procter et al., 2013) analysed manually a sample of tweets expressing different judgements towards rumours and categorised them manually in supporting, denying or questioning. The goal here is to carry out tweet-level judgement classification automatically, in order to assist in (near) real-time rumour monitoring by journalists and authorities (Procter et al., 2013). In addition, information about tweet-level judgements has been used as a first step for early rumour detection by (Zhao et al., 2015). The focus here is on tweet-level judgement classification on unseen rumour</context>
<context position="3733" citStr="Procter et al. (2013)" startWordPosition="550" endWordPosition="553">f this paper are: 1. Formulating the problem of classifying judgements of rumours in both supervised and unsupervised domain adaptation settings. 2. Showing how a multi-task learning approach outperforms singletask methods. 2 Related work In the context of rumour spread in social media, researchers have studied differences in informa2590 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2590–2595, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. tion flows between content of varying credibility. For instance, Procter et al. (2013) grouped source tweets and re-tweets into information flows (Lotan et al., 2011), then ranked these by flow size, as a proxy of significance. Information flows were then categorised manually. Along similar vein, Mendoza et al. (2010) found that users deal with true and false rumours differently: the former are affirmed more than 90% of the time, whereas the latter are challenged (questioned or denied) 50% of the time. Friggeri et al. (2014) analyzed a set rumours from the Snopes.com website that have been matched to Facebook public conversations. They concluded that false rumours are more like</context>
<context position="7112" citStr="Procter et al., 2013" startWordPosition="1081" endWordPosition="1084"> tweets observed) are classified using already known rumours – a much harder and more practical setting. Moreover, unlike Qazvinian et al. (2011), we consider the multi-class classification problem and do not collaps questioning and denying tweets into a single class, since they differ significantly. 3 Data We evaluate our work on several rumours circulating on Twitter during the England riots in 2011 (see Table 2). The dataset was analysed and annotated manually as supporting, questioning, or denying a rumour, by a team of social scientists studying the role of social media during the riots (Procter et al., 2013). The original dataset also included commenting tweets, but these have been removed from our experiments due to their small number (they constituted only 5% of the corpus). As can be seen from the dataset overview in Table 2, different rumours exhibit varying proportions of supporting, denying and questioning tweets, which was also observed in other studies of rumours (Mendoza et al., 2010; Qazvinian et al., 2011). These variations in majority classes across rumours underscores the modeling challenge in tweet-level classification of rumour attitudes. With respect to veracity, one rumour has be</context>
</contexts>
<marker>Procter, Crump, Karstedt, Voss, Cantijoch, 2013</marker>
<rawString>Rob Procter, Jeremy Crump, Susanne Karstedt, Alex Voss, and Marta Cantijoch. 2013. Reading the riots: What were the police doing on twitter? Policing and society, 23(4):413–436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vahed Qazvinian</author>
<author>Emily Rosengren</author>
<author>Dragomir R Radev</author>
<author>Qiaozhu Mei</author>
</authors>
<title>Rumor has it: Identifying misinformation in microblogs.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1589--1599</pages>
<contexts>
<context position="2611" citStr="Qazvinian et al., 2011" startWordPosition="385" endWordPosition="388">text position Birmingham Children’s hospital has support been attacked. F***ing morons. #UKRiots Girlfriend has just called her ward deny in Birmingham Children’s Hospital &amp; there’s no sign of any trouble #Birminghamriots Birmingham children’s hospital question guarded by police? Really? Who would target a childrens hospital #disgusting #Birminghamriots Table 1: Tweets on a rumour about hospital being attacked during 2011 England Riots. set of other already annotated rumours. Previous work on this problem either considered unrealistic settings ignoring temporal ordering and rumour identities (Qazvinian et al., 2011) or proposed regular expressions as a solution (Zhao et al., 2015). We expect posts expressing similar opinions to exhibit many similar characteristics across different rumours. Based on the assumption of a common underlying linguistic signal, we build a transfer learning system that labels newly emerging rumours for which we have little or no annotated data. Results demonstrate that Gaussian Processbased multi task learning allows for significantly improved performance. The novel contributions of this paper are: 1. Formulating the problem of classifying judgements of rumours in both supervise</context>
<context position="5708" citStr="Qazvinian et al. (2011)" startWordPosition="853" endWordPosition="856">de, classified objects are not necessarily rumours and no explicit judgement classification was performed in their approach. Early rumour identification is the focus of Zhao et al. (2015), where regular expressions are used for finding questioning and denying tweets as a key pre-requisite step for rumour detection. Unfortunately, when we applied these regular expressions on our dataset, they yielded only 16% recall for questioning and 14% recall for denying tweets. Consequently, this motivated us to seek a better approach to tweet-level classification. The work most relevant to ours is due to Qazvinian et al. (2011). Their method first carries out rumour retrieval, whereby tweets are classified into rumour related and non-rumour related. Next, rumour-related tweets are classified into supporting and not-supporting. The classifier is trained by ignoring rumour identities, i.e., pooling together tweets from all rumours, and ignoring the temporal dependencies between tweets. In contrast, we formulate the rumour classificaRumour Supporting Denying Questioning army bank 62 42 73 hospital 796 487 132 London Eye 177 295 160 McDonald’s 177 0 13 Miss Selfridge’s 3150 0 7 police beat girl 783 4 95 zoo 616 129 99 T</context>
<context position="7529" citStr="Qazvinian et al., 2011" startWordPosition="1148" endWordPosition="1151"> 2). The dataset was analysed and annotated manually as supporting, questioning, or denying a rumour, by a team of social scientists studying the role of social media during the riots (Procter et al., 2013). The original dataset also included commenting tweets, but these have been removed from our experiments due to their small number (they constituted only 5% of the corpus). As can be seen from the dataset overview in Table 2, different rumours exhibit varying proportions of supporting, denying and questioning tweets, which was also observed in other studies of rumours (Mendoza et al., 2010; Qazvinian et al., 2011). These variations in majority classes across rumours underscores the modeling challenge in tweet-level classification of rumour attitudes. With respect to veracity, one rumour has been confirmed as true (Miss Selfridge’s being on fire), one is unsubstantiated (police beat girl), and the remaining five are known to be false. Note, however, that the focus here is not on classifying truthfulness, but instead on identifying the attitude expressed in each tweet towards the rumour. 2591 4 Problem formulation Let R be a set of rumours, each of which consists of tweets discussing it, ∀rER Tr = {tr1, </context>
</contexts>
<marker>Qazvinian, Rosengren, Radev, Mei, 2011</marker>
<rawString>Vahed Qazvinian, Emily Rosengren, Dragomir R. Radev, and Qiaozhu Mei. 2011. Rumor has it: Identifying misinformation in microblogs. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1589–1599.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Edward Rasmussen</author>
<author>Christopher K I Williams</author>
</authors>
<date>2005</date>
<booktitle>Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning).</booktitle>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="10372" citStr="Rasmussen and Williams, 2005" startWordPosition="1618" endWordPosition="1621">aussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015). We use Gaussian Processes as this probabilistic kernelised framework avoids the need for expensive crossvalidation for hyperparameter selection.1 1There exist frequentist kernel methods, like SVMs, which additionally require extensive heldout parameter tuning. The central concept of Gaussian Process Classification (GPC; (Rasmussen and Williams, 2005)) is a latent function f over inputs x: f(x) ∼ GP(m(x), k(x, x&apos;)), where m is the mean function, assumed to be 0 and k is the kernel function, specifying the degree to which the outputs covary as a function of the inputs. We use a linear kernel, k(x, x&apos;) = σ2xTx&apos;. The latent function is then mapped by the probit function Φ(f) into the range [0, 1], such that the resulting value can be interpreted as p(y = 1|x). The GPC posterior is calculated as � p(f*|X, x*,p(f*|X,y,x*) = |y|X p(f)df, ) n where p(y|f) = H Φ(fj)yj(1−Φ(fj))1−yj is the j=1 Bernoulli likelihood of class y. After calculating the a</context>
<context position="16443" citStr="Rasmussen and Williams, 2005" startWordPosition="2635" endWordPosition="2638">s is very important, as methods using only the target rumour obtain accuracy similar to the Majority vote classifier (GP Brown and GP BOW). The top performing methods are GPCIM and GPPooled, where use of Brown clusters consistently improves results for both methods over BOW, irrespective of the number of tweets about the target rumour annotated for training. Moreover, GPICM is better than GPPooled both with Brown and BOW features and GPCIM with Brown is ultimately the best performing of all. In order to analyse the importance of Brown clusters, Automatic Relevance Determination (ARD) is used (Rasmussen and Williams, 2005) for the best performing GPICM Brown in the LPO scenario. Only the case where the first 10 tweets are used for training is considered, since it already 2593 Figure 1: Accuracy measures for different methods versus the size of the target rumour used for training in the LPO setting. The test set is fixed to all but the first 50 tweets of the target rumour. supporting denying questioning ? fake ? 10001101 11111000001 10001101 ! not ! 10001100 001000 10001100 not ? hope 001000 10001101 01000111110 fake ! true 11111000001 10001100 111110010110 true bullshit searching 111110010110 11110101011111 011</context>
</contexts>
<marker>Rasmussen, Williams, 2005</marker>
<rawString>Carl Edward Rasmussen and Christopher K. I. Williams. 2005. Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning). The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Ratkiewicz</author>
<author>Michael Conover</author>
<author>Mark Meiss</author>
<author>Bruno Gonalves</author>
<author>Alessandro Flammini</author>
<author>Filippo Menczer</author>
</authors>
<title>Detecting and tracking political abuse in social media.</title>
<date>2011</date>
<booktitle>In 5th International AAAI Conference on Weblogs and Social Media, ICWSM’11.</booktitle>
<contexts>
<context position="4585" citStr="Ratkiewicz et al. (2011)" startWordPosition="683" endWordPosition="686">2010) found that users deal with true and false rumours differently: the former are affirmed more than 90% of the time, whereas the latter are challenged (questioned or denied) 50% of the time. Friggeri et al. (2014) analyzed a set rumours from the Snopes.com website that have been matched to Facebook public conversations. They concluded that false rumours are more likely to receive a comment with link to Snopes.com website. However, none of the above attempted to automatically classify rumours. With respect to automatic methods for detecting misinformation and disinformation in social media, Ratkiewicz et al. (2011) detect political abuse (a kind of disinformation) spread through Twitter. The task is defined in purely information diffusion settings and is not necessarily related with the truthfulness of the piece of information. Castillo et al. (2013) proposed methods for identifying newsworthy information cascades on Twitter and then classifying these cascades as credible and not credible. The main difference from our task is that credibility classification is carried out over the entire information cascade, classified objects are not necessarily rumours and no explicit judgement classification was perf</context>
</contexts>
<marker>Ratkiewicz, Conover, Meiss, Gonalves, Flammini, Menczer, 2011</marker>
<rawString>Jacob Ratkiewicz, Michael Conover, Mark Meiss, Bruno Gonalves, Alessandro Flammini, and Filippo Menczer. 2011. Detecting and tracking political abuse in social media. In 5th International AAAI Conference on Weblogs and Social Media, ICWSM’11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhe Zhao</author>
<author>Paul Resnick</author>
<author>Qiaozhu Mei</author>
</authors>
<title>Early detection of rumors in social media from enquiry posts.</title>
<date>2015</date>
<booktitle>In International World Wide Web Conference Committee (IW3C2).</booktitle>
<contexts>
<context position="1889" citStr="Zhao et al., 2015" startWordPosition="281" endWordPosition="284">irmingham’s children hospital and that animals had escaped from the zoo (Procter et al., 2013). Social scientists (Procter et al., 2013) analysed manually a sample of tweets expressing different judgements towards rumours and categorised them manually in supporting, denying or questioning. The goal here is to carry out tweet-level judgement classification automatically, in order to assist in (near) real-time rumour monitoring by journalists and authorities (Procter et al., 2013). In addition, information about tweet-level judgements has been used as a first step for early rumour detection by (Zhao et al., 2015). The focus here is on tweet-level judgement classification on unseen rumours, based on a training text position Birmingham Children’s hospital has support been attacked. F***ing morons. #UKRiots Girlfriend has just called her ward deny in Birmingham Children’s Hospital &amp; there’s no sign of any trouble #Birminghamriots Birmingham children’s hospital question guarded by police? Really? Who would target a childrens hospital #disgusting #Birminghamriots Table 1: Tweets on a rumour about hospital being attacked during 2011 England Riots. set of other already annotated rumours. Previous work on thi</context>
<context position="5272" citStr="Zhao et al. (2015)" startWordPosition="784" endWordPosition="787">tter. The task is defined in purely information diffusion settings and is not necessarily related with the truthfulness of the piece of information. Castillo et al. (2013) proposed methods for identifying newsworthy information cascades on Twitter and then classifying these cascades as credible and not credible. The main difference from our task is that credibility classification is carried out over the entire information cascade, classified objects are not necessarily rumours and no explicit judgement classification was performed in their approach. Early rumour identification is the focus of Zhao et al. (2015), where regular expressions are used for finding questioning and denying tweets as a key pre-requisite step for rumour detection. Unfortunately, when we applied these regular expressions on our dataset, they yielded only 16% recall for questioning and 14% recall for denying tweets. Consequently, this motivated us to seek a better approach to tweet-level classification. The work most relevant to ours is due to Qazvinian et al. (2011). Their method first carries out rumour retrieval, whereby tweets are classified into rumour related and non-rumour related. Next, rumour-related tweets are classif</context>
<context position="9580" citStr="Zhao et al., 2015" startWordPosition="1501" endWordPosition="1504">ts have started monitoring and analysing the related tweet stream. The experiments section investigates how the number of initial training tweets influences classification performance on a fixed test set, namely: {trrl, · · · , trrn}, l &gt; k. The tweet-level classification problem here assumes that tweets from the training set are already labelled with the rumour discussed and the attitude expressed towards that. This information can be acquired either via manual annotation as part of expert analysis, as is the case with our dataset, or automatically, e.g. using pattern-based rumour detection (Zhao et al., 2015). Afterwards, our method can be used to classify the attitudes expressed in each new tweet from outside the training set. 5 Gaussian Processes for Classification Gaussian Processes are a Bayesian non-parametric machine learning framework that has been shown to work well for a range of NLP problems, often beating other state-of-the-art methods (Cohn and Specia, 2013; Lampos et al., 2014; Beck et al., 2014; Preotiuc-Pietro et al., 2015). We use Gaussian Processes as this probabilistic kernelised framework avoids the need for expensive crossvalidation for hyperparameter selection.1 1There exist f</context>
</contexts>
<marker>Zhao, Resnick, Mei, 2015</marker>
<rawString>Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. Early detection of rumors in social media from enquiry posts. In International World Wide Web Conference Committee (IW3C2).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>