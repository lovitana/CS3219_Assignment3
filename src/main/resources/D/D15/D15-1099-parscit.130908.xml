<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007892">
<title confidence="0.9951835">
Multi-label Text Categorization with Joint Learning
Predictions-as-Features Method
</title>
<author confidence="0.663117">
Li Li&apos; Baobao Chang&apos; Shi Zhao&apos; Lei Sha&apos; Xu Sun&apos; Houfeng Wang&apos;
</author>
<note confidence="0.9464365">
Key Laboratory of Computational Linguistics(Peking University), Ministry of Education, China&apos;
Key Laboratory on Machine Perception(Peking University), Ministry of Education, China&apos;
</note>
<email confidence="0.964668">
{li.l, chbb, shalei, z.s, xusun, wanghf}@pku.edu.cn
</email>
<sectionHeader confidence="0.993695" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954285714286">
Multi-label text categorization is a type of
text categorization, where each document
is assigned to one or more categories. Re-
cently, a series of methods have been de-
veloped, which train a classifier for each
label, organize the classifiers in a partially
ordered structure and take predictions pro-
duced by the former classifiers as the latter
classifiers’ features. These predictions-as-
features style methods model high order
label dependencies and obtain high per-
formance. Nevertheless, the predictions-
as-features methods suffer a drawback.
When training a classifier for one label, the
predictions-as-features methods can mod-
el dependencies between former labels and
the current label, but they can’t model de-
pendencies between the current label and
the latter labels. To address this problem,
we propose a novel joint learning algorith-
m that allows the feedbacks to be propa-
gated from the classifiers for latter labels
to the classifier for the current label. We
conduct experiments using real-world tex-
tual data sets, and these experiments il-
lustrate the predictions-as-features models
trained by our algorithm outperform the o-
riginal models.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99972654">
The multi-label text categorization is a type of text
categorization, where each document is assigned
to one or more categories simultaneously. The
multi-label setting is common and useful in the re-
al world. For example, in the news categorization
task, a newspaper article concerning global warm-
ing can be classified into two categories simul-
taneously, namely environment and science. For
another example, in the task of classifying mu-
sic lyrics into emotions, a song’s lyrics can deliv-
er happiness and excitement simultaneously. The
research about the multi-label text categorization
attracts increasing attention (Srivastava and Zane-
Ulman, 2005; Katakis et al., 2008; Rubin et al.,
2012; Nam et al., 2013; Li et al., 2014).
Recently, a series of predictions-as-features
style methods have been developed, which train a
classifier for each label, organize the classifiers in
a partially ordered structure and take prediction-
s produced by the former classifiers as the latter
classifiers’ features. These predictions-as-features
style methods model high order label dependen-
cies (Zhang and Zhang, 2010) and obtain high
performance. Classifier chain (CC) (Read et al.,
2011) and multi-label Learning by Exploiting lA-
bel Dependency (Lead) (Zhang and Zhang, 2010)
are two famous predictions-as-features method-
s. CC organizes classifiers along a chain and
LEAD organizes classifiers in a Bayesian net-
work. Besides, there are other works on extend-
ing the predictions-as-features methods (Zaragoza
et al., 2011; Gonc¸alves et al., 2013; Sucar et al.,
2014). In this paper, we focus on the predictions-
as-features style methods.
The previous works of the predictions-as-
features methods focus on learning the partial-
ly ordered structure. They neglect a draw-
back. When training a classifier for one label,
predictions-as-features methods can model depen-
dencies between former labels and the current la-
bel, but they can’t model dependencies between
the current label and the latter labels. Consider
the case of three labels. We organize classifiers
in a partially ordered structure shown in figure 1.
When training the classifier for the second label,
the feature (the bold lines in figure) consists of the
origin feature and the prediction for the first la-
bel. The information about the third label can’t
be incorporated. It means that we only model the
dependencies between the first label and the sec-
</bodyText>
<page confidence="0.983573">
835
</page>
<note confidence="0.9327785">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 835–839,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figureCaption confidence="0.992265">
Figure 1: When training the classifier for the sec-
</figureCaption>
<bodyText confidence="0.992691111111111">
ond label, the feature (the bold lines) consists of
only the origin feature and the prediction for the
first label. In this time, it is impossible to model
the dependencies between the second label and the
third label.
ond label and that the dependencies between the
second label and the third label is missing.
To address this problem, we propose a nov-
el joint learning algorithm that allows the feed-
backs to be propagated from the classifiers for
latter labels to the classifier for the current la-
bel, so that the information about the latter labels
can be incorporated. It means that the proposed
method can model, not only the dependencies be-
tween former labels and current label as the usual
predictions-as-features methods, but also the de-
pendencies between current label and latter labels.
With not missing dependencies. Hence, the pro-
posed method will improve the performance. Our
experiments illustrate the models trained by our al-
gorithm outperform the original models. You can
find the code of this paper online 1.
The rest of this paper is organized as follows.
Section 2 presents the proposed method. We con-
duct experiments to demonstrate the effectiveness
of the proposed method in section 3. Section 4
concludes this paper.
</bodyText>
<sectionHeader confidence="0.823298" genericHeader="method">
2 Joint Learning Algorithm
</sectionHeader>
<subsectionHeader confidence="0.944871">
2.1 Preliminaries
</subsectionHeader>
<bodyText confidence="0.999852428571429">
Let X denote the document feature space, and
Y = {0,1}m denote label space with m label-
s. A document instance x E X is associated
with a label vector y = (y1, y2, ..., ym), where
yz = 1 denotes the document has the i-th label
and 0 otherwise. The goal of multi-label learn-
ing is to learn a function h : X → Y. In gener-
</bodyText>
<equation confidence="0.5475502">
1https://github.com/rustle1314/Joint_
Learning_Predictions_as_Features_for_
Multi_Label_Classification
al, h consists of m functions, one for a label, i.e.,
h(x) = [h1(x), h2(x), ..., hm(x)].
</equation>
<bodyText confidence="0.9999822">
In the predictions-as-features methods, the clas-
sifiers are organized in a partially ordered structure
and take predictions produced by the former clas-
sifiers as features. We can describe the classifier
in the predictions-as-features method as follows.
</bodyText>
<equation confidence="0.878133">
hj : x, hkEpaj(x) → yj (1)
</equation>
<bodyText confidence="0.999985">
where paj denotes the set of parents of the j-th
classifiers in the partially ordered structure.
</bodyText>
<subsectionHeader confidence="0.999848">
2.2 Architecture and Loss
</subsectionHeader>
<bodyText confidence="0.999972333333333">
In this subsection, we introduce architecture and
loss function of our joint learning algorithm. As
a motivating example, we employ logistic regres-
sion as the base classifier in the predictions-as-
features methods. The classification function is
the sigmoid function, as shown in Eq.(2).
</bodyText>
<equation confidence="0.999357">
pj = hj(x,pkEpaj)
exp([x, pkEpaj]TWj) =(2)
1 + exp([x, pkEpaj]TWj)
</equation>
<bodyText confidence="0.9999129">
where pj denotes the probability the document has
the j-th label, Wj denotes the weight vector of the
j-th model and [x, pkEpaj] denotes the feature vec-
tor x extended with predictions [pkEpaj] produced
by the former classifiers.
The joint algorithm learns classifiers in the par-
tially ordered structure jointly by minimizing a
global loss function. We use the sum of negative
log likelihood losses of all classifiers as the global
loss function.
</bodyText>
<equation confidence="0.9973194">
L(y,h(x)) = �m `(pj, yj)
j=1
�m (yjlog(pj) + (1 − yj)log(1 − pj))
j=1
(3)
</equation>
<bodyText confidence="0.992686">
The joint algorithm minimizes this global loss
function, as Eq.(4) shows.
</bodyText>
<equation confidence="0.983853">
h` = argmin L(y,h(x)) (4)
h
</equation>
<bodyText confidence="0.989598666666667">
Minimizing this global loss function is inequiv-
alent to minimizing the loss function of each base
classifier separately, since minimizing the global
</bodyText>
<page confidence="0.991912">
836
</page>
<bodyText confidence="0.999992090909091">
loss function results in feedbacks from latter clas-
sifiers. In the predictions-as-features methods, the
weights of the k-th classifier are the factors of not
only the k-th classifier but also the latter classi-
fiers. Consequently, when minimizing the global
loss function, the weights of the k-th classifier are
updated according to not only the loss of the k-th
classifier but also the losses of the latter classifiers.
In other words, feedbacks are propagated from the
latter classifiers to the k-th classifier.
The predictions-as-features models trained by
our proposed joint learning algorithm can model
the dependencies between former labels and cur-
rent label, since they take predictions by the for-
mer classifiers to extend the latter classifiers’ fea-
tures, as the usual predictions-as-features methods
do. Besides, they can also model the dependencies
between current label and latter labels due to the
feedbacks incorporated by the joint learning algo-
rithm.
Here, we employ logistic regression as the mo-
tivating example. If we want to employ other clas-
sification models, we use other classification func-
tion and other loss function. For example, if we
want to employ L2 SVM as base classifiers, we
resort to the linear classification function and the
L2 hinge loss function.
We employ the Back propagation Through
Structure (BTS) (Goller and Kuchler, 1996) to
minimize the global loss function. In BTS, par-
ent node is computed with its child nodes at the
forward pass stage; child node receives gradient
as the sum of derivatives from all its parents.
</bodyText>
<sectionHeader confidence="0.999675" genericHeader="method">
3 Experiments
</sectionHeader>
<subsectionHeader confidence="0.960927">
3.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999966230769231">
We perform experiments on four real world da-
ta sets: 1) the first data set is Slashdot (Read et
al., 2011). The Slashdot data set is concerned
about predicting multiple labels given science and
technology news titles and partial blurbs mined
from Slashdot.org. 2) the second data set is Med-
ical (Pestian et al., 2007). This data set involves
the assignment of ICD-9-CM codes to radiology
reports. 3) The third data set is Enron. The enron
data set is a subset of the Enron Email Dataset, as
labelled by the UC Berkeley Enron Email Analy-
sis Project2. It is concerned about classifying e-
mails into some categories. 4) the fourth data set
</bodyText>
<footnote confidence="0.939248">
2http://bailando.sims.berkeley.edu/
enron_email.html
</footnote>
<table confidence="0.9994224">
dataset n d m
slashdot 3782 1079 22
medical 978 1449 45
enron 1702 1001 53
tmc2007 28596 500 22
</table>
<tableCaption confidence="0.83368">
Table 2: Multi-label data sets and associated statis-
tics.
</tableCaption>
<bodyText confidence="0.995140444444444">
is Tmc2007 (Srivastava and Zane-Ulman, 2005).
It is concerned about safety report categorization,
which is to label aviation safety reports with re-
spect to what types of problems they describe.
Table 2 shows these multi-label data sets and as-
sociated statistics. n denotes the size of the entire
data set, d denotes the number of the bag-of-words
features, m denotes the number of labels. These
data sets are available online 3.
</bodyText>
<subsectionHeader confidence="0.99576">
3.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999989333333333">
We use three common used evaluation metrics.
The Hamming loss is defined as the percentage of
the wrong labels to the total number of labels.
</bodyText>
<equation confidence="0.842493">
|h(x)Ay |(5)
</equation>
<bodyText confidence="0.9997015">
where A denotes the symmetric difference of two
sets, equivalent to XOR operator in Boolean logic.
The multi-label 0/1 loss is the exact match mea-
sure as it requires any predicted set of labels h(x)
to match the true set of labels S exactly. The 0/1
loss is defined as follows:
</bodyText>
<equation confidence="0.98986">
0/1loss = I(h(x) =� y) (6)
</equation>
<bodyText confidence="0.99988775">
Let pj and rj denote the precision and recall for
the j-th label. The macro-averaged F score is a
harmonic mean between precision and recall, de-
fined as follows:
</bodyText>
<equation confidence="0.982124">
2*pj*rj (7)
pj + rj
</equation>
<subsectionHeader confidence="0.999678">
3.3 Method Setup
</subsectionHeader>
<bodyText confidence="0.999867428571429">
In this paper, we focus on the predictions-as-
features style methods, and use CC and LEAD as
the baselines. Our methods are JCC and JLEAD.
JCC(JLEAD) is CC(LEAD) trained by our join-
t algorithm and we compare JCC(JLEAD) to C-
C(LEAD) respectively. Put it another way, C-
C/LEAD provide the partial order structure of
</bodyText>
<footnote confidence="0.943417">
3http://mulan.sourceforge.net/
datasets.html and http://mlkd.csd.auth.
gr/multilabel.html
</footnote>
<equation confidence="0.997518">
Hammingloss = 1
m
1 m
Fscore =
m i=j
</equation>
<page confidence="0.994423">
837
</page>
<table confidence="0.9997209375">
Dataset BR CC LEAD JCC JLEAD
hamming loss (lower is better)
slashdot 0.046 f 0.002 0.043 f 0.001 0.045 f 0.0010 0.043 f 0.001 0.043 f 0.001
medical 0.013 f 0.001 0.013 f 0.0019 0.012 f 0.0000 0.011 f 0.000 0.010 f 0.001
enron 0.052 f 0.001 0.053 f 0.0029 0.052 f 0.0010 0.049 f 0.001 0.049 f 0.001
tmc2007 0.063 f 0.002 0.058 f 0.001 0.058 f 0.001 0.057 f 0.001 0.057 f 0.001
0/1 loss (lower is better)
slashdot 0.645 f 0.013 0.637 f 0.0159 0.631 f 0.0170 0.610 f 0.014 0.614 f 0.011
medical 0.398 f 0.034 0.377 f 0.0329 0.379 f 0.0330 0.353 f 0.030 0.345 f 0.030
enron 0.856 f 0.016 0.848 f 0.017 0.853 f 0.017 0.848 f 0.018 0.850 f 0.017
tmc2007 0.698 f 0.004 0.686 f 0.006 0.689 f 0.009 0.684 f 0.006 0.681 f 0.006
F score (higher is better)
slashdot 0.345 f 0.016 0.354 f 0.0159 0.364 f 0.0150 0.385 f 0.017 0.383 f 0.017
medical 0.403 f 0.012 0.416 f 0.0139 0.426 f 0.0110 0.444 f 0.009 0.446 f 0.013
enron 0.222 f 0.014 0.224 f 0.019 0.225 f 0.018 0.223 f 0.017 0.222 f 0.015
tmc2007 0.524 f 0.007 0.531 f 0.0099 0.508 f 0.0170 0.547 f 0.007 0.546 f 0.006
</table>
<tableCaption confidence="0.792467333333333">
Table 1: Performance (mean±std.) of each approach in terms of different evaluation metrics. •/◦
indicates whether JCC/JLEAD is statistically superior to CC/LEAD respectively (pairwise t-test at 5%
significance level).
</tableCaption>
<bodyText confidence="0.999027">
classifiers, and train these classifiers one by one.
JCC/LEAD train classifiers jointly in the partial
order structure provided by CC/LEAD.
For LEAD and JLEAD, we use the Banjo
(Bayesian ANalysis with Java Objects) (Smith et
al., 2006) package as the Bayesian structure learn-
ing tool. Besides, we also perform experiments
with Binary Relevance (BR), which is the baseline
for the predictions-as-features methods. BR trains
a classifier for a label independently, which does-
n’t model dependencies. The base classifier of all
of them is set to logistic regression without regu-
larization. Experiments are performed in ten-fold
cross validation with pairwise t-test at 5% signifi-
cance level.
</bodyText>
<subsectionHeader confidence="0.972487">
3.4 Performance
</subsectionHeader>
<bodyText confidence="0.999904117647059">
We reports the detailed results in terms of different
evaluation metrics on different data sets in table 1.
As shown in this figures, CC and LEAD outperfor-
m BR, which shows the values of the prediction-
as-features methods. JCC and JLEAD wins over
CC and LEAD respectively, which shows the val-
ues of the proposed joint learning algorithm.
The improvements are much smaller on the En-
ron data set than other data sets. In fact, BR, the
original prediction-as-features methods and our
proposed methods share similar performance on
the Enron data set. The reason may be that the
label dependencies in the Enron dataset is weak.
The label dependencies weakness can be validat-
ed by the fact that the modeling-correlation C-
C and LEAD can’t obtain much higher perfor-
mance than the not-modeling-correlation BR. Due
</bodyText>
<table confidence="0.986028333333333">
Criteria JCC against JLEAD against
CC LEAD
hamming loss 2/2/0 3/1/0
0/1 loss 2/2/0 2/2/0
F-score 3/1/0 3/1/0
Total 7/5/0 8/4/0
</table>
<tableCaption confidence="0.998196">
Table 3: The win/tie/loss results for the joint learn-
</tableCaption>
<bodyText confidence="0.929258642857143">
ing algorithm against the original predictions-as-
features methods in terms of different evaluation
metrics (pairwise t-test at 5% significance level).
to the weak label dependencies, the modeling-
correlation-better JCC(JLEAD) can’t obtain much
higher performance than CC(LEAD).
We summarize the detailed results into Table 3.
JCC is significantly superior to CC in 7/12 cas-
es, tie in 5/12 cases, inferior in zero case. JLEAD
is significantly superior to LEAD in 8/12 cases,
tie in 4/12 cases, inferior in zero case. The re-
sults indicates that our proposed joint algorithm
can improve the performance of the predictions-
as-features methods.
</bodyText>
<subsectionHeader confidence="0.954716">
3.5 Time
</subsectionHeader>
<bodyText confidence="0.999968818181818">
The training time (mean) of each approach is
showed detailed in table 4. First, we find the train-
ing time is related to the number of labels. The
training time on the Tmc2007 dataset (28596 in-
stances, 500 features and 22 labels) is less than
that on the Enron dataset (1702 instances, 1001
features and 53 labels). This is very easy to un-
derstand. We train more classifiers with respect
to more labels, which leads to more training time.
Second, LEAD/JLEAD have slightly less training
time than CC/JCC. The Bayesian network struc-
</bodyText>
<page confidence="0.994683">
838
</page>
<table confidence="0.9988398">
Dataset CC JCC LEAD JLEAD
slashdot 63.85 85.63 52.17 73.85
medical 134.11 142.51 115.33 128.78
enron 234.28 257.89 196.87 218.95
tmc2007 153.70 169.52 145.80 158.56
</table>
<tableCaption confidence="0.8180105">
Table 4: The average training time (in seconds) of
each approach
</tableCaption>
<bodyText confidence="0.999866">
ture learning tool limits that a node has five parent
nodes at most. Hence, the partially order struc-
ture of LEAD/JLEAD is much simpler. Third, the
training time of the joint algorithm is slightly more
than that of the original methods. Some time is
spent on back-propagating feedbacks from latter
classifiers.
</bodyText>
<sectionHeader confidence="0.999584" genericHeader="method">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999964142857143">
The multi-label text categorization is a common
and useful text categorization. Recently, a se-
ries of predictions-as-features style methods have
been developed, which model high order label de-
pendencies and obtain high performance. The
predictions-as-features methods suffer from the
drawback that they methods can’t model depen-
dencies between current label and the latter labels.
To address this problem, we propose a novel joint
learning algorithm that allows the feedbacks to be
propagated from the latter classifiers to the curren-
t classifier. Our experiments illustrate the models
trained by our algorithm outperform the original
models.
</bodyText>
<sectionHeader confidence="0.998582" genericHeader="conclusions">
5 Acknowledge
</sectionHeader>
<bodyText confidence="0.999846444444444">
We sincerely thank all the anonymous reviewers
for their valuable comments, which have helped to
improve this paper greatly. Our work is supported
by National High Technology Research and De-
velopment Program of China (863 Program) (No.
2015AA015402), National Natural Science Foun-
dation of China(No.61370117 &amp; No.61433015
)and Major National Social Science Fund of Chi-
na(No.12 &amp; ZD227).
</bodyText>
<sectionHeader confidence="0.998924" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999662952380952">
Christoph Goller and Andreas Kuchler. 1996. Learn-
ing task-dependent distributed representations by
backpropagation through structure. In Neural Net-
works, 1996., IEEE International Conference on,
volume 1, pages 347–352. IEEE.
Eduardo Corrˆea Gonc¸alves, Alexandre Plastino, and
Alex A Freitas. 2013. A genetic algorithm for op-
timizing the label ordering in multi-label classifier
chains. In Tools with Artificial Intelligence (ICTAI),
2013 IEEE 25th International Conference on, pages
469–476. IEEE.
Ioannis Katakis, Grigorios Tsoumakas, and Ioannis
Vlahavas. 2008. Multilabel text classification for
automated tag suggestion. In Proceedings of the
ECML/PKDD.
Li Li, Longkai Zhang, and Houfeng Wang. 2014.
Muli-label text categorization with hidden compo-
nents. In Proceedings of the 2014 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 1816–1821, Doha, Qatar, October.
Association for Computational Linguistics.
Jinseok Nam, Jungi Kim, Iryna Gurevych, and Jo-
hannes F¨urnkranz. 2013. Large-scale multi-label
text classification-revisiting neural networks. arXiv
preprint arXiv:1312.5419.
John P Pestian, Christopher Brew, Paweł Matykiewicz,
DJ Hovermale, Neil Johnson, K Bretonnel Cohen,
and Włodzisław Duch. 2007. A shared task involv-
ing multi-label classification of clinical free text. In
Proceedings of the Workshop on BioNLP 2007: Bio-
logical, Translational, and Clinical Language Pro-
cessing, pages 97–104. Association for Computa-
tional Linguistics.
Jesse Read, Bernhard Pfahringer, Geoff Holmes, and
Eibe Frank. 2011. Classifier chains for multi-label
classification. Machine learning, 85(3):333–359.
Timothy N Rubin, America Chambers, Padhraic S-
myth, and Mark Steyvers. 2012. Statistical topic
models for multi-label document classification. Ma-
chine Learning, 88(1-2):157–208.
V Anne Smith, Jing Yu, Tom V Smulders, Alexander J
Hartemink, and Erich D Jarvis. 2006. Computation-
al inference of neural information flow networks. P-
LoS computational biology, 2(11):e161.
Ashok N Srivastava and Brett Zane-Ulman. 2005. Dis-
covering recurring anomalies in text reports regard-
ing complex space systems. In Aerospace Confer-
ence, 2005 IEEE, pages 3853–3862. IEEE.
L Enrique Sucar, Concha Bielza, Eduardo F Morales,
Pablo Hernandez-Leal, Julio H Zaragoza, and Pe-
dro Larra˜naga. 2014. Multi-label classification with
bayesian network-based chain classifiers. Pattern
Recognition Letters, 41:14–22.
Julio H Zaragoza, Luis Enrique Sucar, Eduardo F
Morales, Concha Bielza, and Pedro Larranaga.
2011. Bayesian chain classifiers for multidimen-
sional classification. In IJCAI, volume 11, pages
2192–2197. Citeseer.
Min-Ling Zhang and Kun Zhang. 2010. Multi-label
learning by exploiting label dependency. In Pro-
ceedings of the 16th ACM SIGKDD international
conference on Knowledge discovery and data min-
ing, pages 999–1008. ACM.
</reference>
<page confidence="0.998935">
839
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.410558">
<title confidence="0.998395">Multi-label Text Categorization with Joint</title>
<author confidence="0.571526">Predictions-as-Features Method</author>
<affiliation confidence="0.9963275">Laboratory of Computational Linguistics(Peking University), Ministry of Education, Laboratory on Machine Perception(Peking University), Ministry of Education,</affiliation>
<email confidence="0.795769">chbb,shalei,z.s,xusun,</email>
<abstract confidence="0.99678375862069">Multi-label text categorization is a type of text categorization, where each document is assigned to one or more categories. Recently, a series of methods have been developed, which train a classifier for each label, organize the classifiers in a partially ordered structure and take predictions produced by the former classifiers as the latter classifiers’ features. These predictions-asfeatures style methods model high order label dependencies and obtain high performance. Nevertheless, the predictionsas-features methods suffer a drawback. When training a classifier for one label, the predictions-as-features methods can model dependencies between former labels and the current label, but they can’t model dependencies between the current label and the latter labels. To address this problem, we propose a novel joint learning algorithm that allows the feedbacks to be propagated from the classifiers for latter labels to the classifier for the current label. We conduct experiments using real-world textual data sets, and these experiments illustrate the predictions-as-features models trained by our algorithm outperform the original models.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christoph Goller</author>
<author>Andreas Kuchler</author>
</authors>
<title>Learning task-dependent distributed representations by backpropagation through structure.</title>
<date>1996</date>
<booktitle>In Neural Networks, 1996., IEEE International Conference on,</booktitle>
<volume>1</volume>
<pages>347--352</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="8880" citStr="Goller and Kuchler, 1996" startWordPosition="1383" endWordPosition="1386">r classifiers’ features, as the usual predictions-as-features methods do. Besides, they can also model the dependencies between current label and latter labels due to the feedbacks incorporated by the joint learning algorithm. Here, we employ logistic regression as the motivating example. If we want to employ other classification models, we use other classification function and other loss function. For example, if we want to employ L2 SVM as base classifiers, we resort to the linear classification function and the L2 hinge loss function. We employ the Back propagation Through Structure (BTS) (Goller and Kuchler, 1996) to minimize the global loss function. In BTS, parent node is computed with its child nodes at the forward pass stage; child node receives gradient as the sum of derivatives from all its parents. 3 Experiments 3.1 Datasets We perform experiments on four real world data sets: 1) the first data set is Slashdot (Read et al., 2011). The Slashdot data set is concerned about predicting multiple labels given science and technology news titles and partial blurbs mined from Slashdot.org. 2) the second data set is Medical (Pestian et al., 2007). This data set involves the assignment of ICD-9-CM codes to</context>
</contexts>
<marker>Goller, Kuchler, 1996</marker>
<rawString>Christoph Goller and Andreas Kuchler. 1996. Learning task-dependent distributed representations by backpropagation through structure. In Neural Networks, 1996., IEEE International Conference on, volume 1, pages 347–352. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduardo Corrˆea Gonc¸alves</author>
<author>Alexandre Plastino</author>
<author>Alex A Freitas</author>
</authors>
<title>A genetic algorithm for optimizing the label ordering in multi-label classifier chains.</title>
<date>2013</date>
<booktitle>In Tools with Artificial Intelligence (ICTAI), 2013 IEEE 25th International Conference on,</booktitle>
<pages>469--476</pages>
<publisher>IEEE.</publisher>
<marker>Gonc¸alves, Plastino, Freitas, 2013</marker>
<rawString>Eduardo Corrˆea Gonc¸alves, Alexandre Plastino, and Alex A Freitas. 2013. A genetic algorithm for optimizing the label ordering in multi-label classifier chains. In Tools with Artificial Intelligence (ICTAI), 2013 IEEE 25th International Conference on, pages 469–476. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Katakis</author>
</authors>
<title>Grigorios Tsoumakas, and Ioannis Vlahavas.</title>
<date>2008</date>
<booktitle>In Proceedings of the ECML/PKDD.</booktitle>
<marker>Katakis, 2008</marker>
<rawString>Ioannis Katakis, Grigorios Tsoumakas, and Ioannis Vlahavas. 2008. Multilabel text classification for automated tag suggestion. In Proceedings of the ECML/PKDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Li</author>
<author>Longkai Zhang</author>
<author>Houfeng Wang</author>
</authors>
<title>Muli-label text categorization with hidden components.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1816--1821</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Doha, Qatar,</location>
<contexts>
<context position="2276" citStr="Li et al., 2014" startWordPosition="333" endWordPosition="336">or more categories simultaneously. The multi-label setting is common and useful in the real world. For example, in the news categorization task, a newspaper article concerning global warming can be classified into two categories simultaneously, namely environment and science. For another example, in the task of classifying music lyrics into emotions, a song’s lyrics can deliver happiness and excitement simultaneously. The research about the multi-label text categorization attracts increasing attention (Srivastava and ZaneUlman, 2005; Katakis et al., 2008; Rubin et al., 2012; Nam et al., 2013; Li et al., 2014). Recently, a series of predictions-as-features style methods have been developed, which train a classifier for each label, organize the classifiers in a partially ordered structure and take predictions produced by the former classifiers as the latter classifiers’ features. These predictions-as-features style methods model high order label dependencies (Zhang and Zhang, 2010) and obtain high performance. Classifier chain (CC) (Read et al., 2011) and multi-label Learning by Exploiting lAbel Dependency (Lead) (Zhang and Zhang, 2010) are two famous predictions-as-features methods. CC organizes cl</context>
</contexts>
<marker>Li, Zhang, Wang, 2014</marker>
<rawString>Li Li, Longkai Zhang, and Houfeng Wang. 2014. Muli-label text categorization with hidden components. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1816–1821, Doha, Qatar, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinseok Nam</author>
<author>Jungi Kim</author>
<author>Iryna Gurevych</author>
<author>Johannes F¨urnkranz</author>
</authors>
<title>Large-scale multi-label text classification-revisiting neural networks. arXiv preprint arXiv:1312.5419.</title>
<date>2013</date>
<marker>Nam, Kim, Gurevych, F¨urnkranz, 2013</marker>
<rawString>Jinseok Nam, Jungi Kim, Iryna Gurevych, and Johannes F¨urnkranz. 2013. Large-scale multi-label text classification-revisiting neural networks. arXiv preprint arXiv:1312.5419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John P Pestian</author>
<author>Christopher Brew</author>
<author>Paweł Matykiewicz</author>
<author>DJ Hovermale</author>
<author>Neil Johnson</author>
<author>K Bretonnel Cohen</author>
<author>Włodzisław Duch</author>
</authors>
<title>A shared task involving multi-label classification of clinical free text.</title>
<date>2007</date>
<booktitle>In Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing,</booktitle>
<pages>97--104</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="9420" citStr="Pestian et al., 2007" startWordPosition="1477" endWordPosition="1480">We employ the Back propagation Through Structure (BTS) (Goller and Kuchler, 1996) to minimize the global loss function. In BTS, parent node is computed with its child nodes at the forward pass stage; child node receives gradient as the sum of derivatives from all its parents. 3 Experiments 3.1 Datasets We perform experiments on four real world data sets: 1) the first data set is Slashdot (Read et al., 2011). The Slashdot data set is concerned about predicting multiple labels given science and technology news titles and partial blurbs mined from Slashdot.org. 2) the second data set is Medical (Pestian et al., 2007). This data set involves the assignment of ICD-9-CM codes to radiology reports. 3) The third data set is Enron. The enron data set is a subset of the Enron Email Dataset, as labelled by the UC Berkeley Enron Email Analysis Project2. It is concerned about classifying emails into some categories. 4) the fourth data set 2http://bailando.sims.berkeley.edu/ enron_email.html dataset n d m slashdot 3782 1079 22 medical 978 1449 45 enron 1702 1001 53 tmc2007 28596 500 22 Table 2: Multi-label data sets and associated statistics. is Tmc2007 (Srivastava and Zane-Ulman, 2005). It is concerned about safety</context>
</contexts>
<marker>Pestian, Brew, Matykiewicz, Hovermale, Johnson, Cohen, Duch, 2007</marker>
<rawString>John P Pestian, Christopher Brew, Paweł Matykiewicz, DJ Hovermale, Neil Johnson, K Bretonnel Cohen, and Włodzisław Duch. 2007. A shared task involving multi-label classification of clinical free text. In Proceedings of the Workshop on BioNLP 2007: Biological, Translational, and Clinical Language Processing, pages 97–104. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesse Read</author>
<author>Bernhard Pfahringer</author>
<author>Geoff Holmes</author>
<author>Eibe Frank</author>
</authors>
<title>Classifier chains for multi-label classification.</title>
<date>2011</date>
<booktitle>Machine learning,</booktitle>
<pages>85--3</pages>
<contexts>
<context position="2725" citStr="Read et al., 2011" startWordPosition="397" endWordPosition="400">lti-label text categorization attracts increasing attention (Srivastava and ZaneUlman, 2005; Katakis et al., 2008; Rubin et al., 2012; Nam et al., 2013; Li et al., 2014). Recently, a series of predictions-as-features style methods have been developed, which train a classifier for each label, organize the classifiers in a partially ordered structure and take predictions produced by the former classifiers as the latter classifiers’ features. These predictions-as-features style methods model high order label dependencies (Zhang and Zhang, 2010) and obtain high performance. Classifier chain (CC) (Read et al., 2011) and multi-label Learning by Exploiting lAbel Dependency (Lead) (Zhang and Zhang, 2010) are two famous predictions-as-features methods. CC organizes classifiers along a chain and LEAD organizes classifiers in a Bayesian network. Besides, there are other works on extending the predictions-as-features methods (Zaragoza et al., 2011; Gonc¸alves et al., 2013; Sucar et al., 2014). In this paper, we focus on the predictionsas-features style methods. The previous works of the predictions-asfeatures methods focus on learning the partially ordered structure. They neglect a drawback. When training a cla</context>
<context position="9209" citStr="Read et al., 2011" startWordPosition="1443" endWordPosition="1446">ls, we use other classification function and other loss function. For example, if we want to employ L2 SVM as base classifiers, we resort to the linear classification function and the L2 hinge loss function. We employ the Back propagation Through Structure (BTS) (Goller and Kuchler, 1996) to minimize the global loss function. In BTS, parent node is computed with its child nodes at the forward pass stage; child node receives gradient as the sum of derivatives from all its parents. 3 Experiments 3.1 Datasets We perform experiments on four real world data sets: 1) the first data set is Slashdot (Read et al., 2011). The Slashdot data set is concerned about predicting multiple labels given science and technology news titles and partial blurbs mined from Slashdot.org. 2) the second data set is Medical (Pestian et al., 2007). This data set involves the assignment of ICD-9-CM codes to radiology reports. 3) The third data set is Enron. The enron data set is a subset of the Enron Email Dataset, as labelled by the UC Berkeley Enron Email Analysis Project2. It is concerned about classifying emails into some categories. 4) the fourth data set 2http://bailando.sims.berkeley.edu/ enron_email.html dataset n d m sla</context>
</contexts>
<marker>Read, Pfahringer, Holmes, Frank, 2011</marker>
<rawString>Jesse Read, Bernhard Pfahringer, Geoff Holmes, and Eibe Frank. 2011. Classifier chains for multi-label classification. Machine learning, 85(3):333–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy N Rubin</author>
<author>America Chambers</author>
<author>Padhraic Smyth</author>
<author>Mark Steyvers</author>
</authors>
<title>Statistical topic models for multi-label document classification.</title>
<date>2012</date>
<booktitle>Machine Learning,</booktitle>
<pages>88--1</pages>
<contexts>
<context position="2240" citStr="Rubin et al., 2012" startWordPosition="325" endWordPosition="328">here each document is assigned to one or more categories simultaneously. The multi-label setting is common and useful in the real world. For example, in the news categorization task, a newspaper article concerning global warming can be classified into two categories simultaneously, namely environment and science. For another example, in the task of classifying music lyrics into emotions, a song’s lyrics can deliver happiness and excitement simultaneously. The research about the multi-label text categorization attracts increasing attention (Srivastava and ZaneUlman, 2005; Katakis et al., 2008; Rubin et al., 2012; Nam et al., 2013; Li et al., 2014). Recently, a series of predictions-as-features style methods have been developed, which train a classifier for each label, organize the classifiers in a partially ordered structure and take predictions produced by the former classifiers as the latter classifiers’ features. These predictions-as-features style methods model high order label dependencies (Zhang and Zhang, 2010) and obtain high performance. Classifier chain (CC) (Read et al., 2011) and multi-label Learning by Exploiting lAbel Dependency (Lead) (Zhang and Zhang, 2010) are two famous predictions-</context>
</contexts>
<marker>Rubin, Chambers, Smyth, Steyvers, 2012</marker>
<rawString>Timothy N Rubin, America Chambers, Padhraic Smyth, and Mark Steyvers. 2012. Statistical topic models for multi-label document classification. Machine Learning, 88(1-2):157–208.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Anne Smith</author>
<author>Jing Yu</author>
<author>Tom V Smulders</author>
<author>Alexander J Hartemink</author>
<author>Erich D Jarvis</author>
</authors>
<date>2006</date>
<booktitle>Computational inference of neural information flow networks. PLoS computational biology,</booktitle>
<pages>2--11</pages>
<contexts>
<context position="13014" citStr="Smith et al., 2006" startWordPosition="2109" endWordPosition="2112">6 f 0.013 enron 0.222 f 0.014 0.224 f 0.019 0.225 f 0.018 0.223 f 0.017 0.222 f 0.015 tmc2007 0.524 f 0.007 0.531 f 0.0099 0.508 f 0.0170 0.547 f 0.007 0.546 f 0.006 Table 1: Performance (mean±std.) of each approach in terms of different evaluation metrics. •/◦ indicates whether JCC/JLEAD is statistically superior to CC/LEAD respectively (pairwise t-test at 5% significance level). classifiers, and train these classifiers one by one. JCC/LEAD train classifiers jointly in the partial order structure provided by CC/LEAD. For LEAD and JLEAD, we use the Banjo (Bayesian ANalysis with Java Objects) (Smith et al., 2006) package as the Bayesian structure learning tool. Besides, we also perform experiments with Binary Relevance (BR), which is the baseline for the predictions-as-features methods. BR trains a classifier for a label independently, which doesn’t model dependencies. The base classifier of all of them is set to logistic regression without regularization. Experiments are performed in ten-fold cross validation with pairwise t-test at 5% significance level. 3.4 Performance We reports the detailed results in terms of different evaluation metrics on different data sets in table 1. As shown in this figure</context>
</contexts>
<marker>Smith, Yu, Smulders, Hartemink, Jarvis, 2006</marker>
<rawString>V Anne Smith, Jing Yu, Tom V Smulders, Alexander J Hartemink, and Erich D Jarvis. 2006. Computational inference of neural information flow networks. PLoS computational biology, 2(11):e161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashok N Srivastava</author>
<author>Brett Zane-Ulman</author>
</authors>
<title>Discovering recurring anomalies in text reports regarding complex space systems.</title>
<date>2005</date>
<booktitle>In Aerospace Conference, 2005 IEEE,</booktitle>
<pages>3853--3862</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="9990" citStr="Srivastava and Zane-Ulman, 2005" startWordPosition="1571" endWordPosition="1574">.org. 2) the second data set is Medical (Pestian et al., 2007). This data set involves the assignment of ICD-9-CM codes to radiology reports. 3) The third data set is Enron. The enron data set is a subset of the Enron Email Dataset, as labelled by the UC Berkeley Enron Email Analysis Project2. It is concerned about classifying emails into some categories. 4) the fourth data set 2http://bailando.sims.berkeley.edu/ enron_email.html dataset n d m slashdot 3782 1079 22 medical 978 1449 45 enron 1702 1001 53 tmc2007 28596 500 22 Table 2: Multi-label data sets and associated statistics. is Tmc2007 (Srivastava and Zane-Ulman, 2005). It is concerned about safety report categorization, which is to label aviation safety reports with respect to what types of problems they describe. Table 2 shows these multi-label data sets and associated statistics. n denotes the size of the entire data set, d denotes the number of the bag-of-words features, m denotes the number of labels. These data sets are available online 3. 3.2 Evaluation Metrics We use three common used evaluation metrics. The Hamming loss is defined as the percentage of the wrong labels to the total number of labels. |h(x)Ay |(5) where A denotes the symmetric differe</context>
</contexts>
<marker>Srivastava, Zane-Ulman, 2005</marker>
<rawString>Ashok N Srivastava and Brett Zane-Ulman. 2005. Discovering recurring anomalies in text reports regarding complex space systems. In Aerospace Conference, 2005 IEEE, pages 3853–3862. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Enrique Sucar</author>
<author>Concha Bielza</author>
<author>Eduardo F Morales</author>
<author>Pablo Hernandez-Leal</author>
<author>Julio H Zaragoza</author>
<author>Pedro Larra˜naga</author>
</authors>
<title>Multi-label classification with bayesian network-based chain classifiers. Pattern Recognition Letters,</title>
<date>2014</date>
<pages>41--14</pages>
<marker>Sucar, Bielza, Morales, Hernandez-Leal, Zaragoza, Larra˜naga, 2014</marker>
<rawString>L Enrique Sucar, Concha Bielza, Eduardo F Morales, Pablo Hernandez-Leal, Julio H Zaragoza, and Pedro Larra˜naga. 2014. Multi-label classification with bayesian network-based chain classifiers. Pattern Recognition Letters, 41:14–22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julio H Zaragoza</author>
<author>Luis Enrique Sucar</author>
<author>Eduardo F Morales</author>
<author>Concha Bielza</author>
<author>Pedro Larranaga</author>
</authors>
<title>Bayesian chain classifiers for multidimensional classification.</title>
<date>2011</date>
<booktitle>In IJCAI,</booktitle>
<volume>11</volume>
<pages>2192--2197</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="3056" citStr="Zaragoza et al., 2011" startWordPosition="446" endWordPosition="449">ally ordered structure and take predictions produced by the former classifiers as the latter classifiers’ features. These predictions-as-features style methods model high order label dependencies (Zhang and Zhang, 2010) and obtain high performance. Classifier chain (CC) (Read et al., 2011) and multi-label Learning by Exploiting lAbel Dependency (Lead) (Zhang and Zhang, 2010) are two famous predictions-as-features methods. CC organizes classifiers along a chain and LEAD organizes classifiers in a Bayesian network. Besides, there are other works on extending the predictions-as-features methods (Zaragoza et al., 2011; Gonc¸alves et al., 2013; Sucar et al., 2014). In this paper, we focus on the predictionsas-features style methods. The previous works of the predictions-asfeatures methods focus on learning the partially ordered structure. They neglect a drawback. When training a classifier for one label, predictions-as-features methods can model dependencies between former labels and the current label, but they can’t model dependencies between the current label and the latter labels. Consider the case of three labels. We organize classifiers in a partially ordered structure shown in figure 1. When training </context>
</contexts>
<marker>Zaragoza, Sucar, Morales, Bielza, Larranaga, 2011</marker>
<rawString>Julio H Zaragoza, Luis Enrique Sucar, Eduardo F Morales, Concha Bielza, and Pedro Larranaga. 2011. Bayesian chain classifiers for multidimensional classification. In IJCAI, volume 11, pages 2192–2197. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min-Ling Zhang</author>
<author>Kun Zhang</author>
</authors>
<title>Multi-label learning by exploiting label dependency.</title>
<date>2010</date>
<booktitle>In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>999--1008</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2654" citStr="Zhang and Zhang, 2010" startWordPosition="386" endWordPosition="389"> deliver happiness and excitement simultaneously. The research about the multi-label text categorization attracts increasing attention (Srivastava and ZaneUlman, 2005; Katakis et al., 2008; Rubin et al., 2012; Nam et al., 2013; Li et al., 2014). Recently, a series of predictions-as-features style methods have been developed, which train a classifier for each label, organize the classifiers in a partially ordered structure and take predictions produced by the former classifiers as the latter classifiers’ features. These predictions-as-features style methods model high order label dependencies (Zhang and Zhang, 2010) and obtain high performance. Classifier chain (CC) (Read et al., 2011) and multi-label Learning by Exploiting lAbel Dependency (Lead) (Zhang and Zhang, 2010) are two famous predictions-as-features methods. CC organizes classifiers along a chain and LEAD organizes classifiers in a Bayesian network. Besides, there are other works on extending the predictions-as-features methods (Zaragoza et al., 2011; Gonc¸alves et al., 2013; Sucar et al., 2014). In this paper, we focus on the predictionsas-features style methods. The previous works of the predictions-asfeatures methods focus on learning the pa</context>
</contexts>
<marker>Zhang, Zhang, 2010</marker>
<rawString>Min-Ling Zhang and Kun Zhang. 2010. Multi-label learning by exploiting label dependency. In Proceedings of the 16th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 999–1008. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>