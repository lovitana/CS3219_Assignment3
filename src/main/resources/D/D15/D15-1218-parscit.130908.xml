<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000135">
<title confidence="0.9985225">
A Coarse-Grained Model for Optimal Coupling of ASR and SMT Systems
for Speech Translation
</title>
<note confidence="0.821629333333333">
Gaurav Kumar 1, Graeme Blackwood 2, Jan Trmal 1, Daniel Povey 1, Sanjeev Khudanpur 1
1 CLSP &amp; HLTCOE, Johns Hopkins University, Baltimore, MD, USA
2IBM T. J. Watson Research Center, Yorktown Heights, NY, USA
</note>
<email confidence="0.979665">
{gkumar6, dpovey1, khudanpur}@jhu.edu,blackwood@us.ibm.com
</email>
<sectionHeader confidence="0.997233" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999735421052632">
Speech translation is conventionally car-
ried out by cascading an automatic speech
recognition (ASR) and a statistical ma-
chine translation (SMT) system. The hy-
potheses chosen for translation are based
on the ASR system’s acoustic and lan-
guage model scores, and typically opti-
mized for word error rate, ignoring the in-
tended downstream use: automatic trans-
lation. In this paper, we present a coarse-
to-fine model that uses features from the
ASR and SMT systems to optimize this
coupling. We demonstrate that several
standard features utilized by ASR and
SMT systems can be used in such a model
at the speech-translation interface, and we
provide empirical results on the Fisher
Spanish-English speech translation cor-
pus.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999864205882353">
Speech translation is the process of translating
speech in the source language to text or speech
in the target language. This process is typically
structured as a three step pipeline. Step one in-
volves training an Automatic Speech Recognition
(ASR) system to transcribe speech to text in the
source language. Step two involves extracting an
appropriate form of the ASR output to translate.
We will refer to this step as the Speech-Translation
interface. In the simplest scenario, the ASR 1-
best output can be used as the source text to trans-
late. It may be useful to consider alternative ASR
hypotheses and these take the form of an N-best
list or a word-lattice. An N-best list can be in-
cluded easily into the tuning and the decoding pro-
cess of a statistical machine translation (SMT) sys-
tem (Zhang et al., 2004). Several researchers have
proposed solutions to incorporating lattices and
confusion networks in this process (Saleem et al.,
2004; Matusov et al., 2005; Bangalore and Ric-
cardi, 2000; Dyer et al., 2008a; Bertoldi and Fed-
erico, 2005; Quan et al., 2005; Mathias and Byrne,
2006; Bertoldi et al., 2007). Word lattice input to
SMT for tuning and decoding increases the com-
plexity of the decoding process because of the ex-
ponential number of alternatives that are present.
Finally, step three involves training and tuning a
Statistical Machine Translation (SMT) system and
decoding the output extracted through the speech
translation interface.
This paper presents a featurized model which
performs the job of hypothesis selection from the
outputs of the ASR system for the input to the
SMT system. Our motivation is as follows:
</bodyText>
<listItem confidence="0.977829916666667">
1. Using downstream information : Hypoth-
esis selection for the input to the SMT sys-
tem should be done jointly by the ASR and
the SMT systems. That is, there may exist
hypotheses that a trained SMT system may
find easier to translate and produce better
translations for than the ones that are deemed
best based on the ASR acoustic and language
model scores. Incorporation of knowledge
from the downstream process (translation) is
vital to selecting translation options, and sub-
sequently producing better translations.
2. Coarse-to-fine grained decoding : An in-
termediate model which acts as an interface
and is a weak (coarse) version of the down-
stream process may be able to select better
hypotheses. In effect, a weak translation de-
coder can be used as the interface to estimate
the expected translation quality of an ASR
hypothesis. This method of hypothesis se-
lection should be able to incorporate features
from the ASR and the SMT system.
3. Phrase units vs. word units: When a phrase
based SMT system is used for translation,
</listItem>
<page confidence="0.969442">
1902
</page>
<note confidence="0.658034">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1902–1907,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.99804525">
optimization for hypothesis selection at the
Speech-Translation interface should be con-
ducted using phrases as the basic unit instead
of words.
</bodyText>
<sectionHeader confidence="0.877596" genericHeader="method">
2 Coarse-to-Fine Speech Translation
</sectionHeader>
<bodyText confidence="0.999118521739131">
In this section, we describe the featurized model
(coarse-grain MT decoder) for hypothesis selec-
tion that uses information from the ASR and SMT
systems (impedance matching). We assume the
presence of ASR and SMT systems that have been
trained separately. In addition to creating almost
no disruption in the traditional pipeline approach,
this allows us to incorporate local gains from each
system. To elaborate, our methods avoid joint op-
timization of the ASR and the SMT system with
respect to a translation metric (Vidal, 1997; Ney,
1999), which is not feasible for larger datasets.
Also, considering the dearth of speech translation
training datasets, this method allows independent
training of the ASR and SMT systems on data cre-
ated only for ASR training and parallel data for
SMT. We start by introducing the formal machin-
ery that will be used and by presenting a simple
example to motivate the model. The complete fea-
turized model follows this exposition.
Let E and F be alphabets of words and phrases
respectively in the source language. Using these,
we can define the following finite state machines:
</bodyText>
<listItem confidence="0.99954915">
1. Word Lattice (L) : A finite state accep-
tor that accepts word-sequences in the source
language ( L : E* —* E*). This represents
the unpruned ASR word lattice output in our
model (Figure 1a).
2. Phrase segmentation Transducer (5) : A
cyclic finite state transducer that transduces
a sequence of words to phrases in the source
language (5 : E* —* F*). This is built from
the source side of the phrase table. Each
path represents one source side phrase in the
phrase table. Traversing a path is equivalent
to consuming the words in a phrase and pro-
ducing the phrase as a token (Figure 1b).
3. Weighted word lattice( ˜LASR) : A weighted
version of L ( ˜LASR : E* —* E*/R+). We
use the subscript to denote the nature/source
of the weights.
4. Phrase acceptor ( ˜WMT) : A finite state ac-
ceptor that accepts source phrases in the SMT
</listItem>
<figureCaption confidence="0.966872">
Figure 1: A toy example for producing a phrase
</figureCaption>
<bodyText confidence="0.9425467">
length weighted phrase lattice. (a) An unweighted
word lattice. (b) A phrase segmentation trans-
ducer which transduces words to phrases and has
a weight of one per path. Each path is a source
phrase in the phrase table. (c) A phrase lat-
tice produced by composing the word lattice and
phrase segmentation transducer.
system’s phrase table ( ˜WMT : F —* F/R).
It is weighted by features derived from the
SMT system.
</bodyText>
<listItem confidence="0.993338166666667">
5. Phrase lattice (P) : The result of the com-
position of a word lattice (acceptor) with the
phrase segmentation transducer (P : E* —*
F*). This represents all possible phrase seg-
mentations of all the ASR hypotheses in the
word lattice.
</listItem>
<equation confidence="0.976899">
P = det(min(L o 5))
</equation>
<bodyText confidence="0.999981">
We will represent weighted versions of P as
˜PASR/MT with subscripts to denote the ori-
gin of the weights (Figure 1c).
</bodyText>
<subsectionHeader confidence="0.933386">
2.1 A simple model: Maximum Spanning
Phrases
</subsectionHeader>
<bodyText confidence="0.970174947368421">
We motivate our model with this fairly simple
scenario. Suppose that we believe that if our
SMT input could be covered by longer source side
phrases1, we would produce better translations.
This may be viewed as a tiling problem where the
tiles are the source phrases in the phrase table and
the goal is to select the ASR hypothesis that re-
quires the least number of phrases to cover2. To
achieve this using our existing machinery, we cre-
ate ˜5, a weighted version of 5 (Figure 1 (b)), such
1In phrase based translation, target translations are pro-
duced for each possible span of the input sentence allowed by
the phrase table. Translation of a longer source side phrase
produces fewer translation options and may be more reliable
given sufficient occurrences in the training data.
2It may be useful to incorporate a brevity penalty here,
since this approach has a strong bias towards selecting shorter
hypotheses. We will use other features to counter this bias in
the following sections.
</bodyText>
<figure confidence="0.9115885">
(a) (b)
(c)
</figure>
<page confidence="0.517214">
1903
</page>
<bodyText confidence="0.304664">
that where ( ˜WMT)* is the Kleene closure of ( ˜WMT ).
</bodyText>
<equation confidence="0.942833">
˜S)) = f 0 : π1(δ(S)) E E and π2(δ(S)) = E
t 1 : π2(δ(S)) E F and π1(δ(S)) = c
</equation>
<bodyText confidence="0.9997435">
where δ( ˜S) is an edge in S˜ and π1 and π2 are the in-
put and output projections respectively. Using this
segmentation transducer and an unweighted word
lattice, L (Figure : 1 (a)), we produce a phrase
lattice ˜PMT. Assuming the weights are in the log-
semiring, the weight of a path δ( P˜)* in ˜PMT is
</bodyText>
<equation confidence="0.861247333333333">
w(δ(
�P)*) =
δ( P˜)Eδ(
</equation>
<bodyText confidence="0.999634545454545">
Figure 1(c) shows an example of this phrase lat-
tice. Weights in the phrase lattice follow the same
definition as the weights in the segmentation trans-
ducer. Hence, the weight of a path in the phrase
lattice is simply the number of phrases used to
cover this path. The shortest path 3 in the phrase
lattice ˜PMT, corresponds to the hypothesis we
were looking for. This simple example, demon-
strates how we may be able to use SMT features
(source phrase length in this case) to select hy-
potheses from the phrase lattice.
</bodyText>
<subsectionHeader confidence="0.9766935">
2.2 A general featurized model for
hypothesis selection
</subsectionHeader>
<bodyText confidence="0.999991583333333">
We now present a general framework in which
hypothesis selection can be carried out using
knowledge (features) from the ASR and the
SMT system. As described earlier, this form of
‘impedance’ matching allows us to select hypothe-
ses from an unpruned ASR word lattice for which
the SMT system is more likely to find good trans-
lations. Incorporating ASR weights also ensures
that we take into account what the ASR system
considers to be good hypotheses. We start with
the previously discussed idea of a phrase lattice,
using weights from the ASR system only. That is,
</bodyText>
<equation confidence="0.641497">
˜PASR = det(min( ˜LASR O S))
</equation>
<bodyText confidence="0.999929">
Now, we use the weighted phrase acceptor ˜WMT
to bring in the SMT features 4. Composing this
with the weighted phrase lattice, we get
</bodyText>
<equation confidence="0.545546">
˜PASR,MT = det(min( ˜PASR O (˜WMT)*)
</equation>
<bodyText confidence="0.980761666666667">
3To compute the shortest path, we switch from the log to
the tropical semiring (A semiring with ordinary addition as
the multiplication operator and max as the addition operator).
4Alternatively, we may have introduced the weights in the
segmentation transducer itself. This separate machine is in-
troduced for efficient training of this model.
We assume that the edge weights are in the log-
semiring. Hence, after these two compositions, the
edge weights in ˜PASR,MT can be represented as
</bodyText>
<equation confidence="0.990923">
�˜PASR,MT )) =
j
�=
i
</equation>
<bodyText confidence="0.999969">
where δ(˜PASR,MT ) is an edge in ˜PASR,MT, β,γ are
feature weights, fASR and fMT are features from
the ASR and SMT system respectively. This form
represents a log-linear model (our features are al-
ready assumed to be in log-space). where fi is any
feature and λi is the corresponding feature weight.
We may now extract the one-best, N-best or lattice
input for the SMT system from ˜PASR,MT .
</bodyText>
<listItem confidence="0.984728789473684">
2.2.1 A discussion about related techniques
1. Decoding (Translation) : Our model closely
resembles a featurized finite-state transducer
based translation model. If we replace the
output alphabet of the acceptor ( ˜WMT)* with
the target side phrases, we will actually get
output in the target language. Even though
this model does not explicity include reorder-
ing, the coarse-grained decoder has access
to information that can enable better deci-
sions about which hypotheses are better for
the downstream process (translation).
2. Lattice Decoding : (Dyer et al., 2008b) sug-
gests passing the entire word lattice to the
SMT system. However, even if these lattices
are not pruned, a beam based decoder might
not consider hypotheses that our model may
produce through coarse-grained decoding.
3. Language model re-scoring : One may use a
</listItem>
<bodyText confidence="0.9259404">
bigger source language model to re-score the
ASR lattice (or an N-best list). This how-
ever, does not consider any SMT features in
re-scoring. With our model, we can simply
use this as an additional feature.
</bodyText>
<subsectionHeader confidence="0.61473">
2.2.2 Training
</subsectionHeader>
<bodyText confidence="0.999848833333333">
Training the hypothesis selection model can be
carried out using standard methods for log linear
models on a held-out set. This also requires decod-
ing (translation) of a deep N-best list derived from
the held-out set. The objective of training then
simply becomes maximization of the translation
</bodyText>
<equation confidence="0.993850125">
w(δ(
P))
w(δ(
P˜)∗
w(δ(
βjfj,ASR + � γkfk,MT
k
λifi
</equation>
<page confidence="0.976532">
1904
</page>
<bodyText confidence="0.754714">
5. Lexical translation entropy: Similarly, we
can use an entropy measure based on the lex-
ical translation probability as a feature.
</bodyText>
<equation confidence="0.962908">
flex(pj) = Hlex(E|pj)
</equation>
<bodyText confidence="0.97059">
quality given any metric that provides sentence
level scores. Each time our model produces a hy-
pothesis, its score can be looked up from the pre-
translated N-best list. Also, whenever the weights
are updated, the only structures that need to be re-
built are W˜∗MT and ˜PASR,MT 5.
</bodyText>
<sectionHeader confidence="0.479036" genericHeader="method">
2.2.3 Features
</sectionHeader>
<bodyText confidence="0.9995375">
We use the following features in our implementa-
tion of this model. However, any relevant ASR
and SMT feature may be readily added to this
model.
</bodyText>
<listItem confidence="0.998169">
1. ASR scores: We incorporate the ASR acous-
tic (AM) and language (LM) model scores as
one combined feature.
</listItem>
<equation confidence="0.978881">
fASR = LM + α ∗ AM
</equation>
<bodyText confidence="0.96894925">
Here, LM, AM are negative log-
probabilities and α is the acoustic scaling
parameter chosen to minimize ASR word
error rate.
</bodyText>
<listItem confidence="0.9952561">
2. Source phrase count: As described in sec-
tion 2.1, this feature may be used to cap-
ture the intuition that using a fewer number
of phrases to cover the input sentence may
produce better translations.
3. Length normalized phrase unigram prob-
ability : We may use a phrase LM feature
by incorporating phrase n-gram probabilities
(normalized) by length.
4. Phrase translation entropy : For each
</listItem>
<bodyText confidence="0.837068833333333">
source side phrase pj, we may have multiple
translations (ei) in the phrase table with dif-
ferent translation probabilities (p(ei|fj)). A
simple entropy measure can be used as a fea-
ture to estimate the confidence that the SMT
system has in translating fj.
</bodyText>
<equation confidence="0.971414333333333">
ftr(pj) = Htr(E|pj)
�= − ptr(ei|fj) log ptr(ei|fj)
i
</equation>
<footnote confidence="0.991674">
5This requires the use of one ASR feature, addressed in
the “Features” section
</footnote>
<equation confidence="0.9668345">
�= − plex(ei|fj) log plex(ei|fj)
i
</equation>
<sectionHeader confidence="0.999825" genericHeader="evaluation">
3 Results
</sectionHeader>
<bodyText confidence="0.999765829268293">
We use the Fisher and Callhome Spanish-English
Speech Translation Corpus (Post et al., 2013) for
our experiments. This Fisher dataset consists of
819 transcribed and translated telephone conver-
sations. The corpus is split into a training, dev
and two test sets (dev-2 and test). We use the dev
set for training the feature weights of the proposed
model.
We use the Kaldi speech recognition tools (Povey
et al., 2011) to build our Spanish ASR systems.
Our state-of-the-art ASR system is the p-norm
DNN system of (Zhang et al., 2014). The word-
error-rates on the dev and test sets of the Fisher
dataset (dev, dev-2, test) are 29.80%, 29.79% and
25.30% respectively.
For the SMT system, we use the phrase based
translation system of Moses (Koehn et al., 2007)
with sparse features. The system is trained and
tuned on the train and dev partitions of the Fisher
dataset respectively. The BLEU scores of the MT
output for the the dev-2 and the test partitions are
65.38% and 62.91% respectively. While decoding
the ASR output, we tune on the 1-best ASR output
for the dev partition. With this modified system,
the BLEU scores for the ASR 1-best output of the
dev2 and the test partitions are 40.06% and 40.4%
respectively. We use this system as the baseline
for our experiments (Table 1).
We note that if we were to use the lattice oracle6
from our ASR system as input to the SMT system,
we get a BLEU score of 46.59% for the dev2 par-
tition of the Fisher dataset. This indicates that the
best gain (+BLEU) that an oracle lattice reranker
could get is only 6.53%.
To tune the weights of the coarse decoder, we
decode 500-best ASR outputs for the tuning set
with the SMT system. This maps each ASR hy-
pothesis to a target language translation. An OOV
feature was added to handle words that were not
seen by the SMT system. The tuning process was
then carried out so as to maximize the BLEU with
</bodyText>
<footnote confidence="0.69947">
6Path in the lattice that has the least word error rate.
</footnote>
<bodyText confidence="0.9532">
where fj is a source side phrase in the phrase
table.
</bodyText>
<equation confidence="0.9828744">
⎡ ⎤len(fj)
⎣ freq(fj)
funi(fj) = E ⎦
freq(fk)
k
</equation>
<page confidence="0.980636">
1905
</page>
<table confidence="0.9997518">
Experiment BLEU (dev2) BLEU (test)
Transcripts 65.4% 62.9%
Lattice Oracle 46.59% 46.17%
ASR 1-best 40.06% 40.4%
Coarse decoder 40.26% 40.46%
</table>
<tableCaption confidence="0.999586">
Table 1: Performance when using the coarse de-
</tableCaption>
<bodyText confidence="0.975840176470588">
coder interface compared to the the decoding the
human transcripts, the ASR 1-best or the lattice
oracle (the path in the ASR lattice with the least
WER : not available during test time.)
respect to the reference translation of the ASR hy-
pothesis selected by the coarse grained decoder.
We used ZMERT (Zaidan, 2009) for tuning which
was configured to expect a 300-best list from the
decoder at every iteration using the Fisher dev set.
15 iterations of tuning were carried out for each
experiment. We then use the tuned weight vec-
tor to decode the Fisher-dev2 and the Fisher-test
set using our coarse grained decoder. We extract
the one-best output and use it as input to the pre-
trained SMT system (description in the preceding
section). Table 1 reports the results achieved the
featurized coarse grained decoder.
</bodyText>
<sectionHeader confidence="0.999681" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999985461538461">
We present a coarse-to-fine featurized model
which acts as the interface between ASR and SMT
systems. By utilizing information from the up-
stream (ASR) and the downstream (SMT) sys-
tems, this model makes more informed decisions
about which hypotheses from the ASR word lat-
tice may result in better translation results. More-
over, the model takes the form of a coarse finite
state transducer based translation decoder which
imitates the downstream system. This enables it to
estimate translation quality even before the com-
plete SMT system is used for decoding. Finally,
the proposed model is featurized and may accept
any weight from the ASR and SMT system that are
deemed useful for optimizing translation quality.
The Spanish Fisher corpus is one of a few con-
versational speech translation datasets available,
and we start with a strong baseline system. We
therefore persevere with the experimental setup
described above, even though the maximum (ora-
cle) improvement by any rescoring method is only
6.5% BLEU, as noted above. This partially ex-
plains the small gains reported here, and suggests
that this method should be evaluated further on an-
other corpus, e.g. the Egyptian Arabic translation
dataset, with greater headroom for improvement.
</bodyText>
<sectionHeader confidence="0.997713" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999974">
This work was partially supported by NSF
award No¯ IIS 0963898 and DARPA contracts
No¯ HR0011-12-C-0015 and HR0011-51-6285.
The U.S. Government is authorized to reproduce
and distribute reprints for Governmental purposes
notwithstanding any copyright annotation thereon.
The views and conclusions contained herein are
those of the authors and should not be interpreted
as necessarily representing the official policies
or endorsements, either expressed or implied, of
NSF, DARPA or the U.S. Government.
</bodyText>
<page confidence="0.992817">
1906
</page>
<sectionHeader confidence="0.995884" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999401608695652">
Srinivas Bangalore and Giuseppe Riccardi. 2000.
Finite-state models for lexical reordering in spoken
language translation. In Proceedings of the Sixth
International Conference on Spoken Language Pro-
cessing, pages 422–425.
N. Bertoldi and Marcello Federico. 2005. A new de-
coder for spoken language translation based on con-
fusion networks. In Proceedings of the IEEE Work-
shop on Automatic Speech Recognition and Under-
standing, pages 86–91.
N. Bertoldi, R. Zens, and Marcello Federico. 2007.
Speech translation by confusion network decoding.
In Proceedings of the IEEE International Confer-
ence in Acoustics, Speech and Signal Processing,
volume IV, pages 1297–1300.
Christopher Dyer, Smaranda Muresan, and Philip
Resnik. 2008a. Generalizing word lattice transla-
tion. In Proceedings of ACL-08: HLT, pages 1012–
1020, Columbus, Ohio, June. Association for Com-
putational Linguistics.
Christopher Dyer, Smaranda Muresan, and Philip
Resnik. 2008b. Generalizing word lattice transla-
tion. 2008/02//.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proceedings of the 45th Annual Meeting of the ACL
on Interactive Poster and Demonstration Sessions,
ACL ’07, pages 177–180, Stroudsburg, PA, USA.
Association for Computational Linguistics.
L. Mathias and W. Byrne. 2006. Statistical phrase-
based speech translation. In Proceedings of the
IEEE International Conference in Acoustics, Speech
and Signal Processing, volume I, pages 561–564.
Evgeny Matusov, Stephan Kanthak, and Hermann Ney.
2005. On the integration of speech recognition and
statistical machine translation. In Proceedings of the
9th European Conference on Speech Communica-
tion and Technology, pages 3177–3180.
Hermann Ney. 1999. Speech translation: coupling of
recognition and translation. In Proceedings of the
IEEE International Conference in Acoustics, Speech
and Signal Processing, volume 1, pages 517–520,
March.
Matt Post, Gaurav Kumar, Adam Lopez, Damianos
Karakos, Chris Callison-Burch, and Sanjeev Khu-
danpur. 2013. General lattice decoding for im-
proved speech-to-text translation with the Fisher and
Callhome Spanish-English speech translation cor-
pus. Proceedings of the International Workshop on
Spoken Language Translation.
Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas
Burget, Ondrej Glembek, Nagendra Goel, Mirko
Hannemann, Petr Motlicek, Yanmin Qian, Petr
Schwarz, Jan Silovsky, Georg Stemmer, and Karel
Vesely. 2011. The Kaldi speech recognition
toolkit. In IEEE 2011 Workshop on Automatic
Speech Recognition and Understanding, December.
Vu H Quan, Marcello Federico, and Mauro Cettolo.
2005. Integrated n-best re-ranking for spoken lan-
guage translation. In Proceedings of the 9th Eu-
ropean Conference on Speech Communication and
Technology, pages 3181–3184.
Shirin Saleem, Szu-Chen Jou, Stephan Vogel, and
Tanja Schultz. 2004. Using word lattice information
for a tighter coupling in speech translation systems.
In Proceedings of the International Conference on
Spoken Language Processing, pages 41–44.
Enrique Vidal. 1997. Finite-state speech-to-speech
translation. In Proceedings of the IEEE Interna-
tional Conference in Acoustics, Speech and Signal
Processing, volume 1, pages 111–114, April.
Omar F. Zaidan. 2009. Z-MERT: A fully configurable
open source tool for minimum error rate training of
machine translation systems. The Prague Bulletin of
Mathematical Linguistics, 91:79–88.
Ruiqiang Zhang, Genichiro Kikui, Hirofumi Ya-
mamoto, Taro Watanabe, Frank Soong, and Wai Kit
Lo. 2004. A unified approach in speech-to-speech
translation: integrating features of speech recogni-
tion and machine translation. In Proceedings of
the 20th international conference on Computational
Linguistics.
Xiaohui Zhang, Jan Trmal, Daniel Povey, and San-
jeev Khudanpur. 2014. Improving deep neural net-
work acoustic models using generalized maxout net-
works. In IEEE International Conference on Acous-
tics, Speech and Signal Processing, ICASSP 2014,
Florence, Italy, May 4-9, 2014, pages 215–219.
</reference>
<page confidence="0.995316">
1907
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.272905">
<title confidence="0.999222">A Coarse-Grained Model for Optimal Coupling of ASR and SMT Systems for Speech Translation</title>
<author confidence="0.743319333333333">Kumar Graeme Blackwood Jan Trmal Daniel Povey Sanjeev Khudanpur</author>
<author confidence="0.743319333333333">Johns Hopkins University HLTCOE</author>
<author confidence="0.743319333333333">T J Watson Research Center Baltimore</author>
<author confidence="0.743319333333333">Yorktown Heights</author>
<author confidence="0.743319333333333">NY</author>
<email confidence="0.952497">dpovey1,</email>
<abstract confidence="0.9880934">Speech translation is conventionally carried out by cascading an automatic speech recognition (ASR) and a statistical machine translation (SMT) system. The hypotheses chosen for translation are based on the ASR system’s acoustic and language model scores, and typically optimized for word error rate, ignoring the intended downstream use: automatic trans- In this paper, we present a coarsethat uses features from the ASR and SMT systems to optimize this coupling. We demonstrate that several standard features utilized by ASR and SMT systems can be used in such a model at the speech-translation interface, and we provide empirical results on the Fisher Spanish-English speech translation corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Giuseppe Riccardi</author>
</authors>
<title>Finite-state models for lexical reordering in spoken language translation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth International Conference on Spoken Language Processing,</booktitle>
<pages>422--425</pages>
<contexts>
<context position="2096" citStr="Bangalore and Riccardi, 2000" startWordPosition="333" endWordPosition="337">output to translate. We will refer to this step as the Speech-Translation interface. In the simplest scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the </context>
</contexts>
<marker>Bangalore, Riccardi, 2000</marker>
<rawString>Srinivas Bangalore and Giuseppe Riccardi. 2000. Finite-state models for lexical reordering in spoken language translation. In Proceedings of the Sixth International Conference on Spoken Language Processing, pages 422–425.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bertoldi</author>
<author>Marcello Federico</author>
</authors>
<title>A new decoder for spoken language translation based on confusion networks.</title>
<date>2005</date>
<booktitle>In Proceedings of the IEEE Workshop on Automatic Speech Recognition and Understanding,</booktitle>
<pages>86--91</pages>
<contexts>
<context position="2145" citStr="Bertoldi and Federico, 2005" startWordPosition="342" endWordPosition="346"> the Speech-Translation interface. In the simplest scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system. Our motivation is as follows: 1. Usin</context>
</contexts>
<marker>Bertoldi, Federico, 2005</marker>
<rawString>N. Bertoldi and Marcello Federico. 2005. A new decoder for spoken language translation based on confusion networks. In Proceedings of the IEEE Workshop on Automatic Speech Recognition and Understanding, pages 86–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Bertoldi</author>
<author>R Zens</author>
<author>Marcello Federico</author>
</authors>
<title>Speech translation by confusion network decoding.</title>
<date>2007</date>
<booktitle>In Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing,</booktitle>
<volume>volume IV,</volume>
<pages>1297--1300</pages>
<contexts>
<context position="2213" citStr="Bertoldi et al., 2007" startWordPosition="355" endWordPosition="358">est output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system. Our motivation is as follows: 1. Using downstream information : Hypothesis selection for the input to the</context>
</contexts>
<marker>Bertoldi, Zens, Federico, 2007</marker>
<rawString>N. Bertoldi, R. Zens, and Marcello Federico. 2007. Speech translation by confusion network decoding. In Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing, volume IV, pages 1297–1300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Dyer</author>
<author>Smaranda Muresan</author>
<author>Philip Resnik</author>
</authors>
<title>Generalizing word lattice translation.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>1012--1020</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="2115" citStr="Dyer et al., 2008" startWordPosition="338" endWordPosition="341">efer to this step as the Speech-Translation interface. In the simplest scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system. Our mot</context>
<context position="11237" citStr="Dyer et al., 2008" startWordPosition="1896" endWordPosition="1899"> lattice input for the SMT system from ˜PASR,MT . 2.2.1 A discussion about related techniques 1. Decoding (Translation) : Our model closely resembles a featurized finite-state transducer based translation model. If we replace the output alphabet of the acceptor ( ˜WMT)* with the target side phrases, we will actually get output in the target language. Even though this model does not explicity include reordering, the coarse-grained decoder has access to information that can enable better decisions about which hypotheses are better for the downstream process (translation). 2. Lattice Decoding : (Dyer et al., 2008b) suggests passing the entire word lattice to the SMT system. However, even if these lattices are not pruned, a beam based decoder might not consider hypotheses that our model may produce through coarse-grained decoding. 3. Language model re-scoring : One may use a bigger source language model to re-score the ASR lattice (or an N-best list). This however, does not consider any SMT features in re-scoring. With our model, we can simply use this as an additional feature. 2.2.2 Training Training the hypothesis selection model can be carried out using standard methods for log linear models on a he</context>
</contexts>
<marker>Dyer, Muresan, Resnik, 2008</marker>
<rawString>Christopher Dyer, Smaranda Muresan, and Philip Resnik. 2008a. Generalizing word lattice translation. In Proceedings of ACL-08: HLT, pages 1012– 1020, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Dyer</author>
<author>Smaranda Muresan</author>
<author>Philip Resnik</author>
</authors>
<title>Generalizing word lattice translation.</title>
<date>2008</date>
<pages>2008--02</pages>
<contexts>
<context position="2115" citStr="Dyer et al., 2008" startWordPosition="338" endWordPosition="341">efer to this step as the Speech-Translation interface. In the simplest scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system. Our mot</context>
<context position="11237" citStr="Dyer et al., 2008" startWordPosition="1896" endWordPosition="1899"> lattice input for the SMT system from ˜PASR,MT . 2.2.1 A discussion about related techniques 1. Decoding (Translation) : Our model closely resembles a featurized finite-state transducer based translation model. If we replace the output alphabet of the acceptor ( ˜WMT)* with the target side phrases, we will actually get output in the target language. Even though this model does not explicity include reordering, the coarse-grained decoder has access to information that can enable better decisions about which hypotheses are better for the downstream process (translation). 2. Lattice Decoding : (Dyer et al., 2008b) suggests passing the entire word lattice to the SMT system. However, even if these lattices are not pruned, a beam based decoder might not consider hypotheses that our model may produce through coarse-grained decoding. 3. Language model re-scoring : One may use a bigger source language model to re-score the ASR lattice (or an N-best list). This however, does not consider any SMT features in re-scoring. With our model, we can simply use this as an additional feature. 2.2.2 Training Training the hypothesis selection model can be carried out using standard methods for log linear models on a he</context>
</contexts>
<marker>Dyer, Muresan, Resnik, 2008</marker>
<rawString>Christopher Dyer, Smaranda Muresan, and Philip Resnik. 2008b. Generalizing word lattice translation. 2008/02//.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="14500" citStr="Koehn et al., 2007" startWordPosition="2452" endWordPosition="2455">nsists of 819 transcribed and translated telephone conversations. The corpus is split into a training, dev and two test sets (dev-2 and test). We use the dev set for training the feature weights of the proposed model. We use the Kaldi speech recognition tools (Povey et al., 2011) to build our Spanish ASR systems. Our state-of-the-art ASR system is the p-norm DNN system of (Zhang et al., 2014). The worderror-rates on the dev and test sets of the Fisher dataset (dev, dev-2, test) are 29.80%, 29.79% and 25.30% respectively. For the SMT system, we use the phrase based translation system of Moses (Koehn et al., 2007) with sparse features. The system is trained and tuned on the train and dev partitions of the Fisher dataset respectively. The BLEU scores of the MT output for the the dev-2 and the test partitions are 65.38% and 62.91% respectively. While decoding the ASR output, we tune on the 1-best ASR output for the dev partition. With this modified system, the BLEU scores for the ASR 1-best output of the dev2 and the test partitions are 40.06% and 40.4% respectively. We use this system as the baseline for our experiments (Table 1). We note that if we were to use the lattice oracle6 from our ASR system as</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 177–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mathias</author>
<author>W Byrne</author>
</authors>
<title>Statistical phrasebased speech translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing, volume I,</booktitle>
<pages>561--564</pages>
<contexts>
<context position="2189" citStr="Mathias and Byrne, 2006" startWordPosition="351" endWordPosition="354">st scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system. Our motivation is as follows: 1. Using downstream information : Hypothesis select</context>
</contexts>
<marker>Mathias, Byrne, 2006</marker>
<rawString>L. Mathias and W. Byrne. 2006. Statistical phrasebased speech translation. In Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing, volume I, pages 561–564.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeny Matusov</author>
<author>Stephan Kanthak</author>
<author>Hermann Ney</author>
</authors>
<title>On the integration of speech recognition and statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th European Conference on Speech Communication and Technology,</booktitle>
<pages>3177--3180</pages>
<contexts>
<context position="2066" citStr="Matusov et al., 2005" startWordPosition="329" endWordPosition="332">riate form of the ASR output to translate. We will refer to this step as the Speech-Translation interface. In the simplest scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the AS</context>
</contexts>
<marker>Matusov, Kanthak, Ney, 2005</marker>
<rawString>Evgeny Matusov, Stephan Kanthak, and Hermann Ney. 2005. On the integration of speech recognition and statistical machine translation. In Proceedings of the 9th European Conference on Speech Communication and Technology, pages 3177–3180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hermann Ney</author>
</authors>
<title>Speech translation: coupling of recognition and translation.</title>
<date>1999</date>
<booktitle>In Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing,</booktitle>
<volume>1</volume>
<pages>517--520</pages>
<contexts>
<context position="4689" citStr="Ney, 1999" startWordPosition="751" endWordPosition="752"> the basic unit instead of words. 2 Coarse-to-Fine Speech Translation In this section, we describe the featurized model (coarse-grain MT decoder) for hypothesis selection that uses information from the ASR and SMT systems (impedance matching). We assume the presence of ASR and SMT systems that have been trained separately. In addition to creating almost no disruption in the traditional pipeline approach, this allows us to incorporate local gains from each system. To elaborate, our methods avoid joint optimization of the ASR and the SMT system with respect to a translation metric (Vidal, 1997; Ney, 1999), which is not feasible for larger datasets. Also, considering the dearth of speech translation training datasets, this method allows independent training of the ASR and SMT systems on data created only for ASR training and parallel data for SMT. We start by introducing the formal machinery that will be used and by presenting a simple example to motivate the model. The complete featurized model follows this exposition. Let E and F be alphabets of words and phrases respectively in the source language. Using these, we can define the following finite state machines: 1. Word Lattice (L) : A finite</context>
</contexts>
<marker>Ney, 1999</marker>
<rawString>Hermann Ney. 1999. Speech translation: coupling of recognition and translation. In Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing, volume 1, pages 517–520, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Post</author>
<author>Gaurav Kumar</author>
<author>Adam Lopez</author>
<author>Damianos Karakos</author>
<author>Chris Callison-Burch</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>General lattice decoding for improved speech-to-text translation with the Fisher and Callhome Spanish-English speech translation corpus.</title>
<date>2013</date>
<booktitle>Proceedings of the International Workshop on Spoken Language Translation.</booktitle>
<contexts>
<context position="13837" citStr="Post et al., 2013" startWordPosition="2338" endWordPosition="2341"> phrase n-gram probabilities (normalized) by length. 4. Phrase translation entropy : For each source side phrase pj, we may have multiple translations (ei) in the phrase table with different translation probabilities (p(ei|fj)). A simple entropy measure can be used as a feature to estimate the confidence that the SMT system has in translating fj. ftr(pj) = Htr(E|pj) �= − ptr(ei|fj) log ptr(ei|fj) i 5This requires the use of one ASR feature, addressed in the “Features” section �= − plex(ei|fj) log plex(ei|fj) i 3 Results We use the Fisher and Callhome Spanish-English Speech Translation Corpus (Post et al., 2013) for our experiments. This Fisher dataset consists of 819 transcribed and translated telephone conversations. The corpus is split into a training, dev and two test sets (dev-2 and test). We use the dev set for training the feature weights of the proposed model. We use the Kaldi speech recognition tools (Povey et al., 2011) to build our Spanish ASR systems. Our state-of-the-art ASR system is the p-norm DNN system of (Zhang et al., 2014). The worderror-rates on the dev and test sets of the Fisher dataset (dev, dev-2, test) are 29.80%, 29.79% and 25.30% respectively. For the SMT system, we use th</context>
</contexts>
<marker>Post, Kumar, Lopez, Karakos, Callison-Burch, Khudanpur, 2013</marker>
<rawString>Matt Post, Gaurav Kumar, Adam Lopez, Damianos Karakos, Chris Callison-Burch, and Sanjeev Khudanpur. 2013. General lattice decoding for improved speech-to-text translation with the Fisher and Callhome Spanish-English speech translation corpus. Proceedings of the International Workshop on Spoken Language Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Povey</author>
<author>Arnab Ghoshal</author>
<author>Gilles Boulianne</author>
<author>Lukas Burget</author>
<author>Ondrej Glembek</author>
<author>Nagendra Goel</author>
<author>Mirko Hannemann</author>
<author>Petr Motlicek</author>
<author>Yanmin Qian</author>
<author>Petr Schwarz</author>
<author>Jan Silovsky</author>
<author>Georg Stemmer</author>
<author>Karel Vesely</author>
</authors>
<title>The Kaldi speech recognition toolkit.</title>
<date>2011</date>
<booktitle>In IEEE 2011 Workshop on Automatic Speech Recognition and Understanding,</booktitle>
<contexts>
<context position="14161" citStr="Povey et al., 2011" startWordPosition="2393" endWordPosition="2396">em has in translating fj. ftr(pj) = Htr(E|pj) �= − ptr(ei|fj) log ptr(ei|fj) i 5This requires the use of one ASR feature, addressed in the “Features” section �= − plex(ei|fj) log plex(ei|fj) i 3 Results We use the Fisher and Callhome Spanish-English Speech Translation Corpus (Post et al., 2013) for our experiments. This Fisher dataset consists of 819 transcribed and translated telephone conversations. The corpus is split into a training, dev and two test sets (dev-2 and test). We use the dev set for training the feature weights of the proposed model. We use the Kaldi speech recognition tools (Povey et al., 2011) to build our Spanish ASR systems. Our state-of-the-art ASR system is the p-norm DNN system of (Zhang et al., 2014). The worderror-rates on the dev and test sets of the Fisher dataset (dev, dev-2, test) are 29.80%, 29.79% and 25.30% respectively. For the SMT system, we use the phrase based translation system of Moses (Koehn et al., 2007) with sparse features. The system is trained and tuned on the train and dev partitions of the Fisher dataset respectively. The BLEU scores of the MT output for the the dev-2 and the test partitions are 65.38% and 62.91% respectively. While decoding the ASR outp</context>
</contexts>
<marker>Povey, Ghoshal, Boulianne, Burget, Glembek, Goel, Hannemann, Motlicek, Qian, Schwarz, Silovsky, Stemmer, Vesely, 2011</marker>
<rawString>Daniel Povey, Arnab Ghoshal, Gilles Boulianne, Lukas Burget, Ondrej Glembek, Nagendra Goel, Mirko Hannemann, Petr Motlicek, Yanmin Qian, Petr Schwarz, Jan Silovsky, Georg Stemmer, and Karel Vesely. 2011. The Kaldi speech recognition toolkit. In IEEE 2011 Workshop on Automatic Speech Recognition and Understanding, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vu H Quan</author>
<author>Marcello Federico</author>
<author>Mauro Cettolo</author>
</authors>
<title>Integrated n-best re-ranking for spoken language translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 9th European Conference on Speech Communication and Technology,</booktitle>
<pages>3181--3184</pages>
<contexts>
<context position="2164" citStr="Quan et al., 2005" startWordPosition="347" endWordPosition="350">face. In the simplest scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from the outputs of the ASR system for the input to the SMT system. Our motivation is as follows: 1. Using downstream inform</context>
</contexts>
<marker>Quan, Federico, Cettolo, 2005</marker>
<rawString>Vu H Quan, Marcello Federico, and Mauro Cettolo. 2005. Integrated n-best re-ranking for spoken language translation. In Proceedings of the 9th European Conference on Speech Communication and Technology, pages 3181–3184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shirin Saleem</author>
<author>Szu-Chen Jou</author>
<author>Stephan Vogel</author>
<author>Tanja Schultz</author>
</authors>
<title>Using word lattice information for a tighter coupling in speech translation systems.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing,</booktitle>
<pages>41--44</pages>
<contexts>
<context position="2044" citStr="Saleem et al., 2004" startWordPosition="325" endWordPosition="328"> extracting an appropriate form of the ASR output to translate. We will refer to this step as the Speech-Translation interface. In the simplest scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted through the speech translation interface. This paper presents a featurized model which performs the job of hypothesis selection from</context>
</contexts>
<marker>Saleem, Jou, Vogel, Schultz, 2004</marker>
<rawString>Shirin Saleem, Szu-Chen Jou, Stephan Vogel, and Tanja Schultz. 2004. Using word lattice information for a tighter coupling in speech translation systems. In Proceedings of the International Conference on Spoken Language Processing, pages 41–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Enrique Vidal</author>
</authors>
<title>Finite-state speech-to-speech translation.</title>
<date>1997</date>
<booktitle>In Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing,</booktitle>
<volume>1</volume>
<pages>111--114</pages>
<contexts>
<context position="4677" citStr="Vidal, 1997" startWordPosition="749" endWordPosition="750">ng phrases as the basic unit instead of words. 2 Coarse-to-Fine Speech Translation In this section, we describe the featurized model (coarse-grain MT decoder) for hypothesis selection that uses information from the ASR and SMT systems (impedance matching). We assume the presence of ASR and SMT systems that have been trained separately. In addition to creating almost no disruption in the traditional pipeline approach, this allows us to incorporate local gains from each system. To elaborate, our methods avoid joint optimization of the ASR and the SMT system with respect to a translation metric (Vidal, 1997; Ney, 1999), which is not feasible for larger datasets. Also, considering the dearth of speech translation training datasets, this method allows independent training of the ASR and SMT systems on data created only for ASR training and parallel data for SMT. We start by introducing the formal machinery that will be used and by presenting a simple example to motivate the model. The complete featurized model follows this exposition. Let E and F be alphabets of words and phrases respectively in the source language. Using these, we can define the following finite state machines: 1. Word Lattice (L</context>
</contexts>
<marker>Vidal, 1997</marker>
<rawString>Enrique Vidal. 1997. Finite-state speech-to-speech translation. In Proceedings of the IEEE International Conference in Acoustics, Speech and Signal Processing, volume 1, pages 111–114, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omar F Zaidan</author>
</authors>
<title>Z-MERT: A fully configurable open source tool for minimum error rate training of machine translation systems.</title>
<date>2009</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics,</booktitle>
<pages>91--79</pages>
<contexts>
<context position="16295" citStr="Zaidan, 2009" startWordPosition="2777" endWordPosition="2778">ate. where fj is a source side phrase in the phrase table. ⎡ ⎤len(fj) ⎣ freq(fj) funi(fj) = E ⎦ freq(fk) k 1905 Experiment BLEU (dev2) BLEU (test) Transcripts 65.4% 62.9% Lattice Oracle 46.59% 46.17% ASR 1-best 40.06% 40.4% Coarse decoder 40.26% 40.46% Table 1: Performance when using the coarse decoder interface compared to the the decoding the human transcripts, the ASR 1-best or the lattice oracle (the path in the ASR lattice with the least WER : not available during test time.) respect to the reference translation of the ASR hypothesis selected by the coarse grained decoder. We used ZMERT (Zaidan, 2009) for tuning which was configured to expect a 300-best list from the decoder at every iteration using the Fisher dev set. 15 iterations of tuning were carried out for each experiment. We then use the tuned weight vector to decode the Fisher-dev2 and the Fisher-test set using our coarse grained decoder. We extract the one-best output and use it as input to the pretrained SMT system (description in the preceding section). Table 1 reports the results achieved the featurized coarse grained decoder. 4 Conclusions We present a coarse-to-fine featurized model which acts as the interface between ASR an</context>
</contexts>
<marker>Zaidan, 2009</marker>
<rawString>Omar F. Zaidan. 2009. Z-MERT: A fully configurable open source tool for minimum error rate training of machine translation systems. The Prague Bulletin of Mathematical Linguistics, 91:79–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruiqiang Zhang</author>
<author>Genichiro Kikui</author>
<author>Hirofumi Yamamoto</author>
<author>Taro Watanabe</author>
<author>Frank Soong</author>
<author>Wai Kit Lo</author>
</authors>
<title>A unified approach in speech-to-speech translation: integrating features of speech recognition and machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics.</booktitle>
<contexts>
<context position="1913" citStr="Zhang et al., 2004" startWordPosition="307" endWordPosition="310">volves training an Automatic Speech Recognition (ASR) system to transcribe speech to text in the source language. Step two involves extracting an appropriate form of the ASR output to translate. We will refer to this step as the Speech-Translation interface. In the simplest scenario, the ASR 1- best output can be used as the source text to translate. It may be useful to consider alternative ASR hypotheses and these take the form of an N-best list or a word-lattice. An N-best list can be included easily into the tuning and the decoding process of a statistical machine translation (SMT) system (Zhang et al., 2004). Several researchers have proposed solutions to incorporating lattices and confusion networks in this process (Saleem et al., 2004; Matusov et al., 2005; Bangalore and Riccardi, 2000; Dyer et al., 2008a; Bertoldi and Federico, 2005; Quan et al., 2005; Mathias and Byrne, 2006; Bertoldi et al., 2007). Word lattice input to SMT for tuning and decoding increases the complexity of the decoding process because of the exponential number of alternatives that are present. Finally, step three involves training and tuning a Statistical Machine Translation (SMT) system and decoding the output extracted t</context>
</contexts>
<marker>Zhang, Kikui, Yamamoto, Watanabe, Soong, Lo, 2004</marker>
<rawString>Ruiqiang Zhang, Genichiro Kikui, Hirofumi Yamamoto, Taro Watanabe, Frank Soong, and Wai Kit Lo. 2004. A unified approach in speech-to-speech translation: integrating features of speech recognition and machine translation. In Proceedings of the 20th international conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohui Zhang</author>
<author>Jan Trmal</author>
<author>Daniel Povey</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Improving deep neural network acoustic models using generalized maxout networks.</title>
<date>2014</date>
<booktitle>In IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2014,</booktitle>
<pages>215--219</pages>
<location>Florence, Italy,</location>
<contexts>
<context position="14276" citStr="Zhang et al., 2014" startWordPosition="2413" endWordPosition="2416">ature, addressed in the “Features” section �= − plex(ei|fj) log plex(ei|fj) i 3 Results We use the Fisher and Callhome Spanish-English Speech Translation Corpus (Post et al., 2013) for our experiments. This Fisher dataset consists of 819 transcribed and translated telephone conversations. The corpus is split into a training, dev and two test sets (dev-2 and test). We use the dev set for training the feature weights of the proposed model. We use the Kaldi speech recognition tools (Povey et al., 2011) to build our Spanish ASR systems. Our state-of-the-art ASR system is the p-norm DNN system of (Zhang et al., 2014). The worderror-rates on the dev and test sets of the Fisher dataset (dev, dev-2, test) are 29.80%, 29.79% and 25.30% respectively. For the SMT system, we use the phrase based translation system of Moses (Koehn et al., 2007) with sparse features. The system is trained and tuned on the train and dev partitions of the Fisher dataset respectively. The BLEU scores of the MT output for the the dev-2 and the test partitions are 65.38% and 62.91% respectively. While decoding the ASR output, we tune on the 1-best ASR output for the dev partition. With this modified system, the BLEU scores for the ASR </context>
</contexts>
<marker>Zhang, Trmal, Povey, Khudanpur, 2014</marker>
<rawString>Xiaohui Zhang, Jan Trmal, Daniel Povey, and Sanjeev Khudanpur. 2014. Improving deep neural network acoustic models using generalized maxout networks. In IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP 2014, Florence, Italy, May 4-9, 2014, pages 215–219.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>