<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000110">
<title confidence="0.9987545">
Semantic Annotation for Microblog Topics
Using Wikipedia Temporal Information
</title>
<author confidence="0.838106">
Tuan Tran Nam Khanh Tran Asmelash Teka Hadgu Robert J¨aschke
</author>
<affiliation confidence="0.642882">
L3S Research Center L3S Research Center L3S Research Center L3S Research Center
Hannover, Germany Hannover, Germany Hannover, Germany Hannover, Germany
</affiliation>
<email confidence="0.946189">
ttran@L3S.de ntran@L3S.de teka@L3S.de jaeschke@L3S.de
</email>
<sectionHeader confidence="0.992177" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999958473684211">
Trending topics in microblogs such as
Twitter are valuable resources to under-
stand social aspects of real-world events.
To enable deep analyses of such trends, se-
mantic annotation is an effective approach;
yet the problem of annotating microblog
trending topics is largely unexplored by
the research community. In this work, we
tackle the problem of mapping trending
Twitter topics to entities from Wikipedia.
We propose a novel model that comple-
ments traditional text-based approaches by
rewarding entities that exhibit a high tem-
poral correlation with topics during their
burst time period. By exploiting temporal
information from the Wikipedia edit his-
tory and page view logs, we have improved
the annotation performance by 17-28%, as
compared to the competitive baselines.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.959496363636364">
With the proliferation of microblogging and its
wide influence on how information is shared and
digested, the studying of microblog sites has
gained interest in recent NLP research. Several ap-
proaches have been proposed to enable a deep un-
derstanding of information on Twitter. An emerg-
ing approach is to use semantic annotation tech-
niques, for instance by mapping Twitter informa-
tion snippets to canonical entities in a knowledge
base or to Wikipedia (Meij et al., 2012; Guo et al.,
2013), or by revisiting NLP tasks in the Twitter do-
main (Owoputi et al., 2013; Ritter et al., 2011).
Much of the existing work focuses on annotating
a single Twitter message (tweet). However, infor-
mation in Twitter is rarely digested in isolation, but
rather in a collective manner, with the adoption of
special mechanisms such as hashtags. When put
together, the unprecedentedly massive adoption of
Hard to believe anyone can do worse than Russia in #Sochi. Brazil
seems to be trying pretty hard though! sportingnews.com...
#sochi Sochi 2014: Record number of positive tests
--‐SkySports: q.gs/6nbAA
</bodyText>
<figure confidence="0.707831">
#Sochi Sea Port. What a
beautiful site! #Russia
2014_Winter_Olympics
Port_of_Sochi
</figure>
<figureCaption confidence="0.997673">
Figure 1: Example of trending hashtag annota-
</figureCaption>
<bodyText confidence="0.9845965">
tion. During the 2014 Winter Olympics, the hash-
tag ‘#sochi’ had a different meaning.
a hashtag within a short time period can lead to
bursts and often reflect trending social attention.
Understanding the meaning of trending hashtags
offers a valuable opportunity for various applica-
tions and studies, such as viral marketing, social
behavior analysis, recommendation, etc. Unfor-
tunately, the task of hashtag annotation has been
largely unexplored so far.
In this paper, we study the problem of annotat-
ing trending hashtags on Twitter by entities de-
rived from Wikipedia. Instead of establishing a
static semantic connection between hashtags and
entities, we are interested in dynamically linking
the hashtags to entities that are closest to the un-
derlying topics during burst time periods of the
hashtags. For instance, while ‘#sochi’ refers to
a city in Russia, during February 2014, the hash-
tag was used to report the 2014 Winter Olympics
(cf. Figure 1). Hence, it should be linked more
to Wikipedia pages related to the event than to the
location.
Compared to traditional domains of text (e.g.,
news articles), annotating hashtags poses addi-
tional challenges. Hashtags’ surface forms are
</bodyText>
<page confidence="0.995936">
97
</page>
<note confidence="0.985046">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 97–106,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.99978524137931">
very ad-hoc, as they are chosen not in favor of
the text quality, but by the dynamics in attention
of the large crowd. In addition, the evolution
of the semantics of hashtags (e.g., in the case of
‘#sochi’) makes them more ambiguous. Further-
more, a hashtag can encode multiple topics at once.
For example, in March 2014, ‘#oscar’ refers to the
86th Academy Awards, but at the same time also
to the Trial of Oscar Pistorius. Sometimes, it is
difficult even for humans to understand a trending
hashtag without knowledge about what was hap-
pening with the related entities in the real world.
In this work, we propose a novel solu-
tion to these challenges by leveraging temporal
knowledge about entity dynamics derived from
Wikipedia. We hypothesize that a trending hashtag
is associated with an increase in public attention to
certain entities, and this can also be observed on
Wikipedia. As in Figure 1, we can identify 2014
Winter Olympics as a prominent entity for ‘#sochi’
during February 2014, by observing the change of
user attention to the entity, for instance via the page
view statistics of Wikipedia articles. We exploit
both Wikipedia edits and page views for annota-
tion. We also propose a novel learning method,
inspired by the information spreading nature of so-
cial media such as Twitter, to suggest the optimal
annotations without the need for human labeling.
In summary:
</bodyText>
<listItem confidence="0.997376818181818">
• We are the first to combine the Wikipedia edit
history and page view statistics to overcome
the temporal ambiguity of Twitter hashtags.
• We propose a novel and efficient learning al-
gorithm based on influence maximization to
automatically annotate hashtags. The idea is
generalizable to other social media sites that
have a similar information spreading nature.
• We conduct thorough experiments on a real-
world dataset and show that our system can
outperform competitive baselines by 17-28%.
</listItem>
<sectionHeader confidence="0.999341" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9996974">
Entity Linking in Microblogs The task of se-
mantic annotation in microblogs has been recently
tackled by different methods, which can be divided
into two classes, i.e., content-based and graph-
based methods. While the content-based methods
(Meij et al., 2012; Guo et al., 2013; Fang and
Chang, 2014) consider tweets independently, the
graph-based methods (Cassidy et al., 2012; Liu et
al., 2013) use all related tweets (e.g., posted by a
user) together. However, most of them focus on
entity mentions in tweets. In contrast, we take
into account hashtags which reflect the topics dis-
cussed in tweets, and leverage external resources
from Wikipedia (in particular, the edit history and
page view logs) for semantic annotation.
Analysis of Twitter Hashtags In an attempt to
understand the user interest dynamics on Twitter,
a rich body of work analyzes the temporal pat-
terns of popular hashtags (Lehmann et al., 2012;
Naaman et al., 2011; Tsur and Rappoport, 2012).
Few works have paid attention to the semantics of
hashtags, i.e., to the underlying topics conveyed
in the corresponding tweets. Recently, Bansal et
al. (2015) attempt to segment a hashtag and link
each of its tokens to a Wikipedia page. However,
the authors only aim to retrieve entities directly
mentioned within a hashtag, which are very few
in practice. The external information derived from
the tweets is largely ignored. In contrast, we ex-
ploit both context information from the microblog
and Wikipedia resources.
Event Mining Using Wikipedia Recently some
works exploit Wikipedia for detecting and ana-
lyzing events on Twitter (Osborne et al., 2012;
Tolomei et al., 2013; Tran et al., 2014). However,
most of the existing studies focus on the statistical
signals of Wikipedia (such as the edit or page view
volumes). We are the first to combine the content
of the Wikipedia edit history and the magnitude of
page views to handle trending topics on Twitter.
</bodyText>
<sectionHeader confidence="0.997408" genericHeader="method">
3 Framework
</sectionHeader>
<bodyText confidence="0.999741466666667">
Preliminaries We refer to an entity (denoted
by e) as any object described by a Wikipedia ar-
ticle (ignoring disambiguation, lists, and redirect
pages). The number of times an entity’s article has
been requested is called the entity view count. The
text content of the article is denoted by C(e). In
this work, we choose to study hashtags at the daily
level, i.e., from the timestamps of tweets we only
consider their creation day. A hashtag is called
trending at a time point (a day) if the number of
tweets where it appears is significantly higher than
that on other days. There are many ways to de-
tect such trendings. (Lappas et al., 2009; Lehmann
et al., 2012). Each trending hashtag has one or
multiple burst time periods, surrounding the trend-
</bodyText>
<page confidence="0.997912">
98
</page>
<bodyText confidence="0.999980172413793">
ing day, where the users’ interest in the underly-
ing topic remains stronger than in other periods.
We denote with T (h) (or T for short) one hashtag
burst time period, and with DT (h) the set of tweets
containing the hashtag h created during T.
Task Definition Given a trending hashtag h and
the burst time period T of h, identify the top-k
most prominent entities to describe h during T.
It is worth noting that not all trending hashtags
are mapable to Wikipedia entities, as the coverage
of topics in Wikipedia is much lower than on Twit-
ter. This is also the limitation of systems relying
on Wikipedia such as entity disambiguation, which
can only disambiguate popular entities and not the
ones in the long tail. In this study, we focus on the
precision and the popular trending hashtags, and
leave the improvement of recall to future work.
Overview We approach the task in three steps.
The first step is to identify all entity candidates by
checking surface forms of the constituent tweets
of the hashtag. In the second step, we compute
different similarities between each candidate and
the hashtag, based on different types of contexts,
which are derived from either side (Wikipedia or
Twitter). Finally, we learn a unified ranking func-
tion for each (hashtag, entity) pair and choose the
top-k entities with the highest scores. The ranking
function is learned through an unsupervised model
and needs no human-defined labels.
</bodyText>
<subsectionHeader confidence="0.998856">
3.1 Entity Linking
</subsectionHeader>
<bodyText confidence="0.999951269230769">
The most obvious resource to identify candidate
entities for a hashtag is via its tweets. We follow
common approaches that use a lexicon to match
each textual phrase in a tweet to a potential en-
tity set (Shen et al., 2013; Fang and Chang, 2014).
Our lexicon is constructed from Wikipedia page ti-
tles, hyperlink anchors, redirects, and disambigua-
tion pages, which are mapped to the correspond-
ing entities. As for the tweet phrases, we extract
all n-grams (n ≤ 5) from the input tweets within
T. We apply the longest-match heuristic (Meij et
al., 2012): We start with the longest n-grams and
stop as soon as the entity set is found, otherwise
we continue with the smaller constituent n-grams.
Candidate Set Expansion While the lexicon-
based linking works well for single tweets, ap-
plying it on the hashtag level has subtle implica-
tions. Processing a huge amount of text, especially
during a hashtag burst time period, incurs expen-
sive computational costs. Therefore, to guarantee a
good recall in this step while still maintaining fea-
sible computation, we apply entity linking only on
a random sample of the complete tweet set. Then,
for each candidate entity e, we include all entities
whose Wikipedia article is linked with the article
of e by an outgoing or incoming link.
</bodyText>
<subsectionHeader confidence="0.999984">
3.2 Measuring Entity–Hashtag Similarities
</subsectionHeader>
<bodyText confidence="0.999914137931035">
To rank the entity by prominence, we measure the
similarity between each candidate entity and the
hashtag. We study three types of similarities:
Mention Similarity This measure relies on the
explicit mentions of entities in tweets. It assumes
that entities directly linked from more prominent
anchors are more relevant to the hashtag. It is es-
timated using both statistics from Wikipedia and
tweet phrases, and turns out to be surprisingly ef-
fective in practice (Fang and Chang, 2014).
Context Similarity For entities that are not di-
rectly linked to mentions (the mention similar-
ity is zero) we exploit external resources instead.
Their prominence is perceived by users via exter-
nal sources, such as web pages linked from tweets,
or entity home pages or Wikipedia pages. By ex-
ploiting the content of entities from these external
sources, we can complement the explicit similarity
metrics based on mentions.
Temporal Similarity The two measures above
rely on the textual representation and are degraded
by the linguistic difference between the two plat-
forms. To overcome this drawback, we incorpo-
rate the temporal dynamics of hashtags and enti-
ties, which serve as a proxy to the change of user
interests towards the underlying topics (Ciglan and
Nørv˚ag, 2010). We employ the correlation be-
tween the times series of hashtag adoption and the
entity view as the third similarity measure.
</bodyText>
<subsectionHeader confidence="0.999906">
3.3 Ranking Entity Prominence
</subsectionHeader>
<bodyText confidence="0.984659222222222">
While each similarity measure captures one evi-
dence of the entity prominence, we need to unify
all scores to obtain a global ranking function. In
this work, we propose to combine the individual
similarities using a linear function:
f(e, h) = αfm(e, h)+βfc(e, h)+γft(e, h) (1)
where α, β, γ are model weights and fm, fc, ft are
the similarity measures based on mentions, con-
text, and temporal information, respectively, be-
</bodyText>
<page confidence="0.992758">
99
</page>
<bodyText confidence="0.999847285714286">
tween the entity e and the hashtag h. We further
constrain that α + β + γ = 1, so that the ranking
scores of entities are normalized between 0 and 1,
and that our learning algorithm is more tractable.
The algorithm, which automatically learns the pa-
rameters without the need of human-labeled data,
is explained in detail in Section 5.
</bodyText>
<sectionHeader confidence="0.986517" genericHeader="method">
4 Similarity Measures
</sectionHeader>
<bodyText confidence="0.9998175">
We now discuss in detail how the similarity mea-
sures between hashtags and entities are computed.
</bodyText>
<subsectionHeader confidence="0.996292">
4.1 Link-based Mention Similarity
</subsectionHeader>
<bodyText confidence="0.999701076923077">
The similarity of an entity with one individual
mention in a tweet can be interpreted as the prob-
abilistic prior in mapping the mention to the en-
tity via the lexicon. One common way to estimate
the entity prior exploits the anchor statistics from
Wikipedia links, and has been proven to work well
in different domains of text. We follow this ap-
proach and define LP(e|m) = |lm(e) |m� |lm�(e)|as the
link prior of the entity e given a mention m, where
lm(e) is the set of links with anchor m that point
to e. The mention similarity fm is measured as the
aggregation of link priors of the entity e over all
mentions in all tweets with the hashtag h:
</bodyText>
<equation confidence="0.911124">
I:
fm(e, h) = (LP (e|m) · q(m)) (2)
m
</equation>
<bodyText confidence="0.9999">
where q(m) is the frequency of the mention m over
all mentions of e in all tweets of h.
</bodyText>
<subsectionHeader confidence="0.580293">
4.1.1 Context Similarity
</subsectionHeader>
<bodyText confidence="0.999927551724138">
To compute fc, we first construct the contexts for
hashtags and entities. The context of a hashtag
is built by extracting all words from its tweets.
We tokenize and parse the tweets’ part-of-speech
tags (Owoputi et al., 2013), and remove words
of Twitter-specific tags (e.g., @-mentions, URLs,
emoticons, etc.). Hashtags are normalized using
the word breaking method by Wang et al. (2011).
The textual context of an entity is extracted from
its Wikipedia article. One subtle aspect is that the
articles are not created at once, but are incremen-
tally updated over time in accordance with chang-
ing information about entities. Texts added in the
same time period of a trending hashtag contribute
more to the context similarity between the entity
and the hashtag. Based on this observation, we use
the Wikipedia revision history – an archive of all
revisions of Wikipedia articles – to calculate the
entity context. We collect the revisions of articles
during the time period T, plus one day to acknowl-
edge possible time lags. We compute the differ-
ence between two consecutive revisions, and ex-
tract only the added text snippets. These snippets
are accumulated to form the temporal context of
an entity e during T, denoted by CT(e). The dis-
tribution of a word w for the entity e is estimated
by a mixture between the probability of generating
w from the temporal context and from the general
context C(e) of the entity:
</bodyText>
<equation confidence="0.969986">
Pˆ(w|e) = λ Pˆ(w|MCT (e))+(1−λ) Pˆ(w|MC(e))
</equation>
<bodyText confidence="0.999914875">
where MCT (e) and MC(e) are the language mod-
els of e based on CT(e) and C(e), respec-
tively. The probability Pˆ(w|MC(e)) can be re-
garded as corresponding to the background model,
while Pˆ (w|MCT (e)) corresponds to the fore-
ground model in traditional language modeling
settings. Here we use a simple maximum like-
lihood estimation to estimate these probabilities:
</bodyText>
<equation confidence="0.9291085">
Pˆ(w|MC(e)) = tfw,c
|C(e) |and Pˆ(w|MCT (e)) =
tfw,cT
|CT (e)|, where t fw,c and t fw,cT are the term fre-
</equation>
<bodyText confidence="0.999082888888889">
quencies of w in the two text sources of C(e)
and CT(e), respectively, and |C(e) |and |CT(e)|
are the lengths of the two texts, respectively. We
use the same estimation for tweets: Pˆ(w|h) =
tfw,D(h) |D(h) |, where D(h) is the concatenated text of
all tweets of h in T. We use and normalize the
Kullback-Leibler divergence to compare the dis-
tributions over all words appearing both in the
Wikipedia contexts and the tweets:
</bodyText>
<equation confidence="0.92549575">
I:
KL(e k h) = Pˆ(w|e) ·
w
fc(e, h) = e−KL(e 11 h) (3)
</equation>
<subsectionHeader confidence="0.666462">
4.1.2 Temporal Similarity
</subsectionHeader>
<bodyText confidence="0.999793692307692">
The third similarity, ft, is computed using tem-
poral signals from both sources – Twitter and
Wikipedia. For the hashtags, we build the time
series based on the volume of tweets adopt-
ing the hashtag h on each day in T: TSh =
[n1, n2,... , n|T|]. Similarly for the entities, we
build the time series of view counts for the entity e
in T: TSe = [v1, v2,.. . , v|T|]. A time series sim-
ilarity metric is then used to compute ft. Several
metrics can be used, however most of them suf-
fer from the time lag and scaling discrepancy, or
incur expensive computational costs (Radinsky et
al., 2011). In this work, we employ a simple yet
</bodyText>
<figure confidence="0.963751375">
Pˆ(w|e)
Pˆ(w|h)
100
#sochi Sochi: Team USA takes 3 more medals,
tops leaderboard  |http://abc7.com
http://adf.ly/dp8Hn
#love #Sochi 2014: Russia&apos;s ice hockey dream
ends as Vladimir Putin watches on ...
...
#Sochi bear after #Mussia&apos;s hockey team
eliminated with loss to #Finland
I&apos;m still happy because Finland won. Is that too
stupid..? #Hockey #Sochi
Vladimir_Pu&gt;n
Finland
2014_Winter_Olympics
United_States
Sochi
Ice_hockey_at_the_2014_
Winter_Olympics
Ice_hockey
Russia_men’s_na&gt;onal
_ice_ hockey_team
Russia
</figure>
<figureCaption confidence="0.999293">
Figure 2: Excerpt of tweets about ice hockey results in the 2014 Winter Olympics (left), and the observed
</figureCaption>
<bodyText confidence="0.9856835">
linking process between time-aligned revisions of candidate Wikipedia entities (right). Links come more
from prominent entities to marginal ones to provide background, or more context for the topics. Thus,
starting from prominent entities, we can reach more entities in the graph of candidate entities
effective metric that is agnostic to the scaling and
time lag of time series (Yang and Leskovec, 2011).
It measures the distance between two time series
by finding optimal shifting and scaling parameters
to match the shape of two time series:
</bodyText>
<equation confidence="0.9378435">
IITSh − δdq(TSe)II (4)
IITShII
</equation>
<bodyText confidence="0.999683333333333">
where dq(TSe) is the time series derived from TSe
by shifting q time units, and II&apos;II is the L2 norm. It
has been proven that Equation 4 has a closed-form
solution for δ given fixed q, thus we can design an
efficient gradient-based optimization algorithm to
compute ft (Yang and Leskovec, 2011).
</bodyText>
<sectionHeader confidence="0.997686" genericHeader="method">
5 Entity Prominence Ranking
</sectionHeader>
<subsectionHeader confidence="0.957911">
5.1 Ranking Framework
</subsectionHeader>
<bodyText confidence="0.999968897959184">
To unify the individual similarities into one global
metric (Equation 1), we need a guiding premise
of what manifest the prominence of an entity to a
hashtag. Such a premise can be instructed through
manual assessment (Meij et al., 2012; Guo et al.,
2013), but it requires human-labeled data and is
biased from evaluator to evaluator. Other heuris-
tics assume that entities close to the main topic of
a text are also coherent to each other (Ratinov et
al., 2011; Liu et al., 2013). Based on this, state-of-
the-art methods in traditional disambiguation es-
timate entity prominence by optimizing the over-
all coherence of the entities’ semantic relatedness.
However, this coherence does not hold for topics
in hashtags: Entities reported in a big topic such
as the Olympics vary greatly with different sub-
events. They are not always coherent to each other,
as they are largely dependent on the users’ diverse
attention to each sub-event. This heterogeneity of
hashtags calls for a different premise, abandoning
the idea of coherence.
Influence Maximization (IM) We propose a
new approach to find entities for a hashtag. We
use an observed behavioral pattern in creating
Wikipedia pages for guiding our approach to en-
tity prominence: Wikipedia articles of entities that
are prominent for a topic are quickly created or
updated,1 and subsequently enriched with links to
related entities. This linking process signals the
dynamics of editor attention and exposure to the
event (Keegan et al., 2011). We argue that the pro-
cess does not, or to a much lesser degree, happen to
more marginal entities or to very general entities.
As illustrated in Figure 2, the entities closer to the
2014 Olympics get more updates in the revisions
of their Wikipedia articles, with subsequent links
pointing to articles of more distant entities. The
direction of the links influences the shifting atten-
tion of users (Keegan et al., 2011) as they follow
the structure of articles in Wikipedia.
We assume that, similar to Wikipedia, the entity
prominence also influences how users are exposed
and spread the hashtag on Twitter. In particular,
the initial spreading of a trending hashtag involves
more entities in the focus of the topic. Subsequent
exposure and spreading of the hashtag then include
other related entities (e.g., discussing background
or providing context), driven by interests in differ-
ent parts of the topic. Based on this assumption,
</bodyText>
<footnote confidence="0.63531">
1Osborne et al. (2012) suggested a time lag of 3 hours.
</footnote>
<bodyText confidence="0.5641005">
ft(e, h) = min
q,δ
</bodyText>
<page confidence="0.986224">
101
</page>
<bodyText confidence="0.99154625">
we propose to gauge the entity prominence as its
potential in maximizing the information spreading
within all entities present in the tweets of the hash-
tag. In other words, the problem of ranking the
most prominent entities becomes identifying the
set of entities that lead to the largest number of en-
tities in the candidate set. This problem is known
in social network research as influence maximiza-
tion (Kempe et al., 2003).
Iterative Influence-Prominence Learning (IPL)
IM itself is an NP-hard problem (Kempe et al.,
2003). Therefore, we propose an approximation
framework, which can jointly learn the influence
scores of the entity and the entity prominence
together. The framework (called IPL) contains
several iterations, each consisting of two steps:
(1) Pick up a model and use it to compute the entity
influence score. (2) Based on the influence scores,
update the entity prominence. In the sequel we de-
tail our learning framework.
</bodyText>
<subsectionHeader confidence="0.997742">
5.2 Entity Graph
</subsectionHeader>
<bodyText confidence="0.999423375">
Influence Graph To compute the entity influ-
ence scores, we first construct the entity influence
graph as follows. For each hashtag h, we construct
a directed graph Gh = (Eh, Vh), where the nodes
Eh C E consist of all candidate entities (cf. Sec-
tion 3.1), and an edge (ei, ej) E Vh indicates that
there is a link from ej’s Wikipedia article to ei’s.
Note that edges of the influence graph are inversed
in direction to links in Wikipedia, as such a link
gives an “influence endorsement” from the desti-
nation entity to the source entity.
Entity Relatedness In this work, we assume that
an entity endorses more of its influence score to
highly related entities than to lower related ones.
We use a popular entity relatedness measure sug-
gested by Milne and Witten (2008):
</bodyText>
<equation confidence="0.989346333333333">
1
MW el, e, = — log(max(|I1|,|I2|)−log(|I1∩I2|)))
( ) log(|E|)−log(min(|I1|,|I2|))
</equation>
<bodyText confidence="0.99738725">
where I1 and I2 are sets of entities having links to
e1 and e2, respectively, and E is the set of all enti-
ties in Wikipedia. The influence transition from ei
to ej is defined as the normalized value:
</bodyText>
<equation confidence="0.965529888888889">
MW (ei, ej)
Algorithm 1: Entity Influence-Prominence Learning
Input : h, T, DT (h), B, k, learning rate µ, threshold e
Output: W, top-k most prominent entities.
Initialize: W := W(0)
Calculate fm, fes, ft, fω := fω(0) using Eqs. 1, 2, 3, 4
while true do
ˆfω := normalize fω
ˆfω, calculate rh using Eq. 6
Sort rh, get the top-k entities E(h, k)
if Ee∈E(h,k) L(f(e, h), r(e, h)) &lt; e then
Stop
end
W := W − µ Ee∈E(h,k) ∇L(f(e, h), r(e, h))
end
return W, E(h, k)
baseline method suggested by Liu et al. (2014):
rh := τBrh + (1 − τ)sh (6)
</equation>
<bodyText confidence="0.999941">
where B is the influence transition matrix, sh are
the initial influence scores that are based on the en-
tity prominence model (Step 1 of IPL), and τ is the
damping factor.
</bodyText>
<subsectionHeader confidence="0.998825">
5.3 Learning Algorithm
</subsectionHeader>
<bodyText confidence="0.9999894">
Now we detail the IPL algorithm. The objective
is to learn the model ω = (α, β, γ) of the global
function (Equation 1). The general idea is that we
find an optimal ω such that the average error with
respect to the top influencing entities is minimized
</bodyText>
<equation confidence="0.9854895">
�ω = arg min L(f(e, h), r(e, h))
E(h,k)
</equation>
<bodyText confidence="0.995477666666667">
where r(e, h) is the influence score of e and h,
E(h, k) is the set of top-k entities with highest
r(e, h), and L is the squared error loss function,
</bodyText>
<equation confidence="0.977605">
L(x, y) = (x−y)2
2 .
</equation>
<bodyText confidence="0.999849428571429">
The main steps are depicted in Algorithm 1. We
start with an initial guess for ω, and compute the
similarities for the candidate entities. Here fm, fc,
ft, and fω represent the similarity score vectors. We
use matrix multiplication to calculate the similari-
ties efficiently. In each iteration, we first normalize
fω such that the entity scores sum up to 1. A ran-
dom walk is performed to calculate the influence
score rh. Then we update ω using a batch gradient
descent method on the top-k influencer entities. To
derive the gradient of the loss function L, we first
remark that our random walk Equation 6 is similar
to context-sensitive PageRank (Haveliwala, 2002).
Using the linearity property (Fogaras et al., 2005),
</bodyText>
<equation confidence="0.970946333333333">
b
i,j = MW e e (5)
�(ei,ek)∈V ( i, k)
</equation>
<bodyText confidence="0.836525">
Influence Score Let rh be the influence score
vector of entities in Gh. We can estimate rh effi-
ciently using random walk models, similarly to the
Set sh :=
</bodyText>
<page confidence="0.964961">
102
</page>
<table confidence="0.999793875">
Total Tweets 500,551,041
Trending Hashtags 2,444
Test Hashtags 30
Test Tweets 352,394
Distinct Mentions 145,941
Test (Entity, Hashtag) pairs 6,965
Candidates per Hashtag (avg.) 50
Extended Candidates (avg.) 182
</table>
<tableCaption confidence="0.999895">
Table 1: Statistics of the dataset.
</tableCaption>
<bodyText confidence="0.947045222222222">
we can express r(e, h) as the linear function of in-
fluence scores obtained by initializing with the in-
dividual similarities fm, fc, and ft instead of fω.
The derivative thus can be written as:
∇L(f(e, h), r(e, h)) = α(rm(e, h) − fm(e, h))+
β(rc(e, h) − fc(e, h)) + γ(rt(e, h) − ft(e, h))
where rm(e, h), rc(e, h), rt(e, h) are the compo-
nents of the three vector solutions of Equation 6,
each having sh replaced by fm, fc, ft respectively.
Since both B and ˆfω are normalized such that
their column sums are equal to 1, Equation 6 is
convergent (Haveliwala, 2002). Also, as discussed
above, rh is a linear combination of factors that
are independent of ω, hence L is a convex func-
tion, and the batch gradient descent is also guaran-
teed to converge. In practice, we can utilize sev-
eral indexing techniques to significantly speed up
the similarity and influence scores calculation.
</bodyText>
<sectionHeader confidence="0.997506" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.972094">
6.1 Setup
</subsectionHeader>
<bodyText confidence="0.999929575757576">
Dataset There is no standard benchmark for our
problem, since available datasets on microblog an-
notation (such as the Microposts challenge (Basave
et al., 2014)) do not have global statistics, so we
cannot identify the trending hashtags. Therefore,
we created our own dataset. We used the Twitter
API to collect from the public stream a sample of
500, 551, 041 tweets from January to April 2014.
We removed hashtags that were adopted by less
than 500 users, having no letters, or having char-
acters repeated more than 4 times (e.g., ‘#oooom-
mgg’). We identified trending hashtags by comput-
ing the daily time series of hashtag tweet counts,
and removing those of which the time series’ vari-
ance score is less than 900. To identify the hashtag
burst time period T, we compute the outlier frac-
tion (Lehmann et al., 2012) for each hashtag h and
day t: pt(h) = m|(nb nb n) , where nt is the num-
ber of tweets containing h, nb is the median value
of nt over all points in a 2-month time window cen-
tered on t, and nmin = 10 is the threshold to filter
low activity hashtags. The hashtag is skipped if its
highest outlier fraction score is less than 15. Fi-
nally, we define the burst time period of a trending
hashtag as the time window of size w, centered at
day t0 with the highest pt0(h).
For the Wikipedia datasets we process the dump
from 3rd May 2014, so as to cover all events in the
Twitter dataset. We have developed Hedera (Tran
and Nguyen, 2014), a scalable tool for process-
ing the Wikipedia revision history dataset based on
Map-Reduce paradigm. In addition, we download
the Wikipedia page view dataset that stores how
many times a Wikipedia article was requested on
an hourly level. We process the dataset for the four
months of our study and use Hedera to accumulate
all view counts of redirects to the actual articles.
Sampling From the trending hashtags, we sam-
ple 30 distinct hashtags for evaluation. Since our
study focuses on trending hashtags that are ma-
pable to entities in Wikipedia, the sampling must
cover a sufficient number of “popular” topics that
are seen in Wikipedia, and at the same time cover
rare topics in the long tail. To do this, we apply
several heuristics in the sampling. First, we only
consider hashtags where the lexicon-based link-
ing (Section 3.1) results in at least 20 different
entities. Second, we randomly choose hashtags
to cover different types of topics (long-running
events, breaking events, endogenous hashtags). In-
stead of inspecting all hashtags in our corpus, we
follow Lehmann et al. (2012) and calculate the
fraction of tweets published before, during and af-
ter the peak. The hashtags are then clustered in
this 3-dimensional vector space. Each cluster sug-
gests a group of hashtags with a distinct seman-
tics (Lehmann et al., 2012). We then pick up hash-
tags randomly from each cluster, resulting in 200
hashtags in total. From this rough sample, three
inspectors carefully checked the tweets and chose
30 hashtags where the meanings and hashtag types
were certain to the knowledge of the inspectors.
Parameter Settings We initialize the similarity
weights to 13, the damping factor to τ = 0.85, and
the weight for the language model to A = 0.9. The
learning rate µ is empirically fixed to µ = 0.003.
</bodyText>
<page confidence="0.996392">
103
</page>
<table confidence="0.998488">
Tagme Wikiminer Meij Kauri M C T IPL
P@5 0.284 0.253 0.500 0.305 0.453 0.263 0.474 0.642
P@15 0.253 0.147 0.670 0.319 0.312 0.245 0.378 0.495
MAP 0.148 0.096 0.375 0.162 0.211 0.140 0.291 0.439
</table>
<tableCaption confidence="0.999121">
Table 2: Experimental results on the sampled trending hashtags.
</tableCaption>
<bodyText confidence="0.999802772727273">
Baseline We compare IPL with other entity an-
notation methods. Our first group of baselines in-
cludes entity linking systems in domains of gen-
eral text, Wikiminer (Milne and Witten, 2008),
and short text, Tagme (Ferragina and Scaiella,
2012). For each method, we use the default param-
eter settings, apply them for the individual tweets,
and take the average of the annotation confidence
scores as the prominence ranking function. The
second group of baselines includes systems specif-
ically designed for microblogs. For the content-
based methods, we compare against Meij et al.
(2012), which uses a supervised method to rank en-
tities with respect to tweets. We train the model us-
ing the same training data as in the original paper.
For the graph-based method, we compare against
KAURI (Shen et al., 2013), a method which uses
user interest propagation to optimize the entity
linking scores. To tune the parameters, we pick
up four hashtags from different clusters, randomly
sample 50 tweets for each, and manually annotate
the tweets. For all baselines, we obtained the im-
plementation from the authors. The exception is
Meij method, where we implemented ourselves,
but we clarified with the authors via emails on sev-
eral settings. In addition, we also compare three
variants of our method, using only local functions
for entity ranking (referred to as M, C, and T for
mention, context, and time, respectively).
Evaluation In total, there are 6,965 entity-
hashtag pairs returned by all systems. We employ
five volunteers to evaluate the pairs in the range
from 0 to 2, where 0 means the entity is noisy or
obviously unrelated, 2 means the entity is strongly
tied to the topic of the hashtag, and 1 means that
although the entity and hashtag might share some
common contexts, they are not involved in a di-
rect relationship (for instance, the entity is a too
general concept such as Ice hockey, as in the case
illustrated in Figure 2). The annotators were ad-
vised to use search engines, the Twitter search box
or Wikipedia archives whenever applicable to get
more background on the stories. Inter-annotator
agreement under Fleiss score is 0.625.
</bodyText>
<subsectionHeader confidence="0.991907">
6.2 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.999731585365854">
Table 2 shows the performance comparison of the
methods using the standard metrics for a ranking
system (precision at 5 and 15 and MAP at 15). In
general, all baselines perform worse than reported
in the literature, confirming the higher complexity
of the hashtag annotation task as compared to tra-
ditional tasks. Interestingly enough, using our lo-
cal similarities already produces better results than
Tagme and Wikiminer. The local model fm signif-
icantly outperforms both the baselines in all met-
rics. Combining the similarities improves the per-
formance even more significantly.2 Compared to
the baselines, IPL improves the performance by
17-28%. The time similarity achieves the high-
est result compared to other content-based mention
and context similarities. This supports our assump-
tion that lexical matching is not always the best
strategy to link entities in tweets. The time series-
based metric incurs lower cost than others, yet it
produces a considerably good performance. Con-
text similarity based on Wikipedia edits does not
yield much improvement. This can be explained
in two ways. First, information in Wikipedia is
largely biased to popular entities, it fails to cap-
ture many entities in the long tail. Second, lan-
guage models are dependent on direct word rep-
resentations, which are different between Twitter
and Wikipedia. This is another advantage of non-
content measures such as ft.
For the second group of baselines (Kauri and
Meij), we also observe the reduction in precision,
especially for Kauri. This is because the method
relies on the coherence of user interests within a
group of tweets to be able to perform well, which
does not hold in the context of hashtags. One as-
tonishing result is that Meij performs better than
IPL in terms of P@15. However, it performs worse
in terms of MAP and P@5, suggesting that most
of the correctly identified entities are ranked lower
in the list. This is reasonable, as Meij attempts to
optimize (with human supervision effort) the se-
</bodyText>
<footnote confidence="0.9688485">
2All significance tests are done against both Tagme and
Wikiminer, with a P-value &lt; 0.01.
</footnote>
<page confidence="0.994444">
104
</page>
<figure confidence="0.749943">
Tagme WM Meij Kauri M C T IPL
</figure>
<figureCaption confidence="0.9955675">
Figure 3: Performance of the methods for different
types of trending hashtags.
</figureCaption>
<figure confidence="0.989071">
0 10 20 30 40 50 60
burst time period window size w in days
</figure>
<figureCaption confidence="0.9762075">
Figure 4: IPL compared to other baselines on dif-
ferent sizes of the burst time window T.
</figureCaption>
<bodyText confidence="0.999984909090909">
mantic agreement between entities and informa-
tion found in the tweets, instead of ranking their
prominence as in our work. To investigate this
case further, we re-examined the hashtags and di-
vided them by their semantics, as to whether the
hashtags are spurious trends of memes inside so-
cial media (endogenous, e.g., “#stopasian2014”),
or whether they reflect external events (exogenous,
e.g., “#mh370”). The performance of the methods
in terms of MAP scores is shown in Figure 3. It can
be clearly seen that entity linking methods perform
well in the endogenous group, but then deteriorate
in the exogenous group. The explanation is that
for endogenous hashtags, the topical consonance
between tweets is very low, thus most of the as-
sessments become just verifying general concepts
(such as locations) In this case, topical annotation
is trumped by conceptual annotation. However,
whenever the hashtag evolves into a meaningful
topic, a deeper annotation method will produce a
significant improvement, as seen in Figure 3.
Finally, we study the impact of the burst time pe-
riod on the annotation quality. For this, we expand
the window size w (cf. Section 6.1) and examine
how different methods perform. The result is de-
picted in Figure 4. It is obvious that within the win-
dow of 2 months (where the hashtag time series is
constructed and a trending time is identified), our
method is stable and always outperforms the base-
lines by a large margin. Even when the trending
hashtag has been saturated, hence introduced more
noise, our method is still able to identify the promi-
nent entities with high quality.
</bodyText>
<sectionHeader confidence="0.990332" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.99998753125">
In this work, we address the new problem of
topically annotating a trending hashtag using
Wikipedia entities, which has many important ap-
plications in social media analysis. We study
Wikipedia temporal resources and find that using
efficient time series-based measures can comple-
ment content-based methods well in the domain
of Twitter. We propose use similarity measures
to model both the local mention-based, as well as
the global context- and time-based prominence of
entities. We propose a novel strategy of topical
annotation of texts using and influence maximiza-
tion approach and design an efficient learning algo-
rithm to automatically unify the similarities with-
out the need of human involvement. The experi-
ments show that our method outperforms signifi-
cantly the established baselines.
As future work, we aim to improve the effi-
ciency of our entire workflow, such that the anno-
tation can become an end-to-end service. We also
aim to improve the context similarity between en-
tities and the topic, for example by using a deeper
distributional semantics-based method, instead of
language models as in our current work. In addi-
tion, we plan to extend the annotation framework
to other types of trending topics, by including the
type of out-of-knowledge entities. Finally, we are
investigating how to apply more advanced influ-
ence maximization methods. We believe that in-
fluence maximization has a great potential in NLP
research, beyond the scope of annotation for mi-
croblogging topics.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99993575">
This work was funded by the European Commis-
sion in the FP7 project ForgetIT (600826) and the
ERC advanced grant ALEXANDRIA (339233),
and by the German Federal Ministry of Educa-
tion and Research for the project “Gute Arbeit”
(01UG1249C). We thank the reviewers for the
fruitful discussion and Claudia Niederee from L3S
for suggestions on improving Section 5.
</bodyText>
<figure confidence="0.99872708">
0.6
0.4
0.3
0.2
0.5
0.1
0
Endogenous
Exogenous
MAP
0.50
0.45
0.40
0.35
0.30
0.25
0.20
0.15
0.10
0.05
0.00
Kauri
Tagme
Wikiminer
IPL
</figure>
<page confidence="0.994696">
105
</page>
<sectionHeader confidence="0.995458" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99988715">
P. Bansal, R. Bansal, and V. Varma. 2015. Towards
deep semantic analysis of hashtags. In ECIR, pages
453–464.
A. E. Cano Basave, G. Rizzo, A. Varga, M. Rowe,
M. Stankovic, and A. Dadzie. 2014. Making sense
of microposts (#microposts2014) named entity ex-
traction &amp; linking challenge. In 4th Workshop on
Making Sense of Microposts.
T. Cassidy, H. Ji, L.-A. Ratinov, A. Zubiaga, and
H. Huang. 2012. Analysis and enhancement of wik-
ification for microblogs with context expansion. In
COLING, pages 441–456.
M. Ciglan and K. Nørv˚ag. 2010. WikiPop: personal-
ized event detection system based on Wikipedia page
view statistics. In CIKM, pages 1931–1932.
Y. Fang and M.-W. Chang. 2014. Entity linking on
microblogs with spatial and temporal signals. Trans.
of the Assoc. for Comp. Linguistics, 2:259–272.
P. Ferragina and U. Scaiella. 2012. Fast and accu-
rate annotation of short texts with Wikipedia pages.
IEEE Softw., 29(1):70–75.
D. Fogaras, B. R´acz, K. Csalog´any, and T. Sarl´os. 2005.
Towards scaling fully personalized PageRank: Al-
gorithms, lower bounds, and experiments. Internet
Mathematics, 2(3):333–358.
S. Guo, M.-W. Chang, and E. Kıcıman. 2013. To link
or not to link? A study on end-to-end tweet entity
linking. In NAACL-HLT, pages 1020–1030.
T. H. Haveliwala. 2002. Topic-sensitive PageRank. In
WWW, pages 517–526.
Brian Keegan, Darren Gergle, and Noshir Contrac-
tor. 2011. Hot off the wiki: Dynamics, practices,
and structures in wikipedia’s coverage of the tohoku
catastrophes. In WikiSym, pages 105–113.
D. Kempe, J. Kleinberg, and ´E. Tardos. 2003. Maxi-
mizing the spread of influence through a social net-
work. In KDD, pages 137–146.
T. Lappas, B. Arai, M. Platakis, D. Kotsakos, and
D. Gunopulos. 2009. On burstiness-aware search
for document sequences. In KDD, pages 477–486.
J. Lehmann, B. Gonc¸alves, J. J. Ramasco, and C. Cat-
tuto. 2012. Dynamical classes of collective attention
in Twitter. In WWW, pages 251–260.
X. Liu, Y. Li, H. Wu, M. Zhou, F. Wei, and Y. Lu. 2013.
Entity linking for tweets. In ACL, pages 1304–1311.
Q. Liu, B. Xiang, E. Chen, H. Xiong, F. Tang, and
J. X. Yu. 2014. Influence maximization over large-
scale social networks: A bounded linear approach.
In CIKM, pages 171–180.
E. Meij, W. Weerkamp, and M. de Rijke. 2012. Adding
semantics to microblog posts. In WSDM, pages 563–
572.
D. Milne and I. H. Witten. 2008. Learning to link with
Wikipedia. In CIKM, pages 509–518.
M. Naaman, H. Becker, and L. Gravano. 2011. Hip and
trendy: Characterizing emerging trends on Twitter.
JASIST, 62(5):902–918.
M. Osborne, S. Petrovic, R. McCreadie, C. Macdonald,
and I. Ounis. 2012. Bieber no more: First story
detection using Twitter and Wikipedia. In Workshop
on Time-aware Information Access.
O. Owoputi, B. O’Connor, C. Dyer, K. Gimpel,
N. Schneider, and N. A. Smith. 2013. Improved
part-of-speech tagging for online conversational text
with word clusters. In NAACL-HLT, pages 380–390.
K. Radinsky, E. Agichtein, E. Gabrilovich, and
S. Markovitch. 2011. A word at a time: Computing
word relatedness using temporal semantic analysis.
In WWW, pages 337–346.
L. Ratinov, D. Roth, D. Downey, and M. Anderson.
2011. Local and Global Algorithms for Disambigua-
tion to Wikipedia. In ACL, pages 1375–1384.
Alan Ritter, Sam Clark, Oren Etzioni, et al. 2011.
Named entity recognition in tweets: an experimen-
tal study. In EMNLP, pages 1524–1534.
W. Shen, J. Wang, P. Luo, and M. Wang. 2013. Link-
ing named entities in tweets with knowledge base via
user interest modeling. In WSDM, pages 68–76.
G. Tolomei, S. Orlando, D. Ceccarelli, and C. Lucch-
ese. 2013. Twitter anticipates bursts of requests
for Wikipedia articles. In Workshop on Data-driven
User Behavioral Modelling and Mining from Social
Media, pages 5–8.
T. Tran and T. Ngoc Nguyen. 2014. Hedera: Scal-
able indexing, exploring entities in Wikipedia revi-
sion history. In ISWC, pages 297–300.
T. Tran, M. Georgescu, X. Zhu, and N. Kanhabua.
2014. Analysing the duration of trending topics in
Twitter using Wikipedia. In Conf. on Web Science,
pages 251–252.
O. Tsur and A. Rappoport. 2012. What’s in a hashtag?:
Content based prediction of the spread of ideas in
microblogging communities. In WSDM, pages 643–
652.
K. Wang, C. Thrasher, and B.-J. P. Hsu. 2011. Web
scale NLP: a case study on URL word breaking. In
WWW, pages 357–366.
J. Yang and J. Leskovec. 2011. Patterns of temporal
variation in online media. In WSDM, pages 177–
186.
</reference>
<page confidence="0.997311">
106
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.760327">
<title confidence="0.999861">Semantic Annotation for Microblog Using Wikipedia Temporal Information</title>
<author confidence="0.99969">Tuan Tran Nam Khanh Tran Asmelash Teka Hadgu Robert J¨aschke</author>
<affiliation confidence="0.999195">L3S Research Center L3S Research Center L3S Research Center L3S Research Center</affiliation>
<address confidence="0.99327">Hannover, Germany Hannover, Germany Hannover, Germany Hannover, Germany</address>
<email confidence="0.935176">ttran@L3S.dentran@L3S.deteka@L3S.dejaeschke@L3S.de</email>
<abstract confidence="0.9826699">Trending topics in microblogs such as Twitter are valuable resources to understand social aspects of real-world events. To enable deep analyses of such trends, semantic annotation is an effective approach; yet the problem of annotating microblog trending topics is largely unexplored by the research community. In this work, we tackle the problem of mapping trending Twitter topics to entities from Wikipedia. We propose a novel model that complements traditional text-based approaches by rewarding entities that exhibit a high temporal correlation with topics during their burst time period. By exploiting temporal information from the Wikipedia edit history and page view logs, we have improved the annotation performance by 17-28%, as compared to the competitive baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Bansal</author>
<author>R Bansal</author>
<author>V Varma</author>
</authors>
<title>Towards deep semantic analysis of hashtags.</title>
<date>2015</date>
<booktitle>In ECIR,</booktitle>
<pages>453--464</pages>
<contexts>
<context position="6755" citStr="Bansal et al. (2015)" startWordPosition="1060" endWordPosition="1063"> tweets. In contrast, we take into account hashtags which reflect the topics discussed in tweets, and leverage external resources from Wikipedia (in particular, the edit history and page view logs) for semantic annotation. Analysis of Twitter Hashtags In an attempt to understand the user interest dynamics on Twitter, a rich body of work analyzes the temporal patterns of popular hashtags (Lehmann et al., 2012; Naaman et al., 2011; Tsur and Rappoport, 2012). Few works have paid attention to the semantics of hashtags, i.e., to the underlying topics conveyed in the corresponding tweets. Recently, Bansal et al. (2015) attempt to segment a hashtag and link each of its tokens to a Wikipedia page. However, the authors only aim to retrieve entities directly mentioned within a hashtag, which are very few in practice. The external information derived from the tweets is largely ignored. In contrast, we exploit both context information from the microblog and Wikipedia resources. Event Mining Using Wikipedia Recently some works exploit Wikipedia for detecting and analyzing events on Twitter (Osborne et al., 2012; Tolomei et al., 2013; Tran et al., 2014). However, most of the existing studies focus on the statistica</context>
</contexts>
<marker>Bansal, Bansal, Varma, 2015</marker>
<rawString>P. Bansal, R. Bansal, and V. Varma. 2015. Towards deep semantic analysis of hashtags. In ECIR, pages 453–464.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A E Cano Basave</author>
<author>G Rizzo</author>
<author>A Varga</author>
<author>M Rowe</author>
<author>M Stankovic</author>
<author>A Dadzie</author>
</authors>
<title>Making sense of microposts (#microposts2014) named entity extraction &amp; linking challenge.</title>
<date>2014</date>
<booktitle>In 4th Workshop on Making Sense of Microposts.</booktitle>
<contexts>
<context position="26748" citStr="Basave et al., 2014" startWordPosition="4474" endWordPosition="4477"> ˆfω are normalized such that their column sums are equal to 1, Equation 6 is convergent (Haveliwala, 2002). Also, as discussed above, rh is a linear combination of factors that are independent of ω, hence L is a convex function, and the batch gradient descent is also guaranteed to converge. In practice, we can utilize several indexing techniques to significantly speed up the similarity and influence scores calculation. 6 Experiments and Results 6.1 Setup Dataset There is no standard benchmark for our problem, since available datasets on microblog annotation (such as the Microposts challenge (Basave et al., 2014)) do not have global statistics, so we cannot identify the trending hashtags. Therefore, we created our own dataset. We used the Twitter API to collect from the public stream a sample of 500, 551, 041 tweets from January to April 2014. We removed hashtags that were adopted by less than 500 users, having no letters, or having characters repeated more than 4 times (e.g., ‘#oooommgg’). We identified trending hashtags by computing the daily time series of hashtag tweet counts, and removing those of which the time series’ variance score is less than 900. To identify the hashtag burst time period T,</context>
</contexts>
<marker>Basave, Rizzo, Varga, Rowe, Stankovic, Dadzie, 2014</marker>
<rawString>A. E. Cano Basave, G. Rizzo, A. Varga, M. Rowe, M. Stankovic, and A. Dadzie. 2014. Making sense of microposts (#microposts2014) named entity extraction &amp; linking challenge. In 4th Workshop on Making Sense of Microposts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Cassidy</author>
<author>H Ji</author>
<author>L-A Ratinov</author>
<author>A Zubiaga</author>
<author>H Huang</author>
</authors>
<title>Analysis and enhancement of wikification for microblogs with context expansion.</title>
<date>2012</date>
<booktitle>In COLING,</booktitle>
<pages>441--456</pages>
<contexts>
<context position="6008" citStr="Cassidy et al., 2012" startWordPosition="938" endWordPosition="941"> idea is generalizable to other social media sites that have a similar information spreading nature. • We conduct thorough experiments on a realworld dataset and show that our system can outperform competitive baselines by 17-28%. 2 Related Work Entity Linking in Microblogs The task of semantic annotation in microblogs has been recently tackled by different methods, which can be divided into two classes, i.e., content-based and graphbased methods. While the content-based methods (Meij et al., 2012; Guo et al., 2013; Fang and Chang, 2014) consider tweets independently, the graph-based methods (Cassidy et al., 2012; Liu et al., 2013) use all related tweets (e.g., posted by a user) together. However, most of them focus on entity mentions in tweets. In contrast, we take into account hashtags which reflect the topics discussed in tweets, and leverage external resources from Wikipedia (in particular, the edit history and page view logs) for semantic annotation. Analysis of Twitter Hashtags In an attempt to understand the user interest dynamics on Twitter, a rich body of work analyzes the temporal patterns of popular hashtags (Lehmann et al., 2012; Naaman et al., 2011; Tsur and Rappoport, 2012). Few works ha</context>
</contexts>
<marker>Cassidy, Ji, Ratinov, Zubiaga, Huang, 2012</marker>
<rawString>T. Cassidy, H. Ji, L.-A. Ratinov, A. Zubiaga, and H. Huang. 2012. Analysis and enhancement of wikification for microblogs with context expansion. In COLING, pages 441–456.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ciglan</author>
<author>K Nørv˚ag</author>
</authors>
<title>WikiPop: personalized event detection system based on Wikipedia page view statistics.</title>
<date>2010</date>
<booktitle>In CIKM,</booktitle>
<pages>1931--1932</pages>
<marker>Ciglan, Nørv˚ag, 2010</marker>
<rawString>M. Ciglan and K. Nørv˚ag. 2010. WikiPop: personalized event detection system based on Wikipedia page view statistics. In CIKM, pages 1931–1932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Fang</author>
<author>M-W Chang</author>
</authors>
<title>Entity linking on microblogs with spatial and temporal signals.</title>
<date>2014</date>
<journal>Trans. of the Assoc. for Comp. Linguistics,</journal>
<pages>2--259</pages>
<contexts>
<context position="5931" citStr="Fang and Chang, 2014" startWordPosition="928" endWordPosition="931">orithm based on influence maximization to automatically annotate hashtags. The idea is generalizable to other social media sites that have a similar information spreading nature. • We conduct thorough experiments on a realworld dataset and show that our system can outperform competitive baselines by 17-28%. 2 Related Work Entity Linking in Microblogs The task of semantic annotation in microblogs has been recently tackled by different methods, which can be divided into two classes, i.e., content-based and graphbased methods. While the content-based methods (Meij et al., 2012; Guo et al., 2013; Fang and Chang, 2014) consider tweets independently, the graph-based methods (Cassidy et al., 2012; Liu et al., 2013) use all related tweets (e.g., posted by a user) together. However, most of them focus on entity mentions in tweets. In contrast, we take into account hashtags which reflect the topics discussed in tweets, and leverage external resources from Wikipedia (in particular, the edit history and page view logs) for semantic annotation. Analysis of Twitter Hashtags In an attempt to understand the user interest dynamics on Twitter, a rich body of work analyzes the temporal patterns of popular hashtags (Lehma</context>
<context position="10014" citStr="Fang and Chang, 2014" startWordPosition="1618" endWordPosition="1621">each candidate and the hashtag, based on different types of contexts, which are derived from either side (Wikipedia or Twitter). Finally, we learn a unified ranking function for each (hashtag, entity) pair and choose the top-k entities with the highest scores. The ranking function is learned through an unsupervised model and needs no human-defined labels. 3.1 Entity Linking The most obvious resource to identify candidate entities for a hashtag is via its tweets. We follow common approaches that use a lexicon to match each textual phrase in a tweet to a potential entity set (Shen et al., 2013; Fang and Chang, 2014). Our lexicon is constructed from Wikipedia page titles, hyperlink anchors, redirects, and disambiguation pages, which are mapped to the corresponding entities. As for the tweet phrases, we extract all n-grams (n ≤ 5) from the input tweets within T. We apply the longest-match heuristic (Meij et al., 2012): We start with the longest n-grams and stop as soon as the entity set is found, otherwise we continue with the smaller constituent n-grams. Candidate Set Expansion While the lexiconbased linking works well for single tweets, applying it on the hashtag level has subtle implications. Processing</context>
<context position="11569" citStr="Fang and Chang, 2014" startWordPosition="1872" endWordPosition="1875">ities whose Wikipedia article is linked with the article of e by an outgoing or incoming link. 3.2 Measuring Entity–Hashtag Similarities To rank the entity by prominence, we measure the similarity between each candidate entity and the hashtag. We study three types of similarities: Mention Similarity This measure relies on the explicit mentions of entities in tweets. It assumes that entities directly linked from more prominent anchors are more relevant to the hashtag. It is estimated using both statistics from Wikipedia and tweet phrases, and turns out to be surprisingly effective in practice (Fang and Chang, 2014). Context Similarity For entities that are not directly linked to mentions (the mention similarity is zero) we exploit external resources instead. Their prominence is perceived by users via external sources, such as web pages linked from tweets, or entity home pages or Wikipedia pages. By exploiting the content of entities from these external sources, we can complement the explicit similarity metrics based on mentions. Temporal Similarity The two measures above rely on the textual representation and are degraded by the linguistic difference between the two platforms. To overcome this drawback,</context>
</contexts>
<marker>Fang, Chang, 2014</marker>
<rawString>Y. Fang and M.-W. Chang. 2014. Entity linking on microblogs with spatial and temporal signals. Trans. of the Assoc. for Comp. Linguistics, 2:259–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Ferragina</author>
<author>U Scaiella</author>
</authors>
<title>Fast and accurate annotation of short texts with Wikipedia pages.</title>
<date>2012</date>
<journal>IEEE Softw.,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="30333" citStr="Ferragina and Scaiella, 2012" startWordPosition="5100" endWordPosition="5103">ng factor to τ = 0.85, and the weight for the language model to A = 0.9. The learning rate µ is empirically fixed to µ = 0.003. 103 Tagme Wikiminer Meij Kauri M C T IPL P@5 0.284 0.253 0.500 0.305 0.453 0.263 0.474 0.642 P@15 0.253 0.147 0.670 0.319 0.312 0.245 0.378 0.495 MAP 0.148 0.096 0.375 0.162 0.211 0.140 0.291 0.439 Table 2: Experimental results on the sampled trending hashtags. Baseline We compare IPL with other entity annotation methods. Our first group of baselines includes entity linking systems in domains of general text, Wikiminer (Milne and Witten, 2008), and short text, Tagme (Ferragina and Scaiella, 2012). For each method, we use the default parameter settings, apply them for the individual tweets, and take the average of the annotation confidence scores as the prominence ranking function. The second group of baselines includes systems specifically designed for microblogs. For the contentbased methods, we compare against Meij et al. (2012), which uses a supervised method to rank entities with respect to tweets. We train the model using the same training data as in the original paper. For the graph-based method, we compare against KAURI (Shen et al., 2013), a method which uses user interest pro</context>
</contexts>
<marker>Ferragina, Scaiella, 2012</marker>
<rawString>P. Ferragina and U. Scaiella. 2012. Fast and accurate annotation of short texts with Wikipedia pages. IEEE Softw., 29(1):70–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Fogaras</author>
<author>B R´acz</author>
<author>K Csalog´any</author>
<author>T Sarl´os</author>
</authors>
<title>Towards scaling fully personalized PageRank: Algorithms, lower bounds, and experiments.</title>
<date>2005</date>
<journal>Internet Mathematics,</journal>
<volume>2</volume>
<issue>3</issue>
<marker>Fogaras, R´acz, Csalog´any, Sarl´os, 2005</marker>
<rawString>D. Fogaras, B. R´acz, K. Csalog´any, and T. Sarl´os. 2005. Towards scaling fully personalized PageRank: Algorithms, lower bounds, and experiments. Internet Mathematics, 2(3):333–358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Guo</author>
<author>M-W Chang</author>
<author>E Kıcıman</author>
</authors>
<title>To link or not to link? A study on end-to-end tweet entity linking.</title>
<date>2013</date>
<booktitle>In NAACL-HLT,</booktitle>
<pages>1020--1030</pages>
<contexts>
<context position="1635" citStr="Guo et al., 2013" startWordPosition="242" endWordPosition="245">page view logs, we have improved the annotation performance by 17-28%, as compared to the competitive baselines. 1 Introduction With the proliferation of microblogging and its wide influence on how information is shared and digested, the studying of microblog sites has gained interest in recent NLP research. Several approaches have been proposed to enable a deep understanding of information on Twitter. An emerging approach is to use semantic annotation techniques, for instance by mapping Twitter information snippets to canonical entities in a knowledge base or to Wikipedia (Meij et al., 2012; Guo et al., 2013), or by revisiting NLP tasks in the Twitter domain (Owoputi et al., 2013; Ritter et al., 2011). Much of the existing work focuses on annotating a single Twitter message (tweet). However, information in Twitter is rarely digested in isolation, but rather in a collective manner, with the adoption of special mechanisms such as hashtags. When put together, the unprecedentedly massive adoption of Hard to believe anyone can do worse than Russia in #Sochi. Brazil seems to be trying pretty hard though! sportingnews.com... #sochi Sochi 2014: Record number of positive tests --‐SkySports: q.gs/6nbAA #Soc</context>
<context position="5908" citStr="Guo et al., 2013" startWordPosition="924" endWordPosition="927">cient learning algorithm based on influence maximization to automatically annotate hashtags. The idea is generalizable to other social media sites that have a similar information spreading nature. • We conduct thorough experiments on a realworld dataset and show that our system can outperform competitive baselines by 17-28%. 2 Related Work Entity Linking in Microblogs The task of semantic annotation in microblogs has been recently tackled by different methods, which can be divided into two classes, i.e., content-based and graphbased methods. While the content-based methods (Meij et al., 2012; Guo et al., 2013; Fang and Chang, 2014) consider tweets independently, the graph-based methods (Cassidy et al., 2012; Liu et al., 2013) use all related tweets (e.g., posted by a user) together. However, most of them focus on entity mentions in tweets. In contrast, we take into account hashtags which reflect the topics discussed in tweets, and leverage external resources from Wikipedia (in particular, the edit history and page view logs) for semantic annotation. Analysis of Twitter Hashtags In an attempt to understand the user interest dynamics on Twitter, a rich body of work analyzes the temporal patterns of </context>
<context position="19062" citStr="Guo et al., 2013" startWordPosition="3144" endWordPosition="3147">)II (4) IITShII where dq(TSe) is the time series derived from TSe by shifting q time units, and II&apos;II is the L2 norm. It has been proven that Equation 4 has a closed-form solution for δ given fixed q, thus we can design an efficient gradient-based optimization algorithm to compute ft (Yang and Leskovec, 2011). 5 Entity Prominence Ranking 5.1 Ranking Framework To unify the individual similarities into one global metric (Equation 1), we need a guiding premise of what manifest the prominence of an entity to a hashtag. Such a premise can be instructed through manual assessment (Meij et al., 2012; Guo et al., 2013), but it requires human-labeled data and is biased from evaluator to evaluator. Other heuristics assume that entities close to the main topic of a text are also coherent to each other (Ratinov et al., 2011; Liu et al., 2013). Based on this, state-ofthe-art methods in traditional disambiguation estimate entity prominence by optimizing the overall coherence of the entities’ semantic relatedness. However, this coherence does not hold for topics in hashtags: Entities reported in a big topic such as the Olympics vary greatly with different subevents. They are not always coherent to each other, as t</context>
</contexts>
<marker>Guo, Chang, Kıcıman, 2013</marker>
<rawString>S. Guo, M.-W. Chang, and E. Kıcıman. 2013. To link or not to link? A study on end-to-end tweet entity linking. In NAACL-HLT, pages 1020–1030.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T H Haveliwala</author>
</authors>
<title>Topic-sensitive PageRank. In</title>
<date>2002</date>
<booktitle>WWW,</booktitle>
<pages>517--526</pages>
<contexts>
<context position="25173" citStr="Haveliwala, 2002" startWordPosition="4202" endWordPosition="4203">start with an initial guess for ω, and compute the similarities for the candidate entities. Here fm, fc, ft, and fω represent the similarity score vectors. We use matrix multiplication to calculate the similarities efficiently. In each iteration, we first normalize fω such that the entity scores sum up to 1. A random walk is performed to calculate the influence score rh. Then we update ω using a batch gradient descent method on the top-k influencer entities. To derive the gradient of the loss function L, we first remark that our random walk Equation 6 is similar to context-sensitive PageRank (Haveliwala, 2002). Using the linearity property (Fogaras et al., 2005), b i,j = MW e e (5) �(ei,ek)∈V ( i, k) Influence Score Let rh be the influence score vector of entities in Gh. We can estimate rh efficiently using random walk models, similarly to the Set sh := 102 Total Tweets 500,551,041 Trending Hashtags 2,444 Test Hashtags 30 Test Tweets 352,394 Distinct Mentions 145,941 Test (Entity, Hashtag) pairs 6,965 Candidates per Hashtag (avg.) 50 Extended Candidates (avg.) 182 Table 1: Statistics of the dataset. we can express r(e, h) as the linear function of influence scores obtained by initializing with the </context>
</contexts>
<marker>Haveliwala, 2002</marker>
<rawString>T. H. Haveliwala. 2002. Topic-sensitive PageRank. In WWW, pages 517–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Keegan</author>
<author>Darren Gergle</author>
<author>Noshir Contractor</author>
</authors>
<title>Hot off the wiki: Dynamics, practices, and structures in wikipedia’s coverage of the tohoku catastrophes. In WikiSym,</title>
<date>2011</date>
<pages>105--113</pages>
<contexts>
<context position="20296" citStr="Keegan et al., 2011" startWordPosition="3342" endWordPosition="3345">y dependent on the users’ diverse attention to each sub-event. This heterogeneity of hashtags calls for a different premise, abandoning the idea of coherence. Influence Maximization (IM) We propose a new approach to find entities for a hashtag. We use an observed behavioral pattern in creating Wikipedia pages for guiding our approach to entity prominence: Wikipedia articles of entities that are prominent for a topic are quickly created or updated,1 and subsequently enriched with links to related entities. This linking process signals the dynamics of editor attention and exposure to the event (Keegan et al., 2011). We argue that the process does not, or to a much lesser degree, happen to more marginal entities or to very general entities. As illustrated in Figure 2, the entities closer to the 2014 Olympics get more updates in the revisions of their Wikipedia articles, with subsequent links pointing to articles of more distant entities. The direction of the links influences the shifting attention of users (Keegan et al., 2011) as they follow the structure of articles in Wikipedia. We assume that, similar to Wikipedia, the entity prominence also influences how users are exposed and spread the hashtag on </context>
</contexts>
<marker>Keegan, Gergle, Contractor, 2011</marker>
<rawString>Brian Keegan, Darren Gergle, and Noshir Contractor. 2011. Hot off the wiki: Dynamics, practices, and structures in wikipedia’s coverage of the tohoku catastrophes. In WikiSym, pages 105–113.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kempe</author>
<author>J Kleinberg</author>
<author>´E Tardos</author>
</authors>
<title>Maximizing the spread of influence through a social network. In</title>
<date>2003</date>
<booktitle>KDD,</booktitle>
<pages>137--146</pages>
<contexts>
<context position="21734" citStr="Kempe et al., 2003" startWordPosition="3583" endWordPosition="3586">g background or providing context), driven by interests in different parts of the topic. Based on this assumption, 1Osborne et al. (2012) suggested a time lag of 3 hours. ft(e, h) = min q,δ 101 we propose to gauge the entity prominence as its potential in maximizing the information spreading within all entities present in the tweets of the hashtag. In other words, the problem of ranking the most prominent entities becomes identifying the set of entities that lead to the largest number of entities in the candidate set. This problem is known in social network research as influence maximization (Kempe et al., 2003). Iterative Influence-Prominence Learning (IPL) IM itself is an NP-hard problem (Kempe et al., 2003). Therefore, we propose an approximation framework, which can jointly learn the influence scores of the entity and the entity prominence together. The framework (called IPL) contains several iterations, each consisting of two steps: (1) Pick up a model and use it to compute the entity influence score. (2) Based on the influence scores, update the entity prominence. In the sequel we detail our learning framework. 5.2 Entity Graph Influence Graph To compute the entity influence scores, we first co</context>
</contexts>
<marker>Kempe, Kleinberg, Tardos, 2003</marker>
<rawString>D. Kempe, J. Kleinberg, and ´E. Tardos. 2003. Maximizing the spread of influence through a social network. In KDD, pages 137–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Lappas</author>
<author>B Arai</author>
<author>M Platakis</author>
<author>D Kotsakos</author>
<author>D Gunopulos</author>
</authors>
<title>On burstiness-aware search for document sequences.</title>
<date>2009</date>
<booktitle>In KDD,</booktitle>
<pages>477--486</pages>
<contexts>
<context position="8211" citStr="Lappas et al., 2009" startWordPosition="1309" endWordPosition="1312">r to an entity (denoted by e) as any object described by a Wikipedia article (ignoring disambiguation, lists, and redirect pages). The number of times an entity’s article has been requested is called the entity view count. The text content of the article is denoted by C(e). In this work, we choose to study hashtags at the daily level, i.e., from the timestamps of tweets we only consider their creation day. A hashtag is called trending at a time point (a day) if the number of tweets where it appears is significantly higher than that on other days. There are many ways to detect such trendings. (Lappas et al., 2009; Lehmann et al., 2012). Each trending hashtag has one or multiple burst time periods, surrounding the trend98 ing day, where the users’ interest in the underlying topic remains stronger than in other periods. We denote with T (h) (or T for short) one hashtag burst time period, and with DT (h) the set of tweets containing the hashtag h created during T. Task Definition Given a trending hashtag h and the burst time period T of h, identify the top-k most prominent entities to describe h during T. It is worth noting that not all trending hashtags are mapable to Wikipedia entities, as the coverage</context>
</contexts>
<marker>Lappas, Arai, Platakis, Kotsakos, Gunopulos, 2009</marker>
<rawString>T. Lappas, B. Arai, M. Platakis, D. Kotsakos, and D. Gunopulos. 2009. On burstiness-aware search for document sequences. In KDD, pages 477–486.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lehmann</author>
<author>B Gonc¸alves</author>
<author>J J Ramasco</author>
<author>C Cattuto</author>
</authors>
<title>Dynamical classes of collective attention in Twitter. In</title>
<date>2012</date>
<booktitle>WWW,</booktitle>
<pages>251--260</pages>
<marker>Lehmann, Gonc¸alves, Ramasco, Cattuto, 2012</marker>
<rawString>J. Lehmann, B. Gonc¸alves, J. J. Ramasco, and C. Cattuto. 2012. Dynamical classes of collective attention in Twitter. In WWW, pages 251–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Liu</author>
<author>Y Li</author>
<author>H Wu</author>
<author>M Zhou</author>
<author>F Wei</author>
<author>Y Lu</author>
</authors>
<title>Entity linking for tweets.</title>
<date>2013</date>
<booktitle>In ACL,</booktitle>
<pages>1304--1311</pages>
<contexts>
<context position="6027" citStr="Liu et al., 2013" startWordPosition="942" endWordPosition="945"> to other social media sites that have a similar information spreading nature. • We conduct thorough experiments on a realworld dataset and show that our system can outperform competitive baselines by 17-28%. 2 Related Work Entity Linking in Microblogs The task of semantic annotation in microblogs has been recently tackled by different methods, which can be divided into two classes, i.e., content-based and graphbased methods. While the content-based methods (Meij et al., 2012; Guo et al., 2013; Fang and Chang, 2014) consider tweets independently, the graph-based methods (Cassidy et al., 2012; Liu et al., 2013) use all related tweets (e.g., posted by a user) together. However, most of them focus on entity mentions in tweets. In contrast, we take into account hashtags which reflect the topics discussed in tweets, and leverage external resources from Wikipedia (in particular, the edit history and page view logs) for semantic annotation. Analysis of Twitter Hashtags In an attempt to understand the user interest dynamics on Twitter, a rich body of work analyzes the temporal patterns of popular hashtags (Lehmann et al., 2012; Naaman et al., 2011; Tsur and Rappoport, 2012). Few works have paid attention t</context>
<context position="19286" citStr="Liu et al., 2013" startWordPosition="3184" endWordPosition="3187">fficient gradient-based optimization algorithm to compute ft (Yang and Leskovec, 2011). 5 Entity Prominence Ranking 5.1 Ranking Framework To unify the individual similarities into one global metric (Equation 1), we need a guiding premise of what manifest the prominence of an entity to a hashtag. Such a premise can be instructed through manual assessment (Meij et al., 2012; Guo et al., 2013), but it requires human-labeled data and is biased from evaluator to evaluator. Other heuristics assume that entities close to the main topic of a text are also coherent to each other (Ratinov et al., 2011; Liu et al., 2013). Based on this, state-ofthe-art methods in traditional disambiguation estimate entity prominence by optimizing the overall coherence of the entities’ semantic relatedness. However, this coherence does not hold for topics in hashtags: Entities reported in a big topic such as the Olympics vary greatly with different subevents. They are not always coherent to each other, as they are largely dependent on the users’ diverse attention to each sub-event. This heterogeneity of hashtags calls for a different premise, abandoning the idea of coherence. Influence Maximization (IM) We propose a new approa</context>
</contexts>
<marker>Liu, Li, Wu, Zhou, Wei, Lu, 2013</marker>
<rawString>X. Liu, Y. Li, H. Wu, M. Zhou, F. Wei, and Y. Lu. 2013. Entity linking for tweets. In ACL, pages 1304–1311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Liu</author>
<author>B Xiang</author>
<author>E Chen</author>
<author>H Xiong</author>
<author>F Tang</author>
<author>J X Yu</author>
</authors>
<title>Influence maximization over largescale social networks: A bounded linear approach.</title>
<date>2014</date>
<booktitle>In CIKM,</booktitle>
<pages>171--180</pages>
<contexts>
<context position="23822" citStr="Liu et al. (2014)" startWordPosition="3950" endWordPosition="3953">he set of all entities in Wikipedia. The influence transition from ei to ej is defined as the normalized value: MW (ei, ej) Algorithm 1: Entity Influence-Prominence Learning Input : h, T, DT (h), B, k, learning rate µ, threshold e Output: W, top-k most prominent entities. Initialize: W := W(0) Calculate fm, fes, ft, fω := fω(0) using Eqs. 1, 2, 3, 4 while true do ˆfω := normalize fω ˆfω, calculate rh using Eq. 6 Sort rh, get the top-k entities E(h, k) if Ee∈E(h,k) L(f(e, h), r(e, h)) &lt; e then Stop end W := W − µ Ee∈E(h,k) ∇L(f(e, h), r(e, h)) end return W, E(h, k) baseline method suggested by Liu et al. (2014): rh := τBrh + (1 − τ)sh (6) where B is the influence transition matrix, sh are the initial influence scores that are based on the entity prominence model (Step 1 of IPL), and τ is the damping factor. 5.3 Learning Algorithm Now we detail the IPL algorithm. The objective is to learn the model ω = (α, β, γ) of the global function (Equation 1). The general idea is that we find an optimal ω such that the average error with respect to the top influencing entities is minimized �ω = arg min L(f(e, h), r(e, h)) E(h,k) where r(e, h) is the influence score of e and h, E(h, k) is the set of top-k entitie</context>
</contexts>
<marker>Liu, Xiang, Chen, Xiong, Tang, Yu, 2014</marker>
<rawString>Q. Liu, B. Xiang, E. Chen, H. Xiong, F. Tang, and J. X. Yu. 2014. Influence maximization over largescale social networks: A bounded linear approach. In CIKM, pages 171–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Meij</author>
<author>W Weerkamp</author>
<author>M de Rijke</author>
</authors>
<title>Adding semantics to microblog posts.</title>
<date>2012</date>
<booktitle>In WSDM,</booktitle>
<pages>563--572</pages>
<marker>Meij, Weerkamp, de Rijke, 2012</marker>
<rawString>E. Meij, W. Weerkamp, and M. de Rijke. 2012. Adding semantics to microblog posts. In WSDM, pages 563– 572.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Milne</author>
<author>I H Witten</author>
</authors>
<title>Learning to link with Wikipedia. In</title>
<date>2008</date>
<booktitle>CIKM,</booktitle>
<pages>509--518</pages>
<contexts>
<context position="23032" citStr="Milne and Witten (2008)" startWordPosition="3802" endWordPosition="3805">ruct a directed graph Gh = (Eh, Vh), where the nodes Eh C E consist of all candidate entities (cf. Section 3.1), and an edge (ei, ej) E Vh indicates that there is a link from ej’s Wikipedia article to ei’s. Note that edges of the influence graph are inversed in direction to links in Wikipedia, as such a link gives an “influence endorsement” from the destination entity to the source entity. Entity Relatedness In this work, we assume that an entity endorses more of its influence score to highly related entities than to lower related ones. We use a popular entity relatedness measure suggested by Milne and Witten (2008): 1 MW el, e, = — log(max(|I1|,|I2|)−log(|I1∩I2|))) ( ) log(|E|)−log(min(|I1|,|I2|)) where I1 and I2 are sets of entities having links to e1 and e2, respectively, and E is the set of all entities in Wikipedia. The influence transition from ei to ej is defined as the normalized value: MW (ei, ej) Algorithm 1: Entity Influence-Prominence Learning Input : h, T, DT (h), B, k, learning rate µ, threshold e Output: W, top-k most prominent entities. Initialize: W := W(0) Calculate fm, fes, ft, fω := fω(0) using Eqs. 1, 2, 3, 4 while true do ˆfω := normalize fω ˆfω, calculate rh using Eq. 6 Sort rh, ge</context>
<context position="30279" citStr="Milne and Witten, 2008" startWordPosition="5092" endWordPosition="5095">itialize the similarity weights to 13, the damping factor to τ = 0.85, and the weight for the language model to A = 0.9. The learning rate µ is empirically fixed to µ = 0.003. 103 Tagme Wikiminer Meij Kauri M C T IPL P@5 0.284 0.253 0.500 0.305 0.453 0.263 0.474 0.642 P@15 0.253 0.147 0.670 0.319 0.312 0.245 0.378 0.495 MAP 0.148 0.096 0.375 0.162 0.211 0.140 0.291 0.439 Table 2: Experimental results on the sampled trending hashtags. Baseline We compare IPL with other entity annotation methods. Our first group of baselines includes entity linking systems in domains of general text, Wikiminer (Milne and Witten, 2008), and short text, Tagme (Ferragina and Scaiella, 2012). For each method, we use the default parameter settings, apply them for the individual tweets, and take the average of the annotation confidence scores as the prominence ranking function. The second group of baselines includes systems specifically designed for microblogs. For the contentbased methods, we compare against Meij et al. (2012), which uses a supervised method to rank entities with respect to tweets. We train the model using the same training data as in the original paper. For the graph-based method, we compare against KAURI (She</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>D. Milne and I. H. Witten. 2008. Learning to link with Wikipedia. In CIKM, pages 509–518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Naaman</author>
<author>H Becker</author>
<author>L Gravano</author>
</authors>
<title>Hip and trendy: Characterizing emerging trends on Twitter.</title>
<date>2011</date>
<journal>JASIST,</journal>
<volume>62</volume>
<issue>5</issue>
<contexts>
<context position="6567" citStr="Naaman et al., 2011" startWordPosition="1031" endWordPosition="1034">independently, the graph-based methods (Cassidy et al., 2012; Liu et al., 2013) use all related tweets (e.g., posted by a user) together. However, most of them focus on entity mentions in tweets. In contrast, we take into account hashtags which reflect the topics discussed in tweets, and leverage external resources from Wikipedia (in particular, the edit history and page view logs) for semantic annotation. Analysis of Twitter Hashtags In an attempt to understand the user interest dynamics on Twitter, a rich body of work analyzes the temporal patterns of popular hashtags (Lehmann et al., 2012; Naaman et al., 2011; Tsur and Rappoport, 2012). Few works have paid attention to the semantics of hashtags, i.e., to the underlying topics conveyed in the corresponding tweets. Recently, Bansal et al. (2015) attempt to segment a hashtag and link each of its tokens to a Wikipedia page. However, the authors only aim to retrieve entities directly mentioned within a hashtag, which are very few in practice. The external information derived from the tweets is largely ignored. In contrast, we exploit both context information from the microblog and Wikipedia resources. Event Mining Using Wikipedia Recently some works ex</context>
</contexts>
<marker>Naaman, Becker, Gravano, 2011</marker>
<rawString>M. Naaman, H. Becker, and L. Gravano. 2011. Hip and trendy: Characterizing emerging trends on Twitter. JASIST, 62(5):902–918.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Osborne</author>
<author>S Petrovic</author>
<author>R McCreadie</author>
<author>C Macdonald</author>
<author>I Ounis</author>
</authors>
<title>Bieber no more: First story detection using Twitter and Wikipedia.</title>
<date>2012</date>
<booktitle>In Workshop on Time-aware Information Access.</booktitle>
<contexts>
<context position="7250" citStr="Osborne et al., 2012" startWordPosition="1139" endWordPosition="1142">he semantics of hashtags, i.e., to the underlying topics conveyed in the corresponding tweets. Recently, Bansal et al. (2015) attempt to segment a hashtag and link each of its tokens to a Wikipedia page. However, the authors only aim to retrieve entities directly mentioned within a hashtag, which are very few in practice. The external information derived from the tweets is largely ignored. In contrast, we exploit both context information from the microblog and Wikipedia resources. Event Mining Using Wikipedia Recently some works exploit Wikipedia for detecting and analyzing events on Twitter (Osborne et al., 2012; Tolomei et al., 2013; Tran et al., 2014). However, most of the existing studies focus on the statistical signals of Wikipedia (such as the edit or page view volumes). We are the first to combine the content of the Wikipedia edit history and the magnitude of page views to handle trending topics on Twitter. 3 Framework Preliminaries We refer to an entity (denoted by e) as any object described by a Wikipedia article (ignoring disambiguation, lists, and redirect pages). The number of times an entity’s article has been requested is called the entity view count. The text content of the article is </context>
<context position="21252" citStr="Osborne et al. (2012)" startWordPosition="3498" endWordPosition="3501">rection of the links influences the shifting attention of users (Keegan et al., 2011) as they follow the structure of articles in Wikipedia. We assume that, similar to Wikipedia, the entity prominence also influences how users are exposed and spread the hashtag on Twitter. In particular, the initial spreading of a trending hashtag involves more entities in the focus of the topic. Subsequent exposure and spreading of the hashtag then include other related entities (e.g., discussing background or providing context), driven by interests in different parts of the topic. Based on this assumption, 1Osborne et al. (2012) suggested a time lag of 3 hours. ft(e, h) = min q,δ 101 we propose to gauge the entity prominence as its potential in maximizing the information spreading within all entities present in the tweets of the hashtag. In other words, the problem of ranking the most prominent entities becomes identifying the set of entities that lead to the largest number of entities in the candidate set. This problem is known in social network research as influence maximization (Kempe et al., 2003). Iterative Influence-Prominence Learning (IPL) IM itself is an NP-hard problem (Kempe et al., 2003). Therefore, we pr</context>
</contexts>
<marker>Osborne, Petrovic, McCreadie, Macdonald, Ounis, 2012</marker>
<rawString>M. Osborne, S. Petrovic, R. McCreadie, C. Macdonald, and I. Ounis. 2012. Bieber no more: First story detection using Twitter and Wikipedia. In Workshop on Time-aware Information Access.</rawString>
</citation>
<citation valid="false">
<authors>
<author>O Owoputi</author>
<author>B O’Connor</author>
<author>C Dyer</author>
<author>K Gimpel</author>
</authors>
<marker>Owoputi, O’Connor, Dyer, Gimpel, </marker>
<rawString>O. Owoputi, B. O’Connor, C. Dyer, K. Gimpel,</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Schneider</author>
<author>N A Smith</author>
</authors>
<title>Improved part-of-speech tagging for online conversational text with word clusters.</title>
<date>2013</date>
<booktitle>In NAACL-HLT,</booktitle>
<pages>380--390</pages>
<marker>Schneider, Smith, 2013</marker>
<rawString>N. Schneider, and N. A. Smith. 2013. Improved part-of-speech tagging for online conversational text with word clusters. In NAACL-HLT, pages 380–390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Radinsky</author>
<author>E Agichtein</author>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>A word at a time: Computing word relatedness using temporal semantic analysis.</title>
<date>2011</date>
<booktitle>In WWW,</booktitle>
<pages>337--346</pages>
<contexts>
<context position="17228" citStr="Radinsky et al., 2011" startWordPosition="2860" endWordPosition="2863">11 h) (3) 4.1.2 Temporal Similarity The third similarity, ft, is computed using temporal signals from both sources – Twitter and Wikipedia. For the hashtags, we build the time series based on the volume of tweets adopting the hashtag h on each day in T: TSh = [n1, n2,... , n|T|]. Similarly for the entities, we build the time series of view counts for the entity e in T: TSe = [v1, v2,.. . , v|T|]. A time series similarity metric is then used to compute ft. Several metrics can be used, however most of them suffer from the time lag and scaling discrepancy, or incur expensive computational costs (Radinsky et al., 2011). In this work, we employ a simple yet Pˆ(w|e) Pˆ(w|h) 100 #sochi Sochi: Team USA takes 3 more medals, tops leaderboard |http://abc7.com http://adf.ly/dp8Hn #love #Sochi 2014: Russia&apos;s ice hockey dream ends as Vladimir Putin watches on ... ... #Sochi bear after #Mussia&apos;s hockey team eliminated with loss to #Finland I&apos;m still happy because Finland won. Is that too stupid..? #Hockey #Sochi Vladimir_Pu&gt;n Finland 2014_Winter_Olympics United_States Sochi Ice_hockey_at_the_2014_ Winter_Olympics Ice_hockey Russia_men’s_na&gt;onal _ice_ hockey_team Russia Figure 2: Excerpt of tweets about ice hockey resu</context>
</contexts>
<marker>Radinsky, Agichtein, Gabrilovich, Markovitch, 2011</marker>
<rawString>K. Radinsky, E. Agichtein, E. Gabrilovich, and S. Markovitch. 2011. A word at a time: Computing word relatedness using temporal semantic analysis. In WWW, pages 337–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ratinov</author>
<author>D Roth</author>
<author>D Downey</author>
<author>M Anderson</author>
</authors>
<title>Local and Global Algorithms for Disambiguation to Wikipedia. In</title>
<date>2011</date>
<booktitle>ACL,</booktitle>
<pages>1375--1384</pages>
<contexts>
<context position="19267" citStr="Ratinov et al., 2011" startWordPosition="3180" endWordPosition="3183">hus we can design an efficient gradient-based optimization algorithm to compute ft (Yang and Leskovec, 2011). 5 Entity Prominence Ranking 5.1 Ranking Framework To unify the individual similarities into one global metric (Equation 1), we need a guiding premise of what manifest the prominence of an entity to a hashtag. Such a premise can be instructed through manual assessment (Meij et al., 2012; Guo et al., 2013), but it requires human-labeled data and is biased from evaluator to evaluator. Other heuristics assume that entities close to the main topic of a text are also coherent to each other (Ratinov et al., 2011; Liu et al., 2013). Based on this, state-ofthe-art methods in traditional disambiguation estimate entity prominence by optimizing the overall coherence of the entities’ semantic relatedness. However, this coherence does not hold for topics in hashtags: Entities reported in a big topic such as the Olympics vary greatly with different subevents. They are not always coherent to each other, as they are largely dependent on the users’ diverse attention to each sub-event. This heterogeneity of hashtags calls for a different premise, abandoning the idea of coherence. Influence Maximization (IM) We p</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>L. Ratinov, D. Roth, D. Downey, and M. Anderson. 2011. Local and Global Algorithms for Disambiguation to Wikipedia. In ACL, pages 1375–1384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: an experimental study.</title>
<date>2011</date>
<booktitle>In EMNLP,</booktitle>
<pages>1524--1534</pages>
<contexts>
<context position="1729" citStr="Ritter et al., 2011" startWordPosition="260" endWordPosition="263">ompetitive baselines. 1 Introduction With the proliferation of microblogging and its wide influence on how information is shared and digested, the studying of microblog sites has gained interest in recent NLP research. Several approaches have been proposed to enable a deep understanding of information on Twitter. An emerging approach is to use semantic annotation techniques, for instance by mapping Twitter information snippets to canonical entities in a knowledge base or to Wikipedia (Meij et al., 2012; Guo et al., 2013), or by revisiting NLP tasks in the Twitter domain (Owoputi et al., 2013; Ritter et al., 2011). Much of the existing work focuses on annotating a single Twitter message (tweet). However, information in Twitter is rarely digested in isolation, but rather in a collective manner, with the adoption of special mechanisms such as hashtags. When put together, the unprecedentedly massive adoption of Hard to believe anyone can do worse than Russia in #Sochi. Brazil seems to be trying pretty hard though! sportingnews.com... #sochi Sochi 2014: Record number of positive tests --‐SkySports: q.gs/6nbAA #Sochi Sea Port. What a beautiful site! #Russia 2014_Winter_Olympics Port_of_Sochi Figure 1: Examp</context>
</contexts>
<marker>Ritter, Clark, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Oren Etzioni, et al. 2011. Named entity recognition in tweets: an experimental study. In EMNLP, pages 1524–1534.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Shen</author>
<author>J Wang</author>
<author>P Luo</author>
<author>M Wang</author>
</authors>
<title>Linking named entities in tweets with knowledge base via user interest modeling.</title>
<date>2013</date>
<booktitle>In WSDM,</booktitle>
<pages>68--76</pages>
<contexts>
<context position="9991" citStr="Shen et al., 2013" startWordPosition="1614" endWordPosition="1617">milarities between each candidate and the hashtag, based on different types of contexts, which are derived from either side (Wikipedia or Twitter). Finally, we learn a unified ranking function for each (hashtag, entity) pair and choose the top-k entities with the highest scores. The ranking function is learned through an unsupervised model and needs no human-defined labels. 3.1 Entity Linking The most obvious resource to identify candidate entities for a hashtag is via its tweets. We follow common approaches that use a lexicon to match each textual phrase in a tweet to a potential entity set (Shen et al., 2013; Fang and Chang, 2014). Our lexicon is constructed from Wikipedia page titles, hyperlink anchors, redirects, and disambiguation pages, which are mapped to the corresponding entities. As for the tweet phrases, we extract all n-grams (n ≤ 5) from the input tweets within T. We apply the longest-match heuristic (Meij et al., 2012): We start with the longest n-grams and stop as soon as the entity set is found, otherwise we continue with the smaller constituent n-grams. Candidate Set Expansion While the lexiconbased linking works well for single tweets, applying it on the hashtag level has subtle i</context>
<context position="30894" citStr="Shen et al., 2013" startWordPosition="5194" endWordPosition="5197">08), and short text, Tagme (Ferragina and Scaiella, 2012). For each method, we use the default parameter settings, apply them for the individual tweets, and take the average of the annotation confidence scores as the prominence ranking function. The second group of baselines includes systems specifically designed for microblogs. For the contentbased methods, we compare against Meij et al. (2012), which uses a supervised method to rank entities with respect to tweets. We train the model using the same training data as in the original paper. For the graph-based method, we compare against KAURI (Shen et al., 2013), a method which uses user interest propagation to optimize the entity linking scores. To tune the parameters, we pick up four hashtags from different clusters, randomly sample 50 tweets for each, and manually annotate the tweets. For all baselines, we obtained the implementation from the authors. The exception is Meij method, where we implemented ourselves, but we clarified with the authors via emails on several settings. In addition, we also compare three variants of our method, using only local functions for entity ranking (referred to as M, C, and T for mention, context, and time, respecti</context>
</contexts>
<marker>Shen, Wang, Luo, Wang, 2013</marker>
<rawString>W. Shen, J. Wang, P. Luo, and M. Wang. 2013. Linking named entities in tweets with knowledge base via user interest modeling. In WSDM, pages 68–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Tolomei</author>
<author>S Orlando</author>
<author>D Ceccarelli</author>
<author>C Lucchese</author>
</authors>
<title>Twitter anticipates bursts of requests for Wikipedia articles.</title>
<date>2013</date>
<booktitle>In Workshop on Data-driven User Behavioral Modelling and Mining from Social Media,</booktitle>
<pages>5--8</pages>
<contexts>
<context position="7272" citStr="Tolomei et al., 2013" startWordPosition="1143" endWordPosition="1146">gs, i.e., to the underlying topics conveyed in the corresponding tweets. Recently, Bansal et al. (2015) attempt to segment a hashtag and link each of its tokens to a Wikipedia page. However, the authors only aim to retrieve entities directly mentioned within a hashtag, which are very few in practice. The external information derived from the tweets is largely ignored. In contrast, we exploit both context information from the microblog and Wikipedia resources. Event Mining Using Wikipedia Recently some works exploit Wikipedia for detecting and analyzing events on Twitter (Osborne et al., 2012; Tolomei et al., 2013; Tran et al., 2014). However, most of the existing studies focus on the statistical signals of Wikipedia (such as the edit or page view volumes). We are the first to combine the content of the Wikipedia edit history and the magnitude of page views to handle trending topics on Twitter. 3 Framework Preliminaries We refer to an entity (denoted by e) as any object described by a Wikipedia article (ignoring disambiguation, lists, and redirect pages). The number of times an entity’s article has been requested is called the entity view count. The text content of the article is denoted by C(e). In th</context>
</contexts>
<marker>Tolomei, Orlando, Ceccarelli, Lucchese, 2013</marker>
<rawString>G. Tolomei, S. Orlando, D. Ceccarelli, and C. Lucchese. 2013. Twitter anticipates bursts of requests for Wikipedia articles. In Workshop on Data-driven User Behavioral Modelling and Mining from Social Media, pages 5–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Tran</author>
<author>T Ngoc Nguyen</author>
</authors>
<title>Hedera: Scalable indexing, exploring entities in Wikipedia revision history. In</title>
<date>2014</date>
<booktitle>ISWC,</booktitle>
<pages>297--300</pages>
<contexts>
<context position="28031" citStr="Tran and Nguyen, 2014" startWordPosition="4714" endWordPosition="4717">ach hashtag h and day t: pt(h) = m|(nb nb n) , where nt is the number of tweets containing h, nb is the median value of nt over all points in a 2-month time window centered on t, and nmin = 10 is the threshold to filter low activity hashtags. The hashtag is skipped if its highest outlier fraction score is less than 15. Finally, we define the burst time period of a trending hashtag as the time window of size w, centered at day t0 with the highest pt0(h). For the Wikipedia datasets we process the dump from 3rd May 2014, so as to cover all events in the Twitter dataset. We have developed Hedera (Tran and Nguyen, 2014), a scalable tool for processing the Wikipedia revision history dataset based on Map-Reduce paradigm. In addition, we download the Wikipedia page view dataset that stores how many times a Wikipedia article was requested on an hourly level. We process the dataset for the four months of our study and use Hedera to accumulate all view counts of redirects to the actual articles. Sampling From the trending hashtags, we sample 30 distinct hashtags for evaluation. Since our study focuses on trending hashtags that are mapable to entities in Wikipedia, the sampling must cover a sufficient number of “po</context>
</contexts>
<marker>Tran, Nguyen, 2014</marker>
<rawString>T. Tran and T. Ngoc Nguyen. 2014. Hedera: Scalable indexing, exploring entities in Wikipedia revision history. In ISWC, pages 297–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Tran</author>
<author>M Georgescu</author>
<author>X Zhu</author>
<author>N Kanhabua</author>
</authors>
<title>Analysing the duration of trending topics in Twitter using Wikipedia. In Conf. on Web Science,</title>
<date>2014</date>
<pages>251--252</pages>
<contexts>
<context position="7292" citStr="Tran et al., 2014" startWordPosition="1147" endWordPosition="1150">lying topics conveyed in the corresponding tweets. Recently, Bansal et al. (2015) attempt to segment a hashtag and link each of its tokens to a Wikipedia page. However, the authors only aim to retrieve entities directly mentioned within a hashtag, which are very few in practice. The external information derived from the tweets is largely ignored. In contrast, we exploit both context information from the microblog and Wikipedia resources. Event Mining Using Wikipedia Recently some works exploit Wikipedia for detecting and analyzing events on Twitter (Osborne et al., 2012; Tolomei et al., 2013; Tran et al., 2014). However, most of the existing studies focus on the statistical signals of Wikipedia (such as the edit or page view volumes). We are the first to combine the content of the Wikipedia edit history and the magnitude of page views to handle trending topics on Twitter. 3 Framework Preliminaries We refer to an entity (denoted by e) as any object described by a Wikipedia article (ignoring disambiguation, lists, and redirect pages). The number of times an entity’s article has been requested is called the entity view count. The text content of the article is denoted by C(e). In this work, we choose t</context>
</contexts>
<marker>Tran, Georgescu, Zhu, Kanhabua, 2014</marker>
<rawString>T. Tran, M. Georgescu, X. Zhu, and N. Kanhabua. 2014. Analysing the duration of trending topics in Twitter using Wikipedia. In Conf. on Web Science, pages 251–252.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Tsur</author>
<author>A Rappoport</author>
</authors>
<title>What’s in a hashtag?: Content based prediction of the spread of ideas in microblogging communities.</title>
<date>2012</date>
<booktitle>In WSDM,</booktitle>
<pages>643--652</pages>
<contexts>
<context position="6594" citStr="Tsur and Rappoport, 2012" startWordPosition="1035" endWordPosition="1038">aph-based methods (Cassidy et al., 2012; Liu et al., 2013) use all related tweets (e.g., posted by a user) together. However, most of them focus on entity mentions in tweets. In contrast, we take into account hashtags which reflect the topics discussed in tweets, and leverage external resources from Wikipedia (in particular, the edit history and page view logs) for semantic annotation. Analysis of Twitter Hashtags In an attempt to understand the user interest dynamics on Twitter, a rich body of work analyzes the temporal patterns of popular hashtags (Lehmann et al., 2012; Naaman et al., 2011; Tsur and Rappoport, 2012). Few works have paid attention to the semantics of hashtags, i.e., to the underlying topics conveyed in the corresponding tweets. Recently, Bansal et al. (2015) attempt to segment a hashtag and link each of its tokens to a Wikipedia page. However, the authors only aim to retrieve entities directly mentioned within a hashtag, which are very few in practice. The external information derived from the tweets is largely ignored. In contrast, we exploit both context information from the microblog and Wikipedia resources. Event Mining Using Wikipedia Recently some works exploit Wikipedia for detecti</context>
</contexts>
<marker>Tsur, Rappoport, 2012</marker>
<rawString>O. Tsur and A. Rappoport. 2012. What’s in a hashtag?: Content based prediction of the spread of ideas in microblogging communities. In WSDM, pages 643– 652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Wang</author>
<author>C Thrasher</author>
<author>B-J P Hsu</author>
</authors>
<title>Web scale NLP: a case study on URL word breaking.</title>
<date>2011</date>
<booktitle>In WWW,</booktitle>
<pages>357--366</pages>
<contexts>
<context position="14598" citStr="Wang et al. (2011)" startWordPosition="2393" endWordPosition="2396">ink priors of the entity e over all mentions in all tweets with the hashtag h: I: fm(e, h) = (LP (e|m) · q(m)) (2) m where q(m) is the frequency of the mention m over all mentions of e in all tweets of h. 4.1.1 Context Similarity To compute fc, we first construct the contexts for hashtags and entities. The context of a hashtag is built by extracting all words from its tweets. We tokenize and parse the tweets’ part-of-speech tags (Owoputi et al., 2013), and remove words of Twitter-specific tags (e.g., @-mentions, URLs, emoticons, etc.). Hashtags are normalized using the word breaking method by Wang et al. (2011). The textual context of an entity is extracted from its Wikipedia article. One subtle aspect is that the articles are not created at once, but are incrementally updated over time in accordance with changing information about entities. Texts added in the same time period of a trending hashtag contribute more to the context similarity between the entity and the hashtag. Based on this observation, we use the Wikipedia revision history – an archive of all revisions of Wikipedia articles – to calculate the entity context. We collect the revisions of articles during the time period T, plus one day </context>
</contexts>
<marker>Wang, Thrasher, Hsu, 2011</marker>
<rawString>K. Wang, C. Thrasher, and B.-J. P. Hsu. 2011. Web scale NLP: a case study on URL word breaking. In WWW, pages 357–366.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Yang</author>
<author>J Leskovec</author>
</authors>
<title>Patterns of temporal variation in online media.</title>
<date>2011</date>
<booktitle>In WSDM,</booktitle>
<pages>177--186</pages>
<contexts>
<context position="18289" citStr="Yang and Leskovec, 2011" startWordPosition="3013" endWordPosition="3016">ted_States Sochi Ice_hockey_at_the_2014_ Winter_Olympics Ice_hockey Russia_men’s_na&gt;onal _ice_ hockey_team Russia Figure 2: Excerpt of tweets about ice hockey results in the 2014 Winter Olympics (left), and the observed linking process between time-aligned revisions of candidate Wikipedia entities (right). Links come more from prominent entities to marginal ones to provide background, or more context for the topics. Thus, starting from prominent entities, we can reach more entities in the graph of candidate entities effective metric that is agnostic to the scaling and time lag of time series (Yang and Leskovec, 2011). It measures the distance between two time series by finding optimal shifting and scaling parameters to match the shape of two time series: IITSh − δdq(TSe)II (4) IITShII where dq(TSe) is the time series derived from TSe by shifting q time units, and II&apos;II is the L2 norm. It has been proven that Equation 4 has a closed-form solution for δ given fixed q, thus we can design an efficient gradient-based optimization algorithm to compute ft (Yang and Leskovec, 2011). 5 Entity Prominence Ranking 5.1 Ranking Framework To unify the individual similarities into one global metric (Equation 1), we need </context>
</contexts>
<marker>Yang, Leskovec, 2011</marker>
<rawString>J. Yang and J. Leskovec. 2011. Patterns of temporal variation in online media. In WSDM, pages 177– 186.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>