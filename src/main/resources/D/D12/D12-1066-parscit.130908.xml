<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.99836">
Generalizing Sub-sentential Paraphrase Acquisition
across Original Signal Type of Text Pairs
</title>
<author confidence="0.84828">
Aur´elien Max Houda Bouamor Anne Vilnat
</author>
<affiliation confidence="0.627434">
LIMSI-CNRS &amp; Univ. Paris Sud
Orsay, France
</affiliation>
<email confidence="0.996868">
firstname.lastname@limsi.fr
</email>
<sectionHeader confidence="0.998584" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998655">
This paper describes a study on the impact of
the original signal (text, speech, visual scene,
event) of a text pair on the task of both man-
ual and automatic sub-sentential paraphrase
acquisition. A corpus of 2,500 annotated sen-
tences in English and French is described, and
performance on this corpus is reported for
an efficient system combination exploiting a
large set of features for paraphrase recogni-
tion. A detailed quantified typology of sub-
sentential paraphrases found in our corpus
types is given.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999965674418605">
Sub-sentential paraphrases can be acquired from text
pairs expressing the same meaning (Madnani and
Dorr, 2010). If the semantic similarity of a text
pair has a direct impact on the quality of the ac-
quired paraphrases, it has, to our knowledge, never
been shown what impact the type of original sig-
nal has on paraphrase acquisition. In this work,
we consider four types of corpora, which we think
are representative of the main types of original
semantic signals: text pairs (roughly, sentences)
originating a) from independent translations of a
text (TEXT), b) from independent translations of a
speech (SPEECH), c) from independent descriptions
of a visual scene (SCENE), and d) from independent
descriptions of some event (EVENT). We will report
the results of experiments on sub-sentential para-
phrase acquisition on all these corpus types in two
languages, English and French, and provide some
answers to the following questions: What types of
paraphrases can be found by human annotators, with
what confidence and in which quantities? How well
can representative paraphrase acquisition systems
perform on each corpus type, and how performance
can be improved through combination? On what
corpus types can performance be improved by using
training material from other corpus types? Our ex-
perimental results will provide several indications of
the differences and complementarities of the corpus
types under study, and will notably show that perfor-
mance on the most readily available corpus type can
be improved by using training data from the set of
all other corpus types.
We will first describe the building procedures
and characteristics of our corpora (section 2), and
then describe our experimental settings for evalu-
ating paraphrase acquisition (section 3.1). Our ex-
periments will first consist of the description (sec-
tion 3.2) and evaluation (section 3.3) of a system
combination on each corpus type and then of our
system provided with additional training data from
the other corpus types (section 3.4). We will finally
briefly review related work (section 4) and discuss
our main findings and future work (section 5).
</bodyText>
<sectionHeader confidence="0.66653" genericHeader="method">
2 Collection of sentence pair corpora
</sectionHeader>
<bodyText confidence="0.9999515">
In this study, we will focus on paraphrase acquisition
from related sentence pairs characteristic of 4 corpus
types, which correspond to different original signal
types of text pairs illustrated by the word alignment
matrices on Figure 1. A corpus for each type has
been collected for 2 languages, English and French,
and comprises 625 sentence pairs per language. We
now briefly describe how each corpus was built.
</bodyText>
<page confidence="0.964044">
721
</page>
<note confidence="0.9688695">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 721–731, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.996933263157895">
It
is
anticipated
that
the
annual
total
foreign
trade
volume
will
exceed
US$9
billion
.
He
uses
those
machines
to
remind
the
living
of
his
face
.
a
boy
rides
a
bike
on
a
dirt
road
.
It
is
estimated
that
the
total
annual
volume
of
import
and
export
will
exceed
9
billion
US
dollars
So
he
uses
the
photo
booths
to
remind
people
what
he
looks
like
a
boy
is
riding
on
a
bicycle
fast
</figure>
<figureCaption confidence="0.99315275">
Figure 1: Example reference alignment matrices for
(from top to bottom) TEXT, SPEECH, SCENE and
EVENT. Sure alignments appear in green or gray (identi-
ties) and possible alignments in yellow.
</figureCaption>
<bodyText confidence="0.942424372093023">
TEXT For English, we used the MTC corpus1 (de-
scribed in (Cohn et al., 2008)) consisting of sets
of news article translations from Chinese, and for
French the CESTA corpus2 consisting of sets of
news article translations from English. For each
sentence cluster, we selected sentence pairs with
minimal edit distance above an empirically-selected
threshold, covering all clusters first and then select-
ing from already used clusters to reach the target
number of sentence pairs.
e.g. It is estimated that the total annual volume of import
and export will exceed 9 billion US dollars. H It is an-
ticipated that the annual total foreign trade volume will
exceed US$9 billion.
SPEECH For English, we used two freely avail-
able subtitle files3 of the French movies Le Fabuleux
Destin d’Am´elie Poulain and Les Choristes, and for
French we used two subtitle files from the Desperate
Housewives TV series. We first aligned each paral-
lel corpus using the algorithm described in (Tiede-
mann, 2007), based on time frames and developed
for bilingual subtitles, we then filtered out sentence
pairs below a minimal edit distance threshold, and
manually removed obvious errors made by the algo-
rithm.
e.g. So he uses the photo booths to remind people what
he looks like. H He uses those machines to remind the
living of his face.
SCENE We used the Multiple Video Description
Corpus (Chen and Dolan, 2011) obtained from mul-
tiple descriptions of short videos. Similarly to what
we did for TEXT, we selected sentence pairs from
clusters by minimal edit distance above a threshold.
An important fact is that for English we were able
to use what is described as “verified” descriptions.
There were, however, far fewer descriptions avail-
able for French, and none had the “verified” status.
We decided to use this corpus nonetheless, but with
the knowledge that this source for French is of a sub-
stantially lower quality (this corpus type will there-
fore appear as “(SCENE)” in all tables to reflect this).
e.g. a boy is riding on a bicycle fast. H a boy rides a bike
on a dirt road.
</bodyText>
<footnote confidence="0.99992475">
1http://www.ldc.upenn.edu/Catalog/
CatalogEntry.jsp?catalogId=LDC2002T01
2http://www.elda.org/article125.html
3http://www.opensubtitles.org
</footnote>
<figure confidence="0.992926352941176">
Pigeons
have
numerical
abilities
just
like
primates
Pigeons
have
an
understanding
of
numbers
on
par
with
primates
</figure>
<page confidence="0.689734">
722
</page>
<table confidence="0.76713505">
Corpus statistics
500 sentence pairs
# tokens # tokens per sent.
Annotator agreements
50 sentence pairs
sure para. possible para.
Tokens in paraphrase statistics
not considering identity paraphrases
sure para. possible para.
% tokens #tokens % tokens #tokens
ENGLISH
TEXT 21,473 21.0 66.1 20.4 18.6 4004 12.3 2651
SPEECH 11,049 10.5 79.1 10.9 17.5 1942 31.6 3500
SCENE 7,783 7.5 80.5 35.2 10.9 851 14.0 1094
EVENT 8,609 8.0 65.3 20.5 17.5 1506 14.5 1251
FRENCH
TEXT 24,641 24.0 64.6 16.6 29.2 7218 6.2 1527
SPEECH 11,850 11.5 82.7 20.8 22.5 2667 16.7 1981
(SCENE) 7,012 6.5 42.8 9.3 3.9 275 9.4 664
EVENT 9,121 9.1 67.8 3.8 19.6 1793 9.6 876
</table>
<tableCaption confidence="0.982597">
Table 1: Description of all corpora and paraphrase reference sets for English (top) and French (bottom). Note that
SCENE for French appears within parentheses as we do not consider it of the same quality as the other corpora.
</tableCaption>
<bodyText confidence="0.9978315">
EVENT We used titles of news article clusters
from the Google News4 news aggregation service.
We further refined the clustering algorithm by filter-
ing out article pairs whose publication dates differed
from more than one day. We repeated the same se-
lection procedure as for TEXT and SCENE to have
a maximal cluster coverage and select more similar
pairs first.
</bodyText>
<construct confidence="0.532835333333333">
e.g. Pigeons Have an Understanding of Numbers on Par
With Primates H Pigeons Have Numerical Abilities Just
Like Primates
</construct>
<bodyText confidence="0.995376764705882">
Table 1 provides various statistics for these cor-
pora. The first observation is that TEXT contains sig-
nificantly larger sentences than the other types, more
than twice as long as those of SPEECH. Annotation
was performed following the guidelines proposed by
Cohn et al. (2008)5 using the YAWAT tool (Germann,
2008), except that alignments where not initially ob-
tained automatically so as not to bias our annota-
tors’ work (there were two annotators per language).
The main guidelines that they had to follow were
that sure and possible paraphrases must be distin-
guished, smaller alignments were to be prefered but
any-to-any alignments may be used, and sentences
should be aligned as much as possible. Henceforth,
we will only consider for all reported statistics and
experiments those paraphrases that are not identity
pairs (e.g. (a nice day H a nice day)), as they are
</bodyText>
<footnote confidence="0.976274">
4http://news.google.com
5See http://staffwww.dcs.shef.ac.uk/
people/T.Cohn/paraphrase_guidelines.pdf
</footnote>
<bodyText confidence="0.99521924137931">
considered trivial as far as acquisition is concerned.
Table 1 also reports inter-annotator agreement6
values computed on sets of 50 sentence pairs. We
find that acceptable values are obtained for sure
paraphrases, but that low values are obtained for
possible paraphrases. This was somehow expected,
given the many possible interpretations of possible
paraphrases, but was not a problem for our experi-
ments: as we will describe in section 3.1, the evalua-
tion metrics we use will not count them as expected
solutions, but will simply not count them as false
when proposed as candidates.
Table 1 finally shows proportions and absolute
numbers of paraphrases of each type for all corpora.
We find that there are approximately the same to-
tal number of paraphrases for English (16,799) and
French (17,001), but that English corpora collec-
tively have an equivalent number of sure and pos-
sible paraphrases (8,303 vs. 8,496) and French have
more sure paraphrases (11,953 vs. 5,048). This may
be explained by the fact that our annotators worked
independently and that the corpora used have dif-
ferences by nature, as our experiments will show.
Other salient results include the fact that TEXT con-
tains more sure paraphrases in number than the other
corpora, that SPEECH contains relatively more pos-
sible paraphrases than the other corpora, and that
SCENE has significantly fewer paraphrases, both in
proportion and number. In Figure 2 various mea-
</bodyText>
<footnote confidence="0.9927615">
6For each paraphrase type, we used the average of recall
values obtained for each annotator set as the reference .
</footnote>
<page confidence="0.995438">
723
</page>
<table confidence="0.923262090909091">
synonymy typography tense inclusion pragmatics syntax morphology number
ENGLISH
TEXT 51.2 7.6 5.1 12.1 0.6 4.4 12.1 6.4
SPEECH 39.8 25.6 3.5 12.3 1.7 3.5 3.5 9.7
SCENE 50.0 1.3 13.5 21.6 0.0 1.3 5.4 6.7
EVENT 36.9 15.0 8.2 19.1 1.3 6.8 6.8 5.4
FRENCH
TEXT 46.9 9.0 8.7 2.1 3.6 6.6 3.0 19.8
SPEECH 45.5 14.2 8.0 8.0 2.6 11.6 3.5 6.2
(SCENE) 46.4 5.3 3.5 8.9 0.0 5.3 0.0 30.3
EVENT 28.3 19.7 6.1 16.0 7.4 8.6 7.4 6.1
</table>
<tableCaption confidence="0.772223">
Table 2: Percentages of paraphrase classes in 50 randomly selected sentence pairs for reference paraphrases for English
(top) and French (bottom). Classes are illustrated by the following examples: (mutual understanding H consensus)
(synonymy), (California H CA) (typography), (letting H having let) (tense), (Asian Development Bank H Asian
Bank) (inclusion), (police dispatcher H woman) (pragmatics), (grief-stricken H struck with grief) (syntactic), (Viet-
name H Vietnam) (morphology), (mortgage H mortgages) (number).
</tableCaption>
<bodyText confidence="0.9881485">
sures of sentence pair similarities are given. TEXT
contains the most similar sentence pairs according to
all metrics, with EVENT at a similar level on French.
SCENE has sentence pairs that are more similar than
those in SPEECH for English, but this is not the case
for French. While the metrics used can only provide
a crude account of semantic equivalence at the sen-
tence level, these results clearly indicate that trans-
lating from text yields more similar sentences than
translating from speech.
Table 2 provides a typology of paraphrases found
in all our corpora and two languages, where each
class has been quantified with respect to the refer-
ence alignments.7 The main observation here is that
phrasal synonymy (e.g. mutual understanding H
consensus) is the most present phenomenon. It is
also interesting to note that the EVENT corpus type,
which is easy to collect on a daily basis, contains ref-
erence paraphrases spread over all classes. Lastly, it
is expected that paraphrases in the pragmatics class
(e.g. police dispatcher H woman) would be diffi-
cult to acquire, as this would often rely on document
context and costly world knowledge.8
7Note that typologies of paraphrases have already been pro-
posed in the literature (e.g. (Culicover, 1968; Vila et al., 2011)),
but that the choice of our classes has been primarily moti-
vated by potential subsequent uses of the acquired paraphrases
(paraphrases could be annotated as belonging to more than one
class). Note also that our experiments will also include results
focused on the synonymy class only (cf. Table 5).
8Reusing such types of paraphrases into applications would
however often be too strongly context-dependent.
</bodyText>
<figureCaption confidence="0.7258726">
Figure 2: Sentence pair average similarities for all cor-
pora for English (left) and French (right) using the co-
sine of token vectors, BLEU (Papineni et al., 2002),
TER (Snover et al., 2006) and METEOR (Lavie and
Agarwal, 2007).
</figureCaption>
<sectionHeader confidence="0.9963785" genericHeader="method">
3 Bilingual experiments across corpus
types
</sectionHeader>
<subsectionHeader confidence="0.999977">
3.1 Evaluation of paraphrase acquisition
</subsectionHeader>
<bodyText confidence="0.999983642857143">
We followed the PARAMETRIC methodology de-
scribed in (Callison-Burch et al., 2008) for assess-
ing the performance of systems on the task of sub-
sentential paraphrase acquisition. In this methodol-
ogy, a set of paraphrase candidates extracted from
a sentence pair is compared with a set of reference
paraphrases, obtained through human annotation, by
computing usual measures of precision (P) and re-
call (R). The first value corresponds to the propor-
tion of paraphrase candidates, denoted H, produced
by a system and that are correct relative to the ref-
erence set containing sure and possible paraphrases,
denoted Rall. Recall is obtained by measuring the
proportion of the reference set of sure paraphrases,
</bodyText>
<figure confidence="0.998661">
COSINE*100 BLEU 1-TER METEOR
COSINE*100 BLEU 1-TER METEOR
60
50
40
30
20
10
0
60
50
40
30
20
10
0
TEXT SPEECH SCENE EVENT
70
</figure>
<page confidence="0.766116">
724
</page>
<figureCaption confidence="0.9985455">
Figure 3: Architecture of our combination system for
paraphrase identification.
</figureCaption>
<bodyText confidence="0.95929075">
denoted Rsure, that are found by a system. We also
computed an F-measure value (Fl), which consid-
ers recall and precision as equally important. These
values are thus given by the following formulae:
</bodyText>
<equation confidence="0.993">
P _ |R n Rall |R _ |R n Rsure |F1 _ 2PR
|R ||Rsure |P + R
</equation>
<bodyText confidence="0.999981818181818">
Note that the way the sets Rall and Rsure of refer-
ence paraphrase pairs are defined ensures that para-
phrase pair candidates that include possible refer-
ence paraphrases will not penalize precision while
not increasing recall.
All performance values reported in the follow-
ing sections will be obtained using 10-fold cross-
validation and averaging the results on each sub-test.
All data sets of cross-validation contain 500 sen-
tence pairs per corpus type, and 125 pairs are kept
for development.
</bodyText>
<subsectionHeader confidence="0.7456335">
3.2 A framework for sub-sentential paraphrase
identification
</subsectionHeader>
<bodyText confidence="0.998246529411765">
We now describe the systems that will be tested
on the various corpora described in section 2 using
the methodology described in section 3.1. Follow-
ing (Bouamor et al., 2012), a combination system
is used to automatically weight paraphrase pair can-
didates produced by individual systems using a set
of features aiming at recognizing paraphrases, as il-
lustrated on Figure 3. Four individual systems have
been used and are described below: the reasons for
considering those systems include their free avail-
ability, the possibility of using comparable resources
when relevant for our two languages, and the spe-
cific characteristics of the techniques used.
Statistical learning of word alignments (GIZA)
The GIZA++ tool (Och and Ney, 2004) com-
putes statistical word alignment models of increas-
ing complexity from parallel corpora. It was run
on each monolingual corpus of sentence pairs in
both directions, symmetrized alignments were kept
and classical phrase extraction heuristics were ap-
plied (Koehn et al., 2003), without growing phrases
with unaligned tokens.
Linguistic knowledge on term variation (FASTR)
The FASTR tool (Jacquemin, 1999) spots term vari-
ants in large corpora, where variants are described
through metarules expressing how the morphosyn-
tactic structure of a term variant can be derived
from a given term by means of regular expressions
on morphosyntactic categories. Paradigmatic varia-
tion can also be expressed with constraints between
words, imposing that they be of the same morpho-
logical or semantic family using existing resources
available in our two languages. Variants for all
phrases from one sentence of a pair are extracted
from the other sentence, and the intersection of the
sets for both directions is kept.
Edit rate on word sequences (TERp) The TERp
tool (Snover et al., 2010) can be used to compute an
optimal set of word and phrase edits that can trans-
form one sentence into another one.9 Edit types are
parameterized by one or more weights which were
optimized towards F-measure by hill climbing with
100 random restarts using the held-out data set con-
sisting of 125 sentence pairs for each corpus type.
Translational equivalence (PIVOT) We exploited
the paraphrase probability defined by Bannard and
Callison-Burch (2005) on bilingual parallel corpora.
We used the Europarl corpus10 of parliamentary de-
bates in English and French, consisting of approx-
imately 1.7 million parallel sentences, using each
language as source and pivot in turn. GIZA++
</bodyText>
<footnote confidence="0.9573778">
9Note that contrarily to what TERp allows, we did not used
the possibility of using word or phrase equivalents as those are
only made available for English. This type of knowledge is
however captured in part by the FASTR and PIVOT systems.
10http://statmt.org/europarl
</footnote>
<figure confidence="0.9773457">
training and
test instances
of sentence
pairs
Original signal type of text pairs
TEXT SPEECH SCENE EVENT
biphrases
GIZA
biphrases
union of
biphrases
with features
FASTR
paraphrases
biphrases
combination
system
TERp
biphrases
PIVOT
</figure>
<page confidence="0.925904">
725
</page>
<table confidence="0.6084203">
Phrase pair features – edit distance between paraphrases, stem identity, bag-of-tokens similarity, phrase
length ratio
Sentence pair features – sentence pair similarity (cosine, BLEU, TER, METEOR), relative position of
paraphrases, presence of common tokens at paraphrase boundaries, presence of another paraphrase pair
from each system at paraphrase boundaries, presence of a paraphrase at a different position in the other
sentence
Distributional features – similarity of token context vectors for each phrase of a paraphrase (derived
from counts in the large English-French parallel corpus from WMT’11 (http://www.statmt.org/
wmt11/translation-task.html) (approx. 30 million parallel sentences)
System features – combination of the individual systems that proposed the paraphrase pair
</table>
<tableCaption confidence="0.9996355">
Table 3: Features used by our classifiers. Discretized intervals based on median values are used for real values, and
binarized values are used for combinations.
</tableCaption>
<bodyText confidence="0.9956646">
was used for word alignment and phrase transla-
tion probabilities were estimated from them by the
MOSES system (Koehn et al., 2007). For each
phrase of a sentence pair, we built its set of para-
phrases, and extracted its paraphrase from the other
sentence with highest probability. We repeated this
process in both directions, and finally kept for each
phrase its paraphrase pair from any direction with
highest probability.
Automatic validation of candidate paraphrases
Taking the union of all paraphrase pair candidates
from all the above systems for each sentence pair, we
perform a Maximum Entropy two-class classifica-
tion11, which allows us to include features that were
not necessarily exploited or straightforward to ex-
ploit by individual systems to determine the proba-
bility that each candidate is a good paraphrase. More
generally, this allows us to attempt to learn a more
generic characterization of paraphrases, which could
trivially accept any number of systems as inputs.
Positive examples for the classifier are those from
the union of candidates that are also in the reference
set Rsure, while negative examples are the remaining
ones from the union. The features that we used are
summarized in Table 3.
</bodyText>
<subsectionHeader confidence="0.995234">
3.3 Experimental results
</subsectionHeader>
<bodyText confidence="0.9998106">
Results for individual systems, their union and our
validation system trained on each corpus type are
given on Table 4. First, we find that all individual
systems fare better on TEXT, for which more train-
ing data were available and where semantic equiv-
</bodyText>
<footnote confidence="0.560316">
11Using the implementation at: http://homepages.
inf.ed.ac.uk/lzhang10/maxent_toolkit.html
</footnote>
<bodyText confidence="0.9998244">
alence of sentence pairs is most likely. EVENT ap-
pears to be the most difficult corpus type, whereas
one could say that being the most readily data source
this is a disapointing result: we will return to this in
section 3.4. In terms of performance on F-measure
per corpus type, GIZA performs best for TEXT and
SPEECH, containing long sentences with possible
repetitions, while TERM, performs on par with GIZA
for SCENE and best for EVENT, where equivalences
that are rare at the corpus level are more present.
FASTR achieves a very low recall, showing that the
encoded definitions of term variants do not cover all
types of paraphrases, and also possibly that the lex-
ical resource that it uses has incomplete coverage.
It nonetheless obtains high precision values, most
notably on TEXT. One last comment regarding in-
dividual systems is that PIVOT is by far the most
precise of all the techniques used, but with a recall
much lower than those of GIZA and TERM,: as is
the case for FASTR, which makes use of manually-
encoded lexical resources, PIVOT encodes in some
sense some kind of semantic knowledge.12
In all cases, our combination system manages
to increase F-measure substantially over the best
individual system for a corpus type and the sim-
ple union. Improvements are strong on TEXT
(resp. +12.5 and +11.6 on English and French)
and on SPEECH (+11.7 and +11.1) and quite good
on SCENE (+3.2 and +6.4) and on EVENT (+5.4
12Note that the fact that English and French were used as the
pivot for one another may have had some positive effect here,
but, incidentally, the two corpora obtained by translating from
the other language (TEXT and SPEECH) are not those where
PIVOT fares better. The difference observed may however lie in
the higher complexity of the sentences in these corpus types.
</bodyText>
<page confidence="0.995021">
726
</page>
<figure confidence="0.351342285714286">
Individual systems
GIZA FASTR TERp--,F PIVOT
P R F1 P R F1 P R F1 P R F1
Combination systems
union validation
P R F1 P R F1
ENGLISH
</figure>
<table confidence="0.998328">
TEXT 48.2 58.9 53.0 63.1 5.9 10.7 41.2 66.4 50.9 73.4 25.8 38.2 20.8 80.8 33.1 68.4 62.8 65.5
SPEECH 39.7 44.2 41.8 27.1 3.5 6.3 25.0 50.3 33.4 79.2 15.3 25.7 25.5 71.4 37.6 51.0 56.3 53.5
SCENE 44.8 57.7 50.5 47.4 5.2 9.5 40.1 67.9 50.4 84.6 14.6 25.0 36.2 83.4 50.5 44.9 66.8 53.7
EVENT 19.0 33.9 24.3 62.9 3.1 6.0 28.8 68.7 40.6 97.4 11.2 20.1 20.8 75.5 32.7 35.0 67.1 46.0
FRENCH
TEXT 52.5 58.9 55.5 56.9 4.9 9.1 46.4 61.4 52.8 64.5 30.3 41.2 41.5 77.9 54.1 74.7 61.0 67.1
SPEECH 44.0 54.9 48.9 30.7 4.3 7.6 34.8 60.2 44.1 75.5 19.0 30.4 31.4 76.2 44.5 60.2 59.7 60.0
(SCENE) 14.4 43.6 21.7 53.0 4.0 7.4 13.8 75.3 23.4 94.6 5.21 9.8 12.7 86.4 22.2 19.9 59.8 29.8
EVENT 28.7 44.2 34.8 34.4 2.3 4.3 29.9 58.9 39.7 79.5 15.0 25.2 25.2 72.5 37.4 40.0 56.3 46.8
</table>
<tableCaption confidence="0.99229">
Table 4: Evaluation results for individual systems (left) and combination systems (right) on all corpus types for English
(top) and French (bottom). Values in bold are for highest values for a given metric for each corpus type and language.
</tableCaption>
<bodyText confidence="0.999199133333333">
and +6.1). Recall from Table 1 that TEXT and
SPEECH were the two corpus types with the highest
number of sure paraphrase examples for both lan-
guages: results show that our classifier was able to
efficiently use them.
Recall values for the union are quite strong for
all corpus types, ranging from 71.4 (SPEECH in En-
glish) to 83.4 (SCENE in English). There is, how-
ever, a substantial decrease between the unions and
the results of our combination systems, although
recall values for our systems are roughly between
56 and 67, which may be considered an acceptable
range on such a task. Further study of false neg-
atives should help with engineering new features to
improve paraphrase recognition. Lastly, we note that
precision is in general highest for a specific system
(PIVOT), and reaches high values for our validation
system on TEXT, where we have the most examples
(resp. 68.4 and 74.7 for English and French).
As seen in Table 2, synonymy is the most present
phenomenon in all our corpora; it is also proba-
bly one of the most useful type of knowledge for
many applications. We now therefore focus on this
class, for which all the sure paraphrases in our cor-
pora falling in this class have been annotated. Ta-
ble 5 shows F-measure values for the individual
techniques and our combination systems on all cor-
pus types. We first observe that our combination sys-
tem also always improves here over the best individ-
ual system, albeit not by a large margin on EVENT.
</bodyText>
<table confidence="0.998394181818182">
GIZA FASTR TERp PIVOT validation
ENGLISH
TEXT 52.2 6.1 47.3 47.1 68.1
SPEECH 42.6 5.0 30.3 39.5 54.9
SCENE 51.8 6.0 48.0 26.0 56.3
EVENT 22.5 2.1 34.8 24.7 35.5
FRENCH
TEXT 55.3 3.9 50.7 50.5 70.3
SPEECH 49.8 1.6 40.9 36.2 57.2
(SCENE) 19.6 4.2 23.1 0.0 24.7
EVENT 36.8 3.5 35.3 25.6 39.9
</table>
<tableCaption confidence="0.973245">
Table 5: F-measure values for test instances in the syn-
</tableCaption>
<figureCaption confidence="0.573945333333333">
onymy class (see Table 2) for all individual systems and
our validation system for English (top) and French (bot-
tom).
</figureCaption>
<bodyText confidence="0.9997608">
Also, we find that PIVOT performs relatively closer
to GIZA and TERp on TEXT and SPEECH than for
the full set of classes, confirming the intuition that
translational equivalence may be appropriate to rec-
ognize synonymy.
</bodyText>
<subsectionHeader confidence="0.991255">
3.4 Experiments across corpus types
</subsectionHeader>
<bodyText confidence="0.9837365">
To test how different the corpora under study are as
regards paraphrase identification, we now consider
using as additional training data for our classifiers
corpora of the other types, both individually and col-
lectively. Results are given on Table 6.13
13Note that our results are still given by performing cross-
validation averaging over 10 test sets for each tested corpus
type.
</bodyText>
<page confidence="0.991591">
727
</page>
<table confidence="0.982991875">
+TEXT +SPEECH +SCENE +EVENT +All
ENGLISH
FRENCH
# ex+ 12,961 3,340 966 2,160
TEXT 67.1 67.2 66.7 67.0
SPEECH 57.6 60.0 56.4 59.6
(SCENE) 23.7 22.0 29.8 23.9
EVENT 45.2 45.6 44.3 46.8
</table>
<tableCaption confidence="0.895830333333333">
Table 6: Evaluation results (Fl scores) for all corpus
types for English (top) and French (bottom) when adding
training material from other corpus types (values with
</tableCaption>
<bodyText confidence="0.963903666666667">
gray background on the diagonal are when no additional
training data are used). “#ex+” rows indicate numbers of
positive paraphrase examples for each additional corpus
type.
The most notable observation is that EVENT is
substantially improved by using all available addi-
tional training data for English (+10.2), and to a
lesser extent for French (+2.5) . It should be noted
that no individual corpus type, save TEXT, individu-
ally improves results on EVENT, and that results are
yet substantially improved over the use of training
data from TEXT when using all available data, re-
vealing a collective contribution of all corpus types.
The second major observation is that all other cor-
pus types seem to be quite specific in nature, as no
addition of training data from other types yields any
improvement (with the exception of SPEECH on En-
glish), but they often in fact decrease performance.
For instance, SCENE in English is substantially neg-
atively impacted by the use of the numerous exam-
ples of TEXT (-4 in F-measure) and even more when
using all other training data (-9). This underlines
the specific nature of this corpus type: independent
descriptions of the same scene in a video may be
worded with much variation that mostly differ from
that present in other corpus types.
Our main conclusion here is therefore that all our
corpora under study are quite specific in nature, but
that EVENT can benefit from all training data from
the other corpus types. We can further note that the
fact that TEXT is almost not impacted by additional
data may also be explained by the fact that this cor-
pus type contains more than half of the total number
of examples for the two languages. Finally, there are
substantially more positive paraphrase examples for
French (19,427) than for English (12,593).
</bodyText>
<sectionHeader confidence="0.999871" genericHeader="method">
4 Related work
</sectionHeader>
<bodyText confidence="0.998664358974359">
Over the years, paraphrase acquisition and genera-
tion have attracted a wealth of research works that
are too many to adequatly summarize here: (Mad-
nani and Dorr, 2010) presents a complete and up-
to-date review of the main approaches. Sentential
paraphrase collection has been tackled from specific
resources increasing the probability of sentences be-
ing paraphrases (Dolan et al., 2004; Bernhard and
Gurevych, 2008; Wubben et al., 2009), from com-
parable monolingual corpora (Barzilay and Elhadad,
2003; Fung and Cheung, 2004; Nelken and Shieber,
2006), and even at web scale (Pasc¸a and Dienes,
2005; Bhagat and Ravichandran, 2008).
Various techniques have been proposed for para-
phrase acquisition from related sentence pairs
(Barzilay and McKeown, 2001; Pang et al., 2003)
and from bilingual parallel corpora (Bannard and
Callison-Burch, 2005; Kok and Brockett, 2010).
The issue of corpus construction for developing and
evaluating paraphrase acquisition techniques are ad-
dressed in (Cohn et al., 2008; Callison-Burch et al.,
2008). To the best of our knowledge, this is the first
time that a study in paraphrase acquisition is con-
ducted on several corpus types and for 2 languages.
Faruqui and Pad´o (2011) study the acquisition of en-
tailment pairs (premise and hypothesis), with ex-
periments in 3 languages and various domains of
newspaper corpora for one language. Although their
work is not directly comparable to ours, they report
that robustness across domains is difficult to achieve.
Laslty, the evaluation of automatically generated
paraphrases has recently received some attention
(Liu et al., 2010; Chen and Dolan, 2011; Met-
zler et al., 2011) although it remains a difficult is-
sue. Application-driven paraphrase generation pro-
vides indirect means of evaluating paraphrase gen-
eration (Zhao et al., 2009). For instance, the field of
Statistical Machine Translation has produced works
showing both the usefulness of human-produced
</bodyText>
<figure confidence="0.95625296">
# ex+ 7,342 2,296 1,784 1,171
SPEECH
EVENT
SCENE
TEXT
49.7 54.3
65.5
56.0
51.1 45.3 42.5
66.2 65.1 66.2
53.5
52.8 54.8
53.7
46.0
53.8
12,593
65.1
56.6
42.7
56.2
19,427
66.6
57.9
21.1
49.3
</figure>
<page confidence="0.9937">
728
</page>
<bodyText confidence="0.97455525">
(Schroeder et al., 2009; Resnik et al., 2010) and au-
tomatically produced paraphrases (Madnani et al.,
2008; Marton et al., 2009; Max, 2010; He et al.,
2011) for improving translation performance.
</bodyText>
<sectionHeader confidence="0.970195" genericHeader="discussions">
5 Discussion and future work
</sectionHeader>
<bodyText confidence="0.995920151515152">
This work has addressed the issue of sub-sentential
paraphrase acquisition from text pairs. Analogu-
ously to bilingual parallel corpora, which are still
to date the most reliable resources for automatic ac-
quisition of sub-sentential translations, monolingual
parallel corpora are generally regarded as very ap-
propriate for paraphrase acquisition. However, their
low availability makes searching for less parallel
corpora a necessity. In this study, we have attempted
to identify corpora of various degrees of semantic
textual similarity by considering text pairs originat-
ing from various signal types. These signal types
allow various degrees of freedom as to how to for-
mulate a text: a text is read and translated into a dif-
ferent language (TEXT); some speech is listened to
in the context of a visual story and translated into a
different language (SPEECH); some action is looked
at and described (SCENE); and some event that took
place is concisely reported (EVENT).
The results presented in this paper have shown
how these corpora differed in various aspects. First,
they contain varying quantities of paraphrases that
are differently distributed into paraphrase classes.
Individual acquisition techniques, based on statis-
tical learning of word alignments (GIZA), linguis-
tic knowledge on term variation (FASTR), edit rate
on word sequence (TERM,), and translational equiv-
alence (PIVOT), for which different performances
were observed among them on the same corpus
type, were shown to achieve different performances
across corpus types. An efficient combination of
candidate paraphrases from these individual tech-
niques exploiting additional features to character-
ize paraphrases has yielded substantial increases in
performance on all corpus types; however, it is in-
teresting to note that the highest amplitude in per-
formance across corpus types was not so much on
recall (amplitude of 10.5 on English and 4.7 on
French) than on precision (amplitude of 33.4 on En-
glish and 34.714 on French). This, some other fac-
14Not considering (SCENE) for French.
tors aside, emphasizes the fact that the correct idenfi-
cation of paraphrases is facilitated when equivalence
of semantic content is more probable. Many works
have accordingly attempted to identify text units that
are as parallel as possible from large corpora, and
the task of measuring semantic textual similarity,
which can find many uses, has received some atten-
tion lately (Agirre et al., 2012). However, it itself
relies on some knowledge on paraphrasing.
Our avenues for future work lie in three main ar-
eas. The first one is to continue our current line of
work and study the impact of additional individual
acquisition techniques and better characterizations
of paraphrases in context, in tandem with working
on identifying parallel text pairs in large corpora.
Another avenue is to start from the output of high
recall techniques and to attempt to characterize the
contexts of possible substitution for candidate para-
phrases from large corpora as a means to acquire
precise paraphrases. As the examples from Table 7
show, some classes of paraphrases, and in particular
in the continuum from our synonymy to pragmat-
ics classes, require the joint acquisition of contextual
information that license substitution. Lastly, we plan
to apply such knowledge in text-to-text applications.
</bodyText>
<construct confidence="0.983963111111111">
synonymy
take part in H participate in
great assistance H enormous help
make a deal H come to an agreement
I don’t care H I don’t give a damn
riding a bicycle H cycling
lady H woman
jail escapee H prison fugitive
apologizes H expresses regret
pragmatics
flew in H arrived in
flood-control materials H needed supplies
face H picture
want to sleep H dream about sleeping
a man H someone
bento H food
violence H bloodshed
anger H emotion
</construct>
<tableCaption confidence="0.9913">
Table 7: Examples in English for the synonymy and
pragmatics classes.
</tableCaption>
<figure confidence="0.996027875">
TEXT
SPEECH
SCENE
EVENT
TEXT
SPEECH
SCENE
EVENT
</figure>
<page confidence="0.991514">
729
</page>
<sectionHeader confidence="0.998412" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99988025">
The authors would like to thank the reviewers for
their comments and suggestions. This work was
partly funded by ANR project Edylex (ANR-09-
CORD-008).
</bodyText>
<sectionHeader confidence="0.998942" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999919010309278">
Eneko Agirre, Daniel Cer, Mona Diab, and Aitor
Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A Pi-
lot on Semantic Textual Similarity. In Proceedings of
SemEval, Montr´eal, Canada.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with Bilingual Parallel Corpora. In Proceed-
ings of ACL, Ann Arbor, USA.
Regina Barzilay and Noemie Elhadad. 2003. Sentence
alignment for monolingual comparable corpora. In
Proceedings of EMNLP, Sapporo, Japan.
Regina Barzilay and Kathleen R. McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Pro-
ceedings of ACL, Toulouse, France.
Delphine Bernhard and Iryna Gurevych. 2008. Answer-
ing Learners’ Questions by Retrieving Question Para-
phrases from Social Q&amp;A Sites. In Proceedings of the
Workshop on Innovative Use of NLP for Building Ed-
ucational Applications, Columbus, USA.
Rahul Bhagat and Deepak Ravichandran. 2008. Large
scale acquisition of paraphrases for learning surface
patterns. In Proceedings of ACL-HLT, Columbus,
USA.
Houda Bouamor, Aur´elien Max, and Anne Vilnat. 2012.
Validation of sub-sentential paraphrases acquired from
parallel monolingual corpora. In EACL, Avignon,
France.
Chris Callison-Burch, Trevor Cohn, and Mirella Lapata.
2008. Parametric: An automatic evaluation metric for
paraphrasing. In Proceedings of COLING, Manch-
ester, UK.
David Chen and William Dolan. 2011. Collecting highly
parallel data for paraphrase evaluation. In Proceedings
of ACL, Portland, USA.
Trevor Cohn, Chris Callison-Burch, and Mirella Lapata.
2008. Constructing corpora for the development and
evaluation of paraphrase systems. Computational Lin-
guistics, 34(4).
P. W. Culicover. 1968. Paraphrase Generation and Infor-
mation Retrieval from Stored Text. Mechanical Trans-
lation and Computational Linguistics, 11:78–88.
Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Un-
supervised construction of large paraphrase corpora:
Exploiting massively parallel news sources. In Pro-
ceedings of COLING, Geneva, Switzerland.
Manaal Faruqui and Sebastian Pad´o. 2011. Acquiring
entailment pairs across languages and domains: A data
analysis. In Proceedings of the International Con-
ference on Computational Semantics (IWCS), Oxford,
UK.
Pascale Fung and Percy Cheung. 2004. Multi-level
bootstrapping for extracting parallel sentences from a
quasi-comparable corpus. In Proceedings of COLING,
Geneva, Switzerland.
Ulrich Germann. 2008. Yawat : Yet Another Word
Alignment Tool. In Proceedings of the ACL-HLT,
demo session, Columbus, USA.
Wei He, Shiqi Zhao, Haifeng Wang, and Ting Liu. 2011.
Enriching SMT Training Data via Paraphrasing. In
Proceedings of IJCNLP, Chiang Mai, Thailand.
Christian Jacquemin. 1999. Syntagmatic and paradig-
matic representations of term variation. In Proceed-
ings of ACL, College Park, USA.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In Pro-
ceedings of NAACL-HLT, Edmonton, Canada.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: Open Source
Toolkit for Statistical Machine Translation. In Pro-
ceedings ofACL, demo session, Prague, Czech Repub-
lic.
Stanley Kok and Chris Brockett. 2010. Hitting the Right
Paraphrases in Good Time. In Proceedings of NAACL,
Los Angeles, USA.
Alon Lavie and Abhaya Agarwal. 2007. METEOR: An
automatic metric for MT evaluation with high levels of
correlation with human judgments. In Proceedings of
the ACL Workshop on Statistical Machine Translation,
Prague, Czech Republic.
Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng. 2010.
PEM: A paraphrase evaluation metric exploiting par-
allel texts. In Proceedings of EMNLP, Cambridge,
USA.
Nitin Madnani and Bonnie J. Dorr. 2010. Generating
Phrasal and Sentential Paraphrases: A Survey of Data-
Driven Methods. Computational Linguistics, 36(3).
Nitin Madnani, Philip Resnik, Bonnie J. Dorr, and
Richard Schwartz. 2008. Are multiple reference
translations necessary? investigating the value of
paraphrased reference translations in parameter opti-
mization. In Proceedings of AMTA, Waikiki, USA.
Yuval Marton, Chris Callison-Burch, and Philip Resnik.
2009. Improved Statistical Machine Translation Using
Monolingually-derived Paraphrases. In Proceedings
of EMNLP, Singapore.
</reference>
<page confidence="0.963432">
730
</page>
<reference confidence="0.999908303571429">
Aur´elien Max. 2010. Example-Based Paraphrasing for
Improved Phrase-Based Statistical Machine Transla-
tion. In Proceedings of EMNLP, Cambridge, USA.
Donald Metzler, Eduard Hovy, and Chunliang Zhang.
2011. An empirical evaluation of data-driven para-
phrase generation techniques. In Proceedings of ACL-
HLT, Portland, USA.
Rani Nelken and Stuart M. Shieber. 2006. Towards ro-
bust context-sensitive sentence alignment for monolin-
gual corpora. In Proceedings of EACL, Trento, Italy.
Franz Josef Och and Herman Ney. 2004. The align-
ment template approach to statistical machine trans-
lation. Computational Linguistics, 30(4).
Bo Pang, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignement of multiple translations: Ex-
tracting paraphrases and generating new sentences. In
Proceedings of NAACL-HLT, Edmonton, Canada.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proceedings of ACL,
Philadelphia, USA.
Marius Pasc¸a and Peter Dienes. 2005. Aligning Nee-
dles in a Haystack: Paraphrase Acquisition Across the
Web. In Proceedings of IJCNLP, Jeju Island, South
Korea.
Philip Resnik, Olivia Buzek, Chang Hu, Yakov Kronrod,
Alex Quinn, and Benjamin B. Bederson. 2010. Im-
proving translation via targeted paraphrasing. In Pro-
ceedings of EMNLP, Cambridge, USA.
Josh Schroeder, Trevor Cohn, and Philipp Koehn. 2009.
Word Lattices for Multi-Source Translation. In Pro-
ceedings of EACL, Athens, Greece.
Matthew Snover, Bonnie J. Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study of
Translation Edit Rate with Targeted Human Annota-
tion. In Proceedings of AMTA, Boston, USA.
Matthew Snover, Nitin Madnani, Bonnie J. Dorr, and
Richard Schwartz. 2010. TER-Plus: paraphrase, se-
mantic, and alignment enhancements to Translation
Edit Rate. Machine Translation, 23(2-3).
J¨org Tiedemann. 2007. Building a Multilingual Paral-
lel Subtitle Corpus. In Proceedings of the Conference
on Computational Linguistics in the Netherlands, Leu-
ven, Belgium.
Marta Vila, M. Ant`onia Marti, and Horacio Rodriguez.
2011. Paraphrase Concept and Typology. A Linguisti-
cally Based and Computationally Oriented Approach.
Procesamiento del Lenguaje Natural, (462-3).
Sander Wubben, Antal van den Bosch, Emiel Krahmer,
and Erwin Marsi. 2009. Clustering and maching
headlines for automatic paraphrase acquisition. In
Proceedings of the European Workshop on Natural
Language Generation, Athens, Greece.
Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009.
Application-driven Statistical Paraphrase Generation.
In Proceedings of ACL-IJCNLP, Singapore.
</reference>
<page confidence="0.998004">
731
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959876">
<title confidence="0.998244">Generalizing Sub-sentential Paraphrase across Original Signal Type of Text Pairs</title>
<author confidence="0.991842">Aur´elien Max Houda Bouamor Anne Vilnat</author>
<affiliation confidence="0.998439">LIMSI-CNRS &amp; Univ. Paris</affiliation>
<address confidence="0.981439">Orsay, France</address>
<email confidence="0.999039">firstname.lastname@limsi.fr</email>
<abstract confidence="0.999318461538461">This paper describes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of subsentential paraphrases found in our corpus types is given.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Daniel Cer</author>
<author>Mona Diab</author>
<author>Aitor Gonzalez-Agirre</author>
</authors>
<date>2012</date>
<booktitle>SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity. In Proceedings of SemEval,</booktitle>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="32971" citStr="Agirre et al., 2012" startWordPosition="5346" endWordPosition="5349">ross corpus types was not so much on recall (amplitude of 10.5 on English and 4.7 on French) than on precision (amplitude of 33.4 on English and 34.714 on French). This, some other fac14Not considering (SCENE) for French. tors aside, emphasizes the fact that the correct idenfication of paraphrases is facilitated when equivalence of semantic content is more probable. Many works have accordingly attempted to identify text units that are as parallel as possible from large corpora, and the task of measuring semantic textual similarity, which can find many uses, has received some attention lately (Agirre et al., 2012). However, it itself relies on some knowledge on paraphrasing. Our avenues for future work lie in three main areas. The first one is to continue our current line of work and study the impact of additional individual acquisition techniques and better characterizations of paraphrases in context, in tandem with working on identifying parallel text pairs in large corpora. Another avenue is to start from the output of high recall techniques and to attempt to characterize the contexts of possible substitution for candidate paraphrases from large corpora as a means to acquire precise paraphrases. As </context>
</contexts>
<marker>Agirre, Cer, Diab, Gonzalez-Agirre, 2012</marker>
<rawString>Eneko Agirre, Daniel Cer, Mona Diab, and Aitor Gonzalez-Agirre. 2012. SemEval-2012 Task 6: A Pilot on Semantic Textual Similarity. In Proceedings of SemEval, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with Bilingual Parallel Corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Ann Arbor, USA.</location>
<contexts>
<context position="17239" citStr="Bannard and Callison-Burch (2005)" startWordPosition="2772" endWordPosition="2775">ce of a pair are extracted from the other sentence, and the intersection of the sets for both directions is kept. Edit rate on word sequences (TERp) The TERp tool (Snover et al., 2010) can be used to compute an optimal set of word and phrase edits that can transform one sentence into another one.9 Edit types are parameterized by one or more weights which were optimized towards F-measure by hill climbing with 100 random restarts using the held-out data set consisting of 125 sentence pairs for each corpus type. Translational equivalence (PIVOT) We exploited the paraphrase probability defined by Bannard and Callison-Burch (2005) on bilingual parallel corpora. We used the Europarl corpus10 of parliamentary debates in English and French, consisting of approximately 1.7 million parallel sentences, using each language as source and pivot in turn. GIZA++ 9Note that contrarily to what TERp allows, we did not used the possibility of using word or phrase equivalents as those are only made available for English. This type of knowledge is however captured in part by the FASTR and PIVOT systems. 10http://statmt.org/europarl training and test instances of sentence pairs Original signal type of text pairs TEXT SPEECH SCENE EVENT </context>
<context position="29008" citStr="Bannard and Callison-Burch, 2005" startWordPosition="4727" endWordPosition="4730">f the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that ro</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with Bilingual Parallel Corpora. In Proceedings of ACL, Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Noemie Elhadad</author>
</authors>
<title>Sentence alignment for monolingual comparable corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="28666" citStr="Barzilay and Elhadad, 2003" startWordPosition="4676" endWordPosition="4679">ally, there are substantially more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study i</context>
</contexts>
<marker>Barzilay, Elhadad, 2003</marker>
<rawString>Regina Barzilay and Noemie Elhadad. 2003. Sentence alignment for monolingual comparable corpora. In Proceedings of EMNLP, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="28918" citStr="Barzilay and McKeown, 2001" startWordPosition="4714" endWordPosition="4717"> summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of ACL, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delphine Bernhard</author>
<author>Iryna Gurevych</author>
</authors>
<title>Answering Learners’ Questions by Retrieving Question Paraphrases from Social Q&amp;A Sites.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Innovative Use of NLP for Building Educational Applications,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="28579" citStr="Bernhard and Gurevych, 2008" startWordPosition="4663" endWordPosition="4666"> type contains more than half of the total number of examples for the two languages. Finally, there are substantially more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-B</context>
</contexts>
<marker>Bernhard, Gurevych, 2008</marker>
<rawString>Delphine Bernhard and Iryna Gurevych. 2008. Answering Learners’ Questions by Retrieving Question Paraphrases from Social Q&amp;A Sites. In Proceedings of the Workshop on Innovative Use of NLP for Building Educational Applications, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Large scale acquisition of paraphrases for learning surface patterns.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="28796" citStr="Bhagat and Ravichandran, 2008" startWordPosition="4697" endWordPosition="4700">Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition </context>
</contexts>
<marker>Bhagat, Ravichandran, 2008</marker>
<rawString>Rahul Bhagat and Deepak Ravichandran. 2008. Large scale acquisition of paraphrases for learning surface patterns. In Proceedings of ACL-HLT, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Houda Bouamor</author>
<author>Aur´elien Max</author>
<author>Anne Vilnat</author>
</authors>
<title>Validation of sub-sentential paraphrases acquired from parallel monolingual corpora.</title>
<date>2012</date>
<booktitle>In EACL,</booktitle>
<location>Avignon, France.</location>
<contexts>
<context position="15154" citStr="Bouamor et al., 2012" startWordPosition="2446" endWordPosition="2449">e pair candidates that include possible reference paraphrases will not penalize precision while not increasing recall. All performance values reported in the following sections will be obtained using 10-fold crossvalidation and averaging the results on each sub-test. All data sets of cross-validation contain 500 sentence pairs per corpus type, and 125 pairs are kept for development. 3.2 A framework for sub-sentential paraphrase identification We now describe the systems that will be tested on the various corpora described in section 2 using the methodology described in section 3.1. Following (Bouamor et al., 2012), a combination system is used to automatically weight paraphrase pair candidates produced by individual systems using a set of features aiming at recognizing paraphrases, as illustrated on Figure 3. Four individual systems have been used and are described below: the reasons for considering those systems include their free availability, the possibility of using comparable resources when relevant for our two languages, and the specific characteristics of the techniques used. Statistical learning of word alignments (GIZA) The GIZA++ tool (Och and Ney, 2004) computes statistical word alignment mo</context>
</contexts>
<marker>Bouamor, Max, Vilnat, 2012</marker>
<rawString>Houda Bouamor, Aur´elien Max, and Anne Vilnat. 2012. Validation of sub-sentential paraphrases acquired from parallel monolingual corpora. In EACL, Avignon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Parametric: An automatic evaluation metric for paraphrasing.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<location>Manchester, UK.</location>
<contexts>
<context position="13338" citStr="Callison-Burch et al., 2008" startWordPosition="2141" endWordPosition="2144">e than one class). Note also that our experiments will also include results focused on the synonymy class only (cf. Table 5). 8Reusing such types of paraphrases into applications would however often be too strongly context-dependent. Figure 2: Sentence pair average similarities for all corpora for English (left) and French (right) using the cosine of token vectors, BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). 3 Bilingual experiments across corpus types 3.1 Evaluation of paraphrase acquisition We followed the PARAMETRIC methodology described in (Callison-Burch et al., 2008) for assessing the performance of systems on the task of subsentential paraphrase acquisition. In this methodology, a set of paraphrase candidates extracted from a sentence pair is compared with a set of reference paraphrases, obtained through human annotation, by computing usual measures of precision (P) and recall (R). The first value corresponds to the proportion of paraphrase candidates, denoted H, produced by a system and that are correct relative to the reference set containing sure and possible paraphrases, denoted Rall. Recall is obtained by measuring the proportion of the reference se</context>
<context position="29197" citStr="Callison-Burch et al., 2008" startWordPosition="4755" endWordPosition="4758">vych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; </context>
</contexts>
<marker>Callison-Burch, Cohn, Lapata, 2008</marker>
<rawString>Chris Callison-Burch, Trevor Cohn, and Mirella Lapata. 2008. Parametric: An automatic evaluation metric for paraphrasing. In Proceedings of COLING, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chen</author>
<author>William Dolan</author>
</authors>
<title>Collecting highly parallel data for paraphrase evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Portland, USA.</location>
<contexts>
<context position="5519" citStr="Chen and Dolan, 2011" startWordPosition="885" endWordPosition="888">leux Destin d’Am´elie Poulain and Les Choristes, and for French we used two subtitle files from the Desperate Housewives TV series. We first aligned each parallel corpus using the algorithm described in (Tiedemann, 2007), based on time frames and developed for bilingual subtitles, we then filtered out sentence pairs below a minimal edit distance threshold, and manually removed obvious errors made by the algorithm. e.g. So he uses the photo booths to remind people what he looks like. H He uses those machines to remind the living of his face. SCENE We used the Multiple Video Description Corpus (Chen and Dolan, 2011) obtained from multiple descriptions of short videos. Similarly to what we did for TEXT, we selected sentence pairs from clusters by minimal edit distance above a threshold. An important fact is that for English we were able to use what is described as “verified” descriptions. There were, however, far fewer descriptions available for French, and none had the “verified” status. We decided to use this corpus nonetheless, but with the knowledge that this source for French is of a substantially lower quality (this corpus type will therefore appear as “(SCENE)” in all tables to reflect this). e.g. </context>
<context position="29795" citStr="Chen and Dolan, 2011" startWordPosition="4851" endWordPosition="4854">on-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al</context>
</contexts>
<marker>Chen, Dolan, 2011</marker>
<rawString>David Chen and William Dolan. 2011. Collecting highly parallel data for paraphrase evaluation. In Proceedings of ACL, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Chris Callison-Burch</author>
<author>Mirella Lapata</author>
</authors>
<title>Constructing corpora for the development and evaluation of paraphrase systems.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="4210" citStr="Cohn et al., 2008" startWordPosition="669" endWordPosition="672">annual total foreign trade volume will exceed US$9 billion . He uses those machines to remind the living of his face . a boy rides a bike on a dirt road . It is estimated that the total annual volume of import and export will exceed 9 billion US dollars So he uses the photo booths to remind people what he looks like a boy is riding on a bicycle fast Figure 1: Example reference alignment matrices for (from top to bottom) TEXT, SPEECH, SCENE and EVENT. Sure alignments appear in green or gray (identities) and possible alignments in yellow. TEXT For English, we used the MTC corpus1 (described in (Cohn et al., 2008)) consisting of sets of news article translations from Chinese, and for French the CESTA corpus2 consisting of sets of news article translations from English. For each sentence cluster, we selected sentence pairs with minimal edit distance above an empirically-selected threshold, covering all clusters first and then selecting from already used clusters to reach the target number of sentence pairs. e.g. It is estimated that the total annual volume of import and export will exceed 9 billion US dollars. H It is anticipated that the annual total foreign trade volume will exceed US$9 billion. SPEEC</context>
<context position="8075" citStr="Cohn et al. (2008)" startWordPosition="1300" endWordPosition="1303"> filtering out article pairs whose publication dates differed from more than one day. We repeated the same selection procedure as for TEXT and SCENE to have a maximal cluster coverage and select more similar pairs first. e.g. Pigeons Have an Understanding of Numbers on Par With Primates H Pigeons Have Numerical Abilities Just Like Primates Table 1 provides various statistics for these corpora. The first observation is that TEXT contains significantly larger sentences than the other types, more than twice as long as those of SPEECH. Annotation was performed following the guidelines proposed by Cohn et al. (2008)5 using the YAWAT tool (Germann, 2008), except that alignments where not initially obtained automatically so as not to bias our annotators’ work (there were two annotators per language). The main guidelines that they had to follow were that sure and possible paraphrases must be distinguished, smaller alignments were to be prefered but any-to-any alignments may be used, and sentences should be aligned as much as possible. Henceforth, we will only consider for all reported statistics and experiments those paraphrases that are not identity pairs (e.g. (a nice day H a nice day)), as they are 4http</context>
<context position="29167" citStr="Cohn et al., 2008" startWordPosition="4751" endWordPosition="4754">; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al.</context>
</contexts>
<marker>Cohn, Callison-Burch, Lapata, 2008</marker>
<rawString>Trevor Cohn, Chris Callison-Burch, and Mirella Lapata. 2008. Constructing corpora for the development and evaluation of paraphrase systems. Computational Linguistics, 34(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P W Culicover</author>
</authors>
<date>1968</date>
<booktitle>Paraphrase Generation and Information Retrieval from Stored Text. Mechanical Translation and Computational Linguistics,</booktitle>
<pages>11--78</pages>
<contexts>
<context position="12515" citStr="Culicover, 1968" startWordPosition="2014" endWordPosition="2015"> the reference alignments.7 The main observation here is that phrasal synonymy (e.g. mutual understanding H consensus) is the most present phenomenon. It is also interesting to note that the EVENT corpus type, which is easy to collect on a daily basis, contains reference paraphrases spread over all classes. Lastly, it is expected that paraphrases in the pragmatics class (e.g. police dispatcher H woman) would be difficult to acquire, as this would often rely on document context and costly world knowledge.8 7Note that typologies of paraphrases have already been proposed in the literature (e.g. (Culicover, 1968; Vila et al., 2011)), but that the choice of our classes has been primarily motivated by potential subsequent uses of the acquired paraphrases (paraphrases could be annotated as belonging to more than one class). Note also that our experiments will also include results focused on the synonymy class only (cf. Table 5). 8Reusing such types of paraphrases into applications would however often be too strongly context-dependent. Figure 2: Sentence pair average similarities for all corpora for English (left) and French (right) using the cosine of token vectors, BLEU (Papineni et al., 2002), TER (Sn</context>
</contexts>
<marker>Culicover, 1968</marker>
<rawString>P. W. Culicover. 1968. Paraphrase Generation and Information Retrieval from Stored Text. Mechanical Translation and Computational Linguistics, 11:78–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Dolan</author>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING,</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="28550" citStr="Dolan et al., 2004" startWordPosition="4659" endWordPosition="4662">act that this corpus type contains more than half of the total number of examples for the two languages. Finally, there are substantially more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (</context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Proceedings of COLING, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manaal Faruqui</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Acquiring entailment pairs across languages and domains: A data analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Computational Semantics (IWCS),</booktitle>
<location>Oxford, UK.</location>
<marker>Faruqui, Pad´o, 2011</marker>
<rawString>Manaal Faruqui and Sebastian Pad´o. 2011. Acquiring entailment pairs across languages and domains: A data analysis. In Proceedings of the International Conference on Computational Semantics (IWCS), Oxford, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Percy Cheung</author>
</authors>
<title>Multi-level bootstrapping for extracting parallel sentences from a quasi-comparable corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of COLING,</booktitle>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="28689" citStr="Fung and Cheung, 2004" startWordPosition="4680" endWordPosition="4683">y more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisitio</context>
</contexts>
<marker>Fung, Cheung, 2004</marker>
<rawString>Pascale Fung and Percy Cheung. 2004. Multi-level bootstrapping for extracting parallel sentences from a quasi-comparable corpus. In Proceedings of COLING, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Germann</author>
</authors>
<title>Yawat : Yet Another Word Alignment Tool.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL-HLT, demo session,</booktitle>
<location>Columbus, USA.</location>
<contexts>
<context position="8113" citStr="Germann, 2008" startWordPosition="1308" endWordPosition="1309">tion dates differed from more than one day. We repeated the same selection procedure as for TEXT and SCENE to have a maximal cluster coverage and select more similar pairs first. e.g. Pigeons Have an Understanding of Numbers on Par With Primates H Pigeons Have Numerical Abilities Just Like Primates Table 1 provides various statistics for these corpora. The first observation is that TEXT contains significantly larger sentences than the other types, more than twice as long as those of SPEECH. Annotation was performed following the guidelines proposed by Cohn et al. (2008)5 using the YAWAT tool (Germann, 2008), except that alignments where not initially obtained automatically so as not to bias our annotators’ work (there were two annotators per language). The main guidelines that they had to follow were that sure and possible paraphrases must be distinguished, smaller alignments were to be prefered but any-to-any alignments may be used, and sentences should be aligned as much as possible. Henceforth, we will only consider for all reported statistics and experiments those paraphrases that are not identity pairs (e.g. (a nice day H a nice day)), as they are 4http://news.google.com 5See http://staffww</context>
</contexts>
<marker>Germann, 2008</marker>
<rawString>Ulrich Germann. 2008. Yawat : Yet Another Word Alignment Tool. In Proceedings of the ACL-HLT, demo session, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei He</author>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
</authors>
<title>Enriching SMT Training Data via Paraphrasing. In</title>
<date>2011</date>
<booktitle>Proceedings of IJCNLP,</booktitle>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="30452" citStr="He et al., 2011" startWordPosition="4960" endWordPosition="4963">ns a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora a necessity. In this study, we have attempted to identify corpora of various degrees of semantic textual simila</context>
</contexts>
<marker>He, Zhao, Wang, Liu, 2011</marker>
<rawString>Wei He, Shiqi Zhao, Haifeng Wang, and Ting Liu. 2011. Enriching SMT Training Data via Paraphrasing. In Proceedings of IJCNLP, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Syntagmatic and paradigmatic representations of term variation.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>College Park, USA.</location>
<contexts>
<context position="16120" citStr="Jacquemin, 1999" startWordPosition="2593" endWordPosition="2594">lity of using comparable resources when relevant for our two languages, and the specific characteristics of the techniques used. Statistical learning of word alignments (GIZA) The GIZA++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. It was run on each monolingual corpus of sentence pairs in both directions, symmetrized alignments were kept and classical phrase extraction heuristics were applied (Koehn et al., 2003), without growing phrases with unaligned tokens. Linguistic knowledge on term variation (FASTR) The FASTR tool (Jacquemin, 1999) spots term variants in large corpora, where variants are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of regular expressions on morphosyntactic categories. Paradigmatic variation can also be expressed with constraints between words, imposing that they be of the same morphological or semantic family using existing resources available in our two languages. Variants for all phrases from one sentence of a pair are extracted from the other sentence, and the intersection of the sets for both directions is kept. </context>
</contexts>
<marker>Jacquemin, 1999</marker>
<rawString>Christian Jacquemin. 1999. Syntagmatic and paradigmatic representations of term variation. In Proceedings of ACL, College Park, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="15992" citStr="Koehn et al., 2003" startWordPosition="2574" endWordPosition="2577">tems have been used and are described below: the reasons for considering those systems include their free availability, the possibility of using comparable resources when relevant for our two languages, and the specific characteristics of the techniques used. Statistical learning of word alignments (GIZA) The GIZA++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. It was run on each monolingual corpus of sentence pairs in both directions, symmetrized alignments were kept and classical phrase extraction heuristics were applied (Koehn et al., 2003), without growing phrases with unaligned tokens. Linguistic knowledge on term variation (FASTR) The FASTR tool (Jacquemin, 1999) spots term variants in large corpora, where variants are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of regular expressions on morphosyntactic categories. Paradigmatic variation can also be expressed with constraints between words, imposing that they be of the same morphological or semantic family using existing resources available in our two languages. Variants for all phrases f</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proceedings of NAACL-HLT, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL, demo session,</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="19049" citStr="Koehn et al., 2007" startWordPosition="3036" endWordPosition="3039">imilarity of token context vectors for each phrase of a paraphrase (derived from counts in the large English-French parallel corpus from WMT’11 (http://www.statmt.org/ wmt11/translation-task.html) (approx. 30 million parallel sentences) System features – combination of the individual systems that proposed the paraphrase pair Table 3: Features used by our classifiers. Discretized intervals based on median values are used for real values, and binarized values are used for combinations. was used for word alignment and phrase translation probabilities were estimated from them by the MOSES system (Koehn et al., 2007). For each phrase of a sentence pair, we built its set of paraphrases, and extracted its paraphrase from the other sentence with highest probability. We repeated this process in both directions, and finally kept for each phrase its paraphrase pair from any direction with highest probability. Automatic validation of candidate paraphrases Taking the union of all paraphrase pair candidates from all the above systems for each sentence pair, we perform a Maximum Entropy two-class classification11, which allows us to include features that were not necessarily exploited or straightforward to exploit </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. In Proceedings ofACL, demo session, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Kok</author>
<author>Chris Brockett</author>
</authors>
<title>Hitting the Right Paraphrases in Good Time.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<location>Los Angeles, USA.</location>
<contexts>
<context position="29033" citStr="Kok and Brockett, 2010" startWordPosition="4731" endWordPosition="4734">paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains i</context>
</contexts>
<marker>Kok, Brockett, 2010</marker>
<rawString>Stanley Kok and Chris Brockett. 2010. Hitting the Right Paraphrases in Good Time. In Proceedings of NAACL, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Abhaya Agarwal</author>
</authors>
<title>METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL Workshop on Statistical Machine Translation,</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="13170" citStr="Lavie and Agarwal, 2007" startWordPosition="2118" endWordPosition="2121"> the choice of our classes has been primarily motivated by potential subsequent uses of the acquired paraphrases (paraphrases could be annotated as belonging to more than one class). Note also that our experiments will also include results focused on the synonymy class only (cf. Table 5). 8Reusing such types of paraphrases into applications would however often be too strongly context-dependent. Figure 2: Sentence pair average similarities for all corpora for English (left) and French (right) using the cosine of token vectors, BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). 3 Bilingual experiments across corpus types 3.1 Evaluation of paraphrase acquisition We followed the PARAMETRIC methodology described in (Callison-Burch et al., 2008) for assessing the performance of systems on the task of subsentential paraphrase acquisition. In this methodology, a set of paraphrase candidates extracted from a sentence pair is compared with a set of reference paraphrases, obtained through human annotation, by computing usual measures of precision (P) and recall (R). The first value corresponds to the proportion of paraphrase candidates, denoted H, produced by a system and t</context>
</contexts>
<marker>Lavie, Agarwal, 2007</marker>
<rawString>Alon Lavie and Abhaya Agarwal. 2007. METEOR: An automatic metric for MT evaluation with high levels of correlation with human judgments. In Proceedings of the ACL Workshop on Statistical Machine Translation, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chang Liu</author>
<author>Daniel Dahlmeier</author>
<author>Hwee Tou Ng</author>
</authors>
<title>PEM: A paraphrase evaluation metric exploiting parallel texts.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Cambridge, USA.</location>
<contexts>
<context position="29773" citStr="Liu et al., 2010" startWordPosition="4847" endWordPosition="4850"> al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced para</context>
</contexts>
<marker>Liu, Dahlmeier, Ng, 2010</marker>
<rawString>Chang Liu, Daniel Dahlmeier, and Hwee Tou Ng. 2010. PEM: A paraphrase evaluation metric exploiting parallel texts. In Proceedings of EMNLP, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Generating Phrasal and Sentential Paraphrases: A Survey of DataDriven Methods.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<contexts>
<context position="848" citStr="Madnani and Dorr, 2010" startWordPosition="123" endWordPosition="126">escribes a study on the impact of the original signal (text, speech, visual scene, event) of a text pair on the task of both manual and automatic sub-sentential paraphrase acquisition. A corpus of 2,500 annotated sentences in English and French is described, and performance on this corpus is reported for an efficient system combination exploiting a large set of features for paraphrase recognition. A detailed quantified typology of subsentential paraphrases found in our corpus types is given. 1 Introduction Sub-sentential paraphrases can be acquired from text pairs expressing the same meaning (Madnani and Dorr, 2010). If the semantic similarity of a text pair has a direct impact on the quality of the acquired paraphrases, it has, to our knowledge, never been shown what impact the type of original signal has on paraphrase acquisition. In this work, we consider four types of corpora, which we think are representative of the main types of original semantic signals: text pairs (roughly, sentences) originating a) from independent translations of a text (TEXT), b) from independent translations of a speech (SPEECH), c) from independent descriptions of a visual scene (SCENE), and d) from independent descriptions </context>
<context position="28333" citStr="Madnani and Dorr, 2010" startWordPosition="4626" endWordPosition="4630"> quite specific in nature, but that EVENT can benefit from all training data from the other corpus types. We can further note that the fact that TEXT is almost not impacted by additional data may also be explained by the fact that this corpus type contains more than half of the total number of examples for the two languages. Finally, there are substantially more positive paraphrase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., </context>
</contexts>
<marker>Madnani, Dorr, 2010</marker>
<rawString>Nitin Madnani and Bonnie J. Dorr. 2010. Generating Phrasal and Sentential Paraphrases: A Survey of DataDriven Methods. Computational Linguistics, 36(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Philip Resnik</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>Are multiple reference translations necessary? investigating the value of paraphrased reference translations in parameter optimization.</title>
<date>2008</date>
<booktitle>In Proceedings of AMTA,</booktitle>
<location>Waikiki, USA.</location>
<contexts>
<context position="30402" citStr="Madnani et al., 2008" startWordPosition="4950" endWordPosition="4953">d Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora a necessity. In this study, we have attempted to identify cor</context>
</contexts>
<marker>Madnani, Resnik, Dorr, Schwartz, 2008</marker>
<rawString>Nitin Madnani, Philip Resnik, Bonnie J. Dorr, and Richard Schwartz. 2008. Are multiple reference translations necessary? investigating the value of paraphrased reference translations in parameter optimization. In Proceedings of AMTA, Waikiki, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Chris Callison-Burch</author>
<author>Philip Resnik</author>
</authors>
<title>Improved Statistical Machine Translation Using Monolingually-derived Paraphrases.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<contexts>
<context position="30423" citStr="Marton et al., 2009" startWordPosition="4954" endWordPosition="4957"> et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora a necessity. In this study, we have attempted to identify corpora of various degre</context>
</contexts>
<marker>Marton, Callison-Burch, Resnik, 2009</marker>
<rawString>Yuval Marton, Chris Callison-Burch, and Philip Resnik. 2009. Improved Statistical Machine Translation Using Monolingually-derived Paraphrases. In Proceedings of EMNLP, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aur´elien Max</author>
</authors>
<title>Example-Based Paraphrasing for Improved Phrase-Based Statistical Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Cambridge, USA.</location>
<contexts>
<context position="30434" citStr="Max, 2010" startWordPosition="4958" endWordPosition="4959">gh it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora a necessity. In this study, we have attempted to identify corpora of various degrees of seman</context>
</contexts>
<marker>Max, 2010</marker>
<rawString>Aur´elien Max. 2010. Example-Based Paraphrasing for Improved Phrase-Based Statistical Machine Translation. In Proceedings of EMNLP, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Metzler</author>
<author>Eduard Hovy</author>
<author>Chunliang Zhang</author>
</authors>
<title>An empirical evaluation of data-driven paraphrase generation techniques.</title>
<date>2011</date>
<booktitle>In Proceedings of ACLHLT,</booktitle>
<location>Portland, USA.</location>
<contexts>
<context position="29818" citStr="Metzler et al., 2011" startWordPosition="4855" endWordPosition="4859">. To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al.,</context>
</contexts>
<marker>Metzler, Hovy, Zhang, 2011</marker>
<rawString>Donald Metzler, Eduard Hovy, and Chunliang Zhang. 2011. An empirical evaluation of data-driven paraphrase generation techniques. In Proceedings of ACLHLT, Portland, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rani Nelken</author>
<author>Stuart M Shieber</author>
</authors>
<title>Towards robust context-sensitive sentence alignment for monolingual corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<location>Trento, Italy.</location>
<contexts>
<context position="28716" citStr="Nelken and Shieber, 2006" startWordPosition="4684" endWordPosition="4687">ase examples for French (19,427) than for English (12,593). 4 Related work Over the years, paraphrase acquisition and generation have attracted a wealth of research works that are too many to adequatly summarize here: (Madnani and Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several c</context>
</contexts>
<marker>Nelken, Shieber, 2006</marker>
<rawString>Rani Nelken and Stuart M. Shieber. 2006. Towards robust context-sensitive sentence alignment for monolingual corpora. In Proceedings of EACL, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Herman Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="15715" citStr="Och and Ney, 2004" startWordPosition="2532" endWordPosition="2535">escribed in section 3.1. Following (Bouamor et al., 2012), a combination system is used to automatically weight paraphrase pair candidates produced by individual systems using a set of features aiming at recognizing paraphrases, as illustrated on Figure 3. Four individual systems have been used and are described below: the reasons for considering those systems include their free availability, the possibility of using comparable resources when relevant for our two languages, and the specific characteristics of the techniques used. Statistical learning of word alignments (GIZA) The GIZA++ tool (Och and Ney, 2004) computes statistical word alignment models of increasing complexity from parallel corpora. It was run on each monolingual corpus of sentence pairs in both directions, symmetrized alignments were kept and classical phrase extraction heuristics were applied (Koehn et al., 2003), without growing phrases with unaligned tokens. Linguistic knowledge on term variation (FASTR) The FASTR tool (Jacquemin, 1999) spots term variants in large corpora, where variants are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of r</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>Franz Josef Och and Herman Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Syntax-based alignement of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<location>Edmonton, Canada.</location>
<contexts>
<context position="28938" citStr="Pang et al., 2003" startWordPosition="4718" endWordPosition="4721">d Dorr, 2010) presents a complete and upto-date review of the main approaches. Sentential paraphrase collection has been tackled from specific resources increasing the probability of sentences being paraphrases (Dolan et al., 2004; Bernhard and Gurevych, 2008; Wubben et al., 2009), from comparable monolingual corpora (Barzilay and Elhadad, 2003; Fung and Cheung, 2004; Nelken and Shieber, 2006), and even at web scale (Pasc¸a and Dienes, 2005; Bhagat and Ravichandran, 2008). Various techniques have been proposed for paraphrase acquisition from related sentence pairs (Barzilay and McKeown, 2001; Pang et al., 2003) and from bilingual parallel corpora (Bannard and Callison-Burch, 2005; Kok and Brockett, 2010). The issue of corpus construction for developing and evaluating paraphrase acquisition techniques are addressed in (Cohn et al., 2008; Callison-Burch et al., 2008). To the best of our knowledge, this is the first time that a study in paraphrase acquisition is conducted on several corpus types and for 2 languages. Faruqui and Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Altho</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based alignement of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings of NAACL-HLT, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Philadelphia, USA.</location>
<contexts>
<context position="13106" citStr="Papineni et al., 2002" startWordPosition="2107" endWordPosition="2110">terature (e.g. (Culicover, 1968; Vila et al., 2011)), but that the choice of our classes has been primarily motivated by potential subsequent uses of the acquired paraphrases (paraphrases could be annotated as belonging to more than one class). Note also that our experiments will also include results focused on the synonymy class only (cf. Table 5). 8Reusing such types of paraphrases into applications would however often be too strongly context-dependent. Figure 2: Sentence pair average similarities for all corpora for English (left) and French (right) using the cosine of token vectors, BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). 3 Bilingual experiments across corpus types 3.1 Evaluation of paraphrase acquisition We followed the PARAMETRIC methodology described in (Callison-Burch et al., 2008) for assessing the performance of systems on the task of subsentential paraphrase acquisition. In this methodology, a set of paraphrase candidates extracted from a sentence pair is compared with a set of reference paraphrases, obtained through human annotation, by computing usual measures of precision (P) and recall (R). The first value corresponds to the proportion</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings of ACL, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasc¸a</author>
<author>Peter Dienes</author>
</authors>
<title>Aligning Needles in a Haystack: Paraphrase Acquisition Across the Web. In</title>
<date>2005</date>
<booktitle>Proceedings of IJCNLP, Jeju Island,</booktitle>
<location>South</location>
<marker>Pasc¸a, Dienes, 2005</marker>
<rawString>Marius Pasc¸a and Peter Dienes. 2005. Aligning Needles in a Haystack: Paraphrase Acquisition Across the Web. In Proceedings of IJCNLP, Jeju Island, South Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Olivia Buzek</author>
<author>Chang Hu</author>
<author>Yakov Kronrod</author>
<author>Alex Quinn</author>
<author>Benjamin B Bederson</author>
</authors>
<title>Improving translation via targeted paraphrasing.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<location>Cambridge, USA.</location>
<contexts>
<context position="30341" citStr="Resnik et al., 2010" startWordPosition="4941" endWordPosition="4944">s recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for less parallel corpora </context>
</contexts>
<marker>Resnik, Buzek, Hu, Kronrod, Quinn, Bederson, 2010</marker>
<rawString>Philip Resnik, Olivia Buzek, Chang Hu, Yakov Kronrod, Alex Quinn, and Benjamin B. Bederson. 2010. Improving translation via targeted paraphrasing. In Proceedings of EMNLP, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Josh Schroeder</author>
<author>Trevor Cohn</author>
<author>Philipp Koehn</author>
</authors>
<title>Word Lattices for Multi-Source Translation.</title>
<date>2009</date>
<booktitle>In Proceedings of EACL,</booktitle>
<location>Athens, Greece.</location>
<contexts>
<context position="30319" citStr="Schroeder et al., 2009" startWordPosition="4937" endWordPosition="4940">generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential paraphrase acquisition from text pairs. Analoguously to bilingual parallel corpora, which are still to date the most reliable resources for automatic acquisition of sub-sentential translations, monolingual parallel corpora are generally regarded as very appropriate for paraphrase acquisition. However, their low availability makes searching for </context>
</contexts>
<marker>Schroeder, Cohn, Koehn, 2009</marker>
<rawString>Josh Schroeder, Trevor Cohn, and Philipp Koehn. 2009. Word Lattices for Multi-Source Translation. In Proceedings of EACL, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Edit Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of AMTA,</booktitle>
<location>Boston, USA.</location>
<contexts>
<context position="13133" citStr="Snover et al., 2006" startWordPosition="2112" endWordPosition="2115">68; Vila et al., 2011)), but that the choice of our classes has been primarily motivated by potential subsequent uses of the acquired paraphrases (paraphrases could be annotated as belonging to more than one class). Note also that our experiments will also include results focused on the synonymy class only (cf. Table 5). 8Reusing such types of paraphrases into applications would however often be too strongly context-dependent. Figure 2: Sentence pair average similarities for all corpora for English (left) and French (right) using the cosine of token vectors, BLEU (Papineni et al., 2002), TER (Snover et al., 2006) and METEOR (Lavie and Agarwal, 2007). 3 Bilingual experiments across corpus types 3.1 Evaluation of paraphrase acquisition We followed the PARAMETRIC methodology described in (Callison-Burch et al., 2008) for assessing the performance of systems on the task of subsentential paraphrase acquisition. In this methodology, a set of paraphrase candidates extracted from a sentence pair is compared with a set of reference paraphrases, obtained through human annotation, by computing usual measures of precision (P) and recall (R). The first value corresponds to the proportion of paraphrase candidates, </context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie J. Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A Study of Translation Edit Rate with Targeted Human Annotation. In Proceedings of AMTA, Boston, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Nitin Madnani</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>TER-Plus: paraphrase, semantic, and alignment enhancements to Translation Edit Rate.</title>
<date>2010</date>
<journal>Machine Translation,</journal>
<pages>23--2</pages>
<contexts>
<context position="16790" citStr="Snover et al., 2010" startWordPosition="2700" endWordPosition="2703">nts are described through metarules expressing how the morphosyntactic structure of a term variant can be derived from a given term by means of regular expressions on morphosyntactic categories. Paradigmatic variation can also be expressed with constraints between words, imposing that they be of the same morphological or semantic family using existing resources available in our two languages. Variants for all phrases from one sentence of a pair are extracted from the other sentence, and the intersection of the sets for both directions is kept. Edit rate on word sequences (TERp) The TERp tool (Snover et al., 2010) can be used to compute an optimal set of word and phrase edits that can transform one sentence into another one.9 Edit types are parameterized by one or more weights which were optimized towards F-measure by hill climbing with 100 random restarts using the held-out data set consisting of 125 sentence pairs for each corpus type. Translational equivalence (PIVOT) We exploited the paraphrase probability defined by Bannard and Callison-Burch (2005) on bilingual parallel corpora. We used the Europarl corpus10 of parliamentary debates in English and French, consisting of approximately 1.7 million p</context>
</contexts>
<marker>Snover, Madnani, Dorr, Schwartz, 2010</marker>
<rawString>Matthew Snover, Nitin Madnani, Bonnie J. Dorr, and Richard Schwartz. 2010. TER-Plus: paraphrase, semantic, and alignment enhancements to Translation Edit Rate. Machine Translation, 23(2-3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>Building a Multilingual Parallel Subtitle Corpus.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference on Computational Linguistics in the Netherlands,</booktitle>
<location>Leuven, Belgium.</location>
<contexts>
<context position="5118" citStr="Tiedemann, 2007" startWordPosition="817" endWordPosition="819">l clusters first and then selecting from already used clusters to reach the target number of sentence pairs. e.g. It is estimated that the total annual volume of import and export will exceed 9 billion US dollars. H It is anticipated that the annual total foreign trade volume will exceed US$9 billion. SPEECH For English, we used two freely available subtitle files3 of the French movies Le Fabuleux Destin d’Am´elie Poulain and Les Choristes, and for French we used two subtitle files from the Desperate Housewives TV series. We first aligned each parallel corpus using the algorithm described in (Tiedemann, 2007), based on time frames and developed for bilingual subtitles, we then filtered out sentence pairs below a minimal edit distance threshold, and manually removed obvious errors made by the algorithm. e.g. So he uses the photo booths to remind people what he looks like. H He uses those machines to remind the living of his face. SCENE We used the Multiple Video Description Corpus (Chen and Dolan, 2011) obtained from multiple descriptions of short videos. Similarly to what we did for TEXT, we selected sentence pairs from clusters by minimal edit distance above a threshold. An important fact is that</context>
</contexts>
<marker>Tiedemann, 2007</marker>
<rawString>J¨org Tiedemann. 2007. Building a Multilingual Parallel Subtitle Corpus. In Proceedings of the Conference on Computational Linguistics in the Netherlands, Leuven, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marta Vila</author>
<author>M Ant`onia Marti</author>
<author>Horacio Rodriguez</author>
</authors>
<title>Paraphrase Concept and Typology. A Linguistically Based and Computationally Oriented Approach.</title>
<date>2011</date>
<booktitle>Procesamiento del Lenguaje Natural,</booktitle>
<pages>462--3</pages>
<contexts>
<context position="12535" citStr="Vila et al., 2011" startWordPosition="2016" endWordPosition="2019">ignments.7 The main observation here is that phrasal synonymy (e.g. mutual understanding H consensus) is the most present phenomenon. It is also interesting to note that the EVENT corpus type, which is easy to collect on a daily basis, contains reference paraphrases spread over all classes. Lastly, it is expected that paraphrases in the pragmatics class (e.g. police dispatcher H woman) would be difficult to acquire, as this would often rely on document context and costly world knowledge.8 7Note that typologies of paraphrases have already been proposed in the literature (e.g. (Culicover, 1968; Vila et al., 2011)), but that the choice of our classes has been primarily motivated by potential subsequent uses of the acquired paraphrases (paraphrases could be annotated as belonging to more than one class). Note also that our experiments will also include results focused on the synonymy class only (cf. Table 5). 8Reusing such types of paraphrases into applications would however often be too strongly context-dependent. Figure 2: Sentence pair average similarities for all corpora for English (left) and French (right) using the cosine of token vectors, BLEU (Papineni et al., 2002), TER (Snover et al., 2006) a</context>
</contexts>
<marker>Vila, Marti, Rodriguez, 2011</marker>
<rawString>Marta Vila, M. Ant`onia Marti, and Horacio Rodriguez. 2011. Paraphrase Concept and Typology. A Linguistically Based and Computationally Oriented Approach. Procesamiento del Lenguaje Natural, (462-3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sander Wubben</author>
<author>Antal van den Bosch</author>
<author>Emiel Krahmer</author>
<author>Erwin Marsi</author>
</authors>
<title>Clustering and maching headlines for automatic paraphrase acquisition.</title>
<date>2009</date>
<booktitle>In Proceedings of the European Workshop on Natural Language Generation,</booktitle>
<location>Athens, Greece.</location>
<marker>Wubben, van den Bosch, Krahmer, Marsi, 2009</marker>
<rawString>Sander Wubben, Antal van den Bosch, Emiel Krahmer, and Erwin Marsi. 2009. Clustering and maching headlines for automatic paraphrase acquisition. In Proceedings of the European Workshop on Natural Language Generation, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Xiang Lan</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Application-driven Statistical Paraphrase Generation.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP,</booktitle>
<contexts>
<context position="29978" citStr="Zhao et al., 2009" startWordPosition="4879" endWordPosition="4882"> Pad´o (2011) study the acquisition of entailment pairs (premise and hypothesis), with experiments in 3 languages and various domains of newspaper corpora for one language. Although their work is not directly comparable to ours, they report that robustness across domains is difficult to achieve. Laslty, the evaluation of automatically generated paraphrases has recently received some attention (Liu et al., 2010; Chen and Dolan, 2011; Metzler et al., 2011) although it remains a difficult issue. Application-driven paraphrase generation provides indirect means of evaluating paraphrase generation (Zhao et al., 2009). For instance, the field of Statistical Machine Translation has produced works showing both the usefulness of human-produced # ex+ 7,342 2,296 1,784 1,171 SPEECH EVENT SCENE TEXT 49.7 54.3 65.5 56.0 51.1 45.3 42.5 66.2 65.1 66.2 53.5 52.8 54.8 53.7 46.0 53.8 12,593 65.1 56.6 42.7 56.2 19,427 66.6 57.9 21.1 49.3 728 (Schroeder et al., 2009; Resnik et al., 2010) and automatically produced paraphrases (Madnani et al., 2008; Marton et al., 2009; Max, 2010; He et al., 2011) for improving translation performance. 5 Discussion and future work This work has addressed the issue of sub-sentential parap</context>
</contexts>
<marker>Zhao, Lan, Liu, Li, 2009</marker>
<rawString>Shiqi Zhao, Xiang Lan, Ting Liu, and Sheng Li. 2009. Application-driven Statistical Paraphrase Generation. In Proceedings of ACL-IJCNLP, Singapore.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>