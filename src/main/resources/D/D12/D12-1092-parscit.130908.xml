<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998432">
Employing Compositional Semantics and Discourse Consistency in
Chinese Event Extraction
</title>
<author confidence="0.999446">
Peifeng Li, Guodong Zhou, Qiaoming Zhu, Libin Hou
</author>
<affiliation confidence="0.999485">
School of Computer Science &amp; Technology
</affiliation>
<address confidence="0.893634">
Soochow University, Suzhou, 215006, China
</address>
<email confidence="0.961591">
{pfli, gdzhou, qmzhu, 20094227021}@suda.edu.cn
</email>
<sectionHeader confidence="0.981615" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998762">
Current Chinese event extraction systems suffer
much from two problems in trigger
identification: unknown triggers and word
segmentation errors to known triggers. To
resolve these problems, this paper proposes two
novel inference mechanisms to explore special
characteristics in Chinese via compositional
semantics inside Chinese triggers and discourse
consistency between Chinese trigger mentions.
Evaluation on the ACE 2005 Chinese corpus
justifies the effectiveness of our approach over
a strong baseline.
</bodyText>
<sectionHeader confidence="0.995083" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995999875">
Event extraction, a classic information extraction
task, is to identify instances of a predefined event
type and can be typically divided into four subtasks:
trigger identification, trigger type determination,
argument identification and argument role
determination. In the literature, most studies focus
on English event extraction and have achieved
certain success (e.g. Grishman et al., 2005; Ahn,
</bodyText>
<note confidence="0.5858995">
2006; Hardy et al., 2006; Maslennikov and Chua,
2007; Finkel et al., 2005; Ji and Grishman, 2008;
Patwardhan and Riloff, 2009, 2011; Liao and
Grishman 2010; Hong et al., 2011).
</note>
<bodyText confidence="0.964197678571429">
In comparison, there are few successful stories
regarding Chinese event extraction due to special
characteristics in Chinese trigger identification. In
particular, there are two major reasons for the low
performance: unknown triggers 1 and word
segmentation errors to known triggers. Table 1
gives the statistics of unknown triggers and word
segmentation errors to known triggers in both the
1 In this paper, a trigger word/phrase occurring in the training
data is called a known trigger and otherwise, an unknown
trigger.
ACE 2005 Chinese and English corpora2 using 10-
fold cross-validation. In each validation, we leave
10% trigger mentions as the test set and the
remaining ones as the training set. If a mention in
the test set doesn’t occurred in the training set, we
regard it as an unknown trigger. It shows that these
two cases cover almost 30% of Chinese trigger
mentions while this figure reduces to only about
9% in English. It also shows that given the same
number of event mentions, there are 30% more
different triggers in Chinese than that in English.
This justifies the low performance (specifically,
the recall) of a Chinese event extraction system,
which normally extracts those known triggers
occurring in the training data as candidate
instances and uses a classifier to distinguish correct
triggers from wrong ones.
</bodyText>
<table confidence="0.918942833333333">
Language Chinese English
%unknown triggers 33.7% 18.5%
%unknown trigger mentions 20.9% 8.9%
%word segmentation errors 8.7% 0%
to known trigger mentions
#triggers 763 586
</table>
<tableCaption confidence="0.8893015">
Table 1. Statistics: a comparison between Chinese and
English event extraction with regard to unknown
triggers and word segmentation errors to known triggers.
Note that word segmentation only applies to Chinese.
</tableCaption>
<bodyText confidence="0.999760153846154">
In this paper, we propose two novel inference
mechanisms to Chinese trigger identification by
employing compositional semantics inside Chinese
triggers and discourse consistency between
Chinese trigger mentions.
The first mechanism is motivated by the
compositional nature of Chinese words, whose
semantics can be often determined by the
component characters. Hence, it is natural to infer
2 The whole Chinese ACE corpus has about 3300 event
mentions. For the sake of fair comparison, we choose the same
number of event mentions from the English corpus as the
cross-validation data.
</bodyText>
<page confidence="0.542508">
1006
</page>
<bodyText confidence="0.999897111111111">
unknown triggers by employing compositional
semantics inside Chinese triggers.
The second mechanism is enlightened by the
wide use of discourse consistency in natural
languages, particularly for Chinese, due to its
discourse-driven nature (Zhu, 1980). Very often,
distinguishing true trigger mentions from pseudo
ones is only possible with contextual information.
The rest of this paper is organized as follows.
Section 2 overviews the related work. Section 3
introduces a state-of-the-art baseline system for
Chinese event extraction. Sections 4 and 5 describe
two novel inference mechanisms to Chinese trigger
identification by employing compositional
semantics inside Chinese triggers and discourse
consistency between Chinese trigger mentions.
Section 6 presents the experimental results. Section
7 concludes the paper and points out future work.
</bodyText>
<sectionHeader confidence="0.978361" genericHeader="introduction">
2 Related Work
</sectionHeader>
<note confidence="0.6499667">
Almost all the existing studies on event extraction
concern English. While earlier studies focus on
sentence-level extraction (Grishman et al., 2005;
Ahn, 2006; Hardy et al., 2006), later ones turn to
employ high-level information, such as document
(Maslennikov and Chua, 2007; Finkel et al., 2005;
Patwardhan and Riloff, 2009), cross-document (Ji
and Grishman, 2008), cross-event (Liao and
Grishman, 2010; Gupta and Ji, 2009) and cross-
entity (Hong et al., 2011) information.
</note>
<subsectionHeader confidence="0.911944">
2.1 Chinese Event Extraction
</subsectionHeader>
<bodyText confidence="0.99988548">
Compared with tremendous efforts in English
event extraction, there are only a few studies on
Chinese event extraction.
Tan et al. (2008) modeled event extraction as a
pipeline of classification tasks. Specially, they used
a local feature selection approach to ensure the
performance of trigger classification (trigger
identification + trigger type determination) and
applied multiple levels of patterns to improve the
coverage of patterns in argument classification
(argument identification + argument role
determination). Chen and Ji (2009a) proposed a
bootstrapping framework, which exploited extra
information captured by an English event
extraction system. Chen and Ji (2009b) applied
various kinds of lexical, syntactic and semantic
features to address the specific issues in Chinese.
They also constructed a global errata table to
record the inconsistency in the training set and
used it to correct the inconsistency in the test set. Ji
(2009) extracted cross-lingual predicate clusters
using bilingual parallel corpora and a cross-lingual
information extraction system, and then used the
derived clusters to improve the performance of
Chinese event extraction.
</bodyText>
<subsectionHeader confidence="0.999334">
2.2 Compositional Semantics
</subsectionHeader>
<bodyText confidence="0.999880866666667">
Almost all the related studies on compositional
semantics focus on how to combine words together
to convey complex meanings, such as semantic
parser (Zettlemoyer and Collins, 2007; Wong and
Mooney, 2007; Liang et al., 2011). However, the
compositional semantics mentioned in this paper is
more fined-grained and focuses on how to
construct Chinese characters into a word and mine
the semantics of words from the word structures,
especially of verbs as event triggers.
To our knowledge, there is only one paper
associated with compositional semantics inside
Chinese words. Li (2011) discussed the internal
structures inside Chinese nouns and used it in word
segmentation.
</bodyText>
<subsectionHeader confidence="0.999503">
2.3 Discourse Consistency
</subsectionHeader>
<bodyText confidence="0.999583958333333">
Discourse consistency is an important hypothesis
in natural languages and has been applied to many
natural language processing applications, such as
named entity recognition and coreference
resolution. Specially, several studies have
successfully incorporated trigger or entity
consistency constraint into event extraction.
Yarowsky (1995) and Yangarber et al.
(Yangarber and Jokipii, 2005; Yangarber et al.,
2007) applied cross-document inference to refine
local extraction results for disease name, location
and start/end time. Mann (2007) proposed some
specific inference rules to improve extraction of
personal information. Ji and Grishman (2008)
employed a rule-based approach to propagate
consistent triggers and arguments across topic-
related documents. Gupta and Ji (2009) used a
similar approach to recover implicit time
information for events. Liao and Grishman (2011)
also used a similar approach and a self-training
strategy to extract events. Liao and Grishman
(2010) employed cross-event consistency
information to improve sentence-level event
extraction. Hong et al. (2011) regarded entity type
</bodyText>
<page confidence="0.600979">
1007
</page>
<bodyText confidence="0.998154666666667">
consistency as a key feature to predict event
mentions and adopted this inference method to
improve the traditional event extraction system.
</bodyText>
<sectionHeader confidence="0.997541" genericHeader="method">
3 Baseline
</sectionHeader>
<bodyText confidence="0.999357615384616">
As a baseline, we re-implement a state-of-the-art
system, which consists of four typical components
(trigger identification, trigger type determination,
argument identification and argument role
determination), in a pipeline way and employ the
same set of features as described in Chen and Ji
(2009b).
Besides, the Maximum-Entropy (ME) model is
employed to train individual component classifiers
for the above four components. During testing,
each word in the test set is first scanned for
instances of known triggers from the training set.
When an instance is found, the trigger identifier is
applied to distinguish true trigger mentions from
pseudo ones. If true, the trigger type determiner is
then applied to recognize its event type. For any
entity mentions in the sentence, the argument
identifier is employed to assign possible arguments
to them afterwards. Finally, the argument role
determiner is introduced to assign a role to each
argument.
One problem with Chen and Ji’s system is its
ignoring effective long-distance features. In order
to resolve this problem and provide a stronger
baseline, we introduce more refined and
dependency features in four components:
</bodyText>
<listItem confidence="0.999223684210526">
➢ Trigger Identification and Trigger Type
Determination: 1) syntactic features: path to
the root of the governing clause, 2) nearest
entity information: entity type of left
syntactically/physically nearest entity to the
trigger + entity, entity type of right
syntactically/physically nearest entity to the
trigger mention in the sentence + entity; 3)
dependency features: the subject and the object
of the trigger when they are entities.
➢ Argument Identification and Argument Role
Determination: 1) basic features: POS of
trigger; 2) neighboring words: left neighboring
word of the entity + its POS, right neighbor
word of the entity + its POS, left neighbor word
of the trigger + its POS, right neighbor word of
the trigger + its POS; 3) dependency feature:
dependency path from the entity to the trigger;
4) semantic role features: Arg0 and Arg1 which
</listItem>
<bodyText confidence="0.581655">
tagged by semantic role labeling tool (Li, et al.,
2010).
</bodyText>
<subsectionHeader confidence="0.998578">
3.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.82996397368421">
The ACE 2005 Chinese corpus (only the training
data is available) is used in all our experiments.
The corpus contains 633 Chinese documents
annotated with 8 predefined event types and 33
predefined subtypes. Similar to previous studies,
we treat these subtypes simply as 33 separate event
types and do not consider the hierarchical structure
among them.
Following Chen and Ji (2009b), we randomly
select 567 documents as the training set and the
remaining 66 documents as the test set. Besides,
we reserve 33 documents in the training set as the
development set, and follow the setting of ACE
diagnostic tasks and use the ground truth entities,
times and values for our training and testing.
For evaluation, we follow the standards as
defined in Ji (2009):
➢ A trigger is correctly identified if its position in
the document matches a reference trigger;
➢ A trigger type is correctly determined if its
event type and position in the document match
a reference trigger;
➢ An argument is correctly identified if its
involved event type and position in the
document match any of the reference argument
mentions;
➢ An argument role is correctly determined if its
involved event type, position in the document,
and role match any of the reference argument
mentions.
Finally, all sentences in the corpus are divided
into words using a word segmentation tool
ICTCLAS3 with all entities annotated in the corpus
kept. Besides, we use Stanford Parser (Levy and
Manning, 2003, Chang, et al., 2009) to create the
constituent and dependency parse trees and employ
the ME model to train individual component
classifiers.
</bodyText>
<subsectionHeader confidence="0.99927">
3.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.9999284">
Table 2 and 3 show the Precision (P), Recall (R)
and F1-Measure (F) on the held-out test set. It
shows that our baseline system outperforms Chen
and Ji (2009b) by 1.8, 2.2, 3.9 and 2.3 in F1-
measure on trigger identification, trigger type
</bodyText>
<equation confidence="0.544459">
3 http://ictclas.org/
1008
</equation>
<bodyText confidence="0.9981092">
determination, argument identification and
argument role determination, respectively, with
both gains in precision and recall. This is simply
due to contribution of the newly-added refined and
dependency features.
</bodyText>
<table confidence="0.999504">
Performance Trigger Trigger Type
System Identification Determination
P(%) R(%) F P(%) R(%) F
Chen and Ji 71.5 51.2 59.7 66.5 47.7 55.6
(2009b)
Our Baseline 75.2 52.0 61.5 70.3 49.0 57.8
</table>
<tableCaption confidence="0.909715">
Table 2. Performance of trigger identification and
trigger type determination
</tableCaption>
<table confidence="0.999916333333333">
Performance Argument Argument Role
System Identification Determination
P(%) R(%) F P(%) R(%) F
Chen and Ji 56.1 38.2 45.4 53.1 36.2 43.1
(2009b)
Our Baseline 58.4 42.7 49.3 55.2 38.6 45.4
</table>
<tableCaption confidence="0.9886165">
Table 3. Performance of argument identification and
argument role determination
</tableCaption>
<bodyText confidence="0.99996315">
For our baseline system, given the small
performance gaps between trigger identification
and trigger type determination (3.7 in F1-measure:
61.5 vs. 57.8) and between argument identification
and argument role determination (3.9 in F1-
measure: 49.3 vs. 45.4), the performance
bottlenecks of our baseline system mainly exist in
trigger identification and argument identification,
particularly for the former one. While argument
identification has the performance gap of 8.5 in
F1-measure compared to trigger type
determination (49.3 vs. 57.8), the former one,
trigger identification, can only achieve the
performance of 61.5 in F1-measure (in particular
the recall with only 52.0). In this paper, we will
focus on trigger identification to improve its
performance, particularly for the recall, via
compositional semantics inside Chinese triggers
and discourse consistency between Chinese trigger
mentions.
</bodyText>
<sectionHeader confidence="0.828069" genericHeader="method">
4 Employing Compositional Semantics
inside Chinese Triggers
</sectionHeader>
<bodyText confidence="0.999958538461539">
Language is perhaps the only communicative
system in nature, which compositionally builds
structured meanings from smaller pieces, and this
compositionality is the cognitive mechanism that
allows for what Humboldt called language’s
“infinite use of finite means.” As usual, the lexical
semantics is the smallest piece in most Chinese
language processing applications. In this section,
we introduce a more fine-grained semantics - the
compositional semantics in Chinese verb structure
- and unveil its effect and usage in Chinese
language processing by employing it into Chinese
event extraction.
</bodyText>
<subsectionHeader confidence="0.9811825">
4.1 Compositional Semantics inside Chinese
Triggers
</subsectionHeader>
<bodyText confidence="0.999404227272727">
In English, a component character is just the basic
unit to form a word instead of a semantics unit. In
comparison, almost all Chinese characters have
their own meanings and can be formed as SCWs
(Single Character Words) themselves. If a Chinese
word contains more than one character, its
meaning can be often inferred from the meanings
of its component characters (Yuan, 1998). Actually,
it is the normal way of understanding a new
Chinese word in everyday life of a Chinese native
speaker. A general method to this problem is to
systematically explore the morphological
structures in Chinese words. In this paper,
compositional semantics provides a simple but
effective compromise to the general method and
we leave the general method in the future work.
Table 4 shows samples of such compositional
semantics in Chinese words. For example, “�h,”
is composed of two characters: “�” and “h,”
which have their own semantics and the semantics
of “ � h, ” comes from that of its component
characters “ ” and “h,”.
</bodyText>
<table confidence="0.9942334">
Words Characters
h, (interview4) � (meet) h,(meet)
r, * (shoot and kill) r, (shoot) * (kill)
*fO(come) * (come) fO (to)
fAfA (private letter) fA(private) fA(letter)
</table>
<tableCaption confidence="0.992154">
Table 4. Examples of compositional semantics in
Chinese words
</tableCaption>
<bodyText confidence="0.99537525">
Therefore, it is natural to infer unknown triggers
by employing compositional semantics inside
Chinese triggers. Take following two sentences as
examples:
</bodyText>
<figure confidence="0.556701428571429">
(1) 4 -;*tRfA 1Cq&apos;f)jo(Known trigger)
4 Most Chinese words have more than one sense. Here, we
just give the one when it acts as a trigger.
1009
(Four students were scratched by the glass.)
(2) 1 名乘客被刺伤。(Unknown trigger)
(A passenger was stabbed.)
</figure>
<bodyText confidence="0.999646666666666">
where “划伤” is a known trigger and “刺伤” is an
unknown one.
In above examples, the semantics of “划伤”
(injure by scratching) can be largely determined
from those of its component characters “ 划 ”
(scratch) and “伤” (injure) while the semantics of
“ 刺 伤 ” (injure by stabbing) from those of its
component characters “刺” (stab) and “伤” (injure).
Since these two triggers have similar internal
structures, we can easily infer that “刺伤” is a
trigger of injure event if “划伤” is known as a
trigger of injure event. Similarly, we can infer
more triggers for injure event, such as “灼伤”
(injure by burning), “撞伤T (injure by hitting), “压
伤 ” (injure by pressing), all with component
character “伤” (injure) as the head and the other
component character as the way of causing injury.
Since most triggers in Chinese event extraction
are verbs 5 , we focus on the compositional
semantics in the verb structure. Statistics on the
training set shows that 3.3% triggers (e.g. “公开
信” (open letter), “事件” (event), “病情” (patient&apos;s
condition), etc.) don’t contain a BV and all of them
are nouns. Normally, almost all verbs contain one
or more single-character verbs as the basic element
to construct a verb (we call it basic verb, shorted as
BV) and the semantics of such a verb thus can be
inferred from its BV. There are some studies on the
Chinese verb structure in linguistics. However,
their structures are much more complex and there
are no annotated corpora available. We define
following six main structures from our empirical
observations:
</bodyText>
<listItem confidence="0.955014625">
(1) BV (e.g. “看” (see), “杀” (kill))
(2) BV + verb (e.g. “会见” (meet))
(3) verb + BV (e.g. “解雇” (fire) )
(4) BV + complementation (e.g. “杀了” (kill) )
(5) BV + noun/adj. (e.g. “回家” (go to home))
(6) noun/adj. +BV (e.g. “枪击” (shoot using
gun)).
5 Actually, in the ACE 2005 Chinese (training) corpus, more
</listItem>
<bodyText confidence="0.97892475">
than 90% of triggers are either verbs al or verbal nouns (those
verbs which act as nouns). For simplicity, we don’t
differentiate these two types in this paper.
From above structures, a BV plays an important
role in the verb structure and most of semantics of
a verb can be interred from its contained BV and
two words normally have very similar semantics if
they have the same BV (e.g. “会见” (meet) and
“会晤” (meet)). Actually, sometime the verb can
be shortened to its contained BV (e.g. “我见王教
授 ” and “ 我 会 见 王 教 授 ” have the same
semantics.).
</bodyText>
<subsectionHeader confidence="0.708358">
4.2 Inferring via Compositional Semantics
inside Chinese Triggers
</subsectionHeader>
<bodyText confidence="0.999541">
Here a simple rule is employed to infer triggers via
compositional semantics inside Chinese triggers: a
verb is a trigger if it contains a BV which occurs
as a known trigger or is contained in a known
trigger. Table 5 shows the distribution of the set of
triggers (contains the same BV 6 ) classified by
number of triggers.
From Table 5, we can find out that 85.3% of
BVs occur in more than one trigger and 56.2% of
them in more than 4 triggers. As for trigger
mentions, these percentages become 89.1% and
65.2% respectively. A extreme example is that
85.2% (75/88) of triggers of Trial-Hearing event
mentions contain “审” (trial) and 85.4% (117/138)
of triggers of injure event mentions contains “伤”
(injure).
</bodyText>
<table confidence="0.999156833333333">
Number Distribution over Distribution over
Triggers Trigger Mentions
1 14.7% 10.9%
2~4 29.1% 23.9%
5~9 28.1% 32.9%
&gt;=10 28.1% 32.3%
</table>
<tableCaption confidence="0.9967665">
Table 5. Distribution of BVs in the number of
triggers/trigger mentions
</tableCaption>
<bodyText confidence="0.985715">
In this paper, the inference is done as follows:
</bodyText>
<listItem confidence="0.777354571428571">
➢ Add all single-character triggers into the BV set
if it’s a verb;
➢ Split all other triggers in the training set into a
set of single characters and include all single
characters into the BV set if it’s a verb;
➢ For each word in the test set, it is identified as a
trigger if it contains a BV.
</listItem>
<bodyText confidence="0.9938095">
It is worthwhile to note that such inference
works for unknown triggers and word
</bodyText>
<footnote confidence="0.443107">
6 We didn’t tag BVs in the training set and regards all single-
character verbs contained in triggers as BVs.
</footnote>
<page confidence="0.407339">
1010
</page>
<bodyText confidence="0.893068">
Statistics on the training set shows that this rule
applies at 95.5% of cases.
segmentation errors to known triggers since in both
cases, their BVs will always exist as either a SCW
or a component of a word.
</bodyText>
<subsectionHeader confidence="0.996462">
4.3 Noise Filtering
</subsectionHeader>
<bodyText confidence="0.9999625">
One problem with above inference is that while it
is able to recover some true triggers and increase
the recall, it may introduce many pseudo ones and
harm the precision. To filter out those pseudo
triggers, we propose following rules according to
our intuition and statistics over the training set.
</bodyText>
<subsectionHeader confidence="0.8709">
Non-trigger Filtering
</subsectionHeader>
<bodyText confidence="0.996365363636363">
A Chinese word will not be a trigger if it
appears in the training set but never trigger an
event. Statistics on the training set shows that this
rule applies at 99.7% of cases.
POS filtering
A Chinese word will not be a trigger if it has a
different POS from that of the same known
trigger or similar known triggers 7 in the
training set. In Chinese, a single-character verb
has very high probability of composing words (e.g.
“到” (come), “为” (act as), “并” (combine), etc)
with different POS from the single-character verb
itself, such as preposition (e.g. “ 为 了 ” (for)),
conjunction (e.g. “并且” (and)), etc. Statistics on
the training set shows that this rule applies at
97.3% of cases.
Verb structure filtering
A Chinese word will not be a trigger if its verb
structure is different from that of the same
known trigger or similar known triggers in the
training set. Figure 1 shows different distributions
of three BVs over six verb structures as described
in subsection 4.1. For example, we can find that all
triggers including “解” (unbind) (e.g. “解聘” (fire),
“解雇” (fire), “解散” (disband)) just have one verb
structure (BV + verb) and those of “杀” (kill) have
4 structures. Obviously, we can use such
distribution information to filter out pseudo
triggers. For example, although both word “劝解”
(console) and “分解” (decompose) are constructed
form verb “解”, their verb structure (verb + BV)
does not appear in the training set. Therefore, they
will be filtered our via verb structure filtering.
</bodyText>
<figure confidence="0.8207485">
7 Similar triggers are those ones which have the same BV and
verb structure.
解
审
</figure>
<figureCaption confidence="0.931813666666667">
Figure 1. Distribution of three BVs (“解” (unbind), “审”
(trial) and “杀” (kill)) over six verb structures in
constructing triggers
</figureCaption>
<sectionHeader confidence="0.791222" genericHeader="method">
5 Employing Discourse Consistency
between Chinese Trigger Mentions
</sectionHeader>
<bodyText confidence="0.999981392857143">
Chinese event extraction may suffer much from the
errors propagated from upstream processing such
as part-of-speech tagging and parsing, especially
word segmentation. To alleviate word
segmentation errors to known triggers, Chen and Ji
(2009b) constructed a global errata table to record
the inconsistency in the training set and proved its
effectiveness. In this paper, a merge and split
method is applied to recover those known triggers.
In this way, word segmentation errors can be
alleviated to certain extent.
For unknown triggers, we can merge two or
more neighboring short words or single characters
as a trigger candidate. In this paper, for each
single-character verb in a document after word
segmentation, this single-character verb can be
merged with either previous SCW or next SCW to
form a trigger candidate if this single-character
verb has occurred in the training set with the same
verb structure.
Given above recovered triggers for both known
and unknown triggers, the key issue here is how to
distinguish true triggers from pseudo ones. In this
paper, we employ discourse consistency between
Chinese trigger mentions for Chinese event
extraction. Previous studies on English event
extraction have proved the effectiveness of both
cross-entity and cross-document consistency.
</bodyText>
<subsectionHeader confidence="0.983792">
5.1 Discourse Consistency between Chinese
Trigger Mentions
</subsectionHeader>
<bodyText confidence="0.981117">
As a discourse-driven language, the syntax of
</bodyText>
<figure confidence="0.997231833333333">
1
0.8
0.6
0.4
0.2
0
</figure>
<page confidence="0.5166005">
杀
1011
</page>
<bodyText confidence="0.9991625">
Chinese is not as strict as English and sometime
we must infer from the discourse-level information
to understand the meaning of a sentence. Kim
(2000) compared the use of overt subjects in
English and Chinese and he found that overt
subjects occupy over 96% in English, while this
percentage drops to only 64% in Chinese.
Similarly, argument missing is another issue in
Chinese event extraction and almost 55% of
arguments are missing in the ACE 2005 Chinese
corpus. Normally, using a feature-based approach
to distinguish true triggers from pseudo ones is
very difficult from the sentence level if some of
related arguments are missing from the trigger-
occurring sentence. Take following two contingent
sentences as examples:
</bodyText>
<figure confidence="0.4100105">
(3) 美国 与北韩 3
(The United States and the Democratic
People&apos;s Republic of Korea finished missile
talks in Kuala Lumpur.)
(4) 会谈的气氛严肃。
(The talks are serious.)
</figure>
<bodyText confidence="0.9966155">
While it is relatively easy to determine that
mention “会谈” in sentence (3) indicates a meet
event from the contained information in itself
(there are many entities, such as agents, time and
place in the sentence) and difficult to determine
that mention “会谈” in sentence (4) is a meet event
from the contained information in itself, we can
easily infer from sentence (3) that sentence (4) also
indicates a meet event, using discourse consistency:
if one instance of a word is a trigger mention, other
instances in the same discourse will be a trigger
mention with high probability.
</bodyText>
<table confidence="0.988945333333333">
Language Discourse-based Instance-based
English 70.2% 87.5%
Chinese 90.5% 95.4%
</table>
<tableCaption confidence="0.997398">
Table 6. Comparison of discourse consistency between
Chinese and English trigger mentions
</tableCaption>
<bodyText confidence="0.992624076923077">
Table 6 compares the probabilities of discourse
consistency between Chinese and English trigger
mentions in the ACE 2005 Chinese and English
corpora. A trigger may appear many times in a
discourse. It’s considered discourse-consistent
when all the appearances of a trigger have the
same event type while instance-based consistency
refers to pair-wired cases. It shows that within the
discourse, there is a strong consistency in both
Chinese and English between trigger mentions: if
one instance of a word is a trigger, other instances
in the same discourse will be a trigger of the same
event type with very high probability.
</bodyText>
<figure confidence="0.9942765">
1
0.95
0.9
0.85
</figure>
<figureCaption confidence="0.9936355">
Figure 2. Probabilities of discourse-level consistency of
top 10 frequent triggers
</figureCaption>
<bodyText confidence="0.999965166666667">
It also shows that discourse consistency in
Chinese triggers holds much more likely than the
English counterpart. Figure 2 give the probabilities
of discourse-level consistency of top 10 frequent
triggers, which occupy 18% of event mentions in
the ACE 2005 Chinese corpus.
</bodyText>
<subsectionHeader confidence="0.929628">
5.2 Inference via Discourse Consistency
between Chinese Trigger Mentions
</subsectionHeader>
<bodyText confidence="0.909965538461539">
Given a discourse and different mentions of a
trigger returned by the trigger identifier, we can
simply accept those mentions with high probability
as true mentions of the trigger and discard those
with low probability8. However, for those mentions
in-between, an additional discourse-level trigger
identifier is further employed to determine whether
a trigger mention is true or not from the discourse
level by augmenting the normal trigger identifier
with several features to explore the consistency
information between trigger mentions in the
discourse (first three features) and the related
information returned from the trigger type
identifier (last two features).
➢ Probability of the discourse consistency of the
candidate trigger mention in the training set. If
it doesn’t exist in the training set, we infer its
probability from that of all of its similar triggers
➢ Number of candidate trigger mentions being a
trigger in the same discourse via trigger
identification
➢ Number of candidate trigger mentions being a
non-trigger in the same discourse via trigger
identification
8 The high and low probability thresholds are fine-tuned to
95% and 5% respectively, using the development set.
</bodyText>
<page confidence="0.751651">
1012
</page>
<bodyText confidence="0.935501">
➢ Event type of candidate trigger mention via
trigger type determination
➢ Confidence of trigger type determination
</bodyText>
<sectionHeader confidence="0.99728" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.9999416">
In this section, we evaluate our two inference
mechanisms in Chinese trigger identification and
its application to overall Chinese event extraction,
using the same experimental settings as described
in Subsection 3.1.
</bodyText>
<subsectionHeader confidence="0.999755">
6.1 Chinese Trigger Identification
</subsectionHeader>
<bodyText confidence="0.997752">
Table 7 shows the impact of compositional
semantics in trigger identification. Here, the
baseline just extracts those triggers occurring in the
training data. It justifies the effectiveness of our
compositional semantics-based inference
mechanism in recovering true triggers and its three
filtering rules in removing pseudo triggers.
</bodyText>
<table confidence="0.998547333333333">
Numbers Triggers Non-triggers
Approaches
Baseline 266 629
+Compositional semantics 334 1885
without filtering
+ Non-trigger filtering 328 1062
+ POS filtering 325 974
+ Verb structure filtering 302 444
Gold 367 -
</table>
<tableCaption confidence="0.8548065">
Table 7. Impact of compositional semantics in trigger
identification
</tableCaption>
<figure confidence="0.53570725">
01
2
3
04
</figure>
<bodyText confidence="0.9991675">
To reduce those pseudo triggers after above
inference process, three rules are introduced.
The first rule, the non-trigger filtering rule,
filters out those pseudo ones in the test set which
do not frequently occur as trigger mentions in the
training set. In particular, to keep true triggers in
our candidate set as many as possible, we just filter
out those candidates which occur as non-triggers
more than 5 times in the training set according to
our validation on the development set. Table 7
shows that 43.7% (823) of pseudo triggers are
filtered out while only 1.8% (6) of true ones is
wrongly filtered out.
The second rule, the POS filtering rule, just
filters out 8.3% (88) of pseudo triggers, due to
POS errors in word segmentation and constituent
parsing (e.g. 9.4% of candidate triggers have
wrong POS tags in the development set.). Manual
inspection shows that if we correct those wrong
POS tags, that percentage will be increased to
14.5%.
The third rule, the verb structure filtering rule, is
deployed in following steps: 1) keeping all
candidates if they act as a trigger in the training set;
2) if the candidate is a SCW, removing it when it
does not occur as a BV in any triggers in the
training set; 3) if the candidate is not a SCW,
calculating the condition probability of its similar
trigger words as triggers in the training set9 and
then deleting all candidates whose conditional
probabilities are less than a threshold 0 , which is
fine-tuned to 0.5. Figure 3 shows the effect on
precision, recall and F1-measure of varying the
threshold0 on the development set.
</bodyText>
<figureCaption confidence="0.952405">
Figure 3. Effect of threshold 0 on the development
</figureCaption>
<table confidence="0.981057615384615">
set
Performance Trigger Identification
System
P(%) R(%) F
Baseline 75.2 52.0 61.5
+Compositional semantics 34.8 66.8 45.8
without filtering
+ Non-trigger filtering 49.4 66.5 56.7
+ POS filtering 50.2 65.9 57.0
+ Verb structure filtering 73.5 e 67.4
Iin
62.1
+Discourse consistency 79.3 63.5 70.5
</table>
<tableCaption confidence="0.9449025">
Table 8. Contribution to Chinese triggers identification
(incremental)
</tableCaption>
<bodyText confidence="0.9980928">
Table 8 shows the contribution of employing
compositional semantics and discourse consistency
to trigger identification on the held-out test set. We
can find out that our approach dramatically
enhances F1-measure by 9.0 units, largely due to a
dramatic increase of 11.5% in recall, benefiting
from both compositional semantics and discourse
consistency mechanisms. We expect that the
precision will also increase since our filtering
approach successfully filters out almost 30% more
</bodyText>
<figure confidence="0.975987352941176">
9 If there are more than one BV in a candidate, we calculate
the average one.
0.8
0.7
0.6
0.5
P
R
F
0
5
6
7
7
U
O
1013
</figure>
<bodyText confidence="0.999463071428571">
non-triggers and the number of non-trigger
mentions is less than that of the baseline.
Unfortunately, the resulting set of 444 non-trigger
mentions (after all filtering) is not a subset of
original 629 non-trigger ones. Our observation
shows that our compositional semantics inference
adds almost 10% new non-triggers into candidates
which are very hard to distinguish.
Table 8 also justifies the impact of the discourse
consistency between trigger mentions in trigger
identification and the effect of the additional
discourse-level trigger identifier, with a big gain of
5.8% in precision and a small gain of 1.4% in
recall.
</bodyText>
<subsectionHeader confidence="0.996814">
6.2 Chinese Event Extraction
</subsectionHeader>
<bodyText confidence="0.998939055555556">
Table 9 shows the contribution of trigger
identification with compositional semantics and
discourse consistency to overall event extraction
on the held-out test set. In addition, we also report
the performance of two human annotators (The
human annotator 1 is a first year postgraduate
student with no background to Chinese event
extraction while the human annotator 2 is a third
year postgraduate student working on Chinese
event extraction) on 33 texts (a subset of the held-
out test set). From the results presented in Table 9,
we can find that our approach can improve the F1-
measure for trigger identification by 9.0 units,
trigger type determination by 9.1 units, argument
identification by 6.0 units and argument role
determination (i.e. overall event extraction) by 5.4
units, largely due to the dramatic increase in recall
of 11.5%, 11.2%, 7.5% and 7.2%.
</bodyText>
<table confidence="0.999438555555555">
Performance Trigger Trigger Type Argument Argument Role
System/Human Identification Determination Identification Determination
P(%) R(%) F P(%) R(%) F P(%) R(%) F P(%) R(%) F
Our Baseline 75.2 52.0 61.5 70.3 49.0 57.8 58.4 42.7 49.3 55.2 38.6 45.4
+Compositional semantics 73.5 62.1 67.4 70.2 59.1 64.2 58.0 48.9 53.0 54.7 44.5 49.1
+Discourse consistency 79.3 63.5 70.5 75.2 60.2 66.9 61.6 50.2 55.3 56.9 45.8 50.8
Human annotator1(blind) 63.3 62.9 63.1 61.7 59.5 60.6 64.6 54.1 58.9 60.9 48.2 53.8
Human annotator2(familiar) 72.6 74.3 73.4 69.1 70.2 69.6 71.5 65.9 68.6 66.4 54.6 59.9
Inter-Annotator Agreement 45.8 42.9 44.3 45.3 42.5 43.8 60.4 49.7 54.5 55.1 45.9 50.1
</table>
<tableCaption confidence="0.999205">
Table 9: Overall contribution to Chinese event extraction
</tableCaption>
<bodyText confidence="0.99997975862069">
In addition, the results of two annotators show
that Chinese event extraction is really challenging
even for a well-educated human being. As shown
in Table 9, the inter-annotator agreement on trigger
identification and trigger type determination is
even less than 45%. Although this figure is very
low, it is not surprising: the results on the English
ACE 2005 corpus show that the inter-annotator
agreement on trigger identification is only about
40% (Ji and Grishman, 2008). Detailed analysis
shows that a human annotator tends to make more
mistakes in trigger identification for two reasons.
The first reason is that a human annotator always
misses some event mentions when a sentence
contains more than one event mention. The second
reason is that it is hard to identify an event mention
due to the failure of following specified annotation
guidelines, as mentioned in Ji and Grishman
(2008). Table 9 also shows the performance gaps
of human annotators between trigger identification
and trigger type determination is very small (2.5%
and 3.8% in F1-measure). It ensures that trigger
identification is the most important step in Chinese
event extraction for a human being. For human
annotators, it’s much easier to determine the event
type of a trigger, identify its arguments and
determine the role of each argument, all with more
than 90% in accuracy, once a trigger is identified
correctly.
</bodyText>
<subsectionHeader confidence="0.959724">
6.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999980461538462">
Compared with English, the word structures in
Chinese are much more complex and diverse,
causing a lot of troubles in Chinese language
processing. We ensure that compositional
semantics in Chinese words is very useful for
many Chinese language processing applications,
such as machine translation, semantic parser, etc.
For example, many actions (e.g. “砍” (hack), “咬”
(bite), “M” (kick), etc) can combine with “伤”
(injure) to form words and most of those words
have similar semantics. The results in table 8 show
its contribution in Chinese event extraction.
Although our approach is simple, the result is
</bodyText>
<page confidence="0.56584">
1014
</page>
<bodyText confidence="0.9999374">
promising enough for further efforts in this
direction.
This paper shows that the compositional
semantics in the verb structure provides an ideal
way to expand the coverage of triggers. As a
discourse-driven language, ellipsis is very common
in Chinese, causing inference from the discourse-
level information is a fundamental requirement to
understand the meaning of a clause, sentence or
discourse.
</bodyText>
<sectionHeader confidence="0.996749" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999743111111111">
In this paper we propose two novel inference
mechanisms to Chinese trigger identification. In
particular, compositional semantics inside Chinese
triggers and discourse consistency between
Chinese trigger mentions are used to resolve two
critical issues in Chinese trigger identification:
unknown triggers and word segmentation errors to
known triggers. We give good reasons why this
should be done, and present effective methods how
this could be done. It shows that such novel
inference mechanisms for Chinese event extraction
are linguistically justified and pragmatically
beneficial to real world applications.
In future work, we will focus on how to
introduce the discourse information into the
individual classifiers to capture those long-distance
features and joint learning of subtasks in Chinese
event extraction.
</bodyText>
<sectionHeader confidence="0.995492" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9956435">
The authors would like to thank three anonymous
reviewers for their comments on this paper. This
research was supported by the National Natural
Science Foundation of China under Grant No.
61070123 and No. 90920004, the National 863
Project of China under Grant No. 2012AA011102.
</bodyText>
<sectionHeader confidence="0.994766" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999137525">
David Ahn. 2006. The Stages of Event Extraction. In
Proc. COLING/ACL 2006 Workshop on Annotating
and Reasoning about Time and Events. Pages 1-8,
Sydney, Australia.
Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and
Christopher Manning. 2009. Discriminative
Reordering with Chinese Grammatical Relations
Features. In Proc. Third Workshop on Syntax and
Structure in Statistical Translation, pages 51-59.
Zheng Chen and Heng Ji. 2009a. Can One Language
Bootstrap the Other: A Case Study on Event
Extraction. In Proc. NAACL HLT Workshop on
Semi-supervised Learning for Natural Language
Processing, pages 66-74, Boulder, Colorado.
Zheng Chen and Heng Ji. 2009b. Language Specific
Issue and Feature Exploration in Chinese Event
Extraction. In Proc. NAACL HLT 2009, pages 209-
212, Boulder, CO.
Jenny Rose Finkel, Trond Grenager and Christopher
Manning. 2005. Incorporating Non-local
Information into Information Extraction Systems by
Gibbs Sampling. In Proc. ACL 2005, pages 363-370,
Ann Arbor, MI.
Prashant Gupta and Heng Ji. 2009. Predicting Unknown
Time Arguments based on Cross-Event Propagation.
In Proc. ACL-IJCNLP 2009, pages 369-272, Suntec,
Singapore.
Ralph Grishman, David Westbrook and Adam Meyers.
2005. NYU’s English ACE 2005 System
Description. In Proc. ACE 2005 Evaluation
Workshop, Gaithersburg, MD.
Hilda Hardy, Vika Kanchakouskaya and Tomek
Strzalkowski. 2006. Automatic Event Classification
Using Surface Text Features. In Proc. AAAI 2006
Workshop on Event Extraction and Synthesis, pages
36-41, Boston, MA.
Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou and Qiaoming Zhu. 2011. Using
Cross-Entity Inference to Improve Event Extraction.
In Proc. ACL 2011, pages 1127-1136, Portland, OR.
Heng Ji. 2009. Cross-lingual Predicate Cluster
Acquisition to Improve Bilingual Event Extraction
by Inductive Learning. In Proc. NAACL HLT
Workshop on Unsupervised and Minimally
Supervised Learning of Lexical Semantics, pages
27-35, Boulder, CO.
Heng Ji and Ralph Grishman. 2008. Refining Event
Extraction through Cross-Document Inference. In
Proc. ACL-08: HLT, pages 254-262, Columbus, OH.
Young-Joo Kim. 2000. Subject/object drop in the
acquisition of Korean: A Cross-linguistic
Comparison. Journal of East Asian Linguistics, 9(4):
325-351.
Roger Levy and Christopher D. Manning. 2003. Is it
harder to parse Chinese, or the Chinese Treebank? In
Proc. ACL 2003, pages 439-446, Sapporo, Japan.
Shasha Liao and Ralph Grishman. 2010. Using
Document Level Cross-Event Inference to Improve
Event Extraction. In Proc. ACL 2010, pages 789-
797, Uppsala, Sweden.
Zhongguo Li. 2011. Parsing the Internal Structure of
Words: A New Paradigm for Chinese Word
Segmentation. In Proc. ACL 2011, pages 1405-1414,
Portland, OR.
Percy Liang, Michael I. Joedan and Dan Klein. 2011.
Learning Dependency-Based Compositional
1015
Semantics. In Proc. ACL 2011, pages 590-599,
Portland, OR.
Gideon Mann. 2007. Multi-document Relationship
Fusion via Constraints on Probabilistic Databases. In
Proc. HLT/NAACL 2007, pages 332-229, Rochester,
NY.
Mstislav Maslennikov and Tat-Seng Chua. 2007. A
Multi Resolution Framework for Information
Extraction from Free Text. In Proc. ACL 2007,
pages 592-599, Prague, Czech Republic.
Siddharth Patwardhan and Ellen Riloff. 2007. Effective
Information Extraction with Semantic Affinity
Patterns and Relevant Regions. In Proc.
EMNLP/CoNLL 2007, pages 717-727, Prague,
Czech Republic.
Siddharth Patwardhan and Ellen Riloff. 2009. A Unified
Model of Phrasal and Sentential Evidence for
Information Extraction. In Proc. EMNLP 2009,
pages 151-160, Singapore.
Hongye Tan, Tiejun Zhao, Jiaheng Zheng. 2008.
Identification of Chinese Event and Their Argument
Roles. Proc. of the 2008 IEEE 8th International
Conference on Computer and Information
Technology Workshops, pages 14-19, Sydney,
Australia.
Yuk Wah Wong and Raymond J. Mooney. 2007.
Learning Synchronous Grammars for Semantic
Parsing with Lambda Calculus. In Proc. ACL 2007,
pages 960-967, Prague, Czech Republic.
Roman Yangarber, Clive Best, Peter von Etter, Flavio
Fuart, David Horby and Ralf Steinberger. 2007.
Combining Information about Epidemic Threats
from Multiple Sources. In Proc. RANLP 2007
workshop on Multi-source, Multilingual Information
Extraction and Summarization. Borovets, pages 41-
48, Borovets, Bulgaria.
Roman Yangarber and Lauri Jokipii. 2005.
Redundancy-based Correction of Automatically
Extracted Facts. In Proc. EMNLP 2005, pages 57-64,
Vancouver, Canada.
David Yarowsky. 1995. Unsupervised Word Sense
Disambiguation Rivaling Supervised Methods. In
Proc. ACL 1995, pages 189-196, Cambridge, MA.
Minglin Yuan. 1998. Studies on Valency in Modern
Chinese. Chinese Commerce and Trade Press,
Beijing, China.
Luke S. Zettlemoyer and Michael Collins. 2007. Online
Learning of Relaxed CCG Grammars for Parsing to
Logical Form. In EMNLP/CoNLL 2007, pages 678-
687, Prague, Czech Republic.
Dexi Zhu. 1980. Research on Chinese Modern
Grammars. Chinese Commerce and Trade Press,
Beijing, China.
</reference>
<page confidence="0.778848">
1016
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.914496">
<title confidence="0.9946415">Employing Compositional Semantics and Discourse Consistency Chinese Event Extraction</title>
<author confidence="0.999696">Peifeng Li</author>
<author confidence="0.999696">Guodong Zhou</author>
<author confidence="0.999696">Qiaoming Zhu</author>
<author confidence="0.999696">Libin Hou</author>
<affiliation confidence="0.999975">School of Computer Science &amp; Technology</affiliation>
<address confidence="0.97445">Soochow University, Suzhou, 215006, China</address>
<email confidence="0.959329">pfli@suda.edu.cn</email>
<email confidence="0.959329">gdzhou@suda.edu.cn</email>
<email confidence="0.959329">qmzhu@suda.edu.cn</email>
<email confidence="0.959329">20094227021@suda.edu.cn</email>
<abstract confidence="0.998936846153846">Current Chinese event extraction systems suffer much from two problems in trigger identification: unknown triggers and word segmentation errors to known triggers. To resolve these problems, this paper proposes two novel inference mechanisms to explore special characteristics in Chinese via compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Ahn</author>
</authors>
<title>The Stages of Event Extraction.</title>
<date>2006</date>
<booktitle>In Proc. COLING/ACL 2006 Workshop on Annotating and Reasoning about Time and Events.</booktitle>
<pages>1--8</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="1205" citStr="Ahn, 2006" startWordPosition="160" endWordPosition="161">e Chinese triggers and discourse consistency between Chinese trigger mentions. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigger word/phr</context>
<context position="4711" citStr="Ahn, 2006" startWordPosition="692" endWordPosition="693">ion 2 overviews the related work. Section 3 introduces a state-of-the-art baseline system for Chinese event extraction. Sections 4 and 5 describe two novel inference mechanisms to Chinese trigger identification by employing compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection appro</context>
</contexts>
<marker>Ahn, 2006</marker>
<rawString>David Ahn. 2006. The Stages of Event Extraction. In Proc. COLING/ACL 2006 Workshop on Annotating and Reasoning about Time and Events. Pages 1-8, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pi-Chuan Chang</author>
<author>Huihsin Tseng</author>
<author>Dan Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>Discriminative Reordering with Chinese Grammatical Relations Features.</title>
<date>2009</date>
<booktitle>In Proc. Third Workshop on Syntax and Structure in Statistical Translation,</booktitle>
<pages>51--59</pages>
<contexts>
<context position="11817" citStr="Chang, et al., 2009" startWordPosition="1769" endWordPosition="1772">type is correctly determined if its event type and position in the document match a reference trigger; ➢ An argument is correctly identified if its involved event type and position in the document match any of the reference argument mentions; ➢ An argument role is correctly determined if its involved event type, position in the document, and role match any of the reference argument mentions. Finally, all sentences in the corpus are divided into words using a word segmentation tool ICTCLAS3 with all entities annotated in the corpus kept. Besides, we use Stanford Parser (Levy and Manning, 2003, Chang, et al., 2009) to create the constituent and dependency parse trees and employ the ME model to train individual component classifiers. 3.2 Experimental Results Table 2 and 3 show the Precision (P), Recall (R) and F1-Measure (F) on the held-out test set. It shows that our baseline system outperforms Chen and Ji (2009b) by 1.8, 2.2, 3.9 and 2.3 in F1- measure on trigger identification, trigger type 3 http://ictclas.org/ 1008 determination, argument identification and argument role determination, respectively, with both gains in precision and recall. This is simply due to contribution of the newly-added refine</context>
</contexts>
<marker>Chang, Tseng, Jurafsky, Manning, 2009</marker>
<rawString>Pi-Chuan Chang, Huihsin Tseng, Dan Jurafsky, and Christopher Manning. 2009. Discriminative Reordering with Chinese Grammatical Relations Features. In Proc. Third Workshop on Syntax and Structure in Statistical Translation, pages 51-59.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Heng Ji</author>
</authors>
<title>Can One Language Bootstrap the Other: A Case Study on Event Extraction.</title>
<date>2009</date>
<booktitle>In Proc. NAACL HLT Workshop on Semi-supervised Learning for Natural Language Processing,</booktitle>
<pages>66--74</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="5598" citStr="Chen and Ji (2009" startWordPosition="819" endWordPosition="822">d crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the coverage of patterns in argument classification (argument identification + argument role determination). Chen and Ji (2009a) proposed a bootstrapping framework, which exploited extra information captured by an English event extraction system. Chen and Ji (2009b) applied various kinds of lexical, syntactic and semantic features to address the specific issues in Chinese. They also constructed a global errata table to record the inconsistency in the training set and used it to correct the inconsistency in the test set. Ji (2009) extracted cross-lingual predicate clusters using bilingual parallel corpora and a cross-lingual information extraction system, and then used the derived clusters to improve the performance o</context>
<context position="8515" citStr="Chen and Ji (2009" startWordPosition="1238" endWordPosition="1241">events. Liao and Grishman (2010) employed cross-event consistency information to improve sentence-level event extraction. Hong et al. (2011) regarded entity type 1007 consistency as a key feature to predict event mentions and adopted this inference method to improve the traditional event extraction system. 3 Baseline As a baseline, we re-implement a state-of-the-art system, which consists of four typical components (trigger identification, trigger type determination, argument identification and argument role determination), in a pipeline way and employ the same set of features as described in Chen and Ji (2009b). Besides, the Maximum-Entropy (ME) model is employed to train individual component classifiers for the above four components. During testing, each word in the test set is first scanned for instances of known triggers from the training set. When an instance is found, the trigger identifier is applied to distinguish true trigger mentions from pseudo ones. If true, the trigger type determiner is then applied to recognize its event type. For any entity mentions in the sentence, the argument identifier is employed to assign possible arguments to them afterwards. Finally, the argument role determ</context>
<context position="10712" citStr="Chen and Ji (2009" startWordPosition="1584" endWordPosition="1587">bor word of the trigger + its POS; 3) dependency feature: dependency path from the entity to the trigger; 4) semantic role features: Arg0 and Arg1 which tagged by semantic role labeling tool (Li, et al., 2010). 3.1 Experimental Setting The ACE 2005 Chinese corpus (only the training data is available) is used in all our experiments. The corpus contains 633 Chinese documents annotated with 8 predefined event types and 33 predefined subtypes. Similar to previous studies, we treat these subtypes simply as 33 separate event types and do not consider the hierarchical structure among them. Following Chen and Ji (2009b), we randomly select 567 documents as the training set and the remaining 66 documents as the test set. Besides, we reserve 33 documents in the training set as the development set, and follow the setting of ACE diagnostic tasks and use the ground truth entities, times and values for our training and testing. For evaluation, we follow the standards as defined in Ji (2009): ➢ A trigger is correctly identified if its position in the document matches a reference trigger; ➢ A trigger type is correctly determined if its event type and position in the document match a reference trigger; ➢ An argumen</context>
<context position="12120" citStr="Chen and Ji (2009" startWordPosition="1819" endWordPosition="1822">t type, position in the document, and role match any of the reference argument mentions. Finally, all sentences in the corpus are divided into words using a word segmentation tool ICTCLAS3 with all entities annotated in the corpus kept. Besides, we use Stanford Parser (Levy and Manning, 2003, Chang, et al., 2009) to create the constituent and dependency parse trees and employ the ME model to train individual component classifiers. 3.2 Experimental Results Table 2 and 3 show the Precision (P), Recall (R) and F1-Measure (F) on the held-out test set. It shows that our baseline system outperforms Chen and Ji (2009b) by 1.8, 2.2, 3.9 and 2.3 in F1- measure on trigger identification, trigger type 3 http://ictclas.org/ 1008 determination, argument identification and argument role determination, respectively, with both gains in precision and recall. This is simply due to contribution of the newly-added refined and dependency features. Performance Trigger Trigger Type System Identification Determination P(%) R(%) F P(%) R(%) F Chen and Ji 71.5 51.2 59.7 66.5 47.7 55.6 (2009b) Our Baseline 75.2 52.0 61.5 70.3 49.0 57.8 Table 2. Performance of trigger identification and trigger type determination Performance </context>
<context position="22681" citStr="Chen and Ji (2009" startWordPosition="3556" endWordPosition="3559">not appear in the training set. Therefore, they will be filtered our via verb structure filtering. 7 Similar triggers are those ones which have the same BV and verb structure. 解 审 Figure 1. Distribution of three BVs (“解” (unbind), “审” (trial) and “杀” (kill)) over six verb structures in constructing triggers 5 Employing Discourse Consistency between Chinese Trigger Mentions Chinese event extraction may suffer much from the errors propagated from upstream processing such as part-of-speech tagging and parsing, especially word segmentation. To alleviate word segmentation errors to known triggers, Chen and Ji (2009b) constructed a global errata table to record the inconsistency in the training set and proved its effectiveness. In this paper, a merge and split method is applied to recover those known triggers. In this way, word segmentation errors can be alleviated to certain extent. For unknown triggers, we can merge two or more neighboring short words or single characters as a trigger candidate. In this paper, for each single-character verb in a document after word segmentation, this single-character verb can be merged with either previous SCW or next SCW to form a trigger candidate if this single-char</context>
</contexts>
<marker>Chen, Ji, 2009</marker>
<rawString>Zheng Chen and Heng Ji. 2009a. Can One Language Bootstrap the Other: A Case Study on Event Extraction. In Proc. NAACL HLT Workshop on Semi-supervised Learning for Natural Language Processing, pages 66-74, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Heng Ji</author>
</authors>
<title>Language Specific Issue and Feature Exploration in Chinese Event Extraction.</title>
<date>2009</date>
<booktitle>In Proc. NAACL HLT</booktitle>
<pages>209--212</pages>
<location>Boulder, CO.</location>
<contexts>
<context position="5598" citStr="Chen and Ji (2009" startWordPosition="819" endWordPosition="822">d crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the coverage of patterns in argument classification (argument identification + argument role determination). Chen and Ji (2009a) proposed a bootstrapping framework, which exploited extra information captured by an English event extraction system. Chen and Ji (2009b) applied various kinds of lexical, syntactic and semantic features to address the specific issues in Chinese. They also constructed a global errata table to record the inconsistency in the training set and used it to correct the inconsistency in the test set. Ji (2009) extracted cross-lingual predicate clusters using bilingual parallel corpora and a cross-lingual information extraction system, and then used the derived clusters to improve the performance o</context>
<context position="8515" citStr="Chen and Ji (2009" startWordPosition="1238" endWordPosition="1241">events. Liao and Grishman (2010) employed cross-event consistency information to improve sentence-level event extraction. Hong et al. (2011) regarded entity type 1007 consistency as a key feature to predict event mentions and adopted this inference method to improve the traditional event extraction system. 3 Baseline As a baseline, we re-implement a state-of-the-art system, which consists of four typical components (trigger identification, trigger type determination, argument identification and argument role determination), in a pipeline way and employ the same set of features as described in Chen and Ji (2009b). Besides, the Maximum-Entropy (ME) model is employed to train individual component classifiers for the above four components. During testing, each word in the test set is first scanned for instances of known triggers from the training set. When an instance is found, the trigger identifier is applied to distinguish true trigger mentions from pseudo ones. If true, the trigger type determiner is then applied to recognize its event type. For any entity mentions in the sentence, the argument identifier is employed to assign possible arguments to them afterwards. Finally, the argument role determ</context>
<context position="10712" citStr="Chen and Ji (2009" startWordPosition="1584" endWordPosition="1587">bor word of the trigger + its POS; 3) dependency feature: dependency path from the entity to the trigger; 4) semantic role features: Arg0 and Arg1 which tagged by semantic role labeling tool (Li, et al., 2010). 3.1 Experimental Setting The ACE 2005 Chinese corpus (only the training data is available) is used in all our experiments. The corpus contains 633 Chinese documents annotated with 8 predefined event types and 33 predefined subtypes. Similar to previous studies, we treat these subtypes simply as 33 separate event types and do not consider the hierarchical structure among them. Following Chen and Ji (2009b), we randomly select 567 documents as the training set and the remaining 66 documents as the test set. Besides, we reserve 33 documents in the training set as the development set, and follow the setting of ACE diagnostic tasks and use the ground truth entities, times and values for our training and testing. For evaluation, we follow the standards as defined in Ji (2009): ➢ A trigger is correctly identified if its position in the document matches a reference trigger; ➢ A trigger type is correctly determined if its event type and position in the document match a reference trigger; ➢ An argumen</context>
<context position="12120" citStr="Chen and Ji (2009" startWordPosition="1819" endWordPosition="1822">t type, position in the document, and role match any of the reference argument mentions. Finally, all sentences in the corpus are divided into words using a word segmentation tool ICTCLAS3 with all entities annotated in the corpus kept. Besides, we use Stanford Parser (Levy and Manning, 2003, Chang, et al., 2009) to create the constituent and dependency parse trees and employ the ME model to train individual component classifiers. 3.2 Experimental Results Table 2 and 3 show the Precision (P), Recall (R) and F1-Measure (F) on the held-out test set. It shows that our baseline system outperforms Chen and Ji (2009b) by 1.8, 2.2, 3.9 and 2.3 in F1- measure on trigger identification, trigger type 3 http://ictclas.org/ 1008 determination, argument identification and argument role determination, respectively, with both gains in precision and recall. This is simply due to contribution of the newly-added refined and dependency features. Performance Trigger Trigger Type System Identification Determination P(%) R(%) F P(%) R(%) F Chen and Ji 71.5 51.2 59.7 66.5 47.7 55.6 (2009b) Our Baseline 75.2 52.0 61.5 70.3 49.0 57.8 Table 2. Performance of trigger identification and trigger type determination Performance </context>
<context position="22681" citStr="Chen and Ji (2009" startWordPosition="3556" endWordPosition="3559">not appear in the training set. Therefore, they will be filtered our via verb structure filtering. 7 Similar triggers are those ones which have the same BV and verb structure. 解 审 Figure 1. Distribution of three BVs (“解” (unbind), “审” (trial) and “杀” (kill)) over six verb structures in constructing triggers 5 Employing Discourse Consistency between Chinese Trigger Mentions Chinese event extraction may suffer much from the errors propagated from upstream processing such as part-of-speech tagging and parsing, especially word segmentation. To alleviate word segmentation errors to known triggers, Chen and Ji (2009b) constructed a global errata table to record the inconsistency in the training set and proved its effectiveness. In this paper, a merge and split method is applied to recover those known triggers. In this way, word segmentation errors can be alleviated to certain extent. For unknown triggers, we can merge two or more neighboring short words or single characters as a trigger candidate. In this paper, for each single-character verb in a document after word segmentation, this single-character verb can be merged with either previous SCW or next SCW to form a trigger candidate if this single-char</context>
</contexts>
<marker>Chen, Ji, 2009</marker>
<rawString>Zheng Chen and Heng Ji. 2009b. Language Specific Issue and Feature Exploration in Chinese Event Extraction. In Proc. NAACL HLT 2009, pages 209-212, Boulder, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling.</title>
<date>2005</date>
<booktitle>In Proc. ACL</booktitle>
<pages>363--370</pages>
<location>Ann Arbor, MI.</location>
<contexts>
<context position="1274" citStr="Finkel et al., 2005" startWordPosition="170" endWordPosition="173">e trigger mentions. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigger word/phrase occurring in the training data is called a known trigger and othe</context>
<context position="4849" citStr="Finkel et al., 2005" startWordPosition="712" endWordPosition="715"> 4 and 5 describe two novel inference mechanisms to Chinese trigger identification by employing compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels </context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager and Christopher Manning. 2005. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. In Proc. ACL 2005, pages 363-370, Ann Arbor, MI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prashant Gupta</author>
<author>Heng Ji</author>
</authors>
<title>Predicting Unknown Time Arguments based on Cross-Event Propagation.</title>
<date>2009</date>
<booktitle>In Proc. ACL-IJCNLP 2009,</booktitle>
<pages>369--272</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="4978" citStr="Gupta and Ji, 2009" startWordPosition="730" endWordPosition="733">inese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the coverage of patterns in argument classification (argument identification + argument role determination</context>
<context position="7730" citStr="Gupta and Ji (2009)" startWordPosition="1124" endWordPosition="1127">y recognition and coreference resolution. Specially, several studies have successfully incorporated trigger or entity consistency constraint into event extraction. Yarowsky (1995) and Yangarber et al. (Yangarber and Jokipii, 2005; Yangarber et al., 2007) applied cross-document inference to refine local extraction results for disease name, location and start/end time. Mann (2007) proposed some specific inference rules to improve extraction of personal information. Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topicrelated documents. Gupta and Ji (2009) used a similar approach to recover implicit time information for events. Liao and Grishman (2011) also used a similar approach and a self-training strategy to extract events. Liao and Grishman (2010) employed cross-event consistency information to improve sentence-level event extraction. Hong et al. (2011) regarded entity type 1007 consistency as a key feature to predict event mentions and adopted this inference method to improve the traditional event extraction system. 3 Baseline As a baseline, we re-implement a state-of-the-art system, which consists of four typical components (trigger iden</context>
</contexts>
<marker>Gupta, Ji, 2009</marker>
<rawString>Prashant Gupta and Heng Ji. 2009. Predicting Unknown Time Arguments based on Cross-Event Propagation. In Proc. ACL-IJCNLP 2009, pages 369-272, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>David Westbrook</author>
<author>Adam Meyers</author>
</authors>
<date>2005</date>
<booktitle>NYU’s English ACE 2005 System Description. In Proc. ACE 2005 Evaluation Workshop,</booktitle>
<location>Gaithersburg, MD.</location>
<contexts>
<context position="1194" citStr="Grishman et al., 2005" startWordPosition="156" endWordPosition="159">itional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigg</context>
<context position="4700" citStr="Grishman et al., 2005" startWordPosition="688" endWordPosition="691">anized as follows. Section 2 overviews the related work. Section 3 introduces a state-of-the-art baseline system for Chinese event extraction. Sections 4 and 5 describe two novel inference mechanisms to Chinese trigger identification by employing compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature sele</context>
</contexts>
<marker>Grishman, Westbrook, Meyers, 2005</marker>
<rawString>Ralph Grishman, David Westbrook and Adam Meyers. 2005. NYU’s English ACE 2005 System Description. In Proc. ACE 2005 Evaluation Workshop, Gaithersburg, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hilda Hardy</author>
<author>Vika Kanchakouskaya</author>
<author>Tomek Strzalkowski</author>
</authors>
<title>Automatic Event Classification Using Surface Text Features.</title>
<date>2006</date>
<booktitle>In Proc. AAAI 2006 Workshop on Event Extraction and Synthesis,</booktitle>
<pages>36--41</pages>
<location>Boston, MA.</location>
<contexts>
<context position="1225" citStr="Hardy et al., 2006" startWordPosition="162" endWordPosition="165">riggers and discourse consistency between Chinese trigger mentions. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigger word/phrase occurring in the</context>
<context position="4732" citStr="Hardy et al., 2006" startWordPosition="694" endWordPosition="697">iews the related work. Section 3 introduces a state-of-the-art baseline system for Chinese event extraction. Sections 4 and 5 describe two novel inference mechanisms to Chinese trigger identification by employing compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the per</context>
</contexts>
<marker>Hardy, Kanchakouskaya, Strzalkowski, 2006</marker>
<rawString>Hilda Hardy, Vika Kanchakouskaya and Tomek Strzalkowski. 2006. Automatic Event Classification Using Surface Text Features. In Proc. AAAI 2006 Workshop on Event Extraction and Synthesis, pages 36-41, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Hong</author>
<author>Jianfeng Zhang</author>
<author>Bin Ma</author>
<author>Jianmin Yao</author>
</authors>
<title>Guodong Zhou and Qiaoming Zhu.</title>
<date>2011</date>
<booktitle>In Proc. ACL 2011,</booktitle>
<pages>1127--1136</pages>
<location>Portland, OR.</location>
<contexts>
<context position="1376" citStr="Hong et al., 2011" startWordPosition="187" endWordPosition="190">ch over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigger word/phrase occurring in the training data is called a known trigger and otherwise, an unknown trigger. ACE 2005 Chinese and English corpora2 using 10- fold cross-validation. In e</context>
<context position="5014" citStr="Hong et al., 2011" startWordPosition="737" endWordPosition="740">ncy between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the coverage of patterns in argument classification (argument identification + argument role determination). Chen and Ji (2009a) proposed a bo</context>
<context position="8038" citStr="Hong et al. (2011)" startWordPosition="1168" endWordPosition="1171">ction results for disease name, location and start/end time. Mann (2007) proposed some specific inference rules to improve extraction of personal information. Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topicrelated documents. Gupta and Ji (2009) used a similar approach to recover implicit time information for events. Liao and Grishman (2011) also used a similar approach and a self-training strategy to extract events. Liao and Grishman (2010) employed cross-event consistency information to improve sentence-level event extraction. Hong et al. (2011) regarded entity type 1007 consistency as a key feature to predict event mentions and adopted this inference method to improve the traditional event extraction system. 3 Baseline As a baseline, we re-implement a state-of-the-art system, which consists of four typical components (trigger identification, trigger type determination, argument identification and argument role determination), in a pipeline way and employ the same set of features as described in Chen and Ji (2009b). Besides, the Maximum-Entropy (ME) model is employed to train individual component classifiers for the above four compon</context>
</contexts>
<marker>Hong, Zhang, Ma, Yao, 2011</marker>
<rawString>Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao, Guodong Zhou and Qiaoming Zhu. 2011. Using Cross-Entity Inference to Improve Event Extraction. In Proc. ACL 2011, pages 1127-1136, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
</authors>
<title>Cross-lingual Predicate Cluster Acquisition to Improve Bilingual Event Extraction by Inductive Learning.</title>
<date>2009</date>
<booktitle>In Proc. NAACL HLT Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics,</booktitle>
<pages>27--35</pages>
<location>Boulder, CO.</location>
<contexts>
<context position="4978" citStr="Ji, 2009" startWordPosition="732" endWordPosition="733">gers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the coverage of patterns in argument classification (argument identification + argument role determination</context>
<context position="7730" citStr="Ji (2009)" startWordPosition="1126" endWordPosition="1127">ion and coreference resolution. Specially, several studies have successfully incorporated trigger or entity consistency constraint into event extraction. Yarowsky (1995) and Yangarber et al. (Yangarber and Jokipii, 2005; Yangarber et al., 2007) applied cross-document inference to refine local extraction results for disease name, location and start/end time. Mann (2007) proposed some specific inference rules to improve extraction of personal information. Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topicrelated documents. Gupta and Ji (2009) used a similar approach to recover implicit time information for events. Liao and Grishman (2011) also used a similar approach and a self-training strategy to extract events. Liao and Grishman (2010) employed cross-event consistency information to improve sentence-level event extraction. Hong et al. (2011) regarded entity type 1007 consistency as a key feature to predict event mentions and adopted this inference method to improve the traditional event extraction system. 3 Baseline As a baseline, we re-implement a state-of-the-art system, which consists of four typical components (trigger iden</context>
<context position="10712" citStr="Ji (2009" startWordPosition="1586" endWordPosition="1587">of the trigger + its POS; 3) dependency feature: dependency path from the entity to the trigger; 4) semantic role features: Arg0 and Arg1 which tagged by semantic role labeling tool (Li, et al., 2010). 3.1 Experimental Setting The ACE 2005 Chinese corpus (only the training data is available) is used in all our experiments. The corpus contains 633 Chinese documents annotated with 8 predefined event types and 33 predefined subtypes. Similar to previous studies, we treat these subtypes simply as 33 separate event types and do not consider the hierarchical structure among them. Following Chen and Ji (2009b), we randomly select 567 documents as the training set and the remaining 66 documents as the test set. Besides, we reserve 33 documents in the training set as the development set, and follow the setting of ACE diagnostic tasks and use the ground truth entities, times and values for our training and testing. For evaluation, we follow the standards as defined in Ji (2009): ➢ A trigger is correctly identified if its position in the document matches a reference trigger; ➢ A trigger type is correctly determined if its event type and position in the document match a reference trigger; ➢ An argumen</context>
<context position="12120" citStr="Ji (2009" startWordPosition="1821" endWordPosition="1822">osition in the document, and role match any of the reference argument mentions. Finally, all sentences in the corpus are divided into words using a word segmentation tool ICTCLAS3 with all entities annotated in the corpus kept. Besides, we use Stanford Parser (Levy and Manning, 2003, Chang, et al., 2009) to create the constituent and dependency parse trees and employ the ME model to train individual component classifiers. 3.2 Experimental Results Table 2 and 3 show the Precision (P), Recall (R) and F1-Measure (F) on the held-out test set. It shows that our baseline system outperforms Chen and Ji (2009b) by 1.8, 2.2, 3.9 and 2.3 in F1- measure on trigger identification, trigger type 3 http://ictclas.org/ 1008 determination, argument identification and argument role determination, respectively, with both gains in precision and recall. This is simply due to contribution of the newly-added refined and dependency features. Performance Trigger Trigger Type System Identification Determination P(%) R(%) F P(%) R(%) F Chen and Ji 71.5 51.2 59.7 66.5 47.7 55.6 (2009b) Our Baseline 75.2 52.0 61.5 70.3 49.0 57.8 Table 2. Performance of trigger identification and trigger type determination Performance </context>
<context position="22681" citStr="Ji (2009" startWordPosition="3558" endWordPosition="3559">r in the training set. Therefore, they will be filtered our via verb structure filtering. 7 Similar triggers are those ones which have the same BV and verb structure. 解 审 Figure 1. Distribution of three BVs (“解” (unbind), “审” (trial) and “杀” (kill)) over six verb structures in constructing triggers 5 Employing Discourse Consistency between Chinese Trigger Mentions Chinese event extraction may suffer much from the errors propagated from upstream processing such as part-of-speech tagging and parsing, especially word segmentation. To alleviate word segmentation errors to known triggers, Chen and Ji (2009b) constructed a global errata table to record the inconsistency in the training set and proved its effectiveness. In this paper, a merge and split method is applied to recover those known triggers. In this way, word segmentation errors can be alleviated to certain extent. For unknown triggers, we can merge two or more neighboring short words or single characters as a trigger candidate. In this paper, for each single-character verb in a document after word segmentation, this single-character verb can be merged with either previous SCW or next SCW to form a trigger candidate if this single-char</context>
</contexts>
<marker>Ji, 2009</marker>
<rawString>Heng Ji. 2009. Cross-lingual Predicate Cluster Acquisition to Improve Bilingual Event Extraction by Inductive Learning. In Proc. NAACL HLT Workshop on Unsupervised and Minimally Supervised Learning of Lexical Semantics, pages 27-35, Boulder, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Refining Event Extraction through Cross-Document Inference.</title>
<date>2008</date>
<booktitle>In Proc. ACL-08: HLT,</booktitle>
<pages>254--262</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="1297" citStr="Ji and Grishman, 2008" startWordPosition="174" endWordPosition="177">valuation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigger word/phrase occurring in the training data is called a known trigger and otherwise, an unknown trigg</context>
<context position="4919" citStr="Ji and Grishman, 2008" startWordPosition="721" endWordPosition="724"> identification by employing compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the coverage of patterns in argument classifica</context>
<context position="7601" citStr="Ji and Grishman (2008)" startWordPosition="1106" endWordPosition="1109">important hypothesis in natural languages and has been applied to many natural language processing applications, such as named entity recognition and coreference resolution. Specially, several studies have successfully incorporated trigger or entity consistency constraint into event extraction. Yarowsky (1995) and Yangarber et al. (Yangarber and Jokipii, 2005; Yangarber et al., 2007) applied cross-document inference to refine local extraction results for disease name, location and start/end time. Mann (2007) proposed some specific inference rules to improve extraction of personal information. Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topicrelated documents. Gupta and Ji (2009) used a similar approach to recover implicit time information for events. Liao and Grishman (2011) also used a similar approach and a self-training strategy to extract events. Liao and Grishman (2010) employed cross-event consistency information to improve sentence-level event extraction. Hong et al. (2011) regarded entity type 1007 consistency as a key feature to predict event mentions and adopted this inference method to improve the traditional event extraction sys</context>
<context position="34116" citStr="Ji and Grishman, 2008" startWordPosition="5361" endWordPosition="5364">.9 Inter-Annotator Agreement 45.8 42.9 44.3 45.3 42.5 43.8 60.4 49.7 54.5 55.1 45.9 50.1 Table 9: Overall contribution to Chinese event extraction In addition, the results of two annotators show that Chinese event extraction is really challenging even for a well-educated human being. As shown in Table 9, the inter-annotator agreement on trigger identification and trigger type determination is even less than 45%. Although this figure is very low, it is not surprising: the results on the English ACE 2005 corpus show that the inter-annotator agreement on trigger identification is only about 40% (Ji and Grishman, 2008). Detailed analysis shows that a human annotator tends to make more mistakes in trigger identification for two reasons. The first reason is that a human annotator always misses some event mentions when a sentence contains more than one event mention. The second reason is that it is hard to identify an event mention due to the failure of following specified annotation guidelines, as mentioned in Ji and Grishman (2008). Table 9 also shows the performance gaps of human annotators between trigger identification and trigger type determination is very small (2.5% and 3.8% in F1-measure). It ensures </context>
</contexts>
<marker>Ji, Grishman, 2008</marker>
<rawString>Heng Ji and Ralph Grishman. 2008. Refining Event Extraction through Cross-Document Inference. In Proc. ACL-08: HLT, pages 254-262, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Young-Joo Kim</author>
</authors>
<title>Subject/object drop in the acquisition of Korean: A Cross-linguistic Comparison.</title>
<date>2000</date>
<journal>Journal of East Asian Linguistics,</journal>
<volume>9</volume>
<issue>4</issue>
<pages>325--351</pages>
<contexts>
<context position="24017" citStr="Kim (2000)" startWordPosition="3768" endWordPosition="3769">known triggers, the key issue here is how to distinguish true triggers from pseudo ones. In this paper, we employ discourse consistency between Chinese trigger mentions for Chinese event extraction. Previous studies on English event extraction have proved the effectiveness of both cross-entity and cross-document consistency. 5.1 Discourse Consistency between Chinese Trigger Mentions As a discourse-driven language, the syntax of 1 0.8 0.6 0.4 0.2 0 杀 1011 Chinese is not as strict as English and sometime we must infer from the discourse-level information to understand the meaning of a sentence. Kim (2000) compared the use of overt subjects in English and Chinese and he found that overt subjects occupy over 96% in English, while this percentage drops to only 64% in Chinese. Similarly, argument missing is another issue in Chinese event extraction and almost 55% of arguments are missing in the ACE 2005 Chinese corpus. Normally, using a feature-based approach to distinguish true triggers from pseudo ones is very difficult from the sentence level if some of related arguments are missing from the triggeroccurring sentence. Take following two contingent sentences as examples: (3) 美国 与北韩 3 (The United</context>
</contexts>
<marker>Kim, 2000</marker>
<rawString>Young-Joo Kim. 2000. Subject/object drop in the acquisition of Korean: A Cross-linguistic Comparison. Journal of East Asian Linguistics, 9(4): 325-351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Christopher D Manning</author>
</authors>
<title>Is it harder to parse Chinese, or the Chinese Treebank? In</title>
<date>2003</date>
<booktitle>Proc. ACL 2003,</booktitle>
<pages>439--446</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="11795" citStr="Levy and Manning, 2003" startWordPosition="1765" endWordPosition="1768">ce trigger; ➢ A trigger type is correctly determined if its event type and position in the document match a reference trigger; ➢ An argument is correctly identified if its involved event type and position in the document match any of the reference argument mentions; ➢ An argument role is correctly determined if its involved event type, position in the document, and role match any of the reference argument mentions. Finally, all sentences in the corpus are divided into words using a word segmentation tool ICTCLAS3 with all entities annotated in the corpus kept. Besides, we use Stanford Parser (Levy and Manning, 2003, Chang, et al., 2009) to create the constituent and dependency parse trees and employ the ME model to train individual component classifiers. 3.2 Experimental Results Table 2 and 3 show the Precision (P), Recall (R) and F1-Measure (F) on the held-out test set. It shows that our baseline system outperforms Chen and Ji (2009b) by 1.8, 2.2, 3.9 and 2.3 in F1- measure on trigger identification, trigger type 3 http://ictclas.org/ 1008 determination, argument identification and argument role determination, respectively, with both gains in precision and recall. This is simply due to contribution of </context>
</contexts>
<marker>Levy, Manning, 2003</marker>
<rawString>Roger Levy and Christopher D. Manning. 2003. Is it harder to parse Chinese, or the Chinese Treebank? In Proc. ACL 2003, pages 439-446, Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shasha Liao</author>
<author>Ralph Grishman</author>
</authors>
<title>Using Document Level Cross-Event Inference to Improve Event Extraction.</title>
<date>2010</date>
<booktitle>In Proc. ACL 2010,</booktitle>
<pages>789--797</pages>
<location>Uppsala,</location>
<contexts>
<context position="1356" citStr="Liao and Grishman 2010" startWordPosition="183" endWordPosition="186">ectiveness of our approach over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigger word/phrase occurring in the training data is called a known trigger and otherwise, an unknown trigger. ACE 2005 Chinese and English corpora2 using 10- fold cr</context>
<context position="4957" citStr="Liao and Grishman, 2010" startWordPosition="726" endWordPosition="729">ional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the coverage of patterns in argument classification (argument identification + argume</context>
<context position="7930" citStr="Liao and Grishman (2010)" startWordPosition="1155" endWordPosition="1158">t al. (Yangarber and Jokipii, 2005; Yangarber et al., 2007) applied cross-document inference to refine local extraction results for disease name, location and start/end time. Mann (2007) proposed some specific inference rules to improve extraction of personal information. Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topicrelated documents. Gupta and Ji (2009) used a similar approach to recover implicit time information for events. Liao and Grishman (2011) also used a similar approach and a self-training strategy to extract events. Liao and Grishman (2010) employed cross-event consistency information to improve sentence-level event extraction. Hong et al. (2011) regarded entity type 1007 consistency as a key feature to predict event mentions and adopted this inference method to improve the traditional event extraction system. 3 Baseline As a baseline, we re-implement a state-of-the-art system, which consists of four typical components (trigger identification, trigger type determination, argument identification and argument role determination), in a pipeline way and employ the same set of features as described in Chen and Ji (2009b). Besides, th</context>
</contexts>
<marker>Liao, Grishman, 2010</marker>
<rawString>Shasha Liao and Ralph Grishman. 2010. Using Document Level Cross-Event Inference to Improve Event Extraction. In Proc. ACL 2010, pages 789-797, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongguo Li</author>
</authors>
<title>Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation.</title>
<date>2011</date>
<booktitle>In Proc. ACL 2011,</booktitle>
<pages>1405--1414</pages>
<location>Portland, OR.</location>
<contexts>
<context position="6835" citStr="Li (2011)" startWordPosition="1005" endWordPosition="1006">2.2 Compositional Semantics Almost all the related studies on compositional semantics focus on how to combine words together to convey complex meanings, such as semantic parser (Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Liang et al., 2011). However, the compositional semantics mentioned in this paper is more fined-grained and focuses on how to construct Chinese characters into a word and mine the semantics of words from the word structures, especially of verbs as event triggers. To our knowledge, there is only one paper associated with compositional semantics inside Chinese words. Li (2011) discussed the internal structures inside Chinese nouns and used it in word segmentation. 2.3 Discourse Consistency Discourse consistency is an important hypothesis in natural languages and has been applied to many natural language processing applications, such as named entity recognition and coreference resolution. Specially, several studies have successfully incorporated trigger or entity consistency constraint into event extraction. Yarowsky (1995) and Yangarber et al. (Yangarber and Jokipii, 2005; Yangarber et al., 2007) applied cross-document inference to refine local extraction results f</context>
</contexts>
<marker>Li, 2011</marker>
<rawString>Zhongguo Li. 2011. Parsing the Internal Structure of Words: A New Paradigm for Chinese Word Segmentation. In Proc. ACL 2011, pages 1405-1414, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Joedan</author>
<author>Dan Klein</author>
</authors>
<date>2011</date>
<journal>Learning Dependency-Based Compositional</journal>
<pages>1015</pages>
<contexts>
<context position="6477" citStr="Liang et al., 2011" startWordPosition="948" endWordPosition="951">constructed a global errata table to record the inconsistency in the training set and used it to correct the inconsistency in the test set. Ji (2009) extracted cross-lingual predicate clusters using bilingual parallel corpora and a cross-lingual information extraction system, and then used the derived clusters to improve the performance of Chinese event extraction. 2.2 Compositional Semantics Almost all the related studies on compositional semantics focus on how to combine words together to convey complex meanings, such as semantic parser (Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Liang et al., 2011). However, the compositional semantics mentioned in this paper is more fined-grained and focuses on how to construct Chinese characters into a word and mine the semantics of words from the word structures, especially of verbs as event triggers. To our knowledge, there is only one paper associated with compositional semantics inside Chinese words. Li (2011) discussed the internal structures inside Chinese nouns and used it in word segmentation. 2.3 Discourse Consistency Discourse consistency is an important hypothesis in natural languages and has been applied to many natural language processing</context>
</contexts>
<marker>Liang, Joedan, Klein, 2011</marker>
<rawString>Percy Liang, Michael I. Joedan and Dan Klein. 2011. Learning Dependency-Based Compositional 1015</rawString>
</citation>
<citation valid="false">
<authors>
<author>Semantics</author>
</authors>
<booktitle>In Proc. ACL 2011,</booktitle>
<pages>590--599</pages>
<location>Portland, OR.</location>
<marker>Semantics, </marker>
<rawString>Semantics. In Proc. ACL 2011, pages 590-599, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon Mann</author>
</authors>
<title>Multi-document Relationship Fusion via Constraints on Probabilistic Databases.</title>
<date>2007</date>
<booktitle>In Proc. HLT/NAACL 2007,</booktitle>
<pages>332--229</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="7492" citStr="Mann (2007)" startWordPosition="1093" endWordPosition="1094">ese nouns and used it in word segmentation. 2.3 Discourse Consistency Discourse consistency is an important hypothesis in natural languages and has been applied to many natural language processing applications, such as named entity recognition and coreference resolution. Specially, several studies have successfully incorporated trigger or entity consistency constraint into event extraction. Yarowsky (1995) and Yangarber et al. (Yangarber and Jokipii, 2005; Yangarber et al., 2007) applied cross-document inference to refine local extraction results for disease name, location and start/end time. Mann (2007) proposed some specific inference rules to improve extraction of personal information. Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topicrelated documents. Gupta and Ji (2009) used a similar approach to recover implicit time information for events. Liao and Grishman (2011) also used a similar approach and a self-training strategy to extract events. Liao and Grishman (2010) employed cross-event consistency information to improve sentence-level event extraction. Hong et al. (2011) regarded entity type 1007 consistency as a key featur</context>
</contexts>
<marker>Mann, 2007</marker>
<rawString>Gideon Mann. 2007. Multi-document Relationship Fusion via Constraints on Probabilistic Databases. In Proc. HLT/NAACL 2007, pages 332-229, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mstislav Maslennikov</author>
<author>Tat-Seng Chua</author>
</authors>
<title>A Multi Resolution Framework for Information Extraction from Free Text.</title>
<date>2007</date>
<booktitle>In Proc. ACL 2007,</booktitle>
<pages>592--599</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1253" citStr="Maslennikov and Chua, 2007" startWordPosition="166" endWordPosition="169">e consistency between Chinese trigger mentions. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigger word/phrase occurring in the training data is called a k</context>
<context position="4828" citStr="Maslennikov and Chua, 2007" startWordPosition="708" endWordPosition="711">e event extraction. Sections 4 and 5 describe two novel inference mechanisms to Chinese trigger identification by employing compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and app</context>
</contexts>
<marker>Maslennikov, Chua, 2007</marker>
<rawString>Mstislav Maslennikov and Tat-Seng Chua. 2007. A Multi Resolution Framework for Information Extraction from Free Text. In Proc. ACL 2007, pages 592-599, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Ellen Riloff</author>
</authors>
<title>Effective Information Extraction with Semantic Affinity Patterns and Relevant Regions.</title>
<date>2007</date>
<booktitle>In Proc. EMNLP/CoNLL 2007,</booktitle>
<pages>717--727</pages>
<location>Prague, Czech Republic.</location>
<marker>Patwardhan, Riloff, 2007</marker>
<rawString>Siddharth Patwardhan and Ellen Riloff. 2007. Effective Information Extraction with Semantic Affinity Patterns and Relevant Regions. In Proc. EMNLP/CoNLL 2007, pages 717-727, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Ellen Riloff</author>
</authors>
<title>A Unified Model of Phrasal and Sentential Evidence for Information Extraction.</title>
<date>2009</date>
<booktitle>In Proc. EMNLP 2009,</booktitle>
<pages>151--160</pages>
<contexts>
<context position="1326" citStr="Patwardhan and Riloff, 2009" startWordPosition="178" endWordPosition="181">05 Chinese corpus justifies the effectiveness of our approach over a strong baseline. 1 Introduction Event extraction, a classic information extraction task, is to identify instances of a predefined event type and can be typically divided into four subtasks: trigger identification, trigger type determination, argument identification and argument role determination. In the literature, most studies focus on English event extraction and have achieved certain success (e.g. Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006; Maslennikov and Chua, 2007; Finkel et al., 2005; Ji and Grishman, 2008; Patwardhan and Riloff, 2009, 2011; Liao and Grishman 2010; Hong et al., 2011). In comparison, there are few successful stories regarding Chinese event extraction due to special characteristics in Chinese trigger identification. In particular, there are two major reasons for the low performance: unknown triggers 1 and word segmentation errors to known triggers. Table 1 gives the statistics of unknown triggers and word segmentation errors to known triggers in both the 1 In this paper, a trigger word/phrase occurring in the training data is called a known trigger and otherwise, an unknown trigger. ACE 2005 Chinese and Engl</context>
<context position="4879" citStr="Patwardhan and Riloff, 2009" startWordPosition="716" endWordPosition="719"> novel inference mechanisms to Chinese trigger identification by employing compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work. 2 Related Work Almost all the existing studies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the cov</context>
</contexts>
<marker>Patwardhan, Riloff, 2009</marker>
<rawString>Siddharth Patwardhan and Ellen Riloff. 2009. A Unified Model of Phrasal and Sentential Evidence for Information Extraction. In Proc. EMNLP 2009, pages 151-160, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongye Tan</author>
<author>Tiejun Zhao</author>
<author>Jiaheng Zheng</author>
</authors>
<title>Identification of Chinese Event and Their Argument Roles.</title>
<date>2008</date>
<booktitle>Proc. of the 2008 IEEE 8th International Conference on Computer and Information Technology Workshops,</booktitle>
<pages>14--19</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="5194" citStr="Tan et al. (2008)" startWordPosition="764" endWordPosition="767">tudies on event extraction concern English. While earlier studies focus on sentence-level extraction (Grishman et al., 2005; Ahn, 2006; Hardy et al., 2006), later ones turn to employ high-level information, such as document (Maslennikov and Chua, 2007; Finkel et al., 2005; Patwardhan and Riloff, 2009), cross-document (Ji and Grishman, 2008), cross-event (Liao and Grishman, 2010; Gupta and Ji, 2009) and crossentity (Hong et al., 2011) information. 2.1 Chinese Event Extraction Compared with tremendous efforts in English event extraction, there are only a few studies on Chinese event extraction. Tan et al. (2008) modeled event extraction as a pipeline of classification tasks. Specially, they used a local feature selection approach to ensure the performance of trigger classification (trigger identification + trigger type determination) and applied multiple levels of patterns to improve the coverage of patterns in argument classification (argument identification + argument role determination). Chen and Ji (2009a) proposed a bootstrapping framework, which exploited extra information captured by an English event extraction system. Chen and Ji (2009b) applied various kinds of lexical, syntactic and semanti</context>
</contexts>
<marker>Tan, Zhao, Zheng, 2008</marker>
<rawString>Hongye Tan, Tiejun Zhao, Jiaheng Zheng. 2008. Identification of Chinese Event and Their Argument Roles. Proc. of the 2008 IEEE 8th International Conference on Computer and Information Technology Workshops, pages 14-19, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuk Wah Wong</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus.</title>
<date>2007</date>
<booktitle>In Proc. ACL 2007,</booktitle>
<pages>960--967</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="6456" citStr="Wong and Mooney, 2007" startWordPosition="944" endWordPosition="947"> in Chinese. They also constructed a global errata table to record the inconsistency in the training set and used it to correct the inconsistency in the test set. Ji (2009) extracted cross-lingual predicate clusters using bilingual parallel corpora and a cross-lingual information extraction system, and then used the derived clusters to improve the performance of Chinese event extraction. 2.2 Compositional Semantics Almost all the related studies on compositional semantics focus on how to combine words together to convey complex meanings, such as semantic parser (Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Liang et al., 2011). However, the compositional semantics mentioned in this paper is more fined-grained and focuses on how to construct Chinese characters into a word and mine the semantics of words from the word structures, especially of verbs as event triggers. To our knowledge, there is only one paper associated with compositional semantics inside Chinese words. Li (2011) discussed the internal structures inside Chinese nouns and used it in word segmentation. 2.3 Discourse Consistency Discourse consistency is an important hypothesis in natural languages and has been applied to many natura</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Yuk Wah Wong and Raymond J. Mooney. 2007. Learning Synchronous Grammars for Semantic Parsing with Lambda Calculus. In Proc. ACL 2007, pages 960-967, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Clive Best</author>
<author>Peter von Etter</author>
<author>Flavio Fuart</author>
<author>David Horby</author>
<author>Ralf Steinberger</author>
</authors>
<title>Combining Information about Epidemic Threats from Multiple Sources.</title>
<date>2007</date>
<booktitle>In Proc. RANLP 2007 workshop on Multi-source, Multilingual Information Extraction and Summarization. Borovets,</booktitle>
<pages>41--48</pages>
<location>Borovets, Bulgaria.</location>
<marker>Yangarber, Best, von Etter, Fuart, Horby, Steinberger, 2007</marker>
<rawString>Roman Yangarber, Clive Best, Peter von Etter, Flavio Fuart, David Horby and Ralf Steinberger. 2007. Combining Information about Epidemic Threats from Multiple Sources. In Proc. RANLP 2007 workshop on Multi-source, Multilingual Information Extraction and Summarization. Borovets, pages 41-48, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Lauri Jokipii</author>
</authors>
<title>Redundancy-based Correction of Automatically Extracted Facts.</title>
<date>2005</date>
<booktitle>In Proc. EMNLP 2005,</booktitle>
<pages>57--64</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="7340" citStr="Yangarber and Jokipii, 2005" startWordPosition="1070" endWordPosition="1073">riggers. To our knowledge, there is only one paper associated with compositional semantics inside Chinese words. Li (2011) discussed the internal structures inside Chinese nouns and used it in word segmentation. 2.3 Discourse Consistency Discourse consistency is an important hypothesis in natural languages and has been applied to many natural language processing applications, such as named entity recognition and coreference resolution. Specially, several studies have successfully incorporated trigger or entity consistency constraint into event extraction. Yarowsky (1995) and Yangarber et al. (Yangarber and Jokipii, 2005; Yangarber et al., 2007) applied cross-document inference to refine local extraction results for disease name, location and start/end time. Mann (2007) proposed some specific inference rules to improve extraction of personal information. Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topicrelated documents. Gupta and Ji (2009) used a similar approach to recover implicit time information for events. Liao and Grishman (2011) also used a similar approach and a self-training strategy to extract events. Liao and Grishman (2010) employed </context>
</contexts>
<marker>Yangarber, Jokipii, 2005</marker>
<rawString>Roman Yangarber and Lauri Jokipii. 2005. Redundancy-based Correction of Automatically Extracted Facts. In Proc. EMNLP 2005, pages 57-64, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation Rivaling Supervised Methods.</title>
<date>1995</date>
<booktitle>In Proc. ACL</booktitle>
<pages>189--196</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="7290" citStr="Yarowsky (1995)" startWordPosition="1064" endWordPosition="1065">ctures, especially of verbs as event triggers. To our knowledge, there is only one paper associated with compositional semantics inside Chinese words. Li (2011) discussed the internal structures inside Chinese nouns and used it in word segmentation. 2.3 Discourse Consistency Discourse consistency is an important hypothesis in natural languages and has been applied to many natural language processing applications, such as named entity recognition and coreference resolution. Specially, several studies have successfully incorporated trigger or entity consistency constraint into event extraction. Yarowsky (1995) and Yangarber et al. (Yangarber and Jokipii, 2005; Yangarber et al., 2007) applied cross-document inference to refine local extraction results for disease name, location and start/end time. Mann (2007) proposed some specific inference rules to improve extraction of personal information. Ji and Grishman (2008) employed a rule-based approach to propagate consistent triggers and arguments across topicrelated documents. Gupta and Ji (2009) used a similar approach to recover implicit time information for events. Liao and Grishman (2011) also used a similar approach and a self-training strategy to </context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised Word Sense Disambiguation Rivaling Supervised Methods. In Proc. ACL 1995, pages 189-196, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minglin Yuan</author>
</authors>
<date>1998</date>
<booktitle>Studies on Valency in Modern Chinese. Chinese Commerce and Trade Press,</booktitle>
<location>Beijing, China.</location>
<contexts>
<context position="14966" citStr="Yuan, 1998" startWordPosition="2237" endWordPosition="2238">ned semantics - the compositional semantics in Chinese verb structure - and unveil its effect and usage in Chinese language processing by employing it into Chinese event extraction. 4.1 Compositional Semantics inside Chinese Triggers In English, a component character is just the basic unit to form a word instead of a semantics unit. In comparison, almost all Chinese characters have their own meanings and can be formed as SCWs (Single Character Words) themselves. If a Chinese word contains more than one character, its meaning can be often inferred from the meanings of its component characters (Yuan, 1998). Actually, it is the normal way of understanding a new Chinese word in everyday life of a Chinese native speaker. A general method to this problem is to systematically explore the morphological structures in Chinese words. In this paper, compositional semantics provides a simple but effective compromise to the general method and we leave the general method in the future work. Table 4 shows samples of such compositional semantics in Chinese words. For example, “�h,” is composed of two characters: “�” and “h,” which have their own semantics and the semantics of “ � h, ” comes from that of its c</context>
</contexts>
<marker>Yuan, 1998</marker>
<rawString>Minglin Yuan. 1998. Studies on Valency in Modern Chinese. Chinese Commerce and Trade Press, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Online Learning of Relaxed CCG Grammars for Parsing to Logical Form. In EMNLP/CoNLL</title>
<date>2007</date>
<pages>678--687</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="6433" citStr="Zettlemoyer and Collins, 2007" startWordPosition="940" endWordPosition="943"> to address the specific issues in Chinese. They also constructed a global errata table to record the inconsistency in the training set and used it to correct the inconsistency in the test set. Ji (2009) extracted cross-lingual predicate clusters using bilingual parallel corpora and a cross-lingual information extraction system, and then used the derived clusters to improve the performance of Chinese event extraction. 2.2 Compositional Semantics Almost all the related studies on compositional semantics focus on how to combine words together to convey complex meanings, such as semantic parser (Zettlemoyer and Collins, 2007; Wong and Mooney, 2007; Liang et al., 2011). However, the compositional semantics mentioned in this paper is more fined-grained and focuses on how to construct Chinese characters into a word and mine the semantics of words from the word structures, especially of verbs as event triggers. To our knowledge, there is only one paper associated with compositional semantics inside Chinese words. Li (2011) discussed the internal structures inside Chinese nouns and used it in word segmentation. 2.3 Discourse Consistency Discourse consistency is an important hypothesis in natural languages and has been</context>
</contexts>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>Luke S. Zettlemoyer and Michael Collins. 2007. Online Learning of Relaxed CCG Grammars for Parsing to Logical Form. In EMNLP/CoNLL 2007, pages 678-687, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dexi Zhu</author>
</authors>
<title>Research on Chinese Modern Grammars. Chinese Commerce and Trade Press,</title>
<date>1980</date>
<location>Beijing, China.</location>
<contexts>
<context position="3936" citStr="Zhu, 1980" startWordPosition="582" endWordPosition="583">ism is motivated by the compositional nature of Chinese words, whose semantics can be often determined by the component characters. Hence, it is natural to infer 2 The whole Chinese ACE corpus has about 3300 event mentions. For the sake of fair comparison, we choose the same number of event mentions from the English corpus as the cross-validation data. 1006 unknown triggers by employing compositional semantics inside Chinese triggers. The second mechanism is enlightened by the wide use of discourse consistency in natural languages, particularly for Chinese, due to its discourse-driven nature (Zhu, 1980). Very often, distinguishing true trigger mentions from pseudo ones is only possible with contextual information. The rest of this paper is organized as follows. Section 2 overviews the related work. Section 3 introduces a state-of-the-art baseline system for Chinese event extraction. Sections 4 and 5 describe two novel inference mechanisms to Chinese trigger identification by employing compositional semantics inside Chinese triggers and discourse consistency between Chinese trigger mentions. Section 6 presents the experimental results. Section 7 concludes the paper and points out future work.</context>
</contexts>
<marker>Zhu, 1980</marker>
<rawString>Dexi Zhu. 1980. Research on Chinese Modern Grammars. Chinese Commerce and Trade Press, Beijing, China.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>