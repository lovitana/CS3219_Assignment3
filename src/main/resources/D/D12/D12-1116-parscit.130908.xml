<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.984862">
Entity based Q&amp;A retrieval
</title>
<author confidence="0.941898">
Amit Singh
</author>
<affiliation confidence="0.7046235">
IBM Research
Bangalore, India
</affiliation>
<email confidence="0.990736">
amising3@in.ibm.com
</email>
<sectionHeader confidence="0.99855" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999823291666667">
Bridging the lexical gap between the user’s
question and the question-answer pairs in the
Q&amp;A archives has been a major challenge for
Q&amp;A retrieval. State-of-the-art approaches
address this issue by implicitly expanding the
queries with additional words using statistical
translation models. While useful, the effec-
tiveness of these models is highly dependant
on the availability of quality corpus in the ab-
sence of which they are troubled by noise is-
sues. Moreover these models perform word
based expansion in a context agnostic manner
resulting in translation that might be mixed
and fairly general. This results in degraded
retrieval performance. In this work we ad-
dress the above issues by extending the lex-
ical word based translation model to incor-
porate semantic concepts (entities). We ex-
plore strategies to learn the translation proba-
bilities between words and the concepts using
the Q&amp;A archives and a popular entity cata-
log. Experiments conducted on a large scale
real data show that the proposed techniques
are promising.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998255">
Over the past few years community-based ques-
tion answering (CQA) portals like Naver, Ya-
hoo! Answers, Baidu Zhidao and WikiAnswers
have attracted great attention from both academia
and industry (Adamic et al., 2008; Singh and
Visweswariah, 2011). These portals foster collab-
orative creation of content by allowing the users to
both submit questions to be answered and answer
questions asked by other users. These portals aim
to provide highly focused access to this information
by directly returning pertinent question and answer
(Q&amp;A) pairs to the users questions, instead of a long
list of ranked URLs. This is in noted contrast to the
usual search paradigm, where the question is used to
search the database of potential answers, in this case
the question is used to search the database of pre-
vious questions, which in turn are associated with
answers. This involves addressing the word mis-
match problem between the users question and the
question-answer pairs in the archive. This is the ma-
jor challenge for Q&amp;A retrieval.
Researchers have proposed the use of translation
models (Berger and Lafferty, 1999; Jeon et al., 2005;
Xue et al., 2008) to solve this problem. As a princi-
pled approach to capturing semantic word relations,
statistical translation language models are built by
using the IBM model 1 (Brown et al., 1993) and
have been shown to outperform traditional docu-
ment language models on Q&amp;A retrieval task. The
basic idea is to estimate the likelihood of translat-
ing a document1 to a query by exploiting the depen-
dencies that exists between query words and doc-
ument words. For example the document contain-
ing the word Wheezing may well answer the ques-
tion containing the term Asthma. They learn the
these dependencies (encoded as translation proba-
bilities) between words using parallel mono-lingual
corpora created from the Q&amp;A pairs. While useful,
the effectiveness of these models is highly depen-
dant on the availability of quality corpus (Lee et al.,
</bodyText>
<footnote confidence="0.9547855">
1we will use (Q&amp;A, document), (word, term) and (user
query, question) interchangeably
</footnote>
<page confidence="0.805349">
1266
</page>
<note confidence="0.991557">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1266–1277, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999684">
Figure 1: Need for entity based expansions
</figureCaption>
<bodyText confidence="0.99986624137931">
2008). Also these models only capture shallow se-
mantics between words via the co-occurrence statis-
tics, while some of the more explicit relationships
between words and entities is freely available exter-
nally. Being context agnostic (Zhou et al., 2007) is
another very common criticism hailed on translation
models as it results in noisy and generic translations.
Example shown in Figure 1 captures these prob-
lems. Specifically, the word Blizzard can
refer to an American game development com-
pany that develops World of Warcraft game or
it could refer to a severe snowstorm. Expand-
ing query without taking the gaming context es-
tablished by the word WOW (acronym for World
of Warcraft) into account would lead to topic
drift. Also it would be difficult to learn relation-
ships between World of Warcraft Burning
Crusade and Blizzard from the Q&amp;A corpus
alone due to the sparsity of co-occurance counts as
these can be expressed in several lexical forms, some
of which are multi word phrases.
In this paper we argue that solution to all the
above problems lies in a unified model in which en-
tities are a primary citizen. The guiding hypothesis
being, an entity based representation provides a less
ambiguous representation of the users question and
provides for a more semantically accurate expansion
if the relationship between entities and words can be
estimated more reliably. Our main contributions are
</bodyText>
<listItem confidence="0.47268">
1. We propose Entity based Translation Language
</listItem>
<bodyText confidence="0.999347724137931">
Model (ETLM) for Q&amp;A retrieval that accom-
modates semantic information associated be-
tween entities and words. Being closely re-
lated to the general source-channel framework
(Berger and Lafferty, 1999), the model enjoys
its benefits, while mitigating some of its short-
comings. Specifically it provides for context
aware expansions of the query by exploiting
entity annotations on both, the document and
the query side. Entity annotations also provide
a means to handle the “many-to-one” (Moore,
2004) translation limitation in the IBM model,
due to which each word in the target document
can be generated by at most one word in the
question2. For the same reasons, it also al-
leviates another related limitation by enabling
translation between contiguous words across
the query and documents (Moore, 2004).
2. We learn relationships between entities and
terms by proposing new ways of organiz-
ing monolingual parallel corpus and simul-
taneously leveraging external resources like
Wikipedia from which one can derive these re-
lationships reliably. This helps alleviate the
noise problem associated with learning transla-
tion models on Q&amp;A archive described above.
An important point to note is that, our tech-
nique has merits independent to the choice
of the entity catalog. In this work we use
</bodyText>
<footnote confidence="0.965337">
2entity mentions can be of more than unit word length
</footnote>
<page confidence="0.973977">
1267
</page>
<table confidence="0.987619555555556">
D original Q&amp;A collection
E set of all entities in catalog
d(e) description of entity e
C D annotated with e E E
quser users question
q quser annotated with e E E
t token span
tq, td token span in q and d
V word vocabulary
</table>
<tableCaption confidence="0.999868">
Table 1: Notation.
</tableCaption>
<bodyText confidence="0.965397588235294">
Wikipedia, as it is a popular choice due to its
large and ever expanding coverage and its abil-
ity to keep up with world events on a timely
basis.
3. We provide detailed evaluation of impact of
modelling assumptions and model components
on retrieval performance on a large scale real
data from Yahoo Answers comprising —5 mil-
lion Q&amp;A pairs.
Rest of the paper is organized as follows: In the
next section, we define ETLM and outline its de-
tails. This is followed by Section 3 which gives
the details of entity annotators and its performance.
Section 4 describes our experiments on the retrieval
method used Q&amp;A retrieval. In Section 5 we com-
pare and contrast related literature. Finally, we con-
clude in Section 6.
</bodyText>
<sectionHeader confidence="0.950216" genericHeader="method">
2 Our Approach
</sectionHeader>
<bodyText confidence="0.988057045454546">
Problem Definition: Let D = d1, d2,..., dn denote
the Q&amp;A collection. Here di refers to the i-th Q&amp;A
data consisting of a question qi and its answer ai.
Given the user question quser, the task of Q&amp;A
retrieval is to rank di according to score(quser, di).
Figure 2 outlines the approach to compute this score
in the ETLM framework.
Offline processing: Using the entity catalog E, we
learn the entity annotation models EAoffline and
EAonline for annotation of entities in the Q&amp;A cor-
pus and the query respectively. Refer Section 3 for
details. For each di E D, we then annotate refer-
ences to entities in Wikipedia using EAoffline re-
sulting in annotated Q&amp;A corpus C. We then com-
pute relationships between entities and words using
C and E. These relationships are used to learn our
ETLM model.
Online processing: At runtime, annotate the user
query quser with entities using EAonlineto create an
enriched question q. Issue this query over the an-
notated corpus C and rank the candidates as per the
ETLM model described below.
</bodyText>
<subsectionHeader confidence="0.502116">
2.1 ETLM Model
</subsectionHeader>
<bodyText confidence="0.9992615">
Let the annotated query q (and similarly annotated
Q&amp;A pair d) be composed of sequence of token
spans Tq (and Td). Each token span tq (similarly
td) corresponds to sequence of contiguous words oc-
curring in the running text. These tq’s can corre-
spond to entity mentions, phrases or words. Let eq
denote the tokens spans that are annotated and neq
that are not (Tq = eq U neq). For example, in the
</bodyText>
<equation confidence="0.836731666666667">
 |Quadratic Formula
{z }
eq
</equation>
<bodyText confidence="0.99748025">
token span Quadratic Formula is linked to an
entity corresponding to Quadratic Equation3, while
all other token spans are marked as neq .
For the sake of simplicity, in this work we do
not identify phrases i.e. neq is always of unit word
length4. In the ETLM framework, the similarity be-
tween a query q and a document d within a collection
C is given by the probability
</bodyText>
<equation confidence="0.995647833333333">
score(q,d) � P(q|d) = Y P(tq|d)
tqEq
tq=eqUneq
P(tq|d) = (1— A)Pml(tq|d) + APml(tq|C)
Pml(tq|d) = X T(tq|td)Pml(td|d) (1)
tdEd
</equation>
<bodyText confidence="0.99868575">
Intuitively this indicates a generative process for cre-
ating q from d. Ideally both q and d are “only” com-
posed of e i.e. btq E q; tq E EU, where EU is the
universal set of entities 5 (similarly for all td). This
is because when the document was created, each and
every td E d had a sense attached to it. however in
reality, for various reasons, set of target entities are
clearly a subset of EU (for e.g. E: set of all entities
</bodyText>
<footnote confidence="0.96823075">
3http://en.wikipedia.org/wiki/Quadratic equation
4its not a restriction as the model is valid for neq consisting
of more than one word.
5language for creating q and d
</footnote>
<figure confidence="0.970070444444444">
query, What
 |{z }
|{z}
is
neq neq
|{z}
a
neq
?,
</figure>
<page confidence="0.672779">
1268
</page>
<figureCaption confidence="0.999673">
Figure 2: ETLM Architecture (gray and brown arrows indicate offline and online processes respectively
</figureCaption>
<bodyText confidence="0.9712045">
in the catalog) also not all of them may be recog-
nized by the annotation system.
</bodyText>
<listItem confidence="0.5301944">
T (tq|td) in Equation 1 denotes the probability
that a token span tq is the translation of token span
td. This induces the desired query expansion effect.
The key task is to estimate Pml(tq|C), T (tq|td) and
Pml(td|d); tq E eq U neq and td E ed U ned
</listItem>
<subsectionHeader confidence="0.988366">
2.2 Estimating Model Parameters
</subsectionHeader>
<bodyText confidence="0.999790333333333">
We adopt 2 different approach for estimating
T (tq|td), leading to 2 different configurations of
ETLM system. As the name suggests, ETLMqa is
estimated from Q&amp;A data (C and D) while we lever-
age the entity catalog (in our case it is Wikipedia) for
ETLMwiki.
</bodyText>
<subsectionHeader confidence="0.993614">
2.3 ETLMqa: Estimate from parallel corpus
</subsectionHeader>
<bodyText confidence="0.984281433333333">
Following (Xue et al., 2008) we pool the question
and answers from D to create a master parallel cor-
pus P = (qi, al), , (qn, an) U (al, qi), (an, qn).
This is used for learning T (ne|ne&apos;)6. Similarly we
create P* from C. We then derive 2 different paral-
lel corpora from P and P* as follows
Pentity We remove all non linked tokens ne from
P* thereby reducing it to parallel corpus over e.
This is used for learning T(e|e&apos;) i.e. translation
probabilities between two entities e and e&apos; in E.
Phybrid This is hybrid of Pentity and P where in
one part of Q&amp;A pair consists on only ne while
other consists of only e. This is used for learn-
ing T (ne|e) and T(e|ne).
To handle entities e, we introduce special id’s in the
ne space. Thus our universal token span set is given
6subscript of q and d has been dropped as translation proba-
bility learnt agnostic to it, due to pooling.
by V U E. This is done so that T (tq|td) is learnt
from P, Pentity and Phybrid, w/o any modification
to the corresponding translation algorithm (Brown
et al., 1993). Lets call this approach ETLMqa&apos;.
We explored another intuitive approach ETLMqa,
to learn T(e|e&apos;), T(e|ne), T(ne|e) and T(ne|ne&apos;)
directly by using only P* as our parallel corpus.
We do so by redistributing the probability mass
i.e. when calculating T(e|e&apos;), we redistribute prob-
ability mass spread over all the ne to e given by
Equation 2 and 3. Similar process is followed for
T(e|ne), T(ne|e) and T(ne|ne&apos;).
</bodyText>
<equation confidence="0.9974565">
_ T(e|e&apos;)
S(e|e&apos;) E (2)
tEV T (t|e&apos;)
S(e|e&apos;)
T(e|e&apos;) = E (3)
tEE T (t|e&apos;)
</equation>
<bodyText confidence="0.997987666666667">
Remaining model components are calculated using
Equation 4 and 5. Here d refers to question part of
the Q&amp;A pair.
</bodyText>
<equation confidence="0.9702905">
tft9,C + 1
Pml(tq|C) = (4)
Et&apos;EC tft&apos;,C + |C|
tft9,d
Pml(tq|d) = (5)
Et&apos;Ed tft&apos;,d
</equation>
<subsectionHeader confidence="0.978229">
2.4 ETLMwiki: Estimating from Wikipedia
</subsectionHeader>
<bodyText confidence="0.999281">
Number of symmetric measures have been pro-
posed (Medelyan et al., 2009) to measure seman-
tic relationships between entities and words using
Wikipedia. For our problem we need an asym-
metric measure. We use co-citation information
in Wikipedia to detect relatedness between enti-
ties (T(e|e&apos;)) and co-occurrence counts to estimate
</bodyText>
<page confidence="0.732349">
1269
</page>
<equation confidence="0.999186083333333">
T (ne|ne0) as follows: . 6
T(e|e0) co(e, e0) ( )
T(ne |ne0) = 7
T(ne|e) = ( )
Ee00 co(e&amp;quot;, e&apos;)
cf(ne, ne0)
E ne�� cf (ne&amp;quot;, ne&apos;)
tfne,D(e) + 1
T(e|ne) =
|D(e) |+ |V |
tfne,D(e) + 1
Ee0∈E tfne,D(e0) +  |E|
</equation>
<bodyText confidence="0.99833325">
Here d(e) represents the page corresponding to
entity e. D(e) represents concatenation of d(e)
and all context of size 5 surrounding anchor text in
Wikipedia that link to e. cf(ne, ne0) is the number
context windows of fixed size containing both
ne and ne0 in Wikipedia. In our case, we set the
window size at 10 (because this size turned out to be
reasonable in our pilot experiments). tft,d(e) is the
frequency of t in d(e); co(e, e0) indicates number
of entities in Wikipedia that have a hyperlink to
both e and e0. As links from pages with a small
number of outgoing links are generally considered
to be more valuable than links from pages with a
high outgoing link degree, we tried with weighted
version of 6 where the co-citations are weighted
by the outdegree of Wikipedia page corresponding
to entity s that link to e and e0. Lets denote the
weighted version by ETLMwiki and unweighted
version by ETLMwiki0. Pml(tq|C) and Pml(tq|d)
are estimated as per Equation 4 and 5 respectively.
</bodyText>
<subsectionHeader confidence="0.990247">
2.5 Self translation probability
</subsectionHeader>
<bodyText confidence="0.9899278">
To make sure self translation probability is not un-
derestimated i.e. T (t|t) &gt; T (t0|t) always holds
true, we introduce new parameter γ as T (t|t0) =
γ + (1 − γ)T(t|t0); γ = 0 when t =�t0 and γ &gt; 0.5
otherwise.
</bodyText>
<subsectionHeader confidence="0.658515">
2.6 ETLMcombo: Combining ETLMqa and
</subsectionHeader>
<bodyText confidence="0.973196071428571">
ETLMwiki
Often, combining language models yields better re-
sults than any of the individual language models
themselves. Linear interpolation is often the tech-
nique of choice in language modelling for combin-
ing models to exploit complementary features of the
component models. It involves taking a weighted
sum of the probabilities given by the component lan-
guage models. An advantage of the linear interpola-
tion is that it is simple and fast to calculate. If the
inputs are probability estimates, also the output is a
probability estimate. The mixture translation model
Tcombo(e|e0) over M component models is given by
Equation 10.
</bodyText>
<equation confidence="0.998619">
M
Tcombo(t|t0) = αjTj(t|t0)
M j=1 (10)
tEEUV; αj = 1; αj &gt; 0
j=1
</equation>
<bodyText confidence="0.999561857142857">
One can immediately notice that Tcombo(t|t0) has
one global weight for each of the M component
models which might not be ideal. With access to
large training data one could employ more power-
ful context dependent interpolation techniques (Liu
et al., 2008). In our case we have 2 components
Tqa and Twiki and four classes for each ; α(e,e0)7,
</bodyText>
<equation confidence="0.835318333333333">
wiki
αwiki , α
(e,ne) wiki and α(ne,e)
</equation>
<bodyText confidence="0.869821">
(ne,ne0) wiki ), one corresponding to
each class of T (t|t0). respectively.
</bodyText>
<sectionHeader confidence="0.994665" genericHeader="method">
3 Entity Annotation
</sectionHeader>
<bodyText confidence="0.999984166666667">
In this section we describe our entity annotation
system. Recently there has been lot of work ad-
dressing the problem of annotating text with links
to Wikipedia entities (Mihalcea and Csomai, 2007;
Bunescu and Pasca, 2006; Milne and Witten, 2008;
Kulkarni et al., 2009; Ratinov et al., 2011; Ferrag-
ina and Scaiella, 2010). We adopt a similar ap-
proach, wherein we first find the best disambigua-
tion (BESTDISAMBIGUATION) for a given mention
and then decide to prune it (PRUNE), via the dummy
mapping NA (similar to “no assignment” (Kulkarni
et al., 2009)).
</bodyText>
<subsectionHeader confidence="0.949776">
3.1 BESTDISAMBIGUATION
</subsectionHeader>
<bodyText confidence="0.999389857142857">
As defined earlier, e E E represent an entity cor-
responding to URN of a Wikipedia article. Let
Em = {em,1, em,2, ··· , em,|E„|I em,i E E repre-
sent the set of possible disambiguations for a men-
tion m (m is an index over all mentions in the cor-
pus). Given a mention m, task is to find best disam-
biguation e from Wikipedia. Without loss of gener-
</bodyText>
<footnote confidence="0.8846055">
7α(e,e ) = I − a(e,e )
9a wili
</footnote>
<page confidence="0.981661">
1270
</page>
<bodyText confidence="0.970665">
ality, we consider em,* E Em as the correct answer.
Let φ(m, em,j) represent the mapping onto features
between an entity mention m and the Wikipedia en-
tity em,j and v be the corresponding weight vector
and D(em,j) = v φ(m, em,j) represent the disam-
biguation score. The task is to learn v such that
argmax D(em,j) gives the best disambiguation for
e.
the mention m.
We pose this as a ranking problem and solve
it using max-margin technique (Joachims, 2002;
Joachims, 2006) as follows
</bodyText>
<equation confidence="0.992755">
W φ(m, em,*) &gt; W φ(m, em,j) + ξi,j (11)
Vi, Vj : ξi,j &gt; 0
</equation>
<bodyText confidence="0.999909285714286">
where E ξi,j is the total training error that upper
bounds the number of pair preferences violations.
This is controlled by adjusting the parameter C. Note
that Equation 11 means pairwise comparison be-
tween the correct disambiguation em,* and other dis-
ambiguation candidates em,j such that j =� index
corresponding to *.
</bodyText>
<subsectionHeader confidence="0.966392">
3.2 PRUNE
</subsectionHeader>
<bodyText confidence="0.999962666666667">
The disambiguation phase produces one candidate
disambiguation per mention. To discard any un-
meaningful annotations a simple strategy similar to
LOCAL (Kulkarni et al., 2009) is followed where the
D(em,*) is compared against a predefined threshold
ρna, so that if D(em,*) &lt; ρna then that annotation
for menton m is discarded by linking m to NA. The
parameter ρna allows the algorithm to back-off when
short of evidence.
</bodyText>
<subsectionHeader confidence="0.846881">
3.3 FEATUREMAP φ(m, em,j)
</subsectionHeader>
<bodyText confidence="0.991154413793103">
Sense probability prior (SP): It represents the prior
probability that a mention name s points to a specific
entity in Wikipedia. For example, without any other
information, mention name “tree” will more likely
refer to the entity woody plant8, rather than the less
8en.wikipedia.org/wiki/Tree
popular notion related to graphs 9.
Entity Probability prior (EP): It captures the pop-
ularity knowledge as a distribution of entities, i.e.,
the EP(ei) should be larger than EP(ej) if ei is
more popular than ej. This score is independent of
the mention name.
Context specific features: It captures the tex-
tual similarity between weighted word vectors cor-
responding to the context of the mention (window
around the mention) and textual description associ-
ated with the entity (Wikipedia page).
Let EAonline and EAoffline represent config-
urations for annotating user question and corpus
respectively. For EAonline, user question repre-
sents the document from which context specific
features are computed. For EAoffline, question
and the answer(best) is concatenated to represents
the document. Based on the “one sense per dis-
course” assumption, one additional heuristic is used
in EAoffline where, for the same Q&amp;A pair, if same
name mention is repeated multiple times across the
question and the answer then one with the maximum
D(em,*) &gt; ρna is annotated for all instances.
</bodyText>
<subsectionHeader confidence="0.987696">
3.4 Annotation Experiments
</subsectionHeader>
<bodyText confidence="0.995904761904762">
We used 2010 version of Wikipedia as our knowl-
edge base. It contains more than 2.5 million en-
tities. Annotations were done by volunteers fluent
in english. Volunteers were told to be as exhaus-
tive as possible and tag all possible name mentions,
even if to mark them as ”NA”. Inter-annotator agree-
ment=92.1%; Kappa coefficient = 0.72. As our cor-
pus, we collected 8.3K manual annotations spanning
1315 Q&amp;A pairs. 2.8K of the annotations were as-
signed to NA. 2.1K annotations (out of 8.3K) were
made in the question of which 551 were assigned to
NA. We use Precision, Recall and F1 score micro-
averaged across documents as the evaluation mea-
sures. We do a linear scan of data to identify en-
tity mentions by first tokenizing and then identify-
ing token sequences that maximally match an en-
tity ID in the entity name dictionary (constructed
using Wikipedia anchor text, redirect pages). Fig-
ure 3 outlines the performance of EAoffline and
EAonline. We measured EAoffline in 3 test data
configurations; (1) EA offline: measured over entire
</bodyText>
<figure confidence="0.76436">
9en.wikipedia.org/wiki/Tree (data structure)
minimize 1 �− ω · 1:
+��+ 2 �− ω + C ξi,j
ω ,ξ
subject to
Vm,Vem,j E Em − em,* :
1271
</figure>
<figureCaption confidence="0.999833">
Figure 3: Precision v/s Recall
</figureCaption>
<bodyText confidence="0.983970307692308">
annotation set; 2) EAoffline&apos; is measured only on
annotations made in question. this is done to com-
pare it with EAonline; 3) EAoffline* is similar to
(2), only difference is that for (2) entire Q&amp;A pair
is the context, while here only question part is the
context. This is done to check if separate annotators
are required for online and online phase. As seen
in Figure 3, this indeed is necessary as EAoffline*
performs worse than EAonline. Closer look at the
feature weights revealed that in EAoffline context
specific features have much more weightage when
compared to its weight in EAonline, on the contrary
EAonline weighs SP significantly higher.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999952">
We now describe the empirical evaluation where
we compare our techniques against the baseline
techniques. We use several standard measures (R-
Precision, MAP, MRR, Precision@k) in evaluation.
We first describe the dataset used followed by de-
scribing an exhaustive set of results across tech-
niques and performance measures.
</bodyText>
<subsectionHeader confidence="0.952688">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.978072">
We crawled a dataset of —5 million questions and
answers from Yahoo! Answers spanning all the leaf
level categories. Tokenization and stop word re-
moval were the only preprocessing steps performed.
We have used a stoplist10 having a vocabulary of 429
common words to remove the stopwords.
In our retrieval experiments we used 339 queries
(average length 5.6 words). We employed pool-
ing technique used in the TREC conference series.
10http://truereader.com/manuals/onix/stopwords1.html
We pooled the top 25 Q&amp;A pairs from retrieval re-
sults generated by varying the retrieval algorithms
and the search field. Relevance judgments were
marked by human annotators without disclosing the
identity of method used for retrieval. The annota-
tors were asked to label candidate as “relevant” or
“irrelevant” based on semantic similarity with the
query. Answer quality/correctness was not a crite-
ria. In case of disagreement between two volunteers,
authors made the final judgment. Inter-annotator
agreement was 87.9% and Kappa coefficient = 0.68.
Over all we had collected more than 12K relevance
judgements corresponding to these queries, of which
&gt;2.3K were marked as relevant.
</bodyText>
<subsectionHeader confidence="0.970737">
4.2 Baselines
</subsectionHeader>
<bodyText confidence="0.999940181818182">
To evaluate the effectiveness of our models we
compared them against the following baselines
Traditional models: VSM (Zobel and Moffat,
2006) and OKAPI BM25 (Robertson et al., 1996)
(k1, b, and k3 are parameters that are set to 1.2, 0.75
and oc respectively).
Translation based language models: TLM (Jeon
et al., 2005), TransLM (using answers) (Xue et al.,
2008) and CTM (Lee et al., 2008).
For our experiments we used a set of 50 queries to
select the model parameters. Translation based lan-
guage model use 2 parameters; smoothing parameter
A in the Language Model and Q to control the self-
translation impact in the TransLM. Final values of
parameters used in our experiments were A = 0.2
(Zhai and Lafferty, 2004) and Q = 0.75 (Xue et
al., 2008). For CTM, we used tf-idf based weigh-
ing scheme (Lee et al., 2008) to remove words from
the (QIIA) corpus P. Word elimination threshold of
20% was selected based on the above 50 queries. Fi-
nal values of ETLM parameters used in our experi-
ments were A = 0.18 and -y = 0.65.
</bodyText>
<subsectionHeader confidence="0.997392">
4.3 Result Analysis
</subsectionHeader>
<bodyText confidence="0.9999715">
Table 2 presents the performance of the various tech-
niques. Under each measure, we highlight the best
performing technique. Performance of all the trans-
lation based models is better than VSM and OKAPI
thereby confirming the importance of addressing the
lexical gap. Using high confidence annotations for
</bodyText>
<page confidence="0.97501">
1272
</page>
<table confidence="0.999792555555555">
MAP %chg MRR %chg R-Prec %chg Prec@5 %chg Prec@10 %chg
VSM 0.221 0.421 0.21 0.202 0.15
OKAPI 0.298 0.532 0.271 0.264 0.214
TLM 0.337 0.583 0.318 0.297 0.239
TransLM 0.352 0.612 0.347 0.332 0.261
CTM 0.361 0.641 0.351 0.341 0.279
ETLMqa 0.3901 8.03 0.6991 9.05 0.3791 7.98 0.3671 7.62 0.3021 8.24
ETLMwiki 0.4131 14.40 0.7191 12.17 0.3991 13.68 0.3911 14.66 0.3231 15.77
ETLMeombo 0.4271 18.28 0.7261 13.26 0.4131 17.66 0.4071 19.35 0.3311 18.64
</table>
<tableCaption confidence="0.9960895">
Table 2: Comparisons of retrieval models. † indicate a statistically significant improvement over the CTM using paired
t-test with p-value &lt; 0.05. %chg indicates change over CTM as it is the most competitive baseline
</tableCaption>
<bodyText confidence="0.999794709677419">
query expansion in ETLM, leads to an improved
performance as compared to the all the baseline
methods that do not consider this signal. This is
validated by the fact that ETLMqa and ETLMwiki
can achieve statistically significant improvements in
terms of all the measures. The reason for this im-
provement is the context sensitive computation of
T(t|t&apos;) leading to reduced spurious expansions and
improved top expansions, this is made possible be-
cause of entity disambiguation. This computation in
baselines happens on word by word basis without
exploiting contextual information. ETLMqa per-
forms worse than ETLMwiki. On close inspec-
tion of failure cases and translation probability ta-
bles we found that T(e|e&apos;) for ETLMqa was much
worse than ETLMwiki. This is because for getting
good estimates of T(e|e&apos;), we need enough instances
where both e and e&apos; need to be correctly annotated
in the same Q&amp;A pair. Failure in this leads to sparse
counts thereby reducing the gap in T(e|e&apos;) scores
for related and unrelated e. Figure 4 shows the
impact of choices made for learning the translation
probabilities T(t|t&apos;). We found that ETLMwiki per-
forms slightly better than ETLMwiki/, indicating the
utility of weighted co-citation measure for comput-
ing T(e|e&apos;). We believe that embedding other mea-
sures that are better in capturing relationships from
Wikipedia, should improve the performance. Simi-
larly ETLMqa also performs better than ETLMqa/.
This is because for creating Pentity all ne are re-
moved. This leads to count sparsity problem dis-
</bodyText>
<figureCaption confidence="0.999105">
Figure 4: Performance of ETLM configurations
</figureCaption>
<bodyText confidence="0.999777285714286">
cussed above, but slightly worse. Due to absence
of ne, in ETLMqa/ e&apos; in d are thought be being
generated “only” from e in q. On the contrary in
ETLMqa, e&apos; had an option of mapping to ne in q.
An interesting observation is that while the perfor-
mances of different configurations vary, all of them
perform better than CTM which is the best baseline.
</bodyText>
<subsectionHeader confidence="0.99945">
4.4 Impact of Annotations on retrieval
</subsectionHeader>
<bodyText confidence="0.9997992">
Since entities are central in our model, impact of
entity annotation on quaer is one of the most im-
portant aspect to be studied. Figure 5 shows the
plot of retrieval measures obtained by varying pna
in EAonline. CTM is shown by horizontal lines. As
explained in Section 3, value of pna is inversely pro-
portional to aggressiveness of annotation. Which
implies for high values, EAonline will annotate only
those mentions in query that its highly confident
about. Beyond a value no annotations are made.
</bodyText>
<page confidence="0.991416">
1273
</page>
<figureCaption confidence="0.998997">
Figure 5: Impact of query annotation on retrieval. x-axis
represents value of pna used to control annotation
</figureCaption>
<bodyText confidence="0.999914666666667">
This is represented on the extreme right in Figure 5.
One important observation is that, even with no an-
notations made in query, performance of ETLMqa
and ETLMwiki is competitive to CTM. This is ev-
idence for addressing the noise related issue for
which CTM is designed. For large range of values,
all ETLM configurations are above CTM. As we de-
crease pna performance increases smoothly and then
after a certain point (pna = 5) is starts decreasing.
</bodyText>
<subsectionHeader confidence="0.851103">
4.5 ETLMcombo
</subsectionHeader>
<bodyText confidence="0.975052">
We believe that T (t|t&apos;) learnt from one source would
encode word association characteristics which might
not be exactly the same across sources.ETLMcombo
tries to address this by combining the two models.
Values for mixing parameters are : α(e,e&apos;)
</bodyText>
<equation confidence="0.921833666666667">
wiki = 0.9511,
α(e,ne) = 0.75, a(ne,ne&apos;) = 0.7 and α(ne,e) = 0.75).
wiki wiki wiki
</equation>
<bodyText confidence="0.999986285714286">
The interpolation weights were obtained by optimiz-
ing the retrieval performance by doing a using grid
search over the parameter space. Same 50 queries
were used for tuning. As seen entity relationships
obtained from Wikipedia are far superior to one
from Q&amp;A corpus. As seen in Table 2 combining
the two models improves the performance.
</bodyText>
<sectionHeader confidence="0.999946" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.9998324">
Recently Q&amp;A retrieval has been garnering lot of at-
tention. Translation model (TLM) (Jeon et al., 2005)
has been extensively employed in question search
and has been shown to outperform the traditional IR
methods significantly (VSM, BM25, LM). Existing
</bodyText>
<equation confidence="0.62857">
11α(e,e�)
qa _ (1 − 0.95)
work can be broadly grouped under the following
topics:
</equation>
<listItem confidence="0.885382555555556">
(a) Improved training of translation models by ex-
ploiting answer content/inter-word co-occurrence
relations and restriction to reliable parallel cor-
pora: Translation-based language model (TRLM)
(Xue et al., 2008) improved stability of TLM by
providing better probability estimates and also ex-
ploited answers for question retrieval. It further im-
proved the retrieval results and obtained the state-of-
the-art performance. Another line of work on trans-
</listItem>
<bodyText confidence="0.975927785714286">
lation models focused on providing suitable parallel
data to learn the translation probabilities. Compact
translation models (CTM) (Lee et al., 2008) tried to
further improve the translation probabilities based
on question-answer pairs by selecting the most im-
portant terms to build compact translation models.
We show that such special-purpose models to con-
trol noisy translations may not be necessary because
models learnt using entity annotations are robust to
noise in Q&amp;A data.
Instead of using noisy Q&amp;A data, new approach
(Bernhard and Gurevych, 2009) to build parallel cor-
pus from reliable sources has showed improvements.
They proposed to use as a parallel training data com-
prising of set the definitions and glosses provided
for the same term by different lexical semantic re-
sources. We move beyond terms and capture rela-
tionships between entities and terms using the page
contents and link structure in Wikipedia.
Apart from translation models there are other
approaches (Gao et al., 2004) that try to extend the
existing language models for adhoc retrieval by
incorporating term relationships or dependencies.
Some expand queries using word relationships
derived from co-occurrence thesaurus (Bai et al.,
2005; Qiu and Frei, 1993), hand-crafted thesaurus
(Liu et al., 2004; Voorhees, 1994) and combination
of both (Cao et al., 2005).
</bodyText>
<listItem confidence="0.9350785">
(b) Incorporation of query context information in
translation models using latent factor modeling
and smoothing approaches: All these existing
approaches mentioned above are considered to be
context independent, in that they do not take into
account any contextual information in modeling
word word relationships. Topic signature model
(Zhou et al., 2007) exploited contextual information
</listItem>
<page confidence="0.992331">
1274
</page>
<bodyText confidence="0.995050235294118">
by decomposing a document into a set of weighted
topic signatures and use it for model smoothing.
This model turns out to be inefficient when con-
fronted with ambiguous words and phrases because
it is unable to disambiguate the sense of topic
signatures. Others (Liu and Croft, 2004) perform
semantic smoothing by means of clustering. Re-
cently (Tu et al., 2010; Cai et al., 2011; Zhou
et al., 2011) showed improved performance by
performing sense based smoothing for document
retrieval, latent topic mining and phase based
retrieval respectively. Contrary to these approaches
we used entity disambiguation to capture contextual
information for improving Q&amp;A retrieval.
(c) Complementary ideas for improving retrieval
performance that can be used alongside translation
models: Other work on question retrieval include
the use of category information available (Cao et
al., 2010), learning-to-rank techniques (Bian et al.,
2008; Surdeanu et al., 2008; Bunescu and Huang,
2010), proposed a syntactic tree matching ((Wang et
al., 2009) or question structure for important phrase
matching (Duan et al., 2008)). These methods seem
orthogonal to ours, in some cases complementary
and can be leveraged to get an even better perfor-
mance
There also exists work where exploiting entity
based representation has been found helpful in in-
formation retrieval (Singh et al., 2009; Egozi et al.,
2011; Meij et al., 2008; Grootjen and van der Weide,
2006). In our work we use entity annotations in
Q&amp;A retrieval context. There is also some work on
using Wikipedia in general web search (Xu et al.,
2009).
</bodyText>
<sectionHeader confidence="0.995661" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999783416666667">
In this work we extend word based model to in-
corporate semantic concepts for addressing the lex-
ical gap issue in retrieval models for large online
Q&amp;A collections. Compared to the existing trans-
lation based model, our model is more robust and
effective in that it can perform context aware expan-
sions. We proposed ways to embed rich information
freely available in Wikipedia into our models and
combine it one learnt from Q&amp;A corpus. Experi-
ments performed on a large real Q&amp;A data demon-
strate that all configurations of ETLM significantly
outperforms existing models for Q&amp;A retrieval.
</bodyText>
<sectionHeader confidence="0.997716" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999819">
Thanks to Srujana Merugu for helpful discussions.
Thanks to the anonymous reviewers for helping us
improve the presentation.
</bodyText>
<sectionHeader confidence="0.998928" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981732">
Lada A. Adamic, Jun Zhang, Eytan Bakshy, and Mark S.
Ackerman. 2008. Knowledge sharing and yahoo an-
swers: everyone knows something. In Proceedings of
the 17th international conference on World Wide Web,
WWW ’08, pages 665–674, New York, NY, USA.
ACM.
Jing Bai, Dawei Song, Peter Bruza, Jian-Yun Nie, and
Guihong Cao. 2005. Query expansion using term
relationships in language models for information re-
trieval. In Proceedings of the 14th ACM interna-
tional conference on Information and knowledge man-
agement, CIKM ’05, pages 688–695, New York, NY,
USA. ACM.
Adam Berger and John Lafferty. 1999. Information
retrieval as statistical translation. In Proceedings of
the 22nd annual international ACM SIGIR conference
on Research and development in information retrieval,
SIGIR ’99, pages 222–229, New York, NY, USA.
ACM.
Delphine Bernhard and Iryna Gurevych. 2009. Combin-
ing lexical semantic resources with question &amp; answer
archives for translation-based answer finding. In ACL-
IJCNLP ’09: Proceedings of the Joint Conference of
the 47th Annual Meeting of the ACL and the 4th Inter-
national Joint Conference on Natural Language Pro-
cessing of the AFNLP: Volume 2, pages 728–736, Mor-
ristown, NJ, USA. Association for Computational Lin-
guistics.
Jiang Bian, Yandong Liu, Eugene Agichtein, and
Hongyuan Zha. 2008. Finding the right facts in the
crowd: factoid question answering over social media.
In WWW ’08: Proceeding of the 17th international
conference on World Wide Web, pages 467–476, New
York, NY, USA. ACM.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Comput. Linguist., 19:263–311, June.
Razvan Bunescu and Yunfeng Huang. 2010. Learning
the relative usefulness of questions in community qa.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, EMNLP
</reference>
<page confidence="0.899668">
1275
</page>
<reference confidence="0.999593420560748">
’10, pages 97–107, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
R. Bunescu and M. Pasca. 2006. Using encyclopedic
knowledge for named entity disambiguation. In Pro-
ceedings of EACL, volume 6, pages 9–16.
Li Cai, Guangyou Zhou, Kang Liu, and Jun Zhao. 2011.
Learning the latent topics for question retrieval in com-
munity qa. In Proceedings of 5th International Joint
Conference on Natural Language Processing, pages
273–281, Chiang Mai, Thailand, November. Asian
Federation of Natural Language Processing.
Guihong Cao, Jian-Yun Nie, and Jing Bai. 2005. Inte-
grating word relationships into language models. In
Proceedings of the 28th annual international ACM SI-
GIR conference on Research and development in in-
formation retrieval, SIGIR ’05, pages 298–305, New
York, NY, USA. ACM.
Xin Cao, Gao Cong, Bin Cui, and Christian S. Jensen.
2010. A generalized framework of exploring category
information for question retrieval in community ques-
tion answer archives. In WWW ’10: Proceedings of
the 19th international conference on World wide web,
pages 201–210, New York, NY, USA. ACM.
Huizhong Duan, Yunbo Cao, Chin yew Lin, and Yong
Yu. 2008. Searching questions by identifying ques-
tion topic and question focus. In In Proceedings of
46th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Tchnologies
(ACL:HLT).
Ofer Egozi, Shaul Markovitch, and Evgeniy Gabrilovich.
2011. Concept-based information retrieval using ex-
plicit semantic analysis. ACM Trans. Inf. Syst.,
29(2):8:1–8:34, April.
Paolo Ferragina and Ugo Scaiella. 2010. Tagme: on-the-
fly annotation of short text fragments (by wikipedia
entities). In Proceedings of the 19th ACM interna-
tional conference on Information and knowledge man-
agement, CIKM ’10, pages 1625–1628, New York,
NY, USA. ACM.
Jianfeng Gao, Jian-Yun Nie, Guangyuan Wu, and Gui-
hong Cao. 2004. Dependence language model for
information retrieval. In Proceedings of the 27th
annual international ACM SIGIR conference on Re-
search and development in information retrieval, SI-
GIR ’04, pages 170–177, New York, NY, USA. ACM.
F. A. Grootjen and Th. P. van der Weide. 2006. Concep-
tual query expansion. Data Knowl. Eng., 56(2):174–
193, February.
Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee. 2005.
Finding similar questions in large question and an-
swer archives. In Proceedings of the 14th ACM in-
ternational conference on Information and knowledge
management, CIKM ’05, pages 84–90, New York, NY,
USA. ACM.
Thorsten Joachims. 2002. Optimizing search engines
using clickthrough data. In Proceedings of the eighth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, KDD ’02, pages 133–
142, New York, NY, USA. ACM.
Thorsten Joachims. 2006. Training linear svms in lin-
ear time. In Proceedings of the 12th ACM SIGKDD
international conference on Knowledge discovery and
data mining, KDD ’06, pages 217–226, New York,
NY, USA. ACM.
S. Kulkarni, A. Singh, G. Ramakrishnan, and
S. Chakrabarti. 2009. Collective annotation of
wikipedia entities in web text. In Proceedings of
the 15th ACM SIGKDD international conference
on Knowledge discovery and data mining, pages
457–466. ACM.
Jung-Tae Lee, Sang-Bum Kim, Young-In Song, and Hae-
Chang Rim. 2008. Bridging lexical gaps between
queries and questions on large online q&amp;a collec-
tions with compact translation models. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, EMNLP ’08, pages 410–418,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Xiaoyong Liu and W. Bruce Croft. 2004. Cluster-based
retrieval using language models. In Proceedings of
the 27th annual international ACM SIGIR conference
on Research and development in information retrieval,
SIGIR ’04, pages 186–193, New York, NY, USA.
ACM.
Shuang Liu, Fang Liu, Clement Yu, and Weiyi Meng.
2004. An effective approach to document retrieval
via utilizing wordnet and recognizing phrases. In Pro-
ceedings of the 27th annual international ACM SIGIR
conference on Research and development in informa-
tion retrieval, SIGIR ’04, pages 266–272, New York,
NY, USA. ACM.
Xunying Liu, Mark J. F. Gales, and Philip C. Woodland.
2008. Context dependent language model adaptation.
In INTERSPEECH 2008, 9th Annual Conference of
the International Speech Communication Association,
Brisbane, Australia, September 22-26, 2008, pages
837–840. ISCA.
Olena Medelyan, David Milne, Catherine Legg, and
Ian H. Witten. 2009. Mining meaning from wikipedia.
Int. J. Hum.-Comput. Stud., 67:716–754, September.
Edgar Meij, Dolf Trieschnigg, Maarten de Rijke, and
Wessel Kraaij. 2008. Parsimonious concept model-
ing. In Proceedings of the 31st annual international
ACM SIGIR conference on Research and development
in information retrieval, SIGIR ’08, pages 815–816,
New York, NY, USA. ACM.
R. Mihalcea and A. Csomai. 2007. Wikify!: linking
</reference>
<page confidence="0.799221">
1276
</page>
<reference confidence="0.999078868131869">
documents to encyclopedic knowledge. In CIKM, vol-
ume 7, pages 233–242.
D. Milne and I.H. Witten. 2008. Learning to link with
wikipedia. In Proceeding of the 17th ACM conference
on Information and knowledge management, pages
509–518. ACM.
Robert C. Moore. 2004. Improving ibm word-alignment
model 1. In Proceedings of the 42nd Annual Meeting
on Association for Computational Linguistics, ACL
’04, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Yonggang Qiu and Hans-Peter Frei. 1993. Concept
based query expansion. In Proceedings of the 16th
annual international ACM SIGIR conference on Re-
search and development in information retrieval, SI-
GIR ’93, pages 160–169, New York, NY, USA. ACM.
Lev Ratinov, Dan Roth, Doug Downey, and Mike An-
derson. 2011. Local and global algorithms for dis-
ambiguation to wikipedia. In Proceedings of the 49th
Annual Meeting of the Association for Computational
Linguistics: Human Language Technologies - Volume
1, HLT ’11, pages 1375–1384, Stroudsburg, PA, USA.
Association for Computational Linguistics.
S.E. Robertson, S. Walker, S. Jones, M.M. Hancock-
Beaulieu, and M. Gatford. 1996. Okapi at trec-3.
pages 109–126.
Amit Singh and Karthik Visweswariah. 2011. CQC:
classifying questions in cqa websites. In Proceedings
of the 20th ACM international conference on Informa-
tion and knowledge management, CIKM ’11, pages
2033–2036, New York, NY, USA. ACM.
Amit Singh, Sayali Kulkarni, Somnath Banerjee, Ganesh
Ramakrishnan, and Soumen Chakrabarti. 2009. Cu-
rating and searching the annotated web. In In SIGKDD
Conference, 2009. ACM.
Mihai Surdeanu, Massimiliano Ciaramita, and Hugo
Zaragoza. 2008. Learning to rank answers on large
online qa collections. In In Proceedings of the 46th
Annual Meeting for the Association for Computational
Linguistics: Human Language Technologies (ACL-08:
HLT, pages 719–727.
Xinhui Tu, Tingting He, Long Chen, Jing Luo, and
Maoyuan Zhang. 2010. Wikipedia-based semantic
smoothing for the language modeling approach to in-
formation retrieval. In Proceedings of the 32nd Eu-
ropean conference on Advances in Information Re-
trieval, ECIR’2010, pages 370–381, Berlin, Heidel-
berg. Springer-Verlag.
Ellen M. Voorhees. 1994. Query expansion using
lexical-semantic relations. In Proceedings of the 17th
annual international ACM SIGIR conference on Re-
search and development in information retrieval, SI-
GIR ’94, pages 61–69, New York, NY, USA. Springer-
Verlag New York, Inc.
Kai Wang, Zhaoyan Ming, and Tat-Seng Chua. 2009.
A syntactic tree matching approach to finding similar
questions in community-based qa services. In Pro-
ceedings of the 32nd international ACM SIGIR con-
ference on Research and development in information
retrieval, SIGIR ’09, pages 187–194, New York, NY,
USA. ACM.
Yang Xu, Gareth J.F. Jones, and Bin Wang. 2009.
Query dependent pseudo-relevance feedback based on
wikipedia. In Proceedings of the 32nd international
ACM SIGIR conference on Research and development
in information retrieval, SIGIR ’09, pages 59–66, New
York, NY, USA. ACM.
Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft. 2008.
Retrieval models for question and answer archives. In
Proceedings of the 31st annual international ACM SI-
GIR conference on Research and development in in-
formation retrieval, SIGIR ’08, pages 475–482, New
York, NY, USA. ACM.
Chengxiang Zhai and John Lafferty. 2004. A study of
smoothing methods for language models applied to in-
formation retrieval. ACM Trans. Inf. Syst., 22(2):179–
214, April.
Xiaohua Zhou, Xiaohua Hu, and Xiaodan Zhang. 2007.
Topic signature language models for ad hoc retrieval.
IEEE Trans. on Knowl. and Data Eng., 19(9):1276–
1287, September.
Guangyou Zhou, Li Cai, Jun Zhao, and Kang Liu. 2011.
Phrase-based translation model for question retrieval
in community question answer archives. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies - Volume 1, HLT ’11, pages 653–662,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Justin Zobel and Alistair Moffat. 2006. Inverted files for
text search engines. ACM Comput. Surv., 38, July.
</reference>
<page confidence="0.99237">
1277
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.647782">
<title confidence="0.953759">Entity based Q&amp;A retrieval</title>
<author confidence="0.820888">Amit</author>
<affiliation confidence="0.892894">IBM Bangalore,</affiliation>
<email confidence="0.997885">amising3@in.ibm.com</email>
<abstract confidence="0.99984228">Bridging the lexical gap between the user’s question and the question-answer pairs in the Q&amp;A archives has been a major challenge for Q&amp;A retrieval. State-of-the-art approaches address this issue by implicitly expanding the queries with additional words using statistical translation models. While useful, the effectiveness of these models is highly dependant on the availability of quality corpus in the absence of which they are troubled by noise issues. Moreover these models perform word based expansion in a context agnostic manner resulting in translation that might be mixed and fairly general. This results in degraded retrieval performance. In this work we address the above issues by extending the lexical word based translation model to incorporate semantic concepts (entities). We explore strategies to learn the translation probabilities between words and the concepts using the Q&amp;A archives and a popular entity catalog. Experiments conducted on a large scale real data show that the proposed techniques are promising.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lada A Adamic</author>
<author>Jun Zhang</author>
<author>Eytan Bakshy</author>
<author>Mark S Ackerman</author>
</authors>
<title>Knowledge sharing and yahoo answers: everyone knows something.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th international conference on World Wide Web, WWW ’08,</booktitle>
<pages>665--674</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1358" citStr="Adamic et al., 2008" startWordPosition="206" endWordPosition="209">rmance. In this work we address the above issues by extending the lexical word based translation model to incorporate semantic concepts (entities). We explore strategies to learn the translation probabilities between words and the concepts using the Q&amp;A archives and a popular entity catalog. Experiments conducted on a large scale real data show that the proposed techniques are promising. 1 Introduction Over the past few years community-based question answering (CQA) portals like Naver, Yahoo! Answers, Baidu Zhidao and WikiAnswers have attracted great attention from both academia and industry (Adamic et al., 2008; Singh and Visweswariah, 2011). These portals foster collaborative creation of content by allowing the users to both submit questions to be answered and answer questions asked by other users. These portals aim to provide highly focused access to this information by directly returning pertinent question and answer (Q&amp;A) pairs to the users questions, instead of a long list of ranked URLs. This is in noted contrast to the usual search paradigm, where the question is used to search the database of potential answers, in this case the question is used to search the database of previous questions, w</context>
</contexts>
<marker>Adamic, Zhang, Bakshy, Ackerman, 2008</marker>
<rawString>Lada A. Adamic, Jun Zhang, Eytan Bakshy, and Mark S. Ackerman. 2008. Knowledge sharing and yahoo answers: everyone knows something. In Proceedings of the 17th international conference on World Wide Web, WWW ’08, pages 665–674, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Bai</author>
<author>Dawei Song</author>
<author>Peter Bruza</author>
<author>Jian-Yun Nie</author>
<author>Guihong Cao</author>
</authors>
<title>Query expansion using term relationships in language models for information retrieval.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM international conference on Information and knowledge management, CIKM ’05,</booktitle>
<pages>688--695</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="30142" citStr="Bai et al., 2005" startWordPosition="5044" endWordPosition="5047"> has showed improvements. They proposed to use as a parallel training data comprising of set the definitions and glosses provided for the same term by different lexical semantic resources. We move beyond terms and capture relationships between entities and terms using the page contents and link structure in Wikipedia. Apart from translation models there are other approaches (Gao et al., 2004) that try to extend the existing language models for adhoc retrieval by incorporating term relationships or dependencies. Some expand queries using word relationships derived from co-occurrence thesaurus (Bai et al., 2005; Qiu and Frei, 1993), hand-crafted thesaurus (Liu et al., 2004; Voorhees, 1994) and combination of both (Cao et al., 2005). (b) Incorporation of query context information in translation models using latent factor modeling and smoothing approaches: All these existing approaches mentioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for </context>
</contexts>
<marker>Bai, Song, Bruza, Nie, Cao, 2005</marker>
<rawString>Jing Bai, Dawei Song, Peter Bruza, Jian-Yun Nie, and Guihong Cao. 2005. Query expansion using term relationships in language models for information retrieval. In Proceedings of the 14th ACM international conference on Information and knowledge management, CIKM ’05, pages 688–695, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Berger</author>
<author>John Lafferty</author>
</authors>
<title>Information retrieval as statistical translation.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’99,</booktitle>
<pages>222--229</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2253" citStr="Berger and Lafferty, 1999" startWordPosition="352" endWordPosition="355">ectly returning pertinent question and answer (Q&amp;A) pairs to the users questions, instead of a long list of ranked URLs. This is in noted contrast to the usual search paradigm, where the question is used to search the database of potential answers, in this case the question is used to search the database of previous questions, which in turn are associated with answers. This involves addressing the word mismatch problem between the users question and the question-answer pairs in the archive. This is the major challenge for Q&amp;A retrieval. Researchers have proposed the use of translation models (Berger and Lafferty, 1999; Jeon et al., 2005; Xue et al., 2008) to solve this problem. As a principled approach to capturing semantic word relations, statistical translation language models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional document language models on Q&amp;A retrieval task. The basic idea is to estimate the likelihood of translating a document1 to a query by exploiting the dependencies that exists between query words and document words. For example the document containing the word Wheezing may well answer the question containing the term Asthma. They lea</context>
<context position="5138" citStr="Berger and Lafferty, 1999" startWordPosition="811" endWordPosition="814">on to all the above problems lies in a unified model in which entities are a primary citizen. The guiding hypothesis being, an entity based representation provides a less ambiguous representation of the users question and provides for a more semantically accurate expansion if the relationship between entities and words can be estimated more reliably. Our main contributions are 1. We propose Entity based Translation Language Model (ETLM) for Q&amp;A retrieval that accommodates semantic information associated between entities and words. Being closely related to the general source-channel framework (Berger and Lafferty, 1999), the model enjoys its benefits, while mitigating some of its shortcomings. Specifically it provides for context aware expansions of the query by exploiting entity annotations on both, the document and the query side. Entity annotations also provide a means to handle the “many-to-one” (Moore, 2004) translation limitation in the IBM model, due to which each word in the target document can be generated by at most one word in the question2. For the same reasons, it also alleviates another related limitation by enabling translation between contiguous words across the query and documents (Moore, 20</context>
</contexts>
<marker>Berger, Lafferty, 1999</marker>
<rawString>Adam Berger and John Lafferty. 1999. Information retrieval as statistical translation. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’99, pages 222–229, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Delphine Bernhard</author>
<author>Iryna Gurevych</author>
</authors>
<title>Combining lexical semantic resources with question &amp; answer archives for translation-based answer finding.</title>
<date>2009</date>
<booktitle>In ACLIJCNLP ’09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>2</volume>
<pages>728--736</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="29479" citStr="Bernhard and Gurevych, 2009" startWordPosition="4941" endWordPosition="4944">btained the state-ofthe-art performance. Another line of work on translation models focused on providing suitable parallel data to learn the translation probabilities. Compact translation models (CTM) (Lee et al., 2008) tried to further improve the translation probabilities based on question-answer pairs by selecting the most important terms to build compact translation models. We show that such special-purpose models to control noisy translations may not be necessary because models learnt using entity annotations are robust to noise in Q&amp;A data. Instead of using noisy Q&amp;A data, new approach (Bernhard and Gurevych, 2009) to build parallel corpus from reliable sources has showed improvements. They proposed to use as a parallel training data comprising of set the definitions and glosses provided for the same term by different lexical semantic resources. We move beyond terms and capture relationships between entities and terms using the page contents and link structure in Wikipedia. Apart from translation models there are other approaches (Gao et al., 2004) that try to extend the existing language models for adhoc retrieval by incorporating term relationships or dependencies. Some expand queries using word relat</context>
</contexts>
<marker>Bernhard, Gurevych, 2009</marker>
<rawString>Delphine Bernhard and Iryna Gurevych. 2009. Combining lexical semantic resources with question &amp; answer archives for translation-based answer finding. In ACLIJCNLP ’09: Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2, pages 728–736, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Bian</author>
<author>Yandong Liu</author>
<author>Eugene Agichtein</author>
<author>Hongyuan Zha</author>
</authors>
<title>Finding the right facts in the crowd: factoid question answering over social media.</title>
<date>2008</date>
<booktitle>In WWW ’08: Proceeding of the 17th international conference on World Wide Web,</booktitle>
<pages>467--476</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="31585" citStr="Bian et al., 2008" startWordPosition="5259" endWordPosition="5262">ng by means of clustering. Recently (Tu et al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations in Q&amp;A retrieval context. There is also some wor</context>
</contexts>
<marker>Bian, Liu, Agichtein, Zha, 2008</marker>
<rawString>Jiang Bian, Yandong Liu, Eugene Agichtein, and Hongyuan Zha. 2008. Finding the right facts in the crowd: factoid question answering over social media. In WWW ’08: Proceeding of the 17th international conference on World Wide Web, pages 467–476, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<contexts>
<context position="2473" citStr="Brown et al., 1993" startWordPosition="390" endWordPosition="393"> of potential answers, in this case the question is used to search the database of previous questions, which in turn are associated with answers. This involves addressing the word mismatch problem between the users question and the question-answer pairs in the archive. This is the major challenge for Q&amp;A retrieval. Researchers have proposed the use of translation models (Berger and Lafferty, 1999; Jeon et al., 2005; Xue et al., 2008) to solve this problem. As a principled approach to capturing semantic word relations, statistical translation language models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional document language models on Q&amp;A retrieval task. The basic idea is to estimate the likelihood of translating a document1 to a query by exploiting the dependencies that exists between query words and document words. For example the document containing the word Wheezing may well answer the question containing the term Asthma. They learn the these dependencies (encoded as translation probabilities) between words using parallel mono-lingual corpora created from the Q&amp;A pairs. While useful, the effectiveness of these models is highly dependant on the av</context>
<context position="11660" citStr="Brown et al., 1993" startWordPosition="1975" endWordPosition="1978">|e&apos;) i.e. translation probabilities between two entities e and e&apos; in E. Phybrid This is hybrid of Pentity and P where in one part of Q&amp;A pair consists on only ne while other consists of only e. This is used for learning T (ne|e) and T(e|ne). To handle entities e, we introduce special id’s in the ne space. Thus our universal token span set is given 6subscript of q and d has been dropped as translation probability learnt agnostic to it, due to pooling. by V U E. This is done so that T (tq|td) is learnt from P, Pentity and Phybrid, w/o any modification to the corresponding translation algorithm (Brown et al., 1993). Lets call this approach ETLMqa&apos;. We explored another intuitive approach ETLMqa, to learn T(e|e&apos;), T(e|ne), T(ne|e) and T(ne|ne&apos;) directly by using only P* as our parallel corpus. We do so by redistributing the probability mass i.e. when calculating T(e|e&apos;), we redistribute probability mass spread over all the ne to e given by Equation 2 and 3. Similar process is followed for T(e|ne), T(ne|e) and T(ne|ne&apos;). _ T(e|e&apos;) S(e|e&apos;) E (2) tEV T (t|e&apos;) S(e|e&apos;) T(e|e&apos;) = E (3) tEE T (t|e&apos;) Remaining model components are calculated using Equation 4 and 5. Here d refers to question part of the Q&amp;A pair. </context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Comput. Linguist., 19:263–311, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Yunfeng Huang</author>
</authors>
<title>Learning the relative usefulness of questions in community qa.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>97--107</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="31634" citStr="Bunescu and Huang, 2010" startWordPosition="5267" endWordPosition="5270"> al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations in Q&amp;A retrieval context. There is also some work on using Wikipedia in general web search (Xu et</context>
</contexts>
<marker>Bunescu, Huang, 2010</marker>
<rawString>Razvan Bunescu and Yunfeng Huang. 2010. Learning the relative usefulness of questions in community qa. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 97–107, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bunescu</author>
<author>M Pasca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<volume>6</volume>
<pages>9--16</pages>
<contexts>
<context position="15581" citStr="Bunescu and Pasca, 2006" startWordPosition="2653" endWordPosition="2656">h of the M component models which might not be ideal. With access to large training data one could employ more powerful context dependent interpolation techniques (Liu et al., 2008). In our case we have 2 components Tqa and Twiki and four classes for each ; α(e,e0)7, wiki αwiki , α (e,ne) wiki and α(ne,e) (ne,ne0) wiki ), one corresponding to each class of T (t|t0). respectively. 3 Entity Annotation In this section we describe our entity annotation system. Recently there has been lot of work addressing the problem of annotating text with links to Wikipedia entities (Mihalcea and Csomai, 2007; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Ferragina and Scaiella, 2010). We adopt a similar approach, wherein we first find the best disambiguation (BESTDISAMBIGUATION) for a given mention and then decide to prune it (PRUNE), via the dummy mapping NA (similar to “no assignment” (Kulkarni et al., 2009)). 3.1 BESTDISAMBIGUATION As defined earlier, e E E represent an entity corresponding to URN of a Wikipedia article. Let Em = {em,1, em,2, ··· , em,|E„|I em,i E E represent the set of possible disambiguations for a mention m (m is an index over all mentions in the corp</context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>R. Bunescu and M. Pasca. 2006. Using encyclopedic knowledge for named entity disambiguation. In Proceedings of EACL, volume 6, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Cai</author>
<author>Guangyou Zhou</author>
<author>Kang Liu</author>
<author>Jun Zhao</author>
</authors>
<title>Learning the latent topics for question retrieval in community qa.</title>
<date>2011</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>273--281</pages>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="31038" citStr="Cai et al., 2011" startWordPosition="5184" endWordPosition="5187">entioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This model turns out to be inefficient when confronted with ambiguous words and phrases because it is unable to disambiguate the sense of topic signatures. Others (Liu and Croft, 2004) perform semantic smoothing by means of clustering. Recently (Tu et al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), pr</context>
</contexts>
<marker>Cai, Zhou, Liu, Zhao, 2011</marker>
<rawString>Li Cai, Guangyou Zhou, Kang Liu, and Jun Zhao. 2011. Learning the latent topics for question retrieval in community qa. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 273–281, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guihong Cao</author>
<author>Jian-Yun Nie</author>
<author>Jing Bai</author>
</authors>
<title>Integrating word relationships into language models.</title>
<date>2005</date>
<booktitle>In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’05,</booktitle>
<pages>298--305</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="30265" citStr="Cao et al., 2005" startWordPosition="5064" endWordPosition="5067">rovided for the same term by different lexical semantic resources. We move beyond terms and capture relationships between entities and terms using the page contents and link structure in Wikipedia. Apart from translation models there are other approaches (Gao et al., 2004) that try to extend the existing language models for adhoc retrieval by incorporating term relationships or dependencies. Some expand queries using word relationships derived from co-occurrence thesaurus (Bai et al., 2005; Qiu and Frei, 1993), hand-crafted thesaurus (Liu et al., 2004; Voorhees, 1994) and combination of both (Cao et al., 2005). (b) Incorporation of query context information in translation models using latent factor modeling and smoothing approaches: All these existing approaches mentioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This model turns out to be inefficient when confronted with ambiguous words and phrases because it is unab</context>
</contexts>
<marker>Cao, Nie, Bai, 2005</marker>
<rawString>Guihong Cao, Jian-Yun Nie, and Jing Bai. 2005. Integrating word relationships into language models. In Proceedings of the 28th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’05, pages 298–305, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Cao</author>
<author>Gao Cong</author>
<author>Bin Cui</author>
<author>Christian S Jensen</author>
</authors>
<title>A generalized framework of exploring category information for question retrieval in community question answer archives.</title>
<date>2010</date>
<booktitle>In WWW ’10: Proceedings of the 19th international conference on World wide web,</booktitle>
<pages>201--210</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="31537" citStr="Cao et al., 2010" startWordPosition="5253" endWordPosition="5256">s (Liu and Croft, 2004) perform semantic smoothing by means of clustering. Recently (Tu et al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations </context>
</contexts>
<marker>Cao, Cong, Cui, Jensen, 2010</marker>
<rawString>Xin Cao, Gao Cong, Bin Cui, and Christian S. Jensen. 2010. A generalized framework of exploring category information for question retrieval in community question answer archives. In WWW ’10: Proceedings of the 19th international conference on World wide web, pages 201–210, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huizhong Duan</author>
<author>Yunbo Cao</author>
<author>Chin yew Lin</author>
<author>Yong Yu</author>
</authors>
<title>Searching questions by identifying question topic and question focus. In</title>
<date>2008</date>
<booktitle>In Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Tchnologies (ACL:HLT).</booktitle>
<contexts>
<context position="31763" citStr="Duan et al., 2008" startWordPosition="5287" endWordPosition="5290">, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations in Q&amp;A retrieval context. There is also some work on using Wikipedia in general web search (Xu et al., 2009). 6 Conclusion In this work we extend word based model to incorporate semantic concepts for addressing the lexical gap</context>
</contexts>
<marker>Duan, Cao, Lin, Yu, 2008</marker>
<rawString>Huizhong Duan, Yunbo Cao, Chin yew Lin, and Yong Yu. 2008. Searching questions by identifying question topic and question focus. In In Proceedings of 46th Annual Meeting of the Association for Computational Linguistics: Human Language Tchnologies (ACL:HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ofer Egozi</author>
<author>Shaul Markovitch</author>
<author>Evgeniy Gabrilovich</author>
</authors>
<title>Concept-based information retrieval using explicit semantic analysis.</title>
<date>2011</date>
<journal>ACM Trans. Inf. Syst.,</journal>
<volume>29</volume>
<issue>2</issue>
<contexts>
<context position="32043" citStr="Egozi et al., 2011" startWordPosition="5333" endWordPosition="5336">on models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations in Q&amp;A retrieval context. There is also some work on using Wikipedia in general web search (Xu et al., 2009). 6 Conclusion In this work we extend word based model to incorporate semantic concepts for addressing the lexical gap issue in retrieval models for large online Q&amp;A collections. Compared to the existing translation based model, our model is more robust and effective in that it can perform context aware expansions. We proposed ways to embed rich information freely available in Wikipedia into our</context>
</contexts>
<marker>Egozi, Markovitch, Gabrilovich, 2011</marker>
<rawString>Ofer Egozi, Shaul Markovitch, and Evgeniy Gabrilovich. 2011. Concept-based information retrieval using explicit semantic analysis. ACM Trans. Inf. Syst., 29(2):8:1–8:34, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Ferragina</author>
<author>Ugo Scaiella</author>
</authors>
<title>Tagme: on-thefly annotation of short text fragments (by wikipedia entities).</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM ’10,</booktitle>
<pages>1625--1628</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="15681" citStr="Ferragina and Scaiella, 2010" startWordPosition="2669" endWordPosition="2673">ould employ more powerful context dependent interpolation techniques (Liu et al., 2008). In our case we have 2 components Tqa and Twiki and four classes for each ; α(e,e0)7, wiki αwiki , α (e,ne) wiki and α(ne,e) (ne,ne0) wiki ), one corresponding to each class of T (t|t0). respectively. 3 Entity Annotation In this section we describe our entity annotation system. Recently there has been lot of work addressing the problem of annotating text with links to Wikipedia entities (Mihalcea and Csomai, 2007; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Ferragina and Scaiella, 2010). We adopt a similar approach, wherein we first find the best disambiguation (BESTDISAMBIGUATION) for a given mention and then decide to prune it (PRUNE), via the dummy mapping NA (similar to “no assignment” (Kulkarni et al., 2009)). 3.1 BESTDISAMBIGUATION As defined earlier, e E E represent an entity corresponding to URN of a Wikipedia article. Let Em = {em,1, em,2, ··· , em,|E„|I em,i E E represent the set of possible disambiguations for a mention m (m is an index over all mentions in the corpus). Given a mention m, task is to find best disambiguation e from Wikipedia. Without loss of gener7</context>
</contexts>
<marker>Ferragina, Scaiella, 2010</marker>
<rawString>Paolo Ferragina and Ugo Scaiella. 2010. Tagme: on-thefly annotation of short text fragments (by wikipedia entities). In Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM ’10, pages 1625–1628, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Jian-Yun Nie</author>
<author>Guangyuan Wu</author>
<author>Guihong Cao</author>
</authors>
<title>Dependence language model for information retrieval.</title>
<date>2004</date>
<booktitle>In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’04,</booktitle>
<pages>170--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="29921" citStr="Gao et al., 2004" startWordPosition="5013" endWordPosition="5016">ay not be necessary because models learnt using entity annotations are robust to noise in Q&amp;A data. Instead of using noisy Q&amp;A data, new approach (Bernhard and Gurevych, 2009) to build parallel corpus from reliable sources has showed improvements. They proposed to use as a parallel training data comprising of set the definitions and glosses provided for the same term by different lexical semantic resources. We move beyond terms and capture relationships between entities and terms using the page contents and link structure in Wikipedia. Apart from translation models there are other approaches (Gao et al., 2004) that try to extend the existing language models for adhoc retrieval by incorporating term relationships or dependencies. Some expand queries using word relationships derived from co-occurrence thesaurus (Bai et al., 2005; Qiu and Frei, 1993), hand-crafted thesaurus (Liu et al., 2004; Voorhees, 1994) and combination of both (Cao et al., 2005). (b) Incorporation of query context information in translation models using latent factor modeling and smoothing approaches: All these existing approaches mentioned above are considered to be context independent, in that they do not take into account any </context>
</contexts>
<marker>Gao, Nie, Wu, Cao, 2004</marker>
<rawString>Jianfeng Gao, Jian-Yun Nie, Guangyuan Wu, and Guihong Cao. 2004. Dependence language model for information retrieval. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’04, pages 170–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P van der Weide</author>
</authors>
<title>Conceptual query expansion.</title>
<date>2006</date>
<journal>Data Knowl. Eng.,</journal>
<volume>56</volume>
<issue>2</issue>
<pages>193</pages>
<marker>van der Weide, 2006</marker>
<rawString>F. A. Grootjen and Th. P. van der Weide. 2006. Conceptual query expansion. Data Knowl. Eng., 56(2):174– 193, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwoon Jeon</author>
<author>W Bruce Croft</author>
<author>Joon Ho Lee</author>
</authors>
<title>Finding similar questions in large question and answer archives.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th ACM international conference on Information and knowledge management, CIKM ’05,</booktitle>
<pages>84--90</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2272" citStr="Jeon et al., 2005" startWordPosition="356" endWordPosition="359">uestion and answer (Q&amp;A) pairs to the users questions, instead of a long list of ranked URLs. This is in noted contrast to the usual search paradigm, where the question is used to search the database of potential answers, in this case the question is used to search the database of previous questions, which in turn are associated with answers. This involves addressing the word mismatch problem between the users question and the question-answer pairs in the archive. This is the major challenge for Q&amp;A retrieval. Researchers have proposed the use of translation models (Berger and Lafferty, 1999; Jeon et al., 2005; Xue et al., 2008) to solve this problem. As a principled approach to capturing semantic word relations, statistical translation language models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional document language models on Q&amp;A retrieval task. The basic idea is to estimate the likelihood of translating a document1 to a query by exploiting the dependencies that exists between query words and document words. For example the document containing the word Wheezing may well answer the question containing the term Asthma. They learn the these depend</context>
<context position="22718" citStr="Jeon et al., 2005" startWordPosition="3832" endWordPosition="3835">eria. In case of disagreement between two volunteers, authors made the final judgment. Inter-annotator agreement was 87.9% and Kappa coefficient = 0.68. Over all we had collected more than 12K relevance judgements corresponding to these queries, of which &gt;2.3K were marked as relevant. 4.2 Baselines To evaluate the effectiveness of our models we compared them against the following baselines Traditional models: VSM (Zobel and Moffat, 2006) and OKAPI BM25 (Robertson et al., 1996) (k1, b, and k3 are parameters that are set to 1.2, 0.75 and oc respectively). Translation based language models: TLM (Jeon et al., 2005), TransLM (using answers) (Xue et al., 2008) and CTM (Lee et al., 2008). For our experiments we used a set of 50 queries to select the model parameters. Translation based language model use 2 parameters; smoothing parameter A in the Language Model and Q to control the selftranslation impact in the TransLM. Final values of parameters used in our experiments were A = 0.2 (Zhai and Lafferty, 2004) and Q = 0.75 (Xue et al., 2008). For CTM, we used tf-idf based weighing scheme (Lee et al., 2008) to remove words from the (QIIA) corpus P. Word elimination threshold of 20% was selected based on the ab</context>
<context position="28240" citStr="Jeon et al., 2005" startWordPosition="4756" endWordPosition="4759">ss this by combining the two models. Values for mixing parameters are : α(e,e&apos;) wiki = 0.9511, α(e,ne) = 0.75, a(ne,ne&apos;) = 0.7 and α(ne,e) = 0.75). wiki wiki wiki The interpolation weights were obtained by optimizing the retrieval performance by doing a using grid search over the parameter space. Same 50 queries were used for tuning. As seen entity relationships obtained from Wikipedia are far superior to one from Q&amp;A corpus. As seen in Table 2 combining the two models improves the performance. 5 Related Work Recently Q&amp;A retrieval has been garnering lot of attention. Translation model (TLM) (Jeon et al., 2005) has been extensively employed in question search and has been shown to outperform the traditional IR methods significantly (VSM, BM25, LM). Existing 11α(e,e�) qa _ (1 − 0.95) work can be broadly grouped under the following topics: (a) Improved training of translation models by exploiting answer content/inter-word co-occurrence relations and restriction to reliable parallel corpora: Translation-based language model (TRLM) (Xue et al., 2008) improved stability of TLM by providing better probability estimates and also exploited answers for question retrieval. It further improved the retrieval re</context>
</contexts>
<marker>Jeon, Croft, Lee, 2005</marker>
<rawString>Jiwoon Jeon, W. Bruce Croft, and Joon Ho Lee. 2005. Finding similar questions in large question and answer archives. In Proceedings of the 14th ACM international conference on Information and knowledge management, CIKM ’05, pages 84–90, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Optimizing search engines using clickthrough data.</title>
<date>2002</date>
<booktitle>In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’02,</booktitle>
<pages>133--142</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="16770" citStr="Joachims, 2002" startWordPosition="2873" endWordPosition="2874"> all mentions in the corpus). Given a mention m, task is to find best disambiguation e from Wikipedia. Without loss of gener7α(e,e ) = I − a(e,e ) 9a wili 1270 ality, we consider em,* E Em as the correct answer. Let φ(m, em,j) represent the mapping onto features between an entity mention m and the Wikipedia entity em,j and v be the corresponding weight vector and D(em,j) = v φ(m, em,j) represent the disambiguation score. The task is to learn v such that argmax D(em,j) gives the best disambiguation for e. the mention m. We pose this as a ranking problem and solve it using max-margin technique (Joachims, 2002; Joachims, 2006) as follows W φ(m, em,*) &gt; W φ(m, em,j) + ξi,j (11) Vi, Vj : ξi,j &gt; 0 where E ξi,j is the total training error that upper bounds the number of pair preferences violations. This is controlled by adjusting the parameter C. Note that Equation 11 means pairwise comparison between the correct disambiguation em,* and other disambiguation candidates em,j such that j =� index corresponding to *. 3.2 PRUNE The disambiguation phase produces one candidate disambiguation per mention. To discard any unmeaningful annotations a simple strategy similar to LOCAL (Kulkarni et al., 2009) is foll</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’02, pages 133– 142, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Training linear svms in linear time.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’06,</booktitle>
<pages>217--226</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="16787" citStr="Joachims, 2006" startWordPosition="2875" endWordPosition="2876"> the corpus). Given a mention m, task is to find best disambiguation e from Wikipedia. Without loss of gener7α(e,e ) = I − a(e,e ) 9a wili 1270 ality, we consider em,* E Em as the correct answer. Let φ(m, em,j) represent the mapping onto features between an entity mention m and the Wikipedia entity em,j and v be the corresponding weight vector and D(em,j) = v φ(m, em,j) represent the disambiguation score. The task is to learn v such that argmax D(em,j) gives the best disambiguation for e. the mention m. We pose this as a ranking problem and solve it using max-margin technique (Joachims, 2002; Joachims, 2006) as follows W φ(m, em,*) &gt; W φ(m, em,j) + ξi,j (11) Vi, Vj : ξi,j &gt; 0 where E ξi,j is the total training error that upper bounds the number of pair preferences violations. This is controlled by adjusting the parameter C. Note that Equation 11 means pairwise comparison between the correct disambiguation em,* and other disambiguation candidates em,j such that j =� index corresponding to *. 3.2 PRUNE The disambiguation phase produces one candidate disambiguation per mention. To discard any unmeaningful annotations a simple strategy similar to LOCAL (Kulkarni et al., 2009) is followed where the D(</context>
</contexts>
<marker>Joachims, 2006</marker>
<rawString>Thorsten Joachims. 2006. Training linear svms in linear time. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, KDD ’06, pages 217–226, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kulkarni</author>
<author>A Singh</author>
<author>G Ramakrishnan</author>
<author>S Chakrabarti</author>
</authors>
<title>Collective annotation of wikipedia entities in web text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>457--466</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="15628" citStr="Kulkarni et al., 2009" startWordPosition="2661" endWordPosition="2664">eal. With access to large training data one could employ more powerful context dependent interpolation techniques (Liu et al., 2008). In our case we have 2 components Tqa and Twiki and four classes for each ; α(e,e0)7, wiki αwiki , α (e,ne) wiki and α(ne,e) (ne,ne0) wiki ), one corresponding to each class of T (t|t0). respectively. 3 Entity Annotation In this section we describe our entity annotation system. Recently there has been lot of work addressing the problem of annotating text with links to Wikipedia entities (Mihalcea and Csomai, 2007; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Ferragina and Scaiella, 2010). We adopt a similar approach, wherein we first find the best disambiguation (BESTDISAMBIGUATION) for a given mention and then decide to prune it (PRUNE), via the dummy mapping NA (similar to “no assignment” (Kulkarni et al., 2009)). 3.1 BESTDISAMBIGUATION As defined earlier, e E E represent an entity corresponding to URN of a Wikipedia article. Let Em = {em,1, em,2, ··· , em,|E„|I em,i E E represent the set of possible disambiguations for a mention m (m is an index over all mentions in the corpus). Given a mention m, task is to find best di</context>
<context position="17362" citStr="Kulkarni et al., 2009" startWordPosition="2970" endWordPosition="2973">rgin technique (Joachims, 2002; Joachims, 2006) as follows W φ(m, em,*) &gt; W φ(m, em,j) + ξi,j (11) Vi, Vj : ξi,j &gt; 0 where E ξi,j is the total training error that upper bounds the number of pair preferences violations. This is controlled by adjusting the parameter C. Note that Equation 11 means pairwise comparison between the correct disambiguation em,* and other disambiguation candidates em,j such that j =� index corresponding to *. 3.2 PRUNE The disambiguation phase produces one candidate disambiguation per mention. To discard any unmeaningful annotations a simple strategy similar to LOCAL (Kulkarni et al., 2009) is followed where the D(em,*) is compared against a predefined threshold ρna, so that if D(em,*) &lt; ρna then that annotation for menton m is discarded by linking m to NA. The parameter ρna allows the algorithm to back-off when short of evidence. 3.3 FEATUREMAP φ(m, em,j) Sense probability prior (SP): It represents the prior probability that a mention name s points to a specific entity in Wikipedia. For example, without any other information, mention name “tree” will more likely refer to the entity woody plant8, rather than the less 8en.wikipedia.org/wiki/Tree popular notion related to graphs 9</context>
</contexts>
<marker>Kulkarni, Singh, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>S. Kulkarni, A. Singh, G. Ramakrishnan, and S. Chakrabarti. 2009. Collective annotation of wikipedia entities in web text. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 457–466. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jung-Tae Lee</author>
<author>Sang-Bum Kim</author>
<author>Young-In Song</author>
<author>HaeChang Rim</author>
</authors>
<title>Bridging lexical gaps between queries and questions on large online q&amp;#38;a collections with compact translation models.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08,</booktitle>
<pages>410--418</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="22789" citStr="Lee et al., 2008" startWordPosition="3845" endWordPosition="3848">inal judgment. Inter-annotator agreement was 87.9% and Kappa coefficient = 0.68. Over all we had collected more than 12K relevance judgements corresponding to these queries, of which &gt;2.3K were marked as relevant. 4.2 Baselines To evaluate the effectiveness of our models we compared them against the following baselines Traditional models: VSM (Zobel and Moffat, 2006) and OKAPI BM25 (Robertson et al., 1996) (k1, b, and k3 are parameters that are set to 1.2, 0.75 and oc respectively). Translation based language models: TLM (Jeon et al., 2005), TransLM (using answers) (Xue et al., 2008) and CTM (Lee et al., 2008). For our experiments we used a set of 50 queries to select the model parameters. Translation based language model use 2 parameters; smoothing parameter A in the Language Model and Q to control the selftranslation impact in the TransLM. Final values of parameters used in our experiments were A = 0.2 (Zhai and Lafferty, 2004) and Q = 0.75 (Xue et al., 2008). For CTM, we used tf-idf based weighing scheme (Lee et al., 2008) to remove words from the (QIIA) corpus P. Word elimination threshold of 20% was selected based on the above 50 queries. Final values of ETLM parameters used in our experiments</context>
<context position="29070" citStr="Lee et al., 2008" startWordPosition="4878" endWordPosition="4881"> following topics: (a) Improved training of translation models by exploiting answer content/inter-word co-occurrence relations and restriction to reliable parallel corpora: Translation-based language model (TRLM) (Xue et al., 2008) improved stability of TLM by providing better probability estimates and also exploited answers for question retrieval. It further improved the retrieval results and obtained the state-ofthe-art performance. Another line of work on translation models focused on providing suitable parallel data to learn the translation probabilities. Compact translation models (CTM) (Lee et al., 2008) tried to further improve the translation probabilities based on question-answer pairs by selecting the most important terms to build compact translation models. We show that such special-purpose models to control noisy translations may not be necessary because models learnt using entity annotations are robust to noise in Q&amp;A data. Instead of using noisy Q&amp;A data, new approach (Bernhard and Gurevych, 2009) to build parallel corpus from reliable sources has showed improvements. They proposed to use as a parallel training data comprising of set the definitions and glosses provided for the same t</context>
</contexts>
<marker>Lee, Kim, Song, Rim, 2008</marker>
<rawString>Jung-Tae Lee, Sang-Bum Kim, Young-In Song, and HaeChang Rim. 2008. Bridging lexical gaps between queries and questions on large online q&amp;#38;a collections with compact translation models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’08, pages 410–418, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoyong Liu</author>
<author>W Bruce Croft</author>
</authors>
<title>Cluster-based retrieval using language models.</title>
<date>2004</date>
<booktitle>In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’04,</booktitle>
<pages>186--193</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="30943" citStr="Liu and Croft, 2004" startWordPosition="5167" endWordPosition="5170">ation models using latent factor modeling and smoothing approaches: All these existing approaches mentioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This model turns out to be inefficient when confronted with ambiguous words and phrases because it is unable to disambiguate the sense of topic signatures. Others (Liu and Croft, 2004) perform semantic smoothing by means of clustering. Recently (Tu et al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), lear</context>
</contexts>
<marker>Liu, Croft, 2004</marker>
<rawString>Xiaoyong Liu and W. Bruce Croft. 2004. Cluster-based retrieval using language models. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’04, pages 186–193, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuang Liu</author>
<author>Fang Liu</author>
<author>Clement Yu</author>
<author>Weiyi Meng</author>
</authors>
<title>An effective approach to document retrieval via utilizing wordnet and recognizing phrases.</title>
<date>2004</date>
<booktitle>In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’04,</booktitle>
<pages>266--272</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="30205" citStr="Liu et al., 2004" startWordPosition="5054" endWordPosition="5057">aining data comprising of set the definitions and glosses provided for the same term by different lexical semantic resources. We move beyond terms and capture relationships between entities and terms using the page contents and link structure in Wikipedia. Apart from translation models there are other approaches (Gao et al., 2004) that try to extend the existing language models for adhoc retrieval by incorporating term relationships or dependencies. Some expand queries using word relationships derived from co-occurrence thesaurus (Bai et al., 2005; Qiu and Frei, 1993), hand-crafted thesaurus (Liu et al., 2004; Voorhees, 1994) and combination of both (Cao et al., 2005). (b) Incorporation of query context information in translation models using latent factor modeling and smoothing approaches: All these existing approaches mentioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This model turns out to be inefficient when co</context>
</contexts>
<marker>Liu, Liu, Yu, Meng, 2004</marker>
<rawString>Shuang Liu, Fang Liu, Clement Yu, and Weiyi Meng. 2004. An effective approach to document retrieval via utilizing wordnet and recognizing phrases. In Proceedings of the 27th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’04, pages 266–272, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xunying Liu</author>
<author>Mark J F Gales</author>
<author>Philip C Woodland</author>
</authors>
<title>Context dependent language model adaptation.</title>
<date>2008</date>
<booktitle>In INTERSPEECH 2008, 9th Annual Conference of the International Speech Communication Association,</booktitle>
<pages>837--840</pages>
<publisher>ISCA.</publisher>
<location>Brisbane, Australia,</location>
<contexts>
<context position="15139" citStr="Liu et al., 2008" startWordPosition="2577" endWordPosition="2580">n by the component language models. An advantage of the linear interpolation is that it is simple and fast to calculate. If the inputs are probability estimates, also the output is a probability estimate. The mixture translation model Tcombo(e|e0) over M component models is given by Equation 10. M Tcombo(t|t0) = αjTj(t|t0) M j=1 (10) tEEUV; αj = 1; αj &gt; 0 j=1 One can immediately notice that Tcombo(t|t0) has one global weight for each of the M component models which might not be ideal. With access to large training data one could employ more powerful context dependent interpolation techniques (Liu et al., 2008). In our case we have 2 components Tqa and Twiki and four classes for each ; α(e,e0)7, wiki αwiki , α (e,ne) wiki and α(ne,e) (ne,ne0) wiki ), one corresponding to each class of T (t|t0). respectively. 3 Entity Annotation In this section we describe our entity annotation system. Recently there has been lot of work addressing the problem of annotating text with links to Wikipedia entities (Mihalcea and Csomai, 2007; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Ferragina and Scaiella, 2010). We adopt a similar approach, wherein we first find the b</context>
</contexts>
<marker>Liu, Gales, Woodland, 2008</marker>
<rawString>Xunying Liu, Mark J. F. Gales, and Philip C. Woodland. 2008. Context dependent language model adaptation. In INTERSPEECH 2008, 9th Annual Conference of the International Speech Communication Association, Brisbane, Australia, September 22-26, 2008, pages 837–840. ISCA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olena Medelyan</author>
<author>David Milne</author>
<author>Catherine Legg</author>
<author>Ian H Witten</author>
</authors>
<title>Mining meaning from wikipedia.</title>
<date>2009</date>
<journal>Int. J. Hum.-Comput. Stud.,</journal>
<pages>67--716</pages>
<contexts>
<context position="12453" citStr="Medelyan et al., 2009" startWordPosition="2110" endWordPosition="2113">l corpus. We do so by redistributing the probability mass i.e. when calculating T(e|e&apos;), we redistribute probability mass spread over all the ne to e given by Equation 2 and 3. Similar process is followed for T(e|ne), T(ne|e) and T(ne|ne&apos;). _ T(e|e&apos;) S(e|e&apos;) E (2) tEV T (t|e&apos;) S(e|e&apos;) T(e|e&apos;) = E (3) tEE T (t|e&apos;) Remaining model components are calculated using Equation 4 and 5. Here d refers to question part of the Q&amp;A pair. tft9,C + 1 Pml(tq|C) = (4) Et&apos;EC tft&apos;,C + |C| tft9,d Pml(tq|d) = (5) Et&apos;Ed tft&apos;,d 2.4 ETLMwiki: Estimating from Wikipedia Number of symmetric measures have been proposed (Medelyan et al., 2009) to measure semantic relationships between entities and words using Wikipedia. For our problem we need an asymmetric measure. We use co-citation information in Wikipedia to detect relatedness between entities (T(e|e&apos;)) and co-occurrence counts to estimate 1269 T (ne|ne0) as follows: . 6 T(e|e0) co(e, e0) ( ) T(ne |ne0) = 7 T(ne|e) = ( ) Ee00 co(e&amp;quot;, e&apos;) cf(ne, ne0) E ne�� cf (ne&amp;quot;, ne&apos;) tfne,D(e) + 1 T(e|ne) = |D(e) |+ |V | tfne,D(e) + 1 Ee0∈E tfne,D(e0) + |E| Here d(e) represents the page corresponding to entity e. D(e) represents concatenation of d(e) and all context of size 5 surrounding anch</context>
</contexts>
<marker>Medelyan, Milne, Legg, Witten, 2009</marker>
<rawString>Olena Medelyan, David Milne, Catherine Legg, and Ian H. Witten. 2009. Mining meaning from wikipedia. Int. J. Hum.-Comput. Stud., 67:716–754, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edgar Meij</author>
<author>Dolf Trieschnigg</author>
<author>Maarten de Rijke</author>
<author>Wessel Kraaij</author>
</authors>
<title>Parsimonious concept modeling.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’08,</booktitle>
<pages>815--816</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>Meij, Trieschnigg, de Rijke, Kraaij, 2008</marker>
<rawString>Edgar Meij, Dolf Trieschnigg, Maarten de Rijke, and Wessel Kraaij. 2008. Parsimonious concept modeling. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’08, pages 815–816, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>A Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In CIKM,</booktitle>
<volume>7</volume>
<pages>233--242</pages>
<contexts>
<context position="15556" citStr="Mihalcea and Csomai, 2007" startWordPosition="2649" endWordPosition="2652">s one global weight for each of the M component models which might not be ideal. With access to large training data one could employ more powerful context dependent interpolation techniques (Liu et al., 2008). In our case we have 2 components Tqa and Twiki and four classes for each ; α(e,e0)7, wiki αwiki , α (e,ne) wiki and α(ne,e) (ne,ne0) wiki ), one corresponding to each class of T (t|t0). respectively. 3 Entity Annotation In this section we describe our entity annotation system. Recently there has been lot of work addressing the problem of annotating text with links to Wikipedia entities (Mihalcea and Csomai, 2007; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Ferragina and Scaiella, 2010). We adopt a similar approach, wherein we first find the best disambiguation (BESTDISAMBIGUATION) for a given mention and then decide to prune it (PRUNE), via the dummy mapping NA (similar to “no assignment” (Kulkarni et al., 2009)). 3.1 BESTDISAMBIGUATION As defined earlier, e E E represent an entity corresponding to URN of a Wikipedia article. Let Em = {em,1, em,2, ··· , em,|E„|I em,i E E represent the set of possible disambiguations for a mention m (m is an index over</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>R. Mihalcea and A. Csomai. 2007. Wikify!: linking documents to encyclopedic knowledge. In CIKM, volume 7, pages 233–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Milne</author>
<author>I H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceeding of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>509--518</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="15605" citStr="Milne and Witten, 2008" startWordPosition="2657" endWordPosition="2660">ls which might not be ideal. With access to large training data one could employ more powerful context dependent interpolation techniques (Liu et al., 2008). In our case we have 2 components Tqa and Twiki and four classes for each ; α(e,e0)7, wiki αwiki , α (e,ne) wiki and α(ne,e) (ne,ne0) wiki ), one corresponding to each class of T (t|t0). respectively. 3 Entity Annotation In this section we describe our entity annotation system. Recently there has been lot of work addressing the problem of annotating text with links to Wikipedia entities (Mihalcea and Csomai, 2007; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Ferragina and Scaiella, 2010). We adopt a similar approach, wherein we first find the best disambiguation (BESTDISAMBIGUATION) for a given mention and then decide to prune it (PRUNE), via the dummy mapping NA (similar to “no assignment” (Kulkarni et al., 2009)). 3.1 BESTDISAMBIGUATION As defined earlier, e E E represent an entity corresponding to URN of a Wikipedia article. Let Em = {em,1, em,2, ··· , em,|E„|I em,i E E represent the set of possible disambiguations for a mention m (m is an index over all mentions in the corpus). Given a mention m, </context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>D. Milne and I.H. Witten. 2008. Learning to link with wikipedia. In Proceeding of the 17th ACM conference on Information and knowledge management, pages 509–518. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Improving ibm word-alignment model 1.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5437" citStr="Moore, 2004" startWordPosition="859" endWordPosition="860">d words can be estimated more reliably. Our main contributions are 1. We propose Entity based Translation Language Model (ETLM) for Q&amp;A retrieval that accommodates semantic information associated between entities and words. Being closely related to the general source-channel framework (Berger and Lafferty, 1999), the model enjoys its benefits, while mitigating some of its shortcomings. Specifically it provides for context aware expansions of the query by exploiting entity annotations on both, the document and the query side. Entity annotations also provide a means to handle the “many-to-one” (Moore, 2004) translation limitation in the IBM model, due to which each word in the target document can be generated by at most one word in the question2. For the same reasons, it also alleviates another related limitation by enabling translation between contiguous words across the query and documents (Moore, 2004). 2. We learn relationships between entities and terms by proposing new ways of organizing monolingual parallel corpus and simultaneously leveraging external resources like Wikipedia from which one can derive these relationships reliably. This helps alleviate the noise problem associated with le</context>
</contexts>
<marker>Moore, 2004</marker>
<rawString>Robert C. Moore. 2004. Improving ibm word-alignment model 1. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yonggang Qiu</author>
<author>Hans-Peter Frei</author>
</authors>
<title>Concept based query expansion.</title>
<date>1993</date>
<booktitle>In Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’93,</booktitle>
<pages>160--169</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="30163" citStr="Qiu and Frei, 1993" startWordPosition="5048" endWordPosition="5051">ements. They proposed to use as a parallel training data comprising of set the definitions and glosses provided for the same term by different lexical semantic resources. We move beyond terms and capture relationships between entities and terms using the page contents and link structure in Wikipedia. Apart from translation models there are other approaches (Gao et al., 2004) that try to extend the existing language models for adhoc retrieval by incorporating term relationships or dependencies. Some expand queries using word relationships derived from co-occurrence thesaurus (Bai et al., 2005; Qiu and Frei, 1993), hand-crafted thesaurus (Liu et al., 2004; Voorhees, 1994) and combination of both (Cao et al., 2005). (b) Incorporation of query context information in translation models using latent factor modeling and smoothing approaches: All these existing approaches mentioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This</context>
</contexts>
<marker>Qiu, Frei, 1993</marker>
<rawString>Yonggang Qiu and Hans-Peter Frei. 1993. Concept based query expansion. In Proceedings of the 16th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’93, pages 160–169, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>1375--1384</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="15650" citStr="Ratinov et al., 2011" startWordPosition="2665" endWordPosition="2668">ge training data one could employ more powerful context dependent interpolation techniques (Liu et al., 2008). In our case we have 2 components Tqa and Twiki and four classes for each ; α(e,e0)7, wiki αwiki , α (e,ne) wiki and α(ne,e) (ne,ne0) wiki ), one corresponding to each class of T (t|t0). respectively. 3 Entity Annotation In this section we describe our entity annotation system. Recently there has been lot of work addressing the problem of annotating text with links to Wikipedia entities (Mihalcea and Csomai, 2007; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011; Ferragina and Scaiella, 2010). We adopt a similar approach, wherein we first find the best disambiguation (BESTDISAMBIGUATION) for a given mention and then decide to prune it (PRUNE), via the dummy mapping NA (similar to “no assignment” (Kulkarni et al., 2009)). 3.1 BESTDISAMBIGUATION As defined earlier, e E E represent an entity corresponding to URN of a Wikipedia article. Let Em = {em,1, em,2, ··· , em,|E„|I em,i E E represent the set of possible disambiguations for a mention m (m is an index over all mentions in the corpus). Given a mention m, task is to find best disambiguation e from Wi</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 1375–1384, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S E Robertson</author>
<author>S Walker</author>
<author>S Jones</author>
<author>M M HancockBeaulieu</author>
<author>M Gatford</author>
</authors>
<title>Okapi at trec-3.</title>
<date>1996</date>
<pages>109--126</pages>
<contexts>
<context position="22581" citStr="Robertson et al., 1996" startWordPosition="3808" endWordPosition="3811"> asked to label candidate as “relevant” or “irrelevant” based on semantic similarity with the query. Answer quality/correctness was not a criteria. In case of disagreement between two volunteers, authors made the final judgment. Inter-annotator agreement was 87.9% and Kappa coefficient = 0.68. Over all we had collected more than 12K relevance judgements corresponding to these queries, of which &gt;2.3K were marked as relevant. 4.2 Baselines To evaluate the effectiveness of our models we compared them against the following baselines Traditional models: VSM (Zobel and Moffat, 2006) and OKAPI BM25 (Robertson et al., 1996) (k1, b, and k3 are parameters that are set to 1.2, 0.75 and oc respectively). Translation based language models: TLM (Jeon et al., 2005), TransLM (using answers) (Xue et al., 2008) and CTM (Lee et al., 2008). For our experiments we used a set of 50 queries to select the model parameters. Translation based language model use 2 parameters; smoothing parameter A in the Language Model and Q to control the selftranslation impact in the TransLM. Final values of parameters used in our experiments were A = 0.2 (Zhai and Lafferty, 2004) and Q = 0.75 (Xue et al., 2008). For CTM, we used tf-idf based we</context>
</contexts>
<marker>Robertson, Walker, Jones, HancockBeaulieu, Gatford, 1996</marker>
<rawString>S.E. Robertson, S. Walker, S. Jones, M.M. HancockBeaulieu, and M. Gatford. 1996. Okapi at trec-3. pages 109–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Singh</author>
<author>Karthik Visweswariah</author>
</authors>
<title>CQC: classifying questions in cqa websites.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM ’11,</booktitle>
<pages>2033--2036</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1389" citStr="Singh and Visweswariah, 2011" startWordPosition="210" endWordPosition="213">we address the above issues by extending the lexical word based translation model to incorporate semantic concepts (entities). We explore strategies to learn the translation probabilities between words and the concepts using the Q&amp;A archives and a popular entity catalog. Experiments conducted on a large scale real data show that the proposed techniques are promising. 1 Introduction Over the past few years community-based question answering (CQA) portals like Naver, Yahoo! Answers, Baidu Zhidao and WikiAnswers have attracted great attention from both academia and industry (Adamic et al., 2008; Singh and Visweswariah, 2011). These portals foster collaborative creation of content by allowing the users to both submit questions to be answered and answer questions asked by other users. These portals aim to provide highly focused access to this information by directly returning pertinent question and answer (Q&amp;A) pairs to the users questions, instead of a long list of ranked URLs. This is in noted contrast to the usual search paradigm, where the question is used to search the database of potential answers, in this case the question is used to search the database of previous questions, which in turn are associated wit</context>
</contexts>
<marker>Singh, Visweswariah, 2011</marker>
<rawString>Amit Singh and Karthik Visweswariah. 2011. CQC: classifying questions in cqa websites. In Proceedings of the 20th ACM international conference on Information and knowledge management, CIKM ’11, pages 2033–2036, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Singh</author>
<author>Sayali Kulkarni</author>
<author>Somnath Banerjee</author>
<author>Ganesh Ramakrishnan</author>
<author>Soumen Chakrabarti</author>
</authors>
<title>Curating and searching the annotated web. In</title>
<date>2009</date>
<booktitle>In SIGKDD Conference,</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="32023" citStr="Singh et al., 2009" startWordPosition="5329" endWordPosition="5332"> alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations in Q&amp;A retrieval context. There is also some work on using Wikipedia in general web search (Xu et al., 2009). 6 Conclusion In this work we extend word based model to incorporate semantic concepts for addressing the lexical gap issue in retrieval models for large online Q&amp;A collections. Compared to the existing translation based model, our model is more robust and effective in that it can perform context aware expansions. We proposed ways to embed rich information freely available i</context>
</contexts>
<marker>Singh, Kulkarni, Banerjee, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>Amit Singh, Sayali Kulkarni, Somnath Banerjee, Ganesh Ramakrishnan, and Soumen Chakrabarti. 2009. Curating and searching the annotated web. In In SIGKDD Conference, 2009. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Massimiliano Ciaramita</author>
<author>Hugo Zaragoza</author>
</authors>
<title>Learning to rank answers on large online qa collections. In</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting for the Association for Computational Linguistics: Human Language Technologies (ACL-08: HLT,</booktitle>
<pages>719--727</pages>
<contexts>
<context position="31608" citStr="Surdeanu et al., 2008" startWordPosition="5263" endWordPosition="5266">tering. Recently (Tu et al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations in Q&amp;A retrieval context. There is also some work on using Wikipedia in</context>
</contexts>
<marker>Surdeanu, Ciaramita, Zaragoza, 2008</marker>
<rawString>Mihai Surdeanu, Massimiliano Ciaramita, and Hugo Zaragoza. 2008. Learning to rank answers on large online qa collections. In In Proceedings of the 46th Annual Meeting for the Association for Computational Linguistics: Human Language Technologies (ACL-08: HLT, pages 719–727.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinhui Tu</author>
<author>Tingting He</author>
<author>Long Chen</author>
<author>Jing Luo</author>
<author>Maoyuan Zhang</author>
</authors>
<title>Wikipedia-based semantic smoothing for the language modeling approach to information retrieval.</title>
<date>2010</date>
<booktitle>In Proceedings of the 32nd European conference on Advances in Information Retrieval, ECIR’2010,</booktitle>
<pages>370--381</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="31020" citStr="Tu et al., 2010" startWordPosition="5180" endWordPosition="5183">ting approaches mentioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This model turns out to be inefficient when confronted with ambiguous words and phrases because it is unable to disambiguate the sense of topic signatures. Others (Liu and Croft, 2004) perform semantic smoothing by means of clustering. Recently (Tu et al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu an</context>
</contexts>
<marker>Tu, He, Chen, Luo, Zhang, 2010</marker>
<rawString>Xinhui Tu, Tingting He, Long Chen, Jing Luo, and Maoyuan Zhang. 2010. Wikipedia-based semantic smoothing for the language modeling approach to information retrieval. In Proceedings of the 32nd European conference on Advances in Information Retrieval, ECIR’2010, pages 370–381, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>Query expansion using lexical-semantic relations.</title>
<date>1994</date>
<booktitle>In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’94,</booktitle>
<pages>61--69</pages>
<publisher>SpringerVerlag</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="30222" citStr="Voorhees, 1994" startWordPosition="5058" endWordPosition="5059">sing of set the definitions and glosses provided for the same term by different lexical semantic resources. We move beyond terms and capture relationships between entities and terms using the page contents and link structure in Wikipedia. Apart from translation models there are other approaches (Gao et al., 2004) that try to extend the existing language models for adhoc retrieval by incorporating term relationships or dependencies. Some expand queries using word relationships derived from co-occurrence thesaurus (Bai et al., 2005; Qiu and Frei, 1993), hand-crafted thesaurus (Liu et al., 2004; Voorhees, 1994) and combination of both (Cao et al., 2005). (b) Incorporation of query context information in translation models using latent factor modeling and smoothing approaches: All these existing approaches mentioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This model turns out to be inefficient when confronted with amb</context>
</contexts>
<marker>Voorhees, 1994</marker>
<rawString>Ellen M. Voorhees. 1994. Query expansion using lexical-semantic relations. In Proceedings of the 17th annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’94, pages 61–69, New York, NY, USA. SpringerVerlag New York, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Wang</author>
<author>Zhaoyan Ming</author>
<author>Tat-Seng Chua</author>
</authors>
<title>A syntactic tree matching approach to finding similar questions in community-based qa services.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09,</booktitle>
<pages>187--194</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="31691" citStr="Wang et al., 2009" startWordPosition="5276" endWordPosition="5279">d performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations in Q&amp;A retrieval context. There is also some work on using Wikipedia in general web search (Xu et al., 2009). 6 Conclusion In this work we extend word bas</context>
</contexts>
<marker>Wang, Ming, Chua, 2009</marker>
<rawString>Kai Wang, Zhaoyan Ming, and Tat-Seng Chua. 2009. A syntactic tree matching approach to finding similar questions in community-based qa services. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09, pages 187–194, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Xu</author>
<author>Gareth J F Jones</author>
<author>Bin Wang</author>
</authors>
<title>Query dependent pseudo-relevance feedback based on wikipedia.</title>
<date>2009</date>
<booktitle>In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09,</booktitle>
<pages>59--66</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="32245" citStr="Xu et al., 2009" startWordPosition="5370" endWordPosition="5373">2010), proposed a syntactic tree matching ((Wang et al., 2009) or question structure for important phrase matching (Duan et al., 2008)). These methods seem orthogonal to ours, in some cases complementary and can be leveraged to get an even better performance There also exists work where exploiting entity based representation has been found helpful in information retrieval (Singh et al., 2009; Egozi et al., 2011; Meij et al., 2008; Grootjen and van der Weide, 2006). In our work we use entity annotations in Q&amp;A retrieval context. There is also some work on using Wikipedia in general web search (Xu et al., 2009). 6 Conclusion In this work we extend word based model to incorporate semantic concepts for addressing the lexical gap issue in retrieval models for large online Q&amp;A collections. Compared to the existing translation based model, our model is more robust and effective in that it can perform context aware expansions. We proposed ways to embed rich information freely available in Wikipedia into our models and combine it one learnt from Q&amp;A corpus. Experiments performed on a large real Q&amp;A data demonstrate that all configurations of ETLM significantly outperforms existing models for Q&amp;A retrieval.</context>
</contexts>
<marker>Xu, Jones, Wang, 2009</marker>
<rawString>Yang Xu, Gareth J.F. Jones, and Bin Wang. 2009. Query dependent pseudo-relevance feedback based on wikipedia. In Proceedings of the 32nd international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’09, pages 59–66, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaobing Xue</author>
<author>Jiwoon Jeon</author>
<author>W Bruce Croft</author>
</authors>
<title>Retrieval models for question and answer archives.</title>
<date>2008</date>
<booktitle>In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’08,</booktitle>
<pages>475--482</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2291" citStr="Xue et al., 2008" startWordPosition="360" endWordPosition="363">(Q&amp;A) pairs to the users questions, instead of a long list of ranked URLs. This is in noted contrast to the usual search paradigm, where the question is used to search the database of potential answers, in this case the question is used to search the database of previous questions, which in turn are associated with answers. This involves addressing the word mismatch problem between the users question and the question-answer pairs in the archive. This is the major challenge for Q&amp;A retrieval. Researchers have proposed the use of translation models (Berger and Lafferty, 1999; Jeon et al., 2005; Xue et al., 2008) to solve this problem. As a principled approach to capturing semantic word relations, statistical translation language models are built by using the IBM model 1 (Brown et al., 1993) and have been shown to outperform traditional document language models on Q&amp;A retrieval task. The basic idea is to estimate the likelihood of translating a document1 to a query by exploiting the dependencies that exists between query words and document words. For example the document containing the word Wheezing may well answer the question containing the term Asthma. They learn the these dependencies (encoded as </context>
<context position="10652" citStr="Xue et al., 2008" startWordPosition="1782" endWordPosition="1785">ystem. T (tq|td) in Equation 1 denotes the probability that a token span tq is the translation of token span td. This induces the desired query expansion effect. The key task is to estimate Pml(tq|C), T (tq|td) and Pml(td|d); tq E eq U neq and td E ed U ned 2.2 Estimating Model Parameters We adopt 2 different approach for estimating T (tq|td), leading to 2 different configurations of ETLM system. As the name suggests, ETLMqa is estimated from Q&amp;A data (C and D) while we leverage the entity catalog (in our case it is Wikipedia) for ETLMwiki. 2.3 ETLMqa: Estimate from parallel corpus Following (Xue et al., 2008) we pool the question and answers from D to create a master parallel corpus P = (qi, al), , (qn, an) U (al, qi), (an, qn). This is used for learning T (ne|ne&apos;)6. Similarly we create P* from C. We then derive 2 different parallel corpora from P and P* as follows Pentity We remove all non linked tokens ne from P* thereby reducing it to parallel corpus over e. This is used for learning T(e|e&apos;) i.e. translation probabilities between two entities e and e&apos; in E. Phybrid This is hybrid of Pentity and P where in one part of Q&amp;A pair consists on only ne while other consists of only e. This is used for </context>
<context position="22762" citStr="Xue et al., 2008" startWordPosition="3839" endWordPosition="3842">unteers, authors made the final judgment. Inter-annotator agreement was 87.9% and Kappa coefficient = 0.68. Over all we had collected more than 12K relevance judgements corresponding to these queries, of which &gt;2.3K were marked as relevant. 4.2 Baselines To evaluate the effectiveness of our models we compared them against the following baselines Traditional models: VSM (Zobel and Moffat, 2006) and OKAPI BM25 (Robertson et al., 1996) (k1, b, and k3 are parameters that are set to 1.2, 0.75 and oc respectively). Translation based language models: TLM (Jeon et al., 2005), TransLM (using answers) (Xue et al., 2008) and CTM (Lee et al., 2008). For our experiments we used a set of 50 queries to select the model parameters. Translation based language model use 2 parameters; smoothing parameter A in the Language Model and Q to control the selftranslation impact in the TransLM. Final values of parameters used in our experiments were A = 0.2 (Zhai and Lafferty, 2004) and Q = 0.75 (Xue et al., 2008). For CTM, we used tf-idf based weighing scheme (Lee et al., 2008) to remove words from the (QIIA) corpus P. Word elimination threshold of 20% was selected based on the above 50 queries. Final values of ETLM paramet</context>
<context position="28684" citStr="Xue et al., 2008" startWordPosition="4821" endWordPosition="4824">e 2 combining the two models improves the performance. 5 Related Work Recently Q&amp;A retrieval has been garnering lot of attention. Translation model (TLM) (Jeon et al., 2005) has been extensively employed in question search and has been shown to outperform the traditional IR methods significantly (VSM, BM25, LM). Existing 11α(e,e�) qa _ (1 − 0.95) work can be broadly grouped under the following topics: (a) Improved training of translation models by exploiting answer content/inter-word co-occurrence relations and restriction to reliable parallel corpora: Translation-based language model (TRLM) (Xue et al., 2008) improved stability of TLM by providing better probability estimates and also exploited answers for question retrieval. It further improved the retrieval results and obtained the state-ofthe-art performance. Another line of work on translation models focused on providing suitable parallel data to learn the translation probabilities. Compact translation models (CTM) (Lee et al., 2008) tried to further improve the translation probabilities based on question-answer pairs by selecting the most important terms to build compact translation models. We show that such special-purpose models to control </context>
</contexts>
<marker>Xue, Jeon, Croft, 2008</marker>
<rawString>Xiaobing Xue, Jiwoon Jeon, and W. Bruce Croft. 2008. Retrieval models for question and answer archives. In Proceedings of the 31st annual international ACM SIGIR conference on Research and development in information retrieval, SIGIR ’08, pages 475–482, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengxiang Zhai</author>
<author>John Lafferty</author>
</authors>
<title>A study of smoothing methods for language models applied to information retrieval.</title>
<date>2004</date>
<journal>ACM Trans. Inf. Syst.,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>214</pages>
<contexts>
<context position="23115" citStr="Zhai and Lafferty, 2004" startWordPosition="3902" endWordPosition="3905">s Traditional models: VSM (Zobel and Moffat, 2006) and OKAPI BM25 (Robertson et al., 1996) (k1, b, and k3 are parameters that are set to 1.2, 0.75 and oc respectively). Translation based language models: TLM (Jeon et al., 2005), TransLM (using answers) (Xue et al., 2008) and CTM (Lee et al., 2008). For our experiments we used a set of 50 queries to select the model parameters. Translation based language model use 2 parameters; smoothing parameter A in the Language Model and Q to control the selftranslation impact in the TransLM. Final values of parameters used in our experiments were A = 0.2 (Zhai and Lafferty, 2004) and Q = 0.75 (Xue et al., 2008). For CTM, we used tf-idf based weighing scheme (Lee et al., 2008) to remove words from the (QIIA) corpus P. Word elimination threshold of 20% was selected based on the above 50 queries. Final values of ETLM parameters used in our experiments were A = 0.18 and -y = 0.65. 4.3 Result Analysis Table 2 presents the performance of the various techniques. Under each measure, we highlight the best performing technique. Performance of all the translation based models is better than VSM and OKAPI thereby confirming the importance of addressing the lexical gap. Using high</context>
</contexts>
<marker>Zhai, Lafferty, 2004</marker>
<rawString>Chengxiang Zhai and John Lafferty. 2004. A study of smoothing methods for language models applied to information retrieval. ACM Trans. Inf. Syst., 22(2):179– 214, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Zhou</author>
<author>Xiaohua Hu</author>
<author>Xiaodan Zhang</author>
</authors>
<title>Topic signature language models for ad hoc retrieval.</title>
<date>2007</date>
<journal>IEEE Trans. on Knowl. and Data Eng.,</journal>
<volume>19</volume>
<issue>9</issue>
<pages>1287</pages>
<contexts>
<context position="3741" citStr="Zhou et al., 2007" startWordPosition="585" endWordPosition="588"> use (Q&amp;A, document), (word, term) and (user query, question) interchangeably 1266 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1266–1277, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics Figure 1: Need for entity based expansions 2008). Also these models only capture shallow semantics between words via the co-occurrence statistics, while some of the more explicit relationships between words and entities is freely available externally. Being context agnostic (Zhou et al., 2007) is another very common criticism hailed on translation models as it results in noisy and generic translations. Example shown in Figure 1 captures these problems. Specifically, the word Blizzard can refer to an American game development company that develops World of Warcraft game or it could refer to a severe snowstorm. Expanding query without taking the gaming context established by the word WOW (acronym for World of Warcraft) into account would lead to topic drift. Also it would be difficult to learn relationships between World of Warcraft Burning Crusade and Blizzard from the Q&amp;A corpus al</context>
<context position="30622" citStr="Zhou et al., 2007" startWordPosition="5115" endWordPosition="5118">ng term relationships or dependencies. Some expand queries using word relationships derived from co-occurrence thesaurus (Bai et al., 2005; Qiu and Frei, 1993), hand-crafted thesaurus (Liu et al., 2004; Voorhees, 1994) and combination of both (Cao et al., 2005). (b) Incorporation of query context information in translation models using latent factor modeling and smoothing approaches: All these existing approaches mentioned above are considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This model turns out to be inefficient when confronted with ambiguous words and phrases because it is unable to disambiguate the sense of topic signatures. Others (Liu and Croft, 2004) perform semantic smoothing by means of clustering. Recently (Tu et al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to the</context>
</contexts>
<marker>Zhou, Hu, Zhang, 2007</marker>
<rawString>Xiaohua Zhou, Xiaohua Hu, and Xiaodan Zhang. 2007. Topic signature language models for ad hoc retrieval. IEEE Trans. on Knowl. and Data Eng., 19(9):1276– 1287, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guangyou Zhou</author>
<author>Li Cai</author>
<author>Jun Zhao</author>
<author>Kang Liu</author>
</authors>
<title>Phrase-based translation model for question retrieval in community question answer archives.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>653--662</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="31058" citStr="Zhou et al., 2011" startWordPosition="5188" endWordPosition="5191"> considered to be context independent, in that they do not take into account any contextual information in modeling word word relationships. Topic signature model (Zhou et al., 2007) exploited contextual information 1274 by decomposing a document into a set of weighted topic signatures and use it for model smoothing. This model turns out to be inefficient when confronted with ambiguous words and phrases because it is unable to disambiguate the sense of topic signatures. Others (Liu and Croft, 2004) perform semantic smoothing by means of clustering. Recently (Tu et al., 2010; Cai et al., 2011; Zhou et al., 2011) showed improved performance by performing sense based smoothing for document retrieval, latent topic mining and phase based retrieval respectively. Contrary to these approaches we used entity disambiguation to capture contextual information for improving Q&amp;A retrieval. (c) Complementary ideas for improving retrieval performance that can be used alongside translation models: Other work on question retrieval include the use of category information available (Cao et al., 2010), learning-to-rank techniques (Bian et al., 2008; Surdeanu et al., 2008; Bunescu and Huang, 2010), proposed a syntactic t</context>
</contexts>
<marker>Zhou, Cai, Zhao, Liu, 2011</marker>
<rawString>Guangyou Zhou, Li Cai, Jun Zhao, and Kang Liu. 2011. Phrase-based translation model for question retrieval in community question answer archives. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 653–662, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Justin Zobel</author>
<author>Alistair Moffat</author>
</authors>
<title>Inverted files for text search engines.</title>
<date>2006</date>
<journal>ACM Comput. Surv.,</journal>
<volume>38</volume>
<contexts>
<context position="22541" citStr="Zobel and Moffat, 2006" startWordPosition="3801" endWordPosition="3804"> used for retrieval. The annotators were asked to label candidate as “relevant” or “irrelevant” based on semantic similarity with the query. Answer quality/correctness was not a criteria. In case of disagreement between two volunteers, authors made the final judgment. Inter-annotator agreement was 87.9% and Kappa coefficient = 0.68. Over all we had collected more than 12K relevance judgements corresponding to these queries, of which &gt;2.3K were marked as relevant. 4.2 Baselines To evaluate the effectiveness of our models we compared them against the following baselines Traditional models: VSM (Zobel and Moffat, 2006) and OKAPI BM25 (Robertson et al., 1996) (k1, b, and k3 are parameters that are set to 1.2, 0.75 and oc respectively). Translation based language models: TLM (Jeon et al., 2005), TransLM (using answers) (Xue et al., 2008) and CTM (Lee et al., 2008). For our experiments we used a set of 50 queries to select the model parameters. Translation based language model use 2 parameters; smoothing parameter A in the Language Model and Q to control the selftranslation impact in the TransLM. Final values of parameters used in our experiments were A = 0.2 (Zhai and Lafferty, 2004) and Q = 0.75 (Xue et al.,</context>
</contexts>
<marker>Zobel, Moffat, 2006</marker>
<rawString>Justin Zobel and Alistair Moffat. 2006. Inverted files for text search engines. ACM Comput. Surv., 38, July.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>