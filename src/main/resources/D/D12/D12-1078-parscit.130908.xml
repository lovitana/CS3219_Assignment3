<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.978618">
Re-training Monolingual Parser Bilingually for Syntactic SMT
</title>
<author confidence="0.98832">
†Shujie Liu*, *Chi-Ho Li, *Mu Li and *Ming Zhou
</author>
<affiliation confidence="0.9980775">
†School of Computer Science and Technology
Harbin Institute of Technology, Harbin, China
</affiliation>
<email confidence="0.899291">
shujieliu@mtlab.hit.edu.cn
</email>
<affiliation confidence="0.841599">
*Microsoft Research Asia, Beijing, China
</affiliation>
<email confidence="0.976382">
{chl, muli, mingzhou}@microsoft.com
</email>
<sectionHeader confidence="0.982782" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998561">
The training of most syntactic SMT approaches
involves two essential components, word
alignment and monolingual parser. In the
current state of the art these two components
are mutually independent, thus causing
problems like lack of rule generalization, and
violation of syntactic correspondence in
translation rules. In this paper, we propose two
ways of re-training monolingual parser with the
target of maximizing the consistency between
parse trees and alignment matrices. One is
targeted self-training with a simple evaluation
function; the other is based on training data
selection from forced alignment of bilingual
data. We also propose an auxiliary method for
boosting alignment quality, by symmetrizing
alignment matrices with respect to parse trees.
The best combination of these novel methods
achieves 3 Bleu point gain in an IWSLT task
and more than 1 Bleu point gain in NIST tasks.
</bodyText>
<sectionHeader confidence="0.995165" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999981283018868">
There are many varieties in syntactic statistical
machine translation (SSMT). Apart from a few
attempts to use synchronous parsing to produce the
tree structure of both source language (SL) and
target language (TL) simultaneously, most SSMT
approaches make use of monolingual parser to
produce the parse tree(s) of the SL and/or TL
sentences, and then link up the information of the
two languages through word alignment. In the
current state of the art, word aligner and
monolingual parser are trained and applied
separately. On the one hand, an average word
aligner does not consider the syntax information of
both languages, and the output links may violate
syntactic correspondence. That is, some SL words
yielded by a SL parse tree node may not be traced
to, via alignment links, some TL words with
legitimate syntactic structure. On the other hand,
parser design is a monolingual activity and its
impact on MT is not well studied (Ambati, 2008).
Many good translation rules may thus be filtered
by a good monolingual parser.
In this paper we will focus on the translation
task from Chinese to English, and the string-to-tree
SSMT model as elaborated in (Galley et al., 2006).
There are two kinds of translation rules in this
model, minimal rules, and composed rules, which
are composition of minimal rules. The minimal
rules are extracted from a special kind of nodes,
known as frontier nodes, on TL parse tree. The
concept of frontier node can be illustrated by
Figure 1, which shows two partial bilingual
sentences with the corresponding TL sub-trees and
word alignment links. The TL words yielded by a
TL parse node can be traced to the corresponding
SL words through alignment links. In the diagram,
each parse node is represented by a rectangle,
showing the phrase label, span, and complement
span respectively. The span of a TL node N is
defined as the minimal contiguous SL string that
covers all the SL words reachable from N. The
complement span of N is the union of spans of all
the nodes that are neither descendants nor
ancestors of N (c.f. Galley et al., 2006) . A frontier
node is a node of which the span and the
complement span do not overlap with each other.
In the diagram, frontier nodes are grey in color.
Frontier node is the key in the SSMT model, as it
identifies the bilingual information which is
consistent with both the parse tree and alignment
matrix.
There are two major problems in the SSMT
model. The first one is the violation of syntactic
</bodyText>
<page confidence="0.653232">
854
</page>
<figure confidence="0.95212225">
A1111 ILIA IIE3 ftM4 M5 M6
A1111 ILIA IIE3 ftM4 M5 M6 *1 912 WN3 -M M5 A6 11X97
*1 912 WN3 -M M5 A6 11X97
(a) (b)
</figure>
<figureCaption confidence="0.988478666666667">
Figure 1. Two example partial bilingual sentences with word alignment and syntactic tree for the
target sentence. All the nodes in gray are frontier nodes. Example (a) contains two error links (in dash
line), and the syntactic tree for the target sentence of example (b) is wrong.
</figureCaption>
<figure confidence="0.997268601851852">
S
1-7
VDB
2
1,3-6
lived1 in2 the3 herdsmen4 ‘s 5 yurts6 at 7 night8
2 3 null1 4 6 6 6 1
3
1-2,4-6
IN
DT
null1
1-6
3-6
1-6
1-3,5-6
PP
1-3,6
4-6
NP
NN
4
1-3,6
4-6
1-6
VP
NP
POS
1-6
6
NNS
1-6
1-6
I
1-6
2-6
PP
2
N
2
N
null
null 7 7 5 6 1 null null null 3 4 4
1-7
DT
a1large2 number3 of4 people5 coming6 to7 listen8 to9 their10 propaganda11 lectures12
1
1-7
J
7
P
NN
1-7
7
1-4,6-7
IN
1-7
5
NP
4
1-5,7
NNS
1-5,7
6
4,7
1-6
PP
NP
6
VBG
3-7
1
4,5,7
1-6
NP
null
1-7
TO
4-7
1-4
VP
null
1-7
VB
1,4-7
3-4
VP
null
1,4-7
TO
1-7
3-4
VP
1,4-7
3-4
PP
1,4-7
PRP
3
1,4-7
3-4
NP
NN
1-7
4
1-7
VP
4
</figure>
<bodyText confidence="0.999429431818182">
structure by incorrect alignment links, as shown by
the two dashed links in Figure 1(a). These two
incorrect links hinder the extraction of a good
minimal rule “MM 4 NNS(yurts) ” and that of a
good composed rule “iftf�, M, 4 NP(DT(the),
NN(herdsmen), POS(&apos;s)) ”. By and large, incorrect
alignment links lead to translation rules that are
large in size, few in number, and poor in
generalization ability (Fossum et al, 2008). The
second problem is parsing error, as shown in
Figure 1(b). The incorrect POS tagging of the word
“lectures&amp;quot; causes a series of parsing errors,
including the absence of the noun phrase
“NP(NN(propaganda), NN(lectures))”. These
parsing errors hinder the extraction of good rules,
such as “ -A iA 4 NP(NN(propaganda),
NN(lectures)) ”.
Note that in Figure 1(a), the parse tree is correct,
and the incorrect alignment links might be fixed if
the aligner takes the parse tree into consideration.
Similarly, in Figure 1(b) some parsing errors might
be fixed if the parser takes into consideration the
correct alignment links about “propaganda” and
“lecture”. That is, alignment errors and parsing
might be fixed if word aligner and parser are not
mutually independent.
In this paper, we emphasize more on the
correction of parsing errors by exploiting
alignment information. The general approach is to
re-train a parser with parse trees which are the
most consistent with alignment matrices. Our first
strategy is to apply the idea of targeted self-
training (Katz-Brown et al., 2011) with the simple
evaluation function of frontier set size. That is to
re-train the parser with the parse trees which give
rise to the largest number of frontier nodes. The
second strategy is to apply forced alignment
(Wuebker et al., 2010) to bilingual data and select
the parse trees generated by our SSMT system for
re-training the parser. Besides, although we do not
invent a new word aligner exploiting syntactic
information, we propose a new method to
symmetrize the alignment matrices of two
directions by taking parse tree into consideration.
</bodyText>
<page confidence="0.948282">
855
</page>
<sectionHeader confidence="0.915537" genericHeader="method">
2 Parser Re-training Strategies
</sectionHeader>
<bodyText confidence="0.999931352941176">
Most monolingual parsers used in SSMT are
trained upon certain tree bank. That is, a parser is
trained with the target of maximizing the
agreement between its decision on syntactic
structure and that decision in the human-annotated
parse trees. As mentioned in Section 1,
monolingual syntactic structure is not necessarily
suitable for translation, and sometimes the
bilingual information in word alignment may help
the parser find out the correct structure. Therefore,
it is desirable if there is a way to re-train a parser
with bilingual information.
What is needed includes a framework of parser
re-training, and a data selection strategy that
maximizes the consistency between parse tree and
alignment matrix. Our two solutions will be
introduced in the next two subsections respectively.
</bodyText>
<subsectionHeader confidence="0.933893">
2.1 Targeted Self-Training with Frontier Set
Based Evaluation (TST-FS)
</subsectionHeader>
<bodyText confidence="0.999964">
The first solution is based on targeted self-training
(TST) (Katz-Brown et al., 2011). In standard self-
training, the top one parse trees produced by the
current parser are taken as training data for the
next round, and the training objective is still the
correctness of monolingual syntactic structure. In
targeted self-training, the training objective shifts
to certain external evaluation function. For each
sentence, the n-best parse trees from the current
parser are re-ranked in accordance with this
external evaluation function, and the top one of the
re-ranked candidates is then selected as training
data for the next round. The key of targeted self-
training is the definition of this external evaluation
function.
As shown by the example in Figure 1(b), an
incorrect parse tree is likely to hinder the
extraction of good translation rules, because the
number of frontier nodes in the incorrect tree is in
general smaller than that in the correct tree.
Consider the example in Figure 2, which is about
the same partial bilingual sentence as in Figure
1(b). Although both parse trees do not have the
correct syntactic structure, the tree in Figure 2 has
more frontier nodes, leads to more valid translation
rules, and is therefore more preferable.
This example suggests a very simple external
evaluation function, viz. the size of frontier set.
Given a bilingual sentence, its alignment matrix,
</bodyText>
<figureCaption confidence="0.7325185">
Figure 2. The parse tree selected by TST-FS for
the example in Figure 1(b)
</figureCaption>
<equation confidence="0.6899815">
1
1
</equation>
<bodyText confidence="0.999958823529412">
and the N-best parse trees of the TL sentence, we
will calculate the number of frontier nodes for each
parse tree, and re-rank the parse trees in its
descending order. The new top one parse tree is
selected as the training data for the next round of
targeted self-training of the TL parser. In the
following we will call this approach as targeted
self-training with frontier set based evaluation
(TST-FS).
Note that the size of the N-best list should be
kept small. It is because sometimes a parse tree
with an extremely mistaken structure happens to
have perfect match with the alignment matrix,
thereby giving rise to nearest the largest frontier set
size. It is empirically found that a 5-best list of
parse trees is already sufficient to significantly
improve translation performance.
</bodyText>
<subsectionHeader confidence="0.973994">
2.2 Forced Alignment-based Parser Re-
Training (FA-PR)
</subsectionHeader>
<bodyText confidence="0.999238214285714">
If we doubt that the parse tree from a monolingual
parser is not appropriate enough for translation
purpose, then it seems reasonable to consider using
the parse tree produced by an SSMT system to re-
train the parser. A naïve idea is simply to run an
SSMT system over some SL sentences and retrieve
the by-product TL parse trees for re-training the
monolingual parser. The biggest problem of this
naïve approach is that the translation by an MT
system is often a &apos;weird&apos; TL sentence, and thus the
associated parse tree is of little use in improving
the parser.
Forced alignment (Wuebker et al., 2010) of
bilingual data is a much more promising approach.
</bodyText>
<figure confidence="0.992462338235294">
VP
1-7
3-4
1,5-7
3-4
PP
VP
1-6
3-4
3-4,7
1,5-7
NP
NP
PP
7
1-6
3-4
1-6
3-5,7
1,5-7
NP
VP
NP
1-5,7
6
3-7
1,5-7
3-4
DT
JJ
NN
IN
NNS
VBG
TO
VB
TO
PRP
NN
VP
null
1-7
1-7
7
1-7
7
1-4,6-7
5
1-5,7
6
3-7
null
1-7
null
1-7
null
1-7
1,4-7
3
1-7
4
1-7
4
a1large2 number3 of4 people5 coming6 to7 listen8 to9 their10 propaganda11 lectures12
NP
1 W2 W33 M6 4 N5 &apos;A6 41 4:7
null 7 7 5 6 1 null null null 3 4 4
856
</figure>
<bodyText confidence="0.999095727272727">
When applied to SSMT, given a bilingual sentence,
it performs phrase segmentation of the SL side,
parsing of the TL side, and word alignment of the
bilingual sentence, using the full translation system
as in decoding. It finds the best decoding path that
generates the TL side of the bilingual sentence, and
the parse tree of the TL sentence is also obtained as
a by-product. The parse trees from forced
alignment are suitable for re-training the
monolingual parser.
Here is the simple iterative re-training algorithm.
First we have a baseline monolingual parser and
plug it into an SSMT system. Then perform forced
alignment, using the SSMT system, of some
bilingual data and obtain the parse trees as new
training data for the parser. The new parser can
then be applied again to do the second round of
forced alignment. This iteration of forced
alignment followed by parser re-training is kept
going until some stopping criterion is met. In the
following we will call this approach as forced
alignment based parser re-training (FA-PR).
</bodyText>
<table confidence="0.3729145">
Algorithm 1 Forced Alignment Based Parser Re-
Training (FA-PR)
</table>
<listItem confidence="0.987805333333333">
• step1: t = 0; Parso = Parsinit.
• step2: Use parser Parst to parse target
sentences of training data, and build a
SSMT systems SYSt.
• step3: Perform forced alignment on training
data with SYSt to get parse trees
</listItem>
<figure confidence="0.603367375">
Trees for target sentence of training
FA R
data.
• step4: Train a new parser ParsFAPR with
Trees .
FA R
• step5: t = t + 1; Parst = ars .
FA R
</figure>
<listItem confidence="0.950899333333333">
• Step6: Go to step 2, until performance of SYSt
on development data drops, or a preset
limit is reached.
</listItem>
<bodyText confidence="0.989247369565218">
There are a few important implementation
details of FA-PR. Forced alignment is guaranteed
to obtain a parse tree if all translation rules are kept
and no pruning is performed during decoding. Yet
in reality an average MT system applies pruning
during translation model training and decoding,
and a lot of translation rules will then be discarded.
In order to have more parse trees be considered by
forced alignment, we keep all translation rules and
relax pruning constraints in the decoder, viz.
Figure 3. The parse tree selected by FA-PR for the
example in Figure 1(b)
enlarge the stack size of each cell in the chart from
50 to 150.
Another measure to guarantee the existence of a
decoding path in forced alignment is to allow part
of a SL or TL sentence translate to null. Consider
the example in Figure 1(b). We also add a null
alignment for any span of the source and target
sentences to handle the null translation scenario. It
is easy to add a null translation candidate for a
span of the source sentence during decoding, but
not easy for target spans. For example, suppose the
best translation candidate for the source span &amp;quot; * 1
NP M&apos; 5 A 6 TP, 7&amp;quot; is &amp;quot;a large number of people
coming NP&amp;quot;, and the best translation candidate for
&amp;quot;plT 2 �� 3 &apos;iA 4&amp;quot; is &amp;quot;their propaganda lectures&amp;quot;,
there is no combination of candidates from two n-
best translation lists which can match a sequence in
the given target part, so we add a translation
candidate (&amp;quot;to listen to &amp;quot;) generated from null,
whose syntactic label can be any label (decided
according to the translated context, which is
“ADJP” here). The feature weights for the added
null alignment are set to be very small, so as to
avoid the competition with the normal candidates.
In order to generate normal trees with not so many
null alignment sub-trees for the target sentence
(such trees are not suitable for parser re-training),
only target spans with less than 4 words can align
to null, and such null-aligned sub-tree can only be
added no more than 3 times.
With all the mentioned modification of the
forced alignment, the partial target tree generated
using forced alignment for the example in Figure
1(b) is shown in Figure 3. We can see that even
</bodyText>
<figure confidence="0.994314701492538">
5-7
1-4
NP
NP
NP
PP
3-4
7
5-6
1,5-7
1-6
1-4,7
NP
3-4
NP
ADJP
1,5-7
NP
6
null
4
1-5,7
1-7
1-3,5-7
DT
JJ
NN
IN
NNS
VBG
TO
VB
TO
PRP
NN
VP
null
7
7
5
6
1
null
null
null
3
4
4
1-7
1-7
1-7
1-4,6-7
1-5,7
3-7
1-7
1-7
1-7
1,4-7
1-7
1-7
a1large2 number3 of4 people5 coming6 to7 listen8 to9 their10 propaganda11 lectures12
null 7 7 5 6 1 null null null 3 4 4
JIC1 91 2 MM W#4 it5 K6 419:7
NP
5-7
1-4
857
</figure>
<bodyText confidence="0.995762333333333">
with an incorrect sub-tree, more useful rules can be
extracted, compared with the baseline sub-tree and
the sub-tree generated from TST-FS.
</bodyText>
<sectionHeader confidence="0.980589" genericHeader="method">
3 Word Alignment Symmetrization
</sectionHeader>
<bodyText confidence="0.99302052631579">
The most widely used word aligners in MT, like
HMM and IBM Models (Och and Ney, 2003), are
directional aligners. Such aligner produces one set
of alignment matrices for the SL-to-TL direction
and another set for the TL-to-SL direction.
Symmetrization refers to the combination of these
two sets of alignment matrices.
The most popular method of symmetrization is
intersect-diag-grow (IDG). Given a bilingual
sentence and its two alignment matrices AST and
A IDG starts with all the links in AST ATS.
TS,
Then IDG considers each link in AST U ATS —
(AST n ATS) in turn. A link is added if its addition
does not make some phrase pairs overlap.
Although IDG is simple and efficient, and has been
shown to be effective in phrase-based SMT, it is
problematic in SSMT, as illustrated by the example
in section 1.
</bodyText>
<subsectionHeader confidence="0.923839">
3.1 Intersect-Diag-Syntactic-Grow (IDSG)
</subsectionHeader>
<bodyText confidence="0.914465166666667">
We propose a new symmetrization method,
Intersect-Diag-Syntactic-Grow (IDSG), which is
an adaptation of IDG but also taking syntactic
information in consideration. It is sketched in
Algorithm 2.
Algorithm 2 Intersect-Diag-Syntactic-Grow
</bodyText>
<listItem confidence="0.998221333333333">
• step1: Generate all the candidate links Acandi
using IDG.
• step2: Select the one which can generate the
biggest frontier set:
• step3: Add l to A, and repeat step 1, until no
new link can be added.
</listItem>
<figure confidence="0.9044546">
Like IDG, IDSG starts with all the links in
A A and its main task is to add links selected
ST TS
from Acandi — AST U ATS — (A A . IDSG is
ST TS)
</figure>
<bodyText confidence="0.9775348">
also subject to the constraints of IDG. The new
criterion in link selection in IDSG is specified in
Step 2. Given a parse tree of the TL side of the
bilingual sentence, in each iteration IDSG
considers the change of frontier set size caused by
</bodyText>
<equation confidence="0.835003">
lived1 in2 the3 herdsmen4 ‘s 5 yurts6 at 7 night8
AIC )R#2 -t3 ftR4 IYJ5 TPIM6
</equation>
<bodyText confidence="0.434054">
Figure 4, the alignment generated by IDSG for the
example in Figure 1(a)
</bodyText>
<equation confidence="0.585629">
1
</equation>
<bodyText confidence="0.999400071428571">
the addition of each link in Acandi . The link
leading to the maximum number of frontier nodes
is added (and removed from Acandi). This process
continues until no more links can be added.
In sum, IDSG add links in an order which take
syntactic structure into consideration, and the link
with the least violation of the syntactic structure is
added first.
For the example in Figure 1(a), IDSG succeeds
in discarding the two incorrect links, and produces
the final alignment and frontier set as shown in
Figure 4. Note that IDSG still fails to produce the
correct link (the3, 牧民 4), since this link does not
appear in Acandi at all.
</bodyText>
<subsectionHeader confidence="0.999931">
3.2 Combining TST-FS/FA-PR and IDSG
</subsectionHeader>
<bodyText confidence="0.999679384615385">
Parser re-training aims to improve a parser with
alignment matrix while IDSG aims to improve
alignment matrix with parse tree. It is reasonable to
combine them, and there are two alternatives of the
combination, depending on the order of application.
That is, we could either improve alignment matrix
by IDSG and then re-train parser with the better
alignment, or re-train parser and then improve
alignment matrix with better syntactic information.
Either alternative can be arranged into an iterative
training routine, but empirically it is found that
only one round of parser re-training before or after
only one round of IDSG is already enough.
</bodyText>
<figure confidence="0.990020261904762">
VDB
2
1,3-6
1-2,4-6
I
DT
null1
1-6
3-6
1-2
4
1-3,5-6
PP
1-3,6
4-5
NP
NN
4-6
1-6
----
1-3
1-4,6
VP
NP
POS
5
NNS
1-5
6
1
1-6
IN
1
2-6
PP
1-6
NN
1
1-6
NP
2 3 null1 4 5 6 1 1
858
</figure>
<sectionHeader confidence="0.900867" genericHeader="method">
4 Experiment
</sectionHeader>
<bodyText confidence="0.999869875">
In this section, we conduct experiments on Chinese
to English translation task to test our proposed
methods of parser re-training and word alignment
symmetrization. The evaluation method is the case
insensitive IBM BLEU-4 (Papineni et al., 2002).
Significant testing is carried out using bootstrap re-
sampling method proposed by Koehn (2004) with
a 95% confidence level.
</bodyText>
<subsectionHeader confidence="0.988643">
4.1 Parser and SMT Decoder
</subsectionHeader>
<bodyText confidence="0.999985727272727">
The syntactic parser we used in this paper is
Berkley parser, with the grammar trained on WSJ
corpus, and the training method follows Petrov and
Klein (2007). Our SMT decoder is an in-house
implementation of string-to-tree decoder. The
features we used are standard used features, such
as translation probabilities, lexical weights,
language model probabilities and distortion
probability. The feature weights are tuned using
the minimum error rate training (MERT) (Och,
2003).
</bodyText>
<subsectionHeader confidence="0.997649">
4.2 Experiment Data Setting and Baselines
</subsectionHeader>
<bodyText confidence="0.996182">
We test our method with two data settings: one is
IWSLT data set, the other is NIST data set.
</bodyText>
<table confidence="0.5043895">
dev8+dialog dev9
Baseline 50.58 49.85
</table>
<tableCaption confidence="0.935201">
Table 1. Baselines for IWSLT data set
</tableCaption>
<table confidence="0.989212">
NIST&apos;03 NIST&apos;05 NIST&apos;08
Baseline 37.57 36.44 24.87
</table>
<tableCaption confidence="0.994868">
Table 2. Baselines for NIST data set
</tableCaption>
<bodyText confidence="0.99997984375">
Our IWSLT data is the IWSLT 2009 dialog task
data set. The training data include the BTEC and
SLDB training data. The training data contains 81k
sentence pairs, 655k Chinese words and 806k
English words. The language model is 5-gram
language model trained with the English sentences
in the training data. We use the combination of
dev8 and dialog as development set, and dev9 as
test set. The TL sentences of the training data with
the selected/generated trees are used as the training
data to re-train the parser. To get the baseline of
this setting, we run IDG to combine the bi-
direction alignment generated by Giza++ (Och
Ney, 2003), and run Berkeley parser (Petrov and
Klein, 2007) to parse the target sentences. With the
baseline alignments and syntactic trees, we extract
rules and calculate features. The baseline results
are shown in Table 1.
For the NIST data set, the bilingual training data
we used is NIST 2008 training set excluding the
Hong Kong Law and Hong Kong Hansard. The
training data contains 354k sentence pairs, 8M
Chinese words and 10M English words, and is also
the training data for our parser re-training. The
language model is 5-gram language model trained
with the Giga-Word corpus plus the English
sentences in the training data. The development
data to tune the feature weights of our decoder is
NIST 2003 evaluation set, and test sets are NIST
2005 and 2008 evaluation sets. The baseline for
NIST data is got in a similar way with for IWSLT,
which are shown in Table 2 .
</bodyText>
<subsectionHeader confidence="0.998145">
4.3 Results of TST-FS/ FA-PR
</subsectionHeader>
<bodyText confidence="0.999966233333333">
The parser re-training strategies TST-FS and FA-
PR are tested with two baselines, one is the default
parser without any re-training and another is
standard self-training (SST). All three re-training
approaches are based on the same bilingual
datasets as used in translation model training. The
MT performances on IWSLT and NIST by the four
approaches are shown in Table 3 and 4
respectively.
It can be seen that just standard self-training
does improve translation performance, as re-
training on the TL side of bilingual data is a kind
of domain adaptation (from WSJ to IWSLT/NIST).
But targeted self-training achieves more noticeable
improvement, almost twice as much as standard
self-training. This confirms the value of word
alignment information in parser re-training. Finally,
the even larger improvement of FA-PR than TST-
FS shows that merely increasing the number of
frontier nodes is not enough. Some frontier nodes
are of poor quality, and the frontier nodes found in
forced alignment are more suitable.
It can also be seen that the improvement in
IWSLT is larger than that in NIST. The first reason
is that both WSJ and NIST are of the news domain
and of formal writing style, whereas IWSLT is of
the tourist domain and of colloquial style.
Therefore any improvement from the default parser,
which is trained on WSJ, is expected to be smaller
in the NIST case. Another reason is that, since the
</bodyText>
<page confidence="0.853553">
859
</page>
<bodyText confidence="0.9999518">
IWSLT dataset is much smaller, the impact of
more and better rules is more obvious.
Note that the figures in Table 3 and 4 are about
parser re-training for only one iteration. It is found
that, more iteration do not lead to further
significant improvement. The forced alignment of
bilingual training data does not obtain a full
decoding path for every bilingual sentence. It is
because, although all translation rules are kept,
there is still pruning during decoding. Only 64% of
the IWSLT dataset and 53% of the NIST dataset
can be successfully forced-aligned. In general, the
longer the bilingual sentence, the less likely forced
alignment is successful, and that is why a lower
proportion of NIST can be forced-aligned.
</bodyText>
<subsectionHeader confidence="0.992657">
4.4 Symmetrization
</subsectionHeader>
<bodyText confidence="0.999233">
The new symmetrization method IDSG is
compared with the baseline method IDG.
</bodyText>
<table confidence="0.995938">
dev8+dialog dev9 # Rules
IDG 50.58 49.85 515K
IDSG 52.71 51.80 626K
(+2.31) (+2.05)
</table>
<tableCaption confidence="0.91368025">
Table 5. MT performance of symmetrization
methods on IWSLT data set. The results in bold
type are significantly better than the performance
of IDG.
</tableCaption>
<table confidence="0.997933">
NIST&apos;03 NIST&apos;05 NIST&apos;08 #Rules
IDG 37.57 36.44 24.87 3,376K
IDSG 38.15 37.07 25.67 4,109K
(+0.58) (+0.63) (+0.80)
</table>
<bodyText confidence="0.901140181818182">
Table 6. MT performance of symmetrization
methods on NIST data. The results in bold type are
significantly better than the performance of IDG.
As shown by the results in Table 5 and 6, IDSG
enlarges the set of translation rules by more than
20%, thereby improving translation performance
significantly. As in parser re-training, the
improvement in the IWSLT task is larger than that
in the NIST task. Again, it is because the IWSLT
dataset is very small and so the effect of rule table
size is more obvious.
</bodyText>
<table confidence="0.9993945">
dev8+dialog dev9 # Rules
Baseline 50.58 49.85 515K
SST 52.04 51.26 574K
(+1.46) (+1.41)
TST-FS 52.75 52.51 572K
(+2.17) (+2.66)
FA-PR 53.31 52.8 591K
(+2.73) (+2.95)
</table>
<tableCaption confidence="0.81917875">
Table 3. MT performance of parser re-training
strategies on IWSLT data set. The results in
bold type are significantly better than the
baseline.
</tableCaption>
<table confidence="0.999755625">
NIST&apos;03 NIST&apos;05 NIST&apos;08 #Rules
Baseline 37.57 36.44 24.87 3,376K
SST 37.98 36.79 25.30 3,462K
(+0.41) (+0.35) (+0.43)
TST-FS 38.42 37.39 25.79 3642K
(+0.85) (+0.95) (+0.92) ,
FA-PR 38.74 37.69 25.89 3976K
(+1.17) (+1.25) (+1.02) ,
</table>
<tableCaption confidence="0.868153">
Table 4. MT performance of parser re-training
strategies on NIST data set. The results in bold
type are significantly better than the baseline.
</tableCaption>
<subsectionHeader confidence="0.985434">
4.5 Methods combined
</subsectionHeader>
<bodyText confidence="0.999934583333333">
As mentioned in section 3.2, parser re-training and
the new symmetrization method can be combined
in two different ways, depending on the order of
application. Table 7 and 8 show the experiment
results of combining FA-PR with IDSG.
It can be seen that either way of the combination
is better than using FA-PR or IDSG alone. Yet
there is no significant difference between the two
kinds of combination.
The best result is a gain of more than 3 Bleu
points on IWSLT and that of more than 1 Bleu
point on NIST.
</bodyText>
<sectionHeader confidence="0.99973" genericHeader="method">
5 Related Works
</sectionHeader>
<bodyText confidence="0.999904333333333">
There are a lot of attempts in improving word
alignment with syntactic information (Cherry and
Lin, 2006; DeNero and Klein, 2007; Hermjackob,
2009) and in improving parser with alignment
information (Burkett and Klein, 2008). Yet strictly
speaking all these attempts aim to improve the
</bodyText>
<page confidence="0.509261">
860
</page>
<bodyText confidence="0.999987128205128">
parser/aligner itself rather than the translation
model.
To improve the performance of syntactic
machine translation, Huang and Knight (2006)
proposed a method incorporating a handful of
relabeling strategies to modify the syntactic trees
structures. Ambati and Lavie (2008) restructured
target parse trees to generate highly isomorphic
target trees that preserve the syntactic boundaries
of constituents aligned in the original parse trees.
Wang et al., (2010) proposed to use re-structuring
and re-labeling to modify the parser tree. The re-
structuring method uses a binarization method to
enable the reuse of sub-constituent structures, and
the linguistic and statistical re-labeling methods to
handle the coarse nonterminal problem, so as to
enhance generalization ability. Different from the
previous work of modifying tree structures with
post-processing methods, our methods try to learn
a suitable grammar for string-to-tree SMT models,
and directly produce trees which are consistent
with word alignment matrices.
Instead of modifying the parse tree to improve
machine translation performance, many methods
were proposed to modify word alignment by taking
syntactic tree into consideration, including deleting
incorrect word alignment links by a discriminative
model (Fossum et al., 2008), re-aligning sentence
pairs using EM method with the rules extracted
with initial alignment (Wang et al., 2010), and
removing ambiguous alignment of functional
words with constraint from chunk-level
information during rule extraction (Wu et al.,
2011). Unlike all these pursuits, to generate a
consistent word alignment, our method modifies
the popularly used IDG symmetrization method to
make it suitable for string-to-tree rule extraction,
and our method is much simpler and faster than the
previous works.
</bodyText>
<sectionHeader confidence="0.998459" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999537777777778">
In this paper we have attempted to improve SSMT
by reducing the errors introduced by the mutual
independence between monolingual parser and
word aligner. Our major contribution is the
strategies of re-training parser with the bilingual
information in alignment matrices. Either of our
proposals of targeted self-training with frontier set
size as evaluation function and forced alignment
based re-training is more effective than baseline
</bodyText>
<table confidence="0.998119727272727">
dev8+dialog dev9 #
Rules
Baseline 50.58 49.85 515K
IDSG 52.71 51.80 626K
(+2.31) (+2.05)
FA-PR 53.31 52.8 591K
(+2.73) (+2.95)
IDSG then 53.64 53.32 602K
FA-PR (3.06) (+3.47)
FA-PR then 53.81 53.26 597K
IDSG (+3.23) (+3.41)
</table>
<tableCaption confidence="0.965963666666667">
Table 7. MT performance of the new methods
on IWSLT data set. The results in bold type
are significantly better than the baseline.
</tableCaption>
<table confidence="0.999160090909091">
NIST&apos;03 NIST&apos;05 NIST&apos;08 #Rules
Baseline 37.57 36.44 24.87 3,376K
IDSG 38.15 37.07 25.67 4,109K
(+0.58) (+0.63) (+0.80)
FA-PR 38.74 37.69 25.89 3976K
(+1.17) (+1.25) (+1.02) ,
IDSG 38.97 37.95 26.74 4,557K
then FA-PR (+1.40) (+1.51) (+1.87)
FA-PR 38.90 37.94 26.52 4,478K
then (+1.33) (+1.50) (+1.65)
IDSG
</table>
<tableCaption confidence="0.952922">
Table 8. MT performance of the new methods
</tableCaption>
<bodyText confidence="0.9736981">
on NIST data set. The results in bold type are
significantly better than the baseline.
parser or standard self-training of parser. As an
auxiliary method, we also attempted to improve
alignment matrices by a new symmetrization
method.
In future, we will explore more alternatives in
integrating parsing information and alignment
information, such as discriminative word
alignment using a lot of features from parser.
</bodyText>
<sectionHeader confidence="0.995465" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.931688333333333">
Vamshi Ambati and Alon Lavie. 2008. Improving
syntax driven translation models by re-structuring
divergent and non-isomorphic parse tree structures.
In Student Research Workshop of the Eighth
Conference of the Association for Machine
Translation in the Americas, pages 235-244.
</reference>
<page confidence="0.559052">
861
</page>
<reference confidence="0.999915376623377">
David Burkett and Dan Klein. 2008. Two languages are
better than one (for syntactic parsing). In
Proceedings of the Conference on Empirical
Methods on Natural Language Processing, pages
877-886.
Colin Cherry and Dekang Lin. 2006. Soft syntactic
constraints for word alignment through
discriminative training. In Proceedings of the 21st
International Conference on Computational
Linguistics and 44th Annual Meeting of the
Association for Computational Linguistics.
John DeNero and Dan Klein. 2007. Tailing word
alignment to syntactic machine translation. In
Proceedings of the Association for Computational
Linguistics, pages 17-24.
Victoria Fossum, Kevin Knight, Steven Abney. 2008.
Using syntax to improve word alignment precision
for syntax-based machine translation. In Proceedings
of the Third Workshop on Statistical Machine
Translation, pages 44-52.
Michel Galley, Jonathan Graehl, Kevin Knight, Daniel
Marcu, Steve Deneefe, Wei Wang and Ignacio
Thayer. 2006. Scalable inference and training of
context-rich syntactic translation models. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meeting
of the Association for Computational Linguistics,
pages 961-968.
Ulf Hermjackob. Improved word alignment with
statistics and linguistic heuristics. In Proceedings of
the Conference on Empirical Methods on Natural
Language Processing, pages 229-237.
Bryant Huang, Kevin Knight. 2006. Relabeling syntax
trees to improve syntax-based machine translation
quality. In Proceedings of the Human Technology
Conference of the North American Chapter of the
ACL, pages 240-247.
Jason Katz-Brown, Slav Petrov, Ryan McDonald, Franz
Och, David Talbot, Hiroshi Ichikawa, Masakazu
Seno, Hideto Kazawa. 2011. Training a parser for
machine translation reordering. In Proceedings of the
Conference on Empirical Methods on Natural
Language Processing, pages 183-192.
Philipp Koehn. 2004. Statistical significance tests for
machine translation evaluation. In Proceedings of the
Conference on Empirical Methods on Natural
Language Processing, pages 388-395.
Wei Wang, Jonathan May, Kevin Knight, Daniel Marcu.
2010. Re-structuring, re-labeling, and re-alignment
for syntax-Based machine translation. Computational
Linguistics, 36(2).
Xianchao Wu, Takuya Matsuzaki and Jun&apos;ichi Tsujii.
2011. Effective use of function words for rule
generalization in forest-based translation. In
Proceedings of the Association for Computational
Linguistics, pages 22-31.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
Association for Computational Linguistics, pages
160-167.
Franz Josef Och and Hermann Ney. 2003. A systematic
comparison of various statistical alignment models.
Computational Linguistics, 29(1).
Joern Wuebker, Arne Mauser and Hermann Ney. 2010.
Training phrase translation models with leaving-one-
out. In Proceedings of the Association for
Computational Linguistics, pages 475-484.
Kishore Papineni, Salim Roukos, Todd Ward and Wei-
jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings of
the Association for Computational Linguistics, pages
311-318.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of Human
Language Technologies: The Annual Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 404–411.
</reference>
<page confidence="0.88918">
862
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.561436">
<title confidence="0.999681">Re-training Monolingual Parser Bilingually for Syntactic SMT</title>
<author confidence="0.999975">Li Zhou</author>
<affiliation confidence="0.9978555">of Computer Science and Harbin Institute of Technology, Harbin,</affiliation>
<email confidence="0.766916">shujieliu@mtlab.hit.edu.cn</email>
<address confidence="0.798294">Research Asia, Beijing, China</address>
<email confidence="0.999665">chl@microsoft.com</email>
<email confidence="0.999665">muli@microsoft.com</email>
<email confidence="0.999665">mingzhou@microsoft.com</email>
<abstract confidence="0.998419571428571">The training of most syntactic SMT approaches involves two essential components, word alignment and monolingual parser. In the current state of the art these two components are mutually independent, thus causing problems like lack of rule generalization, and violation of syntactic correspondence in translation rules. In this paper, we propose two ways of re-training monolingual parser with the target of maximizing the consistency between parse trees and alignment matrices. One is targeted self-training with a simple evaluation function; the other is based on training data selection from forced alignment of bilingual data. We also propose an auxiliary method for boosting alignment quality, by symmetrizing alignment matrices with respect to parse trees. The best combination of these novel methods achieves 3 Bleu point gain in an IWSLT task and more than 1 Bleu point gain in NIST tasks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Vamshi Ambati</author>
<author>Alon Lavie</author>
</authors>
<title>Improving syntax driven translation models by re-structuring divergent and non-isomorphic parse tree structures.</title>
<date>2008</date>
<booktitle>In Student Research Workshop of the Eighth Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>235--244</pages>
<contexts>
<context position="26247" citStr="Ambati and Lavie (2008)" startWordPosition="4506" endWordPosition="4509">nd that of more than 1 Bleu point on NIST. 5 Related Works There are a lot of attempts in improving word alignment with syntactic information (Cherry and Lin, 2006; DeNero and Klein, 2007; Hermjackob, 2009) and in improving parser with alignment information (Burkett and Klein, 2008). Yet strictly speaking all these attempts aim to improve the 860 parser/aligner itself rather than the translation model. To improve the performance of syntactic machine translation, Huang and Knight (2006) proposed a method incorporating a handful of relabeling strategies to modify the syntactic trees structures. Ambati and Lavie (2008) restructured target parse trees to generate highly isomorphic target trees that preserve the syntactic boundaries of constituents aligned in the original parse trees. Wang et al., (2010) proposed to use re-structuring and re-labeling to modify the parser tree. The restructuring method uses a binarization method to enable the reuse of sub-constituent structures, and the linguistic and statistical re-labeling methods to handle the coarse nonterminal problem, so as to enhance generalization ability. Different from the previous work of modifying tree structures with post-processing methods, our m</context>
</contexts>
<marker>Ambati, Lavie, 2008</marker>
<rawString>Vamshi Ambati and Alon Lavie. 2008. Improving syntax driven translation models by re-structuring divergent and non-isomorphic parse tree structures. In Student Research Workshop of the Eighth Conference of the Association for Machine Translation in the Americas, pages 235-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Burkett</author>
<author>Dan Klein</author>
</authors>
<title>Two languages are better than one (for syntactic parsing).</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods on Natural Language Processing,</booktitle>
<pages>877--886</pages>
<contexts>
<context position="25907" citStr="Burkett and Klein, 2008" startWordPosition="4457" endWordPosition="4460">pending on the order of application. Table 7 and 8 show the experiment results of combining FA-PR with IDSG. It can be seen that either way of the combination is better than using FA-PR or IDSG alone. Yet there is no significant difference between the two kinds of combination. The best result is a gain of more than 3 Bleu points on IWSLT and that of more than 1 Bleu point on NIST. 5 Related Works There are a lot of attempts in improving word alignment with syntactic information (Cherry and Lin, 2006; DeNero and Klein, 2007; Hermjackob, 2009) and in improving parser with alignment information (Burkett and Klein, 2008). Yet strictly speaking all these attempts aim to improve the 860 parser/aligner itself rather than the translation model. To improve the performance of syntactic machine translation, Huang and Knight (2006) proposed a method incorporating a handful of relabeling strategies to modify the syntactic trees structures. Ambati and Lavie (2008) restructured target parse trees to generate highly isomorphic target trees that preserve the syntactic boundaries of constituents aligned in the original parse trees. Wang et al., (2010) proposed to use re-structuring and re-labeling to modify the parser tree</context>
</contexts>
<marker>Burkett, Klein, 2008</marker>
<rawString>David Burkett and Dan Klein. 2008. Two languages are better than one (for syntactic parsing). In Proceedings of the Conference on Empirical Methods on Natural Language Processing, pages 877-886.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Soft syntactic constraints for word alignment through discriminative training.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="25787" citStr="Cherry and Lin, 2006" startWordPosition="4440" endWordPosition="4443">ioned in section 3.2, parser re-training and the new symmetrization method can be combined in two different ways, depending on the order of application. Table 7 and 8 show the experiment results of combining FA-PR with IDSG. It can be seen that either way of the combination is better than using FA-PR or IDSG alone. Yet there is no significant difference between the two kinds of combination. The best result is a gain of more than 3 Bleu points on IWSLT and that of more than 1 Bleu point on NIST. 5 Related Works There are a lot of attempts in improving word alignment with syntactic information (Cherry and Lin, 2006; DeNero and Klein, 2007; Hermjackob, 2009) and in improving parser with alignment information (Burkett and Klein, 2008). Yet strictly speaking all these attempts aim to improve the 860 parser/aligner itself rather than the translation model. To improve the performance of syntactic machine translation, Huang and Knight (2006) proposed a method incorporating a handful of relabeling strategies to modify the syntactic trees structures. Ambati and Lavie (2008) restructured target parse trees to generate highly isomorphic target trees that preserve the syntactic boundaries of constituents aligned i</context>
</contexts>
<marker>Cherry, Lin, 2006</marker>
<rawString>Colin Cherry and Dekang Lin. 2006. Soft syntactic constraints for word alignment through discriminative training. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Tailing word alignment to syntactic machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="25811" citStr="DeNero and Klein, 2007" startWordPosition="4444" endWordPosition="4447">parser re-training and the new symmetrization method can be combined in two different ways, depending on the order of application. Table 7 and 8 show the experiment results of combining FA-PR with IDSG. It can be seen that either way of the combination is better than using FA-PR or IDSG alone. Yet there is no significant difference between the two kinds of combination. The best result is a gain of more than 3 Bleu points on IWSLT and that of more than 1 Bleu point on NIST. 5 Related Works There are a lot of attempts in improving word alignment with syntactic information (Cherry and Lin, 2006; DeNero and Klein, 2007; Hermjackob, 2009) and in improving parser with alignment information (Burkett and Klein, 2008). Yet strictly speaking all these attempts aim to improve the 860 parser/aligner itself rather than the translation model. To improve the performance of syntactic machine translation, Huang and Knight (2006) proposed a method incorporating a handful of relabeling strategies to modify the syntactic trees structures. Ambati and Lavie (2008) restructured target parse trees to generate highly isomorphic target trees that preserve the syntactic boundaries of constituents aligned in the original parse tre</context>
</contexts>
<marker>DeNero, Klein, 2007</marker>
<rawString>John DeNero and Dan Klein. 2007. Tailing word alignment to syntactic machine translation. In Proceedings of the Association for Computational Linguistics, pages 17-24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria Fossum</author>
<author>Kevin Knight</author>
<author>Steven Abney</author>
</authors>
<title>Using syntax to improve word alignment precision for syntax-based machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>44--52</pages>
<contexts>
<context position="5098" citStr="Fossum et al, 2008" startWordPosition="891" endWordPosition="894">-7 5 NP 4 1-5,7 NNS 1-5,7 6 4,7 1-6 PP NP 6 VBG 3-7 1 4,5,7 1-6 NP null 1-7 TO 4-7 1-4 VP null 1-7 VB 1,4-7 3-4 VP null 1,4-7 TO 1-7 3-4 VP 1,4-7 3-4 PP 1,4-7 PRP 3 1,4-7 3-4 NP NN 1-7 4 1-7 VP 4 structure by incorrect alignment links, as shown by the two dashed links in Figure 1(a). These two incorrect links hinder the extraction of a good minimal rule “MM 4 NNS(yurts) ” and that of a good composed rule “iftf�, M, 4 NP(DT(the), NN(herdsmen), POS(&apos;s)) ”. By and large, incorrect alignment links lead to translation rules that are large in size, few in number, and poor in generalization ability (Fossum et al, 2008). The second problem is parsing error, as shown in Figure 1(b). The incorrect POS tagging of the word “lectures&amp;quot; causes a series of parsing errors, including the absence of the noun phrase “NP(NN(propaganda), NN(lectures))”. These parsing errors hinder the extraction of good rules, such as “ -A iA 4 NP(NN(propaganda), NN(lectures)) ”. Note that in Figure 1(a), the parse tree is correct, and the incorrect alignment links might be fixed if the aligner takes the parse tree into consideration. Similarly, in Figure 1(b) some parsing errors might be fixed if the parser takes into consideration the c</context>
<context position="27269" citStr="Fossum et al., 2008" startWordPosition="4652" endWordPosition="4655">-labeling methods to handle the coarse nonterminal problem, so as to enhance generalization ability. Different from the previous work of modifying tree structures with post-processing methods, our methods try to learn a suitable grammar for string-to-tree SMT models, and directly produce trees which are consistent with word alignment matrices. Instead of modifying the parse tree to improve machine translation performance, many methods were proposed to modify word alignment by taking syntactic tree into consideration, including deleting incorrect word alignment links by a discriminative model (Fossum et al., 2008), re-aligning sentence pairs using EM method with the rules extracted with initial alignment (Wang et al., 2010), and removing ambiguous alignment of functional words with constraint from chunk-level information during rule extraction (Wu et al., 2011). Unlike all these pursuits, to generate a consistent word alignment, our method modifies the popularly used IDG symmetrization method to make it suitable for string-to-tree rule extraction, and our method is much simpler and faster than the previous works. 6 Conclusion In this paper we have attempted to improve SSMT by reducing the errors introd</context>
</contexts>
<marker>Fossum, Knight, Abney, 2008</marker>
<rawString>Victoria Fossum, Kevin Knight, Steven Abney. 2008. Using syntax to improve word alignment precision for syntax-based machine translation. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 44-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Jonathan Graehl</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
<author>Steve Deneefe</author>
<author>Wei Wang</author>
<author>Ignacio Thayer</author>
</authors>
<title>Scalable inference and training of context-rich syntactic translation models.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>961--968</pages>
<contexts>
<context position="2402" citStr="Galley et al., 2006" startWordPosition="368" endWordPosition="371">aligner does not consider the syntax information of both languages, and the output links may violate syntactic correspondence. That is, some SL words yielded by a SL parse tree node may not be traced to, via alignment links, some TL words with legitimate syntactic structure. On the other hand, parser design is a monolingual activity and its impact on MT is not well studied (Ambati, 2008). Many good translation rules may thus be filtered by a good monolingual parser. In this paper we will focus on the translation task from Chinese to English, and the string-to-tree SSMT model as elaborated in (Galley et al., 2006). There are two kinds of translation rules in this model, minimal rules, and composed rules, which are composition of minimal rules. The minimal rules are extracted from a special kind of nodes, known as frontier nodes, on TL parse tree. The concept of frontier node can be illustrated by Figure 1, which shows two partial bilingual sentences with the corresponding TL sub-trees and word alignment links. The TL words yielded by a TL parse node can be traced to the corresponding SL words through alignment links. In the diagram, each parse node is represented by a rectangle, showing the phrase labe</context>
</contexts>
<marker>Galley, Graehl, Knight, Marcu, Deneefe, Wang, Thayer, 2006</marker>
<rawString>Michel Galley, Jonathan Graehl, Kevin Knight, Daniel Marcu, Steve Deneefe, Wei Wang and Ignacio Thayer. 2006. Scalable inference and training of context-rich syntactic translation models. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 961-968.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ulf Hermjackob</author>
</authors>
<title>Improved word alignment with statistics and linguistic heuristics.</title>
<booktitle>In Proceedings of the Conference on Empirical Methods on Natural Language Processing,</booktitle>
<pages>229--237</pages>
<marker>Hermjackob, </marker>
<rawString>Ulf Hermjackob. Improved word alignment with statistics and linguistic heuristics. In Proceedings of the Conference on Empirical Methods on Natural Language Processing, pages 229-237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bryant Huang</author>
<author>Kevin Knight</author>
</authors>
<title>Relabeling syntax trees to improve syntax-based machine translation quality.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Technology Conference of the North American Chapter of the ACL,</booktitle>
<pages>240--247</pages>
<contexts>
<context position="26114" citStr="Huang and Knight (2006)" startWordPosition="4487" endWordPosition="4490">re is no significant difference between the two kinds of combination. The best result is a gain of more than 3 Bleu points on IWSLT and that of more than 1 Bleu point on NIST. 5 Related Works There are a lot of attempts in improving word alignment with syntactic information (Cherry and Lin, 2006; DeNero and Klein, 2007; Hermjackob, 2009) and in improving parser with alignment information (Burkett and Klein, 2008). Yet strictly speaking all these attempts aim to improve the 860 parser/aligner itself rather than the translation model. To improve the performance of syntactic machine translation, Huang and Knight (2006) proposed a method incorporating a handful of relabeling strategies to modify the syntactic trees structures. Ambati and Lavie (2008) restructured target parse trees to generate highly isomorphic target trees that preserve the syntactic boundaries of constituents aligned in the original parse trees. Wang et al., (2010) proposed to use re-structuring and re-labeling to modify the parser tree. The restructuring method uses a binarization method to enable the reuse of sub-constituent structures, and the linguistic and statistical re-labeling methods to handle the coarse nonterminal problem, so as</context>
</contexts>
<marker>Huang, Knight, 2006</marker>
<rawString>Bryant Huang, Kevin Knight. 2006. Relabeling syntax trees to improve syntax-based machine translation quality. In Proceedings of the Human Technology Conference of the North American Chapter of the ACL, pages 240-247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Katz-Brown</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Franz Och</author>
<author>David Talbot</author>
</authors>
<title>Hiroshi Ichikawa, Masakazu Seno, Hideto Kazawa.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods on Natural Language Processing,</booktitle>
<pages>183--192</pages>
<contexts>
<context position="6178" citStr="Katz-Brown et al., 2011" startWordPosition="1063" endWordPosition="1066">kes the parse tree into consideration. Similarly, in Figure 1(b) some parsing errors might be fixed if the parser takes into consideration the correct alignment links about “propaganda” and “lecture”. That is, alignment errors and parsing might be fixed if word aligner and parser are not mutually independent. In this paper, we emphasize more on the correction of parsing errors by exploiting alignment information. The general approach is to re-train a parser with parse trees which are the most consistent with alignment matrices. Our first strategy is to apply the idea of targeted selftraining (Katz-Brown et al., 2011) with the simple evaluation function of frontier set size. That is to re-train the parser with the parse trees which give rise to the largest number of frontier nodes. The second strategy is to apply forced alignment (Wuebker et al., 2010) to bilingual data and select the parse trees generated by our SSMT system for re-training the parser. Besides, although we do not invent a new word aligner exploiting syntactic information, we propose a new method to symmetrize the alignment matrices of two directions by taking parse tree into consideration. 855 2 Parser Re-training Strategies Most monolingu</context>
<context position="7713" citStr="Katz-Brown et al., 2011" startWordPosition="1302" endWordPosition="1305">itable for translation, and sometimes the bilingual information in word alignment may help the parser find out the correct structure. Therefore, it is desirable if there is a way to re-train a parser with bilingual information. What is needed includes a framework of parser re-training, and a data selection strategy that maximizes the consistency between parse tree and alignment matrix. Our two solutions will be introduced in the next two subsections respectively. 2.1 Targeted Self-Training with Frontier Set Based Evaluation (TST-FS) The first solution is based on targeted self-training (TST) (Katz-Brown et al., 2011). In standard selftraining, the top one parse trees produced by the current parser are taken as training data for the next round, and the training objective is still the correctness of monolingual syntactic structure. In targeted self-training, the training objective shifts to certain external evaluation function. For each sentence, the n-best parse trees from the current parser are re-ranked in accordance with this external evaluation function, and the top one of the re-ranked candidates is then selected as training data for the next round. The key of targeted selftraining is the definition o</context>
</contexts>
<marker>Katz-Brown, Petrov, McDonald, Och, Talbot, 2011</marker>
<rawString>Jason Katz-Brown, Slav Petrov, Ryan McDonald, Franz Och, David Talbot, Hiroshi Ichikawa, Masakazu Seno, Hideto Kazawa. 2011. Training a parser for machine translation reordering. In Proceedings of the Conference on Empirical Methods on Natural Language Processing, pages 183-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods on Natural Language Processing,</booktitle>
<pages>388--395</pages>
<contexts>
<context position="19007" citStr="Koehn (2004)" startWordPosition="3312" endWordPosition="3313">und of parser re-training before or after only one round of IDSG is already enough. VDB 2 1,3-6 1-2,4-6 I DT null1 1-6 3-6 1-2 4 1-3,5-6 PP 1-3,6 4-5 NP NN 4-6 1-6 ---- 1-3 1-4,6 VP NP POS 5 NNS 1-5 6 1 1-6 IN 1 2-6 PP 1-6 NN 1 1-6 NP 2 3 null1 4 5 6 1 1 858 4 Experiment In this section, we conduct experiments on Chinese to English translation task to test our proposed methods of parser re-training and word alignment symmetrization. The evaluation method is the case insensitive IBM BLEU-4 (Papineni et al., 2002). Significant testing is carried out using bootstrap resampling method proposed by Koehn (2004) with a 95% confidence level. 4.1 Parser and SMT Decoder The syntactic parser we used in this paper is Berkley parser, with the grammar trained on WSJ corpus, and the training method follows Petrov and Klein (2007). Our SMT decoder is an in-house implementation of string-to-tree decoder. The features we used are standard used features, such as translation probabilities, lexical weights, language model probabilities and distortion probability. The feature weights are tuned using the minimum error rate training (MERT) (Och, 2003). 4.2 Experiment Data Setting and Baselines We test our method with</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of the Conference on Empirical Methods on Natural Language Processing, pages 388-395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wang</author>
<author>Jonathan May</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Re-structuring, re-labeling, and re-alignment for syntax-Based machine translation.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>2</issue>
<contexts>
<context position="26434" citStr="Wang et al., (2010)" startWordPosition="4533" endWordPosition="4536">rmjackob, 2009) and in improving parser with alignment information (Burkett and Klein, 2008). Yet strictly speaking all these attempts aim to improve the 860 parser/aligner itself rather than the translation model. To improve the performance of syntactic machine translation, Huang and Knight (2006) proposed a method incorporating a handful of relabeling strategies to modify the syntactic trees structures. Ambati and Lavie (2008) restructured target parse trees to generate highly isomorphic target trees that preserve the syntactic boundaries of constituents aligned in the original parse trees. Wang et al., (2010) proposed to use re-structuring and re-labeling to modify the parser tree. The restructuring method uses a binarization method to enable the reuse of sub-constituent structures, and the linguistic and statistical re-labeling methods to handle the coarse nonterminal problem, so as to enhance generalization ability. Different from the previous work of modifying tree structures with post-processing methods, our methods try to learn a suitable grammar for string-to-tree SMT models, and directly produce trees which are consistent with word alignment matrices. Instead of modifying the parse tree to </context>
</contexts>
<marker>Wang, May, Knight, Marcu, 2010</marker>
<rawString>Wei Wang, Jonathan May, Kevin Knight, Daniel Marcu. 2010. Re-structuring, re-labeling, and re-alignment for syntax-Based machine translation. Computational Linguistics, 36(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianchao Wu</author>
<author>Takuya Matsuzaki</author>
<author>Jun&apos;ichi Tsujii</author>
</authors>
<title>Effective use of function words for rule generalization in forest-based translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>22--31</pages>
<contexts>
<context position="27521" citStr="Wu et al., 2011" startWordPosition="4688" endWordPosition="4691">SMT models, and directly produce trees which are consistent with word alignment matrices. Instead of modifying the parse tree to improve machine translation performance, many methods were proposed to modify word alignment by taking syntactic tree into consideration, including deleting incorrect word alignment links by a discriminative model (Fossum et al., 2008), re-aligning sentence pairs using EM method with the rules extracted with initial alignment (Wang et al., 2010), and removing ambiguous alignment of functional words with constraint from chunk-level information during rule extraction (Wu et al., 2011). Unlike all these pursuits, to generate a consistent word alignment, our method modifies the popularly used IDG symmetrization method to make it suitable for string-to-tree rule extraction, and our method is much simpler and faster than the previous works. 6 Conclusion In this paper we have attempted to improve SSMT by reducing the errors introduced by the mutual independence between monolingual parser and word aligner. Our major contribution is the strategies of re-training parser with the bilingual information in alignment matrices. Either of our proposals of targeted self-training with fro</context>
</contexts>
<marker>Wu, Matsuzaki, Tsujii, 2011</marker>
<rawString>Xianchao Wu, Takuya Matsuzaki and Jun&apos;ichi Tsujii. 2011. Effective use of function words for rule generalization in forest-based translation. In Proceedings of the Association for Computational Linguistics, pages 22-31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="19540" citStr="Och, 2003" startWordPosition="3393" endWordPosition="3394">ing is carried out using bootstrap resampling method proposed by Koehn (2004) with a 95% confidence level. 4.1 Parser and SMT Decoder The syntactic parser we used in this paper is Berkley parser, with the grammar trained on WSJ corpus, and the training method follows Petrov and Klein (2007). Our SMT decoder is an in-house implementation of string-to-tree decoder. The features we used are standard used features, such as translation probabilities, lexical weights, language model probabilities and distortion probability. The feature weights are tuned using the minimum error rate training (MERT) (Och, 2003). 4.2 Experiment Data Setting and Baselines We test our method with two data settings: one is IWSLT data set, the other is NIST data set. dev8+dialog dev9 Baseline 50.58 49.85 Table 1. Baselines for IWSLT data set NIST&apos;03 NIST&apos;05 NIST&apos;08 Baseline 37.57 36.44 24.87 Table 2. Baselines for NIST data set Our IWSLT data is the IWSLT 2009 dialog task data set. The training data include the BTEC and SLDB training data. The training data contains 81k sentence pairs, 655k Chinese words and 806k English words. The language model is 5-gram language model trained with the English sentences in the training</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the Association for Computational Linguistics, pages 160-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="15420" citStr="Och and Ney, 2003" startWordPosition="2682" endWordPosition="2685">-7 1-6 1-4,7 NP 3-4 NP ADJP 1,5-7 NP 6 null 4 1-5,7 1-7 1-3,5-7 DT JJ NN IN NNS VBG TO VB TO PRP NN VP null 7 7 5 6 1 null null null 3 4 4 1-7 1-7 1-7 1-4,6-7 1-5,7 3-7 1-7 1-7 1-7 1,4-7 1-7 1-7 a1large2 number3 of4 people5 coming6 to7 listen8 to9 their10 propaganda11 lectures12 null 7 7 5 6 1 null null null 3 4 4 JIC1 91 2 MM W#4 it5 K6 419:7 NP 5-7 1-4 857 with an incorrect sub-tree, more useful rules can be extracted, compared with the baseline sub-tree and the sub-tree generated from TST-FS. 3 Word Alignment Symmetrization The most widely used word aligners in MT, like HMM and IBM Models (Och and Ney, 2003), are directional aligners. Such aligner produces one set of alignment matrices for the SL-to-TL direction and another set for the TL-to-SL direction. Symmetrization refers to the combination of these two sets of alignment matrices. The most popular method of symmetrization is intersect-diag-grow (IDG). Given a bilingual sentence and its two alignment matrices AST and A IDG starts with all the links in AST ATS. TS, Then IDG considers each link in AST U ATS — (AST n ATS) in turn. A link is added if its addition does not make some phrase pairs overlap. Although IDG is simple and efficient, and h</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joern Wuebker</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Training phrase translation models with leaving-oneout.</title>
<date>2010</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>475--484</pages>
<contexts>
<context position="6417" citStr="Wuebker et al., 2010" startWordPosition="1104" endWordPosition="1107">ht be fixed if word aligner and parser are not mutually independent. In this paper, we emphasize more on the correction of parsing errors by exploiting alignment information. The general approach is to re-train a parser with parse trees which are the most consistent with alignment matrices. Our first strategy is to apply the idea of targeted selftraining (Katz-Brown et al., 2011) with the simple evaluation function of frontier set size. That is to re-train the parser with the parse trees which give rise to the largest number of frontier nodes. The second strategy is to apply forced alignment (Wuebker et al., 2010) to bilingual data and select the parse trees generated by our SSMT system for re-training the parser. Besides, although we do not invent a new word aligner exploiting syntactic information, we propose a new method to symmetrize the alignment matrices of two directions by taking parse tree into consideration. 855 2 Parser Re-training Strategies Most monolingual parsers used in SSMT are trained upon certain tree bank. That is, a parser is trained with the target of maximizing the agreement between its decision on syntactic structure and that decision in the human-annotated parse trees. As menti</context>
<context position="10549" citStr="Wuebker et al., 2010" startWordPosition="1774" endWordPosition="1777">er ReTraining (FA-PR) If we doubt that the parse tree from a monolingual parser is not appropriate enough for translation purpose, then it seems reasonable to consider using the parse tree produced by an SSMT system to retrain the parser. A naïve idea is simply to run an SSMT system over some SL sentences and retrieve the by-product TL parse trees for re-training the monolingual parser. The biggest problem of this naïve approach is that the translation by an MT system is often a &apos;weird&apos; TL sentence, and thus the associated parse tree is of little use in improving the parser. Forced alignment (Wuebker et al., 2010) of bilingual data is a much more promising approach. VP 1-7 3-4 1,5-7 3-4 PP VP 1-6 3-4 3-4,7 1,5-7 NP NP PP 7 1-6 3-4 1-6 3-5,7 1,5-7 NP VP NP 1-5,7 6 3-7 1,5-7 3-4 DT JJ NN IN NNS VBG TO VB TO PRP NN VP null 1-7 1-7 7 1-7 7 1-4,6-7 5 1-5,7 6 3-7 null 1-7 null 1-7 null 1-7 1,4-7 3 1-7 4 1-7 4 a1large2 number3 of4 people5 coming6 to7 listen8 to9 their10 propaganda11 lectures12 NP 1 W2 W33 M6 4 N5 &apos;A6 41 4:7 null 7 7 5 6 1 null null null 3 4 4 856 When applied to SSMT, given a bilingual sentence, it performs phrase segmentation of the SL side, parsing of the TL side, and word alignment of the </context>
</contexts>
<marker>Wuebker, Mauser, Ney, 2010</marker>
<rawString>Joern Wuebker, Arne Mauser and Hermann Ney. 2010. Training phrase translation models with leaving-oneout. In Proceedings of the Association for Computational Linguistics, pages 475-484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Weijing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="18912" citStr="Papineni et al., 2002" startWordPosition="3296" endWordPosition="3299">ernative can be arranged into an iterative training routine, but empirically it is found that only one round of parser re-training before or after only one round of IDSG is already enough. VDB 2 1,3-6 1-2,4-6 I DT null1 1-6 3-6 1-2 4 1-3,5-6 PP 1-3,6 4-5 NP NN 4-6 1-6 ---- 1-3 1-4,6 VP NP POS 5 NNS 1-5 6 1 1-6 IN 1 2-6 PP 1-6 NN 1 1-6 NP 2 3 null1 4 5 6 1 1 858 4 Experiment In this section, we conduct experiments on Chinese to English translation task to test our proposed methods of parser re-training and word alignment symmetrization. The evaluation method is the case insensitive IBM BLEU-4 (Papineni et al., 2002). Significant testing is carried out using bootstrap resampling method proposed by Koehn (2004) with a 95% confidence level. 4.1 Parser and SMT Decoder The syntactic parser we used in this paper is Berkley parser, with the grammar trained on WSJ corpus, and the training method follows Petrov and Klein (2007). Our SMT decoder is an in-house implementation of string-to-tree decoder. The features we used are standard used features, such as translation probabilities, lexical weights, language model probabilities and distortion probability. The feature weights are tuned using the minimum error rate</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward and Weijing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the Association for Computational Linguistics, pages 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="19221" citStr="Petrov and Klein (2007)" startWordPosition="3347" endWordPosition="3350">1-6 IN 1 2-6 PP 1-6 NN 1 1-6 NP 2 3 null1 4 5 6 1 1 858 4 Experiment In this section, we conduct experiments on Chinese to English translation task to test our proposed methods of parser re-training and word alignment symmetrization. The evaluation method is the case insensitive IBM BLEU-4 (Papineni et al., 2002). Significant testing is carried out using bootstrap resampling method proposed by Koehn (2004) with a 95% confidence level. 4.1 Parser and SMT Decoder The syntactic parser we used in this paper is Berkley parser, with the grammar trained on WSJ corpus, and the training method follows Petrov and Klein (2007). Our SMT decoder is an in-house implementation of string-to-tree decoder. The features we used are standard used features, such as translation probabilities, lexical weights, language model probabilities and distortion probability. The feature weights are tuned using the minimum error rate training (MERT) (Och, 2003). 4.2 Experiment Data Setting and Baselines We test our method with two data settings: one is IWSLT data set, the other is NIST data set. dev8+dialog dev9 Baseline 50.58 49.85 Table 1. Baselines for IWSLT data set NIST&apos;03 NIST&apos;05 NIST&apos;08 Baseline 37.57 36.44 24.87 Table 2. Baselin</context>
<context position="20527" citStr="Petrov and Klein, 2007" startWordPosition="3560" endWordPosition="3563">ining data include the BTEC and SLDB training data. The training data contains 81k sentence pairs, 655k Chinese words and 806k English words. The language model is 5-gram language model trained with the English sentences in the training data. We use the combination of dev8 and dialog as development set, and dev9 as test set. The TL sentences of the training data with the selected/generated trees are used as the training data to re-train the parser. To get the baseline of this setting, we run IDG to combine the bidirection alignment generated by Giza++ (Och Ney, 2003), and run Berkeley parser (Petrov and Klein, 2007) to parse the target sentences. With the baseline alignments and syntactic trees, we extract rules and calculate features. The baseline results are shown in Table 1. For the NIST data set, the bilingual training data we used is NIST 2008 training set excluding the Hong Kong Law and Hong Kong Hansard. The training data contains 354k sentence pairs, 8M Chinese words and 10M English words, and is also the training data for our parser re-training. The language model is 5-gram language model trained with the Giga-Word corpus plus the English sentences in the training data. The development data to t</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of Human Language Technologies: The Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 404–411.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>