<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000425">
<title confidence="0.994459">
N-gram-based Tense Models for Statistical Machine Translation
</title>
<author confidence="0.998889">
Zhengxian Gong1 Min Zhang2 Chewlim Tan3 Guodong Zhou1*
</author>
<affiliation confidence="0.985399">
1 School of Computer Science and Technology, Soochow University, Suzhou, China 215006
2 Human Language Technology, Institute for Infocomm Research, Singapore 138632
3 School of Computing, National University of Singapore, Singapore 117417
</affiliation>
<email confidence="0.995619">
{zhxgong, gdzhou}@suda.edu.cn mzhang@i2r.a-star.edu.sg tancl@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.995596" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999595833333333">
Tense is a small element to a sentence, how-
ever, error tense can raise odd grammars and
result in misunderstanding. Recently, tense
has drawn attention in many natural language
processing applications. However, most of
current Statistical Machine Translation (SMT)
systems mainly depend on translation model
and language model. They never consider and
make full use of tense information. In this pa-
per, we propose n-gram-based tense models
for SMT and successfully integrate them in-
to a state-of-the-art phrase-based SMT system
via two additional features. Experimental re-
sults on the NIST Chinese-English translation
task show that our proposed tense models are
very effective, contributing performance im-
provement by 0.62 BLUE points over a strong
baseline.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998182">
For many NLP applications, such as event extraction
and summarization, tense has been regarded as a key
factor in providing temporal order. However, tense
information has been largely overlooked by current
SMT research. Consider the following example:
</bodyText>
<equation confidence="0.951578">
SRC: � � �;z,Tfl�Tx01Vkjl�EM&apos;f
, � � �� �� � �� ��REF:The embargo is a result of the Cold War and does not
</equation>
<bodyText confidence="0.971051378378379">
reflect the present situation nor the partnership between China
and the EU.
MOSES: the embargo is the result of the cold war, not reflect
the present situation, it did not reflect the partnership with the
european union.
*Corresponding author.
Although the translated text produced by Moses1
is understandable, it has very odd tense combination
from the grammatical aspect, i.e. with tense incon-
sistency (is/does in REF vs. is/did in Moses). Ob-
viously, slight modification, such as changing “is”
into “was”, can much improve the readability of the
translated text. It is also interesting to note that such
modification can much affect the evaluation. If we
change “did” to “does”, the BLEU-4 score increases
from 22.65 to 27.86 (as matching the 4-gram “does
not reflect the” in REF). However, if we change “is”
to “was”, the BLEU score decreases from 22.65 to
21.44.
The above example seems special. To testify its
impact on SMT in wider range, we design a special
experiment based on the 2005 NIST MT data (see
section 6.1). This data has 4 references. We choose
one reference and modify its sentences with error
tense2. After that, we use other 3 references to mea-
sure this reference. The modified reference leads to
a sharp drop in BLEU-4 score, from 52.46 to 50.27
in all. So it is not a random phenomenon that tense
can affect translation results.
The key is how to detect tense errors and choose
correct tenses during the translation procedure. By
carefully comparing the references with Moses out-
put, we obtain the following useful observations,
Observation(1): to most simple sentences, coor-
dinate verbs should be translated with the same tense
while they have different tense in Moses output;
Observation(2): to some compound sentences,
</bodyText>
<footnote confidence="0.992837666666667">
1http://www.statmt.org/moses/
2Such changes are small by mainly modifying one auxiliary
verb for a sentence, such as “is --+ was”, “has --+ had”.
</footnote>
<page confidence="0.935657">
276
</page>
<note confidence="0.878422">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 276–285, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999862742424243">
the subordinate clause should have the consisten-
t tense with its main clause while Moses fails;
Observation(3): the diversity of tense usage in a
document is common. However, in most cases, the
neighbored sentences tends to share the same main
tense. In some extreme examples, one tense (past or
present), even dominates the whole document.
One possible solution to model above observa-
tions is using rules. Dorr (2002) refers to six ba-
sic English tense structures and defines the possible
paired combinations of “present, past, future”. But
the practical cases are very complicated, especial-
ly in news domain. There are a lot of complicat-
ed sentences in news articles. Our preliminary in-
vestigation shows that such six paired combinations
can only cover limited real cases in Chinese-English
SMT.
This paper proposes a simple yet effective method
to model above observations. For each target sen-
tence in the training corpus, we first parse it and ex-
tract its tense sequence. Then, a target-side tense
n-gram model is constructed. Such model can be
used to estimate the rationality of tense combina-
tion in a sentence and thus supervise SMT to reduce
tense inconsistency errors against Observations (1)
and (2) in the sentence-level. In comparison, Ob-
servation (3) actually reflects the tense distributions
among one document. After extracting each main
tense for each sentence, we build another tense n-
gram model in the document-level. For clarity, this
paper denotes document-level tense as “inter-tense”
and sentence-level tense as “intra-tense”.
After that, we propose to integrate such tense
models into SMT systems in a dynamic way. It
is well known there are many errors in the current
MT output (David et al., 2006). Unlike previously
making trouble with reference texts, the BLEU-4 s-
core cannot be influenced obviously by modifying
a small part of abnormal sentences in a static way.
In our system, both inter-tense and intra-tense mod-
el are integrated into a SMT system via additional
features and thus can supervise the decoding proce-
dure. During decoding, once some words with cor-
rect tense can be determined, with the help of lan-
guage model and other related features, the smal-
l component–“tense”–can affect surrounding words
and improve the performance of the whole sentence.
Our experimental results (see the examples in Sec-
tion 6.4) show the effectiveness of this way.
Rather than the rule-based model, our models are
fully statistical-based. So they can be easily scaled
up and integrated into either phrase-based or syntax-
based SMT systems. In this paper, we employ a
strong phrase-based SMT baseline system, as pro-
posed in Gong et al. (2011), which uses document as
translation unit, for better incorporating document-
level information.
The rest of this paper is organized as follows: Sec-
tion 2 reviews the related work. Section 3 and 4 are
related to tense models. Section 3 describes the pre-
processing work for building tense models. Section
4 presents how to build target-side tense models and
discuss their characteristics. Section 5 shows our
way of integrating such tense models into a SMT
system. Session 6 gives the experimental results. Fi-
nally, we conclude this paper in Section 7.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999406">
In this section, we focus on related work on integrat-
ing the tense information into SMT. Since both inter-
and intra-tense models need to analyze and extract
tense information, we also give a brief overview on
tense prediction (or tagging).
</bodyText>
<subsectionHeader confidence="0.980147">
2.1 Tense Prediction
</subsectionHeader>
<bodyText confidence="0.99983155">
The tense prediction task often needs to build a mod-
el based on a large corpus annotated with temporal
relations and thus its focus is on how to recognize,
interpret and normalize time expressions. As a rep-
resentative, Lapata and Lascarides (2006) proposed
a simple yet effective data-intensive approach. In
particular, they trained models on main and subor-
dinate clauses connected with some special tempo-
ral marker words, such as “after” and “before”, and
employed them in temporal inference.
Another typical task is cross-lingual tense pred-
ication. Some languages, such as English, are in-
flectional, whose verbs can express tense via certain
stems or suffix, while others, such as Chinese of-
ten lack inflectional forms. Take Chinese to English
translation as example, if Chinese text contains par-
ticle word “_T(Le)”, the nearest Chinese verb prefers
to be translated into English verb with the past tense.
Ye and Zhang (2005), Ye et al. (2007) and Liu et al.
(2011) focus on labeling the tenses for keywords in
</bodyText>
<page confidence="0.992914">
277
</page>
<bodyText confidence="0.997502681818182">
source-side language.
Ye and Zhang (2005) first built a small amoun-
t of manually-labeled data, which provide the tense
mapping from Chinese text to English text. Then,
they trained a CRF-based tense classifier to label
tense on Chinese documents. Ye et al. (2007) fur-
ther reported that syntactic features contribute most
to the marking of aspectual information. Liu et al.
(2011) proposed a parallel mapping method to au-
tomatically generate annotated data. In particular,
they used English verbs to label tense information
for Chinese verbs via a parallel Chinese-English cor-
pus.
It is reasonable to label such source-side verb to
supervise the translation process since the tense of
English sentence is often determined by verbs. The
problem is that due to the diversity of English ver-
b inflection, it is difficult to map such Chinese tense
information into the English text. To our best knowl-
edge, although above works attempt to serve for
SMT, all of them fail to address how to integrate
them into a SMT system.
</bodyText>
<subsectionHeader confidence="0.990056">
2.2 Machine Translation with Tense
</subsectionHeader>
<bodyText confidence="0.9998899">
Dorr (1992) described a two-level knowledge repre-
sentation model based on Lexical Conceptual Struc-
tures (LCS) for machine translation which integrates
the aspectual information and the lexical-semantic
information. Her system is based on an inter-lingual
model and does not belong to a SMT system.
Olsen et al. (2001) relied on LCS to generate
appropriately-tensed English translations for Chi-
nese. In particular, they addressed tense reconstruc-
tion on a binary taxonomy (present and past) for
Chinese text and reported that incorporating lexical
aspect features of telicity can obtain a 20% to 35%
boost in accuracy on tense realization.
Ye et al. (2006) showed that incorporating latent
features into tense classifiers can boost the perfor-
mance. They reported the tense resolution results
based on the best-ranked translation text produced
by a SMT system. However, they did not report the
variation of translation performance after introduc-
ing tense information.
</bodyText>
<sectionHeader confidence="0.994864" genericHeader="method">
3 Preprocessing for Tense Modeling
</sectionHeader>
<bodyText confidence="0.999913266666667">
In this paper, tense modeling is done on the target-
side language. Since our experiments are done
on Chinese to English SMT, our tense models are
learned only from the English text. In the literature,
the taxonomy of English tenses typically includes
three basic tenses (i.e. present, past and future) plus
their combination with the progressive and perfec-
tive aspects. Here, we consider four basic tenses:
present, past, future and UNK (unknown) and ignore
the aspectual information. Furthermore, we assume
that one sentence has only one main tense but maybe
has many subordinate tenses.
This section describes the preprocessing work of
building tense models, which mainly involves how
to extract tense sequence via tense verbs.
</bodyText>
<subsectionHeader confidence="0.997485">
3.1 Tense Verbs
</subsectionHeader>
<bodyText confidence="0.981701">
Lapata et al.(2006) used syntactic parse trees to find
clauses connected with special aspect markers and
collected them to train some special classifiers for
temporal inference. Inspired by their work, we use
the Stanford parser3 to parse tense sequence for each
sentence.
Take the following three typical sentences as ex-
amples, (a) is a simple sentence which contains two
coordinate verbs, while (b) and (c) are compound
sentences and (b) contains a quoted text.
</bodyText>
<listItem confidence="0.996608">
(a) Japan’s constitution renounces the right to go to war and
prohibits the nation from having military forces except for self-
defense.
(b) “We also hope Hong Kong will not be affected by diseases
like the severe acute respiratory syndrome again!” , added Ms.
Yang.
(c) Cheng said he felt at home in Hong Kong and he sincerely
wished Hong Kong more peaceful and more prosperous.
</listItem>
<bodyText confidence="0.9992336">
Figure 1 shows the parse tree with Penn Treebank
style for each sentence, which has strict level struc-
tures and POS tags for all the terminal words. Here,
the level structures mainly contribute to extract main
tense for each sentence (to be described in Section
3.2) and POS tags are utilized to detect tense verbs,
i.e. verbs with tense information.
Normally, POS tags in the parse tree can distin-
guish five different forms of verbs: the base form
(tagged as VB), and forms with overt endings D for
</bodyText>
<footnote confidence="0.92753">
3http://nlp.stanford.edu/software/lex-parser.shtml
</footnote>
<page confidence="0.989918">
278
</page>
<figureCaption confidence="0.999947">
Figure 1: The Stanford parse trees with Penn Treebank style
</figureCaption>
<bodyText confidence="0.932356266666667">
past tense, G for present participle, N for past par-
ticiple, and Z for third person singular present. It is
worth noting that VB, VBG and VBN cannot deter-
mine the specific tenses by themselves. In addition,
the verbs with POS tag “MD” need to be special-
ly considered to distinguish future tense from other
tenses.
Algorithm 1 illustrates how to determine what
tense a node has. If the return value is not “UNK”,
the node belongs to a tense verb.
Algorithm 1 Determine the tense of a node.
Input:
The TreeNode of one parse tree, leafnode;
Output:
The tense, tense;
</bodyText>
<listItem confidence="0.962494705882353">
1: tense = “UNK&amp;quot;
2: Obtaining the POS tag lpostag from leafnode;
3: Obtaining the word lword from leafnode;
4: if (lpostag in [“V BP&amp;quot;, “V BZ&amp;quot;]) then
5: tense = “present&amp;quot;
6: else if (lpostag == “V BD&amp;quot;]) then
7: tense = “past&amp;quot;
8: else if (lpostag == “MD&amp;quot;]) then
9: if (lword in [“will&amp;quot;, “ll&amp;quot;, “shall&amp;quot;]) then
10: tense = “future&amp;quot;
11: else if (lword in [“would&amp;quot;, “could&amp;quot;]) then
12: tense = “past&amp;quot;
13: else
14: tense = “present&amp;quot;
15: end if
16: end if
17: return tense;
</listItem>
<subsectionHeader confidence="0.997828">
3.2 Tense Extraction Based on Tense Verbs
</subsectionHeader>
<bodyText confidence="0.999721166666667">
As described in Section 1, the inter-tense
(document-level) refers to the main tense of
one sentence and the intra-tense (sentence-level)
corresponds to all tense sequence of one sentence.
This section introduces how to recognize the main
tense and extract all useful tense sequence for each
sentence.
The idea of determining the main tense is to find
the tense verb located in the top level of a parse tree.
According to the Penn Treebank style, the method
to determine the main tense can be described as fol-
lows:
</bodyText>
<listItem confidence="0.9861876">
(1) Traverse the parse tree top-down until a tree node
containing more than one child is identified, denot-
ed as S,,,, .
(2) Consider each child of S,,,, with tag “VP”, recursive-
ly traverse such “VP” node to find a tense verb. If
found, use it as the main tense and return the tense;
if not, go to step (3).
(3) Consider each child of S,,,, with tag “S”, which ac-
tually corresponds to subordinate clause of this sen-
tence. Starting from the first subordinate clause, ap-
ply the similar policy of step (2) to find the tense
verb. If not found, search remaining subordinate
clauses.
(4) If no tense verb found, return “UNK” as the main
tense.
</listItem>
<bodyText confidence="0.99955125">
Here, “VP” nodes dominated by Sm directly are
preferred over those located in subordinate clauses.
This is to ensure that the main tense is decided by
the top-level tense verb.
</bodyText>
<page confidence="0.990651">
279
</page>
<bodyText confidence="0.999892416666667">
Take Figure 1 as an example, the main tense of
sentence (a) and (b) can be determined only by step
(2). The tense verb of “(VBZ renounces)” dominat-
ed in the “VP” tag determines that (a) is in present
tense. Similarly the node “(VBD added)” indicates
that (b) is in past tense. Sentence (c) needs to be fur-
ther treated by step (3) since there is no “VP” nodes
dominated by 5m directly. The node “(VBD said)”
located in the first subordinate clause shows its main
tense is “past”.
The next task is to extract the tense sequence for
each sentence. They are determined by all tense
verbs in this sentence according to the strict top-
down order. For example, the tense sequence of
sentence (a), (b) and (c) are {present, present},
{present, future, past} and {past, past, past}. In or-
der to explore whether the main tense of intra-tense
model has an impact on SMT or not, we introduce
a special marker “*” to denote the main tense. So
the tense sequence marked with main tense of (a),
(b) and (c) are {present*, present},{present, future,
past*} and {past*, past, past}. It is worth noting, the
intra-tense model (see Section 4) based on the latter
tense sequence is different to the former.
</bodyText>
<sectionHeader confidence="0.986288" genericHeader="method">
4 N-gram-based Tense Models
</sectionHeader>
<subsectionHeader confidence="0.987662">
4.1 Tense N-gram Estimation
</subsectionHeader>
<bodyText confidence="0.99998025">
After applying the previous method to extract tense
for an English text corpus, we can obtain a big tense
corpus.
Given the current tense is indexed as ti, we call
the previous n − 1 tenses plus the current tense as
tense n-gram.
Based on the tense corpus, tense n-gram statistics
can be done according to the Formula 1.
</bodyText>
<equation confidence="0.999159666666667">
P(ti|t(i−(n−1)), ..., t(i−1)) =
count(t(i−(n−1)), . . . , t(i−1), ti) (1)
count(t(i−(n−1)), ..., t(i−1))
</equation>
<bodyText confidence="0.999954941176471">
Here, the function of “count” return the tense n-gram
frequency. In order to avoid doing specific smooth-
ing work, we estimate tense n-gram probability us-
ing SRI language modeling (SRILM) tool (Stolcke,
2002).
To compute the probability of intra-tense n-gram,
we first extract all tense sequence for each sentence
and put them into a new file. Based on this new file,
we can get the intra-tense n-gram model via SRILM
tool.
To compute the probability of inter-tense n-gram,
we need to extract the main tense for each sentence
at first. Then, for each document, we re-organized
the main tenses of all sentences into a special line.
After putting all these special lines into a new file,
we can use SRILM to obtain the inter-tense n-gram
model.
</bodyText>
<subsectionHeader confidence="0.998767">
4.2 Characteristic of Tense N-gram Models
</subsectionHeader>
<bodyText confidence="0.99922115625">
We construct n-gram-based tense models on English
Gigaword corpus (LDC2003T05). This corpus is
used to build language model for most SMT sys-
tems. It includes 30221 documents (we remove such
files: file size is less than 1K or the number of con-
tinuous “UNK” tenses is greater than 5).
Figure 2 shows the unigram and bigram probabil-
ities (Log10-style) for intra-tense and inter-tense.
The part (a) and (c) in Figure 2 refer to unigram.
The horizontal axis indicts tense type, and the ver-
tical axis shows its probabilities. The parts (a) and
(c) also indicate “present” and “past” are two main
tense types in news domain.
The part (b) and (d) refer to bigram. The horizon-
tal axis indicts history tense. Each different color-
ful bar indicts one current tense. The vertical axis
shows the transfer possibilities from a history tense
to a current tense.
The part (b)4 reflects transfer possibilities of tense
types in one sentence. It also slightly reflects some
linguistic information. For example, in one sen-
tence, the probability of co-occurrence of “present
—* present”, “past —* past” and “future —* present”
is more than other combinations, which can be a-
gainst tense inconsistency errors described in Obser-
vation (1) and (2) (see Section 1). However, it seem-
s strange that “present —* past” exceeds “present —*
future”. We checked our corpus and found a lot of
sentences like this–“the bill has been ..., he said. ”.
The part (d) shows tense type can be switched be-
tween two neighbored sentences. However, it shows
the strong tendency to use the same tense type for
</bodyText>
<footnote confidence="0.994307666666667">
4The co-occurrence of the “UNK” tense and other tense
types in one sentence cannot happen, so the “UNK” tense is
omitted.
</footnote>
<page confidence="0.987897">
280
</page>
<figureCaption confidence="0.999903">
Figure 2: statistics of intra-tense and inter-tense N-gram
</figureCaption>
<bodyText confidence="0.8118995">
neighbored sentences. This statistics conform to the
previous observation (3) very much.
</bodyText>
<sectionHeader confidence="0.983593" genericHeader="method">
5 Integrating N-gram-based Tense Models
into SMT
</sectionHeader>
<bodyText confidence="0.9998545">
In this section, we discuss how to integrate the pre-
vious tense models into a SMT system.
</bodyText>
<subsectionHeader confidence="0.993031">
5.1 Basic phrase-based SMT system
</subsectionHeader>
<bodyText confidence="0.999681">
It is well known that the translation process of SMT
can be modeled as obtaining the best translation e
of the source sentence f by maximizing following
posterior probability(Brown et al., 1993):
</bodyText>
<equation confidence="0.99429825">
ebest = arg max P(e|f)
= arg max
e P(f|e)Plm(e) (2)
e
</equation>
<bodyText confidence="0.99990825">
where P(e|f) is a translation model and Plm is a
language model.
Our baseline is a modified Moses, which follows
Koehn et al. (2003) and adopts similar six groups
of features. Besides, the log-linear model ( Och and
Ney, 2000) is employed to linearly interpolate these
features for obtaining the best translation according
to the formula 3:
</bodyText>
<equation confidence="0.999366333333333">
M
ebest = arg max λmhm(e,f) (3)
e m=1
</equation>
<bodyText confidence="0.999937">
where hm(e, f) is a feature function, and λm is
the weight of hm(e, f) optimized by a discrimina-
tive training method on a held-out development da-
ta(Och, 2003).
</bodyText>
<subsectionHeader confidence="0.998108">
5.2 The Workflow of Our System
</subsectionHeader>
<bodyText confidence="0.999924409090909">
Our system works as follows:
When a hypothesis has covered all source-side
words during the decoding procedure, the decoder
first obtains tense sequence for such hypothesis and
computes intra-tense feature Fs(see Section 5.3). At
the same time, it recognizes the main tense of this
hypothesis and associate the main tense of previous
sentence to compute inter-tense feature Fm (see Sec-
tion 5.3).
Next, the decoder uses such two additional feature
values to re-score this hypothesis automatically and
choose one hypothesis with highest score as the final
translation.
After translating one sentence, the decoder caches
its main tense and pass it to the next sentence.
When one document has been processed, the de-
coder cleans this cache.
In order to successfully implement above work-
flow, we should firstly design some related features,
then resolve another key problem of determining
tense (especially main tense) for SMT output. They
are described in Section 5.3 and 5.4 respectively.
</bodyText>
<subsectionHeader confidence="0.993185">
5.3 Two Additional Features
</subsectionHeader>
<bodyText confidence="0.999952">
Although the previous tense models show strong
tendency to use the consistent tenses for one sen-
tence or one document, other tense combinations al-
so can be permitted. So we should use such models
in a soft and dynamic way. We design two features:
inter-tense feature and intra-tense feature. And the
weight of each feature is tuned by the MERT script
in Moses packages.
Given main tense sequence of one documen-
t t1, ... , tm, the inter-tense feature Fm is calculated
according to the following formula:
</bodyText>
<equation confidence="0.817757857142857">
P(ti|ti−(n−1), ... , t(i−1)) (4)
The P(·) of formula 4 can be estimated by the for-
mula 1. It is worth noting the first sentence of one
m
ri
i=2
Fm =
</equation>
<page confidence="0.978849">
281
</page>
<bodyText confidence="0.999318666666667">
document often scares tense information since it cor-
responds to the title at most cases. To the first sen-
tence, the P(·) value is set to 41 (4 tense types).
Given tense sequence of one sentence
s1, ... , se (e &gt; 1), the intra-tense feature F3
is calculated as follows:
</bodyText>
<equation confidence="0.9924124">
P(si|si−(n−1), ... , s(i−1)) (5)
� F3= e−1
e
ri
i=2
</equation>
<bodyText confidence="0.999847142857143">
Here the square-root operator is used to avoid pun-
ishing translations with long tense sequence. It is
worth noting if the sentence only contains one tense,
the P(·) value of formula 5 is also set to 1�.
Since the average length of intra-tense sequence
is about 2.5, we mainly consider intra-tense bigram
model and thus n equals to 2. 5
</bodyText>
<subsectionHeader confidence="0.993567">
5.4 Determining Tense For SMT Output
</subsectionHeader>
<bodyText confidence="0.999078423076923">
The current SMT systems often produce odd transla-
tions partly because of abnormal word ordering and
uncompleted text etc. For these abnormal translated
texts, the syntactic parser cannot work well in our
initial experiments, so the previous method to parse
main tense and tense sequence of regular texts can-
not be applied here too.
Fortunately, the solely utilization of Stanford POS
tagger for our SMT output is not bad although it has
the same issues described in Och et al. (2002). The
reason may be that phrase-based SMT contains short
contexts that POS tagger can utilize while the syntax
parser fails.
Once obtaining a completed hypothesis, the de-
coder will pass it to the Stanford POS tagger and ac-
cording to tense verbs to get all tense sequence for
this hypothesis. However, since the POS tagger can
not return the information about level structures, the
decoder cannot recognize the main tense from such
tense sequence.
Liu et al. (2011) once used target-side verbs to la-
bel tense of source-side verbs. It is natural to consid-
er whether Chinese verbs can provide similar clues
in an opposite direction.
Since Chinese verbs have good correlation with
English verbs (described in section 6.2), we obtain
</bodyText>
<footnote confidence="0.957116">
5In our experiment, the intra-tense bigram model can ob-
tain the comparable performance to the trigram model. And the
inter-tense trigram model can not exceed the bigram one.
</footnote>
<figureCaption confidence="0.99842">
Figure 3: trees for parallel sentences
</figureCaption>
<bodyText confidence="0.999969923076923">
main tense for SMT output according to such tense
verb, which corresponds to the “VV”(Chinese POS
labels are different to English ones, “VV” refers to
Chinese verb) node in the top level of the source-side
parse tree. Take Figure 3 as an example, the English
node “(VBD announced)” is a tense verb which can
tell the main tense for this English sentence. The
Chinese verb “(VV� in the top-level of the
Chinese parse tree is just the corresponding part for
this English verb.
So, before translating one sentence, the decoder
first parses it and records the location of one Chinese
“VV” node which located in the top-level, denotes
this location as 5area.
Once a completed hypothesis is generated, ac-
cording to the phrase alignment information, the de-
coder can map 5area into the English location Tarea
and obtain the main tense according to the POS tags
in Tarea .
If Tarea does not contain tense verb, such as the
verb POS tags in the list of {VB, VBN, VBG},
which cannot tell tense type by themselves, our sys-
tem permits to find main tense in the left/right 3
words neighbored to Tarea. And the proportion that
the top-level verb of Chinese has a verb correspon-
dence in English can reach to 83% in this way.
</bodyText>
<sectionHeader confidence="0.999544" genericHeader="method">
6 Experimentation
</sectionHeader>
<subsectionHeader confidence="0.999686">
6.1 Experimental Setting for SMT
</subsectionHeader>
<bodyText confidence="0.999774333333333">
In our experiment, SRI language modeling toolk-
it was used to train a 5-Gram general language
model on the Xinhua portion of the Gigaword cor-
pus. Word alignment was performed on the train-
ing parallel corpus using GIZA++ ( Och and Ney,
2000) in two directions. For evaluation, the NIST
</bodyText>
<page confidence="0.991502">
282
</page>
<bodyText confidence="0.999354222222222">
BLEU script (version 13) with the default setting is
used to calculate the BLEU score (Papineni et al.,
2002), which measures case-insensitive matching of
4-grams. To see whether an improvement is statisti-
cally significant, we also conduct significance tests
using the paired bootstrap approach (Koehn, 2004).
In this paper, “***” and “**” denote p-values equal
to 0.05, and bigger than 0.05, which mean signifi-
cantly better, moderately better respectively.
</bodyText>
<table confidence="0.9984584">
Corpus Sentences Documents
Role Name
Train FBIS 228455 10000
Dev NIST2003 919 100
Test NIST2005 1082 100
</table>
<tableCaption confidence="0.99991">
Table 1: Corpus statistics
</tableCaption>
<bodyText confidence="0.9996348">
We use FBIS as the training data, the 2003 NIST
MT evaluation test data as the development data, and
the 2005 NIST MT test data as the test data. Table 1
shows the statistics of these data sets (with document
boundaries annotated).
</bodyText>
<subsectionHeader confidence="0.998529">
6.2 The Correlation of Chinese Verbs and
English Verbs
</subsectionHeader>
<bodyText confidence="0.9997">
In this section, an additional experiment is designed
to show English Verbs have close correspondence
with Chinese Verbs.
We use the Stanford POS tagger to tag the Chi-
nese and English sentences in our training corpus
respectively at first. Then we utilize Giza++ to build
alignment for these special Word-POS pairs. Ac-
cording to the alignment results, we find the corre-
sponding relation for some special POS tags in two
languages.
</bodyText>
<table confidence="0.998649090909091">
Chinese Verb POS English POS Number
VV Verb VBD 89830
POS VBP 27276
VBZ 32588
MD 40378
VBG 86025
VBN 75019
VB 153596
In sum: 504712
Other Non-Verb 149318
Verb Corresponding Ratio 0.77169
</table>
<tableCaption confidence="0.999721">
Table 2: The Chinese and English Verb Pos Alignment
</tableCaption>
<bodyText confidence="0.997899714285714">
The “Number” column of Table 2 shows the num-
bers of Chinese words with “VV” tag correspond-
ing to English words with different verb POS tags.
We found Chinese verbs have more than 77% possi-
bilities to align to English verbs in total. However,
our method will fail when some special Chinese sen-
tences only contain noun predicates.
</bodyText>
<subsectionHeader confidence="0.998993">
6.3 Experimental Results
</subsectionHeader>
<bodyText confidence="0.998550285714286">
All the experiment results are showed on the table 3.
Our Baseline is a modified Moses. The major modi-
fication is input and output module in order to trans-
late using document as unit. The performance of our
baseline exceeds the baseline reported by Gong et al.
(2011) about 2 percent based on the similar training
and test corpus.
</bodyText>
<table confidence="0.999041888888889">
System BLEU BLEU on Test(%)
Dev(%)
BLEU NIST
Moses Md(Baseline) 29.21 28.30 8.4528
Baseline+F. 30.56 28.87(***) 8.7935
Baseline+F3 31.28 28.61(**) 8.5645
Baseline+F3(*) 31.04 28.74(**) 8.6271
Baseline+F.+F3 31.75 28.88(***) 8.7987
Baseline+F.+F3(*) 31.42 28.92(***) 8.8201
</table>
<tableCaption confidence="0.9833265">
Table 3: The performance of using different feature com-
binations
</tableCaption>
<bodyText confidence="0.999863166666667">
The system denoted as “Baseline+F,,t” integrates
the inter-tense feature. The performance boosts
0.57(***) in BLEU score.
The system denoted as “Baseline+F3” integrates
the intra-tense feature into the baseline. The im-
provement is less than the inter-tense model, on-
ly 0.31(**). It seems the tenses in one sentence
has more flexible formats than the document-level
ones. It is worth noting, this method can gain high-
er performance on the develop data than the one of
“Baseline+F,,t” while fail to improve the test data.
Maybe the related weight is tuned over-fit.
The system denoted as “Baseline+F3(*)” is s-
lightly different from “Baseline+F3”. This experi-
ment is to check whether the main tense has an im-
pact on intra-tense model or not (see Section 3.2).
Here, the intra-tense model based on the tense se-
quence with main tense marker is slightly different
to the model showed in Figure 2. The results are
slightly better than the previous system by 0.13.
Finally, we use the two features together
(Baseline+F,,t+F3). The best way improved the
performance by 0.62(***) in BLEU score over our
baseline.
</bodyText>
<page confidence="0.994533">
283
</page>
<subsectionHeader confidence="0.654926">
6.4 Discussion
</subsectionHeader>
<bodyText confidence="0.982315111111111">
Table 4 shows special examples whose intra-tenses
are changed in our proposed system. The exam-
ple 1 and 2 show such modification can improve
the BLEU score but the example 3 obtains negative
impact. From these examples, we can see not only
tense verbs have changed but also their surrounding
words have subtle variation.
No. BLEU Translation sentence
1 8.64 Baseline: the gulf countries, the bahraini royal fam-
ily members by the military career of part of the
banned to their marriage stories like children , have
become the theme of television films .
19.71 Ours: the gulf country is a member of the bahraini
royal family , a risk by military career risks part of
the banned to their marriage like children , has be-
come a story of the television and film industry .
2 17.16 Baseline:economists said that the sharp appreciation
of the euro , in the recent investigation continues to
have an impact on economic confidence, it is esti-
mated that the economy is expected to rebound to
pick up .
24.25 Ours: economists said that the sharp appreciation of
the euro , in the recent investigation continued to
have an impact on economic confidence and there-
fore no reason to predict the economy expected to
pick up a rebound.
3 73.03 Baseline: the middle east news agency said that, af-
ter the concerns of all parties concerned in the mid-
dle east peace process , israel and palestine , egypt ,
the united states , russia and several european coun-
tries will hold a meeting in washington .
72.95 Ours: the middle east news agency said that after the
concerns of all parties in the middle east peace pro-
cess , israel and palestine , egypt , the united states ,
russia and several european countries held a meeting
in washington .
</bodyText>
<tableCaption confidence="0.948122">
Table 4: Examples with tense variation using intra-tense
model
</tableCaption>
<bodyText confidence="0.9999789375">
From the results showed on Table 3, the
document-level tense model seems more effective
than the sentence-level one. We manually choose
and analyzed 5 documents with significant improve-
ment in the test data. The part (a) of Figure 4 shows
the main tense distributions of one reference. The
main tense distributions for the baseline and our pro-
posed system are showed in the part (b) and (c) re-
spectively. These documents have different numbers
of sentences but all less than 10. The vertical axis in-
dicates different tense: 1 to “past”, 2 to “present”, 3
to “future” and 4 to “UNK”. It is obvious that our
system has closer distributions to the ones of this
reference.
The examples in Table 5 indicate the joint impact
of inter-tense and intra-tense model on SMT. Sen-
</bodyText>
<figure confidence="0.645376428571429">
Src:
1)U11-6M lkK NJ ifa — * _tM igA , #niX lk2C )t ift&amp;
A 91&amp;
2)E i,rJ_fl#ht 81.`x:*#Rp1E,ritU t i_K7a]7 AN
MA WMR , A A it­t aq 5 U11_6M nM- -&apos;&amp;*VF Lei
JVTtE SM 94 Affi Oft W91 b�A
Ref:
</figure>
<tableCaption confidence="0.898015833333333">
1)Israeli settlers blockaded a major road to protest a mortar attack
on the settlement area.
2)PLO leader Abbas had also been allowed to go to the West Bank
town of Bethlehem, which is the first time in the past four years
Israeli authorities have allowed a senior Palestinian leader to attend
Christmas celebrations.
</tableCaption>
<subsectionHeader confidence="0.400556">
Baseline:
</subsectionHeader>
<bodyText confidence="0.945351545454546">
1)israel has imposed a main road to protest by mortars attack.
2)the palestinian leader also visited the west bank cities and towns
to bethlehem , which in the past four years , the israeli authorities
allowed the palestinian leading figures attended the ceremony.
Ours:
1)israel has imposed a main road to protest against the mortars at-
tack .
2)leader of the palestinian liberation organization have also been
allowed to go to the west bank towns , bethlehem in the past four
years . this is the first time the israeli authorities allow palestinian
leading figures attended the ceremony.
</bodyText>
<tableCaption confidence="0.972228">
Table 5: the joint impact of inter- tense and intra-tense
models on SMT
</tableCaption>
<bodyText confidence="0.9997109">
tence 1) and 2) are two neighbored sentences in one
document. Both the reference and our output tend
to use the same main tense type, but the former is in
“past” tense and the latter is in “present” tense. The
baseline cannot show such tendency. Although our
main tense is different to the reference one, the con-
sistent tenses in document level bring better trans-
lation results than the baseline. And the tenses in
sentence level also show better consistency than the
baseline.
</bodyText>
<sectionHeader confidence="0.99887" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999987285714286">
This paper explores document-level SMT from the
tense perspective. In particular, we focus on how to
build document-level and sentence-level tense mod-
els and how to integrate such models into a popular
SMT system.
Compared with the inter-tense model which great-
ly improves the performance of SMT, the intra-tense
model needs to be further explored. The reasons are
many folds, e.g. the failure to exclude quoted texts
when modeling intra-tense, since tenses in quoted
texts behave much diversely from normal texts. In
the future work, we will focus on modeling intra-
tense variation according to specific sentence types
and using more features to improve it.
</bodyText>
<page confidence="0.997621">
284
</page>
<figureCaption confidence="0.999159">
Figure 4: the comparison of the inter-tense distributions for reference, baseline and our proposed system
</figureCaption>
<sectionHeader confidence="0.997226" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.893220666666667">
This research is supported by part by NUS FRC
Grant R252-000-452-112, the National Natural Sci-
ence Foundation of China under grant No.90920004
and 61003155, the National High Technology Re-
search and Development Program of China (863
Program) under grant No.2012AA011102.
</bodyText>
<sectionHeader confidence="0.990085" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999958242857143">
P.F. Brown, S.A. Della Pietra, V.J. Della Pietra and R.L.
Mercer. 1992. The Mathematics of Statistical Ma-
chine Translation: Parameter Estimation. Computa-
tional Linguistics, 19(2):263-311.
Vilar David, Jia Xu, D `Haro L. F., and Hermann Ney.
2006. Error Analysis of Machine Translation Output.
In Proceedings of the 5th International Conference on
Language Resources and Evaluation, pages 697-702,
Genoa, Italy.
Bonnie J. Dorr. 1992. A parameterized approach to
integrating aspect with lexical-semantics for machine
translation. In Proceedings of of ACL-2002, pages
257-264.
Bonnie J. Dorr and Terry Gaasterland. 2002. Constraints
on the Generation of Tense, Aspect, and Connecting
Words from Temporal Expressions. Technical Reports
from UMIACS.
Zhengxian Gong, Min Zhang and Guodong Zhou.
2011. Cached-based Document-level Statistical Ma-
chine Translation. In Proceedings of the 2011 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 909-919.
Philipp Koehn, Franz Josef Och ,and DanielMarcu. 2003.
Statistical Phrase-Based Translation. In Proceedings
of NAACL-2003, pages 48-54.
Philipp Koehn. 2004. Statistical Significance Tests for
Machine Translation Evaluation. In Proceedings of
the 2004 Conference on Empirical Methods in Natu-
ral Language Processing, pages 388-395.
Mirella Lapata, Alex Lascarides. 2006. Learning
Sentence-internal Temporal Relations. Journal of Ar-
tificial Intelligence Research, 27:85-117.
Feifan Liu, Fei Liu and Yang Liu. 2011. Learning from
Chinese-English Parallel Data for Chinese Tense Pre-
diction. In Proceedings of IJCNLP-2011, pages 1116-
1124,Chiang Mai, Thailand.
Franz Josef Och and Hermann Ney. 2000. Improved Sta-
tistical Alignment Models. In Proceedings of of ACL-
2000, pages 440-447.
Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur,
et.al. 2002. A smorgasbord of Features for Statistical
Machine Translation. In Proceedings of NAACL-2004,
pages 440-447.
Franz Josef Och. 2003. Minimum Error Rate Training
in Statistical Machine Translation. In Proceedings of
ACL-2003,pages 160-167, Sapporo, Japan,July.
Mari Olsen, David Traum,Carol Van Ess-Dykema and
Amy Weinberg. 2001. Implicit Cues for Explicit Gen-
eration: Using Telicity as a Cue for Tense Structure in
a Chinese to English MT System. In Proceedings of
MT Summit VIII, Santiago de Compostella, Spain.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
jing Zhu. 2002. BLEU: A Method for Automatic E-
valuation of Machine Translation. In Proceedings of
ACL-2002, pages 311-318.
Andreas Stolcke. 2002. SRILM-an extensible language
modeling toolkit. In Proceedings of the Internation-
al Conference on Spoken Language Processing,pages
901-904.
Yang Ye and Zhu Zhang. 2005. Tense tagging for verbs
in cross-lingual context: A case study. In Proceedings
of IJCNLP-2005, pages 885-895.
Yang Ye, V.li Fossum, Steven Abney. 2006. Laten-
t features in Temporal Reference Translation. Fifth
SIGHAN Workshop on Chinese Language Processing,
pages 48-55.
Yang Ye, Karl-Michael Schnelder, Steven Abney. 2007.
Aspect Marker Generation in English-to-Chinese Ma-
chine Translation. Proceedings of MT Summit XI,
pages 521-527,Copenhagen, Denmark.
</reference>
<page confidence="0.998526">
285
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.116447">
<title confidence="0.954269">N-gram-based Tense Models for Statistical Machine Translation</title>
<affiliation confidence="0.4158525">of Computer Science and Technology, Soochow University, Suzhou, China Language Technology, Institute for Infocomm Research, Singapore</affiliation>
<address confidence="0.412849">of Computing, National University of Singapore, Singapore</address>
<email confidence="0.786984">mzhang@i2r.a-star.edu.sgtancl@comp.nus.edu.sg</email>
<abstract confidence="0.997034157894737">Tense is a small element to a sentence, however, error tense can raise odd grammars and result in misunderstanding. Recently, tense has drawn attention in many natural language processing applications. However, most of current Statistical Machine Translation (SMT) systems mainly depend on translation model and language model. They never consider and make full use of tense information. In this paper, we propose n-gram-based tense models for SMT and successfully integrate them into a state-of-the-art phrase-based SMT system via two additional features. Experimental results on the NIST Chinese-English translation task show that our proposed tense models are very effective, contributing performance improvement by 0.62 BLUE points over a strong baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>R L Mercer</author>
</authors>
<date>1992</date>
<booktitle>The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics,</booktitle>
<pages>19--2</pages>
<marker>Brown, Pietra, Pietra, Mercer, 1992</marker>
<rawString>P.F. Brown, S.A. Della Pietra, V.J. Della Pietra and R.L. Mercer. 1992. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19(2):263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vilar David</author>
<author>Jia Xu</author>
<author>D `Haro L F</author>
<author>Hermann Ney</author>
</authors>
<title>Error Analysis of Machine Translation Output.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation,</booktitle>
<pages>697--702</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="5432" citStr="David et al., 2006" startWordPosition="844" endWordPosition="847">in a sentence and thus supervise SMT to reduce tense inconsistency errors against Observations (1) and (2) in the sentence-level. In comparison, Observation (3) actually reflects the tense distributions among one document. After extracting each main tense for each sentence, we build another tense ngram model in the document-level. For clarity, this paper denotes document-level tense as “inter-tense” and sentence-level tense as “intra-tense”. After that, we propose to integrate such tense models into SMT systems in a dynamic way. It is well known there are many errors in the current MT output (David et al., 2006). Unlike previously making trouble with reference texts, the BLEU-4 score cannot be influenced obviously by modifying a small part of abnormal sentences in a static way. In our system, both inter-tense and intra-tense model are integrated into a SMT system via additional features and thus can supervise the decoding procedure. During decoding, once some words with correct tense can be determined, with the help of language model and other related features, the small component–“tense”–can affect surrounding words and improve the performance of the whole sentence. Our experimental results (see the</context>
</contexts>
<marker>David, Xu, F, Ney, 2006</marker>
<rawString>Vilar David, Jia Xu, D `Haro L. F., and Hermann Ney. 2006. Error Analysis of Machine Translation Output. In Proceedings of the 5th International Conference on Language Resources and Evaluation, pages 697-702, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
</authors>
<title>A parameterized approach to integrating aspect with lexical-semantics for machine translation.</title>
<date>1992</date>
<booktitle>In Proceedings of of ACL-2002,</booktitle>
<pages>257--264</pages>
<contexts>
<context position="9273" citStr="Dorr (1992)" startWordPosition="1477" endWordPosition="1478">data. In particular, they used English verbs to label tense information for Chinese verbs via a parallel Chinese-English corpus. It is reasonable to label such source-side verb to supervise the translation process since the tense of English sentence is often determined by verbs. The problem is that due to the diversity of English verb inflection, it is difficult to map such Chinese tense information into the English text. To our best knowledge, although above works attempt to serve for SMT, all of them fail to address how to integrate them into a SMT system. 2.2 Machine Translation with Tense Dorr (1992) described a two-level knowledge representation model based on Lexical Conceptual Structures (LCS) for machine translation which integrates the aspectual information and the lexical-semantic information. Her system is based on an inter-lingual model and does not belong to a SMT system. Olsen et al. (2001) relied on LCS to generate appropriately-tensed English translations for Chinese. In particular, they addressed tense reconstruction on a binary taxonomy (present and past) for Chinese text and reported that incorporating lexical aspect features of telicity can obtain a 20% to 35% boost in acc</context>
</contexts>
<marker>Dorr, 1992</marker>
<rawString>Bonnie J. Dorr. 1992. A parameterized approach to integrating aspect with lexical-semantics for machine translation. In Proceedings of of ACL-2002, pages 257-264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Terry Gaasterland</author>
</authors>
<title>Constraints on the Generation of Tense, Aspect, and Connecting Words from Temporal Expressions. Technical Reports from UMIACS.</title>
<date>2002</date>
<marker>Dorr, Gaasterland, 2002</marker>
<rawString>Bonnie J. Dorr and Terry Gaasterland. 2002. Constraints on the Generation of Tense, Aspect, and Connecting Words from Temporal Expressions. Technical Reports from UMIACS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhengxian Gong</author>
<author>Min Zhang</author>
<author>Guodong Zhou</author>
</authors>
<title>Cached-based Document-level Statistical Machine Translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>909--919</pages>
<contexts>
<context position="6369" citStr="Gong et al. (2011)" startWordPosition="997" endWordPosition="1000">ocedure. During decoding, once some words with correct tense can be determined, with the help of language model and other related features, the small component–“tense”–can affect surrounding words and improve the performance of the whole sentence. Our experimental results (see the examples in Section 6.4) show the effectiveness of this way. Rather than the rule-based model, our models are fully statistical-based. So they can be easily scaled up and integrated into either phrase-based or syntaxbased SMT systems. In this paper, we employ a strong phrase-based SMT baseline system, as proposed in Gong et al. (2011), which uses document as translation unit, for better incorporating documentlevel information. The rest of this paper is organized as follows: Section 2 reviews the related work. Section 3 and 4 are related to tense models. Section 3 describes the preprocessing work for building tense models. Section 4 presents how to build target-side tense models and discuss their characteristics. Section 5 shows our way of integrating such tense models into a SMT system. Session 6 gives the experimental results. Finally, we conclude this paper in Section 7. 2 Related Work In this section, we focus on relate</context>
<context position="27658" citStr="Gong et al. (2011)" startWordPosition="4603" endWordPosition="4606"> “Number” column of Table 2 shows the numbers of Chinese words with “VV” tag corresponding to English words with different verb POS tags. We found Chinese verbs have more than 77% possibilities to align to English verbs in total. However, our method will fail when some special Chinese sentences only contain noun predicates. 6.3 Experimental Results All the experiment results are showed on the table 3. Our Baseline is a modified Moses. The major modification is input and output module in order to translate using document as unit. The performance of our baseline exceeds the baseline reported by Gong et al. (2011) about 2 percent based on the similar training and test corpus. System BLEU BLEU on Test(%) Dev(%) BLEU NIST Moses Md(Baseline) 29.21 28.30 8.4528 Baseline+F. 30.56 28.87(***) 8.7935 Baseline+F3 31.28 28.61(**) 8.5645 Baseline+F3(*) 31.04 28.74(**) 8.6271 Baseline+F.+F3 31.75 28.88(***) 8.7987 Baseline+F.+F3(*) 31.42 28.92(***) 8.8201 Table 3: The performance of using different feature combinations The system denoted as “Baseline+F,,t” integrates the inter-tense feature. The performance boosts 0.57(***) in BLEU score. The system denoted as “Baseline+F3” integrates the intra-tense feature into </context>
</contexts>
<marker>Gong, Zhang, Zhou, 2011</marker>
<rawString>Zhengxian Gong, Min Zhang and Guodong Zhou. 2011. Cached-based Document-level Statistical Machine Translation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 909-919.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Franz Josef Och ,and DanielMarcu.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL-2003,</booktitle>
<pages>48--54</pages>
<marker>Koehn, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och ,and DanielMarcu. 2003. Statistical Phrase-Based Translation. In Proceedings of NAACL-2003, pages 48-54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Significance Tests for Machine Translation Evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>388--395</pages>
<contexts>
<context position="25798" citStr="Koehn, 2004" startWordPosition="4288" endWordPosition="4289">Setting for SMT In our experiment, SRI language modeling toolkit was used to train a 5-Gram general language model on the Xinhua portion of the Gigaword corpus. Word alignment was performed on the training parallel corpus using GIZA++ ( Och and Ney, 2000) in two directions. For evaluation, the NIST 282 BLEU script (version 13) with the default setting is used to calculate the BLEU score (Papineni et al., 2002), which measures case-insensitive matching of 4-grams. To see whether an improvement is statistically significant, we also conduct significance tests using the paired bootstrap approach (Koehn, 2004). In this paper, “***” and “**” denote p-values equal to 0.05, and bigger than 0.05, which mean significantly better, moderately better respectively. Corpus Sentences Documents Role Name Train FBIS 228455 10000 Dev NIST2003 919 100 Test NIST2005 1082 100 Table 1: Corpus statistics We use FBIS as the training data, the 2003 NIST MT evaluation test data as the development data, and the 2005 NIST MT test data as the test data. Table 1 shows the statistics of these data sets (with document boundaries annotated). 6.2 The Correlation of Chinese Verbs and English Verbs In this section, an additional </context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical Significance Tests for Machine Translation Evaluation. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, pages 388-395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
</authors>
<title>Alex Lascarides.</title>
<date>2006</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>27--85</pages>
<marker>Lapata, 2006</marker>
<rawString>Mirella Lapata, Alex Lascarides. 2006. Learning Sentence-internal Temporal Relations. Journal of Artificial Intelligence Research, 27:85-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Feifan Liu</author>
<author>Fei Liu</author>
<author>Yang Liu</author>
</authors>
<title>Learning from Chinese-English Parallel Data for Chinese Tense Prediction.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP-2011,</booktitle>
<pages>1116--1124</pages>
<location>Mai, Thailand.</location>
<contexts>
<context position="8161" citStr="Liu et al. (2011)" startWordPosition="1291" endWordPosition="1294">d subordinate clauses connected with some special temporal marker words, such as “after” and “before”, and employed them in temporal inference. Another typical task is cross-lingual tense predication. Some languages, such as English, are inflectional, whose verbs can express tense via certain stems or suffix, while others, such as Chinese often lack inflectional forms. Take Chinese to English translation as example, if Chinese text contains particle word “_T(Le)”, the nearest Chinese verb prefers to be translated into English verb with the past tense. Ye and Zhang (2005), Ye et al. (2007) and Liu et al. (2011) focus on labeling the tenses for keywords in 277 source-side language. Ye and Zhang (2005) first built a small amount of manually-labeled data, which provide the tense mapping from Chinese text to English text. Then, they trained a CRF-based tense classifier to label tense on Chinese documents. Ye et al. (2007) further reported that syntactic features contribute most to the marking of aspectual information. Liu et al. (2011) proposed a parallel mapping method to automatically generate annotated data. In particular, they used English verbs to label tense information for Chinese verbs via a par</context>
<context position="23464" citStr="Liu et al. (2011)" startWordPosition="3890" endWordPosition="3893">. Fortunately, the solely utilization of Stanford POS tagger for our SMT output is not bad although it has the same issues described in Och et al. (2002). The reason may be that phrase-based SMT contains short contexts that POS tagger can utilize while the syntax parser fails. Once obtaining a completed hypothesis, the decoder will pass it to the Stanford POS tagger and according to tense verbs to get all tense sequence for this hypothesis. However, since the POS tagger can not return the information about level structures, the decoder cannot recognize the main tense from such tense sequence. Liu et al. (2011) once used target-side verbs to label tense of source-side verbs. It is natural to consider whether Chinese verbs can provide similar clues in an opposite direction. Since Chinese verbs have good correlation with English verbs (described in section 6.2), we obtain 5In our experiment, the intra-tense bigram model can obtain the comparable performance to the trigram model. And the inter-tense trigram model can not exceed the bigram one. Figure 3: trees for parallel sentences main tense for SMT output according to such tense verb, which corresponds to the “VV”(Chinese POS labels are different to </context>
</contexts>
<marker>Liu, Liu, Liu, 2011</marker>
<rawString>Feifan Liu, Fei Liu and Yang Liu. 2011. Learning from Chinese-English Parallel Data for Chinese Tense Prediction. In Proceedings of IJCNLP-2011, pages 1116-1124,Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Improved Statistical Alignment Models.</title>
<date>2000</date>
<booktitle>In Proceedings of of ACL2000,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="19810" citStr="Och and Ney, 2000" startWordPosition="3264" endWordPosition="3267">e Models into SMT In this section, we discuss how to integrate the previous tense models into a SMT system. 5.1 Basic phrase-based SMT system It is well known that the translation process of SMT can be modeled as obtaining the best translation e of the source sentence f by maximizing following posterior probability(Brown et al., 1993): ebest = arg max P(e|f) = arg max e P(f|e)Plm(e) (2) e where P(e|f) is a translation model and Plm is a language model. Our baseline is a modified Moses, which follows Koehn et al. (2003) and adopts similar six groups of features. Besides, the log-linear model ( Och and Ney, 2000) is employed to linearly interpolate these features for obtaining the best translation according to the formula 3: M ebest = arg max λmhm(e,f) (3) e m=1 where hm(e, f) is a feature function, and λm is the weight of hm(e, f) optimized by a discriminative training method on a held-out development data(Och, 2003). 5.2 The Workflow of Our System Our system works as follows: When a hypothesis has covered all source-side words during the decoding procedure, the decoder first obtains tense sequence for such hypothesis and computes intra-tense feature Fs(see Section 5.3). At the same time, it recogniz</context>
<context position="25441" citStr="Och and Ney, 2000" startWordPosition="4232" endWordPosition="4235"> contain tense verb, such as the verb POS tags in the list of {VB, VBN, VBG}, which cannot tell tense type by themselves, our system permits to find main tense in the left/right 3 words neighbored to Tarea. And the proportion that the top-level verb of Chinese has a verb correspondence in English can reach to 83% in this way. 6 Experimentation 6.1 Experimental Setting for SMT In our experiment, SRI language modeling toolkit was used to train a 5-Gram general language model on the Xinhua portion of the Gigaword corpus. Word alignment was performed on the training parallel corpus using GIZA++ ( Och and Ney, 2000) in two directions. For evaluation, the NIST 282 BLEU script (version 13) with the default setting is used to calculate the BLEU score (Papineni et al., 2002), which measures case-insensitive matching of 4-grams. To see whether an improvement is statistically significant, we also conduct significance tests using the paired bootstrap approach (Koehn, 2004). In this paper, “***” and “**” denote p-values equal to 0.05, and bigger than 0.05, which mean significantly better, moderately better respectively. Corpus Sentences Documents Role Name Train FBIS 228455 10000 Dev NIST2003 919 100 Test NIST20</context>
</contexts>
<marker>Och, Ney, 2000</marker>
<rawString>Franz Josef Och and Hermann Ney. 2000. Improved Statistical Alignment Models. In Proceedings of of ACL2000, pages 440-447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Daniel Gildea</author>
<author>Sanjeev Khudanpur</author>
<author>et al</author>
</authors>
<title>A smorgasbord of Features for Statistical Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of NAACL-2004,</booktitle>
<pages>440--447</pages>
<contexts>
<context position="23000" citStr="Och et al. (2002)" startWordPosition="3812" endWordPosition="3815">nse sequence is about 2.5, we mainly consider intra-tense bigram model and thus n equals to 2. 5 5.4 Determining Tense For SMT Output The current SMT systems often produce odd translations partly because of abnormal word ordering and uncompleted text etc. For these abnormal translated texts, the syntactic parser cannot work well in our initial experiments, so the previous method to parse main tense and tense sequence of regular texts cannot be applied here too. Fortunately, the solely utilization of Stanford POS tagger for our SMT output is not bad although it has the same issues described in Och et al. (2002). The reason may be that phrase-based SMT contains short contexts that POS tagger can utilize while the syntax parser fails. Once obtaining a completed hypothesis, the decoder will pass it to the Stanford POS tagger and according to tense verbs to get all tense sequence for this hypothesis. However, since the POS tagger can not return the information about level structures, the decoder cannot recognize the main tense from such tense sequence. Liu et al. (2011) once used target-side verbs to label tense of source-side verbs. It is natural to consider whether Chinese verbs can provide similar cl</context>
</contexts>
<marker>Och, Gildea, Khudanpur, al, 2002</marker>
<rawString>Franz Josef Och, Daniel Gildea, Sanjeev Khudanpur, et.al. 2002. A smorgasbord of Features for Statistical Machine Translation. In Proceedings of NAACL-2004, pages 440-447.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training in Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL-2003,pages 160-167,</booktitle>
<location>Sapporo, Japan,July.</location>
<contexts>
<context position="20121" citStr="Och, 2003" startWordPosition="3320" endWordPosition="3322">own et al., 1993): ebest = arg max P(e|f) = arg max e P(f|e)Plm(e) (2) e where P(e|f) is a translation model and Plm is a language model. Our baseline is a modified Moses, which follows Koehn et al. (2003) and adopts similar six groups of features. Besides, the log-linear model ( Och and Ney, 2000) is employed to linearly interpolate these features for obtaining the best translation according to the formula 3: M ebest = arg max λmhm(e,f) (3) e m=1 where hm(e, f) is a feature function, and λm is the weight of hm(e, f) optimized by a discriminative training method on a held-out development data(Och, 2003). 5.2 The Workflow of Our System Our system works as follows: When a hypothesis has covered all source-side words during the decoding procedure, the decoder first obtains tense sequence for such hypothesis and computes intra-tense feature Fs(see Section 5.3). At the same time, it recognizes the main tense of this hypothesis and associate the main tense of previous sentence to compute inter-tense feature Fm (see Section 5.3). Next, the decoder uses such two additional feature values to re-score this hypothesis automatically and choose one hypothesis with highest score as the final translation. </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training in Statistical Machine Translation. In Proceedings of ACL-2003,pages 160-167, Sapporo, Japan,July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mari Olsen</author>
<author>David Traum</author>
<author>Carol Van Ess-Dykema</author>
<author>Amy Weinberg</author>
</authors>
<title>Implicit Cues for Explicit Generation: Using Telicity as a Cue for Tense Structure in a Chinese to English MT System. In</title>
<date>2001</date>
<booktitle>Proceedings of MT Summit VIII, Santiago de Compostella,</booktitle>
<marker>Olsen, Traum, Van Ess-Dykema, Weinberg, 2001</marker>
<rawString>Mari Olsen, David Traum,Carol Van Ess-Dykema and Amy Weinberg. 2001. Implicit Cues for Explicit Generation: Using Telicity as a Cue for Tense Structure in a Chinese to English MT System. In Proceedings of MT Summit VIII, Santiago de Compostella, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Weijing Zhu</author>
</authors>
<title>BLEU: A Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL-2002,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="25599" citStr="Papineni et al., 2002" startWordPosition="4259" endWordPosition="4262">tense in the left/right 3 words neighbored to Tarea. And the proportion that the top-level verb of Chinese has a verb correspondence in English can reach to 83% in this way. 6 Experimentation 6.1 Experimental Setting for SMT In our experiment, SRI language modeling toolkit was used to train a 5-Gram general language model on the Xinhua portion of the Gigaword corpus. Word alignment was performed on the training parallel corpus using GIZA++ ( Och and Ney, 2000) in two directions. For evaluation, the NIST 282 BLEU script (version 13) with the default setting is used to calculate the BLEU score (Papineni et al., 2002), which measures case-insensitive matching of 4-grams. To see whether an improvement is statistically significant, we also conduct significance tests using the paired bootstrap approach (Koehn, 2004). In this paper, “***” and “**” denote p-values equal to 0.05, and bigger than 0.05, which mean significantly better, moderately better respectively. Corpus Sentences Documents Role Name Train FBIS 228455 10000 Dev NIST2003 919 100 Test NIST2005 1082 100 Table 1: Corpus statistics We use FBIS as the training data, the 2003 NIST MT evaluation test data as the development data, and the 2005 NIST MT t</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Weijing Zhu. 2002. BLEU: A Method for Automatic Evaluation of Machine Translation. In Proceedings of ACL-2002, pages 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM-an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing,pages</booktitle>
<pages>901--904</pages>
<contexts>
<context position="16744" citStr="Stolcke, 2002" startWordPosition="2745" endWordPosition="2746">previous method to extract tense for an English text corpus, we can obtain a big tense corpus. Given the current tense is indexed as ti, we call the previous n − 1 tenses plus the current tense as tense n-gram. Based on the tense corpus, tense n-gram statistics can be done according to the Formula 1. P(ti|t(i−(n−1)), ..., t(i−1)) = count(t(i−(n−1)), . . . , t(i−1), ti) (1) count(t(i−(n−1)), ..., t(i−1)) Here, the function of “count” return the tense n-gram frequency. In order to avoid doing specific smoothing work, we estimate tense n-gram probability using SRI language modeling (SRILM) tool (Stolcke, 2002). To compute the probability of intra-tense n-gram, we first extract all tense sequence for each sentence and put them into a new file. Based on this new file, we can get the intra-tense n-gram model via SRILM tool. To compute the probability of inter-tense n-gram, we need to extract the main tense for each sentence at first. Then, for each document, we re-organized the main tenses of all sentences into a special line. After putting all these special lines into a new file, we can use SRILM to obtain the inter-tense n-gram model. 4.2 Characteristic of Tense N-gram Models We construct n-gram-bas</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM-an extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing,pages 901-904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Ye</author>
<author>Zhu Zhang</author>
</authors>
<title>Tense tagging for verbs in cross-lingual context: A case study.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCNLP-2005,</booktitle>
<pages>885--895</pages>
<contexts>
<context position="8121" citStr="Ye and Zhang (2005)" startWordPosition="1282" endWordPosition="1285">particular, they trained models on main and subordinate clauses connected with some special temporal marker words, such as “after” and “before”, and employed them in temporal inference. Another typical task is cross-lingual tense predication. Some languages, such as English, are inflectional, whose verbs can express tense via certain stems or suffix, while others, such as Chinese often lack inflectional forms. Take Chinese to English translation as example, if Chinese text contains particle word “_T(Le)”, the nearest Chinese verb prefers to be translated into English verb with the past tense. Ye and Zhang (2005), Ye et al. (2007) and Liu et al. (2011) focus on labeling the tenses for keywords in 277 source-side language. Ye and Zhang (2005) first built a small amount of manually-labeled data, which provide the tense mapping from Chinese text to English text. Then, they trained a CRF-based tense classifier to label tense on Chinese documents. Ye et al. (2007) further reported that syntactic features contribute most to the marking of aspectual information. Liu et al. (2011) proposed a parallel mapping method to automatically generate annotated data. In particular, they used English verbs to label tense</context>
</contexts>
<marker>Ye, Zhang, 2005</marker>
<rawString>Yang Ye and Zhu Zhang. 2005. Tense tagging for verbs in cross-lingual context: A case study. In Proceedings of IJCNLP-2005, pages 885-895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Ye</author>
<author>V li Fossum</author>
<author>Steven Abney</author>
</authors>
<title>Latent features in Temporal Reference Translation.</title>
<date>2006</date>
<booktitle>Fifth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>48--55</pages>
<contexts>
<context position="9917" citStr="Ye et al. (2006)" startWordPosition="1574" endWordPosition="1577">edge representation model based on Lexical Conceptual Structures (LCS) for machine translation which integrates the aspectual information and the lexical-semantic information. Her system is based on an inter-lingual model and does not belong to a SMT system. Olsen et al. (2001) relied on LCS to generate appropriately-tensed English translations for Chinese. In particular, they addressed tense reconstruction on a binary taxonomy (present and past) for Chinese text and reported that incorporating lexical aspect features of telicity can obtain a 20% to 35% boost in accuracy on tense realization. Ye et al. (2006) showed that incorporating latent features into tense classifiers can boost the performance. They reported the tense resolution results based on the best-ranked translation text produced by a SMT system. However, they did not report the variation of translation performance after introducing tense information. 3 Preprocessing for Tense Modeling In this paper, tense modeling is done on the targetside language. Since our experiments are done on Chinese to English SMT, our tense models are learned only from the English text. In the literature, the taxonomy of English tenses typically includes thre</context>
</contexts>
<marker>Ye, Fossum, Abney, 2006</marker>
<rawString>Yang Ye, V.li Fossum, Steven Abney. 2006. Latent features in Temporal Reference Translation. Fifth SIGHAN Workshop on Chinese Language Processing, pages 48-55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Ye</author>
<author>Karl-Michael Schnelder</author>
<author>Steven Abney</author>
</authors>
<title>Aspect Marker Generation in English-to-Chinese Machine Translation.</title>
<date>2007</date>
<booktitle>Proceedings of MT Summit XI,</booktitle>
<pages>521--527</pages>
<contexts>
<context position="8139" citStr="Ye et al. (2007)" startWordPosition="1286" endWordPosition="1289">ned models on main and subordinate clauses connected with some special temporal marker words, such as “after” and “before”, and employed them in temporal inference. Another typical task is cross-lingual tense predication. Some languages, such as English, are inflectional, whose verbs can express tense via certain stems or suffix, while others, such as Chinese often lack inflectional forms. Take Chinese to English translation as example, if Chinese text contains particle word “_T(Le)”, the nearest Chinese verb prefers to be translated into English verb with the past tense. Ye and Zhang (2005), Ye et al. (2007) and Liu et al. (2011) focus on labeling the tenses for keywords in 277 source-side language. Ye and Zhang (2005) first built a small amount of manually-labeled data, which provide the tense mapping from Chinese text to English text. Then, they trained a CRF-based tense classifier to label tense on Chinese documents. Ye et al. (2007) further reported that syntactic features contribute most to the marking of aspectual information. Liu et al. (2011) proposed a parallel mapping method to automatically generate annotated data. In particular, they used English verbs to label tense information for C</context>
</contexts>
<marker>Ye, Schnelder, Abney, 2007</marker>
<rawString>Yang Ye, Karl-Michael Schnelder, Steven Abney. 2007. Aspect Marker Generation in English-to-Chinese Machine Translation. Proceedings of MT Summit XI, pages 521-527,Copenhagen, Denmark.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>