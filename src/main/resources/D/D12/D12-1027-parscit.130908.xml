<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.996411">
Source Language Adaptation for Resource-Poor Machine Translation
</title>
<author confidence="0.998833">
Pidong Wang
</author>
<affiliation confidence="0.9998605">
Department of Computer Science
National University of Singapore
</affiliation>
<address confidence="0.9748115">
13 Computing Drive
Singapore 117417
</address>
<email confidence="0.998029">
wangpd@comp.nus.edu.sg
</email>
<note confidence="0.663917">
Preslav Nakov
QCRI
</note>
<author confidence="0.6237185">
Qatar Foundation
Tornado Tower, P.O. 5825
</author>
<affiliation confidence="0.581977">
Doha, Qatar
</affiliation>
<email confidence="0.98625">
pnakov@qf.org.qa
</email>
<author confidence="0.985932">
Hwee Tou Ng
</author>
<affiliation confidence="0.999807">
Department of Computer Science
National University of Singapore
</affiliation>
<address confidence="0.974778">
13 Computing Drive
Singapore 117417
</address>
<email confidence="0.998567">
nght@comp.nus.edu.sg
</email>
<sectionHeader confidence="0.995627" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997850363636363">
We propose a novel, language-independent
approach for improving machine translation
from a resource-poor language to X by adapt-
ing a large bi-text for a related resource-rich
language and X (the same target language).
We assume a small bi-text for the resource-
poor language to X pair, which we use to
learn word-level and phrase-level paraphrases
and cross-lingual morphological variants be-
tween the resource-rich and the resource-poor
language; we then adapt the former to get
closer to the latter. Our experiments for
Indonesian/Malay–English translation show
that using the large adapted resource-rich bi-
text yields 6.7 BLEU points of improvement
over the unadapted one and 2.6 BLEU points
over the original small bi-text. Moreover,
combining the small bi-text with the adapted
bi-text outperforms the corresponding com-
binations with the unadapted bi-text by 1.5–
3 BLEU points. We also demonstrate applica-
bility to other languages and domains.
</bodyText>
<sectionHeader confidence="0.999122" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993468522727273">
Statistical machine translation (SMT) systems learn
how to translate from large sentence-aligned bilin-
gual corpora of human-generated translations, called
bi-texts. Unfortunately, collecting sufficiently large,
high-quality bi-texts is hard, and thus most of the
6,500+ world languages remain resource-poor. For-
tunately, many of these resource-poor languages
are related to some resource-rich language, with
whom they overlap in vocabulary and share cog-
nates, which offers opportunities for bi-text reuse.
Example pairs of such resource rich–poor lan-
guages include Spanish–Catalan, Finnish–Estonian,
Swedish–Norwegian, Russian–Ukrainian, Irish–
Gaelic Scottish, Standard German–Swiss Ger-
man, Modern Standard Arabic–Dialectical Arabic
(e.g., Gulf, Egyptian), Turkish–Azerbaijani, etc.
Previous work has already demonstrated the ben-
efits of using a bi-text for a related resource-rich
language to X (e.g., X=English) to improve ma-
chine translation from a resource-poor language to
X (Nakov and Ng, 2009; Nakov and Ng, 2012).
Here we take a different, orthogonal approach: we
adapt the resource-rich language to get closer to the
resource-poor one.
We assume a small bi-text for the resource-poor
language, which we use to learn word-level and
phrase-level paraphrases and cross-lingual morpho-
logical variants between the two languages. Assum-
ing translation into the same target language X, we
adapt (the source side of) a large training bi-text for
a related resource-rich language and X.
Training on the adapted large bi-text yields very
significant improvements in translation quality com-
pared to both (a) training on the unadapted version,
and (b) training on the small bi-text for the resource-
poor language. We further achieve very sizable im-
provements when combining the small bi-text with
the large adapted bi-text, compared to combining the
former with the unadapted bi-text.
While we focus on adapting Malay to look like
Indonesian in our experiments, we also demonstrate
the applicability of our approach to another language
pair, Bulgarian–Macedonian, which is also from a
different domain.
</bodyText>
<page confidence="0.971346">
286
</page>
<note confidence="0.9707805">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 286–296, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.997432" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999872888888889">
One relevant line of research is on machine trans-
lation between closely related languages, which is
arguably simpler than general SMT, and thus can
be handled using word-for-word translation, man-
ual language-specific rules that take care of the nec-
essary morphological and syntactic transformations,
or character-level translation/transliteration. This
has been tried for a number of language pairs in-
cluding Czech–Slovak (Hajiˇc et al., 2000), Turkish–
Crimean Tatar (Altintas and Cicekli, 2002), Irish–
Scottish Gaelic (Scannell, 2006), and Bulgarian–
Macedonian (Nakov and Tiedemann, 2012). In con-
trast, we have a different objective – we do not carry
out full translation but rather adaptation since our
ultimate goal is to translate into a third language X.
A special case of this same line of research is the
translation between dialects of the same language,
e.g., between Cantonese and Mandarin (Zhang,
1998), or between a dialect of a language and a stan-
dard version of that language, e.g., between some
Arabic dialect (e.g., Egyptian) and Modern Standard
Arabic (Bakr et al., 2008; Sawaf, 2010; Salloum and
Habash, 2011). Here again, manual rules and/or
language-specific tools are typically used. In the
case of Arabic dialects, a further complication arises
by the informal status of the dialects, which are not
standardized and not used in formal contexts but
rather only in informal online communities1 such as
social networks, chats, Twitter and SMS messages.
This causes further mismatch in domain and genre.
Thus, translating from Arabic dialects to Modern
Standard Arabic requires, among other things, nor-
malizing informal text to a formal form. In fact,
this is a more general problem, which arises with
informal sources like SMS messages and Tweets for
just any language (Aw et al., 2006; Han and Bald-
win, 2011). Here the main focus is on coping with
spelling errors, abbreviations, and slang, which are
typically addressed using string edit distance, while
also taking pronunciation into account. This is dif-
ferent from our task, where we try to adapt good,
formal text from one language into another.
A second relevant line of research is on language
adaptation and normalization, when done specifi-
cally for improving SMT into another language.
</bodyText>
<footnote confidence="0.434578">
1The Egyptian Wikipedia is one notable exception.
</footnote>
<bodyText confidence="0.999805645833333">
For example, Marujo et al. (2011) described a
rule-based system for adapting Brazilian Portuguese
(BP) to European Portuguese (EP), which they used
to adapt BP–English bi-texts to EP–English. They
report small improvements in BLEU for EP–English
translation when training on the adapted “EP”–En
bi-text compared to using the unadapted BP–En
(38.55 vs. 38.29), or when an EP–English bi-text is
used in addition to the adapted/unadapted one (41.07
vs. 40.91 BLEU). Unlike this work, which heav-
ily relied on language-specific rules, our approach is
statistical, and largely language-independent; more-
over, our improvements are much more sizable.
A third relevant line of research is on reusing bi-
texts between related languages without or with very
little adaptation, which works well for very closely
related languages. For example, our previous work
(Nakov and Ng, 2009; Nakov and Ng, 2012) ex-
perimented with various techniques for combining
a small bi-text for a resource-poor language (In-
donesian or Spanish, pretending that Spanish is
resource-poor) with a much larger bi-text for a re-
lated resource-rich language (Malay or Portuguese);
the target language of all bi-texts was English. How-
ever, our previous work did not attempt language
adaptation, except for very simple transliteration for
Portuguese–Spanish that ignored context entirely;
since it could not substitute one word for a com-
pletely different word, it did not help much for
Malay–Indonesian, which use unified spelling. Still,
once we have language-adapted the large bi-text, it
makes sense to try to combine it further with the
small bi-text; thus, below we will directly compare
and combine these two approaches.
Another alternative, which we do not explore in
this work, is to use cascaded translation using a
pivot language (Utiyama and Isahara, 2007; Cohn
and Lapata, 2007; Wu and Wang, 2009). Unfortu-
nately, using the resource-rich language as a pivot
(poor—*rich—*X) would require an additional paral-
lel poor–rich bi-text, which we do not have. Pivoting
over the target X (rich—*X—*poor) for the purpose
of language adaptation, on the other hand, would
miss the opportunity to exploit the relationship be-
tween the resource-poor and the resource-rich lan-
guage; this would also be circular since the first step
would ask an SMT system to translate its own train-
ing data (we only have one rich–X bi-text).
</bodyText>
<page confidence="0.997389">
287
</page>
<sectionHeader confidence="0.957401" genericHeader="method">
3 Malay and Indonesian
</sectionHeader>
<bodyText confidence="0.9952959">
Malay and Indonesian are closely related, mutually
intelligible Austronesian languages with 180 million
speakers combined. They have a unified spelling,
with occasional differences, e.g., kerana vs. karena
(‘because’), Inggeris vs. Inggris (‘English’), and
wang vs. uang (‘money’).
They differ more substantially in vocabulary,
mostly because of loan words, where Malay typi-
cally follows the English pronunciation, while In-
donesian tends to follow Dutch, e.g., televisyen vs.
televisi, Julai vs. Juli, and Jordan vs. Yordania.
While there are many cognates between the two
languages, there are also a lot of false friends, e.g.,
polisi means policy in Malay but police in Indone-
sian. There are also many partial cognates, e.g.,
nanti means both will (future tense marker) and later
in Malay but only later in Indonesian.
Thus, fluent Malay and fluent Indonesian can dif-
fer substantially. Consider, for example, Article 1 of
the Universal Declaration ofHuman Rights:2
</bodyText>
<listItem confidence="0.955668375">
• Semua manusia dilahirkan bebas dan samarata dari segi kemu-
liaan dan hak-hak. Mereka mempunyai pemikiran dan perasaan
hati dan hendaklah bertindak di antara satu sama lain dengan
semangat persaudaraan. (Malay)
• Semua orang dilahirkan merdeka dan mempunyai marta-
bat dan hak-hak yang sama. Mereka dikaruniai akal dan
hati nurani dan hendaknya bergaul satu sama lain dalam
semangat persaudaraan. (Indonesian)
</listItem>
<bodyText confidence="0.999905818181818">
There is only 50% overlap at the word level, but
the actual vocabulary overlap is much higher, e.g.,
there is only one word in the Malay text that does
not exist in Indonesian: samarata (‘equal’). Other
differences are due to the use of different morpho-
logical forms, e.g., hendaklah vs. hendaknya (‘con-
science’), derivational variants of hendak (‘want’).
Of course, word choice in translation is often a
matter of taste. Thus, we asked a native speaker of
Indonesian to adapt the Malay version to Indonesian
while preserving as many words as possible:
</bodyText>
<listItem confidence="0.96865375">
• Semua manusia dilahirkan bebas dan mempunyai martabat
dan hak-hak yang sama. Mereka mempunyai pemikiran dan
perasaan dan hendaklah bergaul satu sama lain dalam
semangat persaudaraan. (Indonesian)
</listItem>
<footnote confidence="0.538410666666667">
2English: All human beings are born free and equal in dig-
nity and rights. They are endowed with reason and conscience
and should act towards one another in a spirit of brotherhood.
</footnote>
<bodyText confidence="0.979462769230769">
Obtaining this latter version from the original
Malay text requires three word-level operations:
(1) deletion of dari, segi, (2) insertion of yang, sama,
and (3) substitution of samarata with mempunyai.
Unfortunately, we do not have parallel Malay-
Indonesian text, which complicates the process of
learning when to apply these operations. Thus, be-
low we restrict our attention to the simplest and most
common operation of word substitution only, leav-
ing the other two3 operations for future work.
Note that word substitution is enough in many
cases, e.g., it is all that is needed for the following
Malay-Indonesian sentence pair:4
</bodyText>
<listItem confidence="0.9996955">
• KDNK Malaysia dijangka cecah 8 peratus pada tahun 2010.
• PDB Malaysia akan mencapai 8 persen pada tahun 2010.
</listItem>
<sectionHeader confidence="0.983409" genericHeader="method">
4 Method
</sectionHeader>
<bodyText confidence="0.9992382">
We improve machine translation from a resource-
poor language (Indonesian) to English by adapting a
bi-text for a related resource-rich language (Malay)
and English, using word-level and phrase-level para-
phrases and cross-lingual morphological variants.
</bodyText>
<subsectionHeader confidence="0.989865">
4.1 Word-Level Paraphrasing
</subsectionHeader>
<bodyText confidence="0.999978238095238">
Given a Malay sentence, we generate a confusion
network containing multiple Indonesian word-level
paraphrase options for each Malay word. Each such
Indonesian option is associated with a correspond-
ing weight in the network, which is defined as the
probability of this option being a translation of the
original Malay word (see Eq. 1 below). We decode
this confusion network using a large Indonesian lan-
guage model, thus generating a ranked list of n cor-
responding adapted “Indonesian” sentences.
Then, we pair each such adapted “Indonesian”
sentence with the English counter-part for the
Malay sentence it was derived from, thus obtain-
ing a synthetic “Indonesian”–English bi-text. Fi-
nally, we combine this synthetic bi-text with the
original Indonesian–English one to train the final
Indonesian–English SMT system.
Below we first describe how we generate word-
level Indonesian options and corresponding weights
for the Malay words. Then, we explain how we
build, decode, and improve the confusion network.
</bodyText>
<footnote confidence="0.8914455">
3There are other potentially useful operations, e.g., a correct
translation for the Malay samarata can be obtained by splitting
it into the Indonesian sequence sama rata.
4Malaysia’s GDP is expected to reach 8 percent in 2010.
</footnote>
<page confidence="0.988145">
288
</page>
<subsectionHeader confidence="0.913753">
4.1.1 Inducing Word-Level Paraphrases
</subsectionHeader>
<bodyText confidence="0.980604090909091">
We use pivoting over English to induce potential
Indonesian translations for a given Malay word.
First, we generate separate word-level alignments
for the Indonesian–English and the Malay–English
bi-texts. Then, we induce Indonesian-Malay word
translation pairs assuming that if an Indonesian word
i and a Malay word m are aligned to the same
English word e, they could be mutual translations.
Each translation pair is associated with a conditional
probability, estimated by pivoting over English:
J:
</bodyText>
<equation confidence="0.858423">
Pr(i|m) = Pr(i|e)Pr(e|m) (1)
e
Pr(i|e) and Pr(e|m) are estimated using maxi-
</equation>
<bodyText confidence="0.865716666666667">
mum likelihood from the word alignments. Follow-
ing (Callison-Burch et al., 2006), we further assume
that i is conditionally independent of m given e.
</bodyText>
<subsubsectionHeader confidence="0.850646">
4.1.2 Confusion Network Construction
</subsubsectionHeader>
<bodyText confidence="0.999984947368421">
Given a Malay sentence, we construct an Indone-
sian confusion network, where each Malay word is
augmented with a set of network transitions: pos-
sible Indonesian word translations. The weight
of such a transition is the conditional Indonesian-
Malay translation probability as calculated by Eq. 1;
the original Malay word is assigned a weight of 1.
Note that we paraphrase each word in the in-
put Malay sentence as opposed to only those Malay
words that we believe not to exist in Indonesian, e.g.,
because they do not appear in our Indonesian mono-
lingual text. This is necessary because of the large
number of false friends and partial cognates between
Malay and Indonesian (see Section 3).
Finally, we decode the confusion network for a
Malay sentence using a large Indonesian language
model, and we extract an n-best list.5 Table 1
shows the 10-best adapted “Indonesian” sentences6
we generated for the confusion network in Figure 1.
</bodyText>
<subsectionHeader confidence="0.589999">
4.1.3 Further Refinements
</subsectionHeader>
<bodyText confidence="0.999992666666667">
Many of our paraphrases are bad: some have very
low probabilities, while others involve rare words
for which the probability estimates are unreliable.
</bodyText>
<footnote confidence="0.5901492">
5For balance, in case of less than n adaptations for a Malay
sentence, we randomly repeat some of the available ones.
6According to a native Indonesian speaker, options 1 and 3
in Table 1 are perfect adaptations, options 2 and 5 have a wrong
word order, and the rest are grammatical though not perfect.
</footnote>
<bodyText confidence="0.992516354166667">
Moreover, the options we propose for a Malay
word are inherently restricted to the small Indone-
sian vocabulary of the Indonesian–English bi-text.
Below we describe how we address these issues.
Score-based filtering. We filter out translation
pairs whose probabilities (Eq. 1) are lower than
some threshold (tuned on the dev dataset), e.g., 0.01.
Improved estimations for Pr(i|e). We concate-
nate k copies of the Indonesian–English bi-text and
one copy of the Malay–English bi-text, where the
value of k is selected so that we have roughly the
same number of Indonesian and Malay sentences.
Then, we generate word-level alignments for the
resulting bi-text. Finally, we truncate these align-
ments keeping them for one copy of the original
Indonesian–English bi-text only. Thus, we end up
with improved word alignments for the Indonesian–
English bi-text, and with better estimations for Eq. 1.
Since Malay and Indonesian share many cognates,
this improves word alignments for Indonesian words
that occur rarely in the small Indonesian–English bi-
text but are relatively frequent in the larger Malay–
English one; it also helps for some frequent words.
Cross-lingual morphological variants. We in-
crease the Indonesian options for a Malay word us-
ing morphology. Since the set of Indonesian op-
tions for a Malay word in pivoting is restricted to
the Indonesian vocabulary of the small Indonesian–
English bi-text, this is a severe limitation of pivot-
ing. Thus, assuming a large monolingual Indone-
sian text, we first build a lexicon of the words in the
text. Then, we lemmatize these words using two dif-
ferent lemmatizers: the Malay lemmatizer of Bald-
win and Awab (2006), and a similar Indonesian lem-
matizer. Since these two analyzers have different
strengths and weaknesses, we combine their outputs
to increase recall. Next, we group all Indonesian
words that share the same lemma, e.g., for minum,
we obtain {diminum, diminumkan, diminumnya, makan-minum,
makananminuman, meminum, meminumkan, meminumnya, meminum-
minuman, minum, minum-minum, minum-minuman, minuman, minu-
manku, minumannya, peminum, peminumnya, perminum, terminum}.
Since Malay and Indonesian are subject to the same
morphological processes and share many lemmata,
we use such groups to propose Indonesian transla-
tion options for a Malay word. We first lemmatize
the target Malay word, and then we find all groups
of Indonesian words the Malay lemmata belong to.
</bodyText>
<page confidence="0.997267">
289
</page>
<figureCaption confidence="0.9889505">
Figure 1: Indonesian confusion network for the Malay sentence “KDIK Malaysia dijangka cecah 8 peratus pada tahun 2010.”
Arcs with scores below 0.01 are omitted, and words that exist in Indonesian are not paraphrased (for better readability).
</figureCaption>
<listItem confidence="0.809591636363636">
Rank “Indonesian” Sentence
1 pdb malaysia akan mencapai 8 persen pada tahun 2010 .
2 pdb malaysia untuk mencapai 8 persen pada tahun 2010 .
3 pdb malaysia diperkirakan mencapai 8 persen pada tahun 2010 .
4 maka malaysia akan mencapai 8 persen pada tahun 2010 .
5 maka malaysia untuk mencapai 8 persen pada tahun 2010 .
6 pdb malaysia dapat mencapai 8 persen pada tahun 2010 .
7 maka malaysia diperkirakan mencapai 8 persen pada tahun 2010 .
8 sebesar malaysia akan mencapai 8 persen pada tahun 2010 .
9 pdb malaysia diharapkan mencapai 8 persen pada tahun 2010 .
10 pdb malaysia ini mencapai 8 persen pada tahun 2010 .
</listItem>
<tableCaption confidence="0.999727">
Table 1: The 10-best “Indonesian” sentences extracted from the confusion network in Figure 1.
</tableCaption>
<figure confidence="0.998453548387097">
remaja|0.047619
mencapai|0.042930
hit|0.030612
sr|0.030482
guncang|0.023810
di|0.022778
untuk|0.018425
hits|0.013605
diguncang|0.010074
akan|0.079793
pdb|0.576172
sebesar|0.052080
maka|0.026044
perkiraan|0.026035
0 1
panggar|0.026035
rkp|0.026035
gdp|0.026034
malaysia|1.0 ke|0.018960
2 3
dapat|0.018436
adalah|0.017422
menjadi|0.011655
ini|0.011158
untuk|0.050155
diharapkan|0.044511
diperkirakan|0.039131
4
8|1.0 persen|0.473588 pada|1.0 tahun|1.0 2010|1.0 .|1.0
5 6 7 8 9 10
per|0.148886
</figure>
<bodyText confidence="0.9999285">
The union of these groups is the set of morpholog-
ical variants that we will add to the confusion net-
work as additional options for the Malay word.7 For
example, given seperminuman (‘drinking’) in the
Malay input, we first find its stem minum, and then
we get the above example set of Indonesian words,
which contains some reasonable substitutes such as
minuman (‘drink’). In the confusion network, the
weight of the original Malay word is set to 1, while
the weight of a morphological option is one minus
the minimum edit distance ratio (Ristad and Yian-
ilos, 1998) between it and the Malay word, multi-
plied by the highest probability for all pivoting vari-
ants for the Malay word.
</bodyText>
<subsectionHeader confidence="0.949524">
4.2 Phrase-Level Paraphrasing
</subsectionHeader>
<bodyText confidence="0.99283284375">
Word-level paraphrasing ignores context when gen-
erating Indonesian variants, relying on the Indone-
sian language model to make the right contextual
choice. We also try to model context more directly
by generating adaptation options at the phrase level.
7While the different morphological forms typically have dif-
ferent meanings, e.g., minum (‘drink’) vs. peminum (‘drinker’),
in some cases the forms could have the same translation in En-
glish, e.g., minum (‘drink’, verb) vs. minuman (‘drink’, noun).
This is our motivation for trying morphological variants, even
though they are almost exclusively derivational, and thus quite
risky as translational variants; see also (Nakov and Ng, 2011).
Phrase-level paraphrase induction. We use
standard phrase-based SMT techniques to build sep-
arate phrase tables for the Indonesian–English and
the Malay–English bi-texts, where we have four
conditional probabilities: forward/reverse phrase
translation probability, and forward/reverse lexical-
ized phrase translation probability. We pivot over
English to generate Indonesian-Malay phrase pairs,
whose probabilities are derived from the corre-
sponding ones in the two phrase tables using Eq. 1.
Cross-lingual morphological variants. While
phrase-level paraphrasing models context better, it
remains limited in the size of its Indonesian vocab-
ulary by the small Indonesian–English bi-text, just
like word-level paraphrasing was. We address this
by transforming the sentences in the development
and the test Indonesian–English bi-texts into confu-
sion networks, where we add Malay morphological
variants for the Indonesian words, weighting them as
before. Note that we do not alter the training bi-text.
</bodyText>
<subsectionHeader confidence="0.99613">
4.3 Combining Bi-texts
</subsectionHeader>
<bodyText confidence="0.9996098">
We combine the Indonesian–English and the syn-
thetic “Indonesian”–English bi-texts as follows:
Simple concatenation. Assuming the two bi-
texts are of comparable quality, we simply train an
SMT system on their concatenation.
</bodyText>
<page confidence="0.972698">
290
</page>
<bodyText confidence="0.999702875">
Balanced concatenation with repetitions. How-
ever, the two bi-texts are not directly comparable and
are clearly not equally good as a source of training
data for an Indonesian-English SMT system. For
one thing, the “Indonesian”–English bi-text is ob-
tained from n-best lists, i.e., it has exactly n very
similar variants for each Malay sentence. Moreover,
the original Malay–English bi-text is much larger
in size than the Indonesian–English one, and now
it has been further expanded n times in order to be-
come an “Indonesian”–English bi-text, which means
that it will dominate the concatenation due to its
size. In order to counter-balance this, we repeat the
smaller Indonesian–English bi-text enough times so
that we can make the number of sentences it contains
roughly the same as for the “Indonesian”–English
bi-text; then we concatenate the two bi-texts and we
train an SMT system on the resulting bi-text.
Sophisticated phrase table combination. Fi-
nally, we experiment with a method for combining
phrase tables proposed in (Nakov and Ng, 2009;
Nakov and Ng, 2012). The first phrase table is
extracted from word alignments for the balanced
concatenation with repetitions, which are then trun-
cated so that they are kept for only one copy of the
Indonesian–English bi-text. The second table is built
from the simple concatenation. The two tables are
then merged as follows: all phrase pairs from the
first one are retained, and to them are added those
phrase pairs from the second one that are not present
in the first one. Each phrase pair retains its orig-
inal scores, which are further augmented with 1–3
additional feature scores indicating its origin: the
first/second/third feature is 1 if the pair came from
the first/second/both table(s), and 0 otherwise. We
experiment using all three, the first two, or the first
feature only; we also try setting the features to 0.5
instead of 0. This makes the following six combina-
tions (0, 00, 000, .5, .5.5, .5.5.5); on testing, we use
the one that achieves the highest BLEU score on the
development set.
Other possibilities for combining the phrase ta-
bles include using alternative decoding paths (Birch
et al., 2007), simple linear interpolation, and direct
phrase table merging with extra features (Callison-
Burch et al., 2006); they were previously found in-
ferior to the last two approaches above (Nakov and
Ng, 2009; Nakov and Ng, 2012).
</bodyText>
<sectionHeader confidence="0.99873" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99983025">
We run two kinds of experiments: (a) isolated,
where we train on the synthetic “Indonesian”–
English bi-text only, and (b) combined, where we
combine it with the Indonesian–English bi-text.
</bodyText>
<subsectionHeader confidence="0.919657">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.9932095">
In our experiments, we use the following datasets,
normally required for Indonesian–English SMT:
</bodyText>
<listItem confidence="0.993795636363636">
• Indonesian–English train bi-text (IN2EN):
28,383 sentence pairs; 915,192 English tokens;
796,787 Indonesian tokens;
• Indon.–English dev bi-text (IN2EN-dev):
2,000 sentence pairs; 36,584 English tokens;
35,708 Indonesian tokens;
• Indon.–English test bi-text (IN2EN-test):
2,018 sentence pairs; 37,101 English tokens;
35,509 Indonesian tokens;
• Monolingual English text (EN-LM): 174,443
sentences; 5,071,988 English tokens.
</listItem>
<bodyText confidence="0.776039333333333">
We also use a Malay–English set (to be turned
into “Indonesian”–English), and monolingual In-
donesian text (for decoding the confusion network):
</bodyText>
<listItem confidence="0.998906666666667">
• Malay–English train bi-text (ML2EN):
290,000 sentence pairs; 8,638,780 English
tokens; 8,061,729 Malay tokens;
• Monolingual Indonesian text (IN-LM):
1,132,082 sentences; 20,452,064 Indonesian
tokens.
</listItem>
<subsectionHeader confidence="0.998101">
5.2 Baseline Systems
</subsectionHeader>
<bodyText confidence="0.999903714285714">
We build five baseline systems – two using a sin-
gle bi-text, ML2EN or IN2EN, and three combin-
ing ML2EN and IN2EN, using simple concatenation,
balanced concatenation, and sophisticated phrase ta-
ble combination. The last combination is a very
strong baseline and the most relevant one we need
to improve upon.
</bodyText>
<subsectionHeader confidence="0.964391">
5.3 Isolated Experiments
</subsectionHeader>
<bodyText confidence="0.999717666666667">
The isolated experiments only use the adapted
“Indonesian”–English bi-text, which allows for a di-
rect comparison to using ML2EN / IN2EN only.
</bodyText>
<subsubsectionHeader confidence="0.645146">
5.3.1 Word-Level Paraphrasing
</subsubsectionHeader>
<bodyText confidence="0.998972">
In our word-level paraphrasing experiments, we
adapt Malay to Indonesian using three kinds of con-
fusion networks (see Section 4.1.3 for details):
</bodyText>
<page confidence="0.990534">
291
</page>
<listItem confidence="0.9983145">
• CI:pivot – using word-level pivoting only;
• CI:pivot′ – using word-level pivoting, with
probabilities from word alignments for II2EI
that were improved using ML2EI;
• CI:pivot′+morph – CI:pivot′ augmented with
cross-lingual morphological variants.
</listItem>
<bodyText confidence="0.997657">
There are two parameter values to be tuned
on II2EI-dev for the above confusion networks:
</bodyText>
<listItem confidence="0.740510333333333">
(1) the minimum pivoting probability threshold for
the Malay-Indonesian word-level paraphrases, and
(2) the number of n-best Indonesian-adapted sen-
tences that are to be generated for each input Malay
sentence. We try 10.001, 0.005, 0.01, 0.05} for the
threshold and 11, 5,10} for n.
</listItem>
<subsubsectionHeader confidence="0.920869">
5.3.2 Phrase-Level Paraphrasing
</subsubsectionHeader>
<bodyText confidence="0.99956675">
In our phrase-level paraphrasing experiments, we
use pivoted phrase tables (PPT) with the following
features for each phrase table entry (in addition to
the phrase penalty; see Section 4.2 for more details):
</bodyText>
<listItem confidence="0.951456333333333">
• PPT:1 – only uses the forward conditional
translation probability;
• PPT:4 – uses all four conditional probabilities;
• PPT:4::CI:morph – PPT:4 but used with a
cross-lingual morphological confusion network
for the dev/test Indonesian sentences.
</listItem>
<bodyText confidence="0.999967333333333">
Here we tune one parameter only: the number of
n-best Indonesian-adapted sentences to be generated
for each input Malay sentence; we try 11, 5,10}.
</bodyText>
<subsectionHeader confidence="0.975607">
5.4 Combined Experiments
</subsectionHeader>
<bodyText confidence="0.9999458">
These experiments assess the impact of our adap-
tation approach when combined with the original
Indonesian–English bi-text II2EI as opposed to
combining ML2EI with II2EI (as was in the last
three baselines). We experiment with the same three
combinations: simple concatenation, balanced con-
catenation, and sophisticated phrase table combina-
tion. We tune the parameters as before; for the last
combination, we further tune the six extra feature
combinations (see Section 4.3 for details).
</bodyText>
<sectionHeader confidence="0.999704" genericHeader="method">
6 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999483">
For all tables, statistically significant improvements
(p &lt; 0.01), according to Collins et al. (2005)’s sign
test, over the baseline are in bold; in case of two
baselines, underline is used for the second baseline.
</bodyText>
<table confidence="0.987552333333333">
System BLEU
ML2EI 14.50
II2EI 18.67
Simple concatenation 18.49
Balanced concatenation 19.79
Sophisticated phrase table combination 20.10(.5.5)
</table>
<tableCaption confidence="0.995759">
Table 2: The five baselines. The subscript indicates the
parameters found on II2EI-dev and used for II2EI-test.
The scores that are statistically significantly better than
ML2EI and II2EI (p &lt; 0.01, Collins’ sign test) are
shown in bold and are underlined, respectively.
</tableCaption>
<subsectionHeader confidence="0.994281">
6.1 Baseline Experiments
</subsectionHeader>
<bodyText confidence="0.999576533333333">
The results for the baseline systems are shown in Ta-
ble 2. We can see that training on ML2EI instead of
II2EI yields over 4 points absolute drop in BLEU
(Papineni et al., 2002) score, even though ML2EI is
about 10 times larger than II2EI and both bi-texts
are from the same domain. This confirms the exis-
tence of important differences between Malay and
Indonesian. While simple concatenation does not
help, balanced concatenation with repetitions im-
proves by 1.12 BLEU points over II2EI, which
shows the importance of giving II2EI a proper
weight in the combined bi-text. This is further re-
confirmed by the sophisticated phrase table combi-
nation, which yields an additional absolute gain of
0.31 BLEU points.
</bodyText>
<subsectionHeader confidence="0.988987">
6.2 Isolated Experiments
</subsectionHeader>
<bodyText confidence="0.999966166666667">
Table 3 shows the results for the isolated experi-
ments. We can see that word-level paraphrasing
improves by up to 5.56 and 1.39 BLEU points
over the two baselines (both statistically signifi-
cant). Compared to ML2EI, CI:pivot yields an ab-
solute improvement of 4.41 BLEU points, CI:pivot′
adds another 0.59, and CI:pivot′+morph adds 0.56
more. The scores for TER (v. 0.7.25) and METEOR
(v. 1.3) are on par with those for BLEU (NIST v. 13).
Table 3 further shows that the optimal parameters
for the word-level SMT systems (CI:*) involve a
very low probability cutoff, and a high number of
n-best sentences. This shows that they are robust to
noise, probably because bad source-side phrases are
unlikely to match the test-time input. Note also the
effect of repetitions: good word choices are shared
by many n-best sentences, and thus they would have
higher probabilities compared to bad word choices.
</bodyText>
<page confidence="0.991148">
292
</page>
<table confidence="0.999304263157895">
System 1-gr. n-gram precision 4-gr. BLEU TER METEOR
2-gr. 3-gr.
ML2EN (baseline) 48.34 19.22 9.54 4.98 14.50 67.14 43.28
IN2EN (baseline) 55.04 23.90 12.87 7.18 18.67 61.99 54.34
CN:pivot 54.50 24.41 13.09 7.35 18.91(+4.41,+0.24) 61.94 51.07
CN:pivot′ 55.05 25.09 13.60 7.69 0.005,10best 60.31 51.97
(i) CN:pivot′+morph 55.97 25.73 14.06 7.99 19.50(+5.00,+0.83)61.25 55.65
(0.001,10best)
20.06(+5.56,+1.39)
(0.005,10best)
PPT:1 55.11 25.04 13.66 7.80 19.58(+5.08,+0.91) 60.92 51.93
PPT:4 56.64 26.20 14.53 8.40 59.33 54.23
(ii) PPT:4::CN:morph 56.91 26.53 14.76 8.55 59.30 57.19
(10best)
20.63(+6.13,+1.96)
(10best)
20.89(+6.39,+2.22)
(10best)
System combination: (i) + (ii) 57.73 27.00 15.03 8.71 21.24(+6.74,+2.57) 58.19 54.63
</table>
<tableCaption confidence="0.9688415">
Table 3: Isolated experiments. The subscript shows the best tuning parameters, and the superscript shows the absolute
test improvement over the ML2EN and the IN2EN baselines. The last line shows system combination results.
</tableCaption>
<table confidence="0.9993929375">
Combination with Combining IN2EN with an adapted version of ML2EN
Simple Concatenation Balanced Concatenation Sophisticated Combination
(i) + ML2EN (unadapted; baseline) 18.49 19.79 20.10(.5.5)
+ CN:pivot 19.99(+1.50) 20.16(+0.37) 20.32(+0.22)
+ CN:pivot′ (0.001,1best) (0.001,10best) (0.01,10best,.5.5)
(ii) + CN:pivot′+morph 20.03(+1.54) 20.80(+1.01) 20.55(+0.45)
(0.05,1best) (0.05,10best) (0.05,10best,.5.5)
20.60(+2.11) 21.15(+1.36) 21.05(+0.95)
(0.01,10best) (0.01,10best) (0.01,5best,00)
+ PPT:1 20.61(+2.12) 20.71(+0.92) 20.32(+0.22)
+ PPT:4 (1best) (10best) (1best,000)
(iii) + PPT:4::CN:morph 20.75(+2.26) 21.08(+1.29) 20.76(+0.66)
(1best) (5best) (10best,.5.5.5)
21.01(+2.52) 21.31(+1.52) 20.98(+0.88)
(1best) (5best) (10best,.5)
System combination: (i) + (ii) + (iii) 21.55(+3.06) 21.64(+1.85) 21.62(+1.52)
</table>
<tableCaption confidence="0.975702">
Table 4: Combined experiments: BLEU. The best tuning parameter values are in subscript, and the absolute test
improvement over the corresponding baseline (on top of each column) is in superscript.
</tableCaption>
<bodyText confidence="0.999987666666667">
The gap between ML2EN and IN2EN for unigram
precision could be explained by vocabulary differ-
ences between Malay and Indonesian. Compared
to IN2EN, all CN:* models have higher 2/3/4-gram
precision. However, CN:pivot has lower unigram
precision, which could be due to bad word align-
ments, as the results for CN:pivot′ show.
When morphological variants are further added,
the unigram precision improves by almost 1% ab-
solute over CN:pivot′. This shows the importance
of morphology for overcoming the limitations of the
small Indonesian vocabulary of the IN2EN bi-text.
The lower part of Table 3 shows that phrase-level
paraphrasing performs a bit better. This confirms the
importance of modeling context for closely-related
languages like Malay and Indonesian, which are rich
in false friends and partial cognates. We further
see that using more scores in the phrase table is
better. Extending the Indonesian vocabulary with
cross-lingual morphological variants is still helpful,
though not as much as at the word-level.
Finally, the combination of the output of
the best PPT and the best CN systems using
MEMT (Heafield and Lavie, 2010) yields even fur-
ther improvements, which shows that the two kinds
of paraphrases are complementary. The best overall
BLEU score for our isolated experiments is 21.24,
which is better than the results for all five baselines
in Table 2, including the three bi-text combination
baselines, which only achieve up to 20.10 BLEU.
</bodyText>
<subsectionHeader confidence="0.999072">
6.3 Combined Experiments
</subsectionHeader>
<bodyText confidence="0.9958956">
Table 4 shows the performance of the three bi-
text combination strategies (see Section 4.3 for ad-
ditional details) when applied to combine IN2EN
(1) with the original ML2EN and (2) with various
adapted versions of it.
We can see that for the word-level paraphras-
ing experiments (CN:*), all combinations except
for CN:pivot perform significantly better than their
corresponding baselines, but the improvements are
most sizeable for the simple concatenation.
</bodyText>
<page confidence="0.996191">
293
</page>
<bodyText confidence="0.999984333333333">
Note that while there is a difference of 0.31 BLEU
points between the balanced concatenation and the
sophisticated combination for the original ML2EN,
they differ little for the adapted versions. This is
probably due to the sophisticated combination as-
suming that the second bi-text is worse than the first
one, which is not really the case for the adapted ver-
sions: as Table 3 shows, they all outperform IN2EN.
Overall, phrase-level paraphrasing performs a bit
better than word-level paraphrasing, and system
combination with MEMT improves even further.
This is consistent with the isolated experiments.
</bodyText>
<sectionHeader confidence="0.969133" genericHeader="method">
7 Further Analysis
</sectionHeader>
<bodyText confidence="0.962903789473684">
Paraphrasing non-Indonesian words only. In
CN:* above, we paraphrased each word in the Malay
input, because of false friends like polisi and partial
cognates like nanti. This risks proposing worse al-
ternatives, e.g., changing beliau (‘he’, respectful) to
ia (‘he’, casual), which confusion network weights
and LM would not always handle. Thus, we tried
paraphrasing non-Indonesian words only, i.e., those
not in IN-LM. Since IN-LM occasionally contains
some Malay-specific words, we also tried paraphras-
ing words that occur at most t times in IN-LM. Ta-
ble 5 shows that this hurts by up to 1 BLEU point
for t = 0;10, and a bit less for t = 20; 40.
System BLEU
CN:pivot, t = 0 17.88(0.01,5best)
CN:pivot, t = 10 17.88(0.05,10best)
CN:pivot, t = 20 18.14(0.01,5best)
CN:pivot, t = 40 18.34(0.01,5best)
CN:pivot (i.e., paraphrase all) 18.91(0.005,10best)
</bodyText>
<tableCaption confidence="0.86036">
Table 5: Paraphrasing non-Indonesian words only:
those appearing at most t times in IN-LM.
</tableCaption>
<bodyText confidence="0.999762631578947">
Manual evaluation. We asked a native Indone-
sian speaker who does not speak Malay to judge
whether our “Indonesian” adaptations are more un-
derstandable to him than the original Malay in-
put for 100 random sentences. We presented him
with two extreme systems: (a) the conservative
CN:pivot,t=0 vs. (b) CN:pivot′+morph. Since the
latter is noisy, the top 3 choices were judged for
it. Table 6 shows that CN:pivot,t=0 is better/equal
to the original 53%/31% of the time. In contrast,
CN:pivot′+morph is typically worse than the orig-
inal; even compared to the best in top 3, the bet-
ter:worse ratio is 45%:43%.
Still, this latter model works better, which means
that phrase-based SMT systems are robust to noise
and prefer more variety. Note also that the judg-
ments were at the sentence level, while phrases are
sub-sentential, i.e., there can be many good phrases
in a “bad” sentence.
</bodyText>
<table confidence="0.999469">
System Better Equal Worse
CN:pivot, t = 0(Rank1) 53% 31% 16%
CN:pivot′+morph(Rank1) 38% 8% 54%
CN:pivot′+morph(Rank2) 41% 9% 50%
CN:pivot′+morph(Rank3) 32% 11% 57%
CN:pivot′+morph(Ranks,1−3) 45% 12% 43%
</table>
<tableCaption confidence="0.9584975">
Table 6: Human judgments: Malay vs. “Indonesian”.
The parameter values are those from Tables 3 and 5.
</tableCaption>
<bodyText confidence="0.95810828125">
Reversed Adaptation. In all experiments above,
we were adapting the Malay sentences to look like
Indonesian. Here we try to reverse the direction of
adaptation, i.e., to adapt Indonesian to Malay: we
thus build a “Malay” confusion network for each
dev/test Indonesian sentence to be used as an in-
put to a Malay–English SMT system trained on the
ML2EN dataset. We tried two variations of this idea:
• lattice: Use Indonesian-to-Malay confusion
networks directly as input to the ML2EN SMT
system, i.e., tune a log-linear model using con-
fusion networks for the source side of the
IN2EN-dev dataset, and then evaluate the tuned
system using confusion networks for the source
side of the IN2EN-test dataset.
• 1-best: Use the 1-best output from the
Indonesian-to-Malay confusion network for
each sentence of IN2EN-dev and IN2EN-test.
Then pair each 1-best output with the corre-
sponding English sentence. Finally, get an
adapted “Malay”–English development set and
an adapted “Malay”–English test set, and use
them to tune and evaluate the ML2EN SMT
system.
Table 7 shows that both variations perform worse
than CN:pivot. We believe this is because lattice en-
codes many options, but does not use a Malay LM,
while 1-best uses a Malay LM, but has to commit
to 1-best. In contrast, CN:pivot uses both n-best
outputs and an Indonesian LM; designing a similar
setup for reversed adaptation is a research direction
we would like to pursue in future work.
</bodyText>
<page confidence="0.993153">
294
</page>
<table confidence="0.99919125">
System BLEU
CI:pivot (Malay→Indonesian) 18.91(0.005,10best)
CI:pivot (Indonesian→Malay) – lattice 17.22(0.05)
CI:pivot (Indonesian→Malay) – 1-best 17.77(0.001)
</table>
<tableCaption confidence="0.999872">
Table 7: Reversed adaptation: Indonesian to Malay.
</tableCaption>
<bodyText confidence="0.999599846153846">
Adapting Macedonian to Bulgarian. We ex-
perimented with another pair of closely-related lan-
guages,8 Macedonian (MK) and Bulgarian (BG), us-
ing data from a different, non-newswire domain: the
OPUS corpus of movie subtitles (Tiedemann, 2009).
We used datasets of sizes that are comparable to
those in the previous experiments: 160K MK2EI
and 1.5M BG2EI sentence pairs (1.2M and 11.5M
EI words). Since the sentences were short, we used
10K MK2EI sentence pairs for tuning and testing
(77K and 72K English words). For the LM, we used
9.2M Macedonian and 433M English words.
Table 8 shows that both CI:* and PPT:* yield
statistically significant improvements over balanced
concatenation with unadapted BG2EI; system com-
bination with MEMT improves even further. This
indicates that our approach can work for other pairs
of related languages and even for other domains.
We should note though that the improvements
here are less sizeable than for Indonesian/Malay.
This may be due to our monolingual MK dataset be-
ing smaller (10M MK vs. 20M II words), and too
noisy, containing many OCR errors, typos, concate-
nated words, and even some Bulgarian text. More-
over, Macedonian and Bulgarian are arguably some-
what more dissimilar than Malay and Indonesian.
</bodyText>
<table confidence="0.972795875">
System BLEU TER METEOR
BG2EI (baseline) 24.57 57.64 41.60
MK2EI (baseline) 26.46 54.55 46.15
Balanced concatenation of MK2EI with an adapted BG2EI
+ BG2EI (unadapted) 27.33 54.61 48.16
+ CI:pivot′+morph 27.97( +0.64,+1.51) 54.08 49.65
+ PPT:4::CI:morph 28.38( +1.05,+1.92) 53.35 48.21
Combining last three 29.05( +1.72,+2.59) 52.31 50.96
</table>
<tableCaption confidence="0.881422">
Table 8: Improving Macedonian–English SMT by
adapting Bulgarian to Macedonian.
</tableCaption>
<bodyText confidence="0.667911833333333">
8There is a heated political and linguistic debate about
whether Macedonian represents a separate language or is a re-
gional literary form of Bulgarian. Since there are no clear cri-
teria for distinguishing a dialect from a language, linguists are
divided on this issue. Politically, the Macedonian remains un-
recognized as a language by Bulgaria and Greece.
</bodyText>
<sectionHeader confidence="0.899884" genericHeader="conclusions">
8 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999802">
We have presented a novel approach for improving
machine translation for a resource-poor language by
adapting a bi-text for a related resource-rich lan-
guage, using confusion networks, word/phrase-level
paraphrasing, and morphological analysis.
We have achieved very significant improvements
over several baselines (6.7 BLEU points over an un-
adapted version of ML2EI, 2.6 BLEU points over
II2EI, and 1.5–3 BLEU points over three bi-text
combinations of ML2EI and II2EI), thus proving
the potential of the idea. We have further demon-
strated the applicability of the general approach to
other languages and domains.
In future work, we would like to add word dele-
tion, insertion, splitting, and concatenation as al-
lowed editing operations. We further want to ex-
plore tighter integration of word-based and phrase-
based paraphrasing. Finally, we plan experiments
with other language pairs and application to other
linguistic problems.
</bodyText>
<sectionHeader confidence="0.997475" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999986454545455">
We would like to give special thanks to Harta Wijaya
and Aldrian Obaja Muis, native speakers of Indone-
sian, for their help in the linguistic analysis of the
input and output of our system. We would also like
to thank the anonymous reviewers for their construc-
tive comments and suggestions, which have helped
us improve the quality of this paper.
This research is supported by the Singapore Na-
tional Research Foundation under its International
Research Centre @ Singapore Funding Initiative
and administered by the IDM Programme Office.
</bodyText>
<sectionHeader confidence="0.999235" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998792">
Kemal Altintas and Ilyas Cicekli. 2002. A machine
translation system between a pair of closely related
languages. In Proceedings of the 17th International
Symposium on Computer and Information Sciences,
ISCIS ’02, pages 192–196.
AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A
phrase-based statistical model for SMS text normal-
ization. In Proceedings of the 21st International Con-
ference on Computational Linguistics and 44th Annual
Meeting of the Association for Computational Linguis-
tics, ACL-COLING ’06.
</reference>
<page confidence="0.974953">
295
</page>
<reference confidence="0.999691644859813">
Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan.
2008. A hybrid approach for converting written Egyp-
tian colloquial dialect into diacritized Arabic. In Pro-
ceedings of the 6th International Conference on Infor-
matics and Systems, INFOS ’08.
Timothy Baldwin and Su’ad Awab. 2006. Open source
corpus analysis tools for Malay. In Proceedings of the
5th International Conference on Language Resources
and Evaluation, LREC ’06, pages 2212–2215.
Alexandra Birch, Miles Osborne, and Philipp Koehn.
2007. CCG supertags in factored statistical machine
translation. In Proceedings of the Second Workshop
on Statistical Machine Translation, WMT ’07, pages
9–16.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine transla-
tion using paraphrases. In Proceedings of the Human
Language Technology Conference of NAACL, HLT-
NAACL ’06, pages 17–24.
Trevor Cohn and Mirella Lapata. 2007. Machine trans-
lation by triangulation: Making effective use of multi-
parallel corpora. In Proceedings of the 45th Annual
Meeting of the Association for Computational Linguis-
tics, ACL ’07, pages 728–735.
Michael Collins, Philipp Koehn, and Ivona Kuˇcerov´a.
2005. Clause restructuring for statistical machine
translation. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguistics,
ACL ’05, pages 531–540.
Jan Hajiˇc, Jan Hric, and Vladislav Kuboˇn. 2000. Ma-
chine translation of very close languages. In Proceed-
ings of the Sixth Conference on Applied Natural Lan-
guage Processing, ANLP ’00, pages 7–12.
Bo Han and Timothy Baldwin. 2011. Lexical normal-
isation of short text messages: Makn sens a #twitter.
In Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics: Human Lan-
guage Technologies, ACL-HLT ’11, pages 368–378.
Kenneth Heafield and Alon Lavie. 2010. Combin-
ing machine translation output with open source:
The Carnegie Mellon multi-engine machine transla-
tion scheme. The Prague Bulletin of Mathematical
Linguistics, 93(1):27–36.
Luis Marujo, Nuno Grazina, Tiago Luis, Wang Ling,
Luisa Coheur, and Isabel Trancoso. 2011. BP2EP -
adaptation of Brazilian Portuguese texts to European
Portuguese. In Proceedings of the 15th Conference
of the European Association for Machine Translation,
EAMT ’11, pages 129–136.
Preslav Nakov and Hwee Tou Ng. 2009. Improved statis-
tical machine translation for resource-poor languages
using related resource-rich languages. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, EMNLP ’09, pages 1358–1367.
Preslav Nakov and Hwee Tou Ng. 2011. Trans-
lating from morphologically complex languages: A
paraphrase-based approach. In Proceedings of the
49th Annual Meeting of the Association for Compu-
tational Linguistics: Human Language Technologies,
ACL-HLT ’11, pages 1298–1307.
Preslav Nakov and Hwee Tou Ng. 2012. Improving
statistical machine translation for a resource-poor lan-
guage using related resource-rich languages. Journal
ofArtificial Intelligence Research, 44:179–222.
Preslav Nakov and J¨org Tiedemann. 2012. Combin-
ing word-level and character-level models for machine
translation between closely-related languages. In Pro-
ceedings ofthe 50th Annual Meeting of the Association
for Computational Linguistics, ACL-Short ’12.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic eval-
uation of machine translation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics, ACL ’02, pages 311–318.
Eric Ristad and Peter Yianilos. 1998. Learning string-
edit distance. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 20(5):522–532.
Wael Salloum and Nizar Habash. 2011. Dialectal
to Standard Arabic paraphrasing to improve Arabic-
English statistical machine translation. In Proc. of the
Workshop on Algorithms and Resources for Modelling
ofDialects and Language Varieties, pages 10–21.
Hassan Sawaf. 2010. Arabic dialect handling in hybrid
machine translation. In Proceedings of the 9th Confer-
ence of the Association for Machine Translation in the
Americas, AMTA ’09.
Kevin P. Scannell. 2006. Machine translation for closely
related language pairs. In Proceedings of the LREC
2006 Workshop on Strategies for Developing Machine
Translation for Minority Languages.
J¨org Tiedemann. 2009. News from OPUS - a collection
of multilingual parallel corpora with tools and inter-
faces. In Recent Advances in Natural Language Pro-
cessing, volume V, pages 237–248.
Masao Utiyama and Hitoshi Isahara. 2007. A com-
parison of pivot methods for phrase-based statistical
machine translation. In Proceedings of the Human
Language Technology Conference of NAACL, HLT-
NAACL ’07, pages 484–491.
Hua Wu and Haifeng Wang. 2009. Revisiting pivot lan-
guage approach for machine translation. In Proceed-
ings of the Joint Conference of the 47th Annual Meet-
ing of the ACL, ACL ’09, pages 154–162.
Xiaoheng Zhang. 1998. Dialect MT: a case study be-
tween Cantonese and Mandarin. In Proceedings of the
17th International Conference on Computational Lin-
guistics, COLING ’98, pages 1460–1464.
</reference>
<page confidence="0.998533">
296
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.032035">
<title confidence="0.99984">Source Language Adaptation for Resource-Poor Machine Translation</title>
<author confidence="0.823875">Pidong</author>
<affiliation confidence="0.910809666666667">Department of Computer National University of 13 Computing</affiliation>
<address confidence="0.937684">Singapore</address>
<email confidence="0.605709">wangpd@comp.nus.edu.sgPreslav</email>
<affiliation confidence="0.352051">Qatar</affiliation>
<address confidence="0.631002">Tornado Tower, P.O. Doha,</address>
<email confidence="0.983192">pnakov@qf.org.qa</email>
<author confidence="0.984391">Hwee Tou</author>
<affiliation confidence="0.91152">Department of Computer National University of 13 Computing</affiliation>
<address confidence="0.939476">Singapore</address>
<email confidence="0.990764">nght@comp.nus.edu.sg</email>
<abstract confidence="0.996144565217391">We propose a novel, language-independent approach for improving machine translation a resource-poor language to adaptlarge bi-text for a related resource-rich and same target language). We assume a small bi-text for the resourcelanguage to which we use to learn word-level and phrase-level paraphrases and cross-lingual morphological variants between the resource-rich and the resource-poor language; we then adapt the former to get closer to the latter. Our experiments for Indonesian/Malay–English translation show that using the large adapted resource-rich bitext yields 6.7 BLEU points of improvement over the unadapted one and 2.6 BLEU points over the original small bi-text. Moreover, combining the small bi-text with the adapted bi-text outperforms the corresponding combinations with the unadapted bi-text by 1.5– 3 BLEU points. We also demonstrate applicability to other languages and domains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kemal Altintas</author>
<author>Ilyas Cicekli</author>
</authors>
<title>A machine translation system between a pair of closely related languages.</title>
<date>2002</date>
<booktitle>In Proceedings of the 17th International Symposium on Computer and Information Sciences, ISCIS ’02,</booktitle>
<pages>192--196</pages>
<contexts>
<context position="4248" citStr="Altintas and Cicekli, 2002" startWordPosition="603" endWordPosition="606">uage Learning, pages 286–296, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics 2 Related Work One relevant line of research is on machine translation between closely related languages, which is arguably simpler than general SMT, and thus can be handled using word-for-word translation, manual language-specific rules that take care of the necessary morphological and syntactic transformations, or character-level translation/transliteration. This has been tried for a number of language pairs including Czech–Slovak (Hajiˇc et al., 2000), Turkish– Crimean Tatar (Altintas and Cicekli, 2002), Irish– Scottish Gaelic (Scannell, 2006), and Bulgarian– Macedonian (Nakov and Tiedemann, 2012). In contrast, we have a different objective – we do not carry out full translation but rather adaptation since our ultimate goal is to translate into a third language X. A special case of this same line of research is the translation between dialects of the same language, e.g., between Cantonese and Mandarin (Zhang, 1998), or between a dialect of a language and a standard version of that language, e.g., between some Arabic dialect (e.g., Egyptian) and Modern Standard Arabic (Bakr et al., 2008; Sawa</context>
</contexts>
<marker>Altintas, Cicekli, 2002</marker>
<rawString>Kemal Altintas and Ilyas Cicekli. 2002. A machine translation system between a pair of closely related languages. In Proceedings of the 17th International Symposium on Computer and Information Sciences, ISCIS ’02, pages 192–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AiTi Aw</author>
<author>Min Zhang</author>
<author>Juan Xiao</author>
<author>Jian Su</author>
</authors>
<title>A phrase-based statistical model for SMS text normalization.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, ACL-COLING ’06.</booktitle>
<contexts>
<context position="5559" citStr="Aw et al., 2006" startWordPosition="815" endWordPosition="818">typically used. In the case of Arabic dialects, a further complication arises by the informal status of the dialects, which are not standardized and not used in formal contexts but rather only in informal online communities1 such as social networks, chats, Twitter and SMS messages. This causes further mismatch in domain and genre. Thus, translating from Arabic dialects to Modern Standard Arabic requires, among other things, normalizing informal text to a formal form. In fact, this is a more general problem, which arises with informal sources like SMS messages and Tweets for just any language (Aw et al., 2006; Han and Baldwin, 2011). Here the main focus is on coping with spelling errors, abbreviations, and slang, which are typically addressed using string edit distance, while also taking pronunciation into account. This is different from our task, where we try to adapt good, formal text from one language into another. A second relevant line of research is on language adaptation and normalization, when done specifically for improving SMT into another language. 1The Egyptian Wikipedia is one notable exception. For example, Marujo et al. (2011) described a rule-based system for adapting Brazilian Por</context>
</contexts>
<marker>Aw, Zhang, Xiao, Su, 2006</marker>
<rawString>AiTi Aw, Min Zhang, Juan Xiao, and Jian Su. 2006. A phrase-based statistical model for SMS text normalization. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, ACL-COLING ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitham Abo Bakr</author>
<author>Khaled Shaalan</author>
<author>Ibrahim Ziedan</author>
</authors>
<title>A hybrid approach for converting written Egyptian colloquial dialect into diacritized Arabic.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Informatics and Systems, INFOS ’08.</booktitle>
<contexts>
<context position="4842" citStr="Bakr et al., 2008" startWordPosition="701" endWordPosition="704">ntas and Cicekli, 2002), Irish– Scottish Gaelic (Scannell, 2006), and Bulgarian– Macedonian (Nakov and Tiedemann, 2012). In contrast, we have a different objective – we do not carry out full translation but rather adaptation since our ultimate goal is to translate into a third language X. A special case of this same line of research is the translation between dialects of the same language, e.g., between Cantonese and Mandarin (Zhang, 1998), or between a dialect of a language and a standard version of that language, e.g., between some Arabic dialect (e.g., Egyptian) and Modern Standard Arabic (Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Here again, manual rules and/or language-specific tools are typically used. In the case of Arabic dialects, a further complication arises by the informal status of the dialects, which are not standardized and not used in formal contexts but rather only in informal online communities1 such as social networks, chats, Twitter and SMS messages. This causes further mismatch in domain and genre. Thus, translating from Arabic dialects to Modern Standard Arabic requires, among other things, normalizing informal text to a formal form. In fact, this is a more ge</context>
</contexts>
<marker>Bakr, Shaalan, Ziedan, 2008</marker>
<rawString>Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan. 2008. A hybrid approach for converting written Egyptian colloquial dialect into diacritized Arabic. In Proceedings of the 6th International Conference on Informatics and Systems, INFOS ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Su’ad Awab</author>
</authors>
<title>Open source corpus analysis tools for Malay.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC ’06,</booktitle>
<pages>2212--2215</pages>
<contexts>
<context position="16924" citStr="Baldwin and Awab (2006)" startWordPosition="2598" endWordPosition="2602">h bitext but are relatively frequent in the larger Malay– English one; it also helps for some frequent words. Cross-lingual morphological variants. We increase the Indonesian options for a Malay word using morphology. Since the set of Indonesian options for a Malay word in pivoting is restricted to the Indonesian vocabulary of the small Indonesian– English bi-text, this is a severe limitation of pivoting. Thus, assuming a large monolingual Indonesian text, we first build a lexicon of the words in the text. Then, we lemmatize these words using two different lemmatizers: the Malay lemmatizer of Baldwin and Awab (2006), and a similar Indonesian lemmatizer. Since these two analyzers have different strengths and weaknesses, we combine their outputs to increase recall. Next, we group all Indonesian words that share the same lemma, e.g., for minum, we obtain {diminum, diminumkan, diminumnya, makan-minum, makananminuman, meminum, meminumkan, meminumnya, meminumminuman, minum, minum-minum, minum-minuman, minuman, minumanku, minumannya, peminum, peminumnya, perminum, terminum}. Since Malay and Indonesian are subject to the same morphological processes and share many lemmata, we use such groups to propose Indonesia</context>
</contexts>
<marker>Baldwin, Awab, 2006</marker>
<rawString>Timothy Baldwin and Su’ad Awab. 2006. Open source corpus analysis tools for Malay. In Proceedings of the 5th International Conference on Language Resources and Evaluation, LREC ’06, pages 2212–2215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Miles Osborne</author>
<author>Philipp Koehn</author>
</authors>
<title>CCG supertags in factored statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Second Workshop on Statistical Machine Translation, WMT ’07,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="23947" citStr="Birch et al., 2007" startWordPosition="3670" endWordPosition="3673">ns its original scores, which are further augmented with 1–3 additional feature scores indicating its origin: the first/second/third feature is 1 if the pair came from the first/second/both table(s), and 0 otherwise. We experiment using all three, the first two, or the first feature only; we also try setting the features to 0.5 instead of 0. This makes the following six combinations (0, 00, 000, .5, .5.5, .5.5.5); on testing, we use the one that achieves the highest BLEU score on the development set. Other possibilities for combining the phrase tables include using alternative decoding paths (Birch et al., 2007), simple linear interpolation, and direct phrase table merging with extra features (CallisonBurch et al., 2006); they were previously found inferior to the last two approaches above (Nakov and Ng, 2009; Nakov and Ng, 2012). 5 Experiments We run two kinds of experiments: (a) isolated, where we train on the synthetic “Indonesian”– English bi-text only, and (b) combined, where we combine it with the Indonesian–English bi-text. 5.1 Datasets In our experiments, we use the following datasets, normally required for Indonesian–English SMT: • Indonesian–English train bi-text (IN2EN): 28,383 sentence pa</context>
</contexts>
<marker>Birch, Osborne, Koehn, 2007</marker>
<rawString>Alexandra Birch, Miles Osborne, and Philipp Koehn. 2007. CCG supertags in factored statistical machine translation. In Proceedings of the Second Workshop on Statistical Machine Translation, WMT ’07, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of NAACL, HLTNAACL ’06,</booktitle>
<pages>17--24</pages>
<contexts>
<context position="13744" citStr="Callison-Burch et al., 2006" startWordPosition="2082" endWordPosition="2085"> to induce potential Indonesian translations for a given Malay word. First, we generate separate word-level alignments for the Indonesian–English and the Malay–English bi-texts. Then, we induce Indonesian-Malay word translation pairs assuming that if an Indonesian word i and a Malay word m are aligned to the same English word e, they could be mutual translations. Each translation pair is associated with a conditional probability, estimated by pivoting over English: J: Pr(i|m) = Pr(i|e)Pr(e|m) (1) e Pr(i|e) and Pr(e|m) are estimated using maximum likelihood from the word alignments. Following (Callison-Burch et al., 2006), we further assume that i is conditionally independent of m given e. 4.1.2 Confusion Network Construction Given a Malay sentence, we construct an Indonesian confusion network, where each Malay word is augmented with a set of network transitions: possible Indonesian word translations. The weight of such a transition is the conditional IndonesianMalay translation probability as calculated by Eq. 1; the original Malay word is assigned a weight of 1. Note that we paraphrase each word in the input Malay sentence as opposed to only those Malay words that we believe not to exist in Indonesian, e.g.,</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the Human Language Technology Conference of NAACL, HLTNAACL ’06, pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Machine translation by triangulation: Making effective use of multiparallel corpora.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, ACL ’07,</booktitle>
<pages>728--735</pages>
<contexts>
<context position="7914" citStr="Cohn and Lapata, 2007" startWordPosition="1181" endWordPosition="1184">ttempt language adaptation, except for very simple transliteration for Portuguese–Spanish that ignored context entirely; since it could not substitute one word for a completely different word, it did not help much for Malay–Indonesian, which use unified spelling. Still, once we have language-adapted the large bi-text, it makes sense to try to combine it further with the small bi-text; thus, below we will directly compare and combine these two approaches. Another alternative, which we do not explore in this work, is to use cascaded translation using a pivot language (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). Unfortunately, using the resource-rich language as a pivot (poor—*rich—*X) would require an additional parallel poor–rich bi-text, which we do not have. Pivoting over the target X (rich—*X—*poor) for the purpose of language adaptation, on the other hand, would miss the opportunity to exploit the relationship between the resource-poor and the resource-rich language; this would also be circular since the first step would ask an SMT system to translate its own training data (we only have one rich–X bi-text). 287 3 Malay and Indonesian Malay and Indonesian are closely related</context>
</contexts>
<marker>Cohn, Lapata, 2007</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2007. Machine translation by triangulation: Making effective use of multiparallel corpora. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics, ACL ’07, pages 728–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Philipp Koehn</author>
<author>Ivona Kuˇcerov´a</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, ACL ’05,</booktitle>
<pages>531--540</pages>
<marker>Collins, Koehn, Kuˇcerov´a, 2005</marker>
<rawString>Michael Collins, Philipp Koehn, and Ivona Kuˇcerov´a. 2005. Clause restructuring for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, ACL ’05, pages 531–540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Jan Hric</author>
<author>Vladislav Kuboˇn</author>
</authors>
<title>Machine translation of very close languages.</title>
<date>2000</date>
<booktitle>In Proceedings of the Sixth Conference on Applied Natural Language Processing, ANLP ’00,</booktitle>
<pages>7--12</pages>
<marker>Hajiˇc, Hric, Kuboˇn, 2000</marker>
<rawString>Jan Hajiˇc, Jan Hric, and Vladislav Kuboˇn. 2000. Machine translation of very close languages. In Proceedings of the Sixth Conference on Applied Natural Language Processing, ANLP ’00, pages 7–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalisation of short text messages: Makn sens a #twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, ACL-HLT ’11,</booktitle>
<pages>368--378</pages>
<contexts>
<context position="5583" citStr="Han and Baldwin, 2011" startWordPosition="819" endWordPosition="823">n the case of Arabic dialects, a further complication arises by the informal status of the dialects, which are not standardized and not used in formal contexts but rather only in informal online communities1 such as social networks, chats, Twitter and SMS messages. This causes further mismatch in domain and genre. Thus, translating from Arabic dialects to Modern Standard Arabic requires, among other things, normalizing informal text to a formal form. In fact, this is a more general problem, which arises with informal sources like SMS messages and Tweets for just any language (Aw et al., 2006; Han and Baldwin, 2011). Here the main focus is on coping with spelling errors, abbreviations, and slang, which are typically addressed using string edit distance, while also taking pronunciation into account. This is different from our task, where we try to adapt good, formal text from one language into another. A second relevant line of research is on language adaptation and normalization, when done specifically for improving SMT into another language. 1The Egyptian Wikipedia is one notable exception. For example, Marujo et al. (2011) described a rule-based system for adapting Brazilian Portuguese (BP) to European</context>
</contexts>
<marker>Han, Baldwin, 2011</marker>
<rawString>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: Makn sens a #twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, ACL-HLT ’11, pages 368–378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Alon Lavie</author>
</authors>
<title>Combining machine translation output with open source: The Carnegie Mellon multi-engine machine translation scheme.</title>
<date>2010</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics,</booktitle>
<volume>93</volume>
<issue>1</issue>
<contexts>
<context position="33124" citStr="Heafield and Lavie, 2010" startWordPosition="5009" endWordPosition="5012">of the small Indonesian vocabulary of the IN2EN bi-text. The lower part of Table 3 shows that phrase-level paraphrasing performs a bit better. This confirms the importance of modeling context for closely-related languages like Malay and Indonesian, which are rich in false friends and partial cognates. We further see that using more scores in the phrase table is better. Extending the Indonesian vocabulary with cross-lingual morphological variants is still helpful, though not as much as at the word-level. Finally, the combination of the output of the best PPT and the best CN systems using MEMT (Heafield and Lavie, 2010) yields even further improvements, which shows that the two kinds of paraphrases are complementary. The best overall BLEU score for our isolated experiments is 21.24, which is better than the results for all five baselines in Table 2, including the three bi-text combination baselines, which only achieve up to 20.10 BLEU. 6.3 Combined Experiments Table 4 shows the performance of the three bitext combination strategies (see Section 4.3 for additional details) when applied to combine IN2EN (1) with the original ML2EN and (2) with various adapted versions of it. We can see that for the word-level </context>
</contexts>
<marker>Heafield, Lavie, 2010</marker>
<rawString>Kenneth Heafield and Alon Lavie. 2010. Combining machine translation output with open source: The Carnegie Mellon multi-engine machine translation scheme. The Prague Bulletin of Mathematical Linguistics, 93(1):27–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luis Marujo</author>
<author>Nuno Grazina</author>
<author>Tiago Luis</author>
<author>Wang Ling</author>
<author>Luisa Coheur</author>
<author>Isabel Trancoso</author>
</authors>
<title>BP2EP -adaptation of Brazilian Portuguese texts to European Portuguese.</title>
<date>2011</date>
<booktitle>In Proceedings of the 15th Conference of the European Association for Machine Translation, EAMT ’11,</booktitle>
<pages>129--136</pages>
<contexts>
<context position="6102" citStr="Marujo et al. (2011)" startWordPosition="902" endWordPosition="905">l sources like SMS messages and Tweets for just any language (Aw et al., 2006; Han and Baldwin, 2011). Here the main focus is on coping with spelling errors, abbreviations, and slang, which are typically addressed using string edit distance, while also taking pronunciation into account. This is different from our task, where we try to adapt good, formal text from one language into another. A second relevant line of research is on language adaptation and normalization, when done specifically for improving SMT into another language. 1The Egyptian Wikipedia is one notable exception. For example, Marujo et al. (2011) described a rule-based system for adapting Brazilian Portuguese (BP) to European Portuguese (EP), which they used to adapt BP–English bi-texts to EP–English. They report small improvements in BLEU for EP–English translation when training on the adapted “EP”–En bi-text compared to using the unadapted BP–En (38.55 vs. 38.29), or when an EP–English bi-text is used in addition to the adapted/unadapted one (41.07 vs. 40.91 BLEU). Unlike this work, which heavily relied on language-specific rules, our approach is statistical, and largely language-independent; moreover, our improvements are much more</context>
</contexts>
<marker>Marujo, Grazina, Luis, Ling, Coheur, Trancoso, 2011</marker>
<rawString>Luis Marujo, Nuno Grazina, Tiago Luis, Wang Ling, Luisa Coheur, and Isabel Trancoso. 2011. BP2EP -adaptation of Brazilian Portuguese texts to European Portuguese. In Proceedings of the 15th Conference of the European Association for Machine Translation, EAMT ’11, pages 129–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Improved statistical machine translation for resource-poor languages using related resource-rich languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’09,</booktitle>
<pages>1358--1367</pages>
<contexts>
<context position="2395" citStr="Nakov and Ng, 2009" startWordPosition="327" endWordPosition="330">ource-rich language, with whom they overlap in vocabulary and share cognates, which offers opportunities for bi-text reuse. Example pairs of such resource rich–poor languages include Spanish–Catalan, Finnish–Estonian, Swedish–Norwegian, Russian–Ukrainian, Irish– Gaelic Scottish, Standard German–Swiss German, Modern Standard Arabic–Dialectical Arabic (e.g., Gulf, Egyptian), Turkish–Azerbaijani, etc. Previous work has already demonstrated the benefits of using a bi-text for a related resource-rich language to X (e.g., X=English) to improve machine translation from a resource-poor language to X (Nakov and Ng, 2009; Nakov and Ng, 2012). Here we take a different, orthogonal approach: we adapt the resource-rich language to get closer to the resource-poor one. We assume a small bi-text for the resource-poor language, which we use to learn word-level and phrase-level paraphrases and cross-lingual morphological variants between the two languages. Assuming translation into the same target language X, we adapt (the source side of) a large training bi-text for a related resource-rich language and X. Training on the adapted large bi-text yields very significant improvements in translation quality compared to bot</context>
<context position="6937" citStr="Nakov and Ng, 2009" startWordPosition="1028" endWordPosition="1031">slation when training on the adapted “EP”–En bi-text compared to using the unadapted BP–En (38.55 vs. 38.29), or when an EP–English bi-text is used in addition to the adapted/unadapted one (41.07 vs. 40.91 BLEU). Unlike this work, which heavily relied on language-specific rules, our approach is statistical, and largely language-independent; moreover, our improvements are much more sizable. A third relevant line of research is on reusing bitexts between related languages without or with very little adaptation, which works well for very closely related languages. For example, our previous work (Nakov and Ng, 2009; Nakov and Ng, 2012) experimented with various techniques for combining a small bi-text for a resource-poor language (Indonesian or Spanish, pretending that Spanish is resource-poor) with a much larger bi-text for a related resource-rich language (Malay or Portuguese); the target language of all bi-texts was English. However, our previous work did not attempt language adaptation, except for very simple transliteration for Portuguese–Spanish that ignored context entirely; since it could not substitute one word for a completely different word, it did not help much for Malay–Indonesian, which us</context>
<context position="22827" citStr="Nakov and Ng, 2009" startWordPosition="3481" endWordPosition="3484">an–English one, and now it has been further expanded n times in order to become an “Indonesian”–English bi-text, which means that it will dominate the concatenation due to its size. In order to counter-balance this, we repeat the smaller Indonesian–English bi-text enough times so that we can make the number of sentences it contains roughly the same as for the “Indonesian”–English bi-text; then we concatenate the two bi-texts and we train an SMT system on the resulting bi-text. Sophisticated phrase table combination. Finally, we experiment with a method for combining phrase tables proposed in (Nakov and Ng, 2009; Nakov and Ng, 2012). The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one copy of the Indonesian–English bi-text. The second table is built from the simple concatenation. The two tables are then merged as follows: all phrase pairs from the first one are retained, and to them are added those phrase pairs from the second one that are not present in the first one. Each phrase pair retains its original scores, which are further augmented with 1–3 additional feature scores indicating i</context>
<context position="24148" citStr="Nakov and Ng, 2009" startWordPosition="3702" endWordPosition="3705">d 0 otherwise. We experiment using all three, the first two, or the first feature only; we also try setting the features to 0.5 instead of 0. This makes the following six combinations (0, 00, 000, .5, .5.5, .5.5.5); on testing, we use the one that achieves the highest BLEU score on the development set. Other possibilities for combining the phrase tables include using alternative decoding paths (Birch et al., 2007), simple linear interpolation, and direct phrase table merging with extra features (CallisonBurch et al., 2006); they were previously found inferior to the last two approaches above (Nakov and Ng, 2009; Nakov and Ng, 2012). 5 Experiments We run two kinds of experiments: (a) isolated, where we train on the synthetic “Indonesian”– English bi-text only, and (b) combined, where we combine it with the Indonesian–English bi-text. 5.1 Datasets In our experiments, we use the following datasets, normally required for Indonesian–English SMT: • Indonesian–English train bi-text (IN2EN): 28,383 sentence pairs; 915,192 English tokens; 796,787 Indonesian tokens; • Indon.–English dev bi-text (IN2EN-dev): 2,000 sentence pairs; 36,584 English tokens; 35,708 Indonesian tokens; • Indon.–English test bi-text (I</context>
</contexts>
<marker>Nakov, Ng, 2009</marker>
<rawString>Preslav Nakov and Hwee Tou Ng. 2009. Improved statistical machine translation for resource-poor languages using related resource-rich languages. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’09, pages 1358–1367.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Translating from morphologically complex languages: A paraphrase-based approach.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, ACL-HLT ’11,</booktitle>
<pages>1298--1307</pages>
<contexts>
<context position="20532" citStr="Nakov and Ng, 2011" startWordPosition="3142" endWordPosition="3145">iants, relying on the Indonesian language model to make the right contextual choice. We also try to model context more directly by generating adaptation options at the phrase level. 7While the different morphological forms typically have different meanings, e.g., minum (‘drink’) vs. peminum (‘drinker’), in some cases the forms could have the same translation in English, e.g., minum (‘drink’, verb) vs. minuman (‘drink’, noun). This is our motivation for trying morphological variants, even though they are almost exclusively derivational, and thus quite risky as translational variants; see also (Nakov and Ng, 2011). Phrase-level paraphrase induction. We use standard phrase-based SMT techniques to build separate phrase tables for the Indonesian–English and the Malay–English bi-texts, where we have four conditional probabilities: forward/reverse phrase translation probability, and forward/reverse lexicalized phrase translation probability. We pivot over English to generate Indonesian-Malay phrase pairs, whose probabilities are derived from the corresponding ones in the two phrase tables using Eq. 1. Cross-lingual morphological variants. While phrase-level paraphrasing models context better, it remains lim</context>
</contexts>
<marker>Nakov, Ng, 2011</marker>
<rawString>Preslav Nakov and Hwee Tou Ng. 2011. Translating from morphologically complex languages: A paraphrase-based approach. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, ACL-HLT ’11, pages 1298–1307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Hwee Tou Ng</author>
</authors>
<title>Improving statistical machine translation for a resource-poor language using related resource-rich languages.</title>
<date>2012</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>44--179</pages>
<contexts>
<context position="2416" citStr="Nakov and Ng, 2012" startWordPosition="331" endWordPosition="334"> with whom they overlap in vocabulary and share cognates, which offers opportunities for bi-text reuse. Example pairs of such resource rich–poor languages include Spanish–Catalan, Finnish–Estonian, Swedish–Norwegian, Russian–Ukrainian, Irish– Gaelic Scottish, Standard German–Swiss German, Modern Standard Arabic–Dialectical Arabic (e.g., Gulf, Egyptian), Turkish–Azerbaijani, etc. Previous work has already demonstrated the benefits of using a bi-text for a related resource-rich language to X (e.g., X=English) to improve machine translation from a resource-poor language to X (Nakov and Ng, 2009; Nakov and Ng, 2012). Here we take a different, orthogonal approach: we adapt the resource-rich language to get closer to the resource-poor one. We assume a small bi-text for the resource-poor language, which we use to learn word-level and phrase-level paraphrases and cross-lingual morphological variants between the two languages. Assuming translation into the same target language X, we adapt (the source side of) a large training bi-text for a related resource-rich language and X. Training on the adapted large bi-text yields very significant improvements in translation quality compared to both (a) training on the</context>
<context position="6958" citStr="Nakov and Ng, 2012" startWordPosition="1032" endWordPosition="1035">g on the adapted “EP”–En bi-text compared to using the unadapted BP–En (38.55 vs. 38.29), or when an EP–English bi-text is used in addition to the adapted/unadapted one (41.07 vs. 40.91 BLEU). Unlike this work, which heavily relied on language-specific rules, our approach is statistical, and largely language-independent; moreover, our improvements are much more sizable. A third relevant line of research is on reusing bitexts between related languages without or with very little adaptation, which works well for very closely related languages. For example, our previous work (Nakov and Ng, 2009; Nakov and Ng, 2012) experimented with various techniques for combining a small bi-text for a resource-poor language (Indonesian or Spanish, pretending that Spanish is resource-poor) with a much larger bi-text for a related resource-rich language (Malay or Portuguese); the target language of all bi-texts was English. However, our previous work did not attempt language adaptation, except for very simple transliteration for Portuguese–Spanish that ignored context entirely; since it could not substitute one word for a completely different word, it did not help much for Malay–Indonesian, which use unified spelling. S</context>
<context position="22848" citStr="Nakov and Ng, 2012" startWordPosition="3485" endWordPosition="3488">now it has been further expanded n times in order to become an “Indonesian”–English bi-text, which means that it will dominate the concatenation due to its size. In order to counter-balance this, we repeat the smaller Indonesian–English bi-text enough times so that we can make the number of sentences it contains roughly the same as for the “Indonesian”–English bi-text; then we concatenate the two bi-texts and we train an SMT system on the resulting bi-text. Sophisticated phrase table combination. Finally, we experiment with a method for combining phrase tables proposed in (Nakov and Ng, 2009; Nakov and Ng, 2012). The first phrase table is extracted from word alignments for the balanced concatenation with repetitions, which are then truncated so that they are kept for only one copy of the Indonesian–English bi-text. The second table is built from the simple concatenation. The two tables are then merged as follows: all phrase pairs from the first one are retained, and to them are added those phrase pairs from the second one that are not present in the first one. Each phrase pair retains its original scores, which are further augmented with 1–3 additional feature scores indicating its origin: the first/</context>
<context position="24169" citStr="Nakov and Ng, 2012" startWordPosition="3706" endWordPosition="3709">periment using all three, the first two, or the first feature only; we also try setting the features to 0.5 instead of 0. This makes the following six combinations (0, 00, 000, .5, .5.5, .5.5.5); on testing, we use the one that achieves the highest BLEU score on the development set. Other possibilities for combining the phrase tables include using alternative decoding paths (Birch et al., 2007), simple linear interpolation, and direct phrase table merging with extra features (CallisonBurch et al., 2006); they were previously found inferior to the last two approaches above (Nakov and Ng, 2009; Nakov and Ng, 2012). 5 Experiments We run two kinds of experiments: (a) isolated, where we train on the synthetic “Indonesian”– English bi-text only, and (b) combined, where we combine it with the Indonesian–English bi-text. 5.1 Datasets In our experiments, we use the following datasets, normally required for Indonesian–English SMT: • Indonesian–English train bi-text (IN2EN): 28,383 sentence pairs; 915,192 English tokens; 796,787 Indonesian tokens; • Indon.–English dev bi-text (IN2EN-dev): 2,000 sentence pairs; 36,584 English tokens; 35,708 Indonesian tokens; • Indon.–English test bi-text (IN2EN-test): 2,018 sen</context>
</contexts>
<marker>Nakov, Ng, 2012</marker>
<rawString>Preslav Nakov and Hwee Tou Ng. 2012. Improving statistical machine translation for a resource-poor language using related resource-rich languages. Journal ofArtificial Intelligence Research, 44:179–222.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>J¨org Tiedemann</author>
</authors>
<title>Combining word-level and character-level models for machine translation between closely-related languages.</title>
<date>2012</date>
<booktitle>In Proceedings ofthe 50th Annual Meeting of the Association for Computational Linguistics, ACL-Short ’12.</booktitle>
<contexts>
<context position="4344" citStr="Nakov and Tiedemann, 2012" startWordPosition="615" endWordPosition="618">tional Linguistics 2 Related Work One relevant line of research is on machine translation between closely related languages, which is arguably simpler than general SMT, and thus can be handled using word-for-word translation, manual language-specific rules that take care of the necessary morphological and syntactic transformations, or character-level translation/transliteration. This has been tried for a number of language pairs including Czech–Slovak (Hajiˇc et al., 2000), Turkish– Crimean Tatar (Altintas and Cicekli, 2002), Irish– Scottish Gaelic (Scannell, 2006), and Bulgarian– Macedonian (Nakov and Tiedemann, 2012). In contrast, we have a different objective – we do not carry out full translation but rather adaptation since our ultimate goal is to translate into a third language X. A special case of this same line of research is the translation between dialects of the same language, e.g., between Cantonese and Mandarin (Zhang, 1998), or between a dialect of a language and a standard version of that language, e.g., between some Arabic dialect (e.g., Egyptian) and Modern Standard Arabic (Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Here again, manual rules and/or language-specific tools are </context>
</contexts>
<marker>Nakov, Tiedemann, 2012</marker>
<rawString>Preslav Nakov and J¨org Tiedemann. 2012. Combining word-level and character-level models for machine translation between closely-related languages. In Proceedings ofthe 50th Annual Meeting of the Association for Computational Linguistics, ACL-Short ’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="28561" citStr="Papineni et al., 2002" startWordPosition="4352" endWordPosition="4355">eline. System BLEU ML2EI 14.50 II2EI 18.67 Simple concatenation 18.49 Balanced concatenation 19.79 Sophisticated phrase table combination 20.10(.5.5) Table 2: The five baselines. The subscript indicates the parameters found on II2EI-dev and used for II2EI-test. The scores that are statistically significantly better than ML2EI and II2EI (p &lt; 0.01, Collins’ sign test) are shown in bold and are underlined, respectively. 6.1 Baseline Experiments The results for the baseline systems are shown in Table 2. We can see that training on ML2EI instead of II2EI yields over 4 points absolute drop in BLEU (Papineni et al., 2002) score, even though ML2EI is about 10 times larger than II2EI and both bi-texts are from the same domain. This confirms the existence of important differences between Malay and Indonesian. While simple concatenation does not help, balanced concatenation with repetitions improves by 1.12 BLEU points over II2EI, which shows the importance of giving II2EI a proper weight in the combined bi-text. This is further reconfirmed by the sophisticated phrase table combination, which yields an additional absolute gain of 0.31 BLEU points. 6.2 Isolated Experiments Table 3 shows the results for the isolated</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, ACL ’02, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Ristad</author>
<author>Peter Yianilos</author>
</authors>
<title>Learning stringedit distance.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="19697" citStr="Ristad and Yianilos, 1998" startWordPosition="3014" endWordPosition="3018">8 pada|1.0 tahun|1.0 2010|1.0 .|1.0 5 6 7 8 9 10 per|0.148886 The union of these groups is the set of morphological variants that we will add to the confusion network as additional options for the Malay word.7 For example, given seperminuman (‘drinking’) in the Malay input, we first find its stem minum, and then we get the above example set of Indonesian words, which contains some reasonable substitutes such as minuman (‘drink’). In the confusion network, the weight of the original Malay word is set to 1, while the weight of a morphological option is one minus the minimum edit distance ratio (Ristad and Yianilos, 1998) between it and the Malay word, multiplied by the highest probability for all pivoting variants for the Malay word. 4.2 Phrase-Level Paraphrasing Word-level paraphrasing ignores context when generating Indonesian variants, relying on the Indonesian language model to make the right contextual choice. We also try to model context more directly by generating adaptation options at the phrase level. 7While the different morphological forms typically have different meanings, e.g., minum (‘drink’) vs. peminum (‘drinker’), in some cases the forms could have the same translation in English, e.g., minum</context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>Eric Ristad and Peter Yianilos. 1998. Learning stringedit distance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(5):522–532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal to Standard Arabic paraphrasing to improve ArabicEnglish statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proc. of the Workshop on Algorithms and Resources</booktitle>
<pages>10--21</pages>
<contexts>
<context position="4882" citStr="Salloum and Habash, 2011" startWordPosition="707" endWordPosition="710">Scottish Gaelic (Scannell, 2006), and Bulgarian– Macedonian (Nakov and Tiedemann, 2012). In contrast, we have a different objective – we do not carry out full translation but rather adaptation since our ultimate goal is to translate into a third language X. A special case of this same line of research is the translation between dialects of the same language, e.g., between Cantonese and Mandarin (Zhang, 1998), or between a dialect of a language and a standard version of that language, e.g., between some Arabic dialect (e.g., Egyptian) and Modern Standard Arabic (Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Here again, manual rules and/or language-specific tools are typically used. In the case of Arabic dialects, a further complication arises by the informal status of the dialects, which are not standardized and not used in formal contexts but rather only in informal online communities1 such as social networks, chats, Twitter and SMS messages. This causes further mismatch in domain and genre. Thus, translating from Arabic dialects to Modern Standard Arabic requires, among other things, normalizing informal text to a formal form. In fact, this is a more general problem, which arises with informa</context>
</contexts>
<marker>Salloum, Habash, 2011</marker>
<rawString>Wael Salloum and Nizar Habash. 2011. Dialectal to Standard Arabic paraphrasing to improve ArabicEnglish statistical machine translation. In Proc. of the Workshop on Algorithms and Resources for Modelling ofDialects and Language Varieties, pages 10–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sawaf</author>
</authors>
<title>Arabic dialect handling in hybrid machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 9th Conference of the Association for Machine Translation in the Americas, AMTA ’09.</booktitle>
<contexts>
<context position="4855" citStr="Sawaf, 2010" startWordPosition="705" endWordPosition="706">002), Irish– Scottish Gaelic (Scannell, 2006), and Bulgarian– Macedonian (Nakov and Tiedemann, 2012). In contrast, we have a different objective – we do not carry out full translation but rather adaptation since our ultimate goal is to translate into a third language X. A special case of this same line of research is the translation between dialects of the same language, e.g., between Cantonese and Mandarin (Zhang, 1998), or between a dialect of a language and a standard version of that language, e.g., between some Arabic dialect (e.g., Egyptian) and Modern Standard Arabic (Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Here again, manual rules and/or language-specific tools are typically used. In the case of Arabic dialects, a further complication arises by the informal status of the dialects, which are not standardized and not used in formal contexts but rather only in informal online communities1 such as social networks, chats, Twitter and SMS messages. This causes further mismatch in domain and genre. Thus, translating from Arabic dialects to Modern Standard Arabic requires, among other things, normalizing informal text to a formal form. In fact, this is a more general problem</context>
</contexts>
<marker>Sawaf, 2010</marker>
<rawString>Hassan Sawaf. 2010. Arabic dialect handling in hybrid machine translation. In Proceedings of the 9th Conference of the Association for Machine Translation in the Americas, AMTA ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin P Scannell</author>
</authors>
<title>Machine translation for closely related language pairs.</title>
<date>2006</date>
<booktitle>In Proceedings of the LREC 2006 Workshop on Strategies for Developing Machine Translation for Minority Languages.</booktitle>
<contexts>
<context position="4289" citStr="Scannell, 2006" startWordPosition="610" endWordPosition="611">14 July 2012. c�2012 Association for Computational Linguistics 2 Related Work One relevant line of research is on machine translation between closely related languages, which is arguably simpler than general SMT, and thus can be handled using word-for-word translation, manual language-specific rules that take care of the necessary morphological and syntactic transformations, or character-level translation/transliteration. This has been tried for a number of language pairs including Czech–Slovak (Hajiˇc et al., 2000), Turkish– Crimean Tatar (Altintas and Cicekli, 2002), Irish– Scottish Gaelic (Scannell, 2006), and Bulgarian– Macedonian (Nakov and Tiedemann, 2012). In contrast, we have a different objective – we do not carry out full translation but rather adaptation since our ultimate goal is to translate into a third language X. A special case of this same line of research is the translation between dialects of the same language, e.g., between Cantonese and Mandarin (Zhang, 1998), or between a dialect of a language and a standard version of that language, e.g., between some Arabic dialect (e.g., Egyptian) and Modern Standard Arabic (Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Here </context>
</contexts>
<marker>Scannell, 2006</marker>
<rawString>Kevin P. Scannell. 2006. Machine translation for closely related language pairs. In Proceedings of the LREC 2006 Workshop on Strategies for Developing Machine Translation for Minority Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
</authors>
<title>News from OPUS - a collection of multilingual parallel corpora with tools and interfaces.</title>
<date>2009</date>
<booktitle>In Recent Advances in Natural Language Processing,</booktitle>
<volume>volume V,</volume>
<pages>237--248</pages>
<contexts>
<context position="38578" citStr="Tiedemann, 2009" startWordPosition="5871" endWordPosition="5872">ot uses both n-best outputs and an Indonesian LM; designing a similar setup for reversed adaptation is a research direction we would like to pursue in future work. 294 System BLEU CI:pivot (Malay→Indonesian) 18.91(0.005,10best) CI:pivot (Indonesian→Malay) – lattice 17.22(0.05) CI:pivot (Indonesian→Malay) – 1-best 17.77(0.001) Table 7: Reversed adaptation: Indonesian to Malay. Adapting Macedonian to Bulgarian. We experimented with another pair of closely-related languages,8 Macedonian (MK) and Bulgarian (BG), using data from a different, non-newswire domain: the OPUS corpus of movie subtitles (Tiedemann, 2009). We used datasets of sizes that are comparable to those in the previous experiments: 160K MK2EI and 1.5M BG2EI sentence pairs (1.2M and 11.5M EI words). Since the sentences were short, we used 10K MK2EI sentence pairs for tuning and testing (77K and 72K English words). For the LM, we used 9.2M Macedonian and 433M English words. Table 8 shows that both CI:* and PPT:* yield statistically significant improvements over balanced concatenation with unadapted BG2EI; system combination with MEMT improves even further. This indicates that our approach can work for other pairs of related languages and </context>
</contexts>
<marker>Tiedemann, 2009</marker>
<rawString>J¨org Tiedemann. 2009. News from OPUS - a collection of multilingual parallel corpora with tools and interfaces. In Recent Advances in Natural Language Processing, volume V, pages 237–248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A comparison of pivot methods for phrase-based statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the Human Language Technology Conference of NAACL, HLTNAACL ’07,</booktitle>
<pages>484--491</pages>
<contexts>
<context position="7891" citStr="Utiyama and Isahara, 2007" startWordPosition="1177" endWordPosition="1180">our previous work did not attempt language adaptation, except for very simple transliteration for Portuguese–Spanish that ignored context entirely; since it could not substitute one word for a completely different word, it did not help much for Malay–Indonesian, which use unified spelling. Still, once we have language-adapted the large bi-text, it makes sense to try to combine it further with the small bi-text; thus, below we will directly compare and combine these two approaches. Another alternative, which we do not explore in this work, is to use cascaded translation using a pivot language (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). Unfortunately, using the resource-rich language as a pivot (poor—*rich—*X) would require an additional parallel poor–rich bi-text, which we do not have. Pivoting over the target X (rich—*X—*poor) for the purpose of language adaptation, on the other hand, would miss the opportunity to exploit the relationship between the resource-poor and the resource-rich language; this would also be circular since the first step would ask an SMT system to translate its own training data (we only have one rich–X bi-text). 287 3 Malay and Indonesian Malay and Indones</context>
</contexts>
<marker>Utiyama, Isahara, 2007</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2007. A comparison of pivot methods for phrase-based statistical machine translation. In Proceedings of the Human Language Technology Conference of NAACL, HLTNAACL ’07, pages 484–491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
</authors>
<title>Revisiting pivot language approach for machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL, ACL ’09,</booktitle>
<pages>154--162</pages>
<contexts>
<context position="7934" citStr="Wu and Wang, 2009" startWordPosition="1185" endWordPosition="1188">ion, except for very simple transliteration for Portuguese–Spanish that ignored context entirely; since it could not substitute one word for a completely different word, it did not help much for Malay–Indonesian, which use unified spelling. Still, once we have language-adapted the large bi-text, it makes sense to try to combine it further with the small bi-text; thus, below we will directly compare and combine these two approaches. Another alternative, which we do not explore in this work, is to use cascaded translation using a pivot language (Utiyama and Isahara, 2007; Cohn and Lapata, 2007; Wu and Wang, 2009). Unfortunately, using the resource-rich language as a pivot (poor—*rich—*X) would require an additional parallel poor–rich bi-text, which we do not have. Pivoting over the target X (rich—*X—*poor) for the purpose of language adaptation, on the other hand, would miss the opportunity to exploit the relationship between the resource-poor and the resource-rich language; this would also be circular since the first step would ask an SMT system to translate its own training data (we only have one rich–X bi-text). 287 3 Malay and Indonesian Malay and Indonesian are closely related, mutually intelligi</context>
</contexts>
<marker>Wu, Wang, 2009</marker>
<rawString>Hua Wu and Haifeng Wang. 2009. Revisiting pivot language approach for machine translation. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL, ACL ’09, pages 154–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoheng Zhang</author>
</authors>
<title>Dialect MT: a case study between Cantonese and Mandarin.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics, COLING ’98,</booktitle>
<pages>1460--1464</pages>
<contexts>
<context position="4668" citStr="Zhang, 1998" startWordPosition="673" endWordPosition="674">haracter-level translation/transliteration. This has been tried for a number of language pairs including Czech–Slovak (Hajiˇc et al., 2000), Turkish– Crimean Tatar (Altintas and Cicekli, 2002), Irish– Scottish Gaelic (Scannell, 2006), and Bulgarian– Macedonian (Nakov and Tiedemann, 2012). In contrast, we have a different objective – we do not carry out full translation but rather adaptation since our ultimate goal is to translate into a third language X. A special case of this same line of research is the translation between dialects of the same language, e.g., between Cantonese and Mandarin (Zhang, 1998), or between a dialect of a language and a standard version of that language, e.g., between some Arabic dialect (e.g., Egyptian) and Modern Standard Arabic (Bakr et al., 2008; Sawaf, 2010; Salloum and Habash, 2011). Here again, manual rules and/or language-specific tools are typically used. In the case of Arabic dialects, a further complication arises by the informal status of the dialects, which are not standardized and not used in formal contexts but rather only in informal online communities1 such as social networks, chats, Twitter and SMS messages. This causes further mismatch in domain an</context>
</contexts>
<marker>Zhang, 1998</marker>
<rawString>Xiaoheng Zhang. 1998. Dialect MT: a case study between Cantonese and Mandarin. In Proceedings of the 17th International Conference on Computational Linguistics, COLING ’98, pages 1460–1464.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>