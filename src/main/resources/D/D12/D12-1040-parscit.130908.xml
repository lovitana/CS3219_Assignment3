<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.999235">
Unsupervised PCFG Induction for Grounded Language Learning
with Highly Ambiguous Supervision
</title>
<author confidence="0.999603">
Joohyun Kim Raymond J. Mooney
</author>
<affiliation confidence="0.9998395">
Department of Computer Science
The University of Texas at Austin
</affiliation>
<address confidence="0.9833095">
1616 Guadalupe, Suite 2.408
Austin, TX 78701, USA
</address>
<email confidence="0.999848">
{scimitar,mooney}@cs.utexas.edu
</email>
<sectionHeader confidence="0.998604" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999336631578947">
“Grounded” language learning employs train-
ing data in the form of sentences paired with
relevant but ambiguous perceptual contexts.
B¨orschinger et al. (2011) introduced an ap-
proach to grounded language learning based
on unsupervised PCFG induction. Their ap-
proach works well when each sentence po-
tentially refers to one of a small set of pos-
sible meanings, such as in the sportscasting
task. However, it does not scale to prob-
lems with a large set of potential meanings
for each sentence, such as the navigation in-
struction following task studied by Chen and
Mooney (2011). This paper presents an en-
hancement of the PCFG approach that scales
to such problems with highly-ambiguous su-
pervision. Experimental results on the naviga-
tion task demonstrates the effectiveness of our
approach.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999910521739131">
The ultimate goal of “grounded” language learning
is to develop computational systems that can acquire
language more like a human child. Given only su-
pervision in the form of sentences paired with rel-
evant but ambiguous perceptual contexts, a system
should learn to interpret and/or generate language
describing situations and events in the world. For
example, systems have learned to commentate sim-
ulated robot soccer games by learning from sample
sportscasts (Chen and Mooney, 2008; Liang et al.,
2009; B¨orschinger et al., 2011), or understand nav-
igation instructions by learning from action traces
produced when following the directions (Chen and
Mooney, 2011; Tellex et al., 2011).
B¨orschinger et al. (2011) recently introduced an
approach to grounded language learning using un-
supervised induction of probabilistic context free
grammars (PCFGs) to learn from ambiguous con-
textual supervision. Their approach first constructs
a large set of production rules from sentences paired
with descriptions of their ambiguous context, and
then trains the parameters of this grammar using
EM. Parsing a novel sentence with this grammar
gives a parse tree which contains the formal mean-
ing representation (MR) for this sentence. This ap-
proach works quite well on the sportscasting task
originally introduced by Chen and Mooney (2008).
In this task, each sentence in a natural-language
commentary describing activity in a simulated robot
soccer game is paired with the small set of actions
observed within the past 5 seconds, one of which
is usually described by the sentence. Even with this
low level of ambiguity in a constrained domain, their
method constructs a PCFG with about 33,000 pro-
ductions. More fundamentally, their approach is re-
stricted to a finite set of potential meaning represen-
tations, and the grammar size grows at least linearly
with the number of possible MRs, which in turn is
inevitably exponential in the number of objects and
actions in the domain.
The navigation task studied by Chen and Mooney
(2011) provides much more ambiguous supervision.
In this task, each instructional sentence is paired
with a formal landmarks plan (represented as a
large graph) that includes a full description of the
observed actions and world-states that result when
</bodyText>
<page confidence="0.992057">
433
</page>
<note confidence="0.8099405">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 433–444, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999871659090909">
someone follows this instruction. An instruction
generally refers to a subgraph of this large graph.
Therefore, there are a combinatorial number of pos-
sible meanings to which a given sentence can refer.
Chen and Mooney (2011) circumvent this combi-
natorial problem by never explicitly enumerating the
exponential number of potential meanings for each
sentence. Their system first induces a semantic lex-
icon that maps words and short phrases to formal
representations of actions and objects in the world.
This lexicon is learned by finding words and phrases
whose occurrence highly correlates with specific ob-
served actions and objects in the simulated environ-
ment when executing the corresponding instruction.
This learned lexicon is then used to directly infer
a formal MR for observed instructional sentences
using a greedy covering algorithm. These inferred
MRs are then used to train a supervised semantic
parser capable of mapping novel sentences to their
formal meanings.
We present a novel enhancement of B¨orschinger
et al.’s PCFG approach that uses Chen and Mooney’s
lexicon learner to avoid a combinatorial explosion in
the number of productions. The learned lexicon is
first used to build a hierarchy of semantic lexemes
(i.e. lexicon entries) called the Lexeme Hierarchy
Graph (LHG) for each ambiguous landmarks plan
in the training data. The intuition behind utilizing
an LHG is that the MR for each lexeme constitutes a
semantic concept that corresponds to some natural-
language (NL) word or phrase. Therefore, the LHG
represents how complex semantic concepts are com-
posed of simpler semantic concepts and ultimately
connected to NL words and phrases. B¨orschinger
et al.’s approach instead produces NL groundings at
the level of atomic MR constituents, which causes
an explosion in the number of PCFG productions
for complex MR languages. We estimated that
B¨orschinger et al.’s approach would require more
than 20! (&gt; 1018) productions for our navigation
problem.1 On the other hand, our method, which
uses correspondences from the LHG at the seman-
tic concept level, constructs a more focused PCFG
of tractable size. It then extracts the MR for a novel
</bodyText>
<footnote confidence="0.971708">
1The corpus contains quite a few examples with landmarks
plans containing more than 20 actions. This results in at least
20! permutations representing possible alignments between ac-
tions and NL words.
</footnote>
<bodyText confidence="0.999928777777778">
sentence from the most-probable parse tree for the
resulting PCFG. Our approach can produce a large,
combinatorial number of different MRs for a wide
range of novel sentences by composing relevant MR
components from the resulting parse tree, whereas
B¨orschinger et al.’s approach is only able to output
MRs that are explicitly included as a nonterminals
in the original learned PCFG.
The remainder of the paper is organized as fol-
lows. Section 2 reviews B¨orschinger et al.’s PCFG
approach as well as the navigation task and data.
Section 3 describes our enhanced PCFG approach
and Section 4 presents an experimental evaluation
of it. Then, Section 5 discusses the unique aspects
of our approach and Section 6 describes additional
related work. Finally, Section 7 presents future re-
search directions and Section 8 gives our conclu-
sions.
</bodyText>
<sectionHeader confidence="0.998763" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.999477">
2.1 Existing PCFG Approach
</subsectionHeader>
<bodyText confidence="0.999986884615385">
Our approach extends that of B¨orschinger et al.
(2011), which in turn was inspired by a series of
previous techniques (Lu et al., 2008; Liang et al.,
2009; Kim and Mooney, 2010) following the idea
of constructing correspondences between NL and
MR in a single probabilistic generative framework.
Particularly, their approach automatically constructs
a PCFG that generates NL sentences from MRs,
which indicates how atomic MR constituents are
probabilistically related to NL words. The nonter-
minals in the grammar correspond to complete MRs,
MR constituents, and NL phrases. The nontermi-
nal for a composite MR generates each of its MR
constituents, and each atomic MR, x, generates an
NL phrase, Phrasex. Each Phrasex then gener-
ates a sequence of Wordx’s for describing x, and
each Wordx can generate each possible word in the
natural language. This allows the system to learn
the words and phrases used to describe each atomic
MR by properly weighting these rules. Figure 1
shows one possible derivation tree for a sample NL-
MR pair and the PCFG rules that are constructed for
it. Once a set of productions are assembled, their
probabilities are learned using the Inside-Outside al-
gorithm. Computing the most probable parse for a
novel sentence with the trained PCFG provides its
</bodyText>
<page confidence="0.999382">
434
</page>
<figureCaption confidence="0.9473374">
Figure 1: Derivation tree for the NL/MR pair: THE
PINK GOALIE PASSES THE BALL TO PINK11 /
pass(pink1, pink11). Left side shows PCFG rules
that are added for each stage (full MR to atomic
MRs, and atomic MRs to NL words).
</figureCaption>
<bodyText confidence="0.962440705882353">
preferred MR interpretation in the topmost nonter-
minal.
Unfortunately, as discussed earlier, this approach
only works for finite MR languages, and the gram-
mar becomes intractably large even for finite but
complex MRs. It effectively assumes that MRs are
fairly small and includes every possible MR con-
stituent as a nonterminal in the PCFG. This is not
tractable for more complex MRs. Therefore, our ex-
tension incorporates a learned lexicon to constrain
the space of productions, thereby making the size
of the PCFG tractable for complex MRs, and even
giving it the ability to handle infinite MR languages.
Moreover, when processing novel sentences, our ap-
proach can produce a large space of novel MRs that
were not anticipated during training, which is not the
case for B¨orschinger et al.’s approach.
</bodyText>
<subsectionHeader confidence="0.999957">
2.2 Navigation Task and Dataset
</subsectionHeader>
<bodyText confidence="0.997343333333333">
We employ the task and data introduced by Chen and
Mooney (2011) whose goal is to interpret and follow
NL navigation instructions in a virtual world. Fig-
ure 2 shows a sample execution path in a particular
virtual world. The challenge is learning to perform
this task by simply observing humans following in-
structions. Formally, given training data of the form
{(el, al, wi), ... , (en, an, wn)1, where ei is an NL
instruction, ai is an observed action sequence, and
wi is the current world state (patterns of floors and
walls, positions of any objects, etc.), we want to pro-
duce the correct actions aj for a novel (ej, wj).
</bodyText>
<figureCaption confidence="0.998650714285714">
Figure 2: Sample virtual world from Chen and
Mooney (2011) of interconnecting hallways with
different floor and wall patterns and objects indi-
cated by letters (e.g. “H” for hatrack).
Figure 3: Sample instruction with its constructed
landmarks plan, components in bold compose the
correct plan.
</figureCaption>
<bodyText confidence="0.999860470588235">
In order to learn, their system infers the intended
formal plan pi (the MR for a sentence) which pro-
duced the action sequence ai from the instruction ei.
However, there is a large space of possible plans for
any given action sequence. Chen and Mooney first
construct a formal landmarks plan, ci, for each ai,
which is a graph representing the context of every
action and the world-state encountered during the
execution of the sequence. The correct plan MR,
pi, is assumed to be a subgraph of ci, and this causes
a combinatorial matching problem between ei and
ci in order to learn the correct meaning of ei among
all the possible subgraphs of ci. The landmarks and
correct plans for a sample instruction are shown in
Figure 3, illustrating the complexity of the MRs.
Instead of directly solving the combinatorial cor-
respondence problem, they first learn a semantic lex-
</bodyText>
<page confidence="0.998886">
435
</page>
<figureCaption confidence="0.687399666666667">
Figure 4: An overview of Chen and Mooney
(2011)’s system. Our method replaces the plan re-
finement and semantic parser parts.
</figureCaption>
<bodyText confidence="0.999784185185185">
icon that maps words and short phrases to small sub-
graphs representing their inferred meanings from the
(ei, ci) pairs. The lexicon is learned by evaluating
pairs of n-grams, wj, and MR graphs, mj, and scor-
ing them based on how much more likely mj is a
subgraph of the context ci when w occurs in the
corresponding instruction ei. This process is simi-
lar to other “cross-situational” approaches to learn-
ing word meanings (Siskind, 1996; Thompson and
Mooney, 2003). Then, a plan refinement step esti-
mates pi from ci by greedily selecting high-scoring
lexemes of the form (wj, mj) whose words and
phrases (wj) cover the instruction ei and introduce
components (mj) from the landmarks plan ci. The
refined plans are used to construct supervised train-
ing data (ei, pi) for a supervised semantic-parser
learner. The trained semantic parser can parse a
novel instruction into a formal plan, which is finally
executed for end-to-end evaluation. Figure 4 illus-
trates the overall system.
As this figure indicates, our new PCFG method
replaces the plan refinement and semantic parser
components in their system with a unified model
that both disambiguates the training data and learns
a semantic parser. We use the landmarks plans and
the learned lexicon produced by Chen and Mooney
(2011) as inputs to our system.2
</bodyText>
<footnote confidence="0.7526335">
2In our experiments, we used the top 1,000 lexemes learned
by Chen and Mooney (2011).
</footnote>
<sectionHeader confidence="0.987394" genericHeader="method">
3 Our PCFG Approach
</sectionHeader>
<bodyText confidence="0.99996164516129">
Like B¨orschinger et al. (2011), our approach learns
a semantic parser directly from ambiguous su-
pervision, specifically NL instructions paired with
their complete landmarks plans as context. Our
method incorporates the semantic lexemes as build-
ing blocks to find correspondences between NL
words and semantic concepts represented by the lex-
eme MRs, instead of building connections between
NL words and every possible MR constituent as in
B¨orschinger et al.’s approach. Particularly, we uti-
lize the hierarchical subgraph relationships between
the MRs in the learned semantic lexicon to produce
a smaller, more focused set of PCFG rules.3 The
intuition behind our approach is analogous to the hi-
erarchical relations between nonterminals in syntac-
tic parsing, where higher-level categories such as S,
VP, or NP are further divided into smaller categories
such as V, N, or Det, thereby forming a hierarchi-
cal structure. Inspired by this idea, we introduce a
directed acyclic graph called the Lexeme Hierarchy
Graph (LHG) which represents the hierarchical rela-
tionships between lexeme MRs. Since complex lex-
eme MRs represent complicated semantic concepts
while simple MRs represent simple concepts, it is
natural to construct a hierarchy amongst them. The
LHGs for all of the training examples are used to
construct production rules for the PCFG, which are
then parametrized using EM. Finally, a novel sen-
tence is semantically parsed by computing its most-
probable parse using the trained PCFG, and then its
MR is extracted from the resulting parse tree.
</bodyText>
<subsectionHeader confidence="0.99995">
3.1 Constructing a Lexeme Hierarchy Graph
</subsectionHeader>
<bodyText confidence="0.980868538461538">
An LHG represents the hierarchy of lexical mean-
ings relevant to a particular training instance by en-
coding the subgraph relations between the MRs of
relevant lexemes. Algorithm 1 describes how an
LHG is constructed for an ambiguous training pair
of a sentence and its corresponding context, (ei, ci).
First, we obtain all relevant lexemes (wij, mij) in the
lexicon L, where the MR mij is a subgraph of the
context ci (denoted as mij C ci). These lexemes are
3The total number of PCFG rules constructed for our navi-
gation training sets is about 18,000, while B¨orschinger et al.’s
method produces 33,000 rules for the much simpler sportscast-
ing domain.
</bodyText>
<page confidence="0.996679">
436
</page>
<bodyText confidence="0.874664125">
Algorithm 1 LEXEME HIERARCHY GRAPH (LHG)
Input: Training instance (ei, ci), Lexicon L
Output: Lexeme hierarchy graph for (ei, ci)
Find relevant lexemes (wi1, mi1), . . . , (win, min)
s.t. mij C ci
Create a starting node T; MR(T) ci
for all mij in the descending order of size do
Create a node Tij; MR(Tij) mij
</bodyText>
<equation confidence="0.627598375">
PLACELEXEME(Tij,T)
end for
procedure PLACELEXEME(T0,T)
for all children Tj of T do
if MR(T0) C MR(Tj) then
PLACELEXEME(T0,Tj)
end if
end for
</equation>
<bodyText confidence="0.89405362962963">
if T0 was not placed under any child Tj then
Add T0 as child of T
end if
end procedure
sorted in descending order based on the number of
nodes in their MRs mij. Then, after setting the con-
text ci as the MR of the root node (MR(T) ci),
lexemes are inserted, in order, into the graph to cre-
ate a hierarchy of MRs, where each child’s MR is a
subgraph of the MR of each of its parents. Figure 5
illustrates a sample construction of an LHG for the
following landmarks plan (ci):
Turn(RIGHT),
Verify(side:HATRACK, front:SOFA),
Travel(steps:3),
Verify(at:EASEL)
The initial LHG may contain nodes with too many
children. This is a problem, because when we sub-
sequently extract PCFG rules, we need to add a pro-
duction for every k-permutation of the children of
each node (see Section 3.2). To reduce the branch-
ing factor in the LHG, we introduce pseudo-lexeme
nodes by repeatedly combining the two most similar
children of each node. Pseudocode for the process is
shown in Algorithm 2. The MR for a pseudo-lexeme
is the minimal graph, m0, that is a supergraph of both
of the lexeme MRs that it combines. The pair of
</bodyText>
<listItem confidence="0.618165571428571">
(a) All relevant lexemes are obtained for the training exam-
ple and ordered by the number of nodes in their MR.
(b) Lexeme MR [1] is added as a child of the top node. MR
[2] is a subgraph of [1], so it is added as its child.
(c) MR [3] is not a subgraph of [1] or [2], so it is added as a
child of the root. MR [4] is added under [3], and MR [5] is
recursively filtered down and added under [2].
</listItem>
<figureCaption confidence="0.989281">
Figure 5: Sample LHG construction.
</figureCaption>
<page confidence="0.96109">
437
</page>
<table confidence="0.659997642857143">
Algorithm 2 ADDING PSEUDO LEXEMES TO LHG
Input: LHG with root T
Output: LHG with pseudo lexemes added
procedure RECONSTRUCTLHG(T)
repeat
((Ti, Tj), m&apos;) ← pick the most similar
pair (Ti, Tj) of children of T and the minimal ex-
tension m&apos; s.t. MR(Ti) ⊂ m&apos;, MR(Tj) ⊂ m&apos;,
m&apos; ⊂ MR(T)
Add child T&apos; of T; MR(T&apos;) ← m&apos;
Move Ti and Tj to be children of T&apos;
until There are no more pairs to combine
for all non-leaf children Tk of T do
RECONSTRUCTLHG(Tk)
</table>
<tableCaption confidence="0.296047">
end for
end procedure
</tableCaption>
<bodyText confidence="0.9825275">
most similar children, (mi, mj), is determined by
measuring the fraction of the nodes in mi and mj
that overlap with their minimum extension m&apos; and
is calculated as follows:
</bodyText>
<equation confidence="0.9956985">
5im(mi, mj, m&apos;) = |mi |� |mj|
2 |m&apos;|
</equation>
<bodyText confidence="0.999954625">
where |m |is the number of nodes in the MR m.
Adding pseudo-lexemes also has another advan-
tage. They can be considered to be higher-level
semantic concepts composed of two or more sub-
concepts. These higher-level concepts will likely
occur in other training examples as well, which al-
lows for more flexible interpretations. For example,
assuming the rule A → BCD is constructed from
an LHG, we will introduce a pseudo lexeme E and
build two rules A → BE and E → CD. It is likely
that E also occurs in another rule constructed from
other training examples such as E → FG. This
increases the model’s expressive power by support-
ing additional derivations such as A →* BFG, pro-
viding more flexibility when parsing novel NL sen-
tences.
</bodyText>
<subsectionHeader confidence="0.999297">
3.2 Composing PCFG Rules
</subsectionHeader>
<bodyText confidence="0.989640242424243">
The next step composes PCFG rules from the LHGs
and is summarized in Figure 6. We basically fol-
low the scheme of B¨orschinger et al. (2011), but
instead of generating NL words from each atomic
MR, words are generated from each lexeme MR,
Figure 6: Summary of the rule generation process.
NLs refer to the set of NL words in the corpus. Lex-
eme rules come from the schemata of B¨orschinger
et al. (2011), and allow every lexeme MR to gener-
ate one or more NL words. Note that pseudo-lexeme
nodes do not produce NL words.
and smaller lexeme MRs are generated from more
complex ones as given by the LHGs. A nonterminal
5m is generated for the MR, m, of each LHG node.
Then, for every LHG node, T, with MR, m, we add
rules of the form 5m → 5mi...5m�, where the RHS
is some k-permutation of the nonterminals for the
MRs of the children of node T. B¨orschinger et al.
assume that every atomic MR generates at least one
NL word. However, since we do not know which
subgraph of the overall context (i.e. ci, the MR of the
root node) conveys the intended plan and is therefore
expressed in the NL instruction, we must allow each
ordered subset of the children of a node (i.e. each
k-permutation) to be a possible generation.
The rest of the process more closely follows
B¨orschinger et al.’s. Every MR, m, of a lexeme
node4 generates a rule 5m → Phrasem, and ev-
ery Phrasem generates a sequence of NL words, in-
cluding one or more “content words” (Wordm) for
expressing m and zero or more “extraneous” words
(Wordo). While B¨orschinger et al. have Wordm
generate all possible NL words (each of which are
</bodyText>
<footnote confidence="0.989986">
4We exclude pseudo-lexeme nodes in this process, because
they should only generate words through generating lexemes.
</footnote>
<page confidence="0.995329">
438
</page>
<bodyText confidence="0.9999298">
subsequently weighted by EM training), in our ap-
proach, each Word, only produces the NL phrase
associated with m in the lexicon, or individual words
that appear in this phrase. The words not covered
by Word, also can be generated by Wordo which
has rules for every word. Ph, and PhX, ensure
that Phrase, produces at least one Word,, where
PhX, indicates that one or more Word,’s have
already been generated, and Ph, indicates that no
Word, has yet been generated.
</bodyText>
<subsectionHeader confidence="0.998986">
3.3 Parsing Novel NL Sentences
</subsectionHeader>
<bodyText confidence="0.999919484848485">
To learn the parameters of the resulting PCFG, we
use the Inside-Outside algorithm.5 Then, the stan-
dard probabilistic CKY algorithm is used to produce
the most probable parse for novel NL sentences (Ju-
rafsky and Martin, 2000).
B¨orschinger et al. (2011) simply read the MR, m,
for a sentence off the top 5, nonterminal of the
most probable parse tree. However, in our approach,
the correct MR is constructed by properly compos-
ing the appropriate subset of lexeme MRs from the
most-probable parse tree. This allows the system to
produce a wide variety of novel MRs for novel sen-
tences, as long as the correct MR is a subgraph of the
complete context (ci) for at least one of the training
sentences.
First, the parse tree is pruned to remove all sub-
trees starting with Phrase,, nodes. This leaves a
tree consisting of the Root and a set of 5, nodes.
The pruned subtrees only concern generating NL
words and phrases from the selected MRs. The re-
maining tree shows which MR constituents were se-
lected from the available context, from which the
sentence is then generated. Each leaf in the pruned
tree represents an MR constituent that was used to
generate a phrase in the sentence. These are the con-
stituents we want to assemble and compose into a
final MR for the sentence.
Algorithm 3 describes the procedure for extract-
ing the final MR from the pruned parse tree. Fig-
ure 7 graphically depicts a sample trace of this algo-
rithm. The algorithm recursively traverses the parse
tree. When a leaf-node is reached, it marks all of the
nodes in its MR. After traversing all of its children,
</bodyText>
<footnote confidence="0.954403333333333">
5We used the implementation available at http://web.
science.mq.edu.au/˜mjohnson/Software.htm
which was also used by B¨orschinger et al. (2011).
</footnote>
<bodyText confidence="0.8651635">
Algorithm 3 CONSTRUCT PARSED MR RESULT
Input: Parse tree T for input NL, e, with all
Phrase,, subtrees removed.
Output: Semantic parse MR, m, for e
</bodyText>
<equation confidence="0.816507769230769">
procedure OBTAINPARSEDOUTPUT(T)
if T is a leaf then
return MR(T) with all its nodes marked
end if
for all children Ti of T do
mi +— OBTAINPARSEDOUTPUT(Ti)
Mark the nodes in MR(T) corresponding
to the marked nodes in mi
end for
if T is not the root then
return MR(T)
end if
return MR(T) with unmarked nodes removed
</equation>
<bodyText confidence="0.932898666666667">
end procedure
a node in the MR for the current parse-tree node is
marked iff its corresponding node in any of the chil-
dren’s MRs were marked. The final output is the MR
constructed by removing all of the unmarked nodes
from the MR for the root node.
</bodyText>
<sectionHeader confidence="0.998601" genericHeader="method">
4 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.999927333333333">
For evaluation, we used the same data and method-
ology as Chen and Mooney (2011). Please see their
paper for more details.
</bodyText>
<subsectionHeader confidence="0.969074">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999976769230769">
We used the English instructions and follower data
collected by MacMahon et al. (2006).6 This data
contains 706 route instructions for three virtual
worlds. The instructions were produced by six in-
structors for 126 unique starting and ending loca-
tion pairs spread evenly across the three worlds, and
there were 1 to 15 human followers for each instruc-
tion who executed an average of 10.4 actions per in-
struction. Each instruction is a paragraph consist-
ing of an average of 5.0 sentences, each contain-
ing an average of 7.8 words. Chen and Mooney
constructed the additional single-sentence corpus by
matching each sentence with the majority of human
</bodyText>
<footnote confidence="0.993522">
6Available at http://www.cs.utexas.edu/users/
ml/clamp/navigation/
</footnote>
<page confidence="0.998982">
439
</page>
<figure confidence="0.995829166666667">
(a) Pruned parse tree showing only MRs for S. (b) Leaf nodes have all their elements marked
nodes
(c) Upper level nodes are marked according to leaf-
node markings
(d) Removing all unmarked elements for the root
node leads to the final MR output
</figure>
<figureCaption confidence="0.999985">
Figure 7: Sample construction of MR output from pruned parse tree.
</figureCaption>
<bodyText confidence="0.999887">
followers’ actions. We use this single-sentence ver-
sion for training, but use both the single-sentence
and the original paragraph version for testing. Each
sentence was manually annotated with a “gold stan-
dard” execution plan, which is used for evaluation
but not for training.
</bodyText>
<subsectionHeader confidence="0.987855">
4.2 Methodology and Results
</subsectionHeader>
<bodyText confidence="0.9999765">
Experiments were conducted using “leave one envi-
ronment out” cross-validation, training on two envi-
ronments and testing on the third, averaging over all
three test environments. We perform direct compar-
ison to the best results of Chen and Mooney (2011)
(referred to as CM). A Wilcoxon signed-rank test
is performed for statistical significance, and ‘*’ de-
notes significant differences (p &lt; .01) in the tables.
</bodyText>
<subsectionHeader confidence="0.988538">
Semantic Parsing Results
</subsectionHeader>
<bodyText confidence="0.9996875">
We first evaluated how well our system learns to
map novel NL sentences for new test environments
into their correct MRs. Partial semantic-parsing ac-
curacy (Chen and Mooney, 2011) is calculated by
</bodyText>
<table confidence="0.999787666666667">
Precision Recall F1
Our system 87.58 *65.41 *74.81
CM *90.22 55.10 68.37
</table>
<tableCaption confidence="0.999877">
Table 1: Test accuracy for semantic parsing.
</tableCaption>
<bodyText confidence="0.994808066666667">
‘*’ denotes difference is statistically significant.
comparing the system’s MR output to the hand-
annotated gold standard. Accuracy is measured in
terms of precision, recall, and F1 for individual MR
constituents (thereby awarding partial credit for ap-
proximately correct MRs).
Table 1 demonstrates that our method outper-
forms CM by 6 points in F1. Our PCFG-based ap-
proach is able to probabilistically disambiguate the
training data as well as simultaneously learn a sta-
tistical semantic parser within a single framework.
This results in better overall performance compared
to CM, since they lose potentially useful informa-
tion, particularly during the refinement stage, due to
the separate disjoint components of the system.
</bodyText>
<page confidence="0.993585">
440
</page>
<table confidence="0.994445666666667">
Single-sentence Paragraph
Our system *57.22% *20.17%
CM 54.40% 16.18%
</table>
<tableCaption confidence="0.9753065">
Table 2: Successful plan execution rates for novel
test data. ‘*’ means statistical significance.
</tableCaption>
<subsectionHeader confidence="0.860504">
Navigation Plan Execution Results
</subsectionHeader>
<bodyText confidence="0.9999659375">
Next, we test the end-to-end system by execut-
ing the parsed navigation plans for test instructions
in novel environments to see if they reach the ex-
act desired destinations in the environment. Table
2 shows the successful end-to-end navigation-task
completion rate for both single-sentences and com-
plete paragraph instructions.
Again, our system outperforms CM’s best results
since more accurate semantic parsing produces more
successful plans. However, the difference in per-
formance is smaller than that observed for semantic
parsing. This is because the redundancy in the hu-
man generated instructions allows an incorrect se-
mantic parse to be successful, as long as the errors
do not affect its ability to guide the system to the
correct destination.
</bodyText>
<sectionHeader confidence="0.998704" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.99034075">
Our approach improves on B¨orschinger et al.
(2011)’s method in the following ways:
• The building blocks for associating NL and MR
are semantic lexemes instead of atomic MR con-
stituents. This prevents the number of constructed
PCFG rules from becoming intractably large as hap-
pens with B¨orschinger et al.’s approach. As previ-
ously mentioned, lexeme MRs are intuitively anal-
ogous to syntactic categories in that complex lex-
eme MRs represent complicated semantic concepts
whereas higher-level syntactic categories such as S,
VP, or NP represent complex syntactic structures.
</bodyText>
<listItem confidence="0.82320125">
• Our approach has the ability to produce previ-
ously unseen MRs, whereas B¨orschinger et al. can
only generate an MR if it is explicitly included in
the PCFG rules constructed from the training data.
</listItem>
<bodyText confidence="0.99879288">
Even though our MR parse is restricted to be a sub-
graph of some training context, cz, our model allows
for exponentially many combinations.
In addition, our approach can produce a wider
range of MR outputs than Chen and Mooney
(2011)’s even though we use their semantic lexi-
con as input. Their system deterministically builds a
supervised training set by greedily selecting high-
scoring lexemes, thus implicitly including only
high-scoring lexemes during training. On the other
hand, our probabilistic approach also considers rela-
tively low-scoring but useful lexemes, thereby utiliz-
ing more semantic concepts in the lexicon. In partic-
ular, this explains why our approach obtains higher
recall in the evaluation of semantic parsing.
Even though we have demonstrated our approach
on the specific task of following navigation in-
structions, it is straightforward to apply it to other
language-grounding tasks where NL sentences po-
tentially refer to some subset of states, events, or ac-
tions in the world, as long as this overall context can
be represented as a semantic graph or logical form.
Since the semantic lexicon is an input to our system,
other approaches to lexicon learning are also easily
incorporated.
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.99989856">
Most work on learning semantic parsers that map
natural-language sentences to formal representa-
tions of their meaning have relied upon totally su-
pervised training data consisting of NL/MR pairs
(Zelle and Mooney, 1996; Zettlemoyer and Collins,
2005; Kate and Mooney, 2006; Wong and Mooney,
2007; Zettlemoyer and Collins, 2007; Lu et al.,
2008; Zettlemoyer and Collins, 2009). Several re-
cent approaches have investigated grounded learn-
ing from ambiguous supervision extracted from per-
ceptual context. A number of approaches (Kate and
Mooney, 2007; Chen and Mooney, 2008; Chen et al.,
2010; Kim and Mooney, 2010; B¨orschinger et al.,
2011) assume training data consisting of a set of sen-
tences each associated with a small set of MRs, one
of which is usually the correct meaning of the sen-
tence. Many of these approaches (Kate and Mooney,
2007; Chen and Mooney, 2008; Chen et al., 2010)
disambiguate the data and match NL sentences to
their correct MR by iteratively retraining a super-
vised semantic parser. Kim and Mooney (2010)
proposed a generative semantic parsing model that
first chooses which MRs to describe and then gen-
erates a hybrid tree structure (Lu et al., 2008) con-
taining both the MR and NL sentence. They train
</bodyText>
<page confidence="0.997399">
441
</page>
<bodyText confidence="0.999952047619048">
this model on ambiguous data using EM. As pre-
viously discussed, B¨orschinger et al. (2011) use a
PCFG generative model and also train it on ambigu-
ous data using EM. Liang et al. (2009) assume each
sentence maps to one or more semantic records (i.e.
MRs) and trains a hierarchical semi-Markov genera-
tive model using EM, and then finds a Viterbi align-
ment between NL words and records and their con-
stituents. Several recent projects (Branavan et al.,
2009; Vogel and Jurafsky, 2010) use NL instructions
to guide reinforcement learning from independent
exploration with delayed rewards. These systems do
not even need the ambiguous supervision obtained
from observing humans follow instructions; how-
ever, they do not learn semantic parsers that map
sentences to complex, structural representations of
their meaning.
Interpreting and executing NL navigation instruc-
tions is our primary task, and several other recent
projects have studied related problems. Shimizu and
Haas (2009) present a system that parses natural lan-
guage instructions into actions. However, they limit
the number of possible actions to only 15 and treat
the problem as a sequence labeling problem that is
solved using a CRF with supervised training. Ma-
tuszek et al. (2010) developed a system that learns to
map NL instructions to executable commands for a
robot navigating in an environment constructed by a
laser range finder. However, their approach has limi-
tations of ignoring any objects or other landmarks in
the environment to which the instructions can refer.
There are several recent projects (Vogel and Juraf-
sky, 2010; Kollar et al., 2010; Tellex et al., 2011)
which learn to follow instructions in more linguisti-
cally complex environments. However, they assume
predefined spatial words, direct matching between
NL words and the names of objects and other land-
marks in the MR, and/or an existing syntactic parser.
By contrast, our work does not assume any prior lin-
guistic knowledge, syntactic, lexical, or semantic,
and must learn the mapping between NL words and
phrases and the MR terms describing landmarks.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="method">
7 Future Work
</sectionHeader>
<bodyText confidence="0.999986578947368">
In the future, we would like to develop a better lex-
icon learner since our PCFG approach critically re-
lies on the quality of the learned lexicon. Particu-
larly, we would like to investigate how syntactic in-
formation (such as part-of-speech tags induced us-
ing unsupervised learning) could be used to improve
semantic-lexicon learning. For example, some of the
current lexicon entries violate the general constraint
that nouns usually refer to objects and verbs to ac-
tions. Ideally, the lexicon learner would be able to
induce and then utilize this sort of relationship be-
tween syntax and semantics.
In addition, we want to investigate the use of dis-
criminative reranking (Collins, 2000), which has
proven effective in various other NLP tasks. We
would expect the final MR output to improve if a
discriminative model, which uses additional global
features, is used to rerank the top-k parses produced
by our generative PCFG model.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999990619047619">
We have presented a novel method for learning a
semantic parser given only highly ambiguous su-
pervision. Our model enhances B¨orschinger et
al. (2011)’s approach to reducing the problem of
grounded learning of semantic parsers to PCFG in-
duction. We use a learned semantic lexicon to aid
the construction of a smaller and more focused set
of PCFG productions. This allows the approach
to scale to complex MR languages that define a
large (potentially infinite) space of representations
for capturing the meaning of sentences. By contrast,
the previous PCFG approach requires a finite MR
language and its grammar grows intractably large
for even moderately complex MR languages. In ad-
dition, our algorithm for composing MRs from the
final parse tree provides the flexibility to produce a
wide range of novel MRs that were not seen during
training. Evaluations on a previous corpus of nav-
igational instructions for virtual environments has
demonstrated the effectiveness of our method com-
pared to a recent competing system.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999754333333333">
We thank the anonymous reviewers and David Chen
for useful comments that helped improve this paper.
This work was funded by NSF grants IIS-0712907
and IIS-1016312. Experiments were performed on
the Mastodon Cluster, provided by NSF grant EIA-
0303609.
</bodyText>
<page confidence="0.997554">
442
</page>
<sectionHeader confidence="0.996388" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999386590476191">
Benjamin B¨orschinger, Bevan K. Jones, and Mark John-
son. 2011. Reducing grounded learning tasks to gram-
matical inference. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP-11), pages 1416–1425, Stroudsburg, PA,
USA. Association for Computational Linguistics.
S.R.K. Branavan, Harr Chen, Luke S. Zettlemoyer, and
Regina Barzilay. 2009. Reinforcement learning for
mapping instructions to actions. In Joint Conference
of the 47th Annual Meeting of the Association for
Computational Linguistics and the 4th International
Joint Conference on Natural Language Processing of
the Asian Federation of Natural Language Processing
(ACL-IJCNLP), Singapore.
David L. Chen and Raymond J. Mooney. 2008. Learn-
ing to sportscast: A test of grounded language ac-
quisition. In Proceedings of 25th International Con-
ference on Machine Learning (ICML-2008), Helsinki,
Finland, July.
David L. Chen and Raymond J. Mooney. 2011. Learn-
ing to interpret natural language navigation instruc-
tions from observations. In Proceedings of the 25th
AAAI Conference on Artificial Intelligence (AAAI-11),
San Francisco, CA, USA, August.
David L. Chen, Joohyun Kim, and Raymond J. Mooney.
2010. Training a multilingual sportscaster: Using per-
ceptual context to learn language. Journal ofArtificial
Intelligence Research, 37:397–435.
Michael Collins. 2000. Discriminative reranking for nat-
ural language parsing. In Proceedings of the Seven-
teenth International Conference on Machine Learning
(ICML-2000), pages 175–182, Stanford, CA, June.
Daniel Jurafsky and James H. Martin. 2000. Speech
and Language Processing: An Introduction to Natu-
ral Language Processing, Computational Linguistics,
and Speech Recognition. Prentice Hall, Upper Saddle
River, NJ.
R. J. Kate and R. J. Mooney. 2006. Using string-
kernels for learning semantic parsers. In Proceedings
of the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associ-
ation for Computational Linguistics (COLING/ACL-
06), pages 913–920, Sydney, Australia, July.
Rohit J. Kate and Raymond J. Mooney. 2007. Learn-
ing language semantics from ambiguous supervision.
In Proceedings of the Twenty-Second Conference on
Artificial Intelligence (AAAI-07), pages 895–900, Van-
couver, Canada, July.
Joohyun Kim and Raymond. J. Mooney. 2010. Genera-
tive alignment and semantic parsing for learning from
ambiguous supervision. In Proceedings of the 23rd In-
ternational Conference on Computational Linguistics
(COLING-10), pages 543–551. Association for Com-
putational Linguistics.
Thomas Kollar, Stefanie Tellex, Deb Roy, and Nicholas
Roy. 2010. Toward understanding natural language
directions. In Proceedings of Human Robot Interac-
tion Conference (HRI-2010).
P. Liang, M. I. Jordan, and D. Klein. 2009. Learning se-
mantic correspondences with less supervision. In Joint
Conference of the 47th Annual Meeting of the Associ-
ation for Computational Linguistics and the 4th Inter-
national Joint Conference on Natural Language Pro-
cessing of the Asian Federation of Natural Language
Processing (ACL-IJCNLP), Singapore.
Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettle-
moyer. 2008. A generative model for parsing natural
language to meaning representations. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP-08), pages 783–792,
Morristown, NJ, USA. Association for Computational
Linguistics.
M. MacMahon, B. Stankiewicz, and B. Kuipers. 2006.
Walk the talk: Connecting language, knowledge, and
action in route instructions. In Proceedings of the
Twenty-First National Conference on Artificial Intel-
ligence (AAAI-06), Boston, MA, July.
Cynthia Matuszek, Dieter Fox, and Karl Koscher. 2010.
Following directions using statistical machine transla-
tion. In Proceedings of the 5th ACM/IEEE interna-
tional conference on Human-robot interaction (HRI-
10), pages 251–258, New York, NY, USA. ACM.
Nobuyuki Shimizu and Andrew Haas. 2009. Learning to
follow navigational route instructions. In Proceedings
of the Twenty First International Joint Conference on
Artificial Intelligence (IJCAI-2009).
Jeffrey M. Siskind. 1996. A computational study
of cross-situational techniques for learning word-to-
meaning mappings. Cognition, 61(1):39–91, October.
Stefanie Tellex, Thomas Kolla, Steven Dickerson,
Matthew R. Walter, Ashis G. Banerjee, Seth Teller, and
Nicholas Roy. 2011. Understanding natural language
commands for robotic navigation and mobile manipu-
lation. In Proceedings of the National Conference on
Artificial Intelligence (AAAI-11), August.
Cynthia A. Thompson and Raymond J. Mooney. 2003.
Acquiring word-meaning mappings for natural lan-
guage interfaces. Journal of Artificial Intelligence Re-
search, 18:1–44.
Adam Vogel and Dan Jurafsky. 2010. Learning to fol-
low navigational directions. In Proceedings of the 48th
Annual Meeting of the Association for Computational
Linguistics (ACL-10).
Yuk Wah Wong and Raymond J. Mooney. 2007. Learn-
ing synchronous grammars for semantic parsing with
</reference>
<page confidence="0.990765">
443
</page>
<reference confidence="0.999622689655172">
lambda calculus. In Proceedings of the 45th Annual
Meeting of the Association for Computational Linguis-
tics (ACL-07), pages 960–967, Prague, Czech Repub-
lic, June.
John M. Zelle and Raymond J. Mooney. 1996. Learn-
ing to parse database queries using inductive logic pro-
gramming. In Proceedings of the Thirteenth National
Conference on Artificial Intelligence (AAAI-96), pages
1050–1055, Portland, OR, August.
Luke S. Zettlemoyer and Michael Collins. 2005. Learn-
ing to map sentences to logical form: Structured clas-
sification with probabilistic categorial grammars. In
Proceedings of 21st Conference on Uncertainty in Ar-
tificial Intelligence (UAI-2005), Edinburgh, Scotland,
July.
Luke S. Zettlemoyer and Michael Collins. 2007. Online
learning of relaxed CCG grammars for parsing to logi-
cal form. In Proceedings of the 2007 Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL-07), pages 678–687, Prague, Czech
Republic, June.
Luke .S. Zettlemoyer and Micheal Collins. 2009. Learn-
ing context-dependent mappings from sentences to
logical form. In Proceedings of the Joint Conference
of the 47th Annual Meeting of the ACL and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP (ACL-IJCNLP-09), pages
976–984. Association for Computational Linguistics.
</reference>
<page confidence="0.998954">
444
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.875565">
<title confidence="0.996651">Unsupervised PCFG Induction for Grounded Language with Highly Ambiguous Supervision</title>
<author confidence="0.999983">Joohyun Kim Raymond J Mooney</author>
<affiliation confidence="0.9941345">Department of Computer The University of Texas at</affiliation>
<address confidence="0.976988">1616 Guadalupe, Suite Austin, TX 78701,</address>
<abstract confidence="0.99645695">Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B¨orschinger et al. (2011) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (2011). This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Benjamin B¨orschinger</author>
<author>Bevan K Jones</author>
<author>Mark Johnson</author>
</authors>
<title>Reducing grounded learning tasks to grammatical inference.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-11),</booktitle>
<pages>1416--1425</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>B¨orschinger, Jones, Johnson, 2011</marker>
<rawString>Benjamin B¨orschinger, Bevan K. Jones, and Mark Johnson. 2011. Reducing grounded learning tasks to grammatical inference. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-11), pages 1416–1425, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Harr Chen</author>
<author>Luke S Zettlemoyer</author>
<author>Regina Barzilay</author>
</authors>
<title>Reinforcement learning for mapping instructions to actions.</title>
<date>2009</date>
<booktitle>In Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP),</booktitle>
<contexts>
<context position="30442" citStr="Branavan et al., 2009" startWordPosition="5051" endWordPosition="5054">sing model that first chooses which MRs to describe and then generates a hybrid tree structure (Lu et al., 2008) containing both the MR and NL sentence. They train 441 this model on ambiguous data using EM. As previously discussed, B¨orschinger et al. (2011) use a PCFG generative model and also train it on ambiguous data using EM. Liang et al. (2009) assume each sentence maps to one or more semantic records (i.e. MRs) and trains a hierarchical semi-Markov generative model using EM, and then finds a Viterbi alignment between NL words and records and their constituents. Several recent projects (Branavan et al., 2009; Vogel and Jurafsky, 2010) use NL instructions to guide reinforcement learning from independent exploration with delayed rewards. These systems do not even need the ambiguous supervision obtained from observing humans follow instructions; however, they do not learn semantic parsers that map sentences to complex, structural representations of their meaning. Interpreting and executing NL navigation instructions is our primary task, and several other recent projects have studied related problems. Shimizu and Haas (2009) present a system that parses natural language instructions into actions. How</context>
</contexts>
<marker>Branavan, Chen, Zettlemoyer, Barzilay, 2009</marker>
<rawString>S.R.K. Branavan, Harr Chen, Luke S. Zettlemoyer, and Regina Barzilay. 2009. Reinforcement learning for mapping instructions to actions. In Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP), Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to sportscast: A test of grounded language acquisition.</title>
<date>2008</date>
<booktitle>In Proceedings of 25th International Conference on Machine Learning (ICML-2008),</booktitle>
<location>Helsinki, Finland,</location>
<contexts>
<context position="1564" citStr="Chen and Mooney, 2008" startWordPosition="236" endWordPosition="239"> highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach. 1 Introduction The ultimate goal of “grounded” language learning is to develop computational systems that can acquire language more like a human child. Given only supervision in the form of sentences paired with relevant but ambiguous perceptual contexts, a system should learn to interpret and/or generate language describing situations and events in the world. For example, systems have learned to commentate simulated robot soccer games by learning from sample sportscasts (Chen and Mooney, 2008; Liang et al., 2009; B¨orschinger et al., 2011), or understand navigation instructions by learning from action traces produced when following the directions (Chen and Mooney, 2011; Tellex et al., 2011). B¨orschinger et al. (2011) recently introduced an approach to grounded language learning using unsupervised induction of probabilistic context free grammars (PCFGs) to learn from ambiguous contextual supervision. Their approach first constructs a large set of production rules from sentences paired with descriptions of their ambiguous context, and then trains the parameters of this grammar usin</context>
<context position="29327" citStr="Chen and Mooney, 2008" startWordPosition="4855" endWordPosition="4858">earning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sentences to their correct MR by iteratively retraining a supervised semantic parser. Kim and Mooney (2010) proposed a generative semantic parsing model that first chooses which MRs to describe and then generates a hybrid tree structure (Lu et al.,</context>
</contexts>
<marker>Chen, Mooney, 2008</marker>
<rawString>David L. Chen and Raymond J. Mooney. 2008. Learning to sportscast: A test of grounded language acquisition. In Proceedings of 25th International Conference on Machine Learning (ICML-2008), Helsinki, Finland, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to interpret natural language navigation instructions from observations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI-11),</booktitle>
<location>San Francisco, CA, USA,</location>
<contexts>
<context position="852" citStr="Chen and Mooney (2011)" startWordPosition="127" endWordPosition="130">01, USA {scimitar,mooney}@cs.utexas.edu Abstract “Grounded” language learning employs training data in the form of sentences paired with relevant but ambiguous perceptual contexts. B¨orschinger et al. (2011) introduced an approach to grounded language learning based on unsupervised PCFG induction. Their approach works well when each sentence potentially refers to one of a small set of possible meanings, such as in the sportscasting task. However, it does not scale to problems with a large set of potential meanings for each sentence, such as the navigation instruction following task studied by Chen and Mooney (2011). This paper presents an enhancement of the PCFG approach that scales to such problems with highly-ambiguous supervision. Experimental results on the navigation task demonstrates the effectiveness of our approach. 1 Introduction The ultimate goal of “grounded” language learning is to develop computational systems that can acquire language more like a human child. Given only supervision in the form of sentences paired with relevant but ambiguous perceptual contexts, a system should learn to interpret and/or generate language describing situations and events in the world. For example, systems ha</context>
<context position="3103" citStr="Chen and Mooney (2011)" startWordPosition="480" endWordPosition="483">g activity in a simulated robot soccer game is paired with the small set of actions observed within the past 5 seconds, one of which is usually described by the sentence. Even with this low level of ambiguity in a constrained domain, their method constructs a PCFG with about 33,000 productions. More fundamentally, their approach is restricted to a finite set of potential meaning representations, and the grammar size grows at least linearly with the number of possible MRs, which in turn is inevitably exponential in the number of objects and actions in the domain. The navigation task studied by Chen and Mooney (2011) provides much more ambiguous supervision. In this task, each instructional sentence is paired with a formal landmarks plan (represented as a large graph) that includes a full description of the observed actions and world-states that result when 433 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 433–444, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics someone follows this instruction. An instruction generally refers to a subgraph of this large graph. Therefore,</context>
<context position="9240" citStr="Chen and Mooney (2011)" startWordPosition="1460" endWordPosition="1463">des every possible MR constituent as a nonterminal in the PCFG. This is not tractable for more complex MRs. Therefore, our extension incorporates a learned lexicon to constrain the space of productions, thereby making the size of the PCFG tractable for complex MRs, and even giving it the ability to handle infinite MR languages. Moreover, when processing novel sentences, our approach can produce a large space of novel MRs that were not anticipated during training, which is not the case for B¨orschinger et al.’s approach. 2.2 Navigation Task and Dataset We employ the task and data introduced by Chen and Mooney (2011) whose goal is to interpret and follow NL navigation instructions in a virtual world. Figure 2 shows a sample execution path in a particular virtual world. The challenge is learning to perform this task by simply observing humans following instructions. Formally, given training data of the form {(el, al, wi), ... , (en, an, wn)1, where ei is an NL instruction, ai is an observed action sequence, and wi is the current world state (patterns of floors and walls, positions of any objects, etc.), we want to produce the correct actions aj for a novel (ej, wj). Figure 2: Sample virtual world from Chen</context>
<context position="11014" citStr="Chen and Mooney (2011)" startWordPosition="1765" endWordPosition="1768">r each ai, which is a graph representing the context of every action and the world-state encountered during the execution of the sequence. The correct plan MR, pi, is assumed to be a subgraph of ci, and this causes a combinatorial matching problem between ei and ci in order to learn the correct meaning of ei among all the possible subgraphs of ci. The landmarks and correct plans for a sample instruction are shown in Figure 3, illustrating the complexity of the MRs. Instead of directly solving the combinatorial correspondence problem, they first learn a semantic lex435 Figure 4: An overview of Chen and Mooney (2011)’s system. Our method replaces the plan refinement and semantic parser parts. icon that maps words and short phrases to small subgraphs representing their inferred meanings from the (ei, ci) pairs. The lexicon is learned by evaluating pairs of n-grams, wj, and MR graphs, mj, and scoring them based on how much more likely mj is a subgraph of the context ci when w occurs in the corresponding instruction ei. This process is similar to other “cross-situational” approaches to learning word meanings (Siskind, 1996; Thompson and Mooney, 2003). Then, a plan refinement step estimates pi from ci by gree</context>
<context position="12371" citStr="Chen and Mooney (2011)" startWordPosition="1989" endWordPosition="1992"> (mj) from the landmarks plan ci. The refined plans are used to construct supervised training data (ei, pi) for a supervised semantic-parser learner. The trained semantic parser can parse a novel instruction into a formal plan, which is finally executed for end-to-end evaluation. Figure 4 illustrates the overall system. As this figure indicates, our new PCFG method replaces the plan refinement and semantic parser components in their system with a unified model that both disambiguates the training data and learns a semantic parser. We use the landmarks plans and the learned lexicon produced by Chen and Mooney (2011) as inputs to our system.2 2In our experiments, we used the top 1,000 lexemes learned by Chen and Mooney (2011). 3 Our PCFG Approach Like B¨orschinger et al. (2011), our approach learns a semantic parser directly from ambiguous supervision, specifically NL instructions paired with their complete landmarks plans as context. Our method incorporates the semantic lexemes as building blocks to find correspondences between NL words and semantic concepts represented by the lexeme MRs, instead of building connections between NL words and every possible MR constituent as in B¨orschinger et al.’s approa</context>
<context position="22925" citStr="Chen and Mooney (2011)" startWordPosition="3851" endWordPosition="3854">then return MR(T) with all its nodes marked end if for all children Ti of T do mi +— OBTAINPARSEDOUTPUT(Ti) Mark the nodes in MR(T) corresponding to the marked nodes in mi end for if T is not the root then return MR(T) end if return MR(T) with unmarked nodes removed end procedure a node in the MR for the current parse-tree node is marked iff its corresponding node in any of the children’s MRs were marked. The final output is the MR constructed by removing all of the unmarked nodes from the MR for the root node. 4 Experimental Evaluation For evaluation, we used the same data and methodology as Chen and Mooney (2011). Please see their paper for more details. 4.1 Data We used the English instructions and follower data collected by MacMahon et al. (2006).6 This data contains 706 route instructions for three virtual worlds. The instructions were produced by six instructors for 126 unique starting and ending location pairs spread evenly across the three worlds, and there were 1 to 15 human followers for each instruction who executed an average of 10.4 actions per instruction. Each instruction is a paragraph consisting of an average of 5.0 sentences, each containing an average of 7.8 words. Chen and Mooney con</context>
<context position="24565" citStr="Chen and Mooney (2011)" startWordPosition="4114" endWordPosition="4117">ure 7: Sample construction of MR output from pruned parse tree. followers’ actions. We use this single-sentence version for training, but use both the single-sentence and the original paragraph version for testing. Each sentence was manually annotated with a “gold standard” execution plan, which is used for evaluation but not for training. 4.2 Methodology and Results Experiments were conducted using “leave one environment out” cross-validation, training on two environments and testing on the third, averaging over all three test environments. We perform direct comparison to the best results of Chen and Mooney (2011) (referred to as CM). A Wilcoxon signed-rank test is performed for statistical significance, and ‘*’ denotes significant differences (p &lt; .01) in the tables. Semantic Parsing Results We first evaluated how well our system learns to map novel NL sentences for new test environments into their correct MRs. Partial semantic-parsing accuracy (Chen and Mooney, 2011) is calculated by Precision Recall F1 Our system 87.58 *65.41 *74.81 CM *90.22 55.10 68.37 Table 1: Test accuracy for semantic parsing. ‘*’ denotes difference is statistically significant. comparing the system’s MR output to the handannot</context>
<context position="27767" citStr="Chen and Mooney (2011)" startWordPosition="4614" endWordPosition="4617">ntactic categories in that complex lexeme MRs represent complicated semantic concepts whereas higher-level syntactic categories such as S, VP, or NP represent complex syntactic structures. • Our approach has the ability to produce previously unseen MRs, whereas B¨orschinger et al. can only generate an MR if it is explicitly included in the PCFG rules constructed from the training data. Even though our MR parse is restricted to be a subgraph of some training context, cz, our model allows for exponentially many combinations. In addition, our approach can produce a wider range of MR outputs than Chen and Mooney (2011)’s even though we use their semantic lexicon as input. Their system deterministically builds a supervised training set by greedily selecting highscoring lexemes, thus implicitly including only high-scoring lexemes during training. On the other hand, our probabilistic approach also considers relatively low-scoring but useful lexemes, thereby utilizing more semantic concepts in the lexicon. In particular, this explains why our approach obtains higher recall in the evaluation of semantic parsing. Even though we have demonstrated our approach on the specific task of following navigation instructio</context>
</contexts>
<marker>Chen, Mooney, 2011</marker>
<rawString>David L. Chen and Raymond J. Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings of the 25th AAAI Conference on Artificial Intelligence (AAAI-11), San Francisco, CA, USA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>Joohyun Kim</author>
<author>Raymond J Mooney</author>
</authors>
<title>Training a multilingual sportscaster: Using perceptual context to learn language.</title>
<date>2010</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<pages>37--397</pages>
<contexts>
<context position="29346" citStr="Chen et al., 2010" startWordPosition="4859" endWordPosition="4862"> incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sentences to their correct MR by iteratively retraining a supervised semantic parser. Kim and Mooney (2010) proposed a generative semantic parsing model that first chooses which MRs to describe and then generates a hybrid tree structure (Lu et al., 2008) containing b</context>
</contexts>
<marker>Chen, Kim, Mooney, 2010</marker>
<rawString>David L. Chen, Joohyun Kim, and Raymond J. Mooney. 2010. Training a multilingual sportscaster: Using perceptual context to learn language. Journal ofArtificial Intelligence Research, 37:397–435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative reranking for natural language parsing.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning (ICML-2000),</booktitle>
<pages>175--182</pages>
<location>Stanford, CA,</location>
<contexts>
<context position="32776" citStr="Collins, 2000" startWordPosition="5423" endWordPosition="5424"> our PCFG approach critically relies on the quality of the learned lexicon. Particularly, we would like to investigate how syntactic information (such as part-of-speech tags induced using unsupervised learning) could be used to improve semantic-lexicon learning. For example, some of the current lexicon entries violate the general constraint that nouns usually refer to objects and verbs to actions. Ideally, the lexicon learner would be able to induce and then utilize this sort of relationship between syntax and semantics. In addition, we want to investigate the use of discriminative reranking (Collins, 2000), which has proven effective in various other NLP tasks. We would expect the final MR output to improve if a discriminative model, which uses additional global features, is used to rerank the top-k parses produced by our generative PCFG model. 8 Conclusions We have presented a novel method for learning a semantic parser given only highly ambiguous supervision. Our model enhances B¨orschinger et al. (2011)’s approach to reducing the problem of grounded learning of semantic parsers to PCFG induction. We use a learned semantic lexicon to aid the construction of a smaller and more focused set of P</context>
</contexts>
<marker>Collins, 2000</marker>
<rawString>Michael Collins. 2000. Discriminative reranking for natural language parsing. In Proceedings of the Seventeenth International Conference on Machine Learning (ICML-2000), pages 175–182, Stanford, CA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James H Martin</author>
</authors>
<title>Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. Prentice Hall, Upper Saddle River,</title>
<date>2000</date>
<location>NJ.</location>
<contexts>
<context position="20606" citStr="Jurafsky and Martin, 2000" startWordPosition="3440" endWordPosition="3444"> associated with m in the lexicon, or individual words that appear in this phrase. The words not covered by Word, also can be generated by Wordo which has rules for every word. Ph, and PhX, ensure that Phrase, produces at least one Word,, where PhX, indicates that one or more Word,’s have already been generated, and Ph, indicates that no Word, has yet been generated. 3.3 Parsing Novel NL Sentences To learn the parameters of the resulting PCFG, we use the Inside-Outside algorithm.5 Then, the standard probabilistic CKY algorithm is used to produce the most probable parse for novel NL sentences (Jurafsky and Martin, 2000). B¨orschinger et al. (2011) simply read the MR, m, for a sentence off the top 5, nonterminal of the most probable parse tree. However, in our approach, the correct MR is constructed by properly composing the appropriate subset of lexeme MRs from the most-probable parse tree. This allows the system to produce a wide variety of novel MRs for novel sentences, as long as the correct MR is a subgraph of the complete context (ci) for at least one of the training sentences. First, the parse tree is pruned to remove all subtrees starting with Phrase,, nodes. This leaves a tree consisting of the Root </context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Daniel Jurafsky and James H. Martin. 2000. Speech and Language Processing: An Introduction to Natural Language Processing, Computational Linguistics, and Speech Recognition. Prentice Hall, Upper Saddle River, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Kate</author>
<author>R J Mooney</author>
</authors>
<title>Using stringkernels for learning semantic parsers.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING/ACL06),</booktitle>
<pages>913--920</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="29030" citStr="Kate and Mooney, 2006" startWordPosition="4810" endWordPosition="4813">ther language-grounding tasks where NL sentences potentially refer to some subset of states, events, or actions in the world, as long as this overall context can be represented as a semantic graph or logical form. Since the semantic lexicon is an input to our system, other approaches to lexicon learning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen </context>
</contexts>
<marker>Kate, Mooney, 2006</marker>
<rawString>R. J. Kate and R. J. Mooney. 2006. Using stringkernels for learning semantic parsers. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING/ACL06), pages 913–920, Sydney, Australia, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit J Kate</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning language semantics from ambiguous supervision.</title>
<date>2007</date>
<booktitle>In Proceedings of the Twenty-Second Conference on Artificial Intelligence (AAAI-07),</booktitle>
<pages>895--900</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="29304" citStr="Kate and Mooney, 2007" startWordPosition="4851" endWordPosition="4854">approaches to lexicon learning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sentences to their correct MR by iteratively retraining a supervised semantic parser. Kim and Mooney (2010) proposed a generative semantic parsing model that first chooses which MRs to describe and then generates a hybrid tre</context>
</contexts>
<marker>Kate, Mooney, 2007</marker>
<rawString>Rohit J. Kate and Raymond J. Mooney. 2007. Learning language semantics from ambiguous supervision. In Proceedings of the Twenty-Second Conference on Artificial Intelligence (AAAI-07), pages 895–900, Vancouver, Canada, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Mooney</author>
</authors>
<title>Generative alignment and semantic parsing for learning from ambiguous supervision.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING-10),</booktitle>
<pages>543--551</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="7016" citStr="Mooney, 2010" startWordPosition="1096" endWordPosition="1097">n 2 reviews B¨orschinger et al.’s PCFG approach as well as the navigation task and data. Section 3 describes our enhanced PCFG approach and Section 4 presents an experimental evaluation of it. Then, Section 5 discusses the unique aspects of our approach and Section 6 describes additional related work. Finally, Section 7 presents future research directions and Section 8 gives our conclusions. 2 Background 2.1 Existing PCFG Approach Our approach extends that of B¨orschinger et al. (2011), which in turn was inspired by a series of previous techniques (Lu et al., 2008; Liang et al., 2009; Kim and Mooney, 2010) following the idea of constructing correspondences between NL and MR in a single probabilistic generative framework. Particularly, their approach automatically constructs a PCFG that generates NL sentences from MRs, which indicates how atomic MR constituents are probabilistically related to NL words. The nonterminals in the grammar correspond to complete MRs, MR constituents, and NL phrases. The nonterminal for a composite MR generates each of its MR constituents, and each atomic MR, x, generates an NL phrase, Phrasex. Each Phrasex then generates a sequence of Wordx’s for describing x, and ea</context>
<context position="29368" citStr="Mooney, 2010" startWordPosition="4865" endWordPosition="4866">rk Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sentences to their correct MR by iteratively retraining a supervised semantic parser. Kim and Mooney (2010) proposed a generative semantic parsing model that first chooses which MRs to describe and then generates a hybrid tree structure (Lu et al., 2008) containing both the MR and NL sent</context>
</contexts>
<marker>Mooney, 2010</marker>
<rawString>Joohyun Kim and Raymond. J. Mooney. 2010. Generative alignment and semantic parsing for learning from ambiguous supervision. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING-10), pages 543–551. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Kollar</author>
<author>Stefanie Tellex</author>
<author>Deb Roy</author>
<author>Nicholas Roy</author>
</authors>
<title>Toward understanding natural language directions.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Robot Interaction Conference (HRI-2010).</booktitle>
<contexts>
<context position="31604" citStr="Kollar et al., 2010" startWordPosition="5231" endWordPosition="5234">at parses natural language instructions into actions. However, they limit the number of possible actions to only 15 and treat the problem as a sequence labeling problem that is solved using a CRF with supervised training. Matuszek et al. (2010) developed a system that learns to map NL instructions to executable commands for a robot navigating in an environment constructed by a laser range finder. However, their approach has limitations of ignoring any objects or other landmarks in the environment to which the instructions can refer. There are several recent projects (Vogel and Jurafsky, 2010; Kollar et al., 2010; Tellex et al., 2011) which learn to follow instructions in more linguistically complex environments. However, they assume predefined spatial words, direct matching between NL words and the names of objects and other landmarks in the MR, and/or an existing syntactic parser. By contrast, our work does not assume any prior linguistic knowledge, syntactic, lexical, or semantic, and must learn the mapping between NL words and phrases and the MR terms describing landmarks. 7 Future Work In the future, we would like to develop a better lexicon learner since our PCFG approach critically relies on th</context>
</contexts>
<marker>Kollar, Tellex, Roy, Roy, 2010</marker>
<rawString>Thomas Kollar, Stefanie Tellex, Deb Roy, and Nicholas Roy. 2010. Toward understanding natural language directions. In Proceedings of Human Robot Interaction Conference (HRI-2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>M I Jordan</author>
<author>D Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP),</booktitle>
<contexts>
<context position="1584" citStr="Liang et al., 2009" startWordPosition="240" endWordPosition="243">vision. Experimental results on the navigation task demonstrates the effectiveness of our approach. 1 Introduction The ultimate goal of “grounded” language learning is to develop computational systems that can acquire language more like a human child. Given only supervision in the form of sentences paired with relevant but ambiguous perceptual contexts, a system should learn to interpret and/or generate language describing situations and events in the world. For example, systems have learned to commentate simulated robot soccer games by learning from sample sportscasts (Chen and Mooney, 2008; Liang et al., 2009; B¨orschinger et al., 2011), or understand navigation instructions by learning from action traces produced when following the directions (Chen and Mooney, 2011; Tellex et al., 2011). B¨orschinger et al. (2011) recently introduced an approach to grounded language learning using unsupervised induction of probabilistic context free grammars (PCFGs) to learn from ambiguous contextual supervision. Their approach first constructs a large set of production rules from sentences paired with descriptions of their ambiguous context, and then trains the parameters of this grammar using EM. Parsing a nove</context>
<context position="6993" citStr="Liang et al., 2009" startWordPosition="1090" endWordPosition="1093">organized as follows. Section 2 reviews B¨orschinger et al.’s PCFG approach as well as the navigation task and data. Section 3 describes our enhanced PCFG approach and Section 4 presents an experimental evaluation of it. Then, Section 5 discusses the unique aspects of our approach and Section 6 describes additional related work. Finally, Section 7 presents future research directions and Section 8 gives our conclusions. 2 Background 2.1 Existing PCFG Approach Our approach extends that of B¨orschinger et al. (2011), which in turn was inspired by a series of previous techniques (Lu et al., 2008; Liang et al., 2009; Kim and Mooney, 2010) following the idea of constructing correspondences between NL and MR in a single probabilistic generative framework. Particularly, their approach automatically constructs a PCFG that generates NL sentences from MRs, which indicates how atomic MR constituents are probabilistically related to NL words. The nonterminals in the grammar correspond to complete MRs, MR constituents, and NL phrases. The nonterminal for a composite MR generates each of its MR constituents, and each atomic MR, x, generates an NL phrase, Phrasex. Each Phrasex then generates a sequence of Wordx’s f</context>
<context position="30173" citStr="Liang et al. (2009)" startWordPosition="5006" endWordPosition="5009">any of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sentences to their correct MR by iteratively retraining a supervised semantic parser. Kim and Mooney (2010) proposed a generative semantic parsing model that first chooses which MRs to describe and then generates a hybrid tree structure (Lu et al., 2008) containing both the MR and NL sentence. They train 441 this model on ambiguous data using EM. As previously discussed, B¨orschinger et al. (2011) use a PCFG generative model and also train it on ambiguous data using EM. Liang et al. (2009) assume each sentence maps to one or more semantic records (i.e. MRs) and trains a hierarchical semi-Markov generative model using EM, and then finds a Viterbi alignment between NL words and records and their constituents. Several recent projects (Branavan et al., 2009; Vogel and Jurafsky, 2010) use NL instructions to guide reinforcement learning from independent exploration with delayed rewards. These systems do not even need the ambiguous supervision obtained from observing humans follow instructions; however, they do not learn semantic parsers that map sentences to complex, structural repre</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>P. Liang, M. I. Jordan, and D. Klein. 2009. Learning semantic correspondences with less supervision. In Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing (ACL-IJCNLP), Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Lu</author>
<author>Hwee Tou Ng</author>
<author>Wee Sun Lee</author>
<author>Luke S Zettlemoyer</author>
</authors>
<title>A generative model for parsing natural language to meaning representations.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-08),</booktitle>
<pages>783--792</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6973" citStr="Lu et al., 2008" startWordPosition="1086" endWordPosition="1089"> of the paper is organized as follows. Section 2 reviews B¨orschinger et al.’s PCFG approach as well as the navigation task and data. Section 3 describes our enhanced PCFG approach and Section 4 presents an experimental evaluation of it. Then, Section 5 discusses the unique aspects of our approach and Section 6 describes additional related work. Finally, Section 7 presents future research directions and Section 8 gives our conclusions. 2 Background 2.1 Existing PCFG Approach Our approach extends that of B¨orschinger et al. (2011), which in turn was inspired by a series of previous techniques (Lu et al., 2008; Liang et al., 2009; Kim and Mooney, 2010) following the idea of constructing correspondences between NL and MR in a single probabilistic generative framework. Particularly, their approach automatically constructs a PCFG that generates NL sentences from MRs, which indicates how atomic MR constituents are probabilistically related to NL words. The nonterminals in the grammar correspond to complete MRs, MR constituents, and NL phrases. The nonterminal for a composite MR generates each of its MR constituents, and each atomic MR, x, generates an NL phrase, Phrasex. Each Phrasex then generates a s</context>
<context position="29101" citStr="Lu et al., 2008" startWordPosition="4822" endWordPosition="4825">bset of states, events, or actions in the world, as long as this overall context can be represented as a semantic graph or logical form. Since the semantic lexicon is an input to our system, other approaches to lexicon learning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sentences to their cor</context>
</contexts>
<marker>Lu, Ng, Lee, Zettlemoyer, 2008</marker>
<rawString>Wei Lu, Hwee Tou Ng, Wee Sun Lee, and Luke S. Zettlemoyer. 2008. A generative model for parsing natural language to meaning representations. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-08), pages 783–792, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M MacMahon</author>
<author>B Stankiewicz</author>
<author>B Kuipers</author>
</authors>
<title>Walk the talk: Connecting language, knowledge, and action in route instructions.</title>
<date>2006</date>
<booktitle>In Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06),</booktitle>
<location>Boston, MA,</location>
<contexts>
<context position="23063" citStr="MacMahon et al. (2006)" startWordPosition="3874" endWordPosition="3877">ponding to the marked nodes in mi end for if T is not the root then return MR(T) end if return MR(T) with unmarked nodes removed end procedure a node in the MR for the current parse-tree node is marked iff its corresponding node in any of the children’s MRs were marked. The final output is the MR constructed by removing all of the unmarked nodes from the MR for the root node. 4 Experimental Evaluation For evaluation, we used the same data and methodology as Chen and Mooney (2011). Please see their paper for more details. 4.1 Data We used the English instructions and follower data collected by MacMahon et al. (2006).6 This data contains 706 route instructions for three virtual worlds. The instructions were produced by six instructors for 126 unique starting and ending location pairs spread evenly across the three worlds, and there were 1 to 15 human followers for each instruction who executed an average of 10.4 actions per instruction. Each instruction is a paragraph consisting of an average of 5.0 sentences, each containing an average of 7.8 words. Chen and Mooney constructed the additional single-sentence corpus by matching each sentence with the majority of human 6Available at http://www.cs.utexas.edu</context>
</contexts>
<marker>MacMahon, Stankiewicz, Kuipers, 2006</marker>
<rawString>M. MacMahon, B. Stankiewicz, and B. Kuipers. 2006. Walk the talk: Connecting language, knowledge, and action in route instructions. In Proceedings of the Twenty-First National Conference on Artificial Intelligence (AAAI-06), Boston, MA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Matuszek</author>
<author>Dieter Fox</author>
<author>Karl Koscher</author>
</authors>
<title>Following directions using statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction (HRI10),</booktitle>
<pages>251--258</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="31229" citStr="Matuszek et al. (2010)" startWordPosition="5169" endWordPosition="5173"> ambiguous supervision obtained from observing humans follow instructions; however, they do not learn semantic parsers that map sentences to complex, structural representations of their meaning. Interpreting and executing NL navigation instructions is our primary task, and several other recent projects have studied related problems. Shimizu and Haas (2009) present a system that parses natural language instructions into actions. However, they limit the number of possible actions to only 15 and treat the problem as a sequence labeling problem that is solved using a CRF with supervised training. Matuszek et al. (2010) developed a system that learns to map NL instructions to executable commands for a robot navigating in an environment constructed by a laser range finder. However, their approach has limitations of ignoring any objects or other landmarks in the environment to which the instructions can refer. There are several recent projects (Vogel and Jurafsky, 2010; Kollar et al., 2010; Tellex et al., 2011) which learn to follow instructions in more linguistically complex environments. However, they assume predefined spatial words, direct matching between NL words and the names of objects and other landmar</context>
</contexts>
<marker>Matuszek, Fox, Koscher, 2010</marker>
<rawString>Cynthia Matuszek, Dieter Fox, and Karl Koscher. 2010. Following directions using statistical machine translation. In Proceedings of the 5th ACM/IEEE international conference on Human-robot interaction (HRI10), pages 251–258, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nobuyuki Shimizu</author>
<author>Andrew Haas</author>
</authors>
<title>Learning to follow navigational route instructions.</title>
<date>2009</date>
<booktitle>In Proceedings of the Twenty First International Joint Conference on Artificial Intelligence (IJCAI-2009).</booktitle>
<contexts>
<context position="30965" citStr="Shimizu and Haas (2009)" startWordPosition="5125" endWordPosition="5128"> between NL words and records and their constituents. Several recent projects (Branavan et al., 2009; Vogel and Jurafsky, 2010) use NL instructions to guide reinforcement learning from independent exploration with delayed rewards. These systems do not even need the ambiguous supervision obtained from observing humans follow instructions; however, they do not learn semantic parsers that map sentences to complex, structural representations of their meaning. Interpreting and executing NL navigation instructions is our primary task, and several other recent projects have studied related problems. Shimizu and Haas (2009) present a system that parses natural language instructions into actions. However, they limit the number of possible actions to only 15 and treat the problem as a sequence labeling problem that is solved using a CRF with supervised training. Matuszek et al. (2010) developed a system that learns to map NL instructions to executable commands for a robot navigating in an environment constructed by a laser range finder. However, their approach has limitations of ignoring any objects or other landmarks in the environment to which the instructions can refer. There are several recent projects (Vogel </context>
</contexts>
<marker>Shimizu, Haas, 2009</marker>
<rawString>Nobuyuki Shimizu and Andrew Haas. 2009. Learning to follow navigational route instructions. In Proceedings of the Twenty First International Joint Conference on Artificial Intelligence (IJCAI-2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey M Siskind</author>
</authors>
<title>A computational study of cross-situational techniques for learning word-tomeaning mappings.</title>
<date>1996</date>
<journal>Cognition,</journal>
<volume>61</volume>
<issue>1</issue>
<contexts>
<context position="11527" citStr="Siskind, 1996" startWordPosition="1855" endWordPosition="1856">pondence problem, they first learn a semantic lex435 Figure 4: An overview of Chen and Mooney (2011)’s system. Our method replaces the plan refinement and semantic parser parts. icon that maps words and short phrases to small subgraphs representing their inferred meanings from the (ei, ci) pairs. The lexicon is learned by evaluating pairs of n-grams, wj, and MR graphs, mj, and scoring them based on how much more likely mj is a subgraph of the context ci when w occurs in the corresponding instruction ei. This process is similar to other “cross-situational” approaches to learning word meanings (Siskind, 1996; Thompson and Mooney, 2003). Then, a plan refinement step estimates pi from ci by greedily selecting high-scoring lexemes of the form (wj, mj) whose words and phrases (wj) cover the instruction ei and introduce components (mj) from the landmarks plan ci. The refined plans are used to construct supervised training data (ei, pi) for a supervised semantic-parser learner. The trained semantic parser can parse a novel instruction into a formal plan, which is finally executed for end-to-end evaluation. Figure 4 illustrates the overall system. As this figure indicates, our new PCFG method replaces t</context>
</contexts>
<marker>Siskind, 1996</marker>
<rawString>Jeffrey M. Siskind. 1996. A computational study of cross-situational techniques for learning word-tomeaning mappings. Cognition, 61(1):39–91, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefanie Tellex</author>
<author>Thomas Kolla</author>
<author>Steven Dickerson</author>
<author>Matthew R Walter</author>
<author>Ashis G Banerjee</author>
<author>Seth Teller</author>
<author>Nicholas Roy</author>
</authors>
<title>Understanding natural language commands for robotic navigation and mobile manipulation.</title>
<date>2011</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence (AAAI-11),</booktitle>
<contexts>
<context position="1766" citStr="Tellex et al., 2011" startWordPosition="267" endWordPosition="270">omputational systems that can acquire language more like a human child. Given only supervision in the form of sentences paired with relevant but ambiguous perceptual contexts, a system should learn to interpret and/or generate language describing situations and events in the world. For example, systems have learned to commentate simulated robot soccer games by learning from sample sportscasts (Chen and Mooney, 2008; Liang et al., 2009; B¨orschinger et al., 2011), or understand navigation instructions by learning from action traces produced when following the directions (Chen and Mooney, 2011; Tellex et al., 2011). B¨orschinger et al. (2011) recently introduced an approach to grounded language learning using unsupervised induction of probabilistic context free grammars (PCFGs) to learn from ambiguous contextual supervision. Their approach first constructs a large set of production rules from sentences paired with descriptions of their ambiguous context, and then trains the parameters of this grammar using EM. Parsing a novel sentence with this grammar gives a parse tree which contains the formal meaning representation (MR) for this sentence. This approach works quite well on the sportscasting task orig</context>
<context position="31626" citStr="Tellex et al., 2011" startWordPosition="5235" endWordPosition="5238">guage instructions into actions. However, they limit the number of possible actions to only 15 and treat the problem as a sequence labeling problem that is solved using a CRF with supervised training. Matuszek et al. (2010) developed a system that learns to map NL instructions to executable commands for a robot navigating in an environment constructed by a laser range finder. However, their approach has limitations of ignoring any objects or other landmarks in the environment to which the instructions can refer. There are several recent projects (Vogel and Jurafsky, 2010; Kollar et al., 2010; Tellex et al., 2011) which learn to follow instructions in more linguistically complex environments. However, they assume predefined spatial words, direct matching between NL words and the names of objects and other landmarks in the MR, and/or an existing syntactic parser. By contrast, our work does not assume any prior linguistic knowledge, syntactic, lexical, or semantic, and must learn the mapping between NL words and phrases and the MR terms describing landmarks. 7 Future Work In the future, we would like to develop a better lexicon learner since our PCFG approach critically relies on the quality of the learn</context>
</contexts>
<marker>Tellex, Kolla, Dickerson, Walter, Banerjee, Teller, Roy, 2011</marker>
<rawString>Stefanie Tellex, Thomas Kolla, Steven Dickerson, Matthew R. Walter, Ashis G. Banerjee, Seth Teller, and Nicholas Roy. 2011. Understanding natural language commands for robotic navigation and mobile manipulation. In Proceedings of the National Conference on Artificial Intelligence (AAAI-11), August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia A Thompson</author>
<author>Raymond J Mooney</author>
</authors>
<title>Acquiring word-meaning mappings for natural language interfaces.</title>
<date>2003</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>18--1</pages>
<contexts>
<context position="11555" citStr="Thompson and Mooney, 2003" startWordPosition="1857" endWordPosition="1860">m, they first learn a semantic lex435 Figure 4: An overview of Chen and Mooney (2011)’s system. Our method replaces the plan refinement and semantic parser parts. icon that maps words and short phrases to small subgraphs representing their inferred meanings from the (ei, ci) pairs. The lexicon is learned by evaluating pairs of n-grams, wj, and MR graphs, mj, and scoring them based on how much more likely mj is a subgraph of the context ci when w occurs in the corresponding instruction ei. This process is similar to other “cross-situational” approaches to learning word meanings (Siskind, 1996; Thompson and Mooney, 2003). Then, a plan refinement step estimates pi from ci by greedily selecting high-scoring lexemes of the form (wj, mj) whose words and phrases (wj) cover the instruction ei and introduce components (mj) from the landmarks plan ci. The refined plans are used to construct supervised training data (ei, pi) for a supervised semantic-parser learner. The trained semantic parser can parse a novel instruction into a formal plan, which is finally executed for end-to-end evaluation. Figure 4 illustrates the overall system. As this figure indicates, our new PCFG method replaces the plan refinement and seman</context>
</contexts>
<marker>Thompson, Mooney, 2003</marker>
<rawString>Cynthia A. Thompson and Raymond J. Mooney. 2003. Acquiring word-meaning mappings for natural language interfaces. Journal of Artificial Intelligence Research, 18:1–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Vogel</author>
<author>Dan Jurafsky</author>
</authors>
<title>Learning to follow navigational directions.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL-10).</booktitle>
<contexts>
<context position="30469" citStr="Vogel and Jurafsky, 2010" startWordPosition="5055" endWordPosition="5058">hooses which MRs to describe and then generates a hybrid tree structure (Lu et al., 2008) containing both the MR and NL sentence. They train 441 this model on ambiguous data using EM. As previously discussed, B¨orschinger et al. (2011) use a PCFG generative model and also train it on ambiguous data using EM. Liang et al. (2009) assume each sentence maps to one or more semantic records (i.e. MRs) and trains a hierarchical semi-Markov generative model using EM, and then finds a Viterbi alignment between NL words and records and their constituents. Several recent projects (Branavan et al., 2009; Vogel and Jurafsky, 2010) use NL instructions to guide reinforcement learning from independent exploration with delayed rewards. These systems do not even need the ambiguous supervision obtained from observing humans follow instructions; however, they do not learn semantic parsers that map sentences to complex, structural representations of their meaning. Interpreting and executing NL navigation instructions is our primary task, and several other recent projects have studied related problems. Shimizu and Haas (2009) present a system that parses natural language instructions into actions. However, they limit the number</context>
</contexts>
<marker>Vogel, Jurafsky, 2010</marker>
<rawString>Adam Vogel and Dan Jurafsky. 2010. Learning to follow navigational directions. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL-10).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuk Wah Wong</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning synchronous grammars for semantic parsing with lambda calculus.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-07),</booktitle>
<pages>960--967</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="29053" citStr="Wong and Mooney, 2007" startWordPosition="4814" endWordPosition="4817"> tasks where NL sentences potentially refer to some subset of states, events, or actions in the world, as long as this overall context can be represented as a semantic graph or logical form. Since the semantic lexicon is an input to our system, other approaches to lexicon learning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambigu</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Yuk Wah Wong and Raymond J. Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics (ACL-07), pages 960–967, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Zelle</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning to parse database queries using inductive logic programming.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96),</booktitle>
<pages>1050--1055</pages>
<location>Portland, OR,</location>
<contexts>
<context position="28976" citStr="Zelle and Mooney, 1996" startWordPosition="4802" endWordPosition="4805">on instructions, it is straightforward to apply it to other language-grounding tasks where NL sentences potentially refer to some subset of states, events, or actions in the world, as long as this overall context can be represented as a semantic graph or logical form. Since the semantic lexicon is an input to our system, other approaches to lexicon learning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approache</context>
</contexts>
<marker>Zelle, Mooney, 1996</marker>
<rawString>John M. Zelle and Raymond J. Mooney. 1996. Learning to parse database queries using inductive logic programming. In Proceedings of the Thirteenth National Conference on Artificial Intelligence (AAAI-96), pages 1050–1055, Portland, OR, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of 21st Conference on Uncertainty in Artificial Intelligence (UAI-2005),</booktitle>
<location>Edinburgh, Scotland,</location>
<contexts>
<context position="29007" citStr="Zettlemoyer and Collins, 2005" startWordPosition="4806" endWordPosition="4809">traightforward to apply it to other language-grounding tasks where NL sentences potentially refer to some subset of states, events, or actions in the world, as long as this overall context can be represented as a semantic graph or logical form. Since the semantic lexicon is an input to our system, other approaches to lexicon learning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen </context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>Luke S. Zettlemoyer and Michael Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of 21st Conference on Uncertainty in Artificial Intelligence (UAI-2005), Edinburgh, Scotland, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Online learning of relaxed CCG grammars for parsing to logical form.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL-07),</booktitle>
<pages>678--687</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="29084" citStr="Zettlemoyer and Collins, 2007" startWordPosition="4818" endWordPosition="4821">es potentially refer to some subset of states, events, or actions in the world, as long as this overall context can be represented as a semantic graph or logical form. Since the semantic lexicon is an input to our system, other approaches to lexicon learning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sente</context>
</contexts>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>Luke S. Zettlemoyer and Michael Collins. 2007. Online learning of relaxed CCG grammars for parsing to logical form. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL-07), pages 678–687, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke S Zettlemoyer</author>
<author>Micheal Collins</author>
</authors>
<title>Learning context-dependent mappings from sentences to logical form.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP-09),</booktitle>
<pages>976--984</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="29133" citStr="Zettlemoyer and Collins, 2009" startWordPosition="4826" endWordPosition="4829">vents, or actions in the world, as long as this overall context can be represented as a semantic graph or logical form. Since the semantic lexicon is an input to our system, other approaches to lexicon learning are also easily incorporated. 6 Related Work Most work on learning semantic parsers that map natural-language sentences to formal representations of their meaning have relied upon totally supervised training data consisting of NL/MR pairs (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Kate and Mooney, 2006; Wong and Mooney, 2007; Zettlemoyer and Collins, 2007; Lu et al., 2008; Zettlemoyer and Collins, 2009). Several recent approaches have investigated grounded learning from ambiguous supervision extracted from perceptual context. A number of approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010; Kim and Mooney, 2010; B¨orschinger et al., 2011) assume training data consisting of a set of sentences each associated with a small set of MRs, one of which is usually the correct meaning of the sentence. Many of these approaches (Kate and Mooney, 2007; Chen and Mooney, 2008; Chen et al., 2010) disambiguate the data and match NL sentences to their correct MR by iteratively retrainin</context>
</contexts>
<marker>Zettlemoyer, Collins, 2009</marker>
<rawString>Luke .S. Zettlemoyer and Micheal Collins. 2009. Learning context-dependent mappings from sentences to logical form. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP-09), pages 976–984. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>