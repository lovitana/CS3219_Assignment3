<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000057">
<title confidence="0.994284">
Local and Global Context
for Supervised and Unsupervised Metonymy Resolution
</title>
<author confidence="0.998614">
Vivi Nastase Alex Judea Katja Markert Michael Strube
</author>
<affiliation confidence="0.996853">
HITS gGmbH University of Stuttgart University of Leeds HITS gGmbH
</affiliation>
<address confidence="0.507186">
Heidelberg, Germany Stuttgart, Germany Leeds, UK Heidelberg, Germany
</address>
<email confidence="0.9792">
vivi.nastase@h-its.org alexander.judea@ims.uni-stuttgart.de K.Markert@leeds.ac.uk michael.strube@h-its.org
</email>
<sectionHeader confidence="0.998464" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999302">
Computational approaches to metonymy res-
olution have focused almost exclusively on
the local context, especially the constraints
placed on a potentially metonymic word by
its grammatical collocates. We expand such
approaches by taking into account the larger
context. Our algorithm is tested on the data
from the metonymy resolution task (Task 8) at
SemEval 2007. The results show that incorpo-
ration of the global context can improve over
the use of the local context alone, depending
on the types of metonymies addressed. As a
second contribution, we move towards unsu-
pervised resolution of metonymies, made fea-
sible by considering ontological relations as
possible readings. We show that such an unsu-
pervised approach delivers promising results:
it beats the supervised most frequent sense
baseline and performs close to a supervised
approach using only standard lexico-syntactic
features.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.986032093023256">
With the exception of explicit tasks in metonymy
and metaphor analysis, computational treatment of
language relies on the assumption that the texts to be
processed have a literal interpretation. This contrasts
with the fact that figurative expressions are com-
mon in language, as exemplified by the metonymy
in the excerpt from a Wikipedia article in Exam-
ple 1 and another in Example 2 from the SemEval
2007 metonymy resolution task (Markert and Nis-
sim, 2009).
(1) In the gold medal game, Canada defeated the
American team 2-0 to win their third consecu-
tive gold.
(2) This keyword is only required when your rela-
tional database is Oracle.
The defeating in Example 1 will not be done
by the country as such, but by a team represent-
ing the country in a sporting event. Hence, in a
metonymy a potentially metonymic expression or
word (here Canada) stands for a conceptually re-
lated entity (here, people of Canada). In the sec-
ond Example, a company name (Oracle) stands for
a product (database) developed by the company.
Metonymy resolution can be important for a
variety of tasks. Textual entailment may need
metonymy resolution (Bentivogli et al., 2007): for
example, we would like to be able to induce from
Example 1 the hypothesis
The Canadian team won ....
Leveling and Hartrumpf (2008) show that
metonymy recognition on location proper names
helps geographical information retrieval by ex-
cluding metonymically used place names from
consideration (such as Example 1 or the use of
Vietnam for the Vietnam war). Metonymies also fre-
quently interact with anaphora resolution (Nunberg,
1995; Markert and Hahn, 2002), as in Example 1
where the metonymic use of Canada is referred to
by a plural pronoun afterward (their).
Metonymies can be quite regular: company
names can be used for their management or their
products, country names can be used for associated
sports teams. Following from this, the currently
</bodyText>
<page confidence="0.988122">
183
</page>
<note confidence="0.787665">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 183–193, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999981818181819">
prevalent set-up for metonymy resolution — as in
the SemEval 2007 task — provides a manually com-
piled list of frequent readings or metonymic patterns
such as organization-for-product for pre-
specified semantic classes (such as organizations) as
well as annotated examples for these patterns so that
systems can then treat metonymy resolution as a (su-
pervised) word sense disambiguation task. How-
ever, this approach needs novel, manual provision
of readings as well as annotated examples for each
new semantic class.
In contrast, we will see readings as relations be-
tween the potentially metonymic word (PMW) and
other concepts in a large concept network, a priori
allowing all possible relations as readings. We base
this approach on the observation that metonymic
words stand in for concepts that they are related
with – e.g. the part for the whole, the company
for the product. These readings are obtained on
the fly and are therefore independent of manually
provided, preclassified interpretations or semantic
classes, leading eventually to the possibility of un-
supervised metonymy resolution. We achieve this
by first linking a PMW to an article in Wikipedia.
Then we extract from a large concept network de-
rived from Wikipedia the relations surrounding the
PMW.
As there will be (many) more than one such rela-
tion, these need to be ranked or scored. We achieve
this in a probabilistic framework where we condi-
tion the probability of a relation on the context of
the PMW. This ranking showcases our second major
innovation in that the flexibility of our framework al-
lows us to incorporate a wider context than in most
prior approaches. Let us consider the indications for
metonymic readings and its interpretation in Exam-
ple 1, on the one hand, and Example 2, on the other
hand. In Example 1, the grammatical relation to the
verb defeat and the verb’s selectional preferences in-
dicate the metonymy. We will call all such grammat-
ically related words and the grammatical relations
the local context of the PMW. Such types of local
context have been used by most prior approaches
(Pustejovsky, 1991; Hobbs et al., 1993; Fass, 1991;
Nastase and Strube, 2009, among others). However,
Example 2 shows that the local context can be am-
biguous or often weak, such as the verb to be. In
these examples, the wider context (database, key-
word) is a better indication for a metonymy but has
not been satisfactorily integrated in prior approaches
(see Section 2). We here call all words surround-
ing the PMW but not grammatically related to it the
global context.
In our approach we integrate both the local and
the global context in our probabilistic framework.
For the local context, we compute the selectional
preferences for the words related to the PMW from a
corpus of English Wikipedia articles and generalize
them in the Wikipedia concept network, thus (auto-
matically) providing a set of abstractions – general
concepts in the network that capture the semantic
classes required by the local context. In the next
step we compute probabilities of the global con-
text surrounding the PMWs under each (locally re-
quired) abstraction, and combine this with the se-
lectional preferences of the grammatically related
words. That we can integrate local and global con-
text in one probabilistic but also knowledge-based
framework is possible because we combine two de-
scriptions of meaning – ontological and distribu-
tional – by exploiting different sources of informa-
tion in Wikipedia (category-article hierarchy and ar-
ticle texts).
We compute the probabilities of the relations (=
readings) between the concept corresponding to the
PMW and its directly related concepts. These can
be used either (i) as additional features in a super-
vised approach or (ii) directly for unsupervised res-
olution. We do both in this paper and show that (i)
the supervised approach using both local and global
context can outperform one using just local con-
text, dependent on the semantic class studied and
(ii) that an unsupervised approach — although lower
than the supervised one — outperforms the super-
vised most frequent reading baseline and performs
close to a standard supervised model with the basic
set of lexico-syntactic features (Nissim and Markert,
2005).
</bodyText>
<sectionHeader confidence="0.999914" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9997376">
The word sense disambiguation setting for
metonymy resolution as developed by Nissim
and Markert (2005) and used for the SemEval 2007
task (Markert and Nissim, 2009) uses a small, pre-
specified number of frequently occurring readings.
</bodyText>
<page confidence="0.998045">
184
</page>
<bodyText confidence="0.999897622222222">
The approaches building on this work (Farkas et
al., 2007; Nicolae et al., 2007, among others) are
supervised, mostly using shallow surface features
as well as grammatical relations.1 Most effective
in the SemEval task as summarized in Markert
and Nissim (2009) has been the local, grammatical
context, with the two systems relying on the global
context or the local/global context in a BOW model
(Leveling, 2007; Poibeau, 2007) not outperforming
the most frequent reading baseline. We believe
that might be due to the lack of a link between the
local and global context in these approaches — in
our work, we condition the global context on the
abstractions and selectional preferences yielded by
the local context and achieve better results.
Lapata (2003), Shutova (2009) as well as Roberts
and Harabagiu (2011) deal with the issue of logical
metonymy, where the participant stands in for the
full event: e.g. Mary enjoyed the book., where book
stands in for reading the book, and this missing event
(reading) can be inferred from a corpus. Utiyama
et al. (2000), Lapata (2003) propose a probabilis-
tic model for finding the correct interpretation of
such metonymies in an unsupervised manner. How-
ever, these event type metonymies differ from the
problem dealt with in our paper and the SemEval
2007 task in that their recognition (i.e. their distinc-
tion from literal occurrences) is achieved simply by
grammatical patterns (a noun instead of a gerund or
to-infinitive following the verb) and the problem is
limited to interpretation.
Our view of relations in a concept network being
the interpretations of metonymies is strongly remi-
niscent of older work in metonymy resolution such
as Hobbs et al. (1993), Fass (1991), Markert and
Hahn (2002) or the use of a generative lexicon and
its relations in Pustejovsky (1991), which also are
unsupervised. However, these approaches lacked
scalability due to the use of small hand-modeled
knowledge bases which our use of a very large
Wikipedia-derived ontology overcomes. In addition,
most of these approaches (Fass, 1991; Hobbs et al.,
1993; Pustejovsky, 1991; Harabagiu, 1998) rely on
the view that metonymies violate selectional restric-
tions in their immediate, local context, usually those
</bodyText>
<footnote confidence="0.859566">
1Brun et al. (2007) is semi-supervised but again relies on the
local grammatical context.
</footnote>
<bodyText confidence="0.999865142857143">
imposed by the verbs on their arguments. As can
be seen in the Example 2, this misses metonymies
which do not violate selectional restrictions. Nas-
tase and Strube (2009) use more flexible proba-
bilistic selectional preferences instead of strict con-
straint violations as well as WordNet as a larger tax-
onomy but are also restricted to the local context.
Markert and Hahn (2002) do propose a treatment of
metonymies that takes into account the larger dis-
course in the form of anaphoric relations between
a metonymy and the prior context. However, they
constrain discourse integration to potential PMWs
that are definite NPs and the context to few previous
noun phrases. In addition, their framework uses a
strict rule-based ranking of competing readings that
cannot be easily extended.
The work presented here also relies on a con-
cept network, built automatically from Wikipedia.
This resource provides us with links between enti-
ties in the text, and also a variety of ontological re-
lations for the PMW, that will allow us to identify a
wide variety of metonymic interpretations. Our ap-
proach combines information from the concept net-
work with automatically acquired selectional prefer-
ences as well as a possibility to combine in a prob-
abilistic framework the influence of the local and
global context on the interpretation of a potentially
metonymic word.
</bodyText>
<sectionHeader confidence="0.978478" genericHeader="method">
3 The Approach
</sectionHeader>
<bodyText confidence="0.999995066666667">
The approach we present takes into account both
the local, grammatical, context and the larger textual
context of a potentially metonymic word. Figure 1
presents a graphical representation of our approach.
On the one hand, the word/term to be interpreted
(the potentially metonymic word/term – PMW) is
mapped onto a concept in the concept network (Sec-
tion 3.3), which gives us access to the conceptual
relations (TZ,) between the PMW and other concepts
(c,, E CIZ). On the other hand, any word w gram-
matically related to the PMW via a grammatical re-
lation r provides us with semantic restrictions on the
interpretation of the PMW, namely preferred seman-
tic classes Aj (we call them abstractions) and a se-
lectional preference score.2 These are automatically
</bodyText>
<footnote confidence="0.732439">
2We restrict the grammatical context that provides selec-
tional preferences to verbs or adjectives grammatically related
</footnote>
<page confidence="0.996606">
185
</page>
<figureCaption confidence="0.9944905">
Figure 1: Metonymy resolution using selectional preferences Aj derived from local context w and r, semantic relations
Ri to the PMW from a concept network, and the global context surrounding a term to be interpreted
</figureCaption>
<figure confidence="0.998660730769231">
w
r
A1 A2
...
An
p(Ri|qj) p(qj|Cont,w,r)
c1 2
c1 1
ck2
ck1
c1 4
ck3 ck4
c13 c1 n−1
c1 n
...
ckm−1
ckm
w1w2w3
... ...
...
... ...
R1 Rk
...
wl
Global context
PMW
</figure>
<bodyText confidence="0.995680230769231">
acquired by using a corpus of Wikipedia articles and
a repository of encyclopedic knowledge (presented
in Section 3.1), as described in detail in 3.2. Because
the abstractions Aj and the PMW’s related concepts
(c,,) come from the same structured resource, we
can compute the probabilities for each R. given the
grammatically related word w and the grammatical
relation r. The global context can also easily be
added to the computation, as the probability of each
word in the context relative to an abstraction Aj can
be computed through the resource’s is a hierarchy
and its link to Wikipedia articles. This is detailed in
Section 3.4.
</bodyText>
<subsectionHeader confidence="0.964853">
3.1 A concept network obtained from
Wikipedia
</subsectionHeader>
<bodyText confidence="0.995732318181818">
We use a Wikipedia article dump (January 2011)
which provided over 3.5 million English articles,
interconnected through a hierarchy of categories
and hyperlinks. This partly structured repository
is transformed into a large-scale multilingual con-
cept network, whose nodes are concepts correspond-
ing to articles or categories in Wikipedia (Nastase
et al., 2010). Concepts in this network are con-
nected through a variety of semantic relations (e.g.
is a, member of, nationality) derived from category
names and infoboxes. The version of WikiNet used
to the PMW.
had 3,707,718 nodes and 49,931,266 relation in-
stances of 494 types, and is freely available3.
WikiNet is used here as a concept inventory,
and its links and structure to generalize more spe-
cific concepts identified in texts to general concepts.
The fact that nodes in WikiNet correspond to arti-
cles/categories in Wikipedia is used to link article
texts in Wikipedia to general concepts, for the pur-
pose of computing various probability scores (de-
tailed in Section 3.4).
</bodyText>
<subsectionHeader confidence="0.999968">
3.2 Selectional preferences and abstractions
</subsectionHeader>
<bodyText confidence="0.999949466666667">
To compute selectional preferences we use the set of
English Wikipedia articles, which describe specific
concepts. Wikipedia contributors are encouraged to
insert hyperlinks, which link important terms in an
article to the corresponding articles. A hyperlink
consists of two parts, the actual link (i.e. a URL)
and a phrase to appear in the text. Hyperlinks then
constitute a bridge from the textual level to the con-
ceptual level without the need for word sense dis-
ambiguation. We exploit these links to gather con-
cept arguments for verbs and adjectives, and gen-
eralize these using the concept network built from
Wikipedia.
The corpus of Wikipedia articles was first en-
riched with hyperlinks, making the “one sense per
</bodyText>
<footnote confidence="0.949343">
3http://www.h-its.org/english/research/
nlp/download/wikinet.php
</footnote>
<page confidence="0.972704">
186
</page>
<equation confidence="0.96663112">
Algorithm 1 computeSelPrefs(G,WkN)
Input: G – grammatical relation triples
WkN – WikiNet
M – maximum number of generalization steps
Output: r
r = {}
for all (w, r) such that (c, r, w) ∈ G do
S = {(c, f)|f is the frequency of (c, r, w) in G}
rw,r = S
mdl = MDL(rw,r, S)
for all i = 1,M do
r&apos; = abstract(S, WkN)
mdlr, = MDL(r&apos;, S)
if mdlr, &lt; mdl then
rw,r = r&apos;
r = {rw,r} ∪ r
return r
Algorithm 2 MDL(r, S)
Input: r = {(c, f)} – a scored list of concepts
S – the set of observations (concept collocates)
Output: MDL(r, S)
�0 =&lt; f1, ..., fn &gt;; (ci, fi) ∈ r
remove {(c, f) ∈ r|f = 1} // parameter description
length :
L(�0|r) = �r� 1
2 ∗ log(|S|) // data description length:
for all (c, f) ∈ r do
L(S|r,�0) = L(S|r,
Algorithm 3 abstract(S,WkN)
Input: S = {(c, f)|(w, R, c) ∈ G}
WkN – WikiNet
Output: S&apos;
S&apos; = {}
for c|(c, ) ∈ S do
while c has only one is a link do
c = c&apos;, (c, is a, c&apos;) ∈ WkN
C = {(c&apos;,c)|(c,is a, c&apos;) ∈ WkN}
for (c&apos;, c) ∈ C do
if (c&apos;, f&apos;) ∈ S&apos; then
replace (c&apos;, f&apos;) with (c&apos;, f&apos; + f
�C�), (c, f) ∈ S
in S&apos;
else
S&apos;∪ = {(c&apos;, f)}, (c, f) ∈ S
// Remove hyponyms.
for all {(c,c&apos;) ∈ S&apos;|(c&apos;, is a, c) ∈ WkN} do
// update frequency f of c
fc = fc + fc,,f ∈ S
delete c&apos;
return S&apos;
</equation>
<bodyText confidence="0.999476342105263">
discourse” assumption – a phrase that appears as-
sociated with a hyperlink once in the article body
will be associated with the same hyperlink through-
out the article (this applies to the article title as well,
which is not hyperlinked in the article itself). This
new version of the corpus was then split into sen-
tences, and those without hyperlinks were removed.
The remaining 18 million sentences were parsed
with a parallelized version of Ensemble4 (Surdeanu
and Manning, 2010), and we extracted G, the set of
all grammatical relations of the type (verb, depen-
dency, hyperlink) and (adjective, dependency, hy-
perlink), with the hyperlinks resolved to their cor-
responding node (concept) in the network ( |G |=
1,578,413 triples). For each verb and adjective in the
extracted collocations, and for each of their depen-
dency relations, their collocates were generalized in
the network defined by the hypernym/hyponym re-
lations in WikiNet following a method similar to the
Minimum Description Length principle (Li and Abe,
1998).
Essentially, we aimed to determine a small set of
(more general) concepts that describe the set of col-
locates for a word w and grammatical relation r.
Starting from the concept collocates gathered, we
go upwards following WikiNet’s is a links, and for
each node found that covers at least N concept col-
locates (N is a parameter, N=2 in the experiments
presented here), the MDL score of the node is com-
puted (Algorithm 2). We place a limit M on the
number of upward steps in the hierarchy (M=3 in
our experiments). The disjoint set of nodes that has
the lowest overall MDL score is chosen (r), and for
each node in this cut (which we call abstraction),
we compute the selectional preference score, based
on the number of concepts it dominates.
As an example, for the verb defeat, the corpus
leads to collocations such as5:
</bodyText>
<figure confidence="0.773689285714286">
defeat
nsubj
Earle Page (10357) – 8, Manuela Maleeva
(1092361) – 7, New York Yankees
(10128601) – 5, Tommy Haas (1118005)
– 5, ...
obj
</figure>
<footnote confidence="0.9485285">
4http://www.surdeanu.name/mihai/
ensemble/
5The format is:
Article name (Article Id) – frequency.
</footnote>
<equation confidence="0.776729333333333">
0) + f ∗ log( f
hyponyms(c�*�r�)
return L(�0|r) − L(S|r, 0)
</equation>
<page confidence="0.7981">
187
</page>
<figure confidence="0.631470933333333">
New York Yankees (10128601) – 9, Oak-
land Athletics (11641124) – 6, Phoenix
Suns (11309373) – 4, Jason Suttie
(10080653) – 3, Ravana (100234) – 3, ...
Determining abstractions and selectional prefer-
ences leads to the following information6:
defeat
nsubj
Martial artists (118977183) – 0.5, Person
(219599) – 0.3518, Interest (146738) –
0.037, .. .
obj
Video games (9570081) – 0.25, British
games (24489088) – 0.25, Person (219599)
– 0.1445, Interest (146738) – 0.1341, ...
</figure>
<subsectionHeader confidence="0.997858">
3.3 Linking the PMW to the concept network
</subsectionHeader>
<bodyText confidence="0.999989380952381">
In our environment, linking the PMW to the con-
cept network is equivalent to finding its correspond-
ing concept in our ontology, WikiNet. We see this
corresponding concept as the literal reading of the
PMW. Doing so is a non-trivial task (see the Cross-
Lingual Link Discovery task at NTCIR-9 (Tang et
al., 2011) and the Cross-Lingual Entity Linking task
– part of the Knowledge Base Population track – at
TAC 20117). In our particular setting, where we use
the metonymy data from SemEval 2007, the domain
of the PMW is well defined: locations and compa-
nies, respectively. Using these constraints, finding
the corresponding Wikipedia articles is much sim-
plified, by using the category hierarchy and con-
straining the concepts to fall under the Geography
and Companies categories respectively. When mul-
tiple options are present, we find instead a matching
disambiguation page. In this case we pick the article
that is listed first on this disambiguation page. On
a manually checked random sample, the accuracy of
the approach was 100% (on a sample of 100 PMWs).
</bodyText>
<subsectionHeader confidence="0.9683625">
3.4 Scoring conceptual relations with local and
global context
</subsectionHeader>
<bodyText confidence="0.99993075">
We work under the assumption that the concept cor-
responding to the PMW is related to the possible in-
terpretations through a semantic relation, in particu-
lar one that is captured in the concept network. After
</bodyText>
<footnote confidence="0.997860333333333">
6The format is:
Concept name (Concept Id) – selectional preference score.
7http://nlp.cs.qc.cuny.edu/kbp/2011/
</footnote>
<note confidence="0.86778775">
countries : Administrator of, Architect of,
Based in, Built in, Continent,...
companies: Association, Brand, Company, Dis-
tributed by, Executive of, ...
</note>
<tableCaption confidence="0.999326">
Table 1: Example conceptual relations
</tableCaption>
<bodyText confidence="0.998681916666667">
establishing the connection to the resource by link-
ing the PMW to the concept cPMW corresponding to
its literal interpretation (see Section 3.3), we extract
the relations in which it is involved (Ri, i = 1, k),
and the concepts it is connected to through these re-
lations (Cpi = {cx|(cPMWRicx)I). Table 1 shows
examples of conceptual relations extracted for com-
panies and countries.
We are interested in computing the likelihood of
a conceptual relation being the correct interpreta-
tion of a PMW, given its local and global context
p(Ri|Cont, w, r).
</bodyText>
<subsectionHeader confidence="0.911972">
3.4.1 The local context
</subsectionHeader>
<bodyText confidence="0.999919454545455">
The local context considered in this work are all
grammatically related verbs and adjectives w and
their associated grammatical relation r. The gram-
matical analysis (see Section 3.2) provides the set of
abstractions corresponding to the grammatically re-
lated word w and grammatical relation r: Aj, j =
1, n. Remember that these are local context con-
straints on the interpretation of the PMW.
Through the knowledge resource used we can es-
tablish and quantify connections between each cx
and Aj, and thus between each Ri and Aj:
</bodyText>
<equation confidence="0.9897355">
(3) p(Ri|Aj) = � p(cx|Aj)
xEC7,i
</equation>
<bodyText confidence="0.791578333333333">
where p(cx|Aj) is the probability of concept cx un-
der abstraction Aj, which is computed based on the
semantic relations in WikiNet:
</bodyText>
<equation confidence="0.982283">
p(cx|Aj) = � ri p(hi|hi+1)
H hiEH
</equation>
<bodyText confidence="0.999289833333333">
where H is in turn each path from cx to Aj following
is a links in WikiNet, starting with cx (i.e. h0 = cx)
and ending in Aj. p(hi|hi+1) is the probability of
the child node hi given its ancestor hi+1. Within this
work we assume a uniform probability distribution
in each node:
</bodyText>
<page confidence="0.93857">
188
</page>
<equation confidence="0.995835">
p(hi|hi+1) = |descendants(hi+1)|
1
</equation>
<bodyText confidence="0.84452875">
Through this, it is straightforward that
Ec. p(cx|Aj) = 1 when cx ranges over all
concepts subsumed by Aj, and is thus a valid
probability distribution.
</bodyText>
<subsectionHeader confidence="0.933222">
3.4.2 The global context
</subsectionHeader>
<bodyText confidence="0.9996425">
The abstractions obtained before are concepts.
We extract all nodes in the network subsumed
by these concepts, and their corresponding articles
in Wikipedia (if they have one). This produces
“abstraction-specific” article sets, based on which
we compute the probability of the global context of
a PMW for each abstraction. We are interested in
the probability of an abstraction, given the context
and the word w and grammatical relation r, which
we compute as:
</bodyText>
<equation confidence="0.989239">
p(Aj|Cont, w, r) = p(Cont|Aj, w, r) * p(Aj, w, r)
p(Cont, w, r)
</equation>
<bodyText confidence="0.9933995">
which, considering that p(Cont, w, r) is the same
for a given context, we approximate as
</bodyText>
<equation confidence="0.9004955">
p(Aj|Cont) Pz� p(Cont|Aj) * p(Aj, w, r)
p(Aj, w, r) = p(Aj|w, r)*p(w, r), and we approxi-
</equation>
<bodyText confidence="0.852487333333333">
mate it through the computed selectional preference
p(Aj|w, r), since p(w, r) is constant for a given ex-
ample to analyze.
</bodyText>
<equation confidence="0.9939785">
p(Cont|Aj)p(Aj|w, r)
m p(wl|Aj))p(Aj|w, r)
(
l=1
</equation>
<bodyText confidence="0.7979875">
where Cont is the global context consisting of m
words wl, l = 1, m.8
</bodyText>
<footnote confidence="0.9937662">
8The global context therefore could be all words in a text
or all words in a sentence or any other token-based definition
in our framework. As the SemEval 2007 data gives metonymic
examples in a three-sentence context we use all the words in the
3 sentences as our global context.
</footnote>
<equation confidence="0.996967">
p(wl|Aj) = |Aj|
count(wl, Aj)
</equation>
<bodyText confidence="0.999822">
where Aj is the set of articles subsumed by abstrac-
tion Aj, and count(wl, Aj) is the number of times
word wl appears in the article collection Aj.
</bodyText>
<subsectionHeader confidence="0.931727">
3.4.3 Putting it all together
</subsectionHeader>
<bodyText confidence="0.999814">
This enables us now to compute p(Ri|Cont, w, r)
based on the formulas 3, 4:
</bodyText>
<equation confidence="0.985895666666667">
n
p(Ri|Cont, w, r) = (p(Ri|Aj)*p(Aj|Cont, w, r))
j=1
</equation>
<sectionHeader confidence="0.998685" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999968909090909">
The computed probabilities for each conceptual re-
lation (= potential readings) of the PMW in the con-
cept network can be used as features in a supervised
framework or directly as an unsupervised prediction,
returning the most likely conceptual relation given
the context as the required reading.
Although the latter is our ultimate goal, to allow
comparison with related work from the metonymy
resolution task (Task 8) at SemEval 2007, we first
investigate the supervised set-up. We then simulate
the unsupervised setting in Section 4.3.
</bodyText>
<subsectionHeader confidence="0.985276">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999879285714286">
We use the data from the metonymy resolution task
(Task 8) at SemEval 2007. It consists of training and
test data for country and company names which are
potentially metonymic. Table 2 shows the statistics
of the data, and the possible interpretations for the
PMWs. The training-test division was achieved ran-
domly so that the test data can have metonymic read-
ings for which no training data exists, showing again
the limitations of a supervised approach of prespec-
ified readings.
Grammatical features The features used by Nis-
sim and Markert (2005), and commonly used for
the supervised classification of metonymy readings
(Markert and Nissim, 2009):
</bodyText>
<listItem confidence="0.983554333333333">
• grammatical role of PMW (subj, obj, ...);
• lemmatized head/modifier of PMW (announce,
say, ...);
</listItem>
<equation confidence="0.984602">
n
p(Cont|Aj, w, r) =
j=1
n
j=1
</equation>
<page confidence="0.988538">
189
</page>
<bodyText confidence="0.980035619047619">
reading train test
locations
literal
mixed
othermet
obj-for-name
obj-for-representation
place-for-people
place-for-event
place-for-product
organizations
literal
mixed
othermet
obj-for-name
obj-for-representation
org-for-members
org-for-event
org-for-product
org-for-facility
org-for-index
</bodyText>
<tableCaption confidence="0.872253">
Table 2: Statistics for the Task 8 data
</tableCaption>
<listItem confidence="0.9999595">
• determiner of PMW (def, indef, bare, demonst,
other, ...);
• grammatical number of PMW (sg, pl);
• number of grammatical roles in which the
PMW appears in its current context;
• number of words in PMW.
</listItem>
<bodyText confidence="0.986172863636364">
All these features can be extracted from the gram-
matically annotated and POS tagged data provided
by the organizers.
The annotations provided are dependency rela-
tions, many of which contain a preposition as an ar-
gument (e.g. (to, pp, UK) from the example ... the
visit to the UK of ...). Such relations are not infor-
mative, but together with the head that dominates the
prepositional complement (e.g. visit to) they may be.
Because of this, we process the provided annotations
and add wherever possible to the simple prepositions
the head of their subsuming constituent. This would
change the above mentioned dependency to (visit,
prep-to, UK).
Semantic relations as features To evaluate the
proposed approach we use the PMW’s conceptual
relations as features. The feature values are the
p(TZi|Cont, w, r) scores.
For the “countries” portion of the data this adds
109 semantic relation features, and for companies
29 features. Table 1 showed examples of these new
features.
</bodyText>
<subsectionHeader confidence="0.997789">
4.2 Supervised learning
</subsectionHeader>
<bodyText confidence="0.976341806451613">
We use the SMO classifier in the WEKA machine
learning toolkit (Witten and Frank, 2000) with its
standard settings, training on the SemEval 2007
(Task 8) training set.
Table 3 shows the results of various configura-
tions on the test data, in comparison with a most
frequent reading baseline (assigning literal to all
PMWs) as well as a system M&amp;N that shows the re-
sults computed using only the features proposed by
Nissim and Markert (2005). In addition, we com-
pare to the best results9 at SemEval 2007 (5Emax)
and Nastase and Strube (2009) (N09). Nastase and
Strube (2009) added WordNet supersenses as fea-
tures, and their values are selectional preferences
computed with reference to WordNet. These are
similar to our abstractions, which in our approach
serve to link the local and the global context to the
ontological relations, but do not appear as features.
Our system 5P shows the results obtained us-
ing the M&amp;N features plus the conceptual relation
features conditioned on both local and global con-
text whereas 5Plocal and 5Pglobal use conceptual
relations conditioned on local (p(Aj|Cont, w, r) �
p(Aj|w, r)) or global context (p(Aj|Cont, w, r) �
p(Aj|Cont) _ En j�1(Hml�1 p(wl|Aj))) only.
While the differences in overall accuracies are
small, there are significant differences in classifying
individual classes, as shown in Tables 4 – 510, where
the distrib. column shows the class distribution in
the test data. It is interesting to note that, in our set-
ting, the global context is more useful than the local
</bodyText>
<footnote confidence="0.980282571428571">
9We show the best result for each category, not necessarily
from the overall best performing system. This holds for Tables
4 and 5 as well.
10The detailed results for previous approaches are reproduced
from (Nastase and Strube, 2009). We include only the classes
that have a non-zero F-score for at least one of the presented
approaches.
</footnote>
<figure confidence="0.99768145">
925 908
737 721
15 20
9 11
0 4
0 0
161 141
3 10
0 1
1090 842
690 520
59 60
14 8
8 6
1 0
220 161
2 1
74 67
15 16
7 3
</figure>
<page confidence="0.98014">
190
</page>
<table confidence="0.998378142857143">
task 1 method -* baseline SEmax N09 M&amp;N SP SPlocal SPglobal SPunsup
LOCATION-COARSE 79.4 85.2 86.1 83.4 85.8 83.0 85.0 81.6
LOCATION-MEDIUM 79.4 84.8 85.9 82.3 85.7 82.7 84.6 81.5
LOCATION-FINE 79.4 84.4 85.0 81.3 84.7 82.1 83.8 81.0
ORGANIZATION-COARSE 61.8 76.7 74.9 74.0 77.0 76.4 76.8 67.8
ORGANIZATION-MEDIUM 61.8 73.3 72.4 69.4 74.6 74.0 74.4 66.3
ORGANIZATION-FINE 61.8 72.8 71.0 68.5 72.8 71.9 72.7 65.3
</table>
<tableCaption confidence="0.7559945">
Table 3: Accuracy scores
task 1 method -* distrib. SEmax N09 SP task 1 method -* distrib. SEmax N09 SP
</tableCaption>
<table confidence="0.995990545454546">
LOCATION-COARSE
79.4 91.2 91.6 91.4
20.6 57.6 59.1 58.5
79.4 91.2 91.6 91.4
18.4 58.0 61.5 61.6
2.2 8.3 16 9.1
79.4 91.2 91.6 91.4
15.5 58.9 61.7 61.1
1.1 16.7 0 0
0.4 66.7 0 0
2.2 8.3 16 9.1
</table>
<tableCaption confidence="0.9859195">
Table 4: Fine-grained results for each classification task
for countries (F-scores)
</tableCaption>
<bodyText confidence="0.999829736842105">
one for resolving metonymies. Combining local and
global evidence improves over both, indicating that
the information they provide is not redundant.
For companies the difference is small in terms of
accuracy, but in classification of individual classes
the difference in performance is higher, but because
of the small data size not statistically significant.
Countries in WikiNet have a high number of sur-
rounding relations, because they are used as cat-
egorization criteria for professionals, for example,
which generates fine-grained relations such as Ad-
ministrator of, Ambassador of, Chemist of .... Such
a fine grained distinction between different profes-
sions for people in a country is not necessary, or in-
deed, desirable, for the metonymy resolution task.
The results show that despite this shortcoming, the
results are on par with the state-of-the-art, but in fu-
ture work we plan to explore the task of relation gen-
eralization and its impact on the current task.
</bodyText>
<table confidence="0.984445916666667">
ORGANIZATION-COARSE
82.5 81.4 82.7
65.2 61.6 65.5
82.5 81.4 82.7
60.4 58.7 63.1
30.8 26.8 27.4
82.6 81.4 82.7
63.0 59.7 66.5
50.0 44.4 35.0
22.2 36.3 45.5
80.0 58.8 44.4
34.3 27.1 27.4
</table>
<tableCaption confidence="0.9903785">
Table 5: Fine-grained results for each classification task
for companies (F-scores)
</tableCaption>
<subsectionHeader confidence="0.787355">
4.3 Simulating unsupervised metonymy
resolution
</subsectionHeader>
<bodyText confidence="0.9996905">
In an unsupervised metonymy resolution approach,
we would assign as interpretation the conceptual re-
lation whose probability given the PMW, global and
local contexts is highest. To simulate then the un-
supervised metonymy resolution task, we make the
relation features (used in the supervised approach)
binary, where for each instance the relation that has
highest probability has the value 1, the others 0.
Using only the relation features simulates an un-
supervised approach – this set-up learns a map-
ping between the relations used as features and
the metonymy classes in the data used. Column
SPUnsup in Table 3 shows the results obtained in
this configuration. As expected the results are lower,
but still close to the supervised method when using
only grammatical features (M&amp;N) for the location
</bodyText>
<figure confidence="0.99871428">
literal
non-literal
LOCATION-MEDIUM
literal
metonymic
mixed
LOCATION-FINE
literal
place-for-people
place-for-event
obj-for-name
mixed
literal 61.8
non-literal 38.2
ORGANIZATION-MEDIUM
literal 61.8
metonymic 31.0
mixed 7.2
ORGANIZATION-FINE
literal 61.8
org-for-members 19.1
org-for-product 8.0
org-for-facility 2.0
org-for-name 0.7
mixed 7.2
</figure>
<page confidence="0.991156">
191
</page>
<bodyText confidence="0.9999719">
setting. The results also significantly beat the base-
line (apart from the Location-Fine setting). One fea-
ture that contributes greatly to the results, especially
for the company semantic class, is the grammatical
role of the PMW, but we could not incorporate this
in the unsupervised setting.
The results in the simulated unsupervised set-
ting indicate that relations are a viable substitute
for manually provided classes in an unsupervised
framework, while leaving space for improvement.
</bodyText>
<sectionHeader confidence="0.999261" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999997181818182">
We have explored the usage of local and global con-
text for the task of metonymy resolution in a prob-
abilistic framework. The global context has been
rarely used for the task of determining the intended
reading of a potentially metonymic word (PMW)
in context. We rely on automatically computed se-
lectional preferences, extracted from a corpus of
Wikipedia articles, and generalized based on a con-
cept network also extracted from Wikipedia. De-
spite relying on automatically derived resources, the
presented approach produces results on-a-par with
current state-of-the-art systems. The method de-
scribed here is also a step towards the unsupervised
resolution of metonymic words in context, by tak-
ing into account knowledge about the concept cor-
responding to the literal interpretation of the PMW,
and its relations to other concepts. This frame-
work would also allow for exploring the metonymy
resolution phenomena in various languages (since
Wikipedia and WikiNet are multilingual), and inves-
tigate whether the same relations apply or different
languages have different metonymic patterns.
</bodyText>
<sectionHeader confidence="0.998137" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99987075">
Katja Markert is the recipient of an Alexander-von-
Humboldt Fellowship for Experienced Researchers.
This work was financially supported by the EC-
funded project CoSyne (FP7-ICT-4-24853) and the
Klaus Tschirra Foundation. We thank the review-
ers for the helpful comments, and Helga Kr¨amer-
Houska for additional support for conference partic-
ipation.
</bodyText>
<sectionHeader confidence="0.998467" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999922692307692">
Luisa Bentivogli, Elena Cabrio, Ido Dagan, Danilo Gi-
ampiccolo, Medea Lo Leggio, and Bernardo Magnini.
2007. Building textual entailment specialized data
sets: A methodology for isolating linguistic phenom-
ena relevant to inference. In Proceedings of the 7th
International Conference on Language Resources and
Evaluation, La Valetta, Malta, 17–23 May 2010.
Caroline Brun, Maud Ehrmann, and Guillaume Jacquet.
2007. XRCE-M: A hybrid system for named en-
tity metonymy resolution. In Proceedings of the
4th International Workshop on Semantic Evaluations
(SemEval-1), Prague, Czech Republic, 23–24 June
2007, pages 488–491.
Rich´ard Farkas, Eszter Simon, Gy¨orgy Szarvas, and
D´aniel Varga. 2007. GYDER: Maxent metonymy res-
olution. In Proceedings of the 4th International Work-
shop on Semantic Evaluations (SemEval-1), Prague,
Czech Republic, 23–24 June 2007, pages 161–164.
Dan C. Fass. 1991. met*: A method for discriminating
metonomy and metaphor by computer. Computational
Linguistics, 17(1):49–90.
Sanda M. Harabagiu. 1998. Deriving metonymic co-
ercions from WordNet. In Proceedings of the Work-
shop on the Usage of WordNet in Natural Language
Systems, Montral, Quebec, Canada, 16 August, 1998,
pages 142–148.
Jerry Hobbs, Mark Stickel, Douglas Appelt, and Paul
Martin. 1993. Interpretation as abduction. Artificial
Intelligence, 63(1-2):69–142.
Maria Lapata. 2003. Probabilistic text structuring: Ex-
periments with sentence ordering. In Proceedings of
the 41st Annual Meeting of the Association for Compu-
tational Linguistics, Sapporo, Japan, 7–12 July 2003,
pages 545–552.
Johannes Leveling and Sven Hartrumpf. 2008. On
metonymy recognition for geographic information re-
trieval. International Journal of Geographical Infor-
mation Science, 22(3):289–299.
Johannes Leveling. 2007. FUH (FernUniversit¨at in Ha-
gen): Metonymy recognition using different kinds of
context for a memory-based learner. In Proceedings
of the 4th International Workshop on Semantic Eval-
uations (SemEval-1), Prague, Czech Republic, 23–24
June 2007, pages 153–156.
Hang Li and Naoki Abe. 1998. Generalizing case frames
using a thesaurus and the MDL principle. Computa-
tional Linguistics, 24(2):217–244.
Katja Markert and Udo Hahn. 2002. Metonymies in dis-
course. Artificial Intelligence, 135(1/2):145–198.
Katja Markert and Malvina Nissim. 2009. Data and
models for metonymy resolution. Language Re-
sources and Evaluation, 43(2):123–138.
</reference>
<page confidence="0.978296">
192
</page>
<reference confidence="0.99897555882353">
Vivi Nastase and Michael Strube. 2009. Combining
collocations, lexical and encyclopedic knowledge for
metonymy resolution. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing, Singapore, 6-7 August 2009, pages
910–918.
Vivi Nastase, Michael Strube, Benjamin B¨orschinger,
C¨acilia Zirn, and Anas Elghafari. 2010. WikiNet:
A very large scale multi-lingual concept network.
In Proceedings of the 7th International Conference
on Language Resources and Evaluation, La Valetta,
Malta, 17–23 May 2010.
Cristina Nicolae, Gabriel Nicolae, and Sanda Harabagiu.
2007. UTD-HLT-CG: Semantic architecture for
metonymy resolution and classification of nominal re-
lations. In Proceedings of the 4th International Work-
shop on Semantic Evaluations (SemEval-1), Prague,
Czech Republic, 23–24 June 2007, pages 454–459.
Malvina Nissim and Katja Markert. 2005. Learning to
buy a Renault and talk to BMW: A supervised ap-
proach to conventional metonymy. In Proceedings of
the 6th International Workshop on Computational Se-
mantics, Tilburg, Netherlands, January 12-14, 2005.
Geoffrey Nunberg. 1995. Transfers of meaning. Journal
of Semantics, 12(1):109–132.
Thierry Poibeau. 2007. Up13: Knowledge-poor meth-
ods (sometimes) perform poorly. In Proceedings of
the 4th International Workshop on Semantic Evalu-
ations (SemEval-1), Prague, Czech Republic, 23–24
June 2007, pages 418–421.
James Pustejovsky. 1991. The generative lexicon. Com-
putational Linguistics, 17(4):209–241.
Kirk Roberts and Sanda M. Harabagiu. 2011. Unsuper-
vised learning of selectional restrictions and detection
of argument coercions. In Proceedings of the 2011
Conference on Empirical Methods in Natural Lan-
guage Processing, Edinburgh, UK, 27-29 July 2011,
pages 980–990.
Ekaterina Shutova. 2009. Sense-based interpretation of
logical metonymy using a statistical method. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the Association for Computational Lin-
guistics and the 4th International Joint Conference on
Natural Language Processing, Singapore, 2–7 August
2009, pages 1–9.
Mihai Surdeanu and Christopher D. Manning. 2010. En-
semble Models for Dependency Parsing: Cheap and
Good? In Proceedings of Human Language Tech-
nologies 2010: The Conference of the North American
Chapter of the Association for Computational Linguis-
tics, Los Angeles, Cal., 2–4 June 2010, pages 649–
652.
Ling-Xiang Tang, Shlomo Geva, Andrew Trotman, Yue
Xu, and Kelly Y. Itakura. 2011. Overview of the
NTCIR-9 crosslink task: Cross-lingual link discovery.
In Proceedings of the 9th NII Test Collection for IR
Systems Workshop meeting – NTCIR-9 Tokyo, Japan,
6–9 December 2011.
Masao Utiyama, Masaki Murata, and Hitoshi Isahara.
2000. A statistical approach to the processing
of metonymy. In Proceedings of the 18th Inter-
national Conference on Computational Linguistics,
Saarbr¨ucken, Germany, 31 July – 4 August 2000,
pages 885–891.
Ian H. Witten and Eibe Frank. 2000. Data Mining:
Practical Machine Learning Tools and Techniques
with Java Implementations. Morgan Kaufmann, San
Diego, CA.
</reference>
<page confidence="0.999245">
193
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.805751">
<title confidence="0.9990495">Local and Global Context for Supervised and Unsupervised Metonymy Resolution</title>
<author confidence="0.999824">Vivi Nastase Alex Judea Katja Markert Michael Strube</author>
<affiliation confidence="0.964605">HITS gGmbH University of Stuttgart University of Leeds HITS gGmbH</affiliation>
<address confidence="0.961626">Heidelberg, Germany Stuttgart, Germany Leeds, UK Heidelberg, Germany</address>
<email confidence="0.970106">vivi.nastase@h-its.orgalexander.judea@ims.uni-stuttgart.deK.Markert@leeds.ac.ukmichael.strube@h-its.org</email>
<abstract confidence="0.994946090909091">Computational approaches to metonymy resolution have focused almost exclusively on the local context, especially the constraints placed on a potentially metonymic word by its grammatical collocates. We expand such approaches by taking into account the larger context. Our algorithm is tested on the data from the metonymy resolution task (Task 8) at SemEval 2007. The results show that incorporation of the global context can improve over the use of the local context alone, depending on the types of metonymies addressed. As a second contribution, we move towards unsupervised resolution of metonymies, made feasible by considering ontological relations as possible readings. We show that such an unsupervised approach delivers promising results: it beats the supervised most frequent sense baseline and performs close to a supervised approach using only standard lexico-syntactic features.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Luisa Bentivogli</author>
<author>Elena Cabrio</author>
<author>Ido Dagan</author>
<author>Danilo Giampiccolo</author>
<author>Medea Lo Leggio</author>
<author>Bernardo Magnini</author>
</authors>
<title>Building textual entailment specialized data sets: A methodology for isolating linguistic phenomena relevant to inference.</title>
<date>2007</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation,</booktitle>
<location>La Valetta, Malta, 17–23</location>
<contexts>
<context position="2438" citStr="Bentivogli et al., 2007" startWordPosition="368" endWordPosition="371">to win their third consecutive gold. (2) This keyword is only required when your relational database is Oracle. The defeating in Example 1 will not be done by the country as such, but by a team representing the country in a sporting event. Hence, in a metonymy a potentially metonymic expression or word (here Canada) stands for a conceptually related entity (here, people of Canada). In the second Example, a company name (Oracle) stands for a product (database) developed by the company. Metonymy resolution can be important for a variety of tasks. Textual entailment may need metonymy resolution (Bentivogli et al., 2007): for example, we would like to be able to induce from Example 1 the hypothesis The Canadian team won .... Leveling and Hartrumpf (2008) show that metonymy recognition on location proper names helps geographical information retrieval by excluding metonymically used place names from consideration (such as Example 1 or the use of Vietnam for the Vietnam war). Metonymies also frequently interact with anaphora resolution (Nunberg, 1995; Markert and Hahn, 2002), as in Example 1 where the metonymic use of Canada is referred to by a plural pronoun afterward (their). Metonymies can be quite regular: c</context>
</contexts>
<marker>Bentivogli, Cabrio, Dagan, Giampiccolo, Leggio, Magnini, 2007</marker>
<rawString>Luisa Bentivogli, Elena Cabrio, Ido Dagan, Danilo Giampiccolo, Medea Lo Leggio, and Bernardo Magnini. 2007. Building textual entailment specialized data sets: A methodology for isolating linguistic phenomena relevant to inference. In Proceedings of the 7th International Conference on Language Resources and Evaluation, La Valetta, Malta, 17–23 May 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Caroline Brun</author>
<author>Maud Ehrmann</author>
<author>Guillaume Jacquet</author>
</authors>
<title>XRCE-M: A hybrid system for named entity metonymy resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1),</booktitle>
<pages>488--491</pages>
<location>Prague, Czech Republic, 23–24</location>
<contexts>
<context position="10176" citStr="Brun et al. (2007)" startWordPosition="1616" endWordPosition="1619">nt of older work in metonymy resolution such as Hobbs et al. (1993), Fass (1991), Markert and Hahn (2002) or the use of a generative lexicon and its relations in Pustejovsky (1991), which also are unsupervised. However, these approaches lacked scalability due to the use of small hand-modeled knowledge bases which our use of a very large Wikipedia-derived ontology overcomes. In addition, most of these approaches (Fass, 1991; Hobbs et al., 1993; Pustejovsky, 1991; Harabagiu, 1998) rely on the view that metonymies violate selectional restrictions in their immediate, local context, usually those 1Brun et al. (2007) is semi-supervised but again relies on the local grammatical context. imposed by the verbs on their arguments. As can be seen in the Example 2, this misses metonymies which do not violate selectional restrictions. Nastase and Strube (2009) use more flexible probabilistic selectional preferences instead of strict constraint violations as well as WordNet as a larger taxonomy but are also restricted to the local context. Markert and Hahn (2002) do propose a treatment of metonymies that takes into account the larger discourse in the form of anaphoric relations between a metonymy and the prior con</context>
</contexts>
<marker>Brun, Ehrmann, Jacquet, 2007</marker>
<rawString>Caroline Brun, Maud Ehrmann, and Guillaume Jacquet. 2007. XRCE-M: A hybrid system for named entity metonymy resolution. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1), Prague, Czech Republic, 23–24 June 2007, pages 488–491.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Eszter Simon</author>
<author>Gy¨orgy Szarvas</author>
<author>D´aniel Varga</author>
</authors>
<title>GYDER: Maxent metonymy resolution.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1),</booktitle>
<pages>161--164</pages>
<location>Prague, Czech Republic, 23–24</location>
<contexts>
<context position="7976" citStr="Farkas et al., 2007" startWordPosition="1264" endWordPosition="1267">t, dependent on the semantic class studied and (ii) that an unsupervised approach — although lower than the supervised one — outperforms the supervised most frequent reading baseline and performs close to a standard supervised model with the basic set of lexico-syntactic features (Nissim and Markert, 2005). 2 Related Work The word sense disambiguation setting for metonymy resolution as developed by Nissim and Markert (2005) and used for the SemEval 2007 task (Markert and Nissim, 2009) uses a small, prespecified number of frequently occurring readings. 184 The approaches building on this work (Farkas et al., 2007; Nicolae et al., 2007, among others) are supervised, mostly using shallow surface features as well as grammatical relations.1 Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global context or the local/global context in a BOW model (Leveling, 2007; Poibeau, 2007) not outperforming the most frequent reading baseline. We believe that might be due to the lack of a link between the local and global context in these approaches — in our work, we condition the global context on the abstractions</context>
</contexts>
<marker>Farkas, Simon, Szarvas, Varga, 2007</marker>
<rawString>Rich´ard Farkas, Eszter Simon, Gy¨orgy Szarvas, and D´aniel Varga. 2007. GYDER: Maxent metonymy resolution. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1), Prague, Czech Republic, 23–24 June 2007, pages 161–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan C Fass</author>
</authors>
<title>met*: A method for discriminating metonomy and metaphor by computer.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="5566" citStr="Fass, 1991" startWordPosition="875" endWordPosition="876">ation in that the flexibility of our framework allows us to incorporate a wider context than in most prior approaches. Let us consider the indications for metonymic readings and its interpretation in Example 1, on the one hand, and Example 2, on the other hand. In Example 1, the grammatical relation to the verb defeat and the verb’s selectional preferences indicate the metonymy. We will call all such grammatically related words and the grammatical relations the local context of the PMW. Such types of local context have been used by most prior approaches (Pustejovsky, 1991; Hobbs et al., 1993; Fass, 1991; Nastase and Strube, 2009, among others). However, Example 2 shows that the local context can be ambiguous or often weak, such as the verb to be. In these examples, the wider context (database, keyword) is a better indication for a metonymy but has not been satisfactorily integrated in prior approaches (see Section 2). We here call all words surrounding the PMW but not grammatically related to it the global context. In our approach we integrate both the local and the global context in our probabilistic framework. For the local context, we compute the selectional preferences for the words rela</context>
<context position="9638" citStr="Fass (1991)" startWordPosition="1536" endWordPosition="1537"> for finding the correct interpretation of such metonymies in an unsupervised manner. However, these event type metonymies differ from the problem dealt with in our paper and the SemEval 2007 task in that their recognition (i.e. their distinction from literal occurrences) is achieved simply by grammatical patterns (a noun instead of a gerund or to-infinitive following the verb) and the problem is limited to interpretation. Our view of relations in a concept network being the interpretations of metonymies is strongly reminiscent of older work in metonymy resolution such as Hobbs et al. (1993), Fass (1991), Markert and Hahn (2002) or the use of a generative lexicon and its relations in Pustejovsky (1991), which also are unsupervised. However, these approaches lacked scalability due to the use of small hand-modeled knowledge bases which our use of a very large Wikipedia-derived ontology overcomes. In addition, most of these approaches (Fass, 1991; Hobbs et al., 1993; Pustejovsky, 1991; Harabagiu, 1998) rely on the view that metonymies violate selectional restrictions in their immediate, local context, usually those 1Brun et al. (2007) is semi-supervised but again relies on the local grammatical </context>
</contexts>
<marker>Fass, 1991</marker>
<rawString>Dan C. Fass. 1991. met*: A method for discriminating metonomy and metaphor by computer. Computational Linguistics, 17(1):49–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
</authors>
<title>Deriving metonymic coercions from WordNet.</title>
<date>1998</date>
<booktitle>In Proceedings of the Workshop on the Usage of WordNet in Natural Language Systems,</booktitle>
<pages>142--148</pages>
<location>Montral, Quebec,</location>
<contexts>
<context position="10041" citStr="Harabagiu, 1998" startWordPosition="1597" endWordPosition="1598">s limited to interpretation. Our view of relations in a concept network being the interpretations of metonymies is strongly reminiscent of older work in metonymy resolution such as Hobbs et al. (1993), Fass (1991), Markert and Hahn (2002) or the use of a generative lexicon and its relations in Pustejovsky (1991), which also are unsupervised. However, these approaches lacked scalability due to the use of small hand-modeled knowledge bases which our use of a very large Wikipedia-derived ontology overcomes. In addition, most of these approaches (Fass, 1991; Hobbs et al., 1993; Pustejovsky, 1991; Harabagiu, 1998) rely on the view that metonymies violate selectional restrictions in their immediate, local context, usually those 1Brun et al. (2007) is semi-supervised but again relies on the local grammatical context. imposed by the verbs on their arguments. As can be seen in the Example 2, this misses metonymies which do not violate selectional restrictions. Nastase and Strube (2009) use more flexible probabilistic selectional preferences instead of strict constraint violations as well as WordNet as a larger taxonomy but are also restricted to the local context. Markert and Hahn (2002) do propose a treat</context>
</contexts>
<marker>Harabagiu, 1998</marker>
<rawString>Sanda M. Harabagiu. 1998. Deriving metonymic coercions from WordNet. In Proceedings of the Workshop on the Usage of WordNet in Natural Language Systems, Montral, Quebec, Canada, 16 August, 1998, pages 142–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
<author>Mark Stickel</author>
<author>Douglas Appelt</author>
<author>Paul Martin</author>
</authors>
<title>Interpretation as abduction.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>63--1</pages>
<contexts>
<context position="5554" citStr="Hobbs et al., 1993" startWordPosition="871" endWordPosition="874">r second major innovation in that the flexibility of our framework allows us to incorporate a wider context than in most prior approaches. Let us consider the indications for metonymic readings and its interpretation in Example 1, on the one hand, and Example 2, on the other hand. In Example 1, the grammatical relation to the verb defeat and the verb’s selectional preferences indicate the metonymy. We will call all such grammatically related words and the grammatical relations the local context of the PMW. Such types of local context have been used by most prior approaches (Pustejovsky, 1991; Hobbs et al., 1993; Fass, 1991; Nastase and Strube, 2009, among others). However, Example 2 shows that the local context can be ambiguous or often weak, such as the verb to be. In these examples, the wider context (database, keyword) is a better indication for a metonymy but has not been satisfactorily integrated in prior approaches (see Section 2). We here call all words surrounding the PMW but not grammatically related to it the global context. In our approach we integrate both the local and the global context in our probabilistic framework. For the local context, we compute the selectional preferences for th</context>
<context position="9625" citStr="Hobbs et al. (1993)" startWordPosition="1532" endWordPosition="1535">a probabilistic model for finding the correct interpretation of such metonymies in an unsupervised manner. However, these event type metonymies differ from the problem dealt with in our paper and the SemEval 2007 task in that their recognition (i.e. their distinction from literal occurrences) is achieved simply by grammatical patterns (a noun instead of a gerund or to-infinitive following the verb) and the problem is limited to interpretation. Our view of relations in a concept network being the interpretations of metonymies is strongly reminiscent of older work in metonymy resolution such as Hobbs et al. (1993), Fass (1991), Markert and Hahn (2002) or the use of a generative lexicon and its relations in Pustejovsky (1991), which also are unsupervised. However, these approaches lacked scalability due to the use of small hand-modeled knowledge bases which our use of a very large Wikipedia-derived ontology overcomes. In addition, most of these approaches (Fass, 1991; Hobbs et al., 1993; Pustejovsky, 1991; Harabagiu, 1998) rely on the view that metonymies violate selectional restrictions in their immediate, local context, usually those 1Brun et al. (2007) is semi-supervised but again relies on the local</context>
</contexts>
<marker>Hobbs, Stickel, Appelt, Martin, 1993</marker>
<rawString>Jerry Hobbs, Mark Stickel, Douglas Appelt, and Paul Martin. 1993. Interpretation as abduction. Artificial Intelligence, 63(1-2):69–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
</authors>
<title>Probabilistic text structuring: Experiments with sentence ordering.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>545--552</pages>
<location>Sapporo,</location>
<contexts>
<context position="8675" citStr="Lapata (2003)" startWordPosition="1378" endWordPosition="1379">tures as well as grammatical relations.1 Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global context or the local/global context in a BOW model (Leveling, 2007; Poibeau, 2007) not outperforming the most frequent reading baseline. We believe that might be due to the lack of a link between the local and global context in these approaches — in our work, we condition the global context on the abstractions and selectional preferences yielded by the local context and achieve better results. Lapata (2003), Shutova (2009) as well as Roberts and Harabagiu (2011) deal with the issue of logical metonymy, where the participant stands in for the full event: e.g. Mary enjoyed the book., where book stands in for reading the book, and this missing event (reading) can be inferred from a corpus. Utiyama et al. (2000), Lapata (2003) propose a probabilistic model for finding the correct interpretation of such metonymies in an unsupervised manner. However, these event type metonymies differ from the problem dealt with in our paper and the SemEval 2007 task in that their recognition (i.e. their distinction f</context>
</contexts>
<marker>Lapata, 2003</marker>
<rawString>Maria Lapata. 2003. Probabilistic text structuring: Experiments with sentence ordering. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, Sapporo, Japan, 7–12 July 2003, pages 545–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Leveling</author>
<author>Sven Hartrumpf</author>
</authors>
<title>On metonymy recognition for geographic information retrieval.</title>
<date>2008</date>
<journal>International Journal of Geographical Information Science,</journal>
<volume>22</volume>
<issue>3</issue>
<contexts>
<context position="2574" citStr="Leveling and Hartrumpf (2008)" startWordPosition="392" endWordPosition="395">ample 1 will not be done by the country as such, but by a team representing the country in a sporting event. Hence, in a metonymy a potentially metonymic expression or word (here Canada) stands for a conceptually related entity (here, people of Canada). In the second Example, a company name (Oracle) stands for a product (database) developed by the company. Metonymy resolution can be important for a variety of tasks. Textual entailment may need metonymy resolution (Bentivogli et al., 2007): for example, we would like to be able to induce from Example 1 the hypothesis The Canadian team won .... Leveling and Hartrumpf (2008) show that metonymy recognition on location proper names helps geographical information retrieval by excluding metonymically used place names from consideration (such as Example 1 or the use of Vietnam for the Vietnam war). Metonymies also frequently interact with anaphora resolution (Nunberg, 1995; Markert and Hahn, 2002), as in Example 1 where the metonymic use of Canada is referred to by a plural pronoun afterward (their). Metonymies can be quite regular: company names can be used for their management or their products, country names can be used for associated sports teams. Following from t</context>
</contexts>
<marker>Leveling, Hartrumpf, 2008</marker>
<rawString>Johannes Leveling and Sven Hartrumpf. 2008. On metonymy recognition for geographic information retrieval. International Journal of Geographical Information Science, 22(3):289–299.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Leveling</author>
</authors>
<title>FUH (FernUniversit¨at in Hagen): Metonymy recognition using different kinds of context for a memory-based learner.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1),</booktitle>
<pages>153--156</pages>
<location>Prague, Czech Republic, 23–24</location>
<contexts>
<context position="8331" citStr="Leveling, 2007" startWordPosition="1322" endWordPosition="1323">g for metonymy resolution as developed by Nissim and Markert (2005) and used for the SemEval 2007 task (Markert and Nissim, 2009) uses a small, prespecified number of frequently occurring readings. 184 The approaches building on this work (Farkas et al., 2007; Nicolae et al., 2007, among others) are supervised, mostly using shallow surface features as well as grammatical relations.1 Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global context or the local/global context in a BOW model (Leveling, 2007; Poibeau, 2007) not outperforming the most frequent reading baseline. We believe that might be due to the lack of a link between the local and global context in these approaches — in our work, we condition the global context on the abstractions and selectional preferences yielded by the local context and achieve better results. Lapata (2003), Shutova (2009) as well as Roberts and Harabagiu (2011) deal with the issue of logical metonymy, where the participant stands in for the full event: e.g. Mary enjoyed the book., where book stands in for reading the book, and this missing event (reading) c</context>
</contexts>
<marker>Leveling, 2007</marker>
<rawString>Johannes Leveling. 2007. FUH (FernUniversit¨at in Hagen): Metonymy recognition using different kinds of context for a memory-based learner. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1), Prague, Czech Republic, 23–24 June 2007, pages 153–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Generalizing case frames using a thesaurus and the MDL principle.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>2</issue>
<contexts>
<context position="17626" citStr="Li and Abe, 1998" startWordPosition="2901" endWordPosition="2904">ed with a parallelized version of Ensemble4 (Surdeanu and Manning, 2010), and we extracted G, the set of all grammatical relations of the type (verb, dependency, hyperlink) and (adjective, dependency, hyperlink), with the hyperlinks resolved to their corresponding node (concept) in the network ( |G |= 1,578,413 triples). For each verb and adjective in the extracted collocations, and for each of their dependency relations, their collocates were generalized in the network defined by the hypernym/hyponym relations in WikiNet following a method similar to the Minimum Description Length principle (Li and Abe, 1998). Essentially, we aimed to determine a small set of (more general) concepts that describe the set of collocates for a word w and grammatical relation r. Starting from the concept collocates gathered, we go upwards following WikiNet’s is a links, and for each node found that covers at least N concept collocates (N is a parameter, N=2 in the experiments presented here), the MDL score of the node is computed (Algorithm 2). We place a limit M on the number of upward steps in the hierarchy (M=3 in our experiments). The disjoint set of nodes that has the lowest overall MDL score is chosen (r), and f</context>
</contexts>
<marker>Li, Abe, 1998</marker>
<rawString>Hang Li and Naoki Abe. 1998. Generalizing case frames using a thesaurus and the MDL principle. Computational Linguistics, 24(2):217–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Udo Hahn</author>
</authors>
<title>Metonymies in discourse.</title>
<date>2002</date>
<journal>Artificial Intelligence,</journal>
<pages>135--1</pages>
<contexts>
<context position="2898" citStr="Markert and Hahn, 2002" startWordPosition="440" endWordPosition="443">e) developed by the company. Metonymy resolution can be important for a variety of tasks. Textual entailment may need metonymy resolution (Bentivogli et al., 2007): for example, we would like to be able to induce from Example 1 the hypothesis The Canadian team won .... Leveling and Hartrumpf (2008) show that metonymy recognition on location proper names helps geographical information retrieval by excluding metonymically used place names from consideration (such as Example 1 or the use of Vietnam for the Vietnam war). Metonymies also frequently interact with anaphora resolution (Nunberg, 1995; Markert and Hahn, 2002), as in Example 1 where the metonymic use of Canada is referred to by a plural pronoun afterward (their). Metonymies can be quite regular: company names can be used for their management or their products, country names can be used for associated sports teams. Following from this, the currently 183 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 183–193, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics prevalent set-up for metonymy resolution — as in the SemEval 2</context>
<context position="9663" citStr="Markert and Hahn (2002)" startWordPosition="1538" endWordPosition="1541">the correct interpretation of such metonymies in an unsupervised manner. However, these event type metonymies differ from the problem dealt with in our paper and the SemEval 2007 task in that their recognition (i.e. their distinction from literal occurrences) is achieved simply by grammatical patterns (a noun instead of a gerund or to-infinitive following the verb) and the problem is limited to interpretation. Our view of relations in a concept network being the interpretations of metonymies is strongly reminiscent of older work in metonymy resolution such as Hobbs et al. (1993), Fass (1991), Markert and Hahn (2002) or the use of a generative lexicon and its relations in Pustejovsky (1991), which also are unsupervised. However, these approaches lacked scalability due to the use of small hand-modeled knowledge bases which our use of a very large Wikipedia-derived ontology overcomes. In addition, most of these approaches (Fass, 1991; Hobbs et al., 1993; Pustejovsky, 1991; Harabagiu, 1998) rely on the view that metonymies violate selectional restrictions in their immediate, local context, usually those 1Brun et al. (2007) is semi-supervised but again relies on the local grammatical context. imposed by the v</context>
</contexts>
<marker>Markert, Hahn, 2002</marker>
<rawString>Katja Markert and Udo Hahn. 2002. Metonymies in discourse. Artificial Intelligence, 135(1/2):145–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Markert</author>
<author>Malvina Nissim</author>
</authors>
<title>Data and models for metonymy resolution.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="1746" citStr="Markert and Nissim, 2009" startWordPosition="248" endWordPosition="252">esults: it beats the supervised most frequent sense baseline and performs close to a supervised approach using only standard lexico-syntactic features. 1 Introduction With the exception of explicit tasks in metonymy and metaphor analysis, computational treatment of language relies on the assumption that the texts to be processed have a literal interpretation. This contrasts with the fact that figurative expressions are common in language, as exemplified by the metonymy in the excerpt from a Wikipedia article in Example 1 and another in Example 2 from the SemEval 2007 metonymy resolution task (Markert and Nissim, 2009). (1) In the gold medal game, Canada defeated the American team 2-0 to win their third consecutive gold. (2) This keyword is only required when your relational database is Oracle. The defeating in Example 1 will not be done by the country as such, but by a team representing the country in a sporting event. Hence, in a metonymy a potentially metonymic expression or word (here Canada) stands for a conceptually related entity (here, people of Canada). In the second Example, a company name (Oracle) stands for a product (database) developed by the company. Metonymy resolution can be important for a</context>
<context position="7846" citStr="Markert and Nissim, 2009" startWordPosition="1243" endWordPosition="1246">h in this paper and show that (i) the supervised approach using both local and global context can outperform one using just local context, dependent on the semantic class studied and (ii) that an unsupervised approach — although lower than the supervised one — outperforms the supervised most frequent reading baseline and performs close to a standard supervised model with the basic set of lexico-syntactic features (Nissim and Markert, 2005). 2 Related Work The word sense disambiguation setting for metonymy resolution as developed by Nissim and Markert (2005) and used for the SemEval 2007 task (Markert and Nissim, 2009) uses a small, prespecified number of frequently occurring readings. 184 The approaches building on this work (Farkas et al., 2007; Nicolae et al., 2007, among others) are supervised, mostly using shallow surface features as well as grammatical relations.1 Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global context or the local/global context in a BOW model (Leveling, 2007; Poibeau, 2007) not outperforming the most frequent reading baseline. We believe that might be due to the lack of </context>
<context position="25452" citStr="Markert and Nissim, 2009" startWordPosition="4215" endWordPosition="4218"> metonymy resolution task (Task 8) at SemEval 2007. It consists of training and test data for country and company names which are potentially metonymic. Table 2 shows the statistics of the data, and the possible interpretations for the PMWs. The training-test division was achieved randomly so that the test data can have metonymic readings for which no training data exists, showing again the limitations of a supervised approach of prespecified readings. Grammatical features The features used by Nissim and Markert (2005), and commonly used for the supervised classification of metonymy readings (Markert and Nissim, 2009): • grammatical role of PMW (subj, obj, ...); • lemmatized head/modifier of PMW (announce, say, ...); n p(Cont|Aj, w, r) = j=1 n j=1 189 reading train test locations literal mixed othermet obj-for-name obj-for-representation place-for-people place-for-event place-for-product organizations literal mixed othermet obj-for-name obj-for-representation org-for-members org-for-event org-for-product org-for-facility org-for-index Table 2: Statistics for the Task 8 data • determiner of PMW (def, indef, bare, demonst, other, ...); • grammatical number of PMW (sg, pl); • number of grammatical roles in wh</context>
</contexts>
<marker>Markert, Nissim, 2009</marker>
<rawString>Katja Markert and Malvina Nissim. 2009. Data and models for metonymy resolution. Language Resources and Evaluation, 43(2):123–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
</authors>
<title>Combining collocations, lexical and encyclopedic knowledge for metonymy resolution.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>910--918</pages>
<contexts>
<context position="5592" citStr="Nastase and Strube, 2009" startWordPosition="877" endWordPosition="880">t the flexibility of our framework allows us to incorporate a wider context than in most prior approaches. Let us consider the indications for metonymic readings and its interpretation in Example 1, on the one hand, and Example 2, on the other hand. In Example 1, the grammatical relation to the verb defeat and the verb’s selectional preferences indicate the metonymy. We will call all such grammatically related words and the grammatical relations the local context of the PMW. Such types of local context have been used by most prior approaches (Pustejovsky, 1991; Hobbs et al., 1993; Fass, 1991; Nastase and Strube, 2009, among others). However, Example 2 shows that the local context can be ambiguous or often weak, such as the verb to be. In these examples, the wider context (database, keyword) is a better indication for a metonymy but has not been satisfactorily integrated in prior approaches (see Section 2). We here call all words surrounding the PMW but not grammatically related to it the global context. In our approach we integrate both the local and the global context in our probabilistic framework. For the local context, we compute the selectional preferences for the words related to the PMW from a corp</context>
<context position="10416" citStr="Nastase and Strube (2009)" startWordPosition="1654" endWordPosition="1658">hes lacked scalability due to the use of small hand-modeled knowledge bases which our use of a very large Wikipedia-derived ontology overcomes. In addition, most of these approaches (Fass, 1991; Hobbs et al., 1993; Pustejovsky, 1991; Harabagiu, 1998) rely on the view that metonymies violate selectional restrictions in their immediate, local context, usually those 1Brun et al. (2007) is semi-supervised but again relies on the local grammatical context. imposed by the verbs on their arguments. As can be seen in the Example 2, this misses metonymies which do not violate selectional restrictions. Nastase and Strube (2009) use more flexible probabilistic selectional preferences instead of strict constraint violations as well as WordNet as a larger taxonomy but are also restricted to the local context. Markert and Hahn (2002) do propose a treatment of metonymies that takes into account the larger discourse in the form of anaphoric relations between a metonymy and the prior context. However, they constrain discourse integration to potential PMWs that are definite NPs and the context to few previous noun phrases. In addition, their framework uses a strict rule-based ranking of competing readings that cannot be eas</context>
<context position="27659" citStr="Nastase and Strube (2009)" startWordPosition="4563" endWordPosition="4566">s 29 features. Table 1 showed examples of these new features. 4.2 Supervised learning We use the SMO classifier in the WEKA machine learning toolkit (Witten and Frank, 2000) with its standard settings, training on the SemEval 2007 (Task 8) training set. Table 3 shows the results of various configurations on the test data, in comparison with a most frequent reading baseline (assigning literal to all PMWs) as well as a system M&amp;N that shows the results computed using only the features proposed by Nissim and Markert (2005). In addition, we compare to the best results9 at SemEval 2007 (5Emax) and Nastase and Strube (2009) (N09). Nastase and Strube (2009) added WordNet supersenses as features, and their values are selectional preferences computed with reference to WordNet. These are similar to our abstractions, which in our approach serve to link the local and the global context to the ontological relations, but do not appear as features. Our system 5P shows the results obtained using the M&amp;N features plus the conceptual relation features conditioned on both local and global context whereas 5Plocal and 5Pglobal use conceptual relations conditioned on local (p(Aj|Cont, w, r) � p(Aj|w, r)) or global context (p(Aj</context>
</contexts>
<marker>Nastase, Strube, 2009</marker>
<rawString>Vivi Nastase and Michael Strube. 2009. Combining collocations, lexical and encyclopedic knowledge for metonymy resolution. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, Singapore, 6-7 August 2009, pages 910–918.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Michael Strube</author>
<author>Benjamin B¨orschinger</author>
<author>C¨acilia Zirn</author>
<author>Anas Elghafari</author>
</authors>
<title>WikiNet: A very large scale multi-lingual concept network.</title>
<date>2010</date>
<booktitle>In Proceedings of the 7th International Conference on Language Resources and Evaluation,</booktitle>
<location>La Valetta, Malta, 17–23</location>
<marker>Nastase, Strube, B¨orschinger, Zirn, Elghafari, 2010</marker>
<rawString>Vivi Nastase, Michael Strube, Benjamin B¨orschinger, C¨acilia Zirn, and Anas Elghafari. 2010. WikiNet: A very large scale multi-lingual concept network. In Proceedings of the 7th International Conference on Language Resources and Evaluation, La Valetta, Malta, 17–23 May 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristina Nicolae</author>
<author>Gabriel Nicolae</author>
<author>Sanda Harabagiu</author>
</authors>
<title>UTD-HLT-CG: Semantic architecture for metonymy resolution and classification of nominal relations.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1),</booktitle>
<pages>454--459</pages>
<location>Prague, Czech Republic, 23–24</location>
<contexts>
<context position="7998" citStr="Nicolae et al., 2007" startWordPosition="1268" endWordPosition="1271">emantic class studied and (ii) that an unsupervised approach — although lower than the supervised one — outperforms the supervised most frequent reading baseline and performs close to a standard supervised model with the basic set of lexico-syntactic features (Nissim and Markert, 2005). 2 Related Work The word sense disambiguation setting for metonymy resolution as developed by Nissim and Markert (2005) and used for the SemEval 2007 task (Markert and Nissim, 2009) uses a small, prespecified number of frequently occurring readings. 184 The approaches building on this work (Farkas et al., 2007; Nicolae et al., 2007, among others) are supervised, mostly using shallow surface features as well as grammatical relations.1 Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global context or the local/global context in a BOW model (Leveling, 2007; Poibeau, 2007) not outperforming the most frequent reading baseline. We believe that might be due to the lack of a link between the local and global context in these approaches — in our work, we condition the global context on the abstractions and selectional prefe</context>
</contexts>
<marker>Nicolae, Nicolae, Harabagiu, 2007</marker>
<rawString>Cristina Nicolae, Gabriel Nicolae, and Sanda Harabagiu. 2007. UTD-HLT-CG: Semantic architecture for metonymy resolution and classification of nominal relations. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1), Prague, Czech Republic, 23–24 June 2007, pages 454–459.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malvina Nissim</author>
<author>Katja Markert</author>
</authors>
<title>Learning to buy a Renault and talk to BMW: A supervised approach to conventional metonymy.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th International Workshop on Computational Semantics,</booktitle>
<location>Tilburg, Netherlands,</location>
<contexts>
<context position="7664" citStr="Nissim and Markert, 2005" startWordPosition="1214" endWordPosition="1217">ing to the PMW and its directly related concepts. These can be used either (i) as additional features in a supervised approach or (ii) directly for unsupervised resolution. We do both in this paper and show that (i) the supervised approach using both local and global context can outperform one using just local context, dependent on the semantic class studied and (ii) that an unsupervised approach — although lower than the supervised one — outperforms the supervised most frequent reading baseline and performs close to a standard supervised model with the basic set of lexico-syntactic features (Nissim and Markert, 2005). 2 Related Work The word sense disambiguation setting for metonymy resolution as developed by Nissim and Markert (2005) and used for the SemEval 2007 task (Markert and Nissim, 2009) uses a small, prespecified number of frequently occurring readings. 184 The approaches building on this work (Farkas et al., 2007; Nicolae et al., 2007, among others) are supervised, mostly using shallow surface features as well as grammatical relations.1 Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global</context>
<context position="25351" citStr="Nissim and Markert (2005)" startWordPosition="4200" endWordPosition="4204">d set-up. We then simulate the unsupervised setting in Section 4.3. 4.1 Data We use the data from the metonymy resolution task (Task 8) at SemEval 2007. It consists of training and test data for country and company names which are potentially metonymic. Table 2 shows the statistics of the data, and the possible interpretations for the PMWs. The training-test division was achieved randomly so that the test data can have metonymic readings for which no training data exists, showing again the limitations of a supervised approach of prespecified readings. Grammatical features The features used by Nissim and Markert (2005), and commonly used for the supervised classification of metonymy readings (Markert and Nissim, 2009): • grammatical role of PMW (subj, obj, ...); • lemmatized head/modifier of PMW (announce, say, ...); n p(Cont|Aj, w, r) = j=1 n j=1 189 reading train test locations literal mixed othermet obj-for-name obj-for-representation place-for-people place-for-event place-for-product organizations literal mixed othermet obj-for-name obj-for-representation org-for-members org-for-event org-for-product org-for-facility org-for-index Table 2: Statistics for the Task 8 data • determiner of PMW (def, indef, </context>
<context position="27559" citStr="Nissim and Markert (2005)" startWordPosition="4545" endWordPosition="4548">. For the “countries” portion of the data this adds 109 semantic relation features, and for companies 29 features. Table 1 showed examples of these new features. 4.2 Supervised learning We use the SMO classifier in the WEKA machine learning toolkit (Witten and Frank, 2000) with its standard settings, training on the SemEval 2007 (Task 8) training set. Table 3 shows the results of various configurations on the test data, in comparison with a most frequent reading baseline (assigning literal to all PMWs) as well as a system M&amp;N that shows the results computed using only the features proposed by Nissim and Markert (2005). In addition, we compare to the best results9 at SemEval 2007 (5Emax) and Nastase and Strube (2009) (N09). Nastase and Strube (2009) added WordNet supersenses as features, and their values are selectional preferences computed with reference to WordNet. These are similar to our abstractions, which in our approach serve to link the local and the global context to the ontological relations, but do not appear as features. Our system 5P shows the results obtained using the M&amp;N features plus the conceptual relation features conditioned on both local and global context whereas 5Plocal and 5Pglobal u</context>
</contexts>
<marker>Nissim, Markert, 2005</marker>
<rawString>Malvina Nissim and Katja Markert. 2005. Learning to buy a Renault and talk to BMW: A supervised approach to conventional metonymy. In Proceedings of the 6th International Workshop on Computational Semantics, Tilburg, Netherlands, January 12-14, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Nunberg</author>
</authors>
<title>Transfers of meaning.</title>
<date>1995</date>
<journal>Journal of Semantics,</journal>
<volume>12</volume>
<issue>1</issue>
<contexts>
<context position="2873" citStr="Nunberg, 1995" startWordPosition="438" endWordPosition="439">roduct (database) developed by the company. Metonymy resolution can be important for a variety of tasks. Textual entailment may need metonymy resolution (Bentivogli et al., 2007): for example, we would like to be able to induce from Example 1 the hypothesis The Canadian team won .... Leveling and Hartrumpf (2008) show that metonymy recognition on location proper names helps geographical information retrieval by excluding metonymically used place names from consideration (such as Example 1 or the use of Vietnam for the Vietnam war). Metonymies also frequently interact with anaphora resolution (Nunberg, 1995; Markert and Hahn, 2002), as in Example 1 where the metonymic use of Canada is referred to by a plural pronoun afterward (their). Metonymies can be quite regular: company names can be used for their management or their products, country names can be used for associated sports teams. Following from this, the currently 183 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 183–193, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics prevalent set-up for metonymy resolut</context>
</contexts>
<marker>Nunberg, 1995</marker>
<rawString>Geoffrey Nunberg. 1995. Transfers of meaning. Journal of Semantics, 12(1):109–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thierry Poibeau</author>
</authors>
<title>Up13: Knowledge-poor methods (sometimes) perform poorly.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1),</booktitle>
<pages>418--421</pages>
<location>Prague, Czech Republic, 23–24</location>
<contexts>
<context position="8347" citStr="Poibeau, 2007" startWordPosition="1324" endWordPosition="1325">esolution as developed by Nissim and Markert (2005) and used for the SemEval 2007 task (Markert and Nissim, 2009) uses a small, prespecified number of frequently occurring readings. 184 The approaches building on this work (Farkas et al., 2007; Nicolae et al., 2007, among others) are supervised, mostly using shallow surface features as well as grammatical relations.1 Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global context or the local/global context in a BOW model (Leveling, 2007; Poibeau, 2007) not outperforming the most frequent reading baseline. We believe that might be due to the lack of a link between the local and global context in these approaches — in our work, we condition the global context on the abstractions and selectional preferences yielded by the local context and achieve better results. Lapata (2003), Shutova (2009) as well as Roberts and Harabagiu (2011) deal with the issue of logical metonymy, where the participant stands in for the full event: e.g. Mary enjoyed the book., where book stands in for reading the book, and this missing event (reading) can be inferred f</context>
</contexts>
<marker>Poibeau, 2007</marker>
<rawString>Thierry Poibeau. 2007. Up13: Knowledge-poor methods (sometimes) perform poorly. In Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-1), Prague, Czech Republic, 23–24 June 2007, pages 418–421.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>The generative lexicon.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<volume>17</volume>
<issue>4</issue>
<contexts>
<context position="5534" citStr="Pustejovsky, 1991" startWordPosition="869" endWordPosition="870">anking showcases our second major innovation in that the flexibility of our framework allows us to incorporate a wider context than in most prior approaches. Let us consider the indications for metonymic readings and its interpretation in Example 1, on the one hand, and Example 2, on the other hand. In Example 1, the grammatical relation to the verb defeat and the verb’s selectional preferences indicate the metonymy. We will call all such grammatically related words and the grammatical relations the local context of the PMW. Such types of local context have been used by most prior approaches (Pustejovsky, 1991; Hobbs et al., 1993; Fass, 1991; Nastase and Strube, 2009, among others). However, Example 2 shows that the local context can be ambiguous or often weak, such as the verb to be. In these examples, the wider context (database, keyword) is a better indication for a metonymy but has not been satisfactorily integrated in prior approaches (see Section 2). We here call all words surrounding the PMW but not grammatically related to it the global context. In our approach we integrate both the local and the global context in our probabilistic framework. For the local context, we compute the selectiona</context>
<context position="9738" citStr="Pustejovsky (1991)" startWordPosition="1553" endWordPosition="1554">, these event type metonymies differ from the problem dealt with in our paper and the SemEval 2007 task in that their recognition (i.e. their distinction from literal occurrences) is achieved simply by grammatical patterns (a noun instead of a gerund or to-infinitive following the verb) and the problem is limited to interpretation. Our view of relations in a concept network being the interpretations of metonymies is strongly reminiscent of older work in metonymy resolution such as Hobbs et al. (1993), Fass (1991), Markert and Hahn (2002) or the use of a generative lexicon and its relations in Pustejovsky (1991), which also are unsupervised. However, these approaches lacked scalability due to the use of small hand-modeled knowledge bases which our use of a very large Wikipedia-derived ontology overcomes. In addition, most of these approaches (Fass, 1991; Hobbs et al., 1993; Pustejovsky, 1991; Harabagiu, 1998) rely on the view that metonymies violate selectional restrictions in their immediate, local context, usually those 1Brun et al. (2007) is semi-supervised but again relies on the local grammatical context. imposed by the verbs on their arguments. As can be seen in the Example 2, this misses meton</context>
</contexts>
<marker>Pustejovsky, 1991</marker>
<rawString>James Pustejovsky. 1991. The generative lexicon. Computational Linguistics, 17(4):209–241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kirk Roberts</author>
<author>Sanda M Harabagiu</author>
</authors>
<title>Unsupervised learning of selectional restrictions and detection of argument coercions.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>27--29</pages>
<location>Edinburgh, UK,</location>
<contexts>
<context position="8731" citStr="Roberts and Harabagiu (2011)" startWordPosition="1385" endWordPosition="1388">Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global context or the local/global context in a BOW model (Leveling, 2007; Poibeau, 2007) not outperforming the most frequent reading baseline. We believe that might be due to the lack of a link between the local and global context in these approaches — in our work, we condition the global context on the abstractions and selectional preferences yielded by the local context and achieve better results. Lapata (2003), Shutova (2009) as well as Roberts and Harabagiu (2011) deal with the issue of logical metonymy, where the participant stands in for the full event: e.g. Mary enjoyed the book., where book stands in for reading the book, and this missing event (reading) can be inferred from a corpus. Utiyama et al. (2000), Lapata (2003) propose a probabilistic model for finding the correct interpretation of such metonymies in an unsupervised manner. However, these event type metonymies differ from the problem dealt with in our paper and the SemEval 2007 task in that their recognition (i.e. their distinction from literal occurrences) is achieved simply by grammatic</context>
</contexts>
<marker>Roberts, Harabagiu, 2011</marker>
<rawString>Kirk Roberts and Sanda M. Harabagiu. 2011. Unsupervised learning of selectional restrictions and detection of argument coercions. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, Edinburgh, UK, 27-29 July 2011, pages 980–990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ekaterina Shutova</author>
</authors>
<title>Sense-based interpretation of logical metonymy using a statistical method.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="8691" citStr="Shutova (2009)" startWordPosition="1380" endWordPosition="1381">s grammatical relations.1 Most effective in the SemEval task as summarized in Markert and Nissim (2009) has been the local, grammatical context, with the two systems relying on the global context or the local/global context in a BOW model (Leveling, 2007; Poibeau, 2007) not outperforming the most frequent reading baseline. We believe that might be due to the lack of a link between the local and global context in these approaches — in our work, we condition the global context on the abstractions and selectional preferences yielded by the local context and achieve better results. Lapata (2003), Shutova (2009) as well as Roberts and Harabagiu (2011) deal with the issue of logical metonymy, where the participant stands in for the full event: e.g. Mary enjoyed the book., where book stands in for reading the book, and this missing event (reading) can be inferred from a corpus. Utiyama et al. (2000), Lapata (2003) propose a probabilistic model for finding the correct interpretation of such metonymies in an unsupervised manner. However, these event type metonymies differ from the problem dealt with in our paper and the SemEval 2007 task in that their recognition (i.e. their distinction from literal occu</context>
</contexts>
<marker>Shutova, 2009</marker>
<rawString>Ekaterina Shutova. 2009. Sense-based interpretation of logical metonymy using a statistical method. In Proceedings of the Joint Conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing, Singapore, 2–7 August 2009, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Christopher D Manning</author>
</authors>
<title>Ensemble Models for Dependency Parsing: Cheap and Good?</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies 2010: The Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>649--652</pages>
<location>Los Angeles, Cal.,</location>
<contexts>
<context position="17081" citStr="Surdeanu and Manning, 2010" startWordPosition="2815" endWordPosition="2818">f)}, (c, f) ∈ S // Remove hyponyms. for all {(c,c&apos;) ∈ S&apos;|(c&apos;, is a, c) ∈ WkN} do // update frequency f of c fc = fc + fc,,f ∈ S delete c&apos; return S&apos; discourse” assumption – a phrase that appears associated with a hyperlink once in the article body will be associated with the same hyperlink throughout the article (this applies to the article title as well, which is not hyperlinked in the article itself). This new version of the corpus was then split into sentences, and those without hyperlinks were removed. The remaining 18 million sentences were parsed with a parallelized version of Ensemble4 (Surdeanu and Manning, 2010), and we extracted G, the set of all grammatical relations of the type (verb, dependency, hyperlink) and (adjective, dependency, hyperlink), with the hyperlinks resolved to their corresponding node (concept) in the network ( |G |= 1,578,413 triples). For each verb and adjective in the extracted collocations, and for each of their dependency relations, their collocates were generalized in the network defined by the hypernym/hyponym relations in WikiNet following a method similar to the Minimum Description Length principle (Li and Abe, 1998). Essentially, we aimed to determine a small set of (mo</context>
</contexts>
<marker>Surdeanu, Manning, 2010</marker>
<rawString>Mihai Surdeanu and Christopher D. Manning. 2010. Ensemble Models for Dependency Parsing: Cheap and Good? In Proceedings of Human Language Technologies 2010: The Conference of the North American Chapter of the Association for Computational Linguistics, Los Angeles, Cal., 2–4 June 2010, pages 649– 652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ling-Xiang Tang</author>
<author>Shlomo Geva</author>
<author>Andrew Trotman</author>
<author>Yue Xu</author>
<author>Kelly Y Itakura</author>
</authors>
<title>Overview of the NTCIR-9 crosslink task: Cross-lingual link discovery.</title>
<date>2011</date>
<booktitle>In Proceedings of the 9th NII Test Collection for IR Systems Workshop meeting – NTCIR-9</booktitle>
<location>Tokyo,</location>
<contexts>
<context position="19569" citStr="Tang et al., 2011" startWordPosition="3234" endWordPosition="3237">eads to the following information6: defeat nsubj Martial artists (118977183) – 0.5, Person (219599) – 0.3518, Interest (146738) – 0.037, .. . obj Video games (9570081) – 0.25, British games (24489088) – 0.25, Person (219599) – 0.1445, Interest (146738) – 0.1341, ... 3.3 Linking the PMW to the concept network In our environment, linking the PMW to the concept network is equivalent to finding its corresponding concept in our ontology, WikiNet. We see this corresponding concept as the literal reading of the PMW. Doing so is a non-trivial task (see the CrossLingual Link Discovery task at NTCIR-9 (Tang et al., 2011) and the Cross-Lingual Entity Linking task – part of the Knowledge Base Population track – at TAC 20117). In our particular setting, where we use the metonymy data from SemEval 2007, the domain of the PMW is well defined: locations and companies, respectively. Using these constraints, finding the corresponding Wikipedia articles is much simplified, by using the category hierarchy and constraining the concepts to fall under the Geography and Companies categories respectively. When multiple options are present, we find instead a matching disambiguation page. In this case we pick the article that</context>
</contexts>
<marker>Tang, Geva, Trotman, Xu, Itakura, 2011</marker>
<rawString>Ling-Xiang Tang, Shlomo Geva, Andrew Trotman, Yue Xu, and Kelly Y. Itakura. 2011. Overview of the NTCIR-9 crosslink task: Cross-lingual link discovery. In Proceedings of the 9th NII Test Collection for IR Systems Workshop meeting – NTCIR-9 Tokyo, Japan, 6–9 December 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Masaki Murata</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A statistical approach to the processing of metonymy.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics, Saarbr¨ucken, Germany, 31 July – 4</booktitle>
<pages>885--891</pages>
<contexts>
<context position="8982" citStr="Utiyama et al. (2000)" startWordPosition="1429" endWordPosition="1432">ming the most frequent reading baseline. We believe that might be due to the lack of a link between the local and global context in these approaches — in our work, we condition the global context on the abstractions and selectional preferences yielded by the local context and achieve better results. Lapata (2003), Shutova (2009) as well as Roberts and Harabagiu (2011) deal with the issue of logical metonymy, where the participant stands in for the full event: e.g. Mary enjoyed the book., where book stands in for reading the book, and this missing event (reading) can be inferred from a corpus. Utiyama et al. (2000), Lapata (2003) propose a probabilistic model for finding the correct interpretation of such metonymies in an unsupervised manner. However, these event type metonymies differ from the problem dealt with in our paper and the SemEval 2007 task in that their recognition (i.e. their distinction from literal occurrences) is achieved simply by grammatical patterns (a noun instead of a gerund or to-infinitive following the verb) and the problem is limited to interpretation. Our view of relations in a concept network being the interpretations of metonymies is strongly reminiscent of older work in meto</context>
</contexts>
<marker>Utiyama, Murata, Isahara, 2000</marker>
<rawString>Masao Utiyama, Masaki Murata, and Hitoshi Isahara. 2000. A statistical approach to the processing of metonymy. In Proceedings of the 18th International Conference on Computational Linguistics, Saarbr¨ucken, Germany, 31 July – 4 August 2000, pages 885–891.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<date>2000</date>
<booktitle>Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations.</booktitle>
<publisher>Morgan Kaufmann,</publisher>
<location>San Diego, CA.</location>
<contexts>
<context position="27207" citStr="Witten and Frank, 2000" startWordPosition="4484" endWordPosition="4487">ed annotations and add wherever possible to the simple prepositions the head of their subsuming constituent. This would change the above mentioned dependency to (visit, prep-to, UK). Semantic relations as features To evaluate the proposed approach we use the PMW’s conceptual relations as features. The feature values are the p(TZi|Cont, w, r) scores. For the “countries” portion of the data this adds 109 semantic relation features, and for companies 29 features. Table 1 showed examples of these new features. 4.2 Supervised learning We use the SMO classifier in the WEKA machine learning toolkit (Witten and Frank, 2000) with its standard settings, training on the SemEval 2007 (Task 8) training set. Table 3 shows the results of various configurations on the test data, in comparison with a most frequent reading baseline (assigning literal to all PMWs) as well as a system M&amp;N that shows the results computed using only the features proposed by Nissim and Markert (2005). In addition, we compare to the best results9 at SemEval 2007 (5Emax) and Nastase and Strube (2009) (N09). Nastase and Strube (2009) added WordNet supersenses as features, and their values are selectional preferences computed with reference to Wor</context>
</contexts>
<marker>Witten, Frank, 2000</marker>
<rawString>Ian H. Witten and Eibe Frank. 2000. Data Mining: Practical Machine Learning Tools and Techniques with Java Implementations. Morgan Kaufmann, San Diego, CA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>