<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.971079">
Constructing Task-Specific Taxonomies for Document Collection Browsing
</title>
<author confidence="0.997971">
Hui Yang
</author>
<affiliation confidence="0.9987585">
Department of Computer Science
Georgetown University
</affiliation>
<address confidence="0.8602255">
37th and O street, NW
Washington, DC, 20057
</address>
<email confidence="0.99782">
huiyang@cs.georgetown.edu
</email>
<sectionHeader confidence="0.984277" genericHeader="abstract">
Abstract
</sectionHeader>
<figureCaption confidence="0.603945">
Taxonomies can serve as browsing tools for
document collections. However, given an ar-
bitrary collection, pre-constructed taxonomies
could not easily adapt to the specific topic/task
present in the collection. This paper explores
techniques to quickly derive task-specific tax-
onomies supporting browsing in arbitrary
document collections. The supervised ap-
proach directly learns semantic distances from
users to propose meaningful task-specific tax-
onomies. The approach aims to produce glob-
ally optimized taxonomy structures by incor-
porating path consistency control and user-
generated task specification into the general
learning framework. A comparison to state-
</figureCaption>
<bodyText confidence="0.925504333333333">
of-the-art systems and a user study jointly
demonstrate that our techniques are highly ef-
fective.
</bodyText>
<sectionHeader confidence="0.998804" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999909282608696">
Taxonomies are widely used for knowledge stan-
dardization, knowledge sharing, and inferencing in
natural language processing (NLP) tasks (Harabagiu
et al., 2003; Szpektor et al., 2004). However, an-
other common function of taxonomies, browsing,
has received little attention in the NLP community.
Browsing is the task of exploring and accessing in-
formation through a structure, e.g. a hierarchy, built
upon a given document collection. In fact, tax-
onomies serve as browsing tools in many venues,
including the Library of Congress Subject Headings
(LCSH, 2011) for the U.S. Library of Congress and
the Open Directory Project (ODP, 2011) for about
5% of the entire Web. We call taxonomies support-
ing browsing as browsing taxonomies.
When used for browsing, concepts1 in taxonomies
are linked to documents containing them and taxo-
nomic structures are navigated to find particular doc-
uments. Users can navigate through a browsing tax-
onomy to explore the documents in the collection.
A browsing taxonomy benefits information access
by providing corpus overview for a document col-
lection and allowing more focused reading by pre-
senting together documents about the same concept.
Most existing browsing taxonomies, such as
LCSH and ODP, are manually constructed to sup-
port large collections in general domains. Not only
their constructions are expensive and slow, but also
their structures are static and difficult to adapt to spe-
cific tasks. In situations where document collections
are given ad-hoc, such as search result organization
(Carpineto et al., 2009), email collection exploration
(Yang and Callan, 2008), and literature investigation
(Chau et al., 2011), existing taxonomies may even
not be able to provide the right coverage of concepts.
It is necessary to explore ad-hoc (semi-)automatic
techniques to quickly derive task-specific browsing
taxonomies for arbitrary document collections.
(Hovy, 2002) pointed out that one key challenge
in taxonomy construction is multiple perspectives
embedded in concepts and relations. One cause for
multiple perspectives is the inherent facets in con-
cepts, e.g., jewelries can be organized by price or by
gemstone types. Another cause is task specification
or even personalization. For example, when build-
ing a taxonomy for search results of query trip to
</bodyText>
<footnote confidence="0.884241">
1English terms or entities; usually nouns or noun phrases.
</footnote>
<page confidence="0.895815">
1278
</page>
<note confidence="0.8002105">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1278–1289, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.923972555555556">
DC, Jane may organize the concepts based on places
of interests while Tom may organize them based on
dates in visit. Typically, a taxonomy only conveys
one or two perspectives from many choices. It is dif-
ficult to decide which perspective should be present.
One realistic solution is to leave the decision to the
constructor independent of the confusion that comes
from facets, task specification or personalization.
When multiple perspectives present in the same
taxonomy, it is not uncommon that the per-
spectives are mixed. For example, along a
path financial institute—*bank—*river bank, finan-
cial institute—*bank shows one perspective and
bank—*river bank shows another. We call this prob-
lem path inconsistency. Many approaches on auto-
matic taxonomy construction suffer from this prob-
lem because their foci are on accurately identifying
local relations between concept pairs (Etzioni et al.,
2005; Pantel and Pennacchiotti, 2006) instead of on
global control over the entire taxonomic structure.
More recently, approaches attempted to build the full
taxonomy structure (Snow et al., 2006; Yang and
Callan, 2009; Kozareva and Hovy, 2010), however,
few have looked into how to incorporate task speci-
fications into taxonomy construction.
In this paper, we extended an existing taxonomy
construction approach (Yang and Callan, 2009) to
build task-specific taxonomies for document collec-
tion browsing. The extension comes in two parts:
handling path consistency and incorporating spec-
ifications from users. We uniquely employ pair-
wise semantic distance as an entry point to incre-
mentally build browsing taxonomies. A supervised
distance learning algorithm not only allows us to
incorporate multiple semantic features to evaluate
the proximity between concepts, but also allows us
to learn the metric function from personal prefer-
ences. Users can thus manually modify the tax-
onomies and to some extent teach the algorithm to
predict his/her way to organize the concepts. More-
over, by minimizing the overall semantic distances
among concepts and restricting minimal semantic
distances along a path, we find the best hierarchical
structure as the browsing taxonomy.
Our contributions include:
- A supervised learning mechanism to capture
task-specific or personalized requirements for orga-
nizing a browsing taxonomy;
- A strategy to address path inconsistency due to
word sense ambiguity and/or mixed perspectives;
- A general scheme to capture user inputs in tax-
onomy construction;
- A user study to evaluate the effectiveness of
task-specific taxonomies for browsing activities.
</bodyText>
<sectionHeader confidence="0.999389" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998645472222222">
Document collection browsing has been studied as
an alternative to the ranked list representation for
search results by the Information Retrieval (IR)
community. The popular IR approaches include
clustering (Cutting et al., 1992) and monothetic con-
cept hierarchies (Sanderson and Croft, 1999; Lawrie
et al., 2001; Kummamuru et al., 2004; Carpineto
et al., 2009). Clustering approaches hierarchically
cluster documents in a collection and label the clus-
ters. Monothetic approaches organize the concepts
into hierarchies and link documents to related con-
cepts. Both approaches are mainly based on pure
statistics, such as document frequency (Sanderson
and Croft, 1999) and conditional probability (Lawrie
et al., 2001). The major drawback of these pure
statistical approaches is their neglect of semantics
among concepts. As an consequence, they often fail
to produce semantically meaningful taxonomies.
The NLP community has extensively studied
automatic taxonomy construction. Although tra-
ditional research on taxonomy construction fo-
cuses on extracting local relations between concept
pairs (Hearst, 1992; Berland and Charniak, 1999;
Ravichandran and Hovy, 2002; Girju et al., 2003;
Etzioni et al., 2005; Pantel and Pennacchiotti, 2006;
Kozareva et al., 2008), more recent efforts has been
made in building full taxonomies. For example,
(Snow et al., 2006) proposed to estimate taxonomic
structure via maximizing the overall likelihood of a
taxonomy. (Kozareva and Hovy, 2010) proposed to
connect local concept pairs by finding the longest
path in a subsumption graph. Yang and Callan pro-
posed the Minimum Evolution (ME) framework
to model the semantic distance d(cx, cy) between
concepts cx and cy as a weighted combination of
various lexical, statistical, and semantic features:
</bodyText>
<equation confidence="0.568726">
E
</equation>
<bodyText confidence="0.942552333333333">
j weightj * featurej(cx, cy) and estimate the taxo-
nomic structure by minimizing the overall semantic
distances.
</bodyText>
<page confidence="0.991628">
1279
</page>
<bodyText confidence="0.999579444444444">
Researcher also attempted to carve out tax-
onomies from existing ones. For example, Stoica
et al. (Stoica and Hearst, 2007) managed to extract a
browsing taxonomy from hypernym relations within
WordNet (Fellbaum, 1998).
To support browsing in arbitrary collections, in
this paper, we propose to incorporate task specifica-
tion in a taxonomy. One way to achieve it is to define
task-specific distances among concepts. Moreover,
through controlling distance scores among concepts,
we can enforce path consistency in taxonomies. For
example, when the distance between financial in-
stitute and river bank is big, the path financial
institute—*bank—*river bank will be pruned and the
concepts will be repositioned. Inspired by ME, we
take a distance learning approach to deal with path
consistency (Section 3) and task specification (Sec-
tion 4) in taxonomy construction.
</bodyText>
<sectionHeader confidence="0.909098" genericHeader="method">
3 Build Structure-Optimized Taxonomies
</sectionHeader>
<bodyText confidence="0.999967977272727">
This section presents how to automatically build tax-
onomies. We take two steps to build browsing tax-
onomy for a given document collection. The first
step is to extract the concepts and the second is to
organize the concepts. For concept extraction, we
take a simple but effective approach: (1) We first
parse the document collection and exhaustively ex-
tract nouns, noun phrases, and named entities that
occur &gt;5 times in the collection. (2) We then fil-
ter out part-of-speech errors and typos by a Web-
based frequency test. In the test, we search each
candidate concept in the Google search engine and
remove a candidate if it appears &lt;4 times within
the top 10 Google snippets. (3) We finally cluster
similar concept candidates into groups by Latent Se-
mantic Analysis (Bellegarda et al., 1996) and select
the candidate with the highest tfidf value within a
group to form the concept set C. Although our ex-
traction algorithm is very effective with 95% preci-
sion and 80% recall in a manual evaluation, some-
times C may still miss some important concepts for
the collection. This can be later corrected by users
interactively through adding new concepts (Section
4).
To organize the concepts in C into taxonomic
structures, we extend the incremental clustering
framework proposed by ME (Yang and Callan,
2009). In ME, concepts are inserted one at a time.
At each insertion, a concept cz is at the parent (or
child) position for every existing node in the current
taxonomy. The evaluation of the best position de-
pends on the semantic distance between cz and its
temporary child (or parent) node and the semantic
distance among all other concepts in the taxonomy.
An advantage in ME is that it allows incorporat-
ing various constraints to the taxonomic structure.
For example, ME can handle concept generality-
specificity by learning different semantic distance
functions for general concepts which are located at
upper levels and specific concepts which are located
at lower levels in a taxonomy.
In this section, we introduce a new semantic dis-
tance learning method (Section 3.1) and extend ME
by controlling path consistency (Section 3.2).
</bodyText>
<subsectionHeader confidence="0.999813">
3.1 Estimating Semantic Distances
</subsectionHeader>
<bodyText confidence="0.9993464">
Pair-wise semantic distances among concepts build
the foundation for taxonomy construction. ME
models the semantic distance d(cx, cy) between con-
cepts cx and cy as a linear combination of underly-
ing feature functions. Similar to ME, we also as-
sume that “there are some underlying feature func-
tions that measure semantic dissimilarity for con-
cepts and a good semantic distance is a combination
of these features”. Different from ME, we model
the semantic distance d(cx, cy) between concepts
</bodyText>
<equation confidence="0.9679274">
(cx, cy) as a Mahalanobis distance (Mahalanobis,
V/
1936): d�x,�y = �(cx, cy)TW−14b(cx, xy), where
4b(cx, cy) is the set of underlying feature functions
IOk : (cx, cy)} with k=1,...,|4b|. W is the weight ma-
</equation>
<bodyText confidence="0.997444222222222">
trix, whose diagonal values weigh the various fea-
ture functions. We use the same set of features as
proposed in ME.
Mahalanobis distance is a general parametric
function widely used in distance metric learning
(Yang, 2006). It measures the dissimilarity between
two random vectors of the same distribution with a
covariance matrix W, which scales the data points
from their original values by
</bodyText>
<listItem confidence="0.690921666666667">
agonal values of W are taken into account, W is
equivalent to assigning weights to different axes in
the random vectors.
We choose Mahalanobis distance for two reasons.
(1) It is in a parametric form so that it allows us to
learn a distance function by supervised learning and
</listItem>
<equation confidence="0.335377">
W1/2. When only di-
</equation>
<page confidence="0.848416">
1280
</page>
<bodyText confidence="0.999307066666667">
provides an opportunity to assign different weights
for each type of semantic features. (2) When W
is properly constrained to be positive semi-definite
(PSD) (Bhatia, 2006), a Mahalanobis-formatted dis-
tance will be guaranteed to satisfy non-negativity
and triangle inequality, which was not addressed in
ME. As long as these two conditions are satisfied,
one may learn other forms of distance functions to
represent a semantic distance.
We can estimate W by minimizing the squared er-
rors between training semantic distances d and the
expected value d. We also need to constrain W
to be PSD to satisfy triangle inequality and non-
negativity. The objective function for semantic dis-
tance estimation is:
</bodyText>
<equation confidence="0.95343125">
y=1
|C |12
(dcx,cy − q4D(cx, cy)T W−14D(cx, cy)J (1)
subject to W &gt;- 0
</equation>
<bodyText confidence="0.999914461538462">
In this implementation, we used (Sedumi, 2011) and
(Yalmip, 2011) to solve the semi-definite program-
ming (SDP).
To generate the training semantic distances, we
collected 100 hypernym taxonomy fragments from
WordNet (Fellbaum, 1998) and ODP. The seman-
tic distance for a concept pair (cx, cy) in a training
taxonomy fragment is generated by assuming ev-
ery edge is weighted as 1 and summing up the edge
weights along the shortest path from cx to cy in the
taxonomy fragment. In Section 4, we will show how
to use user inputs as training data to capture task-
specifications in taxonomy construction.
</bodyText>
<subsectionHeader confidence="0.999651">
3.2 Enforcing Path Consistency
</subsectionHeader>
<bodyText confidence="0.999955384615385">
In ME, the main taxonomy structure optimization
framework is based on minimization of overall se-
mantic distance among all concepts in the taxonomy
and the minimum evolution assumption. We extend
the framework by introducing another optimization
objective to the framework: path consistency objec-
tive. The idea is that in any root-to-leaf path in a tax-
onomy, all concepts on the path should be about the
same topic or the same perspective. Within a root-to-
leaf path, the concepts need to be coherent no mat-
ter how far away they are apart. It suggests that a
good path’s sum of the semantic distances should be
small.
</bodyText>
<subsectionHeader confidence="0.290226">
Algorithm: Automatic Taxonomy Optimization.
</subsectionHeader>
<bodyText confidence="0.206247">
N(c a
</bodyText>
<equation confidence="0.989774625">
W = minW Px=1 Py=1 cr ((dctr ,ctry −
q4D(ctrx , ctry )T W −14D(ctrx, ctry ))2;
foreach cz ∈ C \ S
S ← S ∪ {cz};
if W &gt;_ 0
pd(cz, .) = �(cz, .)T W − 14D(cz, );
R ← R ∪ {arg minR(cz,.)(a objME + (1 − ,\) objpath)};
Output T(S, R)
</equation>
<figureCaption confidence="0.999016125">
Figure 1: An algorithm for taxonomy structure optimiza-
tion with path consistency control. C denotes the entire
concept set, S the current concept set, and R the current
relation set. N(ct,x) is the neighborhood of a training
concept ct,x, including its parent and child(ten). R(c,, .)
indicates the set of relations between a new concept c,
and all other existing concepts. T is the taxonomy with
concept set S and relation set R.
</figureCaption>
<bodyText confidence="0.999981">
Therefore, we propose to minimize the sum of se-
mantic distances along a root-to-leaf path. Particu-
larly, when adding a new concept cz into an existing
browsing hierarchy T, we try it at different positions
in T. At each temporary position, we can calculate
the sum of the semantic distances along the root-to-
leaf path Tcz that contains the new concept cx. The
path consistency objective is given by:
</bodyText>
<equation confidence="0.993632">
�objt,ath = min
Pcz cx,cyEPcz,x&lt;y d(cx, cy) (2)
</equation>
<bodyText confidence="0.999951">
where x &lt; y defines the order of the concepts to
avoid counting the same pair of pair-wise distances
twice.
Towards modeling path consistency in taxonomy
construction, we introduce a Pareto co-efficient A E
[0, 1] to control the contributions from objME, the
overall semantic distance minimization objective as
proposed in ME, and objpath, the path distance min-
imization objective. The optimization is:
</bodyText>
<equation confidence="0.687081">
min A objME + (1 − A) objt,ath (3)
</equation>
<bodyText confidence="0.999709111111111">
where objME =  |ucx,cy∈Cn∪{cz},x&lt;y d(cx, cy) −
Ecx,cy∈Cn,x&lt;y d(cx, cy)|, 0 &lt; A &lt; 1, and Cn is the
concept set after nth concept is added. Empirically,
we set A = 0.8.
The algorithm shown in Figure 1 outlines our
greedy algorithm to build taxonomies with path con-
sistency control. Each time when a new concept ar-
rives, the algorithm first estimates its semantic dis-
tances based on W learned from the training data,
</bodyText>
<equation confidence="0.8469356">
|C|
X
x=1
min
W
</equation>
<page confidence="0.895744">
1281
</page>
<bodyText confidence="0.9999461">
then finds the optimal position for the concept by
minimizing overall semantic distances and path in-
consistency, and gradually grows the structure into a
full taxonomy.
The order of adding concepts may affect the final
taxonomy structure. We hence insert concepts in an
arbitrary order with 10 random restarts with differ-
ent initial concepts and pick the taxonomy that min-
imizes both objectives among all candidate struc-
tures.
</bodyText>
<sectionHeader confidence="0.980193" genericHeader="method">
4 Incorporating Task Specification
</sectionHeader>
<bodyText confidence="0.999931885714285">
This section studies how to incorporate user-defined
task specifications in taxonomy construction. Al-
though the automatic algorithm proposed in Section
3 is able to well-organize most concepts for a given
document collection, it has not yet addressed the is-
sue of mixed perspective in taxonomy construction.
For concepts with multiple perspectives, we need to
decide which perspective is more appropriate for the
browsing taxonomy. This task-specific requirement
can only be captured by the user/constructor who
builds and uses the browsing taxonomy. Moreover,
the automatic algorithm relies on training data from
WordNet and ODP, which are known for imperfect
term organizations such as unbalanced granularity
among terms at the same level. To correct the wrong
relations learned from imperfect training data, we
propose to utilize user inputs in the learning process.
Particularly, we formulate taxonomy construction
as a user-teaching-machine-learning process. To
guide how to organize the concepts, a user trains
the supervised distance learning model via a taxon-
omy construction interface that allows the user to
intuitively modify a taxonomy. The interface sup-
ports editing actions such as dragging and dropping,
adding, deleting, and renaming nodes. When a user
put cx under cy, i.e. cx —* cy, this action indi-
cates that the user wants a relation represented by
cx —* cy to be true in this taxonomy. We did not
expect users to make all the edits. In a human-
computer-interaction cycle, a user is not restricted
to give a certain number of edits. Based on a user
study (Section 5.5), an average number of edits per
interaction is 3.6, which can be achieved with ease
by most users.
The algorithm shown in Figure 2 provides the
</bodyText>
<sectionHeader confidence="0.373618" genericHeader="method">
Algorithm: Interactive Taxonomy Construction.
</sectionHeader>
<listItem confidence="0.9959817">
1. T (S, R) =CreateInitialTaxonomy();
2. U(°)={Unmodified Concepts}=C \ S,
G(°)={Modified concepts}=S, M(°) = 0, i = 0;
3. while (not Satisfied) or U(i) =� 0
4. M(i)=CollectManualGuidance(G(i),U(i));
5. W (i)=LearnDistanceMetricFunction(M(i));
6. D(i)=PredictDistanceScores(W(i),U(i));
7. (G(i+1), U(i+1)) = UpdateTaxonomy(D(i),U(i),G(i));
8. i = i + 1;
9. Output G(i) as the taxonomy.
</listItem>
<figureCaption confidence="0.994382">
Figure 2: Interactive taxonomy construction procedure.
</figureCaption>
<bodyText confidence="0.999947055555556">
pseudo code for the interactive taxonomy construc-
tion procedure. It starts with automatic construction
of initial taxonomies using the techniques presented
in Section 3 (Line 1). We then capture the user in-
puts as manual guidance (Line 4) and make use of it
to adjust the distance learning model (Line 5), make
new predictions for semantic distances of other con-
cepts (Line 6), and organize those concepts to agree
with the user and update the taxonomy accordingly
(Line 7). Line 2 initiates three variables, the unmod-
ified concepts U, the modified concepts G, and the
manual guidance M, indexed by the iteration num-
ber i. The process iterates until the user is satisfied
with the taxonomy’s organization (Line 3).
Learning and predicting distances have been pre-
sented in Section 3.1. In this section, we present how
to capture manual guidance (Section 4.1) and update
the taxonomies accordingly (Section 4.2).
</bodyText>
<subsectionHeader confidence="0.994964">
4.1 Manual Guidance as the Training Data
</subsectionHeader>
<bodyText confidence="0.999967941176471">
Taxonomies are tree-structured. It is not trivial to
model a taxonomy, especially changes in a taxon-
omy, and feed that into a learning algorithm. In
this section, we propose a general scheme to cap-
ture changes, i.e., user inputs during interactions, in
taxonomy construction.
We propose to convert a taxonomy into matrices
of neighboring nodes. We compare the changes be-
tween a series of snapshots of the changing taxon-
omy to identify the user inputs. Specifically, before
a user starts editing in an interaction cycle, we repre-
sent the organization of concepts as a before matrix;
likewise, after the user finishes all edits in one cy-
cle, we represent the new organization of concepts
as an after matrix. For both matrices, the (x , y)th
entry indicates whether (or how confident) a rela-
tion r(cx, cy) is true. r could be any type of relation
</bodyText>
<page confidence="0.984695">
1282
</page>
<tableCaption confidence="0.551425">
mov. osc. sup. pic. geo. mov. osc. sup. pic. geo.
</tableCaption>
<table confidence="0.9993805">
Movie awards 1 0 0 0 0 Movie awards 1 0 0 0 0
Oscars 0 1 1 0 0 Oscars 0 1 0 0 0
Best supporting. 0 1 1 0 0 Best supporting. 0 0 1 1 0
i i
Best pictures 0 0 0 1 0 Best pictures 0 0 1 1 0
George Clooney 0 0 0 0 1 George Clooney 0 0 0 0 1
</table>
<figureCaption confidence="0.8986405">
Figure 3: An example taxonomy before and after human
edits (Concepts unchanged; relation type = sibling).
</figureCaption>
<bodyText confidence="0.983626666666667">
between the concepts. Figure 3 shows an example
taxonomy’s before and after matrices.
We define manual guidance M as a submatrix
which consists of entries in the after matrix B; at
these entries, there exist differences between the be-
fore matrix A and the after matrix B. Formally,
</bodyText>
<equation confidence="0.999789666666667">
M = B[r; c]
r = {i : bij − aij =�0} (4)
c = {j : bij − aij =� 0}
</equation>
<bodyText confidence="0.999753">
where aij is the (i, j)th entry in A, bij is the (i, j)th
entry in B, r indicates the rows and c indicates the
columns.
Note that manual guidance is not simply the
matrix difference between A and B. It is part of
the after matrix because it is the after matrix that
indicates where the user wants the concept hierarchy
to develop. The manual guidance for the example
shown in Figure 3 is: M = B[2, 3, 4; 2, 3, 4] =
</bodyText>
<table confidence="0.8497305">
Oscars Best supporting Best picture
Oscars 1 0 0
Best supporting 0 1 1
Best picture 0 1 1
</table>
<bodyText confidence="0.996648142857143">
When the user adds or deletes concepts, we ex-
pand rows and columns in A and B by filling 0 for
non-diagonal entries and 1 for diagonal entries. The
expanded before and after matrices A0 and B0 are
used in the calculation.
For taxonomies with concept changes, we define
manual guidance with concept set change Mchange
as a submatrix which consists of some entries of the
after matrix B; at these entries, there exist differ-
ences from the expanded before matrix A0 to the ex-
panded after matrix B0. Note that the concepts cor-
responding to these entries should exist in the unex-
panded set of concepts. Formally, manual guidance
with concept set change
</bodyText>
<equation confidence="0.999745">
Mchange = B[r0; c0]
r0 = {i : b0ij − a0ij =� 0, concept ci E CB} (5)
c0 = {j : b0ij − a0ij =� 0, concept cj E CB}
</equation>
<bodyText confidence="0.999752666666667">
where a0ij is the (i, j)th entry in A0, b0 ij is the (i, j)th
entry in B0, CB is the set of concepts in the unex-
panded after matrix B, r indicates the rows and c
indicates the columns.
Based on manual guidance M, we can create
training data for the supervised distance learning
algorithm (Section 3.1). In particular, we trans-
form the manual guidance into a distance matrix
D = 1 − M, which is used as the training data.
The learning algorithm is then able to learn a good
model which best preserves the regularity defined by
the task and the user. The difference is that the train-
ing data here is derived from manual guidance while
in the automatic algorithm we use training data from
WordNet and ODP.
</bodyText>
<subsectionHeader confidence="0.967096">
4.2 Update the Taxonomy
</subsectionHeader>
<bodyText confidence="0.980998333333333">
According to the algorithm shown in Figure 2, after
learning WW, the weight matrix at the ith iteration,
from the manual guidance, we can use it to predict
the pair-wise semantic distances for the unmodified
concepts and further group them in the taxonomy.
When the pair-wise distance score for a concept
pair (cl, cm) is small (&lt;0.5), we consider the rela-
tion between the concept pair is true; when it is big
(&gt;0.5), false. How to organize concepts whose re-
lations are true, is decided again by the relation type
in the distance matrix. If r is “sibling”, cl and cm are
. put under the same parent. If r is “is-a”, cm is put
under cl as one of cl’s children. The user interface
then presents the updated taxonomy to the user and
waits for the next round of manual guidance.
Since only a few changes are made during each
human-computer interaction, the learning model
may suffer from overfitting and the taxonomic struc-
ture may change too rapidly. To avoid such is-
sues caused by too few manual guidance, we em-
ploy background training taxonomy fragments from
WordNet and ODP, to smooth the learning models
and achieve less variance.
Before human edits After human edits
</bodyText>
<figure confidence="0.996239857142857">
Movie awards
Oscars Best supporting actors
Best pictures George Clooney
Before Matrix After Matrix George Clooney
Movie awards
Oscars
Best pictures Best supporting actors
</figure>
<page confidence="0.963389">
1283
</page>
<sectionHeader confidence="0.989423" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.9997055">
We conduct experiments and a user study to evalu-
ate the effectiveness of our approach. We have two
goals for the evaluation. One is to evaluate how the
browsing taxonomies constructed by our approach
compare with those constructed by other baseline
systems. Another is to investigate how well our
system can learns from task-specifications based on
user supervision.
</bodyText>
<subsectionHeader confidence="0.92146">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999648416666667">
The datasets we used in the evaluation are collec-
tions of Web documents crawled for complex search
tasks. For each task, we created the dataset by sub-
mitting 4 to 5 queries to and collecting the returned
Web documents from two search engines bing.com
and google.com. For example, queries “trip to DC”,
“Washington DC”, “DC”, and “Washington” were
submitted for the task “planning a trip to DC”. In to-
tal, we created 50 Web datasets on the topics such as
find a good kindergarten, purchase a used car, plan
a trip to DC, how to make a cake, find a good wed-
ding videographer, write a survey paper for health
care systems, find the best deals for a Mother’s day
gift, write a survey paper for social network, write
a survey paper for EU’s finance, and write a survey
paper for information technology.
Around 1000 Web documents are collected for
each dataset. We filter out spams and advertisements
and then search for more relevant Web documents
to make the total number 1000. However, not all
topics can retrieve 1000 documents. Among all 50
datasets, the average number of documents is 988.5.
The average number of unique words in a dataset is
698,875.
</bodyText>
<subsectionHeader confidence="0.999823">
5.2 Comparing with Baseline Systems
</subsectionHeader>
<bodyText confidence="0.998409">
We compare the following 5 systems.
</bodyText>
<listItem confidence="0.993927555555555">
• Subsumption: the automatic algorithm pro-
posed by (Sanderson and Croft, 1999), the
most effective state-of-the-art browsing hier-
archy construction technique as reported by
(Lawrie et al., 2001).
• KH: the automatic taxonomy construction al-
gorithm proposed by (Kozareva and Hovy,
2010).
• ME: the automatic taxonomy construction al-
</listItem>
<bodyText confidence="0.540405">
gorithm proposed by (Yang and Callan, 2009).
This framework does not perform path consis-
tency control nor learning from users.
</bodyText>
<listItem confidence="0.997981666666667">
• DistOpt: our automatic taxonomy construction
algorithm with path consistency control.
• PDistOpt: our interactive approach with human
supervision. The process starts from a flat list
of concepts. The user built the browsing taxon-
omy from the list in a user study (Section 5.5).
</listItem>
<subsectionHeader confidence="0.99923">
5.3 Browsing Effectiveness
</subsectionHeader>
<bodyText confidence="0.999974333333333">
A popular measure to evaluate the quality of the
browsing taxonomies is the expected mutual infor-
mation measure (EMIM (Lawrie et al., 2001)). It
calculates the mutual information between the lan-
guage model in a taxonomy T and the language
model in a document collection Z. It is defined as:
</bodyText>
<equation confidence="0.996605">
P(c, v)
P(c, v)log
P(c)P(v),
</equation>
<bodyText confidence="0.980261346153846">
where P(c, v) _ EdEZ P(d)P(cjd)P(vjd), C is
the set of concepts in T, V is the set of non-
stopwords in Z, and d is a document in Z. EMIM
only evaluates the content of a browsing taxonomy,
not its structure. However, it is still popularly used
to indicate how representative a browsing taxonomy
is for a document collection.
Table 1 shows the EMIM of the browsing tax-
onomies constructed by the five systems under eval-
uation. Based on the mean EMIM over the 50
datasets, we can rank the systems in terms of EMIM
in the descending order as PDistOpt &gt;&gt; DistOpt
&gt;&gt; ME &gt; KH &gt;&gt; Subsumption.2 It shows that
DistOpt is the best performing automatic algorithm
to generate browsing taxonomies. DistOpt is 109%
and statistically significantly more effective than
ME (p-value&lt;.001, t-test), 159% and statistically
significantly more effective than KH (p-value&lt;.001,
t-test), and 17 times and statistically significantly
more effective than Subsumption (p-value&lt;.001, t-
test). It strongly suggests that our techniques are
2&gt;&gt; indicates statistically significant difference between
the left and the right hand sides (p &lt; .001, t-test) and &gt; indi-
cates moderate statistical significance between the left and the
right hand sides (p &lt; .05, t-test). We will use the same symbols
throughout the remainder of this paper.
</bodyText>
<figure confidence="0.709238333333333">
�
I(C;V ) _
cEC,VEV
</figure>
<page confidence="0.993177">
1284
</page>
<tableCaption confidence="0.999774">
Table 1: Expected Mutual Information (in 1000*EMIM).
</tableCaption>
<table confidence="0.999940666666667">
Example dataset Subs. KH ME DistOpt PDistOpt
kindergarten 0.4 3.8 3.9 5.6 7.3
health care 0.5 2.8 3.1 7.8 8.3
used car 0.1 0.2 0.1 2.8 3.6
trip to DC 0.2 4.3 4.5 6.4 6.8
finance 0.01 0.01 0.1 0.6 0.6
gift 0.2 1.2 1.2 3.8 4.7
social network 0.1 1.5 1.3 2.4 3.2
information 0.3 1.9 2.3 3.5 4.9
cake 0.2 1.2 3.1 6.6 6.8
videographer 0.4 1.8 1.6 4.9 5.6
Mean of 50 sets 0.24 1.7 2.1 4.4 5.2
</table>
<tableCaption confidence="0.900534">
Table 2: Reach time.
</tableCaption>
<table confidence="0.999798916666667">
Example dataset Subs. KH ME DistOpt PDistOpt
kindergarten 14.4 9.8 9.9 8.7 4.3
health care 12.3 9.8 6.8 4.5 3.3
used car 15.4 12.4 10.2 8.7 7.6
trip to DC 11.2 10.3 9,8 8.7 5.8
finance 24.5 18.3 19.7 18.7 15.6
gift 11.2 8.4 7.7 5.6 5.4
social network 14.3 9.8 7.8 7.6 6.8
information 10.6 9.5 8.8 8.9 6.7
cake 8.9 4.8 4.5 3.4 3.2
videographer 9.5 8.8 7.6 6.9 4.5
Mean of 50 sets 14.2 12.2 9.8 7.2 5.2
</table>
<bodyText confidence="0.998867923076923">
more effective than the state-of-the-art systems in
constructing browsing taxonomies.
Moreover, Table 1 shows that the PDistOpt tax-
onomies is 18% more effective than the DistOpt tax-
onomies in terms of EMIM. The result is also sta-
tistically significant (p-value&lt;.01, t-test). It indi-
cates that incorporating user preferences in brows-
ing taxonomy construction is able to produce even
more effective browsing taxonomies than all auto-
mated methods.
Another popular evaluation measure3 for brows-
ing effectiveness is reach time (Carpineto et al.,
2009). It is defined as:
</bodyText>
<equation confidence="0.715166">
1 1: L(ci) + pi,
RI diER
</equation>
<bodyText confidence="0.999572882352941">
where R is the relevant documents, ci is the concept
that connects to a relevant document di, L(ci) is the
path length from the root to reach ci, and pi is the
position that di appears in the document cluster as-
sociated with ci. Reach time evaluates both the con-
tent and the structure of a browsing taxonomy. This
measure needs relevance judgements about a query
for the documents organized by the taxonomies. We
obtained the relevance judgements by using the ma-
jority votes from a user study involving 29 subjects
followed by expert reviews. Three experts manu-
ally examined the majority votes and reached agree-
ments on all relevance judgements.
Table 2 elaborates reach time for the systems.
Based on the mean reach time over 50 datasets,
we obtain a similar ranking of the systems as sug-
gested by EMIM. The ranking based on reach time
</bodyText>
<footnote confidence="0.9837595">
3Other proposed measures include coverage and compact-
ness (Kummamuru et al., 2004).
</footnote>
<figureCaption confidence="0.999364">
Figure 4: Path error rate.
</figureCaption>
<bodyText confidence="0.9998705">
is: PDistOpt &gt;&gt; DistOpt &gt;&gt; ME &gt; KH &gt;&gt;
Subsumption. It shows that the best performing
automatic system is DistOpt, which on average can
produce taxonomies to reach a relevant document by
visiting only 7.2 nodes, including 5.2 non-leaf con-
cepts and 2 documents in the leaf cluster on average.
To find all relevant documents in a collection sized
around 1000, this reach time is very fast. The in-
teractive PDistOpt unsurprisingly gives even better
reach time, 5.2 nodes on average.
</bodyText>
<subsectionHeader confidence="0.999438">
5.4 Path Consistency
</subsectionHeader>
<bodyText confidence="0.999908230769231">
To evaluate how well path consistency is handled,
we compare the path error rate generated by our ap-
proach and by other baseline systems. This evalua-
tion is only applied to automatic algorithms.
The path error is defined as the average number of
wrong ancestor-descendant pairs in a taxonomy. It is
only applied for concepts are not immediately con-
nected. It can be judged and calculated as follows.
Three human assessors manually evaluated the path
errors by (1) gathering the paths by performing a
depth-first traverse in the taxonomy from the root
concept; (2) along each path, counting the number
of wrong ancestor-descendant pairs; (3) summing up
</bodyText>
<figure confidence="0.9845816">
Path Error Rate
0.8
0.6
0.4
0.2
0
1
Subsumption ME KH DistOpt
treach �
1285
5
4
3
2
Subsumption KH ME DistOpt PDistOpt
</figure>
<figureCaption confidence="0.999908">
Figure 5: Perceived browsing effectiveness.
</figureCaption>
<bodyText confidence="0.999742142857143">
the errors that all assessors agree on and normalizing
the sum by the taxonomy size.
Figure 4 shows the path error rate generated by
all the automated algorithms under evaluation. We
can see that DistOpt produces the least path error.
The algorithms can be ranked in terms of the ability
to handle path consistency as DistOpt &gt;&gt; ME &gt;&gt;
KH &gt;&gt; Subsumption. DistOpt statistically signif-
icantly reduces path errors from not using the path
consistency control (ME) by 500% (p-value&lt;.001,
t-test). It strongly indicates that our technique is ef-
fective to maintain path consistency. We conclude
that DistOpt best handles path consistency among
all the system under evaluation.
</bodyText>
<subsectionHeader confidence="0.9972">
5.5 User Study
</subsectionHeader>
<bodyText confidence="0.9998875">
Besides objective evaluations, we conducted an user
study consisting of two parts: qualitative compari-
son of the systems under evaluation, and using our
taxonomy construction user interface to interactively
construct personalized browsing taxonomies.
Twenty-nine (Thirty subjects initially, one was ex-
cluded because of incomplete data entry) graduate
and undergraduate students from various majors in
two universities participated in the study. They were
all familiar with use of computers and highly profi-
cient in English. Each user study lasted for 4 hours.
In the first half of the user study, the participants
were first introduced to the taxonomy construction
user interface for about 10 minutes to get famil-
iar with its functions. After that, the participants
performed an exercise task which lasted about 5
minutes and then started the real tasks. For each
dataset, the participants were asked to interactively
work with PDistOpt to build browsing taxonomies.
Once the real tasks were done, the participants spend
5 minutes to answer a questionnaire regarding their
experience and opinions.
In the second half of the user study, we asked the
participants to use and compare the provided brows-
ing taxonomies with the following task in mind.
Imagine your have a task [task name].
You use a browsing taxonomy designed
for the collection of Web documents about
this task. Use the browsing taxonomy to
find all useful topics for your task. Iden-
tify at least one document for each topic.
For each dataset, we asked the participants to rate
the browsing taxonomies built by the systems un-
der evaluation by answering the following question
about perceived browsing effectiveness - “How well
did the browsing taxonomy help you to complete the
task?”. Ratings in the 5-point Likert-type scale,
ranging from “very good”(5), “good”(4), “fair”(3),
“bad”(2), to “trash”(1), are used to rate browsing ef-
fectiveness perceived by the participants.
</bodyText>
<subsubsectionHeader confidence="0.565396">
5.5.1 Perceived Browsing Effectiveness
</subsubsectionHeader>
<bodyText confidence="0.999941583333333">
Figure 5 shows the mean and 95% confidence in-
terval for the perceived browsing effectiveness for
browsing taxonomies constructed by the systems
under evaluation. These perceived browsing ef-
fectiveness can be ranked in descending order as
PDistOpt &gt;&gt; DistOpt &gt; ME &gt;&gt; KH &gt; Subsump-
tion. PDistOpt shows the highest mean perceived
browsing effectiveness, which is as high as 4.4. Such
high rating shows that browsing taxonomy with per-
sonalization could well satisfy users’ information
needs and are perceived as very effective in brows-
ing by the users.
</bodyText>
<subsectionHeader confidence="0.995671">
5.5.2 Accuracy of System Predictions
</subsectionHeader>
<bodyText confidence="0.999969666666667">
When a user provided manual guidance to the in-
teractive system, during each human-computer in-
teraction cycle, the system made predictions based
on the user’s edits. He or she could directly judge
the correctness of these machine-predicted modi-
fications on-the-fly by selecting an option “yes”
or “no” from the “Accept the change?” menu.
Note that these were personalized tasks and the
predictions were evaluated by the user according
</bodyText>
<note confidence="0.486914">
Perceived Browsing Effectiveness
</note>
<page confidence="0.956352">
1286
</page>
<tableCaption confidence="0.980907">
Table 4: Perceived learning ability.
</tableCaption>
<table confidence="0.995831333333333">
Max Min Avg
perceived learning ability 4.2 2.8 3.61
which dataset health care finance -
</table>
<tableCaption confidence="0.998571">
Table 3: Accuracy of system predictions.
</tableCaption>
<bodyText confidence="0.7624115">
Max Min Avg
accuracy of system predictions 0.98 0.92 0.94
to his/her own standard. We calculate the ac-
curacy of system predictions as: Accuracy =
</bodyText>
<equation confidence="0.8728575">
1 I number of accepted predictions in ith cycle where I
I �i=1 number of predictions in ith cycle ,
</equation>
<bodyText confidence="0.999928545454545">
is the total number of human-computer interaction
cycles when constructing a browsing taxonomy. A
high accuracy indicates that the system learns well
from user edits. This evaluation is only applied to
PDistOpt.
Table 3 shows that for all datasets, the mean ac-
curacy of the system predictions is above 0.92. The
average value is 0.94. This high accuracy clearly
demonstrates that the system successfully learns
from a user and makes highly accurate predictions
on how the user would organize the concepts.
</bodyText>
<subsectionHeader confidence="0.420842">
5.5.3 Perceived Learning Ability
</subsectionHeader>
<bodyText confidence="0.999992272727273">
After completing constructing a browsing taxon-
omy, a participant was asked immediately to rate
how well the system learned from his/her edits. The
question was “How well did the system appear to
learn your method of organizing the concepts?”. We
also used the 5-point Likert-type scale to rate this
perceived system learning ability. This evaluation is
only applied to PDistOpt.
Table 4 shows the max, min, and average re-
sponses of perceived system learning ability. The
mean perceived learning ability is 3.61, with a stan-
dard derivation of 0.45. It suggests that the learning
ability of the system was only perceived as moder-
ately good. This result contradicts with the conclu-
sion that we drew based on the more objective mea-
sure, accuracy of system prediction (Section 5.5.2).
We further investigate why the participants were
only moderately satisfied with the system’s learn-
ing ability. From the after session questionnaire, we
found that participants thought that some datasets
such as “finance” were more difficult than other
datasets such as “health care”. For example, the
dataset “finance” was considered by all participants
as “very difficult” while “health care” was consid-
ered as “very easy”. The participants also com-
plained that they were not familiar with the difficult
datasets. It is interesting that when a dataset is less
familiar for the users, the system was perceived per-
forming badly too. It may suggest that when peo-
ple are not familiar with the tasks, they provide less
promising edits, the system learns from the lower
quality training data, and in the end the users per-
ceive the output as poor system learning ability.
</bodyText>
<sectionHeader confidence="0.998909" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999961142857143">
Document collection browsing is another common
use of taxonomies. Given an arbitrary collection, a
taxonomy must suit the specific domain in order to
support browsing. This paper explores techniques
to quickly derive task-specific taxonomies support-
ing browsing in arbitrary document sets. In par-
ticular, we uniquely employ pair-wise semantic dis-
tance as an entry point to incrementally build brows-
ing taxonomies. The supervised distance learning
algorithm not only allows us to incorporate multi-
ple semantic features to evaluate the proximity be-
tween concepts, but also allows us to learn the met-
ric function from personal preferences. Users can
thus manually modify the taxonomies and to some
extent teach the algorithm to predict his/her way to
organize the concepts. Moreover, by minimizing the
overall semantic distances among concepts and re-
stricting minimal semantic distances along a path,
we find the best hierarchical structure as the brows-
ing hierarchy. It guarantees that semantically close
concepts are put together so that users will have a
good idea about why the concepts are put together.
This greatly increases the interpretability of a con-
structed browsing hierarchy than the existing ap-
proaches. This makes our approach more flexible
and more general to effectively creating browsing
taxonomies to support more complicated and more
realistic tasks such as Web information triage.
</bodyText>
<sectionHeader confidence="0.998027" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999527">
The author sincerely thanks Prof. Jamie Callan for
in-depth discussions about the research and anony-
mous reviewers for valuable comments to this paper.
</bodyText>
<page confidence="0.991416">
1287
</page>
<sectionHeader confidence="0.983628" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999809980769231">
J. R. Bellegarda, J. W. Butzberger, Yen-Lu Chow, N. B.
Coccaro, and D. Naik. 1996. A novel word clustering
algorithm based on latent semantic analysis. In Pro-
ceedings of the Acoustics, Speech, and Signal Process-
ing, 1996. on Conference Proceedings., 1996 IEEE
International Conference - Volume 01, ICASSP ’96,
pages 172–175, Washington, DC, USA. IEEE Com-
puter Society.
Matthew Berland and Eugene Charniak. 1999. Finding
parts in very large corpora. In Proceedings of the 27th
Annual Meeting for the Association for Computational
Linguistics (ACL 1999).
Rajendra Bhatia. 2006. Positive definite matrices
(princeton series in applied mathematics). Princeton
University Press, December.
Claudio Carpineto, Stefano Mizzaro, Giovanni Romano,
and Matteo Snidero. 2009. Mobile information re-
trieval with search results clustering: Prototypes and
evaluations. Journal ofAmerican Society for Informa-
tion Science and Technology (JASIST), pages 877–895.
Duen Horng Chau, Aniket Kittur, Jason I. Hong, and
Christos Faloutsos. 2011. Apolo: making sense of
large network data by combining rich user interaction
and machine learning. In CHI, pages 167–176.
Gouglass R. Cutting, David R. Karger, Jan R. Petersen,
and John W. Tukey. 1992. Scatter/Gather: A cluster-
based approach to browsing large document collec-
tions. In Proceedings of the fifteenth Annual ACM
Conference on Research and Development in Informa-
tion Retrieval (SIGIR 1992).
Oren Etzioni, Michael Cafarella, Doug Downey, Ana-
Maria Popescu, Tal Shaked, Stephen Soderland,
Daniel S. Weld, and Alexander Yates. 2005. Unsu-
pervised named-entity extraction from the web: an ex-
perimental study. In Artificial Intelligence, 165(1):91-
134, June.
Christiane Fellbaum. 1998. WordNet: an electronic lexi-
cal database. MIT Press.
Roxana Girju, Adriana Badulescu, and Dan Moldovan.
2003. Learning semantic constraints for the automatic
discovery of part-whole relations. In Proceedings of
the Human Language Technology Conference/Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics (HLT/NAACL
2003).
Sanda M. Harabagiu, Steve J. Maiorano, and Marius A.
Pasca. 2003. Open-domain textual question answer-
ing techniques. In Natural Language Engineering 9
(3): 1-38.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th International Conference on Computational
Linguistics (COLING 1992).
E. H. Hovy. 2002. Comparing Sets of Semantic Re-
lations in Ontologies. In R. Green, C. A. Bean,
and Myaeng S. H. (eds), editors, The Semantics of
Relationships: An Interdisciplinary Perspective. Dor-
drecht: Kluwer.
Zornitsa Kozareva and Eduard Hovy. 2010. A semi-
supervised method to learn and construct taxonomies
using the web. In Proceedings of the 2010 Conference
on Empirical Methods in Natural Language Process-
ing, pages 1110–1118, Cambridge, MA, October. As-
sociation for Computational Linguistics.
Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008.
Semantic class learning from the web with hyponym
pattern linkage graphs. In Proceedings of the 46th An-
nual Meeting for the Association for Computational
Linguistics (ACL 2008).
Krishna Kummamuru, Rohit Lotlikar, Shourya Roy,
Karan Singal, and Raghu Krishnapuram. 2004. A hi-
erarchical monothetic document clustering algorithm
for summarization and browsing search results. Pro-
ceedings of the 13th conference on World Wide Web
WWW 04, page 658.
Dawn Lawrie, W. Bruce Croft, and Arnold Rosenberg.
2001. Finding topic words for hierarchical summa-
rization. In Proceedings of the 24th Annual ACM Con-
ference on Research and Development in Information
Retrieval (SIGIR 2001), pages 349–357.
LCSH. 2011. Library of congress subject headings.
http://www.loc.gov/.
P. C. Mahalanobis. 1936. On the generalised distance in
statistics. In Proceedings of the National Institute of
Sciences of India 2 (1): 495.
ODP. 2011. Open directory project. http://www.
dmoz.org/.
Patrick Pantel and Marco Pennacchiotti. 2006. Espresso:
Leveraging generic patterns for automatically harvest-
ing semantic relations. In Proceedings of the 44th An-
nual Meeting for the Association for Computational
Linguistics (ACL 2006).
Deepak Ravichandran and Eduard Hovy. 2002. Learning
surface text patterns for a question answering system.
In Proceedings of the 40th Annual Meeting for the As-
sociation for Computational Linguistics (ACL 2002).
Mark Sanderson and W. Bruce Croft. 1999. Deriving
concept hierarchies from text. In Proceedings of the
22nd Annual International ACM SIGIR Conference on
Research and Development in Information Retrieval
(SIGIR 1999).
Sedumi. 2011. http://sedumi.mcmaster.ca.
Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006.
Semantic taxonomy induction from heterogenous evi-
</reference>
<page confidence="0.788756">
1288
</page>
<reference confidence="0.999740666666667">
dence. In Proceedings of the 21st International Con-
ference on Computational Linguistics and 44th Annual
Meeting of the Association for Computational Linguis-
tics (ACL/COLING 2006).
Emilia Stoica and Marti A. Hearst. 2007. Automating
Creation of Hierarchical Faceted Metadata Structures.
In Proceedings of the Human Language Technology
Conference (NAACL-HLT).
Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura
Coppola. 2004. Scaling web-based acquisition of en-
tailment relations. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP 2004).
Yalmip. 2011. http://users.isy.liu.se/
johanl/yalmip.
Hui Yang and Jamie Callan. 2008. Ontology generation
for large email collections. In Proceedings of the 8th
National Conference on Digital Government Research
(Dg.O 2008).
Hui Yang and Jamie Callan. 2009. A metric-based
framework for automatic taxonomy induction. In Pro-
ceedings of the 47th Annual Meeting for the Associa-
tion for Computational Linguistics (ACL 2009).
Liu Yang. 2006. Distance metric learning: A com-
prehensive survey. http://www.cs.cmu.edu/
˜liuy/frame_survey_v2.pdf.
Ka-Ping Yee, Kirsten Swearingen, Kevin Li, and Marti
Hearst. 2003. Faceted metadata for image search and
browsing. In Human factors in computing systems.
ACM.
</reference>
<page confidence="0.994858">
1289
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.335460">
<title confidence="0.999974">Constructing Task-Specific Taxonomies for Document Collection Browsing</title>
<author confidence="0.994401">Hui</author>
<affiliation confidence="0.913729">Department of Computer Georgetown</affiliation>
<address confidence="0.8000515">37th and O street, Washington, DC,</address>
<email confidence="0.99941">huiyang@cs.georgetown.edu</email>
<abstract confidence="0.98074852631579">Taxonomies can serve as browsing tools for document collections. However, given an arbitrary collection, pre-constructed taxonomies could not easily adapt to the specific topic/task present in the collection. This paper explores to taxonomies supporting browsing in arbitrary document collections. The supervised approach directly learns semantic distances from users to propose meaningful task-specific taxonomies. The approach aims to produce globally optimized taxonomy structures by incorporating path consistency control and usergenerated task specification into the general learning framework. A comparison to stateof-the-art systems and a user study jointly demonstrate that our techniques are highly effective.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J R Bellegarda</author>
<author>J W Butzberger</author>
<author>Yen-Lu Chow</author>
<author>N B Coccaro</author>
<author>D Naik</author>
</authors>
<title>A novel word clustering algorithm based on latent semantic analysis.</title>
<date>1996</date>
<booktitle>In Proceedings of the Acoustics, Speech, and Signal Processing,</booktitle>
<pages>172--175</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="9775" citStr="Bellegarda et al., 1996" startWordPosition="1463" endWordPosition="1466">the concepts and the second is to organize the concepts. For concept extraction, we take a simple but effective approach: (1) We first parse the document collection and exhaustively extract nouns, noun phrases, and named entities that occur &gt;5 times in the collection. (2) We then filter out part-of-speech errors and typos by a Webbased frequency test. In the test, we search each candidate concept in the Google search engine and remove a candidate if it appears &lt;4 times within the top 10 Google snippets. (3) We finally cluster similar concept candidates into groups by Latent Semantic Analysis (Bellegarda et al., 1996) and select the candidate with the highest tfidf value within a group to form the concept set C. Although our extraction algorithm is very effective with 95% precision and 80% recall in a manual evaluation, sometimes C may still miss some important concepts for the collection. This can be later corrected by users interactively through adding new concepts (Section 4). To organize the concepts in C into taxonomic structures, we extend the incremental clustering framework proposed by ME (Yang and Callan, 2009). In ME, concepts are inserted one at a time. At each insertion, a concept cz is at the </context>
</contexts>
<marker>Bellegarda, Butzberger, Chow, Coccaro, Naik, 1996</marker>
<rawString>J. R. Bellegarda, J. W. Butzberger, Yen-Lu Chow, N. B. Coccaro, and D. Naik. 1996. A novel word clustering algorithm based on latent semantic analysis. In Proceedings of the Acoustics, Speech, and Signal Processing, 1996. on Conference Proceedings., 1996 IEEE International Conference - Volume 01, ICASSP ’96, pages 172–175, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Berland</author>
<author>Eugene Charniak</author>
</authors>
<title>Finding parts in very large corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 27th Annual Meeting for the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="7313" citStr="Berland and Charniak, 1999" startWordPosition="1073" endWordPosition="1076">hierarchies and link documents to related concepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of vari</context>
</contexts>
<marker>Berland, Charniak, 1999</marker>
<rawString>Matthew Berland and Eugene Charniak. 1999. Finding parts in very large corpora. In Proceedings of the 27th Annual Meeting for the Association for Computational Linguistics (ACL 1999).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rajendra Bhatia</author>
</authors>
<title>Positive definite matrices (princeton series in applied mathematics).</title>
<date>2006</date>
<publisher>Princeton University Press,</publisher>
<contexts>
<context position="12712" citStr="Bhatia, 2006" startWordPosition="1946" endWordPosition="1947">y between two random vectors of the same distribution with a covariance matrix W, which scales the data points from their original values by agonal values of W are taken into account, W is equivalent to assigning weights to different axes in the random vectors. We choose Mahalanobis distance for two reasons. (1) It is in a parametric form so that it allows us to learn a distance function by supervised learning and W1/2. When only di1280 provides an opportunity to assign different weights for each type of semantic features. (2) When W is properly constrained to be positive semi-definite (PSD) (Bhatia, 2006), a Mahalanobis-formatted distance will be guaranteed to satisfy non-negativity and triangle inequality, which was not addressed in ME. As long as these two conditions are satisfied, one may learn other forms of distance functions to represent a semantic distance. We can estimate W by minimizing the squared errors between training semantic distances d and the expected value d. We also need to constrain W to be PSD to satisfy triangle inequality and nonnegativity. The objective function for semantic distance estimation is: y=1 |C |12 (dcx,cy − q4D(cx, cy)T W−14D(cx, cy)J (1) subject to W &gt;- 0 I</context>
</contexts>
<marker>Bhatia, 2006</marker>
<rawString>Rajendra Bhatia. 2006. Positive definite matrices (princeton series in applied mathematics). Princeton University Press, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Carpineto</author>
<author>Stefano Mizzaro</author>
<author>Giovanni Romano</author>
<author>Matteo Snidero</author>
</authors>
<title>Mobile information retrieval with search results clustering: Prototypes and evaluations.</title>
<date>2009</date>
<booktitle>Journal ofAmerican Society for Information Science and Technology (JASIST),</booktitle>
<pages>877--895</pages>
<contexts>
<context position="2538" citStr="Carpineto et al., 2009" startWordPosition="369" endWordPosition="372">omy to explore the documents in the collection. A browsing taxonomy benefits information access by providing corpus overview for a document collection and allowing more focused reading by presenting together documents about the same concept. Most existing browsing taxonomies, such as LCSH and ODP, are manually constructed to support large collections in general domains. Not only their constructions are expensive and slow, but also their structures are static and difficult to adapt to specific tasks. In situations where document collections are given ad-hoc, such as search result organization (Carpineto et al., 2009), email collection exploration (Yang and Callan, 2008), and literature investigation (Chau et al., 2011), existing taxonomies may even not be able to provide the right coverage of concepts. It is necessary to explore ad-hoc (semi-)automatic techniques to quickly derive task-specific browsing taxonomies for arbitrary document collections. (Hovy, 2002) pointed out that one key challenge in taxonomy construction is multiple perspectives embedded in concepts and relations. One cause for multiple perspectives is the inherent facets in concepts, e.g., jewelries can be organized by price or by gemsto</context>
<context position="6541" citStr="Carpineto et al., 2009" startWordPosition="966" endWordPosition="969">ddress path inconsistency due to word sense ambiguity and/or mixed perspectives; - A general scheme to capture user inputs in taxonomy construction; - A user study to evaluate the effectiveness of task-specific taxonomies for browsing activities. 2 Related Work Document collection browsing has been studied as an alternative to the ranked list representation for search results by the Information Retrieval (IR) community. The popular IR approaches include clustering (Cutting et al., 1992) and monothetic concept hierarchies (Sanderson and Croft, 1999; Lawrie et al., 2001; Kummamuru et al., 2004; Carpineto et al., 2009). Clustering approaches hierarchically cluster documents in a collection and label the clusters. Monothetic approaches organize the concepts into hierarchies and link documents to related concepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonom</context>
<context position="30575" citStr="Carpineto et al., 2009" startWordPosition="5030" endWordPosition="5033">4 3.2 videographer 9.5 8.8 7.6 6.9 4.5 Mean of 50 sets 14.2 12.2 9.8 7.2 5.2 more effective than the state-of-the-art systems in constructing browsing taxonomies. Moreover, Table 1 shows that the PDistOpt taxonomies is 18% more effective than the DistOpt taxonomies in terms of EMIM. The result is also statistically significant (p-value&lt;.01, t-test). It indicates that incorporating user preferences in browsing taxonomy construction is able to produce even more effective browsing taxonomies than all automated methods. Another popular evaluation measure3 for browsing effectiveness is reach time (Carpineto et al., 2009). It is defined as: 1 1: L(ci) + pi, RI diER where R is the relevant documents, ci is the concept that connects to a relevant document di, L(ci) is the path length from the root to reach ci, and pi is the position that di appears in the document cluster associated with ci. Reach time evaluates both the content and the structure of a browsing taxonomy. This measure needs relevance judgements about a query for the documents organized by the taxonomies. We obtained the relevance judgements by using the majority votes from a user study involving 29 subjects followed by expert reviews. Three expert</context>
</contexts>
<marker>Carpineto, Mizzaro, Romano, Snidero, 2009</marker>
<rawString>Claudio Carpineto, Stefano Mizzaro, Giovanni Romano, and Matteo Snidero. 2009. Mobile information retrieval with search results clustering: Prototypes and evaluations. Journal ofAmerican Society for Information Science and Technology (JASIST), pages 877–895.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duen Horng Chau</author>
<author>Aniket Kittur</author>
<author>Jason I Hong</author>
<author>Christos Faloutsos</author>
</authors>
<title>Apolo: making sense of large network data by combining rich user interaction and machine learning.</title>
<date>2011</date>
<booktitle>In CHI,</booktitle>
<pages>167--176</pages>
<contexts>
<context position="2642" citStr="Chau et al., 2011" startWordPosition="383" endWordPosition="386">corpus overview for a document collection and allowing more focused reading by presenting together documents about the same concept. Most existing browsing taxonomies, such as LCSH and ODP, are manually constructed to support large collections in general domains. Not only their constructions are expensive and slow, but also their structures are static and difficult to adapt to specific tasks. In situations where document collections are given ad-hoc, such as search result organization (Carpineto et al., 2009), email collection exploration (Yang and Callan, 2008), and literature investigation (Chau et al., 2011), existing taxonomies may even not be able to provide the right coverage of concepts. It is necessary to explore ad-hoc (semi-)automatic techniques to quickly derive task-specific browsing taxonomies for arbitrary document collections. (Hovy, 2002) pointed out that one key challenge in taxonomy construction is multiple perspectives embedded in concepts and relations. One cause for multiple perspectives is the inherent facets in concepts, e.g., jewelries can be organized by price or by gemstone types. Another cause is task specification or even personalization. For example, when building a taxo</context>
</contexts>
<marker>Chau, Kittur, Hong, Faloutsos, 2011</marker>
<rawString>Duen Horng Chau, Aniket Kittur, Jason I. Hong, and Christos Faloutsos. 2011. Apolo: making sense of large network data by combining rich user interaction and machine learning. In CHI, pages 167–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gouglass R Cutting</author>
<author>David R Karger</author>
<author>Jan R Petersen</author>
<author>John W Tukey</author>
</authors>
<title>Scatter/Gather: A clusterbased approach to browsing large document collections.</title>
<date>1992</date>
<booktitle>In Proceedings of the fifteenth Annual ACM Conference on Research and Development in Information Retrieval (SIGIR</booktitle>
<contexts>
<context position="6409" citStr="Cutting et al., 1992" startWordPosition="945" endWordPosition="948">sed learning mechanism to capture task-specific or personalized requirements for organizing a browsing taxonomy; - A strategy to address path inconsistency due to word sense ambiguity and/or mixed perspectives; - A general scheme to capture user inputs in taxonomy construction; - A user study to evaluate the effectiveness of task-specific taxonomies for browsing activities. 2 Related Work Document collection browsing has been studied as an alternative to the ranked list representation for search results by the Information Retrieval (IR) community. The popular IR approaches include clustering (Cutting et al., 1992) and monothetic concept hierarchies (Sanderson and Croft, 1999; Lawrie et al., 2001; Kummamuru et al., 2004; Carpineto et al., 2009). Clustering approaches hierarchically cluster documents in a collection and label the clusters. Monothetic approaches organize the concepts into hierarchies and link documents to related concepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an con</context>
</contexts>
<marker>Cutting, Karger, Petersen, Tukey, 1992</marker>
<rawString>Gouglass R. Cutting, David R. Karger, Jan R. Petersen, and John W. Tukey. 1992. Scatter/Gather: A clusterbased approach to browsing large document collections. In Proceedings of the fifteenth Annual ACM Conference on Research and Development in Information Retrieval (SIGIR 1992).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>AnaMaria Popescu</author>
<author>Tal Shaked</author>
<author>Stephen Soderland</author>
<author>Daniel S Weld</author>
<author>Alexander Yates</author>
</authors>
<title>Unsupervised named-entity extraction from the web: an experimental study.</title>
<date>2005</date>
<journal>In Artificial Intelligence,</journal>
<pages>165--1</pages>
<contexts>
<context position="4488" citStr="Etzioni et al., 2005" startWordPosition="659" endWordPosition="662"> is to leave the decision to the constructor independent of the confusion that comes from facets, task specification or personalization. When multiple perspectives present in the same taxonomy, it is not uncommon that the perspectives are mixed. For example, along a path financial institute—*bank—*river bank, financial institute—*bank shows one perspective and bank—*river bank shows another. We call this problem path inconsistency. Many approaches on automatic taxonomy construction suffer from this problem because their foci are on accurately identifying local relations between concept pairs (Etzioni et al., 2005; Pantel and Pennacchiotti, 2006) instead of on global control over the entire taxonomic structure. More recently, approaches attempted to build the full taxonomy structure (Snow et al., 2006; Yang and Callan, 2009; Kozareva and Hovy, 2010), however, few have looked into how to incorporate task specifications into taxonomy construction. In this paper, we extended an existing taxonomy construction approach (Yang and Callan, 2009) to build task-specific taxonomies for document collection browsing. The extension comes in two parts: handling path consistency and incorporating specifications from u</context>
<context position="7384" citStr="Etzioni et al., 2005" startWordPosition="1085" endWordPosition="1088">y based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and semantic features: E j weightj * featurej</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, AnaMaria Popescu, Tal Shaked, Stephen Soderland, Daniel S. Weld, and Alexander Yates. 2005. Unsupervised named-entity extraction from the web: an experimental study. In Artificial Intelligence, 165(1):91-134, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: an electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="8298" citStr="Fellbaum, 1998" startWordPosition="1228" endWordPosition="1229"> concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and semantic features: E j weightj * featurej(cx, cy) and estimate the taxonomic structure by minimizing the overall semantic distances. 1279 Researcher also attempted to carve out taxonomies from existing ones. For example, Stoica et al. (Stoica and Hearst, 2007) managed to extract a browsing taxonomy from hypernym relations within WordNet (Fellbaum, 1998). To support browsing in arbitrary collections, in this paper, we propose to incorporate task specification in a taxonomy. One way to achieve it is to define task-specific distances among concepts. Moreover, through controlling distance scores among concepts, we can enforce path consistency in taxonomies. For example, when the distance between financial institute and river bank is big, the path financial institute—*bank—*river bank will be pruned and the concepts will be repositioned. Inspired by ME, we take a distance learning approach to deal with path consistency (Section 3) and task specif</context>
<context position="13542" citStr="Fellbaum, 1998" startWordPosition="2079" endWordPosition="2080">tance functions to represent a semantic distance. We can estimate W by minimizing the squared errors between training semantic distances d and the expected value d. We also need to constrain W to be PSD to satisfy triangle inequality and nonnegativity. The objective function for semantic distance estimation is: y=1 |C |12 (dcx,cy − q4D(cx, cy)T W−14D(cx, cy)J (1) subject to W &gt;- 0 In this implementation, we used (Sedumi, 2011) and (Yalmip, 2011) to solve the semi-definite programming (SDP). To generate the training semantic distances, we collected 100 hypernym taxonomy fragments from WordNet (Fellbaum, 1998) and ODP. The semantic distance for a concept pair (cx, cy) in a training taxonomy fragment is generated by assuming every edge is weighted as 1 and summing up the edge weights along the shortest path from cx to cy in the taxonomy fragment. In Section 4, we will show how to use user inputs as training data to capture taskspecifications in taxonomy construction. 3.2 Enforcing Path Consistency In ME, the main taxonomy structure optimization framework is based on minimization of overall semantic distance among all concepts in the taxonomy and the minimum evolution assumption. We extend the framew</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: an electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Adriana Badulescu</author>
<author>Dan Moldovan</author>
</authors>
<title>Learning semantic constraints for the automatic discovery of part-whole relations.</title>
<date>2003</date>
<booktitle>In Proceedings of the Human Language Technology Conference/Annual Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL</booktitle>
<contexts>
<context position="7362" citStr="Girju et al., 2003" startWordPosition="1081" endWordPosition="1084">approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and semantic features: </context>
</contexts>
<marker>Girju, Badulescu, Moldovan, 2003</marker>
<rawString>Roxana Girju, Adriana Badulescu, and Dan Moldovan. 2003. Learning semantic constraints for the automatic discovery of part-whole relations. In Proceedings of the Human Language Technology Conference/Annual Conference of the North American Chapter of the Association for Computational Linguistics (HLT/NAACL 2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanda M Harabagiu</author>
<author>Steve J Maiorano</author>
<author>Marius A Pasca</author>
</authors>
<title>Open-domain textual question answering techniques.</title>
<date>2003</date>
<journal>In Natural Language Engineering</journal>
<volume>9</volume>
<issue>3</issue>
<pages>1--38</pages>
<contexts>
<context position="1145" citStr="Harabagiu et al., 2003" startWordPosition="151" endWordPosition="154">rary document collections. The supervised approach directly learns semantic distances from users to propose meaningful task-specific taxonomies. The approach aims to produce globally optimized taxonomy structures by incorporating path consistency control and usergenerated task specification into the general learning framework. A comparison to stateof-the-art systems and a user study jointly demonstrate that our techniques are highly effective. 1 Introduction Taxonomies are widely used for knowledge standardization, knowledge sharing, and inferencing in natural language processing (NLP) tasks (Harabagiu et al., 2003; Szpektor et al., 2004). However, another common function of taxonomies, browsing, has received little attention in the NLP community. Browsing is the task of exploring and accessing information through a structure, e.g. a hierarchy, built upon a given document collection. In fact, taxonomies serve as browsing tools in many venues, including the Library of Congress Subject Headings (LCSH, 2011) for the U.S. Library of Congress and the Open Directory Project (ODP, 2011) for about 5% of the entire Web. We call taxonomies supporting browsing as browsing taxonomies. When used for browsing, concep</context>
</contexts>
<marker>Harabagiu, Maiorano, Pasca, 2003</marker>
<rawString>Sanda M. Harabagiu, Steve J. Maiorano, and Marius A. Pasca. 2003. Open-domain textual question answering techniques. In Natural Language Engineering 9 (3): 1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics (COLING</booktitle>
<contexts>
<context position="7285" citStr="Hearst, 1992" startWordPosition="1071" endWordPosition="1072">concepts into hierarchies and link documents to related concepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a </context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th International Conference on Computational Linguistics (COLING 1992).</rawString>
</citation>
<citation valid="true">
<authors>
<author>E H Hovy</author>
</authors>
<title>Comparing Sets of Semantic Relations in Ontologies. In</title>
<date>2002</date>
<editor>R. Green, C. A. Bean, and Myaeng S. H. (eds), editors,</editor>
<publisher>Kluwer.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="2890" citStr="Hovy, 2002" startWordPosition="419" endWordPosition="420">domains. Not only their constructions are expensive and slow, but also their structures are static and difficult to adapt to specific tasks. In situations where document collections are given ad-hoc, such as search result organization (Carpineto et al., 2009), email collection exploration (Yang and Callan, 2008), and literature investigation (Chau et al., 2011), existing taxonomies may even not be able to provide the right coverage of concepts. It is necessary to explore ad-hoc (semi-)automatic techniques to quickly derive task-specific browsing taxonomies for arbitrary document collections. (Hovy, 2002) pointed out that one key challenge in taxonomy construction is multiple perspectives embedded in concepts and relations. One cause for multiple perspectives is the inherent facets in concepts, e.g., jewelries can be organized by price or by gemstone types. Another cause is task specification or even personalization. For example, when building a taxonomy for search results of query trip to 1English terms or entities; usually nouns or noun phrases. 1278 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages</context>
<context position="7342" citStr="Hovy, 2002" startWordPosition="1079" endWordPosition="1080">cepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and</context>
</contexts>
<marker>Hovy, 2002</marker>
<rawString>E. H. Hovy. 2002. Comparing Sets of Semantic Relations in Ontologies. In R. Green, C. A. Bean, and Myaeng S. H. (eds), editors, The Semantics of Relationships: An Interdisciplinary Perspective. Dordrecht: Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard Hovy</author>
</authors>
<title>A semisupervised method to learn and construct taxonomies using the web.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1110--1118</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="4728" citStr="Kozareva and Hovy, 2010" startWordPosition="695" endWordPosition="698">re mixed. For example, along a path financial institute—*bank—*river bank, financial institute—*bank shows one perspective and bank—*river bank shows another. We call this problem path inconsistency. Many approaches on automatic taxonomy construction suffer from this problem because their foci are on accurately identifying local relations between concept pairs (Etzioni et al., 2005; Pantel and Pennacchiotti, 2006) instead of on global control over the entire taxonomic structure. More recently, approaches attempted to build the full taxonomy structure (Snow et al., 2006; Yang and Callan, 2009; Kozareva and Hovy, 2010), however, few have looked into how to incorporate task specifications into taxonomy construction. In this paper, we extended an existing taxonomy construction approach (Yang and Callan, 2009) to build task-specific taxonomies for document collection browsing. The extension comes in two parts: handling path consistency and incorporating specifications from users. We uniquely employ pairwise semantic distance as an entry point to incrementally build browsing taxonomies. A supervised distance learning algorithm not only allows us to incorporate multiple semantic features to evaluate the proximit</context>
<context position="7657" citStr="Kozareva and Hovy, 2010" startWordPosition="1126" endWordPosition="1129">l to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and semantic features: E j weightj * featurej(cx, cy) and estimate the taxonomic structure by minimizing the overall semantic distances. 1279 Researcher also attempted to carve out taxonomies from existing ones. For example, Stoica et al. (Stoica and Hearst, 2007) managed to extract a browsing taxonomy from hypernym </context>
<context position="27044" citStr="Kozareva and Hovy, 2010" startWordPosition="4426" endWordPosition="4429">tisements and then search for more relevant Web documents to make the total number 1000. However, not all topics can retrieve 1000 documents. Among all 50 datasets, the average number of documents is 988.5. The average number of unique words in a dataset is 698,875. 5.2 Comparing with Baseline Systems We compare the following 5 systems. • Subsumption: the automatic algorithm proposed by (Sanderson and Croft, 1999), the most effective state-of-the-art browsing hierarchy construction technique as reported by (Lawrie et al., 2001). • KH: the automatic taxonomy construction algorithm proposed by (Kozareva and Hovy, 2010). • ME: the automatic taxonomy construction algorithm proposed by (Yang and Callan, 2009). This framework does not perform path consistency control nor learning from users. • DistOpt: our automatic taxonomy construction algorithm with path consistency control. • PDistOpt: our interactive approach with human supervision. The process starts from a flat list of concepts. The user built the browsing taxonomy from the list in a user study (Section 5.5). 5.3 Browsing Effectiveness A popular measure to evaluate the quality of the browsing taxonomies is the expected mutual information measure (EMIM (L</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard Hovy. 2010. A semisupervised method to learn and construct taxonomies using the web. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1110–1118, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Ellen Riloff</author>
<author>Eduard Hovy</author>
</authors>
<title>Semantic class learning from the web with hyponym pattern linkage graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting for the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="7440" citStr="Kozareva et al., 2008" startWordPosition="1093" endWordPosition="1096"> (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and semantic features: E j weightj * featurej(cx, cy) and estimate the taxonomic structure by minimiz</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Zornitsa Kozareva, Ellen Riloff, and Eduard Hovy. 2008. Semantic class learning from the web with hyponym pattern linkage graphs. In Proceedings of the 46th Annual Meeting for the Association for Computational Linguistics (ACL 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Krishna Kummamuru</author>
<author>Rohit Lotlikar</author>
<author>Shourya Roy</author>
<author>Karan Singal</author>
<author>Raghu Krishnapuram</author>
</authors>
<title>A hierarchical monothetic document clustering algorithm for summarization and browsing search results.</title>
<date>2004</date>
<booktitle>Proceedings of the 13th conference on World Wide Web WWW 04,</booktitle>
<pages>658</pages>
<contexts>
<context position="6516" citStr="Kummamuru et al., 2004" startWordPosition="962" endWordPosition="965">onomy; - A strategy to address path inconsistency due to word sense ambiguity and/or mixed perspectives; - A general scheme to capture user inputs in taxonomy construction; - A user study to evaluate the effectiveness of task-specific taxonomies for browsing activities. 2 Related Work Document collection browsing has been studied as an alternative to the ranked list representation for search results by the Information Retrieval (IR) community. The popular IR approaches include clustering (Cutting et al., 1992) and monothetic concept hierarchies (Sanderson and Croft, 1999; Lawrie et al., 2001; Kummamuru et al., 2004; Carpineto et al., 2009). Clustering approaches hierarchically cluster documents in a collection and label the clusters. Monothetic approaches organize the concepts into hierarchies and link documents to related concepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively </context>
<context position="31539" citStr="Kummamuru et al., 2004" startWordPosition="5200" endWordPosition="5203">ng taxonomy. This measure needs relevance judgements about a query for the documents organized by the taxonomies. We obtained the relevance judgements by using the majority votes from a user study involving 29 subjects followed by expert reviews. Three experts manually examined the majority votes and reached agreements on all relevance judgements. Table 2 elaborates reach time for the systems. Based on the mean reach time over 50 datasets, we obtain a similar ranking of the systems as suggested by EMIM. The ranking based on reach time 3Other proposed measures include coverage and compactness (Kummamuru et al., 2004). Figure 4: Path error rate. is: PDistOpt &gt;&gt; DistOpt &gt;&gt; ME &gt; KH &gt;&gt; Subsumption. It shows that the best performing automatic system is DistOpt, which on average can produce taxonomies to reach a relevant document by visiting only 7.2 nodes, including 5.2 non-leaf concepts and 2 documents in the leaf cluster on average. To find all relevant documents in a collection sized around 1000, this reach time is very fast. The interactive PDistOpt unsurprisingly gives even better reach time, 5.2 nodes on average. 5.4 Path Consistency To evaluate how well path consistency is handled, we compare the path e</context>
</contexts>
<marker>Kummamuru, Lotlikar, Roy, Singal, Krishnapuram, 2004</marker>
<rawString>Krishna Kummamuru, Rohit Lotlikar, Shourya Roy, Karan Singal, and Raghu Krishnapuram. 2004. A hierarchical monothetic document clustering algorithm for summarization and browsing search results. Proceedings of the 13th conference on World Wide Web WWW 04, page 658.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dawn Lawrie</author>
<author>W Bruce Croft</author>
<author>Arnold Rosenberg</author>
</authors>
<title>Finding topic words for hierarchical summarization.</title>
<date>2001</date>
<booktitle>In Proceedings of the 24th Annual ACM Conference on Research and Development in Information Retrieval (SIGIR</booktitle>
<pages>349--357</pages>
<contexts>
<context position="6492" citStr="Lawrie et al., 2001" startWordPosition="958" endWordPosition="961">nizing a browsing taxonomy; - A strategy to address path inconsistency due to word sense ambiguity and/or mixed perspectives; - A general scheme to capture user inputs in taxonomy construction; - A user study to evaluate the effectiveness of task-specific taxonomies for browsing activities. 2 Related Work Document collection browsing has been studied as an alternative to the ranked list representation for search results by the Information Retrieval (IR) community. The popular IR approaches include clustering (Cutting et al., 1992) and monothetic concept hierarchies (Sanderson and Croft, 1999; Lawrie et al., 2001; Kummamuru et al., 2004; Carpineto et al., 2009). Clustering approaches hierarchically cluster documents in a collection and label the clusters. Monothetic approaches organize the concepts into hierarchies and link documents to related concepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP co</context>
<context position="26953" citStr="Lawrie et al., 2001" startWordPosition="4412" endWordPosition="4415">Around 1000 Web documents are collected for each dataset. We filter out spams and advertisements and then search for more relevant Web documents to make the total number 1000. However, not all topics can retrieve 1000 documents. Among all 50 datasets, the average number of documents is 988.5. The average number of unique words in a dataset is 698,875. 5.2 Comparing with Baseline Systems We compare the following 5 systems. • Subsumption: the automatic algorithm proposed by (Sanderson and Croft, 1999), the most effective state-of-the-art browsing hierarchy construction technique as reported by (Lawrie et al., 2001). • KH: the automatic taxonomy construction algorithm proposed by (Kozareva and Hovy, 2010). • ME: the automatic taxonomy construction algorithm proposed by (Yang and Callan, 2009). This framework does not perform path consistency control nor learning from users. • DistOpt: our automatic taxonomy construction algorithm with path consistency control. • PDistOpt: our interactive approach with human supervision. The process starts from a flat list of concepts. The user built the browsing taxonomy from the list in a user study (Section 5.5). 5.3 Browsing Effectiveness A popular measure to evaluate</context>
</contexts>
<marker>Lawrie, Croft, Rosenberg, 2001</marker>
<rawString>Dawn Lawrie, W. Bruce Croft, and Arnold Rosenberg. 2001. Finding topic words for hierarchical summarization. In Proceedings of the 24th Annual ACM Conference on Research and Development in Information Retrieval (SIGIR 2001), pages 349–357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>LCSH</author>
</authors>
<title>Library of congress subject headings.</title>
<date>2011</date>
<note>http://www.loc.gov/.</note>
<contexts>
<context position="1543" citStr="LCSH, 2011" startWordPosition="215" endWordPosition="216">t our techniques are highly effective. 1 Introduction Taxonomies are widely used for knowledge standardization, knowledge sharing, and inferencing in natural language processing (NLP) tasks (Harabagiu et al., 2003; Szpektor et al., 2004). However, another common function of taxonomies, browsing, has received little attention in the NLP community. Browsing is the task of exploring and accessing information through a structure, e.g. a hierarchy, built upon a given document collection. In fact, taxonomies serve as browsing tools in many venues, including the Library of Congress Subject Headings (LCSH, 2011) for the U.S. Library of Congress and the Open Directory Project (ODP, 2011) for about 5% of the entire Web. We call taxonomies supporting browsing as browsing taxonomies. When used for browsing, concepts1 in taxonomies are linked to documents containing them and taxonomic structures are navigated to find particular documents. Users can navigate through a browsing taxonomy to explore the documents in the collection. A browsing taxonomy benefits information access by providing corpus overview for a document collection and allowing more focused reading by presenting together documents about the </context>
</contexts>
<marker>LCSH, 2011</marker>
<rawString>LCSH. 2011. Library of congress subject headings. http://www.loc.gov/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P C Mahalanobis</author>
</authors>
<title>On the generalised distance in statistics.</title>
<date>1936</date>
<booktitle>In Proceedings of the National Institute of Sciences of India</booktitle>
<volume>2</volume>
<issue>1</issue>
<pages>495</pages>
<marker>Mahalanobis, 1936</marker>
<rawString>P. C. Mahalanobis. 1936. On the generalised distance in statistics. In Proceedings of the National Institute of Sciences of India 2 (1): 495.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ODP</author>
</authors>
<title>Open directory project.</title>
<date>2011</date>
<note>http://www. dmoz.org/.</note>
<contexts>
<context position="1619" citStr="ODP, 2011" startWordPosition="228" endWordPosition="229">sed for knowledge standardization, knowledge sharing, and inferencing in natural language processing (NLP) tasks (Harabagiu et al., 2003; Szpektor et al., 2004). However, another common function of taxonomies, browsing, has received little attention in the NLP community. Browsing is the task of exploring and accessing information through a structure, e.g. a hierarchy, built upon a given document collection. In fact, taxonomies serve as browsing tools in many venues, including the Library of Congress Subject Headings (LCSH, 2011) for the U.S. Library of Congress and the Open Directory Project (ODP, 2011) for about 5% of the entire Web. We call taxonomies supporting browsing as browsing taxonomies. When used for browsing, concepts1 in taxonomies are linked to documents containing them and taxonomic structures are navigated to find particular documents. Users can navigate through a browsing taxonomy to explore the documents in the collection. A browsing taxonomy benefits information access by providing corpus overview for a document collection and allowing more focused reading by presenting together documents about the same concept. Most existing browsing taxonomies, such as LCSH and ODP, are m</context>
</contexts>
<marker>ODP, 2011</marker>
<rawString>ODP. 2011. Open directory project. http://www. dmoz.org/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Espresso: Leveraging generic patterns for automatically harvesting semantic relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting for the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="4521" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="663" endWordPosition="666">ion to the constructor independent of the confusion that comes from facets, task specification or personalization. When multiple perspectives present in the same taxonomy, it is not uncommon that the perspectives are mixed. For example, along a path financial institute—*bank—*river bank, financial institute—*bank shows one perspective and bank—*river bank shows another. We call this problem path inconsistency. Many approaches on automatic taxonomy construction suffer from this problem because their foci are on accurately identifying local relations between concept pairs (Etzioni et al., 2005; Pantel and Pennacchiotti, 2006) instead of on global control over the entire taxonomic structure. More recently, approaches attempted to build the full taxonomy structure (Snow et al., 2006; Yang and Callan, 2009; Kozareva and Hovy, 2010), however, few have looked into how to incorporate task specifications into taxonomy construction. In this paper, we extended an existing taxonomy construction approach (Yang and Callan, 2009) to build task-specific taxonomies for document collection browsing. The extension comes in two parts: handling path consistency and incorporating specifications from users. We uniquely employ pairwise</context>
<context position="7416" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="1089" endWordPosition="1092">tics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and semantic features: E j weightj * featurej(cx, cy) and estimate the taxono</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Patrick Pantel and Marco Pennacchiotti. 2006. Espresso: Leveraging generic patterns for automatically harvesting semantic relations. In Proceedings of the 44th Annual Meeting for the Association for Computational Linguistics (ACL 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting for the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="7342" citStr="Ravichandran and Hovy, 2002" startWordPosition="1077" endWordPosition="1080">ts to related concepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings of the 40th Annual Meeting for the Association for Computational Linguistics (ACL 2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Sanderson</author>
<author>W Bruce Croft</author>
</authors>
<title>Deriving concept hierarchies from text.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR</booktitle>
<contexts>
<context position="6471" citStr="Sanderson and Croft, 1999" startWordPosition="954" endWordPosition="957">lized requirements for organizing a browsing taxonomy; - A strategy to address path inconsistency due to word sense ambiguity and/or mixed perspectives; - A general scheme to capture user inputs in taxonomy construction; - A user study to evaluate the effectiveness of task-specific taxonomies for browsing activities. 2 Related Work Document collection browsing has been studied as an alternative to the ranked list representation for search results by the Information Retrieval (IR) community. The popular IR approaches include clustering (Cutting et al., 1992) and monothetic concept hierarchies (Sanderson and Croft, 1999; Lawrie et al., 2001; Kummamuru et al., 2004; Carpineto et al., 2009). Clustering approaches hierarchically cluster documents in a collection and label the clusters. Monothetic approaches organize the concepts into hierarchies and link documents to related concepts. Both approaches are mainly based on pure statistics, such as document frequency (Sanderson and Croft, 1999) and conditional probability (Lawrie et al., 2001). The major drawback of these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful t</context>
<context position="26837" citStr="Sanderson and Croft, 1999" startWordPosition="4396" endWordPosition="4399">vey paper for social network, write a survey paper for EU’s finance, and write a survey paper for information technology. Around 1000 Web documents are collected for each dataset. We filter out spams and advertisements and then search for more relevant Web documents to make the total number 1000. However, not all topics can retrieve 1000 documents. Among all 50 datasets, the average number of documents is 988.5. The average number of unique words in a dataset is 698,875. 5.2 Comparing with Baseline Systems We compare the following 5 systems. • Subsumption: the automatic algorithm proposed by (Sanderson and Croft, 1999), the most effective state-of-the-art browsing hierarchy construction technique as reported by (Lawrie et al., 2001). • KH: the automatic taxonomy construction algorithm proposed by (Kozareva and Hovy, 2010). • ME: the automatic taxonomy construction algorithm proposed by (Yang and Callan, 2009). This framework does not perform path consistency control nor learning from users. • DistOpt: our automatic taxonomy construction algorithm with path consistency control. • PDistOpt: our interactive approach with human supervision. The process starts from a flat list of concepts. The user built the bro</context>
</contexts>
<marker>Sanderson, Croft, 1999</marker>
<rawString>Mark Sanderson and W. Bruce Croft. 1999. Deriving concept hierarchies from text. In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR 1999).</rawString>
</citation>
<citation valid="true">
<authors>
<author>http sedumi mcmaster ca Rion Snow</author>
<author>Daniel Jurafsky</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL/COLING</booktitle>
<contexts>
<context position="4679" citStr="Snow et al., 2006" startWordPosition="687" endWordPosition="690">it is not uncommon that the perspectives are mixed. For example, along a path financial institute—*bank—*river bank, financial institute—*bank shows one perspective and bank—*river bank shows another. We call this problem path inconsistency. Many approaches on automatic taxonomy construction suffer from this problem because their foci are on accurately identifying local relations between concept pairs (Etzioni et al., 2005; Pantel and Pennacchiotti, 2006) instead of on global control over the entire taxonomic structure. More recently, approaches attempted to build the full taxonomy structure (Snow et al., 2006; Yang and Callan, 2009; Kozareva and Hovy, 2010), however, few have looked into how to incorporate task specifications into taxonomy construction. In this paper, we extended an existing taxonomy construction approach (Yang and Callan, 2009) to build task-specific taxonomies for document collection browsing. The extension comes in two parts: handling path consistency and incorporating specifications from users. We uniquely employ pairwise semantic distance as an entry point to incrementally build browsing taxonomies. A supervised distance learning algorithm not only allows us to incorporate mu</context>
<context position="7537" citStr="Snow et al., 2006" startWordPosition="1109" endWordPosition="1112"> these pure statistical approaches is their neglect of semantics among concepts. As an consequence, they often fail to produce semantically meaningful taxonomies. The NLP community has extensively studied automatic taxonomy construction. Although traditional research on taxonomy construction focuses on extracting local relations between concept pairs (Hearst, 1992; Berland and Charniak, 1999; Ravichandran and Hovy, 2002; Girju et al., 2003; Etzioni et al., 2005; Pantel and Pennacchiotti, 2006; Kozareva et al., 2008), more recent efforts has been made in building full taxonomies. For example, (Snow et al., 2006) proposed to estimate taxonomic structure via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and semantic features: E j weightj * featurej(cx, cy) and estimate the taxonomic structure by minimizing the overall semantic distances. 1279 Researcher also attempted to carve out taxonomies from e</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Sedumi. 2011. http://sedumi.mcmaster.ca. Rion Snow, Daniel Jurafsky, and Andrew Y. Ng. 2006. Semantic taxonomy induction from heterogenous evidence. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (ACL/COLING 2006).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emilia Stoica</author>
<author>Marti A Hearst</author>
</authors>
<title>Automating Creation of Hierarchical Faceted Metadata Structures.</title>
<date>2007</date>
<booktitle>In Proceedings of the Human Language Technology Conference (NAACL-HLT).</booktitle>
<contexts>
<context position="8203" citStr="Stoica and Hearst, 2007" startWordPosition="1213" endWordPosition="1216">via maximizing the overall likelihood of a taxonomy. (Kozareva and Hovy, 2010) proposed to connect local concept pairs by finding the longest path in a subsumption graph. Yang and Callan proposed the Minimum Evolution (ME) framework to model the semantic distance d(cx, cy) between concepts cx and cy as a weighted combination of various lexical, statistical, and semantic features: E j weightj * featurej(cx, cy) and estimate the taxonomic structure by minimizing the overall semantic distances. 1279 Researcher also attempted to carve out taxonomies from existing ones. For example, Stoica et al. (Stoica and Hearst, 2007) managed to extract a browsing taxonomy from hypernym relations within WordNet (Fellbaum, 1998). To support browsing in arbitrary collections, in this paper, we propose to incorporate task specification in a taxonomy. One way to achieve it is to define task-specific distances among concepts. Moreover, through controlling distance scores among concepts, we can enforce path consistency in taxonomies. For example, when the distance between financial institute and river bank is big, the path financial institute—*bank—*river bank will be pruned and the concepts will be repositioned. Inspired by ME,</context>
</contexts>
<marker>Stoica, Hearst, 2007</marker>
<rawString>Emilia Stoica and Marti A. Hearst. 2007. Automating Creation of Hierarchical Faceted Metadata Structures. In Proceedings of the Human Language Technology Conference (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Hristo Tanev</author>
<author>Ido Dagan</author>
<author>Bonaventura Coppola</author>
</authors>
<title>Scaling web-based acquisition of entailment relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<contexts>
<context position="1169" citStr="Szpektor et al., 2004" startWordPosition="155" endWordPosition="158">s. The supervised approach directly learns semantic distances from users to propose meaningful task-specific taxonomies. The approach aims to produce globally optimized taxonomy structures by incorporating path consistency control and usergenerated task specification into the general learning framework. A comparison to stateof-the-art systems and a user study jointly demonstrate that our techniques are highly effective. 1 Introduction Taxonomies are widely used for knowledge standardization, knowledge sharing, and inferencing in natural language processing (NLP) tasks (Harabagiu et al., 2003; Szpektor et al., 2004). However, another common function of taxonomies, browsing, has received little attention in the NLP community. Browsing is the task of exploring and accessing information through a structure, e.g. a hierarchy, built upon a given document collection. In fact, taxonomies serve as browsing tools in many venues, including the Library of Congress Subject Headings (LCSH, 2011) for the U.S. Library of Congress and the Open Directory Project (ODP, 2011) for about 5% of the entire Web. We call taxonomies supporting browsing as browsing taxonomies. When used for browsing, concepts1 in taxonomies are li</context>
</contexts>
<marker>Szpektor, Tanev, Dagan, Coppola, 2004</marker>
<rawString>Idan Szpektor, Hristo Tanev, Ido Dagan, and Bonaventura Coppola. 2004. Scaling web-based acquisition of entailment relations. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yalmip</author>
</authors>
<date>2011</date>
<note>http://users.isy.liu.se/ johanl/yalmip.</note>
<contexts>
<context position="13376" citStr="Yalmip, 2011" startWordPosition="2056" endWordPosition="2057">ed to satisfy non-negativity and triangle inequality, which was not addressed in ME. As long as these two conditions are satisfied, one may learn other forms of distance functions to represent a semantic distance. We can estimate W by minimizing the squared errors between training semantic distances d and the expected value d. We also need to constrain W to be PSD to satisfy triangle inequality and nonnegativity. The objective function for semantic distance estimation is: y=1 |C |12 (dcx,cy − q4D(cx, cy)T W−14D(cx, cy)J (1) subject to W &gt;- 0 In this implementation, we used (Sedumi, 2011) and (Yalmip, 2011) to solve the semi-definite programming (SDP). To generate the training semantic distances, we collected 100 hypernym taxonomy fragments from WordNet (Fellbaum, 1998) and ODP. The semantic distance for a concept pair (cx, cy) in a training taxonomy fragment is generated by assuming every edge is weighted as 1 and summing up the edge weights along the shortest path from cx to cy in the taxonomy fragment. In Section 4, we will show how to use user inputs as training data to capture taskspecifications in taxonomy construction. 3.2 Enforcing Path Consistency In ME, the main taxonomy structure opti</context>
</contexts>
<marker>Yalmip, 2011</marker>
<rawString>Yalmip. 2011. http://users.isy.liu.se/ johanl/yalmip.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Yang</author>
<author>Jamie Callan</author>
</authors>
<title>Ontology generation for large email collections.</title>
<date>2008</date>
<booktitle>In Proceedings of the 8th National Conference on Digital Government Research (Dg.O</booktitle>
<contexts>
<context position="2592" citStr="Yang and Callan, 2008" startWordPosition="376" endWordPosition="379">ing taxonomy benefits information access by providing corpus overview for a document collection and allowing more focused reading by presenting together documents about the same concept. Most existing browsing taxonomies, such as LCSH and ODP, are manually constructed to support large collections in general domains. Not only their constructions are expensive and slow, but also their structures are static and difficult to adapt to specific tasks. In situations where document collections are given ad-hoc, such as search result organization (Carpineto et al., 2009), email collection exploration (Yang and Callan, 2008), and literature investigation (Chau et al., 2011), existing taxonomies may even not be able to provide the right coverage of concepts. It is necessary to explore ad-hoc (semi-)automatic techniques to quickly derive task-specific browsing taxonomies for arbitrary document collections. (Hovy, 2002) pointed out that one key challenge in taxonomy construction is multiple perspectives embedded in concepts and relations. One cause for multiple perspectives is the inherent facets in concepts, e.g., jewelries can be organized by price or by gemstone types. Another cause is task specification or even </context>
</contexts>
<marker>Yang, Callan, 2008</marker>
<rawString>Hui Yang and Jamie Callan. 2008. Ontology generation for large email collections. In Proceedings of the 8th National Conference on Digital Government Research (Dg.O 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Yang</author>
<author>Jamie Callan</author>
</authors>
<title>A metric-based framework for automatic taxonomy induction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting for the Association for Computational Linguistics (ACL</booktitle>
<contexts>
<context position="4702" citStr="Yang and Callan, 2009" startWordPosition="691" endWordPosition="694">that the perspectives are mixed. For example, along a path financial institute—*bank—*river bank, financial institute—*bank shows one perspective and bank—*river bank shows another. We call this problem path inconsistency. Many approaches on automatic taxonomy construction suffer from this problem because their foci are on accurately identifying local relations between concept pairs (Etzioni et al., 2005; Pantel and Pennacchiotti, 2006) instead of on global control over the entire taxonomic structure. More recently, approaches attempted to build the full taxonomy structure (Snow et al., 2006; Yang and Callan, 2009; Kozareva and Hovy, 2010), however, few have looked into how to incorporate task specifications into taxonomy construction. In this paper, we extended an existing taxonomy construction approach (Yang and Callan, 2009) to build task-specific taxonomies for document collection browsing. The extension comes in two parts: handling path consistency and incorporating specifications from users. We uniquely employ pairwise semantic distance as an entry point to incrementally build browsing taxonomies. A supervised distance learning algorithm not only allows us to incorporate multiple semantic feature</context>
<context position="10287" citStr="Yang and Callan, 2009" startWordPosition="1548" endWordPosition="1551">e finally cluster similar concept candidates into groups by Latent Semantic Analysis (Bellegarda et al., 1996) and select the candidate with the highest tfidf value within a group to form the concept set C. Although our extraction algorithm is very effective with 95% precision and 80% recall in a manual evaluation, sometimes C may still miss some important concepts for the collection. This can be later corrected by users interactively through adding new concepts (Section 4). To organize the concepts in C into taxonomic structures, we extend the incremental clustering framework proposed by ME (Yang and Callan, 2009). In ME, concepts are inserted one at a time. At each insertion, a concept cz is at the parent (or child) position for every existing node in the current taxonomy. The evaluation of the best position depends on the semantic distance between cz and its temporary child (or parent) node and the semantic distance among all other concepts in the taxonomy. An advantage in ME is that it allows incorporating various constraints to the taxonomic structure. For example, ME can handle concept generalityspecificity by learning different semantic distance functions for general concepts which are located at</context>
<context position="27133" citStr="Yang and Callan, 2009" startWordPosition="4440" endWordPosition="4443">wever, not all topics can retrieve 1000 documents. Among all 50 datasets, the average number of documents is 988.5. The average number of unique words in a dataset is 698,875. 5.2 Comparing with Baseline Systems We compare the following 5 systems. • Subsumption: the automatic algorithm proposed by (Sanderson and Croft, 1999), the most effective state-of-the-art browsing hierarchy construction technique as reported by (Lawrie et al., 2001). • KH: the automatic taxonomy construction algorithm proposed by (Kozareva and Hovy, 2010). • ME: the automatic taxonomy construction algorithm proposed by (Yang and Callan, 2009). This framework does not perform path consistency control nor learning from users. • DistOpt: our automatic taxonomy construction algorithm with path consistency control. • PDistOpt: our interactive approach with human supervision. The process starts from a flat list of concepts. The user built the browsing taxonomy from the list in a user study (Section 5.5). 5.3 Browsing Effectiveness A popular measure to evaluate the quality of the browsing taxonomies is the expected mutual information measure (EMIM (Lawrie et al., 2001)). It calculates the mutual information between the language model in </context>
</contexts>
<marker>Yang, Callan, 2009</marker>
<rawString>Hui Yang and Jamie Callan. 2009. A metric-based framework for automatic taxonomy induction. In Proceedings of the 47th Annual Meeting for the Association for Computational Linguistics (ACL 2009).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liu Yang</author>
</authors>
<title>Distance metric learning: A comprehensive survey.</title>
<date>2006</date>
<note>http://www.cs.cmu.edu/ ˜liuy/frame_survey_v2.pdf.</note>
<contexts>
<context position="12069" citStr="Yang, 2006" startWordPosition="1839" endWordPosition="1840">ure semantic dissimilarity for concepts and a good semantic distance is a combination of these features”. Different from ME, we model the semantic distance d(cx, cy) between concepts (cx, cy) as a Mahalanobis distance (Mahalanobis, V/ 1936): d�x,�y = �(cx, cy)TW−14b(cx, xy), where 4b(cx, cy) is the set of underlying feature functions IOk : (cx, cy)} with k=1,...,|4b|. W is the weight matrix, whose diagonal values weigh the various feature functions. We use the same set of features as proposed in ME. Mahalanobis distance is a general parametric function widely used in distance metric learning (Yang, 2006). It measures the dissimilarity between two random vectors of the same distribution with a covariance matrix W, which scales the data points from their original values by agonal values of W are taken into account, W is equivalent to assigning weights to different axes in the random vectors. We choose Mahalanobis distance for two reasons. (1) It is in a parametric form so that it allows us to learn a distance function by supervised learning and W1/2. When only di1280 provides an opportunity to assign different weights for each type of semantic features. (2) When W is properly constrained to be </context>
</contexts>
<marker>Yang, 2006</marker>
<rawString>Liu Yang. 2006. Distance metric learning: A comprehensive survey. http://www.cs.cmu.edu/ ˜liuy/frame_survey_v2.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ka-Ping Yee</author>
<author>Kirsten Swearingen</author>
<author>Kevin Li</author>
<author>Marti Hearst</author>
</authors>
<title>Faceted metadata for image search and browsing. In Human factors in computing systems.</title>
<date>2003</date>
<publisher>ACM.</publisher>
<marker>Yee, Swearingen, Li, Hearst, 2003</marker>
<rawString>Ka-Ping Yee, Kirsten Swearingen, Kevin Li, and Marti Hearst. 2003. Faceted metadata for image search and browsing. In Human factors in computing systems. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>