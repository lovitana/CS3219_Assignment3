<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000085">
<title confidence="0.994861">
Enlarging Paraphrase Collections through Generalization and Instantiation
</title>
<author confidence="0.994387">
Atsushi Fujita
</author>
<affiliation confidence="0.996076">
Future University Hakodate
</affiliation>
<address confidence="0.8311875">
116-2 Kameda-nakano-cho,
Hakodate, Hokkaido, 041-8655, Japan
</address>
<email confidence="0.998469">
fujita@fun.ac.jp
</email>
<author confidence="0.992934">
Pierre Isabelle Roland Kuhn
</author>
<affiliation confidence="0.993238">
National Research Council Canada
</affiliation>
<address confidence="0.9493355">
283 Alexandre-Tach´e Boulevard,
Gatineau, QC, J8X 3X7, Canada
</address>
<email confidence="0.995615">
{Pierre.Isabelle, Roland.Kuhn}@nrc.ca
</email>
<sectionHeader confidence="0.993698" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999765304347826">
This paper presents a paraphrase acquisition
method that uncovers and exploits generali-
ties underlying paraphrases: paraphrase pat-
terns are first induced and then used to col-
lect novel instances. Unlike existing methods,
ours uses both bilingual parallel and monolin-
gual corpora. While the former are regarded as
a source of high-quality seed paraphrases, the
latter are searched for paraphrases that match
patterns learned from the seed paraphrases.
We show how one can use monolingual cor-
pora, which are far more numerous and larger
than bilingual corpora, to obtain paraphrases
that rival in quality those derived directly from
bilingual corpora. In our experiments, the
number of paraphrase pairs obtained in this
way from monolingual corpora was a large
multiple of the number of seed paraphrases.
Human evaluation through a paraphrase sub-
stitution test demonstrated that the newly ac-
quired paraphrase pairs are of reasonable qual-
ity. Remaining noise can be further reduced
by filtering seed paraphrases.
</bodyText>
<sectionHeader confidence="0.999129" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999220333333333">
Paraphrases are semantically equivalent expressions
in the same language. Because “equivalence” is the
most fundamental semantic relationship, techniques
for generating and recognizing paraphrases play an
important role in a wide range of natural language
processing tasks (Madnani and Dorr, 2010).
In the last decade, automatic acquisition of knowl-
edge about paraphrases from corpora has been draw-
ing the attention of many researchers. Typically, the
acquired knowledge is simply represented as pairs of
semantically equivalent sub-sentential expressions
as in (1).
</bodyText>
<listItem confidence="0.662138">
(1) a. look like .&lt;---&gt; resemble
b. control system q controller
</listItem>
<bodyText confidence="0.999943735294118">
The challenge in acquiring paraphrases is to ensure
good coverage of the targeted classes of paraphrases
along with a low proportion of incorrect pairs. How-
ever, no matter what type of resource has been used,
it has proven difficult to acquire paraphrase pairs
with both high recall and high precision.
Among various types of corpora, monolingual
corpora can be considered the best source for high-
coverage paraphrase acquisition, because there is
far more monolingual than bilingual text avail-
able. Most methods that exploit monolingual cor-
pora rely on the Distributional Hypothesis (Harris,
1968): expressions that appear in similar contexts
are expected to have similar meaning. However,
if one uses purely distributional criteria, it is dif-
ficult to distinguish real paraphrases from pairs of
expressions that are related in other ways, such as
antonyms and cousin words.
In contrast, since the work in (Bannard and
Callison-Burch, 2005), bilingual parallel corpora
have been acknowledged as a good source of high-
quality paraphrases: paraphrases are obtained by
putting together expressions that receive the same
translation in the other language (pivot language).
Because translation expresses a specific meaning
more directly than context in the aforementioned ap-
proach, pairs of expressions acquired in this manner
tend to be correct paraphrases. However, the cov-
erage problem remains: there is much less bilingual
parallel than monolingual text available.
Our objective in this paper is to obtain para-
phrases that have high quality (like those extracted
from bilingual parallel corpora via pivoting) but can
be generated in large quantity (like those extracted
</bodyText>
<page confidence="0.979441">
631
</page>
<note confidence="0.7805685">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 631–642, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999877352941176">
from monolingual corpora via contextual similar-
ity). To achieve this, we propose a method that ex-
ploits general patterns underlying paraphrases and
uses both bilingual parallel and monolingual sources
of information. Given a relatively high-quality set of
paraphrases obtained from a bilingual parallel cor-
pus, a set of paraphrase patterns is first induced.
Then, appropriate instances of such patterns, i.e.,
potential paraphrases, are harvested from a mono-
lingual corpus.
After reviewing existing methods in Section 2,
our method is presented in Section 3. Section 4
describes our experiments in acquiring paraphrases
and presents statistics summarizing the coverage of
our method. Section 5 describes a human evaluation
of the quality of the acquired paraphrases. Finally,
Section 6 concludes this paper.
</bodyText>
<sectionHeader confidence="0.861214" genericHeader="introduction">
2 Literature on Paraphrase Acquisition
</sectionHeader>
<bodyText confidence="0.999753">
This section summarizes existing corpus-based
methods for paraphrase acquisition, following the
classification in (Hashimoto et al., 2011): similarity-
based and alignment-based methods.
</bodyText>
<sectionHeader confidence="0.880974" genericHeader="method">
2.1 Similarity-based Methods
</sectionHeader>
<bodyText confidence="0.999958823529412">
Techniques that use monolingual (non-parallel) cor-
pora mostly rely on the Distributional Hypothesis
(Harris, 1968). Because a large quantity of mono-
lingual data is available for many languages, a large
number of paraphrase candidates can be acquired
(Lin and Pantel, 2001; Pas¸ca and Dienes, 2005; Bha-
gat and Ravichandran, 2008, etc.). The recipes pro-
posed so far are based on three main ingredients, i.e.,
features used for representing context of target ex-
pression (contextual features), criteria for weighting
and filtering features, and aggregation functions.
A drawback of relying only on contextual simi-
larity is that it tends to give high scores to semanti-
cally related but non-equivalent expressions, such as
antonyms and cousin words. To enhance the preci-
sion of the results, filtering mechanisms need to be
introduced (Marton et al., 2011).
</bodyText>
<sectionHeader confidence="0.547894" genericHeader="method">
2.2 Alignment-based Methods
</sectionHeader>
<bodyText confidence="0.99995725">
Pairs of expressions that get translated to the same
expression in a different language can be regarded as
paraphrases. On the basis of this hypothesis, Barzi-
lay and McKeown (2001) and Pang et al. (2003)
created monolingual parallel corpora from multiple
human translations of the same source. Then, they
extracted corresponding parts of such parallel sen-
tences as sub-sentential paraphrases.
Leveraging recent advances in statistical ma-
chine translation (SMT), Bannard and Callison-
Burch (2005) proposed a method for acquiring sub-
sentential paraphrases from bilingual parallel cor-
pora. As in SMT, a translation table is first built on
the basis of alignments between expressions, such as
words, phrases, and subtrees, across a parallel sen-
tence pair. Then, pairs of expressions (e1, e2) in the
same language that are aligned with the same ex-
pressions in the other language (pivot language) are
extracted as paraphrases. The likelihood of e2 being
a paraphrase of e1 is given by
</bodyText>
<equation confidence="0.998629">
∑p(e2|e1) _ p(e2|f)p(f|e1), (1)
fETr(e1re2)
</equation>
<bodyText confidence="0.999985642857143">
where R(e1, e2) stands for the set of shared trans-
lations of e1 and e2. Each factor p(e|f) and p(f|e)
is estimated from the number of times e and f are
aligned and the number of occurrences of each ex-
pression in each language. Kok and Brockett (2010)
showed how one can discover paraphrases that do
not share any translation in one language by travers-
ing a graph created from multiple translation tables,
each corresponding to a bilingual parallel corpus.
This approach, however, suffers from a cover-
age problem, because both monolingual parallel and
bilingual parallel corpora tend to be significantly
smaller than monolingual non-parallel corpora. The
acquired pairs of expressions include some non-
paraphrases as well. Many of these come from er-
roneous alignments, which are particularly frequent
when the given corpus is small.
Monolingual comparable corpora have also been
exploited as sources of paraphrases using alignment-
based methods. For instance, multiple news arti-
cles covering the same event (Shinyama et al., 2002;
Barzilay and Lee, 2003; Dolan et al., 2004; Wubben
et al., 2009) have been used. Such corpora have
also been created manually through crowdsourcing
(Chen and Dolan, 2011). However, the availabil-
ity of monolingual comparable corpora is very lim-
ited for most languages; thus, approaches relying
on these corpora have typically produced only very
</bodyText>
<page confidence="0.9973">
632
</page>
<bodyText confidence="0.9999028">
small collections of paraphrases. Hashimoto et al.
(2011) found a way around this limitation by collect-
ing sentences that constitute explicit definitions of
particular words or phrases from monolingual non-
parallel Web documents, pairing sentences that de-
fine the same noun phrase, and then finding corre-
sponding phrases in each sentence pair. One limita-
tion of this approach is that it requires a considerable
amount of labeled data for both the corpus construc-
tion and the paraphrase extraction steps.
</bodyText>
<subsectionHeader confidence="0.996896">
2.3 Summary
</subsectionHeader>
<bodyText confidence="0.9999604">
Existing methods have investigated one of the fol-
lowing four types of corpora as their principal re-
sourcel: monolingual non-parallel corpora, mono-
lingual parallel corpora, monolingual comparable
corpora, and bilingual parallel corpora. No matter
what type of resource has been used, however, it
has proven difficult to acquire paraphrases with both
high recall and precision, with the possible excep-
tion of the method in (Hashimoto et al., 2011) which
requires large amounts of labeled data.
</bodyText>
<sectionHeader confidence="0.992163" genericHeader="method">
3 Proposed Method
</sectionHeader>
<bodyText confidence="0.947017434782609">
While most existing methods deal with expressions
only at the surface level, ours exploits generalities
underlying paraphrases to achieve better coverage
while retaining high precision. Furthermore, unlike
existing methods, ours uses both bilingual parallel
and monolingual non-parallel corpora as sources for
acquiring paraphrases.
The process is illustrated in Figure 1. First, a
set of high-quality seed paraphrases, Pseed, is ac-
quired from bilingual parallel corpora by using an
alignment-based method. Then, our method collects
further paraphrases through the following two steps.
Generalization (Step 2): Paraphrase patterns are
learned from the seed paraphrases, Pseed.
Instantiation (Step 3): A novel set of paraphrase
pairs, PHvst, is finally harvested from mono-
lingual non-parallel corpora using the learned
patterns; each newly acquired paraphrase pair
is assessed by contextual similarity.
&apos;Chan et al. (2011) used monolingual corpora only for re-
ranking paraphrases obtained from bilingual parallel corpora.
To the best of our knowledge, bilingual comparable corpora
have never been used as sources for acquiring paraphrases.
</bodyText>
<figureCaption confidence="0.99965">
Figure 1: Process of paraphrase acquisition.
</figureCaption>
<bodyText confidence="0.992084666666667">
The set Pseed acquired early in the process can be
pooled with the set PHvst harvested in the last stage
of the process.
</bodyText>
<subsectionHeader confidence="0.998817">
3.1 Step 1. Seed Paraphrase Acquisition
</subsectionHeader>
<bodyText confidence="0.999859448275862">
The goal of the first step is to obtain a set of high-
quality paraphrase pairs, Pseed.
For this purpose, alignment-based methods with
bilingual or monolingual parallel corpora are prefer-
able to similarity-based methods applied to non-
parallel corpora. Among various options, in this pa-
per, we start from the standard technique proposed
by Bannard and Callison-Burch (2005) with bilin-
gual parallel corpora (see also Section 2.2). In par-
ticular, we assume the phrase-based SMT frame-
work (Koehn et al., 2003). Then, we purify the re-
sults with several filtering methods.
The phrase pair extraction process of phrase-
based SMT systems aims at high recall for increased
robustness of the translation process. As a result,
a naive application of the paraphrase acquisition
method produces pairs of expressions that are not
exact paraphrases. For instance, the algorithm ex-
plained in Koehn (2009, p.134) extracts both “dass”
and “, dass” as counterparts of “that” from the sen-
tence pair. To reduce that kind of noise, we apply
some filtering techniques to the candidate translation
pairs. First, statistically unreliable translation pairs
(Johnson et al., 2007) are filtered out. Then, we also
filter out phrases made up entirely of stop words (in-
cluding punctuation marks), both in the language of
interest and in the pivot language.
Let PR,,,, be the initial set of paraphrase pairs ex-
tracted from the sanitized translation table. We first
</bodyText>
<figure confidence="0.9970895">
Monolingual
Non-parallel
Corpus
Bilingual
Parallel
Corpus
PSeed: Seed
Paraphrases
PHvst: Novel
Paraphrases
Paraphrase
Patterns
Translation
Table
</figure>
<figureCaption confidence="0.706539">
Step 1. Seed Paraphrase Acquisition
Step 2. Paraphrase Pattern Induction
Step 3. Paraphrase Instance Acquisition
</figureCaption>
<bodyText confidence="0.9599548">
“health issue” a “probl6me de sant6”
“health problem” a “probl6me de sant6”
“look like” a “ressemble”
“regional issue” a “probl6me regional”
“regional problem” a “probl6me regional”
“resemble” a “ressemble”
“health issue” a “health problem”
“look like” a “resemble”
“regional issue” a “regional problem”
“X issue” a “X problem”;
{food, regional, ...I
“backlog issue” a “backlog problem”
“communal issue” a “communal problem”
“phishing issue” a “phishing problem”
“spatial issue” a “spatial problem”
</bodyText>
<page confidence="0.995196">
633
</page>
<figureCaption confidence="0.999391">
Figure 2: RHS-filtering for “control apparatus”.
</figureCaption>
<bodyText confidence="0.9723856">
discard pairs whose difference comprises only stop
words, such as “the schools” ⇒ “schools and”. We
also remove pairs containing only singular-plural
differences, such as “family unit” ⇒ “family units”.
Depending on the language of interest, other types of
morphological variants, such as those shown in (2),
may also be ignored.
(2) a. “europ´eenne” ⇒ “europ´een”
(Gender in French)
b. “guten L¨osungen” ⇒ “gute L¨osungen”
(Case in German)
We further filter out less reliable pairs, such as
those shown with dotted lines in Figures 2 and 3.
This is carried out by comparing the right-hand side
(RHS) phrases of each left-hand side (LHS) phrase,
and vice versa2. Given a set of paraphrase pairs,
RHS phrases corresponding to the same LHS phrase
lp are compared. A RHS phrase rp is not licensed iff
lp has another RHS phrase rp′ (̸= rp) which satis-
fies the following two conditions (see also Figure 2).
</bodyText>
<listItem confidence="0.959059666666667">
• rp′ is a word sub-sequence of rp
• rp′ is a more likely paraphrase than rp,
i.e., p(rp′|lp) &gt; p(rp|lp)
</listItem>
<bodyText confidence="0.999179">
LHS phrases for each RHS phrase rp are also com-
pared in a similar manner, i.e., a LHS phrase lp is
not qualified as a legitimate source of rp iff rp has
another LHS phrase lp′ (̸= lp) which satisfies the
following conditions (see also Figure 3).
</bodyText>
<listItem confidence="0.956998">
• lp′ is a word sub-sequence of lp
• lp′ is a more likely source than lp,
</listItem>
<bodyText confidence="0.804459">
i.e., p(lp′|rp) &gt; p(lp|rp)
The two directions of filtering are separately applied
and the intersection of their results is retained.
zcf. Denkowski and Lavie (2011); they only compared each
RHS phrase to its corresponding LHS phrase.
</bodyText>
<figureCaption confidence="0.996895">
Figure 3: LHS-filtering for “control device”.
</figureCaption>
<bodyText confidence="0.99995325">
Candidate pairs are finally filtered on the basis
of their reliability score. Traditionally, a threshold
(thp) on the conditional probability given by Eq. (1)
is used (Du et al., 2010; Max, 2010; Denkowski
and Lavie, 2011, etc.). Furthermore, we also re-
quire that LHS and RHS phrases exceed a thresh-
old (ths) on their contextual similarity in a mono-
lingual corpus. This paper neither proposes a spe-
cific recipe nor makes a comprehensive comparison
of existing recipes for computing contextual simi-
larity, although one particular recipe is used in our
experiments (see Section 4.1).
</bodyText>
<subsectionHeader confidence="0.999734">
3.2 Step 2. Paraphrase Pattern Induction
</subsectionHeader>
<bodyText confidence="0.999914333333333">
From a set of seed paraphrases, PSeed, paraphrase
patterns are induced. For instance, from paraphrases
in (3), we induce paraphrase patterns in (4).
</bodyText>
<listItem confidence="0.996725">
(3) a. “restraint system” ⇒ “restraint apparatus”
b. “movement against racism”
⇒ “anti-racism movement”
c. “middle eastern countries”
⇒ “countries in the middle east”
(4) a. “X system” ⇒ “X apparatus”
b. “X against Y ” ⇒ “anti-Y X”
c. “X eastern Y ” ⇒ “Y in the X east”
</listItem>
<bodyText confidence="0.997702666666667">
Word pairs of LHS and RHS phrases will be re-
placed with variable slots iff they are fully identi-
cal or singular-plural variants. Note that stop words
are retained. While a deeper level of lexical cor-
respondences, such as “eastern” and “east” in (3c)
and “system” and “apparatus” in (3a), could be cap-
tured, this would require the use of rich language
resources, thereby making the method less portable
to resource-poor languages.
</bodyText>
<figure confidence="0.975112472222222">
rp: control device
rp: control system
rp: the control device
p(rp|lp)
.172
.032
.015
rp: control device of the
rp: controlling device
.005
lp: control apparatus
.004
.003
rp: control system of
rp: a control system for an
rp: a controlling device
.001
.001
.004
rp: control device
lp: control apparatus of
lp: controlling unit
.002
lp: control equipment
.001
lp: the control apparatus
.008
.010
lp: controller
lp: control apparatus
p(lp|rp)
.153
.135
lp: controller for a
.001
lp: to the control apparatus
</figure>
<page confidence="0.992147">
634
</page>
<bodyText confidence="0.999670222222222">
Note that our aim is to automatically capture gen-
eral paraphrase patterns of the kind that have some-
times been manually described (Jacquemin, 1999;
Fujita et al., 2007). This is different from ap-
proaches that attach variable slots to paraphrases for
calculating their similarity (Lin and Pantel, 2001;
Szpektor and Dagan, 2008) or for constraining
the context in which they are regarded legitimate
(Callison-Burch, 2008; Zhao et al., 2009).
</bodyText>
<subsectionHeader confidence="0.999597">
3.3 Step 3. Paraphrase Instance Acquisition
</subsectionHeader>
<bodyText confidence="0.999982074074074">
Given a set of paraphrase patterns, such as those
shown in (4), a set of novel instances, i.e., novel
paraphrases, PH,st, will now be harvested from
monolingual non-parallel corpora. In other words,
a set of appropriate slot-fillers will be extracted.
First, expressions that match both elements of
the pattern, except stop words, are collected from
a given monolingual corpus. Pattern matching alone
may generate inappropriate pairs, so we then assess
the legitimacy of each collected slot-filler.
Let LHS(w) and RHS(w) be the expressions
generated by instantiating the k variable slots in
LHS and RHS phrases of the pattern with a k-tuple
of slot-fillers w (= wi, ... , wk), respectively. We
estimate how likely RHS(w) is to be a paraphrase of
LHS(w) based on the contextual similarity between
them using a monolingual corpus; a pair of phrases
is discarded if they are used in substantially dissim-
ilar contexts. We use the same recipe and threshold
value for ths with Step 1 in our experiments.
Contextual similarity of antonyms and cousin
words can also be high, as they are often used in sim-
ilar contexts. However, this is not a problem in our
framework, because semantic equivalence between
LHS(w) and RHS(w) is almost entirely guaran-
teed as a result of the way the corresponding patterns
were learned from a bilingual parallel corpus.
</bodyText>
<subsectionHeader confidence="0.948582">
3.4 Characteristics
</subsectionHeader>
<bodyText confidence="0.999977916666667">
In terms of coverage, PH,st is expected to be greatly
larger than PSeed, although it will not cover to-
tally different pairs of paraphrases, such as those
shown in (1). On the other hand, the quality of
PH,st depends on that of PSeed. Unlike in the pure
similarity-based method, PH,st is constrained by the
paraphrase patterns derived from the set of high-
quality paraphrases, PSeed, and will therefore gen-
erally exclude the kind of semantically similar but
non-equivalent pairs that contextual similarity alone
tends to extract alongside real paraphrases.
As mentioned in Section 3.1, other types of meth-
ods can be used for obtaining high-quality seed
paraphrases, PSeed. For instance, the supervised
method proposed by Hashimoto et al. (2011) uses
the existence of shared words as a feature to deter-
mine whether the given pair of expressions are para-
phrases, and thereby extracts many pairs sharing the
same words. Thus, their output has a high potential
to be used as an alternative seed for our method.
Another advantage of our method is that it does
not require any labeled data, unlike the super-
vised methods proposed by Zhao et al. (2009) and
Hashimoto et al. (2011).
</bodyText>
<sectionHeader confidence="0.998611" genericHeader="method">
4 Quantitative Impact
</sectionHeader>
<subsectionHeader confidence="0.930209">
4.1 Experimental Settings
</subsectionHeader>
<bodyText confidence="0.99982704">
Two different sets of corpora were used as data
sources; in both settings, we acquired English para-
phrases.
Europarl: The English-French version of the Eu-
roparl Parallel Corpus3 consisting of 1.8M sen-
tence pairs (51M words in English and 56M
words in French) was used as a bilingual par-
allel corpus, while its English side and the En-
glish side of the 109 French-English corpus4
consisting of 23.8M sentences (649M words)
were used as monolingual data.
Patent: The Japanese-English Patent Translation
data (Fujii et al., 2010) consisting of 3.2M sen-
tence pairs (122M morphemes in Japanese and
106M words in English) was used as a bilingual
parallel corpus, while its English side and the
30.0M sentences (626M words) from the 2007
chapter of NTCIR unaligned patent documents
were used as monolingual data.
To study the behavior of our method for different
amounts of bilingual parallel data, we carried out
learning curve experiments.
We used our in-house tokenizer for segmentation
of English and French sentences and MeCab5 for
Japanese sentences.
</bodyText>
<footnote confidence="0.999922333333333">
3http://statmt.org/europarl/, release 6
4http://statmt.org/wmt10/training-giga-fren.tar
5http://mecab.sourceforge.net/, version 0.98
</footnote>
<page confidence="0.990779">
635
</page>
<figure confidence="0.928437769230769">
PRaw
PRaw (th =0.01)
PSeed (Rp =ε, ths=ε)
PSeed (thp=0.01, ths=ε)
106 107 108
# of words in the English side of bilingual corpus
108
# of paraphrase pairs
107
106
105
104
103
108
# of paraphrase pairs
107
106
105
104
103
PRaw
PRaw (th =0.01)
PSeed (R. =ε, th =ε)
PSeed (thp=0.01, ths=ε)
106 107 108
# of words in the English side of bilingual corpus
</figure>
<figureCaption confidence="0.999963">
Figure 4: # of paraphrase pairs in PSeed (left: Europarl, right: Patent).
</figureCaption>
<bodyText confidence="0.999952434782609">
Stop word lists for sanitizing translation pairs and
paraphrase pairs were manually compiled: we enu-
merated 442 English words, 193 French words, and
149 Japanese morphemes, respectively.
From a bilingual parallel corpus, a translation ta-
ble was created by our in-house phrase-based SMT
system, PORTAGE (Sadat et al., 2005). Phrase
alignments of each sentence pair were identified by
the heuristic “grow-diag-final”6 with a maximum
phrase length 8. The resulting translation pairs were
then filtered with the significance pruning technique
of (Johnson et al., 2007), using α + c as threshold.
As contextual features for computing similarity
of each paraphrase pair, all of the 1- to 4-grams of
words adjacent to each occurrence of a phrase were
counted. This is a compromise between less expen-
sive but noisier approaches, such as bag-of-words,
and more accurate but more expensive approaches
that incorporate syntactic features (Lin and Pantel,
2001; Shinyama et al., 2002; Pang et al., 2003;
Szpektor and Dagan, 2008). Contextual similarity is
finally measured by taking cosine between two fea-
ture vectors.
</bodyText>
<subsectionHeader confidence="0.997316">
4.2 Statistics on Acquired Paraphrases
</subsectionHeader>
<bodyText confidence="0.9964887">
Seed Paraphrases (PSeed)
Figure 4 shows the number of paraphrase pairs
PSeed obtained from the bilingual parallel corpora.
The general trend is simply that the larger the cor-
pus is, the more paraphrases are acquired.
Given the initial set of paraphrases, PR,, (“X”),
our filtering techniques (“❑”) discarded a large por-
tion (63-75% in Europarl and 43-64% in Patent) of
them. Pairs with zero similarity were also filtered
out, i.e., the = c. This suggests that many incorrect
</bodyText>
<footnote confidence="0.788902">
6http://statmt.org/moses/?n=FactoredTraining.AlignWords
</footnote>
<bodyText confidence="0.999695294117647">
and/or relatively useless pairs, such as those shown
in Figures 2 and 3, had originally been acquired.
Lines with “◦” show the results based on a
widely-used threshold value on the conditional prob-
ability in Eq. (1), i.e., the = 0.01 (Du et al., 2010;
Max, 2010; Denkowski and Lavie, 2011, etc.). The
percentage of paraphrase pairs thereby discarded
varied greatly depending on the corpus size (17-78%
in Europarl and 31-82% in Patent), suggesting that
the threshold value should be determined depending
on the given corpus. In the following experiment,
however, we conform to the convention the = 0.01
(“△”) to ensure the quality of PSeed that we will be
using for inducing paraphrase patterns, even though
this results in discarding some less frequent but cor-
rect paraphrase pairs, such as “control apparatus”
=&gt;. “controlling device” in Figure 2.
</bodyText>
<subsectionHeader confidence="0.899742">
Paraphrase Patterns
</subsectionHeader>
<bodyText confidence="0.999982222222222">
Figures 5 and 6 show the number of paraphrase
patterns that our method induced and their cover-
age against PSeed, respectively. Due to their rather
rigid form, the patterns covered no more than 15%
of PSeed in Europarl. In contrast, a higher propor-
tion of PSeed in Patent was generalized into patterns.
We speculate it is because the patent domain con-
tains many expressions, including technical terms,
that have similar variations of constructions.
The acquired patterns were mostly one-variable
patterns: 88-93% and 80-91% of total patterns for
different variants of the Europarl and Patent set-
tings, respectively. Given that there are far more
one-variable patterns than other types, and that one-
variable patterns are the simplest type, we hence-
forth focus on them. More complex patterns, includ-
ing two-variable patterns (7-11% and 8-17% in each
setting), will be investigated in our future work.
</bodyText>
<page confidence="0.993627">
636
</page>
<figure confidence="0.992097566666667">
106
# of paraphrase patterns
105
104
103
Coverage [%] 40
30
20
10
0
All (Patent)
1-var (Patent)
All (Europarl)
1-var (Europarl)
All (Patent)
1-var (Patent)
All (Europarl)
1-var (Europarl)
102 106 107 108
# of words in the English side of bilingual corpus
106 107 108
# of words in the English side of bilingual corpus
108
107
106
105
104
# of paraphrase pairs
# of unique LHS phrases
103
</figure>
<figureCaption confidence="0.924042">
Figure 5: # of paraphrase patterns.
</figureCaption>
<figure confidence="0.97626625">
106 107 108
# of words in the English side of bilingual corpus
Pair in PHvst
LHS in PHvst
Pair in PSeed
LHS in PSeed
18.1M
1.22M
</figure>
<figureCaption confidence="0.98738">
Figure 6: Coverage of the paraphrase patterns.
</figureCaption>
<figure confidence="0.993383625">
# of paraphrase pairs
# of unique LHS phrases
108
107
106
105
104
103
106 107 108
# of words in the English side of bilingual corpus
Pair in PHvst
LHS in PHvst
Pair in PSeed
LHS in PSeed
28.7M
1.41M
</figure>
<figureCaption confidence="0.99999">
Figure 7: # of paraphrase pairs and unique LHS phrases in PSeed and PH,,,,t (left: Europarl, right: Patent).
</figureCaption>
<bodyText confidence="0.999344520833333">
Novel Paraphrases (PHvst)
Using the paraphrase patterns, novel paraphrase
pairs, PHvst, were harvested from the monolingual
non-parallel corpora. In this experiment, we only
retained one-variable patterns and regarded only sin-
gle words as slot-fillers for them. Nevertheless, we
managed to acquire a large number of paraphrase
pairs as depicted in Figure 7, where pairs having
zero similarity were excluded. For instance, when
the full size of bilingual parallel corpus in Patent was
used, we acquired 1.41M pairs of seed paraphrases,
PSeed, and 28.7M pairs of novel paraphrases, PHvst.
In other words, our method expanded PSeed by about
21 times. The number of unique LHS phrases that
PHvst covers was also significantly larger than that
of PSeed.
Figure 8 highlights the remarkably large ratio of
PHvst to PSeed in terms of the number of paraphrase
pairs and the number of unique LHS phrases. The
smaller the bilingual corpus is, the higher the ratio
is, except when there is only a very small amount of
Europarl data. This demonstrates that our method is
quite powerful, given a minimum amount of data.
Another striking difference between PSeed and
PHvst is the average number of RHS phrases per
unique LHS phrase, i.e., their relative yield. As
displayed in Figure 9, the yield for PHvst increased
rapidly with the scaling up of the bilingual cor-
pus, while that of PSeed only grew slowly. The
alignment-based method with bilingual corpora can-
not produce very many RHS phrases per unique
LHS phrase due to its reliance on conditional prob-
ability and the surface level processing. In con-
trast, our method does not limit the number of RHS
phrases: each RHS phrase is separately assessed by
its similarity to the corresponding LHS phrase. One
limitation of our method is that it cannot achieve
high yield for PHvst whenever only a small num-
ber of paraphrase patterns can be extracted from the
bilingual corpus (see also Figure 5).
Both the ratio of PHvst to PSeed and the relative
yield could probably be increased by scaling up the
monolingual corpus. For instance, in the patent do-
main, monolingual documents 10 times larger than
the one used in the above experiments are avail-
able at the NTCIR project7. It would be interesting
to compare the relative gains brought by in-domain
versus general-purpose corpora.
</bodyText>
<footnote confidence="0.962088">
7http://ntcir.nii.ac.jp/PatentMT-2/
</footnote>
<page confidence="0.985423">
637
</page>
<figure confidence="0.997551333333334">
5
4
3
2
Avg. # of RHS phrases
80
Ratio of PHvst to PSeed
60
40
20
0
LHS (Patent)
Pair (Patent)
LHS (Europarl)
Pair (Europarl)
1
PHvst (Patent)
PSeed (Patent)
PHvst (Europarl)
PSeed (Europarl)
106 107 108
# of words in the English side of bilingual corpus
106 107 108
# of words in the English side of bilingual corpus
</figure>
<figureCaption confidence="0.997703">
Figure 8: Ratio of PH,,,gt to PSeed-
</figureCaption>
<figure confidence="0.890285">
.
</figure>
<figureCaption confidence="0.934034">
Figure 9: Average # of RHS phrases per LHS phrase.
</figureCaption>
<figure confidence="0.995316041666667">
# of paraphrase pairs
108
107
106
105
104
103
PHvst (Patent)
PSeed (Patent)
PHvst (Europarl)
PSeed (Europarl)
# of paraphrase pairs
108
107
106
105
104
103
PHvst (Patent)
PSeed (Patent)
PHvst (Europarl)
PSeed (Europarl)
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Probability threshold thp Similarity threshold ths
</figure>
<figureCaption confidence="0.998023">
Figure 10: # of acquired paraphrase pairs against threshold values.
</figureCaption>
<bodyText confidence="0.99022492">
(left: probability-based (0.01 &lt; the &lt; 0.9, th,g = e), right: similarity-based (e &lt; th,g &lt; 0.9, the = 0.01))
Finally, we investigated how the number of para-
phrase pairs varies depending on the values for the
two thresholds, i.e., thp on the conditional probabil-
ity and ths on the contextual similarity, respectively.
Figure 10 shows the results when the full sizes of
bilingual corpora are used. When the pairs were fil-
tered only with thp, the number of paraphrase pairs
in PHvst decreased more slowly than that of PSeed
according to the increase of the threshold value. This
is a benefit from our generalization and instantiation
method. The same paraphrase pattern is often in-
duced from more than one paraphrase pair in PSeed.
Thus, as long as at least one of them has a proba-
bility higher than the given threshold value, corre-
sponding novel paraphrases can be harvested.
On the other hand, as a results of assessing each
individual paraphrase pair by the contextual similar-
ity, many pairs in PHvst, which are supposed to be
incorrect instances of their corresponding pattern,
are filtered out by a larger threshold value for ths.
In contrast, many pairs in PSeed have a relatively
high similarity, e.g., 40% of all pairs have similarity
higher than 0.4. This indicates the quality of PSeed
is highly guaranteed by the shared translations.
</bodyText>
<sectionHeader confidence="0.945877" genericHeader="method">
5 Human Evaluation of Quality
</sectionHeader>
<bodyText confidence="0.999937">
To confirm that the quality of PHvst is sufficiently
high, we carried out a substitution test.
First, by substituting sub-sentential paraphrases
to existing sentences in a given test corpus, pairs
of slightly different sentences were automatically
generated. For instance, by applying “looks like”
==&gt;. “resembles” to (5), (6) was generated.
</bodyText>
<listItem confidence="0.916674">
(5) The roof looks like a prehistoric lizard’s spine.
(6) The roof resembles a prehistoric lizard’s spine.
</listItem>
<bodyText confidence="0.999867153846154">
Human evaluators were then asked to score each
pair of an original sentence and a paraphrased sen-
tence with the following two 5-point scale grades
proposed by Callison-Burch (2008):
Grammaticality: whether the paraphrased sen-
tence is grammatical (1: horrible, 5: perfect)
Meaning: whether the meaning of the original sen-
tence is properly retained by the paraphrased
sentence (1: totally different, 5: equivalent)
To make results more consistent and reduce the
human labor, evaluators were asked to rate at the
same time several paraphrases for the same source
phrase. For instance, given a source sentence (5), the
</bodyText>
<page confidence="0.997055">
638
</page>
<bodyText confidence="0.9460405">
evaluators might be given the following sentences in
addition to a paraphrased sentence (6).
</bodyText>
<listItem confidence="0.8664545">
(7) The roof seems like a prehistoric lizard’s spine.
(8) The roof would look like a prehistoric lizard’s spine.
</listItem>
<bodyText confidence="0.9999305">
In this experiment, we showed five paraphrases
per source phrase, assuming that evaluators would
get confused if too large a number of paraphrase
candidates were presented at the same time.
</bodyText>
<subsectionHeader confidence="0.945324">
5.1 Data for Evaluation
</subsectionHeader>
<bodyText confidence="0.999965684210527">
As in previous work (Callison-Burch, 2008; Chan
et al., 2011), we evaluated paraphrases acquired
from the Europarl corpus on news sentences. Para-
phrase examples were automatically generated from
the English part of WMT 2008-2011 “newstest” data
(10,050 unique sentences) by applying the union of
PSeed and PHvst of the Europarl setting (19.3M para-
phrases for 5.95M phrases).
On the other hand, paraphrases acquired from
patent documents are much more difficult to eval-
uate due to the following reasons. First, they may
be too domain-specific to be of any use in general
areas such as news sentences. However, conduct-
ing an in-domain evaluation would be difficult with-
out enrolling domain experts. We expect that para-
phrases from a domain can be used safely in that
domain. Nevertheless, deciding under what circum-
stances they can be used safely in another domain is
an interesting research question.
To reduce the human labor for the evaluation, sen-
tences were restricted to those with moderate length:
10-30 words, which are expected to provide suf-
ficient but succinct context. To propose multiple
paraphrase candidates at the same time, we also re-
stricted phrases to be paraphrased (LHS phrases) to
those having at least five paraphrases including ones
from PHvst. This resulted in 60,421 paraphrases for
988 phrase tokens (353 unique phrases).
Finally, we randomly sampled 80 unique phrase
tokens and five unique paraphrases for each phrase
token (400 examples in total), and asked six people
having a high level of English proficiency to evalu-
ate them. Inter-evaluator agreement was calculated
from five different pairs of evaluators, each judging
the same 10 examples. The remaining 350 exam-
ples were divided into six chunks of slightly unequal
length, with each chunk being judged by one of the
six evaluators.
</bodyText>
<table confidence="0.9990306">
n 5-point G Binary
G M M Both
PSeed 55 4.60 4.35 0.85 0.93 0.78
Px„st 295 4.22 3.35 0.74 0.67 0.55
Total 350 4.28 3.50 0.76 0.71 0.58
</table>
<tableCaption confidence="0.999863">
Table 1: Avg. score and precision of binary classification.
</tableCaption>
<subsectionHeader confidence="0.900281">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.98812115">
Table 1 shows the average of the original 5-point
scale scores and the percentage of examples that
are judged correct based on a binary judgment
(Callison-Burch, 2008): an example is considered to
be correct iff the grammaticality score is 4 or above
and/or the meaning score is 3 or above. Paraphrases
based on PSeed achieved a quite high performance
in both grammaticality (“G”) and meaning (“M”) in
part because of the effectiveness of our filtering tech-
niques. The performance of paraphrases drawn from
PHvst was reasonably high and similar to the scores
0.68 for grammaticality, 0.61 for meaning, and 0.55
for both, of the best model reported in (Callison-
Burch, 2008), although it was inferior to PSeed.
Despite the fact that all of our evaluators had a
high-level command of English, the agreement was
not very high. This was true even when the col-
lected scores were mapped into binary classes. In
this case, the r. values (Cohen, 1960) for each crite-
rion were 0.45 and 0.45, respectively, which indicate
the agreement was “fair”. To obtain a better r. value,
the criteria for grading will need to be improved.
However, we think that was not too low either$.
The most promising way for improving the qual-
ity of PHvst is to ensure that paraphrase patterns
cover only legitimate paraphrases. We investigated
this by filtering the manually scored paraphrase ex-
amples with two thresholds for cleaning seed para-
phrases PSeed: thp on the conditional probability es-
timated using the bilingual parallel corpus and ths
on the contextual similarity in the monolingual non-
parallel corpus. Figure 11 shows the average score
of the examples whose corresponding paraphrase is
obtainable with the given threshold values. Note that
the points in the figure with higher threshold values
are less reliable than the others, because filtering re-
duces the number of the manually scored examples
NNote that Callison-Burch (2008) might possibly underesti-
mate the chance agreement and overestimate the r, values, be-
cause the distribution of human scores would not be uniform.
</bodyText>
<page confidence="0.98798">
639
</page>
<figure confidence="0.999181782608696">
Avg. score
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Probability threshold thp
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
Similarity threshold ths
Grammaticality (PSeed)
Grammaticality (PHvst)
Meaning (PSeed)
Meaning (PHvst)
4.5
3.5
4
5
3
Grammaticality (PSeed)
Grammaticality (PHvst)
Meaning (PSeed)
Meaning (PHvst)
Avg. score 5
4.5
4
3.5
3
</figure>
<figureCaption confidence="0.7277175">
Figure 11: Average score of paraphrase examples against threshold values.
(left: probability-based (0.01 &lt; the &lt; 0.9, th,g = c), right: similarity-based (c &lt; th,g &lt; 0.9, the = 0.01))
The points with higher threshold values are less reliable than the others,
because filtering reduces the number of the manually scored examples used to calculate scores.
</figureCaption>
<bodyText confidence="0.996970142857143">
used to calculate scores. Nevertheless, it indicates
that better filtering of PSeed with higher threshold
values is likely to produce a better-quality set of
paraphrases PHvst. For instance, an inappropriate
paraphrase pattern (9a) was excluded with the = 0.1
or ths = 0.1, while correct ones (9b) and (9c) re-
mained even when a large threshold value is used.
</bodyText>
<listItem confidence="0.878692666666667">
(9) a. “X years” =&gt;. “turn X”
b. “X supplied” =&gt;. “X provided”
c. “main X” =&gt;. “most significant X”
</listItem>
<bodyText confidence="0.999462428571429">
Kendall’s correlation coefficient &apos;rB (Kendall,
1938) between the contextual similarity and each of
the human scores were 0.24 for grammaticality and
0.21 for meaning, respectively. Although they are ri-
valing the best results reported in (Chan et al., 2011),
i.e., 0.24 and 0.21, similarity metrics should be fur-
ther investigated to realize a more accurate filtering.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999814871794872">
In this paper, we exploited general patterns under-
lying paraphrases to acquire automatically a large
number of high-quality paraphrase pairs using both
bilingual parallel and monolingual non-parallel cor-
pora. Experiments using two sets of corpora demon-
strated that our method is able to leverage informa-
tion in a relatively small bilingual parallel corpus
to exploit large amounts of information in a rela-
tively large monolingual non-parallel corpus. Hu-
man evaluation through a paraphrase substitution
test revealed that the acquired paraphrases are gen-
erally of reasonable quality. Our original objective
was to extract from monolingual corpora a large
quantity of paraphrases whose quality is as high as
that of paraphrases from bilingual parallel corpora.
We have met the quantity part of the objective, and
have come close to meeting the quality part.
There are three main directions for our future
work. First, we intend to carry out in-depth anal-
yses of the proposed method. For instance, while
we showed that the performance of phrase substi-
tution could be improved by removing noisy seed
paraphrases, this also strongly affected the quan-
tity. We will therefore investigate similarity metrics
in our future work. Other interesting questions re-
lated to the work presented here are, as mentioned in
Section 4.2, exploitation of patterns with more than
one variable, learning curve experiments with dif-
ferent amounts of monolingual data, and compari-
son of in-domain and general-purpose monolingual
corpora. Second, we have an interest in exploiting
sophisticated paraphrase patterns; for instance, by
inducing patterns hierarchically (recursively) and in-
corporating lexical resources such as those exempli-
fied in (4). Finally, the developed paraphrase col-
lection will be attested through applications, such
as sentence compression (Cohn and Lapata, 2008;
Ganitkevitch et al., 2011) and machine translation
(Callison-Burch et al., 2006; Marton et al., 2009).
</bodyText>
<sectionHeader confidence="0.998299" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.994253166666667">
We are deeply grateful to our colleagues at National
Research Council Canada, especially George Foster,
Eric Joanis, and Samuel Larkin, for their technical
support. The first author is currently a JSPS (the
Japan Society for the Promotion of Science) Post-
doctoral Fellow for Research Abroad.
</bodyText>
<page confidence="0.996824">
640
</page>
<sectionHeader confidence="0.990234" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998823788461539">
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL), pages 597–604.
Regina Barzilay and Kathleen R. McKeown. 2001. Ex-
tracting paraphrases from a parallel corpus. In Pro-
ceedings of the 39th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 50–57.
Regina Barzilay and Lillian Lee. 2003. Learning to
paraphrase: An unsupervised approach using multiple-
sequence alignment. In Proceedings of the 2003 Hu-
man Language Technology Conference and the North
American Chapter of the Association for Computa-
tional Linguistics (HLT-NAACL), pages 16–23.
Rahul Bhagat and Deepak Ravichandran. 2008. Large
scale acquisition of paraphrases for learning surface
patterns. In Proceedings of the 46th Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 161–170.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine translation
using paraphrases. In Proceedings of the Human Lan-
guage Technology Conference of the North American
Chapter of the Association for Computational Linguis-
tics (HLT-NAACL), pages 17–24.
Chris Callison-Burch. 2008. Syntactic constraints on
paraphrases extracted from parallel corpora. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing (EMNLP), pages
196–205.
Tsz Ping Chan, Chris Callison-Burch, and Benjamin Van-
Durme. 2011. Reranking bilingually extracted para-
phrases using monolingual distributional similarity. In
Proceedings of the Workshop on Geometrical Models
of Natual Language Semantics (GEMS), pages 33–42.
David L. Chen and William B. Dolan. 2011. Collecting
highly parallel data for paraphrase evaluation. In Pro-
ceedings of the 49th Annual Meeting of the Association
for Computational Linguistics (ACL), pages 190–200.
Jacob Cohen. 1960. A coefficient of agreement for nom-
inal scales. Educational and Psychological Measure-
ment, 20(1):37–46.
Trevor Cohn and Mirella Lapata. 2008. Sentence com-
pression beyond word deletion. In Proceedings of the
22nd International Conference on Computational Lin-
guistics (COLING), pages 137–144.
Michael Denkowski and Alon Lavie. 2011. Meteor 1.3:
Automatic metric for reliable optimization and evalua-
tion of machine translation systems. In Proceedings of
the 6th Workshop on Statistical Machine Translation
(WMT), pages 85–91.
Bill Dolan, Chris Quirk, and Chris Brockett. 2004.
Unsupervised construction of large paraphrase cor-
pora: Exploiting massively parallel news sources.
In Proceedings of the 20th International Conference
on Computational Linguistics (COLING), pages 350–
356.
Jinhua Du, Jie Jiang, and Andy Way. 2010. Facilitating
translation using source language paraphrase lattices.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing (EMNLP),
pages 420–429.
Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, Take-
hito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, and
Sayori Shimohata. 2010. Overview of the patent
translation task at the NTCIR-8 workshop. In Pro-
ceedings of NTCIR-8 Workshop Meeting, pages 371–
376.
Atsushi Fujita, Shuhei Kato, Naoki Kato, and Satoshi
Sato. 2007. A compositional approach toward dy-
namic phrasal thesaurus. In Proceedings of the ACL-
PASCAL Workshop on Textual Entailment and Para-
phrasing (WTEP), pages 151–158.
Juri Ganitkevitch, Chris Callison-Burch, Courtney
Napoles, and Benjamin Van Durme. 2011. Learn-
ing sentential paraphrases from bilingual parallel cor-
pora for text-to-text generation. In Proceedings of
the 2011 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 1168–1179.
Zellig Harris. 1968. Mathematical Structures of Lan-
guage. John Wiley &amp; Sons.
Chikara Hashimoto, Kentaro Torisawa, Stijn De Saeger,
Jun’ichi Kazama, and Sadao Kurohashi. 2011. Ex-
tracting paraphrases from definition sentences on the
Web. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics (ACL),
pages 1087–1097.
Christian Jacquemin. 1999. Syntagmatic and paradig-
matic representations of term variation. In Proceed-
ings of the 37th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 341–348.
Howard Johnson, Joel Martin, George Foster, and Roland
Kuhn. 2007. Improving translation quality by dis-
carding most of the phrasetable. In Proceedings of
the 2007 Conference on Empirical Methods in Nat-
ural Language Processing and Computational Natu-
ral Language Learning (EMNLP-CoNLL), pages 967–
975.
Maurice Kendall. 1938. A new measure of rank correla-
tion. Biometrika, 30(1-2):81–93.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proceed-
ings of the 2003 Human Language Technology Con-
ference and the North American Chapter of the Asso-
</reference>
<page confidence="0.979561">
641
</page>
<reference confidence="0.999711820895522">
ciation for Computational Linguistics (HLT-NAACL),
pages 48–54.
Philipp Koehn. 2009. Statistical Machine Translation.
Cambridge University Press.
Stanley Kok and Chris Brockett. 2010. Hitting the right
paraphrases in good time. In Proceedings of Human
Language Technologies: The 2010 Annual Conference
of the North American Chapter of the Association for
Computational Linguistics (NAACL-HLT), pages 145–
153.
Dekang Lin and Patrick Pantel. 2001. Discovery of infer-
ence rules for question answering. Natural Language
Engineering, 7(4):343–360.
Nitin Madnani and Bonnie J. Dorr. 2010. Gener-
ating phrasal and sentential paraphrases: A survey
of data-driven methods. Computational Linguistics,
36(3):341–387.
Yuval Marton, Chris Callison-Burch, and Philip Resnik.
2009. Improved statistical machine translation using
monolingually-derived paraphrases. In Proceedings of
the 2009 Conference on Empirical Methods in Natural
Language Processing (EMNLP), pages 381–390.
Yuval Marton, Ahmed El Kholy, and Nizar Habash.
2011. Filtering antonymous, trend-contrasting, and
polarity-dissimilar distributional paraphrases for im-
proving statistical machine translation. In Proceedings
of the 6th Workshop on Statistical Machine Translation
(WMT), pages 237–249.
Aur´elien Max. 2010. Example-based paraphrasing for
improved phrase-based statistical machine translation.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing (EMNLP),
pages 656–666.
Marius Pas¸ca and P´eter Dienes. 2005. Aligning needles
in a haystack: Paraphrase acquisition across the Web.
In Proceedings of the 2nd International Joint Con-
ference on Natural Language Processing (IJCNLP),
pages 119–130.
Bo Pang, Kevin Knight, and Daniel Marcu. 2003.
Syntax-based alignment of multiple translations: Ex-
tracting paraphrases and generating new sentences. In
Proceedings of the 2003 Human Language Technol-
ogy Conference and the North American Chapter of
the Association for Computational Linguistics (HLT-
NAACL), pages 102–109.
Fatiha Sadat, Howard Johnson, Akakpo Agbago, George
Foster, Roland Kuhn, Joel Martin, and Aaron Tikuisis.
2005. PORTAGE: A phrase-based machine transla-
tion system. In Proceedings of the ACL Workshop on
Building and Using Parallel Texts, pages 129–132.
Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo, and
Ralph Grishman. 2002. Automatic paraphrase acqui-
sition from news articles. In Proceedings of the 2002
Human Language Technology Conference (HLT).
Idan Szpektor and Ido Dagan. 2008. Learning entail-
ment rules for unary templates. In Proceedings of the
22nd International Conference on Computational Lin-
guistics (COLING). 849-856.
Sander Wubben, Antal van den Bosch, Emiel Krahmer,
and Erwin Marsi. 2009. Clustering and matching
headlines for automatic paraphrase acquisition. In
Proceedings of the 12th European Workshop on Nat-
ural Language Generation, pages 122–125.
Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li.
2009. Extracting paraphrase patterns from bilin-
gual parallel corpora. Natural Language Engineering,
15(4):503–526.
</reference>
<page confidence="0.997989">
642
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.404544">
<title confidence="0.999467">Enlarging Paraphrase Collections through Generalization and Instantiation</title>
<author confidence="0.884234">Atsushi</author>
<affiliation confidence="0.999938">Future University</affiliation>
<address confidence="0.9933905">116-2 Hakodate, Hokkaido, 041-8655,</address>
<email confidence="0.994533">fujita@fun.ac.jp</email>
<author confidence="0.997066">Pierre Isabelle Roland Kuhn</author>
<affiliation confidence="0.991058">National Research Council</affiliation>
<address confidence="0.6779345">283 Alexandre-Tach´e Gatineau, QC, J8X 3X7,</address>
<abstract confidence="0.999644208333334">This paper presents a paraphrase acquisition method that uncovers and exploits generalities underlying paraphrases: paraphrase patterns are first induced and then used to collect novel instances. Unlike existing methods, ours uses both bilingual parallel and monolingual corpora. While the former are regarded as a source of high-quality seed paraphrases, the latter are searched for paraphrases that match patterns learned from the seed paraphrases. We show how one can use monolingual corpora, which are far more numerous and larger than bilingual corpora, to obtain paraphrases that rival in quality those derived directly from bilingual corpora. In our experiments, the number of paraphrase pairs obtained in this way from monolingual corpora was a large multiple of the number of seed paraphrases. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrase pairs are of reasonable quality. Remaining noise can be further reduced by filtering seed paraphrases.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>597--604</pages>
<contexts>
<context position="2960" citStr="Bannard and Callison-Burch, 2005" startWordPosition="427" endWordPosition="430">g various types of corpora, monolingual corpora can be considered the best source for highcoverage paraphrase acquisition, because there is far more monolingual than bilingual text available. Most methods that exploit monolingual corpora rely on the Distributional Hypothesis (Harris, 1968): expressions that appear in similar contexts are expected to have similar meaning. However, if one uses purely distributional criteria, it is difficult to distinguish real paraphrases from pairs of expressions that are related in other ways, such as antonyms and cousin words. In contrast, since the work in (Bannard and Callison-Burch, 2005), bilingual parallel corpora have been acknowledged as a good source of highquality paraphrases: paraphrases are obtained by putting together expressions that receive the same translation in the other language (pivot language). Because translation expresses a specific meaning more directly than context in the aforementioned approach, pairs of expressions acquired in this manner tend to be correct paraphrases. However, the coverage problem remains: there is much less bilingual parallel than monolingual text available. Our objective in this paper is to obtain paraphrases that have high quality (</context>
<context position="11008" citStr="Bannard and Callison-Burch (2005)" startWordPosition="1642" endWordPosition="1645">ve never been used as sources for acquiring paraphrases. Figure 1: Process of paraphrase acquisition. The set Pseed acquired early in the process can be pooled with the set PHvst harvested in the last stage of the process. 3.1 Step 1. Seed Paraphrase Acquisition The goal of the first step is to obtain a set of highquality paraphrase pairs, Pseed. For this purpose, alignment-based methods with bilingual or monolingual parallel corpora are preferable to similarity-based methods applied to nonparallel corpora. Among various options, in this paper, we start from the standard technique proposed by Bannard and Callison-Burch (2005) with bilingual parallel corpora (see also Section 2.2). In particular, we assume the phrase-based SMT framework (Koehn et al., 2003). Then, we purify the results with several filtering methods. The phrase pair extraction process of phrasebased SMT systems aims at high recall for increased robustness of the translation process. As a result, a naive application of the paraphrase acquisition method produces pairs of expressions that are not exact paraphrases. For instance, the algorithm explained in Koehn (2009, p.134) extracts both “dass” and “, dass” as counterparts of “that” from the sentence</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 597–604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>50--57</pages>
<contexts>
<context position="6051" citStr="Barzilay and McKeown (2001)" startWordPosition="880" endWordPosition="884">nting context of target expression (contextual features), criteria for weighting and filtering features, and aggregation functions. A drawback of relying only on contextual similarity is that it tends to give high scores to semantically related but non-equivalent expressions, such as antonyms and cousin words. To enhance the precision of the results, filtering mechanisms need to be introduced (Marton et al., 2011). 2.2 Alignment-based Methods Pairs of expressions that get translated to the same expression in a different language can be regarded as paraphrases. On the basis of this hypothesis, Barzilay and McKeown (2001) and Pang et al. (2003) created monolingual parallel corpora from multiple human translations of the same source. Then, they extracted corresponding parts of such parallel sentences as sub-sentential paraphrases. Leveraging recent advances in statistical machine translation (SMT), Bannard and CallisonBurch (2005) proposed a method for acquiring subsentential paraphrases from bilingual parallel corpora. As in SMT, a translation table is first built on the basis of alignments between expressions, such as words, phrases, and subtrees, across a parallel sentence pair. Then, pairs of expressions (e</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings of the 39th Annual Meeting of the Association for Computational Linguistics (ACL), pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Lillian Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiplesequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL),</booktitle>
<pages>16--23</pages>
<contexts>
<context position="7943" citStr="Barzilay and Lee, 2003" startWordPosition="1179" endWordPosition="1182"> bilingual parallel corpus. This approach, however, suffers from a coverage problem, because both monolingual parallel and bilingual parallel corpora tend to be significantly smaller than monolingual non-parallel corpora. The acquired pairs of expressions include some nonparaphrases as well. Many of these come from erroneous alignments, which are particularly frequent when the given corpus is small. Monolingual comparable corpora have also been exploited as sources of paraphrases using alignmentbased methods. For instance, multiple news articles covering the same event (Shinyama et al., 2002; Barzilay and Lee, 2003; Dolan et al., 2004; Wubben et al., 2009) have been used. Such corpora have also been created manually through crowdsourcing (Chen and Dolan, 2011). However, the availability of monolingual comparable corpora is very limited for most languages; thus, approaches relying on these corpora have typically produced only very 632 small collections of paraphrases. Hashimoto et al. (2011) found a way around this limitation by collecting sentences that constitute explicit definitions of particular words or phrases from monolingual nonparallel Web documents, pairing sentences that define the same noun p</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>Regina Barzilay and Lillian Lee. 2003. Learning to paraphrase: An unsupervised approach using multiplesequence alignment. In Proceedings of the 2003 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL), pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Deepak Ravichandran</author>
</authors>
<title>Large scale acquisition of paraphrases for learning surface patterns.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>161--170</pages>
<contexts>
<context position="5319" citStr="Bhagat and Ravichandran, 2008" startWordPosition="765" endWordPosition="769">hrases. Finally, Section 6 concludes this paper. 2 Literature on Paraphrase Acquisition This section summarizes existing corpus-based methods for paraphrase acquisition, following the classification in (Hashimoto et al., 2011): similaritybased and alignment-based methods. 2.1 Similarity-based Methods Techniques that use monolingual (non-parallel) corpora mostly rely on the Distributional Hypothesis (Harris, 1968). Because a large quantity of monolingual data is available for many languages, a large number of paraphrase candidates can be acquired (Lin and Pantel, 2001; Pas¸ca and Dienes, 2005; Bhagat and Ravichandran, 2008, etc.). The recipes proposed so far are based on three main ingredients, i.e., features used for representing context of target expression (contextual features), criteria for weighting and filtering features, and aggregation functions. A drawback of relying only on contextual similarity is that it tends to give high scores to semantically related but non-equivalent expressions, such as antonyms and cousin words. To enhance the precision of the results, filtering mechanisms need to be introduced (Marton et al., 2011). 2.2 Alignment-based Methods Pairs of expressions that get translated to the </context>
</contexts>
<marker>Bhagat, Ravichandran, 2008</marker>
<rawString>Rahul Bhagat and Deepak Ravichandran. 2008. Large scale acquisition of paraphrases for learning surface patterns. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL), pages 161–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL),</booktitle>
<pages>17--24</pages>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL), pages 17–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
</authors>
<title>Syntactic constraints on paraphrases extracted from parallel corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>196--205</pages>
<contexts>
<context position="16886" citStr="Callison-Burch, 2008" startWordPosition="2598" endWordPosition="2599"> controlling unit .002 lp: control equipment .001 lp: the control apparatus .008 .010 lp: controller lp: control apparatus p(lp|rp) .153 .135 lp: controller for a .001 lp: to the control apparatus 634 Note that our aim is to automatically capture general paraphrase patterns of the kind that have sometimes been manually described (Jacquemin, 1999; Fujita et al., 2007). This is different from approaches that attach variable slots to paraphrases for calculating their similarity (Lin and Pantel, 2001; Szpektor and Dagan, 2008) or for constraining the context in which they are regarded legitimate (Callison-Burch, 2008; Zhao et al., 2009). 3.3 Step 3. Paraphrase Instance Acquisition Given a set of paraphrase patterns, such as those shown in (4), a set of novel instances, i.e., novel paraphrases, PH,st, will now be harvested from monolingual non-parallel corpora. In other words, a set of appropriate slot-fillers will be extracted. First, expressions that match both elements of the pattern, except stop words, are collected from a given monolingual corpus. Pattern matching alone may generate inappropriate pairs, so we then assess the legitimacy of each collected slot-filler. Let LHS(w) and RHS(w) be the expres</context>
<context position="30682" citStr="Callison-Burch (2008)" startWordPosition="4870" endWordPosition="4871">rm that the quality of PHvst is sufficiently high, we carried out a substitution test. First, by substituting sub-sentential paraphrases to existing sentences in a given test corpus, pairs of slightly different sentences were automatically generated. For instance, by applying “looks like” ==&gt;. “resembles” to (5), (6) was generated. (5) The roof looks like a prehistoric lizard’s spine. (6) The roof resembles a prehistoric lizard’s spine. Human evaluators were then asked to score each pair of an original sentence and a paraphrased sentence with the following two 5-point scale grades proposed by Callison-Burch (2008): Grammaticality: whether the paraphrased sentence is grammatical (1: horrible, 5: perfect) Meaning: whether the meaning of the original sentence is properly retained by the paraphrased sentence (1: totally different, 5: equivalent) To make results more consistent and reduce the human labor, evaluators were asked to rate at the same time several paraphrases for the same source phrase. For instance, given a source sentence (5), the 638 evaluators might be given the following sentences in addition to a paraphrased sentence (6). (7) The roof seems like a prehistoric lizard’s spine. (8) The roof w</context>
<context position="33731" citStr="Callison-Burch, 2008" startWordPosition="5363" endWordPosition="5364">tor agreement was calculated from five different pairs of evaluators, each judging the same 10 examples. The remaining 350 examples were divided into six chunks of slightly unequal length, with each chunk being judged by one of the six evaluators. n 5-point G Binary G M M Both PSeed 55 4.60 4.35 0.85 0.93 0.78 Px„st 295 4.22 3.35 0.74 0.67 0.55 Total 350 4.28 3.50 0.76 0.71 0.58 Table 1: Avg. score and precision of binary classification. 5.2 Results Table 1 shows the average of the original 5-point scale scores and the percentage of examples that are judged correct based on a binary judgment (Callison-Burch, 2008): an example is considered to be correct iff the grammaticality score is 4 or above and/or the meaning score is 3 or above. Paraphrases based on PSeed achieved a quite high performance in both grammaticality (“G”) and meaning (“M”) in part because of the effectiveness of our filtering techniques. The performance of paraphrases drawn from PHvst was reasonably high and similar to the scores 0.68 for grammaticality, 0.61 for meaning, and 0.55 for both, of the best model reported in (CallisonBurch, 2008), although it was inferior to PSeed. Despite the fact that all of our evaluators had a high-lev</context>
<context position="35476" citStr="Callison-Burch (2008)" startWordPosition="5650" endWordPosition="5651">ses. We investigated this by filtering the manually scored paraphrase examples with two thresholds for cleaning seed paraphrases PSeed: thp on the conditional probability estimated using the bilingual parallel corpus and ths on the contextual similarity in the monolingual nonparallel corpus. Figure 11 shows the average score of the examples whose corresponding paraphrase is obtainable with the given threshold values. Note that the points in the figure with higher threshold values are less reliable than the others, because filtering reduces the number of the manually scored examples NNote that Callison-Burch (2008) might possibly underestimate the chance agreement and overestimate the r, values, because the distribution of human scores would not be uniform. 639 Avg. score 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Probability threshold thp 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 Similarity threshold ths Grammaticality (PSeed) Grammaticality (PHvst) Meaning (PSeed) Meaning (PHvst) 4.5 3.5 4 5 3 Grammaticality (PSeed) Grammaticality (PHvst) Meaning (PSeed) Meaning (PHvst) Avg. score 5 4.5 4 3.5 3 Figure 11: Average score of paraphrase examples against threshold values. (left: probability-based (0.01 &lt; the &lt; </context>
</contexts>
<marker>Callison-Burch, 2008</marker>
<rawString>Chris Callison-Burch. 2008. Syntactic constraints on paraphrases extracted from parallel corpora. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 196–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tsz Ping Chan</author>
<author>Chris Callison-Burch</author>
<author>Benjamin VanDurme</author>
</authors>
<title>Reranking bilingually extracted paraphrases using monolingual distributional similarity.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Geometrical Models of Natual Language Semantics (GEMS),</booktitle>
<pages>33--42</pages>
<contexts>
<context position="10215" citStr="Chan et al. (2011)" startWordPosition="1518" endWordPosition="1521">es for acquiring paraphrases. The process is illustrated in Figure 1. First, a set of high-quality seed paraphrases, Pseed, is acquired from bilingual parallel corpora by using an alignment-based method. Then, our method collects further paraphrases through the following two steps. Generalization (Step 2): Paraphrase patterns are learned from the seed paraphrases, Pseed. Instantiation (Step 3): A novel set of paraphrase pairs, PHvst, is finally harvested from monolingual non-parallel corpora using the learned patterns; each newly acquired paraphrase pair is assessed by contextual similarity. &apos;Chan et al. (2011) used monolingual corpora only for reranking paraphrases obtained from bilingual parallel corpora. To the best of our knowledge, bilingual comparable corpora have never been used as sources for acquiring paraphrases. Figure 1: Process of paraphrase acquisition. The set Pseed acquired early in the process can be pooled with the set PHvst harvested in the last stage of the process. 3.1 Step 1. Seed Paraphrase Acquisition The goal of the first step is to obtain a set of highquality paraphrase pairs, Pseed. For this purpose, alignment-based methods with bilingual or monolingual parallel corpora ar</context>
<context position="31602" citStr="Chan et al., 2011" startWordPosition="5013" endWordPosition="5016">s were asked to rate at the same time several paraphrases for the same source phrase. For instance, given a source sentence (5), the 638 evaluators might be given the following sentences in addition to a paraphrased sentence (6). (7) The roof seems like a prehistoric lizard’s spine. (8) The roof would look like a prehistoric lizard’s spine. In this experiment, we showed five paraphrases per source phrase, assuming that evaluators would get confused if too large a number of paraphrase candidates were presented at the same time. 5.1 Data for Evaluation As in previous work (Callison-Burch, 2008; Chan et al., 2011), we evaluated paraphrases acquired from the Europarl corpus on news sentences. Paraphrase examples were automatically generated from the English part of WMT 2008-2011 “newstest” data (10,050 unique sentences) by applying the union of PSeed and PHvst of the Europarl setting (19.3M paraphrases for 5.95M phrases). On the other hand, paraphrases acquired from patent documents are much more difficult to evaluate due to the following reasons. First, they may be too domain-specific to be of any use in general areas such as news sentences. However, conducting an in-domain evaluation would be difficul</context>
<context position="37032" citStr="Chan et al., 2011" startWordPosition="5904" endWordPosition="5907">reshold values is likely to produce a better-quality set of paraphrases PHvst. For instance, an inappropriate paraphrase pattern (9a) was excluded with the = 0.1 or ths = 0.1, while correct ones (9b) and (9c) remained even when a large threshold value is used. (9) a. “X years” =&gt;. “turn X” b. “X supplied” =&gt;. “X provided” c. “main X” =&gt;. “most significant X” Kendall’s correlation coefficient &apos;rB (Kendall, 1938) between the contextual similarity and each of the human scores were 0.24 for grammaticality and 0.21 for meaning, respectively. Although they are rivaling the best results reported in (Chan et al., 2011), i.e., 0.24 and 0.21, similarity metrics should be further investigated to realize a more accurate filtering. 6 Conclusion In this paper, we exploited general patterns underlying paraphrases to acquire automatically a large number of high-quality paraphrase pairs using both bilingual parallel and monolingual non-parallel corpora. Experiments using two sets of corpora demonstrated that our method is able to leverage information in a relatively small bilingual parallel corpus to exploit large amounts of information in a relatively large monolingual non-parallel corpus. Human evaluation through </context>
</contexts>
<marker>Chan, Callison-Burch, VanDurme, 2011</marker>
<rawString>Tsz Ping Chan, Chris Callison-Burch, and Benjamin VanDurme. 2011. Reranking bilingually extracted paraphrases using monolingual distributional similarity. In Proceedings of the Workshop on Geometrical Models of Natual Language Semantics (GEMS), pages 33–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Chen</author>
<author>William B Dolan</author>
</authors>
<title>Collecting highly parallel data for paraphrase evaluation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>190--200</pages>
<contexts>
<context position="8091" citStr="Chen and Dolan, 2011" startWordPosition="1203" endWordPosition="1206"> tend to be significantly smaller than monolingual non-parallel corpora. The acquired pairs of expressions include some nonparaphrases as well. Many of these come from erroneous alignments, which are particularly frequent when the given corpus is small. Monolingual comparable corpora have also been exploited as sources of paraphrases using alignmentbased methods. For instance, multiple news articles covering the same event (Shinyama et al., 2002; Barzilay and Lee, 2003; Dolan et al., 2004; Wubben et al., 2009) have been used. Such corpora have also been created manually through crowdsourcing (Chen and Dolan, 2011). However, the availability of monolingual comparable corpora is very limited for most languages; thus, approaches relying on these corpora have typically produced only very 632 small collections of paraphrases. Hashimoto et al. (2011) found a way around this limitation by collecting sentences that constitute explicit definitions of particular words or phrases from monolingual nonparallel Web documents, pairing sentences that define the same noun phrase, and then finding corresponding phrases in each sentence pair. One limitation of this approach is that it requires a considerable amount of la</context>
</contexts>
<marker>Chen, Dolan, 2011</marker>
<rawString>David L. Chen and William B. Dolan. 2011. Collecting highly parallel data for paraphrase evaluation. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 190–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>A coefficient of agreement for nominal scales.</title>
<date>1960</date>
<booktitle>Educational and Psychological Measurement,</booktitle>
<pages>20--1</pages>
<contexts>
<context position="34506" citStr="Cohen, 1960" startWordPosition="5495" endWordPosition="5496">uite high performance in both grammaticality (“G”) and meaning (“M”) in part because of the effectiveness of our filtering techniques. The performance of paraphrases drawn from PHvst was reasonably high and similar to the scores 0.68 for grammaticality, 0.61 for meaning, and 0.55 for both, of the best model reported in (CallisonBurch, 2008), although it was inferior to PSeed. Despite the fact that all of our evaluators had a high-level command of English, the agreement was not very high. This was true even when the collected scores were mapped into binary classes. In this case, the r. values (Cohen, 1960) for each criterion were 0.45 and 0.45, respectively, which indicate the agreement was “fair”. To obtain a better r. value, the criteria for grading will need to be improved. However, we think that was not too low either$. The most promising way for improving the quality of PHvst is to ensure that paraphrase patterns cover only legitimate paraphrases. We investigated this by filtering the manually scored paraphrase examples with two thresholds for cleaning seed paraphrases PSeed: thp on the conditional probability estimated using the bilingual parallel corpus and ths on the contextual similari</context>
</contexts>
<marker>Cohen, 1960</marker>
<rawString>Jacob Cohen. 1960. A coefficient of agreement for nominal scales. Educational and Psychological Measurement, 20(1):37–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Sentence compression beyond word deletion.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING),</booktitle>
<pages>137--144</pages>
<marker>Cohn, Lapata, 2008</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2008. Sentence compression beyond word deletion. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING), pages 137–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Alon Lavie</author>
</authors>
<title>Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems.</title>
<date>2011</date>
<booktitle>In Proceedings of the 6th Workshop on Statistical Machine Translation (WMT),</booktitle>
<pages>85--91</pages>
<contexts>
<context position="14370" citStr="Denkowski and Lavie (2011)" startWordPosition="2184" endWordPosition="2187"> two conditions (see also Figure 2). • rp′ is a word sub-sequence of rp • rp′ is a more likely paraphrase than rp, i.e., p(rp′|lp) &gt; p(rp|lp) LHS phrases for each RHS phrase rp are also compared in a similar manner, i.e., a LHS phrase lp is not qualified as a legitimate source of rp iff rp has another LHS phrase lp′ (̸= lp) which satisfies the following conditions (see also Figure 3). • lp′ is a word sub-sequence of lp • lp′ is a more likely source than lp, i.e., p(lp′|rp) &gt; p(lp|rp) The two directions of filtering are separately applied and the intersection of their results is retained. zcf. Denkowski and Lavie (2011); they only compared each RHS phrase to its corresponding LHS phrase. Figure 3: LHS-filtering for “control device”. Candidate pairs are finally filtered on the basis of their reliability score. Traditionally, a threshold (thp) on the conditional probability given by Eq. (1) is used (Du et al., 2010; Max, 2010; Denkowski and Lavie, 2011, etc.). Furthermore, we also require that LHS and RHS phrases exceed a threshold (ths) on their contextual similarity in a monolingual corpus. This paper neither proposes a specific recipe nor makes a comprehensive comparison of existing recipes for computing co</context>
<context position="23110" citStr="Denkowski and Lavie, 2011" startWordPosition="3595" endWordPosition="3598">aphrases are acquired. Given the initial set of paraphrases, PR,, (“X”), our filtering techniques (“❑”) discarded a large portion (63-75% in Europarl and 43-64% in Patent) of them. Pairs with zero similarity were also filtered out, i.e., the = c. This suggests that many incorrect 6http://statmt.org/moses/?n=FactoredTraining.AlignWords and/or relatively useless pairs, such as those shown in Figures 2 and 3, had originally been acquired. Lines with “◦” show the results based on a widely-used threshold value on the conditional probability in Eq. (1), i.e., the = 0.01 (Du et al., 2010; Max, 2010; Denkowski and Lavie, 2011, etc.). The percentage of paraphrase pairs thereby discarded varied greatly depending on the corpus size (17-78% in Europarl and 31-82% in Patent), suggesting that the threshold value should be determined depending on the given corpus. In the following experiment, however, we conform to the convention the = 0.01 (“△”) to ensure the quality of PSeed that we will be using for inducing paraphrase patterns, even though this results in discarding some less frequent but correct paraphrase pairs, such as “control apparatus” =&gt;. “controlling device” in Figure 2. Paraphrase Patterns Figures 5 and 6 sh</context>
</contexts>
<marker>Denkowski, Lavie, 2011</marker>
<rawString>Michael Denkowski and Alon Lavie. 2011. Meteor 1.3: Automatic metric for reliable optimization and evaluation of machine translation systems. In Proceedings of the 6th Workshop on Statistical Machine Translation (WMT), pages 85–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill Dolan</author>
<author>Chris Quirk</author>
<author>Chris Brockett</author>
</authors>
<title>Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>350--356</pages>
<contexts>
<context position="7963" citStr="Dolan et al., 2004" startWordPosition="1183" endWordPosition="1186">us. This approach, however, suffers from a coverage problem, because both monolingual parallel and bilingual parallel corpora tend to be significantly smaller than monolingual non-parallel corpora. The acquired pairs of expressions include some nonparaphrases as well. Many of these come from erroneous alignments, which are particularly frequent when the given corpus is small. Monolingual comparable corpora have also been exploited as sources of paraphrases using alignmentbased methods. For instance, multiple news articles covering the same event (Shinyama et al., 2002; Barzilay and Lee, 2003; Dolan et al., 2004; Wubben et al., 2009) have been used. Such corpora have also been created manually through crowdsourcing (Chen and Dolan, 2011). However, the availability of monolingual comparable corpora is very limited for most languages; thus, approaches relying on these corpora have typically produced only very 632 small collections of paraphrases. Hashimoto et al. (2011) found a way around this limitation by collecting sentences that constitute explicit definitions of particular words or phrases from monolingual nonparallel Web documents, pairing sentences that define the same noun phrase, and then find</context>
</contexts>
<marker>Dolan, Quirk, Brockett, 2004</marker>
<rawString>Bill Dolan, Chris Quirk, and Chris Brockett. 2004. Unsupervised construction of large paraphrase corpora: Exploiting massively parallel news sources. In Proceedings of the 20th International Conference on Computational Linguistics (COLING), pages 350– 356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinhua Du</author>
<author>Jie Jiang</author>
<author>Andy Way</author>
</authors>
<title>Facilitating translation using source language paraphrase lattices.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>420--429</pages>
<contexts>
<context position="14669" citStr="Du et al., 2010" startWordPosition="2231" endWordPosition="2234">ase lp′ (̸= lp) which satisfies the following conditions (see also Figure 3). • lp′ is a word sub-sequence of lp • lp′ is a more likely source than lp, i.e., p(lp′|rp) &gt; p(lp|rp) The two directions of filtering are separately applied and the intersection of their results is retained. zcf. Denkowski and Lavie (2011); they only compared each RHS phrase to its corresponding LHS phrase. Figure 3: LHS-filtering for “control device”. Candidate pairs are finally filtered on the basis of their reliability score. Traditionally, a threshold (thp) on the conditional probability given by Eq. (1) is used (Du et al., 2010; Max, 2010; Denkowski and Lavie, 2011, etc.). Furthermore, we also require that LHS and RHS phrases exceed a threshold (ths) on their contextual similarity in a monolingual corpus. This paper neither proposes a specific recipe nor makes a comprehensive comparison of existing recipes for computing contextual similarity, although one particular recipe is used in our experiments (see Section 4.1). 3.2 Step 2. Paraphrase Pattern Induction From a set of seed paraphrases, PSeed, paraphrase patterns are induced. For instance, from paraphrases in (3), we induce paraphrase patterns in (4). (3) a. “res</context>
<context position="23072" citStr="Du et al., 2010" startWordPosition="3589" endWordPosition="3592"> the corpus is, the more paraphrases are acquired. Given the initial set of paraphrases, PR,, (“X”), our filtering techniques (“❑”) discarded a large portion (63-75% in Europarl and 43-64% in Patent) of them. Pairs with zero similarity were also filtered out, i.e., the = c. This suggests that many incorrect 6http://statmt.org/moses/?n=FactoredTraining.AlignWords and/or relatively useless pairs, such as those shown in Figures 2 and 3, had originally been acquired. Lines with “◦” show the results based on a widely-used threshold value on the conditional probability in Eq. (1), i.e., the = 0.01 (Du et al., 2010; Max, 2010; Denkowski and Lavie, 2011, etc.). The percentage of paraphrase pairs thereby discarded varied greatly depending on the corpus size (17-78% in Europarl and 31-82% in Patent), suggesting that the threshold value should be determined depending on the given corpus. In the following experiment, however, we conform to the convention the = 0.01 (“△”) to ensure the quality of PSeed that we will be using for inducing paraphrase patterns, even though this results in discarding some less frequent but correct paraphrase pairs, such as “control apparatus” =&gt;. “controlling device” in Figure 2. </context>
</contexts>
<marker>Du, Jiang, Way, 2010</marker>
<rawString>Jinhua Du, Jie Jiang, and Andy Way. 2010. Facilitating translation using source language paraphrase lattices. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 420–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
</authors>
<title>Masao Utiyama, Mikio Yamamoto, Takehito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, and Sayori Shimohata.</title>
<date>2010</date>
<booktitle>In Proceedings of NTCIR-8 Workshop Meeting,</booktitle>
<pages>371--376</pages>
<marker>Fujii, 2010</marker>
<rawString>Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, Takehito Utsuro, Terumasa Ehara, Hiroshi Echizen-ya, and Sayori Shimohata. 2010. Overview of the patent translation task at the NTCIR-8 workshop. In Proceedings of NTCIR-8 Workshop Meeting, pages 371– 376.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujita</author>
<author>Shuhei Kato</author>
<author>Naoki Kato</author>
<author>Satoshi Sato</author>
</authors>
<title>A compositional approach toward dynamic phrasal thesaurus.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing (WTEP),</booktitle>
<pages>151--158</pages>
<contexts>
<context position="16635" citStr="Fujita et al., 2007" startWordPosition="2559" endWordPosition="2562">ice p(rp|lp) .172 .032 .015 rp: control device of the rp: controlling device .005 lp: control apparatus .004 .003 rp: control system of rp: a control system for an rp: a controlling device .001 .001 .004 rp: control device lp: control apparatus of lp: controlling unit .002 lp: control equipment .001 lp: the control apparatus .008 .010 lp: controller lp: control apparatus p(lp|rp) .153 .135 lp: controller for a .001 lp: to the control apparatus 634 Note that our aim is to automatically capture general paraphrase patterns of the kind that have sometimes been manually described (Jacquemin, 1999; Fujita et al., 2007). This is different from approaches that attach variable slots to paraphrases for calculating their similarity (Lin and Pantel, 2001; Szpektor and Dagan, 2008) or for constraining the context in which they are regarded legitimate (Callison-Burch, 2008; Zhao et al., 2009). 3.3 Step 3. Paraphrase Instance Acquisition Given a set of paraphrase patterns, such as those shown in (4), a set of novel instances, i.e., novel paraphrases, PH,st, will now be harvested from monolingual non-parallel corpora. In other words, a set of appropriate slot-fillers will be extracted. First, expressions that match b</context>
</contexts>
<marker>Fujita, Kato, Kato, Sato, 2007</marker>
<rawString>Atsushi Fujita, Shuhei Kato, Naoki Kato, and Satoshi Sato. 2007. A compositional approach toward dynamic phrasal thesaurus. In Proceedings of the ACLPASCAL Workshop on Textual Entailment and Paraphrasing (WTEP), pages 151–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Chris Callison-Burch</author>
<author>Courtney Napoles</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>1168--1179</pages>
<marker>Ganitkevitch, Callison-Burch, Napoles, Van Durme, 2011</marker>
<rawString>Juri Ganitkevitch, Chris Callison-Burch, Courtney Napoles, and Benjamin Van Durme. 2011. Learning sentential paraphrases from bilingual parallel corpora for text-to-text generation. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1168–1179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zellig Harris</author>
</authors>
<title>Mathematical Structures of Language.</title>
<date>1968</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="2617" citStr="Harris, 1968" startWordPosition="376" endWordPosition="377">em q controller The challenge in acquiring paraphrases is to ensure good coverage of the targeted classes of paraphrases along with a low proportion of incorrect pairs. However, no matter what type of resource has been used, it has proven difficult to acquire paraphrase pairs with both high recall and high precision. Among various types of corpora, monolingual corpora can be considered the best source for highcoverage paraphrase acquisition, because there is far more monolingual than bilingual text available. Most methods that exploit monolingual corpora rely on the Distributional Hypothesis (Harris, 1968): expressions that appear in similar contexts are expected to have similar meaning. However, if one uses purely distributional criteria, it is difficult to distinguish real paraphrases from pairs of expressions that are related in other ways, such as antonyms and cousin words. In contrast, since the work in (Bannard and Callison-Burch, 2005), bilingual parallel corpora have been acknowledged as a good source of highquality paraphrases: paraphrases are obtained by putting together expressions that receive the same translation in the other language (pivot language). Because translation expresses</context>
<context position="5106" citStr="Harris, 1968" startWordPosition="733" endWordPosition="734">tion 4 describes our experiments in acquiring paraphrases and presents statistics summarizing the coverage of our method. Section 5 describes a human evaluation of the quality of the acquired paraphrases. Finally, Section 6 concludes this paper. 2 Literature on Paraphrase Acquisition This section summarizes existing corpus-based methods for paraphrase acquisition, following the classification in (Hashimoto et al., 2011): similaritybased and alignment-based methods. 2.1 Similarity-based Methods Techniques that use monolingual (non-parallel) corpora mostly rely on the Distributional Hypothesis (Harris, 1968). Because a large quantity of monolingual data is available for many languages, a large number of paraphrase candidates can be acquired (Lin and Pantel, 2001; Pas¸ca and Dienes, 2005; Bhagat and Ravichandran, 2008, etc.). The recipes proposed so far are based on three main ingredients, i.e., features used for representing context of target expression (contextual features), criteria for weighting and filtering features, and aggregation functions. A drawback of relying only on contextual similarity is that it tends to give high scores to semantically related but non-equivalent expressions, such </context>
</contexts>
<marker>Harris, 1968</marker>
<rawString>Zellig Harris. 1968. Mathematical Structures of Language. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chikara Hashimoto</author>
<author>Kentaro Torisawa</author>
<author>Stijn De Saeger</author>
<author>Jun’ichi Kazama</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Extracting paraphrases from definition sentences on the Web.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1087--1097</pages>
<marker>Hashimoto, Torisawa, De Saeger, Kazama, Kurohashi, 2011</marker>
<rawString>Chikara Hashimoto, Kentaro Torisawa, Stijn De Saeger, Jun’ichi Kazama, and Sadao Kurohashi. 2011. Extracting paraphrases from definition sentences on the Web. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1087–1097.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Jacquemin</author>
</authors>
<title>Syntagmatic and paradigmatic representations of term variation.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>341--348</pages>
<contexts>
<context position="16613" citStr="Jacquemin, 1999" startWordPosition="2557" endWordPosition="2558">: the control device p(rp|lp) .172 .032 .015 rp: control device of the rp: controlling device .005 lp: control apparatus .004 .003 rp: control system of rp: a control system for an rp: a controlling device .001 .001 .004 rp: control device lp: control apparatus of lp: controlling unit .002 lp: control equipment .001 lp: the control apparatus .008 .010 lp: controller lp: control apparatus p(lp|rp) .153 .135 lp: controller for a .001 lp: to the control apparatus 634 Note that our aim is to automatically capture general paraphrase patterns of the kind that have sometimes been manually described (Jacquemin, 1999; Fujita et al., 2007). This is different from approaches that attach variable slots to paraphrases for calculating their similarity (Lin and Pantel, 2001; Szpektor and Dagan, 2008) or for constraining the context in which they are regarded legitimate (Callison-Burch, 2008; Zhao et al., 2009). 3.3 Step 3. Paraphrase Instance Acquisition Given a set of paraphrase patterns, such as those shown in (4), a set of novel instances, i.e., novel paraphrases, PH,st, will now be harvested from monolingual non-parallel corpora. In other words, a set of appropriate slot-fillers will be extracted. First, ex</context>
</contexts>
<marker>Jacquemin, 1999</marker>
<rawString>Christian Jacquemin. 1999. Syntagmatic and paradigmatic representations of term variation. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics (ACL), pages 341–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Howard Johnson</author>
<author>Joel Martin</author>
<author>George Foster</author>
<author>Roland Kuhn</author>
</authors>
<title>Improving translation quality by discarding most of the phrasetable.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>967--975</pages>
<contexts>
<context position="11788" citStr="Johnson et al., 2007" startWordPosition="1766" endWordPosition="1769">lts with several filtering methods. The phrase pair extraction process of phrasebased SMT systems aims at high recall for increased robustness of the translation process. As a result, a naive application of the paraphrase acquisition method produces pairs of expressions that are not exact paraphrases. For instance, the algorithm explained in Koehn (2009, p.134) extracts both “dass” and “, dass” as counterparts of “that” from the sentence pair. To reduce that kind of noise, we apply some filtering techniques to the candidate translation pairs. First, statistically unreliable translation pairs (Johnson et al., 2007) are filtered out. Then, we also filter out phrases made up entirely of stop words (including punctuation marks), both in the language of interest and in the pivot language. Let PR,,,, be the initial set of paraphrase pairs extracted from the sanitized translation table. We first Monolingual Non-parallel Corpus Bilingual Parallel Corpus PSeed: Seed Paraphrases PHvst: Novel Paraphrases Paraphrase Patterns Translation Table Step 1. Seed Paraphrase Acquisition Step 2. Paraphrase Pattern Induction Step 3. Paraphrase Instance Acquisition “health issue” a “probl6me de sant6” “health problem” a “prob</context>
<context position="21709" citStr="Johnson et al., 2007" startWordPosition="3373" endWordPosition="3376">raphrase pairs in PSeed (left: Europarl, right: Patent). Stop word lists for sanitizing translation pairs and paraphrase pairs were manually compiled: we enumerated 442 English words, 193 French words, and 149 Japanese morphemes, respectively. From a bilingual parallel corpus, a translation table was created by our in-house phrase-based SMT system, PORTAGE (Sadat et al., 2005). Phrase alignments of each sentence pair were identified by the heuristic “grow-diag-final”6 with a maximum phrase length 8. The resulting translation pairs were then filtered with the significance pruning technique of (Johnson et al., 2007), using α + c as threshold. As contextual features for computing similarity of each paraphrase pair, all of the 1- to 4-grams of words adjacent to each occurrence of a phrase were counted. This is a compromise between less expensive but noisier approaches, such as bag-of-words, and more accurate but more expensive approaches that incorporate syntactic features (Lin and Pantel, 2001; Shinyama et al., 2002; Pang et al., 2003; Szpektor and Dagan, 2008). Contextual similarity is finally measured by taking cosine between two feature vectors. 4.2 Statistics on Acquired Paraphrases Seed Paraphrases (</context>
</contexts>
<marker>Johnson, Martin, Foster, Kuhn, 2007</marker>
<rawString>Howard Johnson, Joel Martin, George Foster, and Roland Kuhn. 2007. Improving translation quality by discarding most of the phrasetable. In Proceedings of the 2007 Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 967– 975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice Kendall</author>
</authors>
<title>A new measure of rank correlation.</title>
<date>1938</date>
<journal>Biometrika,</journal>
<pages>30--1</pages>
<contexts>
<context position="36828" citStr="Kendall, 1938" startWordPosition="5873" endWordPosition="5874">thers, because filtering reduces the number of the manually scored examples used to calculate scores. used to calculate scores. Nevertheless, it indicates that better filtering of PSeed with higher threshold values is likely to produce a better-quality set of paraphrases PHvst. For instance, an inappropriate paraphrase pattern (9a) was excluded with the = 0.1 or ths = 0.1, while correct ones (9b) and (9c) remained even when a large threshold value is used. (9) a. “X years” =&gt;. “turn X” b. “X supplied” =&gt;. “X provided” c. “main X” =&gt;. “most significant X” Kendall’s correlation coefficient &apos;rB (Kendall, 1938) between the contextual similarity and each of the human scores were 0.24 for grammaticality and 0.21 for meaning, respectively. Although they are rivaling the best results reported in (Chan et al., 2011), i.e., 0.24 and 0.21, similarity metrics should be further investigated to realize a more accurate filtering. 6 Conclusion In this paper, we exploited general patterns underlying paraphrases to acquire automatically a large number of high-quality paraphrase pairs using both bilingual parallel and monolingual non-parallel corpora. Experiments using two sets of corpora demonstrated that our met</context>
</contexts>
<marker>Kendall, 1938</marker>
<rawString>Maurice Kendall. 1938. A new measure of rank correlation. Biometrika, 30(1-2):81–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL),</booktitle>
<pages>48--54</pages>
<contexts>
<context position="11141" citStr="Koehn et al., 2003" startWordPosition="1665" endWordPosition="1668">an be pooled with the set PHvst harvested in the last stage of the process. 3.1 Step 1. Seed Paraphrase Acquisition The goal of the first step is to obtain a set of highquality paraphrase pairs, Pseed. For this purpose, alignment-based methods with bilingual or monolingual parallel corpora are preferable to similarity-based methods applied to nonparallel corpora. Among various options, in this paper, we start from the standard technique proposed by Bannard and Callison-Burch (2005) with bilingual parallel corpora (see also Section 2.2). In particular, we assume the phrase-based SMT framework (Koehn et al., 2003). Then, we purify the results with several filtering methods. The phrase pair extraction process of phrasebased SMT systems aims at high recall for increased robustness of the translation process. As a result, a naive application of the paraphrase acquisition method produces pairs of expressions that are not exact paraphrases. For instance, the algorithm explained in Koehn (2009, p.134) extracts both “dass” and “, dass” as counterparts of “that” from the sentence pair. To reduce that kind of noise, we apply some filtering techniques to the candidate translation pairs. First, statistically unre</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proceedings of the 2003 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLT-NAACL), pages 48–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Machine Translation.</title>
<date>2009</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="11522" citStr="Koehn (2009" startWordPosition="1727" endWordPosition="1728">in this paper, we start from the standard technique proposed by Bannard and Callison-Burch (2005) with bilingual parallel corpora (see also Section 2.2). In particular, we assume the phrase-based SMT framework (Koehn et al., 2003). Then, we purify the results with several filtering methods. The phrase pair extraction process of phrasebased SMT systems aims at high recall for increased robustness of the translation process. As a result, a naive application of the paraphrase acquisition method produces pairs of expressions that are not exact paraphrases. For instance, the algorithm explained in Koehn (2009, p.134) extracts both “dass” and “, dass” as counterparts of “that” from the sentence pair. To reduce that kind of noise, we apply some filtering techniques to the candidate translation pairs. First, statistically unreliable translation pairs (Johnson et al., 2007) are filtered out. Then, we also filter out phrases made up entirely of stop words (including punctuation marks), both in the language of interest and in the pivot language. Let PR,,,, be the initial set of paraphrase pairs extracted from the sanitized translation table. We first Monolingual Non-parallel Corpus Bilingual Parallel Co</context>
</contexts>
<marker>Koehn, 2009</marker>
<rawString>Philipp Koehn. 2009. Statistical Machine Translation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Kok</author>
<author>Chris Brockett</author>
</authors>
<title>Hitting the right paraphrases in good time.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT),</booktitle>
<pages>145--153</pages>
<contexts>
<context position="7143" citStr="Kok and Brockett (2010)" startWordPosition="1059" endWordPosition="1062">lignments between expressions, such as words, phrases, and subtrees, across a parallel sentence pair. Then, pairs of expressions (e1, e2) in the same language that are aligned with the same expressions in the other language (pivot language) are extracted as paraphrases. The likelihood of e2 being a paraphrase of e1 is given by ∑p(e2|e1) _ p(e2|f)p(f|e1), (1) fETr(e1re2) where R(e1, e2) stands for the set of shared translations of e1 and e2. Each factor p(e|f) and p(f|e) is estimated from the number of times e and f are aligned and the number of occurrences of each expression in each language. Kok and Brockett (2010) showed how one can discover paraphrases that do not share any translation in one language by traversing a graph created from multiple translation tables, each corresponding to a bilingual parallel corpus. This approach, however, suffers from a coverage problem, because both monolingual parallel and bilingual parallel corpora tend to be significantly smaller than monolingual non-parallel corpora. The acquired pairs of expressions include some nonparaphrases as well. Many of these come from erroneous alignments, which are particularly frequent when the given corpus is small. Monolingual compara</context>
</contexts>
<marker>Kok, Brockett, 2010</marker>
<rawString>Stanley Kok and Chris Brockett. 2010. Hitting the right paraphrases in good time. In Proceedings of Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT), pages 145– 153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>Discovery of inference rules for question answering.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="5263" citStr="Lin and Pantel, 2001" startWordPosition="757" endWordPosition="760">evaluation of the quality of the acquired paraphrases. Finally, Section 6 concludes this paper. 2 Literature on Paraphrase Acquisition This section summarizes existing corpus-based methods for paraphrase acquisition, following the classification in (Hashimoto et al., 2011): similaritybased and alignment-based methods. 2.1 Similarity-based Methods Techniques that use monolingual (non-parallel) corpora mostly rely on the Distributional Hypothesis (Harris, 1968). Because a large quantity of monolingual data is available for many languages, a large number of paraphrase candidates can be acquired (Lin and Pantel, 2001; Pas¸ca and Dienes, 2005; Bhagat and Ravichandran, 2008, etc.). The recipes proposed so far are based on three main ingredients, i.e., features used for representing context of target expression (contextual features), criteria for weighting and filtering features, and aggregation functions. A drawback of relying only on contextual similarity is that it tends to give high scores to semantically related but non-equivalent expressions, such as antonyms and cousin words. To enhance the precision of the results, filtering mechanisms need to be introduced (Marton et al., 2011). 2.2 Alignment-based </context>
<context position="16767" citStr="Lin and Pantel, 2001" startWordPosition="2579" endWordPosition="2582"> of rp: a control system for an rp: a controlling device .001 .001 .004 rp: control device lp: control apparatus of lp: controlling unit .002 lp: control equipment .001 lp: the control apparatus .008 .010 lp: controller lp: control apparatus p(lp|rp) .153 .135 lp: controller for a .001 lp: to the control apparatus 634 Note that our aim is to automatically capture general paraphrase patterns of the kind that have sometimes been manually described (Jacquemin, 1999; Fujita et al., 2007). This is different from approaches that attach variable slots to paraphrases for calculating their similarity (Lin and Pantel, 2001; Szpektor and Dagan, 2008) or for constraining the context in which they are regarded legitimate (Callison-Burch, 2008; Zhao et al., 2009). 3.3 Step 3. Paraphrase Instance Acquisition Given a set of paraphrase patterns, such as those shown in (4), a set of novel instances, i.e., novel paraphrases, PH,st, will now be harvested from monolingual non-parallel corpora. In other words, a set of appropriate slot-fillers will be extracted. First, expressions that match both elements of the pattern, except stop words, are collected from a given monolingual corpus. Pattern matching alone may generate i</context>
<context position="22093" citStr="Lin and Pantel, 2001" startWordPosition="3435" endWordPosition="3438">se alignments of each sentence pair were identified by the heuristic “grow-diag-final”6 with a maximum phrase length 8. The resulting translation pairs were then filtered with the significance pruning technique of (Johnson et al., 2007), using α + c as threshold. As contextual features for computing similarity of each paraphrase pair, all of the 1- to 4-grams of words adjacent to each occurrence of a phrase were counted. This is a compromise between less expensive but noisier approaches, such as bag-of-words, and more accurate but more expensive approaches that incorporate syntactic features (Lin and Pantel, 2001; Shinyama et al., 2002; Pang et al., 2003; Szpektor and Dagan, 2008). Contextual similarity is finally measured by taking cosine between two feature vectors. 4.2 Statistics on Acquired Paraphrases Seed Paraphrases (PSeed) Figure 4 shows the number of paraphrase pairs PSeed obtained from the bilingual parallel corpora. The general trend is simply that the larger the corpus is, the more paraphrases are acquired. Given the initial set of paraphrases, PR,, (“X”), our filtering techniques (“❑”) discarded a large portion (63-75% in Europarl and 43-64% in Patent) of them. Pairs with zero similarity </context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. Discovery of inference rules for question answering. Natural Language Engineering, 7(4):343–360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Madnani</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Generating phrasal and sentential paraphrases: A survey of data-driven methods.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>3</issue>
<contexts>
<context position="1686" citStr="Madnani and Dorr, 2010" startWordPosition="231" endWordPosition="234">s obtained in this way from monolingual corpora was a large multiple of the number of seed paraphrases. Human evaluation through a paraphrase substitution test demonstrated that the newly acquired paraphrase pairs are of reasonable quality. Remaining noise can be further reduced by filtering seed paraphrases. 1 Introduction Paraphrases are semantically equivalent expressions in the same language. Because “equivalence” is the most fundamental semantic relationship, techniques for generating and recognizing paraphrases play an important role in a wide range of natural language processing tasks (Madnani and Dorr, 2010). In the last decade, automatic acquisition of knowledge about paraphrases from corpora has been drawing the attention of many researchers. Typically, the acquired knowledge is simply represented as pairs of semantically equivalent sub-sentential expressions as in (1). (1) a. look like .&lt;---&gt; resemble b. control system q controller The challenge in acquiring paraphrases is to ensure good coverage of the targeted classes of paraphrases along with a low proportion of incorrect pairs. However, no matter what type of resource has been used, it has proven difficult to acquire paraphrase pairs with </context>
</contexts>
<marker>Madnani, Dorr, 2010</marker>
<rawString>Nitin Madnani and Bonnie J. Dorr. 2010. Generating phrasal and sentential paraphrases: A survey of data-driven methods. Computational Linguistics, 36(3):341–387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Chris Callison-Burch</author>
<author>Philip Resnik</author>
</authors>
<title>Improved statistical machine translation using monolingually-derived paraphrases.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>381--390</pages>
<marker>Marton, Callison-Burch, Resnik, 2009</marker>
<rawString>Yuval Marton, Chris Callison-Burch, and Philip Resnik. 2009. Improved statistical machine translation using monolingually-derived paraphrases. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 381–390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuval Marton</author>
<author>Ahmed El Kholy</author>
<author>Nizar Habash</author>
</authors>
<title>Filtering antonymous, trend-contrasting, and polarity-dissimilar distributional paraphrases for improving statistical machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the 6th Workshop on Statistical Machine Translation (WMT),</booktitle>
<pages>237--249</pages>
<marker>Marton, El Kholy, Habash, 2011</marker>
<rawString>Yuval Marton, Ahmed El Kholy, and Nizar Habash. 2011. Filtering antonymous, trend-contrasting, and polarity-dissimilar distributional paraphrases for improving statistical machine translation. In Proceedings of the 6th Workshop on Statistical Machine Translation (WMT), pages 237–249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aur´elien Max</author>
</authors>
<title>Example-based paraphrasing for improved phrase-based statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>656--666</pages>
<contexts>
<context position="14680" citStr="Max, 2010" startWordPosition="2235" endWordPosition="2236">hich satisfies the following conditions (see also Figure 3). • lp′ is a word sub-sequence of lp • lp′ is a more likely source than lp, i.e., p(lp′|rp) &gt; p(lp|rp) The two directions of filtering are separately applied and the intersection of their results is retained. zcf. Denkowski and Lavie (2011); they only compared each RHS phrase to its corresponding LHS phrase. Figure 3: LHS-filtering for “control device”. Candidate pairs are finally filtered on the basis of their reliability score. Traditionally, a threshold (thp) on the conditional probability given by Eq. (1) is used (Du et al., 2010; Max, 2010; Denkowski and Lavie, 2011, etc.). Furthermore, we also require that LHS and RHS phrases exceed a threshold (ths) on their contextual similarity in a monolingual corpus. This paper neither proposes a specific recipe nor makes a comprehensive comparison of existing recipes for computing contextual similarity, although one particular recipe is used in our experiments (see Section 4.1). 3.2 Step 2. Paraphrase Pattern Induction From a set of seed paraphrases, PSeed, paraphrase patterns are induced. For instance, from paraphrases in (3), we induce paraphrase patterns in (4). (3) a. “restraint syst</context>
<context position="23083" citStr="Max, 2010" startWordPosition="3593" endWordPosition="3594">he more paraphrases are acquired. Given the initial set of paraphrases, PR,, (“X”), our filtering techniques (“❑”) discarded a large portion (63-75% in Europarl and 43-64% in Patent) of them. Pairs with zero similarity were also filtered out, i.e., the = c. This suggests that many incorrect 6http://statmt.org/moses/?n=FactoredTraining.AlignWords and/or relatively useless pairs, such as those shown in Figures 2 and 3, had originally been acquired. Lines with “◦” show the results based on a widely-used threshold value on the conditional probability in Eq. (1), i.e., the = 0.01 (Du et al., 2010; Max, 2010; Denkowski and Lavie, 2011, etc.). The percentage of paraphrase pairs thereby discarded varied greatly depending on the corpus size (17-78% in Europarl and 31-82% in Patent), suggesting that the threshold value should be determined depending on the given corpus. In the following experiment, however, we conform to the convention the = 0.01 (“△”) to ensure the quality of PSeed that we will be using for inducing paraphrase patterns, even though this results in discarding some less frequent but correct paraphrase pairs, such as “control apparatus” =&gt;. “controlling device” in Figure 2. Paraphrase </context>
</contexts>
<marker>Max, 2010</marker>
<rawString>Aur´elien Max. 2010. Example-based paraphrasing for improved phrase-based statistical machine translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 656–666.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pas¸ca</author>
<author>P´eter Dienes</author>
</authors>
<title>Aligning needles in a haystack: Paraphrase acquisition across the Web. In</title>
<date>2005</date>
<booktitle>Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<pages>119--130</pages>
<marker>Pas¸ca, Dienes, 2005</marker>
<rawString>Marius Pas¸ca and P´eter Dienes. 2005. Aligning needles in a haystack: Paraphrase acquisition across the Web. In Proceedings of the 2nd International Joint Conference on Natural Language Processing (IJCNLP), pages 119–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLTNAACL),</booktitle>
<pages>102--109</pages>
<contexts>
<context position="6074" citStr="Pang et al. (2003)" startWordPosition="886" endWordPosition="889">on (contextual features), criteria for weighting and filtering features, and aggregation functions. A drawback of relying only on contextual similarity is that it tends to give high scores to semantically related but non-equivalent expressions, such as antonyms and cousin words. To enhance the precision of the results, filtering mechanisms need to be introduced (Marton et al., 2011). 2.2 Alignment-based Methods Pairs of expressions that get translated to the same expression in a different language can be regarded as paraphrases. On the basis of this hypothesis, Barzilay and McKeown (2001) and Pang et al. (2003) created monolingual parallel corpora from multiple human translations of the same source. Then, they extracted corresponding parts of such parallel sentences as sub-sentential paraphrases. Leveraging recent advances in statistical machine translation (SMT), Bannard and CallisonBurch (2005) proposed a method for acquiring subsentential paraphrases from bilingual parallel corpora. As in SMT, a translation table is first built on the basis of alignments between expressions, such as words, phrases, and subtrees, across a parallel sentence pair. Then, pairs of expressions (e1, e2) in the same lang</context>
<context position="22135" citStr="Pang et al., 2003" startWordPosition="3443" endWordPosition="3446">tified by the heuristic “grow-diag-final”6 with a maximum phrase length 8. The resulting translation pairs were then filtered with the significance pruning technique of (Johnson et al., 2007), using α + c as threshold. As contextual features for computing similarity of each paraphrase pair, all of the 1- to 4-grams of words adjacent to each occurrence of a phrase were counted. This is a compromise between less expensive but noisier approaches, such as bag-of-words, and more accurate but more expensive approaches that incorporate syntactic features (Lin and Pantel, 2001; Shinyama et al., 2002; Pang et al., 2003; Szpektor and Dagan, 2008). Contextual similarity is finally measured by taking cosine between two feature vectors. 4.2 Statistics on Acquired Paraphrases Seed Paraphrases (PSeed) Figure 4 shows the number of paraphrase pairs PSeed obtained from the bilingual parallel corpora. The general trend is simply that the larger the corpus is, the more paraphrases are acquired. Given the initial set of paraphrases, PR,, (“X”), our filtering techniques (“❑”) discarded a large portion (63-75% in Europarl and 43-64% in Patent) of them. Pairs with zero similarity were also filtered out, i.e., the = c. Thi</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>Bo Pang, Kevin Knight, and Daniel Marcu. 2003. Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings of the 2003 Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics (HLTNAACL), pages 102–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fatiha Sadat</author>
<author>Howard Johnson</author>
<author>Akakpo Agbago</author>
<author>George Foster</author>
<author>Roland Kuhn</author>
<author>Joel Martin</author>
<author>Aaron Tikuisis</author>
</authors>
<title>PORTAGE: A phrase-based machine translation system.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Building and Using Parallel Texts,</booktitle>
<pages>129--132</pages>
<contexts>
<context position="21467" citStr="Sadat et al., 2005" startWordPosition="3338" endWordPosition="3341">s 108 # of paraphrase pairs 107 106 105 104 103 108 # of paraphrase pairs 107 106 105 104 103 PRaw PRaw (th =0.01) PSeed (R. =ε, th =ε) PSeed (thp=0.01, ths=ε) 106 107 108 # of words in the English side of bilingual corpus Figure 4: # of paraphrase pairs in PSeed (left: Europarl, right: Patent). Stop word lists for sanitizing translation pairs and paraphrase pairs were manually compiled: we enumerated 442 English words, 193 French words, and 149 Japanese morphemes, respectively. From a bilingual parallel corpus, a translation table was created by our in-house phrase-based SMT system, PORTAGE (Sadat et al., 2005). Phrase alignments of each sentence pair were identified by the heuristic “grow-diag-final”6 with a maximum phrase length 8. The resulting translation pairs were then filtered with the significance pruning technique of (Johnson et al., 2007), using α + c as threshold. As contextual features for computing similarity of each paraphrase pair, all of the 1- to 4-grams of words adjacent to each occurrence of a phrase were counted. This is a compromise between less expensive but noisier approaches, such as bag-of-words, and more accurate but more expensive approaches that incorporate syntactic feat</context>
</contexts>
<marker>Sadat, Johnson, Agbago, Foster, Kuhn, Martin, Tikuisis, 2005</marker>
<rawString>Fatiha Sadat, Howard Johnson, Akakpo Agbago, George Foster, Roland Kuhn, Joel Martin, and Aaron Tikuisis. 2005. PORTAGE: A phrase-based machine translation system. In Proceedings of the ACL Workshop on Building and Using Parallel Texts, pages 129–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
<author>Kiyoshi Sudo</author>
<author>Ralph Grishman</author>
</authors>
<title>Automatic paraphrase acquisition from news articles.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Human Language Technology Conference (HLT).</booktitle>
<contexts>
<context position="7919" citStr="Shinyama et al., 2002" startWordPosition="1175" endWordPosition="1178">each corresponding to a bilingual parallel corpus. This approach, however, suffers from a coverage problem, because both monolingual parallel and bilingual parallel corpora tend to be significantly smaller than monolingual non-parallel corpora. The acquired pairs of expressions include some nonparaphrases as well. Many of these come from erroneous alignments, which are particularly frequent when the given corpus is small. Monolingual comparable corpora have also been exploited as sources of paraphrases using alignmentbased methods. For instance, multiple news articles covering the same event (Shinyama et al., 2002; Barzilay and Lee, 2003; Dolan et al., 2004; Wubben et al., 2009) have been used. Such corpora have also been created manually through crowdsourcing (Chen and Dolan, 2011). However, the availability of monolingual comparable corpora is very limited for most languages; thus, approaches relying on these corpora have typically produced only very 632 small collections of paraphrases. Hashimoto et al. (2011) found a way around this limitation by collecting sentences that constitute explicit definitions of particular words or phrases from monolingual nonparallel Web documents, pairing sentences tha</context>
<context position="22116" citStr="Shinyama et al., 2002" startWordPosition="3439" endWordPosition="3442">sentence pair were identified by the heuristic “grow-diag-final”6 with a maximum phrase length 8. The resulting translation pairs were then filtered with the significance pruning technique of (Johnson et al., 2007), using α + c as threshold. As contextual features for computing similarity of each paraphrase pair, all of the 1- to 4-grams of words adjacent to each occurrence of a phrase were counted. This is a compromise between less expensive but noisier approaches, such as bag-of-words, and more accurate but more expensive approaches that incorporate syntactic features (Lin and Pantel, 2001; Shinyama et al., 2002; Pang et al., 2003; Szpektor and Dagan, 2008). Contextual similarity is finally measured by taking cosine between two feature vectors. 4.2 Statistics on Acquired Paraphrases Seed Paraphrases (PSeed) Figure 4 shows the number of paraphrase pairs PSeed obtained from the bilingual parallel corpora. The general trend is simply that the larger the corpus is, the more paraphrases are acquired. Given the initial set of paraphrases, PR,, (“X”), our filtering techniques (“❑”) discarded a large portion (63-75% in Europarl and 43-64% in Patent) of them. Pairs with zero similarity were also filtered out,</context>
</contexts>
<marker>Shinyama, Sekine, Sudo, Grishman, 2002</marker>
<rawString>Yusuke Shinyama, Satoshi Sekine, Kiyoshi Sudo, and Ralph Grishman. 2002. Automatic paraphrase acquisition from news articles. In Proceedings of the 2002 Human Language Technology Conference (HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Learning entailment rules for unary templates.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING).</booktitle>
<pages>849--856</pages>
<contexts>
<context position="16794" citStr="Szpektor and Dagan, 2008" startWordPosition="2583" endWordPosition="2586">em for an rp: a controlling device .001 .001 .004 rp: control device lp: control apparatus of lp: controlling unit .002 lp: control equipment .001 lp: the control apparatus .008 .010 lp: controller lp: control apparatus p(lp|rp) .153 .135 lp: controller for a .001 lp: to the control apparatus 634 Note that our aim is to automatically capture general paraphrase patterns of the kind that have sometimes been manually described (Jacquemin, 1999; Fujita et al., 2007). This is different from approaches that attach variable slots to paraphrases for calculating their similarity (Lin and Pantel, 2001; Szpektor and Dagan, 2008) or for constraining the context in which they are regarded legitimate (Callison-Burch, 2008; Zhao et al., 2009). 3.3 Step 3. Paraphrase Instance Acquisition Given a set of paraphrase patterns, such as those shown in (4), a set of novel instances, i.e., novel paraphrases, PH,st, will now be harvested from monolingual non-parallel corpora. In other words, a set of appropriate slot-fillers will be extracted. First, expressions that match both elements of the pattern, except stop words, are collected from a given monolingual corpus. Pattern matching alone may generate inappropriate pairs, so we t</context>
<context position="22162" citStr="Szpektor and Dagan, 2008" startWordPosition="3447" endWordPosition="3450">stic “grow-diag-final”6 with a maximum phrase length 8. The resulting translation pairs were then filtered with the significance pruning technique of (Johnson et al., 2007), using α + c as threshold. As contextual features for computing similarity of each paraphrase pair, all of the 1- to 4-grams of words adjacent to each occurrence of a phrase were counted. This is a compromise between less expensive but noisier approaches, such as bag-of-words, and more accurate but more expensive approaches that incorporate syntactic features (Lin and Pantel, 2001; Shinyama et al., 2002; Pang et al., 2003; Szpektor and Dagan, 2008). Contextual similarity is finally measured by taking cosine between two feature vectors. 4.2 Statistics on Acquired Paraphrases Seed Paraphrases (PSeed) Figure 4 shows the number of paraphrase pairs PSeed obtained from the bilingual parallel corpora. The general trend is simply that the larger the corpus is, the more paraphrases are acquired. Given the initial set of paraphrases, PR,, (“X”), our filtering techniques (“❑”) discarded a large portion (63-75% in Europarl and 43-64% in Patent) of them. Pairs with zero similarity were also filtered out, i.e., the = c. This suggests that many incorr</context>
</contexts>
<marker>Szpektor, Dagan, 2008</marker>
<rawString>Idan Szpektor and Ido Dagan. 2008. Learning entailment rules for unary templates. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING). 849-856.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sander Wubben</author>
<author>Antal van den Bosch</author>
<author>Emiel Krahmer</author>
<author>Erwin Marsi</author>
</authors>
<title>Clustering and matching headlines for automatic paraphrase acquisition.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th European Workshop on Natural Language Generation,</booktitle>
<pages>122--125</pages>
<marker>Wubben, van den Bosch, Krahmer, Marsi, 2009</marker>
<rawString>Sander Wubben, Antal van den Bosch, Emiel Krahmer, and Erwin Marsi. 2009. Clustering and matching headlines for automatic paraphrase acquisition. In Proceedings of the 12th European Workshop on Natural Language Generation, pages 122–125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shiqi Zhao</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>Extracting paraphrase patterns from bilingual parallel corpora.</title>
<date>2009</date>
<journal>Natural Language Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="16906" citStr="Zhao et al., 2009" startWordPosition="2600" endWordPosition="2603"> lp: control equipment .001 lp: the control apparatus .008 .010 lp: controller lp: control apparatus p(lp|rp) .153 .135 lp: controller for a .001 lp: to the control apparatus 634 Note that our aim is to automatically capture general paraphrase patterns of the kind that have sometimes been manually described (Jacquemin, 1999; Fujita et al., 2007). This is different from approaches that attach variable slots to paraphrases for calculating their similarity (Lin and Pantel, 2001; Szpektor and Dagan, 2008) or for constraining the context in which they are regarded legitimate (Callison-Burch, 2008; Zhao et al., 2009). 3.3 Step 3. Paraphrase Instance Acquisition Given a set of paraphrase patterns, such as those shown in (4), a set of novel instances, i.e., novel paraphrases, PH,st, will now be harvested from monolingual non-parallel corpora. In other words, a set of appropriate slot-fillers will be extracted. First, expressions that match both elements of the pattern, except stop words, are collected from a given monolingual corpus. Pattern matching alone may generate inappropriate pairs, so we then assess the legitimacy of each collected slot-filler. Let LHS(w) and RHS(w) be the expressions generated by i</context>
<context position="19457" citStr="Zhao et al. (2009)" startWordPosition="3020" endWordPosition="3023">t alongside real paraphrases. As mentioned in Section 3.1, other types of methods can be used for obtaining high-quality seed paraphrases, PSeed. For instance, the supervised method proposed by Hashimoto et al. (2011) uses the existence of shared words as a feature to determine whether the given pair of expressions are paraphrases, and thereby extracts many pairs sharing the same words. Thus, their output has a high potential to be used as an alternative seed for our method. Another advantage of our method is that it does not require any labeled data, unlike the supervised methods proposed by Zhao et al. (2009) and Hashimoto et al. (2011). 4 Quantitative Impact 4.1 Experimental Settings Two different sets of corpora were used as data sources; in both settings, we acquired English paraphrases. Europarl: The English-French version of the Europarl Parallel Corpus3 consisting of 1.8M sentence pairs (51M words in English and 56M words in French) was used as a bilingual parallel corpus, while its English side and the English side of the 109 French-English corpus4 consisting of 23.8M sentences (649M words) were used as monolingual data. Patent: The Japanese-English Patent Translation data (Fujii et al., 20</context>
</contexts>
<marker>Zhao, Wang, Liu, Li, 2009</marker>
<rawString>Shiqi Zhao, Haifeng Wang, Ting Liu, and Sheng Li. 2009. Extracting paraphrase patterns from bilingual parallel corpora. Natural Language Engineering, 15(4):503–526.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>