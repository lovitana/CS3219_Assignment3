<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000322">
<title confidence="0.987981">
Wiki-ly Supervised Part-of-Speech Tagging
</title>
<author confidence="0.985166">
Shen Li Jo˜ao V. Grac¸a Ben Taskar
</author>
<affiliation confidence="0.959901">
Computer &amp; Information Science L2F INESC-ID Computer &amp; Information Science
University of Pennsylvania Lisboa, Portugal University of Pennsylvania
</affiliation>
<email confidence="0.997961">
shenli@seas.upenn.edu javg@l2f.inesc-id.pt taskar@cis.upenn.edu
</email>
<sectionHeader confidence="0.995623" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998828695652174">
Despite significant recent work, purely unsu-
pervised techniques for part-of-speech (POS)
tagging have not achieved useful accuracies
required by many language processing tasks.
Use of parallel text between resource-rich and
resource-poor languages is one source of weak
supervision that significantly improves accu-
racy. However, parallel text is not always
available and techniques for using it require
multiple complex algorithmic steps. In this
paper we show that we can build POS-taggers
exceeding state-of-the-art bilingual methods
by using simple hidden Markov models and
a freely available and naturally growing re-
source, the Wiktionary. Across eight lan-
guages for which we have labeled data to eval-
uate results, we achieve accuracy that signifi-
cantly exceeds best unsupervised and parallel
text methods. We achieve highest accuracy re-
ported for several languages and show that our
approach yields better out-of-domain taggers
than those trained using fully supervised Penn
Treebank.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999949093023256">
Part-of-speech categories are elementary building
blocks that play an important role in many natu-
ral language processing tasks, from machine trans-
lation to information extraction. Supervised learn-
ing of taggers from POS-annotated training text is
a well-studied task, with several methods achieving
near-human tagging accuracy (Ratnaparkhi, 1996;
Toutanova et al., 2003; Shen et al., 2007). How-
ever, while English and a handful of other languages
are fortunate enough to have comprehensive POS-
annotated corpora such as the Penn Treebank (Mar-
cus et al., 1993), most of the world’s languages have
no labeled corpora. The annotated corpora that do
exist were costly to build (Abeill´e, 2003), and are
often not freely available or restricted to research-
only use. Furthermore, much of the annotated text is
of limited genre, normally focusing on newswire or
literary text. Performance of treebank-trained sys-
tems degrades significantly when applied to new do-
mains (Blitzer et al., 2006).
Unsupervised induction of POS taggers offers the
possibility of avoiding costly annotation, but de-
spite recent progress, the accuracy of unsupervised
POS taggers still falls far behind supervised sys-
tems, and is not suitable for most applications (Berg-
Kirkpatrick et al., 2010; Grac¸a et al., 2011; Lee et
al., 2010). Using additional information, in the form
of tag dictionaries or parallel text, seems unavoid-
able at present. Early work on using tag dictionaries
used a labeled corpus to extract all allowed word-tag
pairs (Merialdo, 1994), which is quite an unrealis-
tic scenario. More recent work has used a subset of
the observed word-tag pairs and focused on gener-
alizing dictionary entries (Smith and Eisner, 2005;
Haghighi and Klein, 2006; Toutanova and Johnson,
2007; Goldwater and Griffiths, 2007). Using corpus-
based dictionaries greatly biases the test results, and
gives little information about the capacity to gener-
alize to different domains.
Recent work by Das and Petrov (2011) builds
a dictionary for a particular language by transfer-
ring annotated data from a resource-rich language
through the use of word alignments in parallel text.
</bodyText>
<page confidence="0.957172">
1389
</page>
<note confidence="0.7666655">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1389–1398, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.99987">
The main idea is to rely on existing dictionaries for
some languages (e.g. English) and use parallel data
to build a dictionary in the desired language and ex-
tend the dictionary coverage using label propaga-
tion. However, parallel text does not exist for many
pairs of languages and the proposed bilingual pro-
jection algorithms are fairly complex.
In this work we use the Wiktionary, a freely avail-
able, high coverage and constantly growing dic-
tionary for a large number of languages. We ex-
periment with a very simple second-order Hidden
Markov Model with feature-based emissions (Berg-
Kirkpatrick et al., 2010; Grac¸a et al., 2011). We out-
perform best current results using parallel text su-
pervision across 8 different languages, even when
the word type coverage is as low as 20%. Further-
more, using the Brown corpus as out-of-domain data
we show that using the Wiktionary produces bet-
ter taggers than using the Penn Treebank dictionary
(88.5% vs 85.9%). Our empirical analysis and the
natural growth rate of the Wiktionary suggest that
free, high-quality and multi-domain POS-taggers for
a large number of languages can be obtained by stan-
dard and efficient models.
The source code, the dictionary mappings and
the trained models described in this work are
available at http://code.google.com/p/
wikily-supervised-pos-tagger/.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999949415384616">
The scarcity of labeled corpora for resource poor
languages and the challenges of domain adaptation
have led to several efforts to build systems for unsu-
pervised POStagging.
Several lines of research have addressed the fully
unsupervised POS-tagging task: mutual information
clustering (Brown et al., 1992; Clark, 2003) has been
used to group words according to their distributional
context. Using dimensionality reduction on word
contexts followed by clustering has led to accuracy
gains (Sch¨utze, 1995; Lamar et al., 2010). Sequence
models, HMMs in particular, have been used to rep-
resent the probabilistic dependencies between con-
secutive tags. In these approaches, each observa-
tion corresponds to a particular word and each hid-
den state corresponds to a cluster. However, us-
ing maximum likelihood training for such models
does not achieve good results (Clark, 2003): max-
imum likelihood training tends to result in very am-
biguous distributions for common words, in contra-
diction with the rather sparse word-tag distribution.
Several approaches have been proposed to mitigate
this problem, including Bayesian approaches using
an improper Dirichlet prior to favor sparse model
parameters (Johnson, 2007; Gao and Johnson, 2008;
Goldwater and Griffiths, 2007), or using the Poste-
rior Regularization to penalize ambiguous posteri-
ors distributions of tags given tokens (Grac¸a et al.,
2009). Berg-Kirkpatrick et al. (2010) and Grac¸a et
al. (2011) proposed replacing the multinomial emis-
sion distributions of standard HMMs by maximum
entropy (ME) feature-based distributions. This al-
lows the use of features to capture morphological in-
formation, and achieves very promising results. De-
spite these improvements, fully unsupervised sys-
tems require an oracle to map clusters to true tags
and the performance still fails to be of practical use.
In this paper we follow a different line of work
where we rely on a prior tag dictionary indicating for
each word type what POS tags it can take on (Meri-
aldo, 1994). The task is then, for each word token
in the corpus, to disambiguate between the possible
POS tags. Even when using a tag dictionary, disam-
biguating from all possible tags is still a hard prob-
lem and the accuracy of these methods is still fall far
behind their supervised counterparts. The scarcity
of large, manually-constructed tag dictionaries led
to the development of methods that try to generalize
from a small dictionary with only a handful of en-
tries (Smith and Eisner, 2005; Haghighi and Klein,
2006; Toutanova and Johnson, 2007; Goldwater and
Griffiths, 2007), however most previous works build
the dictionary from the labeled corpus they learn on,
which does not represent a realistic dictionary. In
this paper, we argue that the Wiktionary can serve as
an effective and much less biased tag dictionary.
We note that most of the previous dictionary
based approaches can be applied using the Wik-
tionary and would likely lead to similar accuracy in-
creases that we show in this paper. For example, the
work if Ravi and Knight (2009) minimizes the num-
ber of possible tag-tag transitions in the HMM via
a integer program, hence discarding unlikely tran-
sitions that would confuse the model. Models can
also be trained jointly using parallel corpora in sev-
</bodyText>
<page confidence="0.98236">
1390
</page>
<bodyText confidence="0.999949636363636">
eral languages, exploiting the fact that different lan-
guages present different ambiguities (Snyder et al.,
2008).
The Wiktionary has been used extensively for
other tasks such as domain specific information
retrieval (M¨uller and Gurevych, 2009), ontology
matching (Krizhanovsky and Lin, 2009), synonymy
detection (Navarro et al., 2009), sentiment classifi-
cation (Chesley et al., 2006). Recently, Ding (2011)
used the Wiktionary to initialize an HMM for Chi-
nese POS tagging combined with label propagation.
</bodyText>
<sectionHeader confidence="0.607844" genericHeader="method">
3 The Wiktionary and tagged corpora
</sectionHeader>
<bodyText confidence="0.999965523809524">
The Wiktionary1 is a collaborative project that aims
to produce a free, large-scale multilingual dictio-
nary. Its goal is to describe all words from all lan-
guages (currently more than 400) using definitions
and descriptions in English. The coverage of the
Wiktionary varies greatly between languages: cur-
rently there are around 75 languages for which there
exists more than 1000 word types, and 27 for which
there exists more than 10,000 word types. Neverthe-
less, the Wiktionary has been growing at a consid-
erable rate (see Figure 1), and the number of avail-
able words has almost doubled in the last three years.
As more people use the Wiktionary, it is likely to
grow. Unlike tagged corpora, the Wiktionary pro-
vides natural incentives for users to contribute miss-
ing entries and expand this communal resource akin
to Wikipedia. As with Wikipedia, the questions of
accuracy, bias, consistency across languages, and se-
lective coverage are paramount. In this section, we
explore these concerns by comparing Wiktionary to
dictionaries derived from tagged corpora.
</bodyText>
<subsectionHeader confidence="0.999957">
3.1 Labeled corpora and Universal tags
</subsectionHeader>
<bodyText confidence="0.9984909">
We collected part-of-speech tagged corpora for
9 languages, from CoNLL-X and CoNLL-2007
shared tasks on dependency parsing (Buchholz and
Marsi, 2006; Nivre et al., 2007). In this work we
use the Universal POS tag set (Petrov et al., 2011)
that defines 12 universal categories with a relatively
stable functional definition across languages. These
categories include NOUN, VERB, ADJ = adjective,
ADV = adverb, NUM = number, ADP = adposition,
CONJ = conjunction, DET = determiner, PRON =
</bodyText>
<footnote confidence="0.950932">
1http://www.wiktionary.org/
</footnote>
<note confidence="0.740338">
All 9Langs Accuracy
</note>
<figureCaption confidence="0.999001">
Figure 1: Growth of the Wiktionary over the last three
</figureCaption>
<bodyText confidence="0.93937504">
years, showing total number of entries for all languages
and for the 9 languages we consider (left axis). We
also show the corresponding increase in average accuracy
(right axis) achieved by our model across the 9 languages
(see details below).
pronoun, PUNC = punctuation, PRT = particle, and
X = residual (a category for language-specific cat-
egories which defy cross-linguistic classification).
We found several small problems with the mapping2
which we corrected as follows. In Spanish, the fine-
level tag for date (“w”) is mapped to universal tag
NUM, while it should be mapped to NOUN. In Dan-
ish there were no PRT, NUM, PUNC, or DET tags in
the mapping. After examining the corpus guidelines
and the mapping more closely, we found that the tag
AC (Cardinal numeral) and AO (Ordinal numeral)
are mapped to ADJ. Although the corpus guidelines
indicate the category SsCatgram ‘adjective’ that en-
compasses both ‘normal’ adjectives (AN) as well as
cardinal numeral (AC) and ordinal numerals (AO),
we decided to tag AC and AO as NUM, since this
assignment better fits the existing mapping. We also
reassigned all punctuation marks, which were erro-
neously mapped to X, to PUNC and the tag U which
is used for words at, de and som, to PRT.
</bodyText>
<subsectionHeader confidence="0.999644">
3.2 Wiktionary to Universal tags
</subsectionHeader>
<bodyText confidence="0.999741666666667">
There are a total of 330 distinct POS-type tags
in Wiktionary across all languages which we have
mapped to the Universal tagset. Most of the map-
ping was straightforward since the tags used in the
Wiktionary are in fact close to the Universal tag
set. Some exceptions like “Initialism”, “Suffix”
</bodyText>
<footnote confidence="0.66929">
2http://code.google.com/p/
universal-pos-tags/
</footnote>
<figure confidence="0.999386043478261">
5000000
4500000
4000000
3500000
3000000
2500000
2000000
1500000
1000000
500000
0
90.00%
89.00%
88.00%
87.00%
86.00%
85.00%
84.00%
83.00%
82.00%
81.00%
80.00%
Jan-11
Jul-11
Jul-10
Jan-12
Aug-11
Mar-11
Aug-10
Mar-10
Feb-12
Feb-11
Dec-11
Nov-11
Sep-11
Dct-11
Jun-11
Dec-10
Nov-10
Sep-10
Dct-10
Jun-10
Apr-11
May-11
Apr-10
May-10
</figure>
<page confidence="0.979712">
1391
</page>
<bodyText confidence="0.9999835">
were discarded. We also mapped relatively rare tags
such as “Interjection”, “Symbol” to the “X” tag.
A example of POS tags for several words in the
Wiktionary is shown in Table 1. All the mappings
are available at http://code.google.com/
p/wikily-supervised-pos-tagger/.
</bodyText>
<subsectionHeader confidence="0.999504">
3.3 Wiktionary coverage
</subsectionHeader>
<bodyText confidence="0.999875925">
There are two kinds of coverage of interest: type
coverage and token coverage. We define type cov-
erage as the proportion of word types in the corpus
that simply appear in the Wiktionary (accuracy of
the tag sets are considered in the next subsection).
Token coverage is defined similarly as the portion
of all word tokens in the corpus that appear in the
Wiktionary. These statistics reflect two aspects of
the usefulness of a dictionary that affect learning in
different ways: token coverage increases the density
of supervised signal while type coverage increases
the diversity of word shape supervision. At one ex-
treme, with 100% word and token coverage, we re-
cover the POS tag disambiguation scenario and, on
the other extreme of 0% coverage, we recover the
unsupervised POS induction scenario.
The type and token coverage of Wiktionary for
each of the languages we are using for evaluation
is shown in Figure 2. We plot the coverage bar for
three different versions of Wiktionary (v20100326,
v20110321, v20120320), arranged chronologically.
We chose these three versions of the Wiktionary
simply by date, not any other factors like coverage,
quality or tagging accuracy.
As expected, the newer versions of the Wiktionary
generally have larger coverage both on type level
and token level. Nevertheless, even for languages
whose type coverage is relatively low, such as Greek
(el), the token level coverage is still quite good
(more than half of the tokens are covered). The rea-
son for this is likely the bias of the contributors to-
wards more frequent words. This trend is even more
evident when we break up the coverage by frequency
of the words. Since the number of words varies from
corpus to corpus, we normalize the word counts by
the count of the most frequent word(s) in its corpus
and group the normalized frequency into three cat-
egories labeled as “low”, “medium” and “high” and
for each category, we calculate the word type cover-
age, shown in Figure 3.
</bodyText>
<figureCaption confidence="0.929508">
Figure 2: Type-level (top) and token-level (bottom) cov-
erage for the nine languages in three versions of the Wik-
tionary.
</figureCaption>
<bodyText confidence="0.999990333333333">
We also compared the coverage provided by the
Wiktionary versus the Penn Treebank (PTB) ex-
tracted dictionary on the Brown corpus. Figure 4
shows that the Wiktionary provides a greater cover-
age for all sections of the Brown corpus, hence being
a better dictionary for tagging English text in gen-
eral. This is also reflected in the gain in accuracy on
Brown over the taggers learned from the PTB dic-
tionary in our experiments.
</bodyText>
<subsectionHeader confidence="0.990288">
3.4 Wiktionary accuracy
</subsectionHeader>
<bodyText confidence="0.999965714285714">
A more refined notion of quality is the accuracy of
the tag sets for covered words, as measured against
dictionaries extracted from labeled tree bank cor-
pora. We consider word types that are in both the
Wiktionary (W) and the tree bank dictionaries (T).
For each word type, we compare the two tag sets
and distinguish five different possibilities:
</bodyText>
<listItem confidence="0.99898175">
1. Identical: W = T
2. Superset: W D T
3. Subset: W C T
4. Overlap: W n T =� 0
</listItem>
<page confidence="0.858875">
1392
</page>
<table confidence="0.99975675">
Wiktionary Entries Universal POS Set
Language Word POS Definition
English today Adverb # In the current [[era]]; nowadays. {ADV, NOUN}
English today Adverb # On the current [[day]] or [[date]].
English today Noun # A current day or date.
German achtzig Numeral # [[eighty]] {NUM}
Swedish SCB Acronym # [[statistiska]] ... {NOUN}
Portuguese nessa Contraction # {{contraction ... discard entry
</table>
<tableCaption confidence="0.999891">
Table 1: Examples of constructing Universal POS tag sets from the Wiktionary.
</tableCaption>
<figure confidence="0.9988976875">
A B C D E F G H J K L M N P R
TBD Wiktionary
low medium high
da de el en es it nl pt sv
100.00%
80.00%
60.00%
40.00%
20.00%
0.00%
100.00%
80.00%
60.00%
40.00%
20.00%
0.00%
</figure>
<figureCaption confidence="0.996845666666667">
Figure 3: Word type coverage by normalized frequency:
words are grouped by word count / highest word count
ratio: low [0, 0.01), medium [0.01, 0.1), high [0.1, 1].
</figureCaption>
<listItem confidence="0.713093">
5. Disjoint: W n T = 0.
</listItem>
<bodyText confidence="0.9999329">
In Figure 5, the word types are grouped into the
categories described above. Most of the tag sets
(around 90%) in the Wiktionary are identical to or
supersets of the tree bank tag sets for our nine lan-
guages, which is surprisingly accurate. About 10%
of the Wiktionary tag sets are subsets of, partially
overlapping with, or disjoint from the tree bank tag
sets. Our learning methods, which assume the given
tag sets are correct, may be somewhat hurt by these
word types, as we discuss in Section 5.6.
</bodyText>
<sectionHeader confidence="0.998006" genericHeader="method">
4 Models
</sectionHeader>
<bodyText confidence="0.999203">
Our basic models are first and second order Hidden
Markov Models (HMM and SHMM). We also used
feature-based max-ent emission models with both
(HMM-ME and SHMM-ME). Below, we denote the
sequence of words in a sentence as boldface x and
the sequence of hidden states which correspond to
part-of-speech tags as boldface y. To simplify nota-
tion, we assume that every tag sequence is prefixed
</bodyText>
<figureCaption confidence="0.992519">
Figure 4: PTB vs. Wiktionary type coverage across sec-
tions of the Brown corpus.
</figureCaption>
<bodyText confidence="0.999284166666667">
with two conventional start tags y0 = start, y−1 =
start, allowing us to write as p(y1|y0, y−1) the ini-
tial state probability of the SHMM.
The probability of a sentence x along with a par-
ticular hidden state sequence y in the SHMM is
given by:
</bodyText>
<equation confidence="0.979628">
pt(yi  |yi−1, yi−2)po(xi  |yi),
(1)
</equation>
<bodyText confidence="0.99995">
where po(xi  |yi) is the probability of observ-
ing word xi in state yi (emission probability), and
pt(yi  |yi−1, yi−2) is the probability of being in state
yi, given two previous states yi−1, yi−2 (transition
probability).
In this work, we compare multinomial and maxi-
mum entropy (log-linear) emission models. Specifi-
cally, the max-ent emission model is:
</bodyText>
<equation confidence="0.988947666666667">
exp(θ · f(x, y))
po(x|y) = (2)
Ex, exp(θ · fW, y))
</equation>
<bodyText confidence="0.718564">
where f(x, y) is a feature function, x ranges over all
</bodyText>
<equation confidence="0.902908333333333">
p(x, y) = length(x)
�
i=1
</equation>
<page confidence="0.902333">
1393
</page>
<figure confidence="0.998999416666667">
100%
90%
80%
70%
60%
50%
40%
30%
20%
10%
0%
da de el en es it nl pt sv
</figure>
<figureCaption confidence="0.996794666666667">
Figure 5: The Wiktionary vs. tree bank tag sets. Around
90% of the Wiktionary tag sets are identical or subsume
tree bank tag sets. See text for details.
</figureCaption>
<bodyText confidence="0.844494">
word types, and 0 are the model parameters. We use
the following feature templates:
</bodyText>
<listItem confidence="0.99876">
• Word identity - lowercased word form if the
word appears more than 10 times in the corpus.
• Hyphen - word contains a hyphen
• Capital - word is uppercased
• Suffix - last 2 and 3 letters of a word if they
appear in more than 20 different word types.
• Number - word contains a digit
</listItem>
<bodyText confidence="0.985107388888889">
The idea of replacing the multinomial models of an
HMM by maximum entropy models has been ap-
plied before in different domains (Chen, 2003), as
well as in POS induction (Berg-Kirkpatrick et al.,
2010; Grac¸a et al., 2011).
We use the EM algorithm to learn the models,
restricting the tags of each word to those specified
by the dictionary. For each tag y, the observa-
tions probabilities po(x  |y) were initialized ran-
domly for every word type that allows tag y accord-
ing to the Wiktionary and zero otherwise. For the
M-step in max-ent models, there is no closed form
solution so we need to solve an unconstrained op-
timization problem. We use L-BFGS with Wolfe’s
rule line search (Nocedal and Wright, 1999). We
found that EM achieved higher accuracy across lan-
guages compared to direct gradient approach (Berg-
Kirkpatrick et al., 2010).
</bodyText>
<sectionHeader confidence="0.999841" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999958">
We evaluate the accuracy of taggers trained using
the Wiktionary using the 4 different models: A
first order Hidden Markov Model (HMM), a sec-
ond order Hidden Markov Model (SHMM), a first
order Hidden Markov Model with Maximum En-
tropy emission models (HMM-ME) and a second or-
der Hidden Markov Model with Maximum Entropy
emission models (SHMM-ME). For each model we
ran EM for 50 iterations, which was sufficient for
convergence of the likelihood. Following previous
work (Grac¸a et al., 2011), we used a Gaussian prior
with variance of 10 for the max-ent model param-
eters. We obtain hard assignments using posterior
decoding, where for each position we pick the la-
bel with highest posterior probability: this produces
small but consistent improvements over Viterbi de-
coding.
</bodyText>
<subsectionHeader confidence="0.980457">
5.1 Upper and lower bounds
</subsectionHeader>
<bodyText confidence="0.999862235294118">
We situate our results against several upper bounds
that use more supervision. We trained the SHMM-
ME model with a dictionary built from the train-
ing and test tree bank (ALL TBD) and also with
tree bank dictionary intersected with the Wiktionary
(Covered TBD). The Covered TBD dictionary is
more supervised than the Wiktionary in the sense
that some of the tag set mismatches of the Wik-
tionary are cleaned using the true corpus tags. We
also report results from training the SHMM-ME in
the standard supervised fashion, using 50 (50 Sent.),
100 (100 Sent.) and all sentences (All Sent.).
As a lower bound we include the results for un-
supervised systems: a regular HMM model trained
with EM (Johnson, 2007) and an HMM model using
a ME emission model trained using direct gradient
(Berg-Kirkpatrick et al., 2010)3.
</bodyText>
<subsectionHeader confidence="0.999767">
5.2 Bilingual baselines
</subsectionHeader>
<bodyText confidence="0.999844571428571">
Finally, we also compare our system against a strong
set of baselines that use bilingual data. These ap-
proaches build a dictionary by transferring labeled
data from a resource rich language (English) to a re-
source poor language (Das and Petrov, 2011). We
compare against two such methods. The first, pro-
jection, builds a dictionary by transferring the pos
</bodyText>
<subsectionHeader confidence="0.334959">
3Values for these systems where taken from the D&amp;P paper.
</subsectionHeader>
<bodyText confidence="0.412547">
identical superset subset overlap disjoint
</bodyText>
<page confidence="0.9546">
1394
</page>
<bodyText confidence="0.999933428571429">
tags from English to the new language using word
alignments. The second method, D&amp;P, is the cur-
rent state-of-the-art system, and runs label propaga-
tion on the dictionary resulting from the projected
method. We note that both of these approaches are
orthogonal to ours and could be used simultaneously
with the Wiktionary.
</bodyText>
<subsectionHeader confidence="0.999153">
5.3 Analysis
</subsectionHeader>
<bodyText confidence="0.999989419354839">
Table 2 shows results for the different models across
languages. We note that the results are not di-
rectly comparable since both the Unsupervised and
the Bilingual results use a different setup, using the
number of fine grained tags for each language as hid-
den states instead of 12 (as we do). This greatly in-
creases the degrees of freedom of the model allow-
ing it to capture more fine grained distinctions.
The first two observations are that using the ME
entropy emission model always improves over the
standard multinomial model, and using a second or-
der model always performs better. Comparing with
the work of D&amp;P, we see that our model achieves
better accuracy on average and on 5 out of 8 lan-
guages.
The most common errors are due to tag set id-
iosyncrasies. For instance, for English the symbol %
is tagged as NUM by our system while in the Penn
treebank it is tagged as Noun. Other common mis-
takes for English include tagging to as an adposition
(preposition) instead of particle and tagging which
as a pronoun instead of determiner. In the next sub-
sections we analyze the errors in more detail.
Finally, for English we also trained the SHMM-
ME model using the Celex2 dictionary available
from LDC4. Celex2 coverage for the PTB cor-
pus is much smaller than the coverage provided
by the Wiktionary (43.8% type coverage versus
80.0%). Correspondingly, the accuracy of the model
trained using Celex2 is 75.5% compared 87.1%
when trained using the Wiktionary.
</bodyText>
<subsectionHeader confidence="0.986795">
5.4 Performance vs. Wiktionary ambiguity
</subsectionHeader>
<bodyText confidence="0.99830225">
While many words overwhelmingly appear with one
tag in a given genre, in the Wiktionary a large pro-
portion of words are annotated with several tags,
even when those are extremely rare events. Around
</bodyText>
<footnote confidence="0.9403515">
4http://www.ldc.upenn.edu/Catalog/
catalogEntry.jsp?catalogId=LDC96L14
</footnote>
<bodyText confidence="0.9997788">
35% of word types in English have more than one
tag according to the Wiktionary. This increases the
difficulty of predicting the correct tag as compared
to having a corpus-based dictionary, where words
have a smaller level of ambiguity. For example, in
English, for words with one tag, the accuracy is 95%
(the reason it is not 100% is due to a discrepancy be-
tween the Wiktionary and the tree bank.) For words
with two possible tags, accuracy is 81% and for three
tags, it drops to 63%.
</bodyText>
<subsectionHeader confidence="0.993713">
5.5 Generalization to unknown words
</subsectionHeader>
<bodyText confidence="0.99995064516129">
Comparing the performance of the proposed model
for words in the Wiktionary against words not in
the Wiktionary, we see an average drop from 89%
to 63% for out-of-vocabulary words across nine lan-
guages. Table 2 shows that the average loss of accu-
racy between All TBD and Covered TBD of 4.5%
(which is due purely to decrease in coverage) is
larger than the loss between Covered TBD and the
best Wiktionary model, of 3.2% (which is due to tag
set inconsistency).
One advantage of the Wiktionary is that it is a gen-
eral purpose dictionary and not tailored for a partic-
ular domain. To illustrate this we compared several
models on the Brown corpus: the SHMM-ME model
using the Wiktionary (Wik), against using a model
trained using a dictionary extracted from the PTB
corpus (PTBD), or trained fully supervised using the
PTB corpus (PTB). We tested all these models on the
15 different sections of the Brown corpus. We also
compare against a state-of-the-art POS-tagger tagger
(ST)5.
Figure 6 shows the accuracy results for each
model on the different sections. The fully super-
vised SHMM-ME model did not perform as well as
the the Stanford tagger (about 3% behind on aver-
age), most likely because of generative vs. discrim-
inate training of the two models and feature differ-
ences. However, quite surprisingly, the Wiktionary-
tag-set-trained model performs much better not only
than the PTB-tag-set-trained model but also the su-
pervised model on the Brown corpus.
</bodyText>
<footnote confidence="0.8797455">
5Available at http://nlp.stanford.edu/
software/tagger.shtml
</footnote>
<page confidence="0.912384">
1395
</page>
<table confidence="0.999144133333333">
Unsupervised
Danish Dutch German Greek English Italian Portuguese Spanish Swedish avg.
HMM 68.7 57.0 75.9 65.8 63.7 62.9 71.5 68.4 66.7
HMM-ME 69.1 65.1 81.3 71.8 68.1 78.4 80.2 70.1 73.0
Bilingual Projection 73.6 77.0 83.2 79.3 79.7 82.6 80.1 74.7 78.8
D&amp;P 83.2 79.5 82.8 82.5 86.8 87.9 84.2 80.5 83.4
Wiktionary HMM 71.8 80.8 77.1 73.1 85.4 84.6 79.1 83.9 76.7 78.4
HMM-ME 82.8 86.1 81.2 80.1 86.1 85.4 83.7 84.6 85.9 83.7
SHMM 74.5 81.6 81.2 73.1 85.0 85.2 79.9 84.5 78.7 79.8
SHMM-ME 83.3 86.3 85.8 79.2 87.1 86.5 84.5 86.4 86.1 84.8
Supervised Covered TBD 90.1 91.4 89.4 79.7 92.7 86.3 91.5 85.1 91.0 88.6
All TBD 93.6 91.2 95.6 87.9 90.6 92.9 91.2 92.1 83.8 91.0
50 Sent. 65.3 48.5 74.5 74.2 70.2 76.2 79.2 76.2 54.7 68.6
100 Sent. 73.9 52.3 80.9 81.6 77.3 75.3 82.0 80.1 64.8 73.9
All Sent. 93.9 90.9 97.4 95.1 95.8 93.8 95.5 93.8 95.5 94.5
</table>
<tableCaption confidence="0.9246542">
Table 2: Accuracy for Unsupervised, Bilingual, Wiktionary and Supervised models. Avg. is the average of all lan-
guages except English. Unsupervised models are trained without dictionary and use an oracle to map tags to clusters.
Bilingual systems are trained using a dictionary transferred from English into the target language using word align-
ments. The Projection model uses a dictionary build directly from the part-of-speech projection. The D&amp;P model
extends the Projection model dictionary by using Label Propagation. Supervised models are trained using tree bank
</tableCaption>
<figureCaption confidence="0.920078375">
information with SHMM-ME: Covered TBD used tree bank tag set for the words only if they are also in the Wiktionary
and All TBD uses tree bank tag sets for all words. 50, 100 and All Sent. models are trained in a supervised manner
using increasing numbers of training sentences.
Figure 6: Model accuracy across the Brown cor-
pus sections. ST: Stanford tagger, Wik: Wiktionary-
tag-set-trained SHMM-ME, PTBD: PTB-tag-set-trained
SHMM-ME, PTB: Supervised SHMM-ME. Wik outper-
forms PTB and PTBD overall.
</figureCaption>
<subsectionHeader confidence="0.966199">
5.6 Error breakdown
</subsectionHeader>
<bodyText confidence="0.9318773">
In Section 3.4 we discussed the accuracy of the
Wiktionary tag sets and as Table 2 shows, a dictio-
nary with better tag set quality generally (except for
Greek) improves the POS tagging accuracy. In Fig-
ure 7, we group actual errors by the word type clas-
sified into the five cases discussed above: identical,
superset, subset, overlap, disjoint. We also add oov –
out-of-vocabulary word types. The largest source of
error across languages are out-of-vocabulary (oov)
word types at around 45% of the errors, followed
by tag set mismatch types: subset, overlap, dis-
joint, which together comprise another 50% of the
errors. As Wiktionary grows, these types of errors
will likely diminish.
Figure 7: Tag errors broken down by the word type clas-
sified into the six classes: oov, identical, superset, subset,
overlap, disjoint (see text for detail). The largest source of
error across languages are out-of-vocabulary (oov) word
types, followed by tag set mismatch types: subset, over-
lap, disjoint.
</bodyText>
<sectionHeader confidence="0.99941" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999969833333333">
We have shown that the Wiktionary can be used
to train a very simple model to achieve state-of-
art weakly-supervised and out-of-domain POS tag-
gers. The methods outlined in the paper are stan-
dard and easy to replicate, yet highly accurate and
should serve as baselines for more complex propos-
</bodyText>
<page confidence="0.974643">
1396
</page>
<bodyText confidence="0.9998899">
als. These encouraging results show that using free,
collaborative NLP resources can in fact produce re-
sults of the same level or better than using expensive
annotations for many languages. Furthermore, the
Wiktionary contains other possibly useful informa-
tion, such as glosses and translations. It would be
very interesting and perhaps necessary to incorpo-
rate this additional data in order to tackle challenges
that arise across a larger number of language types,
specifically non-European languages.
</bodyText>
<sectionHeader confidence="0.994731" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999847625">
We would like to thank Slav Petrov, Kuzman
Ganchev and Andr´e Martins for their helpful feed-
back in early versions of the manuscript. We would
also like to thank to our anonymous reviewers for
their comments and suggestions. Ben Taskar was
partially supported by a Sloan Fellowship, ONR
2010 Young Investigator Award and NSF Grant
1116676.
</bodyText>
<sectionHeader confidence="0.998118" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999915481012659">
A. Abeill´e. 2003. Treebanks: Building and Using Parsed
Corpora. Springer.
Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cˆot´e,
John DeNero, and Dan Klein. 2010. Painless unsuper-
vised learning with features. In Proc. NAACL, June.
John Blitzer, Ryan McDonald, and Fernando Pereira.
2006. Domain adaptation with structural correspon-
dence learning. In Conference on Empirical Methods
in Natural Language Processing, Sydney, Australia.
Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vin-
cent J. Della Pietra, and Jenifer C. Lai. 1992. Class-
based n-gram models of natural language. Computa-
tional Linguistics, 18:467–479.
S. Buchholz and E. Marsi. 2006. Conll-x shared task
on multilingual dependency parsing. In Proceedings
of the Tenth Conference on Computational Natural
Language Learning, pages 149–164. Association for
Computational Linguistics.
S.F. Chen. 2003. Conditional and joint models for
grapheme-to-phoneme conversion. In Proc. ECSCT.
P. Chesley, B. Vincent, L. Xu, and R.K. Srihari. 2006.
Using verbs and adjectives to automatically classify
blog sentiment. Training, 580(263):233.
Alexander Clark. 2003. Combining distributional and
morphological information for part of speech induc-
tion. In Proc. EACL.
Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based pro-
jections. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies, pages 600–609, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Weiwei Ding. 2011. Weakly supervised part-of-speech
tagging for chinese using label propagation. Master’s
thesis, University of Texas at Austin.
Jianfeng Gao and Mark Johnson. 2008. A comparison of
Bayesian estimators for unsupervised hidden Markov
model POS taggers. In In Proc. EMNLP, pages 344–
352, Honolulu, Hawaii, October. ACL.
S. Goldwater and T. Griffiths. 2007. A fully Bayesian
approach to unsupervised part-of-speech tagging. In
In Proc. ACL, volume 45, page 744.
J.V. Grac¸a, K. Ganchev, L. Coheur, F. Pereira, and
B. Taskar. 2011. Controlling complexity in part-of-
speech induction. Journal ofArtificial Intelligence Re-
search, 41(2):527–551.
J. Grac¸a, K. Ganchev, F. Pereira, and B. Taskar. 2009.
Parameter vs. posterior sparisty in latent variable mod-
els. In Proc. NIPS.
A. Haghighi and D. Klein. 2006. Prototype-driven learn-
ing for sequence models. In Proc. HTL-NAACL. ACL.
M Johnson. 2007. Why doesn’t EM find good HMM
POS-taggers. In In Proc. EMNLP-CoNLL.
AA Krizhanovsky and F. Lin. 2009. Related
terms search based on wordnet/wiktionary and its
application in ontology matching. Arxiv preprint
arXiv:0907.2209.
Michael Lamar, Yariv Maron, Mark Johnson, and Elie
Bienenstock. 2010. SVD and clustering for unsuper-
vised POS tagging. In Proceedings of the ACL 2010
Conference: Short Papers, pages 215–219, Uppsala,
Sweden, July. Association for Computational Linguis-
tics.
Yoong Keok Lee, Aria Haghighi, and Regina Barzilay.
2010. Simple type-level unsupervised POS tagging.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing, pages 853–
861, Cambridge, MA, October. Association for Com-
putational Linguistics.
M.P. Marcus, M.A. Marcinkiewicz, and B. Santorini.
1993. Building a large annotated corpus of En-
glish: The Penn Treebank. Computational linguistics,
19(2):313–330.
B. Merialdo. 1994. Tagging English text with a proba-
bilistic model. Computational linguistics, 20(2):155–
171.
C. M¨uller and I. Gurevych. 2009. Using wikipedia and
wiktionary in domain-specific information retrieval.
</reference>
<page confidence="0.839222">
1397
</page>
<reference confidence="0.999299386363636">
Evaluating Systems for Multilingual and Multimodal
Information Access, pages 219–226.
E. Navarro, F. Sajous, B. Gaume, L. Pr´evot, H. ShuKai,
K. Tzu-Yi, P. Magistry, and H. Chu-Ren. 2009. Wik-
tionary and nlp: Improving synonymy networks. In
Proceedings of the 2009 Workshop on The People’s
Web Meets NLP: Collaboratively Constructed Seman-
tic Resources, pages 19–27. Association for Computa-
tional Linguistics.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The conll 2007 shared
task on dependency parsing. In Proceedings of the
CoNLL Shared Task Session of EMNLP-CoNLL 2007.
Association for Computational Linguistics.
J. Nocedal and Stephen J. Wright. 1999. Numerical op-
timization. Springer.
S. Petrov, D. Das, and R. McDonald. 2011. A
universal part-of-speech tagset. Arxiv preprint
ArXiv:1104.2086.
A. Ratnaparkhi. 1996. A maximum entropy model for
part-of-speech tagging. In Proc. EMNLP. ACL.
Sujith Ravi and Kevin Knight. 2009. Minimized models
for unsupervised part-of-speech tagging. In In Proc.
ACL.
H. Sch¨utze. 1995. Distributional part-of-speech tagging.
In Proc. EACL, pages 141–148.
Libin Shen, Giorgio Satta, and Aravind Joshi. 2007.
Guided learning for bidirectional sequence classifica-
tion. In Proc. ACL, Prague, Czech Republic, June.
N. Smith and J. Eisner. 2005. Contrastive estimation:
Training log-linear models on unlabeled data. In Proc.
ACL. ACL.
B. Snyder, T. Naseem, J. Eisenstein, and R. Barzilay.
2008. Unsupervised multilingual learning for POS
tagging. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1041–1050. Association for Computational Linguis-
tics.
K. Toutanova and M. Johnson. 2007. A Bayesian LDA-
based model for semi-supervised part-of-speech tag-
ging. In Proc. NIPS, 20.
K. Toutanova, D. Klein, C. Manning, and Y. Singer.
2003. Feature-rich part-of-speech tagging with a
cyclic dependency network. In In Proc. HLT-NAACL.
</reference>
<page confidence="0.994027">
1398
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.547115">
<title confidence="0.999284">Wiki-ly Supervised Part-of-Speech Tagging</title>
<author confidence="0.999955">Li V Ben Taskar</author>
<affiliation confidence="0.998526">amp; Information Science INESC-ID Computer &amp; Information Science University of Pennsylvania Lisboa, Portugal University of</affiliation>
<email confidence="0.961276">shenli@seas.upenn.edujavg@l2f.inesc-id.pttaskar@cis.upenn.edu</email>
<abstract confidence="0.999553565217391">Despite significant recent work, purely unsupervised techniques for part-of-speech (POS) tagging have not achieved useful accuracies required by many language processing tasks. Use of parallel text between resource-rich and resource-poor languages is one source of weak supervision that significantly improves accuracy. However, parallel text is not always available and techniques for using it require multiple complex algorithmic steps. In this paper we show that we can build POS-taggers exceeding state-of-the-art bilingual methods by using simple hidden Markov models and a freely available and naturally growing resource, the Wiktionary. Across eight languages for which we have labeled data to evaluate results, we achieve accuracy that significantly exceeds best unsupervised and parallel text methods. We achieve highest accuracy reported for several languages and show that our approach yields better out-of-domain taggers than those trained using fully supervised Penn</abstract>
<intro confidence="0.575937">Treebank.</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeill´e</author>
</authors>
<title>Treebanks: Building and Using Parsed Corpora.</title>
<date>2003</date>
<publisher>Springer.</publisher>
<marker>Abeill´e, 2003</marker>
<rawString>A. Abeill´e. 2003. Treebanks: Building and Using Parsed Corpora. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Berg-Kirkpatrick</author>
<author>Alexandre Bouchard-Cˆot´e</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Painless unsupervised learning with features.</title>
<date>2010</date>
<booktitle>In Proc. NAACL,</booktitle>
<marker>Berg-Kirkpatrick, Bouchard-Cˆot´e, DeNero, Klein, 2010</marker>
<rawString>Taylor Berg-Kirkpatrick, Alexandre Bouchard-Cˆot´e, John DeNero, and Dan Klein. 2010. Painless unsupervised learning with features. In Proc. NAACL, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Blitzer</author>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="2283" citStr="Blitzer et al., 2006" startWordPosition="326" endWordPosition="329">l., 2003; Shen et al., 2007). However, while English and a handful of other languages are fortunate enough to have comprehensive POSannotated corpora such as the Penn Treebank (Marcus et al., 1993), most of the world’s languages have no labeled corpora. The annotated corpora that do exist were costly to build (Abeill´e, 2003), and are often not freely available or restricted to researchonly use. Furthermore, much of the annotated text is of limited genre, normally focusing on newswire or literary text. Performance of treebank-trained systems degrades significantly when applied to new domains (Blitzer et al., 2006). Unsupervised induction of POS taggers offers the possibility of avoiding costly annotation, but despite recent progress, the accuracy of unsupervised POS taggers still falls far behind supervised systems, and is not suitable for most applications (BergKirkpatrick et al., 2010; Grac¸a et al., 2011; Lee et al., 2010). Using additional information, in the form of tag dictionaries or parallel text, seems unavoidable at present. Early work on using tag dictionaries used a labeled corpus to extract all allowed word-tag pairs (Merialdo, 1994), which is quite an unrealistic scenario. More recent wor</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>John Blitzer, Ryan McDonald, and Fernando Pereira. 2006. Domain adaptation with structural correspondence learning. In Conference on Empirical Methods in Natural Language Processing, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V deSouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Classbased n-gram models of natural language.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--467</pages>
<contexts>
<context position="5331" citStr="Brown et al., 1992" startWordPosition="797" endWordPosition="800">t that free, high-quality and multi-domain POS-taggers for a large number of languages can be obtained by standard and efficient models. The source code, the dictionary mappings and the trained models described in this work are available at http://code.google.com/p/ wikily-supervised-pos-tagger/. 2 Related Work The scarcity of labeled corpora for resource poor languages and the challenges of domain adaptation have led to several efforts to build systems for unsupervised POStagging. Several lines of research have addressed the fully unsupervised POS-tagging task: mutual information clustering (Brown et al., 1992; Clark, 2003) has been used to group words according to their distributional context. Using dimensionality reduction on word contexts followed by clustering has led to accuracy gains (Sch¨utze, 1995; Lamar et al., 2010). Sequence models, HMMs in particular, have been used to represent the probabilistic dependencies between consecutive tags. In these approaches, each observation corresponds to a particular word and each hidden state corresponds to a cluster. However, using maximum likelihood training for such models does not achieve good results (Clark, 2003): maximum likelihood training tends</context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Classbased n-gram models of natural language. Computational Linguistics, 18:467–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>Conll-x shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>149--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10086" citStr="Buchholz and Marsi, 2006" startWordPosition="1551" endWordPosition="1554">ple use the Wiktionary, it is likely to grow. Unlike tagged corpora, the Wiktionary provides natural incentives for users to contribute missing entries and expand this communal resource akin to Wikipedia. As with Wikipedia, the questions of accuracy, bias, consistency across languages, and selective coverage are paramount. In this section, we explore these concerns by comparing Wiktionary to dictionaries derived from tagged corpora. 3.1 Labeled corpora and Universal tags We collected part-of-speech tagged corpora for 9 languages, from CoNLL-X and CoNLL-2007 shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). In this work we use the Universal POS tag set (Petrov et al., 2011) that defines 12 universal categories with a relatively stable functional definition across languages. These categories include NOUN, VERB, ADJ = adjective, ADV = adverb, NUM = number, ADP = adposition, CONJ = conjunction, DET = determiner, PRON = 1http://www.wiktionary.org/ All 9Langs Accuracy Figure 1: Growth of the Wiktionary over the last three years, showing total number of entries for all languages and for the 9 languages we consider (left axis). We also show the corresponding increase in average ac</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. Conll-x shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 149–164. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S F Chen</author>
</authors>
<title>Conditional and joint models for grapheme-to-phoneme conversion.</title>
<date>2003</date>
<booktitle>In Proc. ECSCT.</booktitle>
<contexts>
<context position="19041" citStr="Chen, 2003" startWordPosition="3090" endWordPosition="3091">ound 90% of the Wiktionary tag sets are identical or subsume tree bank tag sets. See text for details. word types, and 0 are the model parameters. We use the following feature templates: • Word identity - lowercased word form if the word appears more than 10 times in the corpus. • Hyphen - word contains a hyphen • Capital - word is uppercased • Suffix - last 2 and 3 letters of a word if they appear in more than 20 different word types. • Number - word contains a digit The idea of replacing the multinomial models of an HMM by maximum entropy models has been applied before in different domains (Chen, 2003), as well as in POS induction (Berg-Kirkpatrick et al., 2010; Grac¸a et al., 2011). We use the EM algorithm to learn the models, restricting the tags of each word to those specified by the dictionary. For each tag y, the observations probabilities po(x |y) were initialized randomly for every word type that allows tag y according to the Wiktionary and zero otherwise. For the M-step in max-ent models, there is no closed form solution so we need to solve an unconstrained optimization problem. We use L-BFGS with Wolfe’s rule line search (Nocedal and Wright, 1999). We found that EM achieved higher </context>
</contexts>
<marker>Chen, 2003</marker>
<rawString>S.F. Chen. 2003. Conditional and joint models for grapheme-to-phoneme conversion. In Proc. ECSCT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Chesley</author>
<author>B Vincent</author>
<author>L Xu</author>
<author>R K Srihari</author>
</authors>
<title>Using verbs and adjectives to automatically classify blog sentiment.</title>
<date>2006</date>
<journal>Training,</journal>
<volume>580</volume>
<issue>263</issue>
<contexts>
<context position="8681" citStr="Chesley et al., 2006" startWordPosition="1328" endWordPosition="1331">ight (2009) minimizes the number of possible tag-tag transitions in the HMM via a integer program, hence discarding unlikely transitions that would confuse the model. Models can also be trained jointly using parallel corpora in sev1390 eral languages, exploiting the fact that different languages present different ambiguities (Snyder et al., 2008). The Wiktionary has been used extensively for other tasks such as domain specific information retrieval (M¨uller and Gurevych, 2009), ontology matching (Krizhanovsky and Lin, 2009), synonymy detection (Navarro et al., 2009), sentiment classification (Chesley et al., 2006). Recently, Ding (2011) used the Wiktionary to initialize an HMM for Chinese POS tagging combined with label propagation. 3 The Wiktionary and tagged corpora The Wiktionary1 is a collaborative project that aims to produce a free, large-scale multilingual dictionary. Its goal is to describe all words from all languages (currently more than 400) using definitions and descriptions in English. The coverage of the Wiktionary varies greatly between languages: currently there are around 75 languages for which there exists more than 1000 word types, and 27 for which there exists more than 10,000 word </context>
</contexts>
<marker>Chesley, Vincent, Xu, Srihari, 2006</marker>
<rawString>P. Chesley, B. Vincent, L. Xu, and R.K. Srihari. 2006. Using verbs and adjectives to automatically classify blog sentiment. Training, 580(263):233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Clark</author>
</authors>
<title>Combining distributional and morphological information for part of speech induction.</title>
<date>2003</date>
<booktitle>In Proc. EACL.</booktitle>
<contexts>
<context position="5345" citStr="Clark, 2003" startWordPosition="801" endWordPosition="802">ality and multi-domain POS-taggers for a large number of languages can be obtained by standard and efficient models. The source code, the dictionary mappings and the trained models described in this work are available at http://code.google.com/p/ wikily-supervised-pos-tagger/. 2 Related Work The scarcity of labeled corpora for resource poor languages and the challenges of domain adaptation have led to several efforts to build systems for unsupervised POStagging. Several lines of research have addressed the fully unsupervised POS-tagging task: mutual information clustering (Brown et al., 1992; Clark, 2003) has been used to group words according to their distributional context. Using dimensionality reduction on word contexts followed by clustering has led to accuracy gains (Sch¨utze, 1995; Lamar et al., 2010). Sequence models, HMMs in particular, have been used to represent the probabilistic dependencies between consecutive tags. In these approaches, each observation corresponds to a particular word and each hidden state corresponds to a cluster. However, using maximum likelihood training for such models does not achieve good results (Clark, 2003): maximum likelihood training tends to result in </context>
</contexts>
<marker>Clark, 2003</marker>
<rawString>Alexander Clark. 2003. Combining distributional and morphological information for part of speech induction. In Proc. EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>600--609</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="3277" citStr="Das and Petrov (2011)" startWordPosition="482" endWordPosition="485">ionaries or parallel text, seems unavoidable at present. Early work on using tag dictionaries used a labeled corpus to extract all allowed word-tag pairs (Merialdo, 1994), which is quite an unrealistic scenario. More recent work has used a subset of the observed word-tag pairs and focused on generalizing dictionary entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007). Using corpusbased dictionaries greatly biases the test results, and gives little information about the capacity to generalize to different domains. Recent work by Das and Petrov (2011) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in parallel text. 1389 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1389–1398, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics The main idea is to rely on existing dictionaries for some languages (e.g. English) and use parallel data to build a dictionary in the desired language and extend the dictionary coverage using </context>
<context position="21632" citStr="Das and Petrov, 2011" startWordPosition="3523" endWordPosition="3526">ining the SHMM-ME in the standard supervised fashion, using 50 (50 Sent.), 100 (100 Sent.) and all sentences (All Sent.). As a lower bound we include the results for unsupervised systems: a regular HMM model trained with EM (Johnson, 2007) and an HMM model using a ME emission model trained using direct gradient (Berg-Kirkpatrick et al., 2010)3. 5.2 Bilingual baselines Finally, we also compare our system against a strong set of baselines that use bilingual data. These approaches build a dictionary by transferring labeled data from a resource rich language (English) to a resource poor language (Das and Petrov, 2011). We compare against two such methods. The first, projection, builds a dictionary by transferring the pos 3Values for these systems where taken from the D&amp;P paper. identical superset subset overlap disjoint 1394 tags from English to the new language using word alignments. The second method, D&amp;P, is the current state-of-the-art system, and runs label propagation on the dictionary resulting from the projected method. We note that both of these approaches are orthogonal to ours and could be used simultaneously with the Wiktionary. 5.3 Analysis Table 2 shows results for the different models across</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based projections. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 600–609, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Ding</author>
</authors>
<title>Weakly supervised part-of-speech tagging for chinese using label propagation. Master’s thesis,</title>
<date>2011</date>
<institution>University of Texas at Austin.</institution>
<contexts>
<context position="8704" citStr="Ding (2011)" startWordPosition="1333" endWordPosition="1334">of possible tag-tag transitions in the HMM via a integer program, hence discarding unlikely transitions that would confuse the model. Models can also be trained jointly using parallel corpora in sev1390 eral languages, exploiting the fact that different languages present different ambiguities (Snyder et al., 2008). The Wiktionary has been used extensively for other tasks such as domain specific information retrieval (M¨uller and Gurevych, 2009), ontology matching (Krizhanovsky and Lin, 2009), synonymy detection (Navarro et al., 2009), sentiment classification (Chesley et al., 2006). Recently, Ding (2011) used the Wiktionary to initialize an HMM for Chinese POS tagging combined with label propagation. 3 The Wiktionary and tagged corpora The Wiktionary1 is a collaborative project that aims to produce a free, large-scale multilingual dictionary. Its goal is to describe all words from all languages (currently more than 400) using definitions and descriptions in English. The coverage of the Wiktionary varies greatly between languages: currently there are around 75 languages for which there exists more than 1000 word types, and 27 for which there exists more than 10,000 word types. Nevertheless, th</context>
</contexts>
<marker>Ding, 2011</marker>
<rawString>Weiwei Ding. 2011. Weakly supervised part-of-speech tagging for chinese using label propagation. Master’s thesis, University of Texas at Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>Mark Johnson</author>
</authors>
<title>A comparison of Bayesian estimators for unsupervised hidden Markov model POS taggers. In</title>
<date>2008</date>
<booktitle>In Proc. EMNLP,</booktitle>
<pages>344--352</pages>
<publisher>ACL.</publisher>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="6253" citStr="Gao and Johnson, 2008" startWordPosition="936" endWordPosition="939">tic dependencies between consecutive tags. In these approaches, each observation corresponds to a particular word and each hidden state corresponds to a cluster. However, using maximum likelihood training for such models does not achieve good results (Clark, 2003): maximum likelihood training tends to result in very ambiguous distributions for common words, in contradiction with the rather sparse word-tag distribution. Several approaches have been proposed to mitigate this problem, including Bayesian approaches using an improper Dirichlet prior to favor sparse model parameters (Johnson, 2007; Gao and Johnson, 2008; Goldwater and Griffiths, 2007), or using the Posterior Regularization to penalize ambiguous posteriors distributions of tags given tokens (Grac¸a et al., 2009). Berg-Kirkpatrick et al. (2010) and Grac¸a et al. (2011) proposed replacing the multinomial emission distributions of standard HMMs by maximum entropy (ME) feature-based distributions. This allows the use of features to capture morphological information, and achieves very promising results. Despite these improvements, fully unsupervised systems require an oracle to map clusters to true tags and the performance still fails to be of pra</context>
</contexts>
<marker>Gao, Johnson, 2008</marker>
<rawString>Jianfeng Gao and Mark Johnson. 2008. A comparison of Bayesian estimators for unsupervised hidden Markov model POS taggers. In In Proc. EMNLP, pages 344– 352, Honolulu, Hawaii, October. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>T Griffiths</author>
</authors>
<title>A fully Bayesian approach to unsupervised part-of-speech tagging. In</title>
<date>2007</date>
<booktitle>In Proc. ACL,</booktitle>
<volume>45</volume>
<pages>744</pages>
<contexts>
<context position="3091" citStr="Goldwater and Griffiths, 2007" startWordPosition="453" endWordPosition="456">r behind supervised systems, and is not suitable for most applications (BergKirkpatrick et al., 2010; Grac¸a et al., 2011; Lee et al., 2010). Using additional information, in the form of tag dictionaries or parallel text, seems unavoidable at present. Early work on using tag dictionaries used a labeled corpus to extract all allowed word-tag pairs (Merialdo, 1994), which is quite an unrealistic scenario. More recent work has used a subset of the observed word-tag pairs and focused on generalizing dictionary entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007). Using corpusbased dictionaries greatly biases the test results, and gives little information about the capacity to generalize to different domains. Recent work by Das and Petrov (2011) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in parallel text. 1389 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1389–1398, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics The mai</context>
<context position="6285" citStr="Goldwater and Griffiths, 2007" startWordPosition="940" endWordPosition="943">n consecutive tags. In these approaches, each observation corresponds to a particular word and each hidden state corresponds to a cluster. However, using maximum likelihood training for such models does not achieve good results (Clark, 2003): maximum likelihood training tends to result in very ambiguous distributions for common words, in contradiction with the rather sparse word-tag distribution. Several approaches have been proposed to mitigate this problem, including Bayesian approaches using an improper Dirichlet prior to favor sparse model parameters (Johnson, 2007; Gao and Johnson, 2008; Goldwater and Griffiths, 2007), or using the Posterior Regularization to penalize ambiguous posteriors distributions of tags given tokens (Grac¸a et al., 2009). Berg-Kirkpatrick et al. (2010) and Grac¸a et al. (2011) proposed replacing the multinomial emission distributions of standard HMMs by maximum entropy (ME) feature-based distributions. This allows the use of features to capture morphological information, and achieves very promising results. Despite these improvements, fully unsupervised systems require an oracle to map clusters to true tags and the performance still fails to be of practical use. In this paper we fol</context>
<context position="7600" citStr="Goldwater and Griffiths, 2007" startWordPosition="1156" endWordPosition="1159">ach word type what POS tags it can take on (Merialdo, 1994). The task is then, for each word token in the corpus, to disambiguate between the possible POS tags. Even when using a tag dictionary, disambiguating from all possible tags is still a hard problem and the accuracy of these methods is still fall far behind their supervised counterparts. The scarcity of large, manually-constructed tag dictionaries led to the development of methods that try to generalize from a small dictionary with only a handful of entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007), however most previous works build the dictionary from the labeled corpus they learn on, which does not represent a realistic dictionary. In this paper, we argue that the Wiktionary can serve as an effective and much less biased tag dictionary. We note that most of the previous dictionary based approaches can be applied using the Wiktionary and would likely lead to similar accuracy increases that we show in this paper. For example, the work if Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMM via a integer program, hence discarding unlikely transitions tha</context>
</contexts>
<marker>Goldwater, Griffiths, 2007</marker>
<rawString>S. Goldwater and T. Griffiths. 2007. A fully Bayesian approach to unsupervised part-of-speech tagging. In In Proc. ACL, volume 45, page 744.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J V Grac¸a</author>
<author>K Ganchev</author>
<author>L Coheur</author>
<author>F Pereira</author>
<author>B Taskar</author>
</authors>
<title>Controlling complexity in part-ofspeech induction.</title>
<date>2011</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<volume>41</volume>
<issue>2</issue>
<marker>Grac¸a, Ganchev, Coheur, Pereira, Taskar, 2011</marker>
<rawString>J.V. Grac¸a, K. Ganchev, L. Coheur, F. Pereira, and B. Taskar. 2011. Controlling complexity in part-ofspeech induction. Journal ofArtificial Intelligence Research, 41(2):527–551.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Grac¸a</author>
<author>K Ganchev</author>
<author>F Pereira</author>
<author>B Taskar</author>
</authors>
<title>Parameter vs. posterior sparisty in latent variable models.</title>
<date>2009</date>
<booktitle>In Proc. NIPS.</booktitle>
<marker>Grac¸a, Ganchev, Pereira, Taskar, 2009</marker>
<rawString>J. Grac¸a, K. Ganchev, F. Pereira, and B. Taskar. 2009. Parameter vs. posterior sparisty in latent variable models. In Proc. NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Haghighi</author>
<author>D Klein</author>
</authors>
<title>Prototype-driven learning for sequence models.</title>
<date>2006</date>
<booktitle>In Proc. HTL-NAACL. ACL. M Johnson.</booktitle>
<contexts>
<context position="3030" citStr="Haghighi and Klein, 2006" startWordPosition="445" endWordPosition="448">the accuracy of unsupervised POS taggers still falls far behind supervised systems, and is not suitable for most applications (BergKirkpatrick et al., 2010; Grac¸a et al., 2011; Lee et al., 2010). Using additional information, in the form of tag dictionaries or parallel text, seems unavoidable at present. Early work on using tag dictionaries used a labeled corpus to extract all allowed word-tag pairs (Merialdo, 1994), which is quite an unrealistic scenario. More recent work has used a subset of the observed word-tag pairs and focused on generalizing dictionary entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007). Using corpusbased dictionaries greatly biases the test results, and gives little information about the capacity to generalize to different domains. Recent work by Das and Petrov (2011) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in parallel text. 1389 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1389–1398, Jeju Island, Korea, 12–14 July 2</context>
<context position="7539" citStr="Haghighi and Klein, 2006" startWordPosition="1148" endWordPosition="1151">here we rely on a prior tag dictionary indicating for each word type what POS tags it can take on (Merialdo, 1994). The task is then, for each word token in the corpus, to disambiguate between the possible POS tags. Even when using a tag dictionary, disambiguating from all possible tags is still a hard problem and the accuracy of these methods is still fall far behind their supervised counterparts. The scarcity of large, manually-constructed tag dictionaries led to the development of methods that try to generalize from a small dictionary with only a handful of entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007), however most previous works build the dictionary from the labeled corpus they learn on, which does not represent a realistic dictionary. In this paper, we argue that the Wiktionary can serve as an effective and much less biased tag dictionary. We note that most of the previous dictionary based approaches can be applied using the Wiktionary and would likely lead to similar accuracy increases that we show in this paper. For example, the work if Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMM via</context>
</contexts>
<marker>Haghighi, Klein, 2006</marker>
<rawString>A. Haghighi and D. Klein. 2006. Prototype-driven learning for sequence models. In Proc. HTL-NAACL. ACL. M Johnson. 2007. Why doesn’t EM find good HMM POS-taggers. In In Proc. EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AA Krizhanovsky</author>
<author>F Lin</author>
</authors>
<title>Related terms search based on wordnet/wiktionary and its application in ontology matching. Arxiv preprint arXiv:0907.2209.</title>
<date>2009</date>
<contexts>
<context position="8589" citStr="Krizhanovsky and Lin, 2009" startWordPosition="1315" endWordPosition="1318">ead to similar accuracy increases that we show in this paper. For example, the work if Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMM via a integer program, hence discarding unlikely transitions that would confuse the model. Models can also be trained jointly using parallel corpora in sev1390 eral languages, exploiting the fact that different languages present different ambiguities (Snyder et al., 2008). The Wiktionary has been used extensively for other tasks such as domain specific information retrieval (M¨uller and Gurevych, 2009), ontology matching (Krizhanovsky and Lin, 2009), synonymy detection (Navarro et al., 2009), sentiment classification (Chesley et al., 2006). Recently, Ding (2011) used the Wiktionary to initialize an HMM for Chinese POS tagging combined with label propagation. 3 The Wiktionary and tagged corpora The Wiktionary1 is a collaborative project that aims to produce a free, large-scale multilingual dictionary. Its goal is to describe all words from all languages (currently more than 400) using definitions and descriptions in English. The coverage of the Wiktionary varies greatly between languages: currently there are around 75 languages for which </context>
</contexts>
<marker>Krizhanovsky, Lin, 2009</marker>
<rawString>AA Krizhanovsky and F. Lin. 2009. Related terms search based on wordnet/wiktionary and its application in ontology matching. Arxiv preprint arXiv:0907.2209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lamar</author>
<author>Yariv Maron</author>
<author>Mark Johnson</author>
<author>Elie Bienenstock</author>
</authors>
<title>SVD and clustering for unsupervised POS tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Conference: Short Papers,</booktitle>
<pages>215--219</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="5551" citStr="Lamar et al., 2010" startWordPosition="830" endWordPosition="833">work are available at http://code.google.com/p/ wikily-supervised-pos-tagger/. 2 Related Work The scarcity of labeled corpora for resource poor languages and the challenges of domain adaptation have led to several efforts to build systems for unsupervised POStagging. Several lines of research have addressed the fully unsupervised POS-tagging task: mutual information clustering (Brown et al., 1992; Clark, 2003) has been used to group words according to their distributional context. Using dimensionality reduction on word contexts followed by clustering has led to accuracy gains (Sch¨utze, 1995; Lamar et al., 2010). Sequence models, HMMs in particular, have been used to represent the probabilistic dependencies between consecutive tags. In these approaches, each observation corresponds to a particular word and each hidden state corresponds to a cluster. However, using maximum likelihood training for such models does not achieve good results (Clark, 2003): maximum likelihood training tends to result in very ambiguous distributions for common words, in contradiction with the rather sparse word-tag distribution. Several approaches have been proposed to mitigate this problem, including Bayesian approaches us</context>
</contexts>
<marker>Lamar, Maron, Johnson, Bienenstock, 2010</marker>
<rawString>Michael Lamar, Yariv Maron, Mark Johnson, and Elie Bienenstock. 2010. SVD and clustering for unsupervised POS tagging. In Proceedings of the ACL 2010 Conference: Short Papers, pages 215–219, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoong Keok Lee</author>
<author>Aria Haghighi</author>
<author>Regina Barzilay</author>
</authors>
<title>Simple type-level unsupervised POS tagging.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>853--861</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="2601" citStr="Lee et al., 2010" startWordPosition="376" endWordPosition="379">2003), and are often not freely available or restricted to researchonly use. Furthermore, much of the annotated text is of limited genre, normally focusing on newswire or literary text. Performance of treebank-trained systems degrades significantly when applied to new domains (Blitzer et al., 2006). Unsupervised induction of POS taggers offers the possibility of avoiding costly annotation, but despite recent progress, the accuracy of unsupervised POS taggers still falls far behind supervised systems, and is not suitable for most applications (BergKirkpatrick et al., 2010; Grac¸a et al., 2011; Lee et al., 2010). Using additional information, in the form of tag dictionaries or parallel text, seems unavoidable at present. Early work on using tag dictionaries used a labeled corpus to extract all allowed word-tag pairs (Merialdo, 1994), which is quite an unrealistic scenario. More recent work has used a subset of the observed word-tag pairs and focused on generalizing dictionary entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007). Using corpusbased dictionaries greatly biases the test results, and gives little information about the capac</context>
</contexts>
<marker>Lee, Haghighi, Barzilay, 2010</marker>
<rawString>Yoong Keok Lee, Aria Haghighi, and Regina Barzilay. 2010. Simple type-level unsupervised POS tagging. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 853– 861, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M P Marcus</author>
<author>M A Marcinkiewicz</author>
<author>B Santorini</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational linguistics,</title>
<date>1993</date>
<contexts>
<context position="1859" citStr="Marcus et al., 1993" startWordPosition="258" endWordPosition="262"> trained using fully supervised Penn Treebank. 1 Introduction Part-of-speech categories are elementary building blocks that play an important role in many natural language processing tasks, from machine translation to information extraction. Supervised learning of taggers from POS-annotated training text is a well-studied task, with several methods achieving near-human tagging accuracy (Ratnaparkhi, 1996; Toutanova et al., 2003; Shen et al., 2007). However, while English and a handful of other languages are fortunate enough to have comprehensive POSannotated corpora such as the Penn Treebank (Marcus et al., 1993), most of the world’s languages have no labeled corpora. The annotated corpora that do exist were costly to build (Abeill´e, 2003), and are often not freely available or restricted to researchonly use. Furthermore, much of the annotated text is of limited genre, normally focusing on newswire or literary text. Performance of treebank-trained systems degrades significantly when applied to new domains (Blitzer et al., 2006). Unsupervised induction of POS taggers offers the possibility of avoiding costly annotation, but despite recent progress, the accuracy of unsupervised POS taggers still falls </context>
</contexts>
<marker>Marcus, Marcinkiewicz, Santorini, 1993</marker>
<rawString>M.P. Marcus, M.A. Marcinkiewicz, and B. Santorini. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Merialdo</author>
</authors>
<title>Tagging English text with a probabilistic model.</title>
<date>1994</date>
<journal>Computational linguistics,</journal>
<volume>20</volume>
<issue>2</issue>
<pages>171</pages>
<contexts>
<context position="2826" citStr="Merialdo, 1994" startWordPosition="413" endWordPosition="414">egrades significantly when applied to new domains (Blitzer et al., 2006). Unsupervised induction of POS taggers offers the possibility of avoiding costly annotation, but despite recent progress, the accuracy of unsupervised POS taggers still falls far behind supervised systems, and is not suitable for most applications (BergKirkpatrick et al., 2010; Grac¸a et al., 2011; Lee et al., 2010). Using additional information, in the form of tag dictionaries or parallel text, seems unavoidable at present. Early work on using tag dictionaries used a labeled corpus to extract all allowed word-tag pairs (Merialdo, 1994), which is quite an unrealistic scenario. More recent work has used a subset of the observed word-tag pairs and focused on generalizing dictionary entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007). Using corpusbased dictionaries greatly biases the test results, and gives little information about the capacity to generalize to different domains. Recent work by Das and Petrov (2011) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in par</context>
<context position="7029" citStr="Merialdo, 1994" startWordPosition="1063" endWordPosition="1065">. Berg-Kirkpatrick et al. (2010) and Grac¸a et al. (2011) proposed replacing the multinomial emission distributions of standard HMMs by maximum entropy (ME) feature-based distributions. This allows the use of features to capture morphological information, and achieves very promising results. Despite these improvements, fully unsupervised systems require an oracle to map clusters to true tags and the performance still fails to be of practical use. In this paper we follow a different line of work where we rely on a prior tag dictionary indicating for each word type what POS tags it can take on (Merialdo, 1994). The task is then, for each word token in the corpus, to disambiguate between the possible POS tags. Even when using a tag dictionary, disambiguating from all possible tags is still a hard problem and the accuracy of these methods is still fall far behind their supervised counterparts. The scarcity of large, manually-constructed tag dictionaries led to the development of methods that try to generalize from a small dictionary with only a handful of entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007), however most previous works</context>
</contexts>
<marker>Merialdo, 1994</marker>
<rawString>B. Merialdo. 1994. Tagging English text with a probabilistic model. Computational linguistics, 20(2):155– 171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C M¨uller</author>
<author>I Gurevych</author>
</authors>
<title>Using wikipedia and wiktionary in domain-specific information retrieval. Evaluating Systems for Multilingual and Multimodal Information Access,</title>
<date>2009</date>
<pages>219--226</pages>
<marker>M¨uller, Gurevych, 2009</marker>
<rawString>C. M¨uller and I. Gurevych. 2009. Using wikipedia and wiktionary in domain-specific information retrieval. Evaluating Systems for Multilingual and Multimodal Information Access, pages 219–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Navarro</author>
<author>F Sajous</author>
<author>B Gaume</author>
<author>L Pr´evot</author>
<author>H ShuKai</author>
<author>K Tzu-Yi</author>
<author>P Magistry</author>
<author>H Chu-Ren</author>
</authors>
<title>Wiktionary and nlp: Improving synonymy networks.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Workshop on The People’s Web Meets NLP: Collaboratively Constructed Semantic Resources,</booktitle>
<pages>pages</pages>
<marker>Navarro, Sajous, Gaume, Pr´evot, ShuKai, Tzu-Yi, Magistry, Chu-Ren, 2009</marker>
<rawString>E. Navarro, F. Sajous, B. Gaume, L. Pr´evot, H. ShuKai, K. Tzu-Yi, P. Magistry, and H. Chu-Ren. 2009. Wiktionary and nlp: Improving synonymy networks. In Proceedings of the 2009 Workshop on The People’s Web Meets NLP: Collaboratively Constructed Semantic Resources, pages 19–27. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>The conll</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007. Association for Computational Linguistics.</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The conll 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nocedal</author>
<author>Stephen J Wright</author>
</authors>
<title>Numerical optimization.</title>
<date>1999</date>
<publisher>Springer.</publisher>
<contexts>
<context position="19606" citStr="Nocedal and Wright, 1999" startWordPosition="3187" endWordPosition="3190">ls has been applied before in different domains (Chen, 2003), as well as in POS induction (Berg-Kirkpatrick et al., 2010; Grac¸a et al., 2011). We use the EM algorithm to learn the models, restricting the tags of each word to those specified by the dictionary. For each tag y, the observations probabilities po(x |y) were initialized randomly for every word type that allows tag y according to the Wiktionary and zero otherwise. For the M-step in max-ent models, there is no closed form solution so we need to solve an unconstrained optimization problem. We use L-BFGS with Wolfe’s rule line search (Nocedal and Wright, 1999). We found that EM achieved higher accuracy across languages compared to direct gradient approach (BergKirkpatrick et al., 2010). 5 Results We evaluate the accuracy of taggers trained using the Wiktionary using the 4 different models: A first order Hidden Markov Model (HMM), a second order Hidden Markov Model (SHMM), a first order Hidden Markov Model with Maximum Entropy emission models (HMM-ME) and a second order Hidden Markov Model with Maximum Entropy emission models (SHMM-ME). For each model we ran EM for 50 iterations, which was sufficient for convergence of the likelihood. Following prev</context>
</contexts>
<marker>Nocedal, Wright, 1999</marker>
<rawString>J. Nocedal and Stephen J. Wright. 1999. Numerical optimization. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A universal part-of-speech tagset. Arxiv preprint ArXiv:1104.2086.</title>
<date>2011</date>
<contexts>
<context position="10176" citStr="Petrov et al., 2011" startWordPosition="1569" endWordPosition="1572">atural incentives for users to contribute missing entries and expand this communal resource akin to Wikipedia. As with Wikipedia, the questions of accuracy, bias, consistency across languages, and selective coverage are paramount. In this section, we explore these concerns by comparing Wiktionary to dictionaries derived from tagged corpora. 3.1 Labeled corpora and Universal tags We collected part-of-speech tagged corpora for 9 languages, from CoNLL-X and CoNLL-2007 shared tasks on dependency parsing (Buchholz and Marsi, 2006; Nivre et al., 2007). In this work we use the Universal POS tag set (Petrov et al., 2011) that defines 12 universal categories with a relatively stable functional definition across languages. These categories include NOUN, VERB, ADJ = adjective, ADV = adverb, NUM = number, ADP = adposition, CONJ = conjunction, DET = determiner, PRON = 1http://www.wiktionary.org/ All 9Langs Accuracy Figure 1: Growth of the Wiktionary over the last three years, showing total number of entries for all languages and for the 9 languages we consider (left axis). We also show the corresponding increase in average accuracy (right axis) achieved by our model across the 9 languages (see details below). pron</context>
</contexts>
<marker>Petrov, Das, McDonald, 2011</marker>
<rawString>S. Petrov, D. Das, and R. McDonald. 2011. A universal part-of-speech tagset. Arxiv preprint ArXiv:1104.2086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proc. EMNLP.</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="1646" citStr="Ratnaparkhi, 1996" startWordPosition="224" endWordPosition="225">uracy that significantly exceeds best unsupervised and parallel text methods. We achieve highest accuracy reported for several languages and show that our approach yields better out-of-domain taggers than those trained using fully supervised Penn Treebank. 1 Introduction Part-of-speech categories are elementary building blocks that play an important role in many natural language processing tasks, from machine translation to information extraction. Supervised learning of taggers from POS-annotated training text is a well-studied task, with several methods achieving near-human tagging accuracy (Ratnaparkhi, 1996; Toutanova et al., 2003; Shen et al., 2007). However, while English and a handful of other languages are fortunate enough to have comprehensive POSannotated corpora such as the Penn Treebank (Marcus et al., 1993), most of the world’s languages have no labeled corpora. The annotated corpora that do exist were costly to build (Abeill´e, 2003), and are often not freely available or restricted to researchonly use. Furthermore, much of the annotated text is of limited genre, normally focusing on newswire or literary text. Performance of treebank-trained systems degrades significantly when applied </context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>A. Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proc. EMNLP. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Minimized models for unsupervised part-of-speech tagging. In</title>
<date>2009</date>
<booktitle>In Proc. ACL.</booktitle>
<contexts>
<context position="8071" citStr="Ravi and Knight (2009)" startWordPosition="1237" endWordPosition="1240">ictionary with only a handful of entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007), however most previous works build the dictionary from the labeled corpus they learn on, which does not represent a realistic dictionary. In this paper, we argue that the Wiktionary can serve as an effective and much less biased tag dictionary. We note that most of the previous dictionary based approaches can be applied using the Wiktionary and would likely lead to similar accuracy increases that we show in this paper. For example, the work if Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMM via a integer program, hence discarding unlikely transitions that would confuse the model. Models can also be trained jointly using parallel corpora in sev1390 eral languages, exploiting the fact that different languages present different ambiguities (Snyder et al., 2008). The Wiktionary has been used extensively for other tasks such as domain specific information retrieval (M¨uller and Gurevych, 2009), ontology matching (Krizhanovsky and Lin, 2009), synonymy detection (Navarro et al., 2009), sentiment classification (Chesley et </context>
</contexts>
<marker>Ravi, Knight, 2009</marker>
<rawString>Sujith Ravi and Kevin Knight. 2009. Minimized models for unsupervised part-of-speech tagging. In In Proc. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sch¨utze</author>
</authors>
<title>Distributional part-of-speech tagging.</title>
<date>1995</date>
<booktitle>In Proc. EACL,</booktitle>
<pages>141--148</pages>
<marker>Sch¨utze, 1995</marker>
<rawString>H. Sch¨utze. 1995. Distributional part-of-speech tagging. In Proc. EACL, pages 141–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Giorgio Satta</author>
<author>Aravind Joshi</author>
</authors>
<title>Guided learning for bidirectional sequence classification.</title>
<date>2007</date>
<booktitle>In Proc. ACL,</booktitle>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1690" citStr="Shen et al., 2007" startWordPosition="230" endWordPosition="233">ervised and parallel text methods. We achieve highest accuracy reported for several languages and show that our approach yields better out-of-domain taggers than those trained using fully supervised Penn Treebank. 1 Introduction Part-of-speech categories are elementary building blocks that play an important role in many natural language processing tasks, from machine translation to information extraction. Supervised learning of taggers from POS-annotated training text is a well-studied task, with several methods achieving near-human tagging accuracy (Ratnaparkhi, 1996; Toutanova et al., 2003; Shen et al., 2007). However, while English and a handful of other languages are fortunate enough to have comprehensive POSannotated corpora such as the Penn Treebank (Marcus et al., 1993), most of the world’s languages have no labeled corpora. The annotated corpora that do exist were costly to build (Abeill´e, 2003), and are often not freely available or restricted to researchonly use. Furthermore, much of the annotated text is of limited genre, normally focusing on newswire or literary text. Performance of treebank-trained systems degrades significantly when applied to new domains (Blitzer et al., 2006). Unsup</context>
</contexts>
<marker>Shen, Satta, Joshi, 2007</marker>
<rawString>Libin Shen, Giorgio Satta, and Aravind Joshi. 2007. Guided learning for bidirectional sequence classification. In Proc. ACL, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Smith</author>
<author>J Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proc. ACL.</booktitle>
<publisher>ACL.</publisher>
<contexts>
<context position="3004" citStr="Smith and Eisner, 2005" startWordPosition="441" endWordPosition="444">espite recent progress, the accuracy of unsupervised POS taggers still falls far behind supervised systems, and is not suitable for most applications (BergKirkpatrick et al., 2010; Grac¸a et al., 2011; Lee et al., 2010). Using additional information, in the form of tag dictionaries or parallel text, seems unavoidable at present. Early work on using tag dictionaries used a labeled corpus to extract all allowed word-tag pairs (Merialdo, 1994), which is quite an unrealistic scenario. More recent work has used a subset of the observed word-tag pairs and focused on generalizing dictionary entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007). Using corpusbased dictionaries greatly biases the test results, and gives little information about the capacity to generalize to different domains. Recent work by Das and Petrov (2011) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in parallel text. 1389 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1389–1398, Jeju I</context>
<context position="7513" citStr="Smith and Eisner, 2005" startWordPosition="1144" endWordPosition="1147">different line of work where we rely on a prior tag dictionary indicating for each word type what POS tags it can take on (Merialdo, 1994). The task is then, for each word token in the corpus, to disambiguate between the possible POS tags. Even when using a tag dictionary, disambiguating from all possible tags is still a hard problem and the accuracy of these methods is still fall far behind their supervised counterparts. The scarcity of large, manually-constructed tag dictionaries led to the development of methods that try to generalize from a small dictionary with only a handful of entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007), however most previous works build the dictionary from the labeled corpus they learn on, which does not represent a realistic dictionary. In this paper, we argue that the Wiktionary can serve as an effective and much less biased tag dictionary. We note that most of the previous dictionary based approaches can be applied using the Wiktionary and would likely lead to similar accuracy increases that we show in this paper. For example, the work if Ravi and Knight (2009) minimizes the number of possible tag-tag </context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>N. Smith and J. Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In Proc. ACL. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Snyder</author>
<author>T Naseem</author>
<author>J Eisenstein</author>
<author>R Barzilay</author>
</authors>
<title>Unsupervised multilingual learning for POS tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1041--1050</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8408" citStr="Snyder et al., 2008" startWordPosition="1290" endWordPosition="1293">erve as an effective and much less biased tag dictionary. We note that most of the previous dictionary based approaches can be applied using the Wiktionary and would likely lead to similar accuracy increases that we show in this paper. For example, the work if Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMM via a integer program, hence discarding unlikely transitions that would confuse the model. Models can also be trained jointly using parallel corpora in sev1390 eral languages, exploiting the fact that different languages present different ambiguities (Snyder et al., 2008). The Wiktionary has been used extensively for other tasks such as domain specific information retrieval (M¨uller and Gurevych, 2009), ontology matching (Krizhanovsky and Lin, 2009), synonymy detection (Navarro et al., 2009), sentiment classification (Chesley et al., 2006). Recently, Ding (2011) used the Wiktionary to initialize an HMM for Chinese POS tagging combined with label propagation. 3 The Wiktionary and tagged corpora The Wiktionary1 is a collaborative project that aims to produce a free, large-scale multilingual dictionary. Its goal is to describe all words from all languages (curren</context>
</contexts>
<marker>Snyder, Naseem, Eisenstein, Barzilay, 2008</marker>
<rawString>B. Snyder, T. Naseem, J. Eisenstein, and R. Barzilay. 2008. Unsupervised multilingual learning for POS tagging. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1041–1050. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>M Johnson</author>
</authors>
<title>A Bayesian LDAbased model for semi-supervised part-of-speech tagging.</title>
<date>2007</date>
<booktitle>In Proc. NIPS,</booktitle>
<pages>20</pages>
<contexts>
<context position="3059" citStr="Toutanova and Johnson, 2007" startWordPosition="449" endWordPosition="452">ed POS taggers still falls far behind supervised systems, and is not suitable for most applications (BergKirkpatrick et al., 2010; Grac¸a et al., 2011; Lee et al., 2010). Using additional information, in the form of tag dictionaries or parallel text, seems unavoidable at present. Early work on using tag dictionaries used a labeled corpus to extract all allowed word-tag pairs (Merialdo, 1994), which is quite an unrealistic scenario. More recent work has used a subset of the observed word-tag pairs and focused on generalizing dictionary entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007). Using corpusbased dictionaries greatly biases the test results, and gives little information about the capacity to generalize to different domains. Recent work by Das and Petrov (2011) builds a dictionary for a particular language by transferring annotated data from a resource-rich language through the use of word alignments in parallel text. 1389 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1389–1398, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for C</context>
<context position="7568" citStr="Toutanova and Johnson, 2007" startWordPosition="1152" endWordPosition="1155">g dictionary indicating for each word type what POS tags it can take on (Merialdo, 1994). The task is then, for each word token in the corpus, to disambiguate between the possible POS tags. Even when using a tag dictionary, disambiguating from all possible tags is still a hard problem and the accuracy of these methods is still fall far behind their supervised counterparts. The scarcity of large, manually-constructed tag dictionaries led to the development of methods that try to generalize from a small dictionary with only a handful of entries (Smith and Eisner, 2005; Haghighi and Klein, 2006; Toutanova and Johnson, 2007; Goldwater and Griffiths, 2007), however most previous works build the dictionary from the labeled corpus they learn on, which does not represent a realistic dictionary. In this paper, we argue that the Wiktionary can serve as an effective and much less biased tag dictionary. We note that most of the previous dictionary based approaches can be applied using the Wiktionary and would likely lead to similar accuracy increases that we show in this paper. For example, the work if Ravi and Knight (2009) minimizes the number of possible tag-tag transitions in the HMM via a integer program, hence dis</context>
</contexts>
<marker>Toutanova, Johnson, 2007</marker>
<rawString>K. Toutanova and M. Johnson. 2007. A Bayesian LDAbased model for semi-supervised part-of-speech tagging. In Proc. NIPS, 20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Toutanova</author>
<author>D Klein</author>
<author>C Manning</author>
<author>Y Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>In Proc. HLT-NAACL.</booktitle>
<contexts>
<context position="1670" citStr="Toutanova et al., 2003" startWordPosition="226" endWordPosition="229">antly exceeds best unsupervised and parallel text methods. We achieve highest accuracy reported for several languages and show that our approach yields better out-of-domain taggers than those trained using fully supervised Penn Treebank. 1 Introduction Part-of-speech categories are elementary building blocks that play an important role in many natural language processing tasks, from machine translation to information extraction. Supervised learning of taggers from POS-annotated training text is a well-studied task, with several methods achieving near-human tagging accuracy (Ratnaparkhi, 1996; Toutanova et al., 2003; Shen et al., 2007). However, while English and a handful of other languages are fortunate enough to have comprehensive POSannotated corpora such as the Penn Treebank (Marcus et al., 1993), most of the world’s languages have no labeled corpora. The annotated corpora that do exist were costly to build (Abeill´e, 2003), and are often not freely available or restricted to researchonly use. Furthermore, much of the annotated text is of limited genre, normally focusing on newswire or literary text. Performance of treebank-trained systems degrades significantly when applied to new domains (Blitzer </context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>K. Toutanova, D. Klein, C. Manning, and Y. Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In In Proc. HLT-NAACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>