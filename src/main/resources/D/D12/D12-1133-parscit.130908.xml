<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000011">
<title confidence="0.9996895">
A Transition-Based System for Joint Part-of-Speech Tagging
and Labeled Non-Projective Dependency Parsing
</title>
<author confidence="0.994717">
Bernd Bohnet
</author>
<affiliation confidence="0.926398">
Institute for Natural Language Processing
University Stuttgart
</affiliation>
<email confidence="0.987543">
bohnet@ims.uni-stuttgart.de
</email>
<author confidence="0.987685">
Joakim Nivre
</author>
<affiliation confidence="0.998769">
Department of Linguistics and Philology
Uppsala University
</affiliation>
<email confidence="0.993869">
joakim.nivre@lingfil.uu.se
</email>
<sectionHeader confidence="0.995595" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99952025">
Most current dependency parsers presuppose
that input words have been morphologically
disambiguated using a part-of-speech tagger
before parsing begins. We present a transition-
based system for joint part-of-speech tagging
and labeled dependency parsing with non-
projective trees. Experimental evaluation on
Chinese, Czech, English and German shows
consistent improvements in both tagging and
parsing accuracy when compared to a pipeline
system, which lead to improved state-of-the-
art results for all languages.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999957830188679">
Dependency-based syntactic parsing has been the
focus of intense research efforts during the last
decade, and the state of the art today is represent-
ed by globally normalized discriminative models
that are induced using structured learning. Graph-
based models parameterize the parsing problem by
the structure of the dependency graph and normally
use dynamic programming for inference (McDonald
et al., 2005; McDonald and Pereira, 2006; Carreras,
2007; Koo and Collins, 2010; Bohnet, 2010), but
other inference methods have been explored espe-
cially for non-projective parsing (Riedel and Clarke,
2006; Smith and Eisner, 2008; Martins et al., 2009;
Martins et al., 2010; Koo et al., 2010). Transition-
based models parameterize the problem by elemen-
tary parsing actions and typically use incremental
beam search (Titov and Henderson, 2007; Zhang
and Clark, 2008; Zhang and Clark, 2011). Despite
notable differences in model structure, graph-based
and transition-based parsers both give state-of-the-
art accuracy with proper feature selection and opti-
mization (Koo and Collins, 2010; Zhang and Nivre,
2011; Bohnet, 2011).
It is noteworthy, however, that almost all depen-
dency parsers presuppose that the words of an input
sentence have been morphologically disambiguated
using (at least) a part-of-speech tagger. This is in s-
tark contrast to the best parsers based on PCFG mod-
els, such as the Brown parser (Charniak and John-
son, 2005) and the Berkeley parser (Petrov et al.,
2006; Petrov and Klein, 2007), which not only can
perform their own part-of-speech tagging but nor-
mally give better parsing accuracy when they are al-
lowed to do so. This suggests that joint models for
tagging and parsing might improve accuracy also in
the case of dependency parsing.
It has been argued that joint morphological and
syntactic disambiguation is especially important for
richly inflected languages, where there is consid-
erable interaction between morphology and syntax
such that neither can be fully disambiguated with-
out considering the other. Thus, Lee et al. (2011)
show that a discriminative model for joint morpho-
logical disambiguation and dependency parsing out-
performs a pipeline model in experiments on Latin,
Ancient Greek, Czech and Hungarian. However, Li
et al. (2011) and Hatori et al. (2011) report improve-
ments with a joint model also for Chinese, which
is not a richly inflected language but is nevertheless
rich in part-of-speech ambiguities.
In this paper, we present a transition-based mod-
el for joint part-of-speech tagging and labeled de-
pendency parsing with non-projective trees. Exper-
</bodyText>
<page confidence="0.908733">
1455
</page>
<note confidence="0.762568">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1455–1465, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999298777777778">
iments show that joint modeling improves both tag-
ging and parsing accuracy, leading to state-of-the-art
accuracy for richly inflected languages like Czech
and German as well as more configurational lan-
guages like Chinese and English. To our knowledge,
this is the first joint system that performs labeled de-
pendency parsing. It is also the first joint system that
achieves state-of-the-art accuracy for non-projective
dependency parsing.
</bodyText>
<sectionHeader confidence="0.765538" genericHeader="introduction">
2 Transition-Based Tagging and Parsing
</sectionHeader>
<bodyText confidence="0.999929619047619">
Transition-based dependency parsing was pioneered
by Yamada and Matsumoto (2003) and Nivre et al.
(2004), who used classifiers trained to predict indi-
vidual actions of a deterministic shift-reduce parser.
Recent research has shown that better accuracy can
be achieved by using beam search and optimizing
models on the entire sequence of decisions needed
to parse a sentence instead of single actions (Zhang
and Clark, 2008; Huang and Sagae, 2010; Zhang
and Clark, 2011; Zhang and Nivre, 2011; Bohnet,
2011). In addition, a number of different transition
systems have been proposed, in particular for deal-
ing with non-projective dependencies, which were
beyond the scope of early systems (Attardi, 2006;
Nivre, 2007; Nivre, 2009; Titov et al., 2009).
In this section, we start by defining a transition
system for joint tagging and parsing based on the
non-projective transition system proposed in Nivre
(2009). We then show how to perform beam search
and structured online learning with this model, and
conclude by discussing feature representations.
</bodyText>
<subsectionHeader confidence="0.99242">
2.1 Transition System
</subsectionHeader>
<bodyText confidence="0.996729">
Given a set P of part-of-speech tags and a set D
of dependency labels, a tagged dependency tree for
a sentence x = w1, ... , wn is a directed tree T =
(Vx, A) with labeling functions 7r and 6 such that:
</bodyText>
<listItem confidence="0.9753898">
1. Vx = 10, 1, ... , n} is a set of nodes,
2. A C Vx x Vx is a set of arcs,
3. 7r : Vx —* P is a labeling function for nodes,
4. 6 : A —* D is a labeling function for arcs,
5. 0 is the root of the tree.
</listItem>
<bodyText confidence="0.995052466666667">
The set Vx of nodes is the set of positive integers up
to and including n, each corresponding to the lin-
ear position of a word in the sentence, plus an extra
artificial root node 0. The set A of arcs is a set of
pairs (i, j), where i is the head node and j is the
dependent node. The functions 7r and 6 assign a u-
nique part-of-speech label to each node/word and a
unique dependency label to each arc, respectively.
This notion of dependency tree differs from the s-
tandard definition only by including part-of-speech
labels as well as dependency labels (K¨ubler et al.,
2009).
Following Nivre (2008), we define a transition
system for dependency parsing as a quadruple 5 =
(C, T, cs, Ct), where
</bodyText>
<listItem confidence="0.980390666666667">
1. C is a set of configurations,
2. T is a set of transitions, each of which is a (par-
tial) function t : C —* C,
3. cs is an initialization function, mapping a sen-
tence x to a configuration c E C,
4. Ct C C is a set of terminal configurations.
</listItem>
<bodyText confidence="0.8845605">
A transition sequence for a sentence x in 5 is a
sequence of configuration-transition pairs C0,m =
</bodyText>
<equation confidence="0.536515">
[(c0, t0), (c1, t1), ... , (cm, tm)] where c0 = cs(x),
tm(cm) E Ct and ti(ci) = ci+1 (0 &lt; i &lt; m).1
</equation>
<bodyText confidence="0.999670545454546">
In this paper, we take the set C of configurations
to be the set of all 5-tuples c = (E, B, A, 7r, 6) such
that E (the stack) and B (the buffer) are disjoin-
t sublists of the nodes Vx of some sentence x, A
is a set of dependency arcs over Vx, and 7r and 6
are labeling functions as defined above. We take the
initial configuration for a sentence x = w1, ... , wn
to be cs(x) = ([0], [1, ... , n], 11, 1, 1), where L
is the function that is undefined for all arguments,
and we take the set Ct of terminal configurations
to be the set of all configurations of the form c =
([0], [ ], A, 7r, 6) (for any A, 7r and 6). The tagged de-
pendency tree defined for x by c = (E, B, A, 7r, 6)
is the tree (Vx, A) with labeling functions 7r and 6,
which we write TREE(x, c).
The set T of transitions is shown in Figure 1. The
LEFT-ARCd and RIGHT-ARCd transitions both add
an arc (with dependency label d) between the two
nodes on top of the stack and replaces these nodes
by the head node of the new arc (which is the right-
most node for LEFT-ARCd and the leftmost node for
RIGHT-ARCd). The SHIFTp transition extracts the
</bodyText>
<footnote confidence="0.9423615">
1This definition of transition sequence differs from that of
Nivre (2008) but is equivalent and suits our presentation better.
</footnote>
<page confidence="0.98298">
1456
</page>
<subsectionHeader confidence="0.391142">
Transition Condition
</subsectionHeader>
<equation confidence="0.81189875">
LEFT-ARCd ([σ|i, j], B, A, π, δ) ⇒ ([σ|j], B, A∪{(j, i)}, π, δ[(j, i) → d]) i 7� 0
RIGHT-ARCd ([σ|i, j], B, A, π, δ) ⇒ ([σ|i], B, A∪{(i, j)}, π, δ[(i, j) → d])
SHIFTp (σ, [i|β], A, π, δ) ⇒ ([σ|i], β, A, π[i → p], δ)
SWAP ([σ|i, j], β, A, π, δ) ⇒ ([σ|j], [i|β], A, π, δ) 0 &lt; i &lt; j
</equation>
<figureCaption confidence="0.681712">
Figure 1: Transitions for joint tagging and dependency parsing extending the system of Nivre (2009). The stack E is
represented as a list with its head to the right (and tail σ) and the buffer B as a list with its head to the left (and tail β).
The notation f[a → b] is used to denote the function that is exactly like f except that it maps a to b.
</figureCaption>
<bodyText confidence="0.999941529411765">
first node in the buffer, pushes it onto the stack and
labels it with the part-of-speech tag p. The SWAP
transition extracts the second topmost node from the
stack and moves it back to the buffer, subject to the
condition that the two top nodes on the stack are still
in the order given by the sentence.
Except for the addition of a tag parameter p to
the SHIFT transition, this is equivalent to the sys-
tem described in Nivre (2009), which thanks to the
SWAP transition can handle arbitrary non-projective
trees. The soundness and completeness results giv-
en in that paper trivially carry over to the new sys-
tem. The only thing to note is that, before a terminal
configuration can be reached, every word has to be
pushed onto the stack in a SHIFTp transition, which
ensures that every node/word in the output tree will
be tagged.
</bodyText>
<subsectionHeader confidence="0.987767">
2.2 Inference and Learning
</subsectionHeader>
<bodyText confidence="0.999945235294118">
While early transition-based parsers generally used
greedy best-first inference and locally trained clas-
sifiers, recent work has shown that higher accura-
cy can be obtained using beam search and global
structure learning to mitigate error propagation. In
particular, it seems that the globally learned models
can exploit a much richer feature space than local-
ly trained classifiers, as shown by Zhang and Nivre
(2011). Since joint tagging and parsing increases the
size of the search space and is likely to require nov-
el features, we use beam search in combination with
structured perceptron learning.
The beam search algorithm used to derive the best
parse y for a sentence x is outlined in Figure 2. In
addition to the sentence x, it takes as input a weight
vector w corresponding to a linear model for scor-
ing transitions out of configurations and two prun-
</bodyText>
<equation confidence="0.95286625">
PARSE(x, w, b1, b2)
1 h0.c ← cs(x)
2 h0.s ← 0.0
3 h0.f ← {0.0}d�-(w)
</equation>
<figure confidence="0.847661923076923">
4 BEAM ← [h0]
5 while ∃h ∈ BEAM: h.c ∈6 Ct
6 TMP ← [ ]
7 foreach h ∈ BEAM
8 foreach t ∈ T : PERMISSIBLE(h.c, t)
9 h.f ← h.f + f(h.c, t)
10 h.s ← h.s + f(h.c, t) · w
11 h.c ← t(h.c)
12 TMP ← INSERT(h, TMP)
13 BEAM ← PRUNE(TMP, b1, b2)
14 h ← TOP(BEAM)
15 y ← TREE(x, h.c)
16 return y
</figure>
<figureCaption confidence="0.8103665">
Figure 2: Beam search algorithm for joint tagging and de-
pendency parsing of input sentence x with weight vector
</figureCaption>
<bodyText confidence="0.9646378">
w and beam parameters b1 and b2. The symbols h.c, h.s
and h.f denote, respectively, the configuration, score and
feature representation of a hypothesis h; h.c.A denotes
the arc set of h.c.
ing parameters b1 and b2. A parse hypothesis h is
represented by a configuration h.c, a score h.s and
a feature vector h.f for the transition sequence up to
h.c. Hypotheses are stored in the list BEAM, which
is sorted by descending scores and initialized to hold
the hypothesis h0 corresponding to the initial con-
figuration cs(x) with score 0.0 and all features set
to 0.0 (lines 1–4). In the main loop (lines 5–13), a
set of new hypotheses is derived and stored in the
list TMP, which is finally pruned and assigned as
the new value of BEAM. The main loop terminates
</bodyText>
<page confidence="0.989799">
1457
</page>
<bodyText confidence="0.999471888888889">
when all hypotheses in BEAM contain terminal con-
figurations, and the dependency tree extracted from
the top scoring hypothesis is returned (lines 14–16).
The set of new hypotheses is created in two nest-
ed loops (lines 7–12), where every hypothesis h in
BEAM is updated using every permissible transition
t for the configuration h.c. The feature representa-
tion of the new hypothesis is obtained by adding the
feature vector f(t, h.c) for the current configuration-
transition pair to the feature vector of the old hy-
pothesis (line 9). Similarly, the score of the new
hypothesis is the sum of the score f(t, h.c) · w of
the current configuration-transition pair and the s-
core of the old hypothesis (line 10). The feature
representation/score of a complete parse y for x
with transition sequence C0,m is thus the sum of the
feature representations/scores of the configuration-
transition pairs in C0,m:
</bodyText>
<equation confidence="0.9965725">
f(x, y) = � f(c, t)
(c,t)EC�,�
s(x, y) = f(c, t) · w
(c,t)EC�,�
</equation>
<bodyText confidence="0.999963813953489">
Finally, the configuration of the new hypothesis is
obtained by evaluating t(h.c) (line 11). The new hy-
pothesis is then inserted into TMP in score-sorted or-
der (line 12).
The pruning parameters b1 and b2 determine the
number of hypotheses allowed in the beam and at
the same time control the tradeoff between syntactic
and morphological ambiguity. First, we extract the
b1 highest scoring hypotheses with distinct depen-
dency trees. Then we extract the b2 highest scoring
remaining hypotheses, which will typically be tag-
ging variants of dependency trees that are already in
the beam. In this way, we prevent the beam from
getting filled up with too many tagging variants of
the same dependency tree, which was found to be
harmful in preliminary experiments.
One final thing to note about the inference algo-
rithm is that the notion of permissibility for a transi-
tion t out of a configuration c can be used to capture
not only formal constraints on transitions – such as
the fact that it is impossible to perform a SHIFTp
transition with an empty buffer or illegal to perform
a LEFT-ARCd transition with the special root node
on top of the stack – but also to filter out unlike-
ly dependency labels or tags. Thus, in the experi-
ments later on, we will typically constrain the parser
so that SHIFTp is permissible only if p is one of the
k best part-of-speech tags with a score no more than
α below the score of the 1-best tag, as determined by
a preprocessing tagger. We also filter out instances
of LEFT-ARCd and RIGHT-ARCd, where d does not
occur in the training data for the predicted part-of-
speech tag combination of the head and dependent.
This procedure leads to a significant speed up.
In order to learn a weight vector w from a training
set {(xj, yj)1 j=1 of sentences with their tagged de-
pendency trees, we use a variant of the structured
perceptron, introduced by Collins (2002), which
makes N iterations over the training data and up-
dates the weight vector for every sentence xj where
the highest scoring parse y* is different from yj.
More precisely, we use the passive-aggressive up-
date of Crammer et al. (2006):
</bodyText>
<equation confidence="0.917431">
wi+1 = wi +T(f(xj, yj) − f(xj, y*))
</equation>
<bodyText confidence="0.74891">
where
</bodyText>
<equation confidence="0.971526">
f(xj, yj) − f(xj, y*)
��f(xj,yj) − f(xj,y*)112
</equation>
<bodyText confidence="0.999883636363636">
We also use the early update strategy found benefi-
cial for parsing in several previous studies (Collins
and Roark, 2004; Zhang and Clark, 2008; Huang
and Sagae, 2010), which means that, during learn-
ing, we terminate the beam search as soon as the
hypothesis corresponding to the gold parse yj falls
out of the beam and update with respect to the par-
tial transition sequence constructed up to that point.
Finally, we use the standard technique of averaging
over all weight vectors, as originally proposed by
Collins (2002).
</bodyText>
<subsectionHeader confidence="0.999094">
2.3 Feature Representations
</subsectionHeader>
<bodyText confidence="0.999598777777778">
As already noted, the feature representation f(x, y)
of an input sentence x with parse y decomposes into
feature representations f(c, t) for the transitions t(c)
needed to derive y from cs(x). Features may refer to
any aspect of a configuration, as encoded in the stack
E, the buffer B, the arc set A and the labelings 7r and
S. In addition, we assume that each word w in the
input is assigned up to k candidate part-of-speech
tags 7ri(w) with corresponding scores s(7ri(w)).
</bodyText>
<equation confidence="0.835846">
7 =
</equation>
<page confidence="0.831849">
1458
</page>
<table confidence="0.694018333333333">
Features involving word prefixes and suffixes
πi(B0)p2(B0), πi(B0)s2(B0), πi(B0)p1(B0)p1(E0)
πi(E0)p1(E0)p1(E1), πi(E0)s1(E0)s1(E0)
πi(E0)p2(E0)s3(E1),πi(E0)s3(E0)p2(E1)
πi(E0)w(B0)s1(E0), πi(E0)w(B0)s2(E0)
Features involving tag score differences and ranks
</table>
<equation confidence="0.6931405">
πi(B0)[s(π1(B0)) − s(πi(B0))]
πi(B0)πi(E0)[s(π1(B0)) − s(πi(B0))] i
πi(B0)[s(π1(B0)) − s(πi(B0))]π(E0)
w(B0)[s(π1(B0)) − s(πi(B0))]π(E0)
</equation>
<figureCaption confidence="0.928298">
Figure 3: Specialized feature templates for tagging. We
</figureCaption>
<bodyText confidence="0.98446828358209">
use Ei and Bi to denote the ith token in the stack E and
buffer B, respectively, with indexing starting at 0, and we
use the following functors to extract properties of a token:
πi() = ith best tag; s(πi()) = score of ith best tag; π() =
finally predicted tag; w() = word form; pi() = word prefix
of i characters; si() = word suffix of i characters. Score
differences are binned in discrete steps of 0.05.
The bulk of features used in our system are tak-
en from Zhang and Nivre (2011), although with t-
wo important differences. First of all, like Hatori et
al. (2011), we have omitted all features that presup-
pose an arc-eager parsing order, since our transition
system defines an arc-standard order. Secondly, any
feature that refers to the part-of-speech tag of a word
w in the buffer B will in our system refer to the top-
scoring tag π1(w), rather than the finally predicted
tag. By contrast, for a word in the stack E, part-of-
speech features refer to the tag π(w) chosen when
shifting w onto the stack (which may or may not be
the same as π1(w)).
In addition to the standard features for transition-
based dependency parsing, we have added features
specifically to improve the tagging step in the joint
model. The templates for these features, which are
specified in Figure 3, all involve the ith best tag as-
signed to the first word of the buffer B (the next
word to be shifted in a SHIFTP transition) in combi-
nation with neighboring words, word prefixes, word
suffixes, score differences and tag rank.
Finally, in some experiments, we make use of two
additional feature sets, which we call graph features
(G) and cluster features (C), respectively. Graph fea-
tures are defined over the factors of a graph-based
dependency parser, which was shown to improve the
accuracy of a transition-based parser by Zhang and
Clark (2008). However, while their features were
limited to certain first- and second-order factors, we
use features over second- and third-order factors as
found in the parsers of Bohnet and Kuhn (2012).
These features are scored as soon as the factors are
completed, using a technique that is similar to what
Hatori et al. (2011) call delayed features, although
they use it for part-of-speech tags in the lookahead
while we use it for subgraphs of the dependency tree.
Cluster features, finally, are features over word clus-
ters, as first used by Koo et al. (2008), which replace
part-of-speech tag features.2
We use a hash kernel to map features to weights.
It has been observed that most of the computing time
in feature-rich parsers is spent retrieving the index
of each feature in the weight vector (Bohnet, 2010).
This is usually done via a hash table, but significan-
t speedups can be achieved by using a hash kernel,
which simply replaces table lookup by a hash func-
tion (Bloom, 1970; Shi et al., 2009; Bohnet, 2010).
The price to pay for these speedups is that there may
be collisions, so that different features are mapped to
the same index, but this is often compensated by the
fact that the lower time and memory requirements of
the hash kernel enables the use of negative features,
that is, features that are never seen in the training set
but occur in erroneous hypotheses at training time
and can therefore be helpful also at inference time.
As a result, the hash kernel often improves accuracy
as well as efficiency compared to traditional tech-
niques that only make use of features that occur in
gold standard parses (Bohnet, 2010).
</bodyText>
<sectionHeader confidence="0.999753" genericHeader="background">
3 Experiments
</sectionHeader>
<bodyText confidence="0.996987333333333">
We have evaluated the model for joint tagging and
dependency parsing on four typologically diverse
languages: Chinese, Czech, English, and German.
</bodyText>
<subsectionHeader confidence="0.994712">
3.1 Setup
</subsectionHeader>
<bodyText confidence="0.999507285714286">
Most of the experiments use the CoNLL 2009 da-
ta sets with the training, development and test s-
plit used in the Shared Task (Hajiˇc et al., 2009),
but for better comparison with previous work we
also report results for the standard benchmark data
sets for Chinese and English. For Chinese, this is
the Penn Chinese Treebank 5.1 (CTB5), converted
</bodyText>
<footnote confidence="0.9960905">
2For replicability, a complete description of all features can
be found at http://stp.lingfil.uu.se/∼nivre/exp/emnlp12.html.
</footnote>
<page confidence="0.902798">
1459
</page>
<table confidence="0.99977475">
Parser TLAS Chinese POS TLAS Czech POS TLAS English POS TLAS German POS
k α LAS UAS LAS UAS LAS UAS LAS UAS
1 0.0 73.85 76.12 80.01 92.78 82.36 82.65 88.03 93.26 85.82 87.17 90.41 97.32 85.08 86.60 89.17 97.24
2 0.1 74.39 76.52 80.41 93.37 82.74 83.01 88.34 99.39 86.43 87.79 91.02 97.49 86.12 87.22 89.69 97.85
3 0.1 74.47 76.63 80.50 93.38 82.76 82.97 88.33 99.40 86.40 87.78 90.99 97.43 86.03 87.27 89.60 97.74
3 0.2 74.35 76.48 80.38 93.43 82.85 83.11 88.44 99.32 86.35 87.79 91.01 97.52 86.24 87.37 89.72 97.90
3 0.3 74.18 76.33 80.28 93.48 82.78 83.05 88.38 99.33 85.94 87.57 90.87 96.97 86.35 87.46 89.86 97.90
3 0.4 86.14 87.23 89.66 97.79
</table>
<tableCaption confidence="0.9925465">
Table 1: Accuracy scores for the CoNLL 2009 shared task development sets as a function of the number of tags k and
the score threshold α. Beam parameters fixed at b1 = 40, b2 = 4.
</tableCaption>
<bodyText confidence="0.9999714">
with the head-finding rules and conversion tools of
Zhang and Clark (2008), and with the same split as
in Zhang and Clark (2008) and Li et al. (2011).3 For
English, this is the WSJ section of the Penn Tree-
bank, converted with the head-finding rules of Ya-
mada and Matsumoto (2003) and the labeling rules
of Nivre (2006).4
In order to assign k-best part-of-speech tags and
scores to words in the training set, we used a per-
ceptron tagger with 10-fold jack-knifing. The same
type of tagger was trained on the entire training set
in order to supply tags for the development and test
sets. The feature set of the tagger was optimized
for English and German and provides state-of-the-
art accuracy for these two languages. The 1-best
tagging accuracy for section 23 of the Penn Tree-
bank is 97.28, which is on a par with Toutanova et
al. (2003). For German, we obtain a tagging accura-
cy of 97.24, which is close to the 97.39 achieved by
the RF-Tagger (Schmid and Laws, 2008), which to
our knowledge is the best tagger for German.5 The
results are not directly comparable to the RF-Tagger
as it was evaluated on a different part of the Tiger
Treebank and trained on a larger part of the Tree-
bank. We could not use the larger training set as
it contains the test set of the CoNLL 2009 data that
we use to evaluate the joint model. For Czech, the 1-
best tagging accuracy is 99.11 and for Chinese 92.65
on the CoNLL 2009 test set.
We trained parsers with 25 iterations and report
</bodyText>
<footnote confidence="0.9583905">
3Training: 001–815, 1001–1136. Development: 886–931,
1148–1151. Test: 816–885, 1137–1147.
4Training: 02-21. Development: 24. Test: 23.
5The RF-Tagger can take advantage of an additional lexicon
and then reaches 97.97. The lexicon supplies entries for addi-
tional words that are not found in the training corpus and addi-
tional tags for words that do occur in the training data (Schmid
and Laws, 2008).
</footnote>
<bodyText confidence="0.999962882352941">
results for the model obtained after the last iteration.
For cluster features, available only for English and
German, we used standard Brown clusters based on
the English and German Gigaword Corpus. We re-
stricted the vocabulary to words that occur at least
10 times, used 800 clusters, and took cluster prefix-
es of length 6 to define features.
We report the following evaluation metrics: part-
of-speech accuracy (POS), unlabeled attachment s-
core (UAS), labeled attachment score (LAS), and
tagged labeled attachment score (TLAS). TLAS is
a new metric defined as the percentage of words that
are assigned the correct part-of-speech tag, the cor-
rect head and the correct dependency label. In line
with previous work, punctuation is included in the
evaluation for the CoNLL data sets but excluded for
the two benchmark data sets.
</bodyText>
<subsectionHeader confidence="0.807376">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.999977125">
Table 1 presents results on the development sets of
the CoNLL 2009 shared task with varying values
of the two tag parameters k (number of candidates)
and α (maximum score difference to 1-best tag) and
beam parameters fixed at b1 = 40 and b2 = 4. We
use the combined TLAS score on the development
set to select the optimal settings for each language.
For Chinese, we obtain the best result with 3 tags
and a threshold of 0.1.6 Compared to the baseline,
we observe a POS improvement of 0.60 and a LAS
improvement of 0.51. For Czech, we get the best T-
LAS with k = 3 and α = 0.2, where POS improves
by 0.06 and LAS by 0.46. For English, the best set-
ting is k = 2 and α = 0.1 with a POS improvement of
0.17 and a LAS improvement of 0.62. For German,
finally, we see the greatest improvement with k = 3
</bodyText>
<footnote confidence="0.9606545">
6While tagging accuracy (POS) increases with larger values
of α, TLAS decreases because of a drop in LAS.
</footnote>
<page confidence="0.934195">
1460
</page>
<table confidence="0.99789225">
Parser Chinese Czech English German
TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS
Gesmundo et al. (2009) 76.11 92.37 80.38 99.33 88.79 97.48 87.28 95.46
Bohnet (2010) 76.99 92.37 80.96 99.33 90.33 97.48 88.06 95.46
Baseline (k = 1), bl = 40 73.66 76.55 80.77 92.65 82.07 82.44 87.83 99.11 87.89 89.19 91.74 97.57 86.11 87.78 90.13 97.24
Best dev setting, bl = 40 74.72 77.00 81.18 93.06 82.56 82.70 88.07 99.32 88.26 89.54 92.06 97.77 86.91 88.23 90.43 97.63
Adding G, bl = 80 75.84 78.51 82.52 93.19 83.38 83.73 88.82 99.33 88.92 90.20 92.60 97.77 87.86 89.05 91.16 97.78
Adding G+C, bl = 80 89.22 90.60 92.87 97.84 88.31 89.38 91.37 98.05
</table>
<tableCaption confidence="0.9728935">
Table 2: Accuracy scores for the CoNLL 2009 shared task test sets. Rows 1–2: Top performing systems in the shared
CoNLL Shared Task 2009; Gesmundo et al. (2009) was placed first in the shared task; for Bohnet (2010), we include
</tableCaption>
<bodyText confidence="0.971498783783784">
the updated scores later reported due to some improvements of the parser. Rows 3–4: Baseline (k = 1) and best settings
for k and α on development set. Rows 5–6: Wider beam (b1 = 80) and added graph features (G) and cluster features
(C). Second beam parameter b2 fixed at 4 in all cases.
and α = 0.3, where POS improves by 0.66 and LAS
by 0.86.
Table 2 shows the results on the CoNLL 2009 test
sets. For all languages except English, we obtain
state-of-the-art results already with bi = 40 (row 4),
and for all languages both tagging and parsing ac-
curacy improve compared to the baseline (row 3).
The improvement in TLAS is statistically significant
with p &lt; 0.01 for all languages (paired t-test). Row
5 shows the scores with a beam of 80 and the addi-
tional graph features. Here the LAS scores for Chi-
nese, Czech and German are higher than the best re-
sults on the CoNLL 2009 data sets, and the score
for English is highly competitive. For Chinese, we
achieve 78.51 LAS, which is 1.5 percentage points
higher than the reference score, while the POS s-
core is 0.54 higher than our baseline. For Czech, we
get 83.73 LAS, which is by far the highest score re-
ported for this data set, together with state-of-the-art
POS accuracy. For German, we obtain 89.05 LAS
and 97.78 POS, which in both cases is substantially
better than in the CoNLL shared task. We believe
it is also the highest POS accuracy ever reported for
a tagger/parser trained only on the Tiger Treebank.
Row 6, finally, presents results with added cluster
features for English and German, which results in
additional improvements in all metrics.
Table 3 gives the results for the Penn Treebank
converted with the head-finding rules of Yamada and
Matsumoto (2003) and the labeling rules of Nivre
(2006). We use k = 3 and α = 0.4, which gave the
best results on the development set. The UAS im-
proves by 0.24 when we do joint tagging and pars-
ing. The POS accuracy improves slightly by 0.12
</bodyText>
<table confidence="0.998412333333333">
Parser TLAS UAS LAS POS
McDonald et al. (2005) 90.9
McDonald and Pereira (2006) 91.5
Zhang and Clark (2008) 92.1
Huang and Sagae (2010) 92.1
Koo and Collins (2010) 93.04
Zhang and Nivre (2011) 92.9
Martins et al. (2010) 93.26
Koo et al. (2008) † 93.16
Carreras et al. (2008) † 93.5
Suzuki et al. (2009) † 93.79
Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28
Best dev setting, b1 = 40 89.75 93.03 91.92 97.40
Adding G, b1 = 40 90.12 93.38 92.44 97.33
Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42
</table>
<tableCaption confidence="0.9760408">
Table 3: Accuracy scores for WSJ-PTB converted with
head rules of Yamada and Matsumoto (2003) and labeling
rules of Nivre (2006). Best dev setting: k = 3, α = 0.4.
Results marked with † use additional information sources
and are not directly comparable to the others.
</tableCaption>
<bodyText confidence="0.999704642857143">
but to a lower degree than for the English CoNL-
L data where we observed an improvement of 0.20.
Nonetheless, the improvement in the joint TLAS s-
core is statistically significant at p &lt; 0.01 (paired
t-test). Our joint tagger and dependency parser with
graph features gives very competitive unlabeled de-
pendency scores for English with 93.38 UAS. To
the best of our knowledge, this is the highest score
reported for a (transition-based) dependency parser
that does not use additional information sources. By
adding cluster features and widening the beam to
bi = 80, we achieve 93.67 UAS. We also obtain
a POS accuracy of 97.42, which is on a par with the
best results obtained using semi-supervised taggers
</bodyText>
<page confidence="0.974485">
1461
</page>
<table confidence="0.9892203">
Parser TLAS UAS LAS POS
MSTParser1 75.56 93.51
MSTParser2 77.73 93.51
Li et al. (2011) 3rd-order 80.60 92.80
Li et al. (2011) 2nd-order 80.55 93.08
Hatori et al. (2011) HS 79.60 94.01
Hatori et al. (2011) ZN 81.20 93.94
Baseline (k = 1), bl = 40 61.95 80.33 76.79 92.81
Best dev setting, bl = 40 62.54 80.59 77.06 93.11
Adding G, bl = 80 63.20 81.42 77.91 93.24
</table>
<tableCaption confidence="0.991288285714286">
Table 4: Accuracy scores for Penn Chinese Treebank
converted with the head rules of Zhang and Clark (2008).
Best dev setting: k = 3, α = 0.1. MSTParser results from
Li et al. (2011). UAS scores from Li et al. (2011) and Ha-
tori et al. (2011) recalculated from the separate accuracy
scores for root words and non-root words reported in the
original papers.
</tableCaption>
<bodyText confidence="0.994616538461538">
(Søgaard, 2011).
Table 4 shows the results for the Chinese Penn
Treebank CTB 5.1 together with related work. In ex-
periments with the development set, we could con-
firm the results from the Chinese CoNLL data set
and obtained the best results with the same settings
(k = 3, α = 0.1). With bi = 40, UAS improves by
0.25 and POS by 0.30, and the TLAS improvement
is again highly significant (p &lt; 0.01, paired t-test).
We get the highest UAS, 81.42, with a beam of 80
and added graph features, in which case POS accu-
racy increases from 92.81 to 93.24. Since our tagger
was not optimized for Chinese, we have lower base-
line results for the tagger than both Li et al. (2011)
and Hatori et al. (2011) but still manage to achieve
the highest reported UAS.
The speed of the joint tagger and dependency
parser is quite reasonable with about 0.4 seconds
per sentence on the WSJ-PTB test set, given that we
perform tagging and labeled parsing with a beam of
80 while incorporating the features of a third-order
graph-based model. Experiments were performed
on a computer with an Intel i7-3960X CPU (3.3 GHz
and 6 cores). These performance values are prelim-
inary since we are still working on the speed-up of
the parser.
</bodyText>
<subsectionHeader confidence="0.99939">
3.3 Analysis
</subsectionHeader>
<bodyText confidence="0.999752">
In order to better understand the benefits of the joint
model, we performed an error analysis for German
</bodyText>
<table confidence="0.999868133333333">
Confusion Baseline Joint
Freq F-score Freq F-score
VVINF VVFIN 28 91.1 2 97.7
9
VVINF � VVPP|ADJ*|NN 5
VVFIN VVINF 43 94.2 5 98.5
VVFIN VVPP 20 2
VAINF VAFIN 10 99.1 1 99.9
NE NN 184 128
NE ADJ*|ADV|FM 24 90.7 18 92.4
NE XY 12 21
NN NE 85 97.5 67 98.1
NN � ADJ*|XY|ADV|VV* 39 29
PRELS ART 13 5
PRELS PWS 0 92.9 2 95.4
</table>
<tableCaption confidence="0.998977">
Table 5: Selected entries from the confusion matrix for
</tableCaption>
<bodyText confidence="0.978808848484849">
parts of speech in German with F-scores for the left-hand-
side category. ADJ* (ADJD or ADJA) = adjective; ADV
= adverb; ART = determiner; APPR = preposition; NE
= proper noun; NN = common noun; PRELS = relative
pronoun; VVFIN = finite verb; VVINF = non-finite verb;
VAFIN = finite auxiliary verb; VAINF = non-finite auxil-
iary verb; VVPP = participle; XY = not a word. We use
α* to denote the set of categories with α as a prefix.
and English, where we compared the baseline and
the joint model with respect to F-scores for individu-
al part-of-speech categories and dependency labels.
For the part-of-speech categories, we found an im-
provement across the board for both languages, with
no category having a significant decrease in F-score,
but we also found some interesting patterns for cat-
egories that improved more than the average.
Table 5 shows selected entries from the confu-
sion matrix for German, where we see substantial
improvements for finite and non-finite verbs, which
are often morphologically ambiguous but which can
be disambiguated using syntactic context. We al-
so see improved accuracies for common and proper
nouns, which are both capitalized in standard Ger-
man orthography and therefore often mistagged, and
for relative pronouns, which are less often confused
for determiners in the joint model.
Table 6 gives a similar snapshot for English, and
we again see improvements for verb categories that
are often morphologically ambiguous, such as past
participles, which can be confused for past tense
verbs, and present tense verbs in third person sin-
gular, which can be confused for nouns. We also
see some improvement for the singular noun catego-
</bodyText>
<page confidence="0.988567">
1462
</page>
<table confidence="0.984852">
Baseline Joint
Freq F-score Freq F-score
40 90.5 19 91.5
13 18
19 97.8 13 98.3
6 6
72 58
79 96.8 69 97.2
58 57
126 92.4 93 92.9
86 89
</table>
<tableCaption confidence="0.998081">
Table 6: Selected entries from the confusion matrix for
</tableCaption>
<bodyText confidence="0.972908608695652">
parts of speech in English with F-scores for the left-hand-
side category. DT = determiner; IN = preposition or sub-
ordinating conjunction; JJ = adjective; JJR = compara-
tive adjective; NN = singular or mass noun; NNS = plural
noun; POS = possessive clitic; RB = adverb; RBR = com-
parative adverb; RP = particle; UH = interjection; VB =
base form verb; VBD = past tense verb; VBG = gerund or
present participle; VBN = past participle; VBP = present
tense verb, not 3rd person singular; VBZ = present tense
verb, 3rd person singular. We use α* to denote the set of
categories with α as a prefix.
ry and for adverbs, which are less often confused for
prepositions or subordinating conjunctions thanks to
the syntactic information in the joint model.
For dependency labels, it is hard to extract any
striking patterns and it seems that we mainly see an
improvement in overall parsing accuracy thanks to
less severe tagging errors. However, it is worth ob-
serving that, for both English and German, we see
significant F-score improvements for the core gram-
matical functions subject (91.3 —* 92.1 for German,
95.6 —* 96.1 for English) and object (86.9 —* 87.9
for German, 90.2 —* 91.9 for English).
</bodyText>
<sectionHeader confidence="0.99991" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.99996693220339">
Our work is most closely related to Lee et al. (2011),
Li et al. (2011) and Hatori et al. (2011), who al-
l present discriminative models for joint tagging and
dependency parsing. However, all three models only
perform unlabeled parsing, while our model incor-
porates dependency labels into the parsing process.
Whereas Lee et al. (2011) and Li et al. (2011) take
a graph-based approach to dependency parsing, Ha-
tori et al. (2011) use a transition-based model similar
to ours but limited to projective dependency trees.
Both Li et al. (2011) and Hatori et al. (2011) only
evaluate their model on Chinese, and of these only
Hatori et al. (2011) report consistent improvements
in both tagging and parsing accuracy. Like our sys-
tem, the parser of Lee et al. (2011) can handle non-
projective trees and experimental results are present-
ed for four languages, but their graph-based model
is relatively simple and the baselines therefore well
below the state of the art. We are thus the first to
show consistent improvements in both tagging and
(labeled) parsing accuracy across typologically di-
verse languages at the state-of-the-art level. More-
over, the capacity to handle non-projective depen-
dencies, which is crucial to attain good performance
on Czech and German, does not seem to hurt per-
formance on English and Chinese, where the bench-
mark sets contain only projective trees.
The use of beam search in transition-based depen-
dency parsing in order to mitigate the problem of
error propagation was first proposed by Johansson
and Nugues (2006), although they still used a local-
ly trained model. Globally normalized models were
first explored by Titov and Henderson (2007), who
were also the first to use a parameterized SHIFT tran-
sition like the one found in both Hatori et al. (2011)
and our own work, although Titov and Henderson
(2007) used it to define a generative model by pa-
rameterizing the SHIFT transition by an input word.
Zhang and Clark (2008) was the first to combine
beam search with a globally normalized discrimi-
native model, using structured perceptron learning
and the early update strategy of Collins and Roark
(2004), and also explored the addition of graph-
based features to a transition-based parser. This
approach was further pursued in Zhang and Clark
(2011) and was used by Zhang and Nivre (2011) to
achieve state-of-the-art results in dependency pars-
ing for both Chinese and English through the ad-
dition of rich non-local features. Huang and Sagae
(2010) combined structured perceptron learning and
beam search with the use of a graph-structured stack
to allow ambiguity packing in the beam, a technique
that was reused by Hatori et al. (2011).
Finally, as noted in the introduction, although
joint tagging and parsing is rare in dependency pars-
ing, most state-of-the-art parsers based on PCFG
models naturally incorporate part-of-speech tagging
and usually achieve better parsing accuracy (albeit
not always tagging accuracy) with a joint model than
</bodyText>
<figure confidence="0.9387488">
Confusion
VBN → VBD
VBN → JJ|VB|VBP|NN
VBZ → NN|NNS
VBZ → POS|JJ|RB
NN → VBG|VB|VBN|VBD
NN → JJ|JJR
NN → NN*|RB|IN|DT
RB → IN
RB → JJ*|RP|NN*|RBR|UH
</figure>
<page confidence="0.940471">
1463
</page>
<bodyText confidence="0.999343571428571">
with a pipeline approach (Collins, 1997; Charniak,
2000; Charniak and Johnson, 2005; Petrov et al.,
2006). Models that in addition incorporate mor-
phological analysis and segmentation have been ex-
plored by Tsarfaty (2006), Cohen and Smith (2007),
and Goldberg and Tsarfaty (2008) with special ref-
erence to Hebrew parsing.
</bodyText>
<sectionHeader confidence="0.998865" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999745923076923">
We have presented the first system for joint part-
of-speech tagging and labeled dependency parsing
with non-projective dependency trees. Evaluation
on four languages shows consistent improvements
in both tagging and parsing accuracy over a pipeline
system with state-of-the-art results across the board.
The error analysis reveals improvements in tagging
accuracy for syntactically central categories, mainly
verbs, with improvement in syntactic accuracy for
core grammatical functions as a result. In future
work we intend to explore joint models that incorpo-
rate not only basic part-of-speech tags but also more
fine-grained morphological features.
</bodyText>
<sectionHeader confidence="0.997823" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998589064935065">
Giuseppe Attardi. 2006. Experiments with a multilan-
guage non-projective dependency parser. In Proceed-
ings of CoNLL, pages 166–170.
Burton H. Bloom. 1970. Space/time trade-offs in hash
coding with allowable errors. Communications of the
ACM, 13:422–426.
Bernd Bohnet and Jonas Kuhn. 2012. The best of
both worlds – a graph-based completion model for
transition-based parsers. In Proceedings of EACL,
pages 77–87.
Bernd Bohnet. 2010. Top accuracy and fast dependen-
cy parsing is not a contradiction. In Proceedings of
COLING, pages 89–97.
Bernd Bohnet. 2011. Comparing advanced graph-based
and transition-based dependency parsers. In Proceed-
ings of the International Conference on Dependency
Linguistics (Depling), pages 282–289.
Xavier Carreras, Michael Collins, and Terry Koo. 2008.
Tag, dynamic programming, and the perceptron for ef-
ficient, feature-rich parsing. In Proceedings of CoNL-
L, pages 9–16.
Xavier Carreras. 2007. Experiments with a higher-order
projective dependency parser. In Proceedings of the
CoNLL Shared Task of EMNLP-CoNLL 2007, pages
957–961.
Eugene Charniak and Mark Johnson. 2005. Coarse-to-
fine n-best parsing and MaxEnt discriminative rerank-
ing. In Proceedings ofACL, pages 173–180.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of NAACL, pages 132–139.
Shay B. Cohen and Noah A. Smith. 2007. Joint morpho-
logical and syntactic disambiguation. In Proceedings
of EMNLP-CoNLL, pages 208–217.
Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceedings
of ACL, pages 112–119.
Michael Collins. 1997. Three generative, lexicalised
models for statistical parsing. In Proceedings of ACL-
EACL, pages 16–23.
Michael Collins. 2002. Discriminative training meth-
ods for hidden markov models: Theory and experi-
ments with perceptron algorithms. In Proceedings of
EMNLP, pages 1–8.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-
Shwartz, and Yoram Singer. 2006. Online passive-
aggressive algorithms. Journal of Machine Learning
Research, 7:551–585.
Andrea Gesmundo, James Henderson, Paola Merlo, and
Ivan Titov. 2009. A latent variable model of syn-
chronous syntactic-semantic parsing for multiple lan-
guages. In Proceedings of the 2009 CoNLL Shared
Task, pages 37–42.
Yoav Goldberg and Reut Tsarfaty. 2008. A single gener-
ative model for joint morphological segmentation and
syntactic parsing. In Proceedings of ACL, pages 371–
379.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Ant`onia Martf, L-
lufs M`arquez, Adam Meyers, Joakim Nivre, Sebastian
Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The conll-2009
shared task: Syntactic and semantic dependencies in
multiple languages. In Proceedings of the 2009 CoN-
LL Shared Task, pages 1–18.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and
Jun’ichi Tsujii. 2011. Incremental joint pos tagging
and dependency parsing in chinese. In Proceedings of
IJCNLP, pages 1216–1224.
Liang Huang and Kenji Sagae. 2010. Dynamic program-
ming for linear-time incremental parsing. In Proceed-
ings of ACL, pages 1077–1086.
Richard Johansson and Pierre Nugues. 2006. Investigat-
ing multilingual dependency parsing. In Proceedings
of CoNLL, pages 206–210.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of ACL,
pages 1–11.
</reference>
<page confidence="0.886796">
1464
</page>
<reference confidence="0.999780205882353">
Terry Koo, Xavier Carreras, and Michael Collins. 2008.
Simple semi-supervised dependency parsing. In Pro-
ceedings of ACL, pages 595–603.
Terry Koo, Alexander M. Rush, Michael Collins, Tommi
Jaakkola, and David Sontag. 2010. Dual decomposi-
tion for parsing with non-projective head automata. In
Proceedings of EMNLP, pages 1288–1298.
Sandra K¨ubler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. Morgan and Claypool.
John Lee, Jason Naradowsky, and David A. Smith. 2011.
A discriminative model for joint morphological disam-
biguation and dependency parsing. In Proceedings of
ACL, pages 885–894.
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-
liang Chen, and Haizhou Li. 2011. Joint models for
chinese POS tagging and dependency parsing. In Pro-
ceedings of EMNLP, pages 1180–1191.
Andre Martins, Noah Smith, and Eric Xing. 2009. Con-
cise integer linear programming formulations for de-
pendency parsing. In Proceedings of ACL-IJCNLP,
pages 342–350.
Andre Martins, Noah Smith, Eric Xing, Pedro Aguiar,
and Mario Figueiredo. 2010. Turbo parsers: Depen-
dency parsing by approximate variational inference.
In Proceedings of EMNLP, pages 34–44.
Ryan McDonald and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing al-
gorithms. In Proceedings of EACL, pages 81–88.
Ryan McDonald, Koby Crammer, and Fernando Pereira.
2005. Online large-margin training of dependency
parsers. In Proceedings of ACL, pages 91–98.
Joakim Nivre, Johan Hall, and Jens Nilsson. 2004.
Memory-based dependency parsing. In Proceedings
of CoNLL, pages 49–56.
Joakim Nivre. 2006. Inductive Dependency Parsing.
Springer.
Joakim Nivre. 2007. Incremental non-projective depen-
dency parsing. In Proceedings of NAACL HLT, pages
396–403.
Joakim Nivre. 2008. Algorithms for deterministic incre-
mental dependency parsing. Computational Linguis-
tics, 34:513–553.
Joakim Nivre. 2009. Non-projective dependency pars-
ing in expected linear time. In Proceedings of ACL-
IJCNLP, pages 351–359.
Slav Petrov and Dan Klein. 2007. Improved inference
for unlexicalized parsing. In Proceedings of NAACL
HLT, pages 404–411.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and in-
terpretable tree annotation. In Proceedings of COL-
ING/ACL, pages 433–440.
Sebastian Riedel and James Clarke. 2006. Incremental
integer linear programming for non-projective depen-
dency parsing. In Proceedings of EMNLP, pages 129–
137.
Helmut Schmid and Florian Laws. 2008. Estimation of
conditional probabilities with decision trees and an ap-
plication to fine-grained POS tagging. In Proceedings
of COLING, pages 777–784.
Qinfeng Shi, James Petterson, Gideon Dror, John Lang-
ford, Alex Smola, Alex Strehl, and S V N Vish-
wanathan. 2009. Hash Kernels for Structured Data.
In Journal of Machine Learning.
David Smith and Jason Eisner. 2008. Dependency pars-
ing by belief propagation. In Proceedings of EMNLP,
pages 145–156.
Anders Søgaard. 2011. Semi-supervised condensed n-
earest neighbor for part-of-speech tagging. In Pro-
ceedings of ACL, pages 48–52.
Jun Suzuki, Hideki Isozaki, Xavier Carreras, and Michael
Collins. 2009. An empirical study of semi-supervised
structured conditional models for dependency parsing.
In Proceedings of EMNLP, pages 551–560.
Ivan Titov and James Henderson. 2007. A latent variable
model for generative dependency parsing. In Proceed-
ings of IWPT, pages 144–155.
Ivan Titov, James Henderson, Paola Merlo, and Gabriele
Musillo. 2009. Online graph planarization for syn-
chronous parsing of semantic and syntactic dependen-
cies. In Proceedings of IJCAI.
Kristina Toutanova, Dan Klein, Christopher D. Manning,
and Yoram Singer. 2003. Feature-rich part-of-speech
tagging with a cyclic dependency network. In Pro-
ceedings of NAACL, pages 252–259.
Reut Tsarfaty. 2006. Integrated morphological and syn-
tactic disambiguation for modern hebrew. In Pro-
ceedings of the COLING/ACL 2006 Student Research
Workshop, pages 49–54.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical
dependency analysis with support vector machines. In
Proceedings of IWPT, pages 195–206.
Yue Zhang and Stephen Clark. 2008. A tale of two
parsers: Investigating and combining graph-based and
transition-based dependency parsing. In Proceedings
of EMNLP, pages 562–571.
Yue Zhang and Stephen Clark. 2011. Syntactic process-
ing using the generalized perceptron and beam search.
Computational Linguistics, 37:105–151.
Yue Zhang and Joakim Nivre. 2011. Transition-based
parsing with rich non-local features. In Proceedings
of ACL.
</reference>
<page confidence="0.992989">
1465
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.266094">
<title confidence="0.984227">A Transition-Based System for Joint Part-of-Speech and Labeled Non-Projective Dependency Parsing</title>
<author confidence="0.865058">Bernd</author>
<affiliation confidence="0.989009">Institute for Natural Language University</affiliation>
<email confidence="0.722254">bohnet@ims.uni-stuttgart.deJoakim</email>
<affiliation confidence="0.998996">Department of Linguistics and</affiliation>
<address confidence="0.698741">Uppsala</address>
<email confidence="0.989827">joakim.nivre@lingfil.uu.se</email>
<abstract confidence="0.999087846153846">Most current dependency parsers presuppose that input words have been morphologically disambiguated using a part-of-speech tagger before parsing begins. We present a transitionbased system for joint part-of-speech tagging and labeled dependency parsing with nonprojective trees. Experimental evaluation on Chinese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Giuseppe Attardi</author>
</authors>
<title>Experiments with a multilanguage non-projective dependency parser.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>166--170</pages>
<contexts>
<context position="4855" citStr="Attardi, 2006" startWordPosition="714" endWordPosition="715">re et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of part-of-speech tags and a set D of dependency labels, a tagged dependency tree for a sentence x = w1, ... , wn is a directed tree T = (Vx, A) with labeling functions 7r and 6 such that: 1. Vx = 10, 1, ... , n} is</context>
</contexts>
<marker>Attardi, 2006</marker>
<rawString>Giuseppe Attardi. 2006. Experiments with a multilanguage non-projective dependency parser. In Proceedings of CoNLL, pages 166–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burton H Bloom</author>
</authors>
<title>Space/time trade-offs in hash coding with allowable errors.</title>
<date>1970</date>
<journal>Communications of the ACM,</journal>
<pages>13--422</pages>
<contexts>
<context position="19055" citStr="Bloom, 1970" startWordPosition="3290" endWordPosition="3291"> part-of-speech tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights. It has been observed that most of the computing time in feature-rich parsers is spent retrieving the index of each feature in the weight vector (Bohnet, 2010). This is usually done via a hash table, but significant speedups can be achieved by using a hash kernel, which simply replaces table lookup by a hash function (Bloom, 1970; Shi et al., 2009; Bohnet, 2010). The price to pay for these speedups is that there may be collisions, so that different features are mapped to the same index, but this is often compensated by the fact that the lower time and memory requirements of the hash kernel enables the use of negative features, that is, features that are never seen in the training set but occur in erroneous hypotheses at training time and can therefore be helpful also at inference time. As a result, the hash kernel often improves accuracy as well as efficiency compared to traditional techniques that only make use of fe</context>
</contexts>
<marker>Bloom, 1970</marker>
<rawString>Burton H. Bloom. 1970. Space/time trade-offs in hash coding with allowable errors. Communications of the ACM, 13:422–426.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
<author>Jonas Kuhn</author>
</authors>
<title>The best of both worlds – a graph-based completion model for transition-based parsers.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>77--87</pages>
<contexts>
<context position="18268" citStr="Bohnet and Kuhn (2012)" startWordPosition="3151" endWordPosition="3154">nsition) in combination with neighboring words, word prefixes, word suffixes, score differences and tag rank. Finally, in some experiments, we make use of two additional feature sets, which we call graph features (G) and cluster features (C), respectively. Graph features are defined over the factors of a graph-based dependency parser, which was shown to improve the accuracy of a transition-based parser by Zhang and Clark (2008). However, while their features were limited to certain first- and second-order factors, we use features over second- and third-order factors as found in the parsers of Bohnet and Kuhn (2012). These features are scored as soon as the factors are completed, using a technique that is similar to what Hatori et al. (2011) call delayed features, although they use it for part-of-speech tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights. It has been observed that most of the computing time in feature-rich parsers is spent retrieving the index of each feature in the weight vector</context>
</contexts>
<marker>Bohnet, Kuhn, 2012</marker>
<rawString>Bernd Bohnet and Jonas Kuhn. 2012. The best of both worlds – a graph-based completion model for transition-based parsers. In Proceedings of EACL, pages 77–87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>89--97</pages>
<contexts>
<context position="1330" citStr="Bohnet, 2010" startWordPosition="176" endWordPosition="177">ccuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and </context>
<context position="18883" citStr="Bohnet, 2010" startWordPosition="3258" endWordPosition="3259">These features are scored as soon as the factors are completed, using a technique that is similar to what Hatori et al. (2011) call delayed features, although they use it for part-of-speech tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights. It has been observed that most of the computing time in feature-rich parsers is spent retrieving the index of each feature in the weight vector (Bohnet, 2010). This is usually done via a hash table, but significant speedups can be achieved by using a hash kernel, which simply replaces table lookup by a hash function (Bloom, 1970; Shi et al., 2009; Bohnet, 2010). The price to pay for these speedups is that there may be collisions, so that different features are mapped to the same index, but this is often compensated by the fact that the lower time and memory requirements of the hash kernel enables the use of negative features, that is, features that are never seen in the training set but occur in erroneous hypotheses at training time and can therefo</context>
<context position="24988" citStr="Bohnet (2010)" startWordPosition="4337" endWordPosition="4338"> 0.60 and a LAS improvement of 0.51. For Czech, we get the best TLAS with k = 3 and α = 0.2, where POS improves by 0.06 and LAS by 0.46. For English, the best setting is k = 2 and α = 0.1 with a POS improvement of 0.17 and a LAS improvement of 0.62. For German, finally, we see the greatest improvement with k = 3 6While tagging accuracy (POS) increases with larger values of α, TLAS decreases because of a drop in LAS. 1460 Parser Chinese Czech English German TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS Gesmundo et al. (2009) 76.11 92.37 80.38 99.33 88.79 97.48 87.28 95.46 Bohnet (2010) 76.99 92.37 80.96 99.33 90.33 97.48 88.06 95.46 Baseline (k = 1), bl = 40 73.66 76.55 80.77 92.65 82.07 82.44 87.83 99.11 87.89 89.19 91.74 97.57 86.11 87.78 90.13 97.24 Best dev setting, bl = 40 74.72 77.00 81.18 93.06 82.56 82.70 88.07 99.32 88.26 89.54 92.06 97.77 86.91 88.23 90.43 97.63 Adding G, bl = 80 75.84 78.51 82.52 93.19 83.38 83.73 88.82 99.33 88.92 90.20 92.60 97.77 87.86 89.05 91.16 97.78 Adding G+C, bl = 80 89.22 90.60 92.87 97.84 88.31 89.38 91.37 98.05 Table 2: Accuracy scores for the CoNLL 2009 shared task test sets. Rows 1–2: Top performing systems in the shared CoNLL Share</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Proceedings of COLING, pages 89–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Comparing advanced graph-based and transition-based dependency parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Dependency Linguistics (Depling),</booktitle>
<pages>282--289</pages>
<contexts>
<context position="1956" citStr="Bohnet, 2011" startWordPosition="269" endWordPosition="270">nference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy a</context>
<context position="4660" citStr="Bohnet, 2011" startWordPosition="685" endWordPosition="686">es state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of part-of-speech ta</context>
</contexts>
<marker>Bohnet, 2011</marker>
<rawString>Bernd Bohnet. 2011. Comparing advanced graph-based and transition-based dependency parsers. In Proceedings of the International Conference on Dependency Linguistics (Depling), pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
<author>Terry Koo</author>
</authors>
<title>Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="27911" citStr="Carreras et al. (2008)" startWordPosition="4865" endWordPosition="4868">trics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked with † use additional information sources and are not directly comparable to the others. but to a lower degree than for the English CoNLL data where we observed an improvement of 0.20. Nonetheless</context>
</contexts>
<marker>Carreras, Collins, Koo, 2008</marker>
<rawString>Xavier Carreras, Michael Collins, and Terry Koo. 2008. Tag, dynamic programming, and the perceptron for efficient, feature-rich parsing. In Proceedings of CoNLL, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
</authors>
<title>Experiments with a higher-order projective dependency parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task of EMNLP-CoNLL</booktitle>
<pages>957--961</pages>
<contexts>
<context position="1292" citStr="Carreras, 2007" startWordPosition="170" endWordPosition="171">rovements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimizat</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>Xavier Carreras. 2007. Experiments with a higher-order projective dependency parser. In Proceedings of the CoNLL Shared Task of EMNLP-CoNLL 2007, pages 957–961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarse-tofine n-best parsing and MaxEnt discriminative reranking.</title>
<date>2005</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>173--180</pages>
<contexts>
<context position="2270" citStr="Charniak and Johnson, 2005" startWordPosition="319" endWordPosition="323">search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. </context>
<context position="37796" citStr="Charniak and Johnson, 2005" startWordPosition="6582" endWordPosition="6585">mbiguity packing in the beam, a technique that was reused by Hatori et al. (2011). Finally, as noted in the introduction, although joint tagging and parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than Confusion VBN → VBD VBN → JJ|VB|VBP|NN VBZ → NN|NNS VBZ → POS|JJ|RB NN → VBG|VB|VBN|VBD NN → JJ|JJR NN → NN*|RB|IN|DT RB → IN RB → JJ*|RP|NN*|RBR|UH 1463 with a pipeline approach (Collins, 1997; Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing. 5 Conclusion We have presented the first system for joint partof-speech tagging and labeled dependency parsing with non-projective dependency trees. Evaluation on four languages shows consistent improvements in both tagging and parsing accuracy over a pipeline system with state-of-the-art results across the board. The error analysis reveals improvements in tag</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarse-tofine n-best parsing and MaxEnt discriminative reranking. In Proceedings ofACL, pages 173–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>132--139</pages>
<contexts>
<context position="37768" citStr="Charniak, 2000" startWordPosition="6580" endWordPosition="6581">stack to allow ambiguity packing in the beam, a technique that was reused by Hatori et al. (2011). Finally, as noted in the introduction, although joint tagging and parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than Confusion VBN → VBD VBN → JJ|VB|VBP|NN VBZ → NN|NNS VBZ → POS|JJ|RB NN → VBG|VB|VBN|VBD NN → JJ|JJR NN → NN*|RB|IN|DT RB → IN RB → JJ*|RP|NN*|RBR|UH 1463 with a pipeline approach (Collins, 1997; Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing. 5 Conclusion We have presented the first system for joint partof-speech tagging and labeled dependency parsing with non-projective dependency trees. Evaluation on four languages shows consistent improvements in both tagging and parsing accuracy over a pipeline system with state-of-the-art results across the board. The error analysis</context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of NAACL, pages 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Noah A Smith</author>
</authors>
<title>Joint morphological and syntactic disambiguation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>208--217</pages>
<contexts>
<context position="37957" citStr="Cohen and Smith (2007)" startWordPosition="6607" endWordPosition="6610">in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than Confusion VBN → VBD VBN → JJ|VB|VBP|NN VBZ → NN|NNS VBZ → POS|JJ|RB NN → VBG|VB|VBN|VBD NN → JJ|JJR NN → NN*|RB|IN|DT RB → IN RB → JJ*|RP|NN*|RBR|UH 1463 with a pipeline approach (Collins, 1997; Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing. 5 Conclusion We have presented the first system for joint partof-speech tagging and labeled dependency parsing with non-projective dependency trees. Evaluation on four languages shows consistent improvements in both tagging and parsing accuracy over a pipeline system with state-of-the-art results across the board. The error analysis reveals improvements in tagging accuracy for syntactically central categories, mainly verbs, with improvement in syntactic accuracy for core grammatical functions as a result. In future wo</context>
</contexts>
<marker>Cohen, Smith, 2007</marker>
<rawString>Shay B. Cohen and Noah A. Smith. 2007. Joint morphological and syntactic disambiguation. In Proceedings of EMNLP-CoNLL, pages 208–217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>112--119</pages>
<contexts>
<context position="14886" citStr="Collins and Roark, 2004" startWordPosition="2596" endWordPosition="2599">a weight vector w from a training set {(xj, yj)1 j=1 of sentences with their tagged dependency trees, we use a variant of the structured perceptron, introduced by Collins (2002), which makes N iterations over the training data and updates the weight vector for every sentence xj where the highest scoring parse y* is different from yj. More precisely, we use the passive-aggressive update of Crammer et al. (2006): wi+1 = wi +T(f(xj, yj) − f(xj, y*)) where f(xj, yj) − f(xj, y*) ��f(xj,yj) − f(xj,y*)112 We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010), which means that, during learning, we terminate the beam search as soon as the hypothesis corresponding to the gold parse yj falls out of the beam and update with respect to the partial transition sequence constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors, as originally proposed by Collins (2002). 2.3 Feature Representations As already noted, the feature representation f(x, y) of an input sentence x with parse y decomposes into feature representations f(c, t) for the transitions t(c) needed</context>
<context position="36719" citStr="Collins and Roark (2004)" startWordPosition="6410" endWordPosition="6413"> by Johansson and Nugues (2006), although they still used a locally trained model. Globally normalized models were first explored by Titov and Henderson (2007), who were also the first to use a parameterized SHIFT transition like the one found in both Hatori et al. (2011) and our own work, although Titov and Henderson (2007) used it to define a generative model by parameterizing the SHIFT transition by an input word. Zhang and Clark (2008) was the first to combine beam search with a globally normalized discriminative model, using structured perceptron learning and the early update strategy of Collins and Roark (2004), and also explored the addition of graphbased features to a transition-based parser. This approach was further pursued in Zhang and Clark (2011) and was used by Zhang and Nivre (2011) to achieve state-of-the-art results in dependency parsing for both Chinese and English through the addition of rich non-local features. Huang and Sagae (2010) combined structured perceptron learning and beam search with the use of a graph-structured stack to allow ambiguity packing in the beam, a technique that was reused by Hatori et al. (2011). Finally, as noted in the introduction, although joint tagging and </context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Michael Collins and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In Proceedings of ACL, pages 112–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In Proceedings of ACLEACL,</booktitle>
<pages>16--23</pages>
<contexts>
<context position="37752" citStr="Collins, 1997" startWordPosition="6578" endWordPosition="6579">aph-structured stack to allow ambiguity packing in the beam, a technique that was reused by Hatori et al. (2011). Finally, as noted in the introduction, although joint tagging and parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than Confusion VBN → VBD VBN → JJ|VB|VBP|NN VBZ → NN|NNS VBZ → POS|JJ|RB NN → VBG|VB|VBN|VBD NN → JJ|JJR NN → NN*|RB|IN|DT RB → IN RB → JJ*|RP|NN*|RBR|UH 1463 with a pipeline approach (Collins, 1997; Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing. 5 Conclusion We have presented the first system for joint partof-speech tagging and labeled dependency parsing with non-projective dependency trees. Evaluation on four languages shows consistent improvements in both tagging and parsing accuracy over a pipeline system with state-of-the-art results across the board. Th</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>Michael Collins. 1997. Three generative, lexicalised models for statistical parsing. In Proceedings of ACLEACL, pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="14440" citStr="Collins (2002)" startWordPosition="2520" endWordPosition="2521">e parser so that SHIFTp is permissible only if p is one of the k best part-of-speech tags with a score no more than α below the score of the 1-best tag, as determined by a preprocessing tagger. We also filter out instances of LEFT-ARCd and RIGHT-ARCd, where d does not occur in the training data for the predicted part-ofspeech tag combination of the head and dependent. This procedure leads to a significant speed up. In order to learn a weight vector w from a training set {(xj, yj)1 j=1 of sentences with their tagged dependency trees, we use a variant of the structured perceptron, introduced by Collins (2002), which makes N iterations over the training data and updates the weight vector for every sentence xj where the highest scoring parse y* is different from yj. More precisely, we use the passive-aggressive update of Crammer et al. (2006): wi+1 = wi +T(f(xj, yj) − f(xj, y*)) where f(xj, yj) − f(xj, y*) ��f(xj,yj) − f(xj,y*)112 We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010), which means that, during learning, we terminate the beam search as soon as the hypothesis corresponding t</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proceedings of EMNLP, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai ShalevShwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passiveaggressive algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>7--551</pages>
<contexts>
<context position="14676" citStr="Crammer et al. (2006)" startWordPosition="2559" endWordPosition="2562">T-ARCd and RIGHT-ARCd, where d does not occur in the training data for the predicted part-ofspeech tag combination of the head and dependent. This procedure leads to a significant speed up. In order to learn a weight vector w from a training set {(xj, yj)1 j=1 of sentences with their tagged dependency trees, we use a variant of the structured perceptron, introduced by Collins (2002), which makes N iterations over the training data and updates the weight vector for every sentence xj where the highest scoring parse y* is different from yj. More precisely, we use the passive-aggressive update of Crammer et al. (2006): wi+1 = wi +T(f(xj, yj) − f(xj, y*)) where f(xj, yj) − f(xj, y*) ��f(xj,yj) − f(xj,y*)112 We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010), which means that, during learning, we terminate the beam search as soon as the hypothesis corresponding to the gold parse yj falls out of the beam and update with respect to the partial transition sequence constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors, as originally proposed by Co</context>
</contexts>
<marker>Crammer, Dekel, Keshet, ShalevShwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai ShalevShwartz, and Yoram Singer. 2006. Online passiveaggressive algorithms. Journal of Machine Learning Research, 7:551–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Gesmundo</author>
<author>James Henderson</author>
<author>Paola Merlo</author>
<author>Ivan Titov</author>
</authors>
<title>A latent variable model of synchronous syntactic-semantic parsing for multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 CoNLL Shared Task,</booktitle>
<pages>37--42</pages>
<contexts>
<context position="24926" citStr="Gesmundo et al. (2009)" startWordPosition="4325" endWordPosition="4328">hold of 0.1.6 Compared to the baseline, we observe a POS improvement of 0.60 and a LAS improvement of 0.51. For Czech, we get the best TLAS with k = 3 and α = 0.2, where POS improves by 0.06 and LAS by 0.46. For English, the best setting is k = 2 and α = 0.1 with a POS improvement of 0.17 and a LAS improvement of 0.62. For German, finally, we see the greatest improvement with k = 3 6While tagging accuracy (POS) increases with larger values of α, TLAS decreases because of a drop in LAS. 1460 Parser Chinese Czech English German TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS TLAS LAS UAS POS Gesmundo et al. (2009) 76.11 92.37 80.38 99.33 88.79 97.48 87.28 95.46 Bohnet (2010) 76.99 92.37 80.96 99.33 90.33 97.48 88.06 95.46 Baseline (k = 1), bl = 40 73.66 76.55 80.77 92.65 82.07 82.44 87.83 99.11 87.89 89.19 91.74 97.57 86.11 87.78 90.13 97.24 Best dev setting, bl = 40 74.72 77.00 81.18 93.06 82.56 82.70 88.07 99.32 88.26 89.54 92.06 97.77 86.91 88.23 90.43 97.63 Adding G, bl = 80 75.84 78.51 82.52 93.19 83.38 83.73 88.82 99.33 88.92 90.20 92.60 97.77 87.86 89.05 91.16 97.78 Adding G+C, bl = 80 89.22 90.60 92.87 97.84 88.31 89.38 91.37 98.05 Table 2: Accuracy scores for the CoNLL 2009 shared task test se</context>
</contexts>
<marker>Gesmundo, Henderson, Merlo, Titov, 2009</marker>
<rawString>Andrea Gesmundo, James Henderson, Paola Merlo, and Ivan Titov. 2009. A latent variable model of synchronous syntactic-semantic parsing for multiple languages. In Proceedings of the 2009 CoNLL Shared Task, pages 37–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Reut Tsarfaty</author>
</authors>
<title>A single generative model for joint morphological segmentation and syntactic parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>371--379</pages>
<contexts>
<context position="37991" citStr="Goldberg and Tsarfaty (2008)" startWordPosition="6612" endWordPosition="6615">state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than Confusion VBN → VBD VBN → JJ|VB|VBP|NN VBZ → NN|NNS VBZ → POS|JJ|RB NN → VBG|VB|VBN|VBD NN → JJ|JJR NN → NN*|RB|IN|DT RB → IN RB → JJ*|RP|NN*|RBR|UH 1463 with a pipeline approach (Collins, 1997; Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing. 5 Conclusion We have presented the first system for joint partof-speech tagging and labeled dependency parsing with non-projective dependency trees. Evaluation on four languages shows consistent improvements in both tagging and parsing accuracy over a pipeline system with state-of-the-art results across the board. The error analysis reveals improvements in tagging accuracy for syntactically central categories, mainly verbs, with improvement in syntactic accuracy for core grammatical functions as a result. In future work we intend to explore joint mode</context>
</contexts>
<marker>Goldberg, Tsarfaty, 2008</marker>
<rawString>Yoav Goldberg and Reut Tsarfaty. 2008. A single generative model for joint morphological segmentation and syntactic parsing. In Proceedings of ACL, pages 371– 379.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
<author>Maria Ant`onia Martf</author>
<author>Llufs M`arquez</author>
<author>Adam Meyers</author>
<author>Joakim Nivre</author>
<author>Sebastian Pad´o</author>
<author>Jan ˇStˇep´anek</author>
<author>Pavel Straˇn´ak</author>
<author>Mihai Surdeanu</author>
<author>Nianwen Xue</author>
<author>Yi Zhang</author>
</authors>
<title>The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 CoNLL Shared Task,</booktitle>
<pages>1--18</pages>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, Martf, M`arquez, Meyers, Nivre, Pad´o, ˇStˇep´anek, Straˇn´ak, Surdeanu, Xue, Zhang, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Ant`onia Martf, Llufs M`arquez, Adam Meyers, Joakim Nivre, Sebastian Pad´o, Jan ˇStˇep´anek, Pavel Straˇn´ak, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The conll-2009 shared task: Syntactic and semantic dependencies in multiple languages. In Proceedings of the 2009 CoNLL Shared Task, pages 1–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Hatori</author>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Incremental joint pos tagging and dependency parsing in chinese.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP,</booktitle>
<pages>1216--1224</pages>
<contexts>
<context position="3129" citStr="Hatori et al. (2011)" startWordPosition="456" endWordPosition="459">or tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discriminative model for joint morphological disambiguation and dependency parsing outperforms a pipeline model in experiments on Latin, Ancient Greek, Czech and Hungarian. However, Li et al. (2011) and Hatori et al. (2011) report improvements with a joint model also for Chinese, which is not a richly inflected language but is nevertheless rich in part-of-speech ambiguities. In this paper, we present a transition-based model for joint part-of-speech tagging and labeled dependency parsing with non-projective trees. Exper1455 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1455–1465, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics iments show that joint modeling improves both taggin</context>
<context position="16819" citStr="Hatori et al. (2011)" startWordPosition="2904" endWordPosition="2907">igure 3: Specialized feature templates for tagging. We use Ei and Bi to denote the ith token in the stack E and buffer B, respectively, with indexing starting at 0, and we use the following functors to extract properties of a token: πi() = ith best tag; s(πi()) = score of ith best tag; π() = finally predicted tag; w() = word form; pi() = word prefix of i characters; si() = word suffix of i characters. Score differences are binned in discrete steps of 0.05. The bulk of features used in our system are taken from Zhang and Nivre (2011), although with two important differences. First of all, like Hatori et al. (2011), we have omitted all features that presuppose an arc-eager parsing order, since our transition system defines an arc-standard order. Secondly, any feature that refers to the part-of-speech tag of a word w in the buffer B will in our system refer to the topscoring tag π1(w), rather than the finally predicted tag. By contrast, for a word in the stack E, part-ofspeech features refer to the tag π(w) chosen when shifting w onto the stack (which may or may not be the same as π1(w)). In addition to the standard features for transitionbased dependency parsing, we have added features specifically to i</context>
<context position="18396" citStr="Hatori et al. (2011)" startWordPosition="3174" endWordPosition="3177">eriments, we make use of two additional feature sets, which we call graph features (G) and cluster features (C), respectively. Graph features are defined over the factors of a graph-based dependency parser, which was shown to improve the accuracy of a transition-based parser by Zhang and Clark (2008). However, while their features were limited to certain first- and second-order factors, we use features over second- and third-order factors as found in the parsers of Bohnet and Kuhn (2012). These features are scored as soon as the factors are completed, using a technique that is similar to what Hatori et al. (2011) call delayed features, although they use it for part-of-speech tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights. It has been observed that most of the computing time in feature-rich parsers is spent retrieving the index of each feature in the weight vector (Bohnet, 2010). This is usually done via a hash table, but significant speedups can be achieved by using a hash kernel, which s</context>
<context position="29282" citStr="Hatori et al. (2011)" startWordPosition="5108" endWordPosition="5111">eatures gives very competitive unlabeled dependency scores for English with 93.38 UAS. To the best of our knowledge, this is the highest score reported for a (transition-based) dependency parser that does not use additional information sources. By adding cluster features and widening the beam to bi = 80, we achieve 93.67 UAS. We also obtain a POS accuracy of 97.42, which is on a par with the best results obtained using semi-supervised taggers 1461 Parser TLAS UAS LAS POS MSTParser1 75.56 93.51 MSTParser2 77.73 93.51 Li et al. (2011) 3rd-order 80.60 92.80 Li et al. (2011) 2nd-order 80.55 93.08 Hatori et al. (2011) HS 79.60 94.01 Hatori et al. (2011) ZN 81.20 93.94 Baseline (k = 1), bl = 40 61.95 80.33 76.79 92.81 Best dev setting, bl = 40 62.54 80.59 77.06 93.11 Adding G, bl = 80 63.20 81.42 77.91 93.24 Table 4: Accuracy scores for Penn Chinese Treebank converted with the head rules of Zhang and Clark (2008). Best dev setting: k = 3, α = 0.1. MSTParser results from Li et al. (2011). UAS scores from Li et al. (2011) and Hatori et al. (2011) recalculated from the separate accuracy scores for root words and non-root words reported in the original papers. (Søgaard, 2011). Table 4 shows the results for the </context>
<context position="30523" citStr="Hatori et al. (2011)" startWordPosition="5343" endWordPosition="5346"> CTB 5.1 together with related work. In experiments with the development set, we could confirm the results from the Chinese CoNLL data set and obtained the best results with the same settings (k = 3, α = 0.1). With bi = 40, UAS improves by 0.25 and POS by 0.30, and the TLAS improvement is again highly significant (p &lt; 0.01, paired t-test). We get the highest UAS, 81.42, with a beam of 80 and added graph features, in which case POS accuracy increases from 92.81 to 93.24. Since our tagger was not optimized for Chinese, we have lower baseline results for the tagger than both Li et al. (2011) and Hatori et al. (2011) but still manage to achieve the highest reported UAS. The speed of the joint tagger and dependency parser is quite reasonable with about 0.4 seconds per sentence on the WSJ-PTB test set, given that we perform tagging and labeled parsing with a beam of 80 while incorporating the features of a third-order graph-based model. Experiments were performed on a computer with an Intel i7-3960X CPU (3.3 GHz and 6 cores). These performance values are preliminary since we are still working on the speed-up of the parser. 3.3 Analysis In order to better understand the benefits of the joint model, we perfor</context>
<context position="34686" citStr="Hatori et al. (2011)" startWordPosition="6076" endWordPosition="6079">nctions thanks to the syntactic information in the joint model. For dependency labels, it is hard to extract any striking patterns and it seems that we mainly see an improvement in overall parsing accuracy thanks to less severe tagging errors. However, it is worth observing that, for both English and German, we see significant F-score improvements for the core grammatical functions subject (91.3 —* 92.1 for German, 95.6 —* 96.1 for English) and object (86.9 —* 87.9 for German, 90.2 —* 91.9 for English). 4 Related Work Our work is most closely related to Lee et al. (2011), Li et al. (2011) and Hatori et al. (2011), who all present discriminative models for joint tagging and dependency parsing. However, all three models only perform unlabeled parsing, while our model incorporates dependency labels into the parsing process. Whereas Lee et al. (2011) and Li et al. (2011) take a graph-based approach to dependency parsing, Hatori et al. (2011) use a transition-based model similar to ours but limited to projective dependency trees. Both Li et al. (2011) and Hatori et al. (2011) only evaluate their model on Chinese, and of these only Hatori et al. (2011) report consistent improvements in both tagging and pars</context>
<context position="36367" citStr="Hatori et al. (2011)" startWordPosition="6352" endWordPosition="6355">andle non-projective dependencies, which is crucial to attain good performance on Czech and German, does not seem to hurt performance on English and Chinese, where the benchmark sets contain only projective trees. The use of beam search in transition-based dependency parsing in order to mitigate the problem of error propagation was first proposed by Johansson and Nugues (2006), although they still used a locally trained model. Globally normalized models were first explored by Titov and Henderson (2007), who were also the first to use a parameterized SHIFT transition like the one found in both Hatori et al. (2011) and our own work, although Titov and Henderson (2007) used it to define a generative model by parameterizing the SHIFT transition by an input word. Zhang and Clark (2008) was the first to combine beam search with a globally normalized discriminative model, using structured perceptron learning and the early update strategy of Collins and Roark (2004), and also explored the addition of graphbased features to a transition-based parser. This approach was further pursued in Zhang and Clark (2011) and was used by Zhang and Nivre (2011) to achieve state-of-the-art results in dependency parsing for b</context>
</contexts>
<marker>Hatori, Matsuzaki, Miyao, Tsujii, 2011</marker>
<rawString>Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2011. Incremental joint pos tagging and dependency parsing in chinese. In Proceedings of IJCNLP, pages 1216–1224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1077--1086</pages>
<contexts>
<context position="4599" citStr="Huang and Sagae, 2010" startWordPosition="673" endWordPosition="676">led dependency parsing. It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representati</context>
<context position="14933" citStr="Huang and Sagae, 2010" startWordPosition="2604" endWordPosition="2607"> j=1 of sentences with their tagged dependency trees, we use a variant of the structured perceptron, introduced by Collins (2002), which makes N iterations over the training data and updates the weight vector for every sentence xj where the highest scoring parse y* is different from yj. More precisely, we use the passive-aggressive update of Crammer et al. (2006): wi+1 = wi +T(f(xj, yj) − f(xj, y*)) where f(xj, yj) − f(xj, y*) ��f(xj,yj) − f(xj,y*)112 We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010), which means that, during learning, we terminate the beam search as soon as the hypothesis corresponding to the gold parse yj falls out of the beam and update with respect to the partial transition sequence constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors, as originally proposed by Collins (2002). 2.3 Feature Representations As already noted, the feature representation f(x, y) of an input sentence x with parse y decomposes into feature representations f(c, t) for the transitions t(c) needed to derive y from cs(x). Features may refer to </context>
<context position="27772" citStr="Huang and Sagae (2010)" startWordPosition="4839" endWordPosition="4842">nk. Row 6, finally, presents results with added cluster features for English and German, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked with † use additional information sources and are not dir</context>
<context position="37062" citStr="Huang and Sagae (2010)" startWordPosition="6466" endWordPosition="6469">a generative model by parameterizing the SHIFT transition by an input word. Zhang and Clark (2008) was the first to combine beam search with a globally normalized discriminative model, using structured perceptron learning and the early update strategy of Collins and Roark (2004), and also explored the addition of graphbased features to a transition-based parser. This approach was further pursued in Zhang and Clark (2011) and was used by Zhang and Nivre (2011) to achieve state-of-the-art results in dependency parsing for both Chinese and English through the addition of rich non-local features. Huang and Sagae (2010) combined structured perceptron learning and beam search with the use of a graph-structured stack to allow ambiguity packing in the beam, a technique that was reused by Hatori et al. (2011). Finally, as noted in the introduction, although joint tagging and parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than Confusion VBN → VBD VBN → JJ|VB|VBP|NN VBZ → NN|NNS VBZ → POS|JJ|RB NN → VBG|VB|VBN|VBD NN → JJ|JJR NN </context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of ACL, pages 1077–1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Investigating multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>206--210</pages>
<contexts>
<context position="36126" citStr="Johansson and Nugues (2006)" startWordPosition="6310" endWordPosition="6313">elines therefore well below the state of the art. We are thus the first to show consistent improvements in both tagging and (labeled) parsing accuracy across typologically diverse languages at the state-of-the-art level. Moreover, the capacity to handle non-projective dependencies, which is crucial to attain good performance on Czech and German, does not seem to hurt performance on English and Chinese, where the benchmark sets contain only projective trees. The use of beam search in transition-based dependency parsing in order to mitigate the problem of error propagation was first proposed by Johansson and Nugues (2006), although they still used a locally trained model. Globally normalized models were first explored by Titov and Henderson (2007), who were also the first to use a parameterized SHIFT transition like the one found in both Hatori et al. (2011) and our own work, although Titov and Henderson (2007) used it to define a generative model by parameterizing the SHIFT transition by an input word. Zhang and Clark (2008) was the first to combine beam search with a globally normalized discriminative model, using structured perceptron learning and the early update strategy of Collins and Roark (2004), and a</context>
</contexts>
<marker>Johansson, Nugues, 2006</marker>
<rawString>Richard Johansson and Pierre Nugues. 2006. Investigating multilingual dependency parsing. In Proceedings of CoNLL, pages 206–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Michael Collins</author>
</authors>
<title>Efficient thirdorder dependency parsers.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1--11</pages>
<contexts>
<context position="1315" citStr="Koo and Collins, 2010" startWordPosition="172" endWordPosition="175">h tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2</context>
<context position="27800" citStr="Koo and Collins (2010)" startWordPosition="4844" endWordPosition="4847"> results with added cluster features for English and German, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked with † use additional information sources and are not directly comparable to the othe</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>Terry Koo and Michael Collins. 2010. Efficient thirdorder dependency parsers. In Proceedings of ACL, pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>595--603</pages>
<contexts>
<context position="18630" citStr="Koo et al. (2008)" startWordPosition="3214" endWordPosition="3217"> accuracy of a transition-based parser by Zhang and Clark (2008). However, while their features were limited to certain first- and second-order factors, we use features over second- and third-order factors as found in the parsers of Bohnet and Kuhn (2012). These features are scored as soon as the factors are completed, using a technique that is similar to what Hatori et al. (2011) call delayed features, although they use it for part-of-speech tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights. It has been observed that most of the computing time in feature-rich parsers is spent retrieving the index of each feature in the weight vector (Bohnet, 2010). This is usually done via a hash table, but significant speedups can be achieved by using a hash kernel, which simply replaces table lookup by a hash function (Bloom, 1970; Shi et al., 2009; Bohnet, 2010). The price to pay for these speedups is that there may be collisions, so that different features are mapped to the same index, but this is of</context>
<context position="27880" citStr="Koo et al. (2008)" startWordPosition="4859" endWordPosition="4862">nal improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked with † use additional information sources and are not directly comparable to the others. but to a lower degree than for the English CoNLL data where we observed an i</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>Terry Koo, Xavier Carreras, and Michael Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings of ACL, pages 595–603.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Alexander M Rush</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
<author>David Sontag</author>
</authors>
<title>Dual decomposition for parsing with non-projective head automata.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1288--1298</pages>
<contexts>
<context position="1528" citStr="Koo et al., 2010" startWordPosition="206" endWordPosition="209">arch efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a pa</context>
</contexts>
<marker>Koo, Rush, Collins, Jaakkola, Sontag, 2010</marker>
<rawString>Terry Koo, Alexander M. Rush, Michael Collins, Tommi Jaakkola, and David Sontag. 2010. Dual decomposition for parsing with non-projective head automata. In Proceedings of EMNLP, pages 1288–1298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency Parsing.</title>
<date>2009</date>
<publisher>Morgan</publisher>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>Sandra K¨ubler, Ryan McDonald, and Joakim Nivre. 2009. Dependency Parsing. Morgan and Claypool.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lee</author>
<author>Jason Naradowsky</author>
<author>David A Smith</author>
</authors>
<title>A discriminative model for joint morphological disambiguation and dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>885--894</pages>
<contexts>
<context position="2893" citStr="Lee et al. (2011)" startWordPosition="419" endWordPosition="422">he Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discriminative model for joint morphological disambiguation and dependency parsing outperforms a pipeline model in experiments on Latin, Ancient Greek, Czech and Hungarian. However, Li et al. (2011) and Hatori et al. (2011) report improvements with a joint model also for Chinese, which is not a richly inflected language but is nevertheless rich in part-of-speech ambiguities. In this paper, we present a transition-based model for joint part-of-speech tagging and labeled dependency parsing with non-projective trees. Exper1455 Proceedings of the 2012 Joint Conference on Empirical Met</context>
<context position="34643" citStr="Lee et al. (2011)" startWordPosition="6067" endWordPosition="6070"> for prepositions or subordinating conjunctions thanks to the syntactic information in the joint model. For dependency labels, it is hard to extract any striking patterns and it seems that we mainly see an improvement in overall parsing accuracy thanks to less severe tagging errors. However, it is worth observing that, for both English and German, we see significant F-score improvements for the core grammatical functions subject (91.3 —* 92.1 for German, 95.6 —* 96.1 for English) and object (86.9 —* 87.9 for German, 90.2 —* 91.9 for English). 4 Related Work Our work is most closely related to Lee et al. (2011), Li et al. (2011) and Hatori et al. (2011), who all present discriminative models for joint tagging and dependency parsing. However, all three models only perform unlabeled parsing, while our model incorporates dependency labels into the parsing process. Whereas Lee et al. (2011) and Li et al. (2011) take a graph-based approach to dependency parsing, Hatori et al. (2011) use a transition-based model similar to ours but limited to projective dependency trees. Both Li et al. (2011) and Hatori et al. (2011) only evaluate their model on Chinese, and of these only Hatori et al. (2011) report consi</context>
</contexts>
<marker>Lee, Naradowsky, Smith, 2011</marker>
<rawString>John Lee, Jason Naradowsky, and David A. Smith. 2011. A discriminative model for joint morphological disambiguation and dependency parsing. In Proceedings of ACL, pages 885–894.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhenghua Li</author>
<author>Min Zhang</author>
<author>Wanxiang Che</author>
<author>Ting Liu</author>
<author>Wenliang Chen</author>
<author>Haizhou Li</author>
</authors>
<title>Joint models for chinese POS tagging and dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1180--1191</pages>
<contexts>
<context position="3104" citStr="Li et al. (2011)" startWordPosition="451" endWordPosition="454">s that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discriminative model for joint morphological disambiguation and dependency parsing outperforms a pipeline model in experiments on Latin, Ancient Greek, Czech and Hungarian. However, Li et al. (2011) and Hatori et al. (2011) report improvements with a joint model also for Chinese, which is not a richly inflected language but is nevertheless rich in part-of-speech ambiguities. In this paper, we present a transition-based model for joint part-of-speech tagging and labeled dependency parsing with non-projective trees. Exper1455 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1455–1465, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics iments show that joint mode</context>
<context position="21336" citStr="Li et al. (2011)" startWordPosition="3684" endWordPosition="3687">9.40 86.40 87.78 90.99 97.43 86.03 87.27 89.60 97.74 3 0.2 74.35 76.48 80.38 93.43 82.85 83.11 88.44 99.32 86.35 87.79 91.01 97.52 86.24 87.37 89.72 97.90 3 0.3 74.18 76.33 80.28 93.48 82.78 83.05 88.38 99.33 85.94 87.57 90.87 96.97 86.35 87.46 89.86 97.90 3 0.4 86.14 87.23 89.66 97.79 Table 1: Accuracy scores for the CoNLL 2009 shared task development sets as a function of the number of tags k and the score threshold α. Beam parameters fixed at b1 = 40, b2 = 4. with the head-finding rules and conversion tools of Zhang and Clark (2008), and with the same split as in Zhang and Clark (2008) and Li et al. (2011).3 For English, this is the WSJ section of the Penn Treebank, converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006).4 In order to assign k-best part-of-speech tags and scores to words in the training set, we used a perceptron tagger with 10-fold jack-knifing. The same type of tagger was trained on the entire training set in order to supply tags for the development and test sets. The feature set of the tagger was optimized for English and German and provides state-of-theart accuracy for these two languages. The 1-best tagging accuracy for se</context>
<context position="29200" citStr="Li et al. (2011)" startWordPosition="5094" endWordPosition="5097"> p &lt; 0.01 (paired t-test). Our joint tagger and dependency parser with graph features gives very competitive unlabeled dependency scores for English with 93.38 UAS. To the best of our knowledge, this is the highest score reported for a (transition-based) dependency parser that does not use additional information sources. By adding cluster features and widening the beam to bi = 80, we achieve 93.67 UAS. We also obtain a POS accuracy of 97.42, which is on a par with the best results obtained using semi-supervised taggers 1461 Parser TLAS UAS LAS POS MSTParser1 75.56 93.51 MSTParser2 77.73 93.51 Li et al. (2011) 3rd-order 80.60 92.80 Li et al. (2011) 2nd-order 80.55 93.08 Hatori et al. (2011) HS 79.60 94.01 Hatori et al. (2011) ZN 81.20 93.94 Baseline (k = 1), bl = 40 61.95 80.33 76.79 92.81 Best dev setting, bl = 40 62.54 80.59 77.06 93.11 Adding G, bl = 80 63.20 81.42 77.91 93.24 Table 4: Accuracy scores for Penn Chinese Treebank converted with the head rules of Zhang and Clark (2008). Best dev setting: k = 3, α = 0.1. MSTParser results from Li et al. (2011). UAS scores from Li et al. (2011) and Hatori et al. (2011) recalculated from the separate accuracy scores for root words and non-root words re</context>
<context position="30498" citStr="Li et al. (2011)" startWordPosition="5338" endWordPosition="5341">Chinese Penn Treebank CTB 5.1 together with related work. In experiments with the development set, we could confirm the results from the Chinese CoNLL data set and obtained the best results with the same settings (k = 3, α = 0.1). With bi = 40, UAS improves by 0.25 and POS by 0.30, and the TLAS improvement is again highly significant (p &lt; 0.01, paired t-test). We get the highest UAS, 81.42, with a beam of 80 and added graph features, in which case POS accuracy increases from 92.81 to 93.24. Since our tagger was not optimized for Chinese, we have lower baseline results for the tagger than both Li et al. (2011) and Hatori et al. (2011) but still manage to achieve the highest reported UAS. The speed of the joint tagger and dependency parser is quite reasonable with about 0.4 seconds per sentence on the WSJ-PTB test set, given that we perform tagging and labeled parsing with a beam of 80 while incorporating the features of a third-order graph-based model. Experiments were performed on a computer with an Intel i7-3960X CPU (3.3 GHz and 6 cores). These performance values are preliminary since we are still working on the speed-up of the parser. 3.3 Analysis In order to better understand the benefits of t</context>
<context position="34661" citStr="Li et al. (2011)" startWordPosition="6071" endWordPosition="6074">r subordinating conjunctions thanks to the syntactic information in the joint model. For dependency labels, it is hard to extract any striking patterns and it seems that we mainly see an improvement in overall parsing accuracy thanks to less severe tagging errors. However, it is worth observing that, for both English and German, we see significant F-score improvements for the core grammatical functions subject (91.3 —* 92.1 for German, 95.6 —* 96.1 for English) and object (86.9 —* 87.9 for German, 90.2 —* 91.9 for English). 4 Related Work Our work is most closely related to Lee et al. (2011), Li et al. (2011) and Hatori et al. (2011), who all present discriminative models for joint tagging and dependency parsing. However, all three models only perform unlabeled parsing, while our model incorporates dependency labels into the parsing process. Whereas Lee et al. (2011) and Li et al. (2011) take a graph-based approach to dependency parsing, Hatori et al. (2011) use a transition-based model similar to ours but limited to projective dependency trees. Both Li et al. (2011) and Hatori et al. (2011) only evaluate their model on Chinese, and of these only Hatori et al. (2011) report consistent improvements</context>
</contexts>
<marker>Li, Zhang, Che, Liu, Chen, Li, 2011</marker>
<rawString>Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wenliang Chen, and Haizhou Li. 2011. Joint models for chinese POS tagging and dependency parsing. In Proceedings of EMNLP, pages 1180–1191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP,</booktitle>
<pages>342--350</pages>
<contexts>
<context position="1487" citStr="Martins et al., 2009" startWordPosition="198" endWordPosition="201">c parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologi</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>Andre Martins, Noah Smith, and Eric Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of ACL-IJCNLP, pages 342–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre Martins</author>
<author>Noah Smith</author>
<author>Eric Xing</author>
<author>Pedro Aguiar</author>
<author>Mario Figueiredo</author>
</authors>
<title>Turbo parsers: Dependency parsing by approximate variational inference.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>34--44</pages>
<contexts>
<context position="1509" citStr="Martins et al., 2010" startWordPosition="202" endWordPosition="205"> focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated us</context>
<context position="27856" citStr="Martins et al. (2010)" startWordPosition="4854" endWordPosition="4857">an, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked with † use additional information sources and are not directly comparable to the others. but to a lower degree than for the English CoNLL dat</context>
</contexts>
<marker>Martins, Smith, Xing, Aguiar, Figueiredo, 2010</marker>
<rawString>Andre Martins, Noah Smith, Eric Xing, Pedro Aguiar, and Mario Figueiredo. 2010. Turbo parsers: Dependency parsing by approximate variational inference. In Proceedings of EMNLP, pages 34–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="1276" citStr="McDonald and Pereira, 2006" startWordPosition="166" endWordPosition="169"> German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selecti</context>
<context position="27716" citStr="McDonald and Pereira (2006)" startWordPosition="4829" endWordPosition="4832">reported for a tagger/parser trained only on the Tiger Treebank. Row 6, finally, presents results with added cluster features for English and German, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked w</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of EACL, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>91--98</pages>
<contexts>
<context position="1248" citStr="McDonald et al., 2005" startWordPosition="162" endWordPosition="165">ese, Czech, English and German shows consistent improvements in both tagging and parsing accuracy when compared to a pipeline system, which lead to improved state-of-theart results for all languages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy</context>
<context position="27683" citStr="McDonald et al. (2005)" startWordPosition="4824" endWordPosition="4827">e highest POS accuracy ever reported for a tagger/parser trained only on the Tiger Treebank. Row 6, finally, presents results with added cluster features for English and German, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting:</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of ACL, pages 91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Memory-based dependency parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<pages>49--56</pages>
<contexts>
<context position="4258" citStr="Nivre et al. (2004)" startWordPosition="619" endWordPosition="622">ciation for Computational Linguistics iments show that joint modeling improves both tagging and parsing accuracy, leading to state-of-the-art accuracy for richly inflected languages like Czech and German as well as more configurational languages like Chinese and English. To our knowledge, this is the first joint system that performs labeled dependency parsing. It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; N</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2004</marker>
<rawString>Joakim Nivre, Johan Hall, and Jens Nilsson. 2004. Memory-based dependency parsing. In Proceedings of CoNLL, pages 49–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Inductive Dependency Parsing.</title>
<date>2006</date>
<publisher>Springer.</publisher>
<contexts>
<context position="21505" citStr="Nivre (2006)" startWordPosition="3716" endWordPosition="3717">80.28 93.48 82.78 83.05 88.38 99.33 85.94 87.57 90.87 96.97 86.35 87.46 89.86 97.90 3 0.4 86.14 87.23 89.66 97.79 Table 1: Accuracy scores for the CoNLL 2009 shared task development sets as a function of the number of tags k and the score threshold α. Beam parameters fixed at b1 = 40, b2 = 4. with the head-finding rules and conversion tools of Zhang and Clark (2008), and with the same split as in Zhang and Clark (2008) and Li et al. (2011).3 For English, this is the WSJ section of the Penn Treebank, converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006).4 In order to assign k-best part-of-speech tags and scores to words in the training set, we used a perceptron tagger with 10-fold jack-knifing. The same type of tagger was trained on the entire training set in order to supply tags for the development and test sets. The feature set of the tagger was optimized for English and German and provides state-of-theart accuracy for these two languages. The 1-best tagging accuracy for section 23 of the Penn Treebank is 97.28, which is on a par with Toutanova et al. (2003). For German, we obtain a tagging accuracy of 97.24, which is close to the 97.39 ac</context>
<context position="27451" citStr="Nivre (2006)" startWordPosition="4778" endWordPosition="4779">re reported for this data set, together with state-of-the-art POS accuracy. For German, we obtain 89.05 LAS and 97.78 POS, which in both cases is substantially better than in the CoNLL shared task. We believe it is also the highest POS accuracy ever reported for a tagger/parser trained only on the Tiger Treebank. Row 6, finally, presents results with added cluster features for English and German, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Add</context>
</contexts>
<marker>Nivre, 2006</marker>
<rawString>Joakim Nivre. 2006. Inductive Dependency Parsing. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Incremental non-projective dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL HLT,</booktitle>
<pages>396--403</pages>
<contexts>
<context position="4868" citStr="Nivre, 2007" startWordPosition="716" endWordPosition="717">), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of part-of-speech tags and a set D of dependency labels, a tagged dependency tree for a sentence x = w1, ... , wn is a directed tree T = (Vx, A) with labeling functions 7r and 6 such that: 1. Vx = 10, 1, ... , n} is a set of nod</context>
</contexts>
<marker>Nivre, 2007</marker>
<rawString>Joakim Nivre. 2007. Incremental non-projective dependency parsing. In Proceedings of NAACL HLT, pages 396–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for deterministic incremental dependency parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<pages>34--513</pages>
<contexts>
<context position="6230" citStr="Nivre (2008)" startWordPosition="981" endWordPosition="982"> of the tree. The set Vx of nodes is the set of positive integers up to and including n, each corresponding to the linear position of a word in the sentence, plus an extra artificial root node 0. The set A of arcs is a set of pairs (i, j), where i is the head node and j is the dependent node. The functions 7r and 6 assign a unique part-of-speech label to each node/word and a unique dependency label to each arc, respectively. This notion of dependency tree differs from the standard definition only by including part-of-speech labels as well as dependency labels (K¨ubler et al., 2009). Following Nivre (2008), we define a transition system for dependency parsing as a quadruple 5 = (C, T, cs, Ct), where 1. C is a set of configurations, 2. T is a set of transitions, each of which is a (partial) function t : C —* C, 3. cs is an initialization function, mapping a sentence x to a configuration c E C, 4. Ct C C is a set of terminal configurations. A transition sequence for a sentence x in 5 is a sequence of configuration-transition pairs C0,m = [(c0, t0), (c1, t1), ... , (cm, tm)] where c0 = cs(x), tm(cm) E Ct and ti(ci) = ci+1 (0 &lt; i &lt; m).1 In this paper, we take the set C of configurations to be the s</context>
<context position="7947" citStr="Nivre (2008)" startWordPosition="1334" endWordPosition="1335"> = ([0], [ ], A, 7r, 6) (for any A, 7r and 6). The tagged dependency tree defined for x by c = (E, B, A, 7r, 6) is the tree (Vx, A) with labeling functions 7r and 6, which we write TREE(x, c). The set T of transitions is shown in Figure 1. The LEFT-ARCd and RIGHT-ARCd transitions both add an arc (with dependency label d) between the two nodes on top of the stack and replaces these nodes by the head node of the new arc (which is the rightmost node for LEFT-ARCd and the leftmost node for RIGHT-ARCd). The SHIFTp transition extracts the 1This definition of transition sequence differs from that of Nivre (2008) but is equivalent and suits our presentation better. 1456 Transition Condition LEFT-ARCd ([σ|i, j], B, A, π, δ) ⇒ ([σ|j], B, A∪{(j, i)}, π, δ[(j, i) → d]) i 7� 0 RIGHT-ARCd ([σ|i, j], B, A, π, δ) ⇒ ([σ|i], B, A∪{(i, j)}, π, δ[(i, j) → d]) SHIFTp (σ, [i|β], A, π, δ) ⇒ ([σ|i], β, A, π[i → p], δ) SWAP ([σ|i, j], β, A, π, δ) ⇒ ([σ|j], [i|β], A, π, δ) 0 &lt; i &lt; j Figure 1: Transitions for joint tagging and dependency parsing extending the system of Nivre (2009). The stack E is represented as a list with its head to the right (and tail σ) and the buffer B as a list with its head to the left (and tail</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for deterministic incremental dependency parsing. Computational Linguistics, 34:513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Non-projective dependency parsing in expected linear time.</title>
<date>2009</date>
<booktitle>In Proceedings of ACLIJCNLP,</booktitle>
<pages>351--359</pages>
<contexts>
<context position="4881" citStr="Nivre, 2009" startWordPosition="718" endWordPosition="719">lassifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of part-of-speech tags and a set D of dependency labels, a tagged dependency tree for a sentence x = w1, ... , wn is a directed tree T = (Vx, A) with labeling functions 7r and 6 such that: 1. Vx = 10, 1, ... , n} is a set of nodes, 2. A C Vx</context>
<context position="8406" citStr="Nivre (2009)" startWordPosition="1429" endWordPosition="1430">-ARCd and the leftmost node for RIGHT-ARCd). The SHIFTp transition extracts the 1This definition of transition sequence differs from that of Nivre (2008) but is equivalent and suits our presentation better. 1456 Transition Condition LEFT-ARCd ([σ|i, j], B, A, π, δ) ⇒ ([σ|j], B, A∪{(j, i)}, π, δ[(j, i) → d]) i 7� 0 RIGHT-ARCd ([σ|i, j], B, A, π, δ) ⇒ ([σ|i], B, A∪{(i, j)}, π, δ[(i, j) → d]) SHIFTp (σ, [i|β], A, π, δ) ⇒ ([σ|i], β, A, π[i → p], δ) SWAP ([σ|i, j], β, A, π, δ) ⇒ ([σ|j], [i|β], A, π, δ) 0 &lt; i &lt; j Figure 1: Transitions for joint tagging and dependency parsing extending the system of Nivre (2009). The stack E is represented as a list with its head to the right (and tail σ) and the buffer B as a list with its head to the left (and tail β). The notation f[a → b] is used to denote the function that is exactly like f except that it maps a to b. first node in the buffer, pushes it onto the stack and labels it with the part-of-speech tag p. The SWAP transition extracts the second topmost node from the stack and moves it back to the buffer, subject to the condition that the two top nodes on the stack are still in the order given by the sentence. Except for the addition of a tag parameter p t</context>
</contexts>
<marker>Nivre, 2009</marker>
<rawString>Joakim Nivre. 2009. Non-projective dependency parsing in expected linear time. In Proceedings of ACLIJCNLP, pages 351–359.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of NAACL HLT,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="2340" citStr="Petrov and Klein, 2007" startWordPosition="332" endWordPosition="335"> 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discriminative model for joint mor</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of NAACL HLT, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL,</booktitle>
<pages>433--440</pages>
<contexts>
<context position="2315" citStr="Petrov et al., 2006" startWordPosition="328" endWordPosition="331">008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might improve accuracy also in the case of dependency parsing. It has been argued that joint morphological and syntactic disambiguation is especially important for richly inflected languages, where there is considerable interaction between morphology and syntax such that neither can be fully disambiguated without considering the other. Thus, Lee et al. (2011) show that a discrimin</context>
<context position="37818" citStr="Petrov et al., 2006" startWordPosition="6586" endWordPosition="6589">, a technique that was reused by Hatori et al. (2011). Finally, as noted in the introduction, although joint tagging and parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than Confusion VBN → VBD VBN → JJ|VB|VBP|NN VBZ → NN|NNS VBZ → POS|JJ|RB NN → VBG|VB|VBN|VBD NN → JJ|JJR NN → NN*|RB|IN|DT RB → IN RB → JJ*|RP|NN*|RBR|UH 1463 with a pipeline approach (Collins, 1997; Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing. 5 Conclusion We have presented the first system for joint partof-speech tagging and labeled dependency parsing with non-projective dependency trees. Evaluation on four languages shows consistent improvements in both tagging and parsing accuracy over a pipeline system with state-of-the-art results across the board. The error analysis reveals improvements in tagging accuracy for synt</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of COLING/ACL, pages 433–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>James Clarke</author>
</authors>
<title>Incremental integer linear programming for non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>129--137</pages>
<contexts>
<context position="1441" citStr="Riedel and Clarke, 2006" startWordPosition="190" endWordPosition="193">nguages. 1 Introduction Dependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the w</context>
</contexts>
<marker>Riedel, Clarke, 2006</marker>
<rawString>Sebastian Riedel and James Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proceedings of EMNLP, pages 129– 137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
<author>Florian Laws</author>
</authors>
<title>Estimation of conditional probabilities with decision trees and an application to fine-grained POS tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>777--784</pages>
<contexts>
<context position="22152" citStr="Schmid and Laws, 2008" startWordPosition="3830" endWordPosition="3833">est part-of-speech tags and scores to words in the training set, we used a perceptron tagger with 10-fold jack-knifing. The same type of tagger was trained on the entire training set in order to supply tags for the development and test sets. The feature set of the tagger was optimized for English and German and provides state-of-theart accuracy for these two languages. The 1-best tagging accuracy for section 23 of the Penn Treebank is 97.28, which is on a par with Toutanova et al. (2003). For German, we obtain a tagging accuracy of 97.24, which is close to the 97.39 achieved by the RF-Tagger (Schmid and Laws, 2008), which to our knowledge is the best tagger for German.5 The results are not directly comparable to the RF-Tagger as it was evaluated on a different part of the Tiger Treebank and trained on a larger part of the Treebank. We could not use the larger training set as it contains the test set of the CoNLL 2009 data that we use to evaluate the joint model. For Czech, the 1- best tagging accuracy is 99.11 and for Chinese 92.65 on the CoNLL 2009 test set. We trained parsers with 25 iterations and report 3Training: 001–815, 1001–1136. Development: 886–931, 1148–1151. Test: 816–885, 1137–1147. 4Traini</context>
</contexts>
<marker>Schmid, Laws, 2008</marker>
<rawString>Helmut Schmid and Florian Laws. 2008. Estimation of conditional probabilities with decision trees and an application to fine-grained POS tagging. In Proceedings of COLING, pages 777–784.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qinfeng Shi</author>
<author>James Petterson</author>
<author>Gideon Dror</author>
<author>John Langford</author>
<author>Alex Smola</author>
<author>Alex Strehl</author>
<author>S V N Vishwanathan</author>
</authors>
<title>Hash Kernels for Structured Data. In</title>
<date>2009</date>
<journal>Journal of Machine Learning.</journal>
<contexts>
<context position="19073" citStr="Shi et al., 2009" startWordPosition="3292" endWordPosition="3295">ch tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 We use a hash kernel to map features to weights. It has been observed that most of the computing time in feature-rich parsers is spent retrieving the index of each feature in the weight vector (Bohnet, 2010). This is usually done via a hash table, but significant speedups can be achieved by using a hash kernel, which simply replaces table lookup by a hash function (Bloom, 1970; Shi et al., 2009; Bohnet, 2010). The price to pay for these speedups is that there may be collisions, so that different features are mapped to the same index, but this is often compensated by the fact that the lower time and memory requirements of the hash kernel enables the use of negative features, that is, features that are never seen in the training set but occur in erroneous hypotheses at training time and can therefore be helpful also at inference time. As a result, the hash kernel often improves accuracy as well as efficiency compared to traditional techniques that only make use of features that occur </context>
</contexts>
<marker>Shi, Petterson, Dror, Langford, Smola, Strehl, Vishwanathan, 2009</marker>
<rawString>Qinfeng Shi, James Petterson, Gideon Dror, John Langford, Alex Smola, Alex Strehl, and S V N Vishwanathan. 2009. Hash Kernels for Structured Data. In Journal of Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Dependency parsing by belief propagation.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>145--156</pages>
<contexts>
<context position="1465" citStr="Smith and Eisner, 2008" startWordPosition="194" endWordPosition="197">ependency-based syntactic parsing has been the focus of intense research efforts during the last decade, and the state of the art today is represented by globally normalized discriminative models that are induced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentenc</context>
</contexts>
<marker>Smith, Eisner, 2008</marker>
<rawString>David Smith and Jason Eisner. 2008. Dependency parsing by belief propagation. In Proceedings of EMNLP, pages 145–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
</authors>
<title>Semi-supervised condensed nearest neighbor for part-of-speech tagging.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>48--52</pages>
<contexts>
<context position="29846" citStr="Søgaard, 2011" startWordPosition="5216" endWordPosition="5217"> (2011) 2nd-order 80.55 93.08 Hatori et al. (2011) HS 79.60 94.01 Hatori et al. (2011) ZN 81.20 93.94 Baseline (k = 1), bl = 40 61.95 80.33 76.79 92.81 Best dev setting, bl = 40 62.54 80.59 77.06 93.11 Adding G, bl = 80 63.20 81.42 77.91 93.24 Table 4: Accuracy scores for Penn Chinese Treebank converted with the head rules of Zhang and Clark (2008). Best dev setting: k = 3, α = 0.1. MSTParser results from Li et al. (2011). UAS scores from Li et al. (2011) and Hatori et al. (2011) recalculated from the separate accuracy scores for root words and non-root words reported in the original papers. (Søgaard, 2011). Table 4 shows the results for the Chinese Penn Treebank CTB 5.1 together with related work. In experiments with the development set, we could confirm the results from the Chinese CoNLL data set and obtained the best results with the same settings (k = 3, α = 0.1). With bi = 40, UAS improves by 0.25 and POS by 0.30, and the TLAS improvement is again highly significant (p &lt; 0.01, paired t-test). We get the highest UAS, 81.42, with a beam of 80 and added graph features, in which case POS accuracy increases from 92.81 to 93.24. Since our tagger was not optimized for Chinese, we have lower baseli</context>
</contexts>
<marker>Søgaard, 2011</marker>
<rawString>Anders Søgaard. 2011. Semi-supervised condensed nearest neighbor for part-of-speech tagging. In Proceedings of ACL, pages 48–52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>An empirical study of semi-supervised structured conditional models for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>551--560</pages>
<contexts>
<context position="27939" citStr="Suzuki et al. (2009)" startWordPosition="4871" endWordPosition="4874">ts for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked with † use additional information sources and are not directly comparable to the others. but to a lower degree than for the English CoNLL data where we observed an improvement of 0.20. Nonetheless, the improvement in the joi</context>
</contexts>
<marker>Suzuki, Isozaki, Carreras, Collins, 2009</marker>
<rawString>Jun Suzuki, Hideki Isozaki, Xavier Carreras, and Michael Collins. 2009. An empirical study of semi-supervised structured conditional models for dependency parsing. In Proceedings of EMNLP, pages 551–560.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
</authors>
<title>A latent variable model for generative dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of IWPT,</booktitle>
<pages>144--155</pages>
<contexts>
<context position="1676" citStr="Titov and Henderson, 2007" startWordPosition="227" endWordPosition="230">uced using structured learning. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and t</context>
<context position="36254" citStr="Titov and Henderson (2007)" startWordPosition="6330" endWordPosition="6333">led) parsing accuracy across typologically diverse languages at the state-of-the-art level. Moreover, the capacity to handle non-projective dependencies, which is crucial to attain good performance on Czech and German, does not seem to hurt performance on English and Chinese, where the benchmark sets contain only projective trees. The use of beam search in transition-based dependency parsing in order to mitigate the problem of error propagation was first proposed by Johansson and Nugues (2006), although they still used a locally trained model. Globally normalized models were first explored by Titov and Henderson (2007), who were also the first to use a parameterized SHIFT transition like the one found in both Hatori et al. (2011) and our own work, although Titov and Henderson (2007) used it to define a generative model by parameterizing the SHIFT transition by an input word. Zhang and Clark (2008) was the first to combine beam search with a globally normalized discriminative model, using structured perceptron learning and the early update strategy of Collins and Roark (2004), and also explored the addition of graphbased features to a transition-based parser. This approach was further pursued in Zhang and Cl</context>
</contexts>
<marker>Titov, Henderson, 2007</marker>
<rawString>Ivan Titov and James Henderson. 2007. A latent variable model for generative dependency parsing. In Proceedings of IWPT, pages 144–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
<author>Paola Merlo</author>
<author>Gabriele Musillo</author>
</authors>
<title>Online graph planarization for synchronous parsing of semantic and syntactic dependencies.</title>
<date>2009</date>
<booktitle>In Proceedings of IJCAI.</booktitle>
<contexts>
<context position="4902" citStr="Titov et al., 2009" startWordPosition="720" endWordPosition="723">ained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of part-of-speech tags and a set D of dependency labels, a tagged dependency tree for a sentence x = w1, ... , wn is a directed tree T = (Vx, A) with labeling functions 7r and 6 such that: 1. Vx = 10, 1, ... , n} is a set of nodes, 2. A C Vx x Vx is a set of arc</context>
</contexts>
<marker>Titov, Henderson, Merlo, Musillo, 2009</marker>
<rawString>Ivan Titov, James Henderson, Paola Merlo, and Gabriele Musillo. 2009. Online graph planarization for synchronous parsing of semantic and syntactic dependencies. In Proceedings of IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-of-speech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>252--259</pages>
<contexts>
<context position="22022" citStr="Toutanova et al. (2003)" startWordPosition="3806" endWordPosition="3809">onverted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006).4 In order to assign k-best part-of-speech tags and scores to words in the training set, we used a perceptron tagger with 10-fold jack-knifing. The same type of tagger was trained on the entire training set in order to supply tags for the development and test sets. The feature set of the tagger was optimized for English and German and provides state-of-theart accuracy for these two languages. The 1-best tagging accuracy for section 23 of the Penn Treebank is 97.28, which is on a par with Toutanova et al. (2003). For German, we obtain a tagging accuracy of 97.24, which is close to the 97.39 achieved by the RF-Tagger (Schmid and Laws, 2008), which to our knowledge is the best tagger for German.5 The results are not directly comparable to the RF-Tagger as it was evaluated on a different part of the Tiger Treebank and trained on a larger part of the Treebank. We could not use the larger training set as it contains the test set of the CoNLL 2009 data that we use to evaluate the joint model. For Czech, the 1- best tagging accuracy is 99.11 and for Chinese 92.65 on the CoNLL 2009 test set. We trained parse</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-of-speech tagging with a cyclic dependency network. In Proceedings of NAACL, pages 252–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reut Tsarfaty</author>
</authors>
<title>Integrated morphological and syntactic disambiguation for modern hebrew.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Student Research Workshop,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="37933" citStr="Tsarfaty (2006)" startWordPosition="6605" endWordPosition="6606"> parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albeit not always tagging accuracy) with a joint model than Confusion VBN → VBD VBN → JJ|VB|VBP|NN VBZ → NN|NNS VBZ → POS|JJ|RB NN → VBG|VB|VBN|VBD NN → JJ|JJR NN → NN*|RB|IN|DT RB → IN RB → JJ*|RP|NN*|RBR|UH 1463 with a pipeline approach (Collins, 1997; Charniak, 2000; Charniak and Johnson, 2005; Petrov et al., 2006). Models that in addition incorporate morphological analysis and segmentation have been explored by Tsarfaty (2006), Cohen and Smith (2007), and Goldberg and Tsarfaty (2008) with special reference to Hebrew parsing. 5 Conclusion We have presented the first system for joint partof-speech tagging and labeled dependency parsing with non-projective dependency trees. Evaluation on four languages shows consistent improvements in both tagging and parsing accuracy over a pipeline system with state-of-the-art results across the board. The error analysis reveals improvements in tagging accuracy for syntactically central categories, mainly verbs, with improvement in syntactic accuracy for core grammatical functions a</context>
</contexts>
<marker>Tsarfaty, 2006</marker>
<rawString>Reut Tsarfaty. 2006. Integrated morphological and syntactic disambiguation for modern hebrew. In Proceedings of the COLING/ACL 2006 Student Research Workshop, pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of IWPT,</booktitle>
<pages>195--206</pages>
<contexts>
<context position="4234" citStr="Yamada and Matsumoto (2003)" startWordPosition="614" endWordPosition="617">ea, 12–14 July 2012. c�2012 Association for Computational Linguistics iments show that joint modeling improves both tagging and parsing accuracy, leading to state-of-the-art accuracy for richly inflected languages like Czech and German as well as more configurational languages like Chinese and English. To our knowledge, this is the first joint system that performs labeled dependency parsing. It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early s</context>
<context position="21466" citStr="Yamada and Matsumoto (2003)" startWordPosition="3706" endWordPosition="3710">91.01 97.52 86.24 87.37 89.72 97.90 3 0.3 74.18 76.33 80.28 93.48 82.78 83.05 88.38 99.33 85.94 87.57 90.87 96.97 86.35 87.46 89.86 97.90 3 0.4 86.14 87.23 89.66 97.79 Table 1: Accuracy scores for the CoNLL 2009 shared task development sets as a function of the number of tags k and the score threshold α. Beam parameters fixed at b1 = 40, b2 = 4. with the head-finding rules and conversion tools of Zhang and Clark (2008), and with the same split as in Zhang and Clark (2008) and Li et al. (2011).3 For English, this is the WSJ section of the Penn Treebank, converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006).4 In order to assign k-best part-of-speech tags and scores to words in the training set, we used a perceptron tagger with 10-fold jack-knifing. The same type of tagger was trained on the entire training set in order to supply tags for the development and test sets. The feature set of the tagger was optimized for English and German and provides state-of-theart accuracy for these two languages. The 1-best tagging accuracy for section 23 of the Penn Treebank is 97.28, which is on a par with Toutanova et al. (2003). For German, we obtain a tagging accuracy o</context>
<context position="27412" citStr="Yamada and Matsumoto (2003)" startWordPosition="4769" endWordPosition="4772">ech, we get 83.73 LAS, which is by far the highest score reported for this data set, together with state-of-the-art POS accuracy. For German, we obtain 89.05 LAS and 97.78 POS, which in both cases is substantially better than in the CoNLL shared task. We believe it is also the highest POS accuracy ever reported for a tagger/parser trained only on the Tiger Treebank. Row 6, finally, presents results with added cluster features for English and German, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setti</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of IWPT, pages 195–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>562--571</pages>
<contexts>
<context position="1699" citStr="Zhang and Clark, 2008" startWordPosition="231" endWordPosition="234">ing. Graphbased models parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Pet</context>
<context position="4576" citStr="Zhang and Clark, 2008" startWordPosition="669" endWordPosition="672">stem that performs labeled dependency parsing. It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussi</context>
<context position="14909" citStr="Zhang and Clark, 2008" startWordPosition="2600" endWordPosition="2603">training set {(xj, yj)1 j=1 of sentences with their tagged dependency trees, we use a variant of the structured perceptron, introduced by Collins (2002), which makes N iterations over the training data and updates the weight vector for every sentence xj where the highest scoring parse y* is different from yj. More precisely, we use the passive-aggressive update of Crammer et al. (2006): wi+1 = wi +T(f(xj, yj) − f(xj, y*)) where f(xj, yj) − f(xj, y*) ��f(xj,yj) − f(xj,y*)112 We also use the early update strategy found beneficial for parsing in several previous studies (Collins and Roark, 2004; Zhang and Clark, 2008; Huang and Sagae, 2010), which means that, during learning, we terminate the beam search as soon as the hypothesis corresponding to the gold parse yj falls out of the beam and update with respect to the partial transition sequence constructed up to that point. Finally, we use the standard technique of averaging over all weight vectors, as originally proposed by Collins (2002). 2.3 Feature Representations As already noted, the feature representation f(x, y) of an input sentence x with parse y decomposes into feature representations f(c, t) for the transitions t(c) needed to derive y from cs(x)</context>
<context position="18077" citStr="Zhang and Clark (2008)" startWordPosition="3121" endWordPosition="3124"> model. The templates for these features, which are specified in Figure 3, all involve the ith best tag assigned to the first word of the buffer B (the next word to be shifted in a SHIFTP transition) in combination with neighboring words, word prefixes, word suffixes, score differences and tag rank. Finally, in some experiments, we make use of two additional feature sets, which we call graph features (G) and cluster features (C), respectively. Graph features are defined over the factors of a graph-based dependency parser, which was shown to improve the accuracy of a transition-based parser by Zhang and Clark (2008). However, while their features were limited to certain first- and second-order factors, we use features over second- and third-order factors as found in the parsers of Bohnet and Kuhn (2012). These features are scored as soon as the factors are completed, using a technique that is similar to what Hatori et al. (2011) call delayed features, although they use it for part-of-speech tags in the lookahead while we use it for subgraphs of the dependency tree. Cluster features, finally, are features over word clusters, as first used by Koo et al. (2008), which replace part-of-speech tag features.2 W</context>
<context position="21261" citStr="Zhang and Clark (2008)" startWordPosition="3668" endWordPosition="3671">2 97.49 86.12 87.22 89.69 97.85 3 0.1 74.47 76.63 80.50 93.38 82.76 82.97 88.33 99.40 86.40 87.78 90.99 97.43 86.03 87.27 89.60 97.74 3 0.2 74.35 76.48 80.38 93.43 82.85 83.11 88.44 99.32 86.35 87.79 91.01 97.52 86.24 87.37 89.72 97.90 3 0.3 74.18 76.33 80.28 93.48 82.78 83.05 88.38 99.33 85.94 87.57 90.87 96.97 86.35 87.46 89.86 97.90 3 0.4 86.14 87.23 89.66 97.79 Table 1: Accuracy scores for the CoNLL 2009 shared task development sets as a function of the number of tags k and the score threshold α. Beam parameters fixed at b1 = 40, b2 = 4. with the head-finding rules and conversion tools of Zhang and Clark (2008), and with the same split as in Zhang and Clark (2008) and Li et al. (2011).3 For English, this is the WSJ section of the Penn Treebank, converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006).4 In order to assign k-best part-of-speech tags and scores to words in the training set, we used a perceptron tagger with 10-fold jack-knifing. The same type of tagger was trained on the entire training set in order to supply tags for the development and test sets. The feature set of the tagger was optimized for English and German and provides state-of-</context>
<context position="27744" citStr="Zhang and Clark (2008)" startWordPosition="4834" endWordPosition="4837">ned only on the Tiger Treebank. Row 6, finally, presents results with added cluster features for English and German, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked with † use additional informa</context>
<context position="29582" citStr="Zhang and Clark (2008)" startWordPosition="5166" endWordPosition="5169">i = 80, we achieve 93.67 UAS. We also obtain a POS accuracy of 97.42, which is on a par with the best results obtained using semi-supervised taggers 1461 Parser TLAS UAS LAS POS MSTParser1 75.56 93.51 MSTParser2 77.73 93.51 Li et al. (2011) 3rd-order 80.60 92.80 Li et al. (2011) 2nd-order 80.55 93.08 Hatori et al. (2011) HS 79.60 94.01 Hatori et al. (2011) ZN 81.20 93.94 Baseline (k = 1), bl = 40 61.95 80.33 76.79 92.81 Best dev setting, bl = 40 62.54 80.59 77.06 93.11 Adding G, bl = 80 63.20 81.42 77.91 93.24 Table 4: Accuracy scores for Penn Chinese Treebank converted with the head rules of Zhang and Clark (2008). Best dev setting: k = 3, α = 0.1. MSTParser results from Li et al. (2011). UAS scores from Li et al. (2011) and Hatori et al. (2011) recalculated from the separate accuracy scores for root words and non-root words reported in the original papers. (Søgaard, 2011). Table 4 shows the results for the Chinese Penn Treebank CTB 5.1 together with related work. In experiments with the development set, we could confirm the results from the Chinese CoNLL data set and obtained the best results with the same settings (k = 3, α = 0.1). With bi = 40, UAS improves by 0.25 and POS by 0.30, and the TLAS impr</context>
<context position="36538" citStr="Zhang and Clark (2008)" startWordPosition="6382" endWordPosition="6385">enchmark sets contain only projective trees. The use of beam search in transition-based dependency parsing in order to mitigate the problem of error propagation was first proposed by Johansson and Nugues (2006), although they still used a locally trained model. Globally normalized models were first explored by Titov and Henderson (2007), who were also the first to use a parameterized SHIFT transition like the one found in both Hatori et al. (2011) and our own work, although Titov and Henderson (2007) used it to define a generative model by parameterizing the SHIFT transition by an input word. Zhang and Clark (2008) was the first to combine beam search with a globally normalized discriminative model, using structured perceptron learning and the early update strategy of Collins and Roark (2004), and also explored the addition of graphbased features to a transition-based parser. This approach was further pursued in Zhang and Clark (2011) and was used by Zhang and Nivre (2011) to achieve state-of-the-art results in dependency parsing for both Chinese and English through the addition of rich non-local features. Huang and Sagae (2010) combined structured perceptron learning and beam search with the use of a g</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Yue Zhang and Stephen Clark. 2008. A tale of two parsers: Investigating and combining graph-based and transition-based dependency parsing. In Proceedings of EMNLP, pages 562–571.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Syntactic processing using the generalized perceptron and beam search.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<pages>37--105</pages>
<contexts>
<context position="1723" citStr="Zhang and Clark, 2011" startWordPosition="235" endWordPosition="238">parameterize the parsing problem by the structure of the dependency graph and normally use dynamic programming for inference (McDonald et al., 2005; McDonald and Pereira, 2006; Carreras, 2007; Koo and Collins, 2010; Bohnet, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov</context>
<context position="4622" citStr="Zhang and Clark, 2011" startWordPosition="677" endWordPosition="680"> It is also the first joint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition Sys</context>
<context position="36864" citStr="Zhang and Clark (2011)" startWordPosition="6433" endWordPosition="6436">erson (2007), who were also the first to use a parameterized SHIFT transition like the one found in both Hatori et al. (2011) and our own work, although Titov and Henderson (2007) used it to define a generative model by parameterizing the SHIFT transition by an input word. Zhang and Clark (2008) was the first to combine beam search with a globally normalized discriminative model, using structured perceptron learning and the early update strategy of Collins and Roark (2004), and also explored the addition of graphbased features to a transition-based parser. This approach was further pursued in Zhang and Clark (2011) and was used by Zhang and Nivre (2011) to achieve state-of-the-art results in dependency parsing for both Chinese and English through the addition of rich non-local features. Huang and Sagae (2010) combined structured perceptron learning and beam search with the use of a graph-structured stack to allow ambiguity packing in the beam, a technique that was reused by Hatori et al. (2011). Finally, as noted in the introduction, although joint tagging and parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usuall</context>
</contexts>
<marker>Zhang, Clark, 2011</marker>
<rawString>Yue Zhang and Stephen Clark. 2011. Syntactic processing using the generalized perceptron and beam search. Computational Linguistics, 37:105–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="1941" citStr="Zhang and Nivre, 2011" startWordPosition="265" endWordPosition="268">net, 2010), but other inference methods have been explored especially for non-projective parsing (Riedel and Clarke, 2006; Smith and Eisner, 2008; Martins et al., 2009; Martins et al., 2010; Koo et al., 2010). Transitionbased models parameterize the problem by elementary parsing actions and typically use incremental beam search (Titov and Henderson, 2007; Zhang and Clark, 2008; Zhang and Clark, 2011). Despite notable differences in model structure, graph-based and transition-based parsers both give state-of-theart accuracy with proper feature selection and optimization (Koo and Collins, 2010; Zhang and Nivre, 2011; Bohnet, 2011). It is noteworthy, however, that almost all dependency parsers presuppose that the words of an input sentence have been morphologically disambiguated using (at least) a part-of-speech tagger. This is in stark contrast to the best parsers based on PCFG models, such as the Brown parser (Charniak and Johnson, 2005) and the Berkeley parser (Petrov et al., 2006; Petrov and Klein, 2007), which not only can perform their own part-of-speech tagging but normally give better parsing accuracy when they are allowed to do so. This suggests that joint models for tagging and parsing might imp</context>
<context position="4645" citStr="Zhang and Nivre, 2011" startWordPosition="681" endWordPosition="684">oint system that achieves state-of-the-art accuracy for non-projective dependency parsing. 2 Transition-Based Tagging and Parsing Transition-based dependency parsing was pioneered by Yamada and Matsumoto (2003) and Nivre et al. (2004), who used classifiers trained to predict individual actions of a deterministic shift-reduce parser. Recent research has shown that better accuracy can be achieved by using beam search and optimizing models on the entire sequence of decisions needed to parse a sentence instead of single actions (Zhang and Clark, 2008; Huang and Sagae, 2010; Zhang and Clark, 2011; Zhang and Nivre, 2011; Bohnet, 2011). In addition, a number of different transition systems have been proposed, in particular for dealing with non-projective dependencies, which were beyond the scope of early systems (Attardi, 2006; Nivre, 2007; Nivre, 2009; Titov et al., 2009). In this section, we start by defining a transition system for joint tagging and parsing based on the non-projective transition system proposed in Nivre (2009). We then show how to perform beam search and structured online learning with this model, and conclude by discussing feature representations. 2.1 Transition System Given a set P of pa</context>
<context position="9928" citStr="Zhang and Nivre (2011)" startWordPosition="1700" endWordPosition="1703"> a terminal configuration can be reached, every word has to be pushed onto the stack in a SHIFTp transition, which ensures that every node/word in the output tree will be tagged. 2.2 Inference and Learning While early transition-based parsers generally used greedy best-first inference and locally trained classifiers, recent work has shown that higher accuracy can be obtained using beam search and global structure learning to mitigate error propagation. In particular, it seems that the globally learned models can exploit a much richer feature space than locally trained classifiers, as shown by Zhang and Nivre (2011). Since joint tagging and parsing increases the size of the search space and is likely to require novel features, we use beam search in combination with structured perceptron learning. The beam search algorithm used to derive the best parse y for a sentence x is outlined in Figure 2. In addition to the sentence x, it takes as input a weight vector w corresponding to a linear model for scoring transitions out of configurations and two prunPARSE(x, w, b1, b2) 1 h0.c ← cs(x) 2 h0.s ← 0.0 3 h0.f ← {0.0}d�-(w) 4 BEAM ← [h0] 5 while ∃h ∈ BEAM: h.c ∈6 Ct 6 TMP ← [ ] 7 foreach h ∈ BEAM 8 foreach t ∈ T</context>
<context position="16737" citStr="Zhang and Nivre (2011)" startWordPosition="2890" endWordPosition="2893"> s(πi(B0))] i πi(B0)[s(π1(B0)) − s(πi(B0))]π(E0) w(B0)[s(π1(B0)) − s(πi(B0))]π(E0) Figure 3: Specialized feature templates for tagging. We use Ei and Bi to denote the ith token in the stack E and buffer B, respectively, with indexing starting at 0, and we use the following functors to extract properties of a token: πi() = ith best tag; s(πi()) = score of ith best tag; π() = finally predicted tag; w() = word form; pi() = word prefix of i characters; si() = word suffix of i characters. Score differences are binned in discrete steps of 0.05. The bulk of features used in our system are taken from Zhang and Nivre (2011), although with two important differences. First of all, like Hatori et al. (2011), we have omitted all features that presuppose an arc-eager parsing order, since our transition system defines an arc-standard order. Secondly, any feature that refers to the part-of-speech tag of a word w in the buffer B will in our system refer to the topscoring tag π1(w), rather than the finally predicted tag. By contrast, for a word in the stack E, part-ofspeech features refer to the tag π(w) chosen when shifting w onto the stack (which may or may not be the same as π1(w)). In addition to the standard feature</context>
<context position="27829" citStr="Zhang and Nivre (2011)" startWordPosition="4849" endWordPosition="4852">eatures for English and German, which results in additional improvements in all metrics. Table 3 gives the results for the Penn Treebank converted with the head-finding rules of Yamada and Matsumoto (2003) and the labeling rules of Nivre (2006). We use k = 3 and α = 0.4, which gave the best results on the development set. The UAS improves by 0.24 when we do joint tagging and parsing. The POS accuracy improves slightly by 0.12 Parser TLAS UAS LAS POS McDonald et al. (2005) 90.9 McDonald and Pereira (2006) 91.5 Zhang and Clark (2008) 92.1 Huang and Sagae (2010) 92.1 Koo and Collins (2010) 93.04 Zhang and Nivre (2011) 92.9 Martins et al. (2010) 93.26 Koo et al. (2008) † 93.16 Carreras et al. (2008) † 93.5 Suzuki et al. (2009) † 93.79 Baseline (k = 1), b1 = 40 89.42 92.79 91.71 97.28 Best dev setting, b1 = 40 89.75 93.03 91.92 97.40 Adding G, b1 = 40 90.12 93.38 92.44 97.33 Adding G+C, b1 = 80 † 90.41 93.67 92.68 97.42 Table 3: Accuracy scores for WSJ-PTB converted with head rules of Yamada and Matsumoto (2003) and labeling rules of Nivre (2006). Best dev setting: k = 3, α = 0.4. Results marked with † use additional information sources and are not directly comparable to the others. but to a lower degree tha</context>
<context position="36903" citStr="Zhang and Nivre (2011)" startWordPosition="6441" endWordPosition="6444">o use a parameterized SHIFT transition like the one found in both Hatori et al. (2011) and our own work, although Titov and Henderson (2007) used it to define a generative model by parameterizing the SHIFT transition by an input word. Zhang and Clark (2008) was the first to combine beam search with a globally normalized discriminative model, using structured perceptron learning and the early update strategy of Collins and Roark (2004), and also explored the addition of graphbased features to a transition-based parser. This approach was further pursued in Zhang and Clark (2011) and was used by Zhang and Nivre (2011) to achieve state-of-the-art results in dependency parsing for both Chinese and English through the addition of rich non-local features. Huang and Sagae (2010) combined structured perceptron learning and beam search with the use of a graph-structured stack to allow ambiguity packing in the beam, a technique that was reused by Hatori et al. (2011). Finally, as noted in the introduction, although joint tagging and parsing is rare in dependency parsing, most state-of-the-art parsers based on PCFG models naturally incorporate part-of-speech tagging and usually achieve better parsing accuracy (albe</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based parsing with rich non-local features. In Proceedings of ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>