<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9871">
Part-of-Speech Tagging for Chinese-English Mixed Texts
with Dynamic Features
</title>
<author confidence="0.958431">
Jiayi Zhaot Xipeng Qiut Shu Zhang§ Feng Ji� Xuanjing Huang$
</author>
<affiliation confidence="0.869632">
School of Computer Science, Fudan University, Shanghai, China t t
Fujitsu Research and Development Center, Beijing, China§
</affiliation>
<email confidence="0.976704666666667">
zjy.fudan@gmail.comt
{xpqiu,fengji,xjhuang}@fudan.edu.cnt
zhangshu@cn.fujitsu.com§
</email>
<sectionHeader confidence="0.997244" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999877411764706">
In modern Chinese articles or conversations,
it is very popular to involve a few English
words, especially in emails and Internet liter-
ature. Therefore, it becomes an important and
challenging topic to analyze Chinese-English
mixed texts. The underlying problem is how
to tag part-of-speech (POS) for the English
words involved. Due to the lack of specially
annotated corpus, most of the English words
are tagged as the oversimplified type, “foreign
words”. In this paper, we present a method
using dynamic features to tag POS of mixed
texts. Experiments show that our method
achieves higher performance than traditional
sequence labeling methods. Meanwhile, our
method also boosts the performance of POS
tagging for pure Chinese texts.
</bodyText>
<sectionHeader confidence="0.999513" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997930090909091">
Nowadays, Chinese-English mixed texts are
prevalent in modern articles or emails. More and
more English words are used in Chinese texts as
names of organizations, products, terms and abbre-
viations, such as “eBay”, “iPhone”, “GDP”, “An-
droid” etc. On the other hand, it is also a common
phenomenon to use Chinese-English mixed texts
in daily conversation, especially in communication
among employers in large international corporations.
There are some challenges for analyzing Chinese-
English mixed texts:
</bodyText>
<listItem confidence="0.982512833333333">
1. How to define the POS tags for English words
in these mixed texts. Since the standard of
POS tags for English and Chinese are different,
we cannot use English POS to tag the English
words in mixed texts.
2. Due to lack of annotated corpus for mixed texts,
most of the English words are tagged as “for-
eign words”, which is oversimplified. So we
cannot use them in further processing for the
syntactic and semantic analysis.
3. Most English words used in mixed texts are of-
ten out-of-vocabulary (OOV), which thus in-
</listItem>
<bodyText confidence="0.986227214285714">
creases the difficulties to tag them.
Currently, the mainstream method of Chinese
POS tagging is joint segmentation &amp; tagging with
cross-labels, which can avoid the problem of error
propagation and achieve higher performance on both
subtasks(Ng and Low, 2004). Each label is the cross-
product of a segmentation label and a tagging la-
bel, e.g. {B-NN, I-NN, E-NN, S-NN, ...}. The fea-
tures are generated by position-based templates on
character-level.
Since the main part of mixed texts is in Chinese
and the role of English word is more like Chinese,
we use Chinese POS tags (Xia, 2000) to tag English
words. Since the categories of the most commonly
used English words are nouns, verbs and adjectives,
we can use “NN”, “NR”, “VV”, “VA”, “JJ” to label
their POS tags.
For the English proper nouns and verbs, there
are no significant differences in Chinese and En-
glish POS tags except that English features plural
and tense forms.
For the English nouns, these are some English
nouns used as verbs, such as “我很 [fan/VV] 他。(I
adore him very much.)” where “fan” means “adore”
and is used as a verb.
For the English adjectives, there are two corre-
sponding Chinese POS tags “VA” and “JJ”. For ex-
ample, the roles of some English words in Table 1,
</bodyText>
<page confidence="0.966227">
1379
</page>
<note confidence="0.9894595">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1379–1388, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<tableCaption confidence="0.9501865">
Table 1: The POS tags of English Adjectives in Mixed
Texts
</tableCaption>
<note confidence="0.8410642">
Chinese English
a 4 S [profes- I am very profes-
sional/VA]o sional.
,q*,K [high/VA]o Feel very high.
&apos;Ik [super/JJ] [star/NN] He is a super star.
</note>
<bodyText confidence="0.99991972972973">
such as “professional” and “high”, are different with
their original ones.
Therefore, the POS tagging for mixed texts cannot
be settled with simple methods, such as looking up
in a dictionary.
One of the main differences between Chinese and
English in POS tagging is that the two languages
have character-based features and word-based fea-
tures respectively. To ensure the consistency of tag-
ging models, we prefer to use word-level informa-
tion in Chinese, which is both useful for Chinese-
English mixed texts and Chinese-only texts. For in-
stance, in a sentence “X Jr, Z;t Y ... (X or Y ...)”,
the word Y ought to have the same POS tag as the
word X. Another example is that the word follow-
ing a pronoun is usually a verb, and adjectives of-
ten describe nouns. Some related works show that
word-level features can improve the performance of
Chinese POS tagging (Jiang et al., 2008; Sun, 2011).
In this paper, we propose a method to tag mixed
texts with dynamic features. Our method combines
these dynamic features, which are dynamically gen-
erated at the decoding stage, with traditional static
features. For Chinese-English mixed texts, the tra-
ditional features cannot yield a satisfied result due to
lack of training data. The proposed dynamic features
can improve the performance by using the informa-
tion of a word, such as POS tag or length of the whole
word, which is proven effective by experiments.
The rest of the paper is organized as follows: In
section 2, we introduce the sequence labeling mod-
els, then we describe our method of dynamic features
in section 3 and analyze its complexity in section 4.
Section 5 describes the training method. The exper-
imental results are manifested in section 6. Finally,
We review the relevant research works in section 7
and conclude our work in section 8.
</bodyText>
<sectionHeader confidence="0.716005" genericHeader="introduction">
2 Sequence Labeling Models
</sectionHeader>
<bodyText confidence="0.95272675">
Sequence labeling is the task of assigning labels
y = y1, ... , yn to an input sequence x = x1, ... , xn.
Given a sample x, we define the feature 4b(x, y).
Thus, we can label x with a score function,
</bodyText>
<equation confidence="0.959339">
y� = arg max F(w, -b(x, y)), (1)
y
</equation>
<bodyText confidence="0.9997395">
where w is the parameter of function F(·).
For sequence labeling, the feature can be denoted
as ϕk(yZ, yZ−1, x, i), where i stands for the position in
the sequence and k stands for the number of feature
templates.
we use online Passive-Aggressive (PA) algorithm
(Crammer and Singer, 2003; Crammer et al., 2006)
to train the model parameters. Following (Collins,
2002), the average strategy is used to avoid the over-
fitting problem.
</bodyText>
<sectionHeader confidence="0.99592" genericHeader="method">
3 Dynamic Features
</sectionHeader>
<bodyText confidence="0.639272">
The form of traditional features is shown in Table
2, where C represents a Chinese character, and T
represents the character-based tag. The subscript i
indicates its position related to the current character.
</bodyText>
<tableCaption confidence="0.883535">
Table 2: Traditional Feature Templates
</tableCaption>
<equation confidence="0.880436666666667">
CZ, T0(i = −2,−1,0,1,2)
CZ, Cj, T0(i, j = −2,−1,0,1,2 and i ≠ j)
T−1, T0
</equation>
<bodyText confidence="0.9963232">
Traditional features are generated by position-
fixed templates. Since the length of Chinese word
is unfixed, their meanings are incomplete. We cat-
egorize them as “static” features since they can be
calculated before tagging (except “T−1, T0”).
The form of dynamic features is shown in Table
3, where WORD represents a Chinese word, and
POS (LEN) is the POS tag (length) of the word.
The subscript of dynamic feature template indicates
its position related to the current word.
Table 4 shows an example. If the current posi-
tion is “ Apple”, then {POS−1=CC, POS−2=NR,
WORD−1=“*p”, LEN−2=2}. Since these features
are unavailable before tagging, we call them “dy-
namic” features.
</bodyText>
<page confidence="0.998268">
1380
</page>
<tableCaption confidence="0.999637">
Table 3: Examples of Dynamic Feature Templates
</tableCaption>
<bodyText confidence="0.998280833333333">
POSi, POSj, T0(i, j = −2, −1, 0 and i =� j)
POSi, WORDj, T0(i, j = −2, −1,0)
WORDi, LENj, POSk, T0(i, j, k = −2, −1, 0)
...
Dynamic features are more flexible because the
number of involved characters is dependent on the
length of previous words. Unlike static features, dy-
namic features do not merely rely on the input se-
quence C1:n, so the weights of dynamic features, in
which POS/LEN are involved, can be trained by
Chinese-only texts and used by mixed texts, which
resolve the problem of the lack of training data.
</bodyText>
<sectionHeader confidence="0.92676" genericHeader="method">
4 Tagging with Dynamic Features
</sectionHeader>
<bodyText confidence="0.951769325">
In the tagging stage, we use the current best result
to approximately calculate the unknown tag infor-
mation. For an input sequence C1:n, the current best
tags from index 0 to i−1 can be calculated by Viterbi
algorithm and they can be used to generate dynamic
features for index i. The specific algorithm is shown
in Algorithm 1.
Here is an example to explain the time com-
plexity of the dynamic features. Normal template
xi_2xi_1yi requires to look for the positions of
i − 2 and i − 1 related to the current character
xi, but dynamic template posi_2posi_1yi needs to
know the pos tags of two words. If the length of
wordi_1/wordi_2 is 2, then the positions of i−4, i−
3, i−2, i−1 are needed to generate the dynamic fea-
tures.
For all dynamic features, it is unnecessary to
repetitively calculate the POS/WORD/LEN ar-
ray. Apart from that one time calculation of the ar-
ray, no distinction can be found between the time
complexity of the dynamic features and the tradi-
tional features. For input C1:n, the time complexity
is O(n*[O(op.2)+(Ts.num+Td.num)*O(op.1)+
O(op.4)]), n.b. O(op.1) = O(op.3). Universally
the dynamic features only require the information of
position i − 2 and i − 1, so the time complexity of
calculating the POS/WORD/LEN array can be
ignored as compared with the complexity of Viterbi
algorithm and feature extraction. The approximate
algorithm is thus faster than the Brute-Force way by
input : character sequence C1:n
static templates Ts
dynamic templates Td
number of labels m
trans matrix M
output: results Max &amp; Vp
Initialize: weight matrix W (n x m)
viterbi score matrix Vs (n x m)
viterbi path matrix Vp (n x m)
the index of current best label Max
</bodyText>
<equation confidence="0.966904368421053">
for i = 1··· n do
for ts in Ts do
// create feature string Fs (Op.1)
Fs = createFeature(C1:n, ts);
W [i] += getWeightVector(Fs);
end
// create a list of &lt;posk,wordk,lenk&gt;
// (k = 0, −1, −2 ...) (Op.2)
dList = getCurrentBestPath(Max, Vp);
for td in Td do
// create dynamic features string Fd
// (Op.3)
Fd = createFeature(C1:n, td, dList);
W [i] += getWeightVector(Fd);
end
// Update Vs[i], Vp[i] (Op.4)
viterbi_OneStep(Vs[i − 1], W [i], M);
Max = arg maxi(Vs[i]) ;
end
</equation>
<figureCaption confidence="0.479392">
Algorithm 1: Tagging Algorithm with Dynamic
Features
</figureCaption>
<bodyText confidence="0.869753">
using word-level information.
</bodyText>
<sectionHeader confidence="0.984427" genericHeader="method">
5 Training
</sectionHeader>
<bodyText confidence="0.9993025">
Given an example (x, y), y� are denoted as the in-
correct labels with the highest score
</bodyText>
<equation confidence="0.95866">
γ(w; (x, y)) = wT-b(x, y) − wT-b(x, �y). (3)
</equation>
<bodyText confidence="0.9979115">
Thus, we calculate the hinge loss ℓ(w; (x, y), (ab-
breviated as ℓw) by
</bodyText>
<equation confidence="0.623175">
y� = arg max wT.b(x, z). (2)
z�y
The margin γ(w; (x, y)) is defined as
</equation>
<page confidence="0.98452">
1381
</page>
<tableCaption confidence="0.994647">
Table 4: Example for Chinese-English Mixed POS Tagging
</tableCaption>
<table confidence="0.787555">
OR V *fl Apple M OS A 4 T n o
B-NR E-NR S-CC S-NR S-DEG S-NN B-NN E-NN B-VA E-VA S-PU
</table>
<equation confidence="0.907601714285714">
w ={0, γ(w; (x, y)) &gt; 1 (4)
1 − γ(w; (x, y)), otherwise
In round k, the new weight vector wk+1 is calcu-
lated by
2||w − wk||2 + C · ξ,
1
s.t. ℓ(w; (xk, yk)) &lt;= ξ and ξ &gt;= 0 (5)
</equation>
<bodyText confidence="0.99994">
where ξ is a non-negative slack variable, and C is
a positive parameter which controls the influence of
the slack term on the objective function.
Following the derivation in PA (Crammer et al.,
2006), we can get the update rule,
</bodyText>
<equation confidence="0.9994915">
wk+1 = wk + τk(Φ(xk, yk) − Φ(xk, ˆyk)), (6)
xk, yk) − Φ(xk, ˆyk)∥2) (7)
</equation>
<bodyText confidence="0.835746">
Our algorithm based on PA algorithm is shown in
Algorithm 2.
</bodyText>
<sectionHeader confidence="0.99937" genericHeader="method">
6 Experiments
</sectionHeader>
<bodyText confidence="0.9999830625">
We implement our system based on FudanNLP1.
We employ the commonly used label set {B, I, E,
S} for the segmentation part of cross-labels. {B,
I, E} represent Begin, Inside, End of a multi-node
segmentation respectively, and S represents a Single
node segmentation.
The F1 score is used for evaluation, which is the
harmonic mean of precision P (percentage of pre-
dict phrases that exactly match the reference phrases)
and recall R (percentage of reference phrases that re-
turned by system).
The feature templates, which are used to extract
features, are listed in Table 5. We set traditional
method (static features) as the baseline. The detailed
experimental settings and results are reported in the
following subsections.
</bodyText>
<footnote confidence="0.996275">
1Available at http://code.google.com/p/fudannlp/
</footnote>
<table confidence="0.475642">
Algorithm 2: Training Algorithm
</table>
<tableCaption confidence="0.882581">
Table 5: Feature Templates
</tableCaption>
<table confidence="0.9977735">
Static xi−2yi, xi−1yi, xiyi, xi+1yi, xi+2yi
xi−1xiyi,xi+1xiyi,xi−1xi+1yi,
yi−1yi
Dynamic posi−2posi−1yi, posi−1posiyi
posi−2wordi−1yi, posi−1wordiyi
posi−1wordi−1yi, posiwordiyi
wordi−2wordi−1yi, wordi−1wordiyi
wordileniyi
</table>
<subsectionHeader confidence="0.924319">
6.1 POS Tagging for Chinese-only Texts
</subsectionHeader>
<bodyText confidence="0.999826727272727">
Before the experiments on Chinese-English mixed
texts, we evaluate the performance of our method on
Chinese-only texts. We use the CTB dataset from
the POS tagging task of the Fourth International Chi-
nese Language Processing Bakeoff (SIGHAN Bake-
off 2008)(Jin and Chen, 2008). The details are
shown in Table 6.
The performance comparison on joint segmenta-
tion &amp; POS tagging is shown in Table 7. Our method
obtains an error reduction of 6.7% over the baseline.
The reason is that our dynamic features can utilize
</bodyText>
<table confidence="0.665985583333333">
input : training data sets:
(xi, yi), i = 1, · · · , N, and parameters:
C, K
output: wK
Initialize: wTemp ← 0, w ← 0;
for k = 0···K − 1 do
for i = 1 ··· N do
receive an example (xi, yi);
predict: ˆyi = arg max ⟨wk, Φ(xi, y)⟩;
y
if ˆyi ≠ yi then
update wk+1 with Eq. 6;
</table>
<equation confidence="0.779096714285714">
end
end
wTemp = wTemp + wk+1 ;
end
wK = wTemp/K ;
wk+1 = arg min
w
</equation>
<bodyText confidence="0.510417">
where
</bodyText>
<equation confidence="0.880220333333333">
ℓwk
τk = min(C,
∥Φ(
</equation>
<page confidence="0.989935">
1382
</page>
<tableCaption confidence="0.993727">
Table 6: POS Tagging Dataset in SIGHAN Bakeoff2008
</tableCaption>
<table confidence="0.999149333333333">
Train Set Test Set
(number) (number)
Sentence 23444 2079
Total 642246 59955
NN 168896 16793
Word NR 42906 3970
VV 92887 8641
VA 9106 649
JJ 15640 1581
</table>
<bodyText confidence="0.998633">
word-level information effectively and the feature
templates are more flexible.
words but not the words themselves and over-
come the problem of out-of-vocabulary (OOV)
English words.
For our experiments, we just select 5% of the Chi-
nese nouns and verbs from SIGHAN dataset, and re-
place them in the above two ways. After replace-
ment, the training and test data have 12780 and 1254
English words, respectively. 5189 words are gener-
ated by way of “Respective Replacement”. In the
test data, 326 words are OOV, which comprises 25%
of the whole vocabulary. The information of gener-
ated data is shown in Table 8.
</bodyText>
<tableCaption confidence="0.9797955">
Table 7: Performances of POS Tagging on Chinese-only
Texts with Static and Dynamic Features
</tableCaption>
<table confidence="0.999207">
Method P R F1
Baseline 89.68 89.60 89.64
Our 90.35 90.31 90.33
</table>
<subsectionHeader confidence="0.7077385">
6.2 POS Tagging for Chinese-English Mixed
Texts
</subsectionHeader>
<bodyText confidence="0.997843444444445">
Without annotated corpus for Chinese-English
mixed texts, we use synthetic data as the alternative.
In Chinese-English mixed texts, English words of
noun(NN/NR), verb(VV/VA) and adjective(JJ) cat-
egories are the most commonly used, so we ran-
domly transform a certain percentage of Chinese
words with these POS tags in the SIGHAN Bakeoff
2008 dataset(Jin and Chen, 2008) into their English
counterparts.
</bodyText>
<subsectionHeader confidence="0.827058">
6.2.1 Synthetic Data
</subsectionHeader>
<bodyText confidence="0.999667">
Before trying out an experiment, we first study
how to generate the data of mixed texts.
We use two ways to produce the synthetic data:
“Respective Replacement” and “Unified Replace-
ment”.
Respective Replacement We replace the selected
Chinese words into their corresponding English
counterparts.
Unified Replacement We replace the selected Chi-
nese words with a unified label ENG. The rea-
son we use the label ENG instead of real words
is that we want to consider the context of these
</bodyText>
<tableCaption confidence="0.996887">
Table 8: The Synthetic Chinese-English Mixed Dataset
</tableCaption>
<table confidence="0.8544966">
H
Dataset Numbers of ENG
NN VV
H Train Set 8191 4589
Test Set 842 412
</table>
<bodyText confidence="0.9998828">
We use H1 to represent the dataset generated by
way of “Respective Replacement”, and H2 for the
dataset by way of with “Unified Replacement”. The
experimental results on these two datasets are shown
in Table 9.
</bodyText>
<tableCaption confidence="0.98279">
Table 9: Performances of POS Tagging on Dataset H1
and H2
</tableCaption>
<table confidence="0.9980735">
Method Dataset ENG OOV Total
F1 F1,,, F1
Baseline H1 73.60 54.91 88.93
H2 77.59 73.93 89.11
Our H1 75.60 54.60 89.79
H2 79.82 77.61 89.81
</table>
<bodyText confidence="0.997562666666667">
From Table 9, we can see that the “Unified
Replacement” way is better than the “Respective
Replacement” way for both the baseline and our
method. The main reason is that the “Unified Re-
placement” way can greatly improve the tagging per-
formance of OOV words.
</bodyText>
<subsectionHeader confidence="0.661288">
6.2.2 Detail Comparisons
</subsectionHeader>
<bodyText confidence="0.651479">
For detail comparisons of all situations of
mixed texts, we design six synthetic datasets,
A/B/C/D1/D2/E by randomly selecting 10% or
15% of Chinese words (“NN/NR/VV/VA/JJ”) in the
</bodyText>
<page confidence="0.979052">
1383
</page>
<bodyText confidence="0.996641333333333">
above SIGHAN Bakeoff 2008 dataset, and replacing
them with English label ENG.
The differences of these datasets are as following:
</bodyText>
<listItem confidence="0.998188833333333">
• Dataset A only contains English words with
tags “NN/VV”.
• Dataset B contains English words with tags
“NN/VV/VA”.
• Dataset C contains one more tag “NR” than
Dataset B.
• Datasets D1 and D2 contain one more tag “JJ”
than Dataset B. The difference between D1
and D2 is that D2 has about 50% more English
words than D1 in training set.
• Dataset E contains English words with all the
tags “NN/NR/VV/VA/JJ”.
</listItem>
<bodyText confidence="0.9296905">
The detailed information of datasets
A/B/C/D1/D2/E is shown in Table 10.
</bodyText>
<tableCaption confidence="0.994551">
Table 10: The Synthetic Chinese-English Mixed Dataset
</tableCaption>
<table confidence="0.997967714285714">
Dataset Numbers of ENG
NN NR VV VA JJ
A Train 16302 0 9007 0 0
Test 1675 0 841 0 0
B Train 16116 0 8882 906 0
Test 1573 0 830 58 0
C Train 16312 4057 9067 899 0
Test 1549 400 795 61 0
D1 Train 16042 0 8957 855 1539
Test 1588 0 845 58 150
D2 Train 23705 0 13154 1300 2211
Test 1588 0 845 58 150
E Train 16066 4162 9156 886 1547
Test 1647 415 809 57 141
</table>
<bodyText confidence="0.999520555555555">
The results are shown in Table 11. On dataset E,
our method achieves 6.78% higher performance on
tagging ENG labels than traditional static features.
This result is reasonable because our model can use
more flexible feature templates to extract features
and reduce the problem of being dependent on spe-
cific English words.
Tables 12/13/14/15/16/17 show the detailed re-
sults on datasets A/B/C/D1/D2/E.
</bodyText>
<tableCaption confidence="0.993871">
Table 11: Performances of POS Tagging on Datasets
</tableCaption>
<table confidence="0.972209333333333">
A/B/C/D1/D2/E
Dataset Method ENG labels Total
F1 F1
A Baseline 80.25 88.74
Our 83.03 89.72
B Baseline 76.72 88.51
Our 80.54 89.55
C Baseline 68.16 88.13
Our 70.34 88.99
D1 Baseline 71.30 88.33
Our 74.02 89.15
D2 Baseline 69.59 88.09
Our 74.10 89.15
E Baseline 61.58 87.71
Our 68.36 88.83
</table>
<bodyText confidence="0.998311">
Experiment on dataset A gets the best result be-
cause “NN” and “VV” can be easily distinguished by
its context. Sometimes, “VA” has the similar context
with “VV”, experiment on dataset B shows its influ-
ence. The performances on datasets B/C/E descend
in turn. The reason is that words with tag “NN” or
“NR/JJ” have the similar usage/contexts in Chinese.
Since we use the same form ENG instead of real
words, there are no differences between these words,
which leads to some errors. Though the datasets is
generated randomly, we can see our method perform
better on every dataset than the baseline.
</bodyText>
<tableCaption confidence="0.998018">
Table 12: Performances on Dataset A
</tableCaption>
<table confidence="0.9996286">
POS tag Method P R F1
NN Baseline 84.36 86.33 85.33
Our 85.37 89.91 87.58
VV Baseline 71.45 68.13 69.75
Our 77.53 69.32 73.20
</table>
<tableCaption confidence="0.995338">
Table 13: Performances on Dataset B
</tableCaption>
<table confidence="0.999513285714286">
POS tag Method P R F1
NN Baseline 84.89 80.36 82.56
Our 83.51 88.87 86.11
VV Baseline 65.90 72.65 69.11
Our 75.75 67.35 71.30
VA Baseline 36.84 36.21 36.52
Our 51.02 43.10 46.73
</table>
<page confidence="0.830688">
1384
</page>
<tableCaption confidence="0.997394">
Table 14: Performances on Dataset C
</tableCaption>
<table confidence="0.999527888888889">
POS tag Method P R F1
NN Baseline 73.77 78.24 75.94
Our 76.84 77.99 77.41
VV Baseline 61.67 66.79 64.13
Our 64.94 67.80 66.34
NR Baseline 55.22 37.00 44.31
Our 55.65 50.50 52.95
VA Baseline 63.64 34.43 44.68
Our 60.00 39.34 47.52
</table>
<tableCaption confidence="0.981012">
Table 15: Performances on Dataset D1
</tableCaption>
<table confidence="0.999764444444444">
POS tag Method P R F1
NN Baseline 77.15 81.42 79.23
Our 76.70 88.54 82.20
VV Baseline 67.53 64.50 65.98
Our 79.65 59.76 68.29
JJ Baseline 25.00 18.00 20.93
Our 22.92 14.67 17.89
VA Baseline 36.00 31.03 33.33
Our 28.57 37.93 32.59
</table>
<tableCaption confidence="0.937854">
Table 17: Performances on Dataset E
</tableCaption>
<table confidence="0.999441090909091">
POS tag Method P R F1
NN Baseline 72.41 68.85 70.59
Our 71.18 84.88 77.43
VV Baseline 63.65 59.09 61.28
Our 76.19 55.38 64.14
JJ Baseline 28.57 25.53 26.97
Our 30.21 20.57 24.47
VA Baseline 44.83 45.61 45.22
Our 60.42 50.88 55.24
NR Baseline 38.03 52.05 43.95
Our 52.01 46.75 49.24
</table>
<tableCaption confidence="0.884358">
Table 18: Examples in Real Dataset of Mixed Texts
</tableCaption>
<table confidence="0.63391325">
A ht [Ninja Cloud/NR] M i� Efit *, [Ninja
Blocks/NR] RG &apos;j [Facebook/NR], [Twit-
ter/NR],[Dropbox/NR] )E�i1�o
By using [Ninja Cloud/NR], [Ninja
Blocks/NR] can connect to [Facebook/NR],
[Twitter/NR], [Dropbox/NR].
tij� [follow/VV] FA^AnTJ�o
You should [follow/VV] this man’s work.
</table>
<tableCaption confidence="0.981676">
Table 16: Performances on Dataset D2
</tableCaption>
<table confidence="0.999331444444444">
POS tag Method P R F1
NN Baseline 79.11 74.87 76.93
Our 79.29 82.68 80.95
VV Baseline 55.77 72.78 65.64
Our 69.17 70.89 70.02
JJ Baseline 27.27 12.00 16.67
Our 34.38 22.00 26.83
VA Baseline 37.21 27.59 31.68
Our 52.17 20.69 29.63
</table>
<subsectionHeader confidence="0.9658175">
6.3 POS Tagging for Mixed Texts with a Real
Dataset
</subsectionHeader>
<bodyText confidence="0.999973875">
To investigate the actual performance, we collect
a real dataset from Web, which consists of 142 rep-
resentative Chinese-English mixed sentences. This
dataset contains 4, 238 Chinese characters and 275
English words. Since we focus on the performance
for English words, we only label the POS tags of the
English words. Table 18 shows some examples in
the real dataset of mixed texts.
</bodyText>
<sectionHeader confidence="0.821204" genericHeader="method">
31-:RNMUM !!TR [COOL/VA]!
</sectionHeader>
<bodyText confidence="0.94913125">
... very [COOL/VA]!
The information of the real dataset is shown in Ta-
ble 19. If all involved English words are tagging as
“NN”, the precision is just 56%.
</bodyText>
<tableCaption confidence="0.960429">
Table 19: The Numbers of English Words with Different
Tags in Dataset R
</tableCaption>
<table confidence="0.963231">
Dataset NN VV VA NR
R 154 58 28 35
</table>
<bodyText confidence="0.9894086">
Since there is no noun-modifier “JJ” in our col-
lected data. We use the models trained on dataset
B and C to tag the real data. The results are shown
in Table 20. The difference between model B and
C is that model B regards all words with tag “NR”
as “NN”. Since it is difficult to distinguish between
“NR” and “NN” merely according to the context,
model B performs better than model C.
The detail results of model B and C are shown in
Table 21 and 22.
</bodyText>
<page confidence="0.99631">
1385
</page>
<tableCaption confidence="0.998345">
Table 20: Performances of POS Tagging on R
</tableCaption>
<table confidence="0.999494">
Model Method ENG
F1
B Baseline 74.91
Our 82.55
C Baseline 70.91
Our 74.91
</table>
<tableCaption confidence="0.98052">
Table 21: Performances of Model B on Dataset R
</tableCaption>
<table confidence="0.999742857142857">
POS tag Method P R F1
NN Baseline 88.62 78.31 83.15
Our 91.67 87.30 89.43
VV Baseline 48.31 74.14 58.50
Our 60.53 79.31 68.66
VA Baseline 78.95 53.57 63.83
Our 84.21 57.14 68.09
</table>
<tableCaption confidence="0.981978">
Table 22: Performances of Model C on Dataset R
</tableCaption>
<table confidence="0.999204888888889">
POS tag Method P R F1
NN Baseline 80.25 81.82 81.03
Our 84.56 81.82 83.17
VV Baseline 54.88 77.59 64.29
Our 61.25 84.48 71.01
VA Baseline 84.62 39.29 53.66
Our 88.24 53.57 66.67
NR Baseline 56.52 37.14 44.83
Our 55.17 45.71 50.00
</table>
<sectionHeader confidence="0.998199" genericHeader="method">
7 Related Works
</sectionHeader>
<bodyText confidence="0.999925081967213">
In recent years, POS tagging has undergone great
development. The mainstream method is to regard
POS tagging as sequence labeling problems (Ra-
biner, 1990; Xue, 2003; Peng et al., 2004; Ng and
Low, 2004).
However, the analysis of Chinese-English mixed
texts is rarely involved in previous literature. In
the aspect of the general multilingual POS tagging,
most works focus on modeling cross-lingual corre-
lations and tagging multilingual POS on respective
monolingual texts, not on mixed texts (Cucerzan and
Yarowsky, 2002; Yarowsky et al., 2001; Naseem et
al., 2009).
Since we choose to use dynamic word-level fea-
tures to improve the performance of POS tagging,
we also review some works on word-level features.
Semi-Markov Conditional Random Fields (semi-
CRF) (Sarawagi and Cohen, 2004) is a model in
which segmentation task is implicitly included into
the decoding algorithm. In this model, feature rep-
resentation would be more flexible than traditional
CRFs, since features can be extracted from the previ-
ous/the next segmentation within a window of vari-
able size. The problem of this approach lies in that
the decoding algorithm depends on the predefined
window size to exploit the boundaries of segmenta-
tions but not the real length of words.
Bunescu (2008) presents an improved pipeline
model in which the output of the previous subtasks
are considered as hidden variables, and the hidden
variables together with their probabilities denoting
the confidence are used as probabilistic features in
the next subtasks. One shortcoming of this method
is inefficiency caused by the calculation of marginal
probabilities of features. The other disadvantages
of the pipeline method are error propagation and the
need of separate training of different subtasks in the
pipeline. Another disadvantage of pipeline method
is error propagation.
Jiang et al. (2008) proposes a cascaded linear
model for joint Chinese word segmentation and POS
tagging. With a character-based perceptron as the
core, combined with real-valued features such as lan-
guage models, the cascaded model can efficiently
utilize knowledge sources that are inconvenient to
incorporate into the perceptron directly. However,
they use POS tags or word information in a Brute-
Force way, which may suffer from the problem of
time complexity.
Sun (2011) presents a stacked sub-word model for
joint Chinese word segmentation and POS tagging.
By merging the outputs of the three predictors (in-
cluding one word-based segmenter) into sub-word
sequences, rich contextual features can be approx-
imately derived. The experiments are conducted to
show the effectiveness of using word-based informa-
tion.
The difference between the above methods and
ours is that our word-level features are dynamically
generated in the decoding stage without exhaustive
or preprocessed word segmentation.
</bodyText>
<page confidence="0.990639">
1386
</page>
<sectionHeader confidence="0.998695" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999979272727273">
In this paper, we focus on Chinese-English mixed
texts and use dynamic features for POS tagging.
To overcome the problem of the lack of annotated
corpus on mixed texts, our features use both lo-
cal and non-local information and take advantage of
the characteristics of Chinese-English mixed texts.
The experiments demonstrate the effectiveness of
our method. It should be noted that our method is
also effective for the mixed texts of Chinese and any
foreign languages since we use “Unified Replace-
ment”.
For future works, we plan to improve our approx-
imate tagging algorithm to reduce error propagation.
In addition, we will refer to an English dictionary
to generate some useful features to distinguish be-
tween “NR” and “NN” in Chinese-English mixed
texts and add some statistical features derived from
English resources, such as the most common tag of
each English word. We would also like to investi-
gate these features in more applications of natural
language processing, such as name entity recogni-
tion, information extraction, etc.
</bodyText>
<sectionHeader confidence="0.998195" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999841">
We would like to thank the anonymous reviewers
for their valuable comments. We also thanks Amy
Zhou for her help in spell and grammar checking.
This work was funded by NSFC (No.61003091 and
No.61073069), 863 Program (No.2011AA010604)
and 973 Program (No.2010CB327900).
</bodyText>
<sectionHeader confidence="0.999475" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999952971014493">
Razvan C. Bunescu. 2008. Learning with probabilistic
features for improved pipeline models. In EMNLP,
pages 670–679. ACL.
Michael Collins. 2002. Discriminative training methods
for hidden markov models: theory and experiments
with perceptron algorithms. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing - Volume 10, EMNLP ’02, pages
1–8, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Koby Crammer and Yoram Singer. 2003. Ultraconser-
vative online algorithms for multiclass problems. J.
Mach. Learn. Res., 3:951–991, March.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. J. Mach. Learn. Res.,
7:551–585, December.
Silviu Cucerzan and David Yarowsky. 2002. Boot-
strapping a multilingual part-of-speech tagger in one
person-day. In proceedings of the 6th conference on
Natural language learning - Volume 20, COLING-
02, pages 1–7, Stroudsburg, PA, USA. Association for
Computational Linguistics.
Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan Lü.
2008. A cascaded linear model for joint chinese word
segmentation and part-of-speech tagging. In Kath-
leen McKeown, Johanna D. Moore, Simone Teufel,
James Allan, and Sadaoki Furui, editors, ACL, pages
897–904. The Association for Computer Linguistics.
C. Jin and X. Chen. 2008. The fourth international chi-
nese language processing bakeoff: Chinese word seg-
mentation, named entity recognition and chinese pos
tagging. In Sixth SIGHAN Workshop on Chinese Lan-
guage Processing, page 69.
T. Naseem, B. Snyder, J. Eisenstein, and R. Barzilay.
2009. Multilingual part-of-speech tagging: Two unsu-
pervised approaches. Journal ofArtificial Intelligence
Research, 36(1):341–385.
H.T. Ng and J.K. Low. 2004. Chinese part-of-speech
tagging: One-at-a-time or all-at-once? word-based or
character-based. In Proceedings of EMNLP, volume
2004, page 277.
Fuchun Peng, Fangfang Feng, and Andrew McCallum.
2004. Chinese segmentation and new word detection
using conditional random fields. In Proceedings of the
20th international conference on Computational Lin-
guistics, COLING ’04, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Lawrence R. Rabiner. 1990. Readings in speech recog-
nition. chapter A tutorial on hidden Markov mod-
els and selected applications in speech recognition,
pages 267–296. Morgan Kaufmann Publishers Inc.,
San Francisco, CA, USA.
Sunita Sarawagi and William W. Cohen. 2004. Semi-
markov conditional random fields for information ex-
traction. In NIPS.
Weiwei Sun. 2011. A stacked sub-word model for
joint chinese word segmentation and part-of-speech
tagging. In Dekang Lin, Yuji Matsumoto, and Rada
Mihalcea, editors, ACL, pages 1385–1394. The Asso-
ciation for Computer Linguistics.
F. Xia. 2000. The part-of-speech tagging guidelines for
the Penn Chinese Treebank (3.0).
N. Xue. 2003. Chinese word segmentation as character
tagging. Computational Linguistics and Chinese Lan-
guage Processing, 8(1):29–48.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-
ducing multilingual text analysis tools via robust pro-
jection across aligned corpora. In Proceedings of
</reference>
<page confidence="0.845649">
1387
</page>
<reference confidence="0.938187">
the first international conference on Human language
technology research, pages 1–8. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.993736">
1388
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.249905">
<title confidence="0.976027">Part-of-Speech Tagging for Chinese-English Mixed with Dynamic Features</title>
<author confidence="0.393175">of Computer Science</author>
<author confidence="0.393175">Fudan University</author>
<author confidence="0.393175">China Shanghai</author>
<affiliation confidence="0.406558">Research and Development Center, Beijing,</affiliation>
<abstract confidence="0.9974435">In modern Chinese articles or conversations, it is very popular to involve a few English words, especially in emails and Internet literature. Therefore, it becomes an important and challenging topic to analyze Chinese-English mixed texts. The underlying problem is how to tag part-of-speech (POS) for the English words involved. Due to the lack of specially annotated corpus, most of the English words are tagged as the oversimplified type, “foreign words”. In this paper, we present a method using dynamic features to tag POS of mixed texts. Experiments show that our method achieves higher performance than traditional sequence labeling methods. Meanwhile, our method also boosts the performance of POS tagging for pure Chinese texts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
</authors>
<title>Learning with probabilistic features for improved pipeline models.</title>
<date>2008</date>
<booktitle>In EMNLP,</booktitle>
<pages>670--679</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="23268" citStr="Bunescu (2008)" startWordPosition="3991" endWordPosition="3992">f POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (semiCRF) (Sarawagi and Cohen, 2004) is a model in which segmentation task is implicitly included into the decoding algorithm. In this model, feature representation would be more flexible than traditional CRFs, since features can be extracted from the previous/the next segmentation within a window of variable size. The problem of this approach lies in that the decoding algorithm depends on the predefined window size to exploit the boundaries of segmentations but not the real length of words. Bunescu (2008) presents an improved pipeline model in which the output of the previous subtasks are considered as hidden variables, and the hidden variables together with their probabilities denoting the confidence are used as probabilistic features in the next subtasks. One shortcoming of this method is inefficiency caused by the calculation of marginal probabilities of features. The other disadvantages of the pipeline method are error propagation and the need of separate training of different subtasks in the pipeline. Another disadvantage of pipeline method is error propagation. Jiang et al. (2008) propos</context>
</contexts>
<marker>Bunescu, 2008</marker>
<rawString>Razvan C. Bunescu. 2008. Learning with probabilistic features for improved pipeline models. In EMNLP, pages 670–679. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10, EMNLP ’02,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="6237" citStr="Collins, 2002" startWordPosition="1029" endWordPosition="1030">ling Models Sequence labeling is the task of assigning labels y = y1, ... , yn to an input sequence x = x1, ... , xn. Given a sample x, we define the feature 4b(x, y). Thus, we can label x with a score function, y� = arg max F(w, -b(x, y)), (1) y where w is the parameter of function F(·). For sequence labeling, the feature can be denoted as ϕk(yZ, yZ−1, x, i), where i stands for the position in the sequence and k stands for the number of feature templates. we use online Passive-Aggressive (PA) algorithm (Crammer and Singer, 2003; Crammer et al., 2006) to train the model parameters. Following (Collins, 2002), the average strategy is used to avoid the overfitting problem. 3 Dynamic Features The form of traditional features is shown in Table 2, where C represents a Chinese character, and T represents the character-based tag. The subscript i indicates its position related to the current character. Table 2: Traditional Feature Templates CZ, T0(i = −2,−1,0,1,2) CZ, Cj, T0(i, j = −2,−1,0,1,2 and i ≠ j) T−1, T0 Traditional features are generated by positionfixed templates. Since the length of Chinese word is unfixed, their meanings are incomplete. We categorize them as “static” features since they can </context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative training methods for hidden markov models: theory and experiments with perceptron algorithms. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10, EMNLP ’02, pages 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<volume>3</volume>
<contexts>
<context position="6157" citStr="Crammer and Singer, 2003" startWordPosition="1015" endWordPosition="1018">e relevant research works in section 7 and conclude our work in section 8. 2 Sequence Labeling Models Sequence labeling is the task of assigning labels y = y1, ... , yn to an input sequence x = x1, ... , xn. Given a sample x, we define the feature 4b(x, y). Thus, we can label x with a score function, y� = arg max F(w, -b(x, y)), (1) y where w is the parameter of function F(·). For sequence labeling, the feature can be denoted as ϕk(yZ, yZ−1, x, i), where i stands for the position in the sequence and k stands for the number of feature templates. we use online Passive-Aggressive (PA) algorithm (Crammer and Singer, 2003; Crammer et al., 2006) to train the model parameters. Following (Collins, 2002), the average strategy is used to avoid the overfitting problem. 3 Dynamic Features The form of traditional features is shown in Table 2, where C represents a Chinese character, and T represents the character-based tag. The subscript i indicates its position related to the current character. Table 2: Traditional Feature Templates CZ, T0(i = −2,−1,0,1,2) CZ, Cj, T0(i, j = −2,−1,0,1,2 and i ≠ j) T−1, T0 Traditional features are generated by positionfixed templates. Since the length of Chinese word is unfixed, their </context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. J. Mach. Learn. Res., 3:951–991, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>7--551</pages>
<contexts>
<context position="6180" citStr="Crammer et al., 2006" startWordPosition="1019" endWordPosition="1022">in section 7 and conclude our work in section 8. 2 Sequence Labeling Models Sequence labeling is the task of assigning labels y = y1, ... , yn to an input sequence x = x1, ... , xn. Given a sample x, we define the feature 4b(x, y). Thus, we can label x with a score function, y� = arg max F(w, -b(x, y)), (1) y where w is the parameter of function F(·). For sequence labeling, the feature can be denoted as ϕk(yZ, yZ−1, x, i), where i stands for the position in the sequence and k stands for the number of feature templates. we use online Passive-Aggressive (PA) algorithm (Crammer and Singer, 2003; Crammer et al., 2006) to train the model parameters. Following (Collins, 2002), the average strategy is used to avoid the overfitting problem. 3 Dynamic Features The form of traditional features is shown in Table 2, where C represents a Chinese character, and T represents the character-based tag. The subscript i indicates its position related to the current character. Table 2: Traditional Feature Templates CZ, T0(i = −2,−1,0,1,2) CZ, Cj, T0(i, j = −2,−1,0,1,2 and i ≠ j) T−1, T0 Traditional features are generated by positionfixed templates. Since the length of Chinese word is unfixed, their meanings are incomplete</context>
<context position="10949" citStr="Crammer et al., 2006" startWordPosition="1866" endWordPosition="1869">, y), (abbreviated as ℓw) by y� = arg max wT.b(x, z). (2) z�y The margin γ(w; (x, y)) is defined as 1381 Table 4: Example for Chinese-English Mixed POS Tagging OR V *fl Apple M OS A 4 T n o B-NR E-NR S-CC S-NR S-DEG S-NN B-NN E-NN B-VA E-VA S-PU w ={0, γ(w; (x, y)) &gt; 1 (4) 1 − γ(w; (x, y)), otherwise In round k, the new weight vector wk+1 is calculated by 2||w − wk||2 + C · ξ, 1 s.t. ℓ(w; (xk, yk)) &lt;= ξ and ξ &gt;= 0 (5) where ξ is a non-negative slack variable, and C is a positive parameter which controls the influence of the slack term on the objective function. Following the derivation in PA (Crammer et al., 2006), we can get the update rule, wk+1 = wk + τk(Φ(xk, yk) − Φ(xk, ˆyk)), (6) xk, yk) − Φ(xk, ˆyk)∥2) (7) Our algorithm based on PA algorithm is shown in Algorithm 2. 6 Experiments We implement our system based on FudanNLP1. We employ the commonly used label set {B, I, E, S} for the segmentation part of cross-labels. {B, I, E} represent Begin, Inside, End of a multi-node segmentation respectively, and S represents a Single node segmentation. The F1 score is used for evaluation, which is the harmonic mean of precision P (percentage of predict phrases that exactly match the reference phrases) and re</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. J. Mach. Learn. Res., 7:551–585, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
<author>David Yarowsky</author>
</authors>
<title>Bootstrapping a multilingual part-of-speech tagger in one person-day.</title>
<date>2002</date>
<booktitle>In proceedings of the 6th conference on Natural language learning - Volume 20, COLING02,</booktitle>
<pages>1--7</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="22528" citStr="Cucerzan and Yarowsky, 2002" startWordPosition="3869" endWordPosition="3872">4.62 39.29 53.66 Our 88.24 53.57 66.67 NR Baseline 56.52 37.14 44.83 Our 55.17 45.71 50.00 7 Related Works In recent years, POS tagging has undergone great development. The mainstream method is to regard POS tagging as sequence labeling problems (Rabiner, 1990; Xue, 2003; Peng et al., 2004; Ng and Low, 2004). However, the analysis of Chinese-English mixed texts is rarely involved in previous literature. In the aspect of the general multilingual POS tagging, most works focus on modeling cross-lingual correlations and tagging multilingual POS on respective monolingual texts, not on mixed texts (Cucerzan and Yarowsky, 2002; Yarowsky et al., 2001; Naseem et al., 2009). Since we choose to use dynamic word-level features to improve the performance of POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (semiCRF) (Sarawagi and Cohen, 2004) is a model in which segmentation task is implicitly included into the decoding algorithm. In this model, feature representation would be more flexible than traditional CRFs, since features can be extracted from the previous/the next segmentation within a window of variable size. The problem of this approach lies in that the decoding</context>
</contexts>
<marker>Cucerzan, Yarowsky, 2002</marker>
<rawString>Silviu Cucerzan and David Yarowsky. 2002. Bootstrapping a multilingual part-of-speech tagger in one person-day. In proceedings of the 6th conference on Natural language learning - Volume 20, COLING02, pages 1–7, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbin Jiang</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
<author>Yajuan Lü</author>
</authors>
<title>A cascaded linear model for joint chinese word segmentation and part-of-speech tagging.</title>
<date>2008</date>
<pages>897--904</pages>
<editor>In Kathleen McKeown, Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui, editors, ACL,</editor>
<publisher>The Association for Computer Linguistics.</publisher>
<contexts>
<context position="4686" citStr="Jiang et al., 2008" startWordPosition="755" endWordPosition="758">gging is that the two languages have character-based features and word-based features respectively. To ensure the consistency of tagging models, we prefer to use word-level information in Chinese, which is both useful for ChineseEnglish mixed texts and Chinese-only texts. For instance, in a sentence “X Jr, Z;t Y ... (X or Y ...)”, the word Y ought to have the same POS tag as the word X. Another example is that the word following a pronoun is usually a verb, and adjectives often describe nouns. Some related works show that word-level features can improve the performance of Chinese POS tagging (Jiang et al., 2008; Sun, 2011). In this paper, we propose a method to tag mixed texts with dynamic features. Our method combines these dynamic features, which are dynamically generated at the decoding stage, with traditional static features. For Chinese-English mixed texts, the traditional features cannot yield a satisfied result due to lack of training data. The proposed dynamic features can improve the performance by using the information of a word, such as POS tag or length of the whole word, which is proven effective by experiments. The rest of the paper is organized as follows: In section 2, we introduce t</context>
<context position="23861" citStr="Jiang et al. (2008)" startWordPosition="4077" endWordPosition="4080">h of words. Bunescu (2008) presents an improved pipeline model in which the output of the previous subtasks are considered as hidden variables, and the hidden variables together with their probabilities denoting the confidence are used as probabilistic features in the next subtasks. One shortcoming of this method is inefficiency caused by the calculation of marginal probabilities of features. The other disadvantages of the pipeline method are error propagation and the need of separate training of different subtasks in the pipeline. Another disadvantage of pipeline method is error propagation. Jiang et al. (2008) proposes a cascaded linear model for joint Chinese word segmentation and POS tagging. With a character-based perceptron as the core, combined with real-valued features such as language models, the cascaded model can efficiently utilize knowledge sources that are inconvenient to incorporate into the perceptron directly. However, they use POS tags or word information in a BruteForce way, which may suffer from the problem of time complexity. Sun (2011) presents a stacked sub-word model for joint Chinese word segmentation and POS tagging. By merging the outputs of the three predictors (including </context>
</contexts>
<marker>Jiang, Huang, Liu, Lü, 2008</marker>
<rawString>Wenbin Jiang, Liang Huang, Qun Liu, and Yajuan Lü. 2008. A cascaded linear model for joint chinese word segmentation and part-of-speech tagging. In Kathleen McKeown, Johanna D. Moore, Simone Teufel, James Allan, and Sadaoki Furui, editors, ACL, pages 897–904. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Jin</author>
<author>X Chen</author>
</authors>
<title>The fourth international chinese language processing bakeoff: Chinese word segmentation, named entity recognition and chinese pos tagging.</title>
<date>2008</date>
<booktitle>In Sixth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<pages>69</pages>
<contexts>
<context position="12492" citStr="Jin and Chen, 2008" startWordPosition="2095" endWordPosition="2098">.google.com/p/fudannlp/ Algorithm 2: Training Algorithm Table 5: Feature Templates Static xi−2yi, xi−1yi, xiyi, xi+1yi, xi+2yi xi−1xiyi,xi+1xiyi,xi−1xi+1yi, yi−1yi Dynamic posi−2posi−1yi, posi−1posiyi posi−2wordi−1yi, posi−1wordiyi posi−1wordi−1yi, posiwordiyi wordi−2wordi−1yi, wordi−1wordiyi wordileniyi 6.1 POS Tagging for Chinese-only Texts Before the experiments on Chinese-English mixed texts, we evaluate the performance of our method on Chinese-only texts. We use the CTB dataset from the POS tagging task of the Fourth International Chinese Language Processing Bakeoff (SIGHAN Bakeoff 2008)(Jin and Chen, 2008). The details are shown in Table 6. The performance comparison on joint segmentation &amp; POS tagging is shown in Table 7. Our method obtains an error reduction of 6.7% over the baseline. The reason is that our dynamic features can utilize input : training data sets: (xi, yi), i = 1, · · · , N, and parameters: C, K output: wK Initialize: wTemp ← 0, w ← 0; for k = 0···K − 1 do for i = 1 ··· N do receive an example (xi, yi); predict: ˆyi = arg max ⟨wk, Φ(xi, y)⟩; y if ˆyi ≠ yi then update wk+1 with Eq. 6; end end wTemp = wTemp + wk+1 ; end wK = wTemp/K ; wk+1 = arg min w where ℓwk τk = min(C, ∥Φ( </context>
<context position="14476" citStr="Jin and Chen, 2008" startWordPosition="2456" endWordPosition="2459">ormation of generated data is shown in Table 8. Table 7: Performances of POS Tagging on Chinese-only Texts with Static and Dynamic Features Method P R F1 Baseline 89.68 89.60 89.64 Our 90.35 90.31 90.33 6.2 POS Tagging for Chinese-English Mixed Texts Without annotated corpus for Chinese-English mixed texts, we use synthetic data as the alternative. In Chinese-English mixed texts, English words of noun(NN/NR), verb(VV/VA) and adjective(JJ) categories are the most commonly used, so we randomly transform a certain percentage of Chinese words with these POS tags in the SIGHAN Bakeoff 2008 dataset(Jin and Chen, 2008) into their English counterparts. 6.2.1 Synthetic Data Before trying out an experiment, we first study how to generate the data of mixed texts. We use two ways to produce the synthetic data: “Respective Replacement” and “Unified Replacement”. Respective Replacement We replace the selected Chinese words into their corresponding English counterparts. Unified Replacement We replace the selected Chinese words with a unified label ENG. The reason we use the label ENG instead of real words is that we want to consider the context of these Table 8: The Synthetic Chinese-English Mixed Dataset H Dataset</context>
</contexts>
<marker>Jin, Chen, 2008</marker>
<rawString>C. Jin and X. Chen. 2008. The fourth international chinese language processing bakeoff: Chinese word segmentation, named entity recognition and chinese pos tagging. In Sixth SIGHAN Workshop on Chinese Language Processing, page 69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Naseem</author>
<author>B Snyder</author>
<author>J Eisenstein</author>
<author>R Barzilay</author>
</authors>
<title>Multilingual part-of-speech tagging: Two unsupervised approaches.</title>
<date>2009</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<volume>36</volume>
<issue>1</issue>
<contexts>
<context position="22573" citStr="Naseem et al., 2009" startWordPosition="3877" endWordPosition="3880">6.52 37.14 44.83 Our 55.17 45.71 50.00 7 Related Works In recent years, POS tagging has undergone great development. The mainstream method is to regard POS tagging as sequence labeling problems (Rabiner, 1990; Xue, 2003; Peng et al., 2004; Ng and Low, 2004). However, the analysis of Chinese-English mixed texts is rarely involved in previous literature. In the aspect of the general multilingual POS tagging, most works focus on modeling cross-lingual correlations and tagging multilingual POS on respective monolingual texts, not on mixed texts (Cucerzan and Yarowsky, 2002; Yarowsky et al., 2001; Naseem et al., 2009). Since we choose to use dynamic word-level features to improve the performance of POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (semiCRF) (Sarawagi and Cohen, 2004) is a model in which segmentation task is implicitly included into the decoding algorithm. In this model, feature representation would be more flexible than traditional CRFs, since features can be extracted from the previous/the next segmentation within a window of variable size. The problem of this approach lies in that the decoding algorithm depends on the predefined window s</context>
</contexts>
<marker>Naseem, Snyder, Eisenstein, Barzilay, 2009</marker>
<rawString>T. Naseem, B. Snyder, J. Eisenstein, and R. Barzilay. 2009. Multilingual part-of-speech tagging: Two unsupervised approaches. Journal ofArtificial Intelligence Research, 36(1):341–385.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>J K Low</author>
</authors>
<title>Chinese part-of-speech tagging: One-at-a-time or all-at-once? word-based or character-based.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<volume>volume</volume>
<pages>277</pages>
<contexts>
<context position="2382" citStr="Ng and Low, 2004" startWordPosition="359" endWordPosition="362">ish POS to tag the English words in mixed texts. 2. Due to lack of annotated corpus for mixed texts, most of the English words are tagged as “foreign words”, which is oversimplified. So we cannot use them in further processing for the syntactic and semantic analysis. 3. Most English words used in mixed texts are often out-of-vocabulary (OOV), which thus increases the difficulties to tag them. Currently, the mainstream method of Chinese POS tagging is joint segmentation &amp; tagging with cross-labels, which can avoid the problem of error propagation and achieve higher performance on both subtasks(Ng and Low, 2004). Each label is the crossproduct of a segmentation label and a tagging label, e.g. {B-NN, I-NN, E-NN, S-NN, ...}. The features are generated by position-based templates on character-level. Since the main part of mixed texts is in Chinese and the role of English word is more like Chinese, we use Chinese POS tags (Xia, 2000) to tag English words. Since the categories of the most commonly used English words are nouns, verbs and adjectives, we can use “NN”, “NR”, “VV”, “VA”, “JJ” to label their POS tags. For the English proper nouns and verbs, there are no significant differences in Chinese and En</context>
<context position="22210" citStr="Ng and Low, 2004" startWordPosition="3823" endWordPosition="3826">91.67 87.30 89.43 VV Baseline 48.31 74.14 58.50 Our 60.53 79.31 68.66 VA Baseline 78.95 53.57 63.83 Our 84.21 57.14 68.09 Table 22: Performances of Model C on Dataset R POS tag Method P R F1 NN Baseline 80.25 81.82 81.03 Our 84.56 81.82 83.17 VV Baseline 54.88 77.59 64.29 Our 61.25 84.48 71.01 VA Baseline 84.62 39.29 53.66 Our 88.24 53.57 66.67 NR Baseline 56.52 37.14 44.83 Our 55.17 45.71 50.00 7 Related Works In recent years, POS tagging has undergone great development. The mainstream method is to regard POS tagging as sequence labeling problems (Rabiner, 1990; Xue, 2003; Peng et al., 2004; Ng and Low, 2004). However, the analysis of Chinese-English mixed texts is rarely involved in previous literature. In the aspect of the general multilingual POS tagging, most works focus on modeling cross-lingual correlations and tagging multilingual POS on respective monolingual texts, not on mixed texts (Cucerzan and Yarowsky, 2002; Yarowsky et al., 2001; Naseem et al., 2009). Since we choose to use dynamic word-level features to improve the performance of POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (semiCRF) (Sarawagi and Cohen, 2004) is a model in wh</context>
</contexts>
<marker>Ng, Low, 2004</marker>
<rawString>H.T. Ng and J.K. Low. 2004. Chinese part-of-speech tagging: One-at-a-time or all-at-once? word-based or character-based. In Proceedings of EMNLP, volume 2004, page 277.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fuchun Peng</author>
<author>Fangfang Feng</author>
<author>Andrew McCallum</author>
</authors>
<title>Chinese segmentation and new word detection using conditional random fields.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="22191" citStr="Peng et al., 2004" startWordPosition="3819" endWordPosition="3822">62 78.31 83.15 Our 91.67 87.30 89.43 VV Baseline 48.31 74.14 58.50 Our 60.53 79.31 68.66 VA Baseline 78.95 53.57 63.83 Our 84.21 57.14 68.09 Table 22: Performances of Model C on Dataset R POS tag Method P R F1 NN Baseline 80.25 81.82 81.03 Our 84.56 81.82 83.17 VV Baseline 54.88 77.59 64.29 Our 61.25 84.48 71.01 VA Baseline 84.62 39.29 53.66 Our 88.24 53.57 66.67 NR Baseline 56.52 37.14 44.83 Our 55.17 45.71 50.00 7 Related Works In recent years, POS tagging has undergone great development. The mainstream method is to regard POS tagging as sequence labeling problems (Rabiner, 1990; Xue, 2003; Peng et al., 2004; Ng and Low, 2004). However, the analysis of Chinese-English mixed texts is rarely involved in previous literature. In the aspect of the general multilingual POS tagging, most works focus on modeling cross-lingual correlations and tagging multilingual POS on respective monolingual texts, not on mixed texts (Cucerzan and Yarowsky, 2002; Yarowsky et al., 2001; Naseem et al., 2009). Since we choose to use dynamic word-level features to improve the performance of POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (semiCRF) (Sarawagi and Cohen, 200</context>
</contexts>
<marker>Peng, Feng, McCallum, 2004</marker>
<rawString>Fuchun Peng, Fangfang Feng, and Andrew McCallum. 2004. Chinese segmentation and new word detection using conditional random fields. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence R Rabiner</author>
</authors>
<title>Readings in speech recognition. chapter A tutorial on hidden Markov models and selected applications in speech recognition,</title>
<date>1990</date>
<pages>267--296</pages>
<publisher>Morgan Kaufmann Publishers Inc.,</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="22161" citStr="Rabiner, 1990" startWordPosition="3814" endWordPosition="3816">hod P R F1 NN Baseline 88.62 78.31 83.15 Our 91.67 87.30 89.43 VV Baseline 48.31 74.14 58.50 Our 60.53 79.31 68.66 VA Baseline 78.95 53.57 63.83 Our 84.21 57.14 68.09 Table 22: Performances of Model C on Dataset R POS tag Method P R F1 NN Baseline 80.25 81.82 81.03 Our 84.56 81.82 83.17 VV Baseline 54.88 77.59 64.29 Our 61.25 84.48 71.01 VA Baseline 84.62 39.29 53.66 Our 88.24 53.57 66.67 NR Baseline 56.52 37.14 44.83 Our 55.17 45.71 50.00 7 Related Works In recent years, POS tagging has undergone great development. The mainstream method is to regard POS tagging as sequence labeling problems (Rabiner, 1990; Xue, 2003; Peng et al., 2004; Ng and Low, 2004). However, the analysis of Chinese-English mixed texts is rarely involved in previous literature. In the aspect of the general multilingual POS tagging, most works focus on modeling cross-lingual correlations and tagging multilingual POS on respective monolingual texts, not on mixed texts (Cucerzan and Yarowsky, 2002; Yarowsky et al., 2001; Naseem et al., 2009). Since we choose to use dynamic word-level features to improve the performance of POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (sem</context>
</contexts>
<marker>Rabiner, 1990</marker>
<rawString>Lawrence R. Rabiner. 1990. Readings in speech recognition. chapter A tutorial on hidden Markov models and selected applications in speech recognition, pages 267–296. Morgan Kaufmann Publishers Inc., San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
<author>William W Cohen</author>
</authors>
<title>Semimarkov conditional random fields for information extraction.</title>
<date>2004</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="22793" citStr="Sarawagi and Cohen, 2004" startWordPosition="3911" endWordPosition="3914">2003; Peng et al., 2004; Ng and Low, 2004). However, the analysis of Chinese-English mixed texts is rarely involved in previous literature. In the aspect of the general multilingual POS tagging, most works focus on modeling cross-lingual correlations and tagging multilingual POS on respective monolingual texts, not on mixed texts (Cucerzan and Yarowsky, 2002; Yarowsky et al., 2001; Naseem et al., 2009). Since we choose to use dynamic word-level features to improve the performance of POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (semiCRF) (Sarawagi and Cohen, 2004) is a model in which segmentation task is implicitly included into the decoding algorithm. In this model, feature representation would be more flexible than traditional CRFs, since features can be extracted from the previous/the next segmentation within a window of variable size. The problem of this approach lies in that the decoding algorithm depends on the predefined window size to exploit the boundaries of segmentations but not the real length of words. Bunescu (2008) presents an improved pipeline model in which the output of the previous subtasks are considered as hidden variables, and the</context>
</contexts>
<marker>Sarawagi, Cohen, 2004</marker>
<rawString>Sunita Sarawagi and William W. Cohen. 2004. Semimarkov conditional random fields for information extraction. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
</authors>
<title>A stacked sub-word model for joint chinese word segmentation and part-of-speech tagging.</title>
<date>2011</date>
<pages>1385--1394</pages>
<editor>In Dekang Lin, Yuji Matsumoto, and Rada Mihalcea, editors, ACL,</editor>
<publisher>The Association for Computer Linguistics.</publisher>
<contexts>
<context position="4698" citStr="Sun, 2011" startWordPosition="759" endWordPosition="760">o languages have character-based features and word-based features respectively. To ensure the consistency of tagging models, we prefer to use word-level information in Chinese, which is both useful for ChineseEnglish mixed texts and Chinese-only texts. For instance, in a sentence “X Jr, Z;t Y ... (X or Y ...)”, the word Y ought to have the same POS tag as the word X. Another example is that the word following a pronoun is usually a verb, and adjectives often describe nouns. Some related works show that word-level features can improve the performance of Chinese POS tagging (Jiang et al., 2008; Sun, 2011). In this paper, we propose a method to tag mixed texts with dynamic features. Our method combines these dynamic features, which are dynamically generated at the decoding stage, with traditional static features. For Chinese-English mixed texts, the traditional features cannot yield a satisfied result due to lack of training data. The proposed dynamic features can improve the performance by using the information of a word, such as POS tag or length of the whole word, which is proven effective by experiments. The rest of the paper is organized as follows: In section 2, we introduce the sequence </context>
<context position="24315" citStr="Sun (2011)" startWordPosition="4149" endWordPosition="4150">n and the need of separate training of different subtasks in the pipeline. Another disadvantage of pipeline method is error propagation. Jiang et al. (2008) proposes a cascaded linear model for joint Chinese word segmentation and POS tagging. With a character-based perceptron as the core, combined with real-valued features such as language models, the cascaded model can efficiently utilize knowledge sources that are inconvenient to incorporate into the perceptron directly. However, they use POS tags or word information in a BruteForce way, which may suffer from the problem of time complexity. Sun (2011) presents a stacked sub-word model for joint Chinese word segmentation and POS tagging. By merging the outputs of the three predictors (including one word-based segmenter) into sub-word sequences, rich contextual features can be approximately derived. The experiments are conducted to show the effectiveness of using word-based information. The difference between the above methods and ours is that our word-level features are dynamically generated in the decoding stage without exhaustive or preprocessed word segmentation. 1386 8 Conclusion In this paper, we focus on Chinese-English mixed texts an</context>
</contexts>
<marker>Sun, 2011</marker>
<rawString>Weiwei Sun. 2011. A stacked sub-word model for joint chinese word segmentation and part-of-speech tagging. In Dekang Lin, Yuji Matsumoto, and Rada Mihalcea, editors, ACL, pages 1385–1394. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xia</author>
</authors>
<title>The part-of-speech tagging guidelines for the Penn Chinese Treebank (3.0).</title>
<date>2000</date>
<contexts>
<context position="2706" citStr="Xia, 2000" startWordPosition="419" endWordPosition="420">bulary (OOV), which thus increases the difficulties to tag them. Currently, the mainstream method of Chinese POS tagging is joint segmentation &amp; tagging with cross-labels, which can avoid the problem of error propagation and achieve higher performance on both subtasks(Ng and Low, 2004). Each label is the crossproduct of a segmentation label and a tagging label, e.g. {B-NN, I-NN, E-NN, S-NN, ...}. The features are generated by position-based templates on character-level. Since the main part of mixed texts is in Chinese and the role of English word is more like Chinese, we use Chinese POS tags (Xia, 2000) to tag English words. Since the categories of the most commonly used English words are nouns, verbs and adjectives, we can use “NN”, “NR”, “VV”, “VA”, “JJ” to label their POS tags. For the English proper nouns and verbs, there are no significant differences in Chinese and English POS tags except that English features plural and tense forms. For the English nouns, these are some English nouns used as verbs, such as “我很 [fan/VV] 他。(I adore him very much.)” where “fan” means “adore” and is used as a verb. For the English adjectives, there are two corresponding Chinese POS tags “VA” and “JJ”. For</context>
</contexts>
<marker>Xia, 2000</marker>
<rawString>F. Xia. 2000. The part-of-speech tagging guidelines for the Penn Chinese Treebank (3.0).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Xue</author>
</authors>
<title>Chinese word segmentation as character tagging.</title>
<date>2003</date>
<booktitle>Computational Linguistics and Chinese Language Processing,</booktitle>
<volume>8</volume>
<issue>1</issue>
<contexts>
<context position="22172" citStr="Xue, 2003" startWordPosition="3817" endWordPosition="3818">aseline 88.62 78.31 83.15 Our 91.67 87.30 89.43 VV Baseline 48.31 74.14 58.50 Our 60.53 79.31 68.66 VA Baseline 78.95 53.57 63.83 Our 84.21 57.14 68.09 Table 22: Performances of Model C on Dataset R POS tag Method P R F1 NN Baseline 80.25 81.82 81.03 Our 84.56 81.82 83.17 VV Baseline 54.88 77.59 64.29 Our 61.25 84.48 71.01 VA Baseline 84.62 39.29 53.66 Our 88.24 53.57 66.67 NR Baseline 56.52 37.14 44.83 Our 55.17 45.71 50.00 7 Related Works In recent years, POS tagging has undergone great development. The mainstream method is to regard POS tagging as sequence labeling problems (Rabiner, 1990; Xue, 2003; Peng et al., 2004; Ng and Low, 2004). However, the analysis of Chinese-English mixed texts is rarely involved in previous literature. In the aspect of the general multilingual POS tagging, most works focus on modeling cross-lingual correlations and tagging multilingual POS on respective monolingual texts, not on mixed texts (Cucerzan and Yarowsky, 2002; Yarowsky et al., 2001; Naseem et al., 2009). Since we choose to use dynamic word-level features to improve the performance of POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (semiCRF) (Sara</context>
</contexts>
<marker>Xue, 2003</marker>
<rawString>N. Xue. 2003. Chinese word segmentation as character tagging. Computational Linguistics and Chinese Language Processing, 8(1):29–48.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
<author>R Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the first international conference on Human language technology research,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="22551" citStr="Yarowsky et al., 2001" startWordPosition="3873" endWordPosition="3876">.57 66.67 NR Baseline 56.52 37.14 44.83 Our 55.17 45.71 50.00 7 Related Works In recent years, POS tagging has undergone great development. The mainstream method is to regard POS tagging as sequence labeling problems (Rabiner, 1990; Xue, 2003; Peng et al., 2004; Ng and Low, 2004). However, the analysis of Chinese-English mixed texts is rarely involved in previous literature. In the aspect of the general multilingual POS tagging, most works focus on modeling cross-lingual correlations and tagging multilingual POS on respective monolingual texts, not on mixed texts (Cucerzan and Yarowsky, 2002; Yarowsky et al., 2001; Naseem et al., 2009). Since we choose to use dynamic word-level features to improve the performance of POS tagging, we also review some works on word-level features. Semi-Markov Conditional Random Fields (semiCRF) (Sarawagi and Cohen, 2004) is a model in which segmentation task is implicitly included into the decoding algorithm. In this model, feature representation would be more flexible than traditional CRFs, since features can be extracted from the previous/the next segmentation within a window of variable size. The problem of this approach lies in that the decoding algorithm depends on t</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of the first international conference on Human language technology research, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>