<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.869083">
On Amortizing Inference Cost for Structured Prediction
</title>
<author confidence="0.880108">
Vivek Srikumar* and Gourab Kundu* and Dan Roth
</author>
<affiliation confidence="0.996868">
University of Illinois, Urbana-Champaign
</affiliation>
<address confidence="0.732241">
Urbana, IL. 61801
</address>
<email confidence="0.98895">
1vsrikum2, kundu2, danrl@illinois.edu
</email>
<sectionHeader confidence="0.998534" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999980454545454">
This paper deals with the problem of predict-
ing structures in the context of NLP. Typically,
in structured prediction, an inference proce-
dure is applied to each example independently
of the others. In this paper, we seek to op-
timize the time complexity of inference over
entire datasets, rather than individual exam-
ples. By considering the general inference
representation provided by integer linear pro-
grams, we propose three exact inference the-
orems which allow us to re-use earlier solu-
tions for certain instances, thereby completely
avoiding possibly expensive calls to the infer-
ence procedure. We also identify several ap-
proximation schemes which can provide fur-
ther speedup. We instantiate these ideas to the
structured prediction task of semantic role la-
beling and show that we can achieve a speedup
of over 2.5 using our approach while retain-
ing the guarantees of exactness and a further
speedup of over 3 using approximations that
do not degrade performance.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999854375">
Typically, in structured prediction applications, ev-
ery example is treated independently and an infer-
ence algorithm is applied to each one of them. For
example, consider a dependency parser that uses the
maximum spanning tree algorithm (McDonald et al.,
2005) or its integer linear program variants (Riedel
and Clarke, 2006; Martins et al., 2009) to make pre-
dictions. Given a trained model, the parser addresses
</bodyText>
<note confidence="0.644996">
* These authors contributed equally to this work.
</note>
<bodyText confidence="0.999950558823529">
each sentence separately and runs the inference al-
gorithm to predict the parse tree. Thus, the time
complexity of inference over the test set is linear in
the size of the corpus.
In this paper, we ask the following question: For
a given task, since the inference procedure predicts
structures from the same family of structures (depen-
dency trees, semantic role structures, etc.), can the
fact that we are running inference for a large num-
ber of examples help us improve the time complexity
of inference? In the dependency parsing example,
this question translates to asking whether, having
parsed many sentences, we can decrease the parsing
time for the next sentence.
Since any combinatorial optimization problem
can be phrased as an integer linear program (ILP),
we frame inference problems as ILPs for the purpose
of analysis. By analyzing the objective functions
of integer linear programs, we identify conditions
when two ILPs have the same solution. This allows
us to reuse solutions of previously solved problems
and theoretically guarantee the optimality of the so-
lution. Furthermore, in some cases, even when the
conditions are not satisfied, we can reuse previous
solutions with high probability of being correct.
Given the extensive use of integer linear programs
for structured prediction in Natural Language Pro-
cessing over the last few years, these ideas can be ap-
plied broadly to NLP problems. We instantiate our
improved inference approaches in the structured pre-
diction task of semantic role labeling, where we use
an existing implementation and a previous trained
model that is based on the approach of (Punyakanok
et al., 2008). We merely modify the inference pro-
</bodyText>
<page confidence="0.958151">
1114
</page>
<note confidence="0.82097">
Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural
Language Learning, pages 1114–1124, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.86274">
cess to show that we can realize the theoretical gains
by making fewer calls to the underlying ILP solver.
</bodyText>
<note confidence="0.49137625">
Algorithm Speedup
Theorem 1 2.44
Theorem 2 2.18
Theorem 3 2.50
</note>
<tableCaption confidence="0.990345">
Table 1: The speedup for semantic role labeling cor-
</tableCaption>
<bodyText confidence="0.939604860465117">
responding to the three theorems described in this
paper. These theorems guarantee the optimality of
the solution, thus ensuring that the speedup is not
accompanied by any loss in performance.
Table 1 presents a preview of our results, which
are discussed in Section 4. All three approaches in
this table improve running time, while guaranteeing
optimum solutions. Allowing small violations to the
conditions of the theorems provide an even higher
improvement in speedup (over 3), without loss of
performance.
The primary contributions of this paper are:
1. We pose the problem of optimizing inference
costs over entire datasets rather than individ-
ual examples. Our approach is agnostic to the
underlying models and allows us to use pre-
trained scoring functions.
2. We identify equivalence classes of ILP prob-
lems and use this notion to prove exact con-
ditions under which no inference is required.
These conditions lead to algorithms that can
speed up inference problem without losing the
exactness guarantees. We also use these con-
ditions to develop approximate inference algo-
rithms that can provide a further speedup.
3. We apply our approach to the structured pre-
diction task of semantic role labeling. By not
having to perform inference on some of the in-
stances, those that are equivalent to previously
seen instances, we show significant speed up in
terms of the number of times inference needs to
be performed. These gains are also realized in
terms of wall-clock times.
The rest of this paper is organized as follows: In
section 2, we formulate the problem of amortized
inference and provide motivation for why amortized
gains can be possible. This leads to the theoretical
discussion in section 3, where we present the meta-
algorithm for amortized inference along with sev-
eral exact and approximate inference schemes. We
instantiate these schemes for the task of semantic
role labeling (Section 4). Section 5 discusses related
work and future research directions.
</bodyText>
<sectionHeader confidence="0.981112" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999962074074074">
Many NLP tasks can be phrased as structured pre-
diction problems, where the goal is to jointly assign
values to many inference variables while account-
ing for possible dependencies among them. This de-
cision task is a combinatorial optimization problem
and can be solved using a dynamic programming ap-
proach if the structure permits. In general, the infer-
ence problem can be formulated and solved as inte-
ger linear programs (ILPs).
Following (Roth and Yih, 2004) Integer linear
programs have been used broadly in NLP. For exam-
ple, (Riedel and Clarke, 2006) and (Martins et al.,
2009) addressed the problem of dependency pars-
ing and (Punyakanok et al., 2005; Punyakanok et
al., 2008) dealt with semantic role labeling with this
technique.
In this section, we will use the ILP formulation
of dependency parsing to introduce notation. The
standard approach to framing dependency parsing as
an integer linear program was introduced by (Riedel
and Clarke, 2006), who converted the MST parser
of (McDonald et al., 2005) to use ILP for inference.
The key idea is to build a complete graph consist-
ing of tokens of the sentence where each edge is
weighted by a learned scoring function. The goal
of inference is to select the maximum spanning tree
of this weighted graph.
</bodyText>
<subsectionHeader confidence="0.994669">
2.1 Problem Formulation
</subsectionHeader>
<bodyText confidence="0.999923222222222">
In this work, we consider the general inference prob-
lem of solving a 0-1 integer linear program. To per-
form inference, we assume that we have a model that
assigns scores to the ILP decision variables. Thus,
our work is applicable not only in cases where in-
ference is done after a separate learning phase, as in
(Roth and Yih, 2004; Clarke and Lapata, 2006; Roth
and Yih, 2007) and others, but also when inference
is done during the training phase, for algorithms like
</bodyText>
<page confidence="0.988033">
1115
</page>
<bodyText confidence="0.99992912">
the structured perceptron of (Collins, 2002), struc-
tured SVM (Tsochantaridis et al., 2005) or the con-
straints driven learning approach of (Chang et al.,
2007).
Since structured prediction assigns values to a
collection of inter-related binary decisions, we de-
note the i1h binary decision by yz E 10,1} and the
entire structure as y, the vector composed of all the
binary decisions. In our running example, each edge
in the weighted graph generates a single decision
variable (for unlabeled dependency parsing). For
each yz, let cz E R denote the weight associated with
it. We denote the entire collection of weights by the
vector c, forming the objective for this ILP.
Not all assignments to these variables are valid.
Without loss of generality, these constraints can be
expressed using linear inequalities over the infer-
ence variables, which we write as MTy G b for
a real valued matrix M and a vector b. In depen-
dency parsing, for example, these constraints ensure
that the final output is a spanning tree.
Now, the overall goal of inference is to find the
highest scoring structure. Thus, we can frame infer-
ence as an optimization problem p with n inference
variables as follows:
</bodyText>
<equation confidence="0.858060666666667">
arg max cT y (1)
yE10,11n
subject to MTy G b. (2)
</equation>
<bodyText confidence="0.995866115384616">
For brevity, we denote the space of feasible solutions
that satisfy the constraints for the ILP problem p as
Kp = {y E 10,1}n|MTy G b}. Thus, the goal of
inference is to find
arg max cTy.
yEKp
We refer to Kp as the feasible set for the inference
problem p and yp as its solution.
In the worst case, integer linear programs are
known to be NP-hard. Hence, solving large prob-
lems, (that is, problems with a large number of con-
straints and/or variables) can be infeasible.
For structured prediction problems seen in NLP,
we typically solve many instances of inference prob-
lems. In this paper, we investigate whether an infer-
ence algorithm can use previous predictions to speed
up inference time, thus giving us an amortized gain
in inference time over the lifetime of the program.
We refer to inference algorithms that have this capa-
bility as amortized inference algorithms.
In our running example, each sentence corre-
sponds to a separate ILP. Over the lifetime of the
dependency parser, we create one inference instance
(that is, one ILP) per sentence and solve it. An amor-
tized inference algorithm becomes faster at parsing
as it parses more and more sentences.
</bodyText>
<subsectionHeader confidence="0.8289935">
2.2 Why can inference costs be amortized over
datasets?
</subsectionHeader>
<bodyText confidence="0.868449481481481">
In the rest of this section, we will argue that the time
cost of inference can be amortized because of the
nature of inference in NLP tasks. Our argument is
based on two observations, which are summarized in
Figure (1): (1) Though the space of possible struc-
tures may be large, only a very small fraction of
these occur. (2) The distribution of observed struc-
tures is heavily skewed towards a small number of
them.
Examples
Figure 1: For a structured prediction task, the infer-
ence problem p for an example x needs to be for-
mulated before solving it to get the structure y. In
structured prediction problems seen in NLP, while
an exponential number of structures is possible for a
given instance, in practice, only a small fraction of
these ever occur. This figure illustrates the empirical
observation that there are fewer inference problems
p’s than the number of examples and the number of
observed structures y’s is even lesser.
As an illustration, consider the problem of part-
of-speech tagging. With the standard Penn Treebank
tag set, each token can be assigned one of 45 labels.
Thus, for a sentence of size n, we could have 45n
structures out of which the inference process needs
to choose one. However, a majority of these struc-
tures never occur. For example, we cannot have a
</bodyText>
<figure confidence="0.9958320625">
x’s
Solutions
formulation
p’s
Inference
ILPs
ILP
y’s
1116
SRL statistics , using tagged Gigaword text
160000
140000
120000
100000
80000
60000
40000
20000
0
0 1 2 3 4 5 6 7 8
Size of the input (number of argument candidates)
Number of examples of size
Number of unique SRL structures
(c) Semantic role labeling
Part-of-speech statistics, using tagged Gigaword text
Number of examples of size
Number of unique POS tag sequences
0 10 20 30 40 50
Number of tokens
(a) Part-of-speech tagging
Unlabeled dependency parsing statistics, using tagged Gigaword text
0 10 20 30 40 50
Size of sentence
(b) Unlabeled dependency parsing
Number of examples of size
Number of unique dependency trees
500000
400000
300000
200000
100000
0
500000
400000
300000
200000
100000
0
</figure>
<figureCaption confidence="0.9568804">
Figure 2: Number of inference instances for different input sizes (red solid lines) and the number of unique
structures for each size (blue dotted lines). The x-axis indicates the size of the input (number of tokens
for part of speech and dependency, and number of argument candidates for SRL.) Note that the number of
instances is not the number of unique examples of a given length, but the number of times an inference
procedure is called for an input of a given size.
</figureCaption>
<figure confidence="0.997009230769231">
Log frequency of solutions for sentences with 15 tokens
0 50000 100000 150000 200000 250000 300000 350000
Solution Id
8
1
0
-1
7
6
5
4
3
2
(c) Sentence length = 15
Log frequency of solutions for sentences with 5 tokens
0 5000 10000 15000 20000
Solution Id
(a) Sentence length = 5
Log frequency of solutions for sentences with 10 tokens
0 50000 100000 150000 200000 250000
Solution Id
(b) Sentence length = 10
12
10
8
6
4
2
0
8
7
6
1
0
-1
5
4
3
2
</figure>
<figureCaption confidence="0.996729">
Figure 3: These plots show the log-frequencies of occurrences of part-of-speech sequences for sentences
</figureCaption>
<bodyText confidence="0.978257222222222">
with five, ten and fifteen tokens. The x-axes list different unique part-of-speech tag sequences for the entire
sentence. These plots show that for sentences of a given length, most structures (solutions) that are possible
never occur, or occur very infrequently; only a few of the possible structures (solutions) actually occur
frequently.
sentence where all the tokens are determiners.
Furthermore, many sentences of the same size
share the same part-of-speech tag sequence. To
quantify the redundancy of structures, we part-of-
speech tagged the English Gigaword corpus (Graff
and Cieri, 2003). Figure (2a) shows the number
of sentences in the corpus for different sentence
lengths. In addition, it also shows the number of
unique part-of-speech tag sequences (over the en-
tire sentence) for each size. We see that the number
of structures is much fewer than the number of in-
stances for any sentence size. Note that 45&apos; quickly
outgrows the number of sentences as n increases.
The figures (2b) and (2c) show similar statistics for
unlabeled dependency parsing and semantic role la-
beling. In the former case, the size of the instance is
the number of tokens in a sentence, while in the lat-
ter, the size is the number of argument candidates
that need to be labeled for a given predicate. In
both cases, we see that the number of empirically
observed structures is far fewer than the number of
instances to be labeled.
Thus, for any given input size, the number of in-
stances of that size (over the lifetime of the program)
far exceeds the number of observed structures for
that size. Moreover, the number of observed struc-
tures is significantly smaller than the number of the-
oretically possible structures. Thus, we have a small
number of structures that form optimum structures
for many inference instances of the same size.
Our second observation deals with the distribu-
tion of structures for a given input size. Figure (3)
</bodyText>
<page confidence="0.978835">
1117
</page>
<bodyText confidence="0.999983666666667">
shows the log frequencies of part-of-speech tagging
sequences for sentences of lengths five, ten and fif-
teen. In all cases, we see that a few structures are
most frequent. We observed similar distributions of
structures for all input sizes for dependency parsing
and semantic role labeling as well.
Since the number of structures for a given exam-
ple size is small, many examples x’s, and hence
many inference problems p’s, are associated with
the same structure y. These observations suggest the
possibility of getting an amortized gain in inference
time by characterizing the set of inference problems
that produce the same structure. Then, for a new in-
ference problem, if we can identify that it belongs to
a known set, that is, will yield a solution that we have
already seen, we do not have to run inference at all.
The second observation also suggests that this char-
acterization of sets of problems that have the same
solution can be done in a data-driven way because
characterizing a small number of structures can give
us high coverage.
</bodyText>
<sectionHeader confidence="0.973209" genericHeader="method">
3 Amortizing inference costs
</sectionHeader>
<bodyText confidence="0.999988444444444">
In this section, we present different schemes for
amortized inference leading up to an inference meta-
algorithm. The meta-algorithm is both agnostic to
the underlying inference algorithm that is used by
the problem and maintains the exactness properties
of the underlying inference scheme. That is, if we
have an exact/approximate inference algorithm with
a certain guarantees, the meta-algorithm will have
the same guarantees, but with a speedup.
</bodyText>
<subsectionHeader confidence="0.988912">
3.1 Notation
</subsectionHeader>
<bodyText confidence="0.9958921">
For an integer linear program p with np variables,
we denote its objective coefficients by cp and its fea-
sible set by Kp. We denote its solution as as yp. We
represent vectors by boldfaced symbols and their ith
component using subscripts.
We consider many instantiations of the inference
problem and use superscripts to denote each indi-
vidual instance. Thus, we have a large collection of
inference instances P = {p1, p2, · · · } along with
their respective solutions {y1p, y2p, · · · }.
Definition 1(Equivalence classes of ILPs). Two in-
teger linear programs are said to be in the same
equivalence class if they have the same number of
inference variables and the same feasible set.
We square brackets to denote equivalence classes.
If [P] is an equivalence class of ILPs, we use the
notation K[P] to denote its feasible set and n[P] to
denote the number of variables. Also, for a program
p, we use the notation p — [P] to indicate that it
belongs to the equivalence class [P].
</bodyText>
<subsectionHeader confidence="0.999487">
3.2 Exact theorems
</subsectionHeader>
<bodyText confidence="0.999788142857143">
Our goal is to characterize the set of objective func-
tions which will have the same solution for a given
equivalence class of problems.
Suppose we have solved an ILP p to get a solution
yp. For every inference variable that is active in the
solution (i.e., whose value is 1), increasing the corre-
sponding objective value will not change the optimal
assignment to the variables. Similarly, for all other
variables (whose value in the solution is 0), decreas-
ing the objective value will not change the optimal
solution. This intuition gives us our first theorem for
checking whether two ILPs have the same solution
by looking at the difference between their objective
coefficients.
Theorem 1. Let p denote an inference problem
posed as an integer linear program belonging to an
equivalence class [P]. Let q — [P] be another infer-
ence instance in the same equivalence class. Define
Sc = cq — cp to be the difference of the objective
coefficients of the ILPs. Then, yp is the solution of
the problem q iffor each i E {1, · · · , np}, we have
</bodyText>
<equation confidence="0.99743">
(gyp,i — 1)Sci &gt; 0 (3)
</equation>
<bodyText confidence="0.999265933333333">
The condition in the theorem, that is, inequal-
ity (3), requires that the objective coefficients corre-
sponding to values yp,i that are set to 1 in p increase,
and those that correspond to values of yp,i set to 0,
decrease. Under these conditions, if yp is the max-
imizer of the original objective, then it maximizes
the new objective too.
Theorem 1 identifies perturbations of an ILP’s ob-
jective coefficients that will not change the optimal
assignment. Next, we will characterize the sets of
objective values that will have the same solution us-
ing a criterion that is independent of the actual so-
lution. Suppose we have two ILPs p and q in an
equivalence class [P] whose objective values are cp
and cq respectively. Suppose y* is the solution to
</bodyText>
<page confidence="0.986671">
1118
</page>
<bodyText confidence="0.997925933333333">
both these programs. That is, for every y ∈ K[P],
we have cTpy ≤ cTpy* and cTqy ≤ cT qy*. Multiply-
ing these inequalities by any two positive real num-
bers x1 and x2 and adding them shows us that y*
is also the solution for the ILP in [P] which has the
objective coefficients x1cp + x2cq. Extending this
to an arbitrary number of inference problems gives
us our next theorem.
Theorem 2. Let P denote a collection
{p1, p2, · · · , pm} of m inference problems in
the same equivalence class [P] and suppose that
all the problems have the same solution, yp. Let
q ∼ [P] be a new inference program whose optimal
solution is y. Then y = yp if there is some x ∈ &lt;m
such that x ≥ 0 and
</bodyText>
<equation confidence="0.971162">
�cq = xjcjp. (4)
j
</equation>
<bodyText confidence="0.999176923076923">
From the geometric perspective, the pre-condition
of this theorem implies that if the new coefficients
lie in the cone formed by the coefficients of the pro-
grams that have the same solution, then the new pro-
gram shares the solution.
Theorems 1 and 2 suggest two different ap-
proaches for identifying whether a new ILP can
use the solution of previously solved inference in-
stances. These theorems can be combined to get a
single criterion that uses the objective coefficients of
previously solved inference problems and their com-
mon solution to determine whether a new inference
problem will have the same solution. Given a collec-
tion of solved ILPs that have the same solution, from
theorem 2, we know that an ILP with the objective
coefficients c = �j xjcjp will share the solution.
Considering an ILP whose objective vector is c and
applying theorem 1 to it gives us the next theorem.
Theorem 3. Let P denote a collection
{p1, p2,··· , pm} of m inference problems
belonging to the same equivalence class [P].
Furthermore, suppose all the programs have the
same solution yp. Let q ∼ [P] be a new inference
program in the equivalence class. For any x ∈ &lt;m,
define Ac(x) = cq − �j xjcjp. The assignment
yp is the optimal solution of the problem q if there
</bodyText>
<equation confidence="0.767037666666667">
is some x ∈ &lt;m such that x ≥ 0 and for each
i ∈ {1, np}, we have
(2yp,i − 1)Aci ≥ 0 (5)
</equation>
<table confidence="0.989569428571429">
Theorem Condition
Theorem 1 ∀i ∈ {1, · · · , np},
(2yp,i − 1)Sci ≥ 0; ∀i.
Theorem 2 ∃ x ∈ &lt;m, such that
x ≥ 0 and cq = �j xjcjp
Theorem 3 ∃ x ∈ &lt;m, such that
x ≥ 0 and (2yp,i − 1)Aci ≥ 0; ∀i.
</table>
<tableCaption confidence="0.972907">
Table 2: Conditions for checking whether yp is the
</tableCaption>
<bodyText confidence="0.866187333333333">
solution for an inference problem q ∼ [P] according
to theorems 1, 2 and 3. Please refer to the statements
of the theorems for details about the notation.
</bodyText>
<subsectionHeader confidence="0.986299">
3.3 Implementation
</subsectionHeader>
<bodyText confidence="0.999932677419355">
Theorems 1, 2 and 3 each specify a condition that
checks whether a pre-existing solution is the opti-
mal assignment for a new inference problem. These
conditions are summarized in Table 2. In all cases,
if the condition matches, the theorems guarantee that
the two solutions will be the same. That is, applying
the theorems will not change the performance of the
underlying inference procedure. Only the number of
inference calls will be decreased.
In our implementation of the conditions, we used
a database1 to cache ILPs and implemented the
retrieval of equivalence classes and solutions as
queries to the database. To implement theorem 1,
we iterate over all ILPs in the equivalence class and
check if the condition is satisfied for one of them.
The conditions of theorems 2 and 3 check whether a
collection of linear (in)equalities has a feasible solu-
tion using a linear program solver.
We optimize the wall-clock time of theorems 2
and 3 by making two observations. First, we do not
need to solve linear programs for all possible ob-
served structures. Given an objective vector, we only
need consider the highest scoring structures within
an equivalence class. (All other structures cannot
be the solution to the ILP.) Second, since theorem
2 checks whether an ILP lies within a cone, we can
optimize the cache for theorem 2 by only storing the
ILPs that form on the boundary of the cone. A sim-
ilar optimization can be performed for theorem 3 as
well. Our implementation uses the following weaker
version of this optimization: while caching ILPs, we
</bodyText>
<footnote confidence="0.9997635">
1We used the H2 database engine, which can be downloaded
from http://h2database.com, for all caching.
</footnote>
<page confidence="0.998248">
1119
</page>
<bodyText confidence="0.999905333333333">
do not add an instance to the cache if it already satis-
fies the theorem. This optimization reduces the size
of the linear programs used to check feasibility.
</bodyText>
<subsectionHeader confidence="0.9944">
3.4 Approximation schemes
</subsectionHeader>
<bodyText confidence="0.999877857142857">
So far, in the above three theorems, we retain the
guarantees (in terms of exactness and performance)
of the underlying inference procedure. Now, we will
look at schemes for approximate inference. Unlike
the three theorems listed above, with the following
amortized inference schemes, we are not guaranteed
an optimal solution.
</bodyText>
<subsectionHeader confidence="0.89712">
3.4.1 Most frequent solution
</subsectionHeader>
<bodyText confidence="0.999981545454546">
The first scheme for approximation uses the ob-
servation that the most frequent solution occurs an
overwhelmingly large number of times, compared to
the others. (See the discussion in section 2.2 and fig-
ures 3a, 3b and 3c for part-of-speech tagging.) Un-
der this approximation scheme, given an ILP prob-
lem, we simply pick the most frequent solution for
that equivalence class as the solution, provided this
solution has been seen a sufficient number of times.
If the support available in the cache is insufficient,
we call the underlying inference procedure.
</bodyText>
<sectionHeader confidence="0.431155" genericHeader="method">
3.4.2 Top-K approximation
</sectionHeader>
<bodyText confidence="0.9999778">
The previous scheme for approximate amortized
inference is agnostic to the objective coefficients of
integer linear program to be solved and uses only
its equivalence class to find a candidate structure.
The top-K approach extends this by scoring the K
most frequent solutions using the objective coeffi-
cients and selecting the highest scoring one as the
solution to the ILP problem. As with the previous
scheme, we only consider solutions that have suffi-
cient support.
</bodyText>
<subsectionHeader confidence="0.969192">
3.4.3 Approximations to theorems 1 and 3
</subsectionHeader>
<bodyText confidence="0.99932225">
The next approximate inference schemes relaxes
the conditions in theorems 1 and 3 by allowing the
inequalities to be violated by E. That is, the inequal-
ity (3) from Theorem 1 now becomes
</bodyText>
<equation confidence="0.965795">
(2yp,i − 1)Sci + E &gt; 0. (6)
</equation>
<bodyText confidence="0.783358">
The inequality (5) from Theorem 3 is similarly re-
laxed as follows:
</bodyText>
<equation confidence="0.831011">
(2yp,i − 1)Aci + E &gt; 0 (7)
</equation>
<subsectionHeader confidence="0.945025">
3.5 Amortized inference algorithm
</subsectionHeader>
<bodyText confidence="0.999978777777778">
Each exact and approximate inference approach de-
scribed above specifies a condition to check whether
an inference procedure should be called for a
new problem. This gives us the following meta-
algorithm for amortized inference, parameterized by
the actual scheme used: If the given input instance p
satisfies the condition specified by the scheme, then
use the cached solution. Otherwise, call the infer-
ence procedure and cache the solution for future use.
</bodyText>
<sectionHeader confidence="0.999121" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999969214285714">
In this section, we apply the theory from Section 3 to
the structure prediction problem of semantic role la-
beling. Since the inference schemes presented above
are independent of the learning aspects, we use an
off-the-shelf implementation and merely modify the
inference as discussed in Section 3.5.
The goal of the experiments is to show that us-
ing an amortized inference algorithm, we can make
fewer calls to the underlying inference procedure.
For the exact inference algorithms, doing so will not
change the performance as compared to the under-
lying system. For the approximations, we can make
a trade-off between the inference time and perfor-
mance.
</bodyText>
<subsectionHeader confidence="0.993241">
4.1 Experimental setup
</subsectionHeader>
<bodyText confidence="0.998949684210526">
Our goal is to simulate a long-running NLP process
that can use a cache of already solved problems to
improve inference time. Given a new input problem,
our theorems require us to find all elements in the
equivalence class of that problem along with their
solutions. Intuitively, we expect a higher probability
of finding members of an arbitrary equivalence class
if the size of the cache is large. Hence, we processed
sentences from the Gigaword corpus and cached the
inference problems for our task.
The wall-clock time is strongly dependent on such
specific implementation of the components, which
are independent of the main contributions of this
work. Also, in most interesting applications, the
computation time for each step will be typically
dominated by the number of inference steps, espe-
cially with efficient implementations of caching and
retrieval. Hence, the number of calls to the underly-
ing procedure is the appropriate complexity param-
</bodyText>
<page confidence="0.979004">
1120
</page>
<bodyText confidence="0.999592142857143">
eter. Let NBase be the number of times we would
need to call the underlying inference procedure had
we not used an amortized algorithm. (This is the
same as the number of inference problems.) Let NA
be the number of times the underlying inference pro-
cedure is actually called using an amortized algo-
rithm A. We define the speedup of A as
</bodyText>
<equation confidence="0.9962645">
Speedup(A) = NBase
NA . (8)
</equation>
<bodyText confidence="0.999866571428571">
We also report the clock speedup of our implemen-
tation for all algorithms, which is the ratio of the
wall-clock time taken by the baseline algorithm to
that of the amortized algorithm. For measuring time,
we only measure the time for inference as the other
aspects (feature extraction, scoring, etc.) are not
changed.
</bodyText>
<subsectionHeader confidence="0.996574">
4.2 Semantic Role Labeling
</subsectionHeader>
<bodyText confidence="0.999881786885246">
The goal of Semantic Role Labeling (SRL) (Palmer
et al., 2010) is to identify and assign semantic roles
to arguments of verb predicates in a sentence. For
example, consider the the sentence John gave the
ball to Mary. The verb give takes three arguments,
John, the ball and to Mary, which are labeled A0,
A1 and A2 respectively.
We used the system of (Punyakanok et al., 2008)
as our base SRL system. It consists of two classi-
fiers trained on the Propbank corpus. The first one,
called the argument identifier, filters argument can-
didates which are generated using a syntactic parse-
based heuristic. The second model scores each can-
didate that has not been filtered for all possible argu-
ment labels. The scores for all candidates of a pred-
icate are combined via inference. As in the system
of (Punyakanok et al., 2008), the softmax function
is applied to the raw classifier scores to ensure that
they are in the same numeric range.
Inference mandates that certain structural and
linguistic constraints hold over the full predicate-
argument structure for a verb. (Punyakanok et al.,
2008) modeled inference via an integer linear pro-
gram instance, where each assignment of labels
to candidates corresponds to one decision variable.
Given a set of argument candidates, the feasible set
of decisions is dependent of the number of argument
candidates and the verb predicate. Thus, in terms
of the notation used in this paper, the equivalence
classes are defined by the pair (predicate, number of
argument candidates).
We ran the semantic role labeler on 225,000 verb
predicates from the Gigaword corpus and cached
the equivalence classes, objective coefficients and
solutions generated by the SRL system. We re-
port speedup for the various amortized inference
schemes on the standard Penn Treebank test set. On
this data, the unaltered baseline system, processes
5127 integer linear programs and achieves an F1 of
75.85%.
Table 3 shows the speedup and performance for
the various inference schemes. The most frequent
and top-K systems are both naive solutions that take
advantage of the cache of stored problems. In spite
of their simplicity, they attain F1 scores of 62%
and 70.06% because few structures occur most fre-
quently, as described in section 2.2. We see that all
the exact theorems attain a speedup higher than two
without losing performance. (The variation in F1 be-
tween them is because of the existence of different
equivalent solutions in terms of the objective value.)
This shows us that we can achieve an amortized gain
in inference. Note that a speedup of 2.5 indicates
that the solver is called only for 40% of the exam-
ples. The approximate versions of theorems 1 and 3
(with E = 0.3 in both cases, which was not tuned)
attain an even higher gain in speedup over the base-
line than the base versions of the theorems. Interest-
ingly, the SRL performance in both cases does not
decline much even though the conditions of the the-
orems may be violated.
</bodyText>
<sectionHeader confidence="0.999779" genericHeader="method">
5 Related work and Future directions
</sectionHeader>
<bodyText confidence="0.999936">
In recent years, we have seen several approaches to
speeding up inference using ideas like using the cut-
ting plane approach (Riedel, 2009), dual decompo-
sition and Lagrangian relaxation (Rush et al., 2010;
Chang and Collins, 2011). The key difference be-
tween these and the work in this paper is that all
these approaches solve one instance at a time. Since
we can use any inference procedure as a underlying
system, the speedup reported in this paper is appli-
cable to all these algorithms.
Decomposed amortized inference In this paper,
we have taken advantage of redundancy of struc-
tures that can lead to the re-use of solutions. In the
</bodyText>
<page confidence="0.961884">
1121
</page>
<table confidence="0.9999147">
Type Algorithm # instances # solver Speedup Clock F1
calls speedup
Exact Baseline 5127 5217 1.0 1.0 75.85
Exact Theorem 1 5127 2134 2.44 1.54 75.90
Exact Theorem 2 5127 2390 2.18 1.14 75.79
Exact Theorem 3 5127 2089 2.50 1.36 75.77
Approx. Most frequent (Support = 50) 5127 2812 1.86 1.57 62.00
Approx. Top-10 solutions (Support = 50) 5127 2812 1.86 1.58 70.06
Approx. Theorem 1 (approx, E = 0.3) 5127 1634 3.19 1.81 75.76
Approx. Theorem 3 (approx, E = 0.3) 5127 1607 3.25 1.50 75.46
</table>
<tableCaption confidence="0.997192">
Table 3: Speedup and performance for various inference methods for the task of Semantic Role Labeling.
</tableCaption>
<bodyText confidence="0.977342628571429">
All the exact inference algorithms get a speedup higher than two. The speedup of the approximate version
of the theorems is even higher without loss of performance. The clock speedup is defined as the ratio of the
inference times of the baseline and the given algorithm. All numbers are averaged over ten trials.
part of speech example, we showed redundancy of
structures at the sentence level (Figure 2a). How-
ever, for part-of-speech tagging, the decisions are
rarely, if at all, dependent on a very large context.
One direction of future work is to take advantage of
the fact that the inference problem can be split into
smaller sub-problems. To support this hypothesis,
we counted the number of occurrences of ngrams
of tokens (including overlapping and repeated men-
tions) for n &lt;= 10 and compared this to the number
of unique part-of-speech ngrams of this length. Fig-
ure 4 shows these two counts. Following the argu-
ment in Section 2.2, this promises a large amortized
gain in inference time. We believe that such decom-
position can also be applied to other, more complex
structured prediction tasks.
The value of approximate inference From the
experiments, we see that the first two approximate
inference schemes (most frequent solution and the
top-K scheme) can speed up inference with the
only computational cost being the check for pre-
conditions of the exact theorems. Effectively, these
algorithms have parameters (i.e., the support param-
eter) that allow us to choose between the inference
time and performance. Figure 5 shows the perfor-
mance of the most frequent and top-K baselines for
different values of the support parameter, which in-
dicates how often a structure must occur for it to be
considered. We see that for lower values of support,
we can get a very high speedup but pay with poorer
performance.
Part-of-speech ngram statistics, using tagged Gigavord text
</bodyText>
<figureCaption confidence="0.80241775">
Figure 4: The red line shows the number of ngrams
of tokens (including overlapping and repeated oc-
currences) in the Gigaword corpus and the blue line
shows the number of unique POS tag sequences.
</figureCaption>
<bodyText confidence="0.999687769230769">
However, the prediction of the approximate al-
gorithms can be used to warm-start any solver that
can accept an external initialization. Warm-starting
a solver can give a way to get the exact solution and
yet take advantage of the frequency of structures that
have been observed.
Lifted inference The idea of amortizing inference
time over the dataset is conceptually related to the
idea of lifted inference (de Salvo Braz et al., 2005).
We abstract many instances into equivalence classes
and deal with the inference problem with respect to
the equivalence classes in the same way as done in
lifted inference algorithms.
</bodyText>
<figure confidence="0.9245692">
0 2 4 6 8 10
Number of tokens
7e+06
6e+06
5e+06
4e+06
3e+06
2e+06
1e+06
0
Number of instances for size
Number of unique structures for given length
1122
Performance of the most frequent and top-C schemes for different values of support
Support
</figure>
<figureCaption confidence="0.781199">
Figure 5: Most frequent solutions and top-K:
</figureCaption>
<bodyText confidence="0.735823142857143">
Speedup and SRL performance (F1) for different
values of the support parameter, using the most-
frequent solutions (dashed blue line) and the top-
K scheme (thick gray line). Support indicates how
many times a structure should be seen for it to be
considered. Note that the speedup values for both
schemes are identical (red line).
</bodyText>
<sectionHeader confidence="0.999522" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999958176470588">
In this paper, we addressed structured prediction in
the context of NLP and proposed an approach to im-
prove inference costs over an entire dataset, rather
than individual instances. By treating inference
problems as instances of integer linear programs, we
proposed three exact theorems which identify exam-
ples for which the inference procedure need not be
called at all and previous solutions can be re-used
with the guarantee of optimality. In addition, we
also proposed several approximate algorithms. We
applied our algorithms, which are agnostic to the
actual tasks, to the problem semantic role labeling,
showing significant decrease in the number of infer-
ence calls without any loss in performance. While
the approach suggested in this paper is evaluated in
semantic role labeling, it is generally applicable to
any NLP task that deals with structured prediction.
</bodyText>
<sectionHeader confidence="0.997074" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.916287647058824">
The authors wish to thank Sariel Har-Peled and the members
of the Cognitive Computation Group at the University of Illi-
nois for insightful discussions and the anonymous reviewers for
their valuable feedback. This research is sponsored by the Army
Research Laboratory (ARL) under agreement W911NF-09-2-
0053. The authors also gratefully acknowledge the support
of the Defense Advanced Research Projects Agency (DARPA)
Machine Reading Program under Air Force Research Labo-
ratory (AFRL) prime contract no. FA8750-09-C-0181. This
work is also supported by the Intelligence Advanced Research
Projects Activity (IARPA) Foresight and Understanding from
Scientific Exposition (FUSE) Program via Department of In-
terior National Business Center contract number D11PC2015.
Any opinions, findings, and conclusions or recommendations
expressed in this material are those of the author(s) and do not
necessarily reflect the view of ARL, DARPA, AFRL, IARPA,
or the US government.
</bodyText>
<sectionHeader confidence="0.996496" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999542210526316">
Y-W. Chang and M. Collins. 2011. Exact decoding
of phrase-based translation models through lagrangian
relaxation. EMNLP.
M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semi-
supervision with constraint-driven learning. In ACL.
J. Clarke and M. Lapata. 2006. Constraint-based
sentence compression: An integer programming ap-
proach. In ACL.
M. Collins. 2002. Discriminative training methods for
hidden Markov models: Theory and experiments with
perceptron algorithms. In EMNLP.
R. de Salvo Braz, E. Amir, and D. Roth. 2005. Lifted
first-order probabilistic inference. In IJCAI.
D Graff and C. Cieri. 2003. English gigaword.
A. Martins, N. A. Smith, and E. Xing. 2009. Concise
integer linear programming formulations for depen-
dency parsing. In ACL.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005.
Non-projective dependency parsing using spanning
tree algorithms. In EMNLP, pages 523–530, Vancou-
ver, British Columbia, Canada, October. Association
for Computational Linguistics.
M. Palmer, D. Gildea, and N. Xue. 2010. Semantic Role
Labeling, volume 3. Morgan &amp; Claypool Publishers.
V. Punyakanok, D. Roth, and W. Yih. 2005. The neces-
sity of syntactic parsing for semantic role labeling. In
IJCAI.
V. Punyakanok, D. Roth, and W. Yih. 2008. The impor-
tance of syntactic parsing and inference in semantic
role labeling. Computational Linguistics.
S. Riedel and J. Clarke. 2006. Incremental integer linear
programming for non-projective dependency parsing.
In EMNLP.
S. Riedel. 2009. Cutting Plane MAP Inference for
Markov Logic. Machine Learning.
D. Roth and W. Yih. 2004. A linear programming formu-
lation for global inference in natural language tasks. In
Hwee Tou Ng and Ellen Riloff, editors, CoNLL.
</reference>
<figure confidence="0.995398647058823">
0 200 400 600 800 1000
3.5
2.5
1.5
3
2
1
Speedup
Performance of most frequent solution (F1)
Performance of top-C solution (F1)
80
75
70
65
60
55
50
</figure>
<page confidence="0.900401">
1123
</page>
<reference confidence="0.999412416666667">
D. Roth and W. Yih. 2007. Global inference for entity
and relation identification via a linear programming
formulation. In Lise Getoor and Ben Taskar, editors,
Introduction to Statistical Relational Learning.
A. M. Rush, D. Sontag, M. Collins, and T. Jaakkola.
2010. On dual decomposition and linear program-
ming relaxations for natural language processing. In
EMNLP.
I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Al-
tun. 2005. Large margin methods for structured and
interdependent output variables. Journal of Machine
Learning Research.
</reference>
<page confidence="0.996083">
1124
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.949483">
<title confidence="0.971996">On Amortizing Inference Cost for Structured Prediction</title>
<affiliation confidence="0.999839">University of Illinois,</affiliation>
<address confidence="0.989619">Urbana, IL.</address>
<email confidence="0.995169">1vsrikum2,kundu2,danrl@illinois.edu</email>
<abstract confidence="0.99964347826087">This paper deals with the problem of predicting structures in the context of NLP. Typically, in structured prediction, an inference procedure is applied to each example independently of the others. In this paper, we seek to optimize the time complexity of inference over entire datasets, rather than individual examples. By considering the general inference representation provided by integer linear programs, we propose three exact inference theorems which allow us to re-use earlier solutions for certain instances, thereby completely avoiding possibly expensive calls to the inference procedure. We also identify several approximation schemes which can provide further speedup. We instantiate these ideas to the structured prediction task of semantic role labeling and show that we can achieve a speedup of over 2.5 using our approach while retaining the guarantees of exactness and a further speedup of over 3 using approximations that do not degrade performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y-W Chang</author>
<author>M Collins</author>
</authors>
<title>Exact decoding of phrase-based translation models through lagrangian relaxation.</title>
<date>2011</date>
<publisher>EMNLP.</publisher>
<contexts>
<context position="31459" citStr="Chang and Collins, 2011" startWordPosition="5343" endWordPosition="5346">alled only for 40% of the examples. The approximate versions of theorems 1 and 3 (with E = 0.3 in both cases, which was not tuned) attain an even higher gain in speedup over the baseline than the base versions of the theorems. Interestingly, the SRL performance in both cases does not decline much even though the conditions of the theorems may be violated. 5 Related work and Future directions In recent years, we have seen several approaches to speeding up inference using ideas like using the cutting plane approach (Riedel, 2009), dual decomposition and Lagrangian relaxation (Rush et al., 2010; Chang and Collins, 2011). The key difference between these and the work in this paper is that all these approaches solve one instance at a time. Since we can use any inference procedure as a underlying system, the speedup reported in this paper is applicable to all these algorithms. Decomposed amortized inference In this paper, we have taken advantage of redundancy of structures that can lead to the re-use of solutions. In the 1121 Type Algorithm # instances # solver Speedup Clock F1 calls speedup Exact Baseline 5127 5217 1.0 1.0 75.85 Exact Theorem 1 5127 2134 2.44 1.54 75.90 Exact Theorem 2 5127 2390 2.18 1.14 75.7</context>
</contexts>
<marker>Chang, Collins, 2011</marker>
<rawString>Y-W. Chang and M. Collins. 2011. Exact decoding of phrase-based translation models through lagrangian relaxation. EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Guiding semisupervision with constraint-driven learning.</title>
<date>2007</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7701" citStr="Chang et al., 2007" startWordPosition="1239" endWordPosition="1242">, we consider the general inference problem of solving a 0-1 integer linear program. To perform inference, we assume that we have a model that assigns scores to the ILP decision variables. Thus, our work is applicable not only in cases where inference is done after a separate learning phase, as in (Roth and Yih, 2004; Clarke and Lapata, 2006; Roth and Yih, 2007) and others, but also when inference is done during the training phase, for algorithms like 1115 the structured perceptron of (Collins, 2002), structured SVM (Tsochantaridis et al., 2005) or the constraints driven learning approach of (Chang et al., 2007). Since structured prediction assigns values to a collection of inter-related binary decisions, we denote the i1h binary decision by yz E 10,1} and the entire structure as y, the vector composed of all the binary decisions. In our running example, each edge in the weighted graph generates a single decision variable (for unlabeled dependency parsing). For each yz, let cz E R denote the weight associated with it. We denote the entire collection of weights by the vector c, forming the objective for this ILP. Not all assignments to these variables are valid. Without loss of generality, these const</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semisupervision with constraint-driven learning. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>M Lapata</author>
</authors>
<title>Constraint-based sentence compression: An integer programming approach.</title>
<date>2006</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="7425" citStr="Clarke and Lapata, 2006" startWordPosition="1194" endWordPosition="1197">e ILP for inference. The key idea is to build a complete graph consisting of tokens of the sentence where each edge is weighted by a learned scoring function. The goal of inference is to select the maximum spanning tree of this weighted graph. 2.1 Problem Formulation In this work, we consider the general inference problem of solving a 0-1 integer linear program. To perform inference, we assume that we have a model that assigns scores to the ILP decision variables. Thus, our work is applicable not only in cases where inference is done after a separate learning phase, as in (Roth and Yih, 2004; Clarke and Lapata, 2006; Roth and Yih, 2007) and others, but also when inference is done during the training phase, for algorithms like 1115 the structured perceptron of (Collins, 2002), structured SVM (Tsochantaridis et al., 2005) or the constraints driven learning approach of (Chang et al., 2007). Since structured prediction assigns values to a collection of inter-related binary decisions, we denote the i1h binary decision by yz E 10,1} and the entire structure as y, the vector composed of all the binary decisions. In our running example, each edge in the weighted graph generates a single decision variable (for un</context>
</contexts>
<marker>Clarke, Lapata, 2006</marker>
<rawString>J. Clarke and M. Lapata. 2006. Constraint-based sentence compression: An integer programming approach. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="7587" citStr="Collins, 2002" startWordPosition="1222" endWordPosition="1223">inference is to select the maximum spanning tree of this weighted graph. 2.1 Problem Formulation In this work, we consider the general inference problem of solving a 0-1 integer linear program. To perform inference, we assume that we have a model that assigns scores to the ILP decision variables. Thus, our work is applicable not only in cases where inference is done after a separate learning phase, as in (Roth and Yih, 2004; Clarke and Lapata, 2006; Roth and Yih, 2007) and others, but also when inference is done during the training phase, for algorithms like 1115 the structured perceptron of (Collins, 2002), structured SVM (Tsochantaridis et al., 2005) or the constraints driven learning approach of (Chang et al., 2007). Since structured prediction assigns values to a collection of inter-related binary decisions, we denote the i1h binary decision by yz E 10,1} and the entire structure as y, the vector composed of all the binary decisions. In our running example, each edge in the weighted graph generates a single decision variable (for unlabeled dependency parsing). For each yz, let cz E R denote the weight associated with it. We denote the entire collection of weights by the vector c, forming the</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden Markov models: Theory and experiments with perceptron algorithms. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R de Salvo Braz</author>
<author>E Amir</author>
<author>D Roth</author>
</authors>
<title>Lifted first-order probabilistic inference.</title>
<date>2005</date>
<booktitle>In IJCAI. D Graff</booktitle>
<note>English gigaword.</note>
<contexts>
<context position="34966" citStr="Braz et al., 2005" startWordPosition="5936" endWordPosition="5939">e red line shows the number of ngrams of tokens (including overlapping and repeated occurrences) in the Gigaword corpus and the blue line shows the number of unique POS tag sequences. However, the prediction of the approximate algorithms can be used to warm-start any solver that can accept an external initialization. Warm-starting a solver can give a way to get the exact solution and yet take advantage of the frequency of structures that have been observed. Lifted inference The idea of amortizing inference time over the dataset is conceptually related to the idea of lifted inference (de Salvo Braz et al., 2005). We abstract many instances into equivalence classes and deal with the inference problem with respect to the equivalence classes in the same way as done in lifted inference algorithms. 0 2 4 6 8 10 Number of tokens 7e+06 6e+06 5e+06 4e+06 3e+06 2e+06 1e+06 0 Number of instances for size Number of unique structures for given length 1122 Performance of the most frequent and top-C schemes for different values of support Support Figure 5: Most frequent solutions and top-K: Speedup and SRL performance (F1) for different values of the support parameter, using the mostfrequent solutions (dashed blue</context>
</contexts>
<marker>Braz, Amir, Roth, 2005</marker>
<rawString>R. de Salvo Braz, E. Amir, and D. Roth. 2005. Lifted first-order probabilistic inference. In IJCAI. D Graff and C. Cieri. 2003. English gigaword.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Martins</author>
<author>N A Smith</author>
<author>E Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1537" citStr="Martins et al., 2009" startWordPosition="234" endWordPosition="237">to the structured prediction task of semantic role labeling and show that we can achieve a speedup of over 2.5 using our approach while retaining the guarantees of exactness and a further speedup of over 3 using approximations that do not degrade performance. 1 Introduction Typically, in structured prediction applications, every example is treated independently and an inference algorithm is applied to each one of them. For example, consider a dependency parser that uses the maximum spanning tree algorithm (McDonald et al., 2005) or its integer linear program variants (Riedel and Clarke, 2006; Martins et al., 2009) to make predictions. Given a trained model, the parser addresses * These authors contributed equally to this work. each sentence separately and runs the inference algorithm to predict the parse tree. Thus, the time complexity of inference over the test set is linear in the size of the corpus. In this paper, we ask the following question: For a given task, since the inference procedure predicts structures from the same family of structures (dependency trees, semantic role structures, etc.), can the fact that we are running inference for a large number of examples help us improve the time compl</context>
<context position="6366" citStr="Martins et al., 2009" startWordPosition="1012" endWordPosition="1015">future research directions. 2 Motivation Many NLP tasks can be phrased as structured prediction problems, where the goal is to jointly assign values to many inference variables while accounting for possible dependencies among them. This decision task is a combinatorial optimization problem and can be solved using a dynamic programming approach if the structure permits. In general, the inference problem can be formulated and solved as integer linear programs (ILPs). Following (Roth and Yih, 2004) Integer linear programs have been used broadly in NLP. For example, (Riedel and Clarke, 2006) and (Martins et al., 2009) addressed the problem of dependency parsing and (Punyakanok et al., 2005; Punyakanok et al., 2008) dealt with semantic role labeling with this technique. In this section, we will use the ILP formulation of dependency parsing to introduce notation. The standard approach to framing dependency parsing as an integer linear program was introduced by (Riedel and Clarke, 2006), who converted the MST parser of (McDonald et al., 2005) to use ILP for inference. The key idea is to build a complete graph consisting of tokens of the sentence where each edge is weighted by a learned scoring function. The g</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>A. Martins, N. A. Smith, and E. Xing. 2009. Concise integer linear programming formulations for dependency parsing. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In EMNLP,</booktitle>
<pages>523--530</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="1450" citStr="McDonald et al., 2005" startWordPosition="220" endWordPosition="223">ral approximation schemes which can provide further speedup. We instantiate these ideas to the structured prediction task of semantic role labeling and show that we can achieve a speedup of over 2.5 using our approach while retaining the guarantees of exactness and a further speedup of over 3 using approximations that do not degrade performance. 1 Introduction Typically, in structured prediction applications, every example is treated independently and an inference algorithm is applied to each one of them. For example, consider a dependency parser that uses the maximum spanning tree algorithm (McDonald et al., 2005) or its integer linear program variants (Riedel and Clarke, 2006; Martins et al., 2009) to make predictions. Given a trained model, the parser addresses * These authors contributed equally to this work. each sentence separately and runs the inference algorithm to predict the parse tree. Thus, the time complexity of inference over the test set is linear in the size of the corpus. In this paper, we ask the following question: For a given task, since the inference procedure predicts structures from the same family of structures (dependency trees, semantic role structures, etc.), can the fact that</context>
<context position="6796" citStr="McDonald et al., 2005" startWordPosition="1080" endWordPosition="1083">olved as integer linear programs (ILPs). Following (Roth and Yih, 2004) Integer linear programs have been used broadly in NLP. For example, (Riedel and Clarke, 2006) and (Martins et al., 2009) addressed the problem of dependency parsing and (Punyakanok et al., 2005; Punyakanok et al., 2008) dealt with semantic role labeling with this technique. In this section, we will use the ILP formulation of dependency parsing to introduce notation. The standard approach to framing dependency parsing as an integer linear program was introduced by (Riedel and Clarke, 2006), who converted the MST parser of (McDonald et al., 2005) to use ILP for inference. The key idea is to build a complete graph consisting of tokens of the sentence where each edge is weighted by a learned scoring function. The goal of inference is to select the maximum spanning tree of this weighted graph. 2.1 Problem Formulation In this work, we consider the general inference problem of solving a 0-1 integer linear program. To perform inference, we assume that we have a model that assigns scores to the ILP decision variables. Thus, our work is applicable not only in cases where inference is done after a separate learning phase, as in (Roth and Yih, </context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. In EMNLP, pages 523–530, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
<author>D Gildea</author>
<author>N Xue</author>
</authors>
<date>2010</date>
<booktitle>Semantic Role Labeling,</booktitle>
<volume>3</volume>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="28298" citStr="Palmer et al., 2010" startWordPosition="4811" endWordPosition="4814"> as the number of inference problems.) Let NA be the number of times the underlying inference procedure is actually called using an amortized algorithm A. We define the speedup of A as Speedup(A) = NBase NA . (8) We also report the clock speedup of our implementation for all algorithms, which is the ratio of the wall-clock time taken by the baseline algorithm to that of the amortized algorithm. For measuring time, we only measure the time for inference as the other aspects (feature extraction, scoring, etc.) are not changed. 4.2 Semantic Role Labeling The goal of Semantic Role Labeling (SRL) (Palmer et al., 2010) is to identify and assign semantic roles to arguments of verb predicates in a sentence. For example, consider the the sentence John gave the ball to Mary. The verb give takes three arguments, John, the ball and to Mary, which are labeled A0, A1 and A2 respectively. We used the system of (Punyakanok et al., 2008) as our base SRL system. It consists of two classifiers trained on the Propbank corpus. The first one, called the argument identifier, filters argument candidates which are generated using a syntactic parsebased heuristic. The second model scores each candidate that has not been filter</context>
</contexts>
<marker>Palmer, Gildea, Xue, 2010</marker>
<rawString>M. Palmer, D. Gildea, and N. Xue. 2010. Semantic Role Labeling, volume 3. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>The necessity of syntactic parsing for semantic role labeling.</title>
<date>2005</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="6439" citStr="Punyakanok et al., 2005" startWordPosition="1024" endWordPosition="1027">as structured prediction problems, where the goal is to jointly assign values to many inference variables while accounting for possible dependencies among them. This decision task is a combinatorial optimization problem and can be solved using a dynamic programming approach if the structure permits. In general, the inference problem can be formulated and solved as integer linear programs (ILPs). Following (Roth and Yih, 2004) Integer linear programs have been used broadly in NLP. For example, (Riedel and Clarke, 2006) and (Martins et al., 2009) addressed the problem of dependency parsing and (Punyakanok et al., 2005; Punyakanok et al., 2008) dealt with semantic role labeling with this technique. In this section, we will use the ILP formulation of dependency parsing to introduce notation. The standard approach to framing dependency parsing as an integer linear program was introduced by (Riedel and Clarke, 2006), who converted the MST parser of (McDonald et al., 2005) to use ILP for inference. The key idea is to build a complete graph consisting of tokens of the sentence where each edge is weighted by a learned scoring function. The goal of inference is to select the maximum spanning tree of this weighted </context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2005</marker>
<rawString>V. Punyakanok, D. Roth, and W. Yih. 2005. The necessity of syntactic parsing for semantic role labeling. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>The importance of syntactic parsing and inference in semantic role labeling. Computational Linguistics.</title>
<date>2008</date>
<contexts>
<context position="3299" citStr="Punyakanok et al., 2008" startWordPosition="518" endWordPosition="521">d theoretically guarantee the optimality of the solution. Furthermore, in some cases, even when the conditions are not satisfied, we can reuse previous solutions with high probability of being correct. Given the extensive use of integer linear programs for structured prediction in Natural Language Processing over the last few years, these ideas can be applied broadly to NLP problems. We instantiate our improved inference approaches in the structured prediction task of semantic role labeling, where we use an existing implementation and a previous trained model that is based on the approach of (Punyakanok et al., 2008). We merely modify the inference pro1114 Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1114–1124, Jeju Island, Korea, 12–14 July 2012. c�2012 Association for Computational Linguistics cess to show that we can realize the theoretical gains by making fewer calls to the underlying ILP solver. Algorithm Speedup Theorem 1 2.44 Theorem 2 2.18 Theorem 3 2.50 Table 1: The speedup for semantic role labeling corresponding to the three theorems described in this paper. These theorems guarantee the optimality</context>
<context position="6465" citStr="Punyakanok et al., 2008" startWordPosition="1028" endWordPosition="1031">problems, where the goal is to jointly assign values to many inference variables while accounting for possible dependencies among them. This decision task is a combinatorial optimization problem and can be solved using a dynamic programming approach if the structure permits. In general, the inference problem can be formulated and solved as integer linear programs (ILPs). Following (Roth and Yih, 2004) Integer linear programs have been used broadly in NLP. For example, (Riedel and Clarke, 2006) and (Martins et al., 2009) addressed the problem of dependency parsing and (Punyakanok et al., 2005; Punyakanok et al., 2008) dealt with semantic role labeling with this technique. In this section, we will use the ILP formulation of dependency parsing to introduce notation. The standard approach to framing dependency parsing as an integer linear program was introduced by (Riedel and Clarke, 2006), who converted the MST parser of (McDonald et al., 2005) to use ILP for inference. The key idea is to build a complete graph consisting of tokens of the sentence where each edge is weighted by a learned scoring function. The goal of inference is to select the maximum spanning tree of this weighted graph. 2.1 Problem Formula</context>
<context position="28612" citStr="Punyakanok et al., 2008" startWordPosition="4867" endWordPosition="4870">the wall-clock time taken by the baseline algorithm to that of the amortized algorithm. For measuring time, we only measure the time for inference as the other aspects (feature extraction, scoring, etc.) are not changed. 4.2 Semantic Role Labeling The goal of Semantic Role Labeling (SRL) (Palmer et al., 2010) is to identify and assign semantic roles to arguments of verb predicates in a sentence. For example, consider the the sentence John gave the ball to Mary. The verb give takes three arguments, John, the ball and to Mary, which are labeled A0, A1 and A2 respectively. We used the system of (Punyakanok et al., 2008) as our base SRL system. It consists of two classifiers trained on the Propbank corpus. The first one, called the argument identifier, filters argument candidates which are generated using a syntactic parsebased heuristic. The second model scores each candidate that has not been filtered for all possible argument labels. The scores for all candidates of a predicate are combined via inference. As in the system of (Punyakanok et al., 2008), the softmax function is applied to the raw classifier scores to ensure that they are in the same numeric range. Inference mandates that certain structural an</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2008</marker>
<rawString>V. Punyakanok, D. Roth, and W. Yih. 2008. The importance of syntactic parsing and inference in semantic role labeling. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
<author>J Clarke</author>
</authors>
<title>Incremental integer linear programming for non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1514" citStr="Riedel and Clarke, 2006" startWordPosition="230" endWordPosition="233"> instantiate these ideas to the structured prediction task of semantic role labeling and show that we can achieve a speedup of over 2.5 using our approach while retaining the guarantees of exactness and a further speedup of over 3 using approximations that do not degrade performance. 1 Introduction Typically, in structured prediction applications, every example is treated independently and an inference algorithm is applied to each one of them. For example, consider a dependency parser that uses the maximum spanning tree algorithm (McDonald et al., 2005) or its integer linear program variants (Riedel and Clarke, 2006; Martins et al., 2009) to make predictions. Given a trained model, the parser addresses * These authors contributed equally to this work. each sentence separately and runs the inference algorithm to predict the parse tree. Thus, the time complexity of inference over the test set is linear in the size of the corpus. In this paper, we ask the following question: For a given task, since the inference procedure predicts structures from the same family of structures (dependency trees, semantic role structures, etc.), can the fact that we are running inference for a large number of examples help us</context>
<context position="6339" citStr="Riedel and Clarke, 2006" startWordPosition="1007" endWordPosition="1010"> 5 discusses related work and future research directions. 2 Motivation Many NLP tasks can be phrased as structured prediction problems, where the goal is to jointly assign values to many inference variables while accounting for possible dependencies among them. This decision task is a combinatorial optimization problem and can be solved using a dynamic programming approach if the structure permits. In general, the inference problem can be formulated and solved as integer linear programs (ILPs). Following (Roth and Yih, 2004) Integer linear programs have been used broadly in NLP. For example, (Riedel and Clarke, 2006) and (Martins et al., 2009) addressed the problem of dependency parsing and (Punyakanok et al., 2005; Punyakanok et al., 2008) dealt with semantic role labeling with this technique. In this section, we will use the ILP formulation of dependency parsing to introduce notation. The standard approach to framing dependency parsing as an integer linear program was introduced by (Riedel and Clarke, 2006), who converted the MST parser of (McDonald et al., 2005) to use ILP for inference. The key idea is to build a complete graph consisting of tokens of the sentence where each edge is weighted by a lear</context>
</contexts>
<marker>Riedel, Clarke, 2006</marker>
<rawString>S. Riedel and J. Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
</authors>
<title>Cutting Plane MAP Inference for Markov Logic.</title>
<date>2009</date>
<journal>Machine Learning.</journal>
<contexts>
<context position="31368" citStr="Riedel, 2009" startWordPosition="5331" endWordPosition="5332">zed gain in inference. Note that a speedup of 2.5 indicates that the solver is called only for 40% of the examples. The approximate versions of theorems 1 and 3 (with E = 0.3 in both cases, which was not tuned) attain an even higher gain in speedup over the baseline than the base versions of the theorems. Interestingly, the SRL performance in both cases does not decline much even though the conditions of the theorems may be violated. 5 Related work and Future directions In recent years, we have seen several approaches to speeding up inference using ideas like using the cutting plane approach (Riedel, 2009), dual decomposition and Lagrangian relaxation (Rush et al., 2010; Chang and Collins, 2011). The key difference between these and the work in this paper is that all these approaches solve one instance at a time. Since we can use any inference procedure as a underlying system, the speedup reported in this paper is applicable to all these algorithms. Decomposed amortized inference In this paper, we have taken advantage of redundancy of structures that can lead to the re-use of solutions. In the 1121 Type Algorithm # instances # solver Speedup Clock F1 calls speedup Exact Baseline 5127 5217 1.0 1</context>
</contexts>
<marker>Riedel, 2009</marker>
<rawString>S. Riedel. 2009. Cutting Plane MAP Inference for Markov Logic. Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Hwee Tou Ng</booktitle>
<editor>and Ellen Riloff, editors, CoNLL.</editor>
<contexts>
<context position="6245" citStr="Roth and Yih, 2004" startWordPosition="991" endWordPosition="994"> We instantiate these schemes for the task of semantic role labeling (Section 4). Section 5 discusses related work and future research directions. 2 Motivation Many NLP tasks can be phrased as structured prediction problems, where the goal is to jointly assign values to many inference variables while accounting for possible dependencies among them. This decision task is a combinatorial optimization problem and can be solved using a dynamic programming approach if the structure permits. In general, the inference problem can be formulated and solved as integer linear programs (ILPs). Following (Roth and Yih, 2004) Integer linear programs have been used broadly in NLP. For example, (Riedel and Clarke, 2006) and (Martins et al., 2009) addressed the problem of dependency parsing and (Punyakanok et al., 2005; Punyakanok et al., 2008) dealt with semantic role labeling with this technique. In this section, we will use the ILP formulation of dependency parsing to introduce notation. The standard approach to framing dependency parsing as an integer linear program was introduced by (Riedel and Clarke, 2006), who converted the MST parser of (McDonald et al., 2005) to use ILP for inference. The key idea is to bui</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Hwee Tou Ng and Ellen Riloff, editors, CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Global inference for entity and relation identification via a linear programming formulation.</title>
<date>2007</date>
<booktitle>In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning.</booktitle>
<contexts>
<context position="7446" citStr="Roth and Yih, 2007" startWordPosition="1198" endWordPosition="1201">key idea is to build a complete graph consisting of tokens of the sentence where each edge is weighted by a learned scoring function. The goal of inference is to select the maximum spanning tree of this weighted graph. 2.1 Problem Formulation In this work, we consider the general inference problem of solving a 0-1 integer linear program. To perform inference, we assume that we have a model that assigns scores to the ILP decision variables. Thus, our work is applicable not only in cases where inference is done after a separate learning phase, as in (Roth and Yih, 2004; Clarke and Lapata, 2006; Roth and Yih, 2007) and others, but also when inference is done during the training phase, for algorithms like 1115 the structured perceptron of (Collins, 2002), structured SVM (Tsochantaridis et al., 2005) or the constraints driven learning approach of (Chang et al., 2007). Since structured prediction assigns values to a collection of inter-related binary decisions, we denote the i1h binary decision by yz E 10,1} and the entire structure as y, the vector composed of all the binary decisions. In our running example, each edge in the weighted graph generates a single decision variable (for unlabeled dependency pa</context>
</contexts>
<marker>Roth, Yih, 2007</marker>
<rawString>D. Roth and W. Yih. 2007. Global inference for entity and relation identification via a linear programming formulation. In Lise Getoor and Ben Taskar, editors, Introduction to Statistical Relational Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A M Rush</author>
<author>D Sontag</author>
<author>M Collins</author>
<author>T Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="31433" citStr="Rush et al., 2010" startWordPosition="5339" endWordPosition="5342">hat the solver is called only for 40% of the examples. The approximate versions of theorems 1 and 3 (with E = 0.3 in both cases, which was not tuned) attain an even higher gain in speedup over the baseline than the base versions of the theorems. Interestingly, the SRL performance in both cases does not decline much even though the conditions of the theorems may be violated. 5 Related work and Future directions In recent years, we have seen several approaches to speeding up inference using ideas like using the cutting plane approach (Riedel, 2009), dual decomposition and Lagrangian relaxation (Rush et al., 2010; Chang and Collins, 2011). The key difference between these and the work in this paper is that all these approaches solve one instance at a time. Since we can use any inference procedure as a underlying system, the speedup reported in this paper is applicable to all these algorithms. Decomposed amortized inference In this paper, we have taken advantage of redundancy of structures that can lead to the re-use of solutions. In the 1121 Type Algorithm # instances # solver Speedup Clock F1 calls speedup Exact Baseline 5127 5217 1.0 1.0 75.85 Exact Theorem 1 5127 2134 2.44 1.54 75.90 Exact Theorem </context>
</contexts>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>A. M. Rush, D. Sontag, M. Collins, and T. Jaakkola. 2010. On dual decomposition and linear programming relaxations for natural language processing. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Tsochantaridis</author>
<author>T Joachims</author>
<author>T Hofmann</author>
<author>Y Altun</author>
</authors>
<title>Large margin methods for structured and interdependent output variables.</title>
<date>2005</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="7633" citStr="Tsochantaridis et al., 2005" startWordPosition="1227" endWordPosition="1230">um spanning tree of this weighted graph. 2.1 Problem Formulation In this work, we consider the general inference problem of solving a 0-1 integer linear program. To perform inference, we assume that we have a model that assigns scores to the ILP decision variables. Thus, our work is applicable not only in cases where inference is done after a separate learning phase, as in (Roth and Yih, 2004; Clarke and Lapata, 2006; Roth and Yih, 2007) and others, but also when inference is done during the training phase, for algorithms like 1115 the structured perceptron of (Collins, 2002), structured SVM (Tsochantaridis et al., 2005) or the constraints driven learning approach of (Chang et al., 2007). Since structured prediction assigns values to a collection of inter-related binary decisions, we denote the i1h binary decision by yz E 10,1} and the entire structure as y, the vector composed of all the binary decisions. In our running example, each edge in the weighted graph generates a single decision variable (for unlabeled dependency parsing). For each yz, let cz E R denote the weight associated with it. We denote the entire collection of weights by the vector c, forming the objective for this ILP. Not all assignments t</context>
</contexts>
<marker>Tsochantaridis, Joachims, Hofmann, Altun, 2005</marker>
<rawString>I. Tsochantaridis, T. Joachims, T. Hofmann, and Y. Altun. 2005. Large margin methods for structured and interdependent output variables. Journal of Machine Learning Research.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>