<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000039">
<title confidence="0.994002">
Unsupervised Induction of Cross-lingual Semantic Relations
</title>
<author confidence="0.991255">
Mike Lewis
</author>
<affiliation confidence="0.998262">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.972842">
Edinburgh, E118 9AB, UK
</address>
<email confidence="0.998182">
mike.lewis@ed.ac.uk
</email>
<author confidence="0.996497">
Mark Steedman
</author>
<affiliation confidence="0.9984425">
School of Informatics
University of Edinburgh
</affiliation>
<address confidence="0.972789">
Edinburgh, E118 9AB, UK
</address>
<email confidence="0.99834">
steedman@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.9986" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999145">
Creating a language-independent meaning
representation would benefit many cross-
lingual NLP tasks. We introduce the first un-
supervised approach to this problem, learn-
ing clusters of semantically equivalent English
and French relations between referring expres-
sions, based on their named-entity arguments
in large monolingual corpora. The clusters
can be used as language-independent semantic
relations, by mapping clustered expressions
in different languages onto the same relation.
Our approach needs no parallel text for train-
ing, but outperforms a baseline that uses ma-
chine translation on a cross-lingual question
answering task. We also show how to use the
semantics to improve the accuracy of machine
translation, by using it in a simple reranker.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999893857142857">
Identifying a language-independent semantics is a
major long term goal of computational linguistics,
and is interesting both theoretically and for practical
applications. It assumes that semantically equiva-
lent sentences in any language can be mapped onto
a common meaning representation. Such a repre-
sentation would be of great utility for tasks such
as translation, relation extraction, summarization,
question answering, and information retrieval. Re-
gardless of whether it is even possible to create such
a semantics, we show that an incomplete version can
be useful for downstream tasks.
Semantic machine translation aims to map a
source language to a language-independent meaning
representation, and then generate the target language
translation from this. It is hoped this would allevi-
ate the difficulties of simpler models when translat-
ing between languages with very different word or-
dering and syntax (Vauquois, 1968). Despite many
attempts to define interlingual representations (Mi-
tamura et al., 1991; Beale et al., 1995; Banarescu et
al., 2013), state-of-the-art machine translation still
uses phrase-based models (Koehn et al., 2007). The
major obstacle to defining interlinguas has been de-
vising a meaning representation that is language-
independent, but capable of expressing the limitless
number of meanings that natural languages can ex-
press (Dorr et al., 2004).
Our approach avoids this problem by utilizing the
methods of distributional semantics. Recent work
has shown that paraphrases of expressions can be
learned by clustering those with similar arguments
(Poon and Domingos, 2009; Yao et al., 2011; Lewis
and Steedman, 2013)—for example learning that X
wrote Y and X is the author of Y are equivalent if
they appear in a corpus with similar (X, Y) argument-
pairs such as {(Shakespeare, Macbeth), (Dickens,
Oliver Twist)}. We extend this to the multilingual
case, aiming to also map the French equivalents X
a ´ecrit Y and Y est un roman de X on to the same
cluster as the English paraphrases. Conceptually,
we treat a foreign expression as a paraphrase of an
English expression. The cluster identifier can be
used as a predicate in a logical form, suggesting that
the fundamental predicates of an interlingua can be
learnt in an unsupervised manner via clustering.
In this paper we focus on learning binary relations
between named entities. This problem is much sim-
pler than attempting complete interlingual semantic
</bodyText>
<page confidence="0.978387">
681
</page>
<note confidence="0.733635">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 681–692,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999924916666667">
interpretation, but the approach could be general-
ized. This class of expressions has proved extremely
useful in the monolingual case, with direct applica-
tions for question answering and relation extraction
(Poon and Domingos, 2009; Mintz et al., 2009), and
we demonstrate how to use them to improve ma-
chine translation. It is important to be able to ex-
tract knowledge across languages, as many facts will
not be expressed in all languages—either due to less-
complete encyclopedias being available in some lan-
guages, or facts being most relevant to a single coun-
try.
In contrast to most previous work on machine
translation and cross-lingual clustering, our method
requires no parallel text (see Section 8 for discussion
of some exceptions). It instead exploits an alignment
between named-entities in different languages. The
limited size of parallel corpora is a significant bot-
tleneck for machine translation (Resnik and Smith,
2003), whereas our approach can be used on much
larger monolingual corpora. This means it is poten-
tially useful for language-pairs where little parallel
text is available, for domain adaptation, or for semi-
supervised approaches.
</bodyText>
<sectionHeader confidence="0.972911" genericHeader="introduction">
2 Basic Approach
</sectionHeader>
<bodyText confidence="0.999977777777778">
Our work builds on clustering-based approaches to
monolingual distributional semantics, aiming to cre-
ate clusters of semantically equivalent predicates,
based on their arguments in a corpus. In each lan-
guage, we first map each sentence in a large mono-
lingual corpus onto a simple logical form, by ex-
tracting binary predicates between named entities.
Then, we cluster predicates both within and between
languages into those with similar arguments.
When parsing a new sentence, instead of using
the monolingual predicate, we use the cluster identi-
fier as a language-independent semantic relation, as
shown in Figure 1. The resulting logical form can be
used for inference in question answering.
Unlike traditional approaches to translation, this
does not require parallel text—but it does impose
some additional constraints on language resources.
Our approach requires:
</bodyText>
<listItem confidence="0.662948333333333">
• A large amount of factual text, as we rely on
the same facts being expressed in different lan-
guages. We use Wikipedia, which contains ar-
</listItem>
<bodyText confidence="0.968083333333333">
ticles in 250 languages, including 121 with at
least 10,000 articles.1 Other domains, such as
Newswire, may also be effective.
</bodyText>
<listItem confidence="0.942096454545455">
• A method for extracting binary relations from
sentences. This is straightforward from depen-
dency parses, which are available for many lan-
guages. It is also possible without a parser,
with some language-specific work (Fader et al.,
2011). We describe our approach in Section 3.
• A method for linking entities in the training
data to some canonical representation. Mc-
Namee et al. (2011) report good results on this
task in 21 languages. We describe our method
for this in Section 4.1.
</listItem>
<sectionHeader confidence="0.975096" genericHeader="method">
3 Predicate Extraction
</sectionHeader>
<bodyText confidence="0.999968862068965">
Our method relies on extracting binary predicates
between entities from sentences. Various represen-
tations have been suggested for binary predicates,
such as Reverb patterns (Fader et al., 2011), de-
pendency paths (Lin and Pantel, 2001; Yao et al.,
2011), and binarized predicate-argument relations
derived from a CCG-parse (Lewis and Steedman,
2013). Our approach is formalism-independent, and
is compatible with any method of expressing binary
predicates.
We choose the CCG-based parser of Lewis and
Steedman (2013) for several reasons. It out-
puts a logical form derived automatically from
the CCG-parse, containing predicates such as:
writearg0,arg1(shakespeare,macbeth). By using the
close relationship between the CCG syntax and se-
mantics, it is able to generalize over many seman-
tically equivalent syntactic constructions (such as
passives, conjunctions and relative clauses), mean-
ing we can map both Shakespeare wrote Macbeth
and Macbeth was written by Shakespeare to the
same logical form. Using a dependency-based rep-
resentation, these would have different predicates,
which would need to be clustered later. CCG also
has a well developed theory of operator semantics
(Steedman, 2012), so is able to represent semantic
operators such as quantifiers, negation and tense—
understanding these is crucial to high performance
on question answering or translation tasks. As in
</bodyText>
<footnote confidence="0.693026">
1As of June 2013.
</footnote>
<page confidence="0.994747">
682
</page>
<figure confidence="0.995984238095238">
CCG Parse
Initial Semantic Analysis
writearg0:PER,arg1:BOOK(william shakespeare,
macbeth)
Shakespeare a ´ecrit Macbeth
Dependency Parse
Initial Semantic Analysis
´ecriresubj:PER,obj:BOOK(william shakespeare,
macbeth)
Shakespeare wrote Macbeth
Shakespeare wrote Macbeth
NP (S\NP)/NP NP �
�
S\NP
S
subj
Shakespeare a ´ecrit Macbeth
mod
obj
Lookup predicate
in clustering
</figure>
<figureCaption confidence="0.9918475">
Figure 1: Example showing how our system can map sentences in different languages to the same meaning represen-
.tation, assuming we have clustered the equivalent predicates writearg0:PER,arg1:BOOK and ´ecriresubj:PER,obj:BOOK
</figureCaption>
<bodyText confidence="0.967587375">
relation43(william shakespeare, macbeth)
Lewis and Steedman (2013), clusters derived from
the output from the parser can be integrated into the
lexicon, allowing us to build logical forms which
capture both operator and lexical semantics.
Accurate CCG syntactic parsers are currently
only available for English, whereas dependency
treebanks and parsers exist for many languages
(Buchholz and Marsi, 2006). Consequently, for
French we use the dependency path representation,
which captures the nodes and edges connecting two
named entities in a dependency parse. The extrac-
tion of these paths is language-independent, and
does not depend on the dependency grammar used,
which means our approach could be adapted to new
languages with minimal work.
</bodyText>
<sectionHeader confidence="0.993699" genericHeader="method">
4 Entity Semantics
</sectionHeader>
<subsectionHeader confidence="0.9912">
4.1 Entity Linking
</subsectionHeader>
<bodyText confidence="0.999984153846154">
As discussed, our approach assumes that semanti-
cally similar predicates will have similar argument
entities. This requires us to be able to identify core-
ferring entities across languages during training. In
the monolingual case, it suffices to represent entities
by the string used in the sentence. This is inadequate
in the multilingual case, as many entities may be re-
ferred to by different names in different languages—
for example the United States translates as les ´Etats-
Unis in French and die Vereinigte Staaten in Ger-
man. This problem is worsened by the ambiguity of
named-entity strings—for example, in the context of
a sports article, United States may refer specifically
to a team, rather than a country.
Recent work on multilingual named-entity link-
ing (McNamee et al., 2011) shows how to link
named entities in multiple languages onto English
Wikipedia articles, which can be used as unique
identifiers for entities. This means that we could
gain the information we need from unrestricted
text. However, as we use Wikipedia itself for
our training corpora, we can bootstrap entity infor-
mation directly from its markup. Wikipedia con-
tains cross-language links, e.g. between the United
States articles in different languages, allowing us
to determine the equivalence of entities in differ-
</bodyText>
<page confidence="0.998771">
683
</page>
<bodyText confidence="0.9998853">
ent languages. Wikipedia links also help us au-
tomatically disambiguate entities to a given arti-
cle. For unlinked named-entity mentions, we per-
form some simple heuristic co-reference—based on
word-overlap with previously mentioned entities in
the document, whether the mention name is the ti-
tle of a Wikipedia article, or whether the mention
name is a Freebase (Bollacker et al., 2008) alias of
an entity. We emphasise that this does not mean our
approach is only applicable to the Wikipedia corpus.
</bodyText>
<subsectionHeader confidence="0.995339">
4.2 Entity Typing
</subsectionHeader>
<bodyText confidence="0.9999918">
It has become standard in clustering approaches to
distributional semantics to assign types to predicates
before clustering, and only cluster predicates with
the same type (Schoenmackers et al., 2010; Berant
et al., 2011; Yao et al., 2012). This is useful for
resolving ambiguity—for example the phrase born
in may express a place-of-birth or date-of-birth rela-
tion depending on whether its second argument has
a LOC or DAT type. Ambiguous expressions may
translate differently in other languages—for exam-
ple, the two interpretations of was born in translate
in French as est n´e a` and est n´e en respectively. The
type of a predicate is determined by the type of its
arguments, and predicates with different types are
treated as distinct.
Lewis and Steedman (2013) induce an unsuper-
vised model of entity types using Latent Dirichlet
Allocation (Blei et al., 2003), based on selectional
preferences of verbs and argument-taking nouns.
When applied cross-linguistically, we found this
technique tended to create language-specific topics.
Instead, we exploit the fact that many Wikipedia en-
tities are linked to the Freebase database, which has
a detailed manually-built type-schema. This means
for a Wikipedia entity, we can look up its set of types
in Freebase.2 We use the simplified type-set of 112
types created by Ling and Weld (2012). Where en-
tities have multiple types (for example, Shakespeare
is both an author and a person), we create a separate
relation for each type.
</bodyText>
<footnote confidence="0.7091785">
2Named entities not present in Freebase are ignored during
training.
</footnote>
<sectionHeader confidence="0.985061" genericHeader="method">
5 Relation Clustering
</sectionHeader>
<bodyText confidence="0.999940518518518">
Predicates are clustered into those which are seman-
tically equivalent, based on their argument-pairs in
a corpus. The initial semantic analysis is run over
the corpora, and for each predicate we build a vector
containing counts for each of its argument-pairs (we
divide these counts by the overall frequency of an
argument-pair in the corpus, so that rarer argument-
pairs are more significant). These vectors are used
to compute similarity between predicates.
First, we run the clustering algorithm on each lan-
guage independently, and then we attempt to find an
alignment between the clusters. Duc et al. (2011)
and T¨ackstr¨om et al. (2012) use similar two-step ap-
proaches. Running the clustering on both languages
simultaneously was found to produce many clusters
only containing predicates from a single language.
This appears to be because even if predicates in two
different languages are truth-conditionally equiva-
lent, the language biases the sample of entity-pairs
found in a corpus. For example, the French verb
´ecrire may contain more French author/book pairs
than the English equivalent write. This difference
can make the verbs appear to represent different
predicates to the clustering algorithm. Our two-step
approach also means that advances in monolingual
clustering should directly lead to improved cross-
lingual clusters.
</bodyText>
<subsectionHeader confidence="0.994783">
5.1 Monolingual Clustering
</subsectionHeader>
<bodyText confidence="0.999920823529412">
Following Lewis and Steedman (2013), we use the
Chinese Whispers algorithm (Biemann, 2006) for
monolingual clustering—summarized in Algorithm
1. The algorithm is non-parametric, meaning that
the number of relation clusters is induced from the
data, and highly scalable. We create a separate graph
for each type of predicate in each language—for
example, predicates between types AUTHOR and
BOOK in French (so only predicates with the same
type will be clustered). We create one node per pred-
icate in the graph, and edges represent the distribu-
tional similarity between the predicates.
The distributional similarity between a pair of
predicates is calculated as the cosine-similarity of
their argument pair vectors in the corpus. Many
more sophisticated approaches to determining sim-
ilarity have been proposed (Kotlerman et al., 2010;
</bodyText>
<page confidence="0.99486">
684
</page>
<bodyText confidence="0.9887378125">
Weisman et al., 2012), and future work should ex-
plore these. We prune nodes with less than 25 oc-
currences, edges of weight less than 0.05, and a short
list of stop predicates. We find many of our French
dependency paths do not have a clear semantic inter-
pretation, so add the requirement that dependency
paths contain at least one content word, contain at
most 5 edges, and that one of the dependencies con-
nected to the root is subject, object or the French
preposition de.
Data: Set of predicates P
Result: A cluster assignment rp for all p ∈ P
∀p ∈ P : rp ←− unique cluster identifier;
while not converged do
randomize order of P
for p ∈ P do
</bodyText>
<equation confidence="0.86146025">
rp ←− argmax Ep0 ]Lr=rp0sim(p, p0)
r
end
end
</equation>
<bodyText confidence="0.91882975">
Algorithm 1: Chinese Whispers algorithm, used
for monolingual predicate clustering. sim(p, p0) is
the distributional similarity between p and p0, and
]Lr=r0 is 1 iff r=r’ and 0 otherwise
</bodyText>
<subsectionHeader confidence="0.999049">
5.2 Cross-lingual Cluster Alignment
</subsectionHeader>
<bodyText confidence="0.999997642857143">
We use a simple greedy procedure to find an align-
ment between the monolingual clusters in different
languages. First, the entity-pair vectors for each
predicate in a relation cluster are merged. Then,
the cosine similarity between entity-pair vectors for
clusters in different languages is calculated—we
base this only on argument-pairs that occur in both
languages, to reduce the potential bias of some en-
tities being more relevant to one language. Clus-
ters are then greedily aligned, in order of their sim-
ilarity, as in Algorithm 2 (pruning similarities less
than 0.01). This means that clusters are aligned with
their most similar foreign cluster. We only attempt
to align clusters with the same argument types.
</bodyText>
<sectionHeader confidence="0.9701005" genericHeader="method">
6 Cross Lingual Question Answering
Experiments
</sectionHeader>
<bodyText confidence="0.8675654">
We evaluate our system on English and French, us-
ing Wikipedia for corpora. The English corpus is
POS-tagged and CCG-parsed with the C&amp;C tools
Data: Sets of monolingual relation clusters RL1
and RL2
</bodyText>
<listItem confidence="0.5189015">
Result: An alignment between the monolingual
clusters A
</listItem>
<equation confidence="0.871403875">
A ←− {};
while RL1 =6 {} ∧ RL2 =6 {} do
(r1,r2) ←− argmax sim(r1,r2);
(r1,r2)∈RL1×RL2
A ←− A ∪ {(r1,r2)};
RL1 ←− RL1/{r1};
RL2 ←− RL2/{r2};
end
</equation>
<table confidence="0.975350818181818">
Algorithm 2: Cluster alignment algorithm
English French
X invades Y X envahit Y
invasion de Y par X
X orbits Y X est un satellite de Y
X est une lune de Y
X is a skyscraper in Y X est un gratte-ciel de Y
X is a novel by Y X est un roman de Y
X joins Y X adh`ere a` Y
X is a member of Y X entre dans Y
X rejoint Y
</table>
<tableCaption confidence="0.993794333333333">
Table 1: Some example cross-lingual clusters. Predicates
are given in a human-readable form, and predicate types
are suppressed.
</tableCaption>
<bodyText confidence="0.999804538461539">
(Clark and Curran, 2004). The French corpus is
tagged with MElt (Denis et al., 2009) and parsed
with MaltParser (Nivre et al., 2007), trained on the
French Treebank (Candito et al., 2010). Wikipedia
markup is filtered using Wikiprep (Gabrilovich and
Markovitch, 2007)—replacing internal links with
the name of their target article, to help entity link-
ing. Some example clusters learnt by our model are
shown in Table 1. We find that the cross-lingual
clusters typically contain more French expressions
than English, possibly due to the differing sizes of
the corpora—adjusting the parameters in Section 5
results in larger clusters, but introduces noise.
</bodyText>
<subsectionHeader confidence="0.973503">
6.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999047333333333">
We evaluate our system on a cross-lingual question
answering task, similar to monolingual QA evalua-
tions by Poon and Domingos (2009) and Lewis and
</bodyText>
<page confidence="0.996171">
685
</page>
<bodyText confidence="0.999561684210526">
Steedman (2013). A question is asked in language
L, and is answered by the system from a corpus of
language L’. Human annotators are shown the ques-
tion, answer entity, and the sentence that provided
the answer, and are then asked whether the answer
is a reasonable conclusion based on the sentence.
Whilst this task is much easier than full translation,
it is both a practical application for our approach,
and a reasonably direct extrinsic evaluation for our
cross-lingual clusters.
Following Poon and Domingos (2009) and Lewis
and Steedman (2013), the question dataset is auto-
matically generated from the corpus. This approach
has the advantage of evaluating on expressions in
proportion to their corpus frequency, so understand-
ing frequent expressions is more important than rare
ones. We then sample 1000 questions for each lan-
guage, by extracting binary relations matching cer-
tain patterns (Xnsubj
</bodyText>
<equation confidence="0.971721">
← verbdob → j Y, Xnsubj
← verbpob → j Y or
Xnsub j
← bedob→jnounpob→ j
</equation>
<bodyText confidence="0.999089892857143">
Y), and removing one of the
arguments. For example, from the sentence Obama
lives in Washington we create the questions X lives
in Washington?, and Obama lives in X?.3 Answers
are judged by fluent bilingual humans, and do not
have to match the entity that originally instantiated
X. Multiple answers can be returned for the same
question.
Our system attempts this task by mapping both
the question and candidate answer sentences (which
will be in a different language to the question) on
to a logical form using the clusters, and determin-
ing whether they express the same relation. This
tests the ability of our approach to cluster expres-
sions into those which are semantically equivalent
between languages. It is possible for entities to have
multiple types (see Section 4.2), and answers are
ranked by the number of types in which the entail-
ment relation is predicted to hold.
3Questions are given in a declarative form, to make the tasks
simpler for the machine translation baseline. We found the
machine translation performed poorly on questions such as
What is Obama the president of?, as inverted word-orders and
long-range dependencies are difficult to handle with re-ordering
models and language models (though are straightforward to
handle for a CCG system (Clark et al., 2004)). We find that
machine translation performs much better on declarative equiv-
alents, such as: Obama is the president of X.
</bodyText>
<subsectionHeader confidence="0.993859">
6.2 Baseline
</subsectionHeader>
<bodyText confidence="0.999990516129032">
Our baseline makes use of the Moses machine trans-
lation system (Koehn et al., 2007), and is similar
to previous approaches to cross-lingual question an-
swering such as Ahn et al. (2004). We train a Moses
model on the Europarl corpus (Koehn, 2005). First,
the question is translated from language L to L’,
taking the 50-best translations. As the questions
are typically shorter than corpus sentences, this is
substantially easier for the machine-translation than
translating the corpus. These are then parsed, and
patterns are extracted (as in Section 3). We also
manually supply a translation of the named-entity
in the question (based on the Freebase entity name
translation), to avoid penalizing the translation sys-
tem for failing to translate named-entities that have
not been seen in its training data. These patterns
are then used to find answers to the questions. An-
swers are ranked by the score of the best translation
that produced the pattern. Figure 2 illustrates this
pipeline.
The choice of languages is very favourable to
the machine-translation system, English and French
have similar word-order, and there is a large amount
of parallel text available (Koehn and Monz, 2006).
Our system works with any word-order, and does not
require parallel text for training, so we would expect
better performance relative to machine-translation
on other language pairs. Future work will experi-
ment with more diverse languages. The sentences to
be translated are also very short, reducing the poten-
tial for error.
</bodyText>
<subsectionHeader confidence="0.806473">
6.3 Results
</subsectionHeader>
<bodyText confidence="0.999908846153846">
Results are shown in Table 3, based on a sample
of 100 answers from the output of each of the sys-
tems. Unsurprisingly, the machine-translation has
high accuracy on this task, given the choice of lan-
guages and the short queries. Pleasingly, our clusters
achieve similar accuracy, with much greater recall,
with no usage of parallel text.
Examining the results, we see that the distribu-
tion of answers is highly skewed for all systems,
with many answers to a smaller number of ques-
tions (multiple answers can be returned to the same
question). This is due to the Zipfian nature of lan-
guage, the difficulty of the task (which is far from
</bodyText>
<page confidence="0.991753">
686
</page>
<table confidence="0.999451909090909">
Question Answer
X dies in Moscow SergueiGuerassimov meurt d’une crise cardiaque le mardi
Germany invades X 26 novembre 1985 a` Moscou
X wins the FA Cup ... depuis l’invasion de la Pologne par l’Allemagne et l’URSS
X is a band from Finland Portsmouth FC remporte la FA Challenge Cup en s’imposant en
finale face a` Wolverhampton Wanderers FC
Yearning est un groupe Finlande de doom metal atmosph´erique
X vit en France Dewi Sukarno ... has lived in different countries including
X bat Kurt Angle Switzerland, France and the United States
X est une ville de Kirghizistan Anderson defeated Kurt Angle and Abyss to advance to the finals
Il’chibay is a village in the Issyk Kul Province of Kyrgyzstan
</table>
<tableCaption confidence="0.986223">
Table 2: Example questions correctly answered using our clusters, with the answer entity highlighted in bold.
</tableCaption>
<table confidence="0.659426111111111">
Obama lives in X
Machine Translation
Obama habite a` X
Syntactic Parse
subj prep pobj
V V V
habite a` X
Obama
Semantic Analysis
</table>
<figureCaption confidence="0.99401775">
Figure 2: Pipeline used by baseline system for answering
French questions. The pattern extracted from the trans-
lated sentence is used to search for answers in an English
corpus.
</figureCaption>
<table confidence="0.999500428571429">
English—* French Answers Correct
Baseline 269 86%
Clusters (best 270) 270 100%
Clusters (all) 1032 72%
French—* English Answers Correct
Baseline 274 85%
Clusters (all) 401 93%
</table>
<tableCaption confidence="0.999509">
Table 3: Results on wide-coverage Question Answer-
</tableCaption>
<bodyText confidence="0.987260304347826">
ing task. Best-N results are shown to illustrate the ac-
curacy of our cluster-based system at the same rank as
the baseline. It is not possible to give a recall figure, as
the total number of correct answers in the corpus is un-
known. English—* French results are from the full French
Wikipedia corpus, whereas French—* English results are
from a 10% sample.
solved in the monolingual case), and the possibil-
ity that questions may have no answers in the for-
eign corpus. This is particuarly true for the cluster-
ing approach—although the clustering system finds
more answers with the English corpus, the baseline
system answers slightly more unique questions (57
vs 66). The 1032 answers found by the clusters
in the French corpus came from just 56 questions
(compared to 29 unique questions answered by the
baseline). This suggests that the translations found
by the clustering can be more useful than those of
Moses on this task—for example, it may find an
equivalence between a rare French term and a com-
mon related English term, where machine transla-
tion may only find a more literal translation.
Despite this, we see the clusters have learnt to
</bodyText>
<equation confidence="0.570769">
habitesubj,`a(barack obama, X)
</equation>
<page confidence="0.987224">
687
</page>
<bodyText confidence="0.999937">
paraphrase a variety of relations between languages
with high accuracy, suggesting that there is much
potential for the use of unsupervised clusters in
cross-lingual semantic applications. Some examples
answers are given in Table 2. Most of the errors are
caused by a small number of questions.
</bodyText>
<sectionHeader confidence="0.975848" genericHeader="method">
7 Translation Reranking Experiments
</sectionHeader>
<bodyText confidence="0.999951487179487">
Ultimately, we would like to be able to translate
using semantic parsing with cross-lingual clusters.
As a step towards this, we investigated whether we
could rerank the output of a machine translation sys-
tem, on the basis of whether the semantic parse of
the source sentence is consistent with that of candi-
date translations.
We sample French sentences where we can pro-
duce a semantic parse (i.e. we can extract a predicate
between named entities that maps to a cross-lingual
cluster). These sentences are translated to English
using Moses, taking the 50-best list, and semantic
parses are produced for each of these. If the seman-
tic parse for the 1-best translation does not match the
source semantic parse, we take the parse from the
50-best list that most closely matches it—otherwise
we discard the sentence from our evaluation, as our
semantics agrees with the machine-translation.
To ensure that the evaluation focuses on the clus-
ters, we try to exclude several other factors that
might affect the results. The coverage of our CCG
parsing and semantic analysis drops significantly on
noisy translated sentences, and potentially acts as a
language model by failing to produce any semantic
parse on ungrammatical output sentences. We there-
fore only consider sentences where we can produce
a semantic parse for the 1-best machine translation
output. We also try to avoid penalizing the machine-
translation system for failing to translate named en-
tities correctly, so we do not attempt to rerank sen-
tences where the entities from the source sentence
are not present in the 1-best translation.
Human annotators were shown the source sen-
tence, the 1-best translation, and the translation cho-
sen by the reranker (the translations were shown in
a random order). To focus the evaluation on the se-
mantic relations we are modelling, we ask the anno-
tators which sentence best preserves the meaning be-
tween the named entities that have different relations
</bodyText>
<table confidence="0.9974786">
Percentage of
translations preferred
1-best Moses translation 5%
Cluster-based Reranker 39%
No preference 56%
</table>
<tableCaption confidence="0.634735571428571">
Table 5: Human preference judgements for the transla-
tion reranking experiment, based on a sample of 87 sen-
tences. Results show the percentage of sentences for
which the annotators preferred the original translation,
the reranked translation, or neither. As discussed in the
text, results where annotators had no preference were typ-
ically due to syntactic parse errors.
</tableCaption>
<bodyText confidence="0.999978068965517">
in the semantic parse. This avoids our system being
penalized for choosing a translation that is worse in
aspects other than the relations it is modelling. An
example is shown in Table 4. The data was anno-
tated jointly by two fluent bilingual speakers, who
reported high agreement on this task.
Results are shown in Table 5, and are highly en-
couraging, with the original Moses output being pre-
ferred to the reranked translation in only 5% of cases
where our model makes a positive prediction.
Inspecting the results, we see that many of the
cases where the annotators had no preference were
caused by syntactic parse errors. For example, if
the 1-best translation is correct, but a prepositional
phrase is incorrectly attached, it will appear to have
an incorrect semantics. A similar translation in the
50-best list may be correctly parsed, and conse-
quently selected by our reranker. However, a human
will have no preference between these translations.
Incorporating K-Best parsing into our pipeline may
help mitigate against such cases.
This preliminary experiment suggests that there is
potential for future improvements in machine trans-
lation using cross-lingual distributional semantics.
The system only attempts to rerank a very small
proportion of sentences, but we believe the cover-
age could be greatly improved by including relations
between common nouns (rather than just named-
entities)—future work should explore this.
</bodyText>
<sectionHeader confidence="0.999837" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.973691666666667">
Our work builds on recent progress in monolingual
distributional semantics (Poon and Domingos, 2009;
Yao et al., 2011; Lewis and Steedman, 2013) by
</bodyText>
<page confidence="0.99593">
688
</page>
<table confidence="0.809444">
Source Le Princess Elizabeth arrive a` Dunkerque le 3 aoˆut 1999
Machine translation 1-best Le Princess Elizabeth is to manage to Dunkirk on 3 August 1999
Reranked translation
The Princess Elizabeth arrives at Dunkirk on 3 August 1999
</table>
<tableCaption confidence="0.996083">
Table 4: Example sentence that is reranked by our clusters. Human evaluators were asked which translation best
preserved the meaning between Princess Elizabeth and Dunkirk.
</tableCaption>
<bodyText confidence="0.9999579125">
clustering typed predicates into those which are se-
mantically equivalent. We also show how to boot-
strap semantic information about entities from the
Wikipedia markup, and believe this makes it an in-
teresting corpus for future work on monolingual dis-
tributional semantics.
Cross-language Latent Relational Analysis (Duc
et al., 2011) is perhaps the most similar previous
work to ours, which moves the work of Turney
(2005) into a multilingual setting. Duc et al. (2011)
aim to compute, for example, that the ‘latent rela-
tion’ between (Obama, US) in an English corpus is
similar to that between (Cameron, UK) in a foreign
corpus. This is solved by finding all textual patterns
between the two entity-pairs, and computing their
overall similarity. Like us, they compute similarity
between expressions in different languages based on
named-entity arguments and clustering (unlike us,
they also rely on machine translation for comput-
ing similarity). A key difference is that their sys-
tem aims to understand the overall relation between
an entity-pair based on many observations, whereas
our approach attempts to understand each sentence
individually (as is required for tasks such as transla-
tion).
Various recent papers have explored the rela-
tionship between translation and monolingual para-
phrases —for example Bannard and Callison-Burch
(2005) create paraphrases by pivoting through a for-
eign translation, and Callison-Burch et al. (2006)
show that including monolingual paraphrases im-
proves the quality of translation by reducing spar-
sity. The success of these approaches depends on the
many-to-many relationship between equivalent ex-
pressions in different languages. Our approach aims
to model this relationship explicitly by clustering all
equivalent paraphrases in different languages.
Current state-of-the-art machine translation sys-
tems circumvent the problem of full semantic in-
terpretation, by using phrase-based models learnt
from large parallel corpora (Brown et al., 1993). Al-
though this approach has been very successful, it has
significant limitations—for example, when translat-
ing between languages with very different word-
orders (Birch et al., 2009), or with little parallel text.
Semantic machine translation aims to map the
source language to an interlingual semantic rep-
resentation, and then generate the target language
sentence from this. Jones et al. (2012) show how
this can be done on a small dataset using hyper-
edge replacement grammars. A major obstacle to
this is designing a suitable meaning representation,
which involves choosing a set of primitive concepts
which are abstract enough to be capable of express-
ing meaning in any language (Dorr et al., 2004).
A recent proposal for this is the Abstract Meaning
Representation (Banarescu et al., 2013), which uses
English verbs as a set of predicates. This is a less ab-
stract form of semantic interpretation than our pro-
posal, as semantically equivalent paraphrases may
be given a different representation. Such an ap-
proach also relies on annotating large amounts of
text with the semantic representation—whereas our
unsupervised approach offers a way to build such an
interlingua using only a method for extracting pred-
icates from sentences.
Whilst almost all recent work on machine-
translation has relied on parallel text, there have
been several interesting approaches that do not.
Rapp (1999) learns to translate words based on small
seed bilingual dictionary. Klementiev et al. (2012a)
exploit a variety of interesting indirect sources of
information to learn a lexicon—for example as-
suming that equivalent Wikipedia articles in differ-
ent languages will use semantically similar words.
The Polylingual Topic Model (Mimno et al., 2009)
makes use of similar intuitions. Whilst we exploit
equivalent Wikipedia articles for entity linking, we
do not require aligned articles. Incorporating such
techniques into our model would be a natural next
</bodyText>
<page confidence="0.998112">
689
</page>
<bodyText confidence="0.999855066666667">
step, allowing us to learn a more complete lexicon.
To our knowledge, ours is the first approach to learn
to translate semantic relations, rather than words and
phrases.
Several other recent papers have learnt cross-
lingual word clusters, and used these to improve
cross-lingual tasks such as document-classification
(Klementiev et al., 2012b), parsing (T¨ackstr¨om et
al., 2012) and semantic role labelling (Kozhevnikov
and Titov, 2013) in resource-poor languages. Cross-
lingual word clusters are learnt by aligning mono-
lingual clusters on the basis of parallel text—in
language-pairs where parallel text is available, this
offers an interesting complement to our method of
clustering based on named entities.
</bodyText>
<sectionHeader confidence="0.978321" genericHeader="conclusions">
9 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.99997996">
We have demonstated that our previous work on
monolingual distributional semantics can simply be
extended to learn a language-independent semantics
of relations from unlabelled text, and that this se-
mantics is powerful enough to aid applications such
as question answering and translation reranking.
There is much potential for future extensions to
address the limitations of the process described here.
As we use a flat clustering of relations, we are
only able to model synonyms and not hypernyms.
More sophisticated clustering techniques, such as
those used by Berant et al. (2011), seem to offer
a way to address this. Our system clusters rela-
tions with similar named-entity arguments, but this
means it does not cluster relations whose arguments
are rarely named entities. However, using cross-
lingual clusters of common nouns, such as those
from T¨ackstr¨om et al. (2012), it should be possible to
cluster relations that take semantically similar com-
mon noun arguments. Embedding cluster-identifiers
in a logical form allows us to also model logical op-
erators, such as negation and quantifiers, which may
help to improve the translation of these. It would
also be interesting to experiment with more diverse
languages types.
</bodyText>
<sectionHeader confidence="0.997749" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9993714">
We thank the anonymous reviewers for their helpful
comments, and Eva Hasler for help training Moses.
This work was funded by ERC Advanced Fellow-
ship 249520 GRAMPLUS and IP EC-FP7-270273
Xperience.
</bodyText>
<sectionHeader confidence="0.995881" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995269125">
Kisuh Ahn, Beatrix Alex, Johan Bos, Tiphaine Dalmas,
Jochen L Leidner, and Matthew B Smillie. 2004.
Cross-lingual question answering with QED. In Work-
ing Notes, CLEF Cross-Language Evaluation Forum,
pages 335–342.
Laura Banarescu, Claire Bonial, Shu Cai, Madalina
Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin
Knight, Philipp Koehn, Martha Palmer, and Nathan
Schneider. 2013. Abstract Meaning Representation
for sembanking. In Proceedings of the 7th Linguistic
Annotation Workshop and Interoperability with Dis-
course, Sofia, Bulgaria, August. Association for Com-
putational Linguistics.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of the 43rd Annual Meeting of the Association for
Computational Linguistics (ACL’05), pages 597–604,
Ann Arbor, Michigan, June. Association for Compu-
tational Linguistics.
Stephen Beale, Sergei Nirenburg, and Kavi Mahesh.
1995. Semantic analysis in the Mikrokosmos machine
translation project. In Proceedings of the 2nd Sym-
posium on Natural Language Processing, pages 297–
307.
Jonathan Berant, Ido Dagan, and Jacob Goldberger.
2011. Global learning of typed entailment rules. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies - Volume 1, HLT ’11, pages 610–
619. Association for Computational Linguistics.
C. Biemann. 2006. Chinese whispers: an efficient graph
clustering algorithm and its application to natural lan-
guage processing problems. In Proceedings of the
First Workshop on Graph Based Methods for Natural
Language Processing, pages 73–80. Association for
Computational Linguistics.
Alexandra Birch, Phil Blunsom, and Miles Osborne.
2009. A Quantitative Analysis of Reordering Phenom-
ena. In Proceedings of the Fourth Workshop on Sta-
tistical Machine Translation, pages 197–205, Athens,
Greece, March. Association for Computational Lin-
guistics.
D.M. Blei, A.Y. Ng, and M.I. Jordan. 2003. Latent
dirichlet allocation. the Journal of machine Learning
research, 3:993–1022.
Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim
Sturge, and Jamie Taylor. 2008. Freebase: a col-
laboratively created graph database for structuring hu-
</reference>
<page confidence="0.990669">
690
</page>
<reference confidence="0.989603411214953">
man knowledge. In Proceedings of the 2008 ACM
SIGMOD international conference on Management of
data, SIGMOD ’08, pages 1247–1250, New York, NY,
USA. ACM.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Comput. Linguist., 19(2):263–311, June.
Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared
task on multilingual dependency parsing. In Proceed-
ings of the Tenth Conference on Computational Nat-
ural Language Learning, pages 149–164. Association
for Computational Linguistics.
Chris Callison-Burch, Philipp Koehn, and Miles Os-
borne. 2006. Improved statistical machine transla-
tion using paraphrases. In Proceedings of the Human
Language Technology Conference of the NAACL, Main
Conference, pages 17–24, New York City, USA, June.
Association for Computational Linguistics.
Marie Candito, Benoit Crabb´e, Pascal Denis, et al. 2010.
Statistical french dependency parsing: treebank con-
version and first results. In Proceedings of the Seventh
International Conference on Language Resources and
Evaluation (LREC 2010), pages 1840–1847.
Stephen Clark and James R. Curran. 2004. Parsing the
WSJ using CCG and log-linear models. In Proceed-
ings of the 42nd Annual Meeting on Association for
Computational Linguistics, ACL ’04. Association for
Computational Linguistics.
S. Clark, M. Steedman, and J.R. Curran. 2004. Object-
extraction and question-parsing using CCG. In Pro-
ceedings of the EMNLP Conference, pages 111–118.
Pascal Denis, Benoit Sagot, et al. 2009. Coupling an
annotated corpus and a morphosyntactic lexicon for
state-of-the-art pos tagging with less human effort. In
PACLIC, pages 110–119.
Bonnie J Dorr, Eduard H Hovy, and Lori S Levin. 2004.
Machine translation: Interlingual methods.
Nguyen Tuan Duc, Danushka Bollegala, and Mitsuru
Ishizuka. 2011. Cross-language latent relational
search: Mapping knowledge across languages. Asso-
ciation for the Advancement of Artificial Intelligence,
pages 1237–1242.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information
extraction. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
EMNLP ’11, pages 1535–1545. Association for Com-
putational Linguistics.
Evgeniy Gabrilovich and Shaul Markovitch. 2007. Com-
puting semantic relatedness using wikipedia-based ex-
plicit semantic analysis. In IJCAI, volume 7, pages
1606–1611.
Bevan Jones, Jacob Andreas, Daniel Bauer, Karl Moritz
Hermann, and Kevin Knight. 2012. Semantics-
based machine translation with hyperedge replacement
grammars. Proc. COLING, 2012.
Alexandre Klementiev, Ann Irvine, Chris Callison-
Burch, and David Yarowsky. 2012a. Toward statis-
tical machine translation without parallel corpora. In
Proceedings of the 13th Conference of the European
Chapter of the Association for Computational Linguis-
tics, EACL ’12, pages 130–140. Association for Com-
putational Linguistics.
Alexandre Klementiev, Ivan Titov, and Binod Bhattarai.
2012b. Inducing crosslingual distributed representa-
tions of words. In Proceedings of the International
Conference on Computational Linguistics (COLING),
Bombay, India, December.
Philipp Koehn and Christof Monz. 2006. Manual and au-
tomatic evaluation of machine translation between Eu-
ropean languages. In Proceedings on the Workshop on
Statistical Machine Translation, pages 102–121, New
York City, June. Association for Computational Lin-
guistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Inter-
active Poster and Demonstration Sessions, ACL ’07,
pages 177–180. Association for Computational Lin-
guistics.
Philipp Koehn. 2005. Europarl: A parallel corpus for sta-
tistical machine translation. In MT summit, volume 5.
Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan
Zhitomirsky-geffet. 2010. Directional distributional
similarity for lexical inference. Nat. Lang. Eng.,
16(4):359–389, October.
Mikhail Kozhevnikov and Ivan Titov. 2013. Crosslin-
gual transfer of semantic role models. In To Appear in
Proceedings of the 51th Annual Meeting of the Asso-
ciation for Computational Linguistics, Sofia, Bulgaria,
August. Association for Computational Linguistics.
Mike Lewis and Mark Steedman. 2013. Combined Dis-
tributional and Logical Semantics. Transactions of
the Association for Computational Linguistics, 1:179–
192.
Dekang Lin and Patrick Pantel. 2001. DIRT - Discovery
of Inference Rules from Text. In In Proceedings of the
ACM SIGKDD Conference on Knowledge Discovery
and Data Mining, pages 323–328.
Xiao Ling and Daniel S Weld. 2012. Fine-grained entity
recognition. In Proceedings of the 26th Conference on
Artificial Intelligence (AAAI).
</reference>
<page confidence="0.977466">
691
</page>
<reference confidence="0.999910450000001">
Paul McNamee, James Mayfield, Dawn Lawrie, Dou-
glas W Oard, and David Doermann. 2011. Cross-
language entity linking. Proc. IJCNLP2011.
David Mimno, Hanna M Wallach, Jason Naradowsky,
David A Smith, and Andrew McCallum. 2009.
Polylingual topic models. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 2-Volume 2, pages 880–
889. Association for Computational Linguistics.
M. Mintz, S. Bills, R. Snow, and D. Jurafsky. 2009. Dis-
tant supervision for relation extraction without labeled
data. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP: Volume 2-Volume 2, pages 1003–
1011. Association for Computational Linguistics.
Teruko Mitamura, Eric H Nyberg, and Jaime G Car-
bonell. 1991. An efficient interlingua translation sys-
tem for multi-lingual document production.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,
G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov,
and Erwin Marsi. 2007. Maltparser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(2):95–135.
Hoifung Poon and Pedro Domingos. 2009. Unsuper-
vised semantic parsing. In Proceedings of the 2009
Conference on Empirical Methods in Natural Lan-
guage Processing: Volume 1 - Volume 1, EMNLP ’09,
pages 1–10. Association for Computational Linguis-
tics.
Reinhard Rapp. 1999. Automatic identification of word
translations from unrelated english and german cor-
pora. In Proceedings of the 37th annual meeting of the
Association for Computational Linguistics on Compu-
tational Linguistics, ACL ’99, pages 519–526. Asso-
ciation for Computational Linguistics.
Philip Resnik and Noah A Smith. 2003. The web
as a parallel corpus. Computational Linguistics,
29(3):349–380.
Stefan Schoenmackers, Oren Etzioni, Daniel S. Weld,
and Jesse Davis. 2010. Learning first-order horn
clauses from web text. In Proceedings of the 2010
Conference on Empirical Methods in Natural Lan-
guage Processing, EMNLP ’10, pages 1088–1098.
Association for Computational Linguistics.
Mark Steedman. 2012. Taking Scope: The Natural Se-
mantics of Quantifiers. MIT Press.
Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit.
2012. Cross-lingual word clusters for direct transfer of
linguistic structure. In Proceedings of the 2012 Con-
ference of the North American Chapter of the Associa-
tion for Computational Linguistics: Human Language
Technologies, NAACL HLT ’12, pages 477–487. As-
sociation for Computational Linguistics.
Peter D. Turney. 2005. Measuring semantic similarity
by latent relational analysis. In Proceedings of the
19th international joint conference on Artificial intel-
ligence, IJCAI’05, pages 1136–1141, San Francisco,
CA, USA. Morgan Kaufmann Publishers Inc.
Bernard Vauquois. 1968. A survey of formal grammars
and algorithms for recognition and transformation in
machine translation. In IFIP Congress, volume 68,
pages 254–260.
Hila Weisman, Jonathan Berant, Idan Szpektor, and
Ido Dagan. 2012. Learning verb inference rules
from linguistically-motivated evidence. In Proceed-
ings of the 2012 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Computa-
tional Natural Language Learning, EMNLP-CoNLL
’12, pages 194–204. Association for Computational
Linguistics.
Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew
McCallum. 2011. Structured relation discovery using
generative models. In Proceedings of the Conference
on Empirical Methods in Natural Language Process-
ing, EMNLP ’11, pages 1456–1466. Association for
Computational Linguistics.
Limin Yao, Sebastian Riedel, and Andrew McCallum.
2012. Unsupervised relation discovery with sense dis-
ambiguation. In ACL (1), pages 712–720.
</reference>
<page confidence="0.997909">
692
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.360587">
<title confidence="0.998929">Unsupervised Induction of Cross-lingual Semantic Relations</title>
<author confidence="0.998527">Mike</author>
<affiliation confidence="0.843877333333333">School of University of Edinburgh, E118 9AB,</affiliation>
<email confidence="0.994745">mike.lewis@ed.ac.uk</email>
<author confidence="0.99538">Mark</author>
<affiliation confidence="0.9992835">School of University of</affiliation>
<address confidence="0.716346">Edinburgh, E118 9AB,</address>
<email confidence="0.997869">steedman@inf.ed.ac.uk</email>
<abstract confidence="0.997705777777778">Creating a language-independent meaning representation would benefit many crosslingual NLP tasks. We introduce the first unsupervised approach to this problem, learning clusters of semantically equivalent English and French relations between referring expressions, based on their named-entity arguments in large monolingual corpora. The clusters can be used as language-independent semantic relations, by mapping clustered expressions in different languages onto the same relation. Our approach needs no parallel text for training, but outperforms a baseline that uses machine translation on a cross-lingual question answering task. We also show how to use the semantics to improve the accuracy of machine translation, by using it in a simple reranker.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kisuh Ahn</author>
<author>Beatrix Alex</author>
<author>Johan Bos</author>
<author>Tiphaine Dalmas</author>
<author>Jochen L Leidner</author>
<author>Matthew B Smillie</author>
</authors>
<title>Cross-lingual question answering with QED. In Working Notes, CLEF Cross-Language Evaluation Forum,</title>
<date>2004</date>
<pages>335--342</pages>
<contexts>
<context position="20798" citStr="Ahn et al. (2004)" startWordPosition="3268" endWordPosition="3271"> found the machine translation performed poorly on questions such as What is Obama the president of?, as inverted word-orders and long-range dependencies are difficult to handle with re-ordering models and language models (though are straightforward to handle for a CCG system (Clark et al., 2004)). We find that machine translation performs much better on declarative equivalents, such as: Obama is the president of X. 6.2 Baseline Our baseline makes use of the Moses machine translation system (Koehn et al., 2007), and is similar to previous approaches to cross-lingual question answering such as Ahn et al. (2004). We train a Moses model on the Europarl corpus (Koehn, 2005). First, the question is translated from language L to L’, taking the 50-best translations. As the questions are typically shorter than corpus sentences, this is substantially easier for the machine-translation than translating the corpus. These are then parsed, and patterns are extracted (as in Section 3). We also manually supply a translation of the named-entity in the question (based on the Freebase entity name translation), to avoid penalizing the translation system for failing to translate named-entities that have not been seen </context>
</contexts>
<marker>Ahn, Alex, Bos, Dalmas, Leidner, Smillie, 2004</marker>
<rawString>Kisuh Ahn, Beatrix Alex, Johan Bos, Tiphaine Dalmas, Jochen L Leidner, and Matthew B Smillie. 2004. Cross-lingual question answering with QED. In Working Notes, CLEF Cross-Language Evaluation Forum, pages 335–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Banarescu</author>
<author>Claire Bonial</author>
<author>Shu Cai</author>
<author>Madalina Georgescu</author>
<author>Kira Griffitt</author>
<author>Ulf Hermjakob</author>
<author>Kevin Knight</author>
<author>Philipp Koehn</author>
<author>Martha Palmer</author>
<author>Nathan Schneider</author>
</authors>
<title>Abstract Meaning Representation for sembanking.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="2099" citStr="Banarescu et al., 2013" startWordPosition="299" endWordPosition="302">mation retrieval. Regardless of whether it is even possible to create such a semantics, we show that an incomplete version can be useful for downstream tasks. Semantic machine translation aims to map a source language to a language-independent meaning representation, and then generate the target language translation from this. It is hoped this would alleviate the difficulties of simpler models when translating between languages with very different word ordering and syntax (Vauquois, 1968). Despite many attempts to define interlingual representations (Mitamura et al., 1991; Beale et al., 1995; Banarescu et al., 2013), state-of-the-art machine translation still uses phrase-based models (Koehn et al., 2007). The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express (Dorr et al., 2004). Our approach avoids this problem by utilizing the methods of distributional semantics. Recent work has shown that paraphrases of expressions can be learned by clustering those with similar arguments (Poon and Domingos, 2009; Yao et al., 2011; Lewis and Steedman, 2013)—for exam</context>
<context position="32834" citStr="Banarescu et al., 2013" startWordPosition="5192" endWordPosition="5195"> al., 2009), or with little parallel text. Semantic machine translation aims to map the source language to an interlingual semantic representation, and then generate the target language sentence from this. Jones et al. (2012) show how this can be done on a small dataset using hyperedge replacement grammars. A major obstacle to this is designing a suitable meaning representation, which involves choosing a set of primitive concepts which are abstract enough to be capable of expressing meaning in any language (Dorr et al., 2004). A recent proposal for this is the Abstract Meaning Representation (Banarescu et al., 2013), which uses English verbs as a set of predicates. This is a less abstract form of semantic interpretation than our proposal, as semantically equivalent paraphrases may be given a different representation. Such an approach also relies on annotating large amounts of text with the semantic representation—whereas our unsupervised approach offers a way to build such an interlingua using only a method for extracting predicates from sentences. Whilst almost all recent work on machinetranslation has relied on parallel text, there have been several interesting approaches that do not. Rapp (1999) learn</context>
</contexts>
<marker>Banarescu, Bonial, Cai, Georgescu, Griffitt, Hermjakob, Knight, Koehn, Palmer, Schneider, 2013</marker>
<rawString>Laura Banarescu, Claire Bonial, Shu Cai, Madalina Georgescu, Kira Griffitt, Ulf Hermjakob, Kevin Knight, Philipp Koehn, Martha Palmer, and Nathan Schneider. 2013. Abstract Meaning Representation for sembanking. In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>597--604</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="31401" citStr="Bannard and Callison-Burch (2005)" startWordPosition="4977" endWordPosition="4980">d computing their overall similarity. Like us, they compute similarity between expressions in different languages based on named-entity arguments and clustering (unlike us, they also rely on machine translation for computing similarity). A key difference is that their system aims to understand the overall relation between an entity-pair based on many observations, whereas our approach attempts to understand each sentence individually (as is required for tasks such as translation). Various recent papers have explored the relationship between translation and monolingual paraphrases —for example Bannard and Callison-Burch (2005) create paraphrases by pivoting through a foreign translation, and Callison-Burch et al. (2006) show that including monolingual paraphrases improves the quality of translation by reducing sparsity. The success of these approaches depends on the many-to-many relationship between equivalent expressions in different languages. Our approach aims to model this relationship explicitly by clustering all equivalent paraphrases in different languages. Current state-of-the-art machine translation systems circumvent the problem of full semantic interpretation, by using phrase-based models learnt from lar</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 597–604, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Beale</author>
<author>Sergei Nirenburg</author>
<author>Kavi Mahesh</author>
</authors>
<title>Semantic analysis in the Mikrokosmos machine translation project.</title>
<date>1995</date>
<booktitle>In Proceedings of the 2nd Symposium on Natural Language Processing,</booktitle>
<pages>297--307</pages>
<contexts>
<context position="2074" citStr="Beale et al., 1995" startWordPosition="295" endWordPosition="298">answering, and information retrieval. Regardless of whether it is even possible to create such a semantics, we show that an incomplete version can be useful for downstream tasks. Semantic machine translation aims to map a source language to a language-independent meaning representation, and then generate the target language translation from this. It is hoped this would alleviate the difficulties of simpler models when translating between languages with very different word ordering and syntax (Vauquois, 1968). Despite many attempts to define interlingual representations (Mitamura et al., 1991; Beale et al., 1995; Banarescu et al., 2013), state-of-the-art machine translation still uses phrase-based models (Koehn et al., 2007). The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express (Dorr et al., 2004). Our approach avoids this problem by utilizing the methods of distributional semantics. Recent work has shown that paraphrases of expressions can be learned by clustering those with similar arguments (Poon and Domingos, 2009; Yao et al., 2011; Lewis and</context>
</contexts>
<marker>Beale, Nirenburg, Mahesh, 1995</marker>
<rawString>Stephen Beale, Sergei Nirenburg, and Kavi Mahesh. 1995. Semantic analysis in the Mikrokosmos machine translation project. In Proceedings of the 2nd Symposium on Natural Language Processing, pages 297– 307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Global learning of typed entailment rules.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>610--619</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="11320" citStr="Berant et al., 2011" startWordPosition="1711" endWordPosition="1714">-entity mentions, we perform some simple heuristic co-reference—based on word-overlap with previously mentioned entities in the document, whether the mention name is the title of a Wikipedia article, or whether the mention name is a Freebase (Bollacker et al., 2008) alias of an entity. We emphasise that this does not mean our approach is only applicable to the Wikipedia corpus. 4.2 Entity Typing It has become standard in clustering approaches to distributional semantics to assign types to predicates before clustering, and only cluster predicates with the same type (Schoenmackers et al., 2010; Berant et al., 2011; Yao et al., 2012). This is useful for resolving ambiguity—for example the phrase born in may express a place-of-birth or date-of-birth relation depending on whether its second argument has a LOC or DAT type. Ambiguous expressions may translate differently in other languages—for example, the two interpretations of was born in translate in French as est n´e a` and est n´e en respectively. The type of a predicate is determined by the type of its arguments, and predicates with different types are treated as distinct. Lewis and Steedman (2013) induce an unsupervised model of entity types using La</context>
<context position="35305" citStr="Berant et al. (2011)" startWordPosition="5569" endWordPosition="5572">ties. 9 Conclusions and Future Work We have demonstated that our previous work on monolingual distributional semantics can simply be extended to learn a language-independent semantics of relations from unlabelled text, and that this semantics is powerful enough to aid applications such as question answering and translation reranking. There is much potential for future extensions to address the limitations of the process described here. As we use a flat clustering of relations, we are only able to model synonyms and not hypernyms. More sophisticated clustering techniques, such as those used by Berant et al. (2011), seem to offer a way to address this. Our system clusters relations with similar named-entity arguments, but this means it does not cluster relations whose arguments are rarely named entities. However, using crosslingual clusters of common nouns, such as those from T¨ackstr¨om et al. (2012), it should be possible to cluster relations that take semantically similar common noun arguments. Embedding cluster-identifiers in a logical form allows us to also model logical operators, such as negation and quantifiers, which may help to improve the translation of these. It would also be interesting to </context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2011</marker>
<rawString>Jonathan Berant, Ido Dagan, and Jacob Goldberger. 2011. Global learning of typed entailment rules. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 610– 619. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Biemann</author>
</authors>
<title>Chinese whispers: an efficient graph clustering algorithm and its application to natural language processing problems.</title>
<date>2006</date>
<booktitle>In Proceedings of the First Workshop on Graph Based Methods for Natural Language Processing,</booktitle>
<pages>73--80</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14126" citStr="Biemann, 2006" startWordPosition="2150" endWordPosition="2151"> even if predicates in two different languages are truth-conditionally equivalent, the language biases the sample of entity-pairs found in a corpus. For example, the French verb ´ecrire may contain more French author/book pairs than the English equivalent write. This difference can make the verbs appear to represent different predicates to the clustering algorithm. Our two-step approach also means that advances in monolingual clustering should directly lead to improved crosslingual clusters. 5.1 Monolingual Clustering Following Lewis and Steedman (2013), we use the Chinese Whispers algorithm (Biemann, 2006) for monolingual clustering—summarized in Algorithm 1. The algorithm is non-parametric, meaning that the number of relation clusters is induced from the data, and highly scalable. We create a separate graph for each type of predicate in each language—for example, predicates between types AUTHOR and BOOK in French (so only predicates with the same type will be clustered). We create one node per predicate in the graph, and edges represent the distributional similarity between the predicates. The distributional similarity between a pair of predicates is calculated as the cosine-similarity of thei</context>
</contexts>
<marker>Biemann, 2006</marker>
<rawString>C. Biemann. 2006. Chinese whispers: an efficient graph clustering algorithm and its application to natural language processing problems. In Proceedings of the First Workshop on Graph Based Methods for Natural Language Processing, pages 73–80. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Birch</author>
<author>Phil Blunsom</author>
<author>Miles Osborne</author>
</authors>
<title>A Quantitative Analysis of Reordering Phenomena.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>197--205</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Athens, Greece,</location>
<contexts>
<context position="32222" citStr="Birch et al., 2009" startWordPosition="5093" endWordPosition="5096">success of these approaches depends on the many-to-many relationship between equivalent expressions in different languages. Our approach aims to model this relationship explicitly by clustering all equivalent paraphrases in different languages. Current state-of-the-art machine translation systems circumvent the problem of full semantic interpretation, by using phrase-based models learnt from large parallel corpora (Brown et al., 1993). Although this approach has been very successful, it has significant limitations—for example, when translating between languages with very different wordorders (Birch et al., 2009), or with little parallel text. Semantic machine translation aims to map the source language to an interlingual semantic representation, and then generate the target language sentence from this. Jones et al. (2012) show how this can be done on a small dataset using hyperedge replacement grammars. A major obstacle to this is designing a suitable meaning representation, which involves choosing a set of primitive concepts which are abstract enough to be capable of expressing meaning in any language (Dorr et al., 2004). A recent proposal for this is the Abstract Meaning Representation (Banarescu e</context>
</contexts>
<marker>Birch, Blunsom, Osborne, 2009</marker>
<rawString>Alexandra Birch, Phil Blunsom, and Miles Osborne. 2009. A Quantitative Analysis of Reordering Phenomena. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 197–205, Athens, Greece, March. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Blei</author>
<author>A Y Ng</author>
<author>M I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>the Journal of machine Learning research,</journal>
<pages>3--993</pages>
<contexts>
<context position="11965" citStr="Blei et al., 2003" startWordPosition="1817" endWordPosition="1820">s useful for resolving ambiguity—for example the phrase born in may express a place-of-birth or date-of-birth relation depending on whether its second argument has a LOC or DAT type. Ambiguous expressions may translate differently in other languages—for example, the two interpretations of was born in translate in French as est n´e a` and est n´e en respectively. The type of a predicate is determined by the type of its arguments, and predicates with different types are treated as distinct. Lewis and Steedman (2013) induce an unsupervised model of entity types using Latent Dirichlet Allocation (Blei et al., 2003), based on selectional preferences of verbs and argument-taking nouns. When applied cross-linguistically, we found this technique tended to create language-specific topics. Instead, we exploit the fact that many Wikipedia entities are linked to the Freebase database, which has a detailed manually-built type-schema. This means for a Wikipedia entity, we can look up its set of types in Freebase.2 We use the simplified type-set of 112 types created by Ling and Weld (2012). Where entities have multiple types (for example, Shakespeare is both an author and a person), we create a separate relation f</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>D.M. Blei, A.Y. Ng, and M.I. Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kurt Bollacker</author>
<author>Colin Evans</author>
<author>Praveen Paritosh</author>
<author>Tim Sturge</author>
<author>Jamie Taylor</author>
</authors>
<title>Freebase: a collaboratively created graph database for structuring human knowledge.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, SIGMOD ’08,</booktitle>
<pages>1247--1250</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="10967" citStr="Bollacker et al., 2008" startWordPosition="1655" endWordPosition="1658">pora, we can bootstrap entity information directly from its markup. Wikipedia contains cross-language links, e.g. between the United States articles in different languages, allowing us to determine the equivalence of entities in differ683 ent languages. Wikipedia links also help us automatically disambiguate entities to a given article. For unlinked named-entity mentions, we perform some simple heuristic co-reference—based on word-overlap with previously mentioned entities in the document, whether the mention name is the title of a Wikipedia article, or whether the mention name is a Freebase (Bollacker et al., 2008) alias of an entity. We emphasise that this does not mean our approach is only applicable to the Wikipedia corpus. 4.2 Entity Typing It has become standard in clustering approaches to distributional semantics to assign types to predicates before clustering, and only cluster predicates with the same type (Schoenmackers et al., 2010; Berant et al., 2011; Yao et al., 2012). This is useful for resolving ambiguity—for example the phrase born in may express a place-of-birth or date-of-birth relation depending on whether its second argument has a LOC or DAT type. Ambiguous expressions may translate d</context>
</contexts>
<marker>Bollacker, Evans, Paritosh, Sturge, Taylor, 2008</marker>
<rawString>Kurt Bollacker, Colin Evans, Praveen Paritosh, Tim Sturge, and Jamie Taylor. 2008. Freebase: a collaboratively created graph database for structuring human knowledge. In Proceedings of the 2008 ACM SIGMOD international conference on Management of data, SIGMOD ’08, pages 1247–1250, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="32041" citStr="Brown et al., 1993" startWordPosition="5066" endWordPosition="5069">y pivoting through a foreign translation, and Callison-Burch et al. (2006) show that including monolingual paraphrases improves the quality of translation by reducing sparsity. The success of these approaches depends on the many-to-many relationship between equivalent expressions in different languages. Our approach aims to model this relationship explicitly by clustering all equivalent paraphrases in different languages. Current state-of-the-art machine translation systems circumvent the problem of full semantic interpretation, by using phrase-based models learnt from large parallel corpora (Brown et al., 1993). Although this approach has been very successful, it has significant limitations—for example, when translating between languages with very different wordorders (Birch et al., 2009), or with little parallel text. Semantic machine translation aims to map the source language to an interlingual semantic representation, and then generate the target language sentence from this. Jones et al. (2012) show how this can be done on a small dataset using hyperedge replacement grammars. A major obstacle to this is designing a suitable meaning representation, which involves choosing a set of primitive conce</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Comput. Linguist., 19(2):263–311, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Buchholz</author>
<author>Erwin Marsi</author>
</authors>
<title>Conll-x shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Tenth Conference on Computational Natural Language Learning,</booktitle>
<pages>149--164</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="8899" citStr="Buchholz and Marsi, 2006" startWordPosition="1329" endWordPosition="1332">re 1: Example showing how our system can map sentences in different languages to the same meaning represen.tation, assuming we have clustered the equivalent predicates writearg0:PER,arg1:BOOK and ´ecriresubj:PER,obj:BOOK relation43(william shakespeare, macbeth) Lewis and Steedman (2013), clusters derived from the output from the parser can be integrated into the lexicon, allowing us to build logical forms which capture both operator and lexical semantics. Accurate CCG syntactic parsers are currently only available for English, whereas dependency treebanks and parsers exist for many languages (Buchholz and Marsi, 2006). Consequently, for French we use the dependency path representation, which captures the nodes and edges connecting two named entities in a dependency parse. The extraction of these paths is language-independent, and does not depend on the dependency grammar used, which means our approach could be adapted to new languages with minimal work. 4 Entity Semantics 4.1 Entity Linking As discussed, our approach assumes that semantically similar predicates will have similar argument entities. This requires us to be able to identify coreferring entities across languages during training. In the monoling</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>Sabine Buchholz and Erwin Marsi. 2006. Conll-x shared task on multilingual dependency parsing. In Proceedings of the Tenth Conference on Computational Natural Language Learning, pages 149–164. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Miles Osborne</author>
</authors>
<title>Improved statistical machine translation using paraphrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>17--24</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="31496" citStr="Callison-Burch et al. (2006)" startWordPosition="4991" endWordPosition="4994">ent languages based on named-entity arguments and clustering (unlike us, they also rely on machine translation for computing similarity). A key difference is that their system aims to understand the overall relation between an entity-pair based on many observations, whereas our approach attempts to understand each sentence individually (as is required for tasks such as translation). Various recent papers have explored the relationship between translation and monolingual paraphrases —for example Bannard and Callison-Burch (2005) create paraphrases by pivoting through a foreign translation, and Callison-Burch et al. (2006) show that including monolingual paraphrases improves the quality of translation by reducing sparsity. The success of these approaches depends on the many-to-many relationship between equivalent expressions in different languages. Our approach aims to model this relationship explicitly by clustering all equivalent paraphrases in different languages. Current state-of-the-art machine translation systems circumvent the problem of full semantic interpretation, by using phrase-based models learnt from large parallel corpora (Brown et al., 1993). Although this approach has been very successful, it h</context>
</contexts>
<marker>Callison-Burch, Koehn, Osborne, 2006</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, and Miles Osborne. 2006. Improved statistical machine translation using paraphrases. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 17–24, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Benoit Crabb´e</author>
<author>Pascal Denis</author>
</authors>
<title>Statistical french dependency parsing: treebank conversion and first results.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>1840--1847</pages>
<marker>Candito, Crabb´e, Denis, 2010</marker>
<rawString>Marie Candito, Benoit Crabb´e, Pascal Denis, et al. 2010. Statistical french dependency parsing: treebank conversion and first results. In Proceedings of the Seventh International Conference on Language Resources and Evaluation (LREC 2010), pages 1840–1847.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Parsing the WSJ using CCG and log-linear models.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="17413" citStr="Clark and Curran, 2004" startWordPosition="2716" endWordPosition="2719">l clusters A A ←− {}; while RL1 =6 {} ∧ RL2 =6 {} do (r1,r2) ←− argmax sim(r1,r2); (r1,r2)∈RL1×RL2 A ←− A ∪ {(r1,r2)}; RL1 ←− RL1/{r1}; RL2 ←− RL2/{r2}; end Algorithm 2: Cluster alignment algorithm English French X invades Y X envahit Y invasion de Y par X X orbits Y X est un satellite de Y X est une lune de Y X is a skyscraper in Y X est un gratte-ciel de Y X is a novel by Y X est un roman de Y X joins Y X adh`ere a` Y X is a member of Y X entre dans Y X rejoint Y Table 1: Some example cross-lingual clusters. Predicates are given in a human-readable form, and predicate types are suppressed. (Clark and Curran, 2004). The French corpus is tagged with MElt (Denis et al., 2009) and parsed with MaltParser (Nivre et al., 2007), trained on the French Treebank (Candito et al., 2010). Wikipedia markup is filtered using Wikiprep (Gabrilovich and Markovitch, 2007)—replacing internal links with the name of their target article, to help entity linking. Some example clusters learnt by our model are shown in Table 1. We find that the cross-lingual clusters typically contain more French expressions than English, possibly due to the differing sizes of the corpora—adjusting the parameters in Section 5 results in larger c</context>
</contexts>
<marker>Clark, Curran, 2004</marker>
<rawString>Stephen Clark and James R. Curran. 2004. Parsing the WSJ using CCG and log-linear models. In Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, ACL ’04. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>M Steedman</author>
<author>J R Curran</author>
</authors>
<title>Objectextraction and question-parsing using CCG.</title>
<date>2004</date>
<booktitle>In Proceedings of the EMNLP Conference,</booktitle>
<pages>111--118</pages>
<contexts>
<context position="20478" citStr="Clark et al., 2004" startWordPosition="3214" endWordPosition="3217">mantically equivalent between languages. It is possible for entities to have multiple types (see Section 4.2), and answers are ranked by the number of types in which the entailment relation is predicted to hold. 3Questions are given in a declarative form, to make the tasks simpler for the machine translation baseline. We found the machine translation performed poorly on questions such as What is Obama the president of?, as inverted word-orders and long-range dependencies are difficult to handle with re-ordering models and language models (though are straightforward to handle for a CCG system (Clark et al., 2004)). We find that machine translation performs much better on declarative equivalents, such as: Obama is the president of X. 6.2 Baseline Our baseline makes use of the Moses machine translation system (Koehn et al., 2007), and is similar to previous approaches to cross-lingual question answering such as Ahn et al. (2004). We train a Moses model on the Europarl corpus (Koehn, 2005). First, the question is translated from language L to L’, taking the 50-best translations. As the questions are typically shorter than corpus sentences, this is substantially easier for the machine-translation than tra</context>
</contexts>
<marker>Clark, Steedman, Curran, 2004</marker>
<rawString>S. Clark, M. Steedman, and J.R. Curran. 2004. Objectextraction and question-parsing using CCG. In Proceedings of the EMNLP Conference, pages 111–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascal Denis</author>
<author>Benoit Sagot</author>
</authors>
<title>Coupling an annotated corpus and a morphosyntactic lexicon for state-of-the-art pos tagging with less human effort.</title>
<date>2009</date>
<booktitle>In PACLIC,</booktitle>
<pages>110--119</pages>
<marker>Denis, Sagot, 2009</marker>
<rawString>Pascal Denis, Benoit Sagot, et al. 2009. Coupling an annotated corpus and a morphosyntactic lexicon for state-of-the-art pos tagging with less human effort. In PACLIC, pages 110–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie J Dorr</author>
<author>Eduard H Hovy</author>
<author>Lori S Levin</author>
</authors>
<title>Machine translation: Interlingual methods.</title>
<date>2004</date>
<contexts>
<context position="2420" citStr="Dorr et al., 2004" startWordPosition="346" endWordPosition="349">s. It is hoped this would alleviate the difficulties of simpler models when translating between languages with very different word ordering and syntax (Vauquois, 1968). Despite many attempts to define interlingual representations (Mitamura et al., 1991; Beale et al., 1995; Banarescu et al., 2013), state-of-the-art machine translation still uses phrase-based models (Koehn et al., 2007). The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express (Dorr et al., 2004). Our approach avoids this problem by utilizing the methods of distributional semantics. Recent work has shown that paraphrases of expressions can be learned by clustering those with similar arguments (Poon and Domingos, 2009; Yao et al., 2011; Lewis and Steedman, 2013)—for example learning that X wrote Y and X is the author of Y are equivalent if they appear in a corpus with similar (X, Y) argumentpairs such as {(Shakespeare, Macbeth), (Dickens, Oliver Twist)}. We extend this to the multilingual case, aiming to also map the French equivalents X a ´ecrit Y and Y est un roman de X on to the sam</context>
<context position="32742" citStr="Dorr et al., 2004" startWordPosition="5178" endWordPosition="5181">or example, when translating between languages with very different wordorders (Birch et al., 2009), or with little parallel text. Semantic machine translation aims to map the source language to an interlingual semantic representation, and then generate the target language sentence from this. Jones et al. (2012) show how this can be done on a small dataset using hyperedge replacement grammars. A major obstacle to this is designing a suitable meaning representation, which involves choosing a set of primitive concepts which are abstract enough to be capable of expressing meaning in any language (Dorr et al., 2004). A recent proposal for this is the Abstract Meaning Representation (Banarescu et al., 2013), which uses English verbs as a set of predicates. This is a less abstract form of semantic interpretation than our proposal, as semantically equivalent paraphrases may be given a different representation. Such an approach also relies on annotating large amounts of text with the semantic representation—whereas our unsupervised approach offers a way to build such an interlingua using only a method for extracting predicates from sentences. Whilst almost all recent work on machinetranslation has relied on </context>
</contexts>
<marker>Dorr, Hovy, Levin, 2004</marker>
<rawString>Bonnie J Dorr, Eduard H Hovy, and Lori S Levin. 2004. Machine translation: Interlingual methods.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nguyen Tuan Duc</author>
<author>Danushka Bollegala</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Cross-language latent relational search: Mapping knowledge across languages. Association for the Advancement of Artificial Intelligence,</title>
<date>2011</date>
<pages>1237--1242</pages>
<contexts>
<context position="13280" citStr="Duc et al. (2011)" startWordPosition="2025" endWordPosition="2028">tering Predicates are clustered into those which are semantically equivalent, based on their argument-pairs in a corpus. The initial semantic analysis is run over the corpora, and for each predicate we build a vector containing counts for each of its argument-pairs (we divide these counts by the overall frequency of an argument-pair in the corpus, so that rarer argumentpairs are more significant). These vectors are used to compute similarity between predicates. First, we run the clustering algorithm on each language independently, and then we attempt to find an alignment between the clusters. Duc et al. (2011) and T¨ackstr¨om et al. (2012) use similar two-step approaches. Running the clustering on both languages simultaneously was found to produce many clusters only containing predicates from a single language. This appears to be because even if predicates in two different languages are truth-conditionally equivalent, the language biases the sample of entity-pairs found in a corpus. For example, the French verb ´ecrire may contain more French author/book pairs than the English equivalent write. This difference can make the verbs appear to represent different predicates to the clustering algorithm. </context>
<context position="30393" citStr="Duc et al., 2011" startWordPosition="4821" endWordPosition="4824">age to Dunkirk on 3 August 1999 Reranked translation The Princess Elizabeth arrives at Dunkirk on 3 August 1999 Table 4: Example sentence that is reranked by our clusters. Human evaluators were asked which translation best preserved the meaning between Princess Elizabeth and Dunkirk. clustering typed predicates into those which are semantically equivalent. We also show how to bootstrap semantic information about entities from the Wikipedia markup, and believe this makes it an interesting corpus for future work on monolingual distributional semantics. Cross-language Latent Relational Analysis (Duc et al., 2011) is perhaps the most similar previous work to ours, which moves the work of Turney (2005) into a multilingual setting. Duc et al. (2011) aim to compute, for example, that the ‘latent relation’ between (Obama, US) in an English corpus is similar to that between (Cameron, UK) in a foreign corpus. This is solved by finding all textual patterns between the two entity-pairs, and computing their overall similarity. Like us, they compute similarity between expressions in different languages based on named-entity arguments and clustering (unlike us, they also rely on machine translation for computing </context>
</contexts>
<marker>Duc, Bollegala, Ishizuka, 2011</marker>
<rawString>Nguyen Tuan Duc, Danushka Bollegala, and Mitsuru Ishizuka. 2011. Cross-language latent relational search: Mapping knowledge across languages. Association for the Advancement of Artificial Intelligence, pages 1237–1242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1535--1545</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6229" citStr="Fader et al., 2011" startWordPosition="945" endWordPosition="948"> require parallel text—but it does impose some additional constraints on language resources. Our approach requires: • A large amount of factual text, as we rely on the same facts being expressed in different languages. We use Wikipedia, which contains articles in 250 languages, including 121 with at least 10,000 articles.1 Other domains, such as Newswire, may also be effective. • A method for extracting binary relations from sentences. This is straightforward from dependency parses, which are available for many languages. It is also possible without a parser, with some language-specific work (Fader et al., 2011). We describe our approach in Section 3. • A method for linking entities in the training data to some canonical representation. McNamee et al. (2011) report good results on this task in 21 languages. We describe our method for this in Section 4.1. 3 Predicate Extraction Our method relies on extracting binary predicates between entities from sentences. Various representations have been suggested for binary predicates, such as Reverb patterns (Fader et al., 2011), dependency paths (Lin and Pantel, 2001; Yao et al., 2011), and binarized predicate-argument relations derived from a CCG-parse (Lewis</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1535–1545. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In IJCAI,</booktitle>
<volume>7</volume>
<pages>1606--1611</pages>
<contexts>
<context position="17656" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="2754" endWordPosition="2757">t Y invasion de Y par X X orbits Y X est un satellite de Y X est une lune de Y X is a skyscraper in Y X est un gratte-ciel de Y X is a novel by Y X est un roman de Y X joins Y X adh`ere a` Y X is a member of Y X entre dans Y X rejoint Y Table 1: Some example cross-lingual clusters. Predicates are given in a human-readable form, and predicate types are suppressed. (Clark and Curran, 2004). The French corpus is tagged with MElt (Denis et al., 2009) and parsed with MaltParser (Nivre et al., 2007), trained on the French Treebank (Candito et al., 2010). Wikipedia markup is filtered using Wikiprep (Gabrilovich and Markovitch, 2007)—replacing internal links with the name of their target article, to help entity linking. Some example clusters learnt by our model are shown in Table 1. We find that the cross-lingual clusters typically contain more French expressions than English, possibly due to the differing sizes of the corpora—adjusting the parameters in Section 5 results in larger clusters, but introduces noise. 6.1 Experimental Setup We evaluate our system on a cross-lingual question answering task, similar to monolingual QA evaluations by Poon and Domingos (2009) and Lewis and 685 Steedman (2013). A question is asked i</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using wikipedia-based explicit semantic analysis. In IJCAI, volume 7, pages 1606–1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bevan Jones</author>
<author>Jacob Andreas</author>
<author>Daniel Bauer</author>
<author>Karl Moritz Hermann</author>
<author>Kevin Knight</author>
</authors>
<title>Semanticsbased machine translation with hyperedge replacement grammars.</title>
<date>2012</date>
<booktitle>Proc. COLING,</booktitle>
<contexts>
<context position="32436" citStr="Jones et al. (2012)" startWordPosition="5126" endWordPosition="5129">hrases in different languages. Current state-of-the-art machine translation systems circumvent the problem of full semantic interpretation, by using phrase-based models learnt from large parallel corpora (Brown et al., 1993). Although this approach has been very successful, it has significant limitations—for example, when translating between languages with very different wordorders (Birch et al., 2009), or with little parallel text. Semantic machine translation aims to map the source language to an interlingual semantic representation, and then generate the target language sentence from this. Jones et al. (2012) show how this can be done on a small dataset using hyperedge replacement grammars. A major obstacle to this is designing a suitable meaning representation, which involves choosing a set of primitive concepts which are abstract enough to be capable of expressing meaning in any language (Dorr et al., 2004). A recent proposal for this is the Abstract Meaning Representation (Banarescu et al., 2013), which uses English verbs as a set of predicates. This is a less abstract form of semantic interpretation than our proposal, as semantically equivalent paraphrases may be given a different representati</context>
</contexts>
<marker>Jones, Andreas, Bauer, Hermann, Knight, 2012</marker>
<rawString>Bevan Jones, Jacob Andreas, Daniel Bauer, Karl Moritz Hermann, and Kevin Knight. 2012. Semanticsbased machine translation with hyperedge replacement grammars. Proc. COLING, 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Ann Irvine</author>
<author>Chris CallisonBurch</author>
<author>David Yarowsky</author>
</authors>
<title>Toward statistical machine translation without parallel corpora.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12,</booktitle>
<pages>130--140</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="33520" citStr="Klementiev et al. (2012" startWordPosition="5300" endWordPosition="5303">ss abstract form of semantic interpretation than our proposal, as semantically equivalent paraphrases may be given a different representation. Such an approach also relies on annotating large amounts of text with the semantic representation—whereas our unsupervised approach offers a way to build such an interlingua using only a method for extracting predicates from sentences. Whilst almost all recent work on machinetranslation has relied on parallel text, there have been several interesting approaches that do not. Rapp (1999) learns to translate words based on small seed bilingual dictionary. Klementiev et al. (2012a) exploit a variety of interesting indirect sources of information to learn a lexicon—for example assuming that equivalent Wikipedia articles in different languages will use semantically similar words. The Polylingual Topic Model (Mimno et al., 2009) makes use of similar intuitions. Whilst we exploit equivalent Wikipedia articles for entity linking, we do not require aligned articles. Incorporating such techniques into our model would be a natural next 689 step, allowing us to learn a more complete lexicon. To our knowledge, ours is the first approach to learn to translate semantic relations,</context>
</contexts>
<marker>Klementiev, Irvine, CallisonBurch, Yarowsky, 2012</marker>
<rawString>Alexandre Klementiev, Ann Irvine, Chris CallisonBurch, and David Yarowsky. 2012a. Toward statistical machine translation without parallel corpora. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12, pages 130–140. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Ivan Titov</author>
<author>Binod Bhattarai</author>
</authors>
<title>Inducing crosslingual distributed representations of words.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<location>Bombay, India,</location>
<contexts>
<context position="33520" citStr="Klementiev et al. (2012" startWordPosition="5300" endWordPosition="5303">ss abstract form of semantic interpretation than our proposal, as semantically equivalent paraphrases may be given a different representation. Such an approach also relies on annotating large amounts of text with the semantic representation—whereas our unsupervised approach offers a way to build such an interlingua using only a method for extracting predicates from sentences. Whilst almost all recent work on machinetranslation has relied on parallel text, there have been several interesting approaches that do not. Rapp (1999) learns to translate words based on small seed bilingual dictionary. Klementiev et al. (2012a) exploit a variety of interesting indirect sources of information to learn a lexicon—for example assuming that equivalent Wikipedia articles in different languages will use semantically similar words. The Polylingual Topic Model (Mimno et al., 2009) makes use of similar intuitions. Whilst we exploit equivalent Wikipedia articles for entity linking, we do not require aligned articles. Incorporating such techniques into our model would be a natural next 689 step, allowing us to learn a more complete lexicon. To our knowledge, ours is the first approach to learn to translate semantic relations,</context>
</contexts>
<marker>Klementiev, Titov, Bhattarai, 2012</marker>
<rawString>Alexandre Klementiev, Ivan Titov, and Binod Bhattarai. 2012b. Inducing crosslingual distributed representations of words. In Proceedings of the International Conference on Computational Linguistics (COLING), Bombay, India, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
</authors>
<title>Manual and automatic evaluation of machine translation between European languages.</title>
<date>2006</date>
<booktitle>In Proceedings on the Workshop on Statistical Machine Translation,</booktitle>
<pages>102--121</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City,</location>
<contexts>
<context position="21801" citStr="Koehn and Monz, 2006" startWordPosition="3427" endWordPosition="3430">ally supply a translation of the named-entity in the question (based on the Freebase entity name translation), to avoid penalizing the translation system for failing to translate named-entities that have not been seen in its training data. These patterns are then used to find answers to the questions. Answers are ranked by the score of the best translation that produced the pattern. Figure 2 illustrates this pipeline. The choice of languages is very favourable to the machine-translation system, English and French have similar word-order, and there is a large amount of parallel text available (Koehn and Monz, 2006). Our system works with any word-order, and does not require parallel text for training, so we would expect better performance relative to machine-translation on other language pairs. Future work will experiment with more diverse languages. The sentences to be translated are also very short, reducing the potential for error. 6.3 Results Results are shown in Table 3, based on a sample of 100 answers from the output of each of the systems. Unsurprisingly, the machine-translation has high accuracy on this task, given the choice of languages and the short queries. Pleasingly, our clusters achieve </context>
</contexts>
<marker>Koehn, Monz, 2006</marker>
<rawString>Philipp Koehn and Christof Monz. 2006. Manual and automatic evaluation of machine translation between European languages. In Proceedings on the Workshop on Statistical Machine Translation, pages 102–121, New York City, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Hieu Hoang,</title>
<location>Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi,</location>
<marker>Koehn, </marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 177–180. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: A parallel corpus for statistical machine translation.</title>
<date>2005</date>
<booktitle>In MT summit,</booktitle>
<volume>5</volume>
<contexts>
<context position="20859" citStr="Koehn, 2005" startWordPosition="3281" endWordPosition="3282">as What is Obama the president of?, as inverted word-orders and long-range dependencies are difficult to handle with re-ordering models and language models (though are straightforward to handle for a CCG system (Clark et al., 2004)). We find that machine translation performs much better on declarative equivalents, such as: Obama is the president of X. 6.2 Baseline Our baseline makes use of the Moses machine translation system (Koehn et al., 2007), and is similar to previous approaches to cross-lingual question answering such as Ahn et al. (2004). We train a Moses model on the Europarl corpus (Koehn, 2005). First, the question is translated from language L to L’, taking the 50-best translations. As the questions are typically shorter than corpus sentences, this is substantially easier for the machine-translation than translating the corpus. These are then parsed, and patterns are extracted (as in Section 3). We also manually supply a translation of the named-entity in the question (based on the Freebase entity name translation), to avoid penalizing the translation system for failing to translate named-entities that have not been seen in its training data. These patterns are then used to find an</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: A parallel corpus for statistical machine translation. In MT summit, volume 5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lili Kotlerman</author>
<author>Ido Dagan</author>
<author>Idan Szpektor</author>
<author>Maayan Zhitomirsky-geffet</author>
</authors>
<title>Directional distributional similarity for lexical inference.</title>
<date>2010</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>16</volume>
<issue>4</issue>
<contexts>
<context position="14868" citStr="Kotlerman et al., 2010" startWordPosition="2261" endWordPosition="2264">ion clusters is induced from the data, and highly scalable. We create a separate graph for each type of predicate in each language—for example, predicates between types AUTHOR and BOOK in French (so only predicates with the same type will be clustered). We create one node per predicate in the graph, and edges represent the distributional similarity between the predicates. The distributional similarity between a pair of predicates is calculated as the cosine-similarity of their argument pair vectors in the corpus. Many more sophisticated approaches to determining similarity have been proposed (Kotlerman et al., 2010; 684 Weisman et al., 2012), and future work should explore these. We prune nodes with less than 25 occurrences, edges of weight less than 0.05, and a short list of stop predicates. We find many of our French dependency paths do not have a clear semantic interpretation, so add the requirement that dependency paths contain at least one content word, contain at most 5 edges, and that one of the dependencies connected to the root is subject, object or the French preposition de. Data: Set of predicates P Result: A cluster assignment rp for all p ∈ P ∀p ∈ P : rp ←− unique cluster identifier; while </context>
</contexts>
<marker>Kotlerman, Dagan, Szpektor, Zhitomirsky-geffet, 2010</marker>
<rawString>Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan Zhitomirsky-geffet. 2010. Directional distributional similarity for lexical inference. Nat. Lang. Eng., 16(4):359–389, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Kozhevnikov</author>
<author>Ivan Titov</author>
</authors>
<title>Crosslingual transfer of semantic role models.</title>
<date>2013</date>
<booktitle>In To Appear in Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="34418" citStr="Kozhevnikov and Titov, 2013" startWordPosition="5434" endWordPosition="5437">ar intuitions. Whilst we exploit equivalent Wikipedia articles for entity linking, we do not require aligned articles. Incorporating such techniques into our model would be a natural next 689 step, allowing us to learn a more complete lexicon. To our knowledge, ours is the first approach to learn to translate semantic relations, rather than words and phrases. Several other recent papers have learnt crosslingual word clusters, and used these to improve cross-lingual tasks such as document-classification (Klementiev et al., 2012b), parsing (T¨ackstr¨om et al., 2012) and semantic role labelling (Kozhevnikov and Titov, 2013) in resource-poor languages. Crosslingual word clusters are learnt by aligning monolingual clusters on the basis of parallel text—in language-pairs where parallel text is available, this offers an interesting complement to our method of clustering based on named entities. 9 Conclusions and Future Work We have demonstated that our previous work on monolingual distributional semantics can simply be extended to learn a language-independent semantics of relations from unlabelled text, and that this semantics is powerful enough to aid applications such as question answering and translation rerankin</context>
</contexts>
<marker>Kozhevnikov, Titov, 2013</marker>
<rawString>Mikhail Kozhevnikov and Ivan Titov. 2013. Crosslingual transfer of semantic role models. In To Appear in Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>Combined Distributional and Logical Semantics.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>1</volume>
<pages>192</pages>
<contexts>
<context position="2690" citStr="Lewis and Steedman, 2013" startWordPosition="387" endWordPosition="390">al., 1995; Banarescu et al., 2013), state-of-the-art machine translation still uses phrase-based models (Koehn et al., 2007). The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express (Dorr et al., 2004). Our approach avoids this problem by utilizing the methods of distributional semantics. Recent work has shown that paraphrases of expressions can be learned by clustering those with similar arguments (Poon and Domingos, 2009; Yao et al., 2011; Lewis and Steedman, 2013)—for example learning that X wrote Y and X is the author of Y are equivalent if they appear in a corpus with similar (X, Y) argumentpairs such as {(Shakespeare, Macbeth), (Dickens, Oliver Twist)}. We extend this to the multilingual case, aiming to also map the French equivalents X a ´ecrit Y and Y est un roman de X on to the same cluster as the English paraphrases. Conceptually, we treat a foreign expression as a paraphrase of an English expression. The cluster identifier can be used as a predicate in a logical form, suggesting that the fundamental predicates of an interlingua can be learnt in</context>
<context position="6849" citStr="Lewis and Steedman, 2013" startWordPosition="1043" endWordPosition="1046">2011). We describe our approach in Section 3. • A method for linking entities in the training data to some canonical representation. McNamee et al. (2011) report good results on this task in 21 languages. We describe our method for this in Section 4.1. 3 Predicate Extraction Our method relies on extracting binary predicates between entities from sentences. Various representations have been suggested for binary predicates, such as Reverb patterns (Fader et al., 2011), dependency paths (Lin and Pantel, 2001; Yao et al., 2011), and binarized predicate-argument relations derived from a CCG-parse (Lewis and Steedman, 2013). Our approach is formalism-independent, and is compatible with any method of expressing binary predicates. We choose the CCG-based parser of Lewis and Steedman (2013) for several reasons. It outputs a logical form derived automatically from the CCG-parse, containing predicates such as: writearg0,arg1(shakespeare,macbeth). By using the close relationship between the CCG syntax and semantics, it is able to generalize over many semantically equivalent syntactic constructions (such as passives, conjunctions and relative clauses), meaning we can map both Shakespeare wrote Macbeth and Macbeth was w</context>
<context position="8561" citStr="Lewis and Steedman (2013)" startWordPosition="1279" endWordPosition="1282"> writearg0:PER,arg1:BOOK(william shakespeare, macbeth) Shakespeare a ´ecrit Macbeth Dependency Parse Initial Semantic Analysis ´ecriresubj:PER,obj:BOOK(william shakespeare, macbeth) Shakespeare wrote Macbeth Shakespeare wrote Macbeth NP (S\NP)/NP NP � � S\NP S subj Shakespeare a ´ecrit Macbeth mod obj Lookup predicate in clustering Figure 1: Example showing how our system can map sentences in different languages to the same meaning represen.tation, assuming we have clustered the equivalent predicates writearg0:PER,arg1:BOOK and ´ecriresubj:PER,obj:BOOK relation43(william shakespeare, macbeth) Lewis and Steedman (2013), clusters derived from the output from the parser can be integrated into the lexicon, allowing us to build logical forms which capture both operator and lexical semantics. Accurate CCG syntactic parsers are currently only available for English, whereas dependency treebanks and parsers exist for many languages (Buchholz and Marsi, 2006). Consequently, for French we use the dependency path representation, which captures the nodes and edges connecting two named entities in a dependency parse. The extraction of these paths is language-independent, and does not depend on the dependency grammar use</context>
<context position="11866" citStr="Lewis and Steedman (2013)" startWordPosition="1801" endWordPosition="1804"> predicates with the same type (Schoenmackers et al., 2010; Berant et al., 2011; Yao et al., 2012). This is useful for resolving ambiguity—for example the phrase born in may express a place-of-birth or date-of-birth relation depending on whether its second argument has a LOC or DAT type. Ambiguous expressions may translate differently in other languages—for example, the two interpretations of was born in translate in French as est n´e a` and est n´e en respectively. The type of a predicate is determined by the type of its arguments, and predicates with different types are treated as distinct. Lewis and Steedman (2013) induce an unsupervised model of entity types using Latent Dirichlet Allocation (Blei et al., 2003), based on selectional preferences of verbs and argument-taking nouns. When applied cross-linguistically, we found this technique tended to create language-specific topics. Instead, we exploit the fact that many Wikipedia entities are linked to the Freebase database, which has a detailed manually-built type-schema. This means for a Wikipedia entity, we can look up its set of types in Freebase.2 We use the simplified type-set of 112 types created by Ling and Weld (2012). Where entities have multip</context>
<context position="14071" citStr="Lewis and Steedman (2013)" startWordPosition="2140" endWordPosition="2143">ning predicates from a single language. This appears to be because even if predicates in two different languages are truth-conditionally equivalent, the language biases the sample of entity-pairs found in a corpus. For example, the French verb ´ecrire may contain more French author/book pairs than the English equivalent write. This difference can make the verbs appear to represent different predicates to the clustering algorithm. Our two-step approach also means that advances in monolingual clustering should directly lead to improved crosslingual clusters. 5.1 Monolingual Clustering Following Lewis and Steedman (2013), we use the Chinese Whispers algorithm (Biemann, 2006) for monolingual clustering—summarized in Algorithm 1. The algorithm is non-parametric, meaning that the number of relation clusters is induced from the data, and highly scalable. We create a separate graph for each type of predicate in each language—for example, predicates between types AUTHOR and BOOK in French (so only predicates with the same type will be clustered). We create one node per predicate in the graph, and edges represent the distributional similarity between the predicates. The distributional similarity between a pair of pr</context>
<context position="18766" citStr="Lewis and Steedman (2013)" startWordPosition="2932" endWordPosition="2935"> to monolingual QA evaluations by Poon and Domingos (2009) and Lewis and 685 Steedman (2013). A question is asked in language L, and is answered by the system from a corpus of language L’. Human annotators are shown the question, answer entity, and the sentence that provided the answer, and are then asked whether the answer is a reasonable conclusion based on the sentence. Whilst this task is much easier than full translation, it is both a practical application for our approach, and a reasonably direct extrinsic evaluation for our cross-lingual clusters. Following Poon and Domingos (2009) and Lewis and Steedman (2013), the question dataset is automatically generated from the corpus. This approach has the advantage of evaluating on expressions in proportion to their corpus frequency, so understanding frequent expressions is more important than rare ones. We then sample 1000 questions for each language, by extracting binary relations matching certain patterns (Xnsubj ← verbdob → j Y, Xnsubj ← verbpob → j Y or Xnsub j ← bedob→jnounpob→ j Y), and removing one of the arguments. For example, from the sentence Obama lives in Washington we create the questions X lives in Washington?, and Obama lives in X?.3 Answer</context>
<context position="29645" citStr="Lewis and Steedman, 2013" startWordPosition="4706" endWordPosition="4709">ing K-Best parsing into our pipeline may help mitigate against such cases. This preliminary experiment suggests that there is potential for future improvements in machine translation using cross-lingual distributional semantics. The system only attempts to rerank a very small proportion of sentences, but we believe the coverage could be greatly improved by including relations between common nouns (rather than just namedentities)—future work should explore this. 8 Related Work Our work builds on recent progress in monolingual distributional semantics (Poon and Domingos, 2009; Yao et al., 2011; Lewis and Steedman, 2013) by 688 Source Le Princess Elizabeth arrive a` Dunkerque le 3 aoˆut 1999 Machine translation 1-best Le Princess Elizabeth is to manage to Dunkirk on 3 August 1999 Reranked translation The Princess Elizabeth arrives at Dunkirk on 3 August 1999 Table 4: Example sentence that is reranked by our clusters. Human evaluators were asked which translation best preserved the meaning between Princess Elizabeth and Dunkirk. clustering typed predicates into those which are semantically equivalent. We also show how to bootstrap semantic information about entities from the Wikipedia markup, and believe this </context>
</contexts>
<marker>Lewis, Steedman, 2013</marker>
<rawString>Mike Lewis and Mark Steedman. 2013. Combined Distributional and Logical Semantics. Transactions of the Association for Computational Linguistics, 1:179– 192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
<author>Patrick Pantel</author>
</authors>
<title>DIRT - Discovery of Inference Rules from Text. In</title>
<date>2001</date>
<booktitle>In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>323--328</pages>
<contexts>
<context position="6734" citStr="Lin and Pantel, 2001" startWordPosition="1027" endWordPosition="1030">ble for many languages. It is also possible without a parser, with some language-specific work (Fader et al., 2011). We describe our approach in Section 3. • A method for linking entities in the training data to some canonical representation. McNamee et al. (2011) report good results on this task in 21 languages. We describe our method for this in Section 4.1. 3 Predicate Extraction Our method relies on extracting binary predicates between entities from sentences. Various representations have been suggested for binary predicates, such as Reverb patterns (Fader et al., 2011), dependency paths (Lin and Pantel, 2001; Yao et al., 2011), and binarized predicate-argument relations derived from a CCG-parse (Lewis and Steedman, 2013). Our approach is formalism-independent, and is compatible with any method of expressing binary predicates. We choose the CCG-based parser of Lewis and Steedman (2013) for several reasons. It outputs a logical form derived automatically from the CCG-parse, containing predicates such as: writearg0,arg1(shakespeare,macbeth). By using the close relationship between the CCG syntax and semantics, it is able to generalize over many semantically equivalent syntactic constructions (such a</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>Dekang Lin and Patrick Pantel. 2001. DIRT - Discovery of Inference Rules from Text. In In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 323–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Ling</author>
<author>Daniel S Weld</author>
</authors>
<title>Fine-grained entity recognition.</title>
<date>2012</date>
<booktitle>In Proceedings of the 26th Conference on Artificial Intelligence (AAAI).</booktitle>
<contexts>
<context position="12438" citStr="Ling and Weld (2012)" startWordPosition="1890" endWordPosition="1893">e treated as distinct. Lewis and Steedman (2013) induce an unsupervised model of entity types using Latent Dirichlet Allocation (Blei et al., 2003), based on selectional preferences of verbs and argument-taking nouns. When applied cross-linguistically, we found this technique tended to create language-specific topics. Instead, we exploit the fact that many Wikipedia entities are linked to the Freebase database, which has a detailed manually-built type-schema. This means for a Wikipedia entity, we can look up its set of types in Freebase.2 We use the simplified type-set of 112 types created by Ling and Weld (2012). Where entities have multiple types (for example, Shakespeare is both an author and a person), we create a separate relation for each type. 2Named entities not present in Freebase are ignored during training. 5 Relation Clustering Predicates are clustered into those which are semantically equivalent, based on their argument-pairs in a corpus. The initial semantic analysis is run over the corpora, and for each predicate we build a vector containing counts for each of its argument-pairs (we divide these counts by the overall frequency of an argument-pair in the corpus, so that rarer argumentpai</context>
</contexts>
<marker>Ling, Weld, 2012</marker>
<rawString>Xiao Ling and Daniel S Weld. 2012. Fine-grained entity recognition. In Proceedings of the 26th Conference on Artificial Intelligence (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>James Mayfield</author>
<author>Dawn Lawrie</author>
<author>Douglas W Oard</author>
<author>David Doermann</author>
</authors>
<title>Crosslanguage entity linking.</title>
<date>2011</date>
<booktitle>Proc. IJCNLP2011.</booktitle>
<contexts>
<context position="6378" citStr="McNamee et al. (2011)" startWordPosition="970" endWordPosition="974">t, as we rely on the same facts being expressed in different languages. We use Wikipedia, which contains articles in 250 languages, including 121 with at least 10,000 articles.1 Other domains, such as Newswire, may also be effective. • A method for extracting binary relations from sentences. This is straightforward from dependency parses, which are available for many languages. It is also possible without a parser, with some language-specific work (Fader et al., 2011). We describe our approach in Section 3. • A method for linking entities in the training data to some canonical representation. McNamee et al. (2011) report good results on this task in 21 languages. We describe our method for this in Section 4.1. 3 Predicate Extraction Our method relies on extracting binary predicates between entities from sentences. Various representations have been suggested for binary predicates, such as Reverb patterns (Fader et al., 2011), dependency paths (Lin and Pantel, 2001; Yao et al., 2011), and binarized predicate-argument relations derived from a CCG-parse (Lewis and Steedman, 2013). Our approach is formalism-independent, and is compatible with any method of expressing binary predicates. We choose the CCG-bas</context>
<context position="10067" citStr="McNamee et al., 2011" startWordPosition="1515" endWordPosition="1518">ies across languages during training. In the monolingual case, it suffices to represent entities by the string used in the sentence. This is inadequate in the multilingual case, as many entities may be referred to by different names in different languages— for example the United States translates as les ´EtatsUnis in French and die Vereinigte Staaten in German. This problem is worsened by the ambiguity of named-entity strings—for example, in the context of a sports article, United States may refer specifically to a team, rather than a country. Recent work on multilingual named-entity linking (McNamee et al., 2011) shows how to link named entities in multiple languages onto English Wikipedia articles, which can be used as unique identifiers for entities. This means that we could gain the information we need from unrestricted text. However, as we use Wikipedia itself for our training corpora, we can bootstrap entity information directly from its markup. Wikipedia contains cross-language links, e.g. between the United States articles in different languages, allowing us to determine the equivalence of entities in differ683 ent languages. Wikipedia links also help us automatically disambiguate entities to a</context>
</contexts>
<marker>McNamee, Mayfield, Lawrie, Oard, Doermann, 2011</marker>
<rawString>Paul McNamee, James Mayfield, Dawn Lawrie, Douglas W Oard, and David Doermann. 2011. Crosslanguage entity linking. Proc. IJCNLP2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna M Wallach</author>
<author>Jason Naradowsky</author>
<author>David A Smith</author>
<author>Andrew McCallum</author>
</authors>
<title>Polylingual topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<pages>880--889</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="33771" citStr="Mimno et al., 2009" startWordPosition="5337" endWordPosition="5340">supervised approach offers a way to build such an interlingua using only a method for extracting predicates from sentences. Whilst almost all recent work on machinetranslation has relied on parallel text, there have been several interesting approaches that do not. Rapp (1999) learns to translate words based on small seed bilingual dictionary. Klementiev et al. (2012a) exploit a variety of interesting indirect sources of information to learn a lexicon—for example assuming that equivalent Wikipedia articles in different languages will use semantically similar words. The Polylingual Topic Model (Mimno et al., 2009) makes use of similar intuitions. Whilst we exploit equivalent Wikipedia articles for entity linking, we do not require aligned articles. Incorporating such techniques into our model would be a natural next 689 step, allowing us to learn a more complete lexicon. To our knowledge, ours is the first approach to learn to translate semantic relations, rather than words and phrases. Several other recent papers have learnt crosslingual word clusters, and used these to improve cross-lingual tasks such as document-classification (Klementiev et al., 2012b), parsing (T¨ackstr¨om et al., 2012) and semant</context>
</contexts>
<marker>Mimno, Wallach, Naradowsky, Smith, McCallum, 2009</marker>
<rawString>David Mimno, Hanna M Wallach, Jason Naradowsky, David A Smith, and Andrew McCallum. 2009. Polylingual topic models. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2-Volume 2, pages 880– 889. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Mintz</author>
<author>S Bills</author>
<author>R Snow</author>
<author>D Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="3935" citStr="Mintz et al., 2009" startWordPosition="585" endWordPosition="588">a clustering. In this paper we focus on learning binary relations between named entities. This problem is much simpler than attempting complete interlingual semantic 681 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 681–692, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics interpretation, but the approach could be generalized. This class of expressions has proved extremely useful in the monolingual case, with direct applications for question answering and relation extraction (Poon and Domingos, 2009; Mintz et al., 2009), and we demonstrate how to use them to improve machine translation. It is important to be able to extract knowledge across languages, as many facts will not be expressed in all languages—either due to lesscomplete encyclopedias being available in some languages, or facts being most relevant to a single country. In contrast to most previous work on machine translation and cross-lingual clustering, our method requires no parallel text (see Section 8 for discussion of some exceptions). It instead exploits an alignment between named-entities in different languages. The limited size of parallel co</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>M. Mintz, S. Bills, R. Snow, and D. Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003– 1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Teruko Mitamura</author>
<author>Eric H Nyberg</author>
<author>Jaime G Carbonell</author>
</authors>
<title>An efficient interlingua translation system for multi-lingual document production.</title>
<date>1991</date>
<contexts>
<context position="2054" citStr="Mitamura et al., 1991" startWordPosition="290" endWordPosition="294">ummarization, question answering, and information retrieval. Regardless of whether it is even possible to create such a semantics, we show that an incomplete version can be useful for downstream tasks. Semantic machine translation aims to map a source language to a language-independent meaning representation, and then generate the target language translation from this. It is hoped this would alleviate the difficulties of simpler models when translating between languages with very different word ordering and syntax (Vauquois, 1968). Despite many attempts to define interlingual representations (Mitamura et al., 1991; Beale et al., 1995; Banarescu et al., 2013), state-of-the-art machine translation still uses phrase-based models (Koehn et al., 2007). The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express (Dorr et al., 2004). Our approach avoids this problem by utilizing the methods of distributional semantics. Recent work has shown that paraphrases of expressions can be learned by clustering those with similar arguments (Poon and Domingos, 2009; Yao et </context>
</contexts>
<marker>Mitamura, Nyberg, Carbonell, 1991</marker>
<rawString>Teruko Mitamura, Eric H Nyberg, and Jaime G Carbonell. 1991. An efficient interlingua translation system for multi-lingual document production.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="17521" citStr="Nivre et al., 2007" startWordPosition="2735" endWordPosition="2738">,r2)}; RL1 ←− RL1/{r1}; RL2 ←− RL2/{r2}; end Algorithm 2: Cluster alignment algorithm English French X invades Y X envahit Y invasion de Y par X X orbits Y X est un satellite de Y X est une lune de Y X is a skyscraper in Y X est un gratte-ciel de Y X is a novel by Y X est un roman de Y X joins Y X adh`ere a` Y X is a member of Y X entre dans Y X rejoint Y Table 1: Some example cross-lingual clusters. Predicates are given in a human-readable form, and predicate types are suppressed. (Clark and Curran, 2004). The French corpus is tagged with MElt (Denis et al., 2009) and parsed with MaltParser (Nivre et al., 2007), trained on the French Treebank (Candito et al., 2010). Wikipedia markup is filtered using Wikiprep (Gabrilovich and Markovitch, 2007)—replacing internal links with the name of their target article, to help entity linking. Some example clusters learnt by our model are shown in Table 1. We find that the cross-lingual clusters typically contain more French expressions than English, possibly due to the differing sizes of the corpora—adjusting the parameters in Section 5 results in larger clusters, but introduces noise. 6.1 Experimental Setup We evaluate our system on a cross-lingual question ans</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi. 2007. Maltparser: A languageindependent system for data-driven dependency parsing. Natural Language Engineering, 13(2):95–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hoifung Poon</author>
<author>Pedro Domingos</author>
</authors>
<title>Unsupervised semantic parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, EMNLP ’09,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2645" citStr="Poon and Domingos, 2009" startWordPosition="379" endWordPosition="382">entations (Mitamura et al., 1991; Beale et al., 1995; Banarescu et al., 2013), state-of-the-art machine translation still uses phrase-based models (Koehn et al., 2007). The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express (Dorr et al., 2004). Our approach avoids this problem by utilizing the methods of distributional semantics. Recent work has shown that paraphrases of expressions can be learned by clustering those with similar arguments (Poon and Domingos, 2009; Yao et al., 2011; Lewis and Steedman, 2013)—for example learning that X wrote Y and X is the author of Y are equivalent if they appear in a corpus with similar (X, Y) argumentpairs such as {(Shakespeare, Macbeth), (Dickens, Oliver Twist)}. We extend this to the multilingual case, aiming to also map the French equivalents X a ´ecrit Y and Y est un roman de X on to the same cluster as the English paraphrases. Conceptually, we treat a foreign expression as a paraphrase of an English expression. The cluster identifier can be used as a predicate in a logical form, suggesting that the fundamental </context>
<context position="3914" citStr="Poon and Domingos, 2009" startWordPosition="581" endWordPosition="584">an unsupervised manner via clustering. In this paper we focus on learning binary relations between named entities. This problem is much simpler than attempting complete interlingual semantic 681 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 681–692, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics interpretation, but the approach could be generalized. This class of expressions has proved extremely useful in the monolingual case, with direct applications for question answering and relation extraction (Poon and Domingos, 2009; Mintz et al., 2009), and we demonstrate how to use them to improve machine translation. It is important to be able to extract knowledge across languages, as many facts will not be expressed in all languages—either due to lesscomplete encyclopedias being available in some languages, or facts being most relevant to a single country. In contrast to most previous work on machine translation and cross-lingual clustering, our method requires no parallel text (see Section 8 for discussion of some exceptions). It instead exploits an alignment between named-entities in different languages. The limite</context>
<context position="18199" citStr="Poon and Domingos (2009)" startWordPosition="2838" endWordPosition="2841">). Wikipedia markup is filtered using Wikiprep (Gabrilovich and Markovitch, 2007)—replacing internal links with the name of their target article, to help entity linking. Some example clusters learnt by our model are shown in Table 1. We find that the cross-lingual clusters typically contain more French expressions than English, possibly due to the differing sizes of the corpora—adjusting the parameters in Section 5 results in larger clusters, but introduces noise. 6.1 Experimental Setup We evaluate our system on a cross-lingual question answering task, similar to monolingual QA evaluations by Poon and Domingos (2009) and Lewis and 685 Steedman (2013). A question is asked in language L, and is answered by the system from a corpus of language L’. Human annotators are shown the question, answer entity, and the sentence that provided the answer, and are then asked whether the answer is a reasonable conclusion based on the sentence. Whilst this task is much easier than full translation, it is both a practical application for our approach, and a reasonably direct extrinsic evaluation for our cross-lingual clusters. Following Poon and Domingos (2009) and Lewis and Steedman (2013), the question dataset is automat</context>
<context position="29600" citStr="Poon and Domingos, 2009" startWordPosition="4698" endWordPosition="4701">ence between these translations. Incorporating K-Best parsing into our pipeline may help mitigate against such cases. This preliminary experiment suggests that there is potential for future improvements in machine translation using cross-lingual distributional semantics. The system only attempts to rerank a very small proportion of sentences, but we believe the coverage could be greatly improved by including relations between common nouns (rather than just namedentities)—future work should explore this. 8 Related Work Our work builds on recent progress in monolingual distributional semantics (Poon and Domingos, 2009; Yao et al., 2011; Lewis and Steedman, 2013) by 688 Source Le Princess Elizabeth arrive a` Dunkerque le 3 aoˆut 1999 Machine translation 1-best Le Princess Elizabeth is to manage to Dunkirk on 3 August 1999 Reranked translation The Princess Elizabeth arrives at Dunkirk on 3 August 1999 Table 4: Example sentence that is reranked by our clusters. Human evaluators were asked which translation best preserved the meaning between Princess Elizabeth and Dunkirk. clustering typed predicates into those which are semantically equivalent. We also show how to bootstrap semantic information about entities</context>
</contexts>
<marker>Poon, Domingos, 2009</marker>
<rawString>Hoifung Poon and Pedro Domingos. 2009. Unsupervised semantic parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1 - Volume 1, EMNLP ’09, pages 1–10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, ACL ’99,</booktitle>
<pages>519--526</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="33428" citStr="Rapp (1999)" startWordPosition="5288" endWordPosition="5289">scu et al., 2013), which uses English verbs as a set of predicates. This is a less abstract form of semantic interpretation than our proposal, as semantically equivalent paraphrases may be given a different representation. Such an approach also relies on annotating large amounts of text with the semantic representation—whereas our unsupervised approach offers a way to build such an interlingua using only a method for extracting predicates from sentences. Whilst almost all recent work on machinetranslation has relied on parallel text, there have been several interesting approaches that do not. Rapp (1999) learns to translate words based on small seed bilingual dictionary. Klementiev et al. (2012a) exploit a variety of interesting indirect sources of information to learn a lexicon—for example assuming that equivalent Wikipedia articles in different languages will use semantically similar words. The Polylingual Topic Model (Mimno et al., 2009) makes use of similar intuitions. Whilst we exploit equivalent Wikipedia articles for entity linking, we do not require aligned articles. Incorporating such techniques into our model would be a natural next 689 step, allowing us to learn a more complete lex</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated english and german corpora. In Proceedings of the 37th annual meeting of the Association for Computational Linguistics on Computational Linguistics, ACL ’99, pages 519–526. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
<author>Noah A Smith</author>
</authors>
<title>The web as a parallel corpus.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="4617" citStr="Resnik and Smith, 2003" startWordPosition="694" endWordPosition="697">nslation. It is important to be able to extract knowledge across languages, as many facts will not be expressed in all languages—either due to lesscomplete encyclopedias being available in some languages, or facts being most relevant to a single country. In contrast to most previous work on machine translation and cross-lingual clustering, our method requires no parallel text (see Section 8 for discussion of some exceptions). It instead exploits an alignment between named-entities in different languages. The limited size of parallel corpora is a significant bottleneck for machine translation (Resnik and Smith, 2003), whereas our approach can be used on much larger monolingual corpora. This means it is potentially useful for language-pairs where little parallel text is available, for domain adaptation, or for semisupervised approaches. 2 Basic Approach Our work builds on clustering-based approaches to monolingual distributional semantics, aiming to create clusters of semantically equivalent predicates, based on their arguments in a corpus. In each language, we first map each sentence in a large monolingual corpus onto a simple logical form, by extracting binary predicates between named entities. Then, we </context>
</contexts>
<marker>Resnik, Smith, 2003</marker>
<rawString>Philip Resnik and Noah A Smith. 2003. The web as a parallel corpus. Computational Linguistics, 29(3):349–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Schoenmackers</author>
<author>Oren Etzioni</author>
<author>Daniel S Weld</author>
<author>Jesse Davis</author>
</authors>
<title>Learning first-order horn clauses from web text.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>1088--1098</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="11299" citStr="Schoenmackers et al., 2010" startWordPosition="1707" endWordPosition="1710"> article. For unlinked named-entity mentions, we perform some simple heuristic co-reference—based on word-overlap with previously mentioned entities in the document, whether the mention name is the title of a Wikipedia article, or whether the mention name is a Freebase (Bollacker et al., 2008) alias of an entity. We emphasise that this does not mean our approach is only applicable to the Wikipedia corpus. 4.2 Entity Typing It has become standard in clustering approaches to distributional semantics to assign types to predicates before clustering, and only cluster predicates with the same type (Schoenmackers et al., 2010; Berant et al., 2011; Yao et al., 2012). This is useful for resolving ambiguity—for example the phrase born in may express a place-of-birth or date-of-birth relation depending on whether its second argument has a LOC or DAT type. Ambiguous expressions may translate differently in other languages—for example, the two interpretations of was born in translate in French as est n´e a` and est n´e en respectively. The type of a predicate is determined by the type of its arguments, and predicates with different types are treated as distinct. Lewis and Steedman (2013) induce an unsupervised model of </context>
</contexts>
<marker>Schoenmackers, Etzioni, Weld, Davis, 2010</marker>
<rawString>Stefan Schoenmackers, Oren Etzioni, Daniel S. Weld, and Jesse Davis. 2010. Learning first-order horn clauses from web text. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 1088–1098. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Taking Scope: The Natural Semantics of Quantifiers.</title>
<date>2012</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="7692" citStr="Steedman, 2012" startWordPosition="1168" endWordPosition="1169">atically from the CCG-parse, containing predicates such as: writearg0,arg1(shakespeare,macbeth). By using the close relationship between the CCG syntax and semantics, it is able to generalize over many semantically equivalent syntactic constructions (such as passives, conjunctions and relative clauses), meaning we can map both Shakespeare wrote Macbeth and Macbeth was written by Shakespeare to the same logical form. Using a dependency-based representation, these would have different predicates, which would need to be clustered later. CCG also has a well developed theory of operator semantics (Steedman, 2012), so is able to represent semantic operators such as quantifiers, negation and tense— understanding these is crucial to high performance on question answering or translation tasks. As in 1As of June 2013. 682 CCG Parse Initial Semantic Analysis writearg0:PER,arg1:BOOK(william shakespeare, macbeth) Shakespeare a ´ecrit Macbeth Dependency Parse Initial Semantic Analysis ´ecriresubj:PER,obj:BOOK(william shakespeare, macbeth) Shakespeare wrote Macbeth Shakespeare wrote Macbeth NP (S\NP)/NP NP � � S\NP S subj Shakespeare a ´ecrit Macbeth mod obj Lookup predicate in clustering Figure 1: Example show</context>
</contexts>
<marker>Steedman, 2012</marker>
<rawString>Mark Steedman. 2012. Taking Scope: The Natural Semantics of Quantifiers. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Cross-lingual word clusters for direct transfer of linguistic structure.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12,</booktitle>
<pages>477--487</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>T¨ackstr¨om, McDonald, Uszkoreit, 2012</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Jakob Uszkoreit. 2012. Cross-lingual word clusters for direct transfer of linguistic structure. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, NAACL HLT ’12, pages 477–487. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Measuring semantic similarity by latent relational analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the 19th international joint conference on Artificial intelligence, IJCAI’05,</booktitle>
<pages>1136--1141</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="30482" citStr="Turney (2005)" startWordPosition="4839" endWordPosition="4840">k on 3 August 1999 Table 4: Example sentence that is reranked by our clusters. Human evaluators were asked which translation best preserved the meaning between Princess Elizabeth and Dunkirk. clustering typed predicates into those which are semantically equivalent. We also show how to bootstrap semantic information about entities from the Wikipedia markup, and believe this makes it an interesting corpus for future work on monolingual distributional semantics. Cross-language Latent Relational Analysis (Duc et al., 2011) is perhaps the most similar previous work to ours, which moves the work of Turney (2005) into a multilingual setting. Duc et al. (2011) aim to compute, for example, that the ‘latent relation’ between (Obama, US) in an English corpus is similar to that between (Cameron, UK) in a foreign corpus. This is solved by finding all textual patterns between the two entity-pairs, and computing their overall similarity. Like us, they compute similarity between expressions in different languages based on named-entity arguments and clustering (unlike us, they also rely on machine translation for computing similarity). A key difference is that their system aims to understand the overall relatio</context>
</contexts>
<marker>Turney, 2005</marker>
<rawString>Peter D. Turney. 2005. Measuring semantic similarity by latent relational analysis. In Proceedings of the 19th international joint conference on Artificial intelligence, IJCAI’05, pages 1136–1141, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernard Vauquois</author>
</authors>
<title>A survey of formal grammars and algorithms for recognition and transformation in machine translation.</title>
<date>1968</date>
<booktitle>In IFIP Congress,</booktitle>
<volume>68</volume>
<pages>254--260</pages>
<contexts>
<context position="1969" citStr="Vauquois, 1968" startWordPosition="281" endWordPosition="282">would be of great utility for tasks such as translation, relation extraction, summarization, question answering, and information retrieval. Regardless of whether it is even possible to create such a semantics, we show that an incomplete version can be useful for downstream tasks. Semantic machine translation aims to map a source language to a language-independent meaning representation, and then generate the target language translation from this. It is hoped this would alleviate the difficulties of simpler models when translating between languages with very different word ordering and syntax (Vauquois, 1968). Despite many attempts to define interlingual representations (Mitamura et al., 1991; Beale et al., 1995; Banarescu et al., 2013), state-of-the-art machine translation still uses phrase-based models (Koehn et al., 2007). The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express (Dorr et al., 2004). Our approach avoids this problem by utilizing the methods of distributional semantics. Recent work has shown that paraphrases of expressions can be</context>
</contexts>
<marker>Vauquois, 1968</marker>
<rawString>Bernard Vauquois. 1968. A survey of formal grammars and algorithms for recognition and transformation in machine translation. In IFIP Congress, volume 68, pages 254–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hila Weisman</author>
<author>Jonathan Berant</author>
<author>Idan Szpektor</author>
<author>Ido Dagan</author>
</authors>
<title>Learning verb inference rules from linguistically-motivated evidence.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12,</booktitle>
<pages>194--204</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14895" citStr="Weisman et al., 2012" startWordPosition="2266" endWordPosition="2269"> the data, and highly scalable. We create a separate graph for each type of predicate in each language—for example, predicates between types AUTHOR and BOOK in French (so only predicates with the same type will be clustered). We create one node per predicate in the graph, and edges represent the distributional similarity between the predicates. The distributional similarity between a pair of predicates is calculated as the cosine-similarity of their argument pair vectors in the corpus. Many more sophisticated approaches to determining similarity have been proposed (Kotlerman et al., 2010; 684 Weisman et al., 2012), and future work should explore these. We prune nodes with less than 25 occurrences, edges of weight less than 0.05, and a short list of stop predicates. We find many of our French dependency paths do not have a clear semantic interpretation, so add the requirement that dependency paths contain at least one content word, contain at most 5 edges, and that one of the dependencies connected to the root is subject, object or the French preposition de. Data: Set of predicates P Result: A cluster assignment rp for all p ∈ P ∀p ∈ P : rp ←− unique cluster identifier; while not converged do randomize </context>
</contexts>
<marker>Weisman, Berant, Szpektor, Dagan, 2012</marker>
<rawString>Hila Weisman, Jonathan Berant, Idan Szpektor, and Ido Dagan. 2012. Learning verb inference rules from linguistically-motivated evidence. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12, pages 194–204. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Aria Haghighi</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Structured relation discovery using generative models.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11,</booktitle>
<pages>1456--1466</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2663" citStr="Yao et al., 2011" startWordPosition="383" endWordPosition="386">., 1991; Beale et al., 1995; Banarescu et al., 2013), state-of-the-art machine translation still uses phrase-based models (Koehn et al., 2007). The major obstacle to defining interlinguas has been devising a meaning representation that is languageindependent, but capable of expressing the limitless number of meanings that natural languages can express (Dorr et al., 2004). Our approach avoids this problem by utilizing the methods of distributional semantics. Recent work has shown that paraphrases of expressions can be learned by clustering those with similar arguments (Poon and Domingos, 2009; Yao et al., 2011; Lewis and Steedman, 2013)—for example learning that X wrote Y and X is the author of Y are equivalent if they appear in a corpus with similar (X, Y) argumentpairs such as {(Shakespeare, Macbeth), (Dickens, Oliver Twist)}. We extend this to the multilingual case, aiming to also map the French equivalents X a ´ecrit Y and Y est un roman de X on to the same cluster as the English paraphrases. Conceptually, we treat a foreign expression as a paraphrase of an English expression. The cluster identifier can be used as a predicate in a logical form, suggesting that the fundamental predicates of an i</context>
<context position="6753" citStr="Yao et al., 2011" startWordPosition="1031" endWordPosition="1034">. It is also possible without a parser, with some language-specific work (Fader et al., 2011). We describe our approach in Section 3. • A method for linking entities in the training data to some canonical representation. McNamee et al. (2011) report good results on this task in 21 languages. We describe our method for this in Section 4.1. 3 Predicate Extraction Our method relies on extracting binary predicates between entities from sentences. Various representations have been suggested for binary predicates, such as Reverb patterns (Fader et al., 2011), dependency paths (Lin and Pantel, 2001; Yao et al., 2011), and binarized predicate-argument relations derived from a CCG-parse (Lewis and Steedman, 2013). Our approach is formalism-independent, and is compatible with any method of expressing binary predicates. We choose the CCG-based parser of Lewis and Steedman (2013) for several reasons. It outputs a logical form derived automatically from the CCG-parse, containing predicates such as: writearg0,arg1(shakespeare,macbeth). By using the close relationship between the CCG syntax and semantics, it is able to generalize over many semantically equivalent syntactic constructions (such as passives, conjunc</context>
<context position="29618" citStr="Yao et al., 2011" startWordPosition="4702" endWordPosition="4705">ations. Incorporating K-Best parsing into our pipeline may help mitigate against such cases. This preliminary experiment suggests that there is potential for future improvements in machine translation using cross-lingual distributional semantics. The system only attempts to rerank a very small proportion of sentences, but we believe the coverage could be greatly improved by including relations between common nouns (rather than just namedentities)—future work should explore this. 8 Related Work Our work builds on recent progress in monolingual distributional semantics (Poon and Domingos, 2009; Yao et al., 2011; Lewis and Steedman, 2013) by 688 Source Le Princess Elizabeth arrive a` Dunkerque le 3 aoˆut 1999 Machine translation 1-best Le Princess Elizabeth is to manage to Dunkirk on 3 August 1999 Reranked translation The Princess Elizabeth arrives at Dunkirk on 3 August 1999 Table 4: Example sentence that is reranked by our clusters. Human evaluators were asked which translation best preserved the meaning between Princess Elizabeth and Dunkirk. clustering typed predicates into those which are semantically equivalent. We also show how to bootstrap semantic information about entities from the Wikipedi</context>
</contexts>
<marker>Yao, Haghighi, Riedel, McCallum, 2011</marker>
<rawString>Limin Yao, Aria Haghighi, Sebastian Riedel, and Andrew McCallum. 2011. Structured relation discovery using generative models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, EMNLP ’11, pages 1456–1466. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Unsupervised relation discovery with sense disambiguation.</title>
<date>2012</date>
<booktitle>In ACL (1),</booktitle>
<pages>712--720</pages>
<contexts>
<context position="11339" citStr="Yao et al., 2012" startWordPosition="1715" endWordPosition="1718">perform some simple heuristic co-reference—based on word-overlap with previously mentioned entities in the document, whether the mention name is the title of a Wikipedia article, or whether the mention name is a Freebase (Bollacker et al., 2008) alias of an entity. We emphasise that this does not mean our approach is only applicable to the Wikipedia corpus. 4.2 Entity Typing It has become standard in clustering approaches to distributional semantics to assign types to predicates before clustering, and only cluster predicates with the same type (Schoenmackers et al., 2010; Berant et al., 2011; Yao et al., 2012). This is useful for resolving ambiguity—for example the phrase born in may express a place-of-birth or date-of-birth relation depending on whether its second argument has a LOC or DAT type. Ambiguous expressions may translate differently in other languages—for example, the two interpretations of was born in translate in French as est n´e a` and est n´e en respectively. The type of a predicate is determined by the type of its arguments, and predicates with different types are treated as distinct. Lewis and Steedman (2013) induce an unsupervised model of entity types using Latent Dirichlet Allo</context>
</contexts>
<marker>Yao, Riedel, McCallum, 2012</marker>
<rawString>Limin Yao, Sebastian Riedel, and Andrew McCallum. 2012. Unsupervised relation discovery with sense disambiguation. In ACL (1), pages 712–720.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>