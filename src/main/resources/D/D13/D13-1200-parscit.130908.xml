<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<note confidence="0.9181695">
Well-argued recommendation:
adaptive models based on words in recommender systems
</note>
<author confidence="0.971395">
Julien Gaillard
</author>
<affiliation confidence="0.700844">
University of Avignon
Agorantic
Avignon, France
</affiliation>
<email confidence="0.830506">
julien.gaillard@univ-avignon.fr
</email>
<author confidence="0.969852">
Marc El-Beze
</author>
<affiliation confidence="0.699008333333333">
University of Avignon
Agorantic
Avignon, France
</affiliation>
<email confidence="0.838949">
marc.elbeze@univ-avignon.fr
</email>
<author confidence="0.573491">
Eitan Altman
</author>
<affiliation confidence="0.402062">
INRIA Sophia Antipolis
Agorantic
</affiliation>
<address confidence="0.816167">
Sophia-Antipolis, France
</address>
<email confidence="0.996652">
eitan.altman@inria.fr
</email>
<author confidence="0.990063">
Emmanuel Ethis
</author>
<affiliation confidence="0.690165">
University of Avignon
Agorantic
Avignon, France
</affiliation>
<email confidence="0.869025">
emmanuel.ethis@univ-avignon.fr
</email>
<sectionHeader confidence="0.997977" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99924405882353">
Recommendation systems (RS) take advan-
tage of products and users information in order
to propose items to consumers. Collaborative,
content-based and a few hybrid RS have been
developed in the past. In contrast, we propose
a new domain-independent semantic RS. By
providing textually well-argued recommenda-
tions, we aim to give more responsibility to the
end user in his decision. The system includes
a new similarity measure keeping up both the
accuracy of rating predictions and coverage.
We propose an innovative way to apply a fast
adaptation scheme at a semantic level, provid-
ing recommendations and arguments in phase
with the very recent past. We have performed
several experiments on films data, providing
textually well-argued recommendations.
</bodyText>
<sectionHeader confidence="0.999519" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9993592">
Recommender systems aim at suggesting appropri-
ate items to users from a large catalog of products.
Those systems are individually adapted by using a
specific profile for each user and item, derived from
the analysis of past ratings. The last decade has
shown a historical change in the way we consume
products. People are getting used to receive recom-
mendations. Nevertheless, after a few bad recom-
mendations, users will not be convinced anymore by
the RS. Moreover, if these suggestions come without
explanations, why people should trust it? Numbers
and figures cannot talk to people.
To answer these key issues, we have designed a
new semantic recommender sytem (SRS) including
at least two innovative features:
</bodyText>
<listItem confidence="0.998594">
• Argumentation: each recommendation relies
on and comes along with a textual argumenta-
tion, providing the reasons that led to that rec-
ommendation.
• Fast adaptation: the system is updated in a con-
</listItem>
<bodyText confidence="0.982643083333333">
tinuous way, as each new review is posted.
In doing so, the system will be perceived as less
intrusive thanks to well-chosen words and its fail-
ures will be smoothed over. It is therefore necessary
to design a new generation of RS providing textu-
ally well-argued recommendations. This way, the
end user will have more elements to make a well-
informed choice. Moreover, the system parameters
have to be dynamically and continuously updated,
in order to provide recommendations and arguments
in phase with the very recent past. To do so, we
have adapted the algorithms we described in Gail-
lard (Gaillard et al., 2013), by including a semantic
level, i.e words, terms and phrases as they are natu-
rally expressed in reviews.
This paper is structured as follows. In the next
section, we present the state of the art in recom-
mendation systems and introduce some of the im-
provements we have made. Then, we present our
approach and define the associated methods in sec-
tion 3. We describe the evaluation protocol and how
we have performed some experiments in section 4.
Finally we report results including a comparison to
a baseline in section 5.
</bodyText>
<sectionHeader confidence="0.996549" genericHeader="introduction">
2 Related work and choice of a baseline
</sectionHeader>
<bodyText confidence="0.93662">
We present here some methods used in the litera-
ture. Collaborative Filtering (CF) systems use logs
</bodyText>
<page confidence="0.907853">
1943
</page>
<bodyText confidence="0.97187315625">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1943–1947,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
of users, generally user ratings on items (Burke,
2007; Sarwar et al., 1998). In these systems, the
following assumption is made: if user a and user
b rate n items similarly, they will rate other items
in the same way (Deshpande and Karypis., 2004).
This technique has many well-known issues such
as the “cold start” problem, i.e when new items or
users appear, it is impossible to make a recommen-
dation, due to the absence of rating data (Schein et
al., 2002). Other limitations of RS are sparsity, scal-
ability, overspecialization and domain-dependency
problems.
In Content Based Filtering (CBF) systems, users are
supposed to be independent (Mehta et al., 2008).
Hence for a given user, recommendations rely only
on items he previously rated.
Some RS incorporate semantic knowledge to im-
prove quality. Generally, they apply a concept-
based approach to enhance the user modeling stage
and employ standard vocabularies and ontology re-
sources. For instance, ePaper (scientific-paper rec-
ommender), computes the matching between the
concepts constituting user interests and the concepts
describing an item by using hierarchical relation-
ships of domain concepts (Maidel et al., 2008). Cod-
ina and Ceccaroni (2010) propose to take advantage
of semantics by using an interest-prediction method
based on user ratings and browsing events.
However, none of them are actually based on the
user opinion as it is expressed in natural language.
</bodyText>
<subsectionHeader confidence="0.99586">
2.1 Similarity measures
</subsectionHeader>
<bodyText confidence="0.999972545454546">
Similarity measures are the keystone of RS (Her-
locker et al., 2005). Resnick (1997) was one of the
first to introduce the Pearson correlation coefficient
to derive a similarity measure between two entities.
Other similarity measures such as Jaccard and Co-
sine have been proposed (Meyer, 2012). Let Su be
the set of items rated by u, Ti the set of users who
have rated item i, ru,i the rating of user u on item i
and rx the mean of x (user or item). PEA(i,j) stands
for the Pearson similarity between items i and j and
is computed as follows:
</bodyText>
<equation confidence="0.682385">
∑
u∈Ti∩Tj(ru,i − ri)(ru,j − rj) (1)
</equation>
<bodyText confidence="0.9968955">
Corrected similarity (MWC), that we introduced in
(Gaillard et al., 2013), will be used as a point of
comparison as well1. Again, for none of them, tex-
tual content is taken into account.
</bodyText>
<subsectionHeader confidence="0.999822">
2.2 Rating prediction
</subsectionHeader>
<bodyText confidence="0.999917428571429">
Let i be a given item and u a given user. We suppose
the pair (u, i) is unique. Indeed, most of social net-
works do not allow multiple ratings by the same user
for one item. In this framework, two rating predic-
tion methods have to be defined: one user oriented
and the other item oriented. Sim stands for some
similarity function in the following formula.
</bodyText>
<equation confidence="0.859335">
∑vETz Sim(u, v) x rv,i
rating(u, i) 2
- &apos;VETi I Sim(u, v) I ( )
</equation>
<bodyText confidence="0.9996825">
A symmetrical formula for items rating(i, u) is de-
rived from and combined with (2).
</bodyText>
<equation confidence="0.960512">
ˆru,i = βxrating(u, i)+(1−β)xrating(i, u) (3)
</equation>
<sectionHeader confidence="0.996721" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.999987875">
In this section, we describe the methods we have
used and propose some of the enhancements we
have elaborated in our system. In formula (2),
Sim can be replaced by several similarity such as
Pearson, Cosine or MWC similarity (Tan et al.,
2005). All these methods provide a measurement of
the likeness between two objects. We then conclude
if two users (or items) are ”alike” or not. One has
to define what “alike“ should mean in this case. If
two users rate the same movies with equals ratings,
then these similarities will be maximal. However,
they may have rated identically but for completely
different reasons, making them not alike at all.
Moreover, none of these similarity measures can
express why two users or items are similar. This is
due to the fact that they rely on ratings only.
</bodyText>
<subsectionHeader confidence="0.99881">
3.1 New similarity based on words
</subsectionHeader>
<bodyText confidence="0.9998906">
We propose a new similarity method, taking into ac-
count words used by users in their past reviews about
items. In the remainder, we call it the Word Based
Similarity (WBS). Each user x (or item) has a vo-
cabulary set Vx and each word w in it is associated
</bodyText>
<footnote confidence="0.75114">
1Details on MWC can be found in supplementary material.
</footnote>
<bodyText confidence="0.887597666666667">
√∑u∈Ti∩Tj(ru,i − ri)2 ∑u∈Ti∩Tj(ru,j − rj)2
In the remainder, the Pearson similarity measure will
be used as a baseline. The Manhattan Weighted and
</bodyText>
<page confidence="0.984441">
1944
</page>
<bodyText confidence="0.999962272727273">
with a set of ratings Rw,x and an average usage rat-
ing rw. In order to balance the contribution of each
word, we define a weight function Fw, mixing the
well-known Inverse Document Frequency IDF(w)
with the variance σ2w. Common words and words w
associated with very heterogenous ratings Rw,x (i.e
a high variance) will have a smaller weight in the
similarity. Nw is the number of items in which the
word w appears. Ntot is the total number of items.
D is the maximum difference between two ratings.
Note that Fw has to be updated at each iteration.
</bodyText>
<equation confidence="0.983477333333333">
( Nw/ 1
Fw = −log J × 2 (4)
Ntot σw
∑ w�Vx�V�(D − |rw,x − rw,y|)Fw
WBS(x, y) = D × |Vx ∩ Vy |∑ w�Vx�V� Fw
(5)
</equation>
<subsectionHeader confidence="0.995362">
3.2 Adaptation
</subsectionHeader>
<bodyText confidence="0.999990153846154">
An adaptive framework proposed in (Gaillard et al.,
2013) allows the system to have a dynamic adapta-
tion along time, overcoming most of the drawbacks
due to the cold-start. The authors have designed a
dynamic process following the principle that every
update (u, i) needs to be instantly taken into account
by the system. Consequently, we have to update the
σ2w and IDF(w) at each iteration, for every word.
Paying attention to avoid a whole re-estimation of
these two variables, we derived an iterative relation
for the two of them2. We thus reduced the complex-
ity by one degree, keeping our system very well-
fitted to dynamic adaptation.
</bodyText>
<subsectionHeader confidence="0.999003">
3.3 Textual recommendation
</subsectionHeader>
<bodyText confidence="0.999937166666667">
The main innovative feature of our proposal is to
predict what a user is going to write on an item
we recommend. More precisely, we can tell the
user why he is expected to like or dislike the rec-
ommended item. This is possible thanks to the new
similarity measure we have introduced (WBS). Let
us consider a user u and an item i. To keep it sim-
ple, the system takes into account what u has written
on other items in the past and what other users have
written on item i, by using WBS. The idea consists
in extracting what elements of i have been liked or
disliked by other users, and what u generally likes.
</bodyText>
<footnote confidence="0.674418">
2More details can be found in the supplementary material.
</footnote>
<bodyText confidence="0.999765363636364">
At the intersection of these two pieces of informa-
tion, we extract a set of matching words that we
sort by relevance using Fw. Then, by taking into
account the ratings associated with each word, we
define two sub-sets Pw and Nw. Pw contains what
user u is probably going to like in i and Nw what u
may dislike. Finally, we provide the most relevant
arguments contained in both Pw and Nw, and each
of them is given in the context they have been used
for item i. As an example, some outputs are shown
in section 5.2.
</bodyText>
<sectionHeader confidence="0.989128" genericHeader="method">
4 Evaluation criteria
</sectionHeader>
<bodyText confidence="0.999968578947368">
We present here the evaluation protocol we de-
signed. It should be noted that we are not able
to make online experiments. Therefore, we can
not measure the feedback on our recommendations.
However, the cornerstone of recommender system is
the accuracy of rating predictions (Herlocker et al.,
2004). From this point of view, one could argue that
the quality of a recommender engine could be as-
sessed by its capacity to predict ratings. It is thus
possible to evaluate our system comparing the pre-
diction ˆru,i for a given pair (u, i), with the actual
real rating ru,i.
The classical metrics3 (Bell et al., 2007) Root Mean
Square Error (RMSE) and Mean Absolute Error
(MAE) will be used to evaluate our RS.
Last but not least, we make the following assump-
tion: if WBS results are as good as MWC’s, the
words presented by the system to users as arguments
are likely to be relevant.
</bodyText>
<sectionHeader confidence="0.999365" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999978">
This work has been carried out in partnership with
the website Vodkaster 4, a Cinema social network.
Researchers have used other datasets such as the fa-
mous Netflix. Unfortunately, the latter does not in-
clude textual reviews. It is therefore strictly impos-
sible to experiment a SRS on such a dataset.
</bodyText>
<subsectionHeader confidence="0.995952">
5.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999616">
The corpus has been extracted from Vodkaster’s
database. Users post micro-reviews (MR) to ex-
press their opinion on a movie and rate it, within a
</bodyText>
<footnote confidence="0.999721">
3Details on metrics are given in the supplementary material.
4www.vodkaster.com
</footnote>
<page confidence="0.994765">
1945
</page>
<bodyText confidence="0.9976529">
feature without any loss of perfomances with
respect to any others RS methods that we know of.
140 characters Twitter-like length limit. We divided
the corpus into three parts, chronologically sorted:
training (Tr), development (D) and test (T). Note that
in our experiments, the date is taken into account
since we also work on dynamic adaptation.
In Table 2, we set a constant coverage (2000 pre-
dictions) in order to be able to compare results ob-
tained with different methods.
</bodyText>
<table confidence="0.99921725">
Tr D Tr+D T
Size 55486 9892 65378 9729
Nb of Films 8414 3184 9130 3877
Nb of Users 1627 675 1855 706
</table>
<tableCaption confidence="0.999942">
Table 1: Statistics on the corpus
</tableCaption>
<subsectionHeader confidence="0.863753">
5.2 Results
</subsectionHeader>
<bodyText confidence="0.8590288">
Figure 1 compares four different methods: the
classical Pearson (PEA) method that does not
allow quick adaptation, the MWC method with and
without quick adaptation MNA and ours (WBS).
Within the confidence interval, in terms of accuracy,
</bodyText>
<table confidence="0.997538222222222">
Corp. Met. RMSE MAE %Acc. CI
D PEA 0.99 0.76 86.41 1.49
E MNA 0.93 0.72 90.75 1.26
V MWC 0.89 0.69 92.95 1.12
WBS 0.89 0.70 92.45 1.16
T PEA 1.01 0.78 86.02 1.51
E MNA 0.98 0.75 90.04 1.30
S MWC 0.92 0.71 91.46 1.22
T WBS 0.94 0.72 91.15 1.24
</table>
<tableCaption confidence="0.996191">
Table 2: Results with Pearson (PEA), MWC, MWC with-
out Adaptation (MNA), WBS. CI is the radius confidence
interval estimated in % on accuracy (Acc.).
</tableCaption>
<figure confidence="0.6010805">
Accuracy as a function of Coverage on DEV
Coverage
</figure>
<figureCaption confidence="0.9979495">
Figure 1: Evolution of accuracy as a function of coverage
for PEA, MWC and WBS methods on D corpus.
</figureCaption>
<bodyText confidence="0.9736596875">
the same performances are obtained by MWC and
WBS. Both outperform5 PEA and MNA. Our word
based approach is thus able to offer the arguments
5Note that the key point here is the comparison of results ob-
tained with the baseline and with the method we propose. Both
of them have been evaluated with the same protocol: RMSE is
computed with respect to rating predictions above some empir-
ical threshold as done in (Gaillard et al., 2013).
MNA (MWC without adaptation) being better
and more easily updated than Pearson (PEA), we
have decided to use the adaptive framework only for
MWC. Moreover, for Pearson dynamic adaptation,
the updating algorithm complexity is increased by
one degree.
We want to point out that the results are the same for
both MWC and WBS methods, within a confidence
interval (CI) radius of 1.16%. From a qualitative
point of view, these results can be seen as an
assessment of our approach based on words.
Example of outputs: The movie Apocalypse
Now is recommended to user Theo6 with a rating
prediction equal to 4.3. Why he might like: some
brillant moments (0.99), among the major master-
piece (0.91), Vietnam’s hell (0.8); dislike: did not
understand everything but... (0.71).
The data we have does not contain the informa-
tion on the reaction of the user to the recommen-
dation. In particular, we do not know if the textual
argumentation would have been sufficient for con-
vincing Theo6 to see the film. But we know that
after seeing it, he put a good rating (4.5/5) on this
movie.
</bodyText>
<figure confidence="0.967657857142857">
800 1000 1200 1400 1600 1800 2000
Accuracy
0.86 0.88 0.90 0.92 0.94 0.96
WBS
MWC
MNA
PEA
</figure>
<page confidence="0.959768">
1946
</page>
<sectionHeader confidence="0.959784" genericHeader="conclusions">
6 Conclusion and perspectives
</sectionHeader>
<bodyText confidence="0.9999389">
We have presented an innovative proposal for de-
signing a domain-independent SRS relying on a
word based similarity function (WBS), providing
textually well-argued recommendations to users.
Moreover, this system has been developed in a dy-
namic and adaptive framework. This might be the
first step really made towards an anthromorphic and
evolutive recommender. As future work, we plan to
evaluate how the quality is impacted by the time di-
mension (adaptation delay, cache reset,etc.).
</bodyText>
<sectionHeader confidence="0.914725" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.999772666666667">
The authors would like to thank Vodkaster for pro-
viding the data.
This work has been partly supported by the Eu-
ropean Commission within the framework of the
CONGAS Project (FP7- ICT-2011-8-317672), see
www.congas-project.eu.
</bodyText>
<sectionHeader confidence="0.998689" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99981997826087">
R. Bell, Y. Koren and C. Volinsky. 2007. The BellKor
2008 Solution to the Netflix Prize. The Netflix Prize.
R. Burke. 2007. Hybrid Web Recommender Systems.
The Adaptive Web, 377–408.
V. Codina and Luigi Ceccaroni. 2010. Taking Advan-
tage of Semantics in Recommendation Systems. Pro-
ceedings of the 13th International Conference of the
Catalan Association for A.I.,163–172
M. Deshpande and G. Karypis. 2004. Item based top-
N recommendation algorithms. ACM Transactions on
Information and System Security.
J. Gaillard, M. El-Beze, E. Altman and E. Ethis. 2013.
Flash reactivity: adaptive models in recommender
systems. International Conference on Data Mining
(DMIN), WORLDCOMP.
J. Herlocker, J.A Konstan, L. Terveen and J. Riedl. 2004.
Evaluating collaborative filtering recommender sys-
tems. ACM Transactions on Information Systems
(TOIS).
V. Maidel, P. Shoval, B. Shapira, M. Taieb-Maimon.
2008. Evaluation of an ontology-content based filter-
ing method for a personalized newspaper. RecSys’08:
Proceedings, 91–98.
B. Mehta, T. Hofmann, and W. Nejdl. 2008. Robust col-
laborative filtering. In RecSys
F. Meyer. 2012. Recommender systems in industrial con-
texts. PhD thesis, University of Grenoble, France.
P. Resnick and R. Varian Hal. 1997. Recommender sys-
tems (introduction to special section.) Communica-
tions of the ACM
B.M Sarwar, J.A Konstan, A. Borchers,J. Herlocker, B.
Miller, J. Riedl 1998. Using filtering agents to im-
prove prediction quality in the groupLens research
collaborative filtering system. Proceedings of the
ACM Conference on Computer Supported Coopera-
tive Work
A.I Schein, A. Popescul and L.H Ungar. 2002. Methods
and metrics for cold-start recommendations. ACM SI-
GIR Conference on Research and Development in In-
formation Retrieval.
P. Tan, M. Steinbach and V. Kumar. 2005 Introduction
to Data Mining. Addison-Wesley, 500–524.
C. Ziegler, S.M McNee, J.A Konstan and G. Lausen.
2005. Improving recommendation lists through topic
diversification. Fourteenth International World Wide
Web Conference
</reference>
<page confidence="0.995277">
1947
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.336146">
<title confidence="0.942821">Well-argued recommendation: adaptive models based on words in recommender systems</title>
<author confidence="0.994207">Julien</author>
<affiliation confidence="0.999853">University of</affiliation>
<address confidence="0.969533">Avignon, France</address>
<email confidence="0.996124">julien.gaillard@univ-avignon.fr</email>
<author confidence="0.977206">Marc</author>
<affiliation confidence="0.9998">University of</affiliation>
<address confidence="0.854488">Avignon, France</address>
<email confidence="0.987873">marc.elbeze@univ-avignon.fr</email>
<author confidence="0.587073">Eitan</author>
<affiliation confidence="0.984392">INRIA Sophia</affiliation>
<address confidence="0.971503">Sophia-Antipolis, France</address>
<email confidence="0.996955">eitan.altman@inria.fr</email>
<author confidence="0.877465">Emmanuel</author>
<affiliation confidence="0.999824">University of</affiliation>
<address confidence="0.959177">Avignon, France</address>
<email confidence="0.998769">emmanuel.ethis@univ-avignon.fr</email>
<abstract confidence="0.999620444444445">Recommendation systems (RS) take advantage of products and users information in order to propose items to consumers. Collaborative, content-based and a few hybrid RS have been developed in the past. In contrast, we propose a new domain-independent semantic RS. By providing textually well-argued recommendations, we aim to give more responsibility to the end user in his decision. The system includes a new similarity measure keeping up both the accuracy of rating predictions and coverage. We propose an innovative way to apply a fast adaptation scheme at a semantic level, providing recommendations and arguments in phase with the very recent past. We have performed several experiments on films data, providing textually well-argued recommendations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Bell</author>
<author>Y Koren</author>
<author>C Volinsky</author>
</authors>
<title>The BellKor</title>
<date>2007</date>
<contexts>
<context position="10865" citStr="Bell et al., 2007" startWordPosition="1836" endWordPosition="1839">riteria We present here the evaluation protocol we designed. It should be noted that we are not able to make online experiments. Therefore, we can not measure the feedback on our recommendations. However, the cornerstone of recommender system is the accuracy of rating predictions (Herlocker et al., 2004). From this point of view, one could argue that the quality of a recommender engine could be assessed by its capacity to predict ratings. It is thus possible to evaluate our system comparing the prediction ˆru,i for a given pair (u, i), with the actual real rating ru,i. The classical metrics3 (Bell et al., 2007) Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) will be used to evaluate our RS. Last but not least, we make the following assumption: if WBS results are as good as MWC’s, the words presented by the system to users as arguments are likely to be relevant. 5 Experiments This work has been carried out in partnership with the website Vodkaster 4, a Cinema social network. Researchers have used other datasets such as the famous Netflix. Unfortunately, the latter does not include textual reviews. It is therefore strictly impossible to experiment a SRS on such a dataset. 5.1 Corpus The co</context>
</contexts>
<marker>Bell, Koren, Volinsky, 2007</marker>
<rawString>R. Bell, Y. Koren and C. Volinsky. 2007. The BellKor 2008 Solution to the Netflix Prize. The Netflix Prize.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Burke</author>
</authors>
<title>Hybrid Web Recommender Systems. The Adaptive Web,</title>
<date>2007</date>
<pages>377--408</pages>
<contexts>
<context position="3676" citStr="Burke, 2007" startWordPosition="564" endWordPosition="565">efine the associated methods in section 3. We describe the evaluation protocol and how we have performed some experiments in section 4. Finally we report results including a comparison to a baseline in section 5. 2 Related work and choice of a baseline We present here some methods used in the literature. Collaborative Filtering (CF) systems use logs 1943 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1943–1947, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics of users, generally user ratings on items (Burke, 2007; Sarwar et al., 1998). In these systems, the following assumption is made: if user a and user b rate n items similarly, they will rate other items in the same way (Deshpande and Karypis., 2004). This technique has many well-known issues such as the “cold start” problem, i.e when new items or users appear, it is impossible to make a recommendation, due to the absence of rating data (Schein et al., 2002). Other limitations of RS are sparsity, scalability, overspecialization and domain-dependency problems. In Content Based Filtering (CBF) systems, users are supposed to be independent (Mehta et a</context>
</contexts>
<marker>Burke, 2007</marker>
<rawString>R. Burke. 2007. Hybrid Web Recommender Systems. The Adaptive Web, 377–408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Codina</author>
<author>Luigi Ceccaroni</author>
</authors>
<title>Taking Advantage of Semantics in Recommendation Systems.</title>
<date>2010</date>
<booktitle>Proceedings of the 13th International Conference of the Catalan Association for A.I.,163–172</booktitle>
<contexts>
<context position="4829" citStr="Codina and Ceccaroni (2010)" startWordPosition="743" endWordPosition="747"> Filtering (CBF) systems, users are supposed to be independent (Mehta et al., 2008). Hence for a given user, recommendations rely only on items he previously rated. Some RS incorporate semantic knowledge to improve quality. Generally, they apply a conceptbased approach to enhance the user modeling stage and employ standard vocabularies and ontology resources. For instance, ePaper (scientific-paper recommender), computes the matching between the concepts constituting user interests and the concepts describing an item by using hierarchical relationships of domain concepts (Maidel et al., 2008). Codina and Ceccaroni (2010) propose to take advantage of semantics by using an interest-prediction method based on user ratings and browsing events. However, none of them are actually based on the user opinion as it is expressed in natural language. 2.1 Similarity measures Similarity measures are the keystone of RS (Herlocker et al., 2005). Resnick (1997) was one of the first to introduce the Pearson correlation coefficient to derive a similarity measure between two entities. Other similarity measures such as Jaccard and Cosine have been proposed (Meyer, 2012). Let Su be the set of items rated by u, Ti the set of users </context>
</contexts>
<marker>Codina, Ceccaroni, 2010</marker>
<rawString>V. Codina and Luigi Ceccaroni. 2010. Taking Advantage of Semantics in Recommendation Systems. Proceedings of the 13th International Conference of the Catalan Association for A.I.,163–172</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Deshpande</author>
<author>G Karypis</author>
</authors>
<title>Item based topN recommendation algorithms.</title>
<date>2004</date>
<journal>ACM Transactions on Information and System Security.</journal>
<marker>Deshpande, Karypis, 2004</marker>
<rawString>M. Deshpande and G. Karypis. 2004. Item based topN recommendation algorithms. ACM Transactions on Information and System Security.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Gaillard</author>
<author>M El-Beze</author>
<author>E Altman</author>
<author>E Ethis</author>
</authors>
<title>Flash reactivity: adaptive models in recommender systems.</title>
<date>2013</date>
<booktitle>International Conference on Data Mining (DMIN), WORLDCOMP.</booktitle>
<contexts>
<context position="2755" citStr="Gaillard et al., 2013" startWordPosition="412" endWordPosition="415"> in a continuous way, as each new review is posted. In doing so, the system will be perceived as less intrusive thanks to well-chosen words and its failures will be smoothed over. It is therefore necessary to design a new generation of RS providing textually well-argued recommendations. This way, the end user will have more elements to make a wellinformed choice. Moreover, the system parameters have to be dynamically and continuously updated, in order to provide recommendations and arguments in phase with the very recent past. To do so, we have adapted the algorithms we described in Gaillard (Gaillard et al., 2013), by including a semantic level, i.e words, terms and phrases as they are naturally expressed in reviews. This paper is structured as follows. In the next section, we present the state of the art in recommendation systems and introduce some of the improvements we have made. Then, we present our approach and define the associated methods in section 3. We describe the evaluation protocol and how we have performed some experiments in section 4. Finally we report results including a comparison to a baseline in section 5. 2 Related work and choice of a baseline We present here some methods used in </context>
<context position="5727" citStr="Gaillard et al., 2013" startWordPosition="902" endWordPosition="905">eystone of RS (Herlocker et al., 2005). Resnick (1997) was one of the first to introduce the Pearson correlation coefficient to derive a similarity measure between two entities. Other similarity measures such as Jaccard and Cosine have been proposed (Meyer, 2012). Let Su be the set of items rated by u, Ti the set of users who have rated item i, ru,i the rating of user u on item i and rx the mean of x (user or item). PEA(i,j) stands for the Pearson similarity between items i and j and is computed as follows: ∑ u∈Ti∩Tj(ru,i − ri)(ru,j − rj) (1) Corrected similarity (MWC), that we introduced in (Gaillard et al., 2013), will be used as a point of comparison as well1. Again, for none of them, textual content is taken into account. 2.2 Rating prediction Let i be a given item and u a given user. We suppose the pair (u, i) is unique. Indeed, most of social networks do not allow multiple ratings by the same user for one item. In this framework, two rating prediction methods have to be defined: one user oriented and the other item oriented. Sim stands for some similarity function in the following formula. ∑vETz Sim(u, v) x rv,i rating(u, i) 2 - &apos;VETi I Sim(u, v) I ( ) A symmetrical formula for items rating(i, u) </context>
<context position="8444" citStr="Gaillard et al., 2013" startWordPosition="1400" endWordPosition="1403">we define a weight function Fw, mixing the well-known Inverse Document Frequency IDF(w) with the variance σ2w. Common words and words w associated with very heterogenous ratings Rw,x (i.e a high variance) will have a smaller weight in the similarity. Nw is the number of items in which the word w appears. Ntot is the total number of items. D is the maximum difference between two ratings. Note that Fw has to be updated at each iteration. ( Nw/ 1 Fw = −log J × 2 (4) Ntot σw ∑ w�Vx�V�(D − |rw,x − rw,y|)Fw WBS(x, y) = D × |Vx ∩ Vy |∑ w�Vx�V� Fw (5) 3.2 Adaptation An adaptive framework proposed in (Gaillard et al., 2013) allows the system to have a dynamic adaptation along time, overcoming most of the drawbacks due to the cold-start. The authors have designed a dynamic process following the principle that every update (u, i) needs to be instantly taken into account by the system. Consequently, we have to update the σ2w and IDF(w) at each iteration, for every word. Paying attention to avoid a whole re-estimation of these two variables, we derived an iterative relation for the two of them2. We thus reduced the complexity by one degree, keeping our system very wellfitted to dynamic adaptation. 3.3 Textual recomm</context>
<context position="13529" citStr="Gaillard et al., 2013" startWordPosition="2308" endWordPosition="2311">al estimated in % on accuracy (Acc.). Accuracy as a function of Coverage on DEV Coverage Figure 1: Evolution of accuracy as a function of coverage for PEA, MWC and WBS methods on D corpus. the same performances are obtained by MWC and WBS. Both outperform5 PEA and MNA. Our word based approach is thus able to offer the arguments 5Note that the key point here is the comparison of results obtained with the baseline and with the method we propose. Both of them have been evaluated with the same protocol: RMSE is computed with respect to rating predictions above some empirical threshold as done in (Gaillard et al., 2013). MNA (MWC without adaptation) being better and more easily updated than Pearson (PEA), we have decided to use the adaptive framework only for MWC. Moreover, for Pearson dynamic adaptation, the updating algorithm complexity is increased by one degree. We want to point out that the results are the same for both MWC and WBS methods, within a confidence interval (CI) radius of 1.16%. From a qualitative point of view, these results can be seen as an assessment of our approach based on words. Example of outputs: The movie Apocalypse Now is recommended to user Theo6 with a rating prediction equal to</context>
</contexts>
<marker>Gaillard, El-Beze, Altman, Ethis, 2013</marker>
<rawString>J. Gaillard, M. El-Beze, E. Altman and E. Ethis. 2013. Flash reactivity: adaptive models in recommender systems. International Conference on Data Mining (DMIN), WORLDCOMP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Herlocker</author>
<author>J A Konstan</author>
<author>L Terveen</author>
<author>J Riedl</author>
</authors>
<title>Evaluating collaborative filtering recommender systems.</title>
<date>2004</date>
<journal>ACM Transactions on Information Systems (TOIS).</journal>
<contexts>
<context position="10552" citStr="Herlocker et al., 2004" startWordPosition="1779" endWordPosition="1782">b-sets Pw and Nw. Pw contains what user u is probably going to like in i and Nw what u may dislike. Finally, we provide the most relevant arguments contained in both Pw and Nw, and each of them is given in the context they have been used for item i. As an example, some outputs are shown in section 5.2. 4 Evaluation criteria We present here the evaluation protocol we designed. It should be noted that we are not able to make online experiments. Therefore, we can not measure the feedback on our recommendations. However, the cornerstone of recommender system is the accuracy of rating predictions (Herlocker et al., 2004). From this point of view, one could argue that the quality of a recommender engine could be assessed by its capacity to predict ratings. It is thus possible to evaluate our system comparing the prediction ˆru,i for a given pair (u, i), with the actual real rating ru,i. The classical metrics3 (Bell et al., 2007) Root Mean Square Error (RMSE) and Mean Absolute Error (MAE) will be used to evaluate our RS. Last but not least, we make the following assumption: if WBS results are as good as MWC’s, the words presented by the system to users as arguments are likely to be relevant. 5 Experiments This </context>
</contexts>
<marker>Herlocker, Konstan, Terveen, Riedl, 2004</marker>
<rawString>J. Herlocker, J.A Konstan, L. Terveen and J. Riedl. 2004. Evaluating collaborative filtering recommender systems. ACM Transactions on Information Systems (TOIS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Maidel</author>
<author>P Shoval</author>
<author>B Shapira</author>
<author>M Taieb-Maimon</author>
</authors>
<title>Evaluation of an ontology-content based filtering method for a personalized newspaper.</title>
<date>2008</date>
<booktitle>RecSys’08: Proceedings,</booktitle>
<pages>91--98</pages>
<contexts>
<context position="4800" citStr="Maidel et al., 2008" startWordPosition="739" endWordPosition="742">lems. In Content Based Filtering (CBF) systems, users are supposed to be independent (Mehta et al., 2008). Hence for a given user, recommendations rely only on items he previously rated. Some RS incorporate semantic knowledge to improve quality. Generally, they apply a conceptbased approach to enhance the user modeling stage and employ standard vocabularies and ontology resources. For instance, ePaper (scientific-paper recommender), computes the matching between the concepts constituting user interests and the concepts describing an item by using hierarchical relationships of domain concepts (Maidel et al., 2008). Codina and Ceccaroni (2010) propose to take advantage of semantics by using an interest-prediction method based on user ratings and browsing events. However, none of them are actually based on the user opinion as it is expressed in natural language. 2.1 Similarity measures Similarity measures are the keystone of RS (Herlocker et al., 2005). Resnick (1997) was one of the first to introduce the Pearson correlation coefficient to derive a similarity measure between two entities. Other similarity measures such as Jaccard and Cosine have been proposed (Meyer, 2012). Let Su be the set of items rat</context>
</contexts>
<marker>Maidel, Shoval, Shapira, Taieb-Maimon, 2008</marker>
<rawString>V. Maidel, P. Shoval, B. Shapira, M. Taieb-Maimon. 2008. Evaluation of an ontology-content based filtering method for a personalized newspaper. RecSys’08: Proceedings, 91–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Mehta</author>
<author>T Hofmann</author>
<author>W Nejdl</author>
</authors>
<title>Robust collaborative filtering.</title>
<date>2008</date>
<booktitle>In RecSys</booktitle>
<contexts>
<context position="4285" citStr="Mehta et al., 2008" startWordPosition="663" endWordPosition="666">urke, 2007; Sarwar et al., 1998). In these systems, the following assumption is made: if user a and user b rate n items similarly, they will rate other items in the same way (Deshpande and Karypis., 2004). This technique has many well-known issues such as the “cold start” problem, i.e when new items or users appear, it is impossible to make a recommendation, due to the absence of rating data (Schein et al., 2002). Other limitations of RS are sparsity, scalability, overspecialization and domain-dependency problems. In Content Based Filtering (CBF) systems, users are supposed to be independent (Mehta et al., 2008). Hence for a given user, recommendations rely only on items he previously rated. Some RS incorporate semantic knowledge to improve quality. Generally, they apply a conceptbased approach to enhance the user modeling stage and employ standard vocabularies and ontology resources. For instance, ePaper (scientific-paper recommender), computes the matching between the concepts constituting user interests and the concepts describing an item by using hierarchical relationships of domain concepts (Maidel et al., 2008). Codina and Ceccaroni (2010) propose to take advantage of semantics by using an inte</context>
</contexts>
<marker>Mehta, Hofmann, Nejdl, 2008</marker>
<rawString>B. Mehta, T. Hofmann, and W. Nejdl. 2008. Robust collaborative filtering. In RecSys</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Meyer</author>
</authors>
<title>Recommender systems in industrial contexts.</title>
<date>2012</date>
<tech>PhD thesis,</tech>
<institution>University of Grenoble,</institution>
<contexts>
<context position="5368" citStr="Meyer, 2012" startWordPosition="832" endWordPosition="833">ips of domain concepts (Maidel et al., 2008). Codina and Ceccaroni (2010) propose to take advantage of semantics by using an interest-prediction method based on user ratings and browsing events. However, none of them are actually based on the user opinion as it is expressed in natural language. 2.1 Similarity measures Similarity measures are the keystone of RS (Herlocker et al., 2005). Resnick (1997) was one of the first to introduce the Pearson correlation coefficient to derive a similarity measure between two entities. Other similarity measures such as Jaccard and Cosine have been proposed (Meyer, 2012). Let Su be the set of items rated by u, Ti the set of users who have rated item i, ru,i the rating of user u on item i and rx the mean of x (user or item). PEA(i,j) stands for the Pearson similarity between items i and j and is computed as follows: ∑ u∈Ti∩Tj(ru,i − ri)(ru,j − rj) (1) Corrected similarity (MWC), that we introduced in (Gaillard et al., 2013), will be used as a point of comparison as well1. Again, for none of them, textual content is taken into account. 2.2 Rating prediction Let i be a given item and u a given user. We suppose the pair (u, i) is unique. Indeed, most of social ne</context>
</contexts>
<marker>Meyer, 2012</marker>
<rawString>F. Meyer. 2012. Recommender systems in industrial contexts. PhD thesis, University of Grenoble, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnick</author>
<author>R Varian Hal</author>
</authors>
<title>Recommender systems (introduction to special section.)</title>
<date>1997</date>
<journal>Communications of the ACM</journal>
<marker>Resnick, Hal, 1997</marker>
<rawString>P. Resnick and R. Varian Hal. 1997. Recommender systems (introduction to special section.) Communications of the ACM</rawString>
</citation>
<citation valid="true">
<authors>
<author>B M Sarwar</author>
<author>J A Konstan</author>
<author>A Borchers</author>
<author>J Herlocker</author>
<author>B Miller</author>
<author>J Riedl</author>
</authors>
<title>Using filtering agents to improve prediction quality in the groupLens research collaborative filtering system.</title>
<date>1998</date>
<booktitle>Proceedings of the ACM Conference on Computer Supported Cooperative Work</booktitle>
<contexts>
<context position="3698" citStr="Sarwar et al., 1998" startWordPosition="566" endWordPosition="569">ociated methods in section 3. We describe the evaluation protocol and how we have performed some experiments in section 4. Finally we report results including a comparison to a baseline in section 5. 2 Related work and choice of a baseline We present here some methods used in the literature. Collaborative Filtering (CF) systems use logs 1943 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1943–1947, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics of users, generally user ratings on items (Burke, 2007; Sarwar et al., 1998). In these systems, the following assumption is made: if user a and user b rate n items similarly, they will rate other items in the same way (Deshpande and Karypis., 2004). This technique has many well-known issues such as the “cold start” problem, i.e when new items or users appear, it is impossible to make a recommendation, due to the absence of rating data (Schein et al., 2002). Other limitations of RS are sparsity, scalability, overspecialization and domain-dependency problems. In Content Based Filtering (CBF) systems, users are supposed to be independent (Mehta et al., 2008). Hence for a</context>
</contexts>
<marker>Sarwar, Konstan, Borchers, Herlocker, Miller, Riedl, 1998</marker>
<rawString>B.M Sarwar, J.A Konstan, A. Borchers,J. Herlocker, B. Miller, J. Riedl 1998. Using filtering agents to improve prediction quality in the groupLens research collaborative filtering system. Proceedings of the ACM Conference on Computer Supported Cooperative Work</rawString>
</citation>
<citation valid="true">
<authors>
<author>A I Schein</author>
<author>A Popescul</author>
<author>L H Ungar</author>
</authors>
<title>Methods and metrics for cold-start recommendations.</title>
<date>2002</date>
<booktitle>ACM SIGIR Conference on Research and Development in Information Retrieval.</booktitle>
<contexts>
<context position="4082" citStr="Schein et al., 2002" startWordPosition="635" endWordPosition="638">pirical Methods in Natural Language Processing, pages 1943–1947, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics of users, generally user ratings on items (Burke, 2007; Sarwar et al., 1998). In these systems, the following assumption is made: if user a and user b rate n items similarly, they will rate other items in the same way (Deshpande and Karypis., 2004). This technique has many well-known issues such as the “cold start” problem, i.e when new items or users appear, it is impossible to make a recommendation, due to the absence of rating data (Schein et al., 2002). Other limitations of RS are sparsity, scalability, overspecialization and domain-dependency problems. In Content Based Filtering (CBF) systems, users are supposed to be independent (Mehta et al., 2008). Hence for a given user, recommendations rely only on items he previously rated. Some RS incorporate semantic knowledge to improve quality. Generally, they apply a conceptbased approach to enhance the user modeling stage and employ standard vocabularies and ontology resources. For instance, ePaper (scientific-paper recommender), computes the matching between the concepts constituting user inte</context>
</contexts>
<marker>Schein, Popescul, Ungar, 2002</marker>
<rawString>A.I Schein, A. Popescul and L.H Ungar. 2002. Methods and metrics for cold-start recommendations. ACM SIGIR Conference on Research and Development in Information Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Tan</author>
<author>M Steinbach</author>
<author>V Kumar</author>
</authors>
<title>Introduction to Data Mining.</title>
<date>2005</date>
<pages>500--524</pages>
<publisher>Addison-Wesley,</publisher>
<contexts>
<context position="6665" citStr="Tan et al., 2005" startWordPosition="1076" endWordPosition="1079">ework, two rating prediction methods have to be defined: one user oriented and the other item oriented. Sim stands for some similarity function in the following formula. ∑vETz Sim(u, v) x rv,i rating(u, i) 2 - &apos;VETi I Sim(u, v) I ( ) A symmetrical formula for items rating(i, u) is derived from and combined with (2). ˆru,i = βxrating(u, i)+(1−β)xrating(i, u) (3) 3 Methods In this section, we describe the methods we have used and propose some of the enhancements we have elaborated in our system. In formula (2), Sim can be replaced by several similarity such as Pearson, Cosine or MWC similarity (Tan et al., 2005). All these methods provide a measurement of the likeness between two objects. We then conclude if two users (or items) are ”alike” or not. One has to define what “alike“ should mean in this case. If two users rate the same movies with equals ratings, then these similarities will be maximal. However, they may have rated identically but for completely different reasons, making them not alike at all. Moreover, none of these similarity measures can express why two users or items are similar. This is due to the fact that they rely on ratings only. 3.1 New similarity based on words We propose a new</context>
</contexts>
<marker>Tan, Steinbach, Kumar, 2005</marker>
<rawString>P. Tan, M. Steinbach and V. Kumar. 2005 Introduction to Data Mining. Addison-Wesley, 500–524.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Ziegler</author>
<author>S M McNee</author>
<author>J A Konstan</author>
<author>G Lausen</author>
</authors>
<title>Improving recommendation lists through topic diversification.</title>
<date>2005</date>
<booktitle>Fourteenth International World Wide Web Conference</booktitle>
<marker>Ziegler, McNee, Konstan, Lausen, 2005</marker>
<rawString>C. Ziegler, S.M McNee, J.A Konstan and G. Lausen. 2005. Improving recommendation lists through topic diversification. Fourteenth International World Wide Web Conference</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>