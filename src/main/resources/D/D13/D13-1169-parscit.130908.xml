<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000644">
<title confidence="0.86393">
Deriving adjectival scales from continuous space word representations
</title>
<author confidence="0.547776">
Marie-Catherine de Marneffe
</author>
<affiliation confidence="0.90573">
Department of Linguistics
The Ohio State University
</affiliation>
<address confidence="0.68536">
Columbus, OH 43210, USA
</address>
<email confidence="0.994631">
mcdm@ling.ohio-state.edu
</email>
<author confidence="0.9929">
Joo-Kyung Kim
</author>
<affiliation confidence="0.9952175">
Department of Computer Science and Engineering
The Ohio State University
</affiliation>
<address confidence="0.76613">
Columbus, OH 43210, USA
</address>
<email confidence="0.999369">
kimjook@cse.ohio-state.edu
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9995859">
Continuous space word representations ex-
tracted from neural network language mod-
els have been used effectively for natural lan-
guage processing, but until recently it was not
clear whether the spatial relationships of such
representations were interpretable. Mikolov
et al. (2013) show that these representations
do capture syntactic and semantic regularities.
Here, we push the interpretation of continuous
space word representations further by demon-
strating that vector offsets can be used to de-
rive adjectival scales (e.g., okay &lt; good &lt; ex-
cellent). We evaluate the scales on the indirect
answers to yes/no questions corpus (de Marn-
effe et al., 2010). We obtain 72.8% accuracy,
which outperforms previous results (-60%)
on this corpus and highlights the quality of the
scales extracted, providing further support that
the continuous space word representations are
meaningful.
</bodyText>
<sectionHeader confidence="0.999136" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998809317073171">
There has recently been a surge of interest for deep
learning in natural language processing. In particu-
lar, neural network language models (NNLMs) have
been used to learn distributional word vectors (Ben-
gio et al., 2003; Schwenk, 2007; Mikolov et al.,
2010): the models jointly learn an embedding of
words into an n-dimensional feature space. One of
the advantages put forth for such distributed rep-
resentations compared to traditional n-gram mod-
els is that similar words are likely to have similar
vector representations in a continuous space model,
whereas the discrete units of an n-gram model do
not exhibit any inherent relation with one another.
It has been shown that the continuous space repre-
sentations improve performance in a variety of NLP
tasks, such as POS tagging, semantic role labeling,
named entity resolution, parsing (Collobert and We-
ston, 2008; Turian et al., 2010; Huang et al., 2012).
Mikolov et al. (2013) show that there are some
syntactic and semantic regularities in the word rep-
resentations learned, such as the singular/plural rela-
tion (the difference of singular and plural word vec-
tors are equivalent: apple − apples ≈ car − cars ≈
family − families) or the gender relation (a mascu-
line noun can be transformed into the feminine form:
king − man + woman ≈ queen).
We extend Mikolov et al. (2013)’s approach and
explore further the interpretation of the vector space.
We show that the word vectors learned by NNLMs
are meaningful: we can extract scalar relationships
between adjectives (e.g., bad &lt; okay &lt; good &lt; ex-
cellent), which can not only serve to build a senti-
ment lexicon but also be used for inference. To eval-
uate the quality of the scalar relationships learned
by NNLMs, we use the indirect yes/no question an-
swer pairs (IQAP) from (de Marneffe et al., 2010),
where scales between adjectives are needed to infer
a yes/no answer from a reply without explicit yes or
no such as Was the movie good? It was excellent.
Our method reaches 72.8% accuracy, which is the
best result reported so far when scales are used.
</bodyText>
<sectionHeader confidence="0.995119" genericHeader="method">
2 Previous work
</sectionHeader>
<bodyText confidence="0.999468666666667">
We use the continuous word representations from
(Mikolov et al., 2011), extracted from a recurrent
neural network language model (RNNLM), whose
</bodyText>
<page confidence="0.881512">
1625
</page>
<bodyText confidence="0.376661">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1625–1630,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</bodyText>
<equation confidence="0.320987">
three-layer architecture is represented in Figure 1.
w(t)
</equation>
<figureCaption confidence="0.999911">
Figure 1: The architecture of the RNNLM.
</figureCaption>
<bodyText confidence="0.999417484848485">
In the input layer, w(t) is the input word repre-
sented by 1-of-N coding at time t when the vocabu-
lary size is N. When there are M nodes in the hid-
den layer, the number of connections between the
input layer and the hidden layer is NM and the con-
nections can be represented by a matrix U.
The hidden layer is also connected recurrently to
the context s(t − 1) at time t − 1 (s(0) is initial-
ized with small values like 0.1). The connections
between the previous context and the hidden layer
are represented by a matrix W. The dimension-
ality of the word representations is controlled by
the size of W. The output of the hidden layer is
s(t) = f(Uw(t) + Ws(t − 1)), where f is a sig-
moid function.
Because the inputs of the hidden layer consist of
the word w(t) and the previous hidden layer output
s(t − 1), the current context of the RNN is influ-
enced by the current word and the previous context.
Therefore, we can regard that the continuous repre-
sentations from the RNNLM exploit the context im-
plicitly considering the word sequence information
(Mikolov et al., 2010).
V is a N by M matrix representing the connec-
tions between the hidden layer and the output layer.
The final output is y(t) = g(Vs(t)), where g is a
softmax function to represent the probability distri-
bution over all the words in the vocabulary.
When the RNN is trained by the back propagation
algorithm, we can regard the ith column vector of U
as the continuous representation of the ith word in
the vocabulary since the column was adjusted corre-
spondingly to the ith element of w(t). Because the
s(t) outputs of two input words will be similar when
they have similar s(t − 1) values, the corresponding
column vectors of the words will also be similar.
Mikolov et al. (2013) showed that constant vector
offsets of word pairs can represent linguistic regu-
larities. Let wa and wb denote the vectors for the
words a and b, respectively. Then the vector offset
of the word pair is wa − wb. If a and b are syn-
tactically or semantically related, the vector offset
can be interpreted as a transformation of the syn-
tactic form or the meaning. The offset can also be
added to another word vector c. The word vector
nearest to wa − wb + w, would be related to word c
with the syntactic or semantic difference as the dif-
ference between a and b, as it is the case for the
king, man, and woman example, where king − man
+ woman would approximately represent king with
feminine gender (i.e., queen). They also tried to use
the continuous representations generated by Latent
Semantic Analysis (LSA) (Landauer et al., 1998).
However, the results using LSA were worse because
LSA is a bag-of-words model, in which it is difficult
to exploit word sequence information as the context.
For all the experiments in this paper, we use the
precomputed word representations generated by the
RNNLM from (Mikolov et al., 2013). Their RNN is
trained with 320M words from the Broadcast News
data (the vocabulary size is 82,390 words), and we
used word vectors with a dimensionality of 1,600
(the highest dimensionality provided).1 We stan-
dardized the dataset so that the mean and the vari-
ance of the representations are 0 and 1, respec-
tively.2
</bodyText>
<sectionHeader confidence="0.895929" genericHeader="method">
3 Deriving adjectival scales
</sectionHeader>
<bodyText confidence="0.984793181818182">
Here we explore further the interpretation of word
vectors. Assuming that the transformation of form
or meaning represented by the vector offset is lin-
ear, an intermediate vector between two word vec-
tors would represent some “middle” form or mean-
ing. For example, given the positive and superlative
forms of an adjective (e.g., good and best), we ex-
pect that the word representation in the middle of
1We also experimented with smaller dimensions, but con-
sistent with the analyses in (Mikolov et al., 2013), the highest
dimensionality gave better results.
</bodyText>
<footnote confidence="0.949737">
2http://www.fit.vutbr.cz/˜imikolov/
rnnlm/word_projections-1600.txt.gz
</footnote>
<figure confidence="0.910908857142857">
y(
s(t
sigmoid
V softmax
s(t-1)
U
W
</figure>
<page confidence="0.87795">
1626
</page>
<table confidence="0.8916356">
Input words Words with highest cosine similarities to the mean vector
good:best better: 0.738 strong: 0.644 normal: 0.619 less: 0.609
bad:worst terrible: 0.726 great: 0.678 horrible: 0.674 worse: 0.665
slow:slowest slower: 0.637 sluggish: 0.614 steady: 0.558 brisk: 0.543
fast:fastest faster: 0.645 slower: 0.602 quicker: 0.542 harder: 0.518
</table>
<tableCaption confidence="0.997451">
Table 1: Words with corresponding vectors closest to the mean of positive:superlative word vectors.
</tableCaption>
<table confidence="0.7188615">
First word (-) 1st quarter Half 3rd quarter Second word (+)
furious 1 angry 0.632 unhappy 0.640 pleased 0.516 happy 1
furious 1 angry 0.615 tense 0.465 quiet 0.560 calm 1
terrible 1 horrible 0.783 incredible 0.714 wonderful 0.772 terrific 1
cold 1 mild 0.348 warm 0.517 sticky 0.424 hot 1
ugly 1 nasty 0.672 wacky 0.645 lovely 0.715 gorgeous 1
</table>
<tableCaption confidence="0.995206">
Table 2: Adjectival scales extracted from the RNN: each row represent a scale, and for each intermediate point the
closest word in term of cosine similarity is given.
</tableCaption>
<bodyText confidence="0.999443151515151">
them will correspond to the comparative form (i.e.,
better). To extract the “middle” word between two
word vectors wa and wb, we take the vector offset
wa−wb divided by 2, and add wb: wb+(wa−wb)/2.
The result corresponds to the midpoint between the
two words. Then, we find the word whose cosine
similarity to the midpoint is the highest.
Table 1 gives some positive:superlative pairs and
the top four closest words to the mean vectors, where
the distance metric is the cosine similarity. The
correct comparative forms (in bold) are quite close
to the mean vector of the positive and superlative
form vectors, highlighting the fact that there is some
meaningful interpretation of the vector space: the
word vectors are constituting a scale.
We can extend this idea of extracting an or-
dering between two words. For any two seman-
tically related adjectives, intermediate vectors ex-
tracted along the line connecting the first and sec-
ond word vectors should exhibit scalar properties, as
seen above for the positive-comparative-superlative
triplets. If we take two antonyms (furious and
happy), words extracted at the intermediate points
x1, x2 and x3 should correspond to words lying on
a scale of happiness (from “less furious” to “more
happy”), as illustrated in Figure 2. Table 2 gives
some adjectival scales that we extracted from the
continuous word space, using antonym pairs. We
picked three points with equal intervals on the line
from the first to the second word (1st quarter, half
and 3rd quarter). The extracted scales look quite
reasonable: the words form a continuum from more
negative to more positive meanings.
</bodyText>
<figureCaption confidence="0.993938">
Figure 2: An example of vectors with the highest cosine
similarity to intermediate points on the line between furi-
ous and happy.
</figureCaption>
<bodyText confidence="0.999010333333333">
Tables 1 and 2 demonstrate that the word vector
space is interpretable: intermediate vectors between
two word vectors represent a semantic continuum.
</bodyText>
<sectionHeader confidence="0.992928" genericHeader="method">
4 Evaluation: Indirect answers to yes/no
questions
</sectionHeader>
<bodyText confidence="0.999911888888889">
To evaluate the quality of the adjective scales learned
by the neural network approach, we use the cor-
pus of indirect answers to yes/no questions created
by (de Marneffe et al., 2010), which consists of
question-answer pairs involving gradable modifiers
to test scalar implicatures. We focus on the 125 pairs
in the corpus where both the question and answer
contain an adjective: e.g., Is Obama qualified? I
think he’s young.3 Each question-answer pair has
</bodyText>
<footnote confidence="0.6596385">
3These 125 pairs correspond to the ‘Other adjective’ cate-
gory in (de Marneffe et al., 2010).
</footnote>
<figure confidence="0.993110125">
angry
x3
b--happy
x2
a--furious
unhappy
pleased
x1
</figure>
<page confidence="0.989134">
1627
</page>
<bodyText confidence="0.9984045">
been annotated via Mechanical Turk for whether the
answer conveys yes, no or uncertain.
</bodyText>
<subsectionHeader confidence="0.996505">
4.1 Method
</subsectionHeader>
<bodyText confidence="0.999931956521739">
The previous section showed that we can draw a line
passing through an adjective and its antonym and
that the words extracted along the line are roughly
semantically ordered. To infer a yes or no answer in
the case of the IQAP corpus, we use the following
approach illustrated with the Obama example above
(Figure 3). Using WordNet 3.1 (Fellbaum, 1998),
we look for an antonym of the adjective in the ques-
tion qualified: unqualified is retrieved. Since the
scales extracted are only roughly ordered, to infer
yes when the question and answer words are very
close, we set the decision boundary perpendicular
to the line connecting the two words and passing
through the midpoint of the line.
Since the answer word is young, we check
whether young is in the area including qualified or
in the other area. We infer a yes answer in the for-
mer case, and a no answer in the latter case. If young
is on the boundary, we infer uncertain. If a sentence
contains a negation (e.g., Are you stressed? I am
not peaceful.), we compute the scale for stressed-
peaceful and then reverse the answer obtained, sim-
ilarly to what is done in (de Marneffe et al., 2010).
</bodyText>
<figureCaption confidence="0.969641">
Figure 3: An example of the decision boundary given
qualified as the question and young as the answer.
</figureCaption>
<bodyText confidence="0.9918469">
Since a word can have multiple senses and differ-
ent antonyms for the senses, it is important to select
the most appropriate antonym to build a more accu-
rate decision boundary. We consider all antonyms
across senses and select the antonym that is most
collinear with the question and the answer. For the
word vectors of the question wQ, the ith antonym
wanti, and the answer wa, we select anti where
argmaxanti|cos(wQ − wa, wQ − wanti)|. Figure 4
schematically shows antonym selection when the
</bodyText>
<footnote confidence="0.985784333333333">
4Antonyms in WordNet can be directly opposed to a given
word or indirectly opposed via other words. When there are
direct antonyms for the question word, we only consider those.
</footnote>
<table confidence="0.999399333333333">
de Marneffe (2010) 60.00 59.72 59.40 59.56
Mohtarami (2011) – 62.23 60.88 61.55
RNN model 72.80 69.78 71.39 70.58
</table>
<tableCaption confidence="0.987465">
Table 3: Score (%) comparison on the 125 scalar adjec-
tive pairs in the IQAP corpus.
</tableCaption>
<bodyText confidence="0.9969676">
question is good and the answer is excellent: bad
and evil are the antonym candidates of good.
Because the absolute cosine similarity of good-
excellent to good-bad is higher than to good-evil, we
choose bad as the antonym in this case.
</bodyText>
<figureCaption confidence="0.990556">
Figure 4: An example of antonym selection.
</figureCaption>
<subsectionHeader confidence="0.848662">
4.2 Results and discussion
</subsectionHeader>
<bodyText confidence="0.999934833333333">
Table 3 compares our results with previous ones
where adjectival scales are considered: de Marn-
effe et al. (2010) propose an unsupervised approach
where scales are learned from distributional infor-
mation in a Web corpus; Mohtarami et al. (2011)’s
model is similar to ours but uses word represen-
tations obtained by LSA and a word sense disam-
biguation system (Zhong and Ng, 2010) to choose
antonyms. To compare with Mohtarami et al.
(2011), we use macro-averaged precision and recall
for yes and no. For the given metrics, our model sig-
nificantly outperforms the previous ones (p &lt; 0.05,
McNemar’s test).
Mohtarami et al. (2011) present higher numbers
obtained by replacing the answer words with their
synonyms in WordNet. However, that approach fails
to capture orderings. Two words of different degree
are often regarded as synonyms: even though furi-
ous means extremely angry, furious and angry are
synonyms in WordNet. Therefore using synonyms,
the system will output the same answer irrespective
of the order in the pair. Mohtarami et al. (2012)
also presented results on the interpretation of indi-
rect questions on the IQAP corpus, but their method
</bodyText>
<figure confidence="0.98972896969697">
bad
good
evil
excellent
qualified
young
unqualified
Macro
Acc P R F1
1628
bad good
sure
terrible confident
20
15
10
5
0
dim 2
-5
happy
delighted
unhappy
young
diffident
qualified
-10
-15
-20
unqualified
25
-20 -15 -10 -5 0 5 10 15 20
dim 1
</figure>
<figureCaption confidence="0.995869">
Figure 5: Question words (bold), their antonyms (italic), and answer words (normal) of four pairs from the IQAP
dataset. The words are visualized by MDS.
</figureCaption>
<bodyText confidence="0.999784166666667">
did not involve learning or using scalar implicatures.
Figure 5 gives a qualitative picture: the question
words, antonyms and answer words for four of the
IQAP pairs are visualized in 2D space by multi-
dimensional scaling (MDS). Note that MDS intro-
duces some distortion in the lower dimensions. Bul-
let markers correspond to words in the same pair.
Question words, antonyms, and answer words are
displayed by bold, italic, and normal fonts, respec-
tively. In the Obama example previously mentioned
(Is Obama qualified? I think he’s young.), the ques-
tion word is qualified and the answer word is young.
In Figure 5, qualified is around (2,-20) while its
antonym unqualified is around (-6,-24). Since young
is around (-7,-8), we infer that young is semanti-
cally closer to unqualified which corroborates with
the Turkers’ intuitions in this case. (1), (2) and (3)
give the other examples displayed in Figure 5.
</bodyText>
<listItem confidence="0.9845725">
(1) A: Do you think she’d be happy with this
book?
B: I think she’d be delighted by it.
(2) A: Do you think that’s a good idea?
B: It’s a terrible idea.
(3) A: The president is promising support for
</listItem>
<bodyText confidence="0.9461335">
Americans who have suffered from this
hurricane. Are you confident you are
going to be getting that?
B: I’m not so sure about my insurance
company.
In (1), delighted is stronger than happy, leading to
a yes answer, whereas in (2), terrible is weaker than
good leading to a no answer. In (3), the presence of
a negation will reverse the answer inferred, leading
to no.
</bodyText>
<sectionHeader confidence="0.998915" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.998087">
In this paper we give further evidence that the rela-
tionships in the continuous vector space learned by
recurrent neural network models are interpretable.
We show that using vector offsets, we can success-
fully learn adjectival scales, which are useful for
scalar implicatures, as demonstrated by the high re-
sults we obtain on the IQAP corpus.
</bodyText>
<sectionHeader confidence="0.996515" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999191333333333">
We thank Eric Fosler-Lussier and the anonymous re-
viewers for their helpful comments on previous ver-
sions of this paper.
</bodyText>
<page confidence="0.994737">
1629
</page>
<sectionHeader confidence="0.990171" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999883050847458">
Yoshua Bengio, R´ejean Ducharme, Pascal Vincent, and
Christian Janvin. 2003. A neural probabilistic lan-
guage model. The Journal of Machine Learning Re-
search, 3:1137–1155.
Ronan Collobert and Jason Weston. 2008. A unified ar-
chitecture for natural language processing: deep neu-
ral networks with multitask learning. In Proceedings
of the 25th international conference on Machine learn-
ing, pages 160–167.
Marie-Catherine de Marneffe, Christopher D. Manning,
and Christopher Potts. 2010. Was it good? It was
provocative. Learning the meaning of scalar adjec-
tives. In Proceedings of the 48th Meeting of the Asso-
ciation for Computational Linguistics, pages 167–176.
Christiane Fellbaum. 1998. WordNet: An electronic lex-
ical database. MIT Press.
Eric H. Huang, Richard Socher, Christopher D. Manning,
and Andrew Y Ng. 2012. Improving word representa-
tions via global context and multiple word prototypes.
In Proceedings of the 50th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 873–882.
Association for Computational Linguistics.
Thomas K. Landauer, Peter W. Foltz, and Darrell La-
ham. 1998. An introduction to latent semantic analy-
sis. Discourse Processes, 25:259–284.
Tomas Mikolov, Martin Karafi´at, Luk´aˇs Burget, Jan Cer-
nocky, and Sanjeev Khudanpur. 2010. Recurrent neu-
ral network based language model. In Proceedings of
Interspeech, pages 1045–1048.
Tomas Mikolov, Daniel Povey, Luk´aˇs Burget, and Jan
Cernocky. 2011. Strategies for training large scale
neural network language models. In Proceedings of
ASRU, pages 196–201.
Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig.
2013. Linguistic regularities in continuous space
word representations. In Proceedings of NAACL-HLT,
pages 746–751.
Mitra Mohtarami, Hadi Amiri, Man Lan, and Chew Lim
Tan. 2011. Predicting the uncertainty of sentiment
adjectives in indirect answers. In Proceedings of the
20th ACM international conference on Information
and knowledge management, pages 2485–2488.
Mitra Mohtarami, Hadi Amiri, Man Lan, Thanh Phu
Tran, and Chew Lim Tan. 2012. Sense sentiment sim-
ilarity: an analysis. In Proceedings of the 26th AAAI
Conference on Artificial Intelligence, pages 1706–
1712.
Holger Schwenk. 2007. Continuous space language
models. Computer Speech &amp; Language, 21(3):492–
518.
Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010.
Word representations: a simple and general method for
semi-supervised learning. In Proceedings of the 48th
Annual Meeting of the Association for Computational
Linguistics, pages 384–394.
Zhi Zhong and Hwee Tou Ng. 2010. It makes sense: a
wide-coverage word sense disambiguation system for
free text. In Proceedings of the ACL 2010 System
Demonstrations, pages 78–83.
</reference>
<page confidence="0.989398">
1630
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.652630">
<title confidence="0.995951">Deriving adjectival scales from continuous space word representations</title>
<author confidence="0.993946">Marie-Catherine de_Marneffe</author>
<affiliation confidence="0.975058">Department of Linguistics The Ohio State</affiliation>
<address confidence="0.991792">Columbus, OH 43210,</address>
<email confidence="0.999774">mcdm@ling.ohio-state.edu</email>
<author confidence="0.791037">Joo-Kyung</author>
<affiliation confidence="0.9828335">Department of Computer Science and The Ohio State</affiliation>
<address confidence="0.997384">Columbus, OH 43210,</address>
<email confidence="0.999872">kimjook@cse.ohio-state.edu</email>
<abstract confidence="0.995932904761905">Continuous space word representations extracted from neural network language models have been used effectively for natural language processing, but until recently it was not clear whether the spatial relationships of such representations were interpretable. Mikolov et al. (2013) show that these representations do capture syntactic and semantic regularities. Here, we push the interpretation of continuous space word representations further by demonstrating that vector offsets can be used to deadjectival scales (e.g., ex- We evaluate the scales on the indirect to corpus (de Marneffe et al., 2010). We obtain 72.8% accuracy, outperforms previous results on this corpus and highlights the quality of the scales extracted, providing further support that the continuous space word representations are meaningful.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoshua Bengio</author>
<author>R´ejean Ducharme</author>
<author>Pascal Vincent</author>
<author>Christian Janvin</author>
</authors>
<title>A neural probabilistic language model.</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>3--1137</pages>
<contexts>
<context position="1459" citStr="Bengio et al., 2003" startWordPosition="206" endWordPosition="210">derive adjectival scales (e.g., okay &lt; good &lt; excellent). We evaluate the scales on the indirect answers to yes/no questions corpus (de Marneffe et al., 2010). We obtain 72.8% accuracy, which outperforms previous results (-60%) on this corpus and highlights the quality of the scales extracted, providing further support that the continuous space word representations are meaningful. 1 Introduction There has recently been a surge of interest for deep learning in natural language processing. In particular, neural network language models (NNLMs) have been used to learn distributional word vectors (Bengio et al., 2003; Schwenk, 2007; Mikolov et al., 2010): the models jointly learn an embedding of words into an n-dimensional feature space. One of the advantages put forth for such distributed representations compared to traditional n-gram models is that similar words are likely to have similar vector representations in a continuous space model, whereas the discrete units of an n-gram model do not exhibit any inherent relation with one another. It has been shown that the continuous space representations improve performance in a variety of NLP tasks, such as POS tagging, semantic role labeling, named entity re</context>
</contexts>
<marker>Bengio, Ducharme, Vincent, Janvin, 2003</marker>
<rawString>Yoshua Bengio, R´ejean Ducharme, Pascal Vincent, and Christian Janvin. 2003. A neural probabilistic language model. The Journal of Machine Learning Research, 3:1137–1155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
</authors>
<title>A unified architecture for natural language processing: deep neural networks with multitask learning.</title>
<date>2008</date>
<booktitle>In Proceedings of the 25th international conference on Machine learning,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="2104" citStr="Collobert and Weston, 2008" startWordPosition="309" endWordPosition="313">kolov et al., 2010): the models jointly learn an embedding of words into an n-dimensional feature space. One of the advantages put forth for such distributed representations compared to traditional n-gram models is that similar words are likely to have similar vector representations in a continuous space model, whereas the discrete units of an n-gram model do not exhibit any inherent relation with one another. It has been shown that the continuous space representations improve performance in a variety of NLP tasks, such as POS tagging, semantic role labeling, named entity resolution, parsing (Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012). Mikolov et al. (2013) show that there are some syntactic and semantic regularities in the word representations learned, such as the singular/plural relation (the difference of singular and plural word vectors are equivalent: apple − apples ≈ car − cars ≈ family − families) or the gender relation (a masculine noun can be transformed into the feminine form: king − man + woman ≈ queen). We extend Mikolov et al. (2013)’s approach and explore further the interpretation of the vector space. We show that the word vectors learned by NNLMs are meaningful: we </context>
</contexts>
<marker>Collobert, Weston, 2008</marker>
<rawString>Ronan Collobert and Jason Weston. 2008. A unified architecture for natural language processing: deep neural networks with multitask learning. In Proceedings of the 25th international conference on Machine learning, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
<author>Christopher Potts</author>
</authors>
<title>Was it good? It was provocative. Learning the meaning of scalar adjectives.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Meeting of the Association for Computational Linguistics,</booktitle>
<pages>167--176</pages>
<marker>de Marneffe, Manning, Potts, 2010</marker>
<rawString>Marie-Catherine de Marneffe, Christopher D. Manning, and Christopher Potts. 2010. Was it good? It was provocative. Learning the meaning of scalar adjectives. In Proceedings of the 48th Meeting of the Association for Computational Linguistics, pages 167–176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="11598" citStr="Fellbaum, 1998" startWordPosition="1911" endWordPosition="1912">nswer pair has 3These 125 pairs correspond to the ‘Other adjective’ category in (de Marneffe et al., 2010). angry x3 b--happy x2 a--furious unhappy pleased x1 1627 been annotated via Mechanical Turk for whether the answer conveys yes, no or uncertain. 4.1 Method The previous section showed that we can draw a line passing through an adjective and its antonym and that the words extracted along the line are roughly semantically ordered. To infer a yes or no answer in the case of the IQAP corpus, we use the following approach illustrated with the Obama example above (Figure 3). Using WordNet 3.1 (Fellbaum, 1998), we look for an antonym of the adjective in the question qualified: unqualified is retrieved. Since the scales extracted are only roughly ordered, to infer yes when the question and answer words are very close, we set the decision boundary perpendicular to the line connecting the two words and passing through the midpoint of the line. Since the answer word is young, we check whether young is in the area including qualified or in the other area. We infer a yes answer in the former case, and a no answer in the latter case. If young is on the boundary, we infer uncertain. If a sentence contains </context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998. WordNet: An electronic lexical database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric H Huang</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Improving word representations via global context and multiple word prototypes.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>873--882</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2146" citStr="Huang et al., 2012" startWordPosition="318" endWordPosition="321">embedding of words into an n-dimensional feature space. One of the advantages put forth for such distributed representations compared to traditional n-gram models is that similar words are likely to have similar vector representations in a continuous space model, whereas the discrete units of an n-gram model do not exhibit any inherent relation with one another. It has been shown that the continuous space representations improve performance in a variety of NLP tasks, such as POS tagging, semantic role labeling, named entity resolution, parsing (Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012). Mikolov et al. (2013) show that there are some syntactic and semantic regularities in the word representations learned, such as the singular/plural relation (the difference of singular and plural word vectors are equivalent: apple − apples ≈ car − cars ≈ family − families) or the gender relation (a masculine noun can be transformed into the feminine form: king − man + woman ≈ queen). We extend Mikolov et al. (2013)’s approach and explore further the interpretation of the vector space. We show that the word vectors learned by NNLMs are meaningful: we can extract scalar relationships between a</context>
</contexts>
<marker>Huang, Socher, Manning, Ng, 2012</marker>
<rawString>Eric H. Huang, Richard Socher, Christopher D. Manning, and Andrew Y Ng. 2012. Improving word representations via global context and multiple word prototypes. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 873–882. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Peter W Foltz</author>
<author>Darrell Laham</author>
</authors>
<title>An introduction to latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<pages>25--259</pages>
<contexts>
<context position="6331" citStr="Landauer et al., 1998" startWordPosition="1060" endWordPosition="1063"> If a and b are syntactically or semantically related, the vector offset can be interpreted as a transformation of the syntactic form or the meaning. The offset can also be added to another word vector c. The word vector nearest to wa − wb + w, would be related to word c with the syntactic or semantic difference as the difference between a and b, as it is the case for the king, man, and woman example, where king − man + woman would approximately represent king with feminine gender (i.e., queen). They also tried to use the continuous representations generated by Latent Semantic Analysis (LSA) (Landauer et al., 1998). However, the results using LSA were worse because LSA is a bag-of-words model, in which it is difficult to exploit word sequence information as the context. For all the experiments in this paper, we use the precomputed word representations generated by the RNNLM from (Mikolov et al., 2013). Their RNN is trained with 320M words from the Broadcast News data (the vocabulary size is 82,390 words), and we used word vectors with a dimensionality of 1,600 (the highest dimensionality provided).1 We standardized the dataset so that the mean and the variance of the representations are 0 and 1, respect</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Thomas K. Landauer, Peter W. Foltz, and Darrell Laham. 1998. An introduction to latent semantic analysis. Discourse Processes, 25:259–284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Martin Karafi´at</author>
<author>Luk´aˇs Burget</author>
<author>Jan Cernocky</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Recurrent neural network based language model.</title>
<date>2010</date>
<booktitle>In Proceedings of Interspeech,</booktitle>
<pages>1045--1048</pages>
<marker>Mikolov, Karafi´at, Burget, Cernocky, Khudanpur, 2010</marker>
<rawString>Tomas Mikolov, Martin Karafi´at, Luk´aˇs Burget, Jan Cernocky, and Sanjeev Khudanpur. 2010. Recurrent neural network based language model. In Proceedings of Interspeech, pages 1045–1048.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Daniel Povey</author>
<author>Luk´aˇs Burget</author>
<author>Jan Cernocky</author>
</authors>
<title>Strategies for training large scale neural network language models.</title>
<date>2011</date>
<booktitle>In Proceedings of ASRU,</booktitle>
<pages>196--201</pages>
<contexts>
<context position="3378" citStr="Mikolov et al., 2011" startWordPosition="534" endWordPosition="537">e.g., bad &lt; okay &lt; good &lt; excellent), which can not only serve to build a sentiment lexicon but also be used for inference. To evaluate the quality of the scalar relationships learned by NNLMs, we use the indirect yes/no question answer pairs (IQAP) from (de Marneffe et al., 2010), where scales between adjectives are needed to infer a yes/no answer from a reply without explicit yes or no such as Was the movie good? It was excellent. Our method reaches 72.8% accuracy, which is the best result reported so far when scales are used. 2 Previous work We use the continuous word representations from (Mikolov et al., 2011), extracted from a recurrent neural network language model (RNNLM), whose 1625 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1625–1630, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics three-layer architecture is represented in Figure 1. w(t) Figure 1: The architecture of the RNNLM. In the input layer, w(t) is the input word represented by 1-of-N coding at time t when the vocabulary size is N. When there are M nodes in the hidden layer, the number of connections between the input layer and the hidden </context>
</contexts>
<marker>Mikolov, Povey, Burget, Cernocky, 2011</marker>
<rawString>Tomas Mikolov, Daniel Povey, Luk´aˇs Burget, and Jan Cernocky. 2011. Strategies for training large scale neural network language models. In Proceedings of ASRU, pages 196–201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Wen-tau Yih</author>
<author>Geoffrey Zweig</author>
</authors>
<title>Linguistic regularities in continuous space word representations.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>746--751</pages>
<contexts>
<context position="625" citStr="Mikolov et al. (2013)" startWordPosition="78" endWordPosition="81">ving adjectival scales from continuous space word representations Marie-Catherine de Marneffe Department of Linguistics The Ohio State University Columbus, OH 43210, USA mcdm@ling.ohio-state.edu Joo-Kyung Kim Department of Computer Science and Engineering The Ohio State University Columbus, OH 43210, USA kimjook@cse.ohio-state.edu Abstract Continuous space word representations extracted from neural network language models have been used effectively for natural language processing, but until recently it was not clear whether the spatial relationships of such representations were interpretable. Mikolov et al. (2013) show that these representations do capture syntactic and semantic regularities. Here, we push the interpretation of continuous space word representations further by demonstrating that vector offsets can be used to derive adjectival scales (e.g., okay &lt; good &lt; excellent). We evaluate the scales on the indirect answers to yes/no questions corpus (de Marneffe et al., 2010). We obtain 72.8% accuracy, which outperforms previous results (-60%) on this corpus and highlights the quality of the scales extracted, providing further support that the continuous space word representations are meaningful. 1</context>
<context position="2169" citStr="Mikolov et al. (2013)" startWordPosition="322" endWordPosition="325">to an n-dimensional feature space. One of the advantages put forth for such distributed representations compared to traditional n-gram models is that similar words are likely to have similar vector representations in a continuous space model, whereas the discrete units of an n-gram model do not exhibit any inherent relation with one another. It has been shown that the continuous space representations improve performance in a variety of NLP tasks, such as POS tagging, semantic role labeling, named entity resolution, parsing (Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012). Mikolov et al. (2013) show that there are some syntactic and semantic regularities in the word representations learned, such as the singular/plural relation (the difference of singular and plural word vectors are equivalent: apple − apples ≈ car − cars ≈ family − families) or the gender relation (a masculine noun can be transformed into the feminine form: king − man + woman ≈ queen). We extend Mikolov et al. (2013)’s approach and explore further the interpretation of the vector space. We show that the word vectors learned by NNLMs are meaningful: we can extract scalar relationships between adjectives (e.g., bad &lt; </context>
<context position="5498" citStr="Mikolov et al. (2013)" startWordPosition="908" endWordPosition="911">ween the hidden layer and the output layer. The final output is y(t) = g(Vs(t)), where g is a softmax function to represent the probability distribution over all the words in the vocabulary. When the RNN is trained by the back propagation algorithm, we can regard the ith column vector of U as the continuous representation of the ith word in the vocabulary since the column was adjusted correspondingly to the ith element of w(t). Because the s(t) outputs of two input words will be similar when they have similar s(t − 1) values, the corresponding column vectors of the words will also be similar. Mikolov et al. (2013) showed that constant vector offsets of word pairs can represent linguistic regularities. Let wa and wb denote the vectors for the words a and b, respectively. Then the vector offset of the word pair is wa − wb. If a and b are syntactically or semantically related, the vector offset can be interpreted as a transformation of the syntactic form or the meaning. The offset can also be added to another word vector c. The word vector nearest to wa − wb + w, would be related to word c with the syntactic or semantic difference as the difference between a and b, as it is the case for the king, man, and</context>
<context position="7473" citStr="Mikolov et al., 2013" startWordPosition="1250" endWordPosition="1253">t so that the mean and the variance of the representations are 0 and 1, respectively.2 3 Deriving adjectival scales Here we explore further the interpretation of word vectors. Assuming that the transformation of form or meaning represented by the vector offset is linear, an intermediate vector between two word vectors would represent some “middle” form or meaning. For example, given the positive and superlative forms of an adjective (e.g., good and best), we expect that the word representation in the middle of 1We also experimented with smaller dimensions, but consistent with the analyses in (Mikolov et al., 2013), the highest dimensionality gave better results. 2http://www.fit.vutbr.cz/˜imikolov/ rnnlm/word_projections-1600.txt.gz y( s(t sigmoid V softmax s(t-1) U W 1626 Input words Words with highest cosine similarities to the mean vector good:best better: 0.738 strong: 0.644 normal: 0.619 less: 0.609 bad:worst terrible: 0.726 great: 0.678 horrible: 0.674 worse: 0.665 slow:slowest slower: 0.637 sluggish: 0.614 steady: 0.558 brisk: 0.543 fast:fastest faster: 0.645 slower: 0.602 quicker: 0.542 harder: 0.518 Table 1: Words with corresponding vectors closest to the mean of positive:superlative word vecto</context>
</contexts>
<marker>Mikolov, Yih, Zweig, 2013</marker>
<rawString>Tomas Mikolov, Wen-tau Yih, and Geoffrey Zweig. 2013. Linguistic regularities in continuous space word representations. In Proceedings of NAACL-HLT, pages 746–751.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitra Mohtarami</author>
<author>Hadi Amiri</author>
<author>Man Lan</author>
<author>Chew Lim Tan</author>
</authors>
<title>Predicting the uncertainty of sentiment adjectives in indirect answers.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management,</booktitle>
<pages>2485--2488</pages>
<contexts>
<context position="13913" citStr="Mohtarami et al. (2011)" startWordPosition="2312" endWordPosition="2315">core (%) comparison on the 125 scalar adjective pairs in the IQAP corpus. question is good and the answer is excellent: bad and evil are the antonym candidates of good. Because the absolute cosine similarity of goodexcellent to good-bad is higher than to good-evil, we choose bad as the antonym in this case. Figure 4: An example of antonym selection. 4.2 Results and discussion Table 3 compares our results with previous ones where adjectival scales are considered: de Marneffe et al. (2010) propose an unsupervised approach where scales are learned from distributional information in a Web corpus; Mohtarami et al. (2011)’s model is similar to ours but uses word representations obtained by LSA and a word sense disambiguation system (Zhong and Ng, 2010) to choose antonyms. To compare with Mohtarami et al. (2011), we use macro-averaged precision and recall for yes and no. For the given metrics, our model significantly outperforms the previous ones (p &lt; 0.05, McNemar’s test). Mohtarami et al. (2011) present higher numbers obtained by replacing the answer words with their synonyms in WordNet. However, that approach fails to capture orderings. Two words of different degree are often regarded as synonyms: even thoug</context>
</contexts>
<marker>Mohtarami, Amiri, Lan, Tan, 2011</marker>
<rawString>Mitra Mohtarami, Hadi Amiri, Man Lan, and Chew Lim Tan. 2011. Predicting the uncertainty of sentiment adjectives in indirect answers. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 2485–2488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitra Mohtarami</author>
<author>Hadi Amiri</author>
<author>Man Lan</author>
<author>Thanh Phu Tran</author>
<author>Chew Lim Tan</author>
</authors>
<title>Sense sentiment similarity: an analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of the 26th AAAI Conference on Artificial Intelligence,</booktitle>
<pages>1706--1712</pages>
<contexts>
<context position="14716" citStr="Mohtarami et al. (2012)" startWordPosition="2443" endWordPosition="2446">et al. (2011), we use macro-averaged precision and recall for yes and no. For the given metrics, our model significantly outperforms the previous ones (p &lt; 0.05, McNemar’s test). Mohtarami et al. (2011) present higher numbers obtained by replacing the answer words with their synonyms in WordNet. However, that approach fails to capture orderings. Two words of different degree are often regarded as synonyms: even though furious means extremely angry, furious and angry are synonyms in WordNet. Therefore using synonyms, the system will output the same answer irrespective of the order in the pair. Mohtarami et al. (2012) also presented results on the interpretation of indirect questions on the IQAP corpus, but their method bad good evil excellent qualified young unqualified Macro Acc P R F1 1628 bad good sure terrible confident 20 15 10 5 0 dim 2 -5 happy delighted unhappy young diffident qualified -10 -15 -20 unqualified 25 -20 -15 -10 -5 0 5 10 15 20 dim 1 Figure 5: Question words (bold), their antonyms (italic), and answer words (normal) of four pairs from the IQAP dataset. The words are visualized by MDS. did not involve learning or using scalar implicatures. Figure 5 gives a qualitative picture: the ques</context>
</contexts>
<marker>Mohtarami, Amiri, Lan, Tran, Tan, 2012</marker>
<rawString>Mitra Mohtarami, Hadi Amiri, Man Lan, Thanh Phu Tran, and Chew Lim Tan. 2012. Sense sentiment similarity: an analysis. In Proceedings of the 26th AAAI Conference on Artificial Intelligence, pages 1706– 1712.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Holger Schwenk</author>
</authors>
<title>Continuous space language models.</title>
<date>2007</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>21</volume>
<issue>3</issue>
<pages>518</pages>
<contexts>
<context position="1474" citStr="Schwenk, 2007" startWordPosition="211" endWordPosition="212">les (e.g., okay &lt; good &lt; excellent). We evaluate the scales on the indirect answers to yes/no questions corpus (de Marneffe et al., 2010). We obtain 72.8% accuracy, which outperforms previous results (-60%) on this corpus and highlights the quality of the scales extracted, providing further support that the continuous space word representations are meaningful. 1 Introduction There has recently been a surge of interest for deep learning in natural language processing. In particular, neural network language models (NNLMs) have been used to learn distributional word vectors (Bengio et al., 2003; Schwenk, 2007; Mikolov et al., 2010): the models jointly learn an embedding of words into an n-dimensional feature space. One of the advantages put forth for such distributed representations compared to traditional n-gram models is that similar words are likely to have similar vector representations in a continuous space model, whereas the discrete units of an n-gram model do not exhibit any inherent relation with one another. It has been shown that the continuous space representations improve performance in a variety of NLP tasks, such as POS tagging, semantic role labeling, named entity resolution, parsi</context>
</contexts>
<marker>Schwenk, 2007</marker>
<rawString>Holger Schwenk. 2007. Continuous space language models. Computer Speech &amp; Language, 21(3):492– 518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Turian</author>
<author>Lev Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: a simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>384--394</pages>
<contexts>
<context position="2125" citStr="Turian et al., 2010" startWordPosition="314" endWordPosition="317">els jointly learn an embedding of words into an n-dimensional feature space. One of the advantages put forth for such distributed representations compared to traditional n-gram models is that similar words are likely to have similar vector representations in a continuous space model, whereas the discrete units of an n-gram model do not exhibit any inherent relation with one another. It has been shown that the continuous space representations improve performance in a variety of NLP tasks, such as POS tagging, semantic role labeling, named entity resolution, parsing (Collobert and Weston, 2008; Turian et al., 2010; Huang et al., 2012). Mikolov et al. (2013) show that there are some syntactic and semantic regularities in the word representations learned, such as the singular/plural relation (the difference of singular and plural word vectors are equivalent: apple − apples ≈ car − cars ≈ family − families) or the gender relation (a masculine noun can be transformed into the feminine form: king − man + woman ≈ queen). We extend Mikolov et al. (2013)’s approach and explore further the interpretation of the vector space. We show that the word vectors learned by NNLMs are meaningful: we can extract scalar re</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph Turian, Lev Ratinov, and Yoshua Bengio. 2010. Word representations: a simple and general method for semi-supervised learning. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 384–394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhi Zhong</author>
<author>Hwee Tou Ng</author>
</authors>
<title>It makes sense: a wide-coverage word sense disambiguation system for free text.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 System Demonstrations,</booktitle>
<pages>78--83</pages>
<contexts>
<context position="14046" citStr="Zhong and Ng, 2010" startWordPosition="2336" endWordPosition="2339">the antonym candidates of good. Because the absolute cosine similarity of goodexcellent to good-bad is higher than to good-evil, we choose bad as the antonym in this case. Figure 4: An example of antonym selection. 4.2 Results and discussion Table 3 compares our results with previous ones where adjectival scales are considered: de Marneffe et al. (2010) propose an unsupervised approach where scales are learned from distributional information in a Web corpus; Mohtarami et al. (2011)’s model is similar to ours but uses word representations obtained by LSA and a word sense disambiguation system (Zhong and Ng, 2010) to choose antonyms. To compare with Mohtarami et al. (2011), we use macro-averaged precision and recall for yes and no. For the given metrics, our model significantly outperforms the previous ones (p &lt; 0.05, McNemar’s test). Mohtarami et al. (2011) present higher numbers obtained by replacing the answer words with their synonyms in WordNet. However, that approach fails to capture orderings. Two words of different degree are often regarded as synonyms: even though furious means extremely angry, furious and angry are synonyms in WordNet. Therefore using synonyms, the system will output the same</context>
</contexts>
<marker>Zhong, Ng, 2010</marker>
<rawString>Zhi Zhong and Hwee Tou Ng. 2010. It makes sense: a wide-coverage word sense disambiguation system for free text. In Proceedings of the ACL 2010 System Demonstrations, pages 78–83.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>