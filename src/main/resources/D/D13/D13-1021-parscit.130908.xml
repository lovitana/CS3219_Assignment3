<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006755">
<title confidence="0.9983145">
Noise-aware Character Alignment for Bootstrapping Statistical Machine
Transliteration from Bilingual Corpora
</title>
<author confidence="0.853794">
Katsuhito Sudoh*† Shinsuke Mori$ Masaaki Nagata*
</author>
<affiliation confidence="0.81618">
*NTT Communication Science Laboratories
†Graduate School of Informatics, Kyoto University
$Academic Center for Computing and Media Studies, Kyoto University
</affiliation>
<email confidence="0.996901">
sudoh.katsuhito@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.995608" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999347636363636">
This paper proposes a novel noise-aware char-
acter alignment method for bootstrapping sta-
tistical machine transliteration from automat-
ically extracted phrase pairs. The model is
an extension of a Bayesian many-to-many
alignment method for distinguishing non-
transliteration (noise) parts in phrase pairs. It
worked effectively in the experiments of boot-
strapping Japanese-to-English statistical ma-
chine transliteration in patent domain using
patent bilingual corpora.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999224">
Transliteration is used for providing translations for
source language words that have no appropriate
counterparts in target language, such as some tech-
nical terms and named entities. Statistical machine
transliteration (Knight and Graehl, 1998) is a tech-
nology to solve it in a statistical manner. Bilin-
gual dictionaries can be used to train its model, but
many of their entries are actually translation but not
transliteration. Such non-transliteration pairs hurt
the transliteration model and should be eliminated
beforehand.
Sajjad et al. (2012) proposed a method to iden-
tify such non-transliteration pairs, and applied it
successfully to noisy word pairs obtained from au-
tomatic word alignment on bilingual corpora. It
enables the statistical machine transliteration to be
bootstrapped from bilingual corpora. This approach
is beneficial because it does not require carefully-
developed bilingual transliteration dictionaries and
it can learn domain-specific transliteration patterns
from bilingual corpora in the target domain. How-
ever, their transliteration mining approach is sample-
wise; that is, it makes a decision whether a bilingual
phrase pair is transliteration or not. Suppose that
a compound word in a language A is transliterated
into two words in another language B. Their corre-
spondence may not be fully identified by automatic
word alignment and a wrong alignment between the
compound word in A and only one component word
in B is found. The sample-wise mining cannot make
a correct decision of partial transliteration on the
aligned candidate, and may introduces noise to the
statistical transliteration model.
This paper proposes a novel transliteration mining
method for such partial transliterations. The method
uses a noise-aware character alignment model that
distinguish non-transliteration (noise) parts from
transliteration (signal) parts. The model is an ex-
tension of a Bayesian alignment model (Finch and
Sumita, 2010) and can be trained by a sampling al-
gorithm extended for a constraint on noise. Our
experiments of Japanese-to-English transliteration
achieved 16% relative error reduction in transliter-
ation accuracy from the sample-wise method. The
main contribution of this paper is two-fold:
</bodyText>
<listItem confidence="0.989063166666667">
• we formulate alignment over string pairs with
partial noise and present a solution with a
noise-aware alignment model;
• we proved its effectiveness by experiments
with frequent unknown words in actual
Japanese-to-English patent translation data.
</listItem>
<page confidence="0.977668">
204
</page>
<bodyText confidence="0.3440605">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 204–209,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.71106" genericHeader="method">
2 Bayesian many-to-many alignment
</sectionHeader>
<bodyText confidence="0.998034">
We briefly review a Bayesian many-to-many charac-
ter alignment proposed by Finch and Sumita (2010)
on which our model is based. The model is based
on a generative process of bilingual substring pairs
⟨s,�t⟩ by the following Dirichlet process (DP):
</bodyText>
<figure confidence="0.99790603030303">
(a) no noise
(b) noise
ー
k
キ
e
y
ア _
ブ�
ッnoise
f
l
y
noisenois
ギ ブ
g
i
v
ア Y
e
noise
プ
r e
noise
c
カ
o
バ
v
e r
ー
G|α,G0 ∼ DP(α, G0) (c) partial noise: English (d) partial noise: Japanese side
⟨s,�t⟩|G ∼ G, side should be “give up” should be “リカバー”
</figure>
<bodyText confidence="0.999925">
where G is a probability distribution over substring
pairs according to a DP prior with base measure G0
and hyperparameter α. G0 is modeled as a joint
spelling model as follows:
</bodyText>
<equation confidence="0.9996614">
G0 (⟨s, 1⟩) = |�|� e−&apos;`3v3 |�s |× |�t|� e
A|-4 |At
t −λtv−|
t � (1)
t|
</equation>
<bodyText confidence="0.9999527">
This is a simple joint probability of the spelling
models, in which each alphabet appears based on
a uniform distribution over the vocabulary (of size
vs and vt) and each string length follows a Poisson
distribution (with the average length As and At).
The model handles infinite number of substring
pairs according to the Chinese Restaurant Process
(CRP). The probability of a substring pair ⟨�sk, �tk⟩
is based on the counts of all other substring pairs as
follows:
</bodyText>
<equation confidence="0.997106">
p(⟨�sk,�tk⟩ |{⟨�s,P}�k)
N (⟨�sk,�tk⟩) + αG0 (⟨�sk,�tk⟩)
∑i N (⟨�si,�ti⟩) + α
</equation>
<bodyText confidence="0.998425857142857">
Here {⟨s,�t⟩}−k means a set of substring pairs ex-
cluding ⟨�sk, �tk⟩, and N (⟨sk,�tk⟩) is the number of
⟨�sk, �tk⟩ in the current sample space. This align-
ment model is suitable for representing very sparse
distribution over arbitrary substring pairs, thanks to
reasonable CRP-based smoothing for unseen pairs
based on the spelling model.
</bodyText>
<sectionHeader confidence="0.994472" genericHeader="method">
3 Proposed method
</sectionHeader>
<bodyText confidence="0.99981625">
We propose an extended many-to-many alignment
model that can handle partial noise. We extend the
model in the previous section by introducing a noise
symbol and state-based probability calculation.
</bodyText>
<figureCaption confidence="0.989279">
Figure 1: Three types of noise in transliteration data.
Solid lines are correct many-to-many alignment links.
</figureCaption>
<subsectionHeader confidence="0.999778">
3.1 Partial noise in transliteration data
</subsectionHeader>
<bodyText confidence="0.999715625">
Figure 1 shows transliteration examples with “no
noise,” “noise,” and “partial noise.” Solid lines in the
figure show correct many-to-many alignment links.
The examples (a) and (b) can be distinguished ef-
fectively by Sajjad et al. (2012). We aim to do align-
ment as in the examples (c) and (d) by distinguishing
its non-transliteration (noise) part, which cannot be
handled by the existing methods.
</bodyText>
<subsectionHeader confidence="0.999213">
3.2 Noise-aware alignment model
</subsectionHeader>
<bodyText confidence="0.999955043478261">
We introduce a noise symbol to handle partial noise
in the many-to-many alignment model. Htun et al.
(2012) extended the many-to-many alignment for
the sample-wise transliteration mining, but its noise
model only handles the sample-wise noise and can-
not distinguish partial noise. We model partial noise
in the CRP-based joint substring model.
Partial noise in transliteration data typically ap-
pears in compound words as mentioned earlier, be-
cause their counterparts consisting of two or more
words may not be fully covered in automatically ex-
tracted words and phrases as shown in Figure 1(c).
Another type of partial noise is derived from mor-
phological differences due to inflection, which usu-
ally appear in the sub-word level as prefixes and suf-
fixes as shown in Figure 1(d). According to this
intuition, we assume that partial noise appears in
the beginning and/or end of transliteration data (in
case of sample-wise noise, we assume the noise is in
the beginning). This assumption derives a constraint
between signal and noise parts that helps to avoid
a welter of transliteration and non-transliteration
parts. It also has a shortcoming that it is generally
</bodyText>
<equation confidence="0.7536645">
=
� (2)
</equation>
<page confidence="0.99446">
205
</page>
<figureCaption confidence="0.937268666666667">
Figure 2: Example of many-to-many alignment with par-
tial noise in the beginning and end. “noise” stands for the
noise symbol and “sp” stands for a white space.
</figureCaption>
<bodyText confidence="0.999987266666667">
not appropriate for noise in the middle, but handling
arbitrary number of noise parts increases computa-
tional complexity and sparseness. We rely on this
simple assumption in this paper and consider a more
complex mid-noise problem as future work.
Figure 2 shows a partial noise example in both
the beginning and end. This example is actually
correct translation but includes noise in a sense of
transliteration; an article “the” is wrongly included
in the phrase pair (no articles are used in Japanese)
and a plural noun “masks” is transliterated into
“マスク”(mask). These non-transliteration parts are
aligned to noise symbols in the proposed model. The
noise symbols are treated as zero-length substrings
in the model, same as other substrings.
</bodyText>
<subsectionHeader confidence="0.998105">
3.3 Constrained Gibbs sampling
</subsectionHeader>
<bodyText confidence="0.999842857142857">
Finch and Sumita (2010) used a blocked Gibbs sam-
pling algorithm with forward-filtering backward-
sampling (FFBS) (Mochihashi et al., 2009). We ex-
tend their algorithm for our noise-aware model us-
ing a state-based calculation over the three states:
non-transliteration part in the beginning (noiseB),
transliteration part (signal), non-transliteration part
in the end (noiseE).
Figure 3 illustrates our FFBS steps. At first in
the forward filtering, we begin with transition to
noiseB and signal. The calculation of forward
probabilities itself is almost the same as Finch and
Sumita (2010) except for state transition constraints:
from noiseB to signal, from signal to noiseE. The
backward-sampling traverses a path by probability-
based sampling with true posteriors, starting from
the choice of the ending state among noiseB (means
full noise), signal, and noiseE. This algorithm in-
creases the computational cost by three times to con-
sider three different states, compared to that of Finch
and Sumita (2010).
</bodyText>
<figure confidence="0.989336">
(a) Forward filtering (b) Backward sampling
</figure>
<figureCaption confidence="0.999736">
Figure 3: State-based FFBS for the proposed model.
</figureCaption>
<sectionHeader confidence="0.999086" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9999892">
We conducted experiments comparing the pro-
posed method with the conventional sample-wise
method for the use in bootstrapping statistical
machine transliteration using Japanese-to-English
patent translation dataset (Goto et al., 2013).
</bodyText>
<subsectionHeader confidence="0.996736">
4.1 Training data setup
</subsectionHeader>
<bodyText confidence="0.9999888125">
First, we trained a phrase table on the 3.2M paral-
lel sentences by a standard training procedure using
Moses, with Japanese tokenization using MeCab1.
We obtained 591,840 phrase table entries whose
Japanese side was written in katakana (Japanese
phonogram) only2. Then, we iteratively ran the
method of Sajjad et al. (2012) on these entries and
eliminate non-transliteration pairs, until the num-
ber of pairs converged. Finally we obtain 104,563
katakana-English pairs after 10 iterations; they were
our baseline training set mined by sample-wise
method. We used Sajjad et al.’s method as pre-
processing for filtering sample-wise noise while the
proposed method could also do that, because the
proposed method took much more training time for
all phrase table entries.
</bodyText>
<subsectionHeader confidence="0.981383">
4.2 Transliteration experiments
</subsectionHeader>
<bodyText confidence="0.9999525">
The transliteration experiment used a translation-
based implementation with Moses, using a
</bodyText>
<footnote confidence="0.9240628">
1http://code.google.com/p/mecab/
2This katakana-based filtering is a language dependent
heuristic for choosing potential transliteration candidate, be-
cause transliterations in Japanese are usually written in
katakana.
</footnote>
<figure confidence="0.996512162162162">
noise noise
noise
エ ッ
sp
t h e
sp
e
t c
h i
n
g
sp m a
s
k
s
チ J Y
マ Z ク
to
eBnoiseB
s
s
s
t ig
ot
al
signal
eEnoiseE
t
s
noiseB
t no
t signal
t si
t noiseE
t no
s
s
</figure>
<page confidence="0.997063">
206
</page>
<bodyText confidence="0.9981552">
character-based 7-gram language model trained on
300M English patent sentences. We compared three
transliteration models below.
The test set was top-1000 unknown (in the
Japanese-to-English translation model) katakana
words appeared in 400M Japanese patent sentences.
They covered 15.5% of all unknown katakana words
and 8.8% of all unknown words (excluding num-
bers); that is, more than a half of unknown words
were katakana words.
</bodyText>
<subsectionHeader confidence="0.782299">
4.2.1 Sample-wise method (BASELINE)
</subsectionHeader>
<bodyText confidence="0.999979333333333">
We used the baseline training set to train sta-
tistical machine transliteration model for our base-
line. The training procedure was based on Moses:
MGIZA++ word alignment, grow-diag-final-and
alignment symmetrization and phrase extraction
with the maximum phrase length of 7.
</bodyText>
<subsubsectionHeader confidence="0.817922">
4.2.2 Proposed method (PROPOSED)
</subsubsectionHeader>
<bodyText confidence="0.9994275">
We applied the proposed method to the baseline
training set with 30 sampling iterations and elimi-
nated partial noise. The transliteration model was
trained in the same manner as BASELINE after elim-
inating noise.
The hyperparameters, α, A, and At, were op-
timized using a held-out set of 2,000 katakana-
English pairs that were randomly chosen from a
general-domain bilingual dictionary. The hyperpa-
rameter optimization was based on F-score values
on the held-out set with varying α among 0.01, 0.02,
0.05, 0.1, 1.0, and As among 1, 2, 3, 5.
Table 1 compares the statistics on the training sets
of BASELINE and PROPOSED. Note that we ap-
plied the proposed method to BASELINE data (the
sample-wise method was already applied until con-
vergence). The proposed method eliminated only
two transliteration candidates in sample-wise but
also eliminated 5,714 (0.64%) katakana and 55,737
(4.1%) English characters3.
</bodyText>
<subsubsectionHeader confidence="0.699416">
4.2.3 Proposed method using aligned joint
</subsubsectionHeader>
<bodyText confidence="0.860760333333333">
substrings as phrases (PROPOSED-JOINT)
The many-to-many character alignment actually
induces substring pairs, which can be used as
</bodyText>
<footnote confidence="0.980691333333333">
3The reason of larger number of partial noise in English side
would be a syntactic difference as shown in Figure 2 and the
katakana-based filtering heuristics.
</footnote>
<tableCaption confidence="0.998431">
Table 1: Statistics of the training sets.
</tableCaption>
<table confidence="0.90364">
Method #pairs #Ja chars. #En chars.
BASELINE 104,563 899,080 1,372,993
PROPOSED 104,561 893,366 1,317,256
</table>
<bodyText confidence="0.999094181818182">
phrases in statistical machine transliteration and
improved transliteration performance (Finch and
Sumita, 2010). We extracted them by: 1) generate
many-to-many word alignment, in which all possi-
ble word alignment links in many-to-many corre-
spondences (e.g., 0-0 0-1 0-2 1-0 1-1 1-2 for ⟨コ ン,
c o m⟩), 2) run phrase extraction and scoring same as
a standard Moses training. This procedure extracts
longer phrases satisfying the many-to-many align-
ment constraints than the simple use of extracted
joint substring pairs as phrases.
</bodyText>
<subsectionHeader confidence="0.916244">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999926535714286">
Table 2 shows the results. We used three evalua-
tion metrics: ACC, F-score, and BLEUc. ACC is
a sample-wise accuracy and F-score is a character-
wise F-measure-like score (Li et al., 2010). BLEUc
is BLEU (Papineni et al., 2002) in the character level
with n=4.
PROPOSED achieved 63% in ACC (16% rela-
tive error reduction from BASELINE), and 94.6% in
F-score (25% relative error reduction from BASE-
LINE). These improvements clearly showed an ad-
vantage of the proposed method over the sample-
wise mining. BLEUc showed a similar improve-
ments. Recall that BASELINE and PROPOSED had
a small difference in their training data, actually
0.64% (katakana) and 4.1% (English) in the num-
ber of characters. The results suggest that the partial
noise can hurt transliteration models.
PROPOSED-JOINT showed similar performance
as PROPOSED with a slight drop in BLEUc, al-
though many-to-many substring alignment was ex-
pected to improve transliteration as reported by
Finch and Sumita (2010). The difference may be
due to the difference in coverage of the phrase
tables; PROPOSED-JOINT retained relatively long
substrings by the many-to-many alignment con-
straints in contrast to the less-constrained grow-
diag-final-and alignments in PROPOSED. Since the
training data in our bootstrapping experiments con-
</bodyText>
<page confidence="0.998707">
207
</page>
<tableCaption confidence="0.9606805">
Table 2: Japanese-to-English transliteration results for
top-1000 unknown katakana words. ACC and F-score
stand for the ones used in NEWS workshop, BLEU� is
character-wise BLEU.
</tableCaption>
<table confidence="0.99972575">
Method ACC F-score BLEU�
BASELINE 0.56 0.929 0.864
PROPOSED 0.63 0.946 0.897
PROPOSED-JOINT 0.63 0.943 0.888
</table>
<bodyText confidence="0.996988857142857">
tained many similar phrases unlike dictionary-based
data in Finch and Sumita (2010), the phrase table of
PROPOSED-JOINT may have a small coverage due
to long and sparse substring pairs with large prob-
abilities even if the many-to-many alignment was
good. This sparseness problem is beyond the scope
of this paper and worth further study.
</bodyText>
<subsectionHeader confidence="0.999342">
4.4 Alignment Examples
</subsectionHeader>
<bodyText confidence="0.9999845">
Figure 4 shows examples of the alignment results in
the training data. As expected, partial noise both in
Japanese and English was identified correctly in (a),
(b), and (c). There were some alignment errors in the
signal part in (b), in which characters in boundary
positions were aligned incorrectly to adjacent sub-
strings. These alignment errors did not directly de-
grade the partial noise identification but may cause
a negative effect on overall alignment performance
in the sampling-based optimization. (d) is a nega-
tive example in which partial noise was incorrectly
aligned. (c) and (d) have similar partial noise in their
English word endings, but it could not be identified
in (d). One possible reason for that is the sparse-
ness problem mentioned above, as shown in erro-
neous long character alignments in (d).
</bodyText>
<sectionHeader confidence="0.998954" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9997128">
This paper proposed a noise-aware many-to-many
alignment model that can distinguish partial noise in
transliteration pairs for bootstrapping statistical ma-
chine transliteration model from automatically ex-
tracted phrase pairs. The model and training al-
gorithm are straightforward extension of those by
Finch and Sumita (2010). The proposed method
was proved to be effective in Japanese-to-English
transliteration experiments in patent domain.
Future work will investigate the proposed method
</bodyText>
<figure confidence="0.957831">
(b) Some alignment errors in transliteration part
(c) Correctly aligned (d) Errors in partial noise
</figure>
<figureCaption confidence="0.97556775">
Figure 4: Examples of noise-aware many-to-many align-
ment in the training data. ϕ stands for a zero-length sub-
string. Dashed lines show incorrect alignments, and bold
grey lines mean their corrections.
</figureCaption>
<bodyText confidence="0.9999085">
in other domains and language pairs. The partial
noise would appear in other language pairs, typ-
ically between agglutinative and non-agglutinative
languages. It is also worth extending the approach
into word alignment in statistical machine transla-
tion.
</bodyText>
<sectionHeader confidence="0.99764" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999017">
We would like to thank anonymous reviewers for
their valuable comments and suggestions.
</bodyText>
<sectionHeader confidence="0.998511" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.991943588235294">
Andrew Finch and Eiichiro Sumita. 2010. A Bayesian
Model of Bilingual Segmentation for Transliteration.
In Proceedings of the seventh International Workshop
on Spoken Language Translation (IWSLT), pages 259–
266.
Isao Goto, Ka Po Chow, Bin Lu, Eiichiro Sumita, and
Benjamin K. Tsou. 2013. Overview of the Patent Ma-
chine Translation Task at the NTCIR-10 Workshop. In
The 10th NTCIR Conference, June.
Ohnmar Htun, Andrew Finch, Eiichiro Sumita, and
Yoshiki Mikami. 2012. Improving Transliteration
Mining by Integrating Expert Knowledge with Statis-
tical Approaches. International Journal of Computer
Applications, 58(17):12–22, November.
Kevin Knight and Jonathan Graehl. 1998. Machine
transliteration. Computational Linguistics, 24(4):599–
612.
</reference>
<figure confidence="0.999776098360656">
e
ジ
g
i
n
タ
t a
sp
sp
ク
r c
ー
a
ア
a
n t
n sp
noise noise
x i h
(a) Correctly aligned
T オ
noise noise
ン
d
F
o
ー
p
ピ
i
ン グ φ エ ネ
e
n g
sp
e n
ル
r
ギ
g y
ー
f
フ t
o
ー
r
m
A
e
noise
d
c
ii
u
A タ マ T
s
t
o m i z
X
e
noise
d
</figure>
<page confidence="0.972405">
208
</page>
<reference confidence="0.999872071428571">
Haizhou Li, A Kumaran, Min Zhang, and Vladimir Per-
vouchine. 2010. Whitepaper of NEWS 2010 Shared
Task on Transliteration Generation. In Proceedings
of the 2010 Named Entities Workshop, pages 12–20,
Uppsala, Sweden, July. Association for Computational
Linguistics.
Daichi Mochihashi, Takeshi Yamada, and Naonori Ueda.
2009. Bayesian Unsupervised Word Segmentation
with Nested Pitman-Yor Language Modeling. In Pro-
ceedings of the Joint Conference of the 47th Annual
Meeting of the ACL and the 4th International Joint
Conference on Natural Language Processing of the
AFNLP, pages 100–108, Suntec, Singapore, August.
Association for Computational Linguistics.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of 40th
Annual Meeting of the Association for Computational
Linguistics, pages 311–318, Philadelphia, Pennsylva-
nia, USA, July. Association for Computational Lin-
guistics.
Hassan Sajjad, Alexander Fraser, and Helmut Schmid.
2012. A statistical model for unsupervised and semi-
supervised transliteration mining. In Proceedings of
the 50th Annual Meeting of the Association for Com-
putational Linguistics (Volume 1: Long Papers), pages
469–477, Jeju Island, Korea, July. Association for
Computational Linguistics.
</reference>
<page confidence="0.99896">
209
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.530061">
<title confidence="0.999039">Noise-aware Character Alignment for Bootstrapping Statistical</title>
<author confidence="0.658128">Transliteration from Bilingual Corpora</author>
<affiliation confidence="0.94931">Communication Science School of Informatics, Kyoto Center for Computing and Media Studies, Kyoto</affiliation>
<email confidence="0.918802">sudoh.katsuhito@lab.ntt.co.jp</email>
<abstract confidence="0.99863425">This paper proposes a novel noise-aware character alignment method for bootstrapping statistical machine transliteration from automatically extracted phrase pairs. The model is an extension of a Bayesian many-to-many alignment method for distinguishing nontransliteration (noise) parts in phrase pairs. It worked effectively in the experiments of bootstrapping Japanese-to-English statistical machine transliteration in patent domain using patent bilingual corpora.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Eiichiro Sumita</author>
</authors>
<title>A Bayesian Model of Bilingual Segmentation for Transliteration.</title>
<date>2010</date>
<booktitle>In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT),</booktitle>
<pages>259--266</pages>
<contexts>
<context position="2782" citStr="Finch and Sumita, 2010" startWordPosition="388" endWordPosition="391">ntified by automatic word alignment and a wrong alignment between the compound word in A and only one component word in B is found. The sample-wise mining cannot make a correct decision of partial transliteration on the aligned candidate, and may introduces noise to the statistical transliteration model. This paper proposes a novel transliteration mining method for such partial transliterations. The method uses a noise-aware character alignment model that distinguish non-transliteration (noise) parts from transliteration (signal) parts. The model is an extension of a Bayesian alignment model (Finch and Sumita, 2010) and can be trained by a sampling algorithm extended for a constraint on noise. Our experiments of Japanese-to-English transliteration achieved 16% relative error reduction in transliteration accuracy from the sample-wise method. The main contribution of this paper is two-fold: • we formulate alignment over string pairs with partial noise and present a solution with a noise-aware alignment model; • we proved its effectiveness by experiments with frequent unknown words in actual Japanese-to-English patent translation data. 204 Proceedings of the 2013 Conference on Empirical Methods in Natural L</context>
<context position="8104" citStr="Finch and Sumita (2010)" startWordPosition="1257" endWordPosition="1260">is paper and consider a more complex mid-noise problem as future work. Figure 2 shows a partial noise example in both the beginning and end. This example is actually correct translation but includes noise in a sense of transliteration; an article “the” is wrongly included in the phrase pair (no articles are used in Japanese) and a plural noun “masks” is transliterated into “マスク”(mask). These non-transliteration parts are aligned to noise symbols in the proposed model. The noise symbols are treated as zero-length substrings in the model, same as other substrings. 3.3 Constrained Gibbs sampling Finch and Sumita (2010) used a blocked Gibbs sampling algorithm with forward-filtering backwardsampling (FFBS) (Mochihashi et al., 2009). We extend their algorithm for our noise-aware model using a state-based calculation over the three states: non-transliteration part in the beginning (noiseB), transliteration part (signal), non-transliteration part in the end (noiseE). Figure 3 illustrates our FFBS steps. At first in the forward filtering, we begin with transition to noiseB and signal. The calculation of forward probabilities itself is almost the same as Finch and Sumita (2010) except for state transition constrai</context>
<context position="13003" citStr="Finch and Sumita, 2010" startWordPosition="2009" endWordPosition="2012">7 (4.1%) English characters3. 4.2.3 Proposed method using aligned joint substrings as phrases (PROPOSED-JOINT) The many-to-many character alignment actually induces substring pairs, which can be used as 3The reason of larger number of partial noise in English side would be a syntactic difference as shown in Figure 2 and the katakana-based filtering heuristics. Table 1: Statistics of the training sets. Method #pairs #Ja chars. #En chars. BASELINE 104,563 899,080 1,372,993 PROPOSED 104,561 893,366 1,317,256 phrases in statistical machine transliteration and improved transliteration performance (Finch and Sumita, 2010). We extracted them by: 1) generate many-to-many word alignment, in which all possible word alignment links in many-to-many correspondences (e.g., 0-0 0-1 0-2 1-0 1-1 1-2 for ⟨コ ン, c o m⟩), 2) run phrase extraction and scoring same as a standard Moses training. This procedure extracts longer phrases satisfying the many-to-many alignment constraints than the simple use of extracted joint substring pairs as phrases. 4.3 Results Table 2 shows the results. We used three evaluation metrics: ACC, F-score, and BLEUc. ACC is a sample-wise accuracy and F-score is a characterwise F-measure-like score (L</context>
<context position="14402" citStr="Finch and Sumita (2010)" startWordPosition="2235" endWordPosition="2238">F-score (25% relative error reduction from BASELINE). These improvements clearly showed an advantage of the proposed method over the samplewise mining. BLEUc showed a similar improvements. Recall that BASELINE and PROPOSED had a small difference in their training data, actually 0.64% (katakana) and 4.1% (English) in the number of characters. The results suggest that the partial noise can hurt transliteration models. PROPOSED-JOINT showed similar performance as PROPOSED with a slight drop in BLEUc, although many-to-many substring alignment was expected to improve transliteration as reported by Finch and Sumita (2010). The difference may be due to the difference in coverage of the phrase tables; PROPOSED-JOINT retained relatively long substrings by the many-to-many alignment constraints in contrast to the less-constrained growdiag-final-and alignments in PROPOSED. Since the training data in our bootstrapping experiments con207 Table 2: Japanese-to-English transliteration results for top-1000 unknown katakana words. ACC and F-score stand for the ones used in NEWS workshop, BLEU� is character-wise BLEU. Method ACC F-score BLEU� BASELINE 0.56 0.929 0.864 PROPOSED 0.63 0.946 0.897 PROPOSED-JOINT 0.63 0.943 0.8</context>
<context position="16521" citStr="Finch and Sumita (2010)" startWordPosition="2559" endWordPosition="2562"> in which partial noise was incorrectly aligned. (c) and (d) have similar partial noise in their English word endings, but it could not be identified in (d). One possible reason for that is the sparseness problem mentioned above, as shown in erroneous long character alignments in (d). 5 Conclusion This paper proposed a noise-aware many-to-many alignment model that can distinguish partial noise in transliteration pairs for bootstrapping statistical machine transliteration model from automatically extracted phrase pairs. The model and training algorithm are straightforward extension of those by Finch and Sumita (2010). The proposed method was proved to be effective in Japanese-to-English transliteration experiments in patent domain. Future work will investigate the proposed method (b) Some alignment errors in transliteration part (c) Correctly aligned (d) Errors in partial noise Figure 4: Examples of noise-aware many-to-many alignment in the training data. ϕ stands for a zero-length substring. Dashed lines show incorrect alignments, and bold grey lines mean their corrections. in other domains and language pairs. The partial noise would appear in other language pairs, typically between agglutinative and non</context>
</contexts>
<marker>Finch, Sumita, 2010</marker>
<rawString>Andrew Finch and Eiichiro Sumita. 2010. A Bayesian Model of Bilingual Segmentation for Transliteration. In Proceedings of the seventh International Workshop on Spoken Language Translation (IWSLT), pages 259– 266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isao Goto</author>
<author>Ka Po Chow</author>
<author>Bin Lu</author>
<author>Eiichiro Sumita</author>
<author>Benjamin K Tsou</author>
</authors>
<date>2013</date>
<booktitle>Overview of the Patent Machine Translation Task at the NTCIR-10 Workshop. In The 10th NTCIR Conference,</booktitle>
<contexts>
<context position="9429" citStr="Goto et al., 2013" startWordPosition="1452" endWordPosition="1455">ed sampling with true posteriors, starting from the choice of the ending state among noiseB (means full noise), signal, and noiseE. This algorithm increases the computational cost by three times to consider three different states, compared to that of Finch and Sumita (2010). (a) Forward filtering (b) Backward sampling Figure 3: State-based FFBS for the proposed model. 4 Experiments We conducted experiments comparing the proposed method with the conventional sample-wise method for the use in bootstrapping statistical machine transliteration using Japanese-to-English patent translation dataset (Goto et al., 2013). 4.1 Training data setup First, we trained a phrase table on the 3.2M parallel sentences by a standard training procedure using Moses, with Japanese tokenization using MeCab1. We obtained 591,840 phrase table entries whose Japanese side was written in katakana (Japanese phonogram) only2. Then, we iteratively ran the method of Sajjad et al. (2012) on these entries and eliminate non-transliteration pairs, until the number of pairs converged. Finally we obtain 104,563 katakana-English pairs after 10 iterations; they were our baseline training set mined by sample-wise method. We used Sajjad et al</context>
</contexts>
<marker>Goto, Chow, Lu, Sumita, Tsou, 2013</marker>
<rawString>Isao Goto, Ka Po Chow, Bin Lu, Eiichiro Sumita, and Benjamin K. Tsou. 2013. Overview of the Patent Machine Translation Task at the NTCIR-10 Workshop. In The 10th NTCIR Conference, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ohnmar Htun</author>
<author>Andrew Finch</author>
<author>Eiichiro Sumita</author>
<author>Yoshiki Mikami</author>
</authors>
<title>Improving Transliteration Mining by Integrating Expert Knowledge with Statistical Approaches.</title>
<date>2012</date>
<journal>International Journal of Computer Applications,</journal>
<volume>58</volume>
<issue>17</issue>
<contexts>
<context position="6077" citStr="Htun et al. (2012)" startWordPosition="931" endWordPosition="934"> correct many-to-many alignment links. 3.1 Partial noise in transliteration data Figure 1 shows transliteration examples with “no noise,” “noise,” and “partial noise.” Solid lines in the figure show correct many-to-many alignment links. The examples (a) and (b) can be distinguished effectively by Sajjad et al. (2012). We aim to do alignment as in the examples (c) and (d) by distinguishing its non-transliteration (noise) part, which cannot be handled by the existing methods. 3.2 Noise-aware alignment model We introduce a noise symbol to handle partial noise in the many-to-many alignment model. Htun et al. (2012) extended the many-to-many alignment for the sample-wise transliteration mining, but its noise model only handles the sample-wise noise and cannot distinguish partial noise. We model partial noise in the CRP-based joint substring model. Partial noise in transliteration data typically appears in compound words as mentioned earlier, because their counterparts consisting of two or more words may not be fully covered in automatically extracted words and phrases as shown in Figure 1(c). Another type of partial noise is derived from morphological differences due to inflection, which usually appear i</context>
</contexts>
<marker>Htun, Finch, Sumita, Mikami, 2012</marker>
<rawString>Ohnmar Htun, Andrew Finch, Eiichiro Sumita, and Yoshiki Mikami. 2012. Improving Transliteration Mining by Integrating Expert Knowledge with Statistical Approaches. International Journal of Computer Applications, 58(17):12–22, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<volume>24</volume>
<issue>4</issue>
<pages>612</pages>
<contexts>
<context position="1080" citStr="Knight and Graehl, 1998" startWordPosition="133" endWordPosition="136">ne transliteration from automatically extracted phrase pairs. The model is an extension of a Bayesian many-to-many alignment method for distinguishing nontransliteration (noise) parts in phrase pairs. It worked effectively in the experiments of bootstrapping Japanese-to-English statistical machine transliteration in patent domain using patent bilingual corpora. 1 Introduction Transliteration is used for providing translations for source language words that have no appropriate counterparts in target language, such as some technical terms and named entities. Statistical machine transliteration (Knight and Graehl, 1998) is a technology to solve it in a statistical manner. Bilingual dictionaries can be used to train its model, but many of their entries are actually translation but not transliteration. Such non-transliteration pairs hurt the transliteration model and should be eliminated beforehand. Sajjad et al. (2012) proposed a method to identify such non-transliteration pairs, and applied it successfully to noisy word pairs obtained from automatic word alignment on bilingual corpora. It enables the statistical machine transliteration to be bootstrapped from bilingual corpora. This approach is beneficial be</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4):599– 612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>A Kumaran</author>
<author>Min Zhang</author>
<author>Vladimir Pervouchine</author>
</authors>
<title>Shared Task on Transliteration Generation.</title>
<date>2010</date>
<journal>Whitepaper of NEWS</journal>
<booktitle>In Proceedings of the 2010 Named Entities Workshop,</booktitle>
<pages>12--20</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="13618" citStr="Li et al., 2010" startWordPosition="2111" endWordPosition="2114">). We extracted them by: 1) generate many-to-many word alignment, in which all possible word alignment links in many-to-many correspondences (e.g., 0-0 0-1 0-2 1-0 1-1 1-2 for ⟨コ ン, c o m⟩), 2) run phrase extraction and scoring same as a standard Moses training. This procedure extracts longer phrases satisfying the many-to-many alignment constraints than the simple use of extracted joint substring pairs as phrases. 4.3 Results Table 2 shows the results. We used three evaluation metrics: ACC, F-score, and BLEUc. ACC is a sample-wise accuracy and F-score is a characterwise F-measure-like score (Li et al., 2010). BLEUc is BLEU (Papineni et al., 2002) in the character level with n=4. PROPOSED achieved 63% in ACC (16% relative error reduction from BASELINE), and 94.6% in F-score (25% relative error reduction from BASELINE). These improvements clearly showed an advantage of the proposed method over the samplewise mining. BLEUc showed a similar improvements. Recall that BASELINE and PROPOSED had a small difference in their training data, actually 0.64% (katakana) and 4.1% (English) in the number of characters. The results suggest that the partial noise can hurt transliteration models. PROPOSED-JOINT show</context>
</contexts>
<marker>Li, Kumaran, Zhang, Pervouchine, 2010</marker>
<rawString>Haizhou Li, A Kumaran, Min Zhang, and Vladimir Pervouchine. 2010. Whitepaper of NEWS 2010 Shared Task on Transliteration Generation. In Proceedings of the 2010 Named Entities Workshop, pages 12–20, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daichi Mochihashi</author>
<author>Takeshi Yamada</author>
<author>Naonori Ueda</author>
</authors>
<title>Bayesian Unsupervised Word Segmentation with Nested Pitman-Yor Language Modeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>100--108</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="8217" citStr="Mochihashi et al., 2009" startWordPosition="1273" endWordPosition="1276"> both the beginning and end. This example is actually correct translation but includes noise in a sense of transliteration; an article “the” is wrongly included in the phrase pair (no articles are used in Japanese) and a plural noun “masks” is transliterated into “マスク”(mask). These non-transliteration parts are aligned to noise symbols in the proposed model. The noise symbols are treated as zero-length substrings in the model, same as other substrings. 3.3 Constrained Gibbs sampling Finch and Sumita (2010) used a blocked Gibbs sampling algorithm with forward-filtering backwardsampling (FFBS) (Mochihashi et al., 2009). We extend their algorithm for our noise-aware model using a state-based calculation over the three states: non-transliteration part in the beginning (noiseB), transliteration part (signal), non-transliteration part in the end (noiseE). Figure 3 illustrates our FFBS steps. At first in the forward filtering, we begin with transition to noiseB and signal. The calculation of forward probabilities itself is almost the same as Finch and Sumita (2010) except for state transition constraints: from noiseB to signal, from signal to noiseE. The backward-sampling traverses a path by probabilitybased sam</context>
</contexts>
<marker>Mochihashi, Yamada, Ueda, 2009</marker>
<rawString>Daichi Mochihashi, Takeshi Yamada, and Naonori Ueda. 2009. Bayesian Unsupervised Word Segmentation with Nested Pitman-Yor Language Modeling. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 100–108, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Philadelphia, Pennsylvania, USA,</location>
<contexts>
<context position="13657" citStr="Papineni et al., 2002" startWordPosition="2118" endWordPosition="2121">ate many-to-many word alignment, in which all possible word alignment links in many-to-many correspondences (e.g., 0-0 0-1 0-2 1-0 1-1 1-2 for ⟨コ ン, c o m⟩), 2) run phrase extraction and scoring same as a standard Moses training. This procedure extracts longer phrases satisfying the many-to-many alignment constraints than the simple use of extracted joint substring pairs as phrases. 4.3 Results Table 2 shows the results. We used three evaluation metrics: ACC, F-score, and BLEUc. ACC is a sample-wise accuracy and F-score is a characterwise F-measure-like score (Li et al., 2010). BLEUc is BLEU (Papineni et al., 2002) in the character level with n=4. PROPOSED achieved 63% in ACC (16% relative error reduction from BASELINE), and 94.6% in F-score (25% relative error reduction from BASELINE). These improvements clearly showed an advantage of the proposed method over the samplewise mining. BLEUc showed a similar improvements. Recall that BASELINE and PROPOSED had a small difference in their training data, actually 0.64% (katakana) and 4.1% (English) in the number of characters. The results suggest that the partial noise can hurt transliteration models. PROPOSED-JOINT showed similar performance as PROPOSED with</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a Method for Automatic Evaluation of Machine Translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, Pennsylvania, USA, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hassan Sajjad</author>
<author>Alexander Fraser</author>
<author>Helmut Schmid</author>
</authors>
<title>A statistical model for unsupervised and semisupervised transliteration mining.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>469--477</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="1384" citStr="Sajjad et al. (2012)" startWordPosition="181" endWordPosition="184">ration in patent domain using patent bilingual corpora. 1 Introduction Transliteration is used for providing translations for source language words that have no appropriate counterparts in target language, such as some technical terms and named entities. Statistical machine transliteration (Knight and Graehl, 1998) is a technology to solve it in a statistical manner. Bilingual dictionaries can be used to train its model, but many of their entries are actually translation but not transliteration. Such non-transliteration pairs hurt the transliteration model and should be eliminated beforehand. Sajjad et al. (2012) proposed a method to identify such non-transliteration pairs, and applied it successfully to noisy word pairs obtained from automatic word alignment on bilingual corpora. It enables the statistical machine transliteration to be bootstrapped from bilingual corpora. This approach is beneficial because it does not require carefullydeveloped bilingual transliteration dictionaries and it can learn domain-specific transliteration patterns from bilingual corpora in the target domain. However, their transliteration mining approach is samplewise; that is, it makes a decision whether a bilingual phrase</context>
<context position="5777" citStr="Sajjad et al. (2012)" startWordPosition="882" endWordPosition="885">pelling model. 3 Proposed method We propose an extended many-to-many alignment model that can handle partial noise. We extend the model in the previous section by introducing a noise symbol and state-based probability calculation. Figure 1: Three types of noise in transliteration data. Solid lines are correct many-to-many alignment links. 3.1 Partial noise in transliteration data Figure 1 shows transliteration examples with “no noise,” “noise,” and “partial noise.” Solid lines in the figure show correct many-to-many alignment links. The examples (a) and (b) can be distinguished effectively by Sajjad et al. (2012). We aim to do alignment as in the examples (c) and (d) by distinguishing its non-transliteration (noise) part, which cannot be handled by the existing methods. 3.2 Noise-aware alignment model We introduce a noise symbol to handle partial noise in the many-to-many alignment model. Htun et al. (2012) extended the many-to-many alignment for the sample-wise transliteration mining, but its noise model only handles the sample-wise noise and cannot distinguish partial noise. We model partial noise in the CRP-based joint substring model. Partial noise in transliteration data typically appears in comp</context>
<context position="9778" citStr="Sajjad et al. (2012)" startWordPosition="1507" endWordPosition="1510">for the proposed model. 4 Experiments We conducted experiments comparing the proposed method with the conventional sample-wise method for the use in bootstrapping statistical machine transliteration using Japanese-to-English patent translation dataset (Goto et al., 2013). 4.1 Training data setup First, we trained a phrase table on the 3.2M parallel sentences by a standard training procedure using Moses, with Japanese tokenization using MeCab1. We obtained 591,840 phrase table entries whose Japanese side was written in katakana (Japanese phonogram) only2. Then, we iteratively ran the method of Sajjad et al. (2012) on these entries and eliminate non-transliteration pairs, until the number of pairs converged. Finally we obtain 104,563 katakana-English pairs after 10 iterations; they were our baseline training set mined by sample-wise method. We used Sajjad et al.’s method as preprocessing for filtering sample-wise noise while the proposed method could also do that, because the proposed method took much more training time for all phrase table entries. 4.2 Transliteration experiments The transliteration experiment used a translationbased implementation with Moses, using a 1http://code.google.com/p/mecab/ 2</context>
</contexts>
<marker>Sajjad, Fraser, Schmid, 2012</marker>
<rawString>Hassan Sajjad, Alexander Fraser, and Helmut Schmid. 2012. A statistical model for unsupervised and semisupervised transliteration mining. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 469–477, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>