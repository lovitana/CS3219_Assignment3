<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000075">
<title confidence="0.998303">
Using Soft Constraints in Joint Inference for
Clinical Concept Recognition
</title>
<author confidence="0.99536">
Prateek Jindal and Dan Roth
</author>
<affiliation confidence="0.999023">
Department of Computer Science, UIUC
</affiliation>
<address confidence="0.817507">
201 N. Goodwin Ave, Urbana, IL 61801, USA
</address>
<email confidence="0.998719">
{jindal2, danr}@illinois.edu
</email>
<sectionHeader confidence="0.993866" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999762444444444">
This paper introduces IQPs (Integer Quadratic
Programs) as a way to model joint inference
for the task of concept recognition in clinical
domain. IQPs make it possible to easily in-
corporate soft constraints in the optimization
framework and still support exact global infer-
ence. We show that soft constraints give statis-
tically significant performance improvements
when compared to hard constraints.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.991907612244898">
In this paper, we study the problem of concept
recognition in the clinical domain. State-of-the-art
approaches (de Bruijn et al., 2011; Patrick et al.,
2011; Torii et al., 2011; Minard et al., 2011; Jiang
et al., 2011; Xu et al., 2012; Roberts and Harabagiu,
2011; Jindal and Roth, 2013) for concept recogni-
tion in clinical domain (Uzuner et al., 2011) use
sequence-prediction models like CRF (Lafferty et
al., 2001), MEMM (McCallum et al., 2000) etc.
These approaches are limited by the fact that they
can model only local dependencies (most often,
first-order models like linear chain CRFs are used
to allow tractable inference).
Clinical narratives, unlike newswire data, provide
a domain with significant knowledge that can be ex-
ploited systematically to improve the accuracy of
the prediction task. Knowledge in this domain can
be thought of as belonging to two categories: (1)
Background Knowledge captured in medical ontolo-
gies like UMLS (Url1, 2013), MeSH and SNOMED
CT and (2) Discourse Knowledge driven by the
fact that the narratives adhere to a specific writing
style. While the former can be used by generating
more expressive knowledge-rich features, the lat-
ter is more interesting from our current perspective,
since it provides global constraints on what output
structures are likely and what are not. We exploit
this structural knowledge in our global inference for-
mulation.
Integer Linear Programming (ILP) based ap-
proaches have been used for global inference in
many works (Roth and Yih, 2004; Punyakanok et
al., 2004; Punyakanok et al., 2008; Marciniak and
Strube, 2005; Bramsen et al., 2006; Barzilay and
Lapata, 2006; Riedel and Clarke, 2006; Clarke and
Lapata, 2007; Clarke and Lapata, 2008; Denis et al.,
2007; Chang et al., 2011). However, in most of these
works, researchers have focussed only on hard con-
straints while formulating the inference problem.
Formulating all the constraints as hard constraints
is not always desirable because the constraints are
not perfect in many cases. In this paper, we pro-
pose Integer Quadratic Programs (IQPs) as a way
of formulating the inference problem. IQPs is a
richer family of models than ILPs and it enables
us to easily incorporate soft constraints into the in-
ference procedure. Our experimental results show
that soft constraints indeed give much better perfor-
mance than hard constraints.
</bodyText>
<sectionHeader confidence="0.992897" genericHeader="method">
2 Identifying Medical Concepts
</sectionHeader>
<bodyText confidence="0.9985236">
Task Description Our input consists of clinical re-
ports in free-text (unstructured) format. The task is:
(1) to identify the boundaries of medical concepts
and (2) to assign types to such concepts. Each con-
cept can have 3 possible types: (1) Test, (2) Treat-
ment, and (3) Problem. We would refer to these
three types by TEST, TRE and PROB in the follow-
ing discussion.
Our Approach In the first step, we identify the
concept boundaries using a CRF (with BIO encod-
</bodyText>
<page confidence="0.945029">
1808
</page>
<note confidence="0.818638">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1808–1814,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<figure confidence="0.898776">
Test Problem Problem
[Chest x-ray] gave positive evidence for [atelectasis] and [sarcoidosis].
(a) Example 1
Problem Problem Problem Problem Problem Problem
No [hemoptysis], [hematemesis], [urgency], [abdominal pain], [black or tarry stools], [dysuria].
(b) Example 2
</figure>
<figureCaption confidence="0.999981">
Figure 1: This figure motivates the global inference procedure we used. For discussion, please refer to §2.
</figureCaption>
<bodyText confidence="0.999873157894737">
ing). Features used by the CRF include the con-
stituents given by MetaMap (Aronson and Lang,
2010; Url2, 2013), shallow parse constituents, sur-
face form and part-of-speech (Url3, 2013) of words
in a window of size 3. We also use conjunctions of
the features.
After finding concept boundaries, we determine
the probability distribution for each concept over 4
possible types (TEST, TRE, PROB or NULL). These
probability distributions are found using a multi-
class SVM classifier (Chang and Lin, 2011). Fea-
tures used for training this classifier include con-
cept tokens, full text of concept, bi-grams, head-
word, suffixes of headword, capitalization pattern,
shallow parse constituent, Metamap type of concept,
MetaMap type of headword, occurrence of concept
in MeSH (Url4, 2013) and SNOMED CT (Url5,
2013), MeSH and SNOMED CT descriptors.
Inference Procedure: The final assignment of
types to concepts is determined by an inference pro-
cedure. The basic principle behind our inference
procedure is: “Types of concepts which appear close
to one another are often closely related. For some
concepts, type can be determined with more confi-
dence. And relations between concepts’ types guide
the inference procedure to determine the types of
other concepts.” We will now explain it in more de-
tail with the help of examples. Figure 1 shows two
sentences in which the concepts are shown in brack-
ets and correct (gold) types of concepts are shown
above them.
First, consider first and second concepts in Fig-
ure 1a. These concepts follow the pattern: [Con-
cept1] gave positive evidence for [Concept2]. In
clinical narratives, such a pattern strongly suggests
that Concept1 is of type TEST and Concept2 is of
type PROB. Table 1 shows additional such patterns.
Next, consider different concepts in Figure 1b. All
</bodyText>
<figure confidence="0.88937775">
Pattern
1 using [TRE] for [PROB]
2 [TEST] showed [PROB]
3 Patient presents with [PROB] status post
[TRE]
4 use [TRE] to correct [PROB]
5 [TEST] to rule out [PROB]
6 Unfortunately, [TRE] has caused [PROB]
</figure>
<tableCaption confidence="0.998746">
Table 1: Some patterns that were used in constraints.
</tableCaption>
<bodyText confidence="0.999251">
these concepts are separated by commas and hence,
form a list. It is highly likely that such concepts
should have the same type.
</bodyText>
<sectionHeader confidence="0.785126" genericHeader="method">
3 Modeling Global Inference
</sectionHeader>
<bodyText confidence="0.999812272727273">
Inference is done at the level of sentences. Sup-
pose there are m concepts in a sentence. Each of
the m concepts has to be assigned one of the follow-
ing types: TEST, TRE, PROB or NULL. To represent
this as an inference problem, we define the indicator
variables xzj where i takes values from 1 to m (cor-
responding to concepts) and j takes values from 1 to
4 (corresponding to 4 possible types). pzj refers to
the probability that the ith concept has type j.
We can now write the following optimization
problem to find the optimal concept types:
</bodyText>
<equation confidence="0.9924696">
xzj , pz�g (1)
4
subject to � xzj = 1 Vi (2)
g=1
xzj E {0, 11 Vi, j (3)
</equation>
<bodyText confidence="0.9996035">
The objective function in Equation (1) expresses
the fact that we want to maximize the expected num-
ber of correct predictions in each sentence. Equa-
tion (2) enforces the constraint that each concept has
</bodyText>
<equation confidence="0.938614">
4
m
z=1
max
x
�
g=1
</equation>
<page confidence="0.949643">
1809
</page>
<bodyText confidence="0.7861615">
a unique type. We would refer to these as Type-1
constraints.
</bodyText>
<subsectionHeader confidence="0.999607">
3.1 Constraints Used
</subsectionHeader>
<bodyText confidence="0.999939">
In this subsection, we will describe two addi-
tional types of constraints (Type-2 and Type-3)
that were added to the optimization procedure de-
scribed above. Whereas Type-1 constraints de-
scribed above were formulated as hard constraints,
Type-2 and Type-3 constraints are formulated as
soft constraints.
</bodyText>
<subsectionHeader confidence="0.677172">
3.1.1 Type-2 Constraints
</subsectionHeader>
<bodyText confidence="0.999318125">
Certain constructs like comma, conjunction, etc.
suggest that the 2 concepts appearing in them should
have the same type. Figure 1b shows an example of
such a constraint. Suppose that there are n2 such
constraints. Also, assume that the lth constraint says
that the concepts Rl and Sl should have the same
type. To model this, we define a variable wl as fol-
lows:
</bodyText>
<equation confidence="0.989487666666667">
4
wl = X (x7Z�,m − xS�,m)2 (4)
m=1
</equation>
<bodyText confidence="0.999804285714286">
Now, if the concepts Rl and Sl have the same
type, then wl would be equal to 0; otherwise, wl
would be equal to 2. So, the lth constraint can be
enforced by subtracting (P2 · w�
2 ) from the objective
function given by Equation (1). Thus, a penalty of
P2 would be enforced iff this constraint is violated.
</bodyText>
<subsectionHeader confidence="0.513055">
3.1.2 Type-3 Constraints
</subsectionHeader>
<bodyText confidence="0.999943692307692">
Some short patterns suggest possible types for the
concepts which appear in them. Each such pattern,
thus, enforces a constraint on the types of corre-
sponding concepts. Figure 1a shows an example
of such a constraint. Suppose that there are n3
such constraints. Also, assume that the kth con-
straint says that the concept A1,k should have the
type B1,k and that the concept A2,k should have
the type B2,k. Equivalently, the kth constraint can
be written as follows in boolean algebra notation:
(xA1,k,B1,k = 1)∧(xA2,k,B2,k = 1). For the kth con-
straint, we introduce one more variable zk ∈ {0, 1}
which satisfies the following condition:
</bodyText>
<equation confidence="0.931751">
zk = 1 ⇔ xA1,k,B1,k ∧ xA2,k,B2,k (5)
</equation>
<bodyText confidence="0.998899666666667">
Using boolean algebra, it is easy to show that
Equation (5) can be reduced to a set of linear in-
equalities. Thus, we can incorporate the kth con-
</bodyText>
<equation confidence="0.999502444444444">
P3(1 − zk)
4
PM=1(xR�,�−xS�,�)2
2
4
subject to X xi,j = 1 ∀i (7)
j=1
xi,j ∈ {0, 1} ∀i, j (8)
zk = 1 ⇔ xA1,k,B1,k ∧ xA2,k,B2,k∀k ∈ {1...n3} (9)
</equation>
<figureCaption confidence="0.993075">
Figure 2: Final Optimization Problem (an IQP)
</figureCaption>
<bodyText confidence="0.9999258">
straint in the optimization problem by adding to it
the constraint given by Equation (5) and by subtract-
ing (P3(1 − zk)) from the objective function given
by Equation (1). Thus, a penalty of P3 is imposed iff
kth constraint is not satisfied (zk = 0).
</bodyText>
<subsectionHeader confidence="0.999664">
3.2 Final Optimization Problem - An IQP
</subsectionHeader>
<bodyText confidence="0.999707714285714">
After incorporating all the constraints mentioned
above, the final optimization problem (an IQP) is
shown in Figure 2. We used Gurobi toolkit (Url6,
2013) to solve such IQPs. In our case, it solves
76 IQPs per second on a quad-core server with In-
tel Xeon X5650 @ 2.67 GHz processors and 50 GB
RAM.
</bodyText>
<sectionHeader confidence="0.999007" genericHeader="method">
4 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.999096">
4.1 Datasets and Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.999957294117647">
For our experiments, we used the datasets pro-
vided by i2b2/VA team as part of 2010 i2b2/VA
shared task (Uzuner et al., 2011). The datasets
used for this shared task contained de-identied clin-
ical reports from three medical institutions: Part-
ners Healthcare (PH), Beth-Israel Deaconess Med-
ical Center (BTDMC) and the University of Pitts-
burgh Medical Center (UPMC). UPMC data was di-
vided into 2 sections, namely discharge (UPMCD)
and progress notes (UPMCP). A total of 349 train-
ing reports and 477 test reports were made available
to the participants. However, data which came from
UPMC (more than 50% data) was not made avail-
able for public use. As a result, we had only 170
clinical reports for training and 256 clinical reports
for testing. Table 3 shows the number of clinical re-
ports made available by different institutions. The
</bodyText>
<equation confidence="0.948543705882353">
4
XM
i=1
xi,j · pi,j −
max
x
n3
X
k=1
X
j=1
(6)
n2
−
P2 ·
X
�=1
</equation>
<page confidence="0.884542">
1810
</page>
<table confidence="0.999554333333333">
B BK BC BKC
P R F1 P R F1 P R F1 P R F1
TEST 92.4 79.4 85.4 91.9 80.2 85.7 92.7 79.6 85.7 92.1 80.4 85.8
TRE 92.1 73.6 81.8 92.0 79.5 85.3 92.3 76.8 83.8 92.0 80.2 85.7
PROB 83.6 83.6 83.6 88.9 83.7 86.3 85.9 83.8 84.8 89.6 83.9 86.7
OVERALL 88.4 79.4 83.6 90.7 81.4 85.8 89.6 80.5 84.8 91.0 81.7 86.1
</table>
<tableCaption confidence="0.963645">
Table 2: Our final system, BKC, consistently performed the best among all 4 systems (B, BK, BC and BKC).
</tableCaption>
<table confidence="0.999956333333333">
PH BIDMC UPMCD UPMCP
Train 97 73 98 81
Test 133 123 102 119
</table>
<tableCaption confidence="0.999307">
Table 3: Dataset Characteristics
</tableCaption>
<bodyText confidence="0.9998338">
strikethrough text in this table indicates that the data
was not made available for public use and hence, we
couldn’t use it. We used about 20% of the training
data as a development set. For evaluation, we report
precision, recall and F1 scores.
</bodyText>
<sectionHeader confidence="0.743024" genericHeader="evaluation">
4.2 Results
</sectionHeader>
<bodyText confidence="0.9979543125">
In this section, we would refer to following 4
systems: (1) Baseline (B), (2) Baseline + Knowl-
edge (BK), (3) Baseline + Constraints (BC) and
(4) Baseline + Knowledge + Constraints (BKC).
Please note that the difference between B and
BK is that B does not use the features derived
from domain-specific knowledge sources (namely
MetaMap, UMLS, MeSH and SNOMED CT) for
training the classifiers. Both B and BK do not use
the inference procedure. BKC uses all the features
and also the inference procedure. In addition to
these 4 systems, we would refer to another system,
namely, BKC-HARD. This is similar to BKC sys-
tem. However, it sets p2 = p3 = 1 which effectively
turns Type-2 and Type-3 constraints into hard con-
straints by imposing very high penalty.
</bodyText>
<subsectionHeader confidence="0.923727">
4.2.1 Importance of Soft Constraints
</subsectionHeader>
<bodyText confidence="0.999840625">
Figures 3a and 3b show the effect of varying the
penalties (p2 and p3) for Type-2 and Type-3 con-
straints respectively. These figures show the F1-
score of BKC on the development set. Penalty of
0 means that the constraint is not active. As we in-
crease the penalty, the constraint becomes stronger.
As the penalty becomes 1, the constraint becomes
hard in the sense that final assignments must respect
</bodyText>
<figure confidence="0.889506333333333">
Tuning Penalty Parameter for Type−2 Constraints Tuning Penalty Parameter for Type−3 Constraints
Penalty Parameter for Type−2 Constraints ( ρ2) Penalty Parameter for Type−3 Constraints ( ρ3)
(a) Type-2 Constraints (b) Type-3 Constraints
</figure>
<figureCaption confidence="0.9858865">
Figure 3: These figures show the result of tuning the
penalty parameters (p2 and p3) for soft constraints.
</figureCaption>
<table confidence="0.999405">
BKC-HARD BKC
TEST 84.7 85.8
TRE 84.7 85.7
PROB 85.6 86.7
OVERALL 85.1 86.1
</table>
<tableCaption confidence="0.988052">
Table 4: Soft constraints (BKC) consistently perform
much better than hard constraints (BKC-HARD).
</tableCaption>
<bodyText confidence="0.997841866666667">
the constraint. We observe from Figures 3a and 3b
that for Type-2 and Type-3 constraints, global max-
ima is attained at p2 = 0.6 and p3 = 0.3 respec-
tively.
Hard vs Soft Constraints Table 4 compares the
performance of BKC-HARD with that of BKC.
First 3 rows in this table show the performance of
both systems for the individual categories (TEST,
TRE and PROB). The fourth row shows the overall
score of both systems. BKC outperformed BKC-
HARD on all the categories by statistically signifi-
cant differences at p = 0.05 according to Bootstrap
Resampling Test (Koehn, 2004). For the OVERALL
category, BKC improved over BKC-HARD by 1.0
F1 points.
</bodyText>
<figure confidence="0.9773008">
F1−score
80.7
80.6
80.5
80.4
80.3
80.2
80.1
79.9
79.8
79.7
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
80
F1−swm
81.5
81.4
81.3
81.2
81.1
80.9
80.8
80.7
80.6
80.5
80.4
80.3
0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1
81
1811
Effect of Training Data Size on Performance
</figure>
<figureCaption confidence="0.9956145">
Figure 4: This figure shows the effect of training data
size on performance of concept recognition.
</figureCaption>
<subsectionHeader confidence="0.649176">
4.2.2 Comparing with state-of-the-art baseline
</subsectionHeader>
<bodyText confidence="0.999994611111111">
In the 2010 i2b2/VA shared task, majority of
top systems were CRF-based models, motivating
the use of CRF as our baseline. Table 2 com-
pares the performance of 4 systems: B, BK, BC
and BKC. As pointed out before, our BK system
uses CRF for boundary detection, employs all the
knowledge-based features and is very similar to the
top-performing systems in i2b2 challenge. We see
from Table 2 that BKC consistently performed the
best for individual as well as overall categories1.
This result is statistically significant at p = 0.05
according to Bootstrap Resampling Test (Koehn,
2004). It should also be noted that BC performed
significantly better than B for all the categories.
Thus, the constraints are helpful even in the ab-
sence of knowledge-based features. Since we report
results on publicly available datasets, future works
would be able to compare their results with ours.
</bodyText>
<subsectionHeader confidence="0.718656">
4.2.3 Effect of training data size
</subsectionHeader>
<bodyText confidence="0.9999375">
In Figure 4, we report the overall F1-score on a
part of the development set as we vary the size of the
training data from 40 documents to 130 documents.
We notice that the performance increases steadily as
more and more training data is provided. This sug-
gests that if we could train on full training data as
was made available in the challenge, the final scores
could be much higher. We also notice from the fig-
ure that BKC consistently outperforms the state-of-
the-art BK system as we vary the size of the training
data, indicating the robustness of the joint inference
procedure.
</bodyText>
<footnote confidence="0.982008666666667">
1Please note that the results reported in Table 2 can not be
directly compared with those reported in the challenge because
we only had a fraction of the original training and testing data.
</footnote>
<sectionHeader confidence="0.688" genericHeader="discussions">
5 Discussion and Related Work
</sectionHeader>
<bodyText confidence="0.999948043478261">
In this paper, we chose to train a rather simple se-
quential model (using CRF), and focused on incor-
porating global constraints only at inference time2.
While it is possible to jointly train the model with
the global constraints (as illustrated by Chang et al.
(2007), Mann and McCallum (2007), Mann and Mc-
Callum (2008), Ganchev et al. (2010) etc.), this pro-
cess will be a lot less efficient, and prior work (Roth
and Yih, 2005) has shown that it may not be benefi-
cial.
Roth and Yih (2004, 2007) suggested the use of
integer programs to model joint inference in a fully
supervised setting. Our paper follows their concep-
tual approach. However, they used only hard con-
straints in their inference formulation. Chang et
al. (2012) extended the ILP formulation and used
soft constraints within the Constrained Conditional
Model formulation (Chang, 2011). However, their
implementation performed only approximate infer-
ence. In this paper, we extended the integer lin-
ear programming to a quadratic formulation, argu-
ing that it simplifies the modeling step3, and showed
that it is possible to do exact inference efficiently.
</bodyText>
<sectionHeader confidence="0.663693" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.9999945">
This paper presented a global inference strategy
(using IQP) for concept recognition which allows
us to model structural knowledge of the clinical do-
main as soft constraints in the optimization frame-
work. Our results showed that soft constraints are
more effective than hard constraints.
</bodyText>
<sectionHeader confidence="0.9873" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998653">
This research was supported by Grant HHS
90TR0003/01 and by IARPA FUSE program via
DoI/NBC contract #D11PC2015. Its contents are
solely the responsibility of the authors and do not
necessarily represent the official views, either ex-
pressed or implied, of the HHS, IARPA, DoI/NBC
or the US government. The US Government is
authorized to reproduce and distribute reprints for
Governmental purposes notwithstanding any copy-
right annotation thereon.
</bodyText>
<footnote confidence="0.993018">
2In another experiment, we replaced the CRF with an
MEMM. Surprisingly, MEMM performed as well as CRF.
3It should be noted that it is possible to reduce IQPs to ILPs
using variable substitution. However, the resulting ILPs can be
exponentially larger than original IQPs.
</footnote>
<figure confidence="0.939738416666667">
86
BKC
BK
84
83
82
81
80
40 50 60 70 80 90 100 110 120 130
Training Data Size (# clinical reports)
F1−score
85
</figure>
<page confidence="0.9941">
1812
</page>
<sectionHeader confidence="0.89933" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.939969820754717">
A.R. Aronson and F.M. Lang. 2010. An overview of
metamap: historical perspective and recent advances.
Journal of the American Medical Informatics Associa-
tion, 17(3):229.
R. Barzilay and M. Lapata. 2006. Aggregation via set
partitioning for natural language generation. In Pro-
ceedings of the main conference on Human Language
Technology Conference of the North American Chap-
ter of the Association of Computational Linguistics,
pages 359–366. Association for Computational Lin-
guistics.
P. Bramsen, P. Deshpande, Y.K. Lee, and R. Barzilay.
2006. Inducing temporal graphs. In Proceedings of
the 2006 Conference on Empirical Methods in Natural
Language Processing, pages 189–198. Association for
Computational Linguistics.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM:
A library for support vector machines. ACM Transac-
tions on Intelligent Systems and Technology, 2:27:1–
27:27. Software available at http://www.csie.
ntu.edu.tw/˜cjlin/libsvm.
M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semi-
supervision with constraint-driven learning. InAssoci-
ation for Computational Linguistics, pages 280–287,
Prague, Czech Republic, 6. Association for Computa-
tional Linguistics.
K.-W. Chang, R. Samdani, A. Rozovskaya, N. Rizzolo,
M. Sammons, and D. Roth. 2011. Inference proto-
cols for coreference resolution. In Proceedings of the
Fifteenth Conference on Computational Natural Lan-
guage Learning: Shared Task, pages 40–44, Portland,
Oregon, USA. Association for Computational Linguis-
tics.
Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2012.
Structured learning with constrained conditional mod-
els. Machine learning, pages 1–33.
M. Chang. 2011. Structured Prediction with Indirect
Supervision. Ph.D. thesis, University of Illinois at
Urbana-Champaign.
James Clarke and Mirella Lapata. 2007. Modelling com-
pression with discourse constraints. In Proceedings
of the 2007 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning (EMNLP-CoNLL), pages
1–11.
J. Clarke and M. Lapata. 2008. Global inference for
sentence compression: An integer linear programming
approach. Journal of Artificial Intelligence Research,
31(1):399–429.
B. de Bruijn, C. Cherry, S. Kiritchenko, J. Martin, and
X. Zhu. 2011. Machine-learned solutions for three
stages of clinical information extraction: the state of
the art at i2b2 2010. Journal of the American Medical
Informatics Association, 18(5):557–562.
P. Denis, J. Baldridge, et al. 2007. Joint determi-
nation of anaphoricity and coreference resolution us-
ing integer programming. In Proceedings of Human
Language Technologies 2007: The Conference of the
North American Chapter of the Association for Com-
putational Linguistics, pages 236–243.
Kuzman Ganchev, Joao Grac¸a, Jennifer Gillenwater, and
Ben Taskar. 2010. Posterior regularization for struc-
tured latent variable models. The Journal of Machine
Learning Research, 11:2001–2049.
M. Jiang, Y. Chen, M. Liu, S.T. Rosenbloom, S. Mani,
J.C. Denny, and H. Xu. 2011. A study of machine-
learning-based approaches to extract clinical entities
and their assertions from discharge summaries. J Am
Med Info Assoc, 18(5):601–606.
P. Jindal and D. Roth. 2013. End-to-end coreference res-
olution for clinical narratives. In Proceedings of In-
ternational Joint Conference on Artificial Intelligence
(IJCAI), pages 2106–2112, 8.
P. Koehn. 2004. Statistical significance tests for machine
translation evaluation. In Proceedings of Empirical
Methods in Natural Language Processing, volume 4,
pages 388–395.
John D. Lafferty, Andrew McCallum, and Fernando C. N.
Pereira. 2001. Conditional random fields: Proba-
bilistic models for segmenting and labeling sequence
data. In Proceedings of the Eighteenth International
Conference on Machine Learning, ICML ’01, pages
282–289, San Francisco, CA, USA. Morgan Kauf-
mann Publishers Inc.
Gideon S Mann and Andrew McCallum. 2007. Sim-
ple, robust, scalable semi-supervised learning via ex-
pectation regularization. In Proceedings of the 24th
international conference on Machine learning, pages
593–600. ACM.
Gideon Mann and Andrew McCallum. 2008. General-
ized expectation criteria for semi-supervised learning
of conditional random fields. In Proceedings of Asso-
ciation for Computational Linguistics, pages 870–878.
T. Marciniak and M. Strube. 2005. Beyond the
pipeline: Discrete optimization in nlp. In Proceed-
ings of the Ninth Conference on Computational Nat-
ural Language Learning, pages 136–143. Association
for Computational Linguistics.
A. McCallum, D. Freitag, and F. Pereira. 2000. Maxi-
mum entropy markov models for information extrac-
tion and segmentation. In Proceedings of the Seven-
teenth International Conference on Machine Learning,
pages 591–598.
A.L. Minard, A.L. Ligozat, A.B. Abacha, D. Bernhard,
B. Cartoni, L. Del´eger, B. Grau, S. Rosset, P. Zweigen-
baum, and C. Grouin. 2011. Hybrid methods for
</reference>
<page confidence="0.598747">
1813
</page>
<reference confidence="0.999288457142857">
improving information access in clinical documents:
Concept, assertion, and relation identification. J Am
Med Info Assoc, 18(5):588–593.
J.D. Patrick, D.H.M. Nguyen, Y. Wang, and M. Li.
2011. A knowledge discovery and reuse pipeline
for information extraction in clinical notes. Jour-
nal of the American Medical Informatics Association,
18(5):574–579.
V. Punyakanok, D. Roth, W. Yih, and D. Zimak. 2004.
Semantic role labeling via integer linear programming
inference. In Proceedings of the 20th international
conference on Computational Linguistics, page 1346.
Association for Computational Linguistics.
Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008.
The importance of syntactic parsing and inference in
semantic role labeling. Computational Linguistics,
34(2):257–287.
S. Riedel and J. Clarke. 2006. Incremental integer linear
programming for non-projective dependency parsing.
In Proceedings of the 2006 Conference on Empirical
Methods in Natural Language Processing, pages 129–
137. Association for Computational Linguistics.
K. Roberts and S.M. Harabagiu. 2011. A flexible frame-
work for deriving assertions from electronic medical
records. Journal of the American Medical Informatics
Association, 18(5):568–573.
D. Roth and W. Yih. 2004. A linear programming formu-
lation for global inference in natural language tasks. In
Proceedings of conference on Computational Natural
Language Learning (CoNLL), pages 1–8. Association
for Computational Linguistics.
D. Roth and W. Yih. 2005. Integer linear programming
inference for conditional random fields. In Proceed-
ings of International Conference on Machine Learning
(ICML), pages 737–744.
D. Roth and W. Yih. 2007. Global inference for en-
tity and relation identification via a linear program-
ming formulation. Introduction to Statistical Rela-
tional Learning, pages 553–580.
M. Torii, K. Wagholikar, and H. Liu. 2011. Us-
ing machine learning for concept extraction on clin-
ical documents from multiple data sources. Jour-
nal of the American Medical Informatics Association,
18(5):580–587.
Url1. 2013. Umls: Unified medical language
system (http://www.nlm.nih.gov/research/umls/) (ac-
cessed july 1, 2013).
Url2. 2013. Metamap (http://metamap.nlm.nih.gov/)
(accessed july 1, 2013).
Url3. 2013. Illinois part-of-speech tagger
(http://cogcomp.cs.illinois.edu/page/software view/
pos) (accessed july 1, 2013).
Url4. 2013. Mesh: Medical subject headings
(http://www.nlm.nih.gov/mesh/meshhome.html) (ac-
cessed july 1, 2013).
Url5. 2013. Snomed ct: Snomed clinical terms
(http://www.ihtsdo.org/snomed-ct/) (accessed july 1,
2013).
Url6. 2013. Gurobi optimization toolkit
(http://www.gurobi.com/) (accessed july 1, 2013).
O. Uzuner, B.R. South, S. Shen, and S.L. DuVall. 2011.
2010 i2b2/va challenge on concepts, assertions, and
relations in clinical text. Journal ofAmerican Medical
Informatics Association.
Y. Xu, K. Hong, J. Tsujii, I. Eric, and C. Chang. 2012.
Feature engineering combined with machine learning
and rule-based methods for structured information ex-
traction from narrative clinical discharge summaries.
Journal of the American Medical Informatics Associa-
tion, 19(5):824–832.
</reference>
<page confidence="0.994963">
1814
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.810142">
<title confidence="0.9902445">Using Soft Constraints in Joint Inference Clinical Concept Recognition</title>
<author confidence="0.869733">Jindal</author>
<affiliation confidence="0.999991">Department of Computer Science,</affiliation>
<address confidence="0.999576">201 N. Goodwin Ave, Urbana, IL 61801,</address>
<abstract confidence="0.9934302">This paper introduces IQPs (Integer Quadratic Programs) as a way to model joint inference for the task of concept recognition in clinical domain. IQPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A R Aronson</author>
<author>F M Lang</author>
</authors>
<title>An overview of metamap: historical perspective and recent advances.</title>
<date>2010</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>17</volume>
<issue>3</issue>
<contexts>
<context position="4165" citStr="Aronson and Lang, 2010" startWordPosition="648" endWordPosition="651">thods in Natural Language Processing, pages 1808–1814, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics Test Problem Problem [Chest x-ray] gave positive evidence for [atelectasis] and [sarcoidosis]. (a) Example 1 Problem Problem Problem Problem Problem Problem No [hemoptysis], [hematemesis], [urgency], [abdominal pain], [black or tarry stools], [dysuria]. (b) Example 2 Figure 1: This figure motivates the global inference procedure we used. For discussion, please refer to §2. ing). Features used by the CRF include the constituents given by MetaMap (Aronson and Lang, 2010; Url2, 2013), shallow parse constituents, surface form and part-of-speech (Url3, 2013) of words in a window of size 3. We also use conjunctions of the features. After finding concept boundaries, we determine the probability distribution for each concept over 4 possible types (TEST, TRE, PROB or NULL). These probability distributions are found using a multiclass SVM classifier (Chang and Lin, 2011). Features used for training this classifier include concept tokens, full text of concept, bi-grams, headword, suffixes of headword, capitalization pattern, shallow parse constituent, Metamap type of</context>
</contexts>
<marker>Aronson, Lang, 2010</marker>
<rawString>A.R. Aronson and F.M. Lang. 2010. An overview of metamap: historical perspective and recent advances. Journal of the American Medical Informatics Association, 17(3):229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>M Lapata</author>
</authors>
<title>Aggregation via set partitioning for natural language generation.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>359--366</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2273" citStr="Barzilay and Lapata, 2006" startWordPosition="351" endWordPosition="354">by the fact that the narratives adhere to a specific writing style. While the former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer family of models than ILPs and it enables us to easily incorporate soft constraints into the inference</context>
</contexts>
<marker>Barzilay, Lapata, 2006</marker>
<rawString>R. Barzilay and M. Lapata. 2006. Aggregation via set partitioning for natural language generation. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 359–366. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Bramsen</author>
<author>P Deshpande</author>
<author>Y K Lee</author>
<author>R Barzilay</author>
</authors>
<title>Inducing temporal graphs.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>189--198</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2246" citStr="Bramsen et al., 2006" startWordPosition="347" endWordPosition="350">urse Knowledge driven by the fact that the narratives adhere to a specific writing style. While the former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer family of models than ILPs and it enables us to easily incorporate soft con</context>
</contexts>
<marker>Bramsen, Deshpande, Lee, Barzilay, 2006</marker>
<rawString>P. Bramsen, P. Deshpande, Y.K. Lee, and R. Barzilay. 2006. Inducing temporal graphs. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 189–198. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>2</volume>
<pages>27--27</pages>
<note>Software available at http://www.csie. ntu.edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="4566" citStr="Chang and Lin, 2011" startWordPosition="711" endWordPosition="714"> (b) Example 2 Figure 1: This figure motivates the global inference procedure we used. For discussion, please refer to §2. ing). Features used by the CRF include the constituents given by MetaMap (Aronson and Lang, 2010; Url2, 2013), shallow parse constituents, surface form and part-of-speech (Url3, 2013) of words in a window of size 3. We also use conjunctions of the features. After finding concept boundaries, we determine the probability distribution for each concept over 4 possible types (TEST, TRE, PROB or NULL). These probability distributions are found using a multiclass SVM classifier (Chang and Lin, 2011). Features used for training this classifier include concept tokens, full text of concept, bi-grams, headword, suffixes of headword, capitalization pattern, shallow parse constituent, Metamap type of concept, MetaMap type of headword, occurrence of concept in MeSH (Url4, 2013) and SNOMED CT (Url5, 2013), MeSH and SNOMED CT descriptors. Inference Procedure: The final assignment of types to concepts is determined by an inference procedure. The basic principle behind our inference procedure is: “Types of concepts which appear close to one another are often closely related. For some concepts, type</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1– 27:27. Software available at http://www.csie. ntu.edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Guiding semisupervision with constraint-driven learning. InAssociation for Computational Linguistics,</title>
<date>2007</date>
<pages>280--287</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="16320" citStr="Chang et al. (2007)" startWordPosition="2774" endWordPosition="2777"> the state-ofthe-art BK system as we vary the size of the training data, indicating the robustness of the joint inference procedure. 1Please note that the results reported in Table 2 can not be directly compared with those reported in the challenge because we only had a fraction of the original training and testing data. 5 Discussion and Related Work In this paper, we chose to train a rather simple sequential model (using CRF), and focused on incorporating global constraints only at inference time2. While it is possible to jointly train the model with the global constraints (as illustrated by Chang et al. (2007), Mann and McCallum (2007), Mann and McCallum (2008), Ganchev et al. (2010) etc.), this process will be a lot less efficient, and prior work (Roth and Yih, 2005) has shown that it may not be beneficial. Roth and Yih (2004, 2007) suggested the use of integer programs to model joint inference in a fully supervised setting. Our paper follows their conceptual approach. However, they used only hard constraints in their inference formulation. Chang et al. (2012) extended the ILP formulation and used soft constraints within the Constrained Conditional Model formulation (Chang, 2011). However, their i</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2007</marker>
<rawString>M. Chang, L. Ratinov, and D. Roth. 2007. Guiding semisupervision with constraint-driven learning. InAssociation for Computational Linguistics, pages 280–287, Prague, Czech Republic, 6. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K-W Chang</author>
<author>R Samdani</author>
<author>A Rozovskaya</author>
<author>N Rizzolo</author>
<author>M Sammons</author>
<author>D Roth</author>
</authors>
<title>Inference protocols for coreference resolution.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task,</booktitle>
<pages>40--44</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA.</location>
<contexts>
<context position="2389" citStr="Chang et al., 2011" startWordPosition="371" endWordPosition="374">sive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer family of models than ILPs and it enables us to easily incorporate soft constraints into the inference procedure. Our experimental results show that soft constraints indeed give much better performance than hard constr</context>
</contexts>
<marker>Chang, Samdani, Rozovskaya, Rizzolo, Sammons, Roth, 2011</marker>
<rawString>K.-W. Chang, R. Samdani, A. Rozovskaya, N. Rizzolo, M. Sammons, and D. Roth. 2011. Inference protocols for coreference resolution. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning: Shared Task, pages 40–44, Portland, Oregon, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Wei Chang</author>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Structured learning with constrained conditional models.</title>
<date>2012</date>
<booktitle>Machine learning,</booktitle>
<pages>1--33</pages>
<contexts>
<context position="16780" citStr="Chang et al. (2012)" startWordPosition="2855" endWordPosition="2858"> global constraints only at inference time2. While it is possible to jointly train the model with the global constraints (as illustrated by Chang et al. (2007), Mann and McCallum (2007), Mann and McCallum (2008), Ganchev et al. (2010) etc.), this process will be a lot less efficient, and prior work (Roth and Yih, 2005) has shown that it may not be beneficial. Roth and Yih (2004, 2007) suggested the use of integer programs to model joint inference in a fully supervised setting. Our paper follows their conceptual approach. However, they used only hard constraints in their inference formulation. Chang et al. (2012) extended the ILP formulation and used soft constraints within the Constrained Conditional Model formulation (Chang, 2011). However, their implementation performed only approximate inference. In this paper, we extended the integer linear programming to a quadratic formulation, arguing that it simplifies the modeling step3, and showed that it is possible to do exact inference efficiently. Conclusion This paper presented a global inference strategy (using IQP) for concept recognition which allows us to model structural knowledge of the clinical domain as soft constraints in the optimization fram</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2012</marker>
<rawString>Ming-Wei Chang, Lev Ratinov, and Dan Roth. 2012. Structured learning with constrained conditional models. Machine learning, pages 1–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
</authors>
<title>Structured Prediction with Indirect Supervision.</title>
<date>2011</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Illinois at Urbana-Champaign.</institution>
<contexts>
<context position="16902" citStr="Chang, 2011" startWordPosition="2873" endWordPosition="2874">strated by Chang et al. (2007), Mann and McCallum (2007), Mann and McCallum (2008), Ganchev et al. (2010) etc.), this process will be a lot less efficient, and prior work (Roth and Yih, 2005) has shown that it may not be beneficial. Roth and Yih (2004, 2007) suggested the use of integer programs to model joint inference in a fully supervised setting. Our paper follows their conceptual approach. However, they used only hard constraints in their inference formulation. Chang et al. (2012) extended the ILP formulation and used soft constraints within the Constrained Conditional Model formulation (Chang, 2011). However, their implementation performed only approximate inference. In this paper, we extended the integer linear programming to a quadratic formulation, arguing that it simplifies the modeling step3, and showed that it is possible to do exact inference efficiently. Conclusion This paper presented a global inference strategy (using IQP) for concept recognition which allows us to model structural knowledge of the clinical domain as soft constraints in the optimization framework. Our results showed that soft constraints are more effective than hard constraints. Acknowledgments This research wa</context>
</contexts>
<marker>Chang, 2011</marker>
<rawString>M. Chang. 2011. Structured Prediction with Indirect Supervision. Ph.D. thesis, University of Illinois at Urbana-Champaign.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Modelling compression with discourse constraints.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>1--11</pages>
<contexts>
<context position="2323" citStr="Clarke and Lapata, 2007" startWordPosition="359" endWordPosition="362"> writing style. While the former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer family of models than ILPs and it enables us to easily incorporate soft constraints into the inference procedure. Our experimental results show that sof</context>
</contexts>
<marker>Clarke, Lapata, 2007</marker>
<rawString>James Clarke and Mirella Lapata. 2007. Modelling compression with discourse constraints. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>M Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="2348" citStr="Clarke and Lapata, 2008" startWordPosition="363" endWordPosition="366"> former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer family of models than ILPs and it enables us to easily incorporate soft constraints into the inference procedure. Our experimental results show that soft constraints indeed give</context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>J. Clarke and M. Lapata. 2008. Global inference for sentence compression: An integer linear programming approach. Journal of Artificial Intelligence Research, 31(1):399–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B de Bruijn</author>
<author>C Cherry</author>
<author>S Kiritchenko</author>
<author>J Martin</author>
<author>X Zhu</author>
</authors>
<title>Machine-learned solutions for three stages of clinical information extraction: the state of the art at i2b2</title>
<date>2011</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>18</volume>
<issue>5</issue>
<marker>de Bruijn, Cherry, Kiritchenko, Martin, Zhu, 2011</marker>
<rawString>B. de Bruijn, C. Cherry, S. Kiritchenko, J. Martin, and X. Zhu. 2011. Machine-learned solutions for three stages of clinical information extraction: the state of the art at i2b2 2010. Journal of the American Medical Informatics Association, 18(5):557–562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Denis</author>
<author>J Baldridge</author>
</authors>
<title>Joint determination of anaphoricity and coreference resolution using integer programming.</title>
<date>2007</date>
<booktitle>In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>236--243</pages>
<marker>Denis, Baldridge, 2007</marker>
<rawString>P. Denis, J. Baldridge, et al. 2007. Joint determination of anaphoricity and coreference resolution using integer programming. In Proceedings of Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics, pages 236–243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Joao Grac¸a</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior regularization for structured latent variable models.</title>
<date>2010</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>11--2001</pages>
<marker>Ganchev, Grac¸a, Gillenwater, Taskar, 2010</marker>
<rawString>Kuzman Ganchev, Joao Grac¸a, Jennifer Gillenwater, and Ben Taskar. 2010. Posterior regularization for structured latent variable models. The Journal of Machine Learning Research, 11:2001–2049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Jiang</author>
<author>Y Chen</author>
<author>M Liu</author>
<author>S T Rosenbloom</author>
<author>S Mani</author>
<author>J C Denny</author>
<author>H Xu</author>
</authors>
<title>A study of machinelearning-based approaches to extract clinical entities and their assertions from discharge summaries.</title>
<date>2011</date>
<journal>J Am Med Info Assoc,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="852" citStr="Jiang et al., 2011" startWordPosition="126" endWordPosition="129">roduces IQPs (Integer Quadratic Programs) as a way to model joint inference for the task of concept recognition in clinical domain. IQPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically to improve the accuracy of the prediction task. Knowledge in </context>
</contexts>
<marker>Jiang, Chen, Liu, Rosenbloom, Mani, Denny, Xu, 2011</marker>
<rawString>M. Jiang, Y. Chen, M. Liu, S.T. Rosenbloom, S. Mani, J.C. Denny, and H. Xu. 2011. A study of machinelearning-based approaches to extract clinical entities and their assertions from discharge summaries. J Am Med Info Assoc, 18(5):601–606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Jindal</author>
<author>D Roth</author>
</authors>
<title>End-to-end coreference resolution for clinical narratives.</title>
<date>2013</date>
<booktitle>In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<pages>2106--2112</pages>
<contexts>
<context position="922" citStr="Jindal and Roth, 2013" startWordPosition="138" endWordPosition="141">inference for the task of concept recognition in clinical domain. IQPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically to improve the accuracy of the prediction task. Knowledge in this domain can be thought of as belonging to two categories: (1) Back</context>
</contexts>
<marker>Jindal, Roth, 2013</marker>
<rawString>P. Jindal and D. Roth. 2013. End-to-end coreference resolution for clinical narratives. In Proceedings of International Joint Conference on Artificial Intelligence (IJCAI), pages 2106–2112, 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
</authors>
<title>Statistical significance tests for machine translation evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing,</booktitle>
<volume>4</volume>
<pages>388--395</pages>
<contexts>
<context position="13855" citStr="Koehn, 2004" startWordPosition="2348" endWordPosition="2349">uch better than hard constraints (BKC-HARD). the constraint. We observe from Figures 3a and 3b that for Type-2 and Type-3 constraints, global maxima is attained at p2 = 0.6 and p3 = 0.3 respectively. Hard vs Soft Constraints Table 4 compares the performance of BKC-HARD with that of BKC. First 3 rows in this table show the performance of both systems for the individual categories (TEST, TRE and PROB). The fourth row shows the overall score of both systems. BKC outperformed BKCHARD on all the categories by statistically significant differences at p = 0.05 according to Bootstrap Resampling Test (Koehn, 2004). For the OVERALL category, BKC improved over BKC-HARD by 1.0 F1 points. F1−score 80.7 80.6 80.5 80.4 80.3 80.2 80.1 79.9 79.8 79.7 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 80 F1−swm 81.5 81.4 81.3 81.2 81.1 80.9 80.8 80.7 80.6 80.5 80.4 80.3 0 0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1 81 1811 Effect of Training Data Size on Performance Figure 4: This figure shows the effect of training data size on performance of concept recognition. 4.2.2 Comparing with state-of-the-art baseline In the 2010 i2b2/VA shared task, majority of top systems were CRF-based models, motivating the use of CRF as our baseli</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>P. Koehn. 2004. Statistical significance tests for machine translation evaluation. In Proceedings of Empirical Methods in Natural Language Processing, volume 4, pages 388–395.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="1051" citStr="Lafferty et al., 2001" startWordPosition="158" endWordPosition="161"> the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically to improve the accuracy of the prediction task. Knowledge in this domain can be thought of as belonging to two categories: (1) Background Knowledge captured in medical ontologies like UMLS (Url1, 2013), MeSH and SNOMED CT and (2) Discourse Knowledge driven by </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01, pages 282–289, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Simple, robust, scalable semi-supervised learning via expectation regularization.</title>
<date>2007</date>
<booktitle>In Proceedings of the 24th international conference on Machine learning,</booktitle>
<pages>593--600</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="16346" citStr="Mann and McCallum (2007)" startWordPosition="2778" endWordPosition="2781">BK system as we vary the size of the training data, indicating the robustness of the joint inference procedure. 1Please note that the results reported in Table 2 can not be directly compared with those reported in the challenge because we only had a fraction of the original training and testing data. 5 Discussion and Related Work In this paper, we chose to train a rather simple sequential model (using CRF), and focused on incorporating global constraints only at inference time2. While it is possible to jointly train the model with the global constraints (as illustrated by Chang et al. (2007), Mann and McCallum (2007), Mann and McCallum (2008), Ganchev et al. (2010) etc.), this process will be a lot less efficient, and prior work (Roth and Yih, 2005) has shown that it may not be beneficial. Roth and Yih (2004, 2007) suggested the use of integer programs to model joint inference in a fully supervised setting. Our paper follows their conceptual approach. However, they used only hard constraints in their inference formulation. Chang et al. (2012) extended the ILP formulation and used soft constraints within the Constrained Conditional Model formulation (Chang, 2011). However, their implementation performed on</context>
</contexts>
<marker>Mann, McCallum, 2007</marker>
<rawString>Gideon S Mann and Andrew McCallum. 2007. Simple, robust, scalable semi-supervised learning via expectation regularization. In Proceedings of the 24th international conference on Machine learning, pages 593–600. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon Mann</author>
<author>Andrew McCallum</author>
</authors>
<title>Generalized expectation criteria for semi-supervised learning of conditional random fields.</title>
<date>2008</date>
<booktitle>In Proceedings of Association for Computational Linguistics,</booktitle>
<pages>870--878</pages>
<contexts>
<context position="16372" citStr="Mann and McCallum (2008)" startWordPosition="2782" endWordPosition="2786">ize of the training data, indicating the robustness of the joint inference procedure. 1Please note that the results reported in Table 2 can not be directly compared with those reported in the challenge because we only had a fraction of the original training and testing data. 5 Discussion and Related Work In this paper, we chose to train a rather simple sequential model (using CRF), and focused on incorporating global constraints only at inference time2. While it is possible to jointly train the model with the global constraints (as illustrated by Chang et al. (2007), Mann and McCallum (2007), Mann and McCallum (2008), Ganchev et al. (2010) etc.), this process will be a lot less efficient, and prior work (Roth and Yih, 2005) has shown that it may not be beneficial. Roth and Yih (2004, 2007) suggested the use of integer programs to model joint inference in a fully supervised setting. Our paper follows their conceptual approach. However, they used only hard constraints in their inference formulation. Chang et al. (2012) extended the ILP formulation and used soft constraints within the Constrained Conditional Model formulation (Chang, 2011). However, their implementation performed only approximate inference. </context>
</contexts>
<marker>Mann, McCallum, 2008</marker>
<rawString>Gideon Mann and Andrew McCallum. 2008. Generalized expectation criteria for semi-supervised learning of conditional random fields. In Proceedings of Association for Computational Linguistics, pages 870–878.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Marciniak</author>
<author>M Strube</author>
</authors>
<title>Beyond the pipeline: Discrete optimization in nlp.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning,</booktitle>
<pages>136--143</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2224" citStr="Marciniak and Strube, 2005" startWordPosition="343" endWordPosition="346"> and SNOMED CT and (2) Discourse Knowledge driven by the fact that the narratives adhere to a specific writing style. While the former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer family of models than ILPs and it enables us to easil</context>
</contexts>
<marker>Marciniak, Strube, 2005</marker>
<rawString>T. Marciniak and M. Strube. 2005. Beyond the pipeline: Discrete optimization in nlp. In Proceedings of the Ninth Conference on Computational Natural Language Learning, pages 136–143. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A McCallum</author>
<author>D Freitag</author>
<author>F Pereira</author>
</authors>
<title>Maximum entropy markov models for information extraction and segmentation.</title>
<date>2000</date>
<booktitle>In Proceedings of the Seventeenth International Conference on Machine Learning,</booktitle>
<pages>591--598</pages>
<contexts>
<context position="1081" citStr="McCallum et al., 2000" startWordPosition="163" endWordPosition="166">d still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically to improve the accuracy of the prediction task. Knowledge in this domain can be thought of as belonging to two categories: (1) Background Knowledge captured in medical ontologies like UMLS (Url1, 2013), MeSH and SNOMED CT and (2) Discourse Knowledge driven by the fact that the narratives a</context>
</contexts>
<marker>McCallum, Freitag, Pereira, 2000</marker>
<rawString>A. McCallum, D. Freitag, and F. Pereira. 2000. Maximum entropy markov models for information extraction and segmentation. In Proceedings of the Seventeenth International Conference on Machine Learning, pages 591–598.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A L Minard</author>
<author>A L Ligozat</author>
<author>A B Abacha</author>
<author>D Bernhard</author>
<author>B Cartoni</author>
<author>L Del´eger</author>
<author>B Grau</author>
<author>S Rosset</author>
<author>P Zweigenbaum</author>
<author>C Grouin</author>
</authors>
<title>Hybrid methods for improving information access in clinical documents: Concept, assertion, and relation identification.</title>
<date>2011</date>
<journal>J Am Med Info Assoc,</journal>
<volume>18</volume>
<issue>5</issue>
<marker>Minard, Ligozat, Abacha, Bernhard, Cartoni, Del´eger, Grau, Rosset, Zweigenbaum, Grouin, 2011</marker>
<rawString>A.L. Minard, A.L. Ligozat, A.B. Abacha, D. Bernhard, B. Cartoni, L. Del´eger, B. Grau, S. Rosset, P. Zweigenbaum, and C. Grouin. 2011. Hybrid methods for improving information access in clinical documents: Concept, assertion, and relation identification. J Am Med Info Assoc, 18(5):588–593.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Patrick</author>
<author>D H M Nguyen</author>
<author>Y Wang</author>
<author>M Li</author>
</authors>
<title>A knowledge discovery and reuse pipeline for information extraction in clinical notes.</title>
<date>2011</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="791" citStr="Patrick et al., 2011" startWordPosition="114" endWordPosition="117">61801, USA {jindal2, danr}@illinois.edu Abstract This paper introduces IQPs (Integer Quadratic Programs) as a way to model joint inference for the task of concept recognition in clinical domain. IQPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically </context>
</contexts>
<marker>Patrick, Nguyen, Wang, Li, 2011</marker>
<rawString>J.D. Patrick, D.H.M. Nguyen, Y. Wang, and M. Li. 2011. A knowledge discovery and reuse pipeline for information extraction in clinical notes. Journal of the American Medical Informatics Association, 18(5):574–579.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Punyakanok</author>
<author>D Roth</author>
<author>W Yih</author>
<author>D Zimak</author>
</authors>
<title>Semantic role labeling via integer linear programming inference.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<pages>1346</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2171" citStr="Punyakanok et al., 2004" startWordPosition="335" endWordPosition="338">in medical ontologies like UMLS (Url1, 2013), MeSH and SNOMED CT and (2) Discourse Knowledge driven by the fact that the narratives adhere to a specific writing style. While the former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer </context>
</contexts>
<marker>Punyakanok, Roth, Yih, Zimak, 2004</marker>
<rawString>V. Punyakanok, D. Roth, W. Yih, and D. Zimak. 2004. Semantic role labeling via integer linear programming inference. In Proceedings of the 20th international conference on Computational Linguistics, page 1346. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<title>The importance of syntactic parsing and inference in semantic role labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="2196" citStr="Punyakanok et al., 2008" startWordPosition="339" endWordPosition="342">e UMLS (Url1, 2013), MeSH and SNOMED CT and (2) Discourse Knowledge driven by the fact that the narratives adhere to a specific writing style. While the former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer family of models than ILP</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2008</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008. The importance of syntactic parsing and inference in semantic role labeling. Computational Linguistics, 34(2):257–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Riedel</author>
<author>J Clarke</author>
</authors>
<title>Incremental integer linear programming for non-projective dependency parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>129--137</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2298" citStr="Riedel and Clarke, 2006" startWordPosition="355" endWordPosition="358">ives adhere to a specific writing style. While the former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference problem. IQPs is a richer family of models than ILPs and it enables us to easily incorporate soft constraints into the inference procedure. Our experimen</context>
</contexts>
<marker>Riedel, Clarke, 2006</marker>
<rawString>S. Riedel and J. Clarke. 2006. Incremental integer linear programming for non-projective dependency parsing. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing, pages 129– 137. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Roberts</author>
<author>S M Harabagiu</author>
</authors>
<title>A flexible framework for deriving assertions from electronic medical records.</title>
<date>2011</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="898" citStr="Roberts and Harabagiu, 2011" startWordPosition="134" endWordPosition="137">ams) as a way to model joint inference for the task of concept recognition in clinical domain. IQPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically to improve the accuracy of the prediction task. Knowledge in this domain can be thought of as belonging to </context>
</contexts>
<marker>Roberts, Harabagiu, 2011</marker>
<rawString>K. Roberts and S.M. Harabagiu. 2011. A flexible framework for deriving assertions from electronic medical records. Journal of the American Medical Informatics Association, 18(5):568–573.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Proceedings of conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2146" citStr="Roth and Yih, 2004" startWordPosition="331" endWordPosition="334"> Knowledge captured in medical ontologies like UMLS (Url1, 2013), MeSH and SNOMED CT and (2) Discourse Knowledge driven by the fact that the narratives adhere to a specific writing style. While the former can be used by generating more expressive knowledge-rich features, the latter is more interesting from our current perspective, since it provides global constraints on what output structures are likely and what are not. We exploit this structural knowledge in our global inference formulation. Integer Linear Programming (ILP) based approaches have been used for global inference in many works (Roth and Yih, 2004; Punyakanok et al., 2004; Punyakanok et al., 2008; Marciniak and Strube, 2005; Bramsen et al., 2006; Barzilay and Lapata, 2006; Riedel and Clarke, 2006; Clarke and Lapata, 2007; Clarke and Lapata, 2008; Denis et al., 2007; Chang et al., 2011). However, in most of these works, researchers have focussed only on hard constraints while formulating the inference problem. Formulating all the constraints as hard constraints is not always desirable because the constraints are not perfect in many cases. In this paper, we propose Integer Quadratic Programs (IQPs) as a way of formulating the inference p</context>
<context position="16541" citStr="Roth and Yih (2004" startWordPosition="2817" endWordPosition="2820"> reported in the challenge because we only had a fraction of the original training and testing data. 5 Discussion and Related Work In this paper, we chose to train a rather simple sequential model (using CRF), and focused on incorporating global constraints only at inference time2. While it is possible to jointly train the model with the global constraints (as illustrated by Chang et al. (2007), Mann and McCallum (2007), Mann and McCallum (2008), Ganchev et al. (2010) etc.), this process will be a lot less efficient, and prior work (Roth and Yih, 2005) has shown that it may not be beneficial. Roth and Yih (2004, 2007) suggested the use of integer programs to model joint inference in a fully supervised setting. Our paper follows their conceptual approach. However, they used only hard constraints in their inference formulation. Chang et al. (2012) extended the ILP formulation and used soft constraints within the Constrained Conditional Model formulation (Chang, 2011). However, their implementation performed only approximate inference. In this paper, we extended the integer linear programming to a quadratic formulation, arguing that it simplifies the modeling step3, and showed that it is possible to do</context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Proceedings of conference on Computational Natural Language Learning (CoNLL), pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Integer linear programming inference for conditional random fields.</title>
<date>2005</date>
<booktitle>In Proceedings of International Conference on Machine Learning (ICML),</booktitle>
<pages>737--744</pages>
<contexts>
<context position="16481" citStr="Roth and Yih, 2005" startWordPosition="2804" endWordPosition="2807">s reported in Table 2 can not be directly compared with those reported in the challenge because we only had a fraction of the original training and testing data. 5 Discussion and Related Work In this paper, we chose to train a rather simple sequential model (using CRF), and focused on incorporating global constraints only at inference time2. While it is possible to jointly train the model with the global constraints (as illustrated by Chang et al. (2007), Mann and McCallum (2007), Mann and McCallum (2008), Ganchev et al. (2010) etc.), this process will be a lot less efficient, and prior work (Roth and Yih, 2005) has shown that it may not be beneficial. Roth and Yih (2004, 2007) suggested the use of integer programs to model joint inference in a fully supervised setting. Our paper follows their conceptual approach. However, they used only hard constraints in their inference formulation. Chang et al. (2012) extended the ILP formulation and used soft constraints within the Constrained Conditional Model formulation (Chang, 2011). However, their implementation performed only approximate inference. In this paper, we extended the integer linear programming to a quadratic formulation, arguing that it simplif</context>
</contexts>
<marker>Roth, Yih, 2005</marker>
<rawString>D. Roth and W. Yih. 2005. Integer linear programming inference for conditional random fields. In Proceedings of International Conference on Machine Learning (ICML), pages 737–744.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>Global inference for entity and relation identification via a linear programming formulation. Introduction to Statistical Relational Learning,</title>
<date>2007</date>
<pages>553--580</pages>
<marker>Roth, Yih, 2007</marker>
<rawString>D. Roth and W. Yih. 2007. Global inference for entity and relation identification via a linear programming formulation. Introduction to Statistical Relational Learning, pages 553–580.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Torii</author>
<author>K Wagholikar</author>
<author>H Liu</author>
</authors>
<title>Using machine learning for concept extraction on clinical documents from multiple data sources.</title>
<date>2011</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="811" citStr="Torii et al., 2011" startWordPosition="118" endWordPosition="121">anr}@illinois.edu Abstract This paper introduces IQPs (Integer Quadratic Programs) as a way to model joint inference for the task of concept recognition in clinical domain. IQPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically to improve the accur</context>
</contexts>
<marker>Torii, Wagholikar, Liu, 2011</marker>
<rawString>M. Torii, K. Wagholikar, and H. Liu. 2011. Using machine learning for concept extraction on clinical documents from multiple data sources. Journal of the American Medical Informatics Association, 18(5):580–587.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Url1</author>
</authors>
<title>Umls: Unified medical language system (http://www.nlm.nih.gov/research/umls/) (accessed july 1,</title>
<date>2013</date>
<marker>Url1, 2013</marker>
<rawString>Url1. 2013. Umls: Unified medical language system (http://www.nlm.nih.gov/research/umls/) (accessed july 1, 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Url2</author>
</authors>
<title>Metamap (http://metamap.nlm.nih.gov/) (accessed july 1,</title>
<date>2013</date>
<marker>Url2, 2013</marker>
<rawString>Url2. 2013. Metamap (http://metamap.nlm.nih.gov/) (accessed july 1, 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Url3</author>
</authors>
<title>Illinois part-of-speech tagger (http://cogcomp.cs.illinois.edu/page/software view/ pos) (accessed july 1,</title>
<date>2013</date>
<marker>Url3, 2013</marker>
<rawString>Url3. 2013. Illinois part-of-speech tagger (http://cogcomp.cs.illinois.edu/page/software view/ pos) (accessed july 1, 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Url4</author>
</authors>
<title>Mesh: Medical subject headings (http://www.nlm.nih.gov/mesh/meshhome.html) (accessed july 1,</title>
<date>2013</date>
<marker>Url4, 2013</marker>
<rawString>Url4. 2013. Mesh: Medical subject headings (http://www.nlm.nih.gov/mesh/meshhome.html) (accessed july 1, 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Url5</author>
</authors>
<title>Snomed ct: Snomed clinical terms (http://www.ihtsdo.org/snomed-ct/) (accessed july 1,</title>
<date>2013</date>
<marker>Url5, 2013</marker>
<rawString>Url5. 2013. Snomed ct: Snomed clinical terms (http://www.ihtsdo.org/snomed-ct/) (accessed july 1, 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Url6</author>
</authors>
<title>Gurobi optimization toolkit (http://www.gurobi.com/) (accessed july 1,</title>
<date>2013</date>
<marker>Url6, 2013</marker>
<rawString>Url6. 2013. Gurobi optimization toolkit (http://www.gurobi.com/) (accessed july 1, 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Uzuner</author>
<author>B R South</author>
<author>S Shen</author>
<author>S L DuVall</author>
</authors>
<title>i2b2/va challenge on concepts, assertions, and relations in clinical text.</title>
<date>2011</date>
<journal>Journal ofAmerican Medical Informatics Association.</journal>
<contexts>
<context position="987" citStr="Uzuner et al., 2011" startWordPosition="149" endWordPosition="152">QPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically to improve the accuracy of the prediction task. Knowledge in this domain can be thought of as belonging to two categories: (1) Background Knowledge captured in medical ontologies like UMLS (Url1, </context>
<context position="10044" citStr="Uzuner et al., 2011" startWordPosition="1676" endWordPosition="1679">by Equation (1). Thus, a penalty of P3 is imposed iff kth constraint is not satisfied (zk = 0). 3.2 Final Optimization Problem - An IQP After incorporating all the constraints mentioned above, the final optimization problem (an IQP) is shown in Figure 2. We used Gurobi toolkit (Url6, 2013) to solve such IQPs. In our case, it solves 76 IQPs per second on a quad-core server with Intel Xeon X5650 @ 2.67 GHz processors and 50 GB RAM. 4 Experiments and Results 4.1 Datasets and Evaluation Metrics For our experiments, we used the datasets provided by i2b2/VA team as part of 2010 i2b2/VA shared task (Uzuner et al., 2011). The datasets used for this shared task contained de-identied clinical reports from three medical institutions: Partners Healthcare (PH), Beth-Israel Deaconess Medical Center (BTDMC) and the University of Pittsburgh Medical Center (UPMC). UPMC data was divided into 2 sections, namely discharge (UPMCD) and progress notes (UPMCP). A total of 349 training reports and 477 test reports were made available to the participants. However, data which came from UPMC (more than 50% data) was not made available for public use. As a result, we had only 170 clinical reports for training and 256 clinical rep</context>
</contexts>
<marker>Uzuner, South, Shen, DuVall, 2011</marker>
<rawString>O. Uzuner, B.R. South, S. Shen, and S.L. DuVall. 2011. 2010 i2b2/va challenge on concepts, assertions, and relations in clinical text. Journal ofAmerican Medical Informatics Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Xu</author>
<author>K Hong</author>
<author>J Tsujii</author>
<author>I Eric</author>
<author>C Chang</author>
</authors>
<title>Feature engineering combined with machine learning and rule-based methods for structured information extraction from narrative clinical discharge summaries.</title>
<date>2012</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<volume>19</volume>
<issue>5</issue>
<contexts>
<context position="869" citStr="Xu et al., 2012" startWordPosition="130" endWordPosition="133">r Quadratic Programs) as a way to model joint inference for the task of concept recognition in clinical domain. IQPs make it possible to easily incorporate soft constraints in the optimization framework and still support exact global inference. We show that soft constraints give statistically significant performance improvements when compared to hard constraints. 1 Introduction In this paper, we study the problem of concept recognition in the clinical domain. State-of-the-art approaches (de Bruijn et al., 2011; Patrick et al., 2011; Torii et al., 2011; Minard et al., 2011; Jiang et al., 2011; Xu et al., 2012; Roberts and Harabagiu, 2011; Jindal and Roth, 2013) for concept recognition in clinical domain (Uzuner et al., 2011) use sequence-prediction models like CRF (Lafferty et al., 2001), MEMM (McCallum et al., 2000) etc. These approaches are limited by the fact that they can model only local dependencies (most often, first-order models like linear chain CRFs are used to allow tractable inference). Clinical narratives, unlike newswire data, provide a domain with significant knowledge that can be exploited systematically to improve the accuracy of the prediction task. Knowledge in this domain can b</context>
</contexts>
<marker>Xu, Hong, Tsujii, Eric, Chang, 2012</marker>
<rawString>Y. Xu, K. Hong, J. Tsujii, I. Eric, and C. Chang. 2012. Feature engineering combined with machine learning and rule-based methods for structured information extraction from narrative clinical discharge summaries. Journal of the American Medical Informatics Association, 19(5):824–832.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>