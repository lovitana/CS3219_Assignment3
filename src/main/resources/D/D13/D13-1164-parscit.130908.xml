<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997904">
A Convex Alternative to IBM Model 2
</title>
<author confidence="0.993216">
Andrei Simion
</author>
<affiliation confidence="0.99754">
Columbia University
</affiliation>
<address confidence="0.8420495">
IEOR Department
New York, NY, 10027
</address>
<email confidence="0.974894">
aas2148@columbia.edu
</email>
<author confidence="0.980477">
Michael Collins
</author>
<affiliation confidence="0.97593">
Columbia University
Computer Science
</affiliation>
<address confidence="0.983185">
New York, NY, 10027
</address>
<email confidence="0.98538">
mc3354@columbia.edu
</email>
<author confidence="0.976252">
Clifford Stein
</author>
<affiliation confidence="0.9915">
Columbia University
</affiliation>
<address confidence="0.844113">
IEOR Department
New York, NY, 10027
</address>
<email confidence="0.992261">
cs2035@columbia.edu
</email>
<sectionHeader confidence="0.994609" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997949375">
The IBM translation models have been hugely
influential in statistical machine translation;
they are the basis of the alignment models
used in modern translation systems. Exclud-
ing IBM Model 1, the IBM translation mod-
els, and practically all variants proposed in the
literature, have relied on the optimization of
likelihood functions or similar functions that
are non-convex, and hence have multiple lo-
cal optima. In this paper we introduce a con-
vex relaxation of IBM Model 2, and describe
an optimization algorithm for the relaxation
based on a subgradient method combined
with exponentiated-gradient updates. Our ap-
proach gives the same level of alignment ac-
curacy as IBM Model 2.
</bodyText>
<sectionHeader confidence="0.998427" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998691037037037">
The IBM translation models (Brown et al., 1993)
have been tremendously important in statistical ma-
chine translation (SMT). The IBM models were the
first generation of SMT systems; in recent work,
they play a central role in deriving alignments used
within many modern SMT approaches, for exam-
ple phrase-based translation models (Koehn, 2008)
and syntax-based translation systems (e.g., (Chi-
ang, 2005; Marcu et al., 2006)). Since the origi-
nal IBM paper, there has been a large amount of re-
search exploring the original IBM models and mod-
ern variants (e.g., (Moore, 2004; Liang et al., 2006;
Toutanova and Galley, 2011; Riley and Gildea,
2012; Vogel et al., 1996)).
Excluding IBM Model 1, the IBM translation
models, and practically all variants proposed in the
literature, have relied on the optimization of like-
lihood functions or similar functions that are non-
convex. Unfortunately, non-convex objective func-
tions have multiple local optima, and finding a
global optimum of a non-convex function is typi-
cally a computationally intractible problem. Typi-
cally, an EM algorithm is used, which often runs in
a reasonable amount of time, but with no guarantees
of finding a global optima (or for that matter, even a
near-optimal solution).
In this paper we make the following contributions:
</bodyText>
<listItem confidence="0.865761173913044">
• We introduce a convex relaxation of IBM
Model 2. At a very high level, the relaxation
is derived by replacing the product t(fj|ei) x
d(i|j) with a relaxation that is commonly used
in the linear programming literature (e.g., see
(Bertsimas, 1997; Bertsimas and Tsitsiklis,
1997; Martins et al., 2010)). (Here t(f|e) are
the translation parameters of the model, and
d(i|j) are the distortion parameters; the prod-
uct is non-linear, effectively introducing non-
convexity into the problem.)
• We describe an optimization algorithm for
the relaxed objective, based on a combina-
tion of stochastic subgradient methods with the
exponentiated-gradient (EG) algorithm (Kivi-
nen and Warmuth, 1997; Beck and Teboulle,
2003).
• We describe experiments with the method on
standard alignment datasets, showing that the
EG algorithm converges in only a few passes
over the data, and that our method achieves ac-
curacies that are very similar to those of IBM
Model 2.
</listItem>
<bodyText confidence="0.999726272727273">
Framing the unsupervised learning of alignment
models as a convex optimization problem, with
guaranteed convergence to a global optimum, has
several clear advantages. First, the method is eas-
ier to analyze, as the objective function is being
truly maximized. Second, there is no need for ini-
tialization heuristics with the approach, given that
the method will always converge to a global op-
timum. Finally, we expect that our convexity-
based approach may facilitate the further develop-
ment of more convex models. There has been a rich
</bodyText>
<page confidence="0.951013">
1574
</page>
<note confidence="0.731709">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1574–1583,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999811625">
interplay between convex and non-convex meth-
ods in machine learning: as one example consider
the literature on classification problems, with early
work on the perceptron (linear/convex), then work
on neural networks with back-propagation (non-
linear/non-convex), then the introduction of support
vector machines (non-linear/convex), and finally re-
cent work on deep belief networks (non-linear/non-
convex). In view of these developments, the lack
of convex methods in translation alignment models
has been noticeable, and we hope that our work will
open up new directions and lead to further progress
in this area.
Notation. Throughout this paper, for any integer
N, we use [N] to denote {1... N} and [N]0 to de-
note {0 ... N}.
</bodyText>
<sectionHeader confidence="0.99983" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99994653125">
(Brown et al., 1993) introduced IBM Models 1
through 5, and optimization methods for these mod-
els based on the EM algorithm. While the models
were originally introduced for full translation, they
are now mainly used to derive alignments which are
then used by phrase-based and other modern SMT
systems. Since the original IBM models were in-
troduced, many variants have been introduced in the
literature. (Vogel et al., 1996) introduced a model,
sometimes referred to as IBM 2.5, which uses a pa-
rameterization that is similar to a hidden Markov
model, and which allows the value of each alignment
variable to be conditioned on a previous alignment
variable. (Liang et al., 2006) describe a method that
explicitly incorporates agreement preferences dur-
ing training. (Och and Ney, 2003) give a systematic
comparison of several alignment models in the liter-
ature. (Moore, 2004) gives a detailed study of IBM
Model 1, showing various steps that can be used to
improve its performance. (Ganchev et al., 2010)
describes a method based on posterior regulariza-
tion that incorporates additional constraints within
the EM algorithm for estimation of IBM models.
All of these approaches are unsupervised, in that
they do not require labeled alignment data; however
several authors have considered supervised models
(e.g., see (Lacoste-Julien et al., 2006; Taskar et al.,
2005; Haghighi et al., 2009)). The focus of the cur-
rent paper is on unsupervised learning; the unsuper-
vised variants described above all make use of non-
convex objective functions during training, with the
usual problems with multiple local maxima.
</bodyText>
<sectionHeader confidence="0.998837" genericHeader="method">
3 The IBM Model 1 and Model 2
</sectionHeader>
<subsectionHeader confidence="0.92372">
Optimization Problems
</subsectionHeader>
<bodyText confidence="0.9990324">
In this section we give a brief review of IBM Models
1 and 2, and the optimization problems arising from
these models. The standard approach for optimiza-
tion within these models is the EM algorithm.
Throughout this section, and the remainder of the
paper, we assume that our set of training examples
is (e(k), f(k)) for k = 1... n, where e(k) is the k’th
English sentence and f(k) is the k’th French sen-
tence. Following standard convention, we assume
the task is to translate from French (the “source”
language) into English (the “target” language). We
use E to denote the English vocabulary (set of pos-
sible English words), and F to denote the French
vocabulary. The k’th English sentence is a sequence
of words e(k)
</bodyText>
<equation confidence="0.92057125">
1 ... e(k)
�k where lk is the length of the
k’th English sentence, and each e(k)
� ∈ E; similarly
the k’th French sentence is a sequence f(k)
1 ... f(k)
Mk
where each f(k)
</equation>
<bodyText confidence="0.987222086956522">
� ∈ F. We define e(0k) fork = 1... n
to be a special NULL word (note that E contains the
NULL word). Finally, we define L = maxk=1 lk
and M = maxk=1 Mk.
For each English word e ∈ E, we will assume
that D(e) is a dictionary specifying the set of possi-
ble French words that can be translations of e. The
set D(e) is a subset of F. In practice, D(e) can be
derived in various ways; in our experiments we sim-
ply define D(e) to include all French words f such
that e and f are seen in a translation pair.
Given these definitions, the IBM model 2 opti-
mization problem is given in Figure 1. The parame-
ters in this problem are t(f|e) and d(i|j). The t(f|e)
parameters are translation parameters specifying the
probability of English word e being translated as
French word f. The distortion parameters d(i|j)
specify the probability of the j’th French word in a
sentence being aligned to the i’th English word. We
use a variant of IBM Model 2 where the distortion
variables are shared across all sentence lengths (sim-
ilar variants have been used in (Liang et al., 2006)
and (Koehn, 2008)). The objective function is then
</bodyText>
<page confidence="0.994797">
1575
</page>
<figureCaption confidence="0.973626">
Figure 1: The IBM Model 2 Optimization Problem.
the log-likelihood of the training data (see Eq. 5):
</figureCaption>
<figure confidence="0.5635985">
log p(f(k)
j |e(k)) ,
</figure>
<figureCaption confidence="0.999374">
Figure 2: The IBM Model 1 Optimization Problem.
</figureCaption>
<bodyText confidence="0.942833454545455">
A common heuristic is to initialize the t(f|e) param-
eters in EM optimization of IBM Model 2 using the
output from IBM Model 1. The intuition behind this
heuristic is that the IBM Model 1 values for t(f|e)
will be a reasonable starting point, and the EM al-
gorithm will climb to a “good” local optimum. We
are not aware of any guarantees for this initialization
heuristic, however.
Input: Define E, F, L, M, (e(k), f(k), lk, mk) for
k = 1... n, D(e) for e ∈ E as in Section 3.
Parameters:
</bodyText>
<listItem confidence="0.8654385">
• A parameter t(f|e) for each e ∈ E, f ∈ D(e).
• A parameter d(i|j) for each i ∈ [L]0, j ∈ [M].
</listItem>
<equation confidence="0.963724909090909">
Constraints:
∀e ∈ E, f ∈ D(e), t(f|e) ≥ 0 (1)
∀e ∈ E, X t(f|e) = 1 (2)
fED(e)
∀i ∈ [L]0, j ∈ [M], d(i|j) ≥ 0 (3)
∀j ∈ [M], X d(i|j) = 1 (4)
iE[L]0
Objective: Maximize
t(f(k)
j |e(k)
i )d(i|j) (5)
with respect to the t(f|e) and d(i|j) parameters.
lk
1
n
log
Xn
k=1
X
i=0
Xmk
j=1
</equation>
<bodyText confidence="0.689275">
Input: Define E, F, L, M, (e(k), f(k), lk, mk) for
k = 1... n, D(e) for e ∈ E as in Section 3.
</bodyText>
<figure confidence="0.874252884615384">
Parameters:
• A parameter t(f|e) for each e ∈ E, f ∈ D(e).
Constraints:
∀e ∈ E, f ∈ D(e), t(f|e) ≥ 0 (6)
∀e ∈ E, X t(f|e) = 1 (7)
fED(e)
Objective: Maximize
(8)
(L + 1)
with respect to the t(f|e) parameters.
i=0
Xl k t(f(k)|e(k))
j i
1
n
log
Xn
k=1
Xmk
j=1
1
n
Xn
k=1
Xmk
j=1
</figure>
<bodyText confidence="0.999949142857143">
Crucially, while the constraints in the IBM Model
2 optimization problem are linear, the objective
function in Eq. 5 is non-convex. Therefore, opti-
mization methods for IBM Model 2, in particular
the EM algorithm, are typically only guaranteed to
reach a local maximum of the objective function.
For completeness, Figure 2 shows the optimiza-
tion problem for IBM Model 1. In IBM Model 1
the distortion parameters d(i|j) are all fixed to be
the uniform distribution (i.e., 1/(L + 1)). The ob-
jective function for IBM Model 1 is actually convex,
so the EM algorithm will converge to a global max-
imum. However IBM Model 1 is much weaker than
model 2, and typically gives far worse performance.
</bodyText>
<sectionHeader confidence="0.987173" genericHeader="method">
4 A Convex Relaxation of IBM Model 2
</sectionHeader>
<bodyText confidence="0.9929491875">
We now introduce a convex optimization problem,
the I2CR (IBM 2 Convex Relaxation) problem.
As its name suggests, this optimization problem is
closely related to IBM Model 2, but is convex. Be-
cause of this it will be relatively easy to derive an op-
timization algorithm that is guaranteed to converge
to a global optimum. Our experiments show that
the relaxation gives very similar performance to the
original IBM 2 optimization problem, as described
in the previous section.
We first describe an optimization problem,
I2CR-1, that illustrates the basic idea behind the
convex relaxation. We then describe a refined re-
laxation, I2CR-2, that introduces a couple of modi-
fications, and which performs well in experiments.
where l k t(f(k)
</bodyText>
<equation confidence="0.8629245">
p(f(k) X j |e(k)
j |e(k)) = i=0 i )d(i|j) .
</equation>
<page confidence="0.945346">
1576
</page>
<figureCaption confidence="0.9982475">
Figure 3: The I2CR-1 (IBM 2 Convex Relaxation) Prob-
lem, version 1.
</figureCaption>
<subsectionHeader confidence="0.999275">
4.1 The I2CR-1 Problem
</subsectionHeader>
<bodyText confidence="0.998372">
The I2CR-1 problem is shown in Figure 3. A first
key idea is to introduce a new variable q(i, j, k) for
each k ∈ [n], i ∈ [lk]0, j ∈ [mk]: that is, a new
variable for each triple (i, j, k) specifying a sen-
tence pair, and a specific English and French posi-
tion in that sentence. Each q variable must satisfy
the constraints in Eqs. 13-15, repeated here for con-
venience:
</bodyText>
<construct confidence="0.512814333333333">
∀i, j, k, q(i, j, k) ≥ 0 ,
∀i, j, k, q(i, j, k) ≤ d(i|j) ,
∀i, j, k, q(i, j, k) ≤ t(f(k) j|e(k)
</construct>
<bodyText confidence="0.8423824">
i ) .
The objective function is
q(i, j, k)
which is similar to the objective function in Figure 1,
but where t(f(k)
j |e(k)
i ) × d(i|j) has been replaced by
q(i, j, k). The intuition behind the new problem is as
follows. If, instead of the constraints in Eqs. 13-15,
we had the constraint
</bodyText>
<equation confidence="0.940980333333333">
q(i, j, k) = t(f(k)
j |e(k)
i ) × d(i|j) ,(17)
</equation>
<bodyText confidence="0.9929566">
then the I2CR-1 problem would clearly be identi-
cal to the IBM Model 2 optimization problem. We
have used a standard relaxation of the non-linear
constraint x = y × z where x, y, z are all variables
in the range [0, 1], namely
</bodyText>
<equation confidence="0.950160857142857">
x ≤ y ,
x ≤ z ,
x ≥ y + z − 1 .
These inequalites are a relaxation in the sense that
any (x, y, z) triple that satisfies x = y × z also sat-
isfies these constraints. Applying this relaxation to
Eq. 17 gives
q(i, j, k) ≤ t(f(k)
j |e(k)
i ) ,
q(i, j, k) ≤ d(i|j) ,
q(i,j,k) ≥ t(f(k)
j |e(k)
i ) + d(i|j) − 1 . (18)
</equation>
<bodyText confidence="0.999980357142857">
The final thing to note is that the constraint in
Eq. 18 can be omitted in the I2CR-1 problem. This
is because the task is to maximize the objective
with respect to the q variables and the objective
is strictly increasing as the q values increase—thus
lower bounds on their values are redundant in the
I2CR-1 problem.
It is easily verified that the constraints in the
I2CR-1 problem are linear, and that the objective
function is convex. In Section 5 of this paper we
describe an optimization method for the problem.
Note that because the objective function is being
maximized, and the objective increases monotoni-
cally as the q values increase, at the global optimum1
</bodyText>
<footnote confidence="0.894496666666667">
1More precisely, at any global optimum: the objective func-
tion may not be strictly convex, in which case there will be mul-
tiple global optima.
</footnote>
<bodyText confidence="0.649215333333333">
Input: Define E, F, L, M, (e(k), f(k), lk, mk) for
k = 1... n, D(e) for e ∈ E as in Section 3.
Parameters:
</bodyText>
<listItem confidence="0.71692725">
• A parameter t(f|e) for each e ∈ E, f ∈ D(e).
• A parameter d(i|j) for each i ∈ [L]0, j ∈ [M].
• A parameter q(i, j, k) for each k ∈ [n], i ∈ [lk]0,
j ∈ [mk].
</listItem>
<equation confidence="0.888704428571429">
Constraints:
∀e ∈ E, f ∈ D(e), t(f|e) ≥ 0 (9)
∀e ∈ E, � t(f|e) = 1 (10)
fED(e)
∀i ∈ [L]0, j ∈ [M], d(i|j) ≥ 0 (11)
∀j ∈ [M], � d(i|j) = 1 (12)
iE[L]0
∀i, j, k, q(i, j, k) ≥ 0 (13)
∀i, j, k, q(i, j, k) ≤ d(i|j) (14)
∀i, j, k, q(i, j, k) ≤ t(f(k)
j |e(k)
i ) (15)
Objective: Maximize
q(i, j, k) (16)
</equation>
<bodyText confidence="0.6126455">
with respect to the q(i, j, k), t(f|e) and d(i|j) pa-
rameters.
</bodyText>
<equation confidence="0.45537825">
1
lk
n
log
n
k=1
�
i=0
Mk
j=1
l k
1
n
log
Mk
j=1
�
i=0
n
k=1
</equation>
<page confidence="0.703849">
1577
</page>
<figureCaption confidence="0.9361035">
Figure 4: The I2CR-2 (IBM 2 Convex Relaxation) Prob-
lem, version 2. The problem is identical to the I2CR-1
problem, but it also includes a term in the objective func-
tion that is identical to the IBM Model 1 objective. We
</figureCaption>
<equation confidence="0.967358833333333">
define log&apos;(z) = log(z + λ) where λ is a small positive
constant.
we have
q(i, j, k) = min{t(f(k)
j |e(k)
i ), d(i|j)} ,
</equation>
<bodyText confidence="0.999943">
where min{x, y} returns the minimum of the two
values x and y. Thus, we could actually eliminate
the q variables and write an optimization problem
that is identical to the IBM Model 2 optimization
problem, but with the objective function
</bodyText>
<equation confidence="0.979737">
min{t(f(k) j|e(k)
i ), d(i|j)} .
</equation>
<bodyText confidence="0.991461666666667">
It will turn out that both views of the I2CR-1
problem—with and without the q variables—are
helpful, so we have included both in this paper.
</bodyText>
<subsectionHeader confidence="0.974733">
4.2 The I2CR-2 Problem
</subsectionHeader>
<bodyText confidence="0.999946423076923">
Figure 4 shows the refined optimization problem,
which we call I2CR-2. The problem incorporates
two modifications. First, we modify the objective
function to be
Thus the objective function includes a second term
that is identical to the objective function for IBM
Model 1 (see Figure 2). In preliminary experiments
with the I2CR-1 optimization problem, we found
that the I2CR-1 objective was not sufficiently depen-
dent on the t parameters: intuitively, if the d param-
eters achieve the min on many training examples,
the values for the t variables become unimportant.
The addition of the IBM Model 1 objective fixed this
problem by introducing a term that depends on the t
values alone.
Second, we replace log by log&apos;, where log&apos;(z) =
log(z + λ), and λ is a small positive constant (in
our experiments we used λ = 0.001). Under this
definition the derivatives of log&apos; are upper-bounded
by 1/λ, in contrast to log, where the derivatives
can diverge to infinity. The optimization methods
we use are gradient-based methods (or more pre-
cisely, subgradient-based methods), and we have
found them to be considerably more stable when the
values for gradients do not diverge to infinity.
The modified objective remains convex.
</bodyText>
<sectionHeader confidence="0.9777615" genericHeader="method">
5 A Stochastic Exponentiated-Gradient
Algorithm for Optimization
</sectionHeader>
<bodyText confidence="0.9947615">
We now describe an algorithm for optimizing the
I2CR-2 problem in Figure 4. The algorithm is
closely related to stochastic gradient ascent, but with
two modifications:
</bodyText>
<listItem confidence="0.996079875">
• First, because the t(f|e) and d(i|j) parame-
ters have simplex constraints (see Figure 1),
we use exponentiated gradient (EG) updates.
EG algorithms are gradient-based methods that
maintain simplex constraints; see for exam-
ple: (Kivinen and Warmuth, 1997; Beck and
Teboulle, 2003; Collins et al., 2008).
• Second, the objective function in the I2CR-
2 problem is convex, but is not differentiable
(the gradient may not exist at all points). For
this reason we use subgradients in the place of
gradients. In spite of the non-differentiability
of the objective function, subgradient meth-
ods still have strong convergence guarantees
when combined with EG updates (e.g., the con-
vergence proofs in (Beck and Teboulle, 2003)
</listItem>
<table confidence="0.24382925">
Input: Same as in I2CR-1 (Figure 4).
Parameters: Same as in I2CR-1 (Figure 4).
Constraints: Same as in I2CR-1 (Figure 4).
Objective: Maximize
</table>
<equation confidence="0.710932896551724">
lk t(f(k) |e(k))
j i
(L + 1)
with respect to the q(i, j, k), t(f|e) and d(i|j) pa-
rameters.
i=0
1
lk
2n
log&apos;
�
i=0
q(i, j, k)
n
k=1
�mk
j=1
1
+
2n
log&apos;
n
k=1
�mk
j=1
lk t(f(k)|e(k))
j i
(L + 1) .
i=0
1
l k
2n
log&apos;
�
i=0
q(i, j, k)
n
k=1
�mk
j=1
1
+
2n
log&apos;
n
k=1
�mk
j=1
l k
1
n
log
n
k=1
�
i=0
�mk
j=1
</equation>
<page confidence="0.960535">
1578
</page>
<bodyText confidence="0.966511928571428">
go through with minor modifications; see also
(Bertsekas, 1999)).
To derive the updates, recall that we are maximiz-
ing the following objective function:
h(t, d)
Here we use T to denote the set {1... n}; we will
see shortly why this notation is convenient. We use
t and d to refer to the full set of t and d parameters
respectively; h(t, d) is the function to be maximized.
Recall that log&apos;(z) = log(z + λ) where λ is a small
positive parameter.
Given a concave function f(x) where x ∈ Rd, a
subgradient of f(x) at x is any vector g(x) ∈ Rd
such that for any y ∈ Rd,
</bodyText>
<equation confidence="0.979233">
f(y) ≤ f(x) + g(x) · (y − x) ,
</equation>
<bodyText confidence="0.9991735">
where u·v is the inner product between vectors u and
v. Subgradients are similar to gradients for differ-
entiable concave functions, in that gradients satisfy
the above property. Subgradients can be used in the
place of gradients in many optimization algorithms
(see for example (Bertsekas, 1999)).
The subgradients for the objective function in
Eq. 19 take a simple form. First, define
</bodyText>
<equation confidence="0.979042176470588">
lk
t(f(k)
j |e(k)
i ) ,
lk
min{t(f(k)
j |e(k)
i ), d(i|j)} ,
and
�
1 if t(f(k)
j |e(k)
i ) ≤ d(i|j)
I(i, j, k) = 0 otherwise .
Then the subgradients2 are
(1 I (i, j, k)
R(j,k) + Q(j, k)
</equation>
<bodyText confidence="0.9351955">
2We set Ot(f|e) and Od(i|j) as the subgradients for the
objective function in Eq. 19 with respect to t(f|e) and d(i|j)
respectively.
and
</bodyText>
<equation confidence="0.998452">
1 1 − I(i, j, k)
∇d(i|j) = 2|T  |k:i&lt;lL mk Q(j, k)
</equation>
<bodyText confidence="0.620915">
Exponentiated-gradient updates then take the fol-
lowing form:
</bodyText>
<equation confidence="0.991273">
t(f|e) × exp{γ × ∇t(f|e)}
t(f|e) ← Ef t(f|e) × exp{γ × ∇t(f|e)} (20)
and
d(i|j) × exp{γ × ∇d(i|j)}
d(i|j) ← (21)
Ei d(i|j) × exp{γ × ∇d(i|j)} ,
</equation>
<bodyText confidence="0.999968666666667">
where γ &gt; 0 is a constant step size in the algorithm.
Note that the EG updates make use of subgradients,
but maintain the simplex constraints on the t and d
variables.
The method just described is a batch gradient
method, where the entire training set T = {1... n}
is used to derive the subgradients before the updates
in Eqs. 20 and 21 are made. Many results in ma-
chine learning and NLP have shown that stochastic
gradient methods, where a subset of the training ex-
amples is used before each gradient-based update,
can converge much more quickly than batch gradi-
ent methods. In our notation, this simply involves
replacing T by some subset T&apos; of the training exam-
ples in the above definitions, where |T&apos; |is typically
much smaller than |T |.
Figure 5 shows our final algorithm, a stochastic
version of the exponentiated-gradient method. The
method takes S passes over the data. For each pass,
it randomly partitions the training set into mini-
batches T1 ... TK of size B, where B is an integer
specifying the size of each mini-batch (in our exper-
iments we used B = 125 or B = 250). The al-
gorithm then performs EG updates using each mini-
batch T1 ... TK in turn. As can be seen in Table 3,
our experiments show that the algorithm makes very
significant progress in the first pass over the data,
and takes very few iterations to converge to a good
solution even though we initialized with uniform pa-
rameter values.
</bodyText>
<sectionHeader confidence="0.999451" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.972994">
In this section we describe experiments using the
I2CR-2 optimization problem combined with the
</bodyText>
<equation confidence="0.92287026923077">
1 Mk log0 l k �mint(f k) |eZ(k)),d(i|j)}
2|T  |k∈TL L L
�=1 �=0
1 L
+
2|T  |k∈T
(L + 1) . (19)
t(f(k)�|eZ(k)
Ll k
�=0
log0
Mk
L
�=1
R(j, k) = λ + L
i=0
Q(j,k) = λ + L
i=0
1 L
∇t(f|e) = 2|T |
i,j,k:
f(k)=f
j
e(k)
i =e
.
</equation>
<page confidence="0.977238">
1579
</page>
<figureCaption confidence="0.9971525">
Figure 5: The stochastic exponentiated-gradient algo-
rithm for optimization of I2CR-2.
</figureCaption>
<bodyText confidence="0.999852428571429">
stochastic EG algorithm for parameter estimation.
We first describe the data sets we use, and then de-
scribe experiments with the method, comparing our
approach to results from IBM Model 2. We com-
pare the various algorithms in terms of their accu-
racy in recovering alignments, using metrics such as
F-measure and AER.
</bodyText>
<subsectionHeader confidence="0.99934">
6.1 Data Sets
</subsectionHeader>
<bodyText confidence="0.999958789473684">
We use data from the bilingual word alignment
workshop held at HLT-NAACL 2003 (Michalcea
and Pederson, 2003). As a first dataset, we use the
Canadian Hansards bilingual corpus, with 247,878
English-French sentence pairs as training data, 37
sentences of development data, and 447 sentences
of test data (note that we use a randomly chosen
subset of the original training set of 1.1 million sen-
tences, similar to the setting used in (Moore, 2004)).
The development and test data have been manually
aligned at the word level, annotating alignments be-
tween source and target words in the corpus as ei-
ther “sure” (S) or “possible” (P) alignments, as de-
scribed in (Och and Ney, 2003).
As a second data set, we used the Romanian-
English data from the HLT-NAACL 2003 workshop.
This consisted of a training set of 48,706 Romanian-
English sentence-pairs, a development set of 17 sen-
tence pairs, and a test set of 248 sentence pairs.
</bodyText>
<subsectionHeader confidence="0.997754">
6.2 Methodology
</subsectionHeader>
<bodyText confidence="0.9999569">
For each of the models—IBM Model 1, IBM Model
2, and I2CR-2—we follow convention in applying
the following methodology: first, we estimate the
t and d parameters using models in both source-
target and target-source directions; second, we find
the most likely alignment for each development or
test data sentence in each direction; third, we take
the intersection of the two alignments as the final
output from the model.
For the EG algorithm we use a batch size B =
250 and step size y = 0.5 on the Hansards data, and
B = 125 and y = 0.5 for the Romanian-English
data.
We report the performance of the models in terms
of Precision, Recall, AER, and F-Measure as defined
by (Och and Ney, 2003). If A is the set of align-
ments produced by an algorithm, S is the set of sure
alignments as annotated in test data, and P is the
set of possible alignments, then these quantities are
defined as
</bodyText>
<equation confidence="0.979821">
Recall = |A � S|
|S |,
</equation>
<bodyText confidence="0.8847605">
1: Input: Define E, F, L, M, (e(k), f(k), lk, mk)
fork = 1... n, D(e) for e E E as in Section 3.
An integer B specifying the batch size. An inte-
ger S specifying the number of passes over the
data. A step size y &gt; 0. A parameter A &gt; 0
used in the definition of log&apos; .
</bodyText>
<listItem confidence="0.8531955">
2: Parameters:
• A parameter t(f|e) for each e E E, f E D(e).
• A parameter d(i|j) for each i E [L]0, j E [M].
3: Definitions:
</listItem>
<figure confidence="0.944330714285714">
R(j, k) = A + l k t(f(k)
L j |e(k)
i=0 i )
Q(j, k) = A + l k min{t(f(k)
L j |e(k)
i=0 i ), d(i|j)}
4: Initialization:
• de E E, f E D(e), t(f|e) = 1/|D(e)|
• dj E [M], i E [L]0, d(i|j) = 1/(L + 1)
5: Algorithm:
6: for all s = 1 to S do
7: Randomly partition [n] into subsets T1 ... TK of
size B where K = n/B.
8: for all b = 1 to K do
9: de E E, f E D(e), α(e, f) = 0
10: dj E [M], i E [L]0, 0(i,j) = 0
11: for all k E Tb do
12: for all j = 1 to mk do
13: for all i = 0 to lk do
α(e(k)
i , f(k)
14: j ) += 1/(2R(j, k))
if t(f(k)
j |e(k)
15: i ) &lt; d(i|j) then
α(e(k)
i , f(k)
16: j ) += 1/(2Q(j, k))
17: else
18: 0(i, j) += 1/(2Q(j, k))
19: de, f, t(f|e) = t(f|e) exp (y x α(e, f)/B)
20: di, j, d(i|j) = d(i|j) exp (y x 0(i, j)/B)
21: Renormalize t and d parameters to satisfy
E f t(f|e) = 1 and Ei d(i|j) = 1.
22: Output: t and d parameters.
</figure>
<page confidence="0.732163">
1580
</page>
<equation confidence="0.84170575">
Precision = |A n S|
|A |,
AER = 1 _ |A n S |+ |A n P|
|A |+ |S |,
</equation>
<bodyText confidence="0.999972742857143">
Note that we report results in both AER and
F-measure; however there is evidence (Fraser and
Marcu, 2004) that F-measure is better correlated
with translation quality when the alignments are
used in a full system.
In training IBM Model 1 we follow (Moore,
2004) in running EM for 15 iterations. In training
IBM Model 2 we first train IBM Model 1 for 15
iterations to initialize the t parameters, then train
IBM Model 2 for a further 10 iterations. For the
EG algorithm, we use 10 iterations over the training
data for the Hansards data, and 15 iterations on the
Romanian-English data (on the latter dataset results
on the trial data showed that the method took slightly
longer to converge). We report F-measure and AER
results for each of the iterations under the IBM
Model 2 and I2CR-2 models. See Table 1 for the re-
sults on the Hansards data, and Table 2 for the results
on the English-Romanian dataset. It can be seen that
both I2CR-2 and IBM Model 2 converge to a fairly
stable result after 2-3 iterations. The two models
give very similar levels of performance, for example
after 10 iterations on the Hansard data IBM Model
2 gives 14.22 AER and 0.7516 F-Measure versus
14.60 AER and 0.7506 F-Measure for I2CR-2.
On the right, Table 3 shows the values of the ob-
jective function at each iteration when using the EG
algorithm to optimize the I2CR-2 objective. The
method makes a large amount of progress on the first
iteration and then continues to improve. Finally, we
note that the memory requirements for I2CR-2 and
IBM2 are about the same, but that the time for one
iteration of I2CR-2 on the Hansards data is approxi-
mately one hour, while the time for one iteration of
IBM2 was approximately 10 minutes.
</bodyText>
<sectionHeader confidence="0.997306" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.998161">
We have introduced the first convex model for un-
supervised learning of alignments in statistical ma-
chine translation with performance comparable to
</bodyText>
<table confidence="0.99995875">
Iteration IBM2 I2CR-2 IBM2 I2CR-2
AER AER F-Measure F-Measure
Test Set Statistics
1 0.1491 0.1556 0.7530 0.7369
2 0.1477 0.1489 0.7519 0.7456
3 0.1451 0.1476 0.7527 0.7467
4 0.1426 0.1488 0.7536 0.7449
5 0.1422 0.1495 0.7535 0.7472
6 0.1431 0.1476 0.7511 0.7478
7 0.1434 0.1506 0.7506 0.7456
8 0.1437 0.1495 0.7501 0.7470
9 0.1434 0.1494 0.7501 0.7468
10 0.1422 0.1460 0.7516 0.7506
Development Set Statistics
1 0.1871 0.1971 0.6823 .6676
2 0.1896 0.1760 0.6758 .6827
3 0.1964 0.1860 0.6648 .6739
4 0.1912 0.1835 0.6713 .6775
5 0.1884 0.1813 0.6740 .06773
6 0.1836 0.1851 0.6767 0.6811
7 0.1831 0.1806 0.6749 0.6765
8 0.1842 0.1843 0.6739 0.6775
9 0.1864 0.1928 0.6694 0.6640
10 0.1845 0.1829 0.6703 .6721
</table>
<tableCaption confidence="0.9893375">
Table 1: Results on the Hansards data for IBM Model 2
and the I2CR-2 method.
</tableCaption>
<table confidence="0.999986852941176">
Iteration IBM2 I2CR-2 IBM2 I2CR-2
AER AER F-Measure F-Measure
Test Set Statistics
1 0.4041 0.5354 0.5959 0.4646
2 0.4010 0.4764 0.5990 0.5256
3 0.4020 0.4543 0.5980 0.5457
4 0.4012 0.4384 0.5988 0.5617
5 0.4003 0.4277 0.5997 0.5723
6 0.3990 0.4266 0.6010 0.5834
7 0.4000 0.4162 0.6000 0.5838
8 0.4023 0.4114 0.5977 0.5886
9 0.4022 0.4081 0.5978 0.5919
10 0.4027 0.4043 0.5973 0.5957
11 0.4031 0.4040 0.5969 0.5960
12 0.4042 0.4027 0.5958 0.5973
13 0.4043 0.4021 0.5957 0.5979
14 0.4062 0.4007 0.5938 0.5993
15 0.4057 0.4014 0.5943 0.5986
Development Set Statistics
1 0.4074 0.5841 0.5926 0.4159
2 0.3911 0.4938 0.6089 0.5062
3 0.3888 0.4673 0.6112 0.5327
4 0.3904 0.4596 0.6096 0.5404
5 0.3881 0.4463 0.6119 0.5537
6 0.3904 0.4306 0.6096 0.5694
7 0.3936 0.4175 0.6094 0.5826
8 0.3897 0.4060 0.6103 0.5940
9 0.3961 0.4014 0.6039 0.5986
10 0.3970 0.4072 0.6030 0.5928
11 0.4018 0.3956 0.5982 0.6044
12 0.4035 0.3931 0.5965 0.6069
13 0.4035 0.3862 0.5965 0.6138
14 0.4014 0.3908 0.5986 0.6092
15 0.4063 0.3858 0.5937 0.6142
</table>
<tableCaption confidence="0.94795">
Table 2: Results on the English-Romanian data for IBM
Model 2 and the I2CR-2 method.
</tableCaption>
<figure confidence="0.6492768125">
F-Measure = 1
.5 .5 .
Recall + Precision
1581
Iteration EF Objective FE Objective
0 -99.6053 -79.5566
1 -32.4528 -27.4925
2 -31.1641 -26.262
3 -30.6311 -25.7093
4 -30.3367 -25.3714
5 -30.1428 -25.1456
6 -30.0000 -24.992
7 -29.8736 -24.8605
8 -29.8093 -24.7551
9 -29.7326 -24.684
10 -29.6771 -24.6099
</figure>
<tableCaption confidence="0.941663">
Table 3: Objective values for the EG algorithm opti-
</tableCaption>
<bodyText confidence="0.787344909090909">
mization of I2CR-2 at each iteration. “EF Objective”
corresponds to training a model with t(elf) parameters,
“FE Objective” corresponds to the reverse direction, with
t(f|e) parameters. Iteration 0 corresponds to the objec-
tive value under the initial, uniform parameter values.
the commonly-used IBM Model 2. We believe
that introducing convexity without sacrificing per-
formance will open the door to further improve-
ments in this area. Future work will consider ways to
speed up our algorithm and extensions of the method
to more complex alignment models.
</bodyText>
<sectionHeader confidence="0.998323" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.995805714285714">
Michael Collins is partly supported by NSF grant
IIS-1161814. Cliff Stein is partly supported by NSF
grant CCF-0915681. The authors thank Sasha Rush
for his help with implementation questions. We
also thank the anonymous reviewers for many use-
ful comments; we hope to pursue the comments we
were not able to address in a followup paper.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999899538461538">
Peter L. Bartlett, Ben Taskar, Michael Collins and David
Mcallester. 2004. Exponentiated Gradient Algorithms
for Large-Margin Structured Classification. In Pro-
ceedings of NIPS.
Amir Beck and Marc Teboulle. 2003. Mirror Descent and
Nonlinear Projected Subgradient Methods for Convex
Optimization. Operations Research Letters, 31:167-
175.
Dimitris Bertsimas and John N. Tsitsiklis. 1997. Intro-
duction to Linear Programming. Athena Scientific.
Dimitris Bertsimas. 2005. Optimization Over Integers.
Dynamic Ideas.
Dimitri P. Bertsekas. 1999. Nonlinear Optimization.
Athena Press.
Steven Boyd and Lieven Vandenberghe. 2004. Convex
Optimization. Cambridge University Press.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert. L. Mercer. 1993. The Mathematics
of Statistical Machine Translation: Parameter Estima-
tion. Computational Linguistics, 19:263-311.
David Chiang. 2005. A Hierarchical Phrase-Based Model
for Statistical Machine Translation. In Proceedings of
the ACL.
Michael Collins, Amir Globerson, Terry Koo, Xavier
Carreras and Peter L. Bartlett. 2008. Exponentiated
Gradient Algorithms for Conditional Random Fields
and Max-Margin Markov Networks. Journal Machine
Learning, 9(Aug): 1775-1822.
A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977.
Maximum Likelihood From Incomplete Data via the
EM Algorithm. Journal of the royal statistical society,
series B, 39(1):1-38.
Alexander Fraser and Daniel Marcu. 2007. Measur-
ing Word Alignment Quality for Statistical Ma-
chine Translation. Journal Computational Linguistics,
33(3): 293-303.
Kuzman Ganchev, Joao V. Graca, Jennifer Gillenwater,
Ben Taskar. 2010. Posterior Regularization for Struc-
tured Latent Variable Models. Journal of Machine
Learning, 11(July): 2001-2049.
Joao V. Graca, Kuzman Ganchev and Ben Taskar. 2007.
Expectation Maximization and Posterior Constraints.
In Proceedings of NIPS.
Aria Haghighi, John Blitzer, John DeNero and Dan Klein.
2009. Better Word Alignments with Supervised ITG
Models. In Proceedings of the ACL.
Darcey Riley and Daniel Gildea. 2012. Improving the
IBM Alignment Models Using Variational Bayes. In
Proceedings of the ACL.
Yuhong Guo and Dale Schuurmans. 2007. Convex Relax-
ations of Latent Variable Training. In NIPS.
Simon Lacoste-Julien, Ben Taskar, Dan Klein, and
Michael Jordan. 2008. Word Alignment via Quadratic
Assignment. In Proceedings of the HLT-NAACL.
Phillip Koehn. 2008. Statistical Machine Translation.
Cambridge University Press.
Kivinen, J., Warmuth, M. 1997. Exponentiated Gradient
Versus Gradient Descent for Linear Predictors. Infor-
mation and Computation, 132, 1-63.
Percy Liang, Ben Taskar and Dan Klein. 2006. Alignment
by Agreement. In Proceedings of NAACL.
Daniel Marcu, Wei Wang, Abdessamad Echihabi,
and Kevin Knight. 2006. SPMT: Statistical Ma-
chine Translation with Syntactified Target Language
Phrases. In Proceedings of the EMNLP.
</reference>
<page confidence="0.851829">
1582
</page>
<reference confidence="0.999735083333333">
Andre F. T. Martins, Noah A. Smith and Eric P. Xing.
2010. Turbo Parsers: Dependency Parsing by Ap-
proximate Variational Inference. In Proceedings of the
EMNLP.
Rada Michalcea and Ted Pederson. 2003. An Evalua-
tion Exercise in Word Alignment. HLT-NAACL 2003:
Workshop in building and using Parallel Texts: Data
Driven Machine Translation and Beyond.
Robert C. Moore. 2004. Improving IBM Word-
Alignment Model 1. In Proceedings of the ACL.
Stephan Vogel, Hermann Ney and Christoph Tillman.
1996. HMM-Based Word Alignment in Statistical
Translation. In Proceedings of COLING.
Franz Och and Hermann Ney. 2003. A Systematic
Comparison of Various Statistical Alignment Models.
Computational-Linguistics, 29(1): 19-52.
Libin Shen, Jinxi Xu and Ralph Weischedel. 2008. A
New String-to-Dependency Machine Translation Al-
gorithm with a Target Dependency Language Model.
In Proceedings of the ACL-HLT.
Ben Taskar, Simon Lacoste-Julien and Dan Klein. 2005.
A Discriminative Matching Approach to Word Align-
ment. In Proceedings of the EMNLP.
Kristina Toutanova and Michel Galley. 2011. Why Ini-
tialization Matters for IBM Model 1: Multiple Optima
and Non-Strict Convexity. In Proceedings of the ACL.
Kenji Yamada and Kevin Knight. 2001. A Syntax-Based
Statistical Translation Model. In Proceedings of the
ACL.
Kenji Yamada and Kevin Knight. 2002. A Decoder for
Syntax-Based Statistical Machine Translation. In Pro-
ceedings of the ACL.
Ashish Vaswani, Liang Huang and David Chiang. 2012.
Smaller Alignment Models for Better Translations:
Unsupervised Word Alignment with the LO-norm. In
Proceedings of the ACL.
</reference>
<page confidence="0.977566">
1583
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002293">
<title confidence="0.870591">A Convex Alternative to IBM Model 2</title>
<author confidence="0.624707">Andrei</author>
<affiliation confidence="0.482281">Columbia</affiliation>
<address confidence="0.212684">IEOR</address>
<author confidence="0.916985">New York</author>
<author confidence="0.916985">NY</author>
<email confidence="0.996359">aas2148@columbia.edu</email>
<author confidence="0.86743">Michael</author>
<affiliation confidence="0.942386">Columbia</affiliation>
<title confidence="0.221245">Computer</title>
<author confidence="0.649344">New York</author>
<author confidence="0.649344">NY</author>
<email confidence="0.985364">mc3354@columbia.edu</email>
<affiliation confidence="0.724078">Clifford</affiliation>
<address confidence="0.380229">Columbia</address>
<email confidence="0.39271">IEOR</email>
<author confidence="0.882334">New York</author>
<author confidence="0.882334">NY</author>
<email confidence="0.98905">cs2035@columbia.edu</email>
<abstract confidence="0.997922125">The IBM translation models have been hugely influential in statistical machine translation; they are the basis of the alignment models used in modern translation systems. Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are non-convex, and hence have multiple local optima. In this paper we introduce a convex relaxation of IBM Model 2, and describe an optimization algorithm for the relaxation based on a subgradient method combined with exponentiated-gradient updates. Our approach gives the same level of alignment ac-</abstract>
<note confidence="0.51954">curacy as IBM Model 2.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter L Bartlett</author>
<author>Ben Taskar</author>
<author>Michael Collins</author>
<author>David Mcallester</author>
</authors>
<title>Exponentiated Gradient Algorithms for Large-Margin Structured Classification.</title>
<date>2004</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<marker>Bartlett, Taskar, Collins, Mcallester, 2004</marker>
<rawString>Peter L. Bartlett, Ben Taskar, Michael Collins and David Mcallester. 2004. Exponentiated Gradient Algorithms for Large-Margin Structured Classification. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amir Beck</author>
<author>Marc Teboulle</author>
</authors>
<title>Mirror Descent and Nonlinear Projected Subgradient Methods for Convex Optimization.</title>
<date>2003</date>
<journal>Operations Research Letters,</journal>
<pages>31--167</pages>
<contexts>
<context position="3016" citStr="Beck and Teboulle, 2003" startWordPosition="464" endWordPosition="467">n is derived by replacing the product t(fj|ei) x d(i|j) with a relaxation that is commonly used in the linear programming literature (e.g., see (Bertsimas, 1997; Bertsimas and Tsitsiklis, 1997; Martins et al., 2010)). (Here t(f|e) are the translation parameters of the model, and d(i|j) are the distortion parameters; the product is non-linear, effectively introducing nonconvexity into the problem.) • We describe an optimization algorithm for the relaxed objective, based on a combination of stochastic subgradient methods with the exponentiated-gradient (EG) algorithm (Kivinen and Warmuth, 1997; Beck and Teboulle, 2003). • We describe experiments with the method on standard alignment datasets, showing that the EG algorithm converges in only a few passes over the data, and that our method achieves accuracies that are very similar to those of IBM Model 2. Framing the unsupervised learning of alignment models as a convex optimization problem, with guaranteed convergence to a global optimum, has several clear advantages. First, the method is easier to analyze, as the objective function is being truly maximized. Second, there is no need for initialization heuristics with the approach, given that the method will a</context>
<context position="16751" citStr="Beck and Teboulle, 2003" startWordPosition="2972" endWordPosition="2975">y more stable when the values for gradients do not diverge to infinity. The modified objective remains convex. 5 A Stochastic Exponentiated-Gradient Algorithm for Optimization We now describe an algorithm for optimizing the I2CR-2 problem in Figure 4. The algorithm is closely related to stochastic gradient ascent, but with two modifications: • First, because the t(f|e) and d(i|j) parameters have simplex constraints (see Figure 1), we use exponentiated gradient (EG) updates. EG algorithms are gradient-based methods that maintain simplex constraints; see for example: (Kivinen and Warmuth, 1997; Beck and Teboulle, 2003; Collins et al., 2008). • Second, the objective function in the I2CR2 problem is convex, but is not differentiable (the gradient may not exist at all points). For this reason we use subgradients in the place of gradients. In spite of the non-differentiability of the objective function, subgradient methods still have strong convergence guarantees when combined with EG updates (e.g., the convergence proofs in (Beck and Teboulle, 2003) Input: Same as in I2CR-1 (Figure 4). Parameters: Same as in I2CR-1 (Figure 4). Constraints: Same as in I2CR-1 (Figure 4). Objective: Maximize lk t(f(k) |e(k)) j i</context>
</contexts>
<marker>Beck, Teboulle, 2003</marker>
<rawString>Amir Beck and Marc Teboulle. 2003. Mirror Descent and Nonlinear Projected Subgradient Methods for Convex Optimization. Operations Research Letters, 31:167-175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitris Bertsimas</author>
<author>John N Tsitsiklis</author>
</authors>
<title>Introduction to Linear Programming. Athena Scientific. Dimitris Bertsimas.</title>
<date>1997</date>
<contexts>
<context position="2584" citStr="Bertsimas and Tsitsiklis, 1997" startWordPosition="400" endWordPosition="403">optima, and finding a global optimum of a non-convex function is typically a computationally intractible problem. Typically, an EM algorithm is used, which often runs in a reasonable amount of time, but with no guarantees of finding a global optima (or for that matter, even a near-optimal solution). In this paper we make the following contributions: • We introduce a convex relaxation of IBM Model 2. At a very high level, the relaxation is derived by replacing the product t(fj|ei) x d(i|j) with a relaxation that is commonly used in the linear programming literature (e.g., see (Bertsimas, 1997; Bertsimas and Tsitsiklis, 1997; Martins et al., 2010)). (Here t(f|e) are the translation parameters of the model, and d(i|j) are the distortion parameters; the product is non-linear, effectively introducing nonconvexity into the problem.) • We describe an optimization algorithm for the relaxed objective, based on a combination of stochastic subgradient methods with the exponentiated-gradient (EG) algorithm (Kivinen and Warmuth, 1997; Beck and Teboulle, 2003). • We describe experiments with the method on standard alignment datasets, showing that the EG algorithm converges in only a few passes over the data, and that our met</context>
</contexts>
<marker>Bertsimas, Tsitsiklis, 1997</marker>
<rawString>Dimitris Bertsimas and John N. Tsitsiklis. 1997. Introduction to Linear Programming. Athena Scientific. Dimitris Bertsimas. 2005. Optimization Over Integers. Dynamic Ideas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitri P Bertsekas</author>
</authors>
<title>Nonlinear Optimization.</title>
<date>1999</date>
<publisher>Athena Press.</publisher>
<contexts>
<context position="17701" citStr="Bertsekas, 1999" startWordPosition="3162" endWordPosition="3163">nce guarantees when combined with EG updates (e.g., the convergence proofs in (Beck and Teboulle, 2003) Input: Same as in I2CR-1 (Figure 4). Parameters: Same as in I2CR-1 (Figure 4). Constraints: Same as in I2CR-1 (Figure 4). Objective: Maximize lk t(f(k) |e(k)) j i (L + 1) with respect to the q(i, j, k), t(f|e) and d(i|j) parameters. i=0 1 lk 2n log&apos; � i=0 q(i, j, k) n k=1 �mk j=1 1 + 2n log&apos; n k=1 �mk j=1 lk t(f(k)|e(k)) j i (L + 1) . i=0 1 l k 2n log&apos; � i=0 q(i, j, k) n k=1 �mk j=1 1 + 2n log&apos; n k=1 �mk j=1 l k 1 n log n k=1 � i=0 �mk j=1 1578 go through with minor modifications; see also (Bertsekas, 1999)). To derive the updates, recall that we are maximizing the following objective function: h(t, d) Here we use T to denote the set {1... n}; we will see shortly why this notation is convenient. We use t and d to refer to the full set of t and d parameters respectively; h(t, d) is the function to be maximized. Recall that log&apos;(z) = log(z + λ) where λ is a small positive parameter. Given a concave function f(x) where x ∈ Rd, a subgradient of f(x) at x is any vector g(x) ∈ Rd such that for any y ∈ Rd, f(y) ≤ f(x) + g(x) · (y − x) , where u·v is the inner product between vectors u and v. Subgradien</context>
</contexts>
<marker>Bertsekas, 1999</marker>
<rawString>Dimitri P. Bertsekas. 1999. Nonlinear Optimization. Athena Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Boyd</author>
<author>Lieven Vandenberghe</author>
</authors>
<title>Convex Optimization.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<marker>Boyd, Vandenberghe, 2004</marker>
<rawString>Steven Boyd and Lieven Vandenberghe. 2004. Convex Optimization. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Mercer</author>
</authors>
<date>1993</date>
<booktitle>The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics,</booktitle>
<pages>19--263</pages>
<marker>Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert. L. Mercer. 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation. Computational Linguistics, 19:263-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A Hierarchical Phrase-Based Model for Statistical Machine Translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="1418" citStr="Chiang, 2005" startWordPosition="210" endWordPosition="212">ribe an optimization algorithm for the relaxation based on a subgradient method combined with exponentiated-gradient updates. Our approach gives the same level of alignment accuracy as IBM Model 2. 1 Introduction The IBM translation models (Brown et al., 1993) have been tremendously important in statistical machine translation (SMT). The IBM models were the first generation of SMT systems; in recent work, they play a central role in deriving alignments used within many modern SMT approaches, for example phrase-based translation models (Koehn, 2008) and syntax-based translation systems (e.g., (Chiang, 2005; Marcu et al., 2006)). Since the original IBM paper, there has been a large amount of research exploring the original IBM models and modern variants (e.g., (Moore, 2004; Liang et al., 2006; Toutanova and Galley, 2011; Riley and Gildea, 2012; Vogel et al., 1996)). Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are nonconvex. Unfortunately, non-convex objective functions have multiple local optima, and finding a global optimum of a non-convex function is</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A Hierarchical Phrase-Based Model for Statistical Machine Translation. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Amir Globerson</author>
<author>Terry Koo</author>
<author>Xavier Carreras</author>
<author>Peter L Bartlett</author>
</authors>
<title>Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks.</title>
<date>2008</date>
<booktitle>Journal Machine Learning, 9(Aug):</booktitle>
<pages>1775--1822</pages>
<contexts>
<context position="16774" citStr="Collins et al., 2008" startWordPosition="2976" endWordPosition="2979">lues for gradients do not diverge to infinity. The modified objective remains convex. 5 A Stochastic Exponentiated-Gradient Algorithm for Optimization We now describe an algorithm for optimizing the I2CR-2 problem in Figure 4. The algorithm is closely related to stochastic gradient ascent, but with two modifications: • First, because the t(f|e) and d(i|j) parameters have simplex constraints (see Figure 1), we use exponentiated gradient (EG) updates. EG algorithms are gradient-based methods that maintain simplex constraints; see for example: (Kivinen and Warmuth, 1997; Beck and Teboulle, 2003; Collins et al., 2008). • Second, the objective function in the I2CR2 problem is convex, but is not differentiable (the gradient may not exist at all points). For this reason we use subgradients in the place of gradients. In spite of the non-differentiability of the objective function, subgradient methods still have strong convergence guarantees when combined with EG updates (e.g., the convergence proofs in (Beck and Teboulle, 2003) Input: Same as in I2CR-1 (Figure 4). Parameters: Same as in I2CR-1 (Figure 4). Constraints: Same as in I2CR-1 (Figure 4). Objective: Maximize lk t(f(k) |e(k)) j i (L + 1) with respect t</context>
</contexts>
<marker>Collins, Globerson, Koo, Carreras, Bartlett, 2008</marker>
<rawString>Michael Collins, Amir Globerson, Terry Koo, Xavier Carreras and Peter L. Bartlett. 2008. Exponentiated Gradient Algorithms for Conditional Random Fields and Max-Margin Markov Networks. Journal Machine Learning, 9(Aug): 1775-1822.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A P Dempster</author>
<author>N M Laird</author>
<author>D B Rubin</author>
</authors>
<title>Maximum Likelihood From Incomplete Data via the EM Algorithm.</title>
<date>1977</date>
<journal>Journal of the royal statistical society, series B,</journal>
<pages>39--1</pages>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. P. Dempster, N. M. Laird, and D. B. Rubin. 1977. Maximum Likelihood From Incomplete Data via the EM Algorithm. Journal of the royal statistical society, series B, 39(1):1-38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring Word Alignment Quality for Statistical Machine Translation.</title>
<date>2007</date>
<journal>Journal Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<pages>293--303</pages>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Measuring Word Alignment Quality for Statistical Machine Translation. Journal Computational Linguistics, 33(3): 293-303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Joao V Graca</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Posterior Regularization for Structured Latent Variable Models.</title>
<date>2010</date>
<journal>Journal of Machine Learning,</journal>
<volume>11</volume>
<pages>2001--2049</pages>
<contexts>
<context position="5734" citStr="Ganchev et al., 2010" startWordPosition="899" endWordPosition="902">ced in the literature. (Vogel et al., 1996) introduced a model, sometimes referred to as IBM 2.5, which uses a parameterization that is similar to a hidden Markov model, and which allows the value of each alignment variable to be conditioned on a previous alignment variable. (Liang et al., 2006) describe a method that explicitly incorporates agreement preferences during training. (Och and Ney, 2003) give a systematic comparison of several alignment models in the literature. (Moore, 2004) gives a detailed study of IBM Model 1, showing various steps that can be used to improve its performance. (Ganchev et al., 2010) describes a method based on posterior regularization that incorporates additional constraints within the EM algorithm for estimation of IBM models. All of these approaches are unsupervised, in that they do not require labeled alignment data; however several authors have considered supervised models (e.g., see (Lacoste-Julien et al., 2006; Taskar et al., 2005; Haghighi et al., 2009)). The focus of the current paper is on unsupervised learning; the unsupervised variants described above all make use of nonconvex objective functions during training, with the usual problems with multiple local max</context>
</contexts>
<marker>Ganchev, Graca, Gillenwater, Taskar, 2010</marker>
<rawString>Kuzman Ganchev, Joao V. Graca, Jennifer Gillenwater, Ben Taskar. 2010. Posterior Regularization for Structured Latent Variable Models. Journal of Machine Learning, 11(July): 2001-2049.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joao V Graca</author>
<author>Kuzman Ganchev</author>
<author>Ben Taskar</author>
</authors>
<title>Expectation Maximization and Posterior Constraints.</title>
<date>2007</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<marker>Graca, Ganchev, Taskar, 2007</marker>
<rawString>Joao V. Graca, Kuzman Ganchev and Ben Taskar. 2007. Expectation Maximization and Posterior Constraints. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>John Blitzer</author>
<author>John DeNero</author>
<author>Dan Klein</author>
</authors>
<title>Better Word Alignments with Supervised ITG Models.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="6119" citStr="Haghighi et al., 2009" startWordPosition="956" endWordPosition="959">Och and Ney, 2003) give a systematic comparison of several alignment models in the literature. (Moore, 2004) gives a detailed study of IBM Model 1, showing various steps that can be used to improve its performance. (Ganchev et al., 2010) describes a method based on posterior regularization that incorporates additional constraints within the EM algorithm for estimation of IBM models. All of these approaches are unsupervised, in that they do not require labeled alignment data; however several authors have considered supervised models (e.g., see (Lacoste-Julien et al., 2006; Taskar et al., 2005; Haghighi et al., 2009)). The focus of the current paper is on unsupervised learning; the unsupervised variants described above all make use of nonconvex objective functions during training, with the usual problems with multiple local maxima. 3 The IBM Model 1 and Model 2 Optimization Problems In this section we give a brief review of IBM Models 1 and 2, and the optimization problems arising from these models. The standard approach for optimization within these models is the EM algorithm. Throughout this section, and the remainder of the paper, we assume that our set of training examples is (e(k), f(k)) for k = 1...</context>
</contexts>
<marker>Haghighi, Blitzer, DeNero, Klein, 2009</marker>
<rawString>Aria Haghighi, John Blitzer, John DeNero and Dan Klein. 2009. Better Word Alignments with Supervised ITG Models. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darcey Riley</author>
<author>Daniel Gildea</author>
</authors>
<title>Improving the IBM Alignment Models Using Variational Bayes.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="1659" citStr="Riley and Gildea, 2012" startWordPosition="252" endWordPosition="255">n models (Brown et al., 1993) have been tremendously important in statistical machine translation (SMT). The IBM models were the first generation of SMT systems; in recent work, they play a central role in deriving alignments used within many modern SMT approaches, for example phrase-based translation models (Koehn, 2008) and syntax-based translation systems (e.g., (Chiang, 2005; Marcu et al., 2006)). Since the original IBM paper, there has been a large amount of research exploring the original IBM models and modern variants (e.g., (Moore, 2004; Liang et al., 2006; Toutanova and Galley, 2011; Riley and Gildea, 2012; Vogel et al., 1996)). Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are nonconvex. Unfortunately, non-convex objective functions have multiple local optima, and finding a global optimum of a non-convex function is typically a computationally intractible problem. Typically, an EM algorithm is used, which often runs in a reasonable amount of time, but with no guarantees of finding a global optima (or for that matter, even a near-optimal solution). In t</context>
</contexts>
<marker>Riley, Gildea, 2012</marker>
<rawString>Darcey Riley and Daniel Gildea. 2012. Improving the IBM Alignment Models Using Variational Bayes. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuhong Guo</author>
<author>Dale Schuurmans</author>
</authors>
<title>Convex Relaxations of Latent Variable Training.</title>
<date>2007</date>
<booktitle>In NIPS.</booktitle>
<marker>Guo, Schuurmans, 2007</marker>
<rawString>Yuhong Guo and Dale Schuurmans. 2007. Convex Relaxations of Latent Variable Training. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Lacoste-Julien</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
<author>Michael Jordan</author>
</authors>
<title>Word Alignment via Quadratic Assignment.</title>
<date>2008</date>
<booktitle>In Proceedings of the HLT-NAACL.</booktitle>
<marker>Lacoste-Julien, Taskar, Klein, Jordan, 2008</marker>
<rawString>Simon Lacoste-Julien, Ben Taskar, Dan Klein, and Michael Jordan. 2008. Word Alignment via Quadratic Assignment. In Proceedings of the HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Phillip Koehn</author>
</authors>
<title>Statistical Machine Translation.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1360" citStr="Koehn, 2008" startWordPosition="203" endWordPosition="204"> we introduce a convex relaxation of IBM Model 2, and describe an optimization algorithm for the relaxation based on a subgradient method combined with exponentiated-gradient updates. Our approach gives the same level of alignment accuracy as IBM Model 2. 1 Introduction The IBM translation models (Brown et al., 1993) have been tremendously important in statistical machine translation (SMT). The IBM models were the first generation of SMT systems; in recent work, they play a central role in deriving alignments used within many modern SMT approaches, for example phrase-based translation models (Koehn, 2008) and syntax-based translation systems (e.g., (Chiang, 2005; Marcu et al., 2006)). Since the original IBM paper, there has been a large amount of research exploring the original IBM models and modern variants (e.g., (Moore, 2004; Liang et al., 2006; Toutanova and Galley, 2011; Riley and Gildea, 2012; Vogel et al., 1996)). Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are nonconvex. Unfortunately, non-convex objective functions have multiple local optima</context>
<context position="8359" citStr="Koehn, 2008" startWordPosition="1369" endWordPosition="1370">f are seen in a translation pair. Given these definitions, the IBM model 2 optimization problem is given in Figure 1. The parameters in this problem are t(f|e) and d(i|j). The t(f|e) parameters are translation parameters specifying the probability of English word e being translated as French word f. The distortion parameters d(i|j) specify the probability of the j’th French word in a sentence being aligned to the i’th English word. We use a variant of IBM Model 2 where the distortion variables are shared across all sentence lengths (similar variants have been used in (Liang et al., 2006) and (Koehn, 2008)). The objective function is then 1575 Figure 1: The IBM Model 2 Optimization Problem. the log-likelihood of the training data (see Eq. 5): log p(f(k) j |e(k)) , Figure 2: The IBM Model 1 Optimization Problem. A common heuristic is to initialize the t(f|e) parameters in EM optimization of IBM Model 2 using the output from IBM Model 1. The intuition behind this heuristic is that the IBM Model 1 values for t(f|e) will be a reasonable starting point, and the EM algorithm will climb to a “good” local optimum. We are not aware of any guarantees for this initialization heuristic, however. Input: Def</context>
</contexts>
<marker>Koehn, 2008</marker>
<rawString>Phillip Koehn. 2008. Statistical Machine Translation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kivinen</author>
<author>M Warmuth</author>
</authors>
<title>Exponentiated Gradient Versus Gradient Descent for Linear Predictors.</title>
<date>1997</date>
<journal>Information and Computation,</journal>
<volume>132</volume>
<pages>1--63</pages>
<contexts>
<context position="2990" citStr="Kivinen and Warmuth, 1997" startWordPosition="459" endWordPosition="463">y high level, the relaxation is derived by replacing the product t(fj|ei) x d(i|j) with a relaxation that is commonly used in the linear programming literature (e.g., see (Bertsimas, 1997; Bertsimas and Tsitsiklis, 1997; Martins et al., 2010)). (Here t(f|e) are the translation parameters of the model, and d(i|j) are the distortion parameters; the product is non-linear, effectively introducing nonconvexity into the problem.) • We describe an optimization algorithm for the relaxed objective, based on a combination of stochastic subgradient methods with the exponentiated-gradient (EG) algorithm (Kivinen and Warmuth, 1997; Beck and Teboulle, 2003). • We describe experiments with the method on standard alignment datasets, showing that the EG algorithm converges in only a few passes over the data, and that our method achieves accuracies that are very similar to those of IBM Model 2. Framing the unsupervised learning of alignment models as a convex optimization problem, with guaranteed convergence to a global optimum, has several clear advantages. First, the method is easier to analyze, as the objective function is being truly maximized. Second, there is no need for initialization heuristics with the approach, gi</context>
<context position="16726" citStr="Kivinen and Warmuth, 1997" startWordPosition="2968" endWordPosition="2971">ound them to be considerably more stable when the values for gradients do not diverge to infinity. The modified objective remains convex. 5 A Stochastic Exponentiated-Gradient Algorithm for Optimization We now describe an algorithm for optimizing the I2CR-2 problem in Figure 4. The algorithm is closely related to stochastic gradient ascent, but with two modifications: • First, because the t(f|e) and d(i|j) parameters have simplex constraints (see Figure 1), we use exponentiated gradient (EG) updates. EG algorithms are gradient-based methods that maintain simplex constraints; see for example: (Kivinen and Warmuth, 1997; Beck and Teboulle, 2003; Collins et al., 2008). • Second, the objective function in the I2CR2 problem is convex, but is not differentiable (the gradient may not exist at all points). For this reason we use subgradients in the place of gradients. In spite of the non-differentiability of the objective function, subgradient methods still have strong convergence guarantees when combined with EG updates (e.g., the convergence proofs in (Beck and Teboulle, 2003) Input: Same as in I2CR-1 (Figure 4). Parameters: Same as in I2CR-1 (Figure 4). Constraints: Same as in I2CR-1 (Figure 4). Objective: Maxi</context>
</contexts>
<marker>Kivinen, Warmuth, 1997</marker>
<rawString>Kivinen, J., Warmuth, M. 1997. Exponentiated Gradient Versus Gradient Descent for Linear Predictors. Information and Computation, 132, 1-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Ben Taskar</author>
<author>Dan Klein</author>
</authors>
<title>Alignment by Agreement.</title>
<date>2006</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="1607" citStr="Liang et al., 2006" startWordPosition="244" endWordPosition="247">s IBM Model 2. 1 Introduction The IBM translation models (Brown et al., 1993) have been tremendously important in statistical machine translation (SMT). The IBM models were the first generation of SMT systems; in recent work, they play a central role in deriving alignments used within many modern SMT approaches, for example phrase-based translation models (Koehn, 2008) and syntax-based translation systems (e.g., (Chiang, 2005; Marcu et al., 2006)). Since the original IBM paper, there has been a large amount of research exploring the original IBM models and modern variants (e.g., (Moore, 2004; Liang et al., 2006; Toutanova and Galley, 2011; Riley and Gildea, 2012; Vogel et al., 1996)). Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are nonconvex. Unfortunately, non-convex objective functions have multiple local optima, and finding a global optimum of a non-convex function is typically a computationally intractible problem. Typically, an EM algorithm is used, which often runs in a reasonable amount of time, but with no guarantees of finding a global optima (or </context>
<context position="5409" citStr="Liang et al., 2006" startWordPosition="847" endWordPosition="850">d optimization methods for these models based on the EM algorithm. While the models were originally introduced for full translation, they are now mainly used to derive alignments which are then used by phrase-based and other modern SMT systems. Since the original IBM models were introduced, many variants have been introduced in the literature. (Vogel et al., 1996) introduced a model, sometimes referred to as IBM 2.5, which uses a parameterization that is similar to a hidden Markov model, and which allows the value of each alignment variable to be conditioned on a previous alignment variable. (Liang et al., 2006) describe a method that explicitly incorporates agreement preferences during training. (Och and Ney, 2003) give a systematic comparison of several alignment models in the literature. (Moore, 2004) gives a detailed study of IBM Model 1, showing various steps that can be used to improve its performance. (Ganchev et al., 2010) describes a method based on posterior regularization that incorporates additional constraints within the EM algorithm for estimation of IBM models. All of these approaches are unsupervised, in that they do not require labeled alignment data; however several authors have con</context>
<context position="8341" citStr="Liang et al., 2006" startWordPosition="1364" endWordPosition="1367"> words f such that e and f are seen in a translation pair. Given these definitions, the IBM model 2 optimization problem is given in Figure 1. The parameters in this problem are t(f|e) and d(i|j). The t(f|e) parameters are translation parameters specifying the probability of English word e being translated as French word f. The distortion parameters d(i|j) specify the probability of the j’th French word in a sentence being aligned to the i’th English word. We use a variant of IBM Model 2 where the distortion variables are shared across all sentence lengths (similar variants have been used in (Liang et al., 2006) and (Koehn, 2008)). The objective function is then 1575 Figure 1: The IBM Model 2 Optimization Problem. the log-likelihood of the training data (see Eq. 5): log p(f(k) j |e(k)) , Figure 2: The IBM Model 1 Optimization Problem. A common heuristic is to initialize the t(f|e) parameters in EM optimization of IBM Model 2 using the output from IBM Model 1. The intuition behind this heuristic is that the IBM Model 1 values for t(f|e) will be a reasonable starting point, and the EM algorithm will climb to a “good” local optimum. We are not aware of any guarantees for this initialization heuristic, h</context>
</contexts>
<marker>Liang, Taskar, Klein, 2006</marker>
<rawString>Percy Liang, Ben Taskar and Dan Klein. 2006. Alignment by Agreement. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Wei Wang</author>
<author>Abdessamad Echihabi</author>
<author>Kevin Knight</author>
</authors>
<title>SPMT: Statistical Machine Translation with Syntactified Target Language Phrases.</title>
<date>2006</date>
<booktitle>In Proceedings of the EMNLP.</booktitle>
<contexts>
<context position="1439" citStr="Marcu et al., 2006" startWordPosition="213" endWordPosition="216">zation algorithm for the relaxation based on a subgradient method combined with exponentiated-gradient updates. Our approach gives the same level of alignment accuracy as IBM Model 2. 1 Introduction The IBM translation models (Brown et al., 1993) have been tremendously important in statistical machine translation (SMT). The IBM models were the first generation of SMT systems; in recent work, they play a central role in deriving alignments used within many modern SMT approaches, for example phrase-based translation models (Koehn, 2008) and syntax-based translation systems (e.g., (Chiang, 2005; Marcu et al., 2006)). Since the original IBM paper, there has been a large amount of research exploring the original IBM models and modern variants (e.g., (Moore, 2004; Liang et al., 2006; Toutanova and Galley, 2011; Riley and Gildea, 2012; Vogel et al., 1996)). Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are nonconvex. Unfortunately, non-convex objective functions have multiple local optima, and finding a global optimum of a non-convex function is typically a computat</context>
</contexts>
<marker>Marcu, Wang, Echihabi, Knight, 2006</marker>
<rawString>Daniel Marcu, Wei Wang, Abdessamad Echihabi, and Kevin Knight. 2006. SPMT: Statistical Machine Translation with Syntactified Target Language Phrases. In Proceedings of the EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andre F T Martins</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Turbo Parsers: Dependency Parsing by Approximate Variational Inference.</title>
<date>2010</date>
<booktitle>In Proceedings of the EMNLP.</booktitle>
<contexts>
<context position="2607" citStr="Martins et al., 2010" startWordPosition="404" endWordPosition="407">imum of a non-convex function is typically a computationally intractible problem. Typically, an EM algorithm is used, which often runs in a reasonable amount of time, but with no guarantees of finding a global optima (or for that matter, even a near-optimal solution). In this paper we make the following contributions: • We introduce a convex relaxation of IBM Model 2. At a very high level, the relaxation is derived by replacing the product t(fj|ei) x d(i|j) with a relaxation that is commonly used in the linear programming literature (e.g., see (Bertsimas, 1997; Bertsimas and Tsitsiklis, 1997; Martins et al., 2010)). (Here t(f|e) are the translation parameters of the model, and d(i|j) are the distortion parameters; the product is non-linear, effectively introducing nonconvexity into the problem.) • We describe an optimization algorithm for the relaxed objective, based on a combination of stochastic subgradient methods with the exponentiated-gradient (EG) algorithm (Kivinen and Warmuth, 1997; Beck and Teboulle, 2003). • We describe experiments with the method on standard alignment datasets, showing that the EG algorithm converges in only a few passes over the data, and that our method achieves accuracies</context>
</contexts>
<marker>Martins, Smith, Xing, 2010</marker>
<rawString>Andre F. T. Martins, Noah A. Smith and Eric P. Xing. 2010. Turbo Parsers: Dependency Parsing by Approximate Variational Inference. In Proceedings of the EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Michalcea</author>
<author>Ted Pederson</author>
</authors>
<title>An Evaluation Exercise in Word Alignment. HLT-NAACL 2003: Workshop in building and using Parallel Texts: Data Driven Machine Translation and Beyond.</title>
<date>2003</date>
<contexts>
<context position="21468" citStr="Michalcea and Pederson, 2003" startWordPosition="3869" endWordPosition="3872">g0 Mk L �=1 R(j, k) = λ + L i=0 Q(j,k) = λ + L i=0 1 L ∇t(f|e) = 2|T | i,j,k: f(k)=f j e(k) i =e . 1579 Figure 5: The stochastic exponentiated-gradient algorithm for optimization of I2CR-2. stochastic EG algorithm for parameter estimation. We first describe the data sets we use, and then describe experiments with the method, comparing our approach to results from IBM Model 2. We compare the various algorithms in terms of their accuracy in recovering alignments, using metrics such as F-measure and AER. 6.1 Data Sets We use data from the bilingual word alignment workshop held at HLT-NAACL 2003 (Michalcea and Pederson, 2003). As a first dataset, we use the Canadian Hansards bilingual corpus, with 247,878 English-French sentence pairs as training data, 37 sentences of development data, and 447 sentences of test data (note that we use a randomly chosen subset of the original training set of 1.1 million sentences, similar to the setting used in (Moore, 2004)). The development and test data have been manually aligned at the word level, annotating alignments between source and target words in the corpus as either “sure” (S) or “possible” (P) alignments, as described in (Och and Ney, 2003). As a second data set, we use</context>
</contexts>
<marker>Michalcea, Pederson, 2003</marker>
<rawString>Rada Michalcea and Ted Pederson. 2003. An Evaluation Exercise in Word Alignment. HLT-NAACL 2003: Workshop in building and using Parallel Texts: Data Driven Machine Translation and Beyond.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
</authors>
<title>Improving IBM WordAlignment Model 1.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="1587" citStr="Moore, 2004" startWordPosition="242" endWordPosition="243">nt accuracy as IBM Model 2. 1 Introduction The IBM translation models (Brown et al., 1993) have been tremendously important in statistical machine translation (SMT). The IBM models were the first generation of SMT systems; in recent work, they play a central role in deriving alignments used within many modern SMT approaches, for example phrase-based translation models (Koehn, 2008) and syntax-based translation systems (e.g., (Chiang, 2005; Marcu et al., 2006)). Since the original IBM paper, there has been a large amount of research exploring the original IBM models and modern variants (e.g., (Moore, 2004; Liang et al., 2006; Toutanova and Galley, 2011; Riley and Gildea, 2012; Vogel et al., 1996)). Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are nonconvex. Unfortunately, non-convex objective functions have multiple local optima, and finding a global optimum of a non-convex function is typically a computationally intractible problem. Typically, an EM algorithm is used, which often runs in a reasonable amount of time, but with no guarantees of finding </context>
<context position="5605" citStr="Moore, 2004" startWordPosition="878" endWordPosition="879">hrase-based and other modern SMT systems. Since the original IBM models were introduced, many variants have been introduced in the literature. (Vogel et al., 1996) introduced a model, sometimes referred to as IBM 2.5, which uses a parameterization that is similar to a hidden Markov model, and which allows the value of each alignment variable to be conditioned on a previous alignment variable. (Liang et al., 2006) describe a method that explicitly incorporates agreement preferences during training. (Och and Ney, 2003) give a systematic comparison of several alignment models in the literature. (Moore, 2004) gives a detailed study of IBM Model 1, showing various steps that can be used to improve its performance. (Ganchev et al., 2010) describes a method based on posterior regularization that incorporates additional constraints within the EM algorithm for estimation of IBM models. All of these approaches are unsupervised, in that they do not require labeled alignment data; however several authors have considered supervised models (e.g., see (Lacoste-Julien et al., 2006; Taskar et al., 2005; Haghighi et al., 2009)). The focus of the current paper is on unsupervised learning; the unsupervised varian</context>
<context position="21805" citStr="Moore, 2004" startWordPosition="3927" endWordPosition="3928">esults from IBM Model 2. We compare the various algorithms in terms of their accuracy in recovering alignments, using metrics such as F-measure and AER. 6.1 Data Sets We use data from the bilingual word alignment workshop held at HLT-NAACL 2003 (Michalcea and Pederson, 2003). As a first dataset, we use the Canadian Hansards bilingual corpus, with 247,878 English-French sentence pairs as training data, 37 sentences of development data, and 447 sentences of test data (note that we use a randomly chosen subset of the original training set of 1.1 million sentences, similar to the setting used in (Moore, 2004)). The development and test data have been manually aligned at the word level, annotating alignments between source and target words in the corpus as either “sure” (S) or “possible” (P) alignments, as described in (Och and Ney, 2003). As a second data set, we used the RomanianEnglish data from the HLT-NAACL 2003 workshop. This consisted of a training set of 48,706 RomanianEnglish sentence-pairs, a development set of 17 sentence pairs, and a test set of 248 sentence pairs. 6.2 Methodology For each of the models—IBM Model 1, IBM Model 2, and I2CR-2—we follow convention in applying the following </context>
<context position="24775" citStr="Moore, 2004" startWordPosition="4558" endWordPosition="4559">(k) i , f(k) 16: j ) += 1/(2Q(j, k)) 17: else 18: 0(i, j) += 1/(2Q(j, k)) 19: de, f, t(f|e) = t(f|e) exp (y x α(e, f)/B) 20: di, j, d(i|j) = d(i|j) exp (y x 0(i, j)/B) 21: Renormalize t and d parameters to satisfy E f t(f|e) = 1 and Ei d(i|j) = 1. 22: Output: t and d parameters. 1580 Precision = |A n S| |A |, AER = 1 _ |A n S |+ |A n P| |A |+ |S |, Note that we report results in both AER and F-measure; however there is evidence (Fraser and Marcu, 2004) that F-measure is better correlated with translation quality when the alignments are used in a full system. In training IBM Model 1 we follow (Moore, 2004) in running EM for 15 iterations. In training IBM Model 2 we first train IBM Model 1 for 15 iterations to initialize the t parameters, then train IBM Model 2 for a further 10 iterations. For the EG algorithm, we use 10 iterations over the training data for the Hansards data, and 15 iterations on the Romanian-English data (on the latter dataset results on the trial data showed that the method took slightly longer to converge). We report F-measure and AER results for each of the iterations under the IBM Model 2 and I2CR-2 models. See Table 1 for the results on the Hansards data, and Table 2 for </context>
</contexts>
<marker>Moore, 2004</marker>
<rawString>Robert C. Moore. 2004. Improving IBM WordAlignment Model 1. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillman</author>
</authors>
<title>HMM-Based Word Alignment in Statistical Translation.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING.</booktitle>
<contexts>
<context position="1680" citStr="Vogel et al., 1996" startWordPosition="256" endWordPosition="259">1993) have been tremendously important in statistical machine translation (SMT). The IBM models were the first generation of SMT systems; in recent work, they play a central role in deriving alignments used within many modern SMT approaches, for example phrase-based translation models (Koehn, 2008) and syntax-based translation systems (e.g., (Chiang, 2005; Marcu et al., 2006)). Since the original IBM paper, there has been a large amount of research exploring the original IBM models and modern variants (e.g., (Moore, 2004; Liang et al., 2006; Toutanova and Galley, 2011; Riley and Gildea, 2012; Vogel et al., 1996)). Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are nonconvex. Unfortunately, non-convex objective functions have multiple local optima, and finding a global optimum of a non-convex function is typically a computationally intractible problem. Typically, an EM algorithm is used, which often runs in a reasonable amount of time, but with no guarantees of finding a global optima (or for that matter, even a near-optimal solution). In this paper we make the</context>
<context position="5156" citStr="Vogel et al., 1996" startWordPosition="804" endWordPosition="807">l open up new directions and lead to further progress in this area. Notation. Throughout this paper, for any integer N, we use [N] to denote {1... N} and [N]0 to denote {0 ... N}. 2 Related Work (Brown et al., 1993) introduced IBM Models 1 through 5, and optimization methods for these models based on the EM algorithm. While the models were originally introduced for full translation, they are now mainly used to derive alignments which are then used by phrase-based and other modern SMT systems. Since the original IBM models were introduced, many variants have been introduced in the literature. (Vogel et al., 1996) introduced a model, sometimes referred to as IBM 2.5, which uses a parameterization that is similar to a hidden Markov model, and which allows the value of each alignment variable to be conditioned on a previous alignment variable. (Liang et al., 2006) describe a method that explicitly incorporates agreement preferences during training. (Och and Ney, 2003) give a systematic comparison of several alignment models in the literature. (Moore, 2004) gives a detailed study of IBM Model 1, showing various steps that can be used to improve its performance. (Ganchev et al., 2010) describes a method ba</context>
</contexts>
<marker>Vogel, Ney, Tillman, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney and Christoph Tillman. 1996. HMM-Based Word Alignment in Statistical Translation. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational-Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="5515" citStr="Och and Ney, 2003" startWordPosition="862" endWordPosition="865">ced for full translation, they are now mainly used to derive alignments which are then used by phrase-based and other modern SMT systems. Since the original IBM models were introduced, many variants have been introduced in the literature. (Vogel et al., 1996) introduced a model, sometimes referred to as IBM 2.5, which uses a parameterization that is similar to a hidden Markov model, and which allows the value of each alignment variable to be conditioned on a previous alignment variable. (Liang et al., 2006) describe a method that explicitly incorporates agreement preferences during training. (Och and Ney, 2003) give a systematic comparison of several alignment models in the literature. (Moore, 2004) gives a detailed study of IBM Model 1, showing various steps that can be used to improve its performance. (Ganchev et al., 2010) describes a method based on posterior regularization that incorporates additional constraints within the EM algorithm for estimation of IBM models. All of these approaches are unsupervised, in that they do not require labeled alignment data; however several authors have considered supervised models (e.g., see (Lacoste-Julien et al., 2006; Taskar et al., 2005; Haghighi et al., 2</context>
<context position="22038" citStr="Och and Ney, 2003" startWordPosition="3966" endWordPosition="3969">at HLT-NAACL 2003 (Michalcea and Pederson, 2003). As a first dataset, we use the Canadian Hansards bilingual corpus, with 247,878 English-French sentence pairs as training data, 37 sentences of development data, and 447 sentences of test data (note that we use a randomly chosen subset of the original training set of 1.1 million sentences, similar to the setting used in (Moore, 2004)). The development and test data have been manually aligned at the word level, annotating alignments between source and target words in the corpus as either “sure” (S) or “possible” (P) alignments, as described in (Och and Ney, 2003). As a second data set, we used the RomanianEnglish data from the HLT-NAACL 2003 workshop. This consisted of a training set of 48,706 RomanianEnglish sentence-pairs, a development set of 17 sentence pairs, and a test set of 248 sentence pairs. 6.2 Methodology For each of the models—IBM Model 1, IBM Model 2, and I2CR-2—we follow convention in applying the following methodology: first, we estimate the t and d parameters using models in both sourcetarget and target-source directions; second, we find the most likely alignment for each development or test data sentence in each direction; third, we </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational-Linguistics, 29(1): 19-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
</authors>
<title>A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model.</title>
<date>2008</date>
<booktitle>In Proceedings of the ACL-HLT.</booktitle>
<marker>Shen, Xu, Weischedel, 2008</marker>
<rawString>Libin Shen, Jinxi Xu and Ralph Weischedel. 2008. A New String-to-Dependency Machine Translation Algorithm with a Target Dependency Language Model. In Proceedings of the ACL-HLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Taskar</author>
<author>Simon Lacoste-Julien</author>
<author>Dan Klein</author>
</authors>
<title>A Discriminative Matching Approach to Word Alignment.</title>
<date>2005</date>
<booktitle>In Proceedings of the EMNLP.</booktitle>
<contexts>
<context position="6095" citStr="Taskar et al., 2005" startWordPosition="952" endWordPosition="955">es during training. (Och and Ney, 2003) give a systematic comparison of several alignment models in the literature. (Moore, 2004) gives a detailed study of IBM Model 1, showing various steps that can be used to improve its performance. (Ganchev et al., 2010) describes a method based on posterior regularization that incorporates additional constraints within the EM algorithm for estimation of IBM models. All of these approaches are unsupervised, in that they do not require labeled alignment data; however several authors have considered supervised models (e.g., see (Lacoste-Julien et al., 2006; Taskar et al., 2005; Haghighi et al., 2009)). The focus of the current paper is on unsupervised learning; the unsupervised variants described above all make use of nonconvex objective functions during training, with the usual problems with multiple local maxima. 3 The IBM Model 1 and Model 2 Optimization Problems In this section we give a brief review of IBM Models 1 and 2, and the optimization problems arising from these models. The standard approach for optimization within these models is the EM algorithm. Throughout this section, and the remainder of the paper, we assume that our set of training examples is (</context>
</contexts>
<marker>Taskar, Lacoste-Julien, Klein, 2005</marker>
<rawString>Ben Taskar, Simon Lacoste-Julien and Dan Klein. 2005. A Discriminative Matching Approach to Word Alignment. In Proceedings of the EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Michel Galley</author>
</authors>
<title>Why Initialization Matters for IBM Model 1: Multiple Optima and Non-Strict Convexity.</title>
<date>2011</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<contexts>
<context position="1635" citStr="Toutanova and Galley, 2011" startWordPosition="248" endWordPosition="251">roduction The IBM translation models (Brown et al., 1993) have been tremendously important in statistical machine translation (SMT). The IBM models were the first generation of SMT systems; in recent work, they play a central role in deriving alignments used within many modern SMT approaches, for example phrase-based translation models (Koehn, 2008) and syntax-based translation systems (e.g., (Chiang, 2005; Marcu et al., 2006)). Since the original IBM paper, there has been a large amount of research exploring the original IBM models and modern variants (e.g., (Moore, 2004; Liang et al., 2006; Toutanova and Galley, 2011; Riley and Gildea, 2012; Vogel et al., 1996)). Excluding IBM Model 1, the IBM translation models, and practically all variants proposed in the literature, have relied on the optimization of likelihood functions or similar functions that are nonconvex. Unfortunately, non-convex objective functions have multiple local optima, and finding a global optimum of a non-convex function is typically a computationally intractible problem. Typically, an EM algorithm is used, which often runs in a reasonable amount of time, but with no guarantees of finding a global optima (or for that matter, even a near</context>
</contexts>
<marker>Toutanova, Galley, 2011</marker>
<rawString>Kristina Toutanova and Michel Galley. 2011. Why Initialization Matters for IBM Model 1: Multiple Optima and Non-Strict Convexity. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A Syntax-Based Statistical Translation Model.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A Syntax-Based Statistical Translation Model. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A Decoder for Syntax-Based Statistical Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<marker>Yamada, Knight, 2002</marker>
<rawString>Kenji Yamada and Kevin Knight. 2002. A Decoder for Syntax-Based Statistical Machine Translation. In Proceedings of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Vaswani</author>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the LO-norm.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL.</booktitle>
<marker>Vaswani, Huang, Chiang, 2012</marker>
<rawString>Ashish Vaswani, Liang Huang and David Chiang. 2012. Smaller Alignment Models for Better Translations: Unsupervised Word Alignment with the LO-norm. In Proceedings of the ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>