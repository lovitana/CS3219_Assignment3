<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000117">
<title confidence="0.967116">
Relational Inference for Wikification
</title>
<author confidence="0.998406">
Xiao Cheng Dan Roth
</author>
<affiliation confidence="0.9990235">
Department of Computer Science
University of Illinois at Urbana-Champaign
</affiliation>
<address confidence="0.795799">
Urbana, IL 61801
</address>
<email confidence="0.9989">
{cheng88,danr}@illinois.edu
</email>
<sectionHeader confidence="0.997388" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99820704">
Wikification, commonly referred to as Disam-
biguation to Wikipedia (D2W), is the task of
identifying concepts and entities in text and
disambiguating them into the most specific
corresponding Wikipedia pages. Previous ap-
proaches to D2W focused on the use of lo-
cal and global statistics over the given text,
Wikipedia articles and its link structures, to
evaluate context compatibility among a list of
probable candidates. However, these meth-
ods fail (often, embarrassingly), when some
level of text understanding is needed to sup-
port Wikification. In this paper we introduce
a novel approach to Wikification by incorpo-
rating, along with statistical methods, richer
relational analysis of the text. We provide an
extensible, efficient and modular Integer Lin-
ear Programming (ILP) formulation of Wik-
ification that incorporates the entity-relation
inference problem, and show that the ability
to identify relations in text helps both candi-
date generation and ranking Wikipedia titles
considerably. Our results show significant im-
provements in both Wikification and the TAC
Entity Linking task.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995173844444445">
Wikification (D2W), the task of identifying concepts
and entities in text and disambiguating them into
their corresponding Wikipedia page, is an important
step toward supporting deeper textual understand-
ing, by augmenting the ability to ground text in ex-
isting knowledge and facilitating knowledge expan-
sion.
D2W has been studied extensively recently
(Cucerzan, 2007; Mihalcea and Csomai, 2007;
Milne and Witten, 2008; Ferragina and Scaiella,
2010; Ratinov et al., 2011) and has already found
broad applications in NLP, Information Extraction,
and Knowledge Acquisition from text, from coref-
erence resolution (Ratinov and Roth, 2012) to entity
linking and knowledge population (Ellis et al., 2011;
Ji et al., 2010; Cucerzan, 2011).
Given a document D containing a set of concept
and entity mentions M ( referred to later as surface),
the goal of Wikification is to find the most accurate
mapping from mentions to Wikipedia titles T; this
mapping needs to take into account our understand-
ing of the text as well as background knowledge that
is often needed to determine the most appropriate ti-
tle. We also allow a special NIL title that captures
all mentions that are outside Wikipedia.
Earlier approaches treated this task as a word-
sense disambiguation (WSD) problem, which was
later enhanced with a certain level of global rea-
soning, but essentially all approaches focused on
generic statistical features in order to achieve robust
disambiguation. It was shown that by disambiguat-
ing to the most likely title for every surface, in-
dependently maximizing the conditional probability
Pr(title|surface), we already achieve a very com-
petitive baseline on several Wikification datasets
(Ratinov et al., 2011). This strong statistical baseline
makes use of the relatively comprehensive coverage
of the existing Wikipedia links from surface strings
to Wikipedia titles. Although more involved statis-
tical features are required in order to make substan-
tial improvements, global features such as context
TF-IDF, better string similarity, etc., statistics-based
Wikification systems give a fairly coherent set of
disambiguation when sufficient context is available.
Consider the following example: Earth’s biosphere
</bodyText>
<page confidence="0.940065">
1787
</page>
<note confidence="0.754955">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1787–1796,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.986264371794872">
then significantly altered the atmospheric and other ba-
sic physical conditions, which enabled the proliferation
of organisms. The atmosphere is composed of 78.09%
nitrogen, 20.95% oxygen, 0.93% argon, 0.039% carbon
dioxide, and small amounts of...
The baseline system we adopted (Ratinov et al.,
2011), one of the best Wikification systems, al-
ready disambiguates atmosphere correctly to the ti-
tle Earth’s atmosphere instead of the more general
title Atmosphere, making use of the concept Earth in
its local context to resolve the mention to the more
specific title that better coheres with the topic. How-
ever, consider the following example:
Ex. 1 “As Mubarak, the wife of deposed Egyptian
President Hosni Mubarak got older, her influence...”
The bold faced name should be mapped to Suzanne
Mubarak, but all existing Wikification systems map
both names in this sentence to the dominant page
(the most linked page) of Hosni Mubarak, failing to
understand the relation between them, which should
prevent them from being mapped to the same page.
A certain level of text understanding is required even
to be able to generate a good list of title candidates.
For example, in:
Ex. 2 “...ousted long time Yugoslav President Slo-
bodan Miloˇsevi´c in October. Mr. Miloˇsevi´c’s So-
cialist Party...”
the bold-faced concept should be mapped to the
page of the Socialist Party of Serbia, which is far
down the list of titles that could be related to “So-
cialist Party”; making this title a likely candidate
requires understanding the possessive relation with
Miloˇsevi´c and then making the knowledge-informed
decision that he is more related to Socialist Party of
Serbia than any other possible titles. Finally, in
Ex. 3 “James Senn, director of Robinson College’s
Center for Global Business Leadership at Georgia
State University...”
we must link Robinson College to J. Mack Robin-
son College of Business which is located at Geor-
gia State University instead of Robinson College,
Cambridge, which is the only probable title linked
by the surface Robinson College in the version of
the Wikipedia dump we used.
These examples further illustrate that, along with
understanding the relation expressed in the text, we
need to access background knowledge sources and
to deal with variability in surface representation
across the text, Wikipedia, and knowledge, in order
to reliably address the Wikification problem.
In this paper we focus on understanding those nat-
ural language constructs that will allow eliminat-
ing these “obvious” (to a human reader) mistakes
from Wikification. In particular, we focus on resolv-
ing coreference and a collection of local syntactico-
semantic relations (Chan and Roth, 2011); better un-
derstanding the relational structure of the text allows
us to generate title candidates more accurately given
the text, rank these candidates better and determine
when a mention in text has no corresponding title
in Wikipedia and should be mapped to NIL, a key
problem in Wikification. Moreover, it allows us to
access external knowledge based resources more ef-
fectively in order to support these decisions.
We incorporate the outcome of our relational
analysis, along with the associated features extracted
from external sources and the “standard” wikifica-
tion statistical features, into an ILP-based inference
framework that globally determines the best assign-
ment of mentions to titles in a given document. We
show that by leveraging a better understanding of
the textual relations, we can substantially improve
the Wikification performance. Our system signifi-
cantly outperforms all the top Wikification systems
on the widely adopted standard datasets and shows
state-of-the-art results when evaluated (without be-
ing trained directly) on the TAC 2011 Entity Linking
task.
</bodyText>
<sectionHeader confidence="0.959089" genericHeader="method">
2 The Wikification Approach
</sectionHeader>
<bodyText confidence="0.999697076923077">
A general Wikification decision consists of three
computational components: (1) generating a ranked
list of title candidates for each mention, (2) rank-
ing candidates globally, and (3) dealing with NIL
mentions. For (1), the “standard” way of using
Pr(title|surface) is often not sufficient; consider
the case where the mention is the single word “Presi-
dent”; disambiguating such mentions depends heav-
ily on the context, i.e. to determine the relevant
country or organization. However, it is intractable to
search the entire surface-to-title space, and using an
arbitrary top-K list will inevitably leave out a large
number of potential solutions. For (2), even though
</bodyText>
<page confidence="0.986266">
1788
</page>
<bodyText confidence="0.9990179375">
the anchor texts cover many possible ways of para-
phrasing the Wikipedia article titles and thus using
the top Pr(title|surface) is proven to be a fairly
strong baseline, it is never comprehensive. There is
a need to disambiguate titles that were never linked
by any anchor text, and to disambiguate mentions
that have never been observed as the linked text. For
(3) the Wikifier needs to determine when a mention
corresponds to no title, and map it to a NIL entity.
Simply training a classifier using coherency features
or topical models turns out to be insufficient, since it
has a predetermined granularity at which it can dis-
tinguish entities.
Next we provide a high-level description (Alg. 1)
of our approach to improve Wikification by leverag-
ing textual relations in these three stages.
</bodyText>
<listItem confidence="0.962813666666667">
Algorithm 1 Relational Inference for Wikification
Note: F : M —* T is the sought after mapping from
all mentions in the document to all candidate titles
in Wikipedia.
Require: Document D, Knowledge Base K con-
sisting of relation triples Q = (ta, p, tb), where
p is the relation predicate.
1: Generate initial mentions M = {mi} from D.
2: Generate candidates ti = {tki } for mention mi
and initialize candidate priors Pr(tki |mi) with
existing Wikification system, for all mi E M.
3: Instantiate non-coreference relational con-
straints and add relational candidates.
4: Instantiate coreference relational constraints
and add relational candidates.
5: Construct an ILP objective function and solve
for the arg maxΓ Pr(F).
6: return F.
</listItem>
<bodyText confidence="0.99518">
Most of our discussion addresses the relational
analysis and its impact on stage (2) and (3) above.
We will only briefly discuss improvements to the
standard candidate generation stage in Sec. 4.4
</bodyText>
<sectionHeader confidence="0.989875" genericHeader="method">
3 Problem Formulation
</sectionHeader>
<bodyText confidence="0.99983925">
We now describe how we formulate our global deci-
sion problem as an Integer Linear Program (ILP).
We use two types of boolean variables: eki is
used to denote whether we disambiguate mi to tki
</bodyText>
<equation confidence="0.9230162">
(F(mi) = tki ) or not. r(k,l)
ij is used to denote if
titles tki and tlj are chosen simultaneously, that is,
rij = ek
(k,l) i ∧elj.
</equation>
<bodyText confidence="0.988653142857143">
Our models determine two types of score for
the boolean variables above: ski = Pr(eki ) =
Pr(F(mi) = tki ), represents the initial score for the
kth candidate title being chosen for mention mi. For
a pair of titles (tki , tlj), we denote the confidence of
finding a relation between them by w(k,l)
ij . Its value
depends on the textual relation type and on how co-
herent it is with our existing knowledge.
Our goal is to find the best assignment to vari-
ables eki , such that it satisfies some legitimacy (hard)
constraints and the soft constraints dictated by the
relational constraints (via scores w(k,l)
ij ). To accom-
plish that we define our objective function as a Con-
strained Conditional Model (CCM) (Roth and Yih,
2004; Chang et al., 2012) that is used to reward or
penalize a pair of candidates tki , tlj by w(k,l)
ij when
they are chosen in the same document. Specifically,
we choose the assignment FD that optimizes:
</bodyText>
<equation confidence="0.9211104">
s.t. r(k,l)
ij E {0, 11 Integral constraints
eki E {0, 11 Integral constraints
bi Ek eki = 1 Unique solution
2r(k,l)
</equation>
<bodyText confidence="0.9752902">
ij G eki + elj Relation definition
Note that as in most NLP problems, the prob-
lem is very sparse, resulting in a tractable ILP
that is solved quickly by off-the-shelf ILP packages
(Gurobi Optimization, 2013). In our case the key
reason for the sparseness is that w(k,l)
ij = 0 for most
pairs considered, which does not require explicit in-
stantiation of r(k,l)
ij .
</bodyText>
<sectionHeader confidence="0.996478" genericHeader="method">
4 Relational Analysis
</sectionHeader>
<bodyText confidence="0.999974428571428">
The key challenge in incorporating relational anal-
ysis into the Wikification decision is to systemati-
cally construct the relational constraints (the solid
edges between candidates in Figure 1) and incorpo-
rate them into our inference framework. Two main
components are needed: first, we need to extract
high precision textual relations from the text; then,
</bodyText>
<equation confidence="0.946673666666667">
FD = arg max Y- Y- ski ek + Y-Y-w(k,lyk,l)
ij
Γ i k i,j k,l
</equation>
<page confidence="0.948228">
1789
</page>
<figure confidence="0.995992826086957">
Apposition Coreference Possessive
m1 m2 m3 m4
...ousted long time [ Yugoslav President ] [Slobodan Milošević] in October. Mr. [Milošević]&apos;s [Socialist Party] ...
search in lexical and P(title|surface) space
Slobodan Milošević
=
holds_office
f
Savo Milošević
search in lexical/relational space
Yugoslavia President
...
President of the Federal Republic of Yugoslavia
Slobodan Milošević
...
...founder_o
Socialist Party (France)
Socialist Party
...
Socialist Party of Serbia
t1
t2
...
</figure>
<figureCaption confidence="0.999847">
Figure 1: Textual relation inference framework: The goal is to maximize the objective function assigning mentions
</figureCaption>
<bodyText confidence="0.98470865625">
to titles while enforcing coherency with relations extracted from both text and an external knowledge base. Here,
searching the external KB reveals that Slobodan Miloˇsevi´c is the founder of the Socialist Party of Serbia, which can be
referred to by the surface Socialist Party; we therefore reward the output containing this pair of candidates. The same
idea applies for the relation “Slobodan Miloˇsevi´c holds office as President of the Federal Republic of Yugoslavia” as
well as to the coreference relation between two mentions of Slobodan Miloˇsevi´c.
we need to assign weights to these semantic rela-
tions. We determine the weights by combining type
and confidence of the relation extracted from text
with the confidence in relations retrieved from an ex-
ternal Knowledge Base (KB) by using the mention
pairs as a query. It is noteworthy that although con-
text window based coherency objective functions
capture many proximity relations, using these unfil-
tered relations as constraints in our experiments in-
troduced excessive amount of false-positives for the
intrinsically sparse textual relations and resulted in
severe performance hit.
In Sec. 4.1 we describe how we extract relations
from text; our goal is to reliably identify arguments
that we hypothesize to be in a relation; we show
that this is essential both to our candidate genera-
tion, our ranking and the mapping to NIL. Sec. 4.2
describes how we use an external KB to verify that
these arguments are indeed in a relation. Finally,
Sec. 4.3 shows how we generate scores for the men-
tions and relations, as coefficients in the objective
function of Sec. 3. The process is illustrated in Fig-
ure 1. Overall, our approach is an ambiguity-aware
approach that identifies, filters and scores the rele-
vant relations; this is essential due to the ambiguity,
variability and noise inherent in directly matching
surface forms to titles.
</bodyText>
<subsectionHeader confidence="0.997345">
4.1 Relation Extraction
</subsectionHeader>
<bodyText confidence="0.999951083333333">
Even though relation extraction is an open prob-
lem, analysis on the ACE2004 Relation Detection
and Characterization (RDC) dataset shows that ap-
proximately 80% of the relations are expressed
through syntactico-semantic structures (Chan and
Roth, 2011) that are easy to extract with high pre-
cision. Unlike the general ACE RDC task, we can
restrict relation arguments to be named entities and
thus leverage the large number of known relations in
existing databases (e.g. Wikipedia infoboxes). We
also consider conference relations that potentially
aid mapping different mentions to the same title.
</bodyText>
<subsubsectionHeader confidence="0.52581">
4.1.1 Syntactico-semantic Relations
</subsubsectionHeader>
<bodyText confidence="0.999620761904762">
We introduce our approach using the following
example. Consider a news article discussing Israeli
politics while briefly mentioning:
Ex. 4 An official at the [Iranian]1 [Ministry of
Defense]2 told Tehran Radio that...
A purely statistical approach would very likely map
the entity [Ministry of Defense]2 to Ministry of De-
fense (Israel) instead of Ministry of Defense and
Armed Forces Logistics (Iran) because the context is
more coherent with concepts related to Israel rather
than to Iran. Nevertheless, the pre-modifier relation
between [Iranian]1 and [Ministry of Defense]2 de-
mands the answer to be tightly related to Iran. Even
though human readers may not know the correct ti-
tle needed here, understanding the pre-modifier re-
lation allows them to easily filter through a list of
candidates and enforce constraints that are derived
jointly from the relation expressed in the text and
their background knowledge.
In our attempt to mimic this general approach, we
employ several high precision classifiers to resolve
</bodyText>
<page confidence="0.95006">
1790
</page>
<bodyText confidence="0.999508235294118">
a range of local relations that are used to retrieve
relevant background knowledge, and consequently
integrated into our inference framework. Our in-
put for relation extraction is any segment matched
by the regular expression to be mentioned in sec-
tion 4.4 in the candidate generation stage; we ana-
lyze its constituents by decomposing it into the two
largest sub-entities that have (in Wikipedia) corre-
sponding candidates. In the above example, Ira-
nian Ministry of Defense would be decomposed into
Iranian and Ministry of Defense and our relation
extraction process hypothesizes a relation between
these arguments.
Note that we do not use any full parsing since it
does not address our needs directly nor does it scale
well with the typical amount of data used in Wikifi-
cation.
</bodyText>
<subsubsectionHeader confidence="0.56505">
4.1.2 Coreference Relations
</subsubsectionHeader>
<bodyText confidence="0.999908363636364">
In addition to syntactico-semantic relations, we
could also encounter other textual relations. The fol-
lowing example illustrates the importance of under-
standing co-reference relations in Wikification:
Ex. 5 [Al Goldman]1, chief market strategist at
A.G. Edwards, said ... [Goldman]2 told us that...
There is no Wikipedia entry (or redirection) that
matches the name Al Goldman. Clearly [Goldman]2
refers to the same person and should be mapped to
the same entity (or to NIL) rather than popular en-
tities frequently referred to as Goldman, coherent
with context or not, such as Goldman Sachs. To ac-
complish that, we cluster named entities that share
tokens or are acronyms of each other when there
is no ambiguity (e.g. no other longer named en-
tity mentions containing Goldman in the document)
and use a voting algorithm (Algorithm 2) to generate
candidates locally from within the clusters. We also
experimented with using full-fledged coference sys-
tems, but found it to be time consuming while pro-
viding no significant end-to-end performance differ-
ence.
</bodyText>
<subsectionHeader confidence="0.81298">
4.1.3 Coreferent Nominal Mentions
</subsectionHeader>
<bodyText confidence="0.999925090909091">
Document level coreference also provides impor-
tant relations between named entities and nominal
mentions. Extracting these relations proved to be
very useful for classifying NIL entities, as unfamil-
iar concepts tend to be introduced with these suc-
cinct appositional nominal mentions. These descrip-
tions provide a clean “definition” of the entity, al-
lowing us to abstract the inference to a limited “noun
phrase entailment problem”. That is, it allows us to
determine whether the target mention corresponds to
a candidate title. Consider, for example, wikifying
Dorothy Byrne in: Dorothy Byrne, a state coordi-
nator for the Florida Green Party, ...
Identifying the apposition relation allows us to de-
termine that this Dorothy Byrne is not the baseline
Wikipedia title. We use the TF-IDF cosine similar-
ity between the nominal description and the lexical
context (Ratinov et al., 2011) of the candidate page,
head word attributes and entity relation (i.e. between
Dorothy Byrne and Florida Green Party) to deter-
mine whether any candidates of Dorothy Byrne can
entail the nominal mention.
</bodyText>
<subsectionHeader confidence="0.906598">
4.2 Relational Queries
</subsectionHeader>
<bodyText confidence="0.999964068965517">
Statistics based candidate generation algorithms al-
ways generate the same list of candidates given the
same surface string; even though this approach has
a competitive coverage rate, it will not work well
in some “obvious” (to human) cases; for example,
it offers very little information on highly ambigu-
ous surface strings such as “President” for which it
is even intractable to rank all the candidates. Top-
K lists which were used in previous literature suf-
fer from the same problem. Instead, we make use
of relational queries to generate a more likely set of
candidates.
Once mention pairs are generated from text us-
ing the syntactico-semantic structures and corefer-
ence, we use these to query our KB of relational
triples. We first indexed all Wikipedia links and DB-
pedia relations as unordered triples Q = (ti, p, tj),
where the arguments ti, tj are tokenized, stemmed
and lowercased for best recall. p is either a relation
predicate from the DBpedia ontology or the predi-
cate LINK indicating a hyperlink relation. Since
our baseline system has approximately 80% accu-
racy at this stage, it is reasonable to assume that at
least one of the argument mentions is correctly dis-
ambiguated. Therefore we prune the search space
by making only two queries for each mention pair
(mi, mj): q0 = (tz , mj) and q1 = (mi, t�) where
tz , t� are the strings representing the top titles cho-
sen by the current model for mentions mi, mj re-
</bodyText>
<page confidence="0.978859">
1791
</page>
<bodyText confidence="0.999324666666667">
spectively.
We also aggressively prune the search results in
a way similar to the process in Sec. 4.4, only keep-
ing the arguments that are known to be possible or
very likely candidates of the mention, based on the
ambiguity that exists in the query result.
</bodyText>
<subsectionHeader confidence="0.998686">
4.3 Relation Scoring
</subsectionHeader>
<bodyText confidence="0.999929888888889">
For the final assignment made using our objective
function (Sec. 3) we need to normalize and rescale
the output of individual components of our system as
they come from different scoring functions. We con-
sider adding new title candidates from two sources,
through the coreference module and through the
combined DBpedia and Wikipedia inter-page link
structures. Next we describe how to compute and
combine these scores.
</bodyText>
<subsectionHeader confidence="0.844035">
4.3.1 Scoring Knowledge Base Relations
</subsectionHeader>
<bodyText confidence="0.996985807692308">
Our model uses both explicit relations p =�
LINK from DBpedia and Wikipedia hyperlinks
p = LINK (implicit relation). We want to favor
relations with explicit predicate, each weighted as 0
implicit relation (we use 0 = 5 in our experiments,
noting the results are insensitive to slight changes of
this parameter).
For each query, we denote the score returned by
our KB search engine1 given query q and triple a
as Simσ,q. The relational weight wk,l
i,j between two
candidates (see Sec. 3) is determined as:
where the sum is over the top 20 KB triples, aσ is
the relation type scaling constant (0 or 1), and Z is
a normalization factor that normalizes all wk,l
i,j to the
range [0, 1].
Note that we do not check the type of the relation
against the textual relation. The key reason is that
explicit relations are not as robust, especially con-
sidering that we restrict one of the arguments in the
relation and constraining the other argument’s lexi-
cal form. Moreover, we back off to restricting the re-
lations to be between known candidates when mul-
tiple lexically matched arguments are retrieved with
high ambiguity. Additionally, most of our relations
</bodyText>
<footnote confidence="0.909861">
1http://lucene.apache.org/
</footnote>
<table confidence="0.500708">
Algorithm 2 Coreferent Candidates Voting
Require: Coreference cluster C
</table>
<listItem confidence="0.97812245">
1: Vote collector vt denotes the score for a candi-
date t, which by default is 0.
2: ti = It! i ... tni } is the set of candidates of men-
tion mi.
3: li is the token count of mi
4: for all mi E C, li &gt; 2 do
5: for all tki E ti do
6: vtk i = vtk i + sk i
7: end for
8: end for
9: Let AllSingle denote whether Vi, li = 1
10: for all mi E C where li = 1 do
11: for all tki E ti do
12: if AllSingle or vtk &gt; 0 then
i
13: vtk i = vtk i + sk i
14: end if
15: end for
16: end for
17: return v
</listItem>
<bodyText confidence="0.99914">
do not have explicit predicates in the text anyhow,
and extracting a type would add noise to our deci-
sion.
</bodyText>
<subsectionHeader confidence="0.877363">
4.3.2 Scoring Coreference Relations
</subsectionHeader>
<bodyText confidence="0.99981175">
For coreference relations, we simply use hard
constraints by assigning candidates in the same
coreference cluster a high relational weight, which
is a cheap approximation to penalizing the output
where the coreferent mentions disambiguate to dif-
ferent titles. In practice, using a weight of 10 is suf-
ficient. Another important issue here is that the cor-
rect coreferent candidate might not exist in the can-
didate list of the shorter mentions in the cluster. For
example, if a mention has the surface Richard, the
number of potential candidates is so large that any
top K list of titles will not be informative. We there-
fore ignore candidates generated from short surface
strings and give it the same candidate list as the head
mentions in its cluster. Figure 2 shows the voting al-
gorithm we use to elect the potential candidates for
the cluster.
The reason for separating the votes of longer and
shorter mentions is that shorter mentions are inher-
ently more ambiguous. Once a coreferent relation
</bodyText>
<equation confidence="0.997772">
1 Z
σ
aσSimσ,q
k,l =
w i, j
</equation>
<page confidence="0.951294">
1792
</page>
<bodyText confidence="0.997765">
is determined, longer mentions in the cluster should
dictate what this cluster should collectively refer to.
</bodyText>
<subsectionHeader confidence="0.948038">
4.4 Candidate Generation
</subsectionHeader>
<bodyText confidence="0.99626825">
(Ratinov et al., 2011) to initialize the candidates and
corresponding priors sk in our objective function.
Both the baseline system and our new system are
publicly available 4.
Beyond the algorithmic improvements, the mention
and candidate generation stage is aided by a few
systematic preprocessing improvement briefly de-
scribed below.
</bodyText>
<subsectionHeader confidence="0.781704">
4.4.1 Mention Segmentation
</subsectionHeader>
<bodyText confidence="0.999708916666667">
Since named entities may sometimes overlap with
each other, we use regular expressions to match
longer surface forms that are often incorrectly seg-
mented or ignored by NER 2 due to different an-
notation standards. For example, this will capture:
Prime Minister of the United Kingdom. The regu-
lar expression pattern we used for Step 1 in Algo-
rithm 1 simply adds mentions formed by any two
consecutive capitalized word chunks connected by
up to 2 punctuation marks, prepositions, and the to-
kens “the”, “’s” &amp; “and”. These segments are also
used as arguments for relation extraction.
</bodyText>
<subsectionHeader confidence="0.906324">
4.4.2 Lexical Search
</subsectionHeader>
<bodyText confidence="0.999963923076923">
We link certain mentions directly to their exact
matching titles in Step 3 when there is very low am-
biguity. Specifically, when no title is known for a
mention that is relatively long and fuzzily matches
the lexically retrieved title, we perform this aggres-
sive linking. The lexical similarity metrics are com-
puted using the publicly available NESim 3 package
(Do et al., 2009) with a threshold tuned on a subset
of Wikipedia redirects, and by insisting that ORG
type entities must have the same head word as the
candidate titles. We only accept the link if there ex-
ists exactly one title in the lexical searching result
after pruning.
</bodyText>
<sectionHeader confidence="0.994325" genericHeader="evaluation">
5 Experiments and Evaluation
</sectionHeader>
<bodyText confidence="0.9999694">
This section describes our experimental evaluation.
We compare our system against the top D2W sys-
tems and perform several experiments to analyze
and better understand the power of our approach.
We based our work on the GLOW system from
</bodyText>
<footnote confidence="0.991683">
2We used the IllinoisNER package http://cogcomp.
cs.illinois.edu/page/software_view/4
3http://cogcomp.cs.illinois.edu/page/
software_view/22
</footnote>
<subsectionHeader confidence="0.9877335">
5.1 Comparison with other Wikification
systems
</subsectionHeader>
<bodyText confidence="0.999958833333333">
We first evaluate on the same 4 datasets5 used in
(Ratinov et al., 2011). The AQUAINT dataset, orig-
inally introduced in (Milne and Witten, 2008), re-
sembles the Wikipedia annotation structure in that
only the first mention of a title is linked, and is
thus less sensitive to coreference capabilities. The
MSNBC dataset is from (Cucerzan, 2007) and in-
cludes many mentions that do not easily map to
Wikipedia titles due to rare surface or other idiosyn-
cratic lexicalization (Cucerzan, 2007; Ratinov et al.,
2011). Both of these datasets came from the news
domain and do not contain any annotated NIL enti-
ties. The ACE and Wikipedia datasets are both taken
from (Ratinov et al., 2011) where ACE is a subset
of ACE2004 Coreference documents annotated by
Amazon Mechanical Turkers in a similar standard as
in AQUAINT but with NIL entities. The Wikipedia
dataset is a sample of Wikipedia pages with its orig-
inal hyperlink annotation.
The evaluation methodology Bag of Titles (BOT)
F1 was used in both (Milne and Witten, 2008; Rati-
nov et al., 2011). For each document, the gold bag
of titles is evaluated against our bag of system out-
put titles requiring exact segmentation match.
</bodyText>
<table confidence="0.9989718">
Dataset
System ACE MSNBC AQUAINT Wiki
M&amp;W 72.76 68.49 83.61 80.32
R&amp;R 77.25 74.88 83.94 90.54
RI 85.30 81.20 88.88 93.09
</table>
<tableCaption confidence="0.9507345">
Table 1: Performance on Wikification datasets, BOT F1
Performance. Our system, Relational Inference (RI) ex-
hibits significant improvements over M&amp;W (Milne and
Witten, 2008) and R&amp;R (Ratinov et al., 2011).
</tableCaption>
<footnote confidence="0.997293">
4http://cogcomp.cs.illinois.edu/page/
download_view/Wikifier
5http://cogcomp.cs.illinois.edu/page/
resource_view/4
</footnote>
<page confidence="0.958581">
1793
</page>
<subsectionHeader confidence="0.998742">
5.2 Ablation study
</subsectionHeader>
<bodyText confidence="0.990923230769231">
We incrementally add various components to the
system and study their impact on the end perfor-
mance. Due to the changes in Wikipedia since the
datasets were generated, some of the pages no longer
exist; in order to minimize the interference caused
by these inconsistencies to an accurate evaluation
of various componenents, we consider all non-NIL
gold annotations that do not exist in the current
Wikipedia index as NIL entities. Additionally in the
MSNBC dataset, 127 out of 756 surface forms are
known to be non-recallable. This explains the per-
formance difference between the final rows in Tab.
1 and 2.
</bodyText>
<table confidence="0.999126333333333">
Dataset
Components ACE MSNBC AQUAINT Wiki
Baseline 80.68 83.00 83.93 91.93
+Lexical Match 83.47 84.13 88.88 93.41
+Coreference 83.40 87.88 88.88 93.09
RI 85.83 88.16 88.88 93.09
</table>
<tableCaption confidence="0.947275">
Table 2: Ablation study on Wikification datasets, BOT F1
Performance
</tableCaption>
<bodyText confidence="0.999983076923077">
The Baseline refers to the best performing configu-
ration that was used in (Ratinov et al., 2011) except
for using the current Wikipedia redirects. The Lexi-
cal Match refers to the applying solely the method-
ology introduced in Sec. 4.4. The Coreference per-
formance includes all the inference performed with-
out the KB triples, while the Relational Inference
(RI) line represents all aspects of the proposed re-
lational inference. It is clear that different datasets
show somewhat different characteristics and conse-
quently different gains from the various aspects of
our approach but that, overall, all aspects contribute
to improved performance.
</bodyText>
<subsectionHeader confidence="0.988516">
5.3 TAC Entity Linking 2011
</subsectionHeader>
<bodyText confidence="0.99970196875">
Next we evaluate our approach on the TAC English
Entity Linking Task, which provides standardized
evaluation metrics, allowing us to compare to a large
number of other systems. We did not evaluate on the
2012 English Entity Linking due to the significant
amount of ambiguous NIL entities included (Ellis et
al., 2011) in the queries and the need to cluster them,
which our D2W task definition does not address in
depth. We compare our system with the Top 3 TAC
2011 systems (LCC, MS-MLI and NUSchime) as
well as our baseline system GLOW that participated
in TAC 2011 English Entity Linking (Ratinov and
Roth, 2011) in table 3. The evaluation metric is the
official modified B3 and Micro-Average explained
in (Ji et al., 2011).
Given the TAC Knowledge Base (TKB), which is
a subset of the 2009 Wikipedia Dump, the TAC En-
tity Linking objective is to answer a named entity
query string with either a TKB entry ID or a NIL
entity ID, where the NIL entity IDs should be clus-
tered across documents.
It is important to note that we did not retrain our
system on the TAC data as the top three systems did,
even though the objective function is slightly differ-
ent. Instead, we ran our system on the TAC doc-
uments directly without any query expansion. For
the final output of each query, we simply use the
most confident candidate among all matched men-
tions. Due to the clustering requirement, we also
trivially cluster NIL entities that either are mapped
to the same out-of-KB Wikipedia URL or have the
same surface form.
</bodyText>
<table confidence="0.998763125">
Performance
System MA B3 P B3 R B3 F1
LCC 86.1 84.4 84.7 84.6
MS-MLI 86.8 84.8 83.4 84.1
RI 86.1 82.9 84.5 83.7
NUSchime 86.3 81.5 84.9 83.1
RI-0 81.4 78.6 79.1 78.8
Cogcomp 78.7 75.7 76.5 76.1
</table>
<tableCaption confidence="0.833229">
Table 3: TAC2011 Entity Linking performance. MA is
Micro-Average. LLC (Monahan et al., 2011) is the best
</tableCaption>
<bodyText confidence="0.8592773">
performing system in terms of B3 F1 while MS-MLI
(Cucerzan, 2011) is the best in terms of Micro-Average.
Cogcomp (Ratinov and Roth, 2011) is the GLOW based
system that participated in TAC 2011.RI is the complete
relational inference system described in this paper; as de-
scribed in the text, RI was not trained on the TAC data,
unlike the other top systems.
We performed two runs on the TAC2011 data to
study the effects of relational inference. The first
run, RI-0, uses the current Wikipedia index and
</bodyText>
<page confidence="0.995315">
1794
</page>
<figureCaption confidence="0.991752">
Figure 2: The RI compared with the other top 14
TAC2011 English Entity Linking systems ranked by
modified B3 F1 measure. Original figure from (Ji et al.,
2011).
</figureCaption>
<bodyText confidence="0.9999805">
redirects for lexical matching without any inference,
which scored 2.7% higher than the original GLOW
system (Cogcomp). We can regard this performance
as the new baseline that benefited from the fuzzy
lexical matching capabilities that we have added, as
well as the broader set of surface forms and redirects
from the current Wikipedia dump. In the second run,
RI, the complete relational inference described in
this paper, scored 4.9% higher than the new base-
line and sits on par with the top tier systems despite
not being trained on the given data. The LCC sys-
tem used sophisticated clustering algorithms trained
on the TAC development set (Monahan et al., 2011).
The second-ranked MS-MLI system relied on topic
modeling, external web search engine logs as well as
training on the development data (Cucerzan, 2011).
This shows the robustness of our methods as well
as the general importance of understanding textual
relations in the task of Entity Linking and Wikifica-
tion.
</bodyText>
<sectionHeader confidence="0.999919" genericHeader="related work">
6 Related Work and Discussion
</sectionHeader>
<bodyText confidence="0.999962470588235">
Earlier works on Wikification formulated the task
as a WSD problem (Bunescu and Pasca, 2006; Mi-
halcea and Csomai, 2007) and focused primarily on
training a model using local context. Later, various
global statistical approaches were proposed to em-
phasize different coherence measures between the ti-
tles of the disambiguated mentions in the same doc-
ument (Cucerzan, 2007; Milne and Witten, 2008;
Ratinov et al., 2011). Built on top of the statisti-
cal models, our work focuses on leveraging deeper
understanding of the text to more effectively and ac-
curately utilize existing knowledge.
We have demonstrated that, by incorporating tex-
tual relations and semantic knowledge as linguistic
constraints in an inference framework, it is possible
to significantly improve Wikification performance.
In particular, we have shown that our system is ca-
pable of making “intelligent” inferences that makes
use of basic text understanding and has the ability to
reason with it and verify it against relevant informa-
tion sources. This allows our Relational Inference
approach to resolve a variety of difficult examples
illustrated in the Introduction.
Our system features high modularity since the re-
lations are considered only at inference time; con-
sequently, we can use any underlying Wikification
system as long as it outputs a distribution of title
candidates for each mention.
One possibility for future work is to supply this
framework with a richer set of relations from the
text, such as verbal relations. It will also be inter-
esting to incorporate high-level typed relations and
relax the relation arguments to be general concepts
rather than only named entities.
</bodyText>
<sectionHeader confidence="0.999196" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999945">
We sincerely thank the three anonymous review-
ers for their suggestions on the paper. This ma-
terial is based on research sponsored by DARPA
under agreement number FA8750-13-2-0008, and
partly supported by the Intelligence Advanced Re-
search Projects Activity (IARPA) via Department
of Interior National Business Center contract num-
ber D11PC20155, by the Army Research Labora-
tory (ARL) under agreement W911NF-09-2-0053,
and by the Multimodal Information Access &amp; Syn-
thesis Center at UIUC, part of CCICADA, a DHS
Science and Technology Center of Excellence. The
U.S. Government is authorized to reproduce and dis-
tribute reprints for Governmental purposes notwith-
standing any copyright annotation thereon. Dis-
claimer: The views and conclusions contained
herein are those of the authors and should not be
interpreted as necessarily representing the official
</bodyText>
<figure confidence="0.9978401">
0.9
0.85
0.8
0.75
0.7
0.65
Micro−averaged Accuracy
B−cubed+ F−Measure
B−cubed+ Precision
B−cubed+ Recall
</figure>
<page confidence="0.971561">
1795
</page>
<bodyText confidence="0.865282333333333">
policies or endorsements, either expressed or im-
plied, of DARPA, IARPA, DoI/NBC, ARL, or the
U.S. Government.
</bodyText>
<sectionHeader confidence="0.983745" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999862303030303">
R. Bunescu and M. Pasca. 2006. Using encyclopedic
knowledge for named entity disambiguation. In Pro-
ceedings of the European Chapter of the ACL (EACL).
Y. Chan and D. Roth. 2011. Exploiting syntactico-
semantic structures for relation extraction. In Pro-
ceedings of the Annual Meeting of the Association for
Computational Linguistics (ACL), Portland, Oregon.
M. Chang, L. Ratinov, and D. Roth. 2012. Structured
learning with constrained conditional models. Ma-
chine Learning, 88(3):399–431, 6.
Silviu Cucerzan. 2007. Large-scale named entity disam-
biguation based on Wikipedia data. In Proceedings of
the 2007 Joint Conference of EMNLP-CoNLL, pages
708–716.
Silviu Cucerzan. 2011. Tac entity linking by perform-
ing full-document entity extraction and disambigua-
tion. In Proceedings of the Text Analysis Conference.
Q. Do, D. Roth, M. Sammons, Y. Tu, and V. Vydiswaran.
2009. Robust, light-weight approaches to compute
lexical similarity. Technical report, Computer Science
Department, University of Illinois.
Joe Ellis, Xuansong Li, Kira Griffitt, Stephanie M
Strassel, and Jonathan Wright. 2011. Linguistic re-
sources for 2012 knowledge base population evalua-
tions.
Paolo Ferragina and Ugo Scaiella. 2010. Tagme: on-the-
fly annotation of short text fragments (by wikipedia
entities). In Proceedings of the 19th ACM interna-
tional conference on Information and knowledge man-
agement, CIKM ’10, pages 1625–1628, New York,
NY, USA. ACM.
Inc. Gurobi Optimization. 2013. Gurobi optimizer refer-
ence manual.
Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2010. Overview of the tac 2010
knowledge base population track. In Third Text Anal-
ysis Conference (TAC 2010).
Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011.
Overview of the tac 2011 knowledge base population
track. In Fourth TextAnalysis Conference (TAC 2011).
R. Mihalcea and A. Csomai. 2007. Wikify!: linking doc-
uments to encyclopedic knowledge. In Proceedings
of ACM Conference on Information and Knowledge
Management (CIKM), pages 233–242.
D. Milne and I. H. Witten. 2008. Learning to link
with wikipedia. In Proceedings of ACM Conference
on Information and Knowledge Management (CIKM),
pages 509–518.
Sean Monahan, John Lehmann, Timothy Nyberg, Jesse
Plymale, and Arnold Jung. 2011. Cross-lingual cross-
document coreference with entity linking. In Proceed-
ings of the Text Analysis Conference.
L. Ratinov and D. Roth. 2011. Glow tac-kbp 2011 entity
linking system. In TAC. Text Analysis Conference, 11.
L. Ratinov and D. Roth. 2012. Learning-based multi-
sieve co-reference resolution with knowledge. In
EMNLP.
L. Ratinov, D. Roth, D. Downey, and M. Anderson.
2011. Local and global algorithms for disambiguation
to wikipedia. In ACL.
D. Roth and W. Yih. 2004. A linear programming formu-
lation for global inference in natural language tasks. In
Hwee Tou Ng and Ellen Riloff, editors, Proceedings
of the Annual Conference on Computational Natural
Language Learning (CoNLL), pages 1–8. Association
for Computational Linguistics.
</reference>
<page confidence="0.992465">
1796
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.793103">
<title confidence="0.999881">Relational Inference for Wikification</title>
<author confidence="0.999948">Xiao Cheng Dan Roth</author>
<affiliation confidence="0.9986245">Department of Computer University of Illinois at</affiliation>
<address confidence="0.921324">Urbana, IL</address>
<abstract confidence="0.993955923076923">Wikification, commonly referred to as Disambiguation to Wikipedia (D2W), is the task of identifying concepts and entities in text and disambiguating them into the most specific corresponding Wikipedia pages. Previous approaches to D2W focused on the use of local and global statistics over the given text, Wikipedia articles and its link structures, to evaluate context compatibility among a list of probable candidates. However, these methods fail (often, embarrassingly), when some level of text understanding is needed to support Wikification. In this paper we introduce a novel approach to Wikification by incorporating, along with statistical methods, richer relational analysis of the text. We provide an extensible, efficient and modular Integer Linear Programming (ILP) formulation of Wikification that incorporates the entity-relation inference problem, and show that the ability to identify relations in text helps both candidate generation and ranking Wikipedia titles considerably. Our results show significant improvements in both Wikification and the TAC Entity Linking task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Bunescu</author>
<author>M Pasca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of the European Chapter of the ACL (EACL).</booktitle>
<contexts>
<context position="33263" citStr="Bunescu and Pasca, 2006" startWordPosition="5406" endWordPosition="5409">n par with the top tier systems despite not being trained on the given data. The LCC system used sophisticated clustering algorithms trained on the TAC development set (Monahan et al., 2011). The second-ranked MS-MLI system relied on topic modeling, external web search engine logs as well as training on the development data (Cucerzan, 2011). This shows the robustness of our methods as well as the general importance of understanding textual relations in the task of Entity Linking and Wikification. 6 Related Work and Discussion Earlier works on Wikification formulated the task as a WSD problem (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007) and focused primarily on training a model using local context. Later, various global statistical approaches were proposed to emphasize different coherence measures between the titles of the disambiguated mentions in the same document (Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011). Built on top of the statistical models, our work focuses on leveraging deeper understanding of the text to more effectively and accurately utilize existing knowledge. We have demonstrated that, by incorporating textual relations and semantic knowledge as linguistic constra</context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>R. Bunescu and M. Pasca. 2006. Using encyclopedic knowledge for named entity disambiguation. In Proceedings of the European Chapter of the ACL (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Chan</author>
<author>D Roth</author>
</authors>
<title>Exploiting syntacticosemantic structures for relation extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>Portland, Oregon.</location>
<contexts>
<context position="6388" citStr="Chan and Roth, 2011" startWordPosition="968" endWordPosition="971">the Wikipedia dump we used. These examples further illustrate that, along with understanding the relation expressed in the text, we need to access background knowledge sources and to deal with variability in surface representation across the text, Wikipedia, and knowledge, in order to reliably address the Wikification problem. In this paper we focus on understanding those natural language constructs that will allow eliminating these “obvious” (to a human reader) mistakes from Wikification. In particular, we focus on resolving coreference and a collection of local syntacticosemantic relations (Chan and Roth, 2011); better understanding the relational structure of the text allows us to generate title candidates more accurately given the text, rank these candidates better and determine when a mention in text has no corresponding title in Wikipedia and should be mapped to NIL, a key problem in Wikification. Moreover, it allows us to access external knowledge based resources more effectively in order to support these decisions. We incorporate the outcome of our relational analysis, along with the associated features extracted from external sources and the “standard” wikification statistical features, into </context>
<context position="14854" citStr="Chan and Roth, 2011" startWordPosition="2346" endWordPosition="2349">entions and relations, as coefficients in the objective function of Sec. 3. The process is illustrated in Figure 1. Overall, our approach is an ambiguity-aware approach that identifies, filters and scores the relevant relations; this is essential due to the ambiguity, variability and noise inherent in directly matching surface forms to titles. 4.1 Relation Extraction Even though relation extraction is an open problem, analysis on the ACE2004 Relation Detection and Characterization (RDC) dataset shows that approximately 80% of the relations are expressed through syntactico-semantic structures (Chan and Roth, 2011) that are easy to extract with high precision. Unlike the general ACE RDC task, we can restrict relation arguments to be named entities and thus leverage the large number of known relations in existing databases (e.g. Wikipedia infoboxes). We also consider conference relations that potentially aid mapping different mentions to the same title. 4.1.1 Syntactico-semantic Relations We introduce our approach using the following example. Consider a news article discussing Israeli politics while briefly mentioning: Ex. 4 An official at the [Iranian]1 [Ministry of Defense]2 told Tehran Radio that... A</context>
</contexts>
<marker>Chan, Roth, 2011</marker>
<rawString>Y. Chan and D. Roth. 2011. Exploiting syntacticosemantic structures for relation extraction. In Proceedings of the Annual Meeting of the Association for Computational Linguistics (ACL), Portland, Oregon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chang</author>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Structured learning with constrained conditional models.</title>
<date>2012</date>
<booktitle>Machine Learning,</booktitle>
<volume>88</volume>
<issue>3</issue>
<pages>6</pages>
<contexts>
<context position="10985" citStr="Chang et al., 2012" startWordPosition="1724" endWordPosition="1727">itial score for the kth candidate title being chosen for mention mi. For a pair of titles (tki , tlj), we denote the confidence of finding a relation between them by w(k,l) ij . Its value depends on the textual relation type and on how coherent it is with our existing knowledge. Our goal is to find the best assignment to variables eki , such that it satisfies some legitimacy (hard) constraints and the soft constraints dictated by the relational constraints (via scores w(k,l) ij ). To accomplish that we define our objective function as a Constrained Conditional Model (CCM) (Roth and Yih, 2004; Chang et al., 2012) that is used to reward or penalize a pair of candidates tki , tlj by w(k,l) ij when they are chosen in the same document. Specifically, we choose the assignment FD that optimizes: s.t. r(k,l) ij E {0, 11 Integral constraints eki E {0, 11 Integral constraints bi Ek eki = 1 Unique solution 2r(k,l) ij G eki + elj Relation definition Note that as in most NLP problems, the problem is very sparse, resulting in a tractable ILP that is solved quickly by off-the-shelf ILP packages (Gurobi Optimization, 2013). In our case the key reason for the sparseness is that w(k,l) ij = 0 for most pairs considered</context>
</contexts>
<marker>Chang, Ratinov, Roth, 2012</marker>
<rawString>M. Chang, L. Ratinov, and D. Roth. 2012. Structured learning with constrained conditional models. Machine Learning, 88(3):399–431, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on Wikipedia data.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference of EMNLP-CoNLL,</booktitle>
<pages>708--716</pages>
<contexts>
<context position="1657" citStr="Cucerzan, 2007" startWordPosition="239" endWordPosition="240">blem, and show that the ability to identify relations in text helps both candidate generation and ranking Wikipedia titles considerably. Our results show significant improvements in both Wikification and the TAC Entity Linking task. 1 Introduction Wikification (D2W), the task of identifying concepts and entities in text and disambiguating them into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into a</context>
<context position="26862" citStr="Cucerzan, 2007" startWordPosition="4346" endWordPosition="4347">tter understand the power of our approach. We based our work on the GLOW system from 2We used the IllinoisNER package http://cogcomp. cs.illinois.edu/page/software_view/4 3http://cogcomp.cs.illinois.edu/page/ software_view/22 5.1 Comparison with other Wikification systems We first evaluate on the same 4 datasets5 used in (Ratinov et al., 2011). The AQUAINT dataset, originally introduced in (Milne and Witten, 2008), resembles the Wikipedia annotation structure in that only the first mention of a title is linked, and is thus less sensitive to coreference capabilities. The MSNBC dataset is from (Cucerzan, 2007) and includes many mentions that do not easily map to Wikipedia titles due to rare surface or other idiosyncratic lexicalization (Cucerzan, 2007; Ratinov et al., 2011). Both of these datasets came from the news domain and do not contain any annotated NIL entities. The ACE and Wikipedia datasets are both taken from (Ratinov et al., 2011) where ACE is a subset of ACE2004 Coreference documents annotated by Amazon Mechanical Turkers in a similar standard as in AQUAINT but with NIL entities. The Wikipedia dataset is a sample of Wikipedia pages with its original hyperlink annotation. The evaluation </context>
<context position="33541" citStr="Cucerzan, 2007" startWordPosition="5451" endWordPosition="5452">ll as training on the development data (Cucerzan, 2011). This shows the robustness of our methods as well as the general importance of understanding textual relations in the task of Entity Linking and Wikification. 6 Related Work and Discussion Earlier works on Wikification formulated the task as a WSD problem (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007) and focused primarily on training a model using local context. Later, various global statistical approaches were proposed to emphasize different coherence measures between the titles of the disambiguated mentions in the same document (Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011). Built on top of the statistical models, our work focuses on leveraging deeper understanding of the text to more effectively and accurately utilize existing knowledge. We have demonstrated that, by incorporating textual relations and semantic knowledge as linguistic constraints in an inference framework, it is possible to significantly improve Wikification performance. In particular, we have shown that our system is capable of making “intelligent” inferences that makes use of basic text understanding and has the ability to reason with it and veri</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-scale named entity disambiguation based on Wikipedia data. In Proceedings of the 2007 Joint Conference of EMNLP-CoNLL, pages 708–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Tac entity linking by performing full-document entity extraction and disambiguation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analysis Conference.</booktitle>
<contexts>
<context position="2021" citStr="Cucerzan, 2011" startWordPosition="294" endWordPosition="295">ponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into account our understanding of the text as well as background knowledge that is often needed to determine the most appropriate title. We also allow a special NIL title that captures all mentions that are outside Wikipedia. Earlier approaches treated this task as a wordsense disambiguation (WSD) problem, which was later enhanced with a certain level of global reason</context>
<context position="31561" citStr="Cucerzan, 2011" startWordPosition="5124" endWordPosition="5125"> of each query, we simply use the most confident candidate among all matched mentions. Due to the clustering requirement, we also trivially cluster NIL entities that either are mapped to the same out-of-KB Wikipedia URL or have the same surface form. Performance System MA B3 P B3 R B3 F1 LCC 86.1 84.4 84.7 84.6 MS-MLI 86.8 84.8 83.4 84.1 RI 86.1 82.9 84.5 83.7 NUSchime 86.3 81.5 84.9 83.1 RI-0 81.4 78.6 79.1 78.8 Cogcomp 78.7 75.7 76.5 76.1 Table 3: TAC2011 Entity Linking performance. MA is Micro-Average. LLC (Monahan et al., 2011) is the best performing system in terms of B3 F1 while MS-MLI (Cucerzan, 2011) is the best in terms of Micro-Average. Cogcomp (Ratinov and Roth, 2011) is the GLOW based system that participated in TAC 2011.RI is the complete relational inference system described in this paper; as described in the text, RI was not trained on the TAC data, unlike the other top systems. We performed two runs on the TAC2011 data to study the effects of relational inference. The first run, RI-0, uses the current Wikipedia index and 1794 Figure 2: The RI compared with the other top 14 TAC2011 English Entity Linking systems ranked by modified B3 F1 measure. Original figure from (Ji et al., 201</context>
<context position="32982" citStr="Cucerzan, 2011" startWordPosition="5362" endWordPosition="5363">exical matching capabilities that we have added, as well as the broader set of surface forms and redirects from the current Wikipedia dump. In the second run, RI, the complete relational inference described in this paper, scored 4.9% higher than the new baseline and sits on par with the top tier systems despite not being trained on the given data. The LCC system used sophisticated clustering algorithms trained on the TAC development set (Monahan et al., 2011). The second-ranked MS-MLI system relied on topic modeling, external web search engine logs as well as training on the development data (Cucerzan, 2011). This shows the robustness of our methods as well as the general importance of understanding textual relations in the task of Entity Linking and Wikification. 6 Related Work and Discussion Earlier works on Wikification formulated the task as a WSD problem (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007) and focused primarily on training a model using local context. Later, various global statistical approaches were proposed to emphasize different coherence measures between the titles of the disambiguated mentions in the same document (Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al.,</context>
</contexts>
<marker>Cucerzan, 2011</marker>
<rawString>Silviu Cucerzan. 2011. Tac entity linking by performing full-document entity extraction and disambiguation. In Proceedings of the Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Do</author>
<author>D Roth</author>
<author>M Sammons</author>
<author>Y Tu</author>
<author>V Vydiswaran</author>
</authors>
<title>Robust, light-weight approaches to compute lexical similarity.</title>
<date>2009</date>
<tech>Technical report,</tech>
<institution>Computer Science Department, University of Illinois.</institution>
<contexts>
<context position="25808" citStr="Do et al., 2009" startWordPosition="4183" endWordPosition="4186">ntions formed by any two consecutive capitalized word chunks connected by up to 2 punctuation marks, prepositions, and the tokens “the”, “’s” &amp; “and”. These segments are also used as arguments for relation extraction. 4.4.2 Lexical Search We link certain mentions directly to their exact matching titles in Step 3 when there is very low ambiguity. Specifically, when no title is known for a mention that is relatively long and fuzzily matches the lexically retrieved title, we perform this aggressive linking. The lexical similarity metrics are computed using the publicly available NESim 3 package (Do et al., 2009) with a threshold tuned on a subset of Wikipedia redirects, and by insisting that ORG type entities must have the same head word as the candidate titles. We only accept the link if there exists exactly one title in the lexical searching result after pruning. 5 Experiments and Evaluation This section describes our experimental evaluation. We compare our system against the top D2W systems and perform several experiments to analyze and better understand the power of our approach. We based our work on the GLOW system from 2We used the IllinoisNER package http://cogcomp. cs.illinois.edu/page/softwa</context>
</contexts>
<marker>Do, Roth, Sammons, Tu, Vydiswaran, 2009</marker>
<rawString>Q. Do, D. Roth, M. Sammons, Y. Tu, and V. Vydiswaran. 2009. Robust, light-weight approaches to compute lexical similarity. Technical report, Computer Science Department, University of Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joe Ellis</author>
<author>Xuansong Li</author>
<author>Kira Griffitt</author>
<author>Stephanie M Strassel</author>
<author>Jonathan Wright</author>
</authors>
<title>Linguistic resources for 2012 knowledge base population evaluations.</title>
<date>2011</date>
<contexts>
<context position="1987" citStr="Ellis et al., 2011" startWordPosition="286" endWordPosition="289">disambiguating them into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into account our understanding of the text as well as background knowledge that is often needed to determine the most appropriate title. We also allow a special NIL title that captures all mentions that are outside Wikipedia. Earlier approaches treated this task as a wordsense disambiguation (WSD) problem, which was later enhanced wit</context>
<context position="30001" citStr="Ellis et al., 2011" startWordPosition="4840" endWordPosition="4843">esents all aspects of the proposed relational inference. It is clear that different datasets show somewhat different characteristics and consequently different gains from the various aspects of our approach but that, overall, all aspects contribute to improved performance. 5.3 TAC Entity Linking 2011 Next we evaluate our approach on the TAC English Entity Linking Task, which provides standardized evaluation metrics, allowing us to compare to a large number of other systems. We did not evaluate on the 2012 English Entity Linking due to the significant amount of ambiguous NIL entities included (Ellis et al., 2011) in the queries and the need to cluster them, which our D2W task definition does not address in depth. We compare our system with the Top 3 TAC 2011 systems (LCC, MS-MLI and NUSchime) as well as our baseline system GLOW that participated in TAC 2011 English Entity Linking (Ratinov and Roth, 2011) in table 3. The evaluation metric is the official modified B3 and Micro-Average explained in (Ji et al., 2011). Given the TAC Knowledge Base (TKB), which is a subset of the 2009 Wikipedia Dump, the TAC Entity Linking objective is to answer a named entity query string with either a TKB entry ID or a NI</context>
</contexts>
<marker>Ellis, Li, Griffitt, Strassel, Wright, 2011</marker>
<rawString>Joe Ellis, Xuansong Li, Kira Griffitt, Stephanie M Strassel, and Jonathan Wright. 2011. Linguistic resources for 2012 knowledge base population evaluations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Ferragina</author>
<author>Ugo Scaiella</author>
</authors>
<title>Tagme: on-thefly annotation of short text fragments (by wikipedia entities).</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM ’10,</booktitle>
<pages>1625--1628</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1738" citStr="Ferragina and Scaiella, 2010" startWordPosition="249" endWordPosition="252"> both candidate generation and ranking Wikipedia titles considerably. Our results show significant improvements in both Wikification and the TAC Entity Linking task. 1 Introduction Wikification (D2W), the task of identifying concepts and entities in text and disambiguating them into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into account our understanding of the text as well as background knowledge that is ofte</context>
</contexts>
<marker>Ferragina, Scaiella, 2010</marker>
<rawString>Paolo Ferragina and Ugo Scaiella. 2010. Tagme: on-thefly annotation of short text fragments (by wikipedia entities). In Proceedings of the 19th ACM international conference on Information and knowledge management, CIKM ’10, pages 1625–1628, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gurobi Optimization</author>
</authors>
<date>2013</date>
<note>Gurobi optimizer reference manual.</note>
<contexts>
<context position="11490" citStr="Optimization, 2013" startWordPosition="1817" endWordPosition="1818">we define our objective function as a Constrained Conditional Model (CCM) (Roth and Yih, 2004; Chang et al., 2012) that is used to reward or penalize a pair of candidates tki , tlj by w(k,l) ij when they are chosen in the same document. Specifically, we choose the assignment FD that optimizes: s.t. r(k,l) ij E {0, 11 Integral constraints eki E {0, 11 Integral constraints bi Ek eki = 1 Unique solution 2r(k,l) ij G eki + elj Relation definition Note that as in most NLP problems, the problem is very sparse, resulting in a tractable ILP that is solved quickly by off-the-shelf ILP packages (Gurobi Optimization, 2013). In our case the key reason for the sparseness is that w(k,l) ij = 0 for most pairs considered, which does not require explicit instantiation of r(k,l) ij . 4 Relational Analysis The key challenge in incorporating relational analysis into the Wikification decision is to systematically construct the relational constraints (the solid edges between candidates in Figure 1) and incorporate them into our inference framework. Two main components are needed: first, we need to extract high precision textual relations from the text; then, FD = arg max Y- Y- ski ek + Y-Y-w(k,lyk,l) ij Γ i k i,j k,l 1789</context>
</contexts>
<marker>Optimization, 2013</marker>
<rawString>Inc. Gurobi Optimization. 2013. Gurobi optimizer reference manual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
<author>Kira Griffitt</author>
<author>Joe Ellis</author>
</authors>
<title>Overview of the tac 2010 knowledge base population track.</title>
<date>2010</date>
<booktitle>In Third Text Analysis Conference (TAC</booktitle>
<contexts>
<context position="2004" citStr="Ji et al., 2010" startWordPosition="290" endWordPosition="293">into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into account our understanding of the text as well as background knowledge that is often needed to determine the most appropriate title. We also allow a special NIL title that captures all mentions that are outside Wikipedia. Earlier approaches treated this task as a wordsense disambiguation (WSD) problem, which was later enhanced with a certain level</context>
</contexts>
<marker>Ji, Grishman, Dang, Griffitt, Ellis, 2010</marker>
<rawString>Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Griffitt, and Joe Ellis. 2010. Overview of the tac 2010 knowledge base population track. In Third Text Analysis Conference (TAC 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
</authors>
<title>Overview of the tac 2011 knowledge base population track.</title>
<date>2011</date>
<booktitle>In Fourth TextAnalysis Conference (TAC</booktitle>
<contexts>
<context position="30409" citStr="Ji et al., 2011" startWordPosition="4912" endWordPosition="4915">metrics, allowing us to compare to a large number of other systems. We did not evaluate on the 2012 English Entity Linking due to the significant amount of ambiguous NIL entities included (Ellis et al., 2011) in the queries and the need to cluster them, which our D2W task definition does not address in depth. We compare our system with the Top 3 TAC 2011 systems (LCC, MS-MLI and NUSchime) as well as our baseline system GLOW that participated in TAC 2011 English Entity Linking (Ratinov and Roth, 2011) in table 3. The evaluation metric is the official modified B3 and Micro-Average explained in (Ji et al., 2011). Given the TAC Knowledge Base (TKB), which is a subset of the 2009 Wikipedia Dump, the TAC Entity Linking objective is to answer a named entity query string with either a TKB entry ID or a NIL entity ID, where the NIL entity IDs should be clustered across documents. It is important to note that we did not retrain our system on the TAC data as the top three systems did, even though the objective function is slightly different. Instead, we ran our system on the TAC documents directly without any query expansion. For the final output of each query, we simply use the most confident candidate amon</context>
<context position="32163" citStr="Ji et al., 2011" startWordPosition="5227" endWordPosition="5230">ucerzan, 2011) is the best in terms of Micro-Average. Cogcomp (Ratinov and Roth, 2011) is the GLOW based system that participated in TAC 2011.RI is the complete relational inference system described in this paper; as described in the text, RI was not trained on the TAC data, unlike the other top systems. We performed two runs on the TAC2011 data to study the effects of relational inference. The first run, RI-0, uses the current Wikipedia index and 1794 Figure 2: The RI compared with the other top 14 TAC2011 English Entity Linking systems ranked by modified B3 F1 measure. Original figure from (Ji et al., 2011). redirects for lexical matching without any inference, which scored 2.7% higher than the original GLOW system (Cogcomp). We can regard this performance as the new baseline that benefited from the fuzzy lexical matching capabilities that we have added, as well as the broader set of surface forms and redirects from the current Wikipedia dump. In the second run, RI, the complete relational inference described in this paper, scored 4.9% higher than the new baseline and sits on par with the top tier systems despite not being trained on the given data. The LCC system used sophisticated clustering a</context>
</contexts>
<marker>Ji, Grishman, Dang, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, and Hoa Trang Dang. 2011. Overview of the tac 2011 knowledge base population track. In Fourth TextAnalysis Conference (TAC 2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>A Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of ACM Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>233--242</pages>
<contexts>
<context position="1684" citStr="Mihalcea and Csomai, 2007" startWordPosition="241" endWordPosition="244">hat the ability to identify relations in text helps both candidate generation and ranking Wikipedia titles considerably. Our results show significant improvements in both Wikification and the TAC Entity Linking task. 1 Introduction Wikification (D2W), the task of identifying concepts and entities in text and disambiguating them into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into account our understanding of</context>
<context position="33291" citStr="Mihalcea and Csomai, 2007" startWordPosition="5410" endWordPosition="5414">ystems despite not being trained on the given data. The LCC system used sophisticated clustering algorithms trained on the TAC development set (Monahan et al., 2011). The second-ranked MS-MLI system relied on topic modeling, external web search engine logs as well as training on the development data (Cucerzan, 2011). This shows the robustness of our methods as well as the general importance of understanding textual relations in the task of Entity Linking and Wikification. 6 Related Work and Discussion Earlier works on Wikification formulated the task as a WSD problem (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007) and focused primarily on training a model using local context. Later, various global statistical approaches were proposed to emphasize different coherence measures between the titles of the disambiguated mentions in the same document (Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011). Built on top of the statistical models, our work focuses on leveraging deeper understanding of the text to more effectively and accurately utilize existing knowledge. We have demonstrated that, by incorporating textual relations and semantic knowledge as linguistic constraints in an inference framewo</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>R. Mihalcea and A. Csomai. 2007. Wikify!: linking documents to encyclopedic knowledge. In Proceedings of ACM Conference on Information and Knowledge Management (CIKM), pages 233–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Milne</author>
<author>I H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of ACM Conference on Information and Knowledge Management (CIKM),</booktitle>
<pages>509--518</pages>
<contexts>
<context position="1708" citStr="Milne and Witten, 2008" startWordPosition="245" endWordPosition="248"> relations in text helps both candidate generation and ranking Wikipedia titles considerably. Our results show significant improvements in both Wikification and the TAC Entity Linking task. 1 Introduction Wikification (D2W), the task of identifying concepts and entities in text and disambiguating them into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into account our understanding of the text as well as bac</context>
<context position="26664" citStr="Milne and Witten, 2008" startWordPosition="4312" endWordPosition="4315">ing result after pruning. 5 Experiments and Evaluation This section describes our experimental evaluation. We compare our system against the top D2W systems and perform several experiments to analyze and better understand the power of our approach. We based our work on the GLOW system from 2We used the IllinoisNER package http://cogcomp. cs.illinois.edu/page/software_view/4 3http://cogcomp.cs.illinois.edu/page/ software_view/22 5.1 Comparison with other Wikification systems We first evaluate on the same 4 datasets5 used in (Ratinov et al., 2011). The AQUAINT dataset, originally introduced in (Milne and Witten, 2008), resembles the Wikipedia annotation structure in that only the first mention of a title is linked, and is thus less sensitive to coreference capabilities. The MSNBC dataset is from (Cucerzan, 2007) and includes many mentions that do not easily map to Wikipedia titles due to rare surface or other idiosyncratic lexicalization (Cucerzan, 2007; Ratinov et al., 2011). Both of these datasets came from the news domain and do not contain any annotated NIL entities. The ACE and Wikipedia datasets are both taken from (Ratinov et al., 2011) where ACE is a subset of ACE2004 Coreference documents annotate</context>
<context position="27986" citStr="Milne and Witten, 2008" startWordPosition="4531" endWordPosition="4534">edia dataset is a sample of Wikipedia pages with its original hyperlink annotation. The evaluation methodology Bag of Titles (BOT) F1 was used in both (Milne and Witten, 2008; Ratinov et al., 2011). For each document, the gold bag of titles is evaluated against our bag of system output titles requiring exact segmentation match. Dataset System ACE MSNBC AQUAINT Wiki M&amp;W 72.76 68.49 83.61 80.32 R&amp;R 77.25 74.88 83.94 90.54 RI 85.30 81.20 88.88 93.09 Table 1: Performance on Wikification datasets, BOT F1 Performance. Our system, Relational Inference (RI) exhibits significant improvements over M&amp;W (Milne and Witten, 2008) and R&amp;R (Ratinov et al., 2011). 4http://cogcomp.cs.illinois.edu/page/ download_view/Wikifier 5http://cogcomp.cs.illinois.edu/page/ resource_view/4 1793 5.2 Ablation study We incrementally add various components to the system and study their impact on the end performance. Due to the changes in Wikipedia since the datasets were generated, some of the pages no longer exist; in order to minimize the interference caused by these inconsistencies to an accurate evaluation of various componenents, we consider all non-NIL gold annotations that do not exist in the current Wikipedia index as NIL entitie</context>
<context position="33565" citStr="Milne and Witten, 2008" startWordPosition="5453" endWordPosition="5456">n the development data (Cucerzan, 2011). This shows the robustness of our methods as well as the general importance of understanding textual relations in the task of Entity Linking and Wikification. 6 Related Work and Discussion Earlier works on Wikification formulated the task as a WSD problem (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007) and focused primarily on training a model using local context. Later, various global statistical approaches were proposed to emphasize different coherence measures between the titles of the disambiguated mentions in the same document (Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011). Built on top of the statistical models, our work focuses on leveraging deeper understanding of the text to more effectively and accurately utilize existing knowledge. We have demonstrated that, by incorporating textual relations and semantic knowledge as linguistic constraints in an inference framework, it is possible to significantly improve Wikification performance. In particular, we have shown that our system is capable of making “intelligent” inferences that makes use of basic text understanding and has the ability to reason with it and verify it against relevant i</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>D. Milne and I. H. Witten. 2008. Learning to link with wikipedia. In Proceedings of ACM Conference on Information and Knowledge Management (CIKM), pages 509–518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Monahan</author>
<author>John Lehmann</author>
<author>Timothy Nyberg</author>
<author>Jesse Plymale</author>
<author>Arnold Jung</author>
</authors>
<title>Cross-lingual crossdocument coreference with entity linking.</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analysis Conference.</booktitle>
<contexts>
<context position="31483" citStr="Monahan et al., 2011" startWordPosition="5108" endWordPosition="5111">stem on the TAC documents directly without any query expansion. For the final output of each query, we simply use the most confident candidate among all matched mentions. Due to the clustering requirement, we also trivially cluster NIL entities that either are mapped to the same out-of-KB Wikipedia URL or have the same surface form. Performance System MA B3 P B3 R B3 F1 LCC 86.1 84.4 84.7 84.6 MS-MLI 86.8 84.8 83.4 84.1 RI 86.1 82.9 84.5 83.7 NUSchime 86.3 81.5 84.9 83.1 RI-0 81.4 78.6 79.1 78.8 Cogcomp 78.7 75.7 76.5 76.1 Table 3: TAC2011 Entity Linking performance. MA is Micro-Average. LLC (Monahan et al., 2011) is the best performing system in terms of B3 F1 while MS-MLI (Cucerzan, 2011) is the best in terms of Micro-Average. Cogcomp (Ratinov and Roth, 2011) is the GLOW based system that participated in TAC 2011.RI is the complete relational inference system described in this paper; as described in the text, RI was not trained on the TAC data, unlike the other top systems. We performed two runs on the TAC2011 data to study the effects of relational inference. The first run, RI-0, uses the current Wikipedia index and 1794 Figure 2: The RI compared with the other top 14 TAC2011 English Entity Linking </context>
<context position="32830" citStr="Monahan et al., 2011" startWordPosition="5337" endWordPosition="5340">nference, which scored 2.7% higher than the original GLOW system (Cogcomp). We can regard this performance as the new baseline that benefited from the fuzzy lexical matching capabilities that we have added, as well as the broader set of surface forms and redirects from the current Wikipedia dump. In the second run, RI, the complete relational inference described in this paper, scored 4.9% higher than the new baseline and sits on par with the top tier systems despite not being trained on the given data. The LCC system used sophisticated clustering algorithms trained on the TAC development set (Monahan et al., 2011). The second-ranked MS-MLI system relied on topic modeling, external web search engine logs as well as training on the development data (Cucerzan, 2011). This shows the robustness of our methods as well as the general importance of understanding textual relations in the task of Entity Linking and Wikification. 6 Related Work and Discussion Earlier works on Wikification formulated the task as a WSD problem (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007) and focused primarily on training a model using local context. Later, various global statistical approaches were proposed to emphasize dif</context>
</contexts>
<marker>Monahan, Lehmann, Nyberg, Plymale, Jung, 2011</marker>
<rawString>Sean Monahan, John Lehmann, Timothy Nyberg, Jesse Plymale, and Arnold Jung. 2011. Cross-lingual crossdocument coreference with entity linking. In Proceedings of the Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Glow tac-kbp 2011 entity linking system.</title>
<date>2011</date>
<booktitle>In TAC. Text Analysis Conference,</booktitle>
<volume>11</volume>
<contexts>
<context position="30298" citStr="Ratinov and Roth, 2011" startWordPosition="4893" endWordPosition="4896">ing 2011 Next we evaluate our approach on the TAC English Entity Linking Task, which provides standardized evaluation metrics, allowing us to compare to a large number of other systems. We did not evaluate on the 2012 English Entity Linking due to the significant amount of ambiguous NIL entities included (Ellis et al., 2011) in the queries and the need to cluster them, which our D2W task definition does not address in depth. We compare our system with the Top 3 TAC 2011 systems (LCC, MS-MLI and NUSchime) as well as our baseline system GLOW that participated in TAC 2011 English Entity Linking (Ratinov and Roth, 2011) in table 3. The evaluation metric is the official modified B3 and Micro-Average explained in (Ji et al., 2011). Given the TAC Knowledge Base (TKB), which is a subset of the 2009 Wikipedia Dump, the TAC Entity Linking objective is to answer a named entity query string with either a TKB entry ID or a NIL entity ID, where the NIL entity IDs should be clustered across documents. It is important to note that we did not retrain our system on the TAC data as the top three systems did, even though the objective function is slightly different. Instead, we ran our system on the TAC documents directly w</context>
<context position="31633" citStr="Ratinov and Roth, 2011" startWordPosition="5134" endWordPosition="5137"> all matched mentions. Due to the clustering requirement, we also trivially cluster NIL entities that either are mapped to the same out-of-KB Wikipedia URL or have the same surface form. Performance System MA B3 P B3 R B3 F1 LCC 86.1 84.4 84.7 84.6 MS-MLI 86.8 84.8 83.4 84.1 RI 86.1 82.9 84.5 83.7 NUSchime 86.3 81.5 84.9 83.1 RI-0 81.4 78.6 79.1 78.8 Cogcomp 78.7 75.7 76.5 76.1 Table 3: TAC2011 Entity Linking performance. MA is Micro-Average. LLC (Monahan et al., 2011) is the best performing system in terms of B3 F1 while MS-MLI (Cucerzan, 2011) is the best in terms of Micro-Average. Cogcomp (Ratinov and Roth, 2011) is the GLOW based system that participated in TAC 2011.RI is the complete relational inference system described in this paper; as described in the text, RI was not trained on the TAC data, unlike the other top systems. We performed two runs on the TAC2011 data to study the effects of relational inference. The first run, RI-0, uses the current Wikipedia index and 1794 Figure 2: The RI compared with the other top 14 TAC2011 English Entity Linking systems ranked by modified B3 F1 measure. Original figure from (Ji et al., 2011). redirects for lexical matching without any inference, which scored 2</context>
</contexts>
<marker>Ratinov, Roth, 2011</marker>
<rawString>L. Ratinov and D. Roth. 2011. Glow tac-kbp 2011 entity linking system. In TAC. Text Analysis Conference, 11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Learning-based multisieve co-reference resolution with knowledge.</title>
<date>2012</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1924" citStr="Ratinov and Roth, 2012" startWordPosition="276" endWordPosition="279">on (D2W), the task of identifying concepts and entities in text and disambiguating them into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into account our understanding of the text as well as background knowledge that is often needed to determine the most appropriate title. We also allow a special NIL title that captures all mentions that are outside Wikipedia. Earlier approaches treated this task as a words</context>
</contexts>
<marker>Ratinov, Roth, 2012</marker>
<rawString>L. Ratinov and D. Roth. 2012. Learning-based multisieve co-reference resolution with knowledge. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ratinov</author>
<author>D Roth</author>
<author>D Downey</author>
<author>M Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1761" citStr="Ratinov et al., 2011" startWordPosition="253" endWordPosition="256"> ranking Wikipedia titles considerably. Our results show significant improvements in both Wikification and the TAC Entity Linking task. 1 Introduction Wikification (D2W), the task of identifying concepts and entities in text and disambiguating them into their corresponding Wikipedia page, is an important step toward supporting deeper textual understanding, by augmenting the ability to ground text in existing knowledge and facilitating knowledge expansion. D2W has been studied extensively recently (Cucerzan, 2007; Mihalcea and Csomai, 2007; Milne and Witten, 2008; Ferragina and Scaiella, 2010; Ratinov et al., 2011) and has already found broad applications in NLP, Information Extraction, and Knowledge Acquisition from text, from coreference resolution (Ratinov and Roth, 2012) to entity linking and knowledge population (Ellis et al., 2011; Ji et al., 2010; Cucerzan, 2011). Given a document D containing a set of concept and entity mentions M ( referred to later as surface), the goal of Wikification is to find the most accurate mapping from mentions to Wikipedia titles T; this mapping needs to take into account our understanding of the text as well as background knowledge that is often needed to determine t</context>
<context position="2994" citStr="Ratinov et al., 2011" startWordPosition="449" endWordPosition="452">opriate title. We also allow a special NIL title that captures all mentions that are outside Wikipedia. Earlier approaches treated this task as a wordsense disambiguation (WSD) problem, which was later enhanced with a certain level of global reasoning, but essentially all approaches focused on generic statistical features in order to achieve robust disambiguation. It was shown that by disambiguating to the most likely title for every surface, independently maximizing the conditional probability Pr(title|surface), we already achieve a very competitive baseline on several Wikification datasets (Ratinov et al., 2011). This strong statistical baseline makes use of the relatively comprehensive coverage of the existing Wikipedia links from surface strings to Wikipedia titles. Although more involved statistical features are required in order to make substantial improvements, global features such as context TF-IDF, better string similarity, etc., statistics-based Wikification systems give a fairly coherent set of disambiguation when sufficient context is available. Consider the following example: Earth’s biosphere 1787 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, page</context>
<context position="19034" citStr="Ratinov et al., 2011" startWordPosition="3001" endWordPosition="3004">ional nominal mentions. These descriptions provide a clean “definition” of the entity, allowing us to abstract the inference to a limited “noun phrase entailment problem”. That is, it allows us to determine whether the target mention corresponds to a candidate title. Consider, for example, wikifying Dorothy Byrne in: Dorothy Byrne, a state coordinator for the Florida Green Party, ... Identifying the apposition relation allows us to determine that this Dorothy Byrne is not the baseline Wikipedia title. We use the TF-IDF cosine similarity between the nominal description and the lexical context (Ratinov et al., 2011) of the candidate page, head word attributes and entity relation (i.e. between Dorothy Byrne and Florida Green Party) to determine whether any candidates of Dorothy Byrne can entail the nominal mention. 4.2 Relational Queries Statistics based candidate generation algorithms always generate the same list of candidates given the same surface string; even though this approach has a competitive coverage rate, it will not work well in some “obvious” (to human) cases; for example, it offers very little information on highly ambiguous surface strings such as “President” for which it is even intractab</context>
<context position="24488" citStr="Ratinov et al., 2011" startWordPosition="3970" endWordPosition="3973"> top K list of titles will not be informative. We therefore ignore candidates generated from short surface strings and give it the same candidate list as the head mentions in its cluster. Figure 2 shows the voting algorithm we use to elect the potential candidates for the cluster. The reason for separating the votes of longer and shorter mentions is that shorter mentions are inherently more ambiguous. Once a coreferent relation 1 Z σ aσSimσ,q k,l = w i, j 1792 is determined, longer mentions in the cluster should dictate what this cluster should collectively refer to. 4.4 Candidate Generation (Ratinov et al., 2011) to initialize the candidates and corresponding priors sk in our objective function. Both the baseline system and our new system are publicly available 4. Beyond the algorithmic improvements, the mention and candidate generation stage is aided by a few systematic preprocessing improvement briefly described below. 4.4.1 Mention Segmentation Since named entities may sometimes overlap with each other, we use regular expressions to match longer surface forms that are often incorrectly segmented or ignored by NER 2 due to different annotation standards. For example, this will capture: Prime Ministe</context>
<context position="26592" citStr="Ratinov et al., 2011" startWordPosition="4301" endWordPosition="4304">ccept the link if there exists exactly one title in the lexical searching result after pruning. 5 Experiments and Evaluation This section describes our experimental evaluation. We compare our system against the top D2W systems and perform several experiments to analyze and better understand the power of our approach. We based our work on the GLOW system from 2We used the IllinoisNER package http://cogcomp. cs.illinois.edu/page/software_view/4 3http://cogcomp.cs.illinois.edu/page/ software_view/22 5.1 Comparison with other Wikification systems We first evaluate on the same 4 datasets5 used in (Ratinov et al., 2011). The AQUAINT dataset, originally introduced in (Milne and Witten, 2008), resembles the Wikipedia annotation structure in that only the first mention of a title is linked, and is thus less sensitive to coreference capabilities. The MSNBC dataset is from (Cucerzan, 2007) and includes many mentions that do not easily map to Wikipedia titles due to rare surface or other idiosyncratic lexicalization (Cucerzan, 2007; Ratinov et al., 2011). Both of these datasets came from the news domain and do not contain any annotated NIL entities. The ACE and Wikipedia datasets are both taken from (Ratinov et al</context>
<context position="28017" citStr="Ratinov et al., 2011" startWordPosition="4537" endWordPosition="4540">edia pages with its original hyperlink annotation. The evaluation methodology Bag of Titles (BOT) F1 was used in both (Milne and Witten, 2008; Ratinov et al., 2011). For each document, the gold bag of titles is evaluated against our bag of system output titles requiring exact segmentation match. Dataset System ACE MSNBC AQUAINT Wiki M&amp;W 72.76 68.49 83.61 80.32 R&amp;R 77.25 74.88 83.94 90.54 RI 85.30 81.20 88.88 93.09 Table 1: Performance on Wikification datasets, BOT F1 Performance. Our system, Relational Inference (RI) exhibits significant improvements over M&amp;W (Milne and Witten, 2008) and R&amp;R (Ratinov et al., 2011). 4http://cogcomp.cs.illinois.edu/page/ download_view/Wikifier 5http://cogcomp.cs.illinois.edu/page/ resource_view/4 1793 5.2 Ablation study We incrementally add various components to the system and study their impact on the end performance. Due to the changes in Wikipedia since the datasets were generated, some of the pages no longer exist; in order to minimize the interference caused by these inconsistencies to an accurate evaluation of various componenents, we consider all non-NIL gold annotations that do not exist in the current Wikipedia index as NIL entities. Additionally in the MSNBC da</context>
<context position="33588" citStr="Ratinov et al., 2011" startWordPosition="5457" endWordPosition="5460">Cucerzan, 2011). This shows the robustness of our methods as well as the general importance of understanding textual relations in the task of Entity Linking and Wikification. 6 Related Work and Discussion Earlier works on Wikification formulated the task as a WSD problem (Bunescu and Pasca, 2006; Mihalcea and Csomai, 2007) and focused primarily on training a model using local context. Later, various global statistical approaches were proposed to emphasize different coherence measures between the titles of the disambiguated mentions in the same document (Cucerzan, 2007; Milne and Witten, 2008; Ratinov et al., 2011). Built on top of the statistical models, our work focuses on leveraging deeper understanding of the text to more effectively and accurately utilize existing knowledge. We have demonstrated that, by incorporating textual relations and semantic knowledge as linguistic constraints in an inference framework, it is possible to significantly improve Wikification performance. In particular, we have shown that our system is capable of making “intelligent” inferences that makes use of basic text understanding and has the ability to reason with it and verify it against relevant information sources. Thi</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>L. Ratinov, D. Roth, D. Downey, and M. Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Roth</author>
<author>W Yih</author>
</authors>
<title>A linear programming formulation for global inference in natural language tasks.</title>
<date>2004</date>
<booktitle>In Hwee Tou Ng and Ellen Riloff, editors, Proceedings of the Annual Conference on Computational Natural Language Learning (CoNLL),</booktitle>
<pages>1--8</pages>
<publisher>Association for Computational Linguistics.</publisher>
<contexts>
<context position="10964" citStr="Roth and Yih, 2004" startWordPosition="1720" endWordPosition="1723">), represents the initial score for the kth candidate title being chosen for mention mi. For a pair of titles (tki , tlj), we denote the confidence of finding a relation between them by w(k,l) ij . Its value depends on the textual relation type and on how coherent it is with our existing knowledge. Our goal is to find the best assignment to variables eki , such that it satisfies some legitimacy (hard) constraints and the soft constraints dictated by the relational constraints (via scores w(k,l) ij ). To accomplish that we define our objective function as a Constrained Conditional Model (CCM) (Roth and Yih, 2004; Chang et al., 2012) that is used to reward or penalize a pair of candidates tki , tlj by w(k,l) ij when they are chosen in the same document. Specifically, we choose the assignment FD that optimizes: s.t. r(k,l) ij E {0, 11 Integral constraints eki E {0, 11 Integral constraints bi Ek eki = 1 Unique solution 2r(k,l) ij G eki + elj Relation definition Note that as in most NLP problems, the problem is very sparse, resulting in a tractable ILP that is solved quickly by off-the-shelf ILP packages (Gurobi Optimization, 2013). In our case the key reason for the sparseness is that w(k,l) ij = 0 for </context>
</contexts>
<marker>Roth, Yih, 2004</marker>
<rawString>D. Roth and W. Yih. 2004. A linear programming formulation for global inference in natural language tasks. In Hwee Tou Ng and Ellen Riloff, editors, Proceedings of the Annual Conference on Computational Natural Language Learning (CoNLL), pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>