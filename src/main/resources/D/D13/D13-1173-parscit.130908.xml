<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000886">
<title confidence="0.9974135">
Dependency-Based Decipherment for Resource-Limited Machine
Translation
</title>
<author confidence="0.99711">
Qing Dou and Kevin Knight
</author>
<affiliation confidence="0.992931333333333">
Information Sciences Institute
Department of Computer Science
University of Southern California
</affiliation>
<email confidence="0.99939">
{qdou,knight}@isi.edu
</email>
<sectionHeader confidence="0.99667" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999617454545454">
We introduce dependency relations into deci-
phering foreign languages and show that de-
pendency relations help improve the state-of-
the-art deciphering accuracy by over 500%.
We learn a translation lexicon from large
amounts of genuinely non parallel data with
decipherment to improve a phrase-based ma-
chine translation system trained with limited
parallel data. In experiments, we observe
BLEU gains of 1.2 to 1.8 across three different
test sets.
</bodyText>
<sectionHeader confidence="0.99878" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998525">
State-of-the-art machine translation (MT) systems
apply statistical techniques to learn translation rules
from large amounts of parallel data. However, par-
allel data is limited for many language pairs and do-
mains.
In general, it is easier to obtain non parallel data.
The ability to build a machine translation system
using monolingual data could alleviate problems
caused by insufficient parallel data. Towards build-
ing a machine translation system without a paral-
lel corpus, Klementiev et al. (2012) use non paral-
lel data to estimate parameters for a large scale MT
system. Other work tries to learn full MT systems
using only non parallel data through decipherment
(Ravi and Knight, 2011; Ravi, 2013). However, the
performance of such systems is poor compared with
those trained with parallel data.
Given that we often have some parallel data,
it is more practical to improve a translation sys-
tem trained on parallel corpora with non parallel
</bodyText>
<figureCaption confidence="0.9969475">
Figure 1: Improving machine translation with deci-
pherment (Grey boxes represent new data and process).
Mono: monolingual; LM: language model; LEX: trans-
lation lexicon; TM: translation model.
</figureCaption>
<bodyText confidence="0.997449833333333">
data. Dou and Knight (2012) successfully apply
decipherment to learn a domain specific translation
lexicon from monolingual data to improve out-of-
domain machine translation. Although their ap-
proach works well for Spanish/French, they do not
show whether their approach works for other lan-
guage pairs. Moreover, the non parallel data used in
their experiments is created from a parallel corpus.
Such highly comparable data is difficult to obtain in
reality.
In this work, we improve previous work by Dou
and Knight (2012) using genuinely non parallel data,
</bodyText>
<page confidence="0.930379">
1668
</page>
<note confidence="0.733883">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1668–1676,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999891333333333">
and propose a framework to improve a machine
translation system trained with a small amount of
parallel data. As shown in Figure 1, we use a lexi-
con learned from decipherment to improve transla-
tions of both observed and out-of-vocabulary (OOV)
words. The main contributions of this work are:
</bodyText>
<listItem confidence="0.931526153846154">
• We extract bigrams based on dependency re-
lations for decipherment, which improves the
state-of-the-art deciphering accuracy by over
500%.
• We demonstrate how to improve translations
of words observed in parallel data by us-
ing a translation lexicon obtained from large
amounts of non parallel data.
• We show that decipherment is able to find cor-
rect translations for OOV words.
• We use a translation lexicon learned by de-
ciphering large amounts of non parallel data
to improve a phrase-based MT system trained
</listItem>
<bodyText confidence="0.953096666666667">
with limited amounts of parallel data. In ex-
periments, we observe 1.2 to 1.8 BLEU gains
across three different test sets.
</bodyText>
<sectionHeader confidence="0.996055" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999524636363636">
Motivated by the idea that a translation lexicon in-
duced from non parallel data can be applied to
MT, a variety of prior research has tried to build a
translation lexicon from non parallel or compara-
ble data (Rapp, 1995; Fung and Yee, 1998; Koehn
and Knight, 2002; Haghighi et al., 2008; Garera et
al., 2009; Bergsma and Van Durme, 2011; Daum´e
and Jagarlamudi, 2011; Irvine and Callison-Burch,
2013b; Irvine and Callison-Burch, 2013a). Al-
though previous work is able to build a translation
lexicon without parallel data, little has used the lex-
icon to improve machine translation.
There has been increasing interest in learning
translation lexicons from non parallel data with de-
cipherment techniques (Ravi and Knight, 2011; Dou
and Knight, 2012; Nuhn et al., 2012). Decipher-
ment views one language as a cipher for another and
learns a translation lexicon that produces a good de-
cipherment.
In an effort to build a MT system without a paral-
lel corpus, Ravi and Knight (2011) view Spanish as a
cipher for English and apply Bayesian learning to di-
rectly decipher Spanish into English. Unfortunately,
their approach can only work on small data with lim-
ited vocabulary. Dou and Knight (2012) propose two
techniques to make Bayesian decipherment scalable.
First, unlike Ravi and Knight (2011), who deci-
pher whole sentences, Dou and Knight (2012) deci-
pher bigrams. Reducing a ciphertext to a set of bi-
grams with counts significantly reduces the amount
of cipher data. According to Dou and Knight (2012),
a ciphertext bigram F is generated through the fol-
lowing generative story:
</bodyText>
<listItem confidence="0.998384166666667">
• Generate a sequence of two plaintext tokens
e1e2 with probability P(e1e2) given by a lan-
guage model built from large numbers of plain-
text bigrams.
• Substitute e1 with f1 and e2 with f2 with prob-
ability P(f1|e1) · P(f2|e2).
</listItem>
<bodyText confidence="0.925349">
The probability of any cipher bigram F is:
</bodyText>
<equation confidence="0.989189333333333">
2
P(F) = E P(e1e2) H P(fi|ei)
e1e2 i=1
</equation>
<bodyText confidence="0.9971895">
Given a corpus of N cipher bigrams F1...FN, the
probability of the corpus is:
</bodyText>
<equation confidence="0.997324">
P(corpus) =
</equation>
<bodyText confidence="0.999906928571429">
Given a plaintext bigram language model,
the goal is to manipulate P(f|e) to maximize
P(corpus). Theoretically, one can directly apply
EM to solve the problem (Knight et al., 2006). How-
ever, EM has time complexity O(N · Ve2) and space
complexity O(Vf · Ve), where Vf, Ve are the sizes
of ciphertext and plaintext vocabularies respectively,
and N is the number of cipher bigrams.
Ravi and Knight (2011) apply Bayesian learning
to reduce the space complexity. Instead of esti-
mating probabilities P(f|e), Bayesian learning tries
to draw samples from plaintext sequences given ci-
phertext bigrams. During sampling, the probability
of any possible plaintext sample e1e2 is given as:
</bodyText>
<equation confidence="0.988791571428571">
2
Psample(e1e2) = P(e1e2) H Pbayes(fi|ei)
i=1
N
H
j=1
P(Fj)
</equation>
<page confidence="0.990745">
1669
</page>
<table confidence="0.998602285714286">
misi´on de naciones unidas en oriente medio
misi´on de misi´on naciones
de naciones naciones unidas
naciones unidas misi´on en
unidas en en oriente
en oriente oriente medio
oriente medio
</table>
<tableCaption confidence="0.933693666666667">
Table 1: Comparison of adjacent bigrams (left) and de-
pendency bigrams (right) extracted from the same Span-
ish text
</tableCaption>
<equation confidence="0.997968">
Pbayes(fi|ei) = α + count(ei)
</equation>
<bodyText confidence="0.995108">
where P0 is a base distribution, and α is a parameter
that controls how much we trust P0. count(fi, ei)
and count(ei) record the number of times fi, ei and
ei appear in previously generated samples respec-
tively.
At the end of sampling, P(fi|ei) is estimated by:
</bodyText>
<equation confidence="0.997765">
count(fi, ei)
P(fi|ei) = count(ei)
</equation>
<bodyText confidence="0.999925333333333">
However, Bayesian decipherment is still very
slow with Gibbs sampling (Geman and Geman,
1987), as each sampling step requires considering
Ve possibilities. Dou and Knight (2012) solve the
problem by introducing slice sampling (Neal, 2000)
to Bayesian decipherment.
</bodyText>
<sectionHeader confidence="0.9092405" genericHeader="method">
3 From Adjacent Bigrams to Dependency
Bigrams
</sectionHeader>
<bodyText confidence="0.999607791666667">
A major limitation of work by Dou and Knight
(2012) is their monotonic generative story for deci-
phering adjacent bigrams. While the generation pro-
cess works well for deciphering similar languages
(e.g. Spanish and French) without considering re-
ordering, it does not work well for languages that
are more different in grammar and word order (e.g.
Spanish and English). In this section, we first look
at why adjacent bigrams are bad for decipherment.
Then we describe how to use syntax to solve the
problem.
The left column in Table 1 contains adjacent bi-
grams extracted from the Spanish phrase “misi´on
de naciones unidas en oriente medio”. The cor-
rect decipherment for the bigram “naciones unidas”
should be “united nations”. Since the deciphering
model described by Dou and Knight (2012) does
not consider word reordering, it needs to decipher
the bigram into “nations united” in order to get
the right word translations “naciones”-4“nations”
and “unidas”-4“united”. However, the English lan-
guage model used for decipherment is built from En-
glish adjacent bigrams, so it strongly disprefers “na-
tions united” and is not likely to produce a sensi-
ble decipherment for “naciones unidas”. The Span-
ish bigram “oriente medio” poses the same prob-
lem. Thus, without considering word reordering, the
model described by Dou and Knight (2012) is not a
good fit for deciphering Spanish into English.
However, if we extract bigrams based on depen-
dency relations for both languages, the model fits
better. To extract such bigrams, we first use de-
pendency parsers to parse both languages, and ex-
tract bigrams by putting head word first, followed
by the modifier.1 We call these dependency bi-
grams. The right column in Table 1 lists exam-
ples of Spanish dependency bigrams extracted from
the same Spanish phrase. With a language model
built with English dependency bigrams, the same
model used for deciphering adjacent bigrams is
able to decipher Spanish dependency bigram “na-
ciones(head) unidas(modifier)” into “nations(head)
united(modifier)”.
We might instead propose to consider word re-
ordering when deciphering adjacent bigrams (e.g.
add an operation to swap tokens in a bigram). How-
ever, using dependency bigrams has the following
advantages:
</bodyText>
<listItem confidence="0.995989166666667">
• First, using dependency bigrams avoids com-
plicating the model, keeping deciphering effi-
cient and scalable.
• Second, it addresses the problem of long dis-
tance reordering, which can not be modeled by
swapping tokens in bigrams.
</listItem>
<bodyText confidence="0.8216444">
Furthermore, using dependency bigrams al-
lows us to use dependency types to further
1As use of “del” and “de” in Spanish is much more frequent
than the use of “of” in English, we skip those words by using
their head words as new heads if any of them serves as a head.
</bodyText>
<equation confidence="0.896484">
with Pbayes(fi|ei) defined as:
αP0(fi|ei) + count(fi, ei)
</equation>
<page confidence="0.808048">
1670
</page>
<bodyText confidence="0.999617833333333">
improve decipherment. Suppose we have a
Spanish dependency bigram “accept´o(verb) solici-
tud(object)”. Then all of the following English de-
pendency bigrams are possible decipherments: “ac-
cepted(verb) UN(subject)”, “accepted(verb) govern-
ment(subject)”, “accepted(verb) request(object)”.
However, if we know the type of the Spanish depen-
dency bigram and use a language model built with
the same type in English, the only possible decipher-
ment is “accepted(verb) request(object)”. If we limit
the search space, a system is more likely to find a
better decipherment.
</bodyText>
<sectionHeader confidence="0.95787" genericHeader="method">
4 Deciphering Spanish Gigaword
</sectionHeader>
<bodyText confidence="0.999766333333333">
In this section, we compare dependency bigrams
with adjacent bigrams for deciphering Spanish into
English.
</bodyText>
<subsectionHeader confidence="0.988459">
4.1 Data
</subsectionHeader>
<bodyText confidence="0.999992473684211">
We use the Gigaword corpus for our decipherment
experiments. The corpus contains news articles from
different news agencies and is available in Spanish
and English. We use only the AFP (Agence France-
Presse) section of the corpus in decipherment ex-
periments. We tokenize the corpus using tools that
come with the Europarl corpus (Koehn, 2005). To
shorten the time required for running different sys-
tems on large amounts of data, we keep only the top
5000 most frequent word types in both languages
and replace all other word types with UNK. We also
throw away lines with more than 40 tokens, as the
Spanish parser (Bohnet, 2010) we use is slow when
processing long sentences. After preprocessing, the
corpus contains approximately 440 million tokens in
Spanish and 350 million tokens in English. To ob-
tain dependency bigrams, we use the Bohnet parsers
(Bohnet, 2010) to parse both the Spanish and En-
glish version of the corpus.
</bodyText>
<subsectionHeader confidence="0.988865">
4.2 Systems
</subsectionHeader>
<bodyText confidence="0.999734142857143">
Three systems are evaluated in the experiments. We
implement a baseline system, Adjacent, based on
Dou and Knight (2012). The baseline system col-
lects adjacent bigrams and their counts from Spanish
and English texts. It then builds an English bigram
language model using the English adjacent bigrams
and uses it to decipher the Spanish adjacent bigrams.
</bodyText>
<table confidence="0.9940576">
Dependency Types
Group 1 Verb/Subject
Group 2 Preposition/Preposition-Object,
Noun/Noun-Modifier
Group 3 Verb/Noun-Object
</table>
<tableCaption confidence="0.995853">
Table 2: Dependency relations divided into three groups
</tableCaption>
<bodyText confidence="0.999574153846154">
We build the second system, Dependency, using
dependency bigrams for decipherment. As the two
parsers do not output the same set of dependency re-
lations, we cannot extract all types of dependency
bigrams. Instead, we select a subset of dependency
bigrams whose dependency relations are shared by
the two parser outputs. The selected dependency re-
lations are: Verb/Subject, Verb/Noun-Object, Prepo-
sition/Object, Noun/Modifier. Decipherment runs
the same way as in the baseline system.
The third system, DepType, is built using both
dependent bigrams and their dependency types. We
first extract dependency bigrams for both languages,
then group them based on their dependency types.
As both parsers treat noun phrases dependent on
“del”, “de”, and “of” as prepositional phrases, we
choose to divide the dependency bigrams into 3
groups and list them in Table 2. A separate language
model is built for each group of English dependency
bigrams and used to decipher the group of Spanish
dependency bigrams with same dependency type.
For all the systems, language models are built us-
ing the SRILM toolkit (Stolcke, 2002). For the Ad-
jacent system, we use Good-Turing smoothing. For
the other systems, we use a mix of Witten-Bell and
Good-Turing smoothing.
</bodyText>
<subsectionHeader confidence="0.99968">
4.3 Sampling Procedure
</subsectionHeader>
<bodyText confidence="0.998975555555556">
In experiments, we find that the iterative sam-
pling method described by Dou and Knight (2012)
helps improve deciphering accuracy. We also find
that combining results from different decipherments
helps find more correct translations at each iteration.
Thus, instead of using a single sampling process, we
use 10 different sampling processes at each iteration.
The details of the new sampling procedure are pro-
vided here:
</bodyText>
<listItem confidence="0.9831705">
• Extract dependency bigrams from parsing out-
puts and collect their counts.
</listItem>
<page confidence="0.706419">
1671
</page>
<listItem confidence="0.997724315789474">
• Keep bigrams whose counts are greater than a
threshold α. Then start 10 different randomly
seeded and initialized sampling processes. Per-
form sampling.
• At the end of sampling, extract word transla-
tion pairs (f, e) from the final sample. Esti-
mate translation probabilities P(e|f) for each
pair. Then construct a translation table by keep-
ing translation pairs (f, e) seen in more than
one decipherment and use the average P(e|f)
as the new translation probability.
• Lower the threshold α to include more bigrams
into the sampling process. Start 10 differ-
ent sampling processes again and initialize the
first sample using the translation pairs obtained
from the previous step (for each Spanish token
f, choose an English token e whose P(e|f) is
the highest). Perform sampling again.
• Repeat until α = 1.
</listItem>
<subsectionHeader confidence="0.989121">
4.4 Deciphering Accuracy
</subsectionHeader>
<bodyText confidence="0.99985675">
We choose the first 1000 lines of the monolingual
Spanish texts as our test data. The data contains
37,505 tokens and 6556 word types. We use type ac-
curacy as our evaluation metric: Given a word type
f in Spanish, we find a translation pair (f, e) with
the highest average P(e|f) from the translation ta-
ble learned through decipherment. If the translation
pair (f, e) can also be found in a gold translation
lexicon Tgold, we treat the word type f as correctly
deciphered. Let |C |be the number of word types
correctly deciphered, and |V  |be the total number of
word types evaluated. We define type accuracy as
</bodyText>
<equation confidence="0.931052">
ICI
|V |.
</equation>
<bodyText confidence="0.999424428571429">
To create Tgold, we use GIZA (Och and Ney,
2003) to align a small amount of Spanish-English
parallel text (1 million tokens for each language),
and use the lexicon derived from the alignment as
our gold translation lexicon. Tgold contains a subset
of 4408 types seen in the test data, among which,
2878 are also top 5000 frequent word types.
</bodyText>
<sectionHeader confidence="0.652111" genericHeader="method">
4.5 Results
</sectionHeader>
<bodyText confidence="0.998359">
During decipherment, we gradually increase the size
of Spanish texts and compare the learning curves of
three deciphering systems in Figure 2.
</bodyText>
<figureCaption confidence="0.984077">
Figure 2: Learning curves for three decipherment sys-
tems. Compared with Adjacent (previous state of the art),
systems that use dependency bigrams improve decipher-
ing accuracy by over 500%.
</figureCaption>
<bodyText confidence="0.999969833333333">
With 100k tokens of Spanish text, the perfor-
mance of the three systems are similar. However, the
learning curve of Adjacent plateaus quickly, while
those of the dependency based systems soar up as
more data becomes available and still rise sharply
when the size of Spanish texts increases to 10 mil-
lion tokens, where the DepType system improves
deciphering accuracy of the Adjacent system from
4.2% to 24.6%. In the end, with 100 million tokens,
the accuracy of the DepType system rises to 27.0%.
The accuracy is even higher (41%), when evaluated
against the top 5000 frequent word types only.
</bodyText>
<sectionHeader confidence="0.938366" genericHeader="method">
5 Improving Machine Translation with
Decipherment
</sectionHeader>
<bodyText confidence="0.999974">
In this section, we demonstrate how to use a trans-
lation lexicon learned by deciphering large amounts
of in-domain (news) monolingual data to improve
a phrase-based machine translation system trained
with limited out-of-domain (politics) parallel data.
</bodyText>
<subsectionHeader confidence="0.97536">
5.1 Data
</subsectionHeader>
<bodyText confidence="0.999868">
We use approximately one million tokens of the Eu-
roparl corpus (Koehn, 2005) as our small out-of-
domain parallel training data and Gigaword as our
large in-domain monolingual training data to build
language models and a new translation lexicon to
improve a phrase-based MT baseline system. For
tuning and testing, we use the development data
</bodyText>
<page confidence="0.977769">
1672
</page>
<table confidence="0.9996336">
Parallel
Spanish English
Europarl 1.1 million 1.0 million
Tune-2008 52.6k 49.8k
Test-2009 68.1k 65.6k
Test-2010 65.5k 61.9k
Test-2011 79.4k 74.7k
Non Parallel
Spanish English
Gigaword 894 million 940 million
</table>
<tableCaption confidence="0.969597">
Table 3: Size of training, tuning, and testing data in num-
ber of tokens
</tableCaption>
<bodyText confidence="0.999529">
from the NAACL 2012 workshop on statistical ma-
chine translation. The data contains test data in the
news domain from the 2008, 2009, 2010, and 2011
workshops. We use the 2008 test data for tuning and
the rest for testing. The sizes of the training, tuning,
and testing sets are listed in Table 3.
</bodyText>
<subsectionHeader confidence="0.845739">
5.2 Systems
5.2.1 Baseline Machine Translation System
</subsectionHeader>
<bodyText confidence="0.99962725">
We build a state-of-the-art phrase-based MT sys-
tem, PBMT, using Moses (Koehn et al., 2007).
PBMT has 3 models: a translation model, a distor-
tion model, and a language model. We build a 5-
gram language model using the AFP section of the
English Gigaword. We train the other models using
the Europarl corpus. By default, Moses uses the fol-
lowing 8 features to score a candidate translation:
</bodyText>
<listItem confidence="0.9998195">
• direct and inverse translation probabilities
• direct and inverse lexical weighting
• a language model score
• a distortion score
• phrase penalty
• word penalty
</listItem>
<bodyText confidence="0.9998415">
The 8 features have weights adjusted on the tun-
ing data using minimum error rate training (MERT)
(Och, 2003). PBMT has a phrase table Tphrase.
During decoding, Moses copies out-of-vocabulary
(OOV) words, which can not be found in Tphrase,
directly to output. In the following sections, we de-
scribe how to use a translation lexicon learned from
large amounts of non parallel data to improve trans-
lation of OOV words, as well as words observed in
Tphrase.
</bodyText>
<subsubsectionHeader confidence="0.494245">
5.2.2 Decipherment for Machine Translation
</subsubsectionHeader>
<bodyText confidence="0.975129">
To achieve better decipherment, we:
</bodyText>
<listItem confidence="0.998874">
• Increase the size of Spanish ciphertext from
100 million tokens to 894 million tokens.
• Keep top 50k instead of top 5k most frequent
word types of the ciphertext.
• Instead of seeding the sampling process ran-
</listItem>
<bodyText confidence="0.995955375">
domly, we use a translation lexicon learned
from a limited amount of parallel data as seed:
For each Spanish dependency bigram f1, f2,
where both f1 and f2 are found in the seed lex-
icon, we find the English sequence e1, e2 that
maximizes P(e1, e2)P(e1|f1)P(e2|f2). Other-
wise, for any Spanish token f that can be found
in the seed lexicon, we choose English word e,
where P(e|f) is the highest as the initial sam-
ple; for any f that are not seen in the seed lexi-
con, we do random initialization.
We perform 20 random restarts with 10k iter-
ations on each and build a word-to-word transla-
tion lexicon Tdecipher by collecting translation pairs
seen in at least 3 final decipherments with either
P(f|e) &gt; 0.2 or P(e|f) &gt; 0.2.
</bodyText>
<subsectionHeader confidence="0.988191">
5.2.3 Improving Translation of Observed
Words with Decipherment
</subsectionHeader>
<bodyText confidence="0.99786425">
To improve translation of words observed in our
parallel corpus, we simply use Tdecipher as an addi-
tional parallel corpus. First, we filter Tdecipher by
keeping only translation pairs (f, e), where f is ob-
served in the Spanish part and e is observed in the
English part of the parallel corpus. Then we ap-
pend all the Spanish and English words in the fil-
tered Tdecipher to the end of Spanish part and En-
glish part of the parallel corpus respectively. The
training and tuning process is the same as the base-
line machine translation system PBMT. We denote
this system as Decipher-OBSV.
</bodyText>
<page confidence="0.971012">
1673
</page>
<subsectionHeader confidence="0.917419">
5.2.4 Improving OOV translation with
Decipherment
</subsectionHeader>
<bodyText confidence="0.99953984375">
As Tdecipher is learned from large amounts of in-
domain monolingual data, we expect that Tdecipher
contains a number of useful translations for words
not seen in the limited amount of parallel data (OOV
words). Instead of copying OOV words directly to
output, which is what Moses does by default, we try
to find translations from Tdecipher to improve trans-
lation.
During decoding, if a source word f is in Tphrase,
its translation options are collected from Tphrase ex-
clusively. If f is not in Tphrase but in Tdecipher,
the decoder will find translations from Tdecipher. If
f is not in either translation table, the decoder just
copies it directly to the output. We call this system
Decipher-OOV.
However, when an OOV’s correct translation is
same as its surface form and all its possible transla-
tions in Tdecipher are wrong, it is better to just copy
OOV words directly to output. This scenario hap-
pens frequently, as Spanish and English share many
common words. To avoid over trusting Tdecipher,
we add a new translation pair (f, f) for each source
word f in Tdecipher if the translation pair (f, f) is
not originally in Tdecipher. For each newly added
translation pair, both of its log translation probabil-
ities are set to 0. To distinguish the added transla-
tion pairs from the others learned through decipher-
ment, we add a binary feature 0 to each translation
pair in Tdecipher. The final version of Tdecipher has
three feature scores: P(e|f), P(f|e), and 0. Finally,
we tune weights of the features in Tdecipher using
MERT (Och, 2003) on the tuning set.
</bodyText>
<subsectionHeader confidence="0.983861">
5.2.5 A Combined Approach
</subsectionHeader>
<bodyText confidence="0.999914">
In the end, we build a system Decipher-COMB,
which uses Tdecipher to improve translation of both
observed and OOV words with methods described in
sections 5.2.3 and 5.2.4.
</bodyText>
<subsectionHeader confidence="0.896582">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.999936902439024">
We tune each system three times with MERT and
choose the best weights based on BLEU scores on
tuning set.
Table 4 shows that the translation lexicon learned
from decipherment helps achieve higher BLEU
scores across tuning and testing sets. Decipher-
OBSV improves BLEU scores by as much as 1.2
points. We analyze the results and find the gain
mainly comes from two parts. First, adding Tdecipher
to small amounts of parallel corpus improves word
level translation probabilities, which lead to better
lexical weighting; second, Tdecipher contains new al-
ternative translations for words observed in the par-
allel corpus.
Moreover, Decipher-OOV also achieves better
BLEU scores compared with PBMT across all tun-
ing and test sets. We also observe that systems us-
ing Tdecipher learned by deciphering dependency bi-
grams leads to larger gains in BLEU scores. When
decipherment is used to improve translation of both
observed and OOV words, we see improvement in
BLEU score as high as 1.8 points on the 2010 news
test set.
The consistent improvement on the tuning and
different testing data suggests that decipherment is
capable of learning good translations for a number
of OOV words. To further demonstrate that our
decipherment approach finds useful translations for
OOV words, we list the top 10 most frequent OOV
words from both the tuning set and testing set as well
as their translations (up to three most likely transla-
tions) in Table 5. P(elf) and P(f|e) are average
scores over different decipherment runs.
From the table, we can see that decipherment
finds correct translations (bolded) for 7 out of the
10 most frequent OOV words. Moreover, many
OOVs and their correct translations are homographs
, which makes copying OOVs directly to the output
a strong baseline to beat. Nonetheless, decipherment
still finds enough correct translations to improve the
baseline.
</bodyText>
<sectionHeader confidence="0.999003" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999943777777778">
We introduce syntax for deciphering Spanish into
English. Experiment results show that using de-
pendency bigrams improves decipherment accuracy
by over 500% compared with the state-of-the-art
approach. Moreover, we learn a domain specific
translation lexicon by deciphering large amounts of
monolingual data and show that the lexicon can im-
prove a baseline machine translation system trained
with limited parallel data.
</bodyText>
<page confidence="0.967335">
1674
</page>
<table confidence="0.999919375">
Decipherment System Tune2008 Test2009 Test2010 Test2011
None PBMT (Baseline) 19.1 19.6 21.3 22.1
Adjacent Decipher-OBSV 19.5 20.1 22.2 22.6
Decipher-OOV 19.4 19.9 21.7 22.5
Decipher-COMB 19.5 20.2 22.3 22.5
Dependency Decipher-OBSV 19.7 20.5 22.5 23.0
Decipher-OOV 19.9 20.4 22.4 22.9
Decipher-COMB 20.0 20.8 23.1 23.4
</table>
<tableCaption confidence="0.947113333333333">
Table 4: Systems that use translation lexicons learned from decipherment show consistent improvement over the
baseline system across tuning and testing sets. The best system, Decipher-COMB, achieves as much as 1.8 BLEU
point gain on the 2010 news test set.
</tableCaption>
<table confidence="0.99979888">
Spanish English P(elf) P(f|e)
obama his 0.33 0.01
bush 0.27 0.07
clinton 0.23 0.11
bush bush 0.47 0.45
yeltsin 0.28 0.81
he 0.24 0.05
festival event 0.68 0.35
festival 0.61 0.72
wikileaks zeta 0.03 0.33
venus venus 0.61 0.74
serena 0.47 0.62
colchones mattresses 0.55 0.73
cars 0.31 0.01
helado frigid 0.52 0.44
chill 0.37 0.14
sandwich 0.42 0.27
google microsoft 0.67 0.18
google 0.59 0.69
cantante singer 0.44 0.92
jackson 0.14 0.33
artists 0.14 0.77
mccain mccain 0.66 0.92
it 0.22 0.00
he 0.21 0.00
</table>
<tableCaption confidence="0.9433635">
Table 5: Decipherment finds correct translations for 7 out
of 10 most frequent OOV word types.
</tableCaption>
<sectionHeader confidence="0.997532" genericHeader="acknowledgments">
7 Acknowledgments
</sectionHeader>
<bodyText confidence="0.985392833333333">
This work was supported by NSF Grant 0904684
and ARO grant W911NF-10-1-0533. The authors
would like to thank David Chiang, Malte Nuhn,
Victoria Fossum, Ashish Vaswani, Ulf Hermjakob,
Yang Gao, and Hui Zhang (in no particular order)
for their comments and suggestions.
</bodyText>
<sectionHeader confidence="0.996951" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.955814576923077">
Shane Bergsma and Benjamin Van Durme. 2011. Learn-
ing bilingual lexicons using the visual similarity of
labeled web images. In Proceedings of the Twenty-
Second international joint conference on Artificial In-
telligence - Volume Volume Three. AAAI Press.
Bernd Bohnet. 2010. Top accuracy and fast dependency
parsing is not a contradiction. In Proceedings of the
23rd International Conference on Computational Lin-
guistics. Coling.
Hal Daum´e, III and Jagadeesh Jagarlamudi. 2011. Do-
main adaptation for machine translation by mining un-
seen words. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguistics:
Human Language Technologies. Association for Com-
putational Linguistics.
Qing Dou and Kevin Knight. 2012. Large scale deci-
pherment for out-of-domain machine translation. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning. Associa-
tion for Computational Linguistics.
Pascale Fung and Lo Yuen Yee. 1998. An IR approach
for translating new words from nonparallel, compara-
ble texts. In Proceedings of the 36th Annual Meet-
ing of the Association for Computational Linguistics
and 17th International Conference on Computational
</reference>
<page confidence="0.863825">
1675
</page>
<reference confidence="0.999805483516484">
Linguistics - Volume 1. Association for Computational
Linguistics.
Nikesh Garera, Chris Callison-Burch, and David
Yarowsky. 2009. Improving translation lexicon induc-
tion from monolingual corpora via dependency con-
texts and part-of-speech equivalences. In Proceed-
ings of the Thirteenth Conference on Computational
Natural Language Learning. Association for Compu-
tational Linguistics.
Stuart Geman and Donald Geman. 1987. Stochastic re-
laxation, Gibbs distributions, and the Bayesian restora-
tion of images. In Readings in computer vision: is-
sues, problems, principles, and paradigms. Morgan
Kaufmann Publishers Inc.
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In Proceedings of ACL-
08: HLT. Association for Computational Linguistics.
Ann Irvine and Chris Callison-Burch. 2013a. Combin-
ing bilingual and comparable corpora for low resource
machine translation. In Proceedings of the Eighth
Workshop on Statistical Machine Translation. Associ-
ation for Computational Linguistics, August.
Ann Irvine and Chris Callison-Burch. 2013b. Supervised
bilingual lexicon induction with multiple monolingual
signals. In Proceedings of the 2013 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies. Association for Computational Linguistics.
Alexandre Klementiev, Ann Irvine, Chris Callison-
Burch, and David Yarowsky. 2012. Toward statisti-
cal machine translation without parallel corpora. In
Proceedings of the 13th Conference of the European
Chapter of the Association for Computational Linguis-
tics. Association for Computational Linguistics.
Kevin Knight, Anish Nair, Nishit Rathod, and Kenji Ya-
mada. 2006. Unsupervised analysis for decipher-
ment problems. In Proceedings of the COLING/ACL
2006 Main Conference Poster Sessions. Association
for Computational Linguistics.
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In Pro-
ceedings of the ACL-02 Workshop on Unsupervised
Lexical Acquisition. Association for Computational
Linguistics.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Interac-
tive Poster and Demonstration Sessions. Association
for Computational Linguistics.
Philipp Koehn. 2005. Europarl: a parallel corpus for sta-
tistical machine translation. In In Proceedings of the
Tenth Machine Translation Summit, Phuket, Thailand.
Asia-Pacific Association for Machine Translation.
Radford Neal. 2000. Slice sampling. Annals of Statis-
tics, 31.
Malte Nuhn, Arne Mauser, and Hermann Ney. 2012.
Deciphering foreign language by combining language
models and context vectors. In Proceedings of the 50th
Annual Meeting of the Association for Computational
Linguistics: Long Papers - Volume 1. Association for
Computational Linguistics.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Comput. Linguist.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Computa-
tional Linguistics. Association for Computational Lin-
guistics.
Reinhard Rapp. 1995. Identifying word translations in
non-parallel texts. In Proceedings of the 33rd annual
meeting on Association for Computational Linguistics.
Association for Computational Linguistics.
Sujith Ravi and Kevin Knight. 2011. Deciphering for-
eign language. In Proceedings of the 49th Annual
Meeting of the Association for Computational Linguis-
tics: Human Language Technologies. Association for
Computational Linguistics.
Sujith Ravi. 2013. Scalable decipherment for machine
translation via hash sampling. In Proceedings of the
51th Annual Meeting of the Association for Computa-
tional Linguistics. Association for Computational Lin-
guistics.
Andreas Stolcke. 2002. SRILM - an extensible language
modeling toolkit. In Proceedings of the International
Conference on Spoken Language Processing.
</reference>
<page confidence="0.992452">
1676
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.948104">
<title confidence="0.9978345">Dependency-Based Decipherment for Resource-Limited Machine Translation</title>
<author confidence="0.966855">Qing Dou</author>
<author confidence="0.966855">Kevin</author>
<affiliation confidence="0.999602666666667">Information Sciences Institute Department of Computer Science University of Southern</affiliation>
<abstract confidence="0.998771916666667">We introduce dependency relations into deciphering foreign languages and show that dependency relations help improve the state-ofthe-art deciphering accuracy by over 500%. We learn a translation lexicon from large amounts of genuinely non parallel data with decipherment to improve a phrase-based machine translation system trained with limited parallel data. In experiments, we observe BLEU gains of 1.2 to 1.8 across three different test sets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Learning bilingual lexicons using the visual similarity of labeled web images.</title>
<date>2011</date>
<booktitle>In Proceedings of the TwentySecond international joint conference on Artificial Intelligence - Volume Volume Three.</booktitle>
<publisher>AAAI Press.</publisher>
<marker>Bergsma, Van Durme, 2011</marker>
<rawString>Shane Bergsma and Benjamin Van Durme. 2011. Learning bilingual lexicons using the visual similarity of labeled web images. In Proceedings of the TwentySecond international joint conference on Artificial Intelligence - Volume Volume Three. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics. Coling.</booktitle>
<contexts>
<context position="11308" citStr="Bohnet, 2010" startWordPosition="1807" endWordPosition="1808">aword corpus for our decipherment experiments. The corpus contains news articles from different news agencies and is available in Spanish and English. We use only the AFP (Agence FrancePresse) section of the corpus in decipherment experiments. We tokenize the corpus using tools that come with the Europarl corpus (Koehn, 2005). To shorten the time required for running different systems on large amounts of data, we keep only the top 5000 most frequent word types in both languages and replace all other word types with UNK. We also throw away lines with more than 40 tokens, as the Spanish parser (Bohnet, 2010) we use is slow when processing long sentences. After preprocessing, the corpus contains approximately 440 million tokens in Spanish and 350 million tokens in English. To obtain dependency bigrams, we use the Bohnet parsers (Bohnet, 2010) to parse both the Spanish and English version of the corpus. 4.2 Systems Three systems are evaluated in the experiments. We implement a baseline system, Adjacent, based on Dou and Knight (2012). The baseline system collects adjacent bigrams and their counts from Spanish and English texts. It then builds an English bigram language model using the English adjac</context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics. Coling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Jagadeesh Jagarlamudi</author>
</authors>
<title>Domain adaptation for machine translation by mining unseen words.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<marker>Daum´e, Jagarlamudi, 2011</marker>
<rawString>Hal Daum´e, III and Jagadeesh Jagarlamudi. 2011. Domain adaptation for machine translation by mining unseen words. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qing Dou</author>
<author>Kevin Knight</author>
</authors>
<title>Large scale decipherment for out-of-domain machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1849" citStr="Dou and Knight (2012)" startWordPosition="273" endWordPosition="276">ers for a large scale MT system. Other work tries to learn full MT systems using only non parallel data through decipherment (Ravi and Knight, 2011; Ravi, 2013). However, the performance of such systems is poor compared with those trained with parallel data. Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel corpora with non parallel Figure 1: Improving machine translation with decipherment (Grey boxes represent new data and process). Mono: monolingual; LM: language model; LEX: translation lexicon; TM: translation model. data. Dou and Knight (2012) successfully apply decipherment to learn a domain specific translation lexicon from monolingual data to improve out-ofdomain machine translation. Although their approach works well for Spanish/French, they do not show whether their approach works for other language pairs. Moreover, the non parallel data used in their experiments is created from a parallel corpus. Such highly comparable data is difficult to obtain in reality. In this work, we improve previous work by Dou and Knight (2012) using genuinely non parallel data, 1668 Proceedings of the 2013 Conference on Empirical Methods in Natural</context>
<context position="4273" citStr="Dou and Knight, 2012" startWordPosition="661" endWordPosition="664">rch has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a translation lexicon that produces a good decipherment. In an effort to build a MT system without a parallel corpus, Ravi and Knight (2011) view Spanish as a cipher for English and apply Bayesian learning to directly decipher Spanish into English. Unfortunately, their approach can only work on small data with limited vocabulary. Dou and Knight (2012) propose two techniques to make Bayesian decipherment scalable. First, unlike Ravi and Knight (2011), who decipher whole sentences, Dou and Knight (2012) deci</context>
<context position="7047" citStr="Dou and Knight (2012)" startWordPosition="1125" endWordPosition="1128">o Table 1: Comparison of adjacent bigrams (left) and dependency bigrams (right) extracted from the same Spanish text Pbayes(fi|ei) = α + count(ei) where P0 is a base distribution, and α is a parameter that controls how much we trust P0. count(fi, ei) and count(ei) record the number of times fi, ei and ei appear in previously generated samples respectively. At the end of sampling, P(fi|ei) is estimated by: count(fi, ei) P(fi|ei) = count(ei) However, Bayesian decipherment is still very slow with Gibbs sampling (Geman and Geman, 1987), as each sampling step requires considering Ve possibilities. Dou and Knight (2012) solve the problem by introducing slice sampling (Neal, 2000) to Bayesian decipherment. 3 From Adjacent Bigrams to Dependency Bigrams A major limitation of work by Dou and Knight (2012) is their monotonic generative story for deciphering adjacent bigrams. While the generation process works well for deciphering similar languages (e.g. Spanish and French) without considering reordering, it does not work well for languages that are more different in grammar and word order (e.g. Spanish and English). In this section, we first look at why adjacent bigrams are bad for decipherment. Then we describe </context>
<context position="8512" citStr="Dou and Knight (2012)" startWordPosition="1358" endWordPosition="1361">nited nations”. Since the deciphering model described by Dou and Knight (2012) does not consider word reordering, it needs to decipher the bigram into “nations united” in order to get the right word translations “naciones”-4“nations” and “unidas”-4“united”. However, the English language model used for decipherment is built from English adjacent bigrams, so it strongly disprefers “nations united” and is not likely to produce a sensible decipherment for “naciones unidas”. The Spanish bigram “oriente medio” poses the same problem. Thus, without considering word reordering, the model described by Dou and Knight (2012) is not a good fit for deciphering Spanish into English. However, if we extract bigrams based on dependency relations for both languages, the model fits better. To extract such bigrams, we first use dependency parsers to parse both languages, and extract bigrams by putting head word first, followed by the modifier.1 We call these dependency bigrams. The right column in Table 1 lists examples of Spanish dependency bigrams extracted from the same Spanish phrase. With a language model built with English dependency bigrams, the same model used for deciphering adjacent bigrams is able to decipher S</context>
<context position="11740" citStr="Dou and Knight (2012)" startWordPosition="1875" endWordPosition="1878">ly the top 5000 most frequent word types in both languages and replace all other word types with UNK. We also throw away lines with more than 40 tokens, as the Spanish parser (Bohnet, 2010) we use is slow when processing long sentences. After preprocessing, the corpus contains approximately 440 million tokens in Spanish and 350 million tokens in English. To obtain dependency bigrams, we use the Bohnet parsers (Bohnet, 2010) to parse both the Spanish and English version of the corpus. 4.2 Systems Three systems are evaluated in the experiments. We implement a baseline system, Adjacent, based on Dou and Knight (2012). The baseline system collects adjacent bigrams and their counts from Spanish and English texts. It then builds an English bigram language model using the English adjacent bigrams and uses it to decipher the Spanish adjacent bigrams. Dependency Types Group 1 Verb/Subject Group 2 Preposition/Preposition-Object, Noun/Noun-Modifier Group 3 Verb/Noun-Object Table 2: Dependency relations divided into three groups We build the second system, Dependency, using dependency bigrams for decipherment. As the two parsers do not output the same set of dependency relations, we cannot extract all types of dep</context>
<context position="13518" citStr="Dou and Knight (2012)" startWordPosition="2148" endWordPosition="2151">d “of” as prepositional phrases, we choose to divide the dependency bigrams into 3 groups and list them in Table 2. A separate language model is built for each group of English dependency bigrams and used to decipher the group of Spanish dependency bigrams with same dependency type. For all the systems, language models are built using the SRILM toolkit (Stolcke, 2002). For the Adjacent system, we use Good-Turing smoothing. For the other systems, we use a mix of Witten-Bell and Good-Turing smoothing. 4.3 Sampling Procedure In experiments, we find that the iterative sampling method described by Dou and Knight (2012) helps improve deciphering accuracy. We also find that combining results from different decipherments helps find more correct translations at each iteration. Thus, instead of using a single sampling process, we use 10 different sampling processes at each iteration. The details of the new sampling procedure are provided here: • Extract dependency bigrams from parsing outputs and collect their counts. 1671 • Keep bigrams whose counts are greater than a threshold α. Then start 10 different randomly seeded and initialized sampling processes. Perform sampling. • At the end of sampling, extract word</context>
</contexts>
<marker>Dou, Knight, 2012</marker>
<rawString>Qing Dou and Kevin Knight. 2012. Large scale decipherment for out-of-domain machine translation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Lo Yuen Yee</author>
</authors>
<title>An IR approach for translating new words from nonparallel, comparable texts.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 1. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3766" citStr="Fung and Yee, 1998" startWordPosition="583" endWordPosition="586">ounts of non parallel data. • We show that decipherment is able to find correct translations for OOV words. • We use a translation lexicon learned by deciphering large amounts of non parallel data to improve a phrase-based MT system trained with limited amounts of parallel data. In experiments, we observe 1.2 to 1.8 BLEU gains across three different test sets. 2 Previous Work Motivated by the idea that a translation lexicon induced from non parallel data can be applied to MT, a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a tr</context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>Pascale Fung and Lo Yuen Yee. 1998. An IR approach for translating new words from nonparallel, comparable texts. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics - Volume 1. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikesh Garera</author>
<author>Chris Callison-Burch</author>
<author>David Yarowsky</author>
</authors>
<title>Improving translation lexicon induction from monolingual corpora via dependency contexts and part-of-speech equivalences.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3834" citStr="Garera et al., 2009" startWordPosition="595" endWordPosition="598">find correct translations for OOV words. • We use a translation lexicon learned by deciphering large amounts of non parallel data to improve a phrase-based MT system trained with limited amounts of parallel data. In experiments, we observe 1.2 to 1.8 BLEU gains across three different test sets. 2 Previous Work Motivated by the idea that a translation lexicon induced from non parallel data can be applied to MT, a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a translation lexicon that produces a good decipherment. In an effort to</context>
</contexts>
<marker>Garera, Callison-Burch, Yarowsky, 2009</marker>
<rawString>Nikesh Garera, Chris Callison-Burch, and David Yarowsky. 2009. Improving translation lexicon induction from monolingual corpora via dependency contexts and part-of-speech equivalences. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart Geman</author>
<author>Donald Geman</author>
</authors>
<title>Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. In Readings in computer vision: issues, problems, principles, and paradigms.</title>
<date>1987</date>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<contexts>
<context position="6963" citStr="Geman and Geman, 1987" startWordPosition="1113" endWordPosition="1116">naciones unidas misi´on en unidas en en oriente en oriente oriente medio oriente medio Table 1: Comparison of adjacent bigrams (left) and dependency bigrams (right) extracted from the same Spanish text Pbayes(fi|ei) = α + count(ei) where P0 is a base distribution, and α is a parameter that controls how much we trust P0. count(fi, ei) and count(ei) record the number of times fi, ei and ei appear in previously generated samples respectively. At the end of sampling, P(fi|ei) is estimated by: count(fi, ei) P(fi|ei) = count(ei) However, Bayesian decipherment is still very slow with Gibbs sampling (Geman and Geman, 1987), as each sampling step requires considering Ve possibilities. Dou and Knight (2012) solve the problem by introducing slice sampling (Neal, 2000) to Bayesian decipherment. 3 From Adjacent Bigrams to Dependency Bigrams A major limitation of work by Dou and Knight (2012) is their monotonic generative story for deciphering adjacent bigrams. While the generation process works well for deciphering similar languages (e.g. Spanish and French) without considering reordering, it does not work well for languages that are more different in grammar and word order (e.g. Spanish and English). In this sectio</context>
</contexts>
<marker>Geman, Geman, 1987</marker>
<rawString>Stuart Geman and Donald Geman. 1987. Stochastic relaxation, Gibbs distributions, and the Bayesian restoration of images. In Readings in computer vision: issues, problems, principles, and paradigms. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL08: HLT. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3813" citStr="Haghighi et al., 2008" startWordPosition="591" endWordPosition="594">ecipherment is able to find correct translations for OOV words. • We use a translation lexicon learned by deciphering large amounts of non parallel data to improve a phrase-based MT system trained with limited amounts of parallel data. In experiments, we observe 1.2 to 1.8 BLEU gains across three different test sets. 2 Previous Work Motivated by the idea that a translation lexicon induced from non parallel data can be applied to MT, a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a translation lexicon that produces a good decipher</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In Proceedings of ACL08: HLT. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Irvine</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Combining bilingual and comparable corpora for low resource machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation. Association for Computational Linguistics,</booktitle>
<contexts>
<context position="3926" citStr="Irvine and Callison-Burch, 2013" startWordPosition="608" endWordPosition="611">by deciphering large amounts of non parallel data to improve a phrase-based MT system trained with limited amounts of parallel data. In experiments, we observe 1.2 to 1.8 BLEU gains across three different test sets. 2 Previous Work Motivated by the idea that a translation lexicon induced from non parallel data can be applied to MT, a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a translation lexicon that produces a good decipherment. In an effort to build a MT system without a parallel corpus, Ravi and Knight (2011) view Spanish as a ciphe</context>
</contexts>
<marker>Irvine, Callison-Burch, 2013</marker>
<rawString>Ann Irvine and Chris Callison-Burch. 2013a. Combining bilingual and comparable corpora for low resource machine translation. In Proceedings of the Eighth Workshop on Statistical Machine Translation. Association for Computational Linguistics, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Irvine</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Supervised bilingual lexicon induction with multiple monolingual signals.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association</booktitle>
<contexts>
<context position="3926" citStr="Irvine and Callison-Burch, 2013" startWordPosition="608" endWordPosition="611">by deciphering large amounts of non parallel data to improve a phrase-based MT system trained with limited amounts of parallel data. In experiments, we observe 1.2 to 1.8 BLEU gains across three different test sets. 2 Previous Work Motivated by the idea that a translation lexicon induced from non parallel data can be applied to MT, a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a translation lexicon that produces a good decipherment. In an effort to build a MT system without a parallel corpus, Ravi and Knight (2011) view Spanish as a ciphe</context>
</contexts>
<marker>Irvine, Callison-Burch, 2013</marker>
<rawString>Ann Irvine and Chris Callison-Burch. 2013b. Supervised bilingual lexicon induction with multiple monolingual signals. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Ann Irvine</author>
<author>Chris CallisonBurch</author>
<author>David Yarowsky</author>
</authors>
<title>Toward statistical machine translation without parallel corpora.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1186" citStr="Klementiev et al. (2012)" startWordPosition="166" endWordPosition="169">imited parallel data. In experiments, we observe BLEU gains of 1.2 to 1.8 across three different test sets. 1 Introduction State-of-the-art machine translation (MT) systems apply statistical techniques to learn translation rules from large amounts of parallel data. However, parallel data is limited for many language pairs and domains. In general, it is easier to obtain non parallel data. The ability to build a machine translation system using monolingual data could alleviate problems caused by insufficient parallel data. Towards building a machine translation system without a parallel corpus, Klementiev et al. (2012) use non parallel data to estimate parameters for a large scale MT system. Other work tries to learn full MT systems using only non parallel data through decipherment (Ravi and Knight, 2011; Ravi, 2013). However, the performance of such systems is poor compared with those trained with parallel data. Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel corpora with non parallel Figure 1: Improving machine translation with decipherment (Grey boxes represent new data and process). Mono: monolingual; LM: language model; LEX: translat</context>
</contexts>
<marker>Klementiev, Irvine, CallisonBurch, Yarowsky, 2012</marker>
<rawString>Alexandre Klementiev, Ann Irvine, Chris CallisonBurch, and David Yarowsky. 2012. Toward statistical machine translation without parallel corpora. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Anish Nair</author>
<author>Nishit Rathod</author>
<author>Kenji Yamada</author>
</authors>
<title>Unsupervised analysis for decipherment problems.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5679" citStr="Knight et al., 2006" startWordPosition="903" endWordPosition="906">d through the following generative story: • Generate a sequence of two plaintext tokens e1e2 with probability P(e1e2) given by a language model built from large numbers of plaintext bigrams. • Substitute e1 with f1 and e2 with f2 with probability P(f1|e1) · P(f2|e2). The probability of any cipher bigram F is: 2 P(F) = E P(e1e2) H P(fi|ei) e1e2 i=1 Given a corpus of N cipher bigrams F1...FN, the probability of the corpus is: P(corpus) = Given a plaintext bigram language model, the goal is to manipulate P(f|e) to maximize P(corpus). Theoretically, one can directly apply EM to solve the problem (Knight et al., 2006). However, EM has time complexity O(N · Ve2) and space complexity O(Vf · Ve), where Vf, Ve are the sizes of ciphertext and plaintext vocabularies respectively, and N is the number of cipher bigrams. Ravi and Knight (2011) apply Bayesian learning to reduce the space complexity. Instead of estimating probabilities P(f|e), Bayesian learning tries to draw samples from plaintext sequences given ciphertext bigrams. During sampling, the probability of any possible plaintext sample e1e2 is given as: 2 Psample(e1e2) = P(e1e2) H Pbayes(fi|ei) i=1 N H j=1 P(Fj) 1669 misi´on de naciones unidas en oriente </context>
</contexts>
<marker>Knight, Nair, Rathod, Yamada, 2006</marker>
<rawString>Kevin Knight, Anish Nair, Nishit Rathod, and Kenji Yamada. 2006. Unsupervised analysis for decipherment problems. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3790" citStr="Koehn and Knight, 2002" startWordPosition="587" endWordPosition="590">l data. • We show that decipherment is able to find correct translations for OOV words. • We use a translation lexicon learned by deciphering large amounts of non parallel data to improve a phrase-based MT system trained with limited amounts of parallel data. In experiments, we observe 1.2 to 1.8 BLEU gains across three different test sets. 2 Previous Work Motivated by the idea that a translation lexicon induced from non parallel data can be applied to MT, a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a translation lexicon that p</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of the ACL-02 Workshop on Unsupervised Lexical Acquisition. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Chris Dyer, Ondˇrej Bojar,</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions. Association for Computational Linguistics.</booktitle>
<location>Alexandra</location>
<contexts>
<context position="18038" citStr="Koehn et al., 2007" startWordPosition="2893" endWordPosition="2896">Test-2010 65.5k 61.9k Test-2011 79.4k 74.7k Non Parallel Spanish English Gigaword 894 million 940 million Table 3: Size of training, tuning, and testing data in number of tokens from the NAACL 2012 workshop on statistical machine translation. The data contains test data in the news domain from the 2008, 2009, 2010, and 2011 workshops. We use the 2008 test data for tuning and the rest for testing. The sizes of the training, tuning, and testing sets are listed in Table 3. 5.2 Systems 5.2.1 Baseline Machine Translation System We build a state-of-the-art phrase-based MT system, PBMT, using Moses (Koehn et al., 2007). PBMT has 3 models: a translation model, a distortion model, and a language model. We build a 5- gram language model using the AFP section of the English Gigaword. We train the other models using the Europarl corpus. By default, Moses uses the following 8 features to score a candidate translation: • direct and inverse translation probabilities • direct and inverse lexical weighting • a language model score • a distortion score • phrase penalty • word penalty The 8 features have weights adjusted on the tuning data using minimum error rate training (MERT) (Och, 2003). PBMT has a phrase table Tp</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Europarl: a parallel corpus for statistical machine translation. In</title>
<date>2005</date>
<booktitle>In Proceedings of the Tenth Machine Translation Summit,</booktitle>
<location>Phuket,</location>
<contexts>
<context position="11022" citStr="Koehn, 2005" startWordPosition="1755" endWordPosition="1756">t is “accepted(verb) request(object)”. If we limit the search space, a system is more likely to find a better decipherment. 4 Deciphering Spanish Gigaword In this section, we compare dependency bigrams with adjacent bigrams for deciphering Spanish into English. 4.1 Data We use the Gigaword corpus for our decipherment experiments. The corpus contains news articles from different news agencies and is available in Spanish and English. We use only the AFP (Agence FrancePresse) section of the corpus in decipherment experiments. We tokenize the corpus using tools that come with the Europarl corpus (Koehn, 2005). To shorten the time required for running different systems on large amounts of data, we keep only the top 5000 most frequent word types in both languages and replace all other word types with UNK. We also throw away lines with more than 40 tokens, as the Spanish parser (Bohnet, 2010) we use is slow when processing long sentences. After preprocessing, the corpus contains approximately 440 million tokens in Spanish and 350 million tokens in English. To obtain dependency bigrams, we use the Bohnet parsers (Bohnet, 2010) to parse both the Spanish and English version of the corpus. 4.2 Systems Th</context>
<context position="17047" citStr="Koehn, 2005" startWordPosition="2733" endWordPosition="2734">he Adjacent system from 4.2% to 24.6%. In the end, with 100 million tokens, the accuracy of the DepType system rises to 27.0%. The accuracy is even higher (41%), when evaluated against the top 5000 frequent word types only. 5 Improving Machine Translation with Decipherment In this section, we demonstrate how to use a translation lexicon learned by deciphering large amounts of in-domain (news) monolingual data to improve a phrase-based machine translation system trained with limited out-of-domain (politics) parallel data. 5.1 Data We use approximately one million tokens of the Europarl corpus (Koehn, 2005) as our small out-ofdomain parallel training data and Gigaword as our large in-domain monolingual training data to build language models and a new translation lexicon to improve a phrase-based MT baseline system. For tuning and testing, we use the development data 1672 Parallel Spanish English Europarl 1.1 million 1.0 million Tune-2008 52.6k 49.8k Test-2009 68.1k 65.6k Test-2010 65.5k 61.9k Test-2011 79.4k 74.7k Non Parallel Spanish English Gigaword 894 million 940 million Table 3: Size of training, tuning, and testing data in number of tokens from the NAACL 2012 workshop on statistical machin</context>
</contexts>
<marker>Koehn, 2005</marker>
<rawString>Philipp Koehn. 2005. Europarl: a parallel corpus for statistical machine translation. In In Proceedings of the Tenth Machine Translation Summit, Phuket, Thailand. Asia-Pacific Association for Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radford Neal</author>
</authors>
<title>Slice sampling.</title>
<date>2000</date>
<journal>Annals of Statistics,</journal>
<volume>31</volume>
<contexts>
<context position="7108" citStr="Neal, 2000" startWordPosition="1136" endWordPosition="1137"> (right) extracted from the same Spanish text Pbayes(fi|ei) = α + count(ei) where P0 is a base distribution, and α is a parameter that controls how much we trust P0. count(fi, ei) and count(ei) record the number of times fi, ei and ei appear in previously generated samples respectively. At the end of sampling, P(fi|ei) is estimated by: count(fi, ei) P(fi|ei) = count(ei) However, Bayesian decipherment is still very slow with Gibbs sampling (Geman and Geman, 1987), as each sampling step requires considering Ve possibilities. Dou and Knight (2012) solve the problem by introducing slice sampling (Neal, 2000) to Bayesian decipherment. 3 From Adjacent Bigrams to Dependency Bigrams A major limitation of work by Dou and Knight (2012) is their monotonic generative story for deciphering adjacent bigrams. While the generation process works well for deciphering similar languages (e.g. Spanish and French) without considering reordering, it does not work well for languages that are more different in grammar and word order (e.g. Spanish and English). In this section, we first look at why adjacent bigrams are bad for decipherment. Then we describe how to use syntax to solve the problem. The left column in Ta</context>
</contexts>
<marker>Neal, 2000</marker>
<rawString>Radford Neal. 2000. Slice sampling. Annals of Statistics, 31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malte Nuhn</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Deciphering foreign language by combining language models and context vectors.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association</booktitle>
<contexts>
<context position="4293" citStr="Nuhn et al., 2012" startWordPosition="665" endWordPosition="668"> a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a translation lexicon that produces a good decipherment. In an effort to build a MT system without a parallel corpus, Ravi and Knight (2011) view Spanish as a cipher for English and apply Bayesian learning to directly decipher Spanish into English. Unfortunately, their approach can only work on small data with limited vocabulary. Dou and Knight (2012) propose two techniques to make Bayesian decipherment scalable. First, unlike Ravi and Knight (2011), who decipher whole sentences, Dou and Knight (2012) decipher bigrams. Reduci</context>
</contexts>
<marker>Nuhn, Mauser, Ney, 2012</marker>
<rawString>Malte Nuhn, Arne Mauser, and Hermann Ney. 2012. Deciphering foreign language by combining language models and context vectors. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.</journal>
<contexts>
<context position="15427" citStr="Och and Ney, 2003" startWordPosition="2471" endWordPosition="2474">panish texts as our test data. The data contains 37,505 tokens and 6556 word types. We use type accuracy as our evaluation metric: Given a word type f in Spanish, we find a translation pair (f, e) with the highest average P(e|f) from the translation table learned through decipherment. If the translation pair (f, e) can also be found in a gold translation lexicon Tgold, we treat the word type f as correctly deciphered. Let |C |be the number of word types correctly deciphered, and |V |be the total number of word types evaluated. We define type accuracy as ICI |V |. To create Tgold, we use GIZA (Och and Ney, 2003) to align a small amount of Spanish-English parallel text (1 million tokens for each language), and use the lexicon derived from the alignment as our gold translation lexicon. Tgold contains a subset of 4408 types seen in the test data, among which, 2878 are also top 5000 frequent word types. 4.5 Results During decipherment, we gradually increase the size of Spanish texts and compare the learning curves of three deciphering systems in Figure 2. Figure 2: Learning curves for three decipherment systems. Compared with Adjacent (previous state of the art), systems that use dependency bigrams impro</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="18610" citStr="Och, 2003" startWordPosition="2994" endWordPosition="2995">PBMT, using Moses (Koehn et al., 2007). PBMT has 3 models: a translation model, a distortion model, and a language model. We build a 5- gram language model using the AFP section of the English Gigaword. We train the other models using the Europarl corpus. By default, Moses uses the following 8 features to score a candidate translation: • direct and inverse translation probabilities • direct and inverse lexical weighting • a language model score • a distortion score • phrase penalty • word penalty The 8 features have weights adjusted on the tuning data using minimum error rate training (MERT) (Och, 2003). PBMT has a phrase table Tphrase. During decoding, Moses copies out-of-vocabulary (OOV) words, which can not be found in Tphrase, directly to output. In the following sections, we describe how to use a translation lexicon learned from large amounts of non parallel data to improve translation of OOV words, as well as words observed in Tphrase. 5.2.2 Decipherment for Machine Translation To achieve better decipherment, we: • Increase the size of Spanish ciphertext from 100 million tokens to 894 million tokens. • Keep top 50k instead of top 5k most frequent word types of the ciphertext. • Instead</context>
<context position="22206" citStr="Och, 2003" startWordPosition="3614" endWordPosition="3615">d English share many common words. To avoid over trusting Tdecipher, we add a new translation pair (f, f) for each source word f in Tdecipher if the translation pair (f, f) is not originally in Tdecipher. For each newly added translation pair, both of its log translation probabilities are set to 0. To distinguish the added translation pairs from the others learned through decipherment, we add a binary feature 0 to each translation pair in Tdecipher. The final version of Tdecipher has three feature scores: P(e|f), P(f|e), and 0. Finally, we tune weights of the features in Tdecipher using MERT (Och, 2003) on the tuning set. 5.2.5 A Combined Approach In the end, we build a system Decipher-COMB, which uses Tdecipher to improve translation of both observed and OOV words with methods described in sections 5.2.3 and 5.2.4. 5.3 Results We tune each system three times with MERT and choose the best weights based on BLEU scores on tuning set. Table 4 shows that the translation lexicon learned from decipherment helps achieve higher BLEU scores across tuning and testing sets. DecipherOBSV improves BLEU scores by as much as 1.2 points. We analyze the results and find the gain mainly comes from two parts. </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Identifying word translations in non-parallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd annual meeting on Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="3746" citStr="Rapp, 1995" startWordPosition="581" endWordPosition="582">rom large amounts of non parallel data. • We show that decipherment is able to find correct translations for OOV words. • We use a translation lexicon learned by deciphering large amounts of non parallel data to improve a phrase-based MT system trained with limited amounts of parallel data. In experiments, we observe 1.2 to 1.8 BLEU gains across three different test sets. 2 Previous Work Motivated by the idea that a translation lexicon induced from non parallel data can be applied to MT, a variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for ano</context>
</contexts>
<marker>Rapp, 1995</marker>
<rawString>Reinhard Rapp. 1995. Identifying word translations in non-parallel texts. In Proceedings of the 33rd annual meeting on Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Deciphering foreign language.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<contexts>
<context position="1375" citStr="Ravi and Knight, 2011" startWordPosition="199" endWordPosition="202">echniques to learn translation rules from large amounts of parallel data. However, parallel data is limited for many language pairs and domains. In general, it is easier to obtain non parallel data. The ability to build a machine translation system using monolingual data could alleviate problems caused by insufficient parallel data. Towards building a machine translation system without a parallel corpus, Klementiev et al. (2012) use non parallel data to estimate parameters for a large scale MT system. Other work tries to learn full MT systems using only non parallel data through decipherment (Ravi and Knight, 2011; Ravi, 2013). However, the performance of such systems is poor compared with those trained with parallel data. Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel corpora with non parallel Figure 1: Improving machine translation with decipherment (Grey boxes represent new data and process). Mono: monolingual; LM: language model; LEX: translation lexicon; TM: translation model. data. Dou and Knight (2012) successfully apply decipherment to learn a domain specific translation lexicon from monolingual data to improve out-ofdomain </context>
<context position="4251" citStr="Ravi and Knight, 2011" startWordPosition="657" endWordPosition="660"> variety of prior research has tried to build a translation lexicon from non parallel or comparable data (Rapp, 1995; Fung and Yee, 1998; Koehn and Knight, 2002; Haghighi et al., 2008; Garera et al., 2009; Bergsma and Van Durme, 2011; Daum´e and Jagarlamudi, 2011; Irvine and Callison-Burch, 2013b; Irvine and Callison-Burch, 2013a). Although previous work is able to build a translation lexicon without parallel data, little has used the lexicon to improve machine translation. There has been increasing interest in learning translation lexicons from non parallel data with decipherment techniques (Ravi and Knight, 2011; Dou and Knight, 2012; Nuhn et al., 2012). Decipherment views one language as a cipher for another and learns a translation lexicon that produces a good decipherment. In an effort to build a MT system without a parallel corpus, Ravi and Knight (2011) view Spanish as a cipher for English and apply Bayesian learning to directly decipher Spanish into English. Unfortunately, their approach can only work on small data with limited vocabulary. Dou and Knight (2012) propose two techniques to make Bayesian decipherment scalable. First, unlike Ravi and Knight (2011), who decipher whole sentences, Dou </context>
<context position="5900" citStr="Ravi and Knight (2011)" startWordPosition="942" endWordPosition="945">e2 with f2 with probability P(f1|e1) · P(f2|e2). The probability of any cipher bigram F is: 2 P(F) = E P(e1e2) H P(fi|ei) e1e2 i=1 Given a corpus of N cipher bigrams F1...FN, the probability of the corpus is: P(corpus) = Given a plaintext bigram language model, the goal is to manipulate P(f|e) to maximize P(corpus). Theoretically, one can directly apply EM to solve the problem (Knight et al., 2006). However, EM has time complexity O(N · Ve2) and space complexity O(Vf · Ve), where Vf, Ve are the sizes of ciphertext and plaintext vocabularies respectively, and N is the number of cipher bigrams. Ravi and Knight (2011) apply Bayesian learning to reduce the space complexity. Instead of estimating probabilities P(f|e), Bayesian learning tries to draw samples from plaintext sequences given ciphertext bigrams. During sampling, the probability of any possible plaintext sample e1e2 is given as: 2 Psample(e1e2) = P(e1e2) H Pbayes(fi|ei) i=1 N H j=1 P(Fj) 1669 misi´on de naciones unidas en oriente medio misi´on de misi´on naciones de naciones naciones unidas naciones unidas misi´on en unidas en en oriente en oriente oriente medio oriente medio Table 1: Comparison of adjacent bigrams (left) and dependency bigrams (r</context>
</contexts>
<marker>Ravi, Knight, 2011</marker>
<rawString>Sujith Ravi and Kevin Knight. 2011. Deciphering foreign language. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
</authors>
<title>Scalable decipherment for machine translation via hash sampling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1388" citStr="Ravi, 2013" startWordPosition="203" endWordPosition="204">slation rules from large amounts of parallel data. However, parallel data is limited for many language pairs and domains. In general, it is easier to obtain non parallel data. The ability to build a machine translation system using monolingual data could alleviate problems caused by insufficient parallel data. Towards building a machine translation system without a parallel corpus, Klementiev et al. (2012) use non parallel data to estimate parameters for a large scale MT system. Other work tries to learn full MT systems using only non parallel data through decipherment (Ravi and Knight, 2011; Ravi, 2013). However, the performance of such systems is poor compared with those trained with parallel data. Given that we often have some parallel data, it is more practical to improve a translation system trained on parallel corpora with non parallel Figure 1: Improving machine translation with decipherment (Grey boxes represent new data and process). Mono: monolingual; LM: language model; LEX: translation lexicon; TM: translation model. data. Dou and Knight (2012) successfully apply decipherment to learn a domain specific translation lexicon from monolingual data to improve out-ofdomain machine trans</context>
</contexts>
<marker>Ravi, 2013</marker>
<rawString>Sujith Ravi. 2013. Scalable decipherment for machine translation via hash sampling. In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing.</booktitle>
<contexts>
<context position="13267" citStr="Stolcke, 2002" startWordPosition="2109" endWordPosition="2110"> DepType, is built using both dependent bigrams and their dependency types. We first extract dependency bigrams for both languages, then group them based on their dependency types. As both parsers treat noun phrases dependent on “del”, “de”, and “of” as prepositional phrases, we choose to divide the dependency bigrams into 3 groups and list them in Table 2. A separate language model is built for each group of English dependency bigrams and used to decipher the group of Spanish dependency bigrams with same dependency type. For all the systems, language models are built using the SRILM toolkit (Stolcke, 2002). For the Adjacent system, we use Good-Turing smoothing. For the other systems, we use a mix of Witten-Bell and Good-Turing smoothing. 4.3 Sampling Procedure In experiments, we find that the iterative sampling method described by Dou and Knight (2012) helps improve deciphering accuracy. We also find that combining results from different decipherments helps find more correct translations at each iteration. Thus, instead of using a single sampling process, we use 10 different sampling processes at each iteration. The details of the new sampling procedure are provided here: • Extract dependency b</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an extensible language modeling toolkit. In Proceedings of the International Conference on Spoken Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>