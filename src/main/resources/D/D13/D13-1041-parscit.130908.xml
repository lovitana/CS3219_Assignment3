<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000010">
<title confidence="0.9641">
Efficient Collective Entity Linking with Stacking
</title>
<author confidence="0.952111">
Zhengyan Het Shujie Liut Yang Songt Mu Lit Ming Zhou$ Houfeng Wangt*
</author>
<affiliation confidence="0.9710385">
t Key Laboratory of Computational Linguistics (Peking University) Ministry of Education,China
t Microsoft Research Asia
</affiliation>
<email confidence="0.9639695">
hezhengyan.hit@gmail.com {shujliu,muli,mingzhou}@microsoft.com
songyangmagic@gmail.com wanghf@pku.edu.cn
</email>
<sectionHeader confidence="0.998533" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999572545454545">
Entity disambiguation works by linking am-
biguous mentions in text to their correspond-
ing real-world entities in knowledge base. Re-
cent collective disambiguation methods en-
force coherence among contextual decisions
at the cost of non-trivial inference processes.
We propose a fast collective disambiguation
approach based on stacking. First, we train a
local predictor go with learning to rank as base
learner, to generate initial ranking list of can-
didates. Second, top k candidates of related
instances are searched for constructing expres-
sive global coherence features. A global pre-
dictor gl is trained in the augmented feature
space and stacking is employed to tackle the
train/test mismatch problem. The proposed
method is fast and easy to implement. Exper-
iments show its effectiveness over various al-
gorithms on several public datasets. By learn-
ing a rich semantic relatedness measure be-
tween entity categories and context document,
performance is further improved.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.989930272727273">
When extracting knowledge from natural language
text into a machine readable format, ambiguous
names must be resolved in order to tell which real-
world entity the name refers to. The task of linking
names to knowledge base is known as entity linking
or disambiguation (Ji et al., 2011). The resulting text
is populated with semantic rich links to knowledge
base like Wikipedia, and ready for various down-
stream NLP applications.
&amp;quot;Corresponding author
Previous researches have proposed several kinds
of effective approaches for this problem. Learning
to rank (L2R) approaches use hand-crafted features
f(d, e) to describe the similarity or dissimilarity be-
tween contextual document d and entity definition
e. L2R approaches are very flexible and expres-
sive. Features like name matching, context similar-
ity (Li et al., 2009; Zheng et al., 2010; Lehmann et
al., 2010) and category context correlation (Bunescu
and Pasca, 2006) can be incorporated with ease.
Nevertheless, decisions are made independently and
inconsistent results are found from time to time.
Collective approaches utilize dependencies be-
tween different decisions and resolve all ambiguous
mentions within the same context simultaneously
(Han et al., 2011; Hoffart et al., 2011; Kulkarni
et al., 2009; Ratinov et al., 2011). Collective ap-
proaches can improve performance when local ev-
idence is not confident enough. They often utilize
semantic relations across different mentions, and is
why they are called global approaches, while L2R
methods fall into local approaches (Ratinov et al.,
2011). However, collective inference processes are
often expensive and involve an exponential search
space.
We propose a collective entity linking method
based on stacking. Stacked generalization (Wolpert,
1992) is a powerful meta learning algorithm that
uses two levels of learners. The predictions of the
first learner are taken as augmented features for the
second learner. The nice property of stacking is that
it does not restrict the form of the base learner. In
this paper, our base learner, an L2R ranker, is first
employed to generate a ranking list of candidates.
</bodyText>
<page confidence="0.985801">
426
</page>
<note confidence="0.7335085">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 426–435,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.99987071875">
At the next level, we search for semantic coherent
entities from the top k candidates of neighboring
mentions. The second learner is trained on the aug-
mented feature space to enforce semantic coherence.
Stacking is employed to handle train/test mismatch
problem. Compared with existing collective meth-
ods, the inference process of our method is much
faster because of the simple form of its base learner.
Wikipedians annotate each entity with categories
which provide another source of valuable seman-
tic information. (Bunescu and Pasca, 2006) pro-
pose to generalize beyond context-entity correla-
tion s(d, e) with word-category correlation s(w, c).
However, this method works at word level, and does
not scale well to large number of categories. We
explore a representation learning technique to learn
the category-context association in latent semantic
space, which scales much better to large knowledge
base.
Our contributions are as follows: (1) We pro-
pose a fast and accurate stacking-based collective
entity linking method, which combines the benefits
of both coherence modeling of collective approaches
and expressivity of L2R methods. We show an
effective usage of ranking list as global features,
which is a key improvement for the global predictor.
(2) To overcome problems of scalability and shal-
low word-level comparison, we learn the category-
context correlation with recent advances of repre-
sentation learning, and show that this extra seman-
tic information indeed helps improve entity linking
performance.
</bodyText>
<sectionHeader confidence="0.99989" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999938593220339">
Most popular entity linking systems use the L2R
framework (Bunescu and Pasca, 2006; Li et al.,
2009; Zheng et al., 2010; Lehmann et al., 2010).
Its discriminative nature gives the model enough
flexibility and expressivity. It can include any fea-
tures that describe the similarity or dissimilarity of
context d and candidate entity e. They often per-
form well even on small training set, with carefully-
designed features. This category falls into the local
approach as the decision processes for each mention
are made independently (Ratinov et al., 2011).
(Cucerzan, 2007) first suggests to optimize an ob-
jective function that is similar to the collective ap-
proach. However, the author adopts an approxi-
mation method because of the large search space
(which is O(n&apos;) for a document with m mentions,
each with n candidates). Various other methods
like integer linear programming (Kulkarni et al.,
2009), personalized PageRank (Han et al., 2011) and
greedy graph cutting (Hoffart et al., 2011) have been
explored in literature. Our method without stacking
resembles the method of (Ratinov et al., 2011) in
that they use the predictions of a local ranker to gen-
erate features for global ranker. The differences are
that we use stacking to train the local ranker to han-
dle the train/test mismatch problem and top k candi-
dates to generate features for the global ranker.
Stacked generalization (Wolpert, 1992) is a meta
learning algorithm that uses multiple learners out-
puts to augment the feature space of subsequent
learners. It utilizes a cross-validation strategy to ad-
dress the train set / testset label mismatch problem.
Various applications of stacking in NLP have been
proposed, such as collective document classification
(Kou and Cohen, 2007), stacked dependency parsing
(Martins et al., 2008) and joint Chinese word seg-
mentation and part-of-speech tagging (Sun, 2011).
(Kou and Cohen, 2007) propose stacked graphical
learning which captures dependencies between data
with relational template. Our method is inspired by
their approach. The difference is our base learner is
an L2R model. We search related entity candidates
in a large semantic relatedness graph, based on the
assumption that true candidates are often semanti-
cally correlated while false ones scattered around.
Wikipedians annotate entries in Wikipedia with
category network. This valuable information gener-
alizes entity-context correlation to category-context
correlation. (Bunescu and Pasca, 2006) utilize
category-word as features in their ranking model.
(Kataria et al., 2011) employ a hierarchical topic
model where each inner node in the hierarchy is a
category. Both approaches must rely on pruned cate-
gories because the large number of noisy categories.
We try to address this problem with recent advances
of representation learning (Bai et al., 2009), which
learns the relatedness of category and context in la-
tent continuous space. This method scales well to
potentially large knowledge base.
</bodyText>
<page confidence="0.998995">
427
</page>
<sectionHeader confidence="0.993321" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.999758">
In this section, we first introduce our base learner
and local features used; next, the stacking train-
ing strategy is given, followed by an explana-
tion of our global coherence model with aug-
mented feature space; finally we explain how to
learn category-context correlation with representa-
tion learning technique.
</bodyText>
<subsectionHeader confidence="0.999992">
3.1 Base learner and local predictor g0
</subsectionHeader>
<bodyText confidence="0.999001777777778">
Entity linking is formalized as follows: given
an ambiguous name mention m with its con-
textual document d, a list of candidate entities
e1, e2, ... , en(m) E C(m) is generated for m, our
predictor g will generate a ranking score g(ei) for
each candidate ei. The ranking score will be used
to construct augmented features for the next level
learner, or used by our end system to select the an-
swer:
</bodyText>
<equation confidence="0.9977995">
e� = arg max g(e) (1)
eEC(m)
</equation>
<bodyText confidence="0.985145">
In an L2R framework, the model is often defined
as a linear combination of features. Here, our fea-
tures ⃗f(d, e) are derived from document d and can-
didate e. The model is defined as g(e) = w⃗ ⃗f(d, e).
In our problem, we are given a list of training data
D = {(di, ei)}. We want to optimize the parameter
⃗w, such that the correct entity has a higher score over
negative ones. This is done via a preference learning
technique SV Mrank, first introduced by (Joachims,
2002). The following margin based loss is mini-
mized w.r.t ⃗w:
</bodyText>
<equation confidence="0.99998575">
L = �l l⃗wl l2 + C ξd,e′ (2)
1 �
s.t. ⃗w(⃗f(d, e) − ⃗f(d, e′)) &gt; 1 − ξd,e′ (3)
ξd,e′ &gt; 0 (4)
</equation>
<bodyText confidence="0.9863485">
where C is a trade-off between training error and
margin size; ξ is slacking variable and loops over
all query documents d and negative candidates e′ E
C(m) − {e}.
This model is expressive enough to include any
form of features describing the similarity and dis-
similarity of d and e. We only include some typical
features seen in literature. The inclusion of these
features is not meant to be exhaustive. Our purpose
is to build a moderate model in which some of the
</bodyText>
<listItem confidence="0.9767144">
Surface matching:
1. mention string m exactly matches candidate
e, i.e. m = e
2. neither m is a substring of e nor e is a sub-
string of m
3. m =� e and m is a substring of e
4. m =� e and e is a substring of m
5. m =� e and m is a redirect pointing to e in
Wikipedia
6. m =� e and e starts with m
7. m =� e and e ends with m
Context matching:
1. cosine similarity of TF-IDF score between
context and entire Wikipedia page of candidate
2. cosine similarity of TF-IDF score between
context and introduction of Wikipedia page
3. jaccard distance between context and entire
Wikipedia page of candidate
4. jaccard distance between context and intro-
duction of Wikipedia page
</listItem>
<bodyText confidence="0.4417974">
Popularity or prominence feature:
percentage of Wikipedia hyperlinks pointing to
e given mention m, i.e. P(e|m)
Category-context coherence model:
cat0 and cat1 (details in Section 3.4)
</bodyText>
<tableCaption confidence="0.960179">
Table 1: Features for local predictor go.
</tableCaption>
<bodyText confidence="0.999806428571429">
useful features like string matching and entity pop-
ularity cannot be easily expressed by collective ap-
proaches like (Hoffart et al., 2011; Han et al., 2011).
The features for level 0 predictor g0 are described
in Table 1. The reader can consult (Li et al., 2009;
Zheng et al., 2010; Lehmann et al., 2010) for further
reference.
</bodyText>
<subsectionHeader confidence="0.998772">
3.2 Stacking training for global predictor g1
</subsectionHeader>
<bodyText confidence="0.9131955">
Stacked generalization (Wolpert, 1992) is a meta
learning algorithm that stacks two “levels” of pre-
dictors. Level 0 includes one or more predictors
h(0)
</bodyText>
<equation confidence="0.99611">
1 , h(0)
2 , ... , h(0)
K : Rd —* R, each one is trained on
</equation>
<bodyText confidence="0.959644833333333">
the original d-dimensional feature space. The level
1 predictor h(1) : Rd+K —* R is trained in the aug-
mented (d+K)-dimensional feature space, in which
predictions at level 0 are taken as extra features in
h(1).
(Kou and Cohen, 2007) proposed stacked graphi-
</bodyText>
<page confidence="0.994801">
428
</page>
<bodyText confidence="0.999656125">
cal learning for learning and inference on relational
data. In stacked graphical learning, dependencies
among data are captured by relational template, with
which one searches for related instances of the cur-
rent instance. The augmented feature space does
not necessarily to be d + K. Instead, one can con-
struct any declarative feature with the original data
and predictions of related instances. For instance,
in collective document classification (Kou and Co-
hen, 2007) employ relational template to extract
documents that link to this document, then apply a
COUNT aggregator over each category on neighbor-
ing documents as level 1 features.
In our entity linking task, we use a single predic-
tor g0 trained with local features at level 0. Com-
pared with (Kou and Cohen, 2007), both g0 and g1
are L2R models rather than classifier. At level 1, for
each document-candidate entity pair, we use the re-
lational template N(x) to find related entities for en-
tity x, and construct global features with some func-
tion G({g0(n)|n ∈ N(x)}) (details in Sec. 3.3).
The global predictor g1 receives as input the origi-
nal features plus G.
One problem is that if we use g0 trained on the en-
tire training set to predict related instances in train-
ing set, the accuracy can be somehow different (typ-
ically lower) for future unseen data. g1 with this pre-
diction as input doesn’t generalize well to test data.
This is known as train/test mismatch problem. To
mimic test time behavior, training is performed in a
cross-validation-like way. Let D be the entire train-
ing set:
</bodyText>
<listItem confidence="0.912458090909091">
1. Split D into L partitions {D1, ... , DL}
2. For each split Di:
2.1 Train an instance of g0 on D − Di
2.2 Predict all related instances in Di with this
predictor g0
2.3 Augment feature space for x ∈ Di, with G
applied on predictions of N(x)
3. Train level 0 predictor g0 on entire D, for ex-
panding feature space for test data
4. Train level 1 predictor g1 on entire D, in the
augmented feature space.
</listItem>
<bodyText confidence="0.984369">
In the next subsection, we will describe how to
construct global features from the predictions of g0
on neighbors N(x) with G.
</bodyText>
<subsectionHeader confidence="0.980993">
3.3 Enforcing coherence with global features G
</subsectionHeader>
<bodyText confidence="0.998701523809524">
If one wants to identify the correct entity for an am-
biguous name, he would possibly look for related
entities in its surrounding context. However, sur-
rounding entities can also exhibit some degree of
ambiguity. In ideal cases, most true candidates are
inter-connected with semantic links while negative
candidates are scattered around (Fig. 1). Thus, we
ask the following question: Is there any highly rele-
vant entity to this candidate in context? Or, is there
any mention with highly relevant entity to this can-
didate in the top k ranking list of this mention? And
how many those mentions are? The reason to look
up top k candidates is to improve recall. g0 may not
perfectly rank related entity at the first place, e.g.
“Mitt Romney” in Figure 1.
Assume the ambiguous mention set is M. For
each mention mi ∈ M, we rank each entity ei,j ∈
C(mi) by its score g0(ei,j). Denote its rank as
Rank(ei,j). For each entity e in the candidate set
E _ {ei,j|∀ei,j ∈ C(mi), ∀mi ∈ M}, we search
related instances for e as follows:
</bodyText>
<listItem confidence="0.956479166666667">
1. search in E for entities with semantic related-
ness above a threshold ({0.1,0.3,0.5,0.7,0.9});
2. select those entities in step (1) with Rank(e)
less than or equal to k (k ∈ {1, 3, 5});
3. map entities in step (2) to unique set of men-
tions U, excluding current m, i.e. e ∈ C(m).
</listItem>
<bodyText confidence="0.910756909090909">
This process is relatively fast. It only involves a
sparse matrix slicing operation on the large pre-
computed semantic relatedness matrix in step (1),
and logical operation in step (2,3). The following
features are fired concerning the unique set U:
- if U is empty;
- if U is not empty;
- if the percentage |U|�|M |is above a threshold
(e.g. 0.3).
The above process generates a total of 45 (5 × 3 × 3)
global features.
</bodyText>
<page confidence="0.996188">
429
</page>
<table confidence="0.612414125">
[[Obama|Barack Obama]] received national attention during his campaign ... with his vectory in the March
[[Democratic Party|Democratic Party (United States)]] primary ... He was re-elected president in November
2012, defeating [[Republican|Republican Party (United States)]] nominee [[Romney|Mitt Romney]]
Figure 1: Semantic links for collective entity linking. Annotation [[mention|entity]] follows Wikipedia conventions.
Democratic Party (Italy)
Democratic Party (Serbia)
Obama, Fukui
Obama, Nagasaki
... ... ... ...
Barack Obama Democratic Party (United States)
Republican Party (United States)
Republican Party of Minnesota
Republicanism
Romney, West Virginia
HMS Romney (1694)
Mitt Romney
</table>
<bodyText confidence="0.93320625">
Finally, the semantic relatedness measure of two
entities ei,ej is defined as the common in-links of ei
and ej in Wikipedia (Milne and Witten, 2008; Han
et al., 2011):
</bodyText>
<equation confidence="0.708876333333333">
log(max(|A|, |B|)) − log(|A ∩ B|)
�R(ei, ej) = 1−log(|W|) − log(min(|A|, |B|))
(5)
</equation>
<bodyText confidence="0.999805857142857">
where A and B are the set of in-links for entity ei
and ej respectively, and W is the set of all Wikipedia
pages.
Our method is a trade-off between exact collec-
tive inference and approximating related instance
with top ranked entities produced by go. Most
collective approaches take all ambiguous mentions
into consideration and disambiguate them simulta-
neously, resulting in difficulty when inference in
large search space (Kulkarni et al., 2009; Hoffart
et al., 2011). Others resolve to some kinds of ap-
proximation. (Cucerzan, 2007) construct features as
the average of all candidates for one mention, in-
troducing considerable noise. (Ratinov et al., 2011)
also employ a two level architecture but only take
top 1 prediction for features. This most resembles
our approach, except we use stacking to tackle the
train/test mismatch problem, and construct different
set of features from top k candidates predicted by
go. We will show in our experiments that this indeed
helps boost performance.
</bodyText>
<subsectionHeader confidence="0.815914">
3.4 Learning category-context coherence
model cat
</subsectionHeader>
<bodyText confidence="0.987743078947369">
Entities in Wikipedia are annotated with rich se-
mantic structures. Category network provides us
with another valuable information for entity link-
ing. Take the mention “Romney” as an exam-
ple, one candidate “Mitt Romney” with category
“Republican party presidential nominee” co-occurs
frequently with context like “election” and “cam-
paign”, while another candidate “Milton Romney”
with category “Utah Utes football players” is fre-
quently observed with context like “quarterback”
and “backfield”. The category network forms a di-
rected acyclic graph (DAG). Some entities can share
category through the network, e.g. “Barack Obama”
with category “Democratic Party presidential nom-
inees” shares the category “United States presiden-
tial candidates by party” with “Mitt Romney” when
travelling two levels up the network.
(Bunescu and Pasca, 2006) propose to learn the
category-context correlation at word level through
category-word pair features. This method creates
sparsity problem and does not scale well because
the number of features grows linearly with both the
number of categories and the vocabulary size. More-
over, the category network is somewhat noisy, e.g.
travelling up four levels of the hierarchy can result
in over ten thousand categories, with many irrelevant
ones.
Rather than learning the correlation at word level,
we explore a representation learning method that
learns category-context correlation in the latent se-
mantic space. Supervised Semantic Indexing (SSI)
(Bai et al., 2009) is trained on query-document pairs
to predict their degree of matching. The compar-
ison is performed in the latent semantic space, so
that synonymy and polysemy are implicitly handled
by its inner mechanism. The score function between
query q and document d is defined as:
f(q, d) = qT Wd (6)
</bodyText>
<page confidence="0.982614">
430
</page>
<bodyText confidence="0.999808428571429">
where W is learned with supervision like click-
through data.
Given training data {(qi, di)}, training is done by
randomly sampling a negative target d−. The model
optimizes W such that f(q, d+) &gt; f(q, d−). Thus,
the training objective is to minimize the following
margin-based loss function:
</bodyText>
<equation confidence="0.99057">
� max(0,1 − f(q, d+) + f(q, d−)) (7)
q,d+,d−
</equation>
<bodyText confidence="0.9892958">
which is also known as contrastive estimation
(Smith and Eisner, 2005).
W can become very large and inefficient when we
have a big vocabulary size. This is addressed by re-
placing W with its low rank approximation:
</bodyText>
<equation confidence="0.999539">
W = UT V + I (8)
</equation>
<bodyText confidence="0.9910135">
here, the identity term I is a trade-off between the
latent space model and a vector space model. The
gradient step is performed with Stochastic Gradient
Descent (SGD):
</bodyText>
<equation confidence="0.8927865">
U &lt;--U + AV (d+ − d−)qT,
if 1 − f(q, d+) + f(q, d−) &gt; 0 (9)
V &lt;--V + AUq(d+ − d−)T,
if 1 − f(q, d+) + f(q, d−) &gt; 0. (10)
</equation>
<bodyText confidence="0.9998731875">
where A is the learning rate.
The query and document are not necessary real
query and document. In our case, we treat our
problem as: given the occurring context of an en-
tity, retrieving categories corresponding to this en-
tity. Thus, we use context as query q and the cat-
egories of this candidate entity as d. We also treat
the definition page of an entity as its context, and
first train the model with definition pages, because
definition pages exhibit more focused topic. This
considerably accelerates the training process. To
reduce noise, We input the categories directly con-
nected with one entity as a word vector. The input
can be a TF-IDF vector or binary vector. We denote
model trained with normalized TF-IDF and with bi-
nary input as cat0 and cats respectively.
</bodyText>
<sectionHeader confidence="0.999731" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.91346">
4.1 Datasets
</subsectionHeader>
<bodyText confidence="0.9999740625">
Previous researches have used diverse datasets for
evaluation, which makes it hard for comparison
with others’ approaches. TAC-KBP has several
years of data for evaluating entity linking system,
but is not well suited for evaluating collective ap-
proaches. Recently, (Hoffart et al., 2011) anno-
tated a clean and much larger dataset AIDA 1 for
collective approaches evaluation based on CoNLL
2003 NER dataset. (Ratinov et al., 2011) also re-
fined previous work and contribute four publicly
available datasets 2. Thanks to their great works,
we have enough data to evaluate against. Accord-
ing to the setting of (Hoffart et al., 2011), we
split the AIDA dataset for train/development/test
with 946/216/231 documents. We train a separate
model on the Wikipedia training set for evaluating
ACE/QUAINT/WIKI dataset (Ratinov et al., 2011).
Table 2 gives a brief overview of the datasets used.
For knowledge base, we use the Wikipedia XML
dump 3 to extract over 3.3 million entities. We use
annotation from Wikipedia to build a name dictio-
nary from mention string m to entity e for can-
didate generation, including redirects, disambigua-
tion pages and hyperlinks, follows the approach of
(Cucerzan, 2007). For candidate generation, we
keep the top 30 candidates by popularity (Tbl. 1).
Note that our name dictionary is different from
(Ratinov et al., 2011) and has a much higher recall.
Since (Ratinov et al., 2011) evaluate on “solvable”
mentions and we have no way to recover those men-
tions, we re-implement their global features and the
final scores are not directly comparable to theirs.
</bodyText>
<subsectionHeader confidence="0.998528">
4.2 Methods under comparison
</subsectionHeader>
<bodyText confidence="0.999986636363636">
We compare our algorithm with several state-of-the-
art collective entity disambiguation systems. The
AIDA system proposed by (Hoffart et al., 2011) use
a greedy graph cutting algorithm that iteratively re-
move entities with low confidence scores. (Han et
al., 2011) employ personalized PageRank to prop-
agate evidence between different decisions. Both
algorithms use simple local features without dis-
criminative training. (Kulkarni et al., 2009) pro-
pose to use integer linear programming (ILP) for
inference. Except our re-implementation of Han’s
</bodyText>
<footnote confidence="0.999659">
1available at http://www.mpi-inf.mpg.de/yago-naga/aida/
2http://cogcomp.cs.illinois.edu/Data, we don’t find the
MSNBC dataset in the zip file.
3available at http://dumps.wikimedia.org/enwiki/, we use
the 20110405 xml dump.
</footnote>
<page confidence="0.994875">
431
</page>
<table confidence="0.999694571428571">
Dataset ndocs non- identified solvable
NIL
AIDA dev 216 4791 4791 4707
AIDA test 231 4485 4485 4411
ACE 36 257 238 209(185)
AQUAINT 50 727 697 668(588)
Wikipedia 40 928 918 854(843)
</table>
<tableCaption confidence="0.6171502">
Table 2: Number of mentions in each dataset. “identi-
fied” means the mention exists in our name dictionary
and “solvable” means the true entity are among the top 30
candidates by popularity. Number in parenthesis shows
the results of (Ratinov et al., 2011).
</tableCaption>
<bodyText confidence="0.976207578947369">
method, both AIDA and ILP solution are quite slow
at running time. The online demo of AIDA takes
over 10 sec to process one document with mod-
erate size, while the ILP solution takes around 2-
3 sec/doc. In contrast, our method takes only 0.3
sec/doc, and is easy to implement.
(Ratinov et al., 2011) also utilize a two layer
learner architecture. The difference is that their
method use top 1 candidate generated by local
learner for global feature generation , while we
search the top k candidates. Moreover, stacking is
used to tackle the train/test mismatch problem in
our model. We re-implement the global features of
(Ratinov et al., 2011) and use our local predictor
g0 for level 0 predictor. Note that we only imple-
ment their global features concerning common in-
links and inter-connection (totally 9 features) for fair
comparison because all other models don’t use com-
mon outgoing links for global coherence.
</bodyText>
<subsectionHeader confidence="0.999612">
4.3 Settings
</subsectionHeader>
<bodyText confidence="0.999816761904762">
We implement 5V Mrank with an adaptation of lin-
ear SVM in scikit-learn (which is a wrapper of Li-
blinear). The category-context coherence model is
implemented with Numpy configured with Open-
Blas library, and we train this model on the entire
Wikipedia hyperlink annotation. It takes about 1.5d
for one pass over the entire dataset. The learning
rate A is set to 1e-4 and training cost before update
is below 0.02.
Parameter tuning: there aren’t many parameters
to tune for both g0 and g1. The context document
window size is fixed as 100 for compatibility with
(Ratinov et al., 2011; Hoffart et al., 2011). The num-
ber of candidates is fixed to top 30 ranked by entity’s
popularity. Increase this value will generally boost
recall at the cost of lower precision.
We introduce the following default parameter for
global features in g1. The number of fold for stack-
ing is set to {1,5,10} (see Table 4, default is 10; 1
means no stacking, i.e. training g0 with all training
data and generating level 1 features for training data
directly with this g0). The number k for searching
neighboring entities with relational template is set
to {1,3,5,7} (e.g. in step 2 of Section 3.3 k = 5;
default is 5).
For category-context modeling, the vocabulary
sizes of context and category are set to top 10k and
6k unigrams by frequency. The latent dimension of
low rank approximation is set to 200.
Performance measures: For all non-NIL
queries, we evaluate performance with micro pre-
cision averaged over queries and macro precision
averaged over documents. Mean Reciprocal Rank
(MRR) is an information retrieval measure and is
�defined as Q i Q 1 , where ranki is the rank
ranki
of correct answer in response to query i. For
ACE/AQUAINT/WIKI we also give the accuracy of
“solvable” mentions, but this is not directly compa-
rable to (Ratinov et al., 2011). Our name dictionary
is different from theirs and ours has a higher recall
rate (Tbl. 2). Hence, the “solvable” set is different.
</bodyText>
<table confidence="0.939991666666667">
k recall k recall
1 78.56 6 96.31
2 89.59 7 97.04
3 93.01 8 97.37
4 94.97 9 97.62
5 95.78 10 97.81
</table>
<tableCaption confidence="0.999871">
Table 3: Top k recall for local predictor go.
</tableCaption>
<subsectionHeader confidence="0.995754">
4.4 Discussions
</subsectionHeader>
<bodyText confidence="0.999926428571429">
Table 4 shows the evaluation results on AIDA
dataset and Table 5 shows results on datasets
ACE/AQUAINT/WIKI.
Effect of cat:The first group in Table 4 shows
some baseline features for comparison. We can see
even if the categories only carry incomplete and
noisy information about an entity, it performs much
</bodyText>
<page confidence="0.998776">
432
</page>
<tableCaption confidence="0.9803795">
Table 4: Performance on AIDA dataset. Maximal value in each group are highlighted with bold font. top k means up
to k candidates are used for searching related instances with relational template.
</tableCaption>
<figure confidence="0.985650111111111">
Methods
cosine
jaccard
cat0
cat1
popularity
g0
g0+global(Ratinov)
g1+1fold
g1+5fold
g1+10fold
g1+top1
g1+top3
g1+top5
g1+top7
g0+cat
g1+cat
g1+cat+all context
</figure>
<table confidence="0.9967975">
(Hoffart et al., 2011)
(Shirakawa et al., 2011)
(Kulkarni et al., 2009)
(Han et al., 2011)
Devset Testset
micro macro MRR micro macro MRR
p@1 p@1 p@1 p@1
33.25 28.61 46.03 33.33 28.63 46.54
44.71 36.56 57.76 45.66 36.89 57.08
54.75 47.14 67.70 61.52 54.72 72.55
60.15 54.64 72.98 65.46 61.04 76.84
69.21 67.59 79.26 69.07 72.63 79.45
76.04 73.63 84.21 76.16 78.17 84.58
81.30 78.03 88.14 81.45 81.89 88.70
82.01 78.52 88.90 83.59 83.58 90.05
81.99 78.42 88.87 83.52 83.37 89.99
82.01 78.53 88.91 83.59 83.55 90.03
81.65 78.76 88.51 81.81 82.55 89.06
82.20 78.64 88.98 83.52 83.34 89.94
82.01 78.57 88.90 83.63 83.76 90.05
82.05 78.40 88.90 83.75 83.58 90.08
79.36 76.14 86.66 79.64 80.47 87.32
82.24 78.49 89.02 84.88 84.49 90.65
82.99 78.56 89.51 86.49 85.11 91.55
- - - 82.29 82.02 -
- - - 81.40 83.57 -
- - - 72.87 76.74 -
- - - 78.97 75.77 -
</table>
<bodyText confidence="0.994260694444444">
better than word level features. Group 5 in Table
4 shows cat information generally boosts perfor-
mance for both predictor g0 and g1.
Effect of stacking: Group 3 in Table 4 shows the
results with different fold in stacking training. 1 fold
means training g0 with all training data and directly
augment training data with this g0. Surprisingly, we
do not observe any substantial difference with vari-
ous fold size. We deduce it is possible the way we
fire global features with top k candidates that alle-
viates the problem of train/test mismatch when ex-
tending feature space for g1. Despite the ranking of
true entity can be lower in testset than in training
set, the semantic coherence information can still be
captured with searching over top k candidates.
Effect of top k global features: Group 4 in Table
4 shows the effect of k on g1 performance. Clearly,
increasing k generally improves precision and one
possible reason is the improvement in recall when
searching for related instances. Table 3 shows the
top k recall of local predictor g0. Further increasing
k does not show any improvement.
Our method benefits from such a searching strat-
egy, and consistently outperforms the global fea-
tures of (Ratinov et al., 2011). While their method
is a trade-off between expensive exact search over
all mentions and greedy assigning all mentions
with local predictor, we show this idea can be fur-
ther extended, somewhat like increasing the beam
search size without additional computational over-
head. The only exception is the ACE dataset, since
this dataset is so small, the difference translates to
only one mention. One may notice the improvement
on ACE/AQUAINT datasets is a little inconsistent.
These datasets are much smaller and the results only
differ within 4 mentions. Because these models are
</bodyText>
<page confidence="0.997834">
433
</page>
<table confidence="0.999862714285714">
Method micro macro MRR correct
p@1 p@1 / solv-
able
ACE
g0 77.43 81.30 79.03 95.22
Ratinov 77.43 80.70 78.81 95.22
g1+5fold 77.04 79.85 78.96 94.74
g0+cat 77.82 81.48 79.31 95.69
g1+cat 77.43 80.16 79.25 95.22
AQUAINT
g0 84.46 84.69 87.49 91.92
Ratinov 85.14 85.29 87.90 92.66
g1+5fold 85.83 85.55 88.27 93.41
g0+cat 85.01 85.00 87.89 92.51
g1+cat 85.28 85.14 88.23 92.81
Wikipedia test
g0 83.19 84.30 86.63 90.40
Ratinov 84.48 85.96 87.62 91.80
g1+5fold 84.81 86.29 88.13 92.15
g0+cat 84.38 86.13 87.51 91.69
g1+cat 85.45 87.16 88.31 92.86
</table>
<tableCaption confidence="0.999815">
Table 5: Evaluation on ACE/AQUAINT/WIKI datasets.
</tableCaption>
<bodyText confidence="0.998834285714286">
trained on Wikipedia, the annotation style can be
quite different.
Finally, as we analyze the development set of
AIDA, we discover that some location entities rely
on more distant information across the context, as
we increase the context to the entire contextual doc-
ument, we can gain extra performance boost.
</bodyText>
<subsectionHeader confidence="0.997606">
4.5 Error analysis
</subsectionHeader>
<bodyText confidence="0.9999795">
As we analyze the development set of AIDA, we find
some general problems with location names. Loca-
tion name generally is not part of the main topic
of one document. Thus, comparing context with
its definition is not realistic. Most of the time, we
can find some related location names in context; but
other times, it is not easily distinguished. For in-
stance, in “France beats Turkey in men’s football...”
France refers to “France national football team” but
our system links it to the country page “France” be-
cause it is more popular. This can be addressed by
modeling finer context (Sen, 2012) or local syntac-
tic pattern (Hoffart et al., 2011). In other cases,
our system misclassifies “New York City” for “New
York” and “Netherlands” for “Holland” and “Peo-
ple’s Republic of China” for “China”, because in
all these cases, the latter ones are the most popu-
lar in Wikipedia. It is even hard for us humans to
tell the difference based only on context or global
coherence.
</bodyText>
<sectionHeader confidence="0.995444" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9999865">
We propose a stacking based collective entity link-
ing method, which stacks a global predictor on top
of a local predictor to collect coherence information
from neighboring decisions. It is fast and easy to im-
plement. Our method trades off between inefficient
exact search and greedily assigning mention with lo-
cal predictor. It can be seen as searching related
entities with relational template in stacked graphi-
cal learning, with beam size k. Furthermore, we
adopt recent progress in representation learning to
learn category-context coherence model. It scales
better than existing approaches on large knowledge
base and performs comparison in the latent semantic
space. Combining these two techniques, our model
consistently outperforms all existing more sophisti-
cated collective approaches in our experiments.
</bodyText>
<sectionHeader confidence="0.992695" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.967825333333333">
This research was partly supported by Ma-
jor National Social Science Fund of China(No.
12&amp;ZD227),National High Technology Research
and Development Program of China (863 Program)
(No. 2012AA011101) and National Natural Science
Foundation of China (No.91024009).
</bodyText>
<sectionHeader confidence="0.987629" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999795666666667">
B. Bai, J. Weston, D. Grangier, R. Collobert, O. Chapelle,
and K. Weinberger. 2009. Supervised semantic index-
ing. In The 18th ACM Conference on Information and
Knowledge Management (CIKM).
R. Bunescu and M. Pasca. 2006. Using encyclopedic
knowledge for named entity disambiguation. In Pro-
ceedings of EACL, volume 6, pages 9–16.
S. Cucerzan. 2007. Large-scale named entity disam-
biguation based on wikipedia data. In Proceedings of
EMNLP-CoNLL, volume 6, pages 708–716.
X. Han, L. Sun, and J. Zhao. 2011. Collective entity
linking in web text: a graph-based method. In Pro-
</reference>
<page confidence="0.990207">
434
</page>
<reference confidence="0.999419038961039">
ceedings of the 34th international ACM SIGIR con-
ference on Research and development in Information
Retrieval, pages 765–774. ACM.
J. Hoffart, M.A. Yosef, I. Bordino, H. F¨urstenau,
M. Pinkal, M. Spaniol, B. Taneva, S. Thater, and
G. Weikum. 2011. Robust disambiguation of named
entities in text. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing,
pages 782–792. Association for Computational Lin-
guistics.
Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2011. Overview of the tac 2011
knowledge base population track. In Proceedings of
the Fourth Text Analysis Conference.
Thorsten Joachims. 2002. Optimizing search engines
using clickthrough data. In Proceedings of the eighth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, pages 133–142.
ACM.
S.S. Kataria, K.S. Kumar, R. Rastogi, P. Sen, and S.H.
Sengamedu. 2011. Entity disambiguation with hierar-
chical topic models. In Proceedings of KDD.
Zhenzhen Kou and William W Cohen. 2007. Stacked
graphical models for efficient inference in markov ran-
dom fields. In SDM.
S. Kulkarni, A. Singh, G. Ramakrishnan, and
S. Chakrabarti. 2009. Collective annotation of
wikipedia entities in web text. In Proceedings of
the 15th ACM SIGKDD international conference
on Knowledge discovery and data mining, pages
457–466. ACM.
J. Lehmann, S. Monahan, L. Nezda, A. Jung, and Y. Shi.
2010. Lcc approaches to knowledge base population
at tac 2010. In Proc. TAC 2010 Workshop.
F. Li, Z. Zheng, F. Bu, Y. Tang, X. Zhu, and M. Huang.
2009. Thu quanta at tac 2009 kbp and rte track. In
Proceedings of Test Analysis Conference 2009 (TAC
09).
Andr´e FT Martins, Dipanjan Das, Noah A Smith, and
Eric P Xing. 2008. Stacking dependency parsers. In
Proceedings of the Conference on Empirical Methods
in Natural Language Processing, pages 157–166. As-
sociation for Computational Linguistics.
D. Milne and I.H. Witten. 2008. Learning to link with
wikipedia. In Proceedings of the 17th ACM con-
ference on Information and knowledge management,
pages 509–518. ACM.
L. Ratinov, D. Roth, D. Downey, and M. Anderson.
2011. Local and global algorithms for disambiguation
to wikipedia. In Proceedings of the Annual Meeting of
the Association of Computational Linguistics (ACL).
P. Sen. 2012. Collective context-aware topic models
for entity disambiguation. In Proceedings of the 21st
international conference on World Wide Web, pages
729–738. ACM.
M. Shirakawa, H. Wang, Y. Song, Z. Wang,
K. Nakayama, T. Hara, and S. Nishio. 2011.
Entity disambiguation based on a probabilistic
taxonomy. Technical report, Technical Report
MSR-TR-2011-125, Microsoft Research.
N.A. Smith and J. Eisner. 2005. Contrastive estimation:
Training log-linear models on unlabeled data. In Pro-
ceedings of the 43rd Annual Meeting on Association
for Computational Linguistics, pages 354–362. Asso-
ciation for Computational Linguistics.
Weiwei Sun. 2011. A stacked sub-word model for
joint chinese word segmentation and part-of-speech
tagging. In ACL, pages 1385–1394.
David H Wolpert. 1992. Stacked generalization. Neural
networks, 5(2):241–259.
Zhicheng Zheng, Fangtao Li, Minlie Huang, and Xiaoyan
Zhu. 2010. Learning to link entities with knowledge
base. In Human Language Technologies: The 2010
Annual Conference of the North American Chapter of
the Association for Computational Linguistics, pages
483–491, Los Angeles, California, June. Association
for Computational Linguistics.
</reference>
<page confidence="0.999215">
435
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.156790">
<title confidence="0.995386">Efficient Collective Entity Linking with Stacking</title>
<abstract confidence="0.916308807692308">Laboratory of Computational Linguistics (Peking University) Ministry of Research songyangmagic@gmail.com wanghf@pku.edu.cn Abstract Entity disambiguation works by linking ambiguous mentions in text to their corresponding real-world entities in knowledge base. Recent collective disambiguation methods enforce coherence among contextual decisions at the cost of non-trivial inference processes. We propose a fast collective disambiguation approach based on stacking. First, we train a predictor learning to rank as base learner, to generate initial ranking list of can- Second, top of related instances are searched for constructing expressive global coherence features. A global pretrained in the augmented feature space and stacking is employed to tackle the train/test mismatch problem. The proposed method is fast and easy to implement. Experiments show its effectiveness over various algorithms on several public datasets. By learning a rich semantic relatedness measure between entity categories and context document, performance is further improved.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Bai</author>
<author>J Weston</author>
<author>D Grangier</author>
<author>R Collobert</author>
<author>O Chapelle</author>
<author>K Weinberger</author>
</authors>
<title>Supervised semantic indexing.</title>
<date>2009</date>
<booktitle>In The 18th ACM Conference on Information and Knowledge Management (CIKM).</booktitle>
<contexts>
<context position="8023" citStr="Bai et al., 2009" startWordPosition="1212" endWordPosition="1215">are often semantically correlated while false ones scattered around. Wikipedians annotate entries in Wikipedia with category network. This valuable information generalizes entity-context correlation to category-context correlation. (Bunescu and Pasca, 2006) utilize category-word as features in their ranking model. (Kataria et al., 2011) employ a hierarchical topic model where each inner node in the hierarchy is a category. Both approaches must rely on pruned categories because the large number of noisy categories. We try to address this problem with recent advances of representation learning (Bai et al., 2009), which learns the relatedness of category and context in latent continuous space. This method scales well to potentially large knowledge base. 427 3 Method In this section, we first introduce our base learner and local features used; next, the stacking training strategy is given, followed by an explanation of our global coherence model with augmented feature space; finally we explain how to learn category-context correlation with representation learning technique. 3.1 Base learner and local predictor g0 Entity linking is formalized as follows: given an ambiguous name mention m with its contex</context>
<context position="19127" citStr="Bai et al., 2009" startWordPosition="3104" endWordPosition="3107">rrelation at word level through category-word pair features. This method creates sparsity problem and does not scale well because the number of features grows linearly with both the number of categories and the vocabulary size. Moreover, the category network is somewhat noisy, e.g. travelling up four levels of the hierarchy can result in over ten thousand categories, with many irrelevant ones. Rather than learning the correlation at word level, we explore a representation learning method that learns category-context correlation in the latent semantic space. Supervised Semantic Indexing (SSI) (Bai et al., 2009) is trained on query-document pairs to predict their degree of matching. The comparison is performed in the latent semantic space, so that synonymy and polysemy are implicitly handled by its inner mechanism. The score function between query q and document d is defined as: f(q, d) = qT Wd (6) 430 where W is learned with supervision like clickthrough data. Given training data {(qi, di)}, training is done by randomly sampling a negative target d−. The model optimizes W such that f(q, d+) &gt; f(q, d−). Thus, the training objective is to minimize the following margin-based loss function: � max(0,1 − </context>
</contexts>
<marker>Bai, Weston, Grangier, Collobert, Chapelle, Weinberger, 2009</marker>
<rawString>B. Bai, J. Weston, D. Grangier, R. Collobert, O. Chapelle, and K. Weinberger. 2009. Supervised semantic indexing. In The 18th ACM Conference on Information and Knowledge Management (CIKM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bunescu</author>
<author>M Pasca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<volume>6</volume>
<pages>9--16</pages>
<contexts>
<context position="2261" citStr="Bunescu and Pasca, 2006" startWordPosition="328" endWordPosition="331">g text is populated with semantic rich links to knowledge base like Wikipedia, and ready for various downstream NLP applications. &amp;quot;Corresponding author Previous researches have proposed several kinds of effective approaches for this problem. Learning to rank (L2R) approaches use hand-crafted features f(d, e) to describe the similarity or dissimilarity between contextual document d and entity definition e. L2R approaches are very flexible and expressive. Features like name matching, context similarity (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) and category context correlation (Bunescu and Pasca, 2006) can be incorporated with ease. Nevertheless, decisions are made independently and inconsistent results are found from time to time. Collective approaches utilize dependencies between different decisions and resolve all ambiguous mentions within the same context simultaneously (Han et al., 2011; Hoffart et al., 2011; Kulkarni et al., 2009; Ratinov et al., 2011). Collective approaches can improve performance when local evidence is not confident enough. They often utilize semantic relations across different mentions, and is why they are called global approaches, while L2R methods fall into local</context>
<context position="4208" citStr="Bunescu and Pasca, 2006" startWordPosition="622" endWordPosition="625">ington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics At the next level, we search for semantic coherent entities from the top k candidates of neighboring mentions. The second learner is trained on the augmented feature space to enforce semantic coherence. Stacking is employed to handle train/test mismatch problem. Compared with existing collective methods, the inference process of our method is much faster because of the simple form of its base learner. Wikipedians annotate each entity with categories which provide another source of valuable semantic information. (Bunescu and Pasca, 2006) propose to generalize beyond context-entity correlation s(d, e) with word-category correlation s(w, c). However, this method works at word level, and does not scale well to large number of categories. We explore a representation learning technique to learn the category-context association in latent semantic space, which scales much better to large knowledge base. Our contributions are as follows: (1) We propose a fast and accurate stacking-based collective entity linking method, which combines the benefits of both coherence modeling of collective approaches and expressivity of L2R methods. We</context>
<context position="7663" citStr="Bunescu and Pasca, 2006" startWordPosition="1154" endWordPosition="1157">-speech tagging (Sun, 2011). (Kou and Cohen, 2007) propose stacked graphical learning which captures dependencies between data with relational template. Our method is inspired by their approach. The difference is our base learner is an L2R model. We search related entity candidates in a large semantic relatedness graph, based on the assumption that true candidates are often semantically correlated while false ones scattered around. Wikipedians annotate entries in Wikipedia with category network. This valuable information generalizes entity-context correlation to category-context correlation. (Bunescu and Pasca, 2006) utilize category-word as features in their ranking model. (Kataria et al., 2011) employ a hierarchical topic model where each inner node in the hierarchy is a category. Both approaches must rely on pruned categories because the large number of noisy categories. We try to address this problem with recent advances of representation learning (Bai et al., 2009), which learns the relatedness of category and context in latent continuous space. This method scales well to potentially large knowledge base. 427 3 Method In this section, we first introduce our base learner and local features used; next,</context>
<context position="18469" citStr="Bunescu and Pasca, 2006" startWordPosition="3005" endWordPosition="3008">ney” with category “Republican party presidential nominee” co-occurs frequently with context like “election” and “campaign”, while another candidate “Milton Romney” with category “Utah Utes football players” is frequently observed with context like “quarterback” and “backfield”. The category network forms a directed acyclic graph (DAG). Some entities can share category through the network, e.g. “Barack Obama” with category “Democratic Party presidential nominees” shares the category “United States presidential candidates by party” with “Mitt Romney” when travelling two levels up the network. (Bunescu and Pasca, 2006) propose to learn the category-context correlation at word level through category-word pair features. This method creates sparsity problem and does not scale well because the number of features grows linearly with both the number of categories and the vocabulary size. Moreover, the category network is somewhat noisy, e.g. travelling up four levels of the hierarchy can result in over ten thousand categories, with many irrelevant ones. Rather than learning the correlation at word level, we explore a representation learning method that learns category-context correlation in the latent semantic sp</context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>R. Bunescu and M. Pasca. 2006. Using encyclopedic knowledge for named entity disambiguation. In Proceedings of EACL, volume 6, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on wikipedia data.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<volume>6</volume>
<pages>708--716</pages>
<contexts>
<context position="5766" citStr="Cucerzan, 2007" startWordPosition="865" endWordPosition="866">ve entity linking performance. 2 Related Work Most popular entity linking systems use the L2R framework (Bunescu and Pasca, 2006; Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010). Its discriminative nature gives the model enough flexibility and expressivity. It can include any features that describe the similarity or dissimilarity of context d and candidate entity e. They often perform well even on small training set, with carefullydesigned features. This category falls into the local approach as the decision processes for each mention are made independently (Ratinov et al., 2011). (Cucerzan, 2007) first suggests to optimize an objective function that is similar to the collective approach. However, the author adopts an approximation method because of the large search space (which is O(n&apos;) for a document with m mentions, each with n candidates). Various other methods like integer linear programming (Kulkarni et al., 2009), personalized PageRank (Han et al., 2011) and greedy graph cutting (Hoffart et al., 2011) have been explored in literature. Our method without stacking resembles the method of (Ratinov et al., 2011) in that they use the predictions of a local ranker to generate features</context>
<context position="17121" citStr="Cucerzan, 2007" startWordPosition="2806" endWordPosition="2807">g(max(|A|, |B|)) − log(|A ∩ B|) �R(ei, ej) = 1−log(|W|) − log(min(|A|, |B|)) (5) where A and B are the set of in-links for entity ei and ej respectively, and W is the set of all Wikipedia pages. Our method is a trade-off between exact collective inference and approximating related instance with top ranked entities produced by go. Most collective approaches take all ambiguous mentions into consideration and disambiguate them simultaneously, resulting in difficulty when inference in large search space (Kulkarni et al., 2009; Hoffart et al., 2011). Others resolve to some kinds of approximation. (Cucerzan, 2007) construct features as the average of all candidates for one mention, introducing considerable noise. (Ratinov et al., 2011) also employ a two level architecture but only take top 1 prediction for features. This most resembles our approach, except we use stacking to tackle the train/test mismatch problem, and construct different set of features from top k candidates predicted by go. We will show in our experiments that this indeed helps boost performance. 3.4 Learning category-context coherence model cat Entities in Wikipedia are annotated with rich semantic structures. Category network provid</context>
<context position="22272" citStr="Cucerzan, 2007" startWordPosition="3651" endWordPosition="3652">. According to the setting of (Hoffart et al., 2011), we split the AIDA dataset for train/development/test with 946/216/231 documents. We train a separate model on the Wikipedia training set for evaluating ACE/QUAINT/WIKI dataset (Ratinov et al., 2011). Table 2 gives a brief overview of the datasets used. For knowledge base, we use the Wikipedia XML dump 3 to extract over 3.3 million entities. We use annotation from Wikipedia to build a name dictionary from mention string m to entity e for candidate generation, including redirects, disambiguation pages and hyperlinks, follows the approach of (Cucerzan, 2007). For candidate generation, we keep the top 30 candidates by popularity (Tbl. 1). Note that our name dictionary is different from (Ratinov et al., 2011) and has a much higher recall. Since (Ratinov et al., 2011) evaluate on “solvable” mentions and we have no way to recover those mentions, we re-implement their global features and the final scores are not directly comparable to theirs. 4.2 Methods under comparison We compare our algorithm with several state-of-theart collective entity disambiguation systems. The AIDA system proposed by (Hoffart et al., 2011) use a greedy graph cutting algorithm</context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>S. Cucerzan. 2007. Large-scale named entity disambiguation based on wikipedia data. In Proceedings of EMNLP-CoNLL, volume 6, pages 708–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Han</author>
<author>L Sun</author>
<author>J Zhao</author>
</authors>
<title>Collective entity linking in web text: a graph-based method.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,</booktitle>
<pages>765--774</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2556" citStr="Han et al., 2011" startWordPosition="369" endWordPosition="372">(d, e) to describe the similarity or dissimilarity between contextual document d and entity definition e. L2R approaches are very flexible and expressive. Features like name matching, context similarity (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) and category context correlation (Bunescu and Pasca, 2006) can be incorporated with ease. Nevertheless, decisions are made independently and inconsistent results are found from time to time. Collective approaches utilize dependencies between different decisions and resolve all ambiguous mentions within the same context simultaneously (Han et al., 2011; Hoffart et al., 2011; Kulkarni et al., 2009; Ratinov et al., 2011). Collective approaches can improve performance when local evidence is not confident enough. They often utilize semantic relations across different mentions, and is why they are called global approaches, while L2R methods fall into local approaches (Ratinov et al., 2011). However, collective inference processes are often expensive and involve an exponential search space. We propose a collective entity linking method based on stacking. Stacked generalization (Wolpert, 1992) is a powerful meta learning algorithm that uses two le</context>
<context position="6137" citStr="Han et al., 2011" startWordPosition="923" endWordPosition="926"> entity e. They often perform well even on small training set, with carefullydesigned features. This category falls into the local approach as the decision processes for each mention are made independently (Ratinov et al., 2011). (Cucerzan, 2007) first suggests to optimize an objective function that is similar to the collective approach. However, the author adopts an approximation method because of the large search space (which is O(n&apos;) for a document with m mentions, each with n candidates). Various other methods like integer linear programming (Kulkarni et al., 2009), personalized PageRank (Han et al., 2011) and greedy graph cutting (Hoffart et al., 2011) have been explored in literature. Our method without stacking resembles the method of (Ratinov et al., 2011) in that they use the predictions of a local ranker to generate features for global ranker. The differences are that we use stacking to train the local ranker to handle the train/test mismatch problem and top k candidates to generate features for the global ranker. Stacked generalization (Wolpert, 1992) is a meta learning algorithm that uses multiple learners outputs to augment the feature space of subsequent learners. It utilizes a cross-</context>
<context position="11099" citStr="Han et al., 2011" startWordPosition="1776" endWordPosition="1779">2. cosine similarity of TF-IDF score between context and introduction of Wikipedia page 3. jaccard distance between context and entire Wikipedia page of candidate 4. jaccard distance between context and introduction of Wikipedia page Popularity or prominence feature: percentage of Wikipedia hyperlinks pointing to e given mention m, i.e. P(e|m) Category-context coherence model: cat0 and cat1 (details in Section 3.4) Table 1: Features for local predictor go. useful features like string matching and entity popularity cannot be easily expressed by collective approaches like (Hoffart et al., 2011; Han et al., 2011). The features for level 0 predictor g0 are described in Table 1. The reader can consult (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) for further reference. 3.2 Stacking training for global predictor g1 Stacked generalization (Wolpert, 1992) is a meta learning algorithm that stacks two “levels” of predictors. Level 0 includes one or more predictors h(0) 1 , h(0) 2 , ... , h(0) K : Rd —* R, each one is trained on the original d-dimensional feature space. The level 1 predictor h(1) : Rd+K —* R is trained in the augmented (d+K)-dimensional feature space, in which predictions at lev</context>
<context position="16502" citStr="Han et al., 2011" startWordPosition="2704" endWordPosition="2707">ublican Party (United States)]] nominee [[Romney|Mitt Romney]] Figure 1: Semantic links for collective entity linking. Annotation [[mention|entity]] follows Wikipedia conventions. Democratic Party (Italy) Democratic Party (Serbia) Obama, Fukui Obama, Nagasaki ... ... ... ... Barack Obama Democratic Party (United States) Republican Party (United States) Republican Party of Minnesota Republicanism Romney, West Virginia HMS Romney (1694) Mitt Romney Finally, the semantic relatedness measure of two entities ei,ej is defined as the common in-links of ei and ej in Wikipedia (Milne and Witten, 2008; Han et al., 2011): log(max(|A|, |B|)) − log(|A ∩ B|) �R(ei, ej) = 1−log(|W|) − log(min(|A|, |B|)) (5) where A and B are the set of in-links for entity ei and ej respectively, and W is the set of all Wikipedia pages. Our method is a trade-off between exact collective inference and approximating related instance with top ranked entities produced by go. Most collective approaches take all ambiguous mentions into consideration and disambiguate them simultaneously, resulting in difficulty when inference in large search space (Kulkarni et al., 2009; Hoffart et al., 2011). Others resolve to some kinds of approximatio</context>
<context position="22952" citStr="Han et al., 2011" startWordPosition="3758" endWordPosition="3761">pularity (Tbl. 1). Note that our name dictionary is different from (Ratinov et al., 2011) and has a much higher recall. Since (Ratinov et al., 2011) evaluate on “solvable” mentions and we have no way to recover those mentions, we re-implement their global features and the final scores are not directly comparable to theirs. 4.2 Methods under comparison We compare our algorithm with several state-of-theart collective entity disambiguation systems. The AIDA system proposed by (Hoffart et al., 2011) use a greedy graph cutting algorithm that iteratively remove entities with low confidence scores. (Han et al., 2011) employ personalized PageRank to propagate evidence between different decisions. Both algorithms use simple local features without discriminative training. (Kulkarni et al., 2009) propose to use integer linear programming (ILP) for inference. Except our re-implementation of Han’s 1available at http://www.mpi-inf.mpg.de/yago-naga/aida/ 2http://cogcomp.cs.illinois.edu/Data, we don’t find the MSNBC dataset in the zip file. 3available at http://dumps.wikimedia.org/enwiki/, we use the 20110405 xml dump. 431 Dataset ndocs non- identified solvable NIL AIDA dev 216 4791 4791 4707 AIDA test 231 4485 44</context>
<context position="27712" citStr="Han et al., 2011" startWordPosition="4545" endWordPosition="4548">in Table 4 shows some baseline features for comparison. We can see even if the categories only carry incomplete and noisy information about an entity, it performs much 432 Table 4: Performance on AIDA dataset. Maximal value in each group are highlighted with bold font. top k means up to k candidates are used for searching related instances with relational template. Methods cosine jaccard cat0 cat1 popularity g0 g0+global(Ratinov) g1+1fold g1+5fold g1+10fold g1+top1 g1+top3 g1+top5 g1+top7 g0+cat g1+cat g1+cat+all context (Hoffart et al., 2011) (Shirakawa et al., 2011) (Kulkarni et al., 2009) (Han et al., 2011) Devset Testset micro macro MRR micro macro MRR p@1 p@1 p@1 p@1 33.25 28.61 46.03 33.33 28.63 46.54 44.71 36.56 57.76 45.66 36.89 57.08 54.75 47.14 67.70 61.52 54.72 72.55 60.15 54.64 72.98 65.46 61.04 76.84 69.21 67.59 79.26 69.07 72.63 79.45 76.04 73.63 84.21 76.16 78.17 84.58 81.30 78.03 88.14 81.45 81.89 88.70 82.01 78.52 88.90 83.59 83.58 90.05 81.99 78.42 88.87 83.52 83.37 89.99 82.01 78.53 88.91 83.59 83.55 90.03 81.65 78.76 88.51 81.81 82.55 89.06 82.20 78.64 88.98 83.52 83.34 89.94 82.01 78.57 88.90 83.63 83.76 90.05 82.05 78.40 88.90 83.75 83.58 90.08 79.36 76.14 86.66 79.64 80.47 87</context>
</contexts>
<marker>Han, Sun, Zhao, 2011</marker>
<rawString>X. Han, L. Sun, and J. Zhao. 2011. Collective entity linking in web text: a graph-based method. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 765–774. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hoffart</author>
<author>M A Yosef</author>
<author>I Bordino</author>
<author>H F¨urstenau</author>
<author>M Pinkal</author>
<author>M Spaniol</author>
<author>B Taneva</author>
<author>S Thater</author>
<author>G Weikum</author>
</authors>
<title>Robust disambiguation of named entities in text.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>782--792</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>J. Hoffart, M.A. Yosef, I. Bordino, H. F¨urstenau, M. Pinkal, M. Spaniol, B. Taneva, S. Thater, and G. Weikum. 2011. Robust disambiguation of named entities in text. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 782–792. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
<author>Kira Griffitt</author>
<author>Joe Ellis</author>
</authors>
<title>Overview of the tac 2011 knowledge base population track.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fourth Text Analysis Conference.</booktitle>
<contexts>
<context position="1623" citStr="Ji et al., 2011" startWordPosition="232" endWordPosition="235">ployed to tackle the train/test mismatch problem. The proposed method is fast and easy to implement. Experiments show its effectiveness over various algorithms on several public datasets. By learning a rich semantic relatedness measure between entity categories and context document, performance is further improved. 1 Introduction When extracting knowledge from natural language text into a machine readable format, ambiguous names must be resolved in order to tell which realworld entity the name refers to. The task of linking names to knowledge base is known as entity linking or disambiguation (Ji et al., 2011). The resulting text is populated with semantic rich links to knowledge base like Wikipedia, and ready for various downstream NLP applications. &amp;quot;Corresponding author Previous researches have proposed several kinds of effective approaches for this problem. Learning to rank (L2R) approaches use hand-crafted features f(d, e) to describe the similarity or dissimilarity between contextual document d and entity definition e. L2R approaches are very flexible and expressive. Features like name matching, context similarity (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) and category context</context>
</contexts>
<marker>Ji, Grishman, Dang, Griffitt, Ellis, 2011</marker>
<rawString>Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Griffitt, and Joe Ellis. 2011. Overview of the tac 2011 knowledge base population track. In Proceedings of the Fourth Text Analysis Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Optimizing search engines using clickthrough data.</title>
<date>2002</date>
<booktitle>In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>133--142</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="9431" citStr="Joachims, 2002" startWordPosition="1464" endWordPosition="1465"> used to construct augmented features for the next level learner, or used by our end system to select the answer: e� = arg max g(e) (1) eEC(m) In an L2R framework, the model is often defined as a linear combination of features. Here, our features ⃗f(d, e) are derived from document d and candidate e. The model is defined as g(e) = w⃗ ⃗f(d, e). In our problem, we are given a list of training data D = {(di, ei)}. We want to optimize the parameter ⃗w, such that the correct entity has a higher score over negative ones. This is done via a preference learning technique SV Mrank, first introduced by (Joachims, 2002). The following margin based loss is minimized w.r.t ⃗w: L = �l l⃗wl l2 + C ξd,e′ (2) 1 � s.t. ⃗w(⃗f(d, e) − ⃗f(d, e′)) &gt; 1 − ξd,e′ (3) ξd,e′ &gt; 0 (4) where C is a trade-off between training error and margin size; ξ is slacking variable and loops over all query documents d and negative candidates e′ E C(m) − {e}. This model is expressive enough to include any form of features describing the similarity and dissimilarity of d and e. We only include some typical features seen in literature. The inclusion of these features is not meant to be exhaustive. Our purpose is to build a moderate model in w</context>
</contexts>
<marker>Joachims, 2002</marker>
<rawString>Thorsten Joachims. 2002. Optimizing search engines using clickthrough data. In Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining, pages 133–142. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S S Kataria</author>
<author>K S Kumar</author>
<author>R Rastogi</author>
<author>P Sen</author>
<author>S H Sengamedu</author>
</authors>
<title>Entity disambiguation with hierarchical topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of KDD.</booktitle>
<contexts>
<context position="7744" citStr="Kataria et al., 2011" startWordPosition="1166" endWordPosition="1169">g which captures dependencies between data with relational template. Our method is inspired by their approach. The difference is our base learner is an L2R model. We search related entity candidates in a large semantic relatedness graph, based on the assumption that true candidates are often semantically correlated while false ones scattered around. Wikipedians annotate entries in Wikipedia with category network. This valuable information generalizes entity-context correlation to category-context correlation. (Bunescu and Pasca, 2006) utilize category-word as features in their ranking model. (Kataria et al., 2011) employ a hierarchical topic model where each inner node in the hierarchy is a category. Both approaches must rely on pruned categories because the large number of noisy categories. We try to address this problem with recent advances of representation learning (Bai et al., 2009), which learns the relatedness of category and context in latent continuous space. This method scales well to potentially large knowledge base. 427 3 Method In this section, we first introduce our base learner and local features used; next, the stacking training strategy is given, followed by an explanation of our globa</context>
</contexts>
<marker>Kataria, Kumar, Rastogi, Sen, Sengamedu, 2011</marker>
<rawString>S.S. Kataria, K.S. Kumar, R. Rastogi, P. Sen, and S.H. Sengamedu. 2011. Entity disambiguation with hierarchical topic models. In Proceedings of KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhenzhen Kou</author>
<author>William W Cohen</author>
</authors>
<title>Stacked graphical models for efficient inference in markov random fields.</title>
<date>2007</date>
<booktitle>In SDM.</booktitle>
<contexts>
<context position="6940" citStr="Kou and Cohen, 2007" startWordPosition="1053" endWordPosition="1056">ictions of a local ranker to generate features for global ranker. The differences are that we use stacking to train the local ranker to handle the train/test mismatch problem and top k candidates to generate features for the global ranker. Stacked generalization (Wolpert, 1992) is a meta learning algorithm that uses multiple learners outputs to augment the feature space of subsequent learners. It utilizes a cross-validation strategy to address the train set / testset label mismatch problem. Various applications of stacking in NLP have been proposed, such as collective document classification (Kou and Cohen, 2007), stacked dependency parsing (Martins et al., 2008) and joint Chinese word segmentation and part-of-speech tagging (Sun, 2011). (Kou and Cohen, 2007) propose stacked graphical learning which captures dependencies between data with relational template. Our method is inspired by their approach. The difference is our base learner is an L2R model. We search related entity candidates in a large semantic relatedness graph, based on the assumption that true candidates are often semantically correlated while false ones scattered around. Wikipedians annotate entries in Wikipedia with category network. </context>
<context position="11762" citStr="Kou and Cohen, 2007" startWordPosition="1896" endWordPosition="1899"> described in Table 1. The reader can consult (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) for further reference. 3.2 Stacking training for global predictor g1 Stacked generalization (Wolpert, 1992) is a meta learning algorithm that stacks two “levels” of predictors. Level 0 includes one or more predictors h(0) 1 , h(0) 2 , ... , h(0) K : Rd —* R, each one is trained on the original d-dimensional feature space. The level 1 predictor h(1) : Rd+K —* R is trained in the augmented (d+K)-dimensional feature space, in which predictions at level 0 are taken as extra features in h(1). (Kou and Cohen, 2007) proposed stacked graphi428 cal learning for learning and inference on relational data. In stacked graphical learning, dependencies among data are captured by relational template, with which one searches for related instances of the current instance. The augmented feature space does not necessarily to be d + K. Instead, one can construct any declarative feature with the original data and predictions of related instances. For instance, in collective document classification (Kou and Cohen, 2007) employ relational template to extract documents that link to this document, then apply a COUNT aggreg</context>
</contexts>
<marker>Kou, Cohen, 2007</marker>
<rawString>Zhenzhen Kou and William W Cohen. 2007. Stacked graphical models for efficient inference in markov random fields. In SDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kulkarni</author>
<author>A Singh</author>
<author>G Ramakrishnan</author>
<author>S Chakrabarti</author>
</authors>
<title>Collective annotation of wikipedia entities in web text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>457--466</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2601" citStr="Kulkarni et al., 2009" startWordPosition="377" endWordPosition="380">similarity between contextual document d and entity definition e. L2R approaches are very flexible and expressive. Features like name matching, context similarity (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) and category context correlation (Bunescu and Pasca, 2006) can be incorporated with ease. Nevertheless, decisions are made independently and inconsistent results are found from time to time. Collective approaches utilize dependencies between different decisions and resolve all ambiguous mentions within the same context simultaneously (Han et al., 2011; Hoffart et al., 2011; Kulkarni et al., 2009; Ratinov et al., 2011). Collective approaches can improve performance when local evidence is not confident enough. They often utilize semantic relations across different mentions, and is why they are called global approaches, while L2R methods fall into local approaches (Ratinov et al., 2011). However, collective inference processes are often expensive and involve an exponential search space. We propose a collective entity linking method based on stacking. Stacked generalization (Wolpert, 1992) is a powerful meta learning algorithm that uses two levels of learners. The predictions of the firs</context>
<context position="6095" citStr="Kulkarni et al., 2009" startWordPosition="917" endWordPosition="920">ity or dissimilarity of context d and candidate entity e. They often perform well even on small training set, with carefullydesigned features. This category falls into the local approach as the decision processes for each mention are made independently (Ratinov et al., 2011). (Cucerzan, 2007) first suggests to optimize an objective function that is similar to the collective approach. However, the author adopts an approximation method because of the large search space (which is O(n&apos;) for a document with m mentions, each with n candidates). Various other methods like integer linear programming (Kulkarni et al., 2009), personalized PageRank (Han et al., 2011) and greedy graph cutting (Hoffart et al., 2011) have been explored in literature. Our method without stacking resembles the method of (Ratinov et al., 2011) in that they use the predictions of a local ranker to generate features for global ranker. The differences are that we use stacking to train the local ranker to handle the train/test mismatch problem and top k candidates to generate features for the global ranker. Stacked generalization (Wolpert, 1992) is a meta learning algorithm that uses multiple learners outputs to augment the feature space of</context>
<context position="17033" citStr="Kulkarni et al., 2009" startWordPosition="2790" endWordPosition="2793">s the common in-links of ei and ej in Wikipedia (Milne and Witten, 2008; Han et al., 2011): log(max(|A|, |B|)) − log(|A ∩ B|) �R(ei, ej) = 1−log(|W|) − log(min(|A|, |B|)) (5) where A and B are the set of in-links for entity ei and ej respectively, and W is the set of all Wikipedia pages. Our method is a trade-off between exact collective inference and approximating related instance with top ranked entities produced by go. Most collective approaches take all ambiguous mentions into consideration and disambiguate them simultaneously, resulting in difficulty when inference in large search space (Kulkarni et al., 2009; Hoffart et al., 2011). Others resolve to some kinds of approximation. (Cucerzan, 2007) construct features as the average of all candidates for one mention, introducing considerable noise. (Ratinov et al., 2011) also employ a two level architecture but only take top 1 prediction for features. This most resembles our approach, except we use stacking to tackle the train/test mismatch problem, and construct different set of features from top k candidates predicted by go. We will show in our experiments that this indeed helps boost performance. 3.4 Learning category-context coherence model cat En</context>
<context position="23131" citStr="Kulkarni et al., 2009" startWordPosition="3782" endWordPosition="3785">ntions and we have no way to recover those mentions, we re-implement their global features and the final scores are not directly comparable to theirs. 4.2 Methods under comparison We compare our algorithm with several state-of-theart collective entity disambiguation systems. The AIDA system proposed by (Hoffart et al., 2011) use a greedy graph cutting algorithm that iteratively remove entities with low confidence scores. (Han et al., 2011) employ personalized PageRank to propagate evidence between different decisions. Both algorithms use simple local features without discriminative training. (Kulkarni et al., 2009) propose to use integer linear programming (ILP) for inference. Except our re-implementation of Han’s 1available at http://www.mpi-inf.mpg.de/yago-naga/aida/ 2http://cogcomp.cs.illinois.edu/Data, we don’t find the MSNBC dataset in the zip file. 3available at http://dumps.wikimedia.org/enwiki/, we use the 20110405 xml dump. 431 Dataset ndocs non- identified solvable NIL AIDA dev 216 4791 4791 4707 AIDA test 231 4485 4485 4411 ACE 36 257 238 209(185) AQUAINT 50 727 697 668(588) Wikipedia 40 928 918 854(843) Table 2: Number of mentions in each dataset. “identified” means the mention exists in our</context>
<context position="27693" citStr="Kulkarni et al., 2009" startWordPosition="4541" endWordPosition="4544"> of cat:The first group in Table 4 shows some baseline features for comparison. We can see even if the categories only carry incomplete and noisy information about an entity, it performs much 432 Table 4: Performance on AIDA dataset. Maximal value in each group are highlighted with bold font. top k means up to k candidates are used for searching related instances with relational template. Methods cosine jaccard cat0 cat1 popularity g0 g0+global(Ratinov) g1+1fold g1+5fold g1+10fold g1+top1 g1+top3 g1+top5 g1+top7 g0+cat g1+cat g1+cat+all context (Hoffart et al., 2011) (Shirakawa et al., 2011) (Kulkarni et al., 2009) (Han et al., 2011) Devset Testset micro macro MRR micro macro MRR p@1 p@1 p@1 p@1 33.25 28.61 46.03 33.33 28.63 46.54 44.71 36.56 57.76 45.66 36.89 57.08 54.75 47.14 67.70 61.52 54.72 72.55 60.15 54.64 72.98 65.46 61.04 76.84 69.21 67.59 79.26 69.07 72.63 79.45 76.04 73.63 84.21 76.16 78.17 84.58 81.30 78.03 88.14 81.45 81.89 88.70 82.01 78.52 88.90 83.59 83.58 90.05 81.99 78.42 88.87 83.52 83.37 89.99 82.01 78.53 88.91 83.59 83.55 90.03 81.65 78.76 88.51 81.81 82.55 89.06 82.20 78.64 88.98 83.52 83.34 89.94 82.01 78.57 88.90 83.63 83.76 90.05 82.05 78.40 88.90 83.75 83.58 90.08 79.36 76.14 8</context>
</contexts>
<marker>Kulkarni, Singh, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>S. Kulkarni, A. Singh, G. Ramakrishnan, and S. Chakrabarti. 2009. Collective annotation of wikipedia entities in web text. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 457–466. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lehmann</author>
<author>S Monahan</author>
<author>L Nezda</author>
<author>A Jung</author>
<author>Y Shi</author>
</authors>
<title>Lcc approaches to knowledge base population at tac 2010. In</title>
<date>2010</date>
<booktitle>Proc. TAC 2010 Workshop.</booktitle>
<contexts>
<context position="2202" citStr="Lehmann et al., 2010" startWordPosition="320" endWordPosition="323">inking or disambiguation (Ji et al., 2011). The resulting text is populated with semantic rich links to knowledge base like Wikipedia, and ready for various downstream NLP applications. &amp;quot;Corresponding author Previous researches have proposed several kinds of effective approaches for this problem. Learning to rank (L2R) approaches use hand-crafted features f(d, e) to describe the similarity or dissimilarity between contextual document d and entity definition e. L2R approaches are very flexible and expressive. Features like name matching, context similarity (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) and category context correlation (Bunescu and Pasca, 2006) can be incorporated with ease. Nevertheless, decisions are made independently and inconsistent results are found from time to time. Collective approaches utilize dependencies between different decisions and resolve all ambiguous mentions within the same context simultaneously (Han et al., 2011; Hoffart et al., 2011; Kulkarni et al., 2009; Ratinov et al., 2011). Collective approaches can improve performance when local evidence is not confident enough. They often utilize semantic relations across different mentions, and is why they are </context>
<context position="5339" citStr="Lehmann et al., 2010" startWordPosition="797" endWordPosition="800">ts of both coherence modeling of collective approaches and expressivity of L2R methods. We show an effective usage of ranking list as global features, which is a key improvement for the global predictor. (2) To overcome problems of scalability and shallow word-level comparison, we learn the categorycontext correlation with recent advances of representation learning, and show that this extra semantic information indeed helps improve entity linking performance. 2 Related Work Most popular entity linking systems use the L2R framework (Bunescu and Pasca, 2006; Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010). Its discriminative nature gives the model enough flexibility and expressivity. It can include any features that describe the similarity or dissimilarity of context d and candidate entity e. They often perform well even on small training set, with carefullydesigned features. This category falls into the local approach as the decision processes for each mention are made independently (Ratinov et al., 2011). (Cucerzan, 2007) first suggests to optimize an objective function that is similar to the collective approach. However, the author adopts an approximation method because of the large search </context>
<context position="11247" citStr="Lehmann et al., 2010" startWordPosition="1804" endWordPosition="1807"> page of candidate 4. jaccard distance between context and introduction of Wikipedia page Popularity or prominence feature: percentage of Wikipedia hyperlinks pointing to e given mention m, i.e. P(e|m) Category-context coherence model: cat0 and cat1 (details in Section 3.4) Table 1: Features for local predictor go. useful features like string matching and entity popularity cannot be easily expressed by collective approaches like (Hoffart et al., 2011; Han et al., 2011). The features for level 0 predictor g0 are described in Table 1. The reader can consult (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) for further reference. 3.2 Stacking training for global predictor g1 Stacked generalization (Wolpert, 1992) is a meta learning algorithm that stacks two “levels” of predictors. Level 0 includes one or more predictors h(0) 1 , h(0) 2 , ... , h(0) K : Rd —* R, each one is trained on the original d-dimensional feature space. The level 1 predictor h(1) : Rd+K —* R is trained in the augmented (d+K)-dimensional feature space, in which predictions at level 0 are taken as extra features in h(1). (Kou and Cohen, 2007) proposed stacked graphi428 cal learning for learning and inference on relational dat</context>
</contexts>
<marker>Lehmann, Monahan, Nezda, Jung, Shi, 2010</marker>
<rawString>J. Lehmann, S. Monahan, L. Nezda, A. Jung, and Y. Shi. 2010. Lcc approaches to knowledge base population at tac 2010. In Proc. TAC 2010 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Li</author>
<author>Z Zheng</author>
<author>F Bu</author>
<author>Y Tang</author>
<author>X Zhu</author>
<author>M Huang</author>
</authors>
<title>Thu quanta at tac 2009 kbp and rte track.</title>
<date>2009</date>
<booktitle>In Proceedings of Test Analysis Conference</booktitle>
<contexts>
<context position="2159" citStr="Li et al., 2009" startWordPosition="312" endWordPosition="315">o knowledge base is known as entity linking or disambiguation (Ji et al., 2011). The resulting text is populated with semantic rich links to knowledge base like Wikipedia, and ready for various downstream NLP applications. &amp;quot;Corresponding author Previous researches have proposed several kinds of effective approaches for this problem. Learning to rank (L2R) approaches use hand-crafted features f(d, e) to describe the similarity or dissimilarity between contextual document d and entity definition e. L2R approaches are very flexible and expressive. Features like name matching, context similarity (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) and category context correlation (Bunescu and Pasca, 2006) can be incorporated with ease. Nevertheless, decisions are made independently and inconsistent results are found from time to time. Collective approaches utilize dependencies between different decisions and resolve all ambiguous mentions within the same context simultaneously (Han et al., 2011; Hoffart et al., 2011; Kulkarni et al., 2009; Ratinov et al., 2011). Collective approaches can improve performance when local evidence is not confident enough. They often utilize semantic relations acro</context>
<context position="5296" citStr="Li et al., 2009" startWordPosition="789" endWordPosition="792">ing method, which combines the benefits of both coherence modeling of collective approaches and expressivity of L2R methods. We show an effective usage of ranking list as global features, which is a key improvement for the global predictor. (2) To overcome problems of scalability and shallow word-level comparison, we learn the categorycontext correlation with recent advances of representation learning, and show that this extra semantic information indeed helps improve entity linking performance. 2 Related Work Most popular entity linking systems use the L2R framework (Bunescu and Pasca, 2006; Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010). Its discriminative nature gives the model enough flexibility and expressivity. It can include any features that describe the similarity or dissimilarity of context d and candidate entity e. They often perform well even on small training set, with carefullydesigned features. This category falls into the local approach as the decision processes for each mention are made independently (Ratinov et al., 2011). (Cucerzan, 2007) first suggests to optimize an objective function that is similar to the collective approach. However, the author adopts an approx</context>
<context position="11204" citStr="Li et al., 2009" startWordPosition="1796" endWordPosition="1799"> between context and entire Wikipedia page of candidate 4. jaccard distance between context and introduction of Wikipedia page Popularity or prominence feature: percentage of Wikipedia hyperlinks pointing to e given mention m, i.e. P(e|m) Category-context coherence model: cat0 and cat1 (details in Section 3.4) Table 1: Features for local predictor go. useful features like string matching and entity popularity cannot be easily expressed by collective approaches like (Hoffart et al., 2011; Han et al., 2011). The features for level 0 predictor g0 are described in Table 1. The reader can consult (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) for further reference. 3.2 Stacking training for global predictor g1 Stacked generalization (Wolpert, 1992) is a meta learning algorithm that stacks two “levels” of predictors. Level 0 includes one or more predictors h(0) 1 , h(0) 2 , ... , h(0) K : Rd —* R, each one is trained on the original d-dimensional feature space. The level 1 predictor h(1) : Rd+K —* R is trained in the augmented (d+K)-dimensional feature space, in which predictions at level 0 are taken as extra features in h(1). (Kou and Cohen, 2007) proposed stacked graphi428 cal learning f</context>
</contexts>
<marker>Li, Zheng, Bu, Tang, Zhu, Huang, 2009</marker>
<rawString>F. Li, Z. Zheng, F. Bu, Y. Tang, X. Zhu, and M. Huang. 2009. Thu quanta at tac 2009 kbp and rte track. In Proceedings of Test Analysis Conference 2009 (TAC 09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e FT Martins</author>
<author>Dipanjan Das</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Stacking dependency parsers.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>157--166</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6991" citStr="Martins et al., 2008" startWordPosition="1060" endWordPosition="1063"> global ranker. The differences are that we use stacking to train the local ranker to handle the train/test mismatch problem and top k candidates to generate features for the global ranker. Stacked generalization (Wolpert, 1992) is a meta learning algorithm that uses multiple learners outputs to augment the feature space of subsequent learners. It utilizes a cross-validation strategy to address the train set / testset label mismatch problem. Various applications of stacking in NLP have been proposed, such as collective document classification (Kou and Cohen, 2007), stacked dependency parsing (Martins et al., 2008) and joint Chinese word segmentation and part-of-speech tagging (Sun, 2011). (Kou and Cohen, 2007) propose stacked graphical learning which captures dependencies between data with relational template. Our method is inspired by their approach. The difference is our base learner is an L2R model. We search related entity candidates in a large semantic relatedness graph, based on the assumption that true candidates are often semantically correlated while false ones scattered around. Wikipedians annotate entries in Wikipedia with category network. This valuable information generalizes entity-contex</context>
</contexts>
<marker>Martins, Das, Smith, Xing, 2008</marker>
<rawString>Andr´e FT Martins, Dipanjan Das, Noah A Smith, and Eric P Xing. 2008. Stacking dependency parsers. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 157–166. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Milne</author>
<author>I H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>509--518</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="16483" citStr="Milne and Witten, 2008" startWordPosition="2700" endWordPosition="2703">feating [[Republican|Republican Party (United States)]] nominee [[Romney|Mitt Romney]] Figure 1: Semantic links for collective entity linking. Annotation [[mention|entity]] follows Wikipedia conventions. Democratic Party (Italy) Democratic Party (Serbia) Obama, Fukui Obama, Nagasaki ... ... ... ... Barack Obama Democratic Party (United States) Republican Party (United States) Republican Party of Minnesota Republicanism Romney, West Virginia HMS Romney (1694) Mitt Romney Finally, the semantic relatedness measure of two entities ei,ej is defined as the common in-links of ei and ej in Wikipedia (Milne and Witten, 2008; Han et al., 2011): log(max(|A|, |B|)) − log(|A ∩ B|) �R(ei, ej) = 1−log(|W|) − log(min(|A|, |B|)) (5) where A and B are the set of in-links for entity ei and ej respectively, and W is the set of all Wikipedia pages. Our method is a trade-off between exact collective inference and approximating related instance with top ranked entities produced by go. Most collective approaches take all ambiguous mentions into consideration and disambiguate them simultaneously, resulting in difficulty when inference in large search space (Kulkarni et al., 2009; Hoffart et al., 2011). Others resolve to some ki</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>D. Milne and I.H. Witten. 2008. Learning to link with wikipedia. In Proceedings of the 17th ACM conference on Information and knowledge management, pages 509–518. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ratinov</author>
<author>D Roth</author>
<author>D Downey</author>
<author>M Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="2624" citStr="Ratinov et al., 2011" startWordPosition="381" endWordPosition="384">extual document d and entity definition e. L2R approaches are very flexible and expressive. Features like name matching, context similarity (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) and category context correlation (Bunescu and Pasca, 2006) can be incorporated with ease. Nevertheless, decisions are made independently and inconsistent results are found from time to time. Collective approaches utilize dependencies between different decisions and resolve all ambiguous mentions within the same context simultaneously (Han et al., 2011; Hoffart et al., 2011; Kulkarni et al., 2009; Ratinov et al., 2011). Collective approaches can improve performance when local evidence is not confident enough. They often utilize semantic relations across different mentions, and is why they are called global approaches, while L2R methods fall into local approaches (Ratinov et al., 2011). However, collective inference processes are often expensive and involve an exponential search space. We propose a collective entity linking method based on stacking. Stacked generalization (Wolpert, 1992) is a powerful meta learning algorithm that uses two levels of learners. The predictions of the first learner are taken as </context>
<context position="5748" citStr="Ratinov et al., 2011" startWordPosition="861" endWordPosition="864">ation indeed helps improve entity linking performance. 2 Related Work Most popular entity linking systems use the L2R framework (Bunescu and Pasca, 2006; Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010). Its discriminative nature gives the model enough flexibility and expressivity. It can include any features that describe the similarity or dissimilarity of context d and candidate entity e. They often perform well even on small training set, with carefullydesigned features. This category falls into the local approach as the decision processes for each mention are made independently (Ratinov et al., 2011). (Cucerzan, 2007) first suggests to optimize an objective function that is similar to the collective approach. However, the author adopts an approximation method because of the large search space (which is O(n&apos;) for a document with m mentions, each with n candidates). Various other methods like integer linear programming (Kulkarni et al., 2009), personalized PageRank (Han et al., 2011) and greedy graph cutting (Hoffart et al., 2011) have been explored in literature. Our method without stacking resembles the method of (Ratinov et al., 2011) in that they use the predictions of a local ranker to</context>
<context position="17245" citStr="Ratinov et al., 2011" startWordPosition="2823" endWordPosition="2826"> for entity ei and ej respectively, and W is the set of all Wikipedia pages. Our method is a trade-off between exact collective inference and approximating related instance with top ranked entities produced by go. Most collective approaches take all ambiguous mentions into consideration and disambiguate them simultaneously, resulting in difficulty when inference in large search space (Kulkarni et al., 2009; Hoffart et al., 2011). Others resolve to some kinds of approximation. (Cucerzan, 2007) construct features as the average of all candidates for one mention, introducing considerable noise. (Ratinov et al., 2011) also employ a two level architecture but only take top 1 prediction for features. This most resembles our approach, except we use stacking to tackle the train/test mismatch problem, and construct different set of features from top k candidates predicted by go. We will show in our experiments that this indeed helps boost performance. 3.4 Learning category-context coherence model cat Entities in Wikipedia are annotated with rich semantic structures. Category network provides us with another valuable information for entity linking. Take the mention “Romney” as an example, one candidate “Mitt Rom</context>
<context position="21510" citStr="Ratinov et al., 2011" startWordPosition="3526" endWordPosition="3529">word vector. The input can be a TF-IDF vector or binary vector. We denote model trained with normalized TF-IDF and with binary input as cat0 and cats respectively. 4 Experiments 4.1 Datasets Previous researches have used diverse datasets for evaluation, which makes it hard for comparison with others’ approaches. TAC-KBP has several years of data for evaluating entity linking system, but is not well suited for evaluating collective approaches. Recently, (Hoffart et al., 2011) annotated a clean and much larger dataset AIDA 1 for collective approaches evaluation based on CoNLL 2003 NER dataset. (Ratinov et al., 2011) also refined previous work and contribute four publicly available datasets 2. Thanks to their great works, we have enough data to evaluate against. According to the setting of (Hoffart et al., 2011), we split the AIDA dataset for train/development/test with 946/216/231 documents. We train a separate model on the Wikipedia training set for evaluating ACE/QUAINT/WIKI dataset (Ratinov et al., 2011). Table 2 gives a brief overview of the datasets used. For knowledge base, we use the Wikipedia XML dump 3 to extract over 3.3 million entities. We use annotation from Wikipedia to build a name diction</context>
<context position="23897" citStr="Ratinov et al., 2011" startWordPosition="3897" endWordPosition="3900">o-naga/aida/ 2http://cogcomp.cs.illinois.edu/Data, we don’t find the MSNBC dataset in the zip file. 3available at http://dumps.wikimedia.org/enwiki/, we use the 20110405 xml dump. 431 Dataset ndocs non- identified solvable NIL AIDA dev 216 4791 4791 4707 AIDA test 231 4485 4485 4411 ACE 36 257 238 209(185) AQUAINT 50 727 697 668(588) Wikipedia 40 928 918 854(843) Table 2: Number of mentions in each dataset. “identified” means the mention exists in our name dictionary and “solvable” means the true entity are among the top 30 candidates by popularity. Number in parenthesis shows the results of (Ratinov et al., 2011). method, both AIDA and ILP solution are quite slow at running time. The online demo of AIDA takes over 10 sec to process one document with moderate size, while the ILP solution takes around 2- 3 sec/doc. In contrast, our method takes only 0.3 sec/doc, and is easy to implement. (Ratinov et al., 2011) also utilize a two layer learner architecture. The difference is that their method use top 1 candidate generated by local learner for global feature generation , while we search the top k candidates. Moreover, stacking is used to tackle the train/test mismatch problem in our model. We re-implement</context>
<context position="25409" citStr="Ratinov et al., 2011" startWordPosition="4154" endWordPosition="4157">nks for global coherence. 4.3 Settings We implement 5V Mrank with an adaptation of linear SVM in scikit-learn (which is a wrapper of Liblinear). The category-context coherence model is implemented with Numpy configured with OpenBlas library, and we train this model on the entire Wikipedia hyperlink annotation. It takes about 1.5d for one pass over the entire dataset. The learning rate A is set to 1e-4 and training cost before update is below 0.02. Parameter tuning: there aren’t many parameters to tune for both g0 and g1. The context document window size is fixed as 100 for compatibility with (Ratinov et al., 2011; Hoffart et al., 2011). The number of candidates is fixed to top 30 ranked by entity’s popularity. Increase this value will generally boost recall at the cost of lower precision. We introduce the following default parameter for global features in g1. The number of fold for stacking is set to {1,5,10} (see Table 4, default is 10; 1 means no stacking, i.e. training g0 with all training data and generating level 1 features for training data directly with this g0). The number k for searching neighboring entities with relational template is set to {1,3,5,7} (e.g. in step 2 of Section 3.3 k = 5; de</context>
<context position="26664" citStr="Ratinov et al., 2011" startWordPosition="4370" endWordPosition="4373">modeling, the vocabulary sizes of context and category are set to top 10k and 6k unigrams by frequency. The latent dimension of low rank approximation is set to 200. Performance measures: For all non-NIL queries, we evaluate performance with micro precision averaged over queries and macro precision averaged over documents. Mean Reciprocal Rank (MRR) is an information retrieval measure and is �defined as Q i Q 1 , where ranki is the rank ranki of correct answer in response to query i. For ACE/AQUAINT/WIKI we also give the accuracy of “solvable” mentions, but this is not directly comparable to (Ratinov et al., 2011). Our name dictionary is different from theirs and ours has a higher recall rate (Tbl. 2). Hence, the “solvable” set is different. k recall k recall 1 78.56 6 96.31 2 89.59 7 97.04 3 93.01 8 97.37 4 94.97 9 97.62 5 95.78 10 97.81 Table 3: Top k recall for local predictor go. 4.4 Discussions Table 4 shows the evaluation results on AIDA dataset and Table 5 shows results on datasets ACE/AQUAINT/WIKI. Effect of cat:The first group in Table 4 shows some baseline features for comparison. We can see even if the categories only carry incomplete and noisy information about an entity, it performs much 4</context>
<context position="29690" citStr="Ratinov et al., 2011" startWordPosition="4891" endWordPosition="4894"> true entity can be lower in testset than in training set, the semantic coherence information can still be captured with searching over top k candidates. Effect of top k global features: Group 4 in Table 4 shows the effect of k on g1 performance. Clearly, increasing k generally improves precision and one possible reason is the improvement in recall when searching for related instances. Table 3 shows the top k recall of local predictor g0. Further increasing k does not show any improvement. Our method benefits from such a searching strategy, and consistently outperforms the global features of (Ratinov et al., 2011). While their method is a trade-off between expensive exact search over all mentions and greedy assigning all mentions with local predictor, we show this idea can be further extended, somewhat like increasing the beam search size without additional computational overhead. The only exception is the ACE dataset, since this dataset is so small, the difference translates to only one mention. One may notice the improvement on ACE/AQUAINT datasets is a little inconsistent. These datasets are much smaller and the results only differ within 4 mentions. Because these models are 433 Method micro macro M</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>L. Ratinov, D. Roth, D. Downey, and M. Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In Proceedings of the Annual Meeting of the Association of Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Sen</author>
</authors>
<title>Collective context-aware topic models for entity disambiguation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web,</booktitle>
<pages>729--738</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="31784" citStr="Sen, 2012" startWordPosition="5236" endWordPosition="5237">Error analysis As we analyze the development set of AIDA, we find some general problems with location names. Location name generally is not part of the main topic of one document. Thus, comparing context with its definition is not realistic. Most of the time, we can find some related location names in context; but other times, it is not easily distinguished. For instance, in “France beats Turkey in men’s football...” France refers to “France national football team” but our system links it to the country page “France” because it is more popular. This can be addressed by modeling finer context (Sen, 2012) or local syntactic pattern (Hoffart et al., 2011). In other cases, our system misclassifies “New York City” for “New York” and “Netherlands” for “Holland” and “People’s Republic of China” for “China”, because in all these cases, the latter ones are the most popular in Wikipedia. It is even hard for us humans to tell the difference based only on context or global coherence. 5 Conclusions We propose a stacking based collective entity linking method, which stacks a global predictor on top of a local predictor to collect coherence information from neighboring decisions. It is fast and easy to imp</context>
</contexts>
<marker>Sen, 2012</marker>
<rawString>P. Sen. 2012. Collective context-aware topic models for entity disambiguation. In Proceedings of the 21st international conference on World Wide Web, pages 729–738. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Shirakawa</author>
<author>H Wang</author>
<author>Y Song</author>
<author>Z Wang</author>
<author>K Nakayama</author>
<author>T Hara</author>
<author>S Nishio</author>
</authors>
<title>Entity disambiguation based on a probabilistic taxonomy.</title>
<date>2011</date>
<tech>Technical report, Technical Report MSR-TR-2011-125, Microsoft Research.</tech>
<contexts>
<context position="27669" citStr="Shirakawa et al., 2011" startWordPosition="4537" endWordPosition="4540"> ACE/AQUAINT/WIKI. Effect of cat:The first group in Table 4 shows some baseline features for comparison. We can see even if the categories only carry incomplete and noisy information about an entity, it performs much 432 Table 4: Performance on AIDA dataset. Maximal value in each group are highlighted with bold font. top k means up to k candidates are used for searching related instances with relational template. Methods cosine jaccard cat0 cat1 popularity g0 g0+global(Ratinov) g1+1fold g1+5fold g1+10fold g1+top1 g1+top3 g1+top5 g1+top7 g0+cat g1+cat g1+cat+all context (Hoffart et al., 2011) (Shirakawa et al., 2011) (Kulkarni et al., 2009) (Han et al., 2011) Devset Testset micro macro MRR micro macro MRR p@1 p@1 p@1 p@1 33.25 28.61 46.03 33.33 28.63 46.54 44.71 36.56 57.76 45.66 36.89 57.08 54.75 47.14 67.70 61.52 54.72 72.55 60.15 54.64 72.98 65.46 61.04 76.84 69.21 67.59 79.26 69.07 72.63 79.45 76.04 73.63 84.21 76.16 78.17 84.58 81.30 78.03 88.14 81.45 81.89 88.70 82.01 78.52 88.90 83.59 83.58 90.05 81.99 78.42 88.87 83.52 83.37 89.99 82.01 78.53 88.91 83.59 83.55 90.03 81.65 78.76 88.51 81.81 82.55 89.06 82.20 78.64 88.98 83.52 83.34 89.94 82.01 78.57 88.90 83.63 83.76 90.05 82.05 78.40 88.90 83.75 8</context>
</contexts>
<marker>Shirakawa, Wang, Song, Wang, Nakayama, Hara, Nishio, 2011</marker>
<rawString>M. Shirakawa, H. Wang, Y. Song, Z. Wang, K. Nakayama, T. Hara, and S. Nishio. 2011. Entity disambiguation based on a probabilistic taxonomy. Technical report, Technical Report MSR-TR-2011-125, Microsoft Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N A Smith</author>
<author>J Eisner</author>
</authors>
<title>Contrastive estimation: Training log-linear models on unlabeled data.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>354--362</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="19830" citStr="Smith and Eisner, 2005" startWordPosition="3225" endWordPosition="3228">parison is performed in the latent semantic space, so that synonymy and polysemy are implicitly handled by its inner mechanism. The score function between query q and document d is defined as: f(q, d) = qT Wd (6) 430 where W is learned with supervision like clickthrough data. Given training data {(qi, di)}, training is done by randomly sampling a negative target d−. The model optimizes W such that f(q, d+) &gt; f(q, d−). Thus, the training objective is to minimize the following margin-based loss function: � max(0,1 − f(q, d+) + f(q, d−)) (7) q,d+,d− which is also known as contrastive estimation (Smith and Eisner, 2005). W can become very large and inefficient when we have a big vocabulary size. This is addressed by replacing W with its low rank approximation: W = UT V + I (8) here, the identity term I is a trade-off between the latent space model and a vector space model. The gradient step is performed with Stochastic Gradient Descent (SGD): U &lt;--U + AV (d+ − d−)qT, if 1 − f(q, d+) + f(q, d−) &gt; 0 (9) V &lt;--V + AUq(d+ − d−)T, if 1 − f(q, d+) + f(q, d−) &gt; 0. (10) where A is the learning rate. The query and document are not necessary real query and document. In our case, we treat our problem as: given the occur</context>
</contexts>
<marker>Smith, Eisner, 2005</marker>
<rawString>N.A. Smith and J. Eisner. 2005. Contrastive estimation: Training log-linear models on unlabeled data. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 354–362. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Sun</author>
</authors>
<title>A stacked sub-word model for joint chinese word segmentation and part-of-speech tagging.</title>
<date>2011</date>
<booktitle>In ACL,</booktitle>
<pages>1385--1394</pages>
<contexts>
<context position="7066" citStr="Sun, 2011" startWordPosition="1073" endWordPosition="1074">handle the train/test mismatch problem and top k candidates to generate features for the global ranker. Stacked generalization (Wolpert, 1992) is a meta learning algorithm that uses multiple learners outputs to augment the feature space of subsequent learners. It utilizes a cross-validation strategy to address the train set / testset label mismatch problem. Various applications of stacking in NLP have been proposed, such as collective document classification (Kou and Cohen, 2007), stacked dependency parsing (Martins et al., 2008) and joint Chinese word segmentation and part-of-speech tagging (Sun, 2011). (Kou and Cohen, 2007) propose stacked graphical learning which captures dependencies between data with relational template. Our method is inspired by their approach. The difference is our base learner is an L2R model. We search related entity candidates in a large semantic relatedness graph, based on the assumption that true candidates are often semantically correlated while false ones scattered around. Wikipedians annotate entries in Wikipedia with category network. This valuable information generalizes entity-context correlation to category-context correlation. (Bunescu and Pasca, 2006) ut</context>
</contexts>
<marker>Sun, 2011</marker>
<rawString>Weiwei Sun. 2011. A stacked sub-word model for joint chinese word segmentation and part-of-speech tagging. In ACL, pages 1385–1394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David H Wolpert</author>
</authors>
<date>1992</date>
<booktitle>Stacked generalization. Neural networks,</booktitle>
<pages>5--2</pages>
<contexts>
<context position="3101" citStr="Wolpert, 1992" startWordPosition="451" endWordPosition="452">ous mentions within the same context simultaneously (Han et al., 2011; Hoffart et al., 2011; Kulkarni et al., 2009; Ratinov et al., 2011). Collective approaches can improve performance when local evidence is not confident enough. They often utilize semantic relations across different mentions, and is why they are called global approaches, while L2R methods fall into local approaches (Ratinov et al., 2011). However, collective inference processes are often expensive and involve an exponential search space. We propose a collective entity linking method based on stacking. Stacked generalization (Wolpert, 1992) is a powerful meta learning algorithm that uses two levels of learners. The predictions of the first learner are taken as augmented features for the second learner. The nice property of stacking is that it does not restrict the form of the base learner. In this paper, our base learner, an L2R ranker, is first employed to generate a ranking list of candidates. 426 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 426–435, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics At the next level, we search for se</context>
<context position="6598" citStr="Wolpert, 1992" startWordPosition="1002" endWordPosition="1003">entions, each with n candidates). Various other methods like integer linear programming (Kulkarni et al., 2009), personalized PageRank (Han et al., 2011) and greedy graph cutting (Hoffart et al., 2011) have been explored in literature. Our method without stacking resembles the method of (Ratinov et al., 2011) in that they use the predictions of a local ranker to generate features for global ranker. The differences are that we use stacking to train the local ranker to handle the train/test mismatch problem and top k candidates to generate features for the global ranker. Stacked generalization (Wolpert, 1992) is a meta learning algorithm that uses multiple learners outputs to augment the feature space of subsequent learners. It utilizes a cross-validation strategy to address the train set / testset label mismatch problem. Various applications of stacking in NLP have been proposed, such as collective document classification (Kou and Cohen, 2007), stacked dependency parsing (Martins et al., 2008) and joint Chinese word segmentation and part-of-speech tagging (Sun, 2011). (Kou and Cohen, 2007) propose stacked graphical learning which captures dependencies between data with relational template. Our me</context>
<context position="11355" citStr="Wolpert, 1992" startWordPosition="1820" endWordPosition="1821">feature: percentage of Wikipedia hyperlinks pointing to e given mention m, i.e. P(e|m) Category-context coherence model: cat0 and cat1 (details in Section 3.4) Table 1: Features for local predictor go. useful features like string matching and entity popularity cannot be easily expressed by collective approaches like (Hoffart et al., 2011; Han et al., 2011). The features for level 0 predictor g0 are described in Table 1. The reader can consult (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) for further reference. 3.2 Stacking training for global predictor g1 Stacked generalization (Wolpert, 1992) is a meta learning algorithm that stacks two “levels” of predictors. Level 0 includes one or more predictors h(0) 1 , h(0) 2 , ... , h(0) K : Rd —* R, each one is trained on the original d-dimensional feature space. The level 1 predictor h(1) : Rd+K —* R is trained in the augmented (d+K)-dimensional feature space, in which predictions at level 0 are taken as extra features in h(1). (Kou and Cohen, 2007) proposed stacked graphi428 cal learning for learning and inference on relational data. In stacked graphical learning, dependencies among data are captured by relational template, with which on</context>
</contexts>
<marker>Wolpert, 1992</marker>
<rawString>David H Wolpert. 1992. Stacked generalization. Neural networks, 5(2):241–259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhicheng Zheng</author>
<author>Fangtao Li</author>
<author>Minlie Huang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Learning to link entities with knowledge base.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>483--491</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="2179" citStr="Zheng et al., 2010" startWordPosition="316" endWordPosition="319">is known as entity linking or disambiguation (Ji et al., 2011). The resulting text is populated with semantic rich links to knowledge base like Wikipedia, and ready for various downstream NLP applications. &amp;quot;Corresponding author Previous researches have proposed several kinds of effective approaches for this problem. Learning to rank (L2R) approaches use hand-crafted features f(d, e) to describe the similarity or dissimilarity between contextual document d and entity definition e. L2R approaches are very flexible and expressive. Features like name matching, context similarity (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) and category context correlation (Bunescu and Pasca, 2006) can be incorporated with ease. Nevertheless, decisions are made independently and inconsistent results are found from time to time. Collective approaches utilize dependencies between different decisions and resolve all ambiguous mentions within the same context simultaneously (Han et al., 2011; Hoffart et al., 2011; Kulkarni et al., 2009; Ratinov et al., 2011). Collective approaches can improve performance when local evidence is not confident enough. They often utilize semantic relations across different mention</context>
<context position="5316" citStr="Zheng et al., 2010" startWordPosition="793" endWordPosition="796"> combines the benefits of both coherence modeling of collective approaches and expressivity of L2R methods. We show an effective usage of ranking list as global features, which is a key improvement for the global predictor. (2) To overcome problems of scalability and shallow word-level comparison, we learn the categorycontext correlation with recent advances of representation learning, and show that this extra semantic information indeed helps improve entity linking performance. 2 Related Work Most popular entity linking systems use the L2R framework (Bunescu and Pasca, 2006; Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010). Its discriminative nature gives the model enough flexibility and expressivity. It can include any features that describe the similarity or dissimilarity of context d and candidate entity e. They often perform well even on small training set, with carefullydesigned features. This category falls into the local approach as the decision processes for each mention are made independently (Ratinov et al., 2011). (Cucerzan, 2007) first suggests to optimize an objective function that is similar to the collective approach. However, the author adopts an approximation method becau</context>
<context position="11224" citStr="Zheng et al., 2010" startWordPosition="1800" endWordPosition="1803">and entire Wikipedia page of candidate 4. jaccard distance between context and introduction of Wikipedia page Popularity or prominence feature: percentage of Wikipedia hyperlinks pointing to e given mention m, i.e. P(e|m) Category-context coherence model: cat0 and cat1 (details in Section 3.4) Table 1: Features for local predictor go. useful features like string matching and entity popularity cannot be easily expressed by collective approaches like (Hoffart et al., 2011; Han et al., 2011). The features for level 0 predictor g0 are described in Table 1. The reader can consult (Li et al., 2009; Zheng et al., 2010; Lehmann et al., 2010) for further reference. 3.2 Stacking training for global predictor g1 Stacked generalization (Wolpert, 1992) is a meta learning algorithm that stacks two “levels” of predictors. Level 0 includes one or more predictors h(0) 1 , h(0) 2 , ... , h(0) K : Rd —* R, each one is trained on the original d-dimensional feature space. The level 1 predictor h(1) : Rd+K —* R is trained in the augmented (d+K)-dimensional feature space, in which predictions at level 0 are taken as extra features in h(1). (Kou and Cohen, 2007) proposed stacked graphi428 cal learning for learning and infe</context>
</contexts>
<marker>Zheng, Li, Huang, Zhu, 2010</marker>
<rawString>Zhicheng Zheng, Fangtao Li, Minlie Huang, and Xiaoyan Zhu. 2010. Learning to link entities with knowledge base. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 483–491, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>