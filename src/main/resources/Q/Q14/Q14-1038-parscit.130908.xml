<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.984533">
Learning Strictly Local Subsequential Functions
</title>
<author confidence="0.995535">
Jane Chandlee
</author>
<affiliation confidence="0.920042666666667">
University of Delaware
Department of Linguistics
and Cognitive Science
</affiliation>
<address confidence="0.991213">
125 East Main Street
Newark, DE 19716
</address>
<email confidence="0.998725">
janemc@udel.edu
</email>
<note confidence="0.89387125">
R´emi Eyraud
QARMA team
Laboratoire d’Informatique
Fondamentale
</note>
<address confidence="0.815118">
Marseille, France
</address>
<email confidence="0.6022105">
remi.eyraud@
lif.univ-mrs.fr
</email>
<author confidence="0.994477">
Jeffrey Heinz
</author>
<affiliation confidence="0.920015666666667">
University of Delaware
Department of Linguistics
and Cognitive Science
</affiliation>
<address confidence="0.9912195">
125 East Main Street
Newark, DE 19716
</address>
<email confidence="0.999132">
heinz@udel.edu
</email>
<sectionHeader confidence="0.996663" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999855428571429">
We define two proper subclasses of sub-
sequential functions based on the concept
of Strict Locality (McNaughton and Papert,
1971; Rogers and Pullum, 2011; Rogers et
al., 2013) for formal languages. They are
called Input and Output Strictly Local (ISL
and OSL). We provide an automata-theoretic
characterization of the ISL class and theorems
establishing how the classes are related to each
other and to Strictly Local languages. We give
evidence that local phonological and morpho-
logical processes belong to these classes. Fi-
nally we provide a learning algorithm which
provably identifies the class of ISL functions
in the limit from positive data in polynomial
time and data. We demonstrate this learning
result on appropriately synthesized artificial
corpora. We leave a similar learning result
for OSL functions for future work and sug-
gest future directions for addressing non-local
phonological processes.
</bodyText>
<sectionHeader confidence="0.998892" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998584">
In this paper we define two proper subclasses of sub-
sequential functions based on the properties of the
well-studied Strictly Local formal languages (Mc-
Naughton and Papert, 1971; Rogers and Pullum,
2011; Rogers et al., 2013). These are languages
that can be defined with grammars of substrings of
length k (called k-factors), such that a string is in
the language only if its own k-factors are a subset of
the grammar. These languages have also been char-
acterized by Rogers and Pullum (2011) as those that
have the property expressed in the following theo-
rem (which can be taken as a defining property):
</bodyText>
<construct confidence="0.68847525">
Theorem 1 (Suffix Substitution Closure). L is
Strictly Local ifffor all strings u1, v1, u2, v2, there
exists k E N such that for any string x of length
k − 1, if u1xv1, u2xv2 E L, then u1xv2 E L.
</construct>
<bodyText confidence="0.999773928571429">
These languages can model natural language
phonotactic constraints which pick out contiguous
substrings bounded by some length k (Heinz, 2007;
Heinz, 2010). We define Input Strictly Local (ISL)
and Output Strictly Local (OSL) functions which
model phonological processes for which the target
and triggering context are a bounded contiguous
substring. Here our use of ‘process’ is not specific
to rule-based grammatical formalisms (such as SPE
(Chomsky and Halle, 1968)). ISL and OSL func-
tions model mappings from underlying forms to sur-
face forms, which are also the bedrock of constraint-
based frameworks like Optimality Theory (Prince
and Smolensky, 1993).
By showing that local phonological processes can
be modeled with ISL (and OSL) functions, we pro-
vide the strongest computational characterization of
the input-output mappings these processes repre-
sent. While it has been shown that phonological
mappings describable with rules of the form A →
B / C D (where A, B, C, and D are regular
languages) are regular (Johnson, 1972; Kaplan and
Kay, 1994), and even subsequential (Chandlee and
Heinz, 2012; Heinz and Lai, 2013), many logically
possible regular and subsequential mappings are not
plausible phonological mappings. Since these im-
plausible mappings cannot be modeled with ISL or
OSL functions, we provide a more precise notion of
</bodyText>
<page confidence="0.993268">
491
</page>
<bodyText confidence="0.979739276595745">
Transactions of the Association for Computational Linguistics, vol. 2, pp. 491–503, 2014. Action Editor: Alexander Clark.
Submitted 4/2014; Revised 8/2014; Published November 1, 2014. c�2014 Association for Computational Linguistics.
what constitues plausible phonological mappings.
In addition, we present the Input SL Function
Learning Algorithm (ISLFLA) and prove that it
identifies this class in the limit (Gold, 1967) in poly-
nomial time and data (de la Higuera, 1997). Our
approach follows previous work on learning subse-
quential transductions, namely Oncina et al. (1993),
Oncina and Var`o (1996), Castellanos et al. (1998),
and Gildea and Jurafsky (1996). Oncina et al. (1993)
present OSTIA (Onward Subsequential Transducer
Inference Algorithm), an algorithm that learns the
class of subsequential functions in the limit from
positive data. OSTIA is only guaranteed to identify
total functions exactly, but Oncina and Var`o (1996)
and Castellanos et al. (1998) present the modifica-
tions OSTIA-N, OSTIA-D, and OSTIA-R, which
learn partial functions using negative data, domain
information, and range information, respectively.
In terms of linguistic applications, Gildea and
Jurafsky (1996) show that OSTIA fails to learn
the phonological mapping of English flapping when
given natural language data. The authors modified
OSTIA with three learning heuristics (context, com-
munity, and faithfulness) and showed that the mod-
ified learner successfully learns flapping and sev-
eral other phonological rules. Context encodes the
idea that phonological changes depend on the con-
text of the segment undergoing the change. Commu-
nity gives the learner the ability to deduce that seg-
ments belonging to a natural class are likely to be-
have similarly. Lastly, faithfulness, by which under-
lying segments are assumed to be realized similarly
on the surface, was encoded with a forced alignment
between the input-output strings in the data set.1 We
believe this alignment removes OSTIA’s guarantee
that all subsequential functions are learned.
Similar to the approach of Gildea and Jurafsky
(1996), our learner employs a context bias because
it knows its target is an ISL function and therefore
the transduction only involves bounded contiguous
substrings. And similar to OSTIA-D (Oncina and
Var`o, 1996; Castellanos et al., 1998), the ISLFLA
makes use of domain information, because it makes
decisions based on the input strings of the data set. It
also employs a faithfulness bias in terms of the prop-
</bodyText>
<footnote confidence="0.9949075">
1The alignment was similar to the string-edit distance
mehod used in Hulden et al. (2011).
</footnote>
<bodyText confidence="0.99984784">
erty onwardness (see §2). The ISLFLA is supported
by a theoretical result like Oncina et al. (1993), but
learns a more restrictive class of mappings. We be-
lieve the theoretical results for this class will lead to
new algorithms which include something akin to the
community bias and that will succeed on natural lan-
guage data while keeping strong theoretical results.
The proposed learner also builds on earlier work
by Chandlee and Koirala (2014) and Chandlee and
Jardine (2014) which also used strict locality to learn
phonological processes but with weaker theoretical
results. The former did not precisely identify the
class of functions the learner could learn, and the
latter could only guarantee learnability of the ISL
functions with a closed learning sample.
The paper is organized as follows. §2 presents the
mathematical notations to be used. §3 defines ISL
and OSL functions, provides an automata-theoretic
characterization for ISL, and establishes some prop-
erties of these classes. §4 demonstrates how these
functions can model local phonological processes,
including substitution, insertion, and deletion. §5
presents the ISLFLA, proves that it efficiently learns
the class of ISL functions, and provides demonstra-
tions. §6 concludes.
</bodyText>
<sectionHeader confidence="0.985588" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.99420395">
The set of all possible finite strings of symbols from
a finite alphabet E and the set of strings of length ≤
n are E∗ and E≤n, respectively. The unique empty
string is represented with λ. The length of a string w
is |w|, so |λ |= 0. The set of prefixes of w, Pref(w),
is {p ∈ E∗  |(∃s ∈ E∗)[w = ps]}, and the set of suf-
fixes of w, Suff(w), is {s ∈ E∗  |(∃p ∈ E∗)[w =
ps]}. For all w ∈ E∗ and n ∈ N, Suffn(w) is the
single suffix of w of length n if |w |≥ n; otherwise
Suffn(w) = w. If w = ps, then ws−1 = p and
p−1w = s. The longest common prefix of a set of
strings S, lcp(S), is p ∈ ∩w∈SPref(w) such that
∀p0 ∈ ∩w∈SPref(w), |p0 |C |p|.
A function f with domain A and co-domain B is
written f : A → B. We sometimes write x 7→f y
for f(x) = y. When A and B are free monoids (like
E∗), the input and output languages of a function f
are the stringsets dom(f) = {x  |(∃y)[x 7→f y]} and
image(f) = {y  |(∃x)[x 7→f y]}, respectively.
Following Oncina et al. (1993), a subsequen-
</bodyText>
<page confidence="0.997763">
492
</page>
<bodyText confidence="0.9003690625">
tial finite state transducer (SFST) is a 6-tuple
(Q, q0, E, F, δ, σ), where Q is a finite set of states,
E and F are finite alphabets, q0 ∈ Q is the initial
state, δ ⊆ Q × E × F* × Q is a set of edges, and
σ : Q → F* is the final output function that maps
states to strings that are appended to the output if the
input ends in that state. δ recursively defines a map-
ping δ*: (q, λ, λ, q) ∈ δ*; if (q, u, v, q&apos;) ∈ δ* and
(q&apos;, σ, w, q&apos;&apos;) ∈ δ then (q, uσ, vw, q&apos;&apos;) ∈ δ*. SFSTs
are deterministic, which means their edges have the
following property: [(q, a, u, r), (q, a, v, s) ∈ δ ⇒
u = v ∧ r = s]. Hence, we also refer to δ as
the transition function, and ∀(q, a, u, r) ∈ δ, we let
δ1(q, a) = u and δ2(q, a) = r.
The relation that a SFST T recog-
nizes/accepts/generates is
</bodyText>
<equation confidence="0.999396">
�R(T) = (x, yz) ∈ E* × F*  |(∃q ∈ Q)
[(q0, x, y, q) ∈ δ* ∧ z = σ(q)]} .
</equation>
<bodyText confidence="0.9890802">
Since SFSTs are deterministic, the relations they
recognize are functions. Subsequential functions are
defined as those describable with SFSTs.
For any function f : E* → F* and x ∈ E*, let the
tails of x with respect to f be defined as
</bodyText>
<equation confidence="0.999561">
tailsf(x) = {(y, v)  |f(xy) = uv ∧
u = lcp(f(xE*))I .
</equation>
<bodyText confidence="0.999064777777777">
If strings x1, x2 ∈ E* have the same set of tails with
respect to a function f, they are tail-equivalent with
respect to f and we write x1 ∼f x2. Clearly, ∼f is
an equivalence relation which partitions E*.
Theorem 2 (Oncina and Garcia, 1991). A function
f is subsequential iff ∼f partitions E* into finitely
many blocks.
The above theorem can be seen as the functional
analogue to the MyHill-Nerode theorem for regular
languages. Recall that for any stringset L, the tails
of a word w w.r.t. L is defined as tailsL(w) =
{u  |wu ∈ L}. These tails can be used to par-
tition E* into a finite set of equivalence classes
iff L is regular. Furthermore, these equivalence
classes are the basis for constructing the (unique
up to isomorphism) smallest deterministic acceptor
for a regular language. Likewise, Oncina and Gar-
cia’s proof of Theorem 2 shows how to construct
the (unique up to isomorphism) smallest SFST for
a subsequential function f. We refer to this trans-
ducer as the canonical transducer for f and denote it
with Tf&apos; . The states of Tf&apos; are in one-to-one corre-
spondence with tailsf(x) for all x ∈ E* (Oncina
and Garcia, 1991). To construct Tf&apos; first let, for
all x ∈ E* and a ∈ E, the contribution of a w.r.t.
x be contf(a, x) = lcp(f(xE*)−1lcp(f(xaE*)).
Then,
</bodyText>
<listItem confidence="0.991773142857143">
• Q = {tailsf(x)  |x ∈ E*},
• q0 = tailsf(λ),
• ∀tailsf(x) ∈ Q, σ(tailsf(x)) =
lcp(f(xE*))−1f(x) if x ∈ dom(f) and is un-
defined otherwise,
• δ = {(tailsf(x), a, contf(a, x),
tailsf(xa))}.
</listItem>
<bodyText confidence="0.926340666666667">
Tf&apos; has an important property called onwardness.
Definition 1 (onwardness). For all q ∈ Q let the
outputs of the edges out of q be outs(q) = {u |
(∃a ∈ E)(∃r ∈ Q)[(q, a, u, r) ∈ δ]}. A SFST T is
onward iffor all q ∈ Q \ {q0}, lcp(outs(q)) = λ.
Informally, this means that the writing of output
is never delayed. Readers are referred to Oncina
and Garcia (1991), Oncina et al. (1993), and Mohri
(1997) for more on SFSTs.
</bodyText>
<sectionHeader confidence="0.974089" genericHeader="method">
3 Strictly Local Functions
</sectionHeader>
<bodyText confidence="0.885562083333333">
In this section we define Input and Output Strictly
Local functions and provide properties of these
classes. These definitions are analogous to the
language-theoretic definition of Strictly Local lan-
guages (Theorem 1) (Rogers and Pullum, 2011;
Rogers et al., 2013).
Definition 2 (Input Strictly Local Function). A func-
tion f is Input Strictly Local (ISL) if there is a k
such that for all u1, u2 ∈ E*, if Suffk−1(u1) =
Suffk−1(u2) then tailsf(u1) = tailsf(u2).
The theorem below establishes an automata-
theoretic characterization of ISL functions.
</bodyText>
<listItem confidence="0.6781814">
Theorem 3. A function f is ISL iff there is some k
such that f can be described with a SFST for which
1. Q = E&lt;k−1 and q0 = λ
2. (∀q ∈ Q,∀a ∈ E,∀u ∈ F*)
[(q, a, u, q&apos;) ∈ δ ⇒ q&apos; = Suffk−1(qa)].
</listItem>
<page confidence="0.99723">
493
</page>
<bodyText confidence="0.961886333333333">
This theorem helps make clear how ISL functions
are Markovian: the output for input symbol a de-
pends on the last (k — 1) input symbols. Also, since
the transducer defined in Theorem 3 is determinis-
tic, it is unique and we refer to it as TISL
f .TISL fmay
not be isomorphic to TfC. Figure 1 shows TISL
f (with
k = 2) and TfC for the identity function.2
</bodyText>
<figureCaption confidence="0.998302">
Figure 1: Non-isomorphic TfISL (left) and TfC (right)
</figureCaption>
<bodyText confidence="0.998134">
Before we present the proof of Theorem 3, we make
the following remarks, and then prove a lemma.
</bodyText>
<construct confidence="0.78335425">
Remark 1. For all n, m E N with n &lt; m, and for
all w E E*, Suffn(Suffm(w)) = Suffn(w) since
both w and Suffm(w) share the same n-long suffix.
Remark 2. For all w, v E E*, k E N,
Suffk−1(Suffk−1(w)v) = Suffk−1(wv). This is
a direct consequence of Remark 1.
Lemma 1. Let T be a SFST constructed as in The-
orem 3. If (A, w, u, q) in S* then q = Suffk−1(w).
</construct>
<bodyText confidence="0.993574444444444">
Proof. The proof is by induction on S*. The base
case follows from the facts that (A, A, A, A) E S* (by
definition of S*), and that A = Suffk−1(A).
Next assume the inductive hypothesis (IH) that
there exists w E E*, u E F*, such that (A, w, u, q) E
S* implies q = Suffk−1(w). We show ba E E,
bx E F* that (A, wa, ux, q&apos;) E S* implies q&apos; =
Suffk−1(wa). Now (A, w, u, Suffk−1(w)) E S*
(by IH) so (Suffk−1(w), a, x, q&apos;) E S. By construc-
</bodyText>
<equation confidence="0.708978">
1
</equation>
<bodyText confidence="0.996197333333333">
tion of T, q&apos; = Suffk−1(Suffk−1(w)a), which by
Remark 2, equals Suffk−1(wa).
Proof of Theorem 3. (�) Fix k E N and let f be a
function described by T = {Q, q0, E, F, S, σ} con-
structed as in Theorem 3. Let w1, w2 E E* such
that Suffk−1(w1) = Suffk−1(w2). By Lemma 1,
</bodyText>
<footnote confidence="0.548501333333333">
2In all figures, single-symbol transition labels indicate that
the input and output are identical, and the final output function
is represented as a transition on the end-of-word symbol #.
</footnote>
<bodyText confidence="0.904970666666667">
both w1 and w2 lead to the same state and therefore
tailsf(w1) = tailsf(w2). Thus f is k-ISL.
(=&gt;) Consider any ISL function f. Then there
is a k such that (bw1,w2 E E*)[Suffk−1(w1) =
Suffk−1(w2) =&gt; tailsf(w1) = tailsf(w2)]. We
show that TISL
f exists. Since E&lt;k−1 is a finite set,
the equivalence relation —f partitions E* into at
most |E&lt;k−1 |blocks. Hence by Theorem 2, f is
subsequential and a canonical subsequential trans-
ducer TfC = {Qc, q0c, E, F, Sc, σc} exists.
Construct T = {Q, q0, E, F, S, σ} as follows:
</bodyText>
<listItem confidence="0.9881328">
• Q = E&lt;k−1
and q0 = A
• bq E Q, σ(q) = σc(tailsf(q)) if f(q) is de-
fined, else σ(q) is undefined.
• bq E Q, ba E E, bu E F*,
</listItem>
<equation confidence="0.7728505">
(q, a, u, Suffk−1(qa)) E S iff
(tailsf(q), a, u, tailsf(qa)) E Sc.
</equation>
<bodyText confidence="0.955727766666667">
First, by its construction, the states and transitions
of T meet requirements (1) and (2) of Theorem 3.
Next, we show that T computes the same
function as TfC. We first establish by induc-
tion on S* the following (�): bw E E*,
bu E F*, (q0, w, u, Suffk−1(w)) E S* iff
(tailsf(A), w, u, tailsf(w)) E Sc*.
Clearly (tails f(A), A, A, tails f(A)) E Sc* and
(A, A, A, A) E S* by definition of the extended tran-
sition function. Thus the base case is satisfied.
Next assume the inductive hypothesis (IH) for
w E E* and u E F*. We show ba E E and
bx E F* that (A, wa, ux, Suffk−1(wa)) E S* iff
(tailsf(A), wa, ux, tailsf(wa)) E Sc*.
Suppose (tails f(A), wa, ux, tails f(wa)) E
S*c. By IH, (tailsf(A), w, u, tailsf(w)) E S* c ;
hence (tailsf(w), a, x, tailsf(wa)) E Sc.
Let q = Suffk−1(w). Observe that
Suffk−1(w) =
quently, since f is k-ISL, tailsf(w) = tailsf(q).
Similarly, Suffk−1(wa) = Suffk−1(qa) and thus
tailsf(wa) = tailsf(qa). By substitution then,
we have (tailsf(A), w, u, tailsf(q)) E S*c and
(tailsf(q), a, x, tailsf(qa)) E Sc.
By construction of T, (q, a, x, Suffk−1(qa)) E
S. By IH, (A, w, u, Suffk−1(w)) = (A, w, u, q) E
S*. Thus, (A, wa, ux, Suffk−1(qa)) E S* which is
the same as saying (A, wa, ux, Suffk−1(wa)) E S*.
Conversely, consider any a E E and x E
F* and suppose (A, wa, ux, Suffk−1(wa)) E S*.
</bodyText>
<figure confidence="0.924515888888889">
−ISL TC
T
#:λ
#:λ
λ
#:λ
λ
#:λ
Suffk−1(q) by Remark 1. Conse-
</figure>
<page confidence="0.951099">
494
</page>
<bodyText confidence="0.461013">
By IH, (A, w, u, Suffk−1(w)) E S∗; hence
(Suffk−1(w), a, x, Suffk−1(wa)) E S. As be-
fore, letting q = Suffk−1(w), it follows that
</bodyText>
<equation confidence="0.9827165">
Suffk−1(w) = Suffk−1(q) so tailsf(w) =
tailsf(q), and Suffk−1(wa) = Suffk−1(qa)
so tailsf(wa) = tailsf(qa). Therefore,
(q, a, x, Suffk−1(qa)) E S.
</equation>
<bodyText confidence="0.9997935">
By construction of T, this means
(tailsf(w), a, x, tailsf(wa)) E Sc. By IH,
(tailsf(A), w, u, tailsf(w)) E S∗c. By the defi-
nition of the extended transition function, it follows
that (tailsf(A), wa, ux, tailsf(wa)) E S∗c. This
completes the induction, establishing (*).
Let w E E∗. If f(w) is defined then f(w) = uv
where
</bodyText>
<equation confidence="0.94271475">
(tailsf(A), w, u, tailsf(w)) E S∗c
and Qc(tails f(w)) = v. From (*), we
know �A, w, u, Suffk−1(w)) E S∗. Also,
Q(Suff —1(w)) = Qc(tailsf(Suffk−1(w))).
Since f is k-ISL, tailsf(w)
tailsf(Suffk−1(w)) (cf. Remark 1). Thus
Q(Suffk−1(w)) = Qc(tailsf(w)) = v. There-
fore T (w) = uv also.
</equation>
<bodyText confidence="0.9752822">
If f(w) is not defined then there are two
cases. Case 1: (tailsf(A), w, u, tailsf(w)) E�
S∗c. By the above lemma, it follows
(A, w, u, Suffk−1(w)) E� S∗ and so T (w) is also de-
fined. Case 2: (tailsf(A), w, u, tailsf(w)) E S∗c
but Qc(tailsf(w)) is undefined. By construction
of T, Q(Suffk−1(w)) is also undefined.
Similar to Definition 2 above, the following defi-
nition of OSL functions says that if the outputs of
two input strings share the same suffix of length
(k − 1), then those inputs have the same tails.
Definition 3 (Output Strictly Local Function). A
function f is Output Strictly Local (OSL) if there is a
k such thatfor all u1,u2 E E∗, if Suffk−1(f(u1)) =
Suffk−1(f(u2)) then tailsf(u1) = tailsf(u2).
The automata-theoretic characterization of this class
is left as future work.
Next, some properties of ISL and OSL functions
are identified. The proofs of the following theorems
will refer to the example SFSTs in Figure 2.
First we establish that ISL and OSL functions
are proper subclasses of the subsequential functions.
(They are subclasses by definition.)
Theorem 4. There are subsequential functions
which are neither ISL nor OSL.
</bodyText>
<figureCaption confidence="0.991357">
Figure 2: Examples for proofs of Theorems 4-7
</figureCaption>
<bodyText confidence="0.946628888888889">
Proof. Consider the subsequential function f1 in
Figure 2 and choose any k E N. Since
f1(bckb) = bckb and f1(ackb) = acka it follows
that tailsf1(bck) =� tailsf1(ack) even though in-
puts bck and ack share a common suffix of length
(k − 1). Likewise, the outputs of these inputs
f1(bck) = bck and f1(ack) = ack share a common
suffix of length (k − 1), but the tails of these inputs,
as mentioned, are distinct. Hence by Definitions 2
</bodyText>
<equation confidence="0.601243">
1
</equation>
<bodyText confidence="0.7258484">
and 3, there is no k for which f1 is ISL or OSL.
Theorem 5. The class of ISL functions is incompa-
rable to the class of OSL functions.
Proof. Consider f2 in Figure 2. This function is ISL
by Theorem 3. However it is not OSL. Consider any
k E N. Observe that f2(aak) = f2(abk) = abk and
so the outputs share the same suffix of length (k −
1). However, tailsf2(aak) =� tailsf2(abk) since
(a, b) E tailsf2(aak) but (a, a) E tailsf2(abk).
Similarly, consider f3 in Figure 2. This function is
</bodyText>
<equation confidence="0.663895">
1
</equation>
<bodyText confidence="0.999785142857143">
2-OSL because inputs mapped to outputs which end
in a have the same tails (i.e., they all lead to state a),
and inputs mapped to outputs ending in b have the
same tails.
However, f3 is not ISL. Consider any k E
N. The inputs cbk and abk share the same suf-
fix of length (k − 1). However, tailsf3(cbk) =�
</bodyText>
<figure confidence="0.996602705882353">
#:λ
#:λ
#:λ
:
#:λ
λ
λ
f5
f6
:
#:λ
:
#:λ #:λ
0 1
#:λ
λ
#:λ
f,
: :
#:λ
#:λ
:
:
:
f3
f4
0 1
#:a #:
0 1
#:a #:a
:a
f2
:
=
</figure>
<page confidence="0.98967">
495
</page>
<bodyText confidence="0.980210222222222">
tailsf3(abk) since (b, b) ∈ tailsf3(cbk) but
(b, a) ∈ tailsf3(abk).
Finally, the two classes are obviously not disjoint,
since the identity function is both ISL and OSL.
Theorem 6. The output language of an ISL or OSL
function is not necessarily a Strictly Local language.
Proof. Consider f4 in Figure 2. By Theorem 3, it
is ISL. It is also 2-OSL since inputs mapped to out-
puts which end in a have the same tails (i.e., they all
lead to state a). Similarly, inputs mapped to outputs
ending in b have the same tails.
Let k ∈ N. Observe that f4(ak) = a2k and fur-
ther that there is no input x and k such that f4(x) =
a2k+1. Since a2k = ak−1aka = ak−2akaa, if the
output language of f4 were SL it would follow, by
Theorem 1, that ak−1akaa = a2k+1 also belongs
to the output language. But there is no input in E∗
which f4 maps to an odd sequence of a’s.
</bodyText>
<construct confidence="0.545976">
Theorem 7. If either the output or input language
of a subsequential function f is Strictly Local then it
does not follow that f belongs to either ISL or OSL.
</construct>
<bodyText confidence="0.998983857142857">
Proof. Let E = F = {a} and consider the function
f5 which, for all n ∈ N, maps an to an if n is even
and an to ana if n is odd. f5 is subsequential, as
shown in Figure 2, and its domain, a∗, is a Strictly
Local language. However, f5 is neither ISL nor OSL
for any k since the tails of a2k includes (A, A) but
the tails of aa2k includes (A, a).
Next consider f6, which for all n ∈ N maps an to
am where m = (n div 2) if n is even and m = (n div
2)+1 if n is odd. f6 is subsequential, as shown in
Figure 2, and the image(f) = a∗ is Strictly Local.
However, f is neither ISL nor OSL for any k since
the tails of a2k includes (a, a) but the tails of
aa2k includes (a, A).
</bodyText>
<sectionHeader confidence="0.992896" genericHeader="method">
4 Relevance to Phonology
</sectionHeader>
<bodyText confidence="0.9999658">
This section will briefly discuss the range of phono-
logical processes that can be modeled with ISL
and/or OSL functions by providing illustrative ex-
amples for three common, representative processes.
These are shown in (1) with SPE-style rules.
</bodyText>
<listItem confidence="0.998097">
(1) a. Devoicing: D → T / #
b. Epenthesis: 0 → a / {l, r} [-coronal]
c. Deletion: {0, d} → 0 / {0, s}
</listItem>
<bodyText confidence="0.998712090909091">
See Chandlee (2014) for more details.
First, consider the process of final obstruent de-
voicing (1-a), attested in German and other lan-
guages. This process causes an underlying voiced
obstruent in word-final position to surface as its
voiceless counterpart. In (1-a), D abbreviates the set
of voiced obstruents and T the voiceless obstruents.3
The mapping from underlying form to surface
form that this process describes is represented with
the 2-ISL function in Figure 3 (note N represents any
sonorant).
</bodyText>
<figureCaption confidence="0.997646">
Figure 3: TISL
</figureCaption>
<bodyText confidence="0.996328388888889">
f for (1-a) with k = 2 and E = {T, D, N}
In addition to substitution processes like (1-a), an-
other common type of process is insertion of a seg-
ment, such as the a-epenthesis process attested in
Dutch (Warner et al., 2001). This process inserts
a schwa between a liquid and a non-coronal con-
sonant, as specified by (1-b). Using L to represent
the liquids {l, r} and K to represent any non-coronal
consonant, Figure 4 presentsT ISL
f for this process.
Following Beesley and Karttunen (2003), the sym-
bol ‘?’ represents any segment of the alphabet other
than the ones for which transitions are defined.4
Lastly, an example deletion process from Greek
(Joseph and Philippaki-Warburton, 1987) deletes in-
terdental fricatives before /0/ or /s/, as in (1-c). Fig-
ure 5 presents TISL
f for this process.
</bodyText>
<footnote confidence="0.959248111111111">
3These abbreviations serve to improve the readability of the
1
FST - it is assumed that the transduction replaces a given voiced
obstruent with its voiceless counterpart (not with any voiceless
obstruent).
4This means Figure 4 is actually a shorthand for TISL
f , which
would otherwise have a distinct state for each symbol now rep-
resented with ‘?’.
</footnote>
<figure confidence="0.9769685">
:λ
#:
:λ
#:λ
:
:
λ
:λ
#:λ
#:λ
</figure>
<page confidence="0.909015">
496
</page>
<figureCaption confidence="0.998153">
Figure 4: TISL
</figureCaption>
<figure confidence="0.483832">
f for (1-b) with k = 2 and E = {L, K, ?}
</figure>
<figureCaption confidence="0.998692">
Figure 5: TISL
</figureCaption>
<bodyText confidence="0.998079294117647">
f for (1-c) with k = 2 and E = {0, d, s, ?}
The German, Dutch, and Greek examples demon-
strate how ISL functions can be used to model the
input-output mapping of a phonological rule. Be-
yond substitution, insertion, and deletion, it is shown
in Chandlee (2014) that ISL and/or OSL functions
can also model many metathesis patterns, specifi-
cally those for which there is an upper bound on
the amount of material that intervenes between a
segment’s original and surface positions (this ap-
pears to include all synchronic patterns). In addi-
tion, morpho-phonological processes such as local
partial reduplication (i.e., in which the reduplicant
is affixed adjacent to the portion of the base it was
copied from) and general affixation are also shown
to be ISL or OSL. More generally, we currently con-
jecture that a SPE-style rewrite rule of the form A
</bodyText>
<equation confidence="0.474187">
1
</equation>
<bodyText confidence="0.999550913043478">
→ B/ C D which applies simultaneously (left-
to-right) describes an Input (Output) Strictly Local
function iff there is a k such that for all w E CAD
it is the case that |w |G k. We refer readers to Ka-
plan and Kay (1994) and Hulden (2009) for more
on how SPE rules and application modes determine
mappings.
In contrast, non-local (long-distance) processes
such as vowel harmony with transparent vowels
(Gainor et al., 2012; Heinz and Lai, 2013), long dis-
tance consonant harmony (Hansson, 2001; Rose and
Walker, 2004; Luo, 2013) and dissimilation (Suzuki,
1998; Bennett, 2013; Payne, 2013), unbounded dis-
placement/metathesis (Chandlee et al., 2012; Chan-
dlee and Heinz, 2012), non-local partial reduplica-
tion (Riggle, 2003), and some tonal patterns (Jar-
dine, 2013) cannot be modeled with ISL or OSL
functions. In §6 we comment on the potential for
adapting the current analysis to non-local mappings.
The next section presents a learning algorithm for
ISL functions, the ISLFLA. The development of a
corresponding algorithm for OSL functions is the
subject of ongoing work, but see §6 for comments.
</bodyText>
<sectionHeader confidence="0.979199" genericHeader="method">
5 Learning Input Strictly Local Functions
</sectionHeader>
<bodyText confidence="0.999934">
We now present a learning algorithm for the class of
ISL functions that uses its defining property as an in-
ductive principle to generalize from a finite amount
of data to a possibly infinite function. This learner
begins with a prefix tree representation of this data
and then generalizes by merging states.5 Its state
merging criterion is based on the defining property
of ISL functions: two input strings with the same
suffix of length (k −1) have the same tails. The next
section explains in detail how the algorithm works.
</bodyText>
<subsectionHeader confidence="0.967974">
5.1 The Algorithm: ISLFLA
</subsectionHeader>
<bodyText confidence="0.967532222222222">
Given a finite dataset D of input-output string pairs
(w, w&apos;) such that f(w) = w&apos;, where f is the target
function, the learner tries to build TISL
f . The dataset
is submitted to the learner in the form of a prefix tree
transducer (PTT), which is defined in Definition 4.
Definition 4 (Prefix Tree Transducer). A prefix tree
transducer for finite set D =
for some f is PTT (D) = (Q, q0, E, Γ, S, σ), where
</bodyText>
<listItem confidence="0.996927666666667">
• Q = U{Pref(w)|(w, w&apos;) E D} and q0 = λ
• S = {(u, a, λ, ua)  |u, ua E Q}
• σ(w) = w&apos; for all (w, w&apos;) E D
</listItem>
<footnote confidence="0.8925885">
5This general strategy is common in grammatical inference.
See Angluin (1982), Heinz (2009), and de la Higuera (2010).
</footnote>
<figure confidence="0.9984719">
#:A
:a
#:A
A
#:A
#:A
#:λ
D
D:λ
#:λ D:λ D T:λ T:λ#:T
#:D
λ D:T T
T:λ
:T
T:λ
:D
T:λ
#:λ
D:λ
{(w, w&apos;)  |f(w) = w&apos;}
</figure>
<page confidence="0.995918">
497
</page>
<bodyText confidence="0.999607875">
As an example, the sample of data in (2) exempli-
fies the final devoicing rule in (1-a). Figure 6 gives
the PTT for this data.
deterministic. Non-determinism is removed in the
inner loop with additional state merges.
Consider the situation depicted on the lefthand
side of Figure 8, which resulted from a previous
merge. The non-determinism could be resolved by
</bodyText>
<figure confidence="0.434197">
(2) {(D, T), (DD, DT), (DNT, DNT), (NND,
NNT), (TDN, TDN)}
</figure>
<figureCaption confidence="0.997467">
Figure 6: PTT for the data in (2)
</figureCaption>
<bodyText confidence="0.999358222222222">
Given such a PTT, the learner’s first step is to make
it onward. In the PTT, the output string is with-
held until the end of the input (i.e., #) is reached.
In the onward version (shown in Figure 7), output is
advanced as close to the root as possible. This in-
volves determining the lcp of all the output strings
of all outgoing transitions of a state (starting from
the leaves) and suffixing that lcp to the output of
the single incoming transition of the state.
</bodyText>
<figureCaption confidence="0.998508">
Figure 7: Onward version of the PTT in Figure 6
</figureCaption>
<bodyText confidence="0.950453">
Once the learner has constructed this onward rep-
resentation of the data, it begins to merge states,
using two nested loops. The outer loop proceeds
through the entire state set (ordered lexicographi-
cally) and merges each state with the state that cor-
responds to its (k − 1)-length suffix. For example,
for final devoicing k = 2, so each state will be
merged with the state that represents its final sym-
bol. This merging may introduce non-determinism,
which must be removed since by definition TISL
f is
</bodyText>
<figureCaption confidence="0.999056">
Figure 8: Before (left) and after (right) pushback
</figureCaption>
<bodyText confidence="0.955950285714286">
merging states 1 and 2, except for the fact that the
output strings of the two transitions differ. Before
merging 1 and 2, therefore, the learner performs an
operation called pushback that retains the lcp of
the two output strings and prefixes what’s left to all
output strings of all outgoing transitions from the re-
spective destination states.
</bodyText>
<construct confidence="0.908846">
Definition 5 (pushback (Oncina et al., 1993)).
For SFST T = (Q, q0, E, F, 6, o), v E E*, and
e = (q, a, w, q&apos;) E 6, pushback(T, v, e) =
(Q, q0, E, F, 6&apos;, o) where 6&apos; = (6 U
{q, a, wv−1, q&apos;)} U {(q&apos;, b, vz, q&apos;&apos;)|(q&apos;, b, z, q&apos;&apos;) E
6}) \ ({(q&apos;, b, z, q&apos;&apos;)} U {e}).
</construct>
<bodyText confidence="0.967966368421053">
In the example in Figure 8, pushback is applied
to the edges (0, T, DT, 1) and (0, T, DTN, 2). Only
the lcp of the output strings, which is DT, is retained
as the output string of both edges. The remainder
(which is A and N, respectively) is prefixed to the
output string of all transitions leaving the respective
destination state. The result is shown on the right-
hand side of Figure 8. Essentially, pushback ‘un-
does’ onwardness when needed.
After pushback, states 1 and 2 can be merged.
This removes the initial non-determinism but creates
new non-determinism. The inner loop iterates un-
til all non-determinism is resolved, after which the
outer loop continues with the next state in the order.
If the inner loop encounters non-determinism that
cannot be removed, the ISLFLA exits with a mes-
sage indicating that the data sample is insufficient.
Non-removable non-determinism occurs if and
only if the situation depicted on the left in Figure
</bodyText>
<page confidence="0.352826">
9 obtains. The normal procedure for removing non-
</page>
<figure confidence="0.998468341463415">
:λ #:
:λ
:λ
#:
#:λ
λ
:λ
:λ
:λ
#:
:λ :λ #:
:λ :λ
#:
#:
#:λ
:λ
:λ #:λ
:
:
#:λ
:λ :λ #:λ
#:λ
λ
:
:
:λ
:λ
0 : 0
:
1
:
:A
:
:
1
:a
:
2
:A
2
:
</figure>
<page confidence="0.918165">
498
</page>
<figureCaption confidence="0.825193">
Figure 9: Irreparable non-determinism (left) and non-
determinism from an outer loop merge (right).
</figureCaption>
<bodyText confidence="0.998859875">
determinism cannot be applied in this case. Assum-
ing z =6 A, all of z would have to be pushed back,
but since this transition has no destination state there
is nowhere for z to go. OSTIA handles this situ-
ation by rejecting the outer loop merge that led to
it, restoring the FST to its state before that merge
and moving on to the next possible merge. But the
ISLFLA cannot reject merges. If it could, the pos-
sibility would arise that two states with the same
(k − 1)-length suffix would remain distinct in the
final FST the learner outputs. Such a FST would
not (by definition) be ISL. Therefore, the algorithm
is at an impasse: rejecting a merge can lead to a
non-ISL FST, while allowing it can lead to a non-
subsequential (hence non-ISL) FST. It therefore ter-
minates. Below is pseudo-code for the ISLFLA.
</bodyText>
<equation confidence="0.949704375">
Data: PTT (D)
Result:T ISL
f
τ = onward(PTT)
q = next(Qτ, first(Qτ))
while q &lt; last(Qτ) do
merge(q, Suffk−1(q))
1
</equation>
<construct confidence="0.747534166666667">
while ∃(q, a, x, q1), (q, a, y, q2) ∈ 6τ do
if a = # and x =6 y then
exit ‘Insufficient data’
else
pushback(τ, (q, a, x, q1), lcp(x, y))
pushback(τ, (q, a, y, q2), lcp(x, y))
</construct>
<equation confidence="0.765352">
merge(q1, q2)
q = next(Qτ, q)
return τ
</equation>
<construct confidence="0.466001">
Algorithm 1: Pseudo-code for the ISLFLA
</construct>
<subsectionHeader confidence="0.999823">
5.2 Learning Results
</subsectionHeader>
<bodyText confidence="0.990111727272727">
Here, we present a proof that the ISLFLA identifies
the class of ISL functions in the limit from positive
data, in the sense of Gold (1967), with polynomial
bounds on time and data (de la Higuera, 1997). First,
we establish the notion of characteristic sample.
Definition 6 (Characteristic sample). A sample CS
is characteristic of a function f for an algorithm 9A if
for all samples S s.t. CS ⊆ S, 9A returns a represen-
tation τ such that for all x ∈ dom(f), τ(x) = f(x),
and for all x ∈/ dom(f), τ(x) is not defined.
We can now define the learning criteria.
</bodyText>
<figureCaption confidence="0.5958724">
Definition 7 (Identification in polynomial time and
data (de la Higuera, 1997)). A class F offunctions
is identifiable in polynomial time and data using a
class T of representations iff there exist an algorithm
9A and two polynomials p() and q() such that:
</figureCaption>
<listItem confidence="0.8606108">
1. Given a sample S of size m for f ∈ F, 9 re-
turns a hypothesis in O(p(m)) time;
2. For each representation τ of size k of a function
f ∈ F, there exists a characteristic sample CS
of f for 9A of size at most O(q(k)).
</listItem>
<bodyText confidence="0.991437375">
Essentially the proof for convergence follows
from the fact that given a sufficient sample the al-
gorithm merges all and only states with the same
(k − 1)-length suffix.
Clearly, merges in the outer loop only involve
states with the same (k − 1)-length suffix. This is
also the case for inner loop merges. Consider the
scenario depicted on the right in Figure 9, in which
q is a state created by an outer loop merge.
After pushback, states s and t will be merged. If
x = Suffk−1(q), then both s and t must have xa as a
suffix. Since |xa |= k, it follows that Suffk−1(s) =
Suffk−1(t). It also follows that additional states
merged to remove non-determinism resulting from
the merge of s and t will have the same suffix of
length (k − 1). To show that all states with the same
(k − 1)-length suffix will be merged, it is shown
that the ISLFLA will never encounter the situation
in Figure 9, provided the data set includes a seed de-
fined as follows.
Definition 8 (ISLFLA seed). Given a k-ISL function
f and TISL
f , let Q&apos; = {q ∈ Q  |61(q, #) =6 A}. A
seed for f is S = S&apos; ∪ S&apos;&apos;, where
</bodyText>
<listItem confidence="0.9913365">
• S&apos; = {(w, w&apos;)  |[w ∈ Elk ∧ f(w) = w&apos;]}
• S&apos;&apos; = {(wa, w&apos;&apos;)  |a ∈ E, [w ∈ Ek ∧
</listItem>
<figure confidence="0.8529496">
Suffk−1(w) ∈ Q&apos; ∧ f(wa) = w&apos;&apos;]}.
:
:
#:a
#:
</figure>
<page confidence="0.997095">
499
</page>
<bodyText confidence="0.988045268041237">
Lemma 2 (Convergence). A seed for an ISL func-
tion f is a characteristic sample for ISLFLA.
Proof. We show that for any ISL function f and a
dataset D that contains a seed S the output of the
ISLFLA is T ISL
f .
Let PTT (D) = (QPTT, q0PTT , E, F, δPTT,
σPTT) be the input to the ISLFLA and T =
(QT , q0T , E, F, δT , σT ) be its output. First we show
that QT = E&lt;k−1. By Definitions 4 and 8,
E&lt;k−1 ⊆ QPTT. Since the ISLFLA only merges
states with the same (k − 1)-length suffix, E&lt;k−1 ⊆
QT . Since it does not exit until all states q have been
merged with Suffk−1(q), QT =
Next we show that given S, the algorithm will
never need to merge two states q1 and q2 such that
δ1(q1, #) =6 δ1(q2, #). Let δ1(q1, #) = z, and
δ1(q2, #) = x with z =6 x and q1 = Suffk−1(q2).
By Definition 2, tailsf(q1) = tailsf(q2), so if
z =6 x it must be the case that q2 does not have tran-
sitions for all a ∈ E. This is because the only way
for the output strings of the outgoing transitions of
q2 to differ from those of q1 is if fewer transitions
were present on q2 when the PTT was made onward.
(By definition of S we know q1 has transitions for all
a ∈ E.) But since tailsf(q1) = tailsf(q2), we
also know that z = ux for some u ∈ F*.
By Definition 8, all states up to length k have tran-
sitions for all a ∈ E; therefore, |q2 |≥ k + 1. This
means ∃q&apos; ∈ Ek between q1 and q2, which will be
merged with some other state before q2 will. This
merge will cause non-determinism, which in turn
will trigger pushback and cause u to move further
down the branch toward q2. By extension there will
be |q2 |− k states between q1 and q2, each of which
will be merged, triggering pushback of u, so that
by the time q1 and q2 are merged, δ1(q2, #) = ux =
z = δ1(q2,#). Thus, all non-determinism can be
removed, and so T is subsequential.
It remains to show that ∀q ∈ QT , a ∈ E,
δ2(q,a) = Suffk−1(qa). Since state merging pre-
serves transitions, this follows from the construction
of PTT (D). By Theorem 3, T = T ISL
f .
Next we establish complexity bounds on the run-
time of the ISLFLA and the size of the characteristic
sample for ISL functions. We observe that both of
these bounds improve the bounds of OSTIA. While
not surprising, since ISL functions are less general
than subsequential functions, the result is important
since it is an example of greater a priori knowledge
enabling learning with less time and data.
Let m be the length of the longest output string in
the sample and let n denote the number of states of
the PTT; n is at most the sum of the lengths of the
input strings of the pairs in the sample.
Lemma 3 (Polynomial time). The time complexity
of the ISLFLA is in O(n · m · k · |E|).
Proof. First, making the PTT onward can be done in
O(m · n): it consists of a depth-first parsing of the
PTT from its root, with a computation at each state
of the lcp of the outgoing transition outputs after
the recursive computation of the function (see de la
Higuera (2010), Chap. 18, for details). As the com-
putation of the lcptakes at most m steps, and as it
has to be done for each state, the complexity of this
step is effectively in O(m · n).
For the two loops, we need to find a bound on the
number of merges that can occur. States q such that
|q |&lt; k do not yield any merges in the outer loop.
All other states q&apos; are merged with Suffk−1(q), in
the outer loop or in the inner one. The number of
merges is thus bounded by n. Computing the suffix
of length (k − 1) of any word can be done in O(k)
with a correct implementation of strings of charac-
ters. The test of the inner loop can be done in con-
stant time and so can the merge and pushback pro-
cedures. After each merge, the test of the inner loop
needs to be done at most |E |times. As computing
the lcp has a complexity in O(m), the overall com-
plexity of the two loops is in O(n · m · k · |E|).
The overall complexity of the algorithm is thus
O(m · n + n · m · k ·|E|) = O(n · m · k ·|E|).
Let TISL
f = (Q, q0, E, F, δ, σ) be a target trans-
ducer. We define m = max{|u  ||(q, a, u, q&apos;) ∈ δ},
n = |Q|, and p = max {|v  ||(q, #, v) ∈ σ}.
Lemma 4 (Polynomial data). The size of the charac-
teristic sample is in O(n·|E|·k·m+n2·m+n·|E|·p).
Proof. The first item of the seed, S&apos;, covers all and
only the states of the target: the left projection of
these pairs is thus linear in n and every right projec-
tion is at most n · m + p. Thus the size of S&apos; is at
most n · (n + n · m + p) = O(n2 · m + n · p).
Concerning the second part, S&apos;&apos;, its cardinality is
at most n · |E |(in the rare case where Q&apos; = Q).
E&lt;k−1.
</bodyText>
<page confidence="0.905801">
500
</page>
<bodyText confidence="0.9635967">
Each element of the left projection of S&amp;quot; is of length
(k + 1) and each element of its right projection is at
most of length (k+1)·m+p. The size of S&amp;quot; is thus
in O(n · |E |· (k · m + p)).
Therefore, the size of the characteristic sample is
in O(n·|�•k•m+n2
E m+n•JEJ•p), which is clearly
polynomial in the size of the target transducer.
Theorem 8. The ISLFLA identifies the class of ISL
functions in polynomial time and data.
</bodyText>
<subsectionHeader confidence="0.6740885">
Proof. Immediate from Lemmas 2, 3, and 4.
5.3 Demonstrations
</subsectionHeader>
<bodyText confidence="0.997929204081633">
We tested the ISLFLA with the three examples in
§4, as well as the English flapping process (t → r /
V´ V). For each case, a data set was constructed
according to Definition 8 using the alphabets pre-
sented in §4. The alphabet for English flapping was
{ ´V, V, t, ?}. The value of k is 2 for final devoicing,
a-epenthesis, and fricative deletion and 3 for English
flapping. A few additional data points of length 5 or
6 were also added to make the data set a superset of
the seed. In all four cases, the learner returned the
correct T ISL
f .
The decision to use artificial corpora in these
demonstrations was motivated by the fact that the
sample in Definition 8 will not be present in a natural
language corpus. That sample includes all possible
sequences of symbols from the alphabet of a given
length, whereas a natural language corpus will re-
flect the language-particular restrictions against cer-
tain segment sequences (i.e., phonotactics).
As discussed in the introduction, Gildea and Ju-
rafsky (1996) address this issue with natural lan-
guage data by equipping OSTIA with a community
bias, whereby segments belonging to a natural class
(i.e., stops, fricatives, sonorants) are expected to be-
have similarly, and a faithfulness bias, whereby seg-
ments are assumed to be realized similarly on the
surface. In our demonstrations we put aside the is-
sue of the behavior of segments in a natural class by
using abbreviated alphabets (e.g., T for all voiceless
stops). But if in fact knowledge of natural classes
precedes the learning of phonological processes, the
use of such an alphabet is appropriate.
In future developments of the ISLFLA we like-
wise aim to accommodate natural language data,
but in a way that maintains the theoretical result of
identification in the limit. The restrictions on seg-
ment sequences represented in natural language data
amount to ‘missing’ transitions in the initial prefix
tree transducer that is built from that data. In other
words, the transducer represents a partial, not a to-
tal function. Thus it seems the approach of Oncina
and Var`o (1996) and Castellanos et al. (1998) could
be very instructive, as their use of domain informa-
tion enabled OSTIA to learn partial functions. In
our case, the fact that the domain of an ISL function
is an SL language could provide a means of ‘filling
in’ the missing transitions. The details of such an
approach are, however, being left for future work.
</bodyText>
<sectionHeader confidence="0.999439" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999989642857143">
This paper has defined Input and Output Strictly
Local functions, which synthesize the properties of
subsequential transduction and Strictly Local formal
languages. It has provided language-theoretic char-
acterizations of these functions and argued that they
can model many phonological and morphological
processes. Lastly, an automata-theoretic character-
ization of ISL functions was presented, along with a
learning algorithm that efficiently learn this class in
the limit from positive data.
Current work includes developing a comparable
automata characterization and learning algorithm for
OSL functions, as well as defining additional func-
tional classes to model those phonological processes
that cannot be modeled with ISL or OSL functions.
The SL languages are just one region of a subregu-
lar hierarchy of formal languages (McNaughton and
Papert, 1971; Rogers and Pullum, 2011; Rogers et
al., 2013). The ISL and OSL functions defined here
are the first step in developing a corresponding hi-
erarchy of subregular functions. Of immediate in-
terest to phonology are functional counterparts for
the Tier-Based Strictly Local and Strictly Piecewise
language classes, which have been shown to model
long-distance phonotactics (Heinz, 2010; Heinz et
al., 2011). Such functions might be useful for mod-
eling the long-distance processes that repair viola-
tions of these phonotactic constraints.
</bodyText>
<sectionHeader confidence="0.997642" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999515">
We thank Adam Jardine, Jim Rogers, and the three
anonymous reviewers for helpful comments. This
research was supported by NSF CPS#1035577.
</bodyText>
<page confidence="0.996334">
501
</page>
<sectionHeader confidence="0.99388" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999744009615385">
Dana Angluin. 1982. Inference of reversible languages.
Journal for the Association of Computing Machinery,
29(3):741–765.
Kenneth R. Beesley and Lauri Karttunen. 2003. Finite
State Morphology. Center for the Study of Language
and Information.
William Bennett. 2013. Dissimilation, Consonant Har-
mony, and Surface Correspondence. Ph.D. thesis, Rut-
gers University.
Antonio Castellanos, Enrique Vidal, Miguel A. Var´o, and
Jos´e Oncina. 1998. Language understanding and sub-
sequential transducer learning. Computer Speech and
Language, 12:193–228.
Jane Chandlee and Jeffrey Heinz. 2012. Bounded copy-
ing is subsequential: implications for metathesis and
reduplication. In Proceedings of SIGMORPHON 12.
Jane Chandlee and Adam Jardine. 2014. Learn-
ing phonological mappings by learning Strictly Local
functions. In John Kingston, Claire Moore-Cantwell,
Joe Pater, and Robert Staubs, editors, Proceedings of
the 2013 Meeting on Phonology. LSA.
Jane Chandlee and Cesar Koirala. 2014. Learning local
phonological rules. In Proceedings of the 37th Penn
Linguistics Conference.
Jane Chandlee, Angeliki Athanasopoulou, and Jeffrey
Heinz. 2012. Evidence for classifying metathesis
patterns as subsequential. In The Proceedings of the
29th West Coast Conference on Formal Linguistics,
Somerville, MA. Cascadilla.
Jane Chandlee. 2014. Strictly Local Phonological Pro-
cesses. Ph.D. thesis, University of Delaware.
Noam Chomsky and Morris Halle. 1968. The Sound
Pattern of English. Harper &amp; Row, New York.
Colin de la Higuera. 1997. Characteristic sets for poly-
nomial grammatical inference. Machine Learning,
27(2):125–138.
Colin de la Higuera. 2010. Grammatical Inference:
Learning Automata and Grammars. Cambridge Uni-
versity Press.
Brian Gainor, Regine Lai, and Jeffrey Heinz. 2012.
Computational characterizations of vowel harmony
patterns and pathologies. In The Proceedings of the
29th West Coast Conference on Formal Linguistics,
pages 63–71, Somerville, MA. Cascadilla.
Daniel Gildea and Daniel Jurafsky. 1996. Learning bias
and phonological-rule induction. Computational Lin-
guistics, 22(4):497–530.
E. Mark Gold. 1967. Language identification in the
limit. Information and Control, 10:447–474.
Gunnar Hansson. 2001. Theoretical and Typological Is-
sues in Consonant Harmony. Ph.D. thesis, University
of California, Berkeley.
Jeffrey Heinz and Regine Lai. 2013. Vowel harmony
and subsequentiality. In Andras Kornai and Marco
Kuhlmann, editors, Proceedings of the 13th Meeting
on the Mathematics of Language (MoL 13), pages 52–
Jeffrey Heinz, Chetan Rawal, and Herbert G. Tanner.
2011. Tier-based Strictly Local constraints for phonol-
ogy. In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics, pages 58–
64. Association for Computational Linguistics.
Jeffrey Heinz. 2007. The Inductive Learning of Phono-
tactic Patterns. Ph.D. thesis, University of California,
Los Angeles.
Jeffrey Heinz. 2009. On the role of locality in learning
stress patterns. Phonology, 26:303–351.
Jeffrey Heinz. 2010. Learning long-distance phonotac-
tics. Linguistic Inquiry, 41:623–661.
Mans Hulden, I˜naki Alegria, Izaskun Etxeberria, and
Montse Maritxalar. 2011. Learning word-level dialec-
tal variation as phonological replacement rules using
a limited parallel corpus. In Proceedings of the First
Workshop on Algorithms and Resources for Modelling
of Dialects and Language Varieties, DIALECTS ’11,
pages 39–48. Association for Computational Linguis-
tics.
Mans Hulden. 2009. Finite-State Machine Construction
Methods and Algorithms for Phonology and Morphol-
ogy. Ph.D. thesis, University of Arizona.
Adam Jardine. 2013. Tone is (computationally) differ-
ent. Unpublished manuscript, University of Delaware.
C. Douglas Johnson. 1972. Formal Aspects of Phonolog-
ical Description. The Hague, Mouton.
Brian D. Joseph and Irene Philippaki-Warburton. 1987.
Modern Greek. Croom Helm, Wolfeboro, NH.
Ronald M. Kaplan and Martin Kay. 1994. Regular mod-
els of phonological rule systems. Computational Lin-
guistics, 20:371–387.
Huan Luo. 2013. Long-distance consonant harmony and
subsequentiality. Unpublished manuscript, University
of Delaware.
Robert McNaughton and Seymour A. Papert. 1971.
Counter-Free Automata. MIT Press.
Mehryar Mohri. 1997. Finite-state transducers in lan-
guage and speech processing. Computational Linguis-
tics, 23:269–311.
Jos´e Oncina and Pedro Garc´ıa. 1991. Inductive learning
of subsequential functions. Technical Report DSIC II-
34, University Polit´ecnia de Valencia.
Jos´e Oncina and Miguel A. Var`o. 1996. Using do-
main information during the learning of a subsequen-
tial transducer. Lecture Notes in Computer Science
- Lecture Notes in Artificial Intelligence, pages 313–
325.
</reference>
<page confidence="0.972755">
502
</page>
<reference confidence="0.999717363636364">
Jos´e Oncina, Pedro Garc´ıa, and Enrique Vidal. 1993.
Learning subsequential transducers for pattern recog-
nition interpretation tasks. IEEE Transactions on Pat-
tern Analysis and Machine Intelligence, 15(5):448–
457.
Amanda Payne. 2013. Dissimilation as a subsequen-
tial process. Unpublished manuscript, University of
Delaware.
Alan Prince and Paul Smolensky. 1993. Optimality
Theory: Constraint interaction in generative gram-
mar. Technical Report 2, Rutgers University Center
for Cognitive Science.
Jason Riggle. 2003. Non-local reduplication. In Pro-
ceedings of the 34th Annual Meeting of the North East-
ern Linguistic Society.
James Rogers and Geoffrey K. Pullum. 2011. Aural pat-
tern recognition experiments and the subregular hier-
archy. Journal of Logic, Language and Information,
20:329–342.
James Rogers, Jeffrey Heinz, Margaret Fero, Jeremy
Hurst, Dakotah Lambert, and Sean Wibel. 2013. Cog-
nitive and sub-regular complexity. In Glyn Morrill and
Mark-Jan Nederhof, editors, Formal Grammar, Lec-
ture Notes in Computer Science, volume 8036, pages
90–108. Springer.
Sharon Rose and Rachel Walker. 2004. A typology of
consonant agreement as correspondence. Language,
80:475–531.
Keiichiro Suzuki. 1998. A Typological Investigation of
Dissimilation. Ph.D. thesis, University of Arizona.
Natasha Warner, Allard Jongman, Anne Cutler, and Doris
M¨ucke. 2001. The phonological status of Dutch
epenthetic schwa. Phonology, 18:387–420.
</reference>
<page confidence="0.9994055">
503
504
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.303857">
<title confidence="0.999962">Learning Strictly Local Subsequential Functions</title>
<author confidence="0.997825">Jane</author>
<affiliation confidence="0.993876">University of Department of and Cognitive</affiliation>
<address confidence="0.879137">125 East Main Newark, DE</address>
<email confidence="0.999106">janemc@udel.edu</email>
<author confidence="0.828688">R´emi</author>
<affiliation confidence="0.9481965">QARMA Laboratoire</affiliation>
<address confidence="0.835174">Marseille,</address>
<email confidence="0.998168">lif.univ-mrs.fr</email>
<author confidence="0.964646">Jeffrey</author>
<affiliation confidence="0.993016666666667">University of Department of and Cognitive</affiliation>
<address confidence="0.8369945">125 East Main Newark, DE</address>
<email confidence="0.99893">heinz@udel.edu</email>
<abstract confidence="0.994664454545455">We define two proper subclasses of subsequential functions based on the concept of Strict Locality (McNaughton and Papert, 1971; Rogers and Pullum, 2011; Rogers et al., 2013) for formal languages. They are called Input and Output Strictly Local (ISL and OSL). We provide an automata-theoretic characterization of the ISL class and theorems establishing how the classes are related to each other and to Strictly Local languages. We give evidence that local phonological and morphological processes belong to these classes. Finally we provide a learning algorithm which provably identifies the class of ISL functions in the limit from positive data in polynomial time and data. We demonstrate this learning result on appropriately synthesized artificial corpora. We leave a similar learning result for OSL functions for future work and suggest future directions for addressing non-local phonological processes.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Dana Angluin</author>
</authors>
<title>Inference of reversible languages.</title>
<date>1982</date>
<journal>Journal for the Association of Computing Machinery,</journal>
<volume>29</volume>
<issue>3</issue>
<contexts>
<context position="26302" citStr="Angluin (1982)" startWordPosition="4769" endWordPosition="4770">5.1 The Algorithm: ISLFLA Given a finite dataset D of input-output string pairs (w, w&apos;) such that f(w) = w&apos;, where f is the target function, the learner tries to build TISL f . The dataset is submitted to the learner in the form of a prefix tree transducer (PTT), which is defined in Definition 4. Definition 4 (Prefix Tree Transducer). A prefix tree transducer for finite set D = for some f is PTT (D) = (Q, q0, E, Γ, S, σ), where • Q = U{Pref(w)|(w, w&apos;) E D} and q0 = λ • S = {(u, a, λ, ua) |u, ua E Q} • σ(w) = w&apos; for all (w, w&apos;) E D 5This general strategy is common in grammatical inference. See Angluin (1982), Heinz (2009), and de la Higuera (2010). #:A :a #:A A #:A #:A #:λ D D:λ #:λ D:λ D T:λ T:λ#:T #:D λ D:T T T:λ :T T:λ :D T:λ #:λ D:λ {(w, w&apos;) |f(w) = w&apos;} 497 As an example, the sample of data in (2) exemplifies the final devoicing rule in (1-a). Figure 6 gives the PTT for this data. deterministic. Non-determinism is removed in the inner loop with additional state merges. Consider the situation depicted on the lefthand side of Figure 8, which resulted from a previous merge. The non-determinism could be resolved by (2) {(D, T), (DD, DT), (DNT, DNT), (NND, NNT), (TDN, TDN)} Figure 6: PTT for the d</context>
</contexts>
<marker>Angluin, 1982</marker>
<rawString>Dana Angluin. 1982. Inference of reversible languages. Journal for the Association of Computing Machinery, 29(3):741–765.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth R Beesley</author>
<author>Lauri Karttunen</author>
</authors>
<title>Finite State Morphology. Center for the Study of Language and Information.</title>
<date>2003</date>
<contexts>
<context position="22417" citStr="Beesley and Karttunen (2003)" startWordPosition="4078" endWordPosition="4081">urface form that this process describes is represented with the 2-ISL function in Figure 3 (note N represents any sonorant). Figure 3: TISL f for (1-a) with k = 2 and E = {T, D, N} In addition to substitution processes like (1-a), another common type of process is insertion of a segment, such as the a-epenthesis process attested in Dutch (Warner et al., 2001). This process inserts a schwa between a liquid and a non-coronal consonant, as specified by (1-b). Using L to represent the liquids {l, r} and K to represent any non-coronal consonant, Figure 4 presentsT ISL f for this process. Following Beesley and Karttunen (2003), the symbol ‘?’ represents any segment of the alphabet other than the ones for which transitions are defined.4 Lastly, an example deletion process from Greek (Joseph and Philippaki-Warburton, 1987) deletes interdental fricatives before /0/ or /s/, as in (1-c). Figure 5 presents TISL f for this process. 3These abbreviations serve to improve the readability of the 1 FST - it is assumed that the transduction replaces a given voiced obstruent with its voiceless counterpart (not with any voiceless obstruent). 4This means Figure 4 is actually a shorthand for TISL f , which would otherwise have a di</context>
</contexts>
<marker>Beesley, Karttunen, 2003</marker>
<rawString>Kenneth R. Beesley and Lauri Karttunen. 2003. Finite State Morphology. Center for the Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Bennett</author>
</authors>
<title>Dissimilation, Consonant Harmony, and Surface Correspondence.</title>
<date>2013</date>
<tech>Ph.D. thesis,</tech>
<institution>Rutgers University.</institution>
<contexts>
<context position="24596" citStr="Bennett, 2013" startWordPosition="4464" endWordPosition="4465">a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input Strictly Local Functions We now present a learning algorithm</context>
</contexts>
<marker>Bennett, 2013</marker>
<rawString>William Bennett. 2013. Dissimilation, Consonant Harmony, and Surface Correspondence. Ph.D. thesis, Rutgers University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Castellanos</author>
<author>Enrique Vidal</author>
<author>Miguel A Var´o</author>
<author>Jos´e Oncina</author>
</authors>
<title>Language understanding and subsequential transducer learning.</title>
<date>1998</date>
<journal>Computer Speech and Language,</journal>
<pages>12--193</pages>
<marker>Castellanos, Vidal, Var´o, Oncina, 1998</marker>
<rawString>Antonio Castellanos, Enrique Vidal, Miguel A. Var´o, and Jos´e Oncina. 1998. Language understanding and subsequential transducer learning. Computer Speech and Language, 12:193–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Chandlee</author>
<author>Jeffrey Heinz</author>
</authors>
<title>Bounded copying is subsequential: implications for metathesis and reduplication.</title>
<date>2012</date>
<booktitle>In Proceedings of SIGMORPHON 12.</booktitle>
<contexts>
<context position="3271" citStr="Chandlee and Heinz, 2012" startWordPosition="508" endWordPosition="511"> OSL functions model mappings from underlying forms to surface forms, which are also the bedrock of constraintbased frameworks like Optimality Theory (Prince and Smolensky, 1993). By showing that local phonological processes can be modeled with ISL (and OSL) functions, we provide the strongest computational characterization of the input-output mappings these processes represent. While it has been shown that phonological mappings describable with rules of the form A → B / C D (where A, B, C, and D are regular languages) are regular (Johnson, 1972; Kaplan and Kay, 1994), and even subsequential (Chandlee and Heinz, 2012; Heinz and Lai, 2013), many logically possible regular and subsequential mappings are not plausible phonological mappings. Since these implausible mappings cannot be modeled with ISL or OSL functions, we provide a more precise notion of 491 Transactions of the Association for Computational Linguistics, vol. 2, pp. 491–503, 2014. Action Editor: Alexander Clark. Submitted 4/2014; Revised 8/2014; Published November 1, 2014. c�2014 Association for Computational Linguistics. what constitues plausible phonological mappings. In addition, we present the Input SL Function Learning Algorithm (ISLFLA) a</context>
<context position="24695" citStr="Chandlee and Heinz, 2012" startWordPosition="4475" endWordPosition="4479">right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input Strictly Local Functions We now present a learning algorithm for the class of ISL functions that uses its defining property as an inductive principle to genera</context>
</contexts>
<marker>Chandlee, Heinz, 2012</marker>
<rawString>Jane Chandlee and Jeffrey Heinz. 2012. Bounded copying is subsequential: implications for metathesis and reduplication. In Proceedings of SIGMORPHON 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Chandlee</author>
<author>Adam Jardine</author>
</authors>
<title>Learning phonological mappings by learning Strictly Local functions. In</title>
<date>2014</date>
<booktitle>Proceedings of the 2013 Meeting on Phonology. LSA.</booktitle>
<editor>John Kingston, Claire Moore-Cantwell, Joe Pater, and Robert Staubs, editors,</editor>
<contexts>
<context position="6575" citStr="Chandlee and Jardine (2014)" startWordPosition="1015" endWordPosition="1018"> It also employs a faithfulness bias in terms of the prop1The alignment was similar to the string-edit distance mehod used in Hulden et al. (2011). erty onwardness (see §2). The ISLFLA is supported by a theoretical result like Oncina et al. (1993), but learns a more restrictive class of mappings. We believe the theoretical results for this class will lead to new algorithms which include something akin to the community bias and that will succeed on natural language data while keeping strong theoretical results. The proposed learner also builds on earlier work by Chandlee and Koirala (2014) and Chandlee and Jardine (2014) which also used strict locality to learn phonological processes but with weaker theoretical results. The former did not precisely identify the class of functions the learner could learn, and the latter could only guarantee learnability of the ISL functions with a closed learning sample. The paper is organized as follows. §2 presents the mathematical notations to be used. §3 defines ISL and OSL functions, provides an automata-theoretic characterization for ISL, and establishes some properties of these classes. §4 demonstrates how these functions can model local phonological processes, includin</context>
</contexts>
<marker>Chandlee, Jardine, 2014</marker>
<rawString>Jane Chandlee and Adam Jardine. 2014. Learning phonological mappings by learning Strictly Local functions. In John Kingston, Claire Moore-Cantwell, Joe Pater, and Robert Staubs, editors, Proceedings of the 2013 Meeting on Phonology. LSA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Chandlee</author>
<author>Cesar Koirala</author>
</authors>
<title>Learning local phonological rules.</title>
<date>2014</date>
<booktitle>In Proceedings of the 37th Penn Linguistics Conference.</booktitle>
<contexts>
<context position="6543" citStr="Chandlee and Koirala (2014)" startWordPosition="1010" endWordPosition="1013">e input strings of the data set. It also employs a faithfulness bias in terms of the prop1The alignment was similar to the string-edit distance mehod used in Hulden et al. (2011). erty onwardness (see §2). The ISLFLA is supported by a theoretical result like Oncina et al. (1993), but learns a more restrictive class of mappings. We believe the theoretical results for this class will lead to new algorithms which include something akin to the community bias and that will succeed on natural language data while keeping strong theoretical results. The proposed learner also builds on earlier work by Chandlee and Koirala (2014) and Chandlee and Jardine (2014) which also used strict locality to learn phonological processes but with weaker theoretical results. The former did not precisely identify the class of functions the learner could learn, and the latter could only guarantee learnability of the ISL functions with a closed learning sample. The paper is organized as follows. §2 presents the mathematical notations to be used. §3 defines ISL and OSL functions, provides an automata-theoretic characterization for ISL, and establishes some properties of these classes. §4 demonstrates how these functions can model local </context>
</contexts>
<marker>Chandlee, Koirala, 2014</marker>
<rawString>Jane Chandlee and Cesar Koirala. 2014. Learning local phonological rules. In Proceedings of the 37th Penn Linguistics Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Chandlee</author>
<author>Angeliki Athanasopoulou</author>
<author>Jeffrey Heinz</author>
</authors>
<title>Evidence for classifying metathesis patterns as subsequential.</title>
<date>2012</date>
<booktitle>In The Proceedings of the 29th West Coast Conference on Formal Linguistics,</booktitle>
<publisher>Cascadilla.</publisher>
<location>Somerville, MA.</location>
<contexts>
<context position="24668" citStr="Chandlee et al., 2012" startWordPosition="4471" endWordPosition="4474">simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input Strictly Local Functions We now present a learning algorithm for the class of ISL functions that uses its defining property as an in</context>
</contexts>
<marker>Chandlee, Athanasopoulou, Heinz, 2012</marker>
<rawString>Jane Chandlee, Angeliki Athanasopoulou, and Jeffrey Heinz. 2012. Evidence for classifying metathesis patterns as subsequential. In The Proceedings of the 29th West Coast Conference on Formal Linguistics, Somerville, MA. Cascadilla.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Chandlee</author>
</authors>
<title>Strictly Local Phonological Processes.</title>
<date>2014</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Delaware.</institution>
<contexts>
<context position="21428" citStr="Chandlee (2014)" startWordPosition="3912" endWordPosition="3913"> 2)+1 if n is odd. f6 is subsequential, as shown in Figure 2, and the image(f) = a∗ is Strictly Local. However, f is neither ISL nor OSL for any k since the tails of a2k includes (a, a) but the tails of aa2k includes (a, A). 4 Relevance to Phonology This section will briefly discuss the range of phonological processes that can be modeled with ISL and/or OSL functions by providing illustrative examples for three common, representative processes. These are shown in (1) with SPE-style rules. (1) a. Devoicing: D → T / # b. Epenthesis: 0 → a / {l, r} [-coronal] c. Deletion: {0, d} → 0 / {0, s} See Chandlee (2014) for more details. First, consider the process of final obstruent devoicing (1-a), attested in German and other languages. This process causes an underlying voiced obstruent in word-final position to surface as its voiceless counterpart. In (1-a), D abbreviates the set of voiced obstruents and T the voiceless obstruents.3 The mapping from underlying form to surface form that this process describes is represented with the 2-ISL function in Figure 3 (note N represents any sonorant). Figure 3: TISL f for (1-a) with k = 2 and E = {T, D, N} In addition to substitution processes like (1-a), another </context>
<context position="23435" citStr="Chandlee (2014)" startWordPosition="4268" endWordPosition="4269">uction replaces a given voiced obstruent with its voiceless counterpart (not with any voiceless obstruent). 4This means Figure 4 is actually a shorthand for TISL f , which would otherwise have a distinct state for each symbol now represented with ‘?’. :λ #: :λ #:λ : : λ :λ #:λ #:λ 496 Figure 4: TISL f for (1-b) with k = 2 and E = {L, K, ?} Figure 5: TISL f for (1-c) with k = 2 and E = {0, d, s, ?} The German, Dutch, and Greek examples demonstrate how ISL functions can be used to model the input-output mapping of a phonological rule. Beyond substitution, insertion, and deletion, it is shown in Chandlee (2014) that ISL and/or OSL functions can also model many metathesis patterns, specifically those for which there is an upper bound on the amount of material that intervenes between a segment’s original and surface positions (this appears to include all synchronic patterns). In addition, morpho-phonological processes such as local partial reduplication (i.e., in which the reduplicant is affixed adjacent to the portion of the base it was copied from) and general affixation are also shown to be ISL or OSL. More generally, we currently conjecture that a SPE-style rewrite rule of the form A 1 → B/ C D wh</context>
</contexts>
<marker>Chandlee, 2014</marker>
<rawString>Jane Chandlee. 2014. Strictly Local Phonological Processes. Ph.D. thesis, University of Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
<author>Morris Halle</author>
</authors>
<title>The Sound Pattern of English.</title>
<date>1968</date>
<publisher>Harper &amp; Row,</publisher>
<location>New York.</location>
<contexts>
<context position="2637" citStr="Chomsky and Halle, 1968" startWordPosition="405" endWordPosition="408"> L is Strictly Local ifffor all strings u1, v1, u2, v2, there exists k E N such that for any string x of length k − 1, if u1xv1, u2xv2 E L, then u1xv2 E L. These languages can model natural language phonotactic constraints which pick out contiguous substrings bounded by some length k (Heinz, 2007; Heinz, 2010). We define Input Strictly Local (ISL) and Output Strictly Local (OSL) functions which model phonological processes for which the target and triggering context are a bounded contiguous substring. Here our use of ‘process’ is not specific to rule-based grammatical formalisms (such as SPE (Chomsky and Halle, 1968)). ISL and OSL functions model mappings from underlying forms to surface forms, which are also the bedrock of constraintbased frameworks like Optimality Theory (Prince and Smolensky, 1993). By showing that local phonological processes can be modeled with ISL (and OSL) functions, we provide the strongest computational characterization of the input-output mappings these processes represent. While it has been shown that phonological mappings describable with rules of the form A → B / C D (where A, B, C, and D are regular languages) are regular (Johnson, 1972; Kaplan and Kay, 1994), and even subse</context>
</contexts>
<marker>Chomsky, Halle, 1968</marker>
<rawString>Noam Chomsky and Morris Halle. 1968. The Sound Pattern of English. Harper &amp; Row, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin de la Higuera</author>
</authors>
<title>Characteristic sets for polynomial grammatical inference.</title>
<date>1997</date>
<booktitle>Machine Learning,</booktitle>
<volume>27</volume>
<issue>2</issue>
<contexts>
<context position="3985" citStr="Higuera, 1997" startWordPosition="614" endWordPosition="615"> phonological mappings. Since these implausible mappings cannot be modeled with ISL or OSL functions, we provide a more precise notion of 491 Transactions of the Association for Computational Linguistics, vol. 2, pp. 491–503, 2014. Action Editor: Alexander Clark. Submitted 4/2014; Revised 8/2014; Published November 1, 2014. c�2014 Association for Computational Linguistics. what constitues plausible phonological mappings. In addition, we present the Input SL Function Learning Algorithm (ISLFLA) and prove that it identifies this class in the limit (Gold, 1967) in polynomial time and data (de la Higuera, 1997). Our approach follows previous work on learning subsequential transductions, namely Oncina et al. (1993), Oncina and Var`o (1996), Castellanos et al. (1998), and Gildea and Jurafsky (1996). Oncina et al. (1993) present OSTIA (Onward Subsequential Transducer Inference Algorithm), an algorithm that learns the class of subsequential functions in the limit from positive data. OSTIA is only guaranteed to identify total functions exactly, but Oncina and Var`o (1996) and Castellanos et al. (1998) present the modifications OSTIA-N, OSTIA-D, and OSTIA-R, which learn partial functions using negative da</context>
<context position="31214" citStr="Higuera, 1997" startWordPosition="5698" endWordPosition="5699">o-code for the ISLFLA. Data: PTT (D) Result:T ISL f τ = onward(PTT) q = next(Qτ, first(Qτ)) while q &lt; last(Qτ) do merge(q, Suffk−1(q)) 1 while ∃(q, a, x, q1), (q, a, y, q2) ∈ 6τ do if a = # and x =6 y then exit ‘Insufficient data’ else pushback(τ, (q, a, x, q1), lcp(x, y)) pushback(τ, (q, a, y, q2), lcp(x, y)) merge(q1, q2) q = next(Qτ, q) return τ Algorithm 1: Pseudo-code for the ISLFLA 5.2 Learning Results Here, we present a proof that the ISLFLA identifies the class of ISL functions in the limit from positive data, in the sense of Gold (1967), with polynomial bounds on time and data (de la Higuera, 1997). First, we establish the notion of characteristic sample. Definition 6 (Characteristic sample). A sample CS is characteristic of a function f for an algorithm 9A if for all samples S s.t. CS ⊆ S, 9A returns a representation τ such that for all x ∈ dom(f), τ(x) = f(x), and for all x ∈/ dom(f), τ(x) is not defined. We can now define the learning criteria. Definition 7 (Identification in polynomial time and data (de la Higuera, 1997)). A class F offunctions is identifiable in polynomial time and data using a class T of representations iff there exist an algorithm 9A and two polynomials p() and q</context>
</contexts>
<marker>Higuera, 1997</marker>
<rawString>Colin de la Higuera. 1997. Characteristic sets for polynomial grammatical inference. Machine Learning, 27(2):125–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin de la Higuera</author>
</authors>
<title>Grammatical Inference: Learning Automata and Grammars.</title>
<date>2010</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="26342" citStr="Higuera (2010)" startWordPosition="4776" endWordPosition="4777"> dataset D of input-output string pairs (w, w&apos;) such that f(w) = w&apos;, where f is the target function, the learner tries to build TISL f . The dataset is submitted to the learner in the form of a prefix tree transducer (PTT), which is defined in Definition 4. Definition 4 (Prefix Tree Transducer). A prefix tree transducer for finite set D = for some f is PTT (D) = (Q, q0, E, Γ, S, σ), where • Q = U{Pref(w)|(w, w&apos;) E D} and q0 = λ • S = {(u, a, λ, ua) |u, ua E Q} • σ(w) = w&apos; for all (w, w&apos;) E D 5This general strategy is common in grammatical inference. See Angluin (1982), Heinz (2009), and de la Higuera (2010). #:A :a #:A A #:A #:A #:λ D D:λ #:λ D:λ D T:λ T:λ#:T #:D λ D:T T T:λ :T T:λ :D T:λ #:λ D:λ {(w, w&apos;) |f(w) = w&apos;} 497 As an example, the sample of data in (2) exemplifies the final devoicing rule in (1-a). Figure 6 gives the PTT for this data. deterministic. Non-determinism is removed in the inner loop with additional state merges. Consider the situation depicted on the lefthand side of Figure 8, which resulted from a previous merge. The non-determinism could be resolved by (2) {(D, T), (DD, DT), (DNT, DNT), (NND, NNT), (TDN, TDN)} Figure 6: PTT for the data in (2) Given such a PTT, the learner</context>
<context position="36198" citStr="Higuera (2010)" startWordPosition="6704" endWordPosition="6705">knowledge enabling learning with less time and data. Let m be the length of the longest output string in the sample and let n denote the number of states of the PTT; n is at most the sum of the lengths of the input strings of the pairs in the sample. Lemma 3 (Polynomial time). The time complexity of the ISLFLA is in O(n · m · k · |E|). Proof. First, making the PTT onward can be done in O(m · n): it consists of a depth-first parsing of the PTT from its root, with a computation at each state of the lcp of the outgoing transition outputs after the recursive computation of the function (see de la Higuera (2010), Chap. 18, for details). As the computation of the lcptakes at most m steps, and as it has to be done for each state, the complexity of this step is effectively in O(m · n). For the two loops, we need to find a bound on the number of merges that can occur. States q such that |q |&lt; k do not yield any merges in the outer loop. All other states q&apos; are merged with Suffk−1(q), in the outer loop or in the inner one. The number of merges is thus bounded by n. Computing the suffix of length (k − 1) of any word can be done in O(k) with a correct implementation of strings of characters. The test of the</context>
</contexts>
<marker>Higuera, 2010</marker>
<rawString>Colin de la Higuera. 2010. Grammatical Inference: Learning Automata and Grammars. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Gainor</author>
<author>Regine Lai</author>
<author>Jeffrey Heinz</author>
</authors>
<title>Computational characterizations of vowel harmony patterns and pathologies.</title>
<date>2012</date>
<booktitle>In The Proceedings of the 29th West Coast Conference on Formal Linguistics,</booktitle>
<pages>63--71</pages>
<publisher>Cascadilla.</publisher>
<location>Somerville, MA.</location>
<contexts>
<context position="24444" citStr="Gainor et al., 2012" startWordPosition="4439" endWordPosition="4442"> adjacent to the portion of the base it was copied from) and general affixation are also shown to be ISL or OSL. More generally, we currently conjecture that a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm </context>
</contexts>
<marker>Gainor, Lai, Heinz, 2012</marker>
<rawString>Brian Gainor, Regine Lai, and Jeffrey Heinz. 2012. Computational characterizations of vowel harmony patterns and pathologies. In The Proceedings of the 29th West Coast Conference on Formal Linguistics, pages 63–71, Somerville, MA. Cascadilla.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Learning bias and phonological-rule induction.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>4</issue>
<contexts>
<context position="4174" citStr="Gildea and Jurafsky (1996)" startWordPosition="640" endWordPosition="643"> Computational Linguistics, vol. 2, pp. 491–503, 2014. Action Editor: Alexander Clark. Submitted 4/2014; Revised 8/2014; Published November 1, 2014. c�2014 Association for Computational Linguistics. what constitues plausible phonological mappings. In addition, we present the Input SL Function Learning Algorithm (ISLFLA) and prove that it identifies this class in the limit (Gold, 1967) in polynomial time and data (de la Higuera, 1997). Our approach follows previous work on learning subsequential transductions, namely Oncina et al. (1993), Oncina and Var`o (1996), Castellanos et al. (1998), and Gildea and Jurafsky (1996). Oncina et al. (1993) present OSTIA (Onward Subsequential Transducer Inference Algorithm), an algorithm that learns the class of subsequential functions in the limit from positive data. OSTIA is only guaranteed to identify total functions exactly, but Oncina and Var`o (1996) and Castellanos et al. (1998) present the modifications OSTIA-N, OSTIA-D, and OSTIA-R, which learn partial functions using negative data, domain information, and range information, respectively. In terms of linguistic applications, Gildea and Jurafsky (1996) show that OSTIA fails to learn the phonological mapping of Engli</context>
<context position="5599" citStr="Gildea and Jurafsky (1996)" startWordPosition="854" endWordPosition="857"> flapping and several other phonological rules. Context encodes the idea that phonological changes depend on the context of the segment undergoing the change. Community gives the learner the ability to deduce that segments belonging to a natural class are likely to behave similarly. Lastly, faithfulness, by which underlying segments are assumed to be realized similarly on the surface, was encoded with a forced alignment between the input-output strings in the data set.1 We believe this alignment removes OSTIA’s guarantee that all subsequential functions are learned. Similar to the approach of Gildea and Jurafsky (1996), our learner employs a context bias because it knows its target is an ISL function and therefore the transduction only involves bounded contiguous substrings. And similar to OSTIA-D (Oncina and Var`o, 1996; Castellanos et al., 1998), the ISLFLA makes use of domain information, because it makes decisions based on the input strings of the data set. It also employs a faithfulness bias in terms of the prop1The alignment was similar to the string-edit distance mehod used in Hulden et al. (2011). erty onwardness (see §2). The ISLFLA is supported by a theoretical result like Oncina et al. (1993), bu</context>
<context position="39280" citStr="Gildea and Jurafsky (1996)" startWordPosition="7324" endWordPosition="7328">additional data points of length 5 or 6 were also added to make the data set a superset of the seed. In all four cases, the learner returned the correct T ISL f . The decision to use artificial corpora in these demonstrations was motivated by the fact that the sample in Definition 8 will not be present in a natural language corpus. That sample includes all possible sequences of symbols from the alphabet of a given length, whereas a natural language corpus will reflect the language-particular restrictions against certain segment sequences (i.e., phonotactics). As discussed in the introduction, Gildea and Jurafsky (1996) address this issue with natural language data by equipping OSTIA with a community bias, whereby segments belonging to a natural class (i.e., stops, fricatives, sonorants) are expected to behave similarly, and a faithfulness bias, whereby segments are assumed to be realized similarly on the surface. In our demonstrations we put aside the issue of the behavior of segments in a natural class by using abbreviated alphabets (e.g., T for all voiceless stops). But if in fact knowledge of natural classes precedes the learning of phonological processes, the use of such an alphabet is appropriate. In f</context>
</contexts>
<marker>Gildea, Jurafsky, 1996</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 1996. Learning bias and phonological-rule induction. Computational Linguistics, 22(4):497–530.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Mark Gold</author>
</authors>
<date>1967</date>
<booktitle>Language identification in the limit. Information and Control,</booktitle>
<pages>10--447</pages>
<contexts>
<context position="3935" citStr="Gold, 1967" startWordPosition="604" endWordPosition="605">ar and subsequential mappings are not plausible phonological mappings. Since these implausible mappings cannot be modeled with ISL or OSL functions, we provide a more precise notion of 491 Transactions of the Association for Computational Linguistics, vol. 2, pp. 491–503, 2014. Action Editor: Alexander Clark. Submitted 4/2014; Revised 8/2014; Published November 1, 2014. c�2014 Association for Computational Linguistics. what constitues plausible phonological mappings. In addition, we present the Input SL Function Learning Algorithm (ISLFLA) and prove that it identifies this class in the limit (Gold, 1967) in polynomial time and data (de la Higuera, 1997). Our approach follows previous work on learning subsequential transductions, namely Oncina et al. (1993), Oncina and Var`o (1996), Castellanos et al. (1998), and Gildea and Jurafsky (1996). Oncina et al. (1993) present OSTIA (Onward Subsequential Transducer Inference Algorithm), an algorithm that learns the class of subsequential functions in the limit from positive data. OSTIA is only guaranteed to identify total functions exactly, but Oncina and Var`o (1996) and Castellanos et al. (1998) present the modifications OSTIA-N, OSTIA-D, and OSTIA-</context>
<context position="31151" citStr="Gold (1967)" startWordPosition="5687" endWordPosition="5688">(hence non-ISL) FST. It therefore terminates. Below is pseudo-code for the ISLFLA. Data: PTT (D) Result:T ISL f τ = onward(PTT) q = next(Qτ, first(Qτ)) while q &lt; last(Qτ) do merge(q, Suffk−1(q)) 1 while ∃(q, a, x, q1), (q, a, y, q2) ∈ 6τ do if a = # and x =6 y then exit ‘Insufficient data’ else pushback(τ, (q, a, x, q1), lcp(x, y)) pushback(τ, (q, a, y, q2), lcp(x, y)) merge(q1, q2) q = next(Qτ, q) return τ Algorithm 1: Pseudo-code for the ISLFLA 5.2 Learning Results Here, we present a proof that the ISLFLA identifies the class of ISL functions in the limit from positive data, in the sense of Gold (1967), with polynomial bounds on time and data (de la Higuera, 1997). First, we establish the notion of characteristic sample. Definition 6 (Characteristic sample). A sample CS is characteristic of a function f for an algorithm 9A if for all samples S s.t. CS ⊆ S, 9A returns a representation τ such that for all x ∈ dom(f), τ(x) = f(x), and for all x ∈/ dom(f), τ(x) is not defined. We can now define the learning criteria. Definition 7 (Identification in polynomial time and data (de la Higuera, 1997)). A class F offunctions is identifiable in polynomial time and data using a class T of representation</context>
</contexts>
<marker>Gold, 1967</marker>
<rawString>E. Mark Gold. 1967. Language identification in the limit. Information and Control, 10:447–474.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunnar Hansson</author>
</authors>
<title>Theoretical and Typological Issues in Consonant Harmony.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California, Berkeley.</institution>
<contexts>
<context position="24514" citStr="Hansson, 2001" startWordPosition="4452" endWordPosition="4453">ion are also shown to be ISL or OSL. More generally, we currently conjecture that a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comme</context>
</contexts>
<marker>Hansson, 2001</marker>
<rawString>Gunnar Hansson. 2001. Theoretical and Typological Issues in Consonant Harmony. Ph.D. thesis, University of California, Berkeley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Heinz</author>
<author>Regine Lai</author>
</authors>
<title>Vowel harmony and subsequentiality.</title>
<date>2013</date>
<booktitle>In Andras Kornai and Marco Kuhlmann, editors, Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13),</booktitle>
<pages>52</pages>
<contexts>
<context position="3293" citStr="Heinz and Lai, 2013" startWordPosition="512" endWordPosition="515">ngs from underlying forms to surface forms, which are also the bedrock of constraintbased frameworks like Optimality Theory (Prince and Smolensky, 1993). By showing that local phonological processes can be modeled with ISL (and OSL) functions, we provide the strongest computational characterization of the input-output mappings these processes represent. While it has been shown that phonological mappings describable with rules of the form A → B / C D (where A, B, C, and D are regular languages) are regular (Johnson, 1972; Kaplan and Kay, 1994), and even subsequential (Chandlee and Heinz, 2012; Heinz and Lai, 2013), many logically possible regular and subsequential mappings are not plausible phonological mappings. Since these implausible mappings cannot be modeled with ISL or OSL functions, we provide a more precise notion of 491 Transactions of the Association for Computational Linguistics, vol. 2, pp. 491–503, 2014. Action Editor: Alexander Clark. Submitted 4/2014; Revised 8/2014; Published November 1, 2014. c�2014 Association for Computational Linguistics. what constitues plausible phonological mappings. In addition, we present the Input SL Function Learning Algorithm (ISLFLA) and prove that it ident</context>
<context position="24466" citStr="Heinz and Lai, 2013" startWordPosition="4443" endWordPosition="4446">ion of the base it was copied from) and general affixation are also shown to be ISL or OSL. More generally, we currently conjecture that a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is t</context>
</contexts>
<marker>Heinz, Lai, 2013</marker>
<rawString>Jeffrey Heinz and Regine Lai. 2013. Vowel harmony and subsequentiality. In Andras Kornai and Marco Kuhlmann, editors, Proceedings of the 13th Meeting on the Mathematics of Language (MoL 13), pages 52–</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Heinz</author>
<author>Chetan Rawal</author>
<author>Herbert G Tanner</author>
</authors>
<title>Tier-based Strictly Local constraints for phonology.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>pages</pages>
<marker>Heinz, Rawal, Tanner, 2011</marker>
<rawString>Jeffrey Heinz, Chetan Rawal, and Herbert G. Tanner. 2011. Tier-based Strictly Local constraints for phonology. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 58– 64. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Heinz</author>
</authors>
<title>The Inductive Learning of Phonotactic Patterns.</title>
<date>2007</date>
<tech>Ph.D. thesis,</tech>
<institution>University of California,</institution>
<location>Los Angeles.</location>
<contexts>
<context position="2310" citStr="Heinz, 2007" startWordPosition="358" endWordPosition="359"> that a string is in the language only if its own k-factors are a subset of the grammar. These languages have also been characterized by Rogers and Pullum (2011) as those that have the property expressed in the following theorem (which can be taken as a defining property): Theorem 1 (Suffix Substitution Closure). L is Strictly Local ifffor all strings u1, v1, u2, v2, there exists k E N such that for any string x of length k − 1, if u1xv1, u2xv2 E L, then u1xv2 E L. These languages can model natural language phonotactic constraints which pick out contiguous substrings bounded by some length k (Heinz, 2007; Heinz, 2010). We define Input Strictly Local (ISL) and Output Strictly Local (OSL) functions which model phonological processes for which the target and triggering context are a bounded contiguous substring. Here our use of ‘process’ is not specific to rule-based grammatical formalisms (such as SPE (Chomsky and Halle, 1968)). ISL and OSL functions model mappings from underlying forms to surface forms, which are also the bedrock of constraintbased frameworks like Optimality Theory (Prince and Smolensky, 1993). By showing that local phonological processes can be modeled with ISL (and OSL) func</context>
</contexts>
<marker>Heinz, 2007</marker>
<rawString>Jeffrey Heinz. 2007. The Inductive Learning of Phonotactic Patterns. Ph.D. thesis, University of California, Los Angeles.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Heinz</author>
</authors>
<title>On the role of locality in learning stress patterns.</title>
<date>2009</date>
<tech>Phonology,</tech>
<pages>26--303</pages>
<contexts>
<context position="26316" citStr="Heinz (2009)" startWordPosition="4771" endWordPosition="4772">m: ISLFLA Given a finite dataset D of input-output string pairs (w, w&apos;) such that f(w) = w&apos;, where f is the target function, the learner tries to build TISL f . The dataset is submitted to the learner in the form of a prefix tree transducer (PTT), which is defined in Definition 4. Definition 4 (Prefix Tree Transducer). A prefix tree transducer for finite set D = for some f is PTT (D) = (Q, q0, E, Γ, S, σ), where • Q = U{Pref(w)|(w, w&apos;) E D} and q0 = λ • S = {(u, a, λ, ua) |u, ua E Q} • σ(w) = w&apos; for all (w, w&apos;) E D 5This general strategy is common in grammatical inference. See Angluin (1982), Heinz (2009), and de la Higuera (2010). #:A :a #:A A #:A #:A #:λ D D:λ #:λ D:λ D T:λ T:λ#:T #:D λ D:T T T:λ :T T:λ :D T:λ #:λ D:λ {(w, w&apos;) |f(w) = w&apos;} 497 As an example, the sample of data in (2) exemplifies the final devoicing rule in (1-a). Figure 6 gives the PTT for this data. deterministic. Non-determinism is removed in the inner loop with additional state merges. Consider the situation depicted on the lefthand side of Figure 8, which resulted from a previous merge. The non-determinism could be resolved by (2) {(D, T), (DD, DT), (DNT, DNT), (NND, NNT), (TDN, TDN)} Figure 6: PTT for the data in (2) Giv</context>
</contexts>
<marker>Heinz, 2009</marker>
<rawString>Jeffrey Heinz. 2009. On the role of locality in learning stress patterns. Phonology, 26:303–351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Heinz</author>
</authors>
<title>Learning long-distance phonotactics. Linguistic Inquiry,</title>
<date>2010</date>
<pages>41--623</pages>
<contexts>
<context position="2324" citStr="Heinz, 2010" startWordPosition="360" endWordPosition="361">g is in the language only if its own k-factors are a subset of the grammar. These languages have also been characterized by Rogers and Pullum (2011) as those that have the property expressed in the following theorem (which can be taken as a defining property): Theorem 1 (Suffix Substitution Closure). L is Strictly Local ifffor all strings u1, v1, u2, v2, there exists k E N such that for any string x of length k − 1, if u1xv1, u2xv2 E L, then u1xv2 E L. These languages can model natural language phonotactic constraints which pick out contiguous substrings bounded by some length k (Heinz, 2007; Heinz, 2010). We define Input Strictly Local (ISL) and Output Strictly Local (OSL) functions which model phonological processes for which the target and triggering context are a bounded contiguous substring. Here our use of ‘process’ is not specific to rule-based grammatical formalisms (such as SPE (Chomsky and Halle, 1968)). ISL and OSL functions model mappings from underlying forms to surface forms, which are also the bedrock of constraintbased frameworks like Optimality Theory (Prince and Smolensky, 1993). By showing that local phonological processes can be modeled with ISL (and OSL) functions, we prov</context>
</contexts>
<marker>Heinz, 2010</marker>
<rawString>Jeffrey Heinz. 2010. Learning long-distance phonotactics. Linguistic Inquiry, 41:623–661.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mans Hulden</author>
<author>I˜naki Alegria</author>
<author>Izaskun Etxeberria</author>
<author>Montse Maritxalar</author>
</authors>
<title>Learning word-level dialectal variation as phonological replacement rules using a limited parallel corpus.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, DIALECTS ’11,</booktitle>
<pages>39--48</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6094" citStr="Hulden et al. (2011)" startWordPosition="936" endWordPosition="939">removes OSTIA’s guarantee that all subsequential functions are learned. Similar to the approach of Gildea and Jurafsky (1996), our learner employs a context bias because it knows its target is an ISL function and therefore the transduction only involves bounded contiguous substrings. And similar to OSTIA-D (Oncina and Var`o, 1996; Castellanos et al., 1998), the ISLFLA makes use of domain information, because it makes decisions based on the input strings of the data set. It also employs a faithfulness bias in terms of the prop1The alignment was similar to the string-edit distance mehod used in Hulden et al. (2011). erty onwardness (see §2). The ISLFLA is supported by a theoretical result like Oncina et al. (1993), but learns a more restrictive class of mappings. We believe the theoretical results for this class will lead to new algorithms which include something akin to the community bias and that will succeed on natural language data while keeping strong theoretical results. The proposed learner also builds on earlier work by Chandlee and Koirala (2014) and Chandlee and Jardine (2014) which also used strict locality to learn phonological processes but with weaker theoretical results. The former did no</context>
</contexts>
<marker>Hulden, Alegria, Etxeberria, Maritxalar, 2011</marker>
<rawString>Mans Hulden, I˜naki Alegria, Izaskun Etxeberria, and Montse Maritxalar. 2011. Learning word-level dialectal variation as phonological replacement rules using a limited parallel corpus. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, DIALECTS ’11, pages 39–48. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mans Hulden</author>
</authors>
<title>Finite-State Machine Construction Methods and Algorithms for Phonology and Morphology.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Arizona.</institution>
<contexts>
<context position="24260" citStr="Hulden (2009)" startWordPosition="4414" endWordPosition="4415">tions (this appears to include all synchronic patterns). In addition, morpho-phonological processes such as local partial reduplication (i.e., in which the reduplicant is affixed adjacent to the portion of the base it was copied from) and general affixation are also shown to be ISL or OSL. More generally, we currently conjecture that a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potent</context>
</contexts>
<marker>Hulden, 2009</marker>
<rawString>Mans Hulden. 2009. Finite-State Machine Construction Methods and Algorithms for Phonology and Morphology. Ph.D. thesis, University of Arizona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Jardine</author>
</authors>
<title>Tone is (computationally) different. Unpublished manuscript,</title>
<date>2013</date>
<institution>University of</institution>
<location>Mouton.</location>
<contexts>
<context position="24784" citStr="Jardine, 2013" startWordPosition="4490" endWordPosition="4492">D it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input Strictly Local Functions We now present a learning algorithm for the class of ISL functions that uses its defining property as an inductive principle to generalize from a finite amount of data to a possibly infinite function. This learner begins wi</context>
</contexts>
<marker>Jardine, 2013</marker>
<rawString>Adam Jardine. 2013. Tone is (computationally) different. Unpublished manuscript, University of Delaware. C. Douglas Johnson. 1972. Formal Aspects of Phonological Description. The Hague, Mouton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian D Joseph</author>
<author>Irene Philippaki-Warburton</author>
</authors>
<title>Modern Greek. Croom Helm,</title>
<date>1987</date>
<location>Wolfeboro, NH.</location>
<contexts>
<context position="22615" citStr="Joseph and Philippaki-Warburton, 1987" startWordPosition="4108" endWordPosition="4111">tion to substitution processes like (1-a), another common type of process is insertion of a segment, such as the a-epenthesis process attested in Dutch (Warner et al., 2001). This process inserts a schwa between a liquid and a non-coronal consonant, as specified by (1-b). Using L to represent the liquids {l, r} and K to represent any non-coronal consonant, Figure 4 presentsT ISL f for this process. Following Beesley and Karttunen (2003), the symbol ‘?’ represents any segment of the alphabet other than the ones for which transitions are defined.4 Lastly, an example deletion process from Greek (Joseph and Philippaki-Warburton, 1987) deletes interdental fricatives before /0/ or /s/, as in (1-c). Figure 5 presents TISL f for this process. 3These abbreviations serve to improve the readability of the 1 FST - it is assumed that the transduction replaces a given voiced obstruent with its voiceless counterpart (not with any voiceless obstruent). 4This means Figure 4 is actually a shorthand for TISL f , which would otherwise have a distinct state for each symbol now represented with ‘?’. :λ #: :λ #:λ : : λ :λ #:λ #:λ 496 Figure 4: TISL f for (1-b) with k = 2 and E = {L, K, ?} Figure 5: TISL f for (1-c) with k = 2 and E = {0, d, </context>
</contexts>
<marker>Joseph, Philippaki-Warburton, 1987</marker>
<rawString>Brian D. Joseph and Irene Philippaki-Warburton. 1987. Modern Greek. Croom Helm, Wolfeboro, NH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Martin Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<pages>20--371</pages>
<contexts>
<context position="3221" citStr="Kaplan and Kay, 1994" startWordPosition="501" endWordPosition="504">such as SPE (Chomsky and Halle, 1968)). ISL and OSL functions model mappings from underlying forms to surface forms, which are also the bedrock of constraintbased frameworks like Optimality Theory (Prince and Smolensky, 1993). By showing that local phonological processes can be modeled with ISL (and OSL) functions, we provide the strongest computational characterization of the input-output mappings these processes represent. While it has been shown that phonological mappings describable with rules of the form A → B / C D (where A, B, C, and D are regular languages) are regular (Johnson, 1972; Kaplan and Kay, 1994), and even subsequential (Chandlee and Heinz, 2012; Heinz and Lai, 2013), many logically possible regular and subsequential mappings are not plausible phonological mappings. Since these implausible mappings cannot be modeled with ISL or OSL functions, we provide a more precise notion of 491 Transactions of the Association for Computational Linguistics, vol. 2, pp. 491–503, 2014. Action Editor: Alexander Clark. Submitted 4/2014; Revised 8/2014; Published November 1, 2014. c�2014 Association for Computational Linguistics. what constitues plausible phonological mappings. In addition, we present t</context>
<context position="24242" citStr="Kaplan and Kay (1994)" startWordPosition="4408" endWordPosition="4412"> original and surface positions (this appears to include all synchronic patterns). In addition, morpho-phonological processes such as local partial reduplication (i.e., in which the reduplicant is affixed adjacent to the portion of the base it was copied from) and general affixation are also shown to be ISL or OSL. More generally, we currently conjecture that a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we com</context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Ronald M. Kaplan and Martin Kay. 1994. Regular models of phonological rule systems. Computational Linguistics, 20:371–387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huan Luo</author>
</authors>
<title>Long-distance consonant harmony and subsequentiality.</title>
<date>2013</date>
<institution>University of Delaware.</institution>
<note>Unpublished manuscript,</note>
<contexts>
<context position="24549" citStr="Luo, 2013" startWordPosition="4458" endWordPosition="4459">ore generally, we currently conjecture that a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input Strictly Loca</context>
</contexts>
<marker>Luo, 2013</marker>
<rawString>Huan Luo. 2013. Long-distance consonant harmony and subsequentiality. Unpublished manuscript, University of Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert McNaughton</author>
<author>Seymour A Papert</author>
</authors>
<title>Counter-Free Automata.</title>
<date>1971</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1546" citStr="McNaughton and Papert, 1971" startWordPosition="219" endWordPosition="223">orphological processes belong to these classes. Finally we provide a learning algorithm which provably identifies the class of ISL functions in the limit from positive data in polynomial time and data. We demonstrate this learning result on appropriately synthesized artificial corpora. We leave a similar learning result for OSL functions for future work and suggest future directions for addressing non-local phonological processes. 1 Introduction In this paper we define two proper subclasses of subsequential functions based on the properties of the well-studied Strictly Local formal languages (McNaughton and Papert, 1971; Rogers and Pullum, 2011; Rogers et al., 2013). These are languages that can be defined with grammars of substrings of length k (called k-factors), such that a string is in the language only if its own k-factors are a subset of the grammar. These languages have also been characterized by Rogers and Pullum (2011) as those that have the property expressed in the following theorem (which can be taken as a defining property): Theorem 1 (Suffix Substitution Closure). L is Strictly Local ifffor all strings u1, v1, u2, v2, there exists k E N such that for any string x of length k − 1, if u1xv1, u2xv</context>
<context position="41569" citStr="McNaughton and Papert, 1971" startWordPosition="7688" endWordPosition="7691">nctions and argued that they can model many phonological and morphological processes. Lastly, an automata-theoretic characterization of ISL functions was presented, along with a learning algorithm that efficiently learn this class in the limit from positive data. Current work includes developing a comparable automata characterization and learning algorithm for OSL functions, as well as defining additional functional classes to model those phonological processes that cannot be modeled with ISL or OSL functions. The SL languages are just one region of a subregular hierarchy of formal languages (McNaughton and Papert, 1971; Rogers and Pullum, 2011; Rogers et al., 2013). The ISL and OSL functions defined here are the first step in developing a corresponding hierarchy of subregular functions. Of immediate interest to phonology are functional counterparts for the Tier-Based Strictly Local and Strictly Piecewise language classes, which have been shown to model long-distance phonotactics (Heinz, 2010; Heinz et al., 2011). Such functions might be useful for modeling the long-distance processes that repair violations of these phonotactic constraints. Acknowledgements We thank Adam Jardine, Jim Rogers, and the three an</context>
</contexts>
<marker>McNaughton, Papert, 1971</marker>
<rawString>Robert McNaughton and Seymour A. Papert. 1971. Counter-Free Automata. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
</authors>
<title>Finite-state transducers in language and speech processing.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<pages>23--269</pages>
<contexts>
<context position="11319" citStr="Mohri (1997)" startWordPosition="1944" endWordPosition="1945">E*)−1lcp(f(xaE*)). Then, • Q = {tailsf(x) |x ∈ E*}, • q0 = tailsf(λ), • ∀tailsf(x) ∈ Q, σ(tailsf(x)) = lcp(f(xE*))−1f(x) if x ∈ dom(f) and is undefined otherwise, • δ = {(tailsf(x), a, contf(a, x), tailsf(xa))}. Tf&apos; has an important property called onwardness. Definition 1 (onwardness). For all q ∈ Q let the outputs of the edges out of q be outs(q) = {u | (∃a ∈ E)(∃r ∈ Q)[(q, a, u, r) ∈ δ]}. A SFST T is onward iffor all q ∈ Q \ {q0}, lcp(outs(q)) = λ. Informally, this means that the writing of output is never delayed. Readers are referred to Oncina and Garcia (1991), Oncina et al. (1993), and Mohri (1997) for more on SFSTs. 3 Strictly Local Functions In this section we define Input and Output Strictly Local functions and provide properties of these classes. These definitions are analogous to the language-theoretic definition of Strictly Local languages (Theorem 1) (Rogers and Pullum, 2011; Rogers et al., 2013). Definition 2 (Input Strictly Local Function). A function f is Input Strictly Local (ISL) if there is a k such that for all u1, u2 ∈ E*, if Suffk−1(u1) = Suffk−1(u2) then tailsf(u1) = tailsf(u2). The theorem below establishes an automatatheoretic characterization of ISL functions. Theore</context>
</contexts>
<marker>Mohri, 1997</marker>
<rawString>Mehryar Mohri. 1997. Finite-state transducers in language and speech processing. Computational Linguistics, 23:269–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Oncina</author>
<author>Pedro Garc´ıa</author>
</authors>
<title>Inductive learning of subsequential functions.</title>
<date>1991</date>
<tech>Technical Report DSIC II34,</tech>
<institution>University Polit´ecnia de Valencia.</institution>
<marker>Oncina, Garc´ıa, 1991</marker>
<rawString>Jos´e Oncina and Pedro Garc´ıa. 1991. Inductive learning of subsequential functions. Technical Report DSIC II34, University Polit´ecnia de Valencia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Oncina</author>
<author>Miguel A Var`o</author>
</authors>
<title>Using domain information during the learning of a subsequential transducer.</title>
<date>1996</date>
<booktitle>Lecture Notes in Computer Science - Lecture Notes in Artificial Intelligence,</booktitle>
<pages>313--325</pages>
<marker>Oncina, Var`o, 1996</marker>
<rawString>Jos´e Oncina and Miguel A. Var`o. 1996. Using domain information during the learning of a subsequential transducer. Lecture Notes in Computer Science - Lecture Notes in Artificial Intelligence, pages 313– 325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jos´e Oncina</author>
<author>Pedro Garc´ıa</author>
<author>Enrique Vidal</author>
</authors>
<title>Learning subsequential transducers for pattern recognition interpretation tasks.</title>
<date>1993</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>15</volume>
<issue>5</issue>
<pages>457</pages>
<marker>Oncina, Garc´ıa, Vidal, 1993</marker>
<rawString>Jos´e Oncina, Pedro Garc´ıa, and Enrique Vidal. 1993. Learning subsequential transducers for pattern recognition interpretation tasks. IEEE Transactions on Pattern Analysis and Machine Intelligence, 15(5):448– 457.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amanda Payne</author>
</authors>
<title>Dissimilation as a subsequential process.</title>
<date>2013</date>
<institution>University of Delaware.</institution>
<note>Unpublished manuscript,</note>
<contexts>
<context position="24610" citStr="Payne, 2013" startWordPosition="4466" endWordPosition="4467">rite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input Strictly Local Functions We now present a learning algorithm for the class</context>
</contexts>
<marker>Payne, 2013</marker>
<rawString>Amanda Payne. 2013. Dissimilation as a subsequential process. Unpublished manuscript, University of Delaware.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Prince</author>
<author>Paul Smolensky</author>
</authors>
<title>Optimality Theory: Constraint interaction in generative grammar.</title>
<date>1993</date>
<tech>Technical Report 2,</tech>
<institution>Rutgers University Center for Cognitive Science.</institution>
<contexts>
<context position="2825" citStr="Prince and Smolensky, 1993" startWordPosition="435" endWordPosition="438">ural language phonotactic constraints which pick out contiguous substrings bounded by some length k (Heinz, 2007; Heinz, 2010). We define Input Strictly Local (ISL) and Output Strictly Local (OSL) functions which model phonological processes for which the target and triggering context are a bounded contiguous substring. Here our use of ‘process’ is not specific to rule-based grammatical formalisms (such as SPE (Chomsky and Halle, 1968)). ISL and OSL functions model mappings from underlying forms to surface forms, which are also the bedrock of constraintbased frameworks like Optimality Theory (Prince and Smolensky, 1993). By showing that local phonological processes can be modeled with ISL (and OSL) functions, we provide the strongest computational characterization of the input-output mappings these processes represent. While it has been shown that phonological mappings describable with rules of the form A → B / C D (where A, B, C, and D are regular languages) are regular (Johnson, 1972; Kaplan and Kay, 1994), and even subsequential (Chandlee and Heinz, 2012; Heinz and Lai, 2013), many logically possible regular and subsequential mappings are not plausible phonological mappings. Since these implausible mappin</context>
</contexts>
<marker>Prince, Smolensky, 1993</marker>
<rawString>Alan Prince and Paul Smolensky. 1993. Optimality Theory: Constraint interaction in generative grammar. Technical Report 2, Rutgers University Center for Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Riggle</author>
</authors>
<title>Non-local reduplication.</title>
<date>2003</date>
<booktitle>In Proceedings of the 34th Annual Meeting of the North Eastern Linguistic Society.</booktitle>
<contexts>
<context position="24743" citStr="Riggle, 2003" startWordPosition="4484" endWordPosition="4485">ff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input Strictly Local Functions We now present a learning algorithm for the class of ISL functions that uses its defining property as an inductive principle to generalize from a finite amount of data to a possibly </context>
</contexts>
<marker>Riggle, 2003</marker>
<rawString>Jason Riggle. 2003. Non-local reduplication. In Proceedings of the 34th Annual Meeting of the North Eastern Linguistic Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Rogers</author>
<author>Geoffrey K Pullum</author>
</authors>
<title>Aural pattern recognition experiments and the subregular hierarchy.</title>
<date>2011</date>
<journal>Journal of Logic, Language and Information,</journal>
<pages>20--329</pages>
<contexts>
<context position="1571" citStr="Rogers and Pullum, 2011" startWordPosition="224" endWordPosition="227"> to these classes. Finally we provide a learning algorithm which provably identifies the class of ISL functions in the limit from positive data in polynomial time and data. We demonstrate this learning result on appropriately synthesized artificial corpora. We leave a similar learning result for OSL functions for future work and suggest future directions for addressing non-local phonological processes. 1 Introduction In this paper we define two proper subclasses of subsequential functions based on the properties of the well-studied Strictly Local formal languages (McNaughton and Papert, 1971; Rogers and Pullum, 2011; Rogers et al., 2013). These are languages that can be defined with grammars of substrings of length k (called k-factors), such that a string is in the language only if its own k-factors are a subset of the grammar. These languages have also been characterized by Rogers and Pullum (2011) as those that have the property expressed in the following theorem (which can be taken as a defining property): Theorem 1 (Suffix Substitution Closure). L is Strictly Local ifffor all strings u1, v1, u2, v2, there exists k E N such that for any string x of length k − 1, if u1xv1, u2xv2 E L, then u1xv2 E L. Th</context>
<context position="11608" citStr="Rogers and Pullum, 2011" startWordPosition="1986" endWordPosition="1989">ardness). For all q ∈ Q let the outputs of the edges out of q be outs(q) = {u | (∃a ∈ E)(∃r ∈ Q)[(q, a, u, r) ∈ δ]}. A SFST T is onward iffor all q ∈ Q \ {q0}, lcp(outs(q)) = λ. Informally, this means that the writing of output is never delayed. Readers are referred to Oncina and Garcia (1991), Oncina et al. (1993), and Mohri (1997) for more on SFSTs. 3 Strictly Local Functions In this section we define Input and Output Strictly Local functions and provide properties of these classes. These definitions are analogous to the language-theoretic definition of Strictly Local languages (Theorem 1) (Rogers and Pullum, 2011; Rogers et al., 2013). Definition 2 (Input Strictly Local Function). A function f is Input Strictly Local (ISL) if there is a k such that for all u1, u2 ∈ E*, if Suffk−1(u1) = Suffk−1(u2) then tailsf(u1) = tailsf(u2). The theorem below establishes an automatatheoretic characterization of ISL functions. Theorem 3. A function f is ISL iff there is some k such that f can be described with a SFST for which 1. Q = E&lt;k−1 and q0 = λ 2. (∀q ∈ Q,∀a ∈ E,∀u ∈ F*) [(q, a, u, q&apos;) ∈ δ ⇒ q&apos; = Suffk−1(qa)]. 493 This theorem helps make clear how ISL functions are Markovian: the output for input symbol a depen</context>
<context position="41594" citStr="Rogers and Pullum, 2011" startWordPosition="7692" endWordPosition="7695">can model many phonological and morphological processes. Lastly, an automata-theoretic characterization of ISL functions was presented, along with a learning algorithm that efficiently learn this class in the limit from positive data. Current work includes developing a comparable automata characterization and learning algorithm for OSL functions, as well as defining additional functional classes to model those phonological processes that cannot be modeled with ISL or OSL functions. The SL languages are just one region of a subregular hierarchy of formal languages (McNaughton and Papert, 1971; Rogers and Pullum, 2011; Rogers et al., 2013). The ISL and OSL functions defined here are the first step in developing a corresponding hierarchy of subregular functions. Of immediate interest to phonology are functional counterparts for the Tier-Based Strictly Local and Strictly Piecewise language classes, which have been shown to model long-distance phonotactics (Heinz, 2010; Heinz et al., 2011). Such functions might be useful for modeling the long-distance processes that repair violations of these phonotactic constraints. Acknowledgements We thank Adam Jardine, Jim Rogers, and the three anonymous reviewers for hel</context>
</contexts>
<marker>Rogers, Pullum, 2011</marker>
<rawString>James Rogers and Geoffrey K. Pullum. 2011. Aural pattern recognition experiments and the subregular hierarchy. Journal of Logic, Language and Information, 20:329–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Rogers</author>
<author>Jeffrey Heinz</author>
<author>Margaret Fero</author>
<author>Jeremy Hurst</author>
<author>Dakotah Lambert</author>
<author>Sean Wibel</author>
</authors>
<title>Cognitive and sub-regular complexity.</title>
<date>2013</date>
<booktitle>In Glyn Morrill and Mark-Jan Nederhof, editors, Formal Grammar, Lecture Notes in Computer Science,</booktitle>
<volume>8036</volume>
<pages>90--108</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1593" citStr="Rogers et al., 2013" startWordPosition="228" endWordPosition="231">y we provide a learning algorithm which provably identifies the class of ISL functions in the limit from positive data in polynomial time and data. We demonstrate this learning result on appropriately synthesized artificial corpora. We leave a similar learning result for OSL functions for future work and suggest future directions for addressing non-local phonological processes. 1 Introduction In this paper we define two proper subclasses of subsequential functions based on the properties of the well-studied Strictly Local formal languages (McNaughton and Papert, 1971; Rogers and Pullum, 2011; Rogers et al., 2013). These are languages that can be defined with grammars of substrings of length k (called k-factors), such that a string is in the language only if its own k-factors are a subset of the grammar. These languages have also been characterized by Rogers and Pullum (2011) as those that have the property expressed in the following theorem (which can be taken as a defining property): Theorem 1 (Suffix Substitution Closure). L is Strictly Local ifffor all strings u1, v1, u2, v2, there exists k E N such that for any string x of length k − 1, if u1xv1, u2xv2 E L, then u1xv2 E L. These languages can mode</context>
<context position="11630" citStr="Rogers et al., 2013" startWordPosition="1990" endWordPosition="1993">et the outputs of the edges out of q be outs(q) = {u | (∃a ∈ E)(∃r ∈ Q)[(q, a, u, r) ∈ δ]}. A SFST T is onward iffor all q ∈ Q \ {q0}, lcp(outs(q)) = λ. Informally, this means that the writing of output is never delayed. Readers are referred to Oncina and Garcia (1991), Oncina et al. (1993), and Mohri (1997) for more on SFSTs. 3 Strictly Local Functions In this section we define Input and Output Strictly Local functions and provide properties of these classes. These definitions are analogous to the language-theoretic definition of Strictly Local languages (Theorem 1) (Rogers and Pullum, 2011; Rogers et al., 2013). Definition 2 (Input Strictly Local Function). A function f is Input Strictly Local (ISL) if there is a k such that for all u1, u2 ∈ E*, if Suffk−1(u1) = Suffk−1(u2) then tailsf(u1) = tailsf(u2). The theorem below establishes an automatatheoretic characterization of ISL functions. Theorem 3. A function f is ISL iff there is some k such that f can be described with a SFST for which 1. Q = E&lt;k−1 and q0 = λ 2. (∀q ∈ Q,∀a ∈ E,∀u ∈ F*) [(q, a, u, q&apos;) ∈ δ ⇒ q&apos; = Suffk−1(qa)]. 493 This theorem helps make clear how ISL functions are Markovian: the output for input symbol a depends on the last (k — 1)</context>
<context position="41616" citStr="Rogers et al., 2013" startWordPosition="7696" endWordPosition="7699">al and morphological processes. Lastly, an automata-theoretic characterization of ISL functions was presented, along with a learning algorithm that efficiently learn this class in the limit from positive data. Current work includes developing a comparable automata characterization and learning algorithm for OSL functions, as well as defining additional functional classes to model those phonological processes that cannot be modeled with ISL or OSL functions. The SL languages are just one region of a subregular hierarchy of formal languages (McNaughton and Papert, 1971; Rogers and Pullum, 2011; Rogers et al., 2013). The ISL and OSL functions defined here are the first step in developing a corresponding hierarchy of subregular functions. Of immediate interest to phonology are functional counterparts for the Tier-Based Strictly Local and Strictly Piecewise language classes, which have been shown to model long-distance phonotactics (Heinz, 2010; Heinz et al., 2011). Such functions might be useful for modeling the long-distance processes that repair violations of these phonotactic constraints. Acknowledgements We thank Adam Jardine, Jim Rogers, and the three anonymous reviewers for helpful comments. This re</context>
</contexts>
<marker>Rogers, Heinz, Fero, Hurst, Lambert, Wibel, 2013</marker>
<rawString>James Rogers, Jeffrey Heinz, Margaret Fero, Jeremy Hurst, Dakotah Lambert, and Sean Wibel. 2013. Cognitive and sub-regular complexity. In Glyn Morrill and Mark-Jan Nederhof, editors, Formal Grammar, Lecture Notes in Computer Science, volume 8036, pages 90–108. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Rose</author>
<author>Rachel Walker</author>
</authors>
<title>A typology of consonant agreement as correspondence.</title>
<date>2004</date>
<tech>Language, 80:475–531.</tech>
<contexts>
<context position="24537" citStr="Rose and Walker, 2004" startWordPosition="4454" endWordPosition="4457">own to be ISL or OSL. More generally, we currently conjecture that a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input S</context>
</contexts>
<marker>Rose, Walker, 2004</marker>
<rawString>Sharon Rose and Rachel Walker. 2004. A typology of consonant agreement as correspondence. Language, 80:475–531.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keiichiro Suzuki</author>
</authors>
<title>A Typological Investigation of Dissimilation.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Arizona.</institution>
<contexts>
<context position="24581" citStr="Suzuki, 1998" startWordPosition="4462" endWordPosition="4463">njecture that a SPE-style rewrite rule of the form A 1 → B/ C D which applies simultaneously (leftto-right) describes an Input (Output) Strictly Local function iff there is a k such that for all w E CAD it is the case that |w |G k. We refer readers to Kaplan and Kay (1994) and Hulden (2009) for more on how SPE rules and application modes determine mappings. In contrast, non-local (long-distance) processes such as vowel harmony with transparent vowels (Gainor et al., 2012; Heinz and Lai, 2013), long distance consonant harmony (Hansson, 2001; Rose and Walker, 2004; Luo, 2013) and dissimilation (Suzuki, 1998; Bennett, 2013; Payne, 2013), unbounded displacement/metathesis (Chandlee et al., 2012; Chandlee and Heinz, 2012), non-local partial reduplication (Riggle, 2003), and some tonal patterns (Jardine, 2013) cannot be modeled with ISL or OSL functions. In §6 we comment on the potential for adapting the current analysis to non-local mappings. The next section presents a learning algorithm for ISL functions, the ISLFLA. The development of a corresponding algorithm for OSL functions is the subject of ongoing work, but see §6 for comments. 5 Learning Input Strictly Local Functions We now present a lea</context>
</contexts>
<marker>Suzuki, 1998</marker>
<rawString>Keiichiro Suzuki. 1998. A Typological Investigation of Dissimilation. Ph.D. thesis, University of Arizona.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Natasha Warner</author>
<author>Allard Jongman</author>
<author>Anne Cutler</author>
<author>Doris M¨ucke</author>
</authors>
<title>The phonological status of Dutch epenthetic schwa.</title>
<date>2001</date>
<tech>Phonology,</tech>
<pages>18--387</pages>
<marker>Warner, Jongman, Cutler, M¨ucke, 2001</marker>
<rawString>Natasha Warner, Allard Jongman, Anne Cutler, and Doris M¨ucke. 2001. The phonological status of Dutch epenthetic schwa. Phonology, 18:387–420.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>