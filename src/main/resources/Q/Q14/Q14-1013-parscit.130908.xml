<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000042">
<title confidence="0.9983405">
Senti-LSSVM: Sentiment-Oriented Multi-Relation Extraction
with Latent Structural SVM
</title>
<author confidence="0.903961">
Lizhen Qu
</author>
<affiliation confidence="0.660914666666667">
Max Planck Institute
for Informatics
lqu@mpi-inf.mpg.de
</affiliation>
<author confidence="0.981436">
Lili Jiang
</author>
<affiliation confidence="0.815955333333333">
Max Planck Institute
for Informatics
ljiang@mpi-inf.mpg.de
</affiliation>
<author confidence="0.503864">
Yi Zhang
</author>
<affiliation confidence="0.367345">
Nuance Communications
</affiliation>
<email confidence="0.843966">
yi.zhang@nuance.com
</email>
<author confidence="0.981687">
Rainer Gemulla
</author>
<affiliation confidence="0.795074333333333">
Max Planck Institute
for Informatics
rgemulla@mpi-inf.mpg.de
</affiliation>
<author confidence="0.445395">
Rui Wang
</author>
<affiliation confidence="0.363491">
DFKI GmbH
</affiliation>
<email confidence="0.76881">
mars198356@hotmail.com
</email>
<author confidence="0.978957">
Gerhard Weikum
</author>
<affiliation confidence="0.9188555">
Max Planck Institute
for Informatics
</affiliation>
<email confidence="0.528099">
weikum@mpi-inf.mpg.de
</email>
<sectionHeader confidence="0.991638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9950119">
Extracting instances of sentiment-oriented re-
lations from user-generated web documents is
important for online marketing analysis. Un-
like previous work, we formulate this extrac-
tion task as a structured prediction problem
and design the corresponding inference as an
integer linear program. Our latent structural
SVM based model can learn from training cor-
pora that do not contain explicit annotations of
sentiment-bearing expressions, and it can si-
multaneously recognize instances of both bi-
nary (polarity) and ternary (comparative) re-
lations with regard to entity mentions of in-
terest. The empirical evaluation shows that
our approach significantly outperforms state-
of-the-art systems across domains (cameras
and movies) and across genres (reviews and
forum posts). The gold standard corpus that
we built will also be a valuable resource for
the community.
</bodyText>
<sectionHeader confidence="0.998882" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99996797826087">
Sentiment-oriented relation extraction (Choi et al.,
2006) is concerned with recognizing sentiment po-
larities and comparative relations between entities
from natural language text. Identifying such rela-
tions often requires syntactic and semantic analysis
at both sentence and phrase level. Most prior work
on sentiment analysis consider either i) subjective
sentence detection (Yu and Kübler, 2011), ii) po-
larity classification (Johansson and Moschitti, 2011;
Wilson et al., 2005), or iii) comparative relation
identification (Jindal and Liu, 2006; Ganapathib-
hotla and Liu, 2008). In practice, however, differ-
ent types of sentiment-oriented relations frequently
coexist in documents. In particular, we found that
more than 38% of the sentences in our test corpus
contain more than one type of relations. The iso-
lated analysis approach is inappropriate because i) it
sacrifices acuracy by ignoring the intricate interplay
among different types of relations; ii) it could lead to
conflicting predictions such as estimating a relation
candidate as both negative and comparative. There-
fore, in this paper, we identify instances of both sen-
timent polarities and comparative relations for enti-
ties of interest simultaneously. We assume that all
the mentions of entities and attributes are given, and
entities are disambiguated. It is a widely used as-
sumption when evaluating a module in a pipeline
system that the outputs of preceding modules are
error-free.
To the best of our knowledge, the only exist-
ing system capable of extracting both comparisons
and sentiment polarities is a rule-based system pro-
posed by Ding et al. (2009). We argue that it is
better to tackle the task by using a unified model
with structured outputs. It allows us to consider a
set of correlated relation instances jointly and char-
acterize their interaction through a set of soft and
hard constraints. For example, we can encode con-
straints to discourage an attribute to participate in
a polarity relation and a comparative relation at the
same time. As a result, the system extracts a set of
correlated instances of sentiment-oriented relations
from a given sentence. For example, with the sen-
tence about the camera Canon 7D, “The sensor is
great, but the price is higher than Nikon D7000.”
the expected output is positive(Canon 7D, sensor)
</bodyText>
<page confidence="0.993888">
155
</page>
<bodyText confidence="0.97806305">
Transactions of the Association for Computational Linguistics, 2 (2014) 155–168. Action Editor: Janyce Wiebe.
Submitted 6/2013; Revised 11/2013; Published 4/2014. c�2014 Association for Computational Linguistics.
and preferred(Nikon D7000, Canon 7D, textit-
price).
However, constructing a fully annotated train-
ing corpus for this task is labor-intensive and re-
quires strong linguistic background. We minimize
this overhead by applying a simplified annotation
scheme, in which annotators mark mentions of en-
tities and attributes, disambiguate the entities, and
label instances of relations for each sentence. Based
on the new scheme, we have created a small Senti-
ment Relation Graph (SRG) corpus for the domains
of cameras and movies, which significantly differs
from the corpora used in prior work (Wei and Gulla,
2010; Kessler et al., 2010; Toprak et al., 2010;
Wiebe et al., 2005; Hu and Liu, 2004) in the follow-
ing ways: i) both sentiment polarities and compar-
ative relations are annotated; ii) all mentioned en-
tities are disambiguated; and iii) no subjective ex-
pressions are annotated, unless they are part of entity
mentions.
The new annotation scheme raises a new chal-
lenge for learning algorithms in that they need to
automatically find textual evidences for each anno-
tated relation during training. For example, with the
sentence “I like the Rebel a little better, but that is
another price jump”, simply assigning a sentiment-
bearing expression to the nearest relation candidate
is insufficient, especially when the sentiment is not
explicitly expressed.
In this paper, we propose SENTI-LSSVM, a latent
structural SVM based model for sentiment-oriented
relation extraction. SENTI-LSSVM is applied to find
the most likely set of the relation instances expressed
in a given sentence, where the latent variables are
used to assign the most appropriate textual evidences
to the respective instances.
In summary, the contributions of this paper are the
following:
</bodyText>
<listItem confidence="0.9948579375">
• We propose SENTI-LSSVM: the first unified sta-
tistical model with the capability of extracting
instances of both binary and ternary sentiment-
oriented relations.
• We design a task-specific integer linear pro-
gramming (ILP) formulation for inference.
• We construct a new SRG corpus as a valuable
asset for the evaluation of sentiment relation
extraction.
• We conduct extensive experiments with on-
line reviews and forum posts, showing that
SENTI-LSSVM model can effectively learn from
a training corpus without explicitly annotated
subjective expressions and that its performance
significantly outperforms state-of-the-art sys-
tems.
</listItem>
<sectionHeader confidence="0.99883" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99996772972973">
There are ample works on analyzing sentiment po-
larities and entity comparisons, but the majority of
them studied the two tasks in isolation.
Most prior approaches for fine-grained sentiment
analysis focus on polarity classification. Super-
vised approaches on expression-level analysis re-
quire the annotation of sentiment-bearing expres-
sions as training data (Jin et al., 2009; Choi
and Cardie, 2010; Johansson and Moschitti, 2011;
Yessenalina and Cardie, 2011; Wei and Gulla,
2010). However, the corresponding annotation pro-
cess is time-consuming. Although sentence-level
annotations are easier to obtain, the analysis at this
level cannot cope with sentences conveying relations
of multiple types (McDonald et al., 2007; Täckström
and McDonald, 2011; Socher et al., 2012). Lexicon-
based approaches require no training data (Ku et al.,
2006; Kim and Hovy, 2006; Godbole et al., 2007;
Ding et al., 2008; Popescu and Etzioni, 2005; Liu et
al., 2005) but suffer from inferior performance (Wil-
son et al., 2005; Qu et al., 2012). In contrast, our
method requires no annotation of sentiment-bearing
expressions for training and can predict both senti-
ment polarities and comparative relations.
Sentiment-oriented comparative relations have
been studied in the context of user-generated dis-
course (Jindal and Liu, 2006; Ganapathibhotla and
Liu, 2008). Approaches rely on linguistically moti-
vated rules and assume the existence of independent
keywords in sentences which indicate comparative
relations. Therefore, these methods fall short of ex-
tracting comparative relations based on domain de-
pendent information.
Both Johansson and Moschitti (2011) and Wu et
al. (2011) formulate fine-grained sentiment analy-
sis as a learning problem with structured outputs.
However, they focus only on polarity classification
</bodyText>
<page confidence="0.998105">
156
</page>
<bodyText confidence="0.9997679">
of expressions and require annotation of sentiment-
bearing expressions for training as well.
While ILP has been previously applied for infer-
ence in sentiment analysis (Choi and Cardie, 2009;
Somasundaran and Wiebe, 2009; Wu et al., 2011),
our task requires a complete ILP reformulation due
to 1) the absence of annotated sentiment expressions
and 2) the constraints imposed by the joint extrac-
tion of both sentiment polarity and comparative re-
lations.
</bodyText>
<sectionHeader confidence="0.966364" genericHeader="method">
3 System Overview
</sectionHeader>
<bodyText confidence="0.999821428571429">
This section gives an overview of the whole system
for extracting sentiment-oriented relation instances.
Prior to presenting the system architecture, we in-
troduce the essential concepts and the definitions of
two kinds of directed hypergraphs as the represen-
tation of correlated relation instances extracted from
sentences.
</bodyText>
<subsectionHeader confidence="0.997779">
3.1 Concepts and Definitions
</subsectionHeader>
<bodyText confidence="0.984210461538462">
Entity. An entity is an abstract or concrete thing,
which needs not be of material existence. An entity
in this paper refers to either a product or a brand.
Attribute. An attribute is an object closely associ-
ated with or belonging to an entity, such as the lens
of digital camera.
Sentiment-Oriented Relation. A sentiment-
oriented relation is either a sentiment polarity or a
comparative relation, defined on tuples of entities
and attributes. A sentiment polarity relation conveys
either a positive or a negative attitude towards enti-
ties or their attributes, whereas a comparative rela-
tion indicates the preference of one entity over the
other entity w.r.t. an attribute.
Relation Instance. An instance of sentiment polar-
ity takes the form r(entity, attribute) with r E {pos-
itive, negative}, such as positive(Canon 7D, sen-
sor). The polarity instances expressed in the form
of unary relations, such as “Nikon D7000 is ex-
cellent.”, are denoted as binary relations r(entity,
whole), where the attribute whole indicates the en-
tity as a whole. In contrast, an instance of compar-
ative relation is in the form of preferred{entity, en-
tity, attribute}, e.g. preferred(Canon 7D, Nikon
D7000, price). For brevity, we refer to an instance
set of sentiment-oriented relations extracted from a
sentence as an sSoR. To represent the instances
of the remaining relations, we represent them as
other{entity, attribute}, such as textitpartOf{wheel,
car}. These relations include objective relations
and the subjective relations other than sentiment-
oriented relations.
Mention-Based Relation Instances. A mention-
based relation instance refers to a tuple of entity
mentions with a certain relation. This concept is in-
troduced as the representation of instances in a sen-
tence by replacing entities with the corresponding
entity mentions, such as positive(“Canon SD880i”,
“wide angle view”).
</bodyText>
<figureCaption confidence="0.998406">
Figure 1: An example of MRG.
</figureCaption>
<bodyText confidence="0.999612666666667">
Mention-Based Relation Graph. A mention-based
relation graph (or MRG ) represents a collection of
mention-based relation instances expressed in a sen-
tence. As illustrated in Figure 1, an MRG is a di-
rected hypergraph G = (M, E) with a vertex set
M and an edge set E. A vertex mi E M denotes
a mention of an entity or an attribute occurring ei-
ther within the sentence or in its context. We say
that a mention is from the context if it is mentioned
in the previous sentence or is an attribute implied
in the current sentence. An instance of a binary re-
lation in an MRG takes the form of a binary edge
el = (mi, ma), where mi and ma denote an en-
tity mention and an attribute mention respectively,
and the type l E {positive, negative, other}. A
ternary edge el indicating comparative relation is
represented as el = (mi, mj, ma), where two en-
tity mentions mi and mj are compared with respect
to the attribute mention ma. We define the type
l E {better,worse} to indicate two possible direc-
tions of the relation and assume mi occurs before
mj. As a result, we have a set L of five relation
types: positive, negative, better, worse or other. Ac-
cording to these definitions, the annotations in the
SRG corpus are actually MRGs and disambiguated
entities. If there are multiple mentions referring to
the same entity, annotators are asked to choose the
</bodyText>
<page confidence="0.99653">
157
</page>
<bodyText confidence="0.952138333333333">
most obvious one because it saves annotation time
and is less demanding for the entity recognition and
diambiguation modules.
</bodyText>
<figureCaption confidence="0.925108">
Figure 2: An example of eMRG. The textual evi-
dences are wrapped by green dashed boxes.
</figureCaption>
<bodyText confidence="0.986717">
Evidentiary Mention-Based Relation Graph. An
evidentiary mention-based relation graph, coined
eMRG , extends an MRG by associating each edge
with a textual evidence to support the corresponding
relation assertions (see Figure 2). Consequently, an
edge in an eMRG is denoted by a pair (a, c), where
a represents a mention-based relation instance and
c is the associated textual evidence. It is also re-
ferred to as an evidentiary edge. represented as
el = (mi, mj, ma), an MRG as an evidentiary MRG
(eMRG) and the edges of eMRGs as evidentiary
edges, as shown in Figure 2.
</bodyText>
<subsectionHeader confidence="0.995792">
3.2 System Architecture
</subsectionHeader>
<figureCaption confidence="0.986694">
Figure 3: System architecture.
</figureCaption>
<bodyText confidence="0.999995607142857">
As illustrated by Figure 3, at the core of our sys-
tem is the SENTI-LSSVM model, which extracts sets
of mention-based relationships in the form of eMRGs
from sentences. For a given sentence with known
entity mentions, we select all possible mention sets
as relation candidates, where each set includes at
least one entity mention. Then we associate each
relation candidate with a set of constituents or the
whole sentence as the textual evidence candidates
(cf. Section 6.1). Subsequently, the inference com-
ponent aims to find the most likely eMRG from all
possible combinations of mention-based relation in-
stances and their textual evidences (cf. Section 6.2).
The representation eMRG is chosen because it char-
acterizes exactly the model outputs by letting each
edge correspond to an instance of mention-based re-
lation and the associated textual evidence. Finally,
the model parameters of this model are learned by
an online algorithm (cf. Section 7).
Since instance sets of sentiment-oriented relations
(sSoRs) are the expected outputs, we can obtain
sSoRs from MRGs by using a simple rule-based al-
gorithm. The algorithm essentially maps the men-
tions from an MRG into entities and attributes in an
sSoR and label the corresponding tuples with the re-
lation types of the edges from an MRG. For instances
of comparative relation, the label better or worse is
mapped to the relation type preferred.
</bodyText>
<sectionHeader confidence="0.999793" genericHeader="method">
4 SENTI-LSSVM Model
</sectionHeader>
<bodyText confidence="0.999939157894737">
The task of sentiment-oriented relation extraction
is to determine the most likely sSoR in a sentence.
Since sSoRs are derived from the corresponding
MRGs as described in Section 3, the task is reduced
to find the most likely MRG for each sentence. Since
an MRG is created by assigning relation types to a
subset of all relation candidates, which are possible
tuples of mentions with unknown relation types, the
number of MRGs can be extremely high.
To tackle the task, one solution is to employ
an edge-factored linear model in the framework of
structural SVM (Martins et al., 2009; Tsochantaridis
et al., 2004). The model suggests that a bag of fea-
tures should be specified for each relation candidate,
and then the model predicts the most likely candi-
date sets along with their relation types to form the
optimal MRGs. As we observed, for a relation can-
didate, the most informative features are the words
near its entity mentions in the original text. How-
</bodyText>
<page confidence="0.992027">
158
</page>
<bodyText confidence="0.999879136363636">
ever, if we represent a candidate by all these words,
it is very likely that the instances of different relation
types share overly similar features, because a men-
tion is often involved in more than one relation can-
didate, as shown in Figure 2. As a consequence, the
instances of different relations represented by overly
similar features can easily confuse the learning algo-
rithm. Thus, it is critical to select proper constituents
or sentences as textual evidences for each relation
candidate in both training and testing.
Consequently, we divide the task of sentiment-
oriented relation extraction into two subtasks : i)
identifying the most likely MRGs; ii) assigning
proper textual evidences to each edge of MRGs to
support their relation assertions. It is desirable to
carry out the two subtasks jointly as these two sub-
tasks could enhance each other. First, the identifi-
cation of relation types requires proper textual ev-
idences; second, the soft and hard constraints im-
posed by the correlated relation instances facilitate
the recognition of the corresponding textual evi-
dences. Since the eMRGs are created by attaching
every MRG with a set of textual evidences, tackling
the two subtasks simultaneously is equivalent to se-
lecting the most likely eMRG from a set of eMRG
candidates. It is challenging because our SRG corpus
does not contain any annotation of textual evidences.
Formally, let X denote the set of all available sen-
tences, and we define y ∈ Y(x)(x ∈ X) as the set
of labeled edges of an MRG and Y = ∪xEXY(x).
Since the assignments of textual evidences are not
observed, an assignment of evidences to y is de-
noted by a latent variable h ∈ H(x) and H =
∪xEXH(x). Then (y, h) corresponds to an eMRG,
and (a, c) ∈ (y, h) is a labeled edge a attached
with a textual evidence c. Given a labeled dataset
D = {(x1, y1), ..., (xn, yn)} ∈ (X × Y)n, we aim
to learn a discriminant function f : X → Y ×H that
outputs the optimal eMRG (y, h) ∈ Y(x)×H(x) for
a given sentence x.
Due to the introduction of latent variables, we
adopt the latent structural SVM (Yu and Joachims,
2009) for structural classification. Our discriminant
function is defined as
</bodyText>
<equation confidence="0.99577">
f(x) = argmax(y,h)EY(x)XW(x)βTΦ(x, y, h) (1)
</equation>
<bodyText confidence="0.999911285714286">
where Φ(x, y, h) is the feature function of an eMRG
(y, h) and β is the corresponding weight vector.
To ensure tractability, we also employ edge-based
factorization for our model. Let Mp denote a set of
entity mentions and yr(mi) be a set of edges labeled
with sentiment-oriented relations incident to mi, the
factorization of Φ(x, y, h) is given as
</bodyText>
<equation confidence="0.9967115">
Φ(x, y, h) = � Φe(x, a, c) + (2)
(a,c)E(y,h)
Φc(a, a&apos;)
a,a1Eyr(mi),a#a1
</equation>
<bodyText confidence="0.9999512">
where Φe(x, a, c) is a local edge feature function
for a labeled edge a attached with a textual evidence
c and Φc(a, a&apos;) is a feature function capturing co-
occurrence of two labeled edges ami and a&apos;mi inci-
dent to an entity mention mi.
</bodyText>
<sectionHeader confidence="0.983978" genericHeader="method">
5 Feature Space
</sectionHeader>
<bodyText confidence="0.999852451612903">
The following features are used in the feature func-
tions (Equation 2):
Unigrams: As mentioned before, a textual evi-
dence attached to an edge in MRG is either a word,
phrase or sentence. We consider all lemmatized un-
igrams in the textual evidence as unigram features.
Context: Since web users usually express related
sentiments about the same entity across sentence
boundaries, we describe the sentiment flow using a
set of contextual binary features. For example, if en-
tity A is mentioned in both the previous sentence and
the current sentence, a set of contextual binary fea-
tures are used to indicate all possible combinations
of the current and the previous mentioned sentiment-
oriented relations regarding to entity A.
Co-occurrence: We have mentioned the co-
occurrence feature in Equation 2, indicated by
Φc(a, a&apos;). It captures the co-occurrence of two la-
beled edges incident to the same entity mention.
Note that the co-occurrence feature function is con-
sidered only if there is a contrast conjunction such as
“but” between the non-shared entity mentions inci-
dent to the two labeled edges.
Senti-predictors: Following the idea of (Qu et
al., 2012), we encode the prediction results from
the rule-based phrase-level multi-relation predic-
tor (Ding et al., 2009) and from the bag-of-opinions
predictor (Qu et al., 2010) as features based on the
textual evidence. The output of the first predictor
is an integer value, while the output of the second
predictor is a sentiment relation, such as “positive”,
</bodyText>
<figure confidence="0.51808">
E
miEMp
</figure>
<page confidence="0.984841">
159
</page>
<bodyText confidence="0.999888555555556">
“negative”, “better” or “worse”. We map the rela-
tional outputs into integer values and then encode
the outputs from both predictors as senti-predictor
features.
Others: The commonly used part-of-speech tags
are also included as features. Moreover, for an edge
candidate, a set of binary features are used to denote
the types of the edge and its entity mentions. For in-
stance, a binary feature indicates whether an edge is
a binary edge related to an entity mentioned in con-
text. To characterize the syntactic dependencies be-
tween two adjacent entity mentions, we use the path
in the dependency tree between the heads of the cor-
responding constituents, the number of words and
other mentions in-between as features. Additionally,
if the textual evidence is a constituent, its feature
w.r.t. an edge is the dependency path to the clos-
est mention of the edge that does not overlap with
this constituent.
tion. For a binary edge connecting two entity men-
tions, we consider type I candidates starting from
both mentions. Moreover, for a comparative ternary
edge, we consider both type I and type II candidates
starting from the attribute mention. This strategy is
based on our observation that these candidates of-
ten cover the most important information w.r.t. the
covered entity mentions.
</bodyText>
<subsectionHeader confidence="0.988596">
6.2 ILP Formulation
</subsectionHeader>
<bodyText confidence="0.93874">
We formulate the inference problem of finding the
best eMRG as an ILP problem due to its convenient
integration of both soft and hard constraints.
Given the model parameters ,3, we reformulate
the score of an eMRG in the discriminant function
(1) as follows,
</bodyText>
<equation confidence="0.99222825">
,3TΦ(x, y, h) = � saczac +
(a,c)E(y,h)
6 Structural Inference � � saa0zaa0
miEMp a,a0Eyr(mi),a=,4a0
</equation>
<bodyText confidence="0.999908">
In order to find the best eMRG for a given sentence
with a well trained model, we need to determine
the most likely relation type for each relation candi-
date and support the corresponding assertions with
proper textual evidences. We formulate this task
as an Integer Linear Programming (ILP). Instead of
considering all constituents of a sentence, we empir-
ically select a subset as textual evidences for each
relation candidate.
</bodyText>
<subsectionHeader confidence="0.996318">
6.1 Textual Evidence Candidates Selection
</subsectionHeader>
<bodyText confidence="0.999954833333333">
Textual evidences are selected based on the con-
stituent trees of sentences parsed by the Stanford
parser (Klein and Manning, 2003). For each men-
tion in a sentence, we first locate a constituent in
the tree with the maximal overlap by Jaccard sim-
ilarity. Starting from this constituent, we consider
two types of candidates: type I candidates are con-
stituents at the highest level which contain neither
any word of another mention nor any contrast con-
junctions such as “but”; type II candidates are con-
stituents at the highest level which cover exactly two
mentions of an edge and do not overlap with any
other mentions. For a binary edge connecting an en-
tity mention and an attribute mention, we consider
a type I candidate starting from the attribute men-
where sac = ,3TΦe(x, a, c) denotes the score of a
labeled edge a attached with a textual evidence c,
saa0 = ,3TΦc(a, a&apos;) is the edge co-occurrence score,
the binary variable zac indicates the presence or ab-
sence of the corresponding edge, and zaa0 indicates
if two edges co-occurr. As not every edge set can
form an eMRG, we require that a valid eMRG should
satisfy a set of linear constraints, which form our
constraint space. Then function (1) is equivalent to
</bodyText>
<equation confidence="0.913750333333333">
max sTz + µzd
z∈B
z, 77, T E B
</equation>
<bodyText confidence="0.998198666666667">
where B = 2S with S = {0, 1}, and 77 and T are
auxiliary binary variables that help define the con-
straint space. The above optimization problem takes
exactly the form of an ILP because both the con-
straints and the objective function are linear, and all
variables take only integer values.
In the following, we consider two types of con-
straint space, 1) an eMRG with only binary edges and
2) an eMRG with both binary and ternary edges.
</bodyText>
<figure confidence="0.926732857142857">
⎡
s.t. A ⎣
⎤
⎦≤ d
z
77
T
</figure>
<page confidence="0.960382">
160
</page>
<bodyText confidence="0.9973496">
eMRG with only Binary Edges: An eMRG has
only binary edges if a sentence contains no attribute
mention or at most one entity mention. We expect
that each edge has only one relation type and is sup-
ported by a single textual evidence. To facilitate the
formulation of constraints, we introduce ηel to de-
note the presence or absence of a labeled edge el,
and ηec to indicate if a textual evidence c is assigned
to an unlabeled edge e. Then the binary variable for
the corresponding evidentiary edge zelc = ηec n ηel,
where the ILP formulation of conjunction can be
found in (Martins et al., 2009).
Let Ce denote the set of textual evidence candi-
dates of an unlabeled edge e. The constraint of at
most one textual evidence per edge is formulated as:
</bodyText>
<equation confidence="0.9244915">
X ηec G 1 (3)
c∈Ce
</equation>
<bodyText confidence="0.9997872">
Once a textual evidence is assigned to an edge,
their relation labels should match and the number
of labeled edges must agree with the number of at-
tached textual evidences. Further, we assume that a
textual evidence c conveys at most one relation so
that an evidence will not be assigned to the relations
of different types, which is the main problem for the
structural SVM based model. Let ηcl indicate that
the textual evidence c is labeled by the relation type
l. The corresponding constraints are expressed as,
</bodyText>
<equation confidence="0.8517385">
X Xηel = Xηec; zelc G ηcl; ηcl G 1
l∈Le c∈Ce l∈L
</equation>
<bodyText confidence="0.997199076923077">
where Le denotes the set of all possible labels for
an unlabeled edge e, and L is the set of all relation
types of MRGs (cf. Section 3).
In order to avoid a textual evidence being overly
reused by multiple relation candidates, we first pe-
nalize the assignment of a textual evidence c to a
labeled edge a by associating the corresponding zac
with a fixed negative cost −µ in the objective func-
tion. Then the selection of one textual evidence per
edge a is encouraged by associating µ to zd c in the
objective function, where zd c = We∈Sc ηec and Sc is
the set of edges that the textual evidence c serves as
a candidate. The disjunction zdc is expressed as:
</bodyText>
<figure confidence="0.8777386">
zdc &gt; ηe, e E Sc
Xzdc G ηe
e∈Sc
(a) Binary edge structure
(b) Ternary edge structure
</figure>
<figureCaption confidence="0.9960095">
Figure 4: Alternative structures associated with an
attribute mention.
</figureCaption>
<bodyText confidence="0.998703714285714">
This soft constraint not only encourages one textual
evidence per edge, but also keeps it eligible for mul-
tiple assignments.
For any two labeled edge a and a0 incident
to the same entity mention, the edge-to-edge co-
occurrence is described by zca,a, = za n zap.
eMRG with both Binary and Ternary Edges: If
there are more than one entity mentions and at least
one attribute mention in a sentence, an eMRG can
potentially have both binary and ternary edges. In
this case, we assume that each mention of attributes
can participate either in binary relations or in ternary
relations. The assumption holds in more than 99.9%
of the sentences in our SRG corpus, thus we describe
it as a set of hard constraints. Geometrically, the as-
sumption can be visualized as the selection between
two alternative structures incident to the same at-
tribute mention, as shown in Figure 4. Note that,
in the binary edge structure, we include not only the
edges incident to the attribute mention but also the
edge between the two entity mentions.
</bodyText>
<subsectionHeader confidence="0.832485">
Let Sb
</subsectionHeader>
<bodyText confidence="0.999987111111111">
mi be the set of all possible labeled edges
in a binary edge structure of an attribute mention
mi. Variable τbmi = W el∈Sb mi ηel indicates whether
the attribute mention is associated with a binary
edge structure or not. In the same manner, we use
τtmi = Wel∈St mi ηel to indicate the association of the
an attribute mention mi with an ternary edge struc-
ture from the set of all incident ternary edges Stmi.
The selection between two alternative structures is
</bodyText>
<page confidence="0.996567">
161
</page>
<bodyText confidence="0.998178">
formulated as τbma + τtma = 1. As this influences
only the edges incident to an attribute mention, we
keep all the constraints introduced in the previous
section unchanged except for constraint (3), which
is modified as
</bodyText>
<equation confidence="0.9733375">
X ηec &lt; τbma;
cECe
</equation>
<bodyText confidence="0.999447">
Therefore, we can have either binary edges or
ternary edges for an attribute mention.
</bodyText>
<sectionHeader confidence="0.989857" genericHeader="method">
7 Learning Model Parameters
</sectionHeader>
<bodyText confidence="0.999701">
Given a set of training sentences D =
{(x1, y1), ... , (xn, yn)}, the best weight vec-
tor β of the discriminant function (1) is found by
solving the following optimization problem:
</bodyText>
<equation confidence="0.999158">
[ ^. max (β&gt;Φ(x,ˆy,ˆh)+δ(ˆh,ˆy,y))
(P,h)∈Y(x) ×H(x)
− max
¯h∈H(x) β&gt;Φ(x, y, ¯h)] + ρ|β|] (4)
</equation>
<bodyText confidence="0.999935307692308">
where δ(ˆh, ˆy, y) is a loss function measuring the dis-
crepancies between an eMRG (y, ¯h) with gold stan-
dard edge labels y and an eMRG (ˆy, ˆh) with inferred
labeled edges yˆ and textual evidences ˆh. Due to the
sparse nature of the lexical features, we apply L1
regularizer to the weight vector β, and the degree of
sparsity is controlled by the hyperparameter ρ.
Since the L1 norm in the above optimization
problem is not differentiable at zero, we apply the
online forward-backward splitting (FOBOS) algo-
rithm (Duchi and Singer, 2009). It requires two steps
for updating the weight vector β by using a single
training sentence x on each iteration t.
</bodyText>
<equation confidence="0.9983215">
βt+ 12 = βt − εtΔt
βt+1 = arg min
β 211β − βt112 + εtρ|β|
1
</equation>
<bodyText confidence="0.99884488">
where Δt is the subgradient computed without con-
sidering the L1 norm and εt is the learning rate.
For a labeled sentence x, Δt = Φ(x, ˆy*, ˆh*) −
Φ(x, y, h*), where the feature functions of the corre-
sponding eMRGs are inferred by solving (ˆy*, ˆh*) =
arg max(ˆh,ˆy)E?i(x)xY(x)[βTΦ(x, ˆy, ˆh) + δ(ˆh, ˆy, y)]
and (y, ¯h*) = arg max¯hE?i(x) βTΦ(x, y, ¯h), as in-
dicated in the optimization problem (4).
The former inference problem is similar to the
one we considered in the previous section except
the inclusion of the loss function. We incorporate
the loss function into the ILP formulation by defin-
ing the loss between an MRG (y, h) and a gold stan-
dard MRG as the sum of per-edge costs. In our ex-
periments, we consider a positive cost ϕ for each
wrongly labeled edge a, so that if an edge a has a
different label from the gold standard, we add ϕ to
the coefficient sac of the corresponding variable zac
in the objective function of the ILP formulation.
In addition, since the non-positive weights of edge
labels in the initial learning phrase often lead to
eMRGs with many unlabeled edges, which harms the
learning performance, we fix it by adding a con-
straint for the minimal number of labeled edges in
an eMRG,
</bodyText>
<equation confidence="0.966226">
ηac &gt;_ ζ (5)
</equation>
<bodyText confidence="0.999977375">
where A is the set of all labeled edge candidates and
ζ denotes the minimal number of labeled edges.
Empirically, the best way to determine ζ is to
make it equal to the maximal number of labeled
edges in an eMRG with the restriction that a tex-
tual evidence can be assigned to at most one edge.
By considering all the edge candidates A and all the
textual evidence candidates C as two vertex sets in a
bipartite graph Gˆ = (V = (A, C), E) (with edges in
E indicating which textual evidence can be assigned
to which edge), ζ corresponds to exactly the size of
a maximum matching of the bipartite graph1.
To find the optimal eMRG (y, ¯h*), for the gold la-
bel k of each edge, we consider the following set of
constraints for inference since the labels of the edges
are known for the training data,
</bodyText>
<equation confidence="0.995089">
X ηec &lt; 1; ηec &lt; lck
cECe
X
k&apos;EL
</equation>
<bodyText confidence="0.9999668">
We include also the soft constraints, which avoid
a textual evidence being overly reused by multiple
relations, and the constraints similar to (5) to ensure
a minimal number of labeled edges and a minimal
number of sentiment-oriented relations.
</bodyText>
<footnote confidence="0.9861235">
1It is computed by the Hopcroft-Karp algorithm (Hopcroft
and Karp, 1973) in our implementation.
</footnote>
<equation confidence="0.987275444444444">
X
cECe
t
ηec &lt; τma
1
n
min
β
Xn
i=1
X
a∈A
X
c∈Ca
X
eESc
lck&apos; &lt; 1;
ηec &lt; 1
</equation>
<page confidence="0.99749">
162
</page>
<sectionHeader confidence="0.987034" genericHeader="method">
8 SRG Corpus
</sectionHeader>
<bodyText confidence="0.99982028">
For evaluation we constructed the SRG corpus,
which in total consists of 1686 manually annotated
online reviews and forum posts in the digital camera
and movie domains2. For each domain, we maintain
a set of attributes and a list of entity names.
The annotation scheme for the sentiment repre-
sentation asserts minimal linguistic knowledge from
our annotators. By focusing on the meanings of the
sentences, the annotators make decisions based on
their language intuition, not restricted by specific
syntactic structures. Taking the example in Figure
2, the annotators only need to mark the mentions of
entities and attributes from both the sentences and
the context, disambiguate them, and label (“Canon
7D”, “Nikon D7000”, price) as worse and (“Canon
7D”, “sensor”) as positive, whereas in prior work,
people have annotated the sentiment-bearing expres-
sions such as “great” and link them to the respective
relation instances as well. This also enables them
to annotate instances of both sentiment polarity and
comparative relaton, which are conveyed by not only
explicit sentiment-bearing expressions like “excel-
lent performance”, but also factual expressions im-
plying evaluations such as “The 7V has 10x optical
zoom and the 9V has 16x.”.
</bodyText>
<table confidence="0.9982798">
Camera Movie
Reviews Forums Reviews Forums
positive 386 1539 879 905
negative 165 363 529 331
comparison 30 480 39 35
</table>
<tableCaption confidence="0.999656">
Table 1: Distribution of relation instances in SRG corpus.
</tableCaption>
<bodyText confidence="0.961140966666667">
14 annotators participated in the annotation
project. After a short training period, annotators
worked on randomly assigned documents one at a
time. For product reviews, the system lists all rel-
evant information about the entity and the prede-
fined attributes. For forum posts, the system shows
only the attribute list. For each sentence in a doc-
ument, the annotator first determines if it refers to
an entity of interest. If not, the sentence is marked
2The 107 camera reviews are from bestbuy.com and Ama-
zon.com; the 667 camera forum posts are downloaded from fo-
rum.digitalcamerareview.com; the 138 movie reviews and 774
forum posts are from imdb.com and boards.ie respectively
as off-topic. Otherwise, the annotator will identify
the most obvious mentions, disambiguate them, and
mark the MRGs. We evaluate the inter-annotator
agreement on sSoRs in terms of Cohen’s Kappa
(κ) (Cohen, 1968). An average Kappa value of 0.698
was achieved on a randomly selected set consisting
of 412 sentences.
Table 1 shows the corpus distribution after nor-
malizing them into sSoRs. Camera forum posts con-
tain the largest proportion of comparisons because
they are mainly about the recommendation of dig-
ital cameras. In contrast, web users are much less
interested in comparing movies, in both reviews and
forums. In all subsets, positive relations play a dom-
inant role since web users intend to express more
positive attitudes online than negative ones (Pang
and Lee, 2007).
</bodyText>
<sectionHeader confidence="0.995254" genericHeader="evaluation">
9 Experiments
</sectionHeader>
<bodyText confidence="0.999731333333333">
This section describes the empirical evaluation of
SENTI-LSSVM together with two competitive base-
lines on the SRG corpus.
</bodyText>
<subsectionHeader confidence="0.990209">
9.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999974">
We implemented a rule-based baseline (DING-
RULE) and a structural SVM (Tsochantaridis et
al., 2004) baseline (SENTI-SSVM) for comparison.
The former system extends the work of Ding et
al. (2009), which designed several linguistically-
motivated rules based on a sentiment polarity lexi-
con for relation identification and assumes there is
only one type of sentiment relation in a sentence. In
our implementation, we keep all the rules of (Ding et
al., 2009) and add one phrase-level rule when there
are more than one mention in a sentence. The ad-
ditional rule assigns sentiment-bearing words and
negators to its nearest relation candidates based on
the absolute surface distance between the words and
the corresponding mentions. In this case, the phrase-
level sentiment-oriented relations depend only on
the assigned sentiment words and negators. The lat-
ter system is based on a structural SVM and does
not consider the assignment of textual evidences to
relation instances during inference. The textual fea-
tures of a relation candidate are all lexical and sen-
timent predictor features within a surface distance
of four words from the mentions of the candidate.
</bodyText>
<page confidence="0.997824">
163
</page>
<bodyText confidence="0.99997492">
Thus, this baseline does not need the inference con-
straints of SENTI-LSSVM for the selection of textual
evidences. To gain more insights into the model,
we also evaluate the contribution of individual fea-
tures of SENTI-LSSVM. In addition, to show if identi-
fying sentiment polarities and comparative relations
jointly works better than tackling each task on its
own, we train SENTI-LSSVM for each task separately
and combine their predictions according to compat-
ibility rules and the corresponding graph scores.
For each domain and text genre, we withheld 15%
documents for development and use the remaining
for cross validation. The hyperparameters of all sys-
tems are tuned on the development datasets. For all
experiments of SENTI-LSSVM, we use p = 0.0001
for the L1 regularizer in Eq.(4) and co = 0.05 for
the loss function; and for SENTI-SSVM, p = 0.0001
and co = 0.01. Since the relation type of off-topic
sentences is certainly other, we evaluate all systems
with 5-fold cross-validation only on the on-topic
sentences in the evaluation dataset. Since the same
sSoR can have several equivalent MRGs and the rela-
tion type other is not of our interest, we evaluate the
sSoRs in terms of precision, recall and F-measure.
All reported numbers are averages over the 5 folds.
</bodyText>
<subsectionHeader confidence="0.87017">
9.2 Results
</subsectionHeader>
<bodyText confidence="0.999916289855073">
Table 2 shows the complete results of all sys-
tems. Here our model SENTI-LSSVM outperformed
all baselines in terms of the average F-measure
scores and recalls by a large margin. The F-measure
on movie reviews is about 14% over the best base-
line. The rule-based system has higher precision
than recall in most cases. However, simply increas-
ing the coverage of the domain independent senti-
ment polarity lexicon might lead to worse perfor-
mance (Taboada et al., 2011) because many sen-
timent oriented relations are conveyed by domain
dependent expressions and factual expressions im-
plying evaluations, such as “This camera does not
have manual control.” Compared to DING-RULE,
SENTI-SSVM performs better in the camera domain
but worse for the movies due to many misclassi-
fication of negative relation instances as other. It
also wrongly predicted more positive instances as
other than SENTI-LSSVM. We found that the recalls
of these instances are low because they often have
overly similar features with the instances of the type
other linking to the same mentions. The problem
gets worse in the movie domain since i) many sen-
tences contain no explicit sentiment-bearing words;
ii) the prior polarity of the sentiment-bearing words
do not agree with their contextual polarity in the
sentences. Consider the following example from a
forum post about the movie “Superman Returns”:
“Have a look at Superman: the Animated Series or
Justice League Unlimited ... that is how the char-
acters of Superman and Lex Luthor should be.”. In
contrast, our model minimizes the overlapping fea-
tures by assigning them to the most likely relation
candidates. This leads to significantly better per-
formance. Although SENTI-SSVM has low recall for
both positive and negative relations, it achieves the
highest recall for the comparative relation among all
systems in the movie domain and camera reviews.
Since less than 1% of all instances are for compara-
tive relations in these document sets and all models
are trained to optimize the overall accuracy, SENTI-
LSSVM intends to trade off the minority class for the
overall better performance. This advantage disap-
pears on the camera forum posts, where the number
of instances of comparative relation is 12 times more
than that in the other data sets.
All systems perform better in predicting positive
relations than the negative ones. This corresponds
well to the empirical findings in (Wilson, 2008) that
people intend to use more complex expressions for
negative sentiments than their affirmative counter-
parts. It is also in accordance with the distribution of
these relations in our SRG corpus which is randomly
sampled from the online documents. For learning
systems, it can also be explained by the fact that the
training data for positive relations are considerably
more than those for negative ones. The comparative
relation is the hardest one to process since we found
that many corresponding expressions do not contain
explicit keywords for comparison.
To understand the performance of the key fea-
ture groups in our model better, we remove each
group from the full SENTI-LSSVM system and eval-
uate the variations with movie reviews and camera
forum posts, which have relatively balanced distri-
bution of relation types. As shown in Table 3, the
features from the sentiment predictors make signif-
icant contributions for both datasets. The differ-
ent drops of the performance indicate that the po-
</bodyText>
<page confidence="0.993412">
164
</page>
<table confidence="0.99997255">
P Positive F P Negative F Comparison Micro-average
R R P R F P R F
Camera DING-RULE 56.4 39.0 46.1 46.2 24.0 31.6 42.6 14.0 21.0 53.4 30.8 39.0
Forum
SENTI-SSVM 60.2 35.6 44.8 44.2 38.5 41.2 28.0 40.1 32.9 43.7 36.7 39.9
SENTI-LSSVM 69.2 38.9 49.8 50.8 39.3 44.3 42.6 35.1 38.5 56.5 38.0 45.4
Camera DING-RULE 83.6 69.0 75.6 68.6 38.8 49.6 30.0 16.9 21.6 81.1 58.6 68.1
Movie
Re-
Forum view
SENTI-SSVM 72.6 75.4 74.0 63.9 62.5 63.2 28.0 38.9 32.5 68.1 70.4 69.3
SENTI-LSSVM 77.3 85.4 81.2 68.9 61.3 64.9 22.3 20.7 21.6 73.1 73.4 73.7
DING-RULE 63.7 37.4 47.1 27.6 34.3 30.6 8.9 5.6 6.8 48.2 35.9 41.2
SENTI-SSVM 66.2 30.1 41.3 25.6 17.3 20.7 44.2 56.7 49.7 53.3 27.9 36.6
SENTI-LSSVM 63.3 44.2 52.1 29.7 45.6 36.0 40.1 45.0 42.4 49.7 44.6 47.0
Movie DING-RULE 66.5 47.2 55.2 42.0 39.1 40.5 31.4 12.0 17.4 56.2 44.0 49.4
Re-
view
SENTI-SSVM 61.3 54.0 57.4 45.2 13.7 21.1 24.5 63.3 35.3 54.6 39.2 45.7
SENTI-LSSVM 59.0 79.1 67.6 53.3 51.4 52.3 28.3 34.0 30.9 57.9 68.8 62.9
</table>
<tableCaption confidence="0.995498">
Table 2: Evaluation results for DING-RULE, SENTI-SSVM and SENTI-LSSVM. Boldface figures are statistically
significantly better than all others in the same comparison group under t-test with p = 0.05.
</tableCaption>
<table confidence="0.999659333333333">
Feature Models Movie Reviews Camera Forums
full system 62.9 45.4
¬unigram 63.2 (+0.3) 41.2 (-4.2)
¬context 54.5 (-8.4) 46.0 (+0.6)
¬co-occurrence 62.6 (-0.3) 44.9 (-0.5)
¬senti-predictors 61.3 (-1.6) 34.3 (-11.1)
</table>
<tableCaption confidence="0.883363">
Table 3: Micro-average F-measure of SENTI-LSSVM
with different feature models
</tableCaption>
<bodyText confidence="0.99995478125">
larities predicted by rules are more consistent in
camera forum posts than in movie reviews. Due
to the complexity of expressions in the movie re-
views our model cannot benefit from the unigram
features but these features are a good compensation
for the sentiment predictor features in camera fo-
rum posts. The sharp drop by removing the context
features from our model on movie reviews indicates
that the sentiments in movie reviews depend highly
on the relations of the previous sentences. In con-
trast, the sentiment-oriented relations of the previ-
ous sentences could be a reason of overfitting for
camera forum data. The edge co-occurrence fea-
tures do not play an important role in our model
since the number of co-occurred sentiment-oriented
relations in the sentences with contrast conjunctions
like “but” is small. However, we found that allow-
ing the co-occurrence of any sentiment-oriented re-
lations would harm the performance of the model.
In addition, our experiments showed that the sep-
arated approach, which trains a model for senti-
ment polarities and comparative relations respec-
tively, leads to a decrease by almost 1% in terms of
the F-measure averaged over all four datasets. The
largest drop of F-measure is 3% on camera forum
posts, since this dataset contains the largest propor-
tion of comparative relations. We found that the er-
rors are increased when the trained models make
conflicting predictions. In this case, the joint ap-
proach can take all factors into account and make
more consistent decisions than the separated ap-
proaches.
</bodyText>
<sectionHeader confidence="0.993182" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.999931222222222">
We proposed SENTI-LSSVM model for extracting in-
stances of both sentiment polarities and comparative
relations. For evaluating and training the model, we
created an SRG corpus by using a lightweight an-
notation scheme. We showed that our model can
automatically find textual evidences to support its
relation predictions and achieves significantly bet-
ter F-measure scores than alternative state-of-the-art
methods.
</bodyText>
<sectionHeader confidence="0.998047" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9314635">
Yejin Choi and Claire Cardie. 2009. Adapting a polarity
lexicon using integer linear programming for domain-
specific sentiment classification. In Proceedings of
the 2009 Conference on Empirical Methods in Natural
</reference>
<page confidence="0.994837">
165
</page>
<reference confidence="0.996483490566038">
Language Processing: Volume 2 - Volume 2, EMNLP
’09, pages 590–598, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Yejin Choi and Claire Cardie. 2010. Hierarchical se-
quential learning for extracting opinions and their at-
tributes. In Proceedings of the Annual meeting of
the Association for Computational Linguistics, pages
269–274. Association for Computational Linguistics.
Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint
extraction of entities and relations for opinion recog-
nition. In Proceedings of the Conference on Empirical
Methods in Natural Language Processing, pages 431–
439, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Jacob Cohen. 1968. Weighted Kappa: Nominal Scale
Agreement Provision for Scaled Disagreement or Par-
tial Credit. Psychological bulletin, 70(4):213.
Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A
holistic lexicon-based approach to opinion mining. In
Proceedings of the 2008 International Conference on
Web Search and Data Mining, pages 231–240, New
York, NY, USA. ACM.
Xiaowen Ding, Bing Liu, and Lei Zhang. 2009. Entity
discovery and assignment for opinion mining applica-
tions. In Proceedings of the ACM SIGKDD Confer-
ence on Knowledge Discovery and Data Mining, pages
1125–1134.
John Duchi and Yoram Singer. 2009. Efficient online
and batch learning using forward backward splitting.
The Journal of Machine Learning Research, 10:2899–
2934.
Murthy Ganapathibhotla and Bing Liu. 2008. Mining
opinions in comparative sentences. In Proceedings of
the 22nd International Conference on Computational
Linguistics - Volume 1, pages 241–248, Stroudsburg,
PA, USA. Association for Computational Linguistics.
Namrata Godbole, Manjunath Srinivasaiah, and Steven
Skiena. 2007. Large-scale sentiment analysis for
news and blogs (system demonstration). In Proceed-
ings of the International AAAI Conference on Weblogs
and Social Media.
John E Hopcroft and Richard M Karp. 1973. An nˆ5/2
algorithm for maximum matchings in bipartite graphs.
SIAM Journal on computing, 2(4):225–231.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD international conference on Knowl-
edge discovery and data mining, Proceedings of the
ACM SIGKDD Conference on Knowledge Discov-
ery and Data Mining, pages 168–177, New York, NY,
USA. ACM.
Wei Jin, Hung Hay Ho, and Rohini K. Srihari. 2009.
Opinionminer: a novel machine learning system for
web opinion mining and extraction. In Proceedings
of the 15th ACM SIGKDD international conference on
Knowledge discovery and data mining, pages 1195–
1204, New York, NY, USA. ACM.
Nitin Jindal and Bing Liu. 2006. Mining comparative
sentences and relations. In Proceedings of the 21st In-
ternational Conference on Artificial Intelligence - Vol-
ume 2, AAAI’06, pages 1331–1336. AAAI Press.
Richard Johansson and Alessandro Moschitti. 2011.
Extracting opinion expressions and their polarities–
exploration of pipelines and joint models. In Proceed-
ings of the Annual meeting of the Association for Com-
putational Linguistics, volume 11, pages 101–106.
Jason S. Kessler, Miriam Eckert, Lyndsie Clark, and
Nicolas Nicolov. 2010. The 2010 icwsm jdpa sent-
ment corpus for the automotive domain. In 4th Inter-
national AAAI Conference on Weblogs and Social Me-
dia Data Workshop Challenge (ICWSM-DWC 2010).
Soo-Min Kim and Eduard Hovy. 2006. Extracting opin-
ions, opinion holders, and topics expressed in online
news media text. In Proceedings of the Workshop on
Sentiment and Subjectivity in Text, SST ’06, pages 1–8,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Dan Klein and Christopher D. Manning. 2003. Accurate
unlexicalized parsing. In Proceedings of the 41st An-
nual Meeting on Association for Computational Lin-
guistics - Volume 1, ACL ’03, pages 423–430, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen. 2006.
Opinion extraction, summarization and tracking in
news and blog corpora. In AAAI Spring Sympo-
sium: Computational Approaches to Analyzing We-
blogs, pages 100–107.
Bing Liu, Minqing Hu, and Junsheng Cheng. 2005.
Opinion observer: analyzing and comparing opinions
on the web. In Proceedings of the 14th international
conference on World Wide Web, pages 342–351, New
York, NY, USA. ACM.
André L. Martins, Noah A. Smith, and Eric P. Xing.
2009. Concise integer linear programming formula-
tions for dependency parsing. In Proceedings of the
Annual meeting of the Association for Computational
Linguistics, pages 342–350.
Ryan T. McDonald, Kerry Hannan, Tyler Neylon, Mike
Wells, and Jeffrey C. Reynar. 2007. Structured mod-
els for fine-to-coarse sentiment analysis. In Proceed-
ings of the Annual meeting of the Association for Com-
putational Linguistics.
Bo Pang and Lillian Lee. 2007. Opinion mining and
sentiment analysis. Foundations and Trends in Infor-
mation Retrieval, 2(1-2):1–135.
</reference>
<page confidence="0.98536">
166
</page>
<reference confidence="0.999772170212766">
Ana-Maria Popescu and Oren Etzioni. 2005. Extract-
ing product features and opinions from reviews. In
Proceedings of the conference on Human Language
Technology and Empirical Methods in Natural Lan-
guage Processing, HLT ’05, pages 339–346, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Lizhen Qu, Georgiana Ifrim, and Gerhard Weikum.
2010. The bag-of-opinions method for review rat-
ing prediction from sparse text patterns. In Chu-Ren
Huang and Dan Jurafsky, editors, Proceedings of the
23rd International Conference on Computational Lin-
guistics (Coling 2010), ACL Anthology, pages 913–
921, Beijing, China. Tsinghua University Press.
Lizhen Qu, Rainer Gemulla, and Gerhard Weikum. 2012.
A weakly supervised model for sentence-level seman-
tic orientation analysis with multiple experts. In Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning (EMNLP-CoNLL), pages 149–159,
Jeju Island, Korea, July. Proceedings of the Annual
meeting of the Association for Computational Linguis-
tics.
Richard Socher, Brody Huval, Christopher D. Manning,
and Andrew Y. Ng. 2012. Semantic compositionality
through recursive matrix-vector spaces. In Proceed-
ings of the Conference on Empirical Methods in Natu-
ral Language Processing, pages 1201–1211.
Swapna Somasundaran and Janyce Wiebe. 2009. Rec-
ognizing stances in online debates. In Proceedings of
the Joint conference of the 47th Annual Meeting of the
Association for Computational Linguistics and the 4th
International Joint Conference on Natural Language
Processing of the Asian Federation of Natural Lan-
guage Processing, pages 226–234.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly D. Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computational
Linguistics, 37(2):267–307.
Oscar Täckström and Ryan McDonald. 2011. Discov-
ering fine-grained sentiment with latent variable struc-
tured prediction models. In Proceedings of the 33rd
European conference on Advances in information re-
trieval, ECIR’11, pages 368–374, Berlin, Heidelberg.
Springer-Verlag.
Cigdem Toprak, Niklas Jakob, and Iryna Gurevych.
2010. Sentence and expression level annotation of
opinions in user-generated discourse. In Proceedings
of the 48th Annual Meeting of the Association for
Computational Linguistics, ACL ’10, pages 575–584,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
Ioannis Tsochantaridis, Thomas Hofmann, Thorsten
Joachims, and Yasemin Altun. 2004. Support vec-
tor machine learning for interdependent and structured
output spaces. In Proceedings of the International
Conference on Machine Learning, pages 104–112.
Wei Wei and Jon Atle Gulla. 2010. Sentiment learn-
ing on product reviews via sentiment ontology tree. In
Proceedings of the Annual meeting of the Association
for Computational Linguistics, pages 404–413.
Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005.
Annotating expressions of opinions and emotions in
language. Language Resources and Evaluation, 39(2-
3):165–210.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-level
sentiment analysis. In Proceedings of the confer-
ence on Human Language Technology and Empirical
Methods in Natural Language Processing, HLT ’05,
pages 347–354, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Theresa Ann Wilson. 2008. Fine-grained subjectivity
and sentiment analysis: recognizing the intensity, po-
larity, and attitudes of private states. Ph.D. thesis,
UNIVERSITY OF PITTSBURGH.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu.
2011. Structural opinion mining for graph-based sen-
timent representation. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 1332–1341.
Ainur Yessenalina and Claire Cardie. 2011. Composi-
tional matrix-space models for sentiment analysis. In
Proceedings of the Conference on Empirical Methods
in Natural Language Processing, pages 172–182.
Chun-Nam John Yu and Thorsten Joachims. 2009.
Learning structural svms with latent variables. In Pro-
ceedings of the International Conference on Machine
Learning, page 147.
Ning Yu and Sandra Kübler. 2011. Filling the gap:
Semi-supervised learning for opinion detection across
domains. In Proceedings of the Fifteenth Conference
on Computational Natural Language Learning, pages
200–209. Association for Computational Linguistics.
</reference>
<page confidence="0.999202">
167
168
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.029647">
<title confidence="0.964982333333333">Senti-LSSVM: Sentiment-Oriented Multi-Relation with Latent Structural SVM Lizhen</title>
<author confidence="0.999296">Max Planck</author>
<email confidence="0.6874575">forlqu@mpi-inf.mpg.de</email>
<author confidence="0.65787">Lili Max Planck</author>
<email confidence="0.696732">forljiang@mpi-inf.mpg.de</email>
<author confidence="0.999176">Yi Zhang</author>
<affiliation confidence="0.950962">Nuance Communications</affiliation>
<email confidence="0.997837">yi.zhang@nuance.com</email>
<author confidence="0.9796325">Rainer Max Planck</author>
<email confidence="0.7485375">forrgemulla@mpi-inf.mpg.de</email>
<author confidence="0.978994">Rui</author>
<affiliation confidence="0.999667">DFKI GmbH</affiliation>
<email confidence="0.985593">mars198356@hotmail.com</email>
<author confidence="0.9170845">Gerhard Max Planck</author>
<email confidence="0.838089">forweikum@mpi-inf.mpg.de</email>
<abstract confidence="0.995790476190476">Extracting instances of sentiment-oriented relations from user-generated web documents is important for online marketing analysis. Unlike previous work, we formulate this extraction task as a structured prediction problem and design the corresponding inference as an integer linear program. Our latent structural SVM based model can learn from training corpora that do not contain explicit annotations of sentiment-bearing expressions, and it can simultaneously recognize instances of both binary (polarity) and ternary (comparative) relations with regard to entity mentions of interest. The empirical evaluation shows that our approach significantly outperforms stateof-the-art systems across domains (cameras and movies) and across genres (reviews and forum posts). The gold standard corpus that we built will also be a valuable resource for the community.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Adapting a polarity lexicon using integer linear programming for domainspecific sentiment classification.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2 - Volume 2, EMNLP ’09,</booktitle>
<pages>590--598</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8271" citStr="Choi and Cardie, 2009" startWordPosition="1230" endWordPosition="1233">lly motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall short of extracting comparative relations based on domain dependent information. Both Johansson and Moschitti (2011) and Wu et al. (2011) formulate fine-grained sentiment analysis as a learning problem with structured outputs. However, they focus only on polarity classification 156 of expressions and require annotation of sentimentbearing expressions for training as well. While ILP has been previously applied for inference in sentiment analysis (Choi and Cardie, 2009; Somasundaran and Wiebe, 2009; Wu et al., 2011), our task requires a complete ILP reformulation due to 1) the absence of annotated sentiment expressions and 2) the constraints imposed by the joint extraction of both sentiment polarity and comparative relations. 3 System Overview This section gives an overview of the whole system for extracting sentiment-oriented relation instances. Prior to presenting the system architecture, we introduce the essential concepts and the definitions of two kinds of directed hypergraphs as the representation of correlated relation instances extracted from senten</context>
</contexts>
<marker>Choi, Cardie, 2009</marker>
<rawString>Yejin Choi and Claire Cardie. 2009. Adapting a polarity lexicon using integer linear programming for domainspecific sentiment classification. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2 - Volume 2, EMNLP ’09, pages 590–598, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Hierarchical sequential learning for extracting opinions and their attributes.</title>
<date>2010</date>
<booktitle>In Proceedings of the Annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>269--274</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6675" citStr="Choi and Cardie, 2010" startWordPosition="994" endWordPosition="997">ts, showing that SENTI-LSSVM model can effectively learn from a training corpus without explicitly annotated subjective expressions and that its performance significantly outperforms state-of-the-art systems. 2 Related Work There are ample works on analyzing sentiment polarities and entity comparisons, but the majority of them studied the two tasks in isolation. Most prior approaches for fine-grained sentiment analysis focus on polarity classification. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al.</context>
</contexts>
<marker>Choi, Cardie, 2010</marker>
<rawString>Yejin Choi and Claire Cardie. 2010. Hierarchical sequential learning for extracting opinions and their attributes. In Proceedings of the Annual meeting of the Association for Computational Linguistics, pages 269–274. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Eric Breck</author>
<author>Claire Cardie</author>
</authors>
<title>Joint extraction of entities and relations for opinion recognition.</title>
<date>2006</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>431--439</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1405" citStr="Choi et al., 2006" startWordPosition="183" endWordPosition="186">VM based model can learn from training corpora that do not contain explicit annotations of sentiment-bearing expressions, and it can simultaneously recognize instances of both binary (polarity) and ternary (comparative) relations with regard to entity mentions of interest. The empirical evaluation shows that our approach significantly outperforms stateof-the-art systems across domains (cameras and movies) and across genres (reviews and forum posts). The gold standard corpus that we built will also be a valuable resource for the community. 1 Introduction Sentiment-oriented relation extraction (Choi et al., 2006) is concerned with recognizing sentiment polarities and comparative relations between entities from natural language text. Identifying such relations often requires syntactic and semantic analysis at both sentence and phrase level. Most prior work on sentiment analysis consider either i) subjective sentence detection (Yu and Kübler, 2011), ii) polarity classification (Johansson and Moschitti, 2011; Wilson et al., 2005), or iii) comparative relation identification (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). In practice, however, different types of sentiment-oriented relations frequen</context>
</contexts>
<marker>Choi, Breck, Cardie, 2006</marker>
<rawString>Yejin Choi, Eric Breck, and Claire Cardie. 2006. Joint extraction of entities and relations for opinion recognition. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 431– 439, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jacob Cohen</author>
</authors>
<title>Weighted Kappa: Nominal Scale Agreement Provision for Scaled Disagreement or Partial Credit. Psychological bulletin,</title>
<date>1968</date>
<pages>70--4</pages>
<contexts>
<context position="33377" citStr="Cohen, 1968" startWordPosition="5547" endWordPosition="5548">e system shows only the attribute list. For each sentence in a document, the annotator first determines if it refers to an entity of interest. If not, the sentence is marked 2The 107 camera reviews are from bestbuy.com and Amazon.com; the 667 camera forum posts are downloaded from forum.digitalcamerareview.com; the 138 movie reviews and 774 forum posts are from imdb.com and boards.ie respectively as off-topic. Otherwise, the annotator will identify the most obvious mentions, disambiguate them, and mark the MRGs. We evaluate the inter-annotator agreement on sSoRs in terms of Cohen’s Kappa (κ) (Cohen, 1968). An average Kappa value of 0.698 was achieved on a randomly selected set consisting of 412 sentences. Table 1 shows the corpus distribution after normalizing them into sSoRs. Camera forum posts contain the largest proportion of comparisons because they are mainly about the recommendation of digital cameras. In contrast, web users are much less interested in comparing movies, in both reviews and forums. In all subsets, positive relations play a dominant role since web users intend to express more positive attitudes online than negative ones (Pang and Lee, 2007). 9 Experiments This section desc</context>
</contexts>
<marker>Cohen, 1968</marker>
<rawString>Jacob Cohen. 1968. Weighted Kappa: Nominal Scale Agreement Provision for Scaled Disagreement or Partial Credit. Psychological bulletin, 70(4):213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Philip S Yu</author>
</authors>
<title>A holistic lexicon-based approach to opinion mining.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 International Conference on Web Search and Data Mining,</booktitle>
<pages>231--240</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7177" citStr="Ding et al., 2008" startWordPosition="1070" endWordPosition="1073">s require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefo</context>
</contexts>
<marker>Ding, Liu, Yu, 2008</marker>
<rawString>Xiaowen Ding, Bing Liu, and Philip S. Yu. 2008. A holistic lexicon-based approach to opinion mining. In Proceedings of the 2008 International Conference on Web Search and Data Mining, pages 231–240, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaowen Ding</author>
<author>Bing Liu</author>
<author>Lei Zhang</author>
</authors>
<title>Entity discovery and assignment for opinion mining applications.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>1125--1134</pages>
<contexts>
<context position="2972" citStr="Ding et al. (2009)" startWordPosition="423" endWordPosition="426">as estimating a relation candidate as both negative and comparative. Therefore, in this paper, we identify instances of both sentiment polarities and comparative relations for entities of interest simultaneously. We assume that all the mentions of entities and attributes are given, and entities are disambiguated. It is a widely used assumption when evaluating a module in a pipeline system that the outputs of preceding modules are error-free. To the best of our knowledge, the only existing system capable of extracting both comparisons and sentiment polarities is a rule-based system proposed by Ding et al. (2009). We argue that it is better to tackle the task by using a unified model with structured outputs. It allows us to consider a set of correlated relation instances jointly and characterize their interaction through a set of soft and hard constraints. For example, we can encode constraints to discourage an attribute to participate in a polarity relation and a comparative relation at the same time. As a result, the system extracts a set of correlated instances of sentiment-oriented relations from a given sentence. For example, with the sentence about the camera Canon 7D, “The sensor is great, but </context>
<context position="19509" citStr="Ding et al., 2009" startWordPosition="3111" endWordPosition="3114">nd the previous mentioned sentimentoriented relations regarding to entity A. Co-occurrence: We have mentioned the cooccurrence feature in Equation 2, indicated by Φc(a, a&apos;). It captures the co-occurrence of two labeled edges incident to the same entity mention. Note that the co-occurrence feature function is considered only if there is a contrast conjunction such as “but” between the non-shared entity mentions incident to the two labeled edges. Senti-predictors: Following the idea of (Qu et al., 2012), we encode the prediction results from the rule-based phrase-level multi-relation predictor (Ding et al., 2009) and from the bag-of-opinions predictor (Qu et al., 2010) as features based on the textual evidence. The output of the first predictor is an integer value, while the output of the second predictor is a sentiment relation, such as “positive”, E miEMp 159 “negative”, “better” or “worse”. We map the relational outputs into integer values and then encode the outputs from both predictors as senti-predictor features. Others: The commonly used part-of-speech tags are also included as features. Moreover, for an edge candidate, a set of binary features are used to denote the types of the edge and its e</context>
<context position="34298" citStr="Ding et al. (2009)" startWordPosition="5691" endWordPosition="5694">meras. In contrast, web users are much less interested in comparing movies, in both reviews and forums. In all subsets, positive relations play a dominant role since web users intend to express more positive attitudes online than negative ones (Pang and Lee, 2007). 9 Experiments This section describes the empirical evaluation of SENTI-LSSVM together with two competitive baselines on the SRG corpus. 9.1 Experimental Setup We implemented a rule-based baseline (DINGRULE) and a structural SVM (Tsochantaridis et al., 2004) baseline (SENTI-SSVM) for comparison. The former system extends the work of Ding et al. (2009), which designed several linguisticallymotivated rules based on a sentiment polarity lexicon for relation identification and assumes there is only one type of sentiment relation in a sentence. In our implementation, we keep all the rules of (Ding et al., 2009) and add one phrase-level rule when there are more than one mention in a sentence. The additional rule assigns sentiment-bearing words and negators to its nearest relation candidates based on the absolute surface distance between the words and the corresponding mentions. In this case, the phraselevel sentiment-oriented relations depend on</context>
</contexts>
<marker>Ding, Liu, Zhang, 2009</marker>
<rawString>Xiaowen Ding, Bing Liu, and Lei Zhang. 2009. Entity discovery and assignment for opinion mining applications. In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 1125–1134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Duchi</author>
<author>Yoram Singer</author>
</authors>
<title>Efficient online and batch learning using forward backward splitting.</title>
<date>2009</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>10</volume>
<pages>2934</pages>
<contexts>
<context position="28408" citStr="Duchi and Singer, 2009" startWordPosition="4677" endWordPosition="4680">x (β&gt;Φ(x,ˆy,ˆh)+δ(ˆh,ˆy,y)) (P,h)∈Y(x) ×H(x) − max ¯h∈H(x) β&gt;Φ(x, y, ¯h)] + ρ|β|] (4) where δ(ˆh, ˆy, y) is a loss function measuring the discrepancies between an eMRG (y, ¯h) with gold standard edge labels y and an eMRG (ˆy, ˆh) with inferred labeled edges yˆ and textual evidences ˆh. Due to the sparse nature of the lexical features, we apply L1 regularizer to the weight vector β, and the degree of sparsity is controlled by the hyperparameter ρ. Since the L1 norm in the above optimization problem is not differentiable at zero, we apply the online forward-backward splitting (FOBOS) algorithm (Duchi and Singer, 2009). It requires two steps for updating the weight vector β by using a single training sentence x on each iteration t. βt+ 12 = βt − εtΔt βt+1 = arg min β 211β − βt112 + εtρ|β| 1 where Δt is the subgradient computed without considering the L1 norm and εt is the learning rate. For a labeled sentence x, Δt = Φ(x, ˆy*, ˆh*) − Φ(x, y, h*), where the feature functions of the corresponding eMRGs are inferred by solving (ˆy*, ˆh*) = arg max(ˆh,ˆy)E?i(x)xY(x)[βTΦ(x, ˆy, ˆh) + δ(ˆh, ˆy, y)] and (y, ¯h*) = arg max¯hE?i(x) βTΦ(x, y, ¯h), as indicated in the optimization problem (4). The former inference pro</context>
</contexts>
<marker>Duchi, Singer, 2009</marker>
<rawString>John Duchi and Yoram Singer. 2009. Efficient online and batch learning using forward backward splitting. The Journal of Machine Learning Research, 10:2899– 2934.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Murthy Ganapathibhotla</author>
<author>Bing Liu</author>
</authors>
<title>Mining opinions in comparative sentences.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics -</booktitle>
<volume>1</volume>
<pages>241--248</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1926" citStr="Ganapathibhotla and Liu, 2008" startWordPosition="256" endWordPosition="260">aluable resource for the community. 1 Introduction Sentiment-oriented relation extraction (Choi et al., 2006) is concerned with recognizing sentiment polarities and comparative relations between entities from natural language text. Identifying such relations often requires syntactic and semantic analysis at both sentence and phrase level. Most prior work on sentiment analysis consider either i) subjective sentence detection (Yu and Kübler, 2011), ii) polarity classification (Johansson and Moschitti, 2011; Wilson et al., 2005), or iii) comparative relation identification (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). In practice, however, different types of sentiment-oriented relations frequently coexist in documents. In particular, we found that more than 38% of the sentences in our test corpus contain more than one type of relations. The isolated analysis approach is inappropriate because i) it sacrifices acuracy by ignoring the intricate interplay among different types of relations; ii) it could lead to conflicting predictions such as estimating a relation candidate as both negative and comparative. Therefore, in this paper, we identify instances of both sentiment polarities and comparative relations </context>
<context position="7618" citStr="Ganapathibhotla and Liu, 2008" startWordPosition="1135" endWordPosition="1138">al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall short of extracting comparative relations based on domain dependent information. Both Johansson and Moschitti (2011) and Wu et al. (2011) formulate fine-grained sentiment analysis as a learning problem with structured outputs. However, they focus only on polarity classification 156 of expressions and require annotation of sentimentbearing expressions for training as well. While ILP has been previously applied for i</context>
</contexts>
<marker>Ganapathibhotla, Liu, 2008</marker>
<rawString>Murthy Ganapathibhotla and Bing Liu. 2008. Mining opinions in comparative sentences. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, pages 241–248, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Namrata Godbole</author>
<author>Manjunath Srinivasaiah</author>
<author>Steven Skiena</author>
</authors>
<title>Large-scale sentiment analysis for news and blogs (system demonstration).</title>
<date>2007</date>
<booktitle>In Proceedings of the International AAAI Conference on Weblogs and Social Media.</booktitle>
<contexts>
<context position="7158" citStr="Godbole et al., 2007" startWordPosition="1066" endWordPosition="1069">pression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative</context>
</contexts>
<marker>Godbole, Srinivasaiah, Skiena, 2007</marker>
<rawString>Namrata Godbole, Manjunath Srinivasaiah, and Steven Skiena. 2007. Large-scale sentiment analysis for news and blogs (system demonstration). In Proceedings of the International AAAI Conference on Weblogs and Social Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John E Hopcroft</author>
<author>Richard M Karp</author>
</authors>
<title>An nˆ5/2 algorithm for maximum matchings in bipartite graphs.</title>
<date>1973</date>
<journal>SIAM Journal on computing,</journal>
<pages>2--4</pages>
<contexts>
<context position="30954" citStr="Hopcroft and Karp, 1973" startWordPosition="5150" endWordPosition="5153"> ζ corresponds to exactly the size of a maximum matching of the bipartite graph1. To find the optimal eMRG (y, ¯h*), for the gold label k of each edge, we consider the following set of constraints for inference since the labels of the edges are known for the training data, X ηec &lt; 1; ηec &lt; lck cECe X k&apos;EL We include also the soft constraints, which avoid a textual evidence being overly reused by multiple relations, and the constraints similar to (5) to ensure a minimal number of labeled edges and a minimal number of sentiment-oriented relations. 1It is computed by the Hopcroft-Karp algorithm (Hopcroft and Karp, 1973) in our implementation. X cECe t ηec &lt; τma 1 n min β Xn i=1 X a∈A X c∈Ca X eESc lck&apos; &lt; 1; ηec &lt; 1 162 8 SRG Corpus For evaluation we constructed the SRG corpus, which in total consists of 1686 manually annotated online reviews and forum posts in the digital camera and movie domains2. For each domain, we maintain a set of attributes and a list of entity names. The annotation scheme for the sentiment representation asserts minimal linguistic knowledge from our annotators. By focusing on the meanings of the sentences, the annotators make decisions based on their language intuition, not restricted</context>
</contexts>
<marker>Hopcroft, Karp, 1973</marker>
<rawString>John E Hopcroft and Richard M Karp. 1973. An nˆ5/2 algorithm for maximum matchings in bipartite graphs. SIAM Journal on computing, 2(4):225–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4564" citStr="Hu and Liu, 2004" startWordPosition="675" endWordPosition="678">ing a fully annotated training corpus for this task is labor-intensive and requires strong linguistic background. We minimize this overhead by applying a simplified annotation scheme, in which annotators mark mentions of entities and attributes, disambiguate the entities, and label instances of relations for each sentence. Based on the new scheme, we have created a small Sentiment Relation Graph (SRG) corpus for the domains of cameras and movies, which significantly differs from the corpora used in prior work (Wei and Gulla, 2010; Kessler et al., 2010; Toprak et al., 2010; Wiebe et al., 2005; Hu and Liu, 2004) in the following ways: i) both sentiment polarities and comparative relations are annotated; ii) all mentioned entities are disambiguated; and iii) no subjective expressions are annotated, unless they are part of entity mentions. The new annotation scheme raises a new challenge for learning algorithms in that they need to automatically find textual evidences for each annotated relation during training. For example, with the sentence “I like the Rebel a little better, but that is another price jump”, simply assigning a sentimentbearing expression to the nearest relation candidate is insufficie</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 168–177, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Jin</author>
<author>Hung Hay Ho</author>
<author>Rohini K Srihari</author>
</authors>
<title>Opinionminer: a novel machine learning system for web opinion mining and extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>1195--1204</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="6652" citStr="Jin et al., 2009" startWordPosition="990" endWordPosition="993">iews and forum posts, showing that SENTI-LSSVM model can effectively learn from a training corpus without explicitly annotated subjective expressions and that its performance significantly outperforms state-of-the-art systems. 2 Related Work There are ample works on analyzing sentiment polarities and entity comparisons, but the majority of them studied the two tasks in isolation. Most prior approaches for fine-grained sentiment analysis focus on polarity classification. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior per</context>
</contexts>
<marker>Jin, Ho, Srihari, 2009</marker>
<rawString>Wei Jin, Hung Hay Ho, and Rohini K. Srihari. 2009. Opinionminer: a novel machine learning system for web opinion mining and extraction. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1195– 1204, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nitin Jindal</author>
<author>Bing Liu</author>
</authors>
<title>Mining comparative sentences and relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Artificial Intelligence - Volume 2, AAAI’06,</booktitle>
<pages>1331--1336</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="1894" citStr="Jindal and Liu, 2006" startWordPosition="252" endWordPosition="255">built will also be a valuable resource for the community. 1 Introduction Sentiment-oriented relation extraction (Choi et al., 2006) is concerned with recognizing sentiment polarities and comparative relations between entities from natural language text. Identifying such relations often requires syntactic and semantic analysis at both sentence and phrase level. Most prior work on sentiment analysis consider either i) subjective sentence detection (Yu and Kübler, 2011), ii) polarity classification (Johansson and Moschitti, 2011; Wilson et al., 2005), or iii) comparative relation identification (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). In practice, however, different types of sentiment-oriented relations frequently coexist in documents. In particular, we found that more than 38% of the sentences in our test corpus contain more than one type of relations. The isolated analysis approach is inappropriate because i) it sacrifices acuracy by ignoring the intricate interplay among different types of relations; ii) it could lead to conflicting predictions such as estimating a relation candidate as both negative and comparative. Therefore, in this paper, we identify instances of both sentiment polar</context>
<context position="7586" citStr="Jindal and Liu, 2006" startWordPosition="1131" endWordPosition="1134">le types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall short of extracting comparative relations based on domain dependent information. Both Johansson and Moschitti (2011) and Wu et al. (2011) formulate fine-grained sentiment analysis as a learning problem with structured outputs. However, they focus only on polarity classification 156 of expressions and require annotation of sentimentbearing expressions for training as well. While ILP h</context>
</contexts>
<marker>Jindal, Liu, 2006</marker>
<rawString>Nitin Jindal and Bing Liu. 2006. Mining comparative sentences and relations. In Proceedings of the 21st International Conference on Artificial Intelligence - Volume 2, AAAI’06, pages 1331–1336. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Extracting opinion expressions and their polarities– exploration of pipelines and joint models.</title>
<date>2011</date>
<booktitle>In Proceedings of the Annual meeting of the Association for Computational Linguistics,</booktitle>
<volume>11</volume>
<pages>101--106</pages>
<contexts>
<context position="1805" citStr="Johansson and Moschitti, 2011" startWordPosition="239" endWordPosition="242">cameras and movies) and across genres (reviews and forum posts). The gold standard corpus that we built will also be a valuable resource for the community. 1 Introduction Sentiment-oriented relation extraction (Choi et al., 2006) is concerned with recognizing sentiment polarities and comparative relations between entities from natural language text. Identifying such relations often requires syntactic and semantic analysis at both sentence and phrase level. Most prior work on sentiment analysis consider either i) subjective sentence detection (Yu and Kübler, 2011), ii) polarity classification (Johansson and Moschitti, 2011; Wilson et al., 2005), or iii) comparative relation identification (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). In practice, however, different types of sentiment-oriented relations frequently coexist in documents. In particular, we found that more than 38% of the sentences in our test corpus contain more than one type of relations. The isolated analysis approach is inappropriate because i) it sacrifices acuracy by ignoring the intricate interplay among different types of relations; ii) it could lead to conflicting predictions such as estimating a relation candidate as both negative</context>
<context position="6706" citStr="Johansson and Moschitti, 2011" startWordPosition="998" endWordPosition="1001">LSSVM model can effectively learn from a training corpus without explicitly annotated subjective expressions and that its performance significantly outperforms state-of-the-art systems. 2 Related Work There are ample works on analyzing sentiment polarities and entity comparisons, but the majority of them studied the two tasks in isolation. Most prior approaches for fine-grained sentiment analysis focus on polarity classification. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In co</context>
</contexts>
<marker>Johansson, Moschitti, 2011</marker>
<rawString>Richard Johansson and Alessandro Moschitti. 2011. Extracting opinion expressions and their polarities– exploration of pipelines and joint models. In Proceedings of the Annual meeting of the Association for Computational Linguistics, volume 11, pages 101–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason S Kessler</author>
<author>Miriam Eckert</author>
<author>Lyndsie Clark</author>
<author>Nicolas Nicolov</author>
</authors>
<title>icwsm jdpa sentment corpus for the automotive domain.</title>
<date>2010</date>
<booktitle>In 4th International AAAI Conference on Weblogs and Social Media Data Workshop Challenge (ICWSM-DWC</booktitle>
<publisher>The</publisher>
<contexts>
<context position="4504" citStr="Kessler et al., 2010" startWordPosition="663" endWordPosition="666">eferred(Nikon D7000, Canon 7D, textitprice). However, constructing a fully annotated training corpus for this task is labor-intensive and requires strong linguistic background. We minimize this overhead by applying a simplified annotation scheme, in which annotators mark mentions of entities and attributes, disambiguate the entities, and label instances of relations for each sentence. Based on the new scheme, we have created a small Sentiment Relation Graph (SRG) corpus for the domains of cameras and movies, which significantly differs from the corpora used in prior work (Wei and Gulla, 2010; Kessler et al., 2010; Toprak et al., 2010; Wiebe et al., 2005; Hu and Liu, 2004) in the following ways: i) both sentiment polarities and comparative relations are annotated; ii) all mentioned entities are disambiguated; and iii) no subjective expressions are annotated, unless they are part of entity mentions. The new annotation scheme raises a new challenge for learning algorithms in that they need to automatically find textual evidences for each annotated relation during training. For example, with the sentence “I like the Rebel a little better, but that is another price jump”, simply assigning a sentimentbearin</context>
</contexts>
<marker>Kessler, Eckert, Clark, Nicolov, 2010</marker>
<rawString>Jason S. Kessler, Miriam Eckert, Lyndsie Clark, and Nicolas Nicolov. 2010. The 2010 icwsm jdpa sentment corpus for the automotive domain. In 4th International AAAI Conference on Weblogs and Social Media Data Workshop Challenge (ICWSM-DWC 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Extracting opinions, opinion holders, and topics expressed in online news media text.</title>
<date>2006</date>
<booktitle>In Proceedings of the Workshop on Sentiment and Subjectivity in Text, SST ’06,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7136" citStr="Kim and Hovy, 2006" startWordPosition="1062" endWordPosition="1065">sed approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences whic</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Extracting opinions, opinion holders, and topics expressed in online news media text. In Proceedings of the Workshop on Sentiment and Subjectivity in Text, SST ’06, pages 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="22028" citStr="Klein and Manning, 2003" startWordPosition="3523" endWordPosition="3526">EMp a,a0Eyr(mi),a=,4a0 In order to find the best eMRG for a given sentence with a well trained model, we need to determine the most likely relation type for each relation candidate and support the corresponding assertions with proper textual evidences. We formulate this task as an Integer Linear Programming (ILP). Instead of considering all constituents of a sentence, we empirically select a subset as textual evidences for each relation candidate. 6.1 Textual Evidence Candidates Selection Textual evidences are selected based on the constituent trees of sentences parsed by the Stanford parser (Klein and Manning, 2003). For each mention in a sentence, we first locate a constituent in the tree with the maximal overlap by Jaccard similarity. Starting from this constituent, we consider two types of candidates: type I candidates are constituents at the highest level which contain neither any word of another mention nor any contrast conjunctions such as “but”; type II candidates are constituents at the highest level which cover exactly two mentions of an edge and do not overlap with any other mentions. For a binary edge connecting an entity mention and an attribute mention, we consider a type I candidate startin</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 423–430, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-Wei Ku</author>
<author>Yu-Ting Liang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Opinion extraction, summarization and tracking in news and blog corpora. In AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs,</title>
<date>2006</date>
<pages>100--107</pages>
<contexts>
<context position="7116" citStr="Ku et al., 2006" startWordPosition="1058" endWordPosition="1061">fication. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywor</context>
</contexts>
<marker>Ku, Liang, Chen, 2006</marker>
<rawString>Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen. 2006. Opinion extraction, summarization and tracking in news and blog corpora. In AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs, pages 100–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
<author>Minqing Hu</author>
<author>Junsheng Cheng</author>
</authors>
<title>Opinion observer: analyzing and comparing opinions on the web.</title>
<date>2005</date>
<booktitle>In Proceedings of the 14th international conference on World Wide Web,</booktitle>
<pages>342--351</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7223" citStr="Liu et al., 2005" startWordPosition="1078" endWordPosition="1081">expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall short of extracting com</context>
</contexts>
<marker>Liu, Hu, Cheng, 2005</marker>
<rawString>Bing Liu, Minqing Hu, and Junsheng Cheng. 2005. Opinion observer: analyzing and comparing opinions on the web. In Proceedings of the 14th international conference on World Wide Web, pages 342–351, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>André L Martins</author>
<author>Noah A Smith</author>
<author>Eric P Xing</author>
</authors>
<title>Concise integer linear programming formulations for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>342--350</pages>
<contexts>
<context position="14990" citStr="Martins et al., 2009" startWordPosition="2334" endWordPosition="2337">n type preferred. 4 SENTI-LSSVM Model The task of sentiment-oriented relation extraction is to determine the most likely sSoR in a sentence. Since sSoRs are derived from the corresponding MRGs as described in Section 3, the task is reduced to find the most likely MRG for each sentence. Since an MRG is created by assigning relation types to a subset of all relation candidates, which are possible tuples of mentions with unknown relation types, the number of MRGs can be extremely high. To tackle the task, one solution is to employ an edge-factored linear model in the framework of structural SVM (Martins et al., 2009; Tsochantaridis et al., 2004). The model suggests that a bag of features should be specified for each relation candidate, and then the model predicts the most likely candidate sets along with their relation types to form the optimal MRGs. As we observed, for a relation candidate, the most informative features are the words near its entity mentions in the original text. How158 ever, if we represent a candidate by all these words, it is very likely that the instances of different relation types share overly similar features, because a mention is often involved in more than one relation candidat</context>
<context position="24203" citStr="Martins et al., 2009" startWordPosition="3925" endWordPosition="3928"> s.t. A ⎣ ⎤ ⎦≤ d z 77 T 160 eMRG with only Binary Edges: An eMRG has only binary edges if a sentence contains no attribute mention or at most one entity mention. We expect that each edge has only one relation type and is supported by a single textual evidence. To facilitate the formulation of constraints, we introduce ηel to denote the presence or absence of a labeled edge el, and ηec to indicate if a textual evidence c is assigned to an unlabeled edge e. Then the binary variable for the corresponding evidentiary edge zelc = ηec n ηel, where the ILP formulation of conjunction can be found in (Martins et al., 2009). Let Ce denote the set of textual evidence candidates of an unlabeled edge e. The constraint of at most one textual evidence per edge is formulated as: X ηec G 1 (3) c∈Ce Once a textual evidence is assigned to an edge, their relation labels should match and the number of labeled edges must agree with the number of attached textual evidences. Further, we assume that a textual evidence c conveys at most one relation so that an evidence will not be assigned to the relations of different types, which is the main problem for the structural SVM based model. Let ηcl indicate that the textual evidenc</context>
</contexts>
<marker>Martins, Smith, Xing, 2009</marker>
<rawString>André L. Martins, Noah A. Smith, and Eric P. Xing. 2009. Concise integer linear programming formulations for dependency parsing. In Proceedings of the Annual meeting of the Association for Computational Linguistics, pages 342–350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
<author>Kerry Hannan</author>
<author>Tyler Neylon</author>
<author>Mike Wells</author>
<author>Jeffrey C Reynar</author>
</authors>
<title>Structured models for fine-to-coarse sentiment analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the Annual meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="6997" citStr="McDonald et al., 2007" startWordPosition="1039" endWordPosition="1042">f them studied the two tasks in isolation. Most prior approaches for fine-grained sentiment analysis focus on polarity classification. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathi</context>
</contexts>
<marker>McDonald, Hannan, Neylon, Wells, Reynar, 2007</marker>
<rawString>Ryan T. McDonald, Kerry Hannan, Tyler Neylon, Mike Wells, and Jeffrey C. Reynar. 2007. Structured models for fine-to-coarse sentiment analysis. In Proceedings of the Annual meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2007</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="33944" citStr="Pang and Lee, 2007" startWordPosition="5638" endWordPosition="5641">on sSoRs in terms of Cohen’s Kappa (κ) (Cohen, 1968). An average Kappa value of 0.698 was achieved on a randomly selected set consisting of 412 sentences. Table 1 shows the corpus distribution after normalizing them into sSoRs. Camera forum posts contain the largest proportion of comparisons because they are mainly about the recommendation of digital cameras. In contrast, web users are much less interested in comparing movies, in both reviews and forums. In all subsets, positive relations play a dominant role since web users intend to express more positive attitudes online than negative ones (Pang and Lee, 2007). 9 Experiments This section describes the empirical evaluation of SENTI-LSSVM together with two competitive baselines on the SRG corpus. 9.1 Experimental Setup We implemented a rule-based baseline (DINGRULE) and a structural SVM (Tsochantaridis et al., 2004) baseline (SENTI-SSVM) for comparison. The former system extends the work of Ding et al. (2009), which designed several linguisticallymotivated rules based on a sentiment polarity lexicon for relation identification and assumes there is only one type of sentiment relation in a sentence. In our implementation, we keep all the rules of (Ding</context>
</contexts>
<marker>Pang, Lee, 2007</marker>
<rawString>Bo Pang and Lillian Lee. 2007. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana-Maria Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>339--346</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7204" citStr="Popescu and Etzioni, 2005" startWordPosition="1074" endWordPosition="1077">ation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall shor</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>Ana-Maria Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 339–346, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lizhen Qu</author>
<author>Georgiana Ifrim</author>
<author>Gerhard Weikum</author>
</authors>
<title>The bag-of-opinions method for review rating prediction from sparse text patterns.</title>
<date>2010</date>
<booktitle>In Chu-Ren Huang and Dan Jurafsky, editors, Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), ACL Anthology,</booktitle>
<pages>913--921</pages>
<publisher>Tsinghua University Press.</publisher>
<location>Beijing,</location>
<contexts>
<context position="19566" citStr="Qu et al., 2010" startWordPosition="3120" endWordPosition="3123">ding to entity A. Co-occurrence: We have mentioned the cooccurrence feature in Equation 2, indicated by Φc(a, a&apos;). It captures the co-occurrence of two labeled edges incident to the same entity mention. Note that the co-occurrence feature function is considered only if there is a contrast conjunction such as “but” between the non-shared entity mentions incident to the two labeled edges. Senti-predictors: Following the idea of (Qu et al., 2012), we encode the prediction results from the rule-based phrase-level multi-relation predictor (Ding et al., 2009) and from the bag-of-opinions predictor (Qu et al., 2010) as features based on the textual evidence. The output of the first predictor is an integer value, while the output of the second predictor is a sentiment relation, such as “positive”, E miEMp 159 “negative”, “better” or “worse”. We map the relational outputs into integer values and then encode the outputs from both predictors as senti-predictor features. Others: The commonly used part-of-speech tags are also included as features. Moreover, for an edge candidate, a set of binary features are used to denote the types of the edge and its entity mentions. For instance, a binary feature indicates </context>
</contexts>
<marker>Qu, Ifrim, Weikum, 2010</marker>
<rawString>Lizhen Qu, Georgiana Ifrim, and Gerhard Weikum. 2010. The bag-of-opinions method for review rating prediction from sparse text patterns. In Chu-Ren Huang and Dan Jurafsky, editors, Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), ACL Anthology, pages 913– 921, Beijing, China. Tsinghua University Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Lizhen Qu</author>
<author>Rainer Gemulla</author>
<author>Gerhard Weikum</author>
</authors>
<title>A weakly supervised model for sentence-level semantic orientation analysis with multiple experts.</title>
<date>2012</date>
<booktitle>In Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>149--159</pages>
<location>Jeju Island,</location>
<contexts>
<context position="7299" citStr="Qu et al., 2012" startWordPosition="1092" endWordPosition="1095">son and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall short of extracting comparative relations based on domain dependent information. Both Johansson and</context>
<context position="19397" citStr="Qu et al., 2012" startWordPosition="3095" endWordPosition="3098"> sentence, a set of contextual binary features are used to indicate all possible combinations of the current and the previous mentioned sentimentoriented relations regarding to entity A. Co-occurrence: We have mentioned the cooccurrence feature in Equation 2, indicated by Φc(a, a&apos;). It captures the co-occurrence of two labeled edges incident to the same entity mention. Note that the co-occurrence feature function is considered only if there is a contrast conjunction such as “but” between the non-shared entity mentions incident to the two labeled edges. Senti-predictors: Following the idea of (Qu et al., 2012), we encode the prediction results from the rule-based phrase-level multi-relation predictor (Ding et al., 2009) and from the bag-of-opinions predictor (Qu et al., 2010) as features based on the textual evidence. The output of the first predictor is an integer value, while the output of the second predictor is a sentiment relation, such as “positive”, E miEMp 159 “negative”, “better” or “worse”. We map the relational outputs into integer values and then encode the outputs from both predictors as senti-predictor features. Others: The commonly used part-of-speech tags are also included as featur</context>
</contexts>
<marker>Qu, Gemulla, Weikum, 2012</marker>
<rawString>Lizhen Qu, Rainer Gemulla, and Gerhard Weikum. 2012. A weakly supervised model for sentence-level semantic orientation analysis with multiple experts. In Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 149–159, Jeju Island, Korea, July. Proceedings of the Annual meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1201--1211</pages>
<contexts>
<context position="7049" citStr="Socher et al., 2012" startWordPosition="1047" endWordPosition="1050"> approaches for fine-grained sentiment analysis focus on polarity classification. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistic</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1201–1211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Janyce Wiebe</author>
</authors>
<title>Recognizing stances in online debates.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing,</booktitle>
<pages>226--234</pages>
<contexts>
<context position="8301" citStr="Somasundaran and Wiebe, 2009" startWordPosition="1234" endWordPosition="1237"> assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall short of extracting comparative relations based on domain dependent information. Both Johansson and Moschitti (2011) and Wu et al. (2011) formulate fine-grained sentiment analysis as a learning problem with structured outputs. However, they focus only on polarity classification 156 of expressions and require annotation of sentimentbearing expressions for training as well. While ILP has been previously applied for inference in sentiment analysis (Choi and Cardie, 2009; Somasundaran and Wiebe, 2009; Wu et al., 2011), our task requires a complete ILP reformulation due to 1) the absence of annotated sentiment expressions and 2) the constraints imposed by the joint extraction of both sentiment polarity and comparative relations. 3 System Overview This section gives an overview of the whole system for extracting sentiment-oriented relation instances. Prior to presenting the system architecture, we introduce the essential concepts and the definitions of two kinds of directed hypergraphs as the representation of correlated relation instances extracted from sentences. 3.1 Concepts and Definiti</context>
</contexts>
<marker>Somasundaran, Wiebe, 2009</marker>
<rawString>Swapna Somasundaran and Janyce Wiebe. 2009. Recognizing stances in online debates. In Proceedings of the Joint conference of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, pages 226–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly D Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexiconbased methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="37015" citStr="Taboada et al., 2011" startWordPosition="6136" endWordPosition="6139">her is not of our interest, we evaluate the sSoRs in terms of precision, recall and F-measure. All reported numbers are averages over the 5 folds. 9.2 Results Table 2 shows the complete results of all systems. Here our model SENTI-LSSVM outperformed all baselines in terms of the average F-measure scores and recalls by a large margin. The F-measure on movie reviews is about 14% over the best baseline. The rule-based system has higher precision than recall in most cases. However, simply increasing the coverage of the domain independent sentiment polarity lexicon might lead to worse performance (Taboada et al., 2011) because many sentiment oriented relations are conveyed by domain dependent expressions and factual expressions implying evaluations, such as “This camera does not have manual control.” Compared to DING-RULE, SENTI-SSVM performs better in the camera domain but worse for the movies due to many misclassification of negative relation instances as other. It also wrongly predicted more positive instances as other than SENTI-LSSVM. We found that the recalls of these instances are low because they often have overly similar features with the instances of the type other linking to the same mentions. Th</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly D. Voll, and Manfred Stede. 2011. Lexiconbased methods for sentiment analysis. Computational Linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar Täckström</author>
<author>Ryan McDonald</author>
</authors>
<title>Discovering fine-grained sentiment with latent variable structured prediction models.</title>
<date>2011</date>
<booktitle>In Proceedings of the 33rd European conference on Advances in information retrieval, ECIR’11,</booktitle>
<pages>368--374</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<contexts>
<context position="7027" citStr="Täckström and McDonald, 2011" startWordPosition="1043" endWordPosition="1046">tasks in isolation. Most prior approaches for fine-grained sentiment analysis focus on polarity classification. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approac</context>
</contexts>
<marker>Täckström, McDonald, 2011</marker>
<rawString>Oscar Täckström and Ryan McDonald. 2011. Discovering fine-grained sentiment with latent variable structured prediction models. In Proceedings of the 33rd European conference on Advances in information retrieval, ECIR’11, pages 368–374, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cigdem Toprak</author>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Sentence and expression level annotation of opinions in user-generated discourse.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10,</booktitle>
<pages>575--584</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4525" citStr="Toprak et al., 2010" startWordPosition="667" endWordPosition="670">anon 7D, textitprice). However, constructing a fully annotated training corpus for this task is labor-intensive and requires strong linguistic background. We minimize this overhead by applying a simplified annotation scheme, in which annotators mark mentions of entities and attributes, disambiguate the entities, and label instances of relations for each sentence. Based on the new scheme, we have created a small Sentiment Relation Graph (SRG) corpus for the domains of cameras and movies, which significantly differs from the corpora used in prior work (Wei and Gulla, 2010; Kessler et al., 2010; Toprak et al., 2010; Wiebe et al., 2005; Hu and Liu, 2004) in the following ways: i) both sentiment polarities and comparative relations are annotated; ii) all mentioned entities are disambiguated; and iii) no subjective expressions are annotated, unless they are part of entity mentions. The new annotation scheme raises a new challenge for learning algorithms in that they need to automatically find textual evidences for each annotated relation during training. For example, with the sentence “I like the Rebel a little better, but that is another price jump”, simply assigning a sentimentbearing expression to the n</context>
</contexts>
<marker>Toprak, Jakob, Gurevych, 2010</marker>
<rawString>Cigdem Toprak, Niklas Jakob, and Iryna Gurevych. 2010. Sentence and expression level annotation of opinions in user-generated discourse. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, ACL ’10, pages 575–584, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ioannis Tsochantaridis</author>
<author>Thomas Hofmann</author>
<author>Thorsten Joachims</author>
<author>Yasemin Altun</author>
</authors>
<title>Support vector machine learning for interdependent and structured output spaces.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Conference on Machine Learning,</booktitle>
<pages>104--112</pages>
<contexts>
<context position="15020" citStr="Tsochantaridis et al., 2004" startWordPosition="2338" endWordPosition="2341">NTI-LSSVM Model The task of sentiment-oriented relation extraction is to determine the most likely sSoR in a sentence. Since sSoRs are derived from the corresponding MRGs as described in Section 3, the task is reduced to find the most likely MRG for each sentence. Since an MRG is created by assigning relation types to a subset of all relation candidates, which are possible tuples of mentions with unknown relation types, the number of MRGs can be extremely high. To tackle the task, one solution is to employ an edge-factored linear model in the framework of structural SVM (Martins et al., 2009; Tsochantaridis et al., 2004). The model suggests that a bag of features should be specified for each relation candidate, and then the model predicts the most likely candidate sets along with their relation types to form the optimal MRGs. As we observed, for a relation candidate, the most informative features are the words near its entity mentions in the original text. How158 ever, if we represent a candidate by all these words, it is very likely that the instances of different relation types share overly similar features, because a mention is often involved in more than one relation candidate, as shown in Figure 2. As a </context>
<context position="34203" citStr="Tsochantaridis et al., 2004" startWordPosition="5676" endWordPosition="5679">tain the largest proportion of comparisons because they are mainly about the recommendation of digital cameras. In contrast, web users are much less interested in comparing movies, in both reviews and forums. In all subsets, positive relations play a dominant role since web users intend to express more positive attitudes online than negative ones (Pang and Lee, 2007). 9 Experiments This section describes the empirical evaluation of SENTI-LSSVM together with two competitive baselines on the SRG corpus. 9.1 Experimental Setup We implemented a rule-based baseline (DINGRULE) and a structural SVM (Tsochantaridis et al., 2004) baseline (SENTI-SSVM) for comparison. The former system extends the work of Ding et al. (2009), which designed several linguisticallymotivated rules based on a sentiment polarity lexicon for relation identification and assumes there is only one type of sentiment relation in a sentence. In our implementation, we keep all the rules of (Ding et al., 2009) and add one phrase-level rule when there are more than one mention in a sentence. The additional rule assigns sentiment-bearing words and negators to its nearest relation candidates based on the absolute surface distance between the words and t</context>
</contexts>
<marker>Tsochantaridis, Hofmann, Joachims, Altun, 2004</marker>
<rawString>Ioannis Tsochantaridis, Thomas Hofmann, Thorsten Joachims, and Yasemin Altun. 2004. Support vector machine learning for interdependent and structured output spaces. In Proceedings of the International Conference on Machine Learning, pages 104–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wei</author>
<author>Jon Atle Gulla</author>
</authors>
<title>Sentiment learning on product reviews via sentiment ontology tree.</title>
<date>2010</date>
<booktitle>In Proceedings of the Annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>404--413</pages>
<contexts>
<context position="4482" citStr="Wei and Gulla, 2010" startWordPosition="659" endWordPosition="662">l Linguistics. and preferred(Nikon D7000, Canon 7D, textitprice). However, constructing a fully annotated training corpus for this task is labor-intensive and requires strong linguistic background. We minimize this overhead by applying a simplified annotation scheme, in which annotators mark mentions of entities and attributes, disambiguate the entities, and label instances of relations for each sentence. Based on the new scheme, we have created a small Sentiment Relation Graph (SRG) corpus for the domains of cameras and movies, which significantly differs from the corpora used in prior work (Wei and Gulla, 2010; Kessler et al., 2010; Toprak et al., 2010; Wiebe et al., 2005; Hu and Liu, 2004) in the following ways: i) both sentiment polarities and comparative relations are annotated; ii) all mentioned entities are disambiguated; and iii) no subjective expressions are annotated, unless they are part of entity mentions. The new annotation scheme raises a new challenge for learning algorithms in that they need to automatically find textual evidences for each annotated relation during training. For example, with the sentence “I like the Rebel a little better, but that is another price jump”, simply assig</context>
<context position="6758" citStr="Wei and Gulla, 2010" startWordPosition="1006" endWordPosition="1009">out explicitly annotated subjective expressions and that its performance significantly outperforms state-of-the-art systems. 2 Related Work There are ample works on analyzing sentiment polarities and entity comparisons, but the majority of them studied the two tasks in isolation. Most prior approaches for fine-grained sentiment analysis focus on polarity classification. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentime</context>
</contexts>
<marker>Wei, Gulla, 2010</marker>
<rawString>Wei Wei and Jon Atle Gulla. 2010. Sentiment learning on product reviews via sentiment ontology tree. In Proceedings of the Annual meeting of the Association for Computational Linguistics, pages 404–413.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language. Language Resources and Evaluation,</title>
<date>2005</date>
<pages>39--2</pages>
<contexts>
<context position="4545" citStr="Wiebe et al., 2005" startWordPosition="671" endWordPosition="674">. However, constructing a fully annotated training corpus for this task is labor-intensive and requires strong linguistic background. We minimize this overhead by applying a simplified annotation scheme, in which annotators mark mentions of entities and attributes, disambiguate the entities, and label instances of relations for each sentence. Based on the new scheme, we have created a small Sentiment Relation Graph (SRG) corpus for the domains of cameras and movies, which significantly differs from the corpora used in prior work (Wei and Gulla, 2010; Kessler et al., 2010; Toprak et al., 2010; Wiebe et al., 2005; Hu and Liu, 2004) in the following ways: i) both sentiment polarities and comparative relations are annotated; ii) all mentioned entities are disambiguated; and iii) no subjective expressions are annotated, unless they are part of entity mentions. The new annotation scheme raises a new challenge for learning algorithms in that they need to automatically find textual evidences for each annotated relation during training. For example, with the sentence “I like the Rebel a little better, but that is another price jump”, simply assigning a sentimentbearing expression to the nearest relation cand</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language. Language Resources and Evaluation, 39(2-3):165–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phrase-level sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05,</booktitle>
<pages>347--354</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1827" citStr="Wilson et al., 2005" startWordPosition="243" endWordPosition="246">genres (reviews and forum posts). The gold standard corpus that we built will also be a valuable resource for the community. 1 Introduction Sentiment-oriented relation extraction (Choi et al., 2006) is concerned with recognizing sentiment polarities and comparative relations between entities from natural language text. Identifying such relations often requires syntactic and semantic analysis at both sentence and phrase level. Most prior work on sentiment analysis consider either i) subjective sentence detection (Yu and Kübler, 2011), ii) polarity classification (Johansson and Moschitti, 2011; Wilson et al., 2005), or iii) comparative relation identification (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). In practice, however, different types of sentiment-oriented relations frequently coexist in documents. In particular, we found that more than 38% of the sentences in our test corpus contain more than one type of relations. The isolated analysis approach is inappropriate because i) it sacrifices acuracy by ignoring the intricate interplay among different types of relations; ii) it could lead to conflicting predictions such as estimating a relation candidate as both negative and comparative. Ther</context>
<context position="7281" citStr="Wilson et al., 2005" startWordPosition="1087" endWordPosition="1091"> Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall short of extracting comparative relations based on domain dependent information. </context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phrase-level sentiment analysis. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, HLT ’05, pages 347–354, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Ann Wilson</author>
</authors>
<title>Fine-grained subjectivity and sentiment analysis: recognizing the intensity, polarity, and attitudes of private states.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>UNIVERSITY OF PITTSBURGH.</institution>
<contexts>
<context position="38974" citStr="Wilson, 2008" startWordPosition="6451" endWordPosition="6452">e relation among all systems in the movie domain and camera reviews. Since less than 1% of all instances are for comparative relations in these document sets and all models are trained to optimize the overall accuracy, SENTILSSVM intends to trade off the minority class for the overall better performance. This advantage disappears on the camera forum posts, where the number of instances of comparative relation is 12 times more than that in the other data sets. All systems perform better in predicting positive relations than the negative ones. This corresponds well to the empirical findings in (Wilson, 2008) that people intend to use more complex expressions for negative sentiments than their affirmative counterparts. It is also in accordance with the distribution of these relations in our SRG corpus which is randomly sampled from the online documents. For learning systems, it can also be explained by the fact that the training data for positive relations are considerably more than those for negative ones. The comparative relation is the hardest one to process since we found that many corresponding expressions do not contain explicit keywords for comparison. To understand the performance of the k</context>
</contexts>
<marker>Wilson, 2008</marker>
<rawString>Theresa Ann Wilson. 2008. Fine-grained subjectivity and sentiment analysis: recognizing the intensity, polarity, and attitudes of private states. Ph.D. thesis, UNIVERSITY OF PITTSBURGH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Structural opinion mining for graph-based sentiment representation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1332--1341</pages>
<contexts>
<context position="7937" citStr="Wu et al. (2011)" startWordPosition="1181" endWordPosition="1184">hod requires no annotation of sentiment-bearing expressions for training and can predict both sentiment polarities and comparative relations. Sentiment-oriented comparative relations have been studied in the context of user-generated discourse (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). Approaches rely on linguistically motivated rules and assume the existence of independent keywords in sentences which indicate comparative relations. Therefore, these methods fall short of extracting comparative relations based on domain dependent information. Both Johansson and Moschitti (2011) and Wu et al. (2011) formulate fine-grained sentiment analysis as a learning problem with structured outputs. However, they focus only on polarity classification 156 of expressions and require annotation of sentimentbearing expressions for training as well. While ILP has been previously applied for inference in sentiment analysis (Choi and Cardie, 2009; Somasundaran and Wiebe, 2009; Wu et al., 2011), our task requires a complete ILP reformulation due to 1) the absence of annotated sentiment expressions and 2) the constraints imposed by the joint extraction of both sentiment polarity and comparative relations. 3 S</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2011</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2011. Structural opinion mining for graph-based sentiment representation. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1332–1341.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ainur Yessenalina</author>
<author>Claire Cardie</author>
</authors>
<title>Compositional matrix-space models for sentiment analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>172--182</pages>
<contexts>
<context position="6736" citStr="Yessenalina and Cardie, 2011" startWordPosition="1002" endWordPosition="1005">rn from a training corpus without explicitly annotated subjective expressions and that its performance significantly outperforms state-of-the-art systems. 2 Related Work There are ample works on analyzing sentiment polarities and entity comparisons, but the majority of them studied the two tasks in isolation. Most prior approaches for fine-grained sentiment analysis focus on polarity classification. Supervised approaches on expression-level analysis require the annotation of sentiment-bearing expressions as training data (Jin et al., 2009; Choi and Cardie, 2010; Johansson and Moschitti, 2011; Yessenalina and Cardie, 2011; Wei and Gulla, 2010). However, the corresponding annotation process is time-consuming. Although sentence-level annotations are easier to obtain, the analysis at this level cannot cope with sentences conveying relations of multiple types (McDonald et al., 2007; Täckström and McDonald, 2011; Socher et al., 2012). Lexiconbased approaches require no training data (Ku et al., 2006; Kim and Hovy, 2006; Godbole et al., 2007; Ding et al., 2008; Popescu and Etzioni, 2005; Liu et al., 2005) but suffer from inferior performance (Wilson et al., 2005; Qu et al., 2012). In contrast, our method requires no</context>
</contexts>
<marker>Yessenalina, Cardie, 2011</marker>
<rawString>Ainur Yessenalina and Claire Cardie. 2011. Compositional matrix-space models for sentiment analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 172–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chun-Nam John Yu</author>
<author>Thorsten Joachims</author>
</authors>
<title>Learning structural svms with latent variables.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Conference on Machine Learning,</booktitle>
<pages>147</pages>
<contexts>
<context position="17458" citStr="Yu and Joachims, 2009" startWordPosition="2768" endWordPosition="2771">x ∈ X) as the set of labeled edges of an MRG and Y = ∪xEXY(x). Since the assignments of textual evidences are not observed, an assignment of evidences to y is denoted by a latent variable h ∈ H(x) and H = ∪xEXH(x). Then (y, h) corresponds to an eMRG, and (a, c) ∈ (y, h) is a labeled edge a attached with a textual evidence c. Given a labeled dataset D = {(x1, y1), ..., (xn, yn)} ∈ (X × Y)n, we aim to learn a discriminant function f : X → Y ×H that outputs the optimal eMRG (y, h) ∈ Y(x)×H(x) for a given sentence x. Due to the introduction of latent variables, we adopt the latent structural SVM (Yu and Joachims, 2009) for structural classification. Our discriminant function is defined as f(x) = argmax(y,h)EY(x)XW(x)βTΦ(x, y, h) (1) where Φ(x, y, h) is the feature function of an eMRG (y, h) and β is the corresponding weight vector. To ensure tractability, we also employ edge-based factorization for our model. Let Mp denote a set of entity mentions and yr(mi) be a set of edges labeled with sentiment-oriented relations incident to mi, the factorization of Φ(x, y, h) is given as Φ(x, y, h) = � Φe(x, a, c) + (2) (a,c)E(y,h) Φc(a, a&apos;) a,a1Eyr(mi),a#a1 where Φe(x, a, c) is a local edge feature function for a labe</context>
</contexts>
<marker>Yu, Joachims, 2009</marker>
<rawString>Chun-Nam John Yu and Thorsten Joachims. 2009. Learning structural svms with latent variables. In Proceedings of the International Conference on Machine Learning, page 147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ning Yu</author>
<author>Sandra Kübler</author>
</authors>
<title>Filling the gap: Semi-supervised learning for opinion detection across domains.</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>200--209</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1745" citStr="Yu and Kübler, 2011" startWordPosition="231" endWordPosition="234">utperforms stateof-the-art systems across domains (cameras and movies) and across genres (reviews and forum posts). The gold standard corpus that we built will also be a valuable resource for the community. 1 Introduction Sentiment-oriented relation extraction (Choi et al., 2006) is concerned with recognizing sentiment polarities and comparative relations between entities from natural language text. Identifying such relations often requires syntactic and semantic analysis at both sentence and phrase level. Most prior work on sentiment analysis consider either i) subjective sentence detection (Yu and Kübler, 2011), ii) polarity classification (Johansson and Moschitti, 2011; Wilson et al., 2005), or iii) comparative relation identification (Jindal and Liu, 2006; Ganapathibhotla and Liu, 2008). In practice, however, different types of sentiment-oriented relations frequently coexist in documents. In particular, we found that more than 38% of the sentences in our test corpus contain more than one type of relations. The isolated analysis approach is inappropriate because i) it sacrifices acuracy by ignoring the intricate interplay among different types of relations; ii) it could lead to conflicting predicti</context>
</contexts>
<marker>Yu, Kübler, 2011</marker>
<rawString>Ning Yu and Sandra Kübler. 2011. Filling the gap: Semi-supervised learning for opinion detection across domains. In Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 200–209. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>