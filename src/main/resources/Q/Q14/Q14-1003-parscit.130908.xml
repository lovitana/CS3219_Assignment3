<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000062">
<title confidence="0.872197">
Automatic Detection and Language Identification of Multilingual Documents
</title>
<author confidence="0.995716">
Marco Lui♥♣, Jey Han Lau♠ and Timothy Baldwin♥♣
</author>
<affiliation confidence="0.8500256">
♥ Department of Computing and Information Systems
The University of Melbourne
♣ NICTA Victoria Research Laboratory
♠ Department of Philosophy
King’s College London
</affiliation>
<email confidence="0.995016">
mhlui@unimelb.edu.au, jeyhan.lau@gmail.com, tb@ldwin.net
</email>
<sectionHeader confidence="0.998598" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999826769230769">
Language identification is the task of automat-
ically detecting the language(s) present in a
document based on the content of the docu-
ment. In this work, we address the problem
of detecting documents that contain text from
more than one language (multilingual docu-
ments). We introduce a method that is able to
detect that a document is multilingual, iden-
tify the languages present, and estimate their
relative proportions. We demonstrate the ef-
fectiveness of our method over synthetic data,
as well as real-world multilingual documents
collected from the web.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999966153846154">
Language identification is the task of automatically
detecting the language(s) present in a document
based on the content of the document. Language
identification techniques commonly assume that ev-
ery document is written in one of a closed set of
known languages for which there is training data,
and is thus formulated as the task of selecting the
most likely language from the set of training lan-
guages. In this work, we remove this monolingual
assumption, and address the problem of language
identification in documents that may contain text
from more than one language from the candidate set.
We propose a method that concurrently detects that a
document is multilingual, and estimates the propor-
tion of the document that is written in each language.
Detecting multilingual documents has a variety
of applications. Most natural language processing
techniques presuppose monolingual input data, so
inclusion of data in foreign languages introduces
noise, and can degrade the performance of NLP sys-
tems (Alex et al., 2007; Cook and Lui, 2012). Au-
tomatic detection of multilingual documents can be
used as a pre-filtering step to improve the quality of
input data. Detecting multilingual documents is also
important for acquiring linguistic data from the web
(Scannell, 2007; Abney and Bird, 2010), and has
applications in mining bilingual texts for statistical
machine translation from online resources (Resnik,
1999; Nie et al., 1999; Ling et al., 2013). There has
been particular interest in extracting text resources
for low-density languages from multilingual web
pages containing both the low-density language and
another language such as English (Yamaguchi and
Tanaka-Ishii, 2012; King and Abney, 2013). King
and Abney (2013, p1118) specifically mention the
need for an automatic method “to examine a mul-
tilingual document, and with high accuracy, list the
languages that are present in the document”.
We introduce a method that is able to detect multi-
lingual documents, and simultaneously identify each
language present as well as estimate the propor-
tion of the document written in that language. We
achieve this with a probabilistic mixture model, us-
ing a document representation developed for mono-
lingual language identification (Lui and Baldwin,
2011). The model posits that each document is gen-
erated as samples from an unknown mixture of lan-
guages from the training set. We introduce a Gibbs
sampler to map samples to languages for any given
set of languages, and use this to select the set of lan-
guages that maximizes the posterior probability of
the document.
</bodyText>
<page confidence="0.993688">
27
</page>
<bodyText confidence="0.949879615384615">
Transactions of the Association for Computational Linguistics, 2 (2014) 27–40. Action Editor: Kristina Toutanova.
Submitted 1/2013; Revised 7/2013; Published 2/2014. c�2014 Association for Computational Linguistics.
Our method is able to learn a language identi-
fier for multilingual documents from monolingual
training data. This is an important property as there
are no standard corpora of multilingual documents
available, whereas corpora of monolingual docu-
ments are readily available for a reasonably large
number of languages (Lui and Baldwin, 2011). We
demonstrate the effectiveness of our method empir-
ically, firstly by evaluating it on synthetic datasets
drawn from Wikipedia data, and then by applying it
to real-world data, showing that we are able to iden-
tify multilingual documents in targeted web crawls
of minority languages (King and Abney, 2013).
Our main contributions are: (1) we present a
method for identifying multilingual documents, the
languages contained therein and the relative propor-
tion of the document in each language; (2) we show
that our method outperforms state-of-the-art meth-
ods for language identification in multilingual doc-
uments; (3) we show that our method is able to es-
timate the proportion of the document in each lan-
guage to a high degree of accuracy; and (4) we show
that our method is able to identify multilingual doc-
uments in real-world data.
</bodyText>
<sectionHeader confidence="0.995266" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999958666666667">
Most language identification research focuses on
language identification for monolingual documents
(Hughes et al., 2006). In monolingual LangID, the
task is to assign each document D a unique language
Li ∈ L. Some work has reported near-perfect accu-
racy for language identification of large documents
in a small number of languages (Cavnar and Tren-
kle, 1994; McNamee, 2005). However, in order to
attain such accuracy, a large number of simplifying
assumptions have to be made (Hughes et al., 2006;
Baldwin and Lui, 2010a). In this work, we tackle
the assumption that each document is monolingual,
i.e. it contains text from a single language.
In language identification, documents are mod-
eled as a stream of characters (Cavnar and Trenkle,
1994; Kikui, 1996), often approximated by the cor-
responding stream of bytes (Kruengkrai et al., 2005;
Baldwin and Lui, 2010a) for robustness over vari-
able character encodings. In this work, we follow
Baldwin and Lui (2010a) in training a single model
for languages that naturally use multiple encodings
(e.g. UTF8, Big5 and GB encodings for Chinese), as
issues of encoding are not the focus of this research.
The document representation used for language
identification generally involves estimating the rel-
ative distributions of particular byte sequences, se-
lected such that their distributions differ between
languages. In some cases the relevant sequences
may be externally specified, such as function words
and common suffixes (Giguet, 1995) or grammati-
cal word classes (Dueire Lins and Gonc¸alves, 2004),
though they are more frequently learned from la-
beled data (Cavnar and Trenkle, 1994; Grefenstette,
1995; Prager, 1999a; Lui and Baldwin, 2011).
Learning algorithms applied to language identi-
fication fall into two general categories: Bayesian
classifiers and nearest-prototype (Rocchio-style)
classifiers. Bayesian approaches include Markov
processes (Dunning, 1994), naive Bayes methods
(Grefenstette, 1995; Lui and Baldwin, 2011; Tiede-
mann and Ljubeˇsi´c, 2012), and compressive mod-
els (Teahan, 2000). The nearest-prototype methods
vary primarily in the distance measure used, includ-
ing measures based on rank order statistics (Cav-
nar and Trenkle, 1994), information theory (Bald-
win and Lui, 2010a), string kernels (Kruengkrai et
al., 2005) and vector space models (Prager, 1999a;
McNamee, 2005).
Language identification has been applied in do-
mains such as USENET messages (Cavnar and
Trenkle, 1994), web pages (Kikui, 1996; Mar-
tins and Silva, 2005; Liu and Liang, 2008), web
search queries (Ceylan and Kim, 2009; Bosca and
Dini, 2010), mining the web for bilingual text
(Resnik, 1999; Nie et al., 1999), building minor-
ity language corpora (Ghani et al., 2004; Scannell,
2007; Bergsma et al., 2012) as well as a large-
scale database of Interlinear Glossed Text (Xia et al.,
2010), and the construction of a large-scale multilin-
gual web crawl (Callan and Hoy, 2009).
</bodyText>
<subsectionHeader confidence="0.985545">
2.1 Multilingual Documents
</subsectionHeader>
<bodyText confidence="0.999817571428571">
Language identification over documents that contain
text from more than one language has been identified
as an open research question (Hughes et al., 2006).
Common examples of multilingual documents are
web pages that contain excerpts from another lan-
guage, and documents from multilingual organiza-
tions such as the European Union.
</bodyText>
<page confidence="0.997864">
28
</page>
<table confidence="0.294237">
English French Italian German Dutch Japanese
character the pour di auf voo U
byte 74 68 65 20 70 6F 75 7 20 64 69 20 20 61 75 66 76 6F 6 E3 81 AF
</table>
<tableCaption confidence="0.996789">
Table 1: Examples of per-language byte sequences selected by information gain.
</tableCaption>
<bodyText confidence="0.999986313725491">
The Australiasian Language Technology Work-
shop 2010 hosted a shared task where participants
were required to predict the language(s) present in a
held-out test set containing monolingual and bilin-
gual documents (Baldwin and Lui, 2010b). The
dataset was prepared using data from Wikipedia, and
bilingual documents were produced using a segment
from a page in one language, and a segment from the
same page in another language. We use the dataset
from this shared task for our initial experiments.
To the authors’ knowledge, the only other work to
directly tackle identification of multiple languages
and their relative proportions in a single document is
the LINGUINI system (Prager, 1999a). The system
is based on a vector space model, and cosine simi-
larity between a feature vector for the test document
and a feature vector for each language Li, computed
as the sum of feature vectors for all the documents
for language Li in the training data. The elements
in the feature vectors are frequency counts over
byte n-grams (2&lt;n&lt;5) and words. Language iden-
tification for multilingual documents is performed
through the use of virtual mixed languages. Prager
(1999a) shows how to construct vectors representa-
tive of particular combinations of languages inde-
pendent of the relative proportions, and proposes a
method for choosing combinations of languages to
consider for any given document.
Language identification in multilingual docu-
ments could also be performed by application of su-
pervised language segmentation algorithms. Given
a system that can segment a document into la-
beled monolingual segments, we can then extract
the languages present as well as the relative propor-
tion of text in each language. Several methods for
supervised language segmentation have been pro-
posed. Teahan (2000) proposed a system based on
text compression that identifies multilingual docu-
ments by first segmenting the text into monolingual
blocks. Rehurek and Kolkus (2009) perform lan-
guage segmentation by computing a relevance score
between terms and languages, smoothing across ad-
joining terms and finally identifying points of transi-
tion between high and low relevance, which are in-
terpreted as boundaries between languages. Yam-
aguchi and Tanaka-Ishii (2012) use a minimum de-
scription length approach, embedding a compressive
model to compute the description length of text seg-
ments in each language. They present a linear-time
dynamic programming solution to optimize the lo-
cation of segment boundaries and language labels.
</bodyText>
<sectionHeader confidence="0.999165" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.998230538461538">
Language identification for multilingual documents
is a multi-label classification task, in which a doc-
ument can be mapped onto any number of labels
from a closed set. In the remainder of this paper,
we denote the set of all languages by L. We de-
note a document D which contains languages Lx
and Ly as D → {Lx, Ly}, where Lx, Ly E L.
We denote a document that does not contain a lan-
guage Lx by D → {Lx}, though we generally omit
all the languages not contained in the document for
brevity. We denote classifier output using &gt;; e.g.
D &gt; {La, Lb} indicates that document D has been
predicted to contain text in languages La and Lb.
</bodyText>
<subsectionHeader confidence="0.997722">
3.1 Document Representation and Feature
Selection
</subsectionHeader>
<bodyText confidence="0.999995666666667">
We represent each document D as a frequency dis-
tribution over byte n-gram sequences such as those
in Table 1. Each document is converted into a vector
where each entry counts the number of times a par-
ticular byte n-gram is present in the document. This
is analogous to a bag-of-words model, where the vo-
cabulary of “words” is a set of byte sequences that
has been selected to distinguish between languages.
The exact set of features is selected from the
training data using Information Gain (IG), an
information-theoretic metric developed as a split-
ting criterion for decision trees (Quinlan, 1993). IG-
based feature selection combined with a naive Bayes
classifier has been shown to be particularly effective
for language identification (Lui and Baldwin, 2011).
</bodyText>
<page confidence="0.997247">
29
</page>
<subsectionHeader confidence="0.987077">
3.2 Generative Mixture Models
</subsectionHeader>
<bodyText confidence="0.99982">
Generative mixture models are popular for text mod-
eling tasks where a mixture of influences governs the
content of a document, such as in multi-label doc-
ument classification (McCallum, 1999; Ramage et
al., 2009), and topic modeling (Blei et al., 2003).
Such models normally assume full exchangeability
between tokens (i.e. the bag-of-words assumption),
and label each token with a single discrete label.
Multi-label text classification, topic modeling and
our model for language identification in multilingual
documents share the same fundamental representa-
tion of the latent structure of a document. Each la-
bel is modeled with a probability distribution over
tokens, and each document is modeled as a proba-
bilistic mixture of labels. As presented in Griffiths
and Steyvers (2004), the probability of the ith token
(wi) given a set of T labels z1· · ·zT is modeled as:
</bodyText>
<equation confidence="0.998770333333333">
T
P(wi) = E P(wi|zi = j)P(zi = j) (1)
j=1
</equation>
<bodyText confidence="0.999973516129032">
The set of tokens w is the document itself, which
in all cases is observed. In the case of topic model-
ing, the tokens are words and the labels are topics,
and z is latent. Whereas topic modeling is gener-
ally unsupervised, multi-label text classification is
a supervised text modeling task, where the labels
are a set of pre-defined categories (such as RUBBER,
IRON-STEEL, TRADE, etc. in the popular Reuters-
21578 data set (Lewis, 1997)), and the tokens are
individual words in documents. z is still latent, but
constrained in the training data (i.e. documents are
labeled but the individual words are not). Some ap-
proaches to labeling unseen documents require that
z for the training data be inferred, and methods for
doing this include an application of the Expectation-
Maximization (EM) algorithm (McCallum, 1999)
and Labeled LDA (Ramage et al., 2009).
The model that we propose for language identifi-
cation in multilingual documents is similar to multi-
label text classification. In the framework of Equa-
tion 1, each per-token label zi is a language and the
vocabulary of tokens is not given by words but rather
by specific byte sequences (Section 3.1). The key
difference with multi-label text classification is that
we use monolingual (i.e. mono-label) training data.
Hence, z is effectively observed for the training data
(since all tokens must share the same label). To infer
z for unlabeled documents, we utilize a Gibbs sam-
pler, closely related to that proposed by Griffiths and
Steyvers (2004) for LDA. The sampling probability
for a label zi for token w in a document d is:
</bodyText>
<equation confidence="0.999854285714286">
P(zi = j|z−i, w) ∝ φ(w)
j · θ(d) (2)
j
φ(w)
j = P(wi|zi = j, z−i, w−i)
θ(d)
j = P(zi = j|z−i)
</equation>
<bodyText confidence="0.949172333333334">
In the LDA model, θ(d)
j is assumed to have a Dirich-
let distribution with hyperparameter α, and the word
distribution for each topic φ(w)
j is also assumed to
have a Dirichlet distribution with hyperparameter
β. Griffiths (2002) describes a generative model for
LDA where both φ(w)
j and θ(d) jare inferred from
the output of a Gibbs sampler. In our method, we
estimate φ(w) jusing maximum likelihood estima-
tion (MLE) from the training data. Estimating φ(w)
j
through MLE is equivalent to a multinomial Naive
Bayes model (McCallum and Nigam, 1998):
</bodyText>
<equation confidence="0.970897333333333">
j = (3)
nj + Wβ
(.)
</equation>
<bodyText confidence="0.973834210526316">
where n(w)
j is the number of times word w occurs
with label j, and n(.)
j is the total number of words
that occur with label j. By setting β to 1, we obtain
standard Laplacian smoothing. Hence, only
updated at each step in the Gibbs sampler:
where n(d)
−i,j is the number of tokens in document d
that are currently mapped to language j, and n(d)
−i is
the total number of tokens in document d. In both
cases, the current assignment of zi is excluded from
the count. T is the number of languages (i.e. the size
of the label set). For simplicity, we set α to 0. We
note that in the LDA model, α and β influence the
sparsity of the solution, and so it may be possible
to tune these parameters for our model as well. We
leave this as an avenue for further research.
</bodyText>
<equation confidence="0.98535575">
n(w)
j + β
ˆφ(w)
ˆθ(d)
j is
(d)
−i,j + α
ˆθ(d)
j = n
(4)
n(d)
−i + Tα
</equation>
<page confidence="0.986347">
30
</page>
<subsectionHeader confidence="0.9418035">
3.3 Language Identification in Multilingual
Documents
</subsectionHeader>
<bodyText confidence="0.999907967741936">
The model described in Section 3.2 can be used to
compute the most likely distribution to have gen-
erated an unlabeled document over a given set of
languages for which we have monolingual training
data, by letting the set of terms w be the byte n-gram
sequences we selected using per-language informa-
tion gain (Section 3.1), and allowing the labels z to
range over the set of all languages L. Using train-
ing data, we compute ˆφ(w)
j (Equation 3), and then
we infer P(Lj|D) for each Lj E L for the unla-
beled document, by running the Gibbs sampler until
the samples for zi converge and then tabulating zi
over the whole d and normalizing by |d|. Naively,
we could identify the languages present in the doc-
ument by D &gt; {Lx if ](zi = Lx|D)}, but closely-
related languages tend to have similar frequency dis-
tributions over byte n-gram features, and hence it is
likely that some tokens will be incorrectly mapped to
a language that is similar to the “correct” language.
We address this issue by finding the subset of lan-
guages A from the training set L that maximizes
P(A|D) (a similar approach is taken in McCallum
(1999)). Through an application of Bayes’ theorem,
P(A|D) a P(D|A)·P(A), noting that P(D) is a
normalizing constant and can be dropped. We as-
sume that P(A) is constant (i.e. any subset of lan-
guages is equally likely, a reasonable assumption in
the absence of other evidence), and hence maximize
P(D|A). For any given D = w1· · ·wn and A, we
infer P(D|A) from the output of the Gibbs sampler:
</bodyText>
<equation confidence="0.917300666666667">
P(wi|A) (5)
� P(wi|zi = j)P(zi = j) (6)
jEλ
</equation>
<bodyText confidence="0.999984888888889">
where both P(wi|zi = j) and P(zi = j) are esti-
mated by their maximum likelihood estimates.
In practice, exhaustive evaluation of the powerset
of L is prohibitively expensive, and so we greed-
ily approximate the optimal A using Algorithm 1. In
essence, we initially rank all the candidate languages
by computing the most likely distribution over the
full set of candidate languages. Then, for each of
the top-N languages in turn, we consider whether
</bodyText>
<equation confidence="0.917855714285714">
Algorithm 1 DetectLang(L, D)
LN +- top-N z E L by P(z|D)
A +- {Lu}
for each Lt E LN do
A&apos; +- A U Lt
if P(D|A) + t &lt; P(D|A&apos;) then
A +- A&apos;
end if
end for
A +- A \ {Lu}
return D &gt; A
to add it to A. A is initialized with Lu, a dummy
language with a uniform distribution over terms (i.e.
P (w|Lu) = 1
</equation>
<bodyText confidence="0.993506">
|w|). A language is added if it improves
P(D|A) by at least t. The threshold t is required
to suppress the addition of spurious classes. Adding
languages gives the model additional freedom to fit
parameters, and so will generally increase P(D|A).
In the limit case, adding a completely irrelevant lan-
guage will result in no tokens being mapped to the
a language, and so the model will be no worse than
without the language. The threshold t is thus used to
control “how much” improvement is required before
including the new language in A.
</bodyText>
<subsectionHeader confidence="0.993473">
3.4 Benchmark Approaches
</subsectionHeader>
<bodyText confidence="0.9998048">
We compare our approach to two methods for
language identification in multilingual documents:
(1) the virtual mixed languages approach (Prager,
1999a); and (2) the text segmentation approach (Ya-
maguchi and Tanaka-Ishii, 2012).
Prager (1999a) describes LINGUINI, a language
identifier based on the vector-space model com-
monly used in text classification and information re-
trieval. The document representation used by Prager
(1999a) is a vector of counts across a set of charac-
ter sequences. Prager (1999a) selects the feature set
based on a TFIDF-like approach. Terms with occur-
rence count m &lt; n x k are rejected, where m is the
number of times the term occurs in the training data
(the TF component), n is the number of languages in
which the term occurred (the IDF component, where
“document” is replaced with “language”), and k is a
parameter to control the overall number of terms se-
lected. In Prager (1999a), the value of k is reported
to be optimal in the region 0.3 to 0.5. In practice,
</bodyText>
<equation confidence="0.992602">
N
P(D|A) =
i=1
N
i=1
</equation>
<page confidence="0.997901">
31
</page>
<bodyText confidence="0.999149021276596">
the value of k indirectly controls the number of fea-
tures selected. Values of k are not comparable across
datasets as m is not normalized for the size of the
training data, so in this work we do not report the
values of k and instead directly select the top-N fea-
tures, weighted by mn . In LINGUINI, each language
is modeled as a single pseudo-document, obtained
by concatenating all the training data for the given
language. A document is then classified according
to the vector with which it has the smallest angle;
this is implemented by finding the language vector
with the highest cosine with the document vector.
Prager (1999a) also proposes an extension to the
approach to allow identification of bilingual docu-
ments, and suggests how this may be generalized to
any number of languages in a document. The gist
of the method is simple: for any given pair of lan-
guages, the projection of a document vector onto
the hyperplane containing the language vectors of
the two languages gives the mixture proportions of
the two languages that minimizes the angle with the
document vector. Prager (1999a) terms this projec-
tion a virtual mixed language (VML), and shows
how to find the angle between the document vec-
tor and the VML. If this angle is less than that be-
tween the document vector and any individual lan-
guage vector, the document is labeled as bilingual in
the two languages from which the mixed vector was
derived. The practical difficulty presented by this
approach is that exhaustively evaluating all possible
combinations of languages is prohibitively expen-
sive. Prager (1999a) addresses this by arguing that in
multilingual documents, “the individual component
languages will be close to d (the document vector)
– probably closer than most or all other languages”.
Hence, language mixtures are only considered for
combinations of the top m languages.
Prager (1999a) shows how to obtain the mixture
coefficients for bilingual VMLs, arguing that the
process generalizes. Prager (1999b) includes the
coefficients for 3-language VMLs, which are much
more complex than the 2-language variants. Us-
ing a computer algebra system, we verified the an-
alytic forms of the coefficients in the 3-language
VML. We also attempted to obtain an analytic form
for the coefficients in a 4-language VML, but these
were too complex for the computer algebra system
to compute. Thus, our evaluation of the VML ap-
proach proposed by Prager (1999a) is limited to 3-
language VMLs. Neither Prager (1999a) nor Prager
(1999b) include an empirical evaluation over mul-
tilingual documents, so to the best of our knowl-
edge this paper is the first empirical evaluation of
the method on multilingual documents. As no refer-
ence implementation of this method is available, we
have produced our own implementation, which we
have made freely available.1
The other benchmark we consider in this paper is
the method for text segmentation by language pro-
posed by Yamaguchi and Tanaka-Ishii (2012) (here-
after referred to as SEGLANG). The actual task ad-
dressed by Yamaguchi and Tanaka-Ishii (2012) is to
divide a document into monolingual segments. This
is formulated as the task of segmenting a document
D = x1, · · · , x|D |(where xi denotes the ith char-
acter of D and |D |is the length of the document)
by finding a list of boundaries B = [B1, · · · , B|B|]
where each Bi indicates the location of a language
boundary as an offset from the start of the document,
resulting in a list of segments X = [X0, · · · , X|B|].
For each segment Xi, the system predicts Li, the
language associated with the segment, producing a
list of labellings L = [L0, · · · , L|B|], with the con-
straint that adjacent elements in L must differ. Ya-
maguchi and Tanaka-Ishii (2012) solve the problem
of determining X and L for an unlabeled text us-
ing a method based on minimum description length.
They present a dynamic programming solution to
this problem, and analyze a number of parameters
that affect the overall accuracy of the system. Given
this method to determine X and L, it is then triv-
ial to label an unlabeled document according to
D &gt; {Lx if ]Lx E L}, and the length of each seg-
ment in X can then be used to determine the pro-
portions of the document that are in each language.
In this work, we use a reference implementation of
SEGLANG kindly provided to us by the authors.
Using the text segmentation approach of
SEGLANG to detect multilingual documents differs
from LINGUINI and our method primarily in that
LINGUINI and our method fragment the document
into small sequences of bytes, and discard informa-
tion about the relative order of the fragments. This
is in contrast to SEGLANG, where this information
</bodyText>
<footnote confidence="0.987962">
1https://github.com/saffsd/linguini.py
</footnote>
<page confidence="0.979482">
32
</page>
<table confidence="0.999860833333333">
System PM RM FM Pµ Rµ Fµ
Benchmark .497 .467 .464 .833 .826 .829
Winner .718 .703 .699 .932 .931 .932
SEGLANG .801 .810 .784 .866 .946 .905
LINGUINI .616 .535 .513 .713 .688 .700
Our method .753 .771 .748 .945 .922 .933
</table>
<tableCaption confidence="0.995424">
Table 2: Results on the ALTW2010 dataset.
</tableCaption>
<bodyText confidence="0.991311454545455">
“Benchmark” is the benchmark system proposed by
the shared task organizers. “Winner” is the highest-
Fµ system submitted to the shared task.
is utilized in the sequential prediction of labels for
consecutive segments of text, and is thus able to
make better use of the locality of text (since there are
likely to be monolingual blocks of text in any given
multilingual document). The disadvantage of this is
that the underlying model becomes more complex
and hence more computationally expensive, as we
observe in Section 5.
</bodyText>
<subsectionHeader confidence="0.636837">
3.5 Evaluation
</subsectionHeader>
<bodyText confidence="0.990816186046512">
We seek to evaluate the ability of each method:
(1) to correctly identify the language(s) present in
each test document; and (2) for multilingual doc-
uments, to estimate the relative proportion of the
document written in each language. In the first in-
stance, this is a classification problem, and the stan-
dard notions of precision (P), recall (R) and F-score
(F) apply. Consistent with previous work in lan-
guage identification, we report both the document-
level micro-average, as well as the language-level
macro-average. For consistency with Baldwin and
Lui (2010a), the macro-averaged F-score we report
is the average of the per-class F-scores, rather than
the harmonic mean of the macro-averaged precision
and recall; as such, it is possible for the F-score
to not fall between the precision and recall values.
As is common practice, we compute the F-score for
β = 1, giving equal importance to precision and
recall.2 We tested the difference in performance
for statistical significance using an approximate ran-
domization procedure (Yeh, 2000) with 10000 iter-
ations. Within each table of results (Tables 2, 3 and
2Intuitively, it may seem that the maximal precision and re-
call should be achieved when precision and recall are balanced.
However, because of the multi-label nature of the task and vari-
able number of labels assigned to a given document by our mod-
els, it is theoretically possible and indeed common in our results
for the maximal macro-averaged F-score to be achieved when
macro-averaged precision and recall are not balanced.
4), all differences between systems are statistically
significant at a p &lt; 0.05 level.
To evaluate the predictions of the relative propor-
tions of a document D written in each detected lan-
guage Li, we compare the topic proportion predicted
by our model to the gold-standard proportion, mea-
sured as a byte ratio as follows:
length of Li part of D in bytes
gs(Li|D) = (7)
length of D in bytes
We report the correlation between predicted and ac-
tual proportions in terms of Pearson’s r coefficient.
We also report the mean absolute error (MAE) over
all document–language pairs.
</bodyText>
<sectionHeader confidence="0.995934" genericHeader="method">
4 Experiments on ALTW2010
</sectionHeader>
<bodyText confidence="0.9998895">
Our first experiment utilizes the ALTW2010 shared
task dataset (Baldwin and Lui, 2010b), a synthetic
dataset of 10000 bilingual documents3 generated
from Wikipedia data, introduced in the ALTW2010
shared task,4 The dataset is organized into training,
development and test partitions. Following standard
machine learning practice, we train each system us-
ing the training partition, and tune parameters using
the development partition. We then report macro and
micro-averaged precision, recall and F-score on the
test partition, using the tuned parameters.
The results on the ALTW2010 shared task dataset
are summarized in Table 2. Each of the three sys-
tems we compare was re-trained using the training
data provided for the shared task, with a slight dif-
ference: in the shared task, participants were pro-
vided with multilingual training documents, but the
systems targeted in this research require monolin-
gual training data. We thus split the training doc-
uments into monolingual segments using the meta-
data provided with the dataset. The metadata was
only published after completion of the task and was
not available to task participants. For comparison,
we have included the benchmark results published
by the shared task organizers, as well as the score
attained by the winning entry (Tran et al., 2010).
</bodyText>
<footnote confidence="0.976348166666667">
3With a small number of monolingual documents, formed
by randomly selecting the two languages for a given docu-
ment independently, leaving the possibility of the same two lan-
guages being selected.
4http://comp.mq.edu.au/programming/task_
description/
</footnote>
<page confidence="0.999414">
33
</page>
<bodyText confidence="0.999987905660377">
We tune the parameters for each system using the
development partition of the dataset, and report re-
sults on the test partition. For LINGUINI, there is a
single parameter k to be tuned: the number of fea-
tures per language. We tested values between 10000
and 50000, and selected 46000 features as the opti-
mal value. For our method, there are two parameters
to be tuned: (1) the number of features selected for
each language, and (2) the threshold t for including
a language. We tested features-per-language counts
between 30 and 150, and found that adding features
beyond 70 per language had minimal effect. We
tested values of the threshold t from 0.01 to 0.15,
and found the best value was 0.14. For SEGLANG,
we introduce a threshold t on the minimum propor-
tion of a document (measured in bytes) that must
be labeled by a language before that language is in-
cluded in the output set. This was done because our
initial experiments indicate that SEGLANG tends to
over-produce labels. Using the development data,
we found the best value of t was 0.10.
We find that of the three systems tested, two out-
perform the winning entry to the shared task. This
is more evident in the macro-averaged results than
in the micro-averaged results. In micro-averaged
terms, our method is the best performer, whereas
on the macro-average, SEGLANG has the high-
est F-score. This suggests that our method does
well on higher-density languages (relative to the
ALTW2010 dataset), and poorly on lower-density
languages. This also accounts for the higher micro-
averaged precision but lower micro-averaged recall
for our method as compared to SEGLANG. The im-
proved macro-average F-score of SEGLANG comes
at a much higher computational cost, which in-
creases dramatically as the number of languages is
increased. In our testing on a 16-core worksta-
tion, SEGLANG took almost 24 hours to process the
ALTW2010 shared task test data, compared to 2
minutes for our method and 40 seconds for LIN-
GUINI. As such, SEGLANG is poorly suited to de-
tecting multilingual documents where a large num-
ber of candidate languages is considered.
The ALTW2010 dataset is an excellent starting
point for this research, but it predominantly contains
bilingual documents, making it difficult to assess the
ability of systems to distinguish multilingual docu-
ments from monolingual ones. Furthermore, we are
unable to use it to assess the ability of systems to
detect more than 2 languages in a document. To ad-
dress these shortcomings, we construct a new dataset
in a similar vein. The dataset and experiments per-
formed on it are described in the next section.
</bodyText>
<sectionHeader confidence="0.992631" genericHeader="method">
5 Experiments on WIKIPEDIAMULTI
</sectionHeader>
<bodyText confidence="0.999570227272727">
To fully test the capabilities of our model, we gen-
erated WIKIPEDIAMULTI, a dataset that contains
a mixture of monolingual and multilingual docu-
ments. To allow for replicability of our results and
to facilitate research in language identification, we
have made the dataset publicly available.5 WIKI-
PEDIAMULTI is generated using excerpts from the
mediawiki sources of Wikipedia pages downloaded
from the Wikimedia foundation.6 The dumps we
used are from July–August 2010.
To generate WIKIPEDIAMULTI, we first normal-
ized the raw mediawiki documents. Mediawiki doc-
uments typically contain one paragraph per line, in-
terspersed with structural elements. We filtered each
document to remove all structural elements, and
only kept documents that exceeded 2500 bytes after
normalization. This yielded a collection of around
500,000 documents in 156 languages. From this
initial document set (hereafter referred to as WI-
KICONTENT), we only retained languages that had
more than 1000 documents (44 languages), and gen-
erated documents for WIKIPEDIAMULTI as follows:
</bodyText>
<listItem confidence="0.995775">
1. randomly select the number of languages K
(1&lt;K&lt;5)
2. randomly select a set of K languages S =
{LiEL for i = 1· · ·K} without replacement
3. randomly select a document for each LiES
from WIKICONTENT without replacement
4. take the top 1K lines of the document
5. join the K sections into a single document.
</listItem>
<bodyText confidence="0.99995675">
As a result of the procedure, the relative propor-
tion of each language in a multilingual document
tends not to be uniform, as it is conditioned on the
length of the original document from which it was
sourced, independent of the other K −1 for the other
languages that it was combined with. Overall, the
average document length is 5500 bytes (standard de-
viation = 3800 bytes). Due to rounding up in taking
</bodyText>
<footnote confidence="0.999971">
5http://www.csse.unimelb.edu.au/˜tim/
6http://dumps.wikimedia.org
</footnote>
<page confidence="0.995238">
34
</page>
<table confidence="0.999542">
System PM RM FM Pµ Rµ Fµ
SEGLANG .809 .975 .875 .771 .975 .861
LINGUINI .853 .772 .802 .838 .774 .805
Our method .962 .954 .957 .963 .955 .959
</table>
<tableCaption confidence="0.999941">
Table 3: Results on the WIKIPEDIAMULTI dataset.
</tableCaption>
<bodyText confidence="0.999865272727273">
the top 1 lines (step 4), documents with higher K
tend to be longer (6200 bytes for K = 5 vs 5100
bytes for K = 1).
The WIKIPEDIAMULTI dataset contains training,
development and test partitions. The training parti-
tion consists of 5000 monolingual (i.e. K = 1) doc-
uments. The development partition consists of 5000
documents, 1000 documents for each value of K
where 1≤K≤5. The test partition contains 200 doc-
uments for each K, for a total of 1000 documents.
There is no overlap between any of the partitions.
</bodyText>
<subsectionHeader confidence="0.777056">
5.1 Results over WIKIPEDIAMULTI
</subsectionHeader>
<bodyText confidence="0.999992918918919">
We trained each system using the monolingual train-
ing partition, and tuned parameters using the devel-
opment partition. For LINGUINI, we tested feature
counts between 10000 and 50000, and found that
the effect was relatively small. We thus use 10000
features as the optimum value. For SEGLANG, we
tested values for threshold t between 0.01 and 0.20,
and found that the maximal macro-averaged F-score
is attained when t = 0.06. Finally, for our method
we tested features-per-language counts between 30
and 130 and found the best performance with 120
features per language, although the actual effect of
varying this value is rather small. We tested values
of the threshold t for adding an extra language to
A from 0.01 to 0.15, and found that the best results
were attained when t = 0.02.
The results of evaluating each system on the
test partition are summarized in Table 3. In this
evaluation, our method clearly outperforms both
SEGLANG and LINGUINI. The results on WIKI-
PEDIAMULTI and ALTW2010 are difficult to com-
pare directly due to the different compositions of the
two datasets. ALTW2010 is predominantly bilin-
gual, whereas WIKIPEDIAMULTI contains docu-
ments with text in 1–5 languages. Furthermore, the
average document in ALTW2010 is half the length
of that in WIKIPEDIAMULTI. Overall, we observe
that SEGLANG has a tendency to over-label (despite
the introduction of the t parameter to reduce this ef-
fect), evidenced by high recall but lower precision.
LINGUINI is inherently limited in that it is only able
to detect up to 3 languages per document, causing
recall to suffer on WIKIPEDIAMULTI. However, it
also tends to always output 3 languages, regardless
of the actual number of languages in the document,
hurting precision. Furthermore, even on ALTW2010
it has lower recall than the other two systems.
</bodyText>
<sectionHeader confidence="0.923187" genericHeader="method">
6 Estimating Language Proportions
</sectionHeader>
<bodyText confidence="0.999990378378378">
In addition to detecting multiple languages within
a document, our method also estimates the relative
proportions of the document that are written in each
language. This information may be useful for detect-
ing documents that are candidate bitexts for training
machine translation systems, since we may expect
languages in the document to be present in equal
proportions. It also allows us to identify the pre-
dominant language of a document.
A core element of our model of a document is
a distribution over a set of labels. Since each la-
bel corresponds to a language, as a first approxima-
tion, we take the probability mass associated with
each label as a direct estimate of the proportion of
the document written in that language. We examine
the results for predicting the language proportions
in the test partition of WIKIPEDIAMULTI. Mapping
label distributions directly to language proportions
produces excellent results, with a Pearson’s r value
of 0.863 and an MAE of 0.108.
Although labels have a one-to-one correspon-
dence with languages, the label distribution does
not actually correspond directly to the language pro-
portion, because the distribution estimates the pro-
portion of byte n-gram sequences associated with
a label and not the proportion of bytes directly.
The same number of bytes in different languages
can produce different numbers of n-gram sequences,
because after feature selection not all n-gram se-
quences are retained in the feature set. Hereafter,
we refer to each n-gram sequence as a token, and the
average number of tokens produced per byte of text
as the token emission rate.
We estimate the per-language token emission rate
(Figure 1) using the training partition of WIKIPE-
DIAMULTI. To improve our estimate of the lan-
guage proportions, we correct our label distribution
</bodyText>
<page confidence="0.99569">
35
</page>
<figure confidence="0.817549">
Original text the cat in the hat
Emission rate #bytes = 18 _ 1.5 b tes/token
#tokens 12 — Y
</figure>
<figureCaption confidence="0.879784">
Figure 1: Example of calculating n-gram emission
rate for a text string.
</figureCaption>
<bodyText confidence="0.9736918">
using estimates of the per-language token emission
rate RLi in bytes per token for LiEL. Assume that
a document D of length |D |is estimated to contain
K languages in proportions Pi for i = 1· · ·K. The
corrected estimate for the proportion of Li is:
</bodyText>
<equation confidence="0.996698">
Prop(Li) = KPi x RLi (8)
EK
(Pj x RLj)
</equation>
<bodyText confidence="0.999987625">
Note that the |D |term is common to the numerator
and denominator and has thus been eliminated.
This correction improves our estimates of lan-
guage proportions. After correction, the Pearson’s
r rises to 0.981, and the MAE is reduced to 0.024.
The improvement is most noticeable for language–
document pairs where the proportion of the docu-
ment in the given language is about 0.5 (Figure 2).
</bodyText>
<sectionHeader confidence="0.959904" genericHeader="method">
7 Real-world Multilingual Documents
</sectionHeader>
<bodyText confidence="0.999991333333334">
So far, we have demonstrated the effectiveness of
our proposed approach using synthetic data. The
results have been excellent, and in this section we
validate the approach by applying it to a real-world
task that has recently been discussed in the lit-
erature. Yamaguchi and Tanaka-Ishii (2012) and
King and Abney (2013) both observe that in trying
to gather linguistic data for “non-major” languages
from the web, one challenge faced is that documents
retrieved often contain sections in another language.
SEGLANG (the solution of Yamaguchi and Tanaka-
Ishii (2012)) concurrently detects multilingual doc-
uments and segments them by language, but the ap-
proach is computationally expensive and has a ten-
dency to over-label (Section 5). On the other hand,
the solution of King and Abney (2013) is incom-
plete, and they specifically mention the need for an
automatic method “to examine a multilingual docu-
ment, and with high accuracy, list the languages that
are present in the document”. In this section, we
show that our method is able to fill this need. We
</bodyText>
<table confidence="0.9997474">
System P R F
Baseline 0.719 1.00 0.837
SEGLANG 0.779 0.991 0.872
LINGUINI 0.729 0.981 0.837
Our method 0.907 0.916 0.912
</table>
<tableCaption confidence="0.915985">
Table 4: Detection accuracy for English-language
inclusion in web documents from targeted web
crawls for low-density languages.
</tableCaption>
<bodyText confidence="0.961220525">
make use of manually-annotated data kindly pro-
vided to us by Ben King, which consists of 149 doc-
uments containing 42 languages retrieved from the
web using a set of targeted queries for low-density
languages. Note that the dataset described in King
and Abney (2013) was based on manual confirma-
tion of the presence of English in addition to the low-
density language of primary interest; our dataset
contains these bilingual documents as well as mono-
lingual documents in the low-density language of in-
terest. Our purpose in this section is to investigate
the ability of automatic systems to select this subset
of bilingual documents. Specifically, given a col-
lection of documents retrieved for a target language,
the task is to identify the documents that contain text
in English in addition to the target language. Thus,
we re-train each system for each target language, us-
ing only training data for English and the target lan-
guage. We reserve the data provided by Ben King
for evaluation, and train our methods using data sep-
arately obtained from the Universal Declaration of
Human Rights (UDHR). Where UDHR translations
for a particular language were not available, we used
data from Wikipedia or from a bible translation. Ap-
proximately 20–80 kB of data were used for each
language. As we do not have suitable development
data, we made use of the best parameters for each
system from the experiments on WIKIPEDIAMULTI.
We find that all 3 systems are able to detect that
each document contains the target language with
100% accuracy. However, systems vary in their abil-
ity to detect if a document also contains English in
addition to the target language. The detection accu-
racy for English-language inclusion is summarized
in Table 4.7 For comparison, we include a heuristic
baseline based on labeling all documents as contain-
7Note that Table 2 and Table 3 both report macro and micro-
averaged results across a number of languages. In contrast Ta-
ble 4 only reports results for English, and the values are not
directly comparable to our earlier evaluation.
</bodyText>
<equation confidence="0.593119">
he : 2 the : 2
hat : 1 in : 1
th : 1 the : 1
hat : 1 he c : 1
in t : 1 n th : 1
n-gram features
I
I
</equation>
<page confidence="0.383754">
36
</page>
<figure confidence="0.999631772727273">
Predicted Proportion
Predicted Proportion
0.2 0.4 0.6 0.8 1.0
Actual Proportion
(a) without emission rate correction
0.2 0.4 0.6 0.8 1.0
Actual Proportion
(b) with emission rate correction
1.0
0.8
0.6
0.4
0.2
Pearson&apos;s r: 0.863
MAE: 0.108
1.0
0.8
0.6
0.4
0.2
Pearson&apos;s r: 0.981
MAE: 0.0241
</figure>
<figureCaption confidence="0.9769755">
Figure 2: Scatterplot of the predicted vs. actual language proportions in a document for the test partition of
WIKIPEDIAMULTI (predictions are from our method; each point corresponds to a document-language pair).
</figureCaption>
<bodyText confidence="0.997953727272727">
ing English. We find that, like the heuristic base-
line, SEGLANG and LINGUINI both tend to over-
label documents, producing false positive labels of
English, resulting in increased recall at the expense
of precision. Our method produces less false pos-
itives (but slightly more false negatives). Overall,
our method attains the best .F for detecting En-
glish inclusions. Manual error analysis suggests that
the false negatives for our method generally occur
where a relatively small proportion of the document
is written in English.
</bodyText>
<sectionHeader confidence="0.999662" genericHeader="method">
8 Future Work
</sectionHeader>
<bodyText confidence="0.99998556">
Document segmentation by language could be ac-
complished by a combination of our method and the
method of King and Abney (2013), which could be
compared to the method of Yamaguchi and Tanaka-
Ishii (2012) in the context of constructing corpora
for low-density languages using the web. Another
area we have identified in this paper is the tuning
of the parameters α and 0 in our model (currently
α = 0 and 0 = 1), which may have some effect on
the sparsity of the model.
Further work is required in dealing with cross-
domain effects, to allow for “off-the-shelf” language
identification in multilingual documents. Previous
work has shown that it is possible to generate a docu-
ment representation that is robust to variation across
domains (Lui and Baldwin, 2011), and we intend to
investigate if these results are also applicable to lan-
guage identification in multilingual documents. An-
other open question is the extension of the genera-
tive mixture models to “unknown” language identi-
fication (i.e. eliminating the closed-world assump-
tion (Hughes et al., 2006)), which may be possible
through the use of non-parametric mixture models
such as Hierarchical Dirichlet Processes (Teh et al.,
2006).
</bodyText>
<sectionHeader confidence="0.99764" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999878222222222">
We have presented a system for language identifi-
cation in multilingual documents using a generative
mixture model inspired by supervised topic model-
ing algorithms, combined with a document represen-
tation based on previous research in language iden-
tification for monolingual documents. We showed
that the system outperforms alternative approaches
from the literature on synthetic data, as well as on
real-world data from related research on linguistic
corpus creation for low-density languages using the
web as a resource. We also showed that our system
is able to accurately estimate the proportion of the
document written in each of the languages identi-
fied. We have made a full reference implementation
of our system freely available,8 as well as the syn-
thetic dataset prepared for this paper (Section 5), in
order to facilitate the adoption of this technology and
further research in this area.
</bodyText>
<footnote confidence="0.963297">
8https://github.com/saffsd/polyglot
</footnote>
<page confidence="0.999335">
37
</page>
<sectionHeader confidence="0.999215" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999913636363636">
We thank Hiroshi Yamaguchi for making a reference
implementation of SEGLANG available to us, and
Ben King for providing us with a collection of real-
world multilingual web documents. This work was
substantially improved as a result of the insightful
feedback received from the reviewers.
NICTA is funded by the Australian Government
as represented by the Department of Broadband,
Communications and the Digital Economy and the
Australian Research Council through the ICT Cen-
tre of Excellence program.
</bodyText>
<sectionHeader confidence="0.999352" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999444102272727">
Steven Abney and Steven Bird. 2010. The human
language project: building a universal corpus of the
world’s languages. In Proceedings of the 48th Annual
Meeting of the Association for Computational Linguis-
tics, pages 88–97. Association for Computational Lin-
guistics.
Beatrice Alex, Amit Dubey, and Frank Keller. 2007.
Using foreign inclusion detection to improve parsing
performance. In Proceedings of the Joint Conference
on Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
2007 (EMNLP-CoNLL 2007), pages 151–160, Prague,
Czech Republic.
Timothy Baldwin and Marco Lui. 2010a. Language
identification: The long and the short of the matter. In
Proceedings of Human Language Technologies: The
11th Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL HLT 2010), pages 229–237, Los Angeles,
USA.
Timothy Baldwin and Marco Lui. 2010b. Multilin-
gual language identification: ALTW 2010 shared task
dataset. In Proceedings of the Australasian Language
Technology Workshop 2010 (ALTW 2010), pages 5–7,
Melbourne, Australia.
Shane Bergsma, Paul McNamee, Mossaab Bagdouri,
Clayton Fink, and Theresa Wilson. 2012. Language
identification for creating language-specific Twitter
collections. In Proceedings the Second Workshop on
Language in Social Media (LSM2012), pages 65–74,
Montr´eal, Canada.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet allocation. Journal of Machine
Learning Research, 3:993–1022.
Alessio Bosca and Luca Dini. 2010. Language identi-
fication strategies for cross language information re-
trieval. In Working Notes of the Cross Language Eval-
uation Forum (CLEF).
Jamie Callan and Mark Hoy, 2009. ClueWeb09
Dataset. Availableathttp://boston.lti.cs.
cmu.edu/Data/clueweb09/.
William B. Cavnar and John M. Trenkle. 1994. N-
gram-based text categorization. In Proceedings of the
Third Symposium on Document Analysis and Informa-
tion Retrieval, pages 161–175, Las Vegas, USA.
Hakan Ceylan and Yookyung Kim. 2009. Language
identification of search engine queries. In Proceedings
of the Joint Conference of the 47th Annual Meeting
of the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP, pages
1066–1074, Singapore.
Paul Cook and Marco Lui. 2012. langid.py for bet-
ter language modelling. In Proceedings of the Aus-
tralasian Language Technology Association Workshop
2012, pages 107–112, Dunedin, New Zealand.
Rafael Dueire Lins and Paulo Gonc¸alves. 2004. Au-
tomatic language identification of written texts. In
Proceedings of the 2004 ACM Symposium on Applied
Computing (SAC 2004), pages 1128–1133, Nicosia,
Cyprus.
Ted Dunning. 1994. Statistical identification of lan-
guage. Technical Report MCCS 940-273, Computing
Research Laboratory, New Mexico State University.
Rayid Ghani, Rosie Jones, and Dunja Mladenic. 2004.
Building minority language corpora by learning to
generate web search queries. Knowledge and Infor-
mation Systems, 7(1):56–83.
Emmanuel Giguet. 1995. Categorisation according to
language: A step toward combining linguistic knowl-
edge and statistical learning. In Proceedings of the
4th International Workshop on Parsing Technologies
(IWPT-1995), Prague, Czech Republic.
Gregory Grefenstette. 1995. Comparing two language
identification schemes. In Proceedings of Analisi
Statistica dei Dati Testuali (JADT), pages 263–268,
Rome, Italy.
Thomas L. Griffiths and Mark Steyvers. 2004. Find-
ing scientific topics. Proceedings of the National
Academy of Sciences, 101:5228–5235.
Thomas Griffiths. 2002. Gibbs sampling in the gener-
ative model of latent Dirichlet allocation. Technical
Report, Stanford University.
Baden Hughes, Timothy Baldwin, Steven Bird, Jeremy
Nicholson, and Andrew MacKinlay. 2006. Recon-
sidering language identification for written language
resources. In Proceedings of the 5th International
Conference on Language Resources and Evaluation
(LREC 2006), pages 485–488, Genoa, Italy.
</reference>
<page confidence="0.985583">
38
</page>
<reference confidence="0.999588555555555">
Genitiro Kikui. 1996. Identifying the coding system
and language of on-line documents on the internet. In
Proceedings of the 16th International Conference on
Computational Linguistics (COLING ’96), pages 652–
657, Kyoto, Japan.
Ben King and Steven Abney. 2013. Labeling the lan-
guages of words in mixed-language documents using
weakly supervised methods. In Proceedings of the
2013 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies, pages 1110–1119, At-
lanta, Georgia.
Canasai Kruengkrai, Prapass Srichaivattana, Virach
Sornlertlamvanich, and Hitoshi Isahara. 2005. Lan-
guage identification based on string kernels. In Pro-
ceedings of the 5th International Symposium on Com-
munications and Information Technologies (ISCIT-
2005), pages 896–899, Beijing, China.
David D. Lewis. 1997. The Reuters-21578 data set.
available at http://www.daviddlewis.
com/resources/testcollections/
reuters21578/.
Wang Ling, Guang Xiang, Chris Dyer, Alan Black, and
Isabel Trancoso. 2013. Microblogs as parallel cor-
pora. In Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (Volume 1:
Long Papers), pages 176–186, Sofia, Bulgaria, Au-
gust. Association for Computational Linguistics.
Jicheng Liu and Chunyan Liang. 2008. Text Categoriza-
tion of Multilingual Web Pages in Specific Domain.
In Proceedings of the 12th Pacific-Asia Conference on
Advances in Knowledge Discovery and Data Mining,
PAKDD’08, pages 938–944, Osaka, Japan.
Marco Lui and Timothy Baldwin. 2011. Cross-domain
feature selection for language identification. In Pro-
ceedings of the 5th International Joint Conference on
Natural Language Processing (IJCNLP 2011), pages
553–561, Chiang Mai, Thailand.
Bruno Martins and M´ario J. Silva. 2005. Language iden-
tification in web pages. In Proceedings of the 2005
ACM symposium on Applied computing, pages 764–
768, Santa Fe, USA.
Andrew McCallum and Kamal Nigam. 1998. A com-
parison of event models for Naive Bayes text classifi-
cation. In Proceedings of the AAAI-98 Workshop on
Learning for Text Categorization, pages Available as
Technical Report WS–98–05, AAAI Press., Madison,
USA.
Andrew Kachites McCallum. 1999. Multi-label text
classification with a mixture model trained by EM. In
Proceedings of AAAI 99 Workshop on Text Learning.
Paul McNamee. 2005. Language identification: a solved
problem suitable for undergraduate instruction. Jour-
nal of Computing Sciences in Colleges, 20(3):94–101.
Jian-Yun Nie, Michel Simard, Pierre Isabelle, and
Richard Durand. 1999. Cross-language information
retrieval based on parallel texts and automatic min-
ing of parallel texts from the web. In Proceedings
of 22nd International ACM-SIGIR Conference on Re-
search and Development in Information Retrieval (SI-
GIR’99), pages 74–81, Berkeley, USA.
John M. Prager. 1999a. Linguini: language identification
for multilingual documents. In Proceedings the 32nd
Annual Hawaii International Conference on Systems
Sciences (HICSS-32), Maui, Hawaii.
John M. Prager. 1999b. Linguini: Language identifica-
tion for multilingual documents. Journal of Manage-
ment Information Systems, 16(3):71–101.
John Ross Quinlan. 1993. C4.5: Programs for Machine
Learning. Morgan Kaufmann, San Mateo, USA.
Daniel Ramage, David Hall, Ramesh Nallapati, and
Christopher D. Manning. 2009. Labeled LDA: A
supervised topic model for credit attribution in multi-
labeled corpora. In Proceedings of the 2009 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP 2009), pages 248–256, Singapore.
Radim Rehurek and Milan Kolkus. 2009. Language
Identification on the Web: Extending the Dictionary
Method. In Proceedings of Computational Linguis-
tics and Intelligent Text Processing, 10th International
Conference (CICLing 2009), pages 357–368, Mexico
City, Mexico.
Philip Resnik. 1999. Mining the Web for bilingual text.
In Proceedings of the 37th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 527–534,
College Park, USA.
Kevin P Scannell. 2007. The Cr´ubad´an Project: Cor-
pus building for under-resourced languages. In Build-
ing and Exploring Web Corpora: Proceedings of the
3rd Web as Corpus Workshop, pages 5–15, Louvain-
la-Neuve, Belgium.
W. J. Teahan. 2000. Text Classification and Seg-
mentation Using Minimum Cross-Entropy. In Pro-
ceedings the 6th International Conference “Recherche
d’Information Assistee par Ordinateur” (RIAO’00),
pages 943–961, Paris, France.
Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and
David M. Blei. 2006. Hierarchical Dirichlet pro-
cesses. Journal of the American Statistical Associa-
tion, 101:1566–1581.
J¨org Tiedemann and Nikola Ljubeˇsi´c. 2012. Efficient
discrimination between closely related languages. In
Proceedings of the 24th International Conference on
Computational Linguistics (COLING 2012), pages
2619–2634, Mumbai, India.
Giang Binh Tran, Dat Ba Nguyen, and Bin Thanh
Kieu. 2010. N-gram based approach for mul-
tilingual language identification. poster. available
</reference>
<page confidence="0.988389">
39
</page>
<reference confidence="0.997781625">
at http://comp.mq.edu.au/programming/
task_description/VILangTek.pdf.
Fei Xia, Carrie Lewis, and William D. Lewis. 2010. Lan-
guage ID for a thousand languages. In LSA Annual
Meeting Extended Abstracts, Baltimore,USA.
Hiroshi Yamaguchi and Kumiko Tanaka-Ishii. 2012.
Text segmentation by language using minimum de-
scription length. In Proceedings the 50th Annual
Meeting of the Association for Computational Linguis-
tics (Volume 1: Long Papers), pages 969–978, Jeju Is-
land, Korea.
Alexander Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In Proceed-
ings of the 18th International Conference on Compu-
tational Linguistics (COLING 2000), pages 947–953,
Saarbr¨ucken, Germany.
</reference>
<page confidence="0.998634">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.443302">
<title confidence="0.999864">Automatic Detection and Language Identification of Multilingual Documents</title>
<author confidence="0.998051">Jey Han</author>
<author confidence="0.998051">Timothy</author>
<affiliation confidence="0.9071006">of Computing and Information The University of Melbourne Victoria Research Laboratory of King’s College London</affiliation>
<email confidence="0.983648">mhlui@unimelb.edu.au,jeyhan.lau@gmail.com,tb@ldwin.net</email>
<abstract confidence="0.98109">Language identification is the task of automatically detecting the language(s) present in a document based on the content of the document. In this work, we address the problem of detecting documents that contain text from than one language documents). We introduce a method that is able to detect that a document is multilingual, identify the languages present, and estimate their relative proportions. We demonstrate the effectiveness of our method over synthetic data, as well as real-world multilingual documents collected from the web.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
<author>Steven Bird</author>
</authors>
<title>The human language project: building a universal corpus of the world’s languages.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>88--97</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2224" citStr="Abney and Bird, 2010" startWordPosition="335" endWordPosition="338">nd estimates the proportion of the document that is written in each language. Detecting multilingual documents has a variety of applications. Most natural language processing techniques presuppose monolingual input data, so inclusion of data in foreign languages introduces noise, and can degrade the performance of NLP systems (Alex et al., 2007; Cook and Lui, 2012). Automatic detection of multilingual documents can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and another language such as English (Yamaguchi and Tanaka-Ishii, 2012; King and Abney, 2013). King and Abney (2013, p1118) specifically mention the need for an automatic method “to examine a multilingual document, and with high accuracy, list the languages that are present in the</context>
</contexts>
<marker>Abney, Bird, 2010</marker>
<rawString>Steven Abney and Steven Bird. 2010. The human language project: building a universal corpus of the world’s languages. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 88–97. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beatrice Alex</author>
<author>Amit Dubey</author>
<author>Frank Keller</author>
</authors>
<title>Using foreign inclusion detection to improve parsing performance.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>151--160</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="1949" citStr="Alex et al., 2007" startWordPosition="292" endWordPosition="295">In this work, we remove this monolingual assumption, and address the problem of language identification in documents that may contain text from more than one language from the candidate set. We propose a method that concurrently detects that a document is multilingual, and estimates the proportion of the document that is written in each language. Detecting multilingual documents has a variety of applications. Most natural language processing techniques presuppose monolingual input data, so inclusion of data in foreign languages introduces noise, and can degrade the performance of NLP systems (Alex et al., 2007; Cook and Lui, 2012). Automatic detection of multilingual documents can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and an</context>
</contexts>
<marker>Alex, Dubey, Keller, 2007</marker>
<rawString>Beatrice Alex, Amit Dubey, and Frank Keller. 2007. Using foreign inclusion detection to improve parsing performance. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning 2007 (EMNLP-CoNLL 2007), pages 151–160, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Marco Lui</author>
</authors>
<title>Language identification: The long and the short of the matter.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010),</booktitle>
<pages>229--237</pages>
<location>Los Angeles, USA.</location>
<contexts>
<context position="5427" citStr="Baldwin and Lui, 2010" startWordPosition="837" endWordPosition="840">) we show that our method is able to identify multilingual documents in real-world data. 2 Background Most language identification research focuses on language identification for monolingual documents (Hughes et al., 2006). In monolingual LangID, the task is to assign each document D a unique language Li ∈ L. Some work has reported near-perfect accuracy for language identification of large documents in a small number of languages (Cavnar and Trenkle, 1994; McNamee, 2005). However, in order to attain such accuracy, a large number of simplifying assumptions have to be made (Hughes et al., 2006; Baldwin and Lui, 2010a). In this work, we tackle the assumption that each document is monolingual, i.e. it contains text from a single language. In language identification, documents are modeled as a stream of characters (Cavnar and Trenkle, 1994; Kikui, 1996), often approximated by the corresponding stream of bytes (Kruengkrai et al., 2005; Baldwin and Lui, 2010a) for robustness over variable character encodings. In this work, we follow Baldwin and Lui (2010a) in training a single model for languages that naturally use multiple encodings (e.g. UTF8, Big5 and GB encodings for Chinese), as issues of encoding are no</context>
<context position="7155" citStr="Baldwin and Lui, 2010" startWordPosition="1091" endWordPosition="1095">e, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construc</context>
<context position="8644" citStr="Baldwin and Lui, 2010" startWordPosition="1338" endWordPosition="1341"> of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as the European Union. 28 English French Italian German Dutch Japanese character the pour di auf voo U byte 74 68 65 20 70 6F 75 7 20 64 69 20 20 61 75 66 76 6F 6 E3 81 AF Table 1: Examples of per-language byte sequences selected by information gain. The Australiasian Language Technology Workshop 2010 hosted a shared task where participants were required to predict the language(s) present in a held-out test set containing monolingual and bilingual documents (Baldwin and Lui, 2010b). The dataset was prepared using data from Wikipedia, and bilingual documents were produced using a segment from a page in one language, and a segment from the same page in another language. We use the dataset from this shared task for our initial experiments. To the authors’ knowledge, the only other work to directly tackle identification of multiple languages and their relative proportions in a single document is the LINGUINI system (Prager, 1999a). The system is based on a vector space model, and cosine similarity between a feature vector for the test document and a feature vector for eac</context>
<context position="26395" citStr="Baldwin and Lui (2010" startWordPosition="4404" endWordPosition="4407">ally expensive, as we observe in Section 5. 3.5 Evaluation We seek to evaluate the ability of each method: (1) to correctly identify the language(s) present in each test document; and (2) for multilingual documents, to estimate the relative proportion of the document written in each language. In the first instance, this is a classification problem, and the standard notions of precision (P), recall (R) and F-score (F) apply. Consistent with previous work in language identification, we report both the documentlevel micro-average, as well as the language-level macro-average. For consistency with Baldwin and Lui (2010a), the macro-averaged F-score we report is the average of the per-class F-scores, rather than the harmonic mean of the macro-averaged precision and recall; as such, it is possible for the F-score to not fall between the precision and recall values. As is common practice, we compute the F-score for β = 1, giving equal importance to precision and recall.2 We tested the difference in performance for statistical significance using an approximate randomization procedure (Yeh, 2000) with 10000 iterations. Within each table of results (Tables 2, 3 and 2Intuitively, it may seem that the maximal preci</context>
<context position="28058" citStr="Baldwin and Lui, 2010" startWordPosition="4679" endWordPosition="4682">nt at a p &lt; 0.05 level. To evaluate the predictions of the relative proportions of a document D written in each detected language Li, we compare the topic proportion predicted by our model to the gold-standard proportion, measured as a byte ratio as follows: length of Li part of D in bytes gs(Li|D) = (7) length of D in bytes We report the correlation between predicted and actual proportions in terms of Pearson’s r coefficient. We also report the mean absolute error (MAE) over all document–language pairs. 4 Experiments on ALTW2010 Our first experiment utilizes the ALTW2010 shared task dataset (Baldwin and Lui, 2010b), a synthetic dataset of 10000 bilingual documents3 generated from Wikipedia data, introduced in the ALTW2010 shared task,4 The dataset is organized into training, development and test partitions. Following standard machine learning practice, we train each system using the training partition, and tune parameters using the development partition. We then report macro and micro-averaged precision, recall and F-score on the test partition, using the tuned parameters. The results on the ALTW2010 shared task dataset are summarized in Table 2. Each of the three systems we compare was re-trained usi</context>
</contexts>
<marker>Baldwin, Lui, 2010</marker>
<rawString>Timothy Baldwin and Marco Lui. 2010a. Language identification: The long and the short of the matter. In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010), pages 229–237, Los Angeles, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Marco Lui</author>
</authors>
<title>Multilingual language identification: ALTW</title>
<date>2010</date>
<booktitle>In Proceedings of the Australasian Language Technology Workshop</booktitle>
<pages>5--7</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="5427" citStr="Baldwin and Lui, 2010" startWordPosition="837" endWordPosition="840">) we show that our method is able to identify multilingual documents in real-world data. 2 Background Most language identification research focuses on language identification for monolingual documents (Hughes et al., 2006). In monolingual LangID, the task is to assign each document D a unique language Li ∈ L. Some work has reported near-perfect accuracy for language identification of large documents in a small number of languages (Cavnar and Trenkle, 1994; McNamee, 2005). However, in order to attain such accuracy, a large number of simplifying assumptions have to be made (Hughes et al., 2006; Baldwin and Lui, 2010a). In this work, we tackle the assumption that each document is monolingual, i.e. it contains text from a single language. In language identification, documents are modeled as a stream of characters (Cavnar and Trenkle, 1994; Kikui, 1996), often approximated by the corresponding stream of bytes (Kruengkrai et al., 2005; Baldwin and Lui, 2010a) for robustness over variable character encodings. In this work, we follow Baldwin and Lui (2010a) in training a single model for languages that naturally use multiple encodings (e.g. UTF8, Big5 and GB encodings for Chinese), as issues of encoding are no</context>
<context position="7155" citStr="Baldwin and Lui, 2010" startWordPosition="1091" endWordPosition="1095">e, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construc</context>
<context position="8644" citStr="Baldwin and Lui, 2010" startWordPosition="1338" endWordPosition="1341"> of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as the European Union. 28 English French Italian German Dutch Japanese character the pour di auf voo U byte 74 68 65 20 70 6F 75 7 20 64 69 20 20 61 75 66 76 6F 6 E3 81 AF Table 1: Examples of per-language byte sequences selected by information gain. The Australiasian Language Technology Workshop 2010 hosted a shared task where participants were required to predict the language(s) present in a held-out test set containing monolingual and bilingual documents (Baldwin and Lui, 2010b). The dataset was prepared using data from Wikipedia, and bilingual documents were produced using a segment from a page in one language, and a segment from the same page in another language. We use the dataset from this shared task for our initial experiments. To the authors’ knowledge, the only other work to directly tackle identification of multiple languages and their relative proportions in a single document is the LINGUINI system (Prager, 1999a). The system is based on a vector space model, and cosine similarity between a feature vector for the test document and a feature vector for eac</context>
<context position="26395" citStr="Baldwin and Lui (2010" startWordPosition="4404" endWordPosition="4407">ally expensive, as we observe in Section 5. 3.5 Evaluation We seek to evaluate the ability of each method: (1) to correctly identify the language(s) present in each test document; and (2) for multilingual documents, to estimate the relative proportion of the document written in each language. In the first instance, this is a classification problem, and the standard notions of precision (P), recall (R) and F-score (F) apply. Consistent with previous work in language identification, we report both the documentlevel micro-average, as well as the language-level macro-average. For consistency with Baldwin and Lui (2010a), the macro-averaged F-score we report is the average of the per-class F-scores, rather than the harmonic mean of the macro-averaged precision and recall; as such, it is possible for the F-score to not fall between the precision and recall values. As is common practice, we compute the F-score for β = 1, giving equal importance to precision and recall.2 We tested the difference in performance for statistical significance using an approximate randomization procedure (Yeh, 2000) with 10000 iterations. Within each table of results (Tables 2, 3 and 2Intuitively, it may seem that the maximal preci</context>
<context position="28058" citStr="Baldwin and Lui, 2010" startWordPosition="4679" endWordPosition="4682">nt at a p &lt; 0.05 level. To evaluate the predictions of the relative proportions of a document D written in each detected language Li, we compare the topic proportion predicted by our model to the gold-standard proportion, measured as a byte ratio as follows: length of Li part of D in bytes gs(Li|D) = (7) length of D in bytes We report the correlation between predicted and actual proportions in terms of Pearson’s r coefficient. We also report the mean absolute error (MAE) over all document–language pairs. 4 Experiments on ALTW2010 Our first experiment utilizes the ALTW2010 shared task dataset (Baldwin and Lui, 2010b), a synthetic dataset of 10000 bilingual documents3 generated from Wikipedia data, introduced in the ALTW2010 shared task,4 The dataset is organized into training, development and test partitions. Following standard machine learning practice, we train each system using the training partition, and tune parameters using the development partition. We then report macro and micro-averaged precision, recall and F-score on the test partition, using the tuned parameters. The results on the ALTW2010 shared task dataset are summarized in Table 2. Each of the three systems we compare was re-trained usi</context>
</contexts>
<marker>Baldwin, Lui, 2010</marker>
<rawString>Timothy Baldwin and Marco Lui. 2010b. Multilingual language identification: ALTW 2010 shared task dataset. In Proceedings of the Australasian Language Technology Workshop 2010 (ALTW 2010), pages 5–7, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shane Bergsma</author>
<author>Paul McNamee</author>
<author>Mossaab Bagdouri</author>
<author>Clayton Fink</author>
<author>Theresa Wilson</author>
</authors>
<title>Language identification for creating language-specific Twitter collections.</title>
<date>2012</date>
<booktitle>In Proceedings the Second Workshop on Language in Social Media (LSM2012),</booktitle>
<pages>65--74</pages>
<location>Montr´eal, Canada.</location>
<contexts>
<context position="7657" citStr="Bergsma et al., 2012" startWordPosition="1173" endWordPosition="1176">including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as the European Union. 28 English French Italian German Dutch Japanese character the pour di auf </context>
</contexts>
<marker>Bergsma, McNamee, Bagdouri, Fink, Wilson, 2012</marker>
<rawString>Shane Bergsma, Paul McNamee, Mossaab Bagdouri, Clayton Fink, and Theresa Wilson. 2012. Language identification for creating language-specific Twitter collections. In Proceedings the Second Workshop on Language in Social Media (LSM2012), pages 65–74, Montr´eal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="12662" citStr="Blei et al., 2003" startWordPosition="1992" endWordPosition="1995">ures is selected from the training data using Information Gain (IG), an information-theoretic metric developed as a splitting criterion for decision trees (Quinlan, 1993). IGbased feature selection combined with a naive Bayes classifier has been shown to be particularly effective for language identification (Lui and Baldwin, 2011). 29 3.2 Generative Mixture Models Generative mixture models are popular for text modeling tasks where a mixture of influences governs the content of a document, such as in multi-label document classification (McCallum, 1999; Ramage et al., 2009), and topic modeling (Blei et al., 2003). Such models normally assume full exchangeability between tokens (i.e. the bag-of-words assumption), and label each token with a single discrete label. Multi-label text classification, topic modeling and our model for language identification in multilingual documents share the same fundamental representation of the latent structure of a document. Each label is modeled with a probability distribution over tokens, and each document is modeled as a probabilistic mixture of labels. As presented in Griffiths and Steyvers (2004), the probability of the ith token (wi) given a set of T labels z1· · ·</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessio Bosca</author>
<author>Luca Dini</author>
</authors>
<title>Language identification strategies for cross language information retrieval.</title>
<date>2010</date>
<booktitle>In Working Notes of the Cross Language Evaluation Forum (CLEF).</booktitle>
<contexts>
<context position="7494" citStr="Bosca and Dini, 2010" startWordPosition="1146" endWordPosition="1149"> Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from ano</context>
</contexts>
<marker>Bosca, Dini, 2010</marker>
<rawString>Alessio Bosca and Luca Dini. 2010. Language identification strategies for cross language information retrieval. In Working Notes of the Cross Language Evaluation Forum (CLEF).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jamie Callan</author>
<author>Mark Hoy</author>
</authors>
<date>2009</date>
<booktitle>ClueWeb09 Dataset. Availableathttp://boston.lti.cs. cmu.edu/Data/clueweb09/.</booktitle>
<contexts>
<context position="7822" citStr="Callan and Hoy, 2009" startWordPosition="1202" endWordPosition="1205">nd vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as the European Union. 28 English French Italian German Dutch Japanese character the pour di auf voo U byte 74 68 65 20 70 6F 75 7 20 64 69 20 20 61 75 66 76 6F 6 E3 81 AF Table 1: Examples of per-language byte sequences selected by information gain. The Austral</context>
</contexts>
<marker>Callan, Hoy, 2009</marker>
<rawString>Jamie Callan and Mark Hoy, 2009. ClueWeb09 Dataset. Availableathttp://boston.lti.cs. cmu.edu/Data/clueweb09/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William B Cavnar</author>
<author>John M Trenkle</author>
</authors>
<title>Ngram-based text categorization.</title>
<date>1994</date>
<booktitle>In Proceedings of the Third Symposium on Document Analysis and Information Retrieval,</booktitle>
<pages>161--175</pages>
<location>Las Vegas, USA.</location>
<contexts>
<context position="5265" citStr="Cavnar and Trenkle, 1994" startWordPosition="809" endWordPosition="813">ation in multilingual documents; (3) we show that our method is able to estimate the proportion of the document in each language to a high degree of accuracy; and (4) we show that our method is able to identify multilingual documents in real-world data. 2 Background Most language identification research focuses on language identification for monolingual documents (Hughes et al., 2006). In monolingual LangID, the task is to assign each document D a unique language Li ∈ L. Some work has reported near-perfect accuracy for language identification of large documents in a small number of languages (Cavnar and Trenkle, 1994; McNamee, 2005). However, in order to attain such accuracy, a large number of simplifying assumptions have to be made (Hughes et al., 2006; Baldwin and Lui, 2010a). In this work, we tackle the assumption that each document is monolingual, i.e. it contains text from a single language. In language identification, documents are modeled as a stream of characters (Cavnar and Trenkle, 1994; Kikui, 1996), often approximated by the corresponding stream of bytes (Kruengkrai et al., 2005; Baldwin and Lui, 2010a) for robustness over variable character encodings. In this work, we follow Baldwin and Lui (</context>
<context position="6541" citStr="Cavnar and Trenkle, 1994" startWordPosition="1009" endWordPosition="1012"> naturally use multiple encodings (e.g. UTF8, Big5 and GB encodings for Chinese), as issues of encoding are not the focus of this research. The document representation used for language identification generally involves estimating the relative distributions of particular byte sequences, selected such that their distributions differ between languages. In some cases the relevant sequences may be externally specified, such as function words and common suffixes (Giguet, 1995) or grammatical word classes (Dueire Lins and Gonc¸alves, 2004), though they are more frequently learned from labeled data (Cavnar and Trenkle, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin</context>
</contexts>
<marker>Cavnar, Trenkle, 1994</marker>
<rawString>William B. Cavnar and John M. Trenkle. 1994. Ngram-based text categorization. In Proceedings of the Third Symposium on Document Analysis and Information Retrieval, pages 161–175, Las Vegas, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hakan Ceylan</author>
<author>Yookyung Kim</author>
</authors>
<title>Language identification of search engine queries.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>1066--1074</pages>
<contexts>
<context position="7471" citStr="Ceylan and Kim, 2009" startWordPosition="1142" endWordPosition="1145">nstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that co</context>
</contexts>
<marker>Ceylan, Kim, 2009</marker>
<rawString>Hakan Ceylan and Yookyung Kim. 2009. Language identification of search engine queries. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 1066–1074, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Marco Lui</author>
</authors>
<title>langid.py for better language modelling.</title>
<date>2012</date>
<booktitle>In Proceedings of the Australasian Language Technology Association Workshop 2012,</booktitle>
<pages>107--112</pages>
<location>Dunedin, New Zealand.</location>
<contexts>
<context position="1970" citStr="Cook and Lui, 2012" startWordPosition="296" endWordPosition="299">move this monolingual assumption, and address the problem of language identification in documents that may contain text from more than one language from the candidate set. We propose a method that concurrently detects that a document is multilingual, and estimates the proportion of the document that is written in each language. Detecting multilingual documents has a variety of applications. Most natural language processing techniques presuppose monolingual input data, so inclusion of data in foreign languages introduces noise, and can degrade the performance of NLP systems (Alex et al., 2007; Cook and Lui, 2012). Automatic detection of multilingual documents can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and another language such a</context>
</contexts>
<marker>Cook, Lui, 2012</marker>
<rawString>Paul Cook and Marco Lui. 2012. langid.py for better language modelling. In Proceedings of the Australasian Language Technology Association Workshop 2012, pages 107–112, Dunedin, New Zealand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rafael Dueire Lins</author>
<author>Paulo Gonc¸alves</author>
</authors>
<title>Automatic language identification of written texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 ACM Symposium on Applied Computing (SAC 2004),</booktitle>
<pages>1128--1133</pages>
<location>Nicosia, Cyprus.</location>
<marker>Lins, Gonc¸alves, 2004</marker>
<rawString>Rafael Dueire Lins and Paulo Gonc¸alves. 2004. Automatic language identification of written texts. In Proceedings of the 2004 ACM Symposium on Applied Computing (SAC 2004), pages 1128–1133, Nicosia, Cyprus.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Statistical identification of language.</title>
<date>1994</date>
<tech>Technical Report MCCS 940-273,</tech>
<institution>Computing Research Laboratory, New Mexico State University.</institution>
<contexts>
<context position="6823" citStr="Dunning, 1994" startWordPosition="1044" endWordPosition="1045">cted such that their distributions differ between languages. In some cases the relevant sequences may be externally specified, such as function words and common suffixes (Giguet, 1995) or grammatical word classes (Dueire Lins and Gonc¸alves, 2004), though they are more frequently learned from labeled data (Cavnar and Trenkle, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang,</context>
</contexts>
<marker>Dunning, 1994</marker>
<rawString>Ted Dunning. 1994. Statistical identification of language. Technical Report MCCS 940-273, Computing Research Laboratory, New Mexico State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rayid Ghani</author>
<author>Rosie Jones</author>
<author>Dunja Mladenic</author>
</authors>
<title>Building minority language corpora by learning to generate web search queries.</title>
<date>2004</date>
<journal>Knowledge and Information Systems,</journal>
<volume>7</volume>
<issue>1</issue>
<contexts>
<context position="7618" citStr="Ghani et al., 2004" startWordPosition="1167" endWordPosition="1170">arily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as the European Union. 28 English French Italian German Du</context>
</contexts>
<marker>Ghani, Jones, Mladenic, 2004</marker>
<rawString>Rayid Ghani, Rosie Jones, and Dunja Mladenic. 2004. Building minority language corpora by learning to generate web search queries. Knowledge and Information Systems, 7(1):56–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Giguet</author>
</authors>
<title>Categorisation according to language: A step toward combining linguistic knowledge and statistical learning.</title>
<date>1995</date>
<booktitle>In Proceedings of the 4th International Workshop on Parsing Technologies (IWPT-1995),</booktitle>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="6393" citStr="Giguet, 1995" startWordPosition="987" endWordPosition="988">bustness over variable character encodings. In this work, we follow Baldwin and Lui (2010a) in training a single model for languages that naturally use multiple encodings (e.g. UTF8, Big5 and GB encodings for Chinese), as issues of encoding are not the focus of this research. The document representation used for language identification generally involves estimating the relative distributions of particular byte sequences, selected such that their distributions differ between languages. In some cases the relevant sequences may be externally specified, such as function words and common suffixes (Giguet, 1995) or grammatical word classes (Dueire Lins and Gonc¸alves, 2004), though they are more frequently learned from labeled data (Cavnar and Trenkle, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods va</context>
</contexts>
<marker>Giguet, 1995</marker>
<rawString>Emmanuel Giguet. 1995. Categorisation according to language: A step toward combining linguistic knowledge and statistical learning. In Proceedings of the 4th International Workshop on Parsing Technologies (IWPT-1995), Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregory Grefenstette</author>
</authors>
<title>Comparing two language identification schemes.</title>
<date>1995</date>
<booktitle>In Proceedings of Analisi Statistica dei Dati Testuali (JADT),</booktitle>
<pages>263--268</pages>
<location>Rome, Italy.</location>
<contexts>
<context position="6561" citStr="Grefenstette, 1995" startWordPosition="1013" endWordPosition="1014">codings (e.g. UTF8, Big5 and GB encodings for Chinese), as issues of encoding are not the focus of this research. The document representation used for language identification generally involves estimating the relative distributions of particular byte sequences, selected such that their distributions differ between languages. In some cases the relevant sequences may be externally specified, such as function words and common suffixes (Giguet, 1995) or grammatical word classes (Dueire Lins and Gonc¸alves, 2004), though they are more frequently learned from labeled data (Cavnar and Trenkle, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), st</context>
</contexts>
<marker>Grefenstette, 1995</marker>
<rawString>Gregory Grefenstette. 1995. Comparing two language identification schemes. In Proceedings of Analisi Statistica dei Dati Testuali (JADT), pages 263–268, Rome, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding scientific topics.</title>
<date>2004</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<pages>101--5228</pages>
<contexts>
<context position="13191" citStr="Griffiths and Steyvers (2004)" startWordPosition="2070" endWordPosition="2073">ocument classification (McCallum, 1999; Ramage et al., 2009), and topic modeling (Blei et al., 2003). Such models normally assume full exchangeability between tokens (i.e. the bag-of-words assumption), and label each token with a single discrete label. Multi-label text classification, topic modeling and our model for language identification in multilingual documents share the same fundamental representation of the latent structure of a document. Each label is modeled with a probability distribution over tokens, and each document is modeled as a probabilistic mixture of labels. As presented in Griffiths and Steyvers (2004), the probability of the ith token (wi) given a set of T labels z1· · ·zT is modeled as: T P(wi) = E P(wi|zi = j)P(zi = j) (1) j=1 The set of tokens w is the document itself, which in all cases is observed. In the case of topic modeling, the tokens are words and the labels are topics, and z is latent. Whereas topic modeling is generally unsupervised, multi-label text classification is a supervised text modeling task, where the labels are a set of pre-defined categories (such as RUBBER, IRON-STEEL, TRADE, etc. in the popular Reuters21578 data set (Lewis, 1997)), and the tokens are individual wo</context>
<context position="14821" citStr="Griffiths and Steyvers (2004)" startWordPosition="2348" endWordPosition="2351"> propose for language identification in multilingual documents is similar to multilabel text classification. In the framework of Equation 1, each per-token label zi is a language and the vocabulary of tokens is not given by words but rather by specific byte sequences (Section 3.1). The key difference with multi-label text classification is that we use monolingual (i.e. mono-label) training data. Hence, z is effectively observed for the training data (since all tokens must share the same label). To infer z for unlabeled documents, we utilize a Gibbs sampler, closely related to that proposed by Griffiths and Steyvers (2004) for LDA. The sampling probability for a label zi for token w in a document d is: P(zi = j|z−i, w) ∝ φ(w) j · θ(d) (2) j φ(w) j = P(wi|zi = j, z−i, w−i) θ(d) j = P(zi = j|z−i) In the LDA model, θ(d) j is assumed to have a Dirichlet distribution with hyperparameter α, and the word distribution for each topic φ(w) j is also assumed to have a Dirichlet distribution with hyperparameter β. Griffiths (2002) describes a generative model for LDA where both φ(w) j and θ(d) jare inferred from the output of a Gibbs sampler. In our method, we estimate φ(w) jusing maximum likelihood estimation (MLE) from t</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding scientific topics. Proceedings of the National Academy of Sciences, 101:5228–5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Griffiths</author>
</authors>
<title>Gibbs sampling in the generative model of latent Dirichlet allocation.</title>
<date>2002</date>
<tech>Technical Report,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="15225" citStr="Griffiths (2002)" startWordPosition="2431" endWordPosition="2432">ively observed for the training data (since all tokens must share the same label). To infer z for unlabeled documents, we utilize a Gibbs sampler, closely related to that proposed by Griffiths and Steyvers (2004) for LDA. The sampling probability for a label zi for token w in a document d is: P(zi = j|z−i, w) ∝ φ(w) j · θ(d) (2) j φ(w) j = P(wi|zi = j, z−i, w−i) θ(d) j = P(zi = j|z−i) In the LDA model, θ(d) j is assumed to have a Dirichlet distribution with hyperparameter α, and the word distribution for each topic φ(w) j is also assumed to have a Dirichlet distribution with hyperparameter β. Griffiths (2002) describes a generative model for LDA where both φ(w) j and θ(d) jare inferred from the output of a Gibbs sampler. In our method, we estimate φ(w) jusing maximum likelihood estimation (MLE) from the training data. Estimating φ(w) j through MLE is equivalent to a multinomial Naive Bayes model (McCallum and Nigam, 1998): j = (3) nj + Wβ (.) where n(w) j is the number of times word w occurs with label j, and n(.) j is the total number of words that occur with label j. By setting β to 1, we obtain standard Laplacian smoothing. Hence, only updated at each step in the Gibbs sampler: where n(d) −i,j </context>
</contexts>
<marker>Griffiths, 2002</marker>
<rawString>Thomas Griffiths. 2002. Gibbs sampling in the generative model of latent Dirichlet allocation. Technical Report, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baden Hughes</author>
<author>Timothy Baldwin</author>
<author>Steven Bird</author>
<author>Jeremy Nicholson</author>
<author>Andrew MacKinlay</author>
</authors>
<title>Reconsidering language identification for written language resources.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC</booktitle>
<pages>485--488</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="5028" citStr="Hughes et al., 2006" startWordPosition="769" endWordPosition="772">nt a method for identifying multilingual documents, the languages contained therein and the relative proportion of the document in each language; (2) we show that our method outperforms state-of-the-art methods for language identification in multilingual documents; (3) we show that our method is able to estimate the proportion of the document in each language to a high degree of accuracy; and (4) we show that our method is able to identify multilingual documents in real-world data. 2 Background Most language identification research focuses on language identification for monolingual documents (Hughes et al., 2006). In monolingual LangID, the task is to assign each document D a unique language Li ∈ L. Some work has reported near-perfect accuracy for language identification of large documents in a small number of languages (Cavnar and Trenkle, 1994; McNamee, 2005). However, in order to attain such accuracy, a large number of simplifying assumptions have to be made (Hughes et al., 2006; Baldwin and Lui, 2010a). In this work, we tackle the assumption that each document is monolingual, i.e. it contains text from a single language. In language identification, documents are modeled as a stream of characters (</context>
<context position="8006" citStr="Hughes et al., 2006" startWordPosition="1229" endWordPosition="1232">rtins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as the European Union. 28 English French Italian German Dutch Japanese character the pour di auf voo U byte 74 68 65 20 70 6F 75 7 20 64 69 20 20 61 75 66 76 6F 6 E3 81 AF Table 1: Examples of per-language byte sequences selected by information gain. The Australiasian Language Technology Workshop 2010 hosted a shared task where participants were required to predict the language(s) present in a held-out test set containing monolingual and bili</context>
<context position="44832" citStr="Hughes et al., 2006" startWordPosition="7452" endWordPosition="7455">t on the sparsity of the model. Further work is required in dealing with crossdomain effects, to allow for “off-the-shelf” language identification in multilingual documents. Previous work has shown that it is possible to generate a document representation that is robust to variation across domains (Lui and Baldwin, 2011), and we intend to investigate if these results are also applicable to language identification in multilingual documents. Another open question is the extension of the generative mixture models to “unknown” language identification (i.e. eliminating the closed-world assumption (Hughes et al., 2006)), which may be possible through the use of non-parametric mixture models such as Hierarchical Dirichlet Processes (Teh et al., 2006). 9 Conclusion We have presented a system for language identification in multilingual documents using a generative mixture model inspired by supervised topic modeling algorithms, combined with a document representation based on previous research in language identification for monolingual documents. We showed that the system outperforms alternative approaches from the literature on synthetic data, as well as on real-world data from related research on linguistic c</context>
</contexts>
<marker>Hughes, Baldwin, Bird, Nicholson, MacKinlay, 2006</marker>
<rawString>Baden Hughes, Timothy Baldwin, Steven Bird, Jeremy Nicholson, and Andrew MacKinlay. 2006. Reconsidering language identification for written language resources. In Proceedings of the 5th International Conference on Language Resources and Evaluation (LREC 2006), pages 485–488, Genoa, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Genitiro Kikui</author>
</authors>
<title>Identifying the coding system and language of on-line documents on the internet.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th International Conference on Computational Linguistics (COLING ’96),</booktitle>
<pages>652--657</pages>
<location>Kyoto, Japan.</location>
<contexts>
<context position="5666" citStr="Kikui, 1996" startWordPosition="877" endWordPosition="878">he task is to assign each document D a unique language Li ∈ L. Some work has reported near-perfect accuracy for language identification of large documents in a small number of languages (Cavnar and Trenkle, 1994; McNamee, 2005). However, in order to attain such accuracy, a large number of simplifying assumptions have to be made (Hughes et al., 2006; Baldwin and Lui, 2010a). In this work, we tackle the assumption that each document is monolingual, i.e. it contains text from a single language. In language identification, documents are modeled as a stream of characters (Cavnar and Trenkle, 1994; Kikui, 1996), often approximated by the corresponding stream of bytes (Kruengkrai et al., 2005; Baldwin and Lui, 2010a) for robustness over variable character encodings. In this work, we follow Baldwin and Lui (2010a) in training a single model for languages that naturally use multiple encodings (e.g. UTF8, Big5 and GB encodings for Chinese), as issues of encoding are not the focus of this research. The document representation used for language identification generally involves estimating the relative distributions of particular byte sequences, selected such that their distributions differ between languag</context>
<context position="7382" citStr="Kikui, 1996" startWordPosition="1128" endWordPosition="1129"> approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research questi</context>
</contexts>
<marker>Kikui, 1996</marker>
<rawString>Genitiro Kikui. 1996. Identifying the coding system and language of on-line documents on the internet. In Proceedings of the 16th International Conference on Computational Linguistics (COLING ’96), pages 652– 657, Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben King</author>
<author>Steven Abney</author>
</authors>
<title>Labeling the languages of words in mixed-language documents using weakly supervised methods.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>1110--1119</pages>
<location>Atlanta,</location>
<contexts>
<context position="2636" citStr="King and Abney, 2013" startWordPosition="394" endWordPosition="397">ts can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and another language such as English (Yamaguchi and Tanaka-Ishii, 2012; King and Abney, 2013). King and Abney (2013, p1118) specifically mention the need for an automatic method “to examine a multilingual document, and with high accuracy, list the languages that are present in the document”. We introduce a method that is able to detect multilingual documents, and simultaneously identify each language present as well as estimate the proportion of the document written in that language. We achieve this with a probabilistic mixture model, using a document representation developed for monolingual language identification (Lui and Baldwin, 2011). The model posits that each document is genera</context>
<context position="4366" citStr="King and Abney, 2013" startWordPosition="664" endWordPosition="667">arn a language identifier for multilingual documents from monolingual training data. This is an important property as there are no standard corpora of multilingual documents available, whereas corpora of monolingual documents are readily available for a reasonably large number of languages (Lui and Baldwin, 2011). We demonstrate the effectiveness of our method empirically, firstly by evaluating it on synthetic datasets drawn from Wikipedia data, and then by applying it to real-world data, showing that we are able to identify multilingual documents in targeted web crawls of minority languages (King and Abney, 2013). Our main contributions are: (1) we present a method for identifying multilingual documents, the languages contained therein and the relative proportion of the document in each language; (2) we show that our method outperforms state-of-the-art methods for language identification in multilingual documents; (3) we show that our method is able to estimate the proportion of the document in each language to a high degree of accuracy; and (4) we show that our method is able to identify multilingual documents in real-world data. 2 Background Most language identification research focuses on language </context>
<context position="39591" citStr="King and Abney (2013)" startWordPosition="6570" endWordPosition="6573">estimates of language proportions. After correction, the Pearson’s r rises to 0.981, and the MAE is reduced to 0.024. The improvement is most noticeable for language– document pairs where the proportion of the document in the given language is about 0.5 (Figure 2). 7 Real-world Multilingual Documents So far, we have demonstrated the effectiveness of our proposed approach using synthetic data. The results have been excellent, and in this section we validate the approach by applying it to a real-world task that has recently been discussed in the literature. Yamaguchi and Tanaka-Ishii (2012) and King and Abney (2013) both observe that in trying to gather linguistic data for “non-major” languages from the web, one challenge faced is that documents retrieved often contain sections in another language. SEGLANG (the solution of Yamaguchi and TanakaIshii (2012)) concurrently detects multilingual documents and segments them by language, but the approach is computationally expensive and has a tendency to over-label (Section 5). On the other hand, the solution of King and Abney (2013) is incomplete, and they specifically mention the need for an automatic method “to examine a multilingual document, and with high a</context>
<context position="40839" citStr="King and Abney (2013)" startWordPosition="6774" endWordPosition="6777"> that are present in the document”. In this section, we show that our method is able to fill this need. We System P R F Baseline 0.719 1.00 0.837 SEGLANG 0.779 0.991 0.872 LINGUINI 0.729 0.981 0.837 Our method 0.907 0.916 0.912 Table 4: Detection accuracy for English-language inclusion in web documents from targeted web crawls for low-density languages. make use of manually-annotated data kindly provided to us by Ben King, which consists of 149 documents containing 42 languages retrieved from the web using a set of targeted queries for low-density languages. Note that the dataset described in King and Abney (2013) was based on manual confirmation of the presence of English in addition to the lowdensity language of primary interest; our dataset contains these bilingual documents as well as monolingual documents in the low-density language of interest. Our purpose in this section is to investigate the ability of automatic systems to select this subset of bilingual documents. Specifically, given a collection of documents retrieved for a target language, the task is to identify the documents that contain text in English in addition to the target language. Thus, we re-train each system for each target langu</context>
<context position="43903" citStr="King and Abney (2013)" startWordPosition="7298" endWordPosition="7301">aseline, SEGLANG and LINGUINI both tend to overlabel documents, producing false positive labels of English, resulting in increased recall at the expense of precision. Our method produces less false positives (but slightly more false negatives). Overall, our method attains the best .F for detecting English inclusions. Manual error analysis suggests that the false negatives for our method generally occur where a relatively small proportion of the document is written in English. 8 Future Work Document segmentation by language could be accomplished by a combination of our method and the method of King and Abney (2013), which could be compared to the method of Yamaguchi and TanakaIshii (2012) in the context of constructing corpora for low-density languages using the web. Another area we have identified in this paper is the tuning of the parameters α and 0 in our model (currently α = 0 and 0 = 1), which may have some effect on the sparsity of the model. Further work is required in dealing with crossdomain effects, to allow for “off-the-shelf” language identification in multilingual documents. Previous work has shown that it is possible to generate a document representation that is robust to variation across </context>
</contexts>
<marker>King, Abney, 2013</marker>
<rawString>Ben King and Steven Abney. 2013. Labeling the languages of words in mixed-language documents using weakly supervised methods. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 1110–1119, Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Canasai Kruengkrai</author>
<author>Prapass Srichaivattana</author>
<author>Virach Sornlertlamvanich</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Language identification based on string kernels.</title>
<date>2005</date>
<booktitle>In Proceedings of the 5th International Symposium on Communications and Information Technologies (ISCIT2005),</booktitle>
<pages>896--899</pages>
<location>Beijing, China.</location>
<contexts>
<context position="5748" citStr="Kruengkrai et al., 2005" startWordPosition="888" endWordPosition="891">k has reported near-perfect accuracy for language identification of large documents in a small number of languages (Cavnar and Trenkle, 1994; McNamee, 2005). However, in order to attain such accuracy, a large number of simplifying assumptions have to be made (Hughes et al., 2006; Baldwin and Lui, 2010a). In this work, we tackle the assumption that each document is monolingual, i.e. it contains text from a single language. In language identification, documents are modeled as a stream of characters (Cavnar and Trenkle, 1994; Kikui, 1996), often approximated by the corresponding stream of bytes (Kruengkrai et al., 2005; Baldwin and Lui, 2010a) for robustness over variable character encodings. In this work, we follow Baldwin and Lui (2010a) in training a single model for languages that naturally use multiple encodings (e.g. UTF8, Big5 and GB encodings for Chinese), as issues of encoding are not the focus of this research. The document representation used for language identification generally involves estimating the relative distributions of particular byte sequences, selected such that their distributions differ between languages. In some cases the relevant sequences may be externally specified, such as func</context>
<context position="7199" citStr="Kruengkrai et al., 2005" startWordPosition="1098" endWordPosition="1101">a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl</context>
</contexts>
<marker>Kruengkrai, Srichaivattana, Sornlertlamvanich, Isahara, 2005</marker>
<rawString>Canasai Kruengkrai, Prapass Srichaivattana, Virach Sornlertlamvanich, and Hitoshi Isahara. 2005. Language identification based on string kernels. In Proceedings of the 5th International Symposium on Communications and Information Technologies (ISCIT2005), pages 896–899, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
</authors>
<title>The Reuters-21578 data set. available at http://www.daviddlewis. com/resources/testcollections/ reuters21578/.</title>
<date>1997</date>
<contexts>
<context position="13756" citStr="Lewis, 1997" startWordPosition="2177" endWordPosition="2178">. As presented in Griffiths and Steyvers (2004), the probability of the ith token (wi) given a set of T labels z1· · ·zT is modeled as: T P(wi) = E P(wi|zi = j)P(zi = j) (1) j=1 The set of tokens w is the document itself, which in all cases is observed. In the case of topic modeling, the tokens are words and the labels are topics, and z is latent. Whereas topic modeling is generally unsupervised, multi-label text classification is a supervised text modeling task, where the labels are a set of pre-defined categories (such as RUBBER, IRON-STEEL, TRADE, etc. in the popular Reuters21578 data set (Lewis, 1997)), and the tokens are individual words in documents. z is still latent, but constrained in the training data (i.e. documents are labeled but the individual words are not). Some approaches to labeling unseen documents require that z for the training data be inferred, and methods for doing this include an application of the ExpectationMaximization (EM) algorithm (McCallum, 1999) and Labeled LDA (Ramage et al., 2009). The model that we propose for language identification in multilingual documents is similar to multilabel text classification. In the framework of Equation 1, each per-token label zi</context>
</contexts>
<marker>Lewis, 1997</marker>
<rawString>David D. Lewis. 1997. The Reuters-21578 data set. available at http://www.daviddlewis. com/resources/testcollections/ reuters21578/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wang Ling</author>
<author>Guang Xiang</author>
<author>Chris Dyer</author>
<author>Alan Black</author>
<author>Isabel Trancoso</author>
</authors>
<title>Microblogs as parallel corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>176--186</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="2382" citStr="Ling et al., 2013" startWordPosition="359" endWordPosition="362">ge processing techniques presuppose monolingual input data, so inclusion of data in foreign languages introduces noise, and can degrade the performance of NLP systems (Alex et al., 2007; Cook and Lui, 2012). Automatic detection of multilingual documents can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and another language such as English (Yamaguchi and Tanaka-Ishii, 2012; King and Abney, 2013). King and Abney (2013, p1118) specifically mention the need for an automatic method “to examine a multilingual document, and with high accuracy, list the languages that are present in the document”. We introduce a method that is able to detect multilingual documents, and simultaneously identify each language present as well as estimate the pro</context>
</contexts>
<marker>Ling, Xiang, Dyer, Black, Trancoso, 2013</marker>
<rawString>Wang Ling, Guang Xiang, Chris Dyer, Alan Black, and Isabel Trancoso. 2013. Microblogs as parallel corpora. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 176–186, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jicheng Liu</author>
<author>Chunyan Liang</author>
</authors>
<title>Text Categorization of Multilingual Web Pages in Specific Domain.</title>
<date>2008</date>
<booktitle>In Proceedings of the 12th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, PAKDD’08,</booktitle>
<pages>938--944</pages>
<location>Osaka, Japan.</location>
<contexts>
<context position="7429" citStr="Liu and Liang, 2008" startWordPosition="1135" endWordPosition="1138">Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of mu</context>
</contexts>
<marker>Liu, Liang, 2008</marker>
<rawString>Jicheng Liu and Chunyan Liang. 2008. Text Categorization of Multilingual Web Pages in Specific Domain. In Proceedings of the 12th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining, PAKDD’08, pages 938–944, Osaka, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Timothy Baldwin</author>
</authors>
<title>Cross-domain feature selection for language identification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011),</booktitle>
<pages>553--561</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="3189" citStr="Lui and Baldwin, 2011" startWordPosition="481" endWordPosition="484">h as English (Yamaguchi and Tanaka-Ishii, 2012; King and Abney, 2013). King and Abney (2013, p1118) specifically mention the need for an automatic method “to examine a multilingual document, and with high accuracy, list the languages that are present in the document”. We introduce a method that is able to detect multilingual documents, and simultaneously identify each language present as well as estimate the proportion of the document written in that language. We achieve this with a probabilistic mixture model, using a document representation developed for monolingual language identification (Lui and Baldwin, 2011). The model posits that each document is generated as samples from an unknown mixture of languages from the training set. We introduce a Gibbs sampler to map samples to languages for any given set of languages, and use this to select the set of languages that maximizes the posterior probability of the document. 27 Transactions of the Association for Computational Linguistics, 2 (2014) 27–40. Action Editor: Kristina Toutanova. Submitted 1/2013; Revised 7/2013; Published 2/2014. c�2014 Association for Computational Linguistics. Our method is able to learn a language identifier for multilingual d</context>
<context position="6600" citStr="Lui and Baldwin, 2011" startWordPosition="1017" endWordPosition="1020">odings for Chinese), as issues of encoding are not the focus of this research. The document representation used for language identification generally involves estimating the relative distributions of particular byte sequences, selected such that their distributions differ between languages. In some cases the relevant sequences may be externally specified, such as function words and common suffixes (Giguet, 1995) or grammatical word classes (Dueire Lins and Gonc¸alves, 2004), though they are more frequently learned from labeled data (Cavnar and Trenkle, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) </context>
<context position="12376" citStr="Lui and Baldwin, 2011" startWordPosition="1946" endWordPosition="1949">nto a vector where each entry counts the number of times a particular byte n-gram is present in the document. This is analogous to a bag-of-words model, where the vocabulary of “words” is a set of byte sequences that has been selected to distinguish between languages. The exact set of features is selected from the training data using Information Gain (IG), an information-theoretic metric developed as a splitting criterion for decision trees (Quinlan, 1993). IGbased feature selection combined with a naive Bayes classifier has been shown to be particularly effective for language identification (Lui and Baldwin, 2011). 29 3.2 Generative Mixture Models Generative mixture models are popular for text modeling tasks where a mixture of influences governs the content of a document, such as in multi-label document classification (McCallum, 1999; Ramage et al., 2009), and topic modeling (Blei et al., 2003). Such models normally assume full exchangeability between tokens (i.e. the bag-of-words assumption), and label each token with a single discrete label. Multi-label text classification, topic modeling and our model for language identification in multilingual documents share the same fundamental representation of </context>
<context position="44534" citStr="Lui and Baldwin, 2011" startWordPosition="7406" endWordPosition="7409">ould be compared to the method of Yamaguchi and TanakaIshii (2012) in the context of constructing corpora for low-density languages using the web. Another area we have identified in this paper is the tuning of the parameters α and 0 in our model (currently α = 0 and 0 = 1), which may have some effect on the sparsity of the model. Further work is required in dealing with crossdomain effects, to allow for “off-the-shelf” language identification in multilingual documents. Previous work has shown that it is possible to generate a document representation that is robust to variation across domains (Lui and Baldwin, 2011), and we intend to investigate if these results are also applicable to language identification in multilingual documents. Another open question is the extension of the generative mixture models to “unknown” language identification (i.e. eliminating the closed-world assumption (Hughes et al., 2006)), which may be possible through the use of non-parametric mixture models such as Hierarchical Dirichlet Processes (Teh et al., 2006). 9 Conclusion We have presented a system for language identification in multilingual documents using a generative mixture model inspired by supervised topic modeling al</context>
</contexts>
<marker>Lui, Baldwin, 2011</marker>
<rawString>Marco Lui and Timothy Baldwin. 2011. Cross-domain feature selection for language identification. In Proceedings of the 5th International Joint Conference on Natural Language Processing (IJCNLP 2011), pages 553–561, Chiang Mai, Thailand.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Martins</author>
<author>M´ario J Silva</author>
</authors>
<title>Language identification in web pages.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 ACM symposium on Applied computing,</booktitle>
<pages>764--768</pages>
<location>Santa Fe, USA.</location>
<contexts>
<context position="7407" citStr="Martins and Silva, 2005" startWordPosition="1130" endWordPosition="1134">nclude Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006).</context>
</contexts>
<marker>Martins, Silva, 2005</marker>
<rawString>Bruno Martins and M´ario J. Silva. 2005. Language identification in web pages. In Proceedings of the 2005 ACM symposium on Applied computing, pages 764– 768, Santa Fe, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew McCallum</author>
<author>Kamal Nigam</author>
</authors>
<title>A comparison of event models for Naive Bayes text classification.</title>
<date>1998</date>
<booktitle>In Proceedings of the AAAI-98 Workshop on Learning for Text Categorization, pages Available as Technical Report WS–98–05,</booktitle>
<publisher>AAAI Press.,</publisher>
<location>Madison, USA.</location>
<contexts>
<context position="15544" citStr="McCallum and Nigam, 1998" startWordPosition="2483" endWordPosition="2486"> ∝ φ(w) j · θ(d) (2) j φ(w) j = P(wi|zi = j, z−i, w−i) θ(d) j = P(zi = j|z−i) In the LDA model, θ(d) j is assumed to have a Dirichlet distribution with hyperparameter α, and the word distribution for each topic φ(w) j is also assumed to have a Dirichlet distribution with hyperparameter β. Griffiths (2002) describes a generative model for LDA where both φ(w) j and θ(d) jare inferred from the output of a Gibbs sampler. In our method, we estimate φ(w) jusing maximum likelihood estimation (MLE) from the training data. Estimating φ(w) j through MLE is equivalent to a multinomial Naive Bayes model (McCallum and Nigam, 1998): j = (3) nj + Wβ (.) where n(w) j is the number of times word w occurs with label j, and n(.) j is the total number of words that occur with label j. By setting β to 1, we obtain standard Laplacian smoothing. Hence, only updated at each step in the Gibbs sampler: where n(d) −i,j is the number of tokens in document d that are currently mapped to language j, and n(d) −i is the total number of tokens in document d. In both cases, the current assignment of zi is excluded from the count. T is the number of languages (i.e. the size of the label set). For simplicity, we set α to 0. We note that in t</context>
</contexts>
<marker>McCallum, Nigam, 1998</marker>
<rawString>Andrew McCallum and Kamal Nigam. 1998. A comparison of event models for Naive Bayes text classification. In Proceedings of the AAAI-98 Workshop on Learning for Text Categorization, pages Available as Technical Report WS–98–05, AAAI Press., Madison, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Multi-label text classification with a mixture model trained by EM.</title>
<date>1999</date>
<booktitle>In Proceedings of AAAI 99 Workshop on Text Learning.</booktitle>
<contexts>
<context position="12600" citStr="McCallum, 1999" startWordPosition="1983" endWordPosition="1984">ed to distinguish between languages. The exact set of features is selected from the training data using Information Gain (IG), an information-theoretic metric developed as a splitting criterion for decision trees (Quinlan, 1993). IGbased feature selection combined with a naive Bayes classifier has been shown to be particularly effective for language identification (Lui and Baldwin, 2011). 29 3.2 Generative Mixture Models Generative mixture models are popular for text modeling tasks where a mixture of influences governs the content of a document, such as in multi-label document classification (McCallum, 1999; Ramage et al., 2009), and topic modeling (Blei et al., 2003). Such models normally assume full exchangeability between tokens (i.e. the bag-of-words assumption), and label each token with a single discrete label. Multi-label text classification, topic modeling and our model for language identification in multilingual documents share the same fundamental representation of the latent structure of a document. Each label is modeled with a probability distribution over tokens, and each document is modeled as a probabilistic mixture of labels. As presented in Griffiths and Steyvers (2004), the pro</context>
<context position="14135" citStr="McCallum, 1999" startWordPosition="2237" endWordPosition="2238">generally unsupervised, multi-label text classification is a supervised text modeling task, where the labels are a set of pre-defined categories (such as RUBBER, IRON-STEEL, TRADE, etc. in the popular Reuters21578 data set (Lewis, 1997)), and the tokens are individual words in documents. z is still latent, but constrained in the training data (i.e. documents are labeled but the individual words are not). Some approaches to labeling unseen documents require that z for the training data be inferred, and methods for doing this include an application of the ExpectationMaximization (EM) algorithm (McCallum, 1999) and Labeled LDA (Ramage et al., 2009). The model that we propose for language identification in multilingual documents is similar to multilabel text classification. In the framework of Equation 1, each per-token label zi is a language and the vocabulary of tokens is not given by words but rather by specific byte sequences (Section 3.1). The key difference with multi-label text classification is that we use monolingual (i.e. mono-label) training data. Hence, z is effectively observed for the training data (since all tokens must share the same label). To infer z for unlabeled documents, we util</context>
<context position="17570" citStr="McCallum (1999)" startWordPosition="2873" endWordPosition="2874">abeled document, by running the Gibbs sampler until the samples for zi converge and then tabulating zi over the whole d and normalizing by |d|. Naively, we could identify the languages present in the document by D &gt; {Lx if ](zi = Lx|D)}, but closelyrelated languages tend to have similar frequency distributions over byte n-gram features, and hence it is likely that some tokens will be incorrectly mapped to a language that is similar to the “correct” language. We address this issue by finding the subset of languages A from the training set L that maximizes P(A|D) (a similar approach is taken in McCallum (1999)). Through an application of Bayes’ theorem, P(A|D) a P(D|A)·P(A), noting that P(D) is a normalizing constant and can be dropped. We assume that P(A) is constant (i.e. any subset of languages is equally likely, a reasonable assumption in the absence of other evidence), and hence maximize P(D|A). For any given D = w1· · ·wn and A, we infer P(D|A) from the output of the Gibbs sampler: P(wi|A) (5) � P(wi|zi = j)P(zi = j) (6) jEλ where both P(wi|zi = j) and P(zi = j) are estimated by their maximum likelihood estimates. In practice, exhaustive evaluation of the powerset of L is prohibitively expens</context>
</contexts>
<marker>McCallum, 1999</marker>
<rawString>Andrew Kachites McCallum. 1999. Multi-label text classification with a mixture model trained by EM. In Proceedings of AAAI 99 Workshop on Text Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
</authors>
<title>Language identification: a solved problem suitable for undergraduate instruction.</title>
<date>2005</date>
<journal>Journal of Computing Sciences in Colleges,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="5281" citStr="McNamee, 2005" startWordPosition="814" endWordPosition="815">ments; (3) we show that our method is able to estimate the proportion of the document in each language to a high degree of accuracy; and (4) we show that our method is able to identify multilingual documents in real-world data. 2 Background Most language identification research focuses on language identification for monolingual documents (Hughes et al., 2006). In monolingual LangID, the task is to assign each document D a unique language Li ∈ L. Some work has reported near-perfect accuracy for language identification of large documents in a small number of languages (Cavnar and Trenkle, 1994; McNamee, 2005). However, in order to attain such accuracy, a large number of simplifying assumptions have to be made (Hughes et al., 2006; Baldwin and Lui, 2010a). In this work, we tackle the assumption that each document is monolingual, i.e. it contains text from a single language. In language identification, documents are modeled as a stream of characters (Cavnar and Trenkle, 1994; Kikui, 1996), often approximated by the corresponding stream of bytes (Kruengkrai et al., 2005; Baldwin and Lui, 2010a) for robustness over variable character encodings. In this work, we follow Baldwin and Lui (2010a) in traini</context>
<context position="7254" citStr="McNamee, 2005" startWordPosition="1108" endWordPosition="1109">e identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Lan</context>
</contexts>
<marker>McNamee, 2005</marker>
<rawString>Paul McNamee. 2005. Language identification: a solved problem suitable for undergraduate instruction. Journal of Computing Sciences in Colleges, 20(3):94–101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jian-Yun Nie</author>
<author>Michel Simard</author>
<author>Pierre Isabelle</author>
<author>Richard Durand</author>
</authors>
<title>Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the web.</title>
<date>1999</date>
<booktitle>In Proceedings of 22nd International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’99),</booktitle>
<pages>74--81</pages>
<location>Berkeley, USA.</location>
<contexts>
<context position="2362" citStr="Nie et al., 1999" startWordPosition="355" endWordPosition="358">ost natural language processing techniques presuppose monolingual input data, so inclusion of data in foreign languages introduces noise, and can degrade the performance of NLP systems (Alex et al., 2007; Cook and Lui, 2012). Automatic detection of multilingual documents can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and another language such as English (Yamaguchi and Tanaka-Ishii, 2012; King and Abney, 2013). King and Abney (2013, p1118) specifically mention the need for an automatic method “to examine a multilingual document, and with high accuracy, list the languages that are present in the document”. We introduce a method that is able to detect multilingual documents, and simultaneously identify each language present as well</context>
<context position="7562" citStr="Nie et al., 1999" startWordPosition="1158" endWordPosition="1161">(Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as</context>
</contexts>
<marker>Nie, Simard, Isabelle, Durand, 1999</marker>
<rawString>Jian-Yun Nie, Michel Simard, Pierre Isabelle, and Richard Durand. 1999. Cross-language information retrieval based on parallel texts and automatic mining of parallel texts from the web. In Proceedings of 22nd International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’99), pages 74–81, Berkeley, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Prager</author>
</authors>
<title>Linguini: language identification for multilingual documents.</title>
<date>1999</date>
<booktitle>In Proceedings the 32nd Annual Hawaii International Conference on Systems Sciences (HICSS-32), Maui,</booktitle>
<location>Hawaii.</location>
<contexts>
<context position="6575" citStr="Prager, 1999" startWordPosition="1015" endWordPosition="1016">Big5 and GB encodings for Chinese), as issues of encoding are not the focus of this research. The document representation used for language identification generally involves estimating the relative distributions of particular byte sequences, selected such that their distributions differ between languages. In some cases the relevant sequences may be externally specified, such as function words and common suffixes (Giguet, 1995) or grammatical word classes (Dueire Lins and Gonc¸alves, 2004), though they are more frequently learned from labeled data (Cavnar and Trenkle, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (</context>
<context position="9098" citStr="Prager, 1999" startWordPosition="1413" endWordPosition="1414">ere participants were required to predict the language(s) present in a held-out test set containing monolingual and bilingual documents (Baldwin and Lui, 2010b). The dataset was prepared using data from Wikipedia, and bilingual documents were produced using a segment from a page in one language, and a segment from the same page in another language. We use the dataset from this shared task for our initial experiments. To the authors’ knowledge, the only other work to directly tackle identification of multiple languages and their relative proportions in a single document is the LINGUINI system (Prager, 1999a). The system is based on a vector space model, and cosine similarity between a feature vector for the test document and a feature vector for each language Li, computed as the sum of feature vectors for all the documents for language Li in the training data. The elements in the feature vectors are frequency counts over byte n-grams (2&lt;n&lt;5) and words. Language identification for multilingual documents is performed through the use of virtual mixed languages. Prager (1999a) shows how to construct vectors representative of particular combinations of languages independent of the relative proportio</context>
<context position="19456" citStr="Prager, 1999" startWordPosition="3218" endWordPosition="3219">ss the addition of spurious classes. Adding languages gives the model additional freedom to fit parameters, and so will generally increase P(D|A). In the limit case, adding a completely irrelevant language will result in no tokens being mapped to the a language, and so the model will be no worse than without the language. The threshold t is thus used to control “how much” improvement is required before including the new language in A. 3.4 Benchmark Approaches We compare our approach to two methods for language identification in multilingual documents: (1) the virtual mixed languages approach (Prager, 1999a); and (2) the text segmentation approach (Yamaguchi and Tanaka-Ishii, 2012). Prager (1999a) describes LINGUINI, a language identifier based on the vector-space model commonly used in text classification and information retrieval. The document representation used by Prager (1999a) is a vector of counts across a set of character sequences. Prager (1999a) selects the feature set based on a TFIDF-like approach. Terms with occurrence count m &lt; n x k are rejected, where m is the number of times the term occurs in the training data (the TF component), n is the number of languages in which the term </context>
<context position="20956" citStr="Prager (1999" startWordPosition="3482" endWordPosition="3483">rectly controls the number of features selected. Values of k are not comparable across datasets as m is not normalized for the size of the training data, so in this work we do not report the values of k and instead directly select the top-N features, weighted by mn . In LINGUINI, each language is modeled as a single pseudo-document, obtained by concatenating all the training data for the given language. A document is then classified according to the vector with which it has the smallest angle; this is implemented by finding the language vector with the highest cosine with the document vector. Prager (1999a) also proposes an extension to the approach to allow identification of bilingual documents, and suggests how this may be generalized to any number of languages in a document. The gist of the method is simple: for any given pair of languages, the projection of a document vector onto the hyperplane containing the language vectors of the two languages gives the mixture proportions of the two languages that minimizes the angle with the document vector. Prager (1999a) terms this projection a virtual mixed language (VML), and shows how to find the angle between the document vector and the VML. If </context>
<context position="22200" citStr="Prager (1999" startWordPosition="3685" endWordPosition="3686">ween the document vector and any individual language vector, the document is labeled as bilingual in the two languages from which the mixed vector was derived. The practical difficulty presented by this approach is that exhaustively evaluating all possible combinations of languages is prohibitively expensive. Prager (1999a) addresses this by arguing that in multilingual documents, “the individual component languages will be close to d (the document vector) – probably closer than most or all other languages”. Hence, language mixtures are only considered for combinations of the top m languages. Prager (1999a) shows how to obtain the mixture coefficients for bilingual VMLs, arguing that the process generalizes. Prager (1999b) includes the coefficients for 3-language VMLs, which are much more complex than the 2-language variants. Using a computer algebra system, we verified the analytic forms of the coefficients in the 3-language VML. We also attempted to obtain an analytic form for the coefficients in a 4-language VML, but these were too complex for the computer algebra system to compute. Thus, our evaluation of the VML approach proposed by Prager (1999a) is limited to 3- language VMLs. Neither P</context>
</contexts>
<marker>Prager, 1999</marker>
<rawString>John M. Prager. 1999a. Linguini: language identification for multilingual documents. In Proceedings the 32nd Annual Hawaii International Conference on Systems Sciences (HICSS-32), Maui, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John M Prager</author>
</authors>
<title>Linguini: Language identification for multilingual documents.</title>
<date>1999</date>
<journal>Journal of Management Information Systems,</journal>
<volume>16</volume>
<issue>3</issue>
<contexts>
<context position="6575" citStr="Prager, 1999" startWordPosition="1015" endWordPosition="1016">Big5 and GB encodings for Chinese), as issues of encoding are not the focus of this research. The document representation used for language identification generally involves estimating the relative distributions of particular byte sequences, selected such that their distributions differ between languages. In some cases the relevant sequences may be externally specified, such as function words and common suffixes (Giguet, 1995) or grammatical word classes (Dueire Lins and Gonc¸alves, 2004), though they are more frequently learned from labeled data (Cavnar and Trenkle, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (</context>
<context position="9098" citStr="Prager, 1999" startWordPosition="1413" endWordPosition="1414">ere participants were required to predict the language(s) present in a held-out test set containing monolingual and bilingual documents (Baldwin and Lui, 2010b). The dataset was prepared using data from Wikipedia, and bilingual documents were produced using a segment from a page in one language, and a segment from the same page in another language. We use the dataset from this shared task for our initial experiments. To the authors’ knowledge, the only other work to directly tackle identification of multiple languages and their relative proportions in a single document is the LINGUINI system (Prager, 1999a). The system is based on a vector space model, and cosine similarity between a feature vector for the test document and a feature vector for each language Li, computed as the sum of feature vectors for all the documents for language Li in the training data. The elements in the feature vectors are frequency counts over byte n-grams (2&lt;n&lt;5) and words. Language identification for multilingual documents is performed through the use of virtual mixed languages. Prager (1999a) shows how to construct vectors representative of particular combinations of languages independent of the relative proportio</context>
<context position="19456" citStr="Prager, 1999" startWordPosition="3218" endWordPosition="3219">ss the addition of spurious classes. Adding languages gives the model additional freedom to fit parameters, and so will generally increase P(D|A). In the limit case, adding a completely irrelevant language will result in no tokens being mapped to the a language, and so the model will be no worse than without the language. The threshold t is thus used to control “how much” improvement is required before including the new language in A. 3.4 Benchmark Approaches We compare our approach to two methods for language identification in multilingual documents: (1) the virtual mixed languages approach (Prager, 1999a); and (2) the text segmentation approach (Yamaguchi and Tanaka-Ishii, 2012). Prager (1999a) describes LINGUINI, a language identifier based on the vector-space model commonly used in text classification and information retrieval. The document representation used by Prager (1999a) is a vector of counts across a set of character sequences. Prager (1999a) selects the feature set based on a TFIDF-like approach. Terms with occurrence count m &lt; n x k are rejected, where m is the number of times the term occurs in the training data (the TF component), n is the number of languages in which the term </context>
<context position="20956" citStr="Prager (1999" startWordPosition="3482" endWordPosition="3483">rectly controls the number of features selected. Values of k are not comparable across datasets as m is not normalized for the size of the training data, so in this work we do not report the values of k and instead directly select the top-N features, weighted by mn . In LINGUINI, each language is modeled as a single pseudo-document, obtained by concatenating all the training data for the given language. A document is then classified according to the vector with which it has the smallest angle; this is implemented by finding the language vector with the highest cosine with the document vector. Prager (1999a) also proposes an extension to the approach to allow identification of bilingual documents, and suggests how this may be generalized to any number of languages in a document. The gist of the method is simple: for any given pair of languages, the projection of a document vector onto the hyperplane containing the language vectors of the two languages gives the mixture proportions of the two languages that minimizes the angle with the document vector. Prager (1999a) terms this projection a virtual mixed language (VML), and shows how to find the angle between the document vector and the VML. If </context>
<context position="22200" citStr="Prager (1999" startWordPosition="3685" endWordPosition="3686">ween the document vector and any individual language vector, the document is labeled as bilingual in the two languages from which the mixed vector was derived. The practical difficulty presented by this approach is that exhaustively evaluating all possible combinations of languages is prohibitively expensive. Prager (1999a) addresses this by arguing that in multilingual documents, “the individual component languages will be close to d (the document vector) – probably closer than most or all other languages”. Hence, language mixtures are only considered for combinations of the top m languages. Prager (1999a) shows how to obtain the mixture coefficients for bilingual VMLs, arguing that the process generalizes. Prager (1999b) includes the coefficients for 3-language VMLs, which are much more complex than the 2-language variants. Using a computer algebra system, we verified the analytic forms of the coefficients in the 3-language VML. We also attempted to obtain an analytic form for the coefficients in a 4-language VML, but these were too complex for the computer algebra system to compute. Thus, our evaluation of the VML approach proposed by Prager (1999a) is limited to 3- language VMLs. Neither P</context>
</contexts>
<marker>Prager, 1999</marker>
<rawString>John M. Prager. 1999b. Linguini: Language identification for multilingual documents. Journal of Management Information Systems, 16(3):71–101.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Ross Quinlan</author>
</authors>
<title>C4.5: Programs for Machine Learning.</title>
<date>1993</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, USA.</location>
<contexts>
<context position="12214" citStr="Quinlan, 1993" startWordPosition="1924" endWordPosition="1925">ature Selection We represent each document D as a frequency distribution over byte n-gram sequences such as those in Table 1. Each document is converted into a vector where each entry counts the number of times a particular byte n-gram is present in the document. This is analogous to a bag-of-words model, where the vocabulary of “words” is a set of byte sequences that has been selected to distinguish between languages. The exact set of features is selected from the training data using Information Gain (IG), an information-theoretic metric developed as a splitting criterion for decision trees (Quinlan, 1993). IGbased feature selection combined with a naive Bayes classifier has been shown to be particularly effective for language identification (Lui and Baldwin, 2011). 29 3.2 Generative Mixture Models Generative mixture models are popular for text modeling tasks where a mixture of influences governs the content of a document, such as in multi-label document classification (McCallum, 1999; Ramage et al., 2009), and topic modeling (Blei et al., 2003). Such models normally assume full exchangeability between tokens (i.e. the bag-of-words assumption), and label each token with a single discrete label.</context>
</contexts>
<marker>Quinlan, 1993</marker>
<rawString>John Ross Quinlan. 1993. C4.5: Programs for Machine Learning. Morgan Kaufmann, San Mateo, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ramage</author>
<author>David Hall</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Labeled LDA: A supervised topic model for credit attribution in multilabeled corpora.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>248--256</pages>
<contexts>
<context position="12622" citStr="Ramage et al., 2009" startWordPosition="1985" endWordPosition="1988">h between languages. The exact set of features is selected from the training data using Information Gain (IG), an information-theoretic metric developed as a splitting criterion for decision trees (Quinlan, 1993). IGbased feature selection combined with a naive Bayes classifier has been shown to be particularly effective for language identification (Lui and Baldwin, 2011). 29 3.2 Generative Mixture Models Generative mixture models are popular for text modeling tasks where a mixture of influences governs the content of a document, such as in multi-label document classification (McCallum, 1999; Ramage et al., 2009), and topic modeling (Blei et al., 2003). Such models normally assume full exchangeability between tokens (i.e. the bag-of-words assumption), and label each token with a single discrete label. Multi-label text classification, topic modeling and our model for language identification in multilingual documents share the same fundamental representation of the latent structure of a document. Each label is modeled with a probability distribution over tokens, and each document is modeled as a probabilistic mixture of labels. As presented in Griffiths and Steyvers (2004), the probability of the ith to</context>
<context position="14173" citStr="Ramage et al., 2009" startWordPosition="2242" endWordPosition="2245">el text classification is a supervised text modeling task, where the labels are a set of pre-defined categories (such as RUBBER, IRON-STEEL, TRADE, etc. in the popular Reuters21578 data set (Lewis, 1997)), and the tokens are individual words in documents. z is still latent, but constrained in the training data (i.e. documents are labeled but the individual words are not). Some approaches to labeling unseen documents require that z for the training data be inferred, and methods for doing this include an application of the ExpectationMaximization (EM) algorithm (McCallum, 1999) and Labeled LDA (Ramage et al., 2009). The model that we propose for language identification in multilingual documents is similar to multilabel text classification. In the framework of Equation 1, each per-token label zi is a language and the vocabulary of tokens is not given by words but rather by specific byte sequences (Section 3.1). The key difference with multi-label text classification is that we use monolingual (i.e. mono-label) training data. Hence, z is effectively observed for the training data (since all tokens must share the same label). To infer z for unlabeled documents, we utilize a Gibbs sampler, closely related t</context>
</contexts>
<marker>Ramage, Hall, Nallapati, Manning, 2009</marker>
<rawString>Daniel Ramage, David Hall, Ramesh Nallapati, and Christopher D. Manning. 2009. Labeled LDA: A supervised topic model for credit attribution in multilabeled corpora. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP 2009), pages 248–256, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radim Rehurek</author>
<author>Milan Kolkus</author>
</authors>
<title>Language Identification on the Web: Extending the Dictionary Method.</title>
<date>2009</date>
<booktitle>In Proceedings of Computational Linguistics and Intelligent Text Processing, 10th International Conference (CICLing</booktitle>
<pages>357--368</pages>
<location>Mexico City, Mexico.</location>
<contexts>
<context position="10366" citStr="Rehurek and Kolkus (2009)" startWordPosition="1609" endWordPosition="1612">inations of languages to consider for any given document. Language identification in multilingual documents could also be performed by application of supervised language segmentation algorithms. Given a system that can segment a document into labeled monolingual segments, we can then extract the languages present as well as the relative proportion of text in each language. Several methods for supervised language segmentation have been proposed. Teahan (2000) proposed a system based on text compression that identifies multilingual documents by first segmenting the text into monolingual blocks. Rehurek and Kolkus (2009) perform language segmentation by computing a relevance score between terms and languages, smoothing across adjoining terms and finally identifying points of transition between high and low relevance, which are interpreted as boundaries between languages. Yamaguchi and Tanaka-Ishii (2012) use a minimum description length approach, embedding a compressive model to compute the description length of text segments in each language. They present a linear-time dynamic programming solution to optimize the location of segment boundaries and language labels. 3 Methodology Language identification for mu</context>
</contexts>
<marker>Rehurek, Kolkus, 2009</marker>
<rawString>Radim Rehurek and Milan Kolkus. 2009. Language Identification on the Web: Extending the Dictionary Method. In Proceedings of Computational Linguistics and Intelligent Text Processing, 10th International Conference (CICLing 2009), pages 357–368, Mexico City, Mexico.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Mining the Web for bilingual text.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>527--534</pages>
<location>College Park, USA.</location>
<contexts>
<context position="2344" citStr="Resnik, 1999" startWordPosition="353" endWordPosition="354">pplications. Most natural language processing techniques presuppose monolingual input data, so inclusion of data in foreign languages introduces noise, and can degrade the performance of NLP systems (Alex et al., 2007; Cook and Lui, 2012). Automatic detection of multilingual documents can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and another language such as English (Yamaguchi and Tanaka-Ishii, 2012; King and Abney, 2013). King and Abney (2013, p1118) specifically mention the need for an automatic method “to examine a multilingual document, and with high accuracy, list the languages that are present in the document”. We introduce a method that is able to detect multilingual documents, and simultaneously identify each langua</context>
<context position="7543" citStr="Resnik, 1999" startWordPosition="1156" endWordPosition="1157">essive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual or</context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Philip Resnik. 1999. Mining the Web for bilingual text. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 527–534, College Park, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin P Scannell</author>
</authors>
<title>The Cr´ubad´an Project: Corpus building for under-resourced languages. In Building and Exploring Web Corpora:</title>
<date>2007</date>
<booktitle>Proceedings of the 3rd Web as Corpus Workshop,</booktitle>
<pages>5--15</pages>
<location>Louvainla-Neuve, Belgium.</location>
<contexts>
<context position="2201" citStr="Scannell, 2007" startWordPosition="333" endWordPosition="334"> multilingual, and estimates the proportion of the document that is written in each language. Detecting multilingual documents has a variety of applications. Most natural language processing techniques presuppose monolingual input data, so inclusion of data in foreign languages introduces noise, and can degrade the performance of NLP systems (Alex et al., 2007; Cook and Lui, 2012). Automatic detection of multilingual documents can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and another language such as English (Yamaguchi and Tanaka-Ishii, 2012; King and Abney, 2013). King and Abney (2013, p1118) specifically mention the need for an automatic method “to examine a multilingual document, and with high accuracy, list the languages </context>
<context position="7634" citStr="Scannell, 2007" startWordPosition="1171" endWordPosition="1172">e measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as the European Union. 28 English French Italian German Dutch Japanese cha</context>
</contexts>
<marker>Scannell, 2007</marker>
<rawString>Kevin P Scannell. 2007. The Cr´ubad´an Project: Corpus building for under-resourced languages. In Building and Exploring Web Corpora: Proceedings of the 3rd Web as Corpus Workshop, pages 5–15, Louvainla-Neuve, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J Teahan</author>
</authors>
<title>Text Classification and Segmentation Using Minimum Cross-Entropy.</title>
<date>2000</date>
<booktitle>In Proceedings the 6th International Conference “Recherche d’Information Assistee par Ordinateur” (RIAO’00),</booktitle>
<pages>943--961</pages>
<location>Paris, France.</location>
<contexts>
<context position="6959" citStr="Teahan, 2000" startWordPosition="1064" endWordPosition="1065">nction words and common suffixes (Giguet, 1995) or grammatical word classes (Dueire Lins and Gonc¸alves, 2004), though they are more frequently learned from labeled data (Cavnar and Trenkle, 1994; Grefenstette, 1995; Prager, 1999a; Lui and Baldwin, 2011). Learning algorithms applied to language identification fall into two general categories: Bayesian classifiers and nearest-prototype (Rocchio-style) classifiers. Bayesian approaches include Markov processes (Dunning, 1994), naive Bayes methods (Grefenstette, 1995; Lui and Baldwin, 2011; Tiedemann and Ljubeˇsi´c, 2012), and compressive models (Teahan, 2000). The nearest-prototype methods vary primarily in the distance measure used, including measures based on rank order statistics (Cavnar and Trenkle, 1994), information theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 19</context>
<context position="10203" citStr="Teahan (2000)" startWordPosition="1587" endWordPosition="1588">nstruct vectors representative of particular combinations of languages independent of the relative proportions, and proposes a method for choosing combinations of languages to consider for any given document. Language identification in multilingual documents could also be performed by application of supervised language segmentation algorithms. Given a system that can segment a document into labeled monolingual segments, we can then extract the languages present as well as the relative proportion of text in each language. Several methods for supervised language segmentation have been proposed. Teahan (2000) proposed a system based on text compression that identifies multilingual documents by first segmenting the text into monolingual blocks. Rehurek and Kolkus (2009) perform language segmentation by computing a relevance score between terms and languages, smoothing across adjoining terms and finally identifying points of transition between high and low relevance, which are interpreted as boundaries between languages. Yamaguchi and Tanaka-Ishii (2012) use a minimum description length approach, embedding a compressive model to compute the description length of text segments in each language. They </context>
</contexts>
<marker>Teahan, 2000</marker>
<rawString>W. J. Teahan. 2000. Text Classification and Segmentation Using Minimum Cross-Entropy. In Proceedings the 6th International Conference “Recherche d’Information Assistee par Ordinateur” (RIAO’00), pages 943–961, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
<author>Michael I Jordan</author>
<author>Matthew J Beal</author>
<author>David M Blei</author>
</authors>
<title>Hierarchical Dirichlet processes.</title>
<date>2006</date>
<journal>Journal of the American Statistical Association,</journal>
<pages>101--1566</pages>
<contexts>
<context position="44965" citStr="Teh et al., 2006" startWordPosition="7472" endWordPosition="7475">tification in multilingual documents. Previous work has shown that it is possible to generate a document representation that is robust to variation across domains (Lui and Baldwin, 2011), and we intend to investigate if these results are also applicable to language identification in multilingual documents. Another open question is the extension of the generative mixture models to “unknown” language identification (i.e. eliminating the closed-world assumption (Hughes et al., 2006)), which may be possible through the use of non-parametric mixture models such as Hierarchical Dirichlet Processes (Teh et al., 2006). 9 Conclusion We have presented a system for language identification in multilingual documents using a generative mixture model inspired by supervised topic modeling algorithms, combined with a document representation based on previous research in language identification for monolingual documents. We showed that the system outperforms alternative approaches from the literature on synthetic data, as well as on real-world data from related research on linguistic corpus creation for low-density languages using the web as a resource. We also showed that our system is able to accurately estimate t</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and David M. Blei. 2006. Hierarchical Dirichlet processes. Journal of the American Statistical Association, 101:1566–1581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J¨org Tiedemann</author>
<author>Nikola Ljubeˇsi´c</author>
</authors>
<title>Efficient discrimination between closely related languages.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012),</booktitle>
<pages>2619--2634</pages>
<location>Mumbai, India.</location>
<marker>Tiedemann, Ljubeˇsi´c, 2012</marker>
<rawString>J¨org Tiedemann and Nikola Ljubeˇsi´c. 2012. Efficient discrimination between closely related languages. In Proceedings of the 24th International Conference on Computational Linguistics (COLING 2012), pages 2619–2634, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giang Binh Tran</author>
<author>Dat Ba Nguyen</author>
<author>Bin Thanh Kieu</author>
</authors>
<title>N-gram based approach for multilingual language identification. poster. available at http://comp.mq.edu.au/programming/ task_description/VILangTek.pdf.</title>
<date>2010</date>
<contexts>
<context position="29277" citStr="Tran et al., 2010" startWordPosition="4869" endWordPosition="4872">g the training data provided for the shared task, with a slight difference: in the shared task, participants were provided with multilingual training documents, but the systems targeted in this research require monolingual training data. We thus split the training documents into monolingual segments using the metadata provided with the dataset. The metadata was only published after completion of the task and was not available to task participants. For comparison, we have included the benchmark results published by the shared task organizers, as well as the score attained by the winning entry (Tran et al., 2010). 3With a small number of monolingual documents, formed by randomly selecting the two languages for a given document independently, leaving the possibility of the same two languages being selected. 4http://comp.mq.edu.au/programming/task_ description/ 33 We tune the parameters for each system using the development partition of the dataset, and report results on the test partition. For LINGUINI, there is a single parameter k to be tuned: the number of features per language. We tested values between 10000 and 50000, and selected 46000 features as the optimal value. For our method, there are two </context>
</contexts>
<marker>Tran, Nguyen, Kieu, 2010</marker>
<rawString>Giang Binh Tran, Dat Ba Nguyen, and Bin Thanh Kieu. 2010. N-gram based approach for multilingual language identification. poster. available at http://comp.mq.edu.au/programming/ task_description/VILangTek.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xia</author>
<author>Carrie Lewis</author>
<author>William D Lewis</author>
</authors>
<title>Language ID for a thousand languages. In</title>
<date>2010</date>
<booktitle>LSA Annual Meeting Extended Abstracts,</booktitle>
<location>Baltimore,USA.</location>
<contexts>
<context position="7737" citStr="Xia et al., 2010" startWordPosition="1188" endWordPosition="1191">ation theory (Baldwin and Lui, 2010a), string kernels (Kruengkrai et al., 2005) and vector space models (Prager, 1999a; McNamee, 2005). Language identification has been applied in domains such as USENET messages (Cavnar and Trenkle, 1994), web pages (Kikui, 1996; Martins and Silva, 2005; Liu and Liang, 2008), web search queries (Ceylan and Kim, 2009; Bosca and Dini, 2010), mining the web for bilingual text (Resnik, 1999; Nie et al., 1999), building minority language corpora (Ghani et al., 2004; Scannell, 2007; Bergsma et al., 2012) as well as a largescale database of Interlinear Glossed Text (Xia et al., 2010), and the construction of a large-scale multilingual web crawl (Callan and Hoy, 2009). 2.1 Multilingual Documents Language identification over documents that contain text from more than one language has been identified as an open research question (Hughes et al., 2006). Common examples of multilingual documents are web pages that contain excerpts from another language, and documents from multilingual organizations such as the European Union. 28 English French Italian German Dutch Japanese character the pour di auf voo U byte 74 68 65 20 70 6F 75 7 20 64 69 20 20 61 75 66 76 6F 6 E3 81 AF Table</context>
</contexts>
<marker>Xia, Lewis, Lewis, 2010</marker>
<rawString>Fei Xia, Carrie Lewis, and William D. Lewis. 2010. Language ID for a thousand languages. In LSA Annual Meeting Extended Abstracts, Baltimore,USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Yamaguchi</author>
<author>Kumiko Tanaka-Ishii</author>
</authors>
<title>Text segmentation by language using minimum description length.</title>
<date>2012</date>
<booktitle>In Proceedings the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>969--978</pages>
<location>Jeju Island,</location>
<contexts>
<context position="2613" citStr="Yamaguchi and Tanaka-Ishii, 2012" startWordPosition="390" endWordPosition="393"> detection of multilingual documents can be used as a pre-filtering step to improve the quality of input data. Detecting multilingual documents is also important for acquiring linguistic data from the web (Scannell, 2007; Abney and Bird, 2010), and has applications in mining bilingual texts for statistical machine translation from online resources (Resnik, 1999; Nie et al., 1999; Ling et al., 2013). There has been particular interest in extracting text resources for low-density languages from multilingual web pages containing both the low-density language and another language such as English (Yamaguchi and Tanaka-Ishii, 2012; King and Abney, 2013). King and Abney (2013, p1118) specifically mention the need for an automatic method “to examine a multilingual document, and with high accuracy, list the languages that are present in the document”. We introduce a method that is able to detect multilingual documents, and simultaneously identify each language present as well as estimate the proportion of the document written in that language. We achieve this with a probabilistic mixture model, using a document representation developed for monolingual language identification (Lui and Baldwin, 2011). The model posits that </context>
<context position="10655" citStr="Yamaguchi and Tanaka-Ishii (2012)" startWordPosition="1651" endWordPosition="1655">hen extract the languages present as well as the relative proportion of text in each language. Several methods for supervised language segmentation have been proposed. Teahan (2000) proposed a system based on text compression that identifies multilingual documents by first segmenting the text into monolingual blocks. Rehurek and Kolkus (2009) perform language segmentation by computing a relevance score between terms and languages, smoothing across adjoining terms and finally identifying points of transition between high and low relevance, which are interpreted as boundaries between languages. Yamaguchi and Tanaka-Ishii (2012) use a minimum description length approach, embedding a compressive model to compute the description length of text segments in each language. They present a linear-time dynamic programming solution to optimize the location of segment boundaries and language labels. 3 Methodology Language identification for multilingual documents is a multi-label classification task, in which a document can be mapped onto any number of labels from a closed set. In the remainder of this paper, we denote the set of all languages by L. We denote a document D which contains languages Lx and Ly as D → {Lx, Ly}, whe</context>
<context position="19533" citStr="Yamaguchi and Tanaka-Ishii, 2012" startWordPosition="3226" endWordPosition="3230">ves the model additional freedom to fit parameters, and so will generally increase P(D|A). In the limit case, adding a completely irrelevant language will result in no tokens being mapped to the a language, and so the model will be no worse than without the language. The threshold t is thus used to control “how much” improvement is required before including the new language in A. 3.4 Benchmark Approaches We compare our approach to two methods for language identification in multilingual documents: (1) the virtual mixed languages approach (Prager, 1999a); and (2) the text segmentation approach (Yamaguchi and Tanaka-Ishii, 2012). Prager (1999a) describes LINGUINI, a language identifier based on the vector-space model commonly used in text classification and information retrieval. The document representation used by Prager (1999a) is a vector of counts across a set of character sequences. Prager (1999a) selects the feature set based on a TFIDF-like approach. Terms with occurrence count m &lt; n x k are rejected, where m is the number of times the term occurs in the training data (the TF component), n is the number of languages in which the term occurred (the IDF component, where “document” is replaced with “language”), a</context>
<context position="23290" citStr="Yamaguchi and Tanaka-Ishii (2012)" startWordPosition="3859" endWordPosition="3862">mputer algebra system to compute. Thus, our evaluation of the VML approach proposed by Prager (1999a) is limited to 3- language VMLs. Neither Prager (1999a) nor Prager (1999b) include an empirical evaluation over multilingual documents, so to the best of our knowledge this paper is the first empirical evaluation of the method on multilingual documents. As no reference implementation of this method is available, we have produced our own implementation, which we have made freely available.1 The other benchmark we consider in this paper is the method for text segmentation by language proposed by Yamaguchi and Tanaka-Ishii (2012) (hereafter referred to as SEGLANG). The actual task addressed by Yamaguchi and Tanaka-Ishii (2012) is to divide a document into monolingual segments. This is formulated as the task of segmenting a document D = x1, · · · , x|D |(where xi denotes the ith character of D and |D |is the length of the document) by finding a list of boundaries B = [B1, · · · , B|B|] where each Bi indicates the location of a language boundary as an offset from the start of the document, resulting in a list of segments X = [X0, · · · , X|B|]. For each segment Xi, the system predicts Li, the language associated with th</context>
<context position="39565" citStr="Yamaguchi and Tanaka-Ishii (2012)" startWordPosition="6565" endWordPosition="6568">minated. This correction improves our estimates of language proportions. After correction, the Pearson’s r rises to 0.981, and the MAE is reduced to 0.024. The improvement is most noticeable for language– document pairs where the proportion of the document in the given language is about 0.5 (Figure 2). 7 Real-world Multilingual Documents So far, we have demonstrated the effectiveness of our proposed approach using synthetic data. The results have been excellent, and in this section we validate the approach by applying it to a real-world task that has recently been discussed in the literature. Yamaguchi and Tanaka-Ishii (2012) and King and Abney (2013) both observe that in trying to gather linguistic data for “non-major” languages from the web, one challenge faced is that documents retrieved often contain sections in another language. SEGLANG (the solution of Yamaguchi and TanakaIshii (2012)) concurrently detects multilingual documents and segments them by language, but the approach is computationally expensive and has a tendency to over-label (Section 5). On the other hand, the solution of King and Abney (2013) is incomplete, and they specifically mention the need for an automatic method “to examine a multilingual</context>
</contexts>
<marker>Yamaguchi, Tanaka-Ishii, 2012</marker>
<rawString>Hiroshi Yamaguchi and Kumiko Tanaka-Ishii. 2012. Text segmentation by language using minimum description length. In Proceedings the 50th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 969–978, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yeh</author>
</authors>
<title>More accurate tests for the statistical significance of result differences.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING</booktitle>
<pages>947--953</pages>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="26877" citStr="Yeh, 2000" startWordPosition="4482" endWordPosition="4483">rt both the documentlevel micro-average, as well as the language-level macro-average. For consistency with Baldwin and Lui (2010a), the macro-averaged F-score we report is the average of the per-class F-scores, rather than the harmonic mean of the macro-averaged precision and recall; as such, it is possible for the F-score to not fall between the precision and recall values. As is common practice, we compute the F-score for β = 1, giving equal importance to precision and recall.2 We tested the difference in performance for statistical significance using an approximate randomization procedure (Yeh, 2000) with 10000 iterations. Within each table of results (Tables 2, 3 and 2Intuitively, it may seem that the maximal precision and recall should be achieved when precision and recall are balanced. However, because of the multi-label nature of the task and variable number of labels assigned to a given document by our models, it is theoretically possible and indeed common in our results for the maximal macro-averaged F-score to be achieved when macro-averaged precision and recall are not balanced. 4), all differences between systems are statistically significant at a p &lt; 0.05 level. To evaluate the </context>
</contexts>
<marker>Yeh, 2000</marker>
<rawString>Alexander Yeh. 2000. More accurate tests for the statistical significance of result differences. In Proceedings of the 18th International Conference on Computational Linguistics (COLING 2000), pages 947–953, Saarbr¨ucken, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>