<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000185">
<title confidence="0.928338">
Modeling Tweet Arrival Times using Log-Gaussian Cox Processes
</title>
<author confidence="0.97997">
Michal Lukasik,&apos; P.K. Srijith,&apos; Trevor Cohn,&apos; and Kalina Bontcheva&apos;
</author>
<affiliation confidence="0.99796375">
&apos;Department of Computer Science,
The University of Sheffield
&apos;Department of Computing and Information Systems,
The University of Melbourne
</affiliation>
<email confidence="0.9910635">
{m.lukasik, pk.srijith, k.bontcheva}@shef.ac.uk
t.cohn@unimelb.edu.au
</email>
<sectionHeader confidence="0.993777" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999749823529412">
Research on modeling time series text cor-
pora has typically focused on predicting
what text will come next, but less well
studied is predicting when the next text
event will occur. In this paper we ad-
dress the latter case, framed as modeling
continuous inter-arrival times under a log-
Gaussian Cox process, a form of inhomo-
geneous Poisson process which captures
the varying rate at which the tweets ar-
rive over time. In an application to ru-
mour modeling of tweets surrounding the
2014 Ferguson riots, we show how inter-
arrival times between tweets can be ac-
curately predicted, and that incorporating
textual features further improves predic-
tions.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998908037037037">
Twitter is a popular micro-blogging service which
provides real-time information on events happen-
ing across the world. Evolution of events over time
can be monitored there with applications to dis-
aster management, journalism etc. For example,
Twitter has been used to detect the occurrence of
earthquakes in Japan through user posts (Sakaki
et al., 2010). Modeling the temporal dynamics of
tweets provides useful information about the evo-
lution of events. Inter-arrival time prediction is a
type of such modeling and has application in many
settings featuring continuous time streaming text
corpora, including journalism for event monitor-
ing, real-time disaster monitoring and advertising
on social media. For example, journalists track
several rumours related to an event. Predicted ar-
rival times of tweets can be applied for ranking
rumours according to their activity and narrow the
interest to investigate a rumour with a short inter-
arrival time over that of a longer one.
Modeling the inter-arrival time of tweets is a
challenging task due to complex temporal patterns
exhibited. Tweets associated with an event stream
arrive at different rates at different points in time.
For example, Figure 1a shows the arrival times
(denoted by black crosses) of tweets associated
with an example rumour around Ferguson riots in
2014. Notice the existence of regions of both high
and low density of arrival times over a one hour
interval. We propose to address inter-arrival time
prediction problem with log-Gaussian Cox pro-
cess (LGCP), an inhomogeneous Poisson process
(IPP) which models tweets to be generated by an
underlying intensity function which varies across
time. Moreover, it assumes a non-parametric form
for the intensity function allowing the model com-
plexity to depend on the data set. We also pro-
vide an approach to consider textual content of
tweets to model inter-arrival times. We evaluate
the models using Twitter rumours from the 2014
Ferguson unrest, and demonstrate that they pro-
vide good predictions for inter-arrival times, beat-
ing the baselines e.g. homogeneous Poisson Pro-
cess, Gaussian Process regression and univariate
Hawkes Process. Even though the central appli-
cation is rumours, one could apply the proposed
approaches to model the arrival times of tweets
corresponding to other types of memes, e.g. dis-
cussions about politics.
This paper makes the following contributions:
1. Introduces log-Gaussian Cox process to predict
tweet arrival times. 2. Demonstrates how incor-
porating text improves results of inter-arrival time
prediction.
</bodyText>
<sectionHeader confidence="0.999798" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9990146">
Previous approaches to modeling inter-arrival
times of tweets (Perera et al., 2010; Sakaki et al.,
2010; Esteban et al., 2012; Doerr et al., 2013) were
not complex enough to consider their time vary-
ing characteristics. Perera et al. (2010) modeled
</bodyText>
<page confidence="0.947661">
250
</page>
<note confidence="0.856809">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 250–255,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figure confidence="0.999569">
Intensity function values
15
10
5
0
Intensity function values
1h 2h
Time
(a) rumour #39
1h 2h
Time
(b) rumour #60
15
10
5
0
LGCPTXT
LGCP
LGCPTXT
LGCP
</figure>
<figureCaption confidence="0.921174333333333">
Figure 1: Intensity functions and corresponding predicted arrival times for different methods across
example Ferguson rumours. Arrival times predicted by LGCP are denoted by red pluses, LGCPTXT by
blue dots, and ground truth by black crosses. Light regions denote uncertainty of predictions.
</figureCaption>
<bodyText confidence="0.999938269230769">
inter-arrival times as independent and exponen-
tially distributed with a constant rate parameter. A
similar model is used by Sakaki et al. (2010) to
monitor the tweets related to earthquakes. The re-
newal process model used by Esteban et al. (2012)
assumes the inter-arrival times to be independent
and identically distributed. Gonzalez et al. (2014)
attempts to model arrival times of tweets using a
Gaussian process but assumes the tweet arrivals to
be independent every hour. These approaches do
not take into account the varying characteristics of
arrival times of tweets.
Point processes such as Poisson and Hawkess
process have been used for spatio-temporal model-
ing of meme spread in social networks (Yang and
Zha, 2013; Simma and Jordan, 2010). Hawkes
processes (Yang and Zha, 2013) were also found
to be useful for modeling the underlying network
structure. These models capture relevant network
information in the underlying intensity function.
We use a log-Gaussian cox process which provides
a Bayesian method to capture relevant information
through the prior. It has been found to be use-
ful e.g. for conflict mapping (Zammit-Mangion
et al., 2012) and for frequency prediction in Twit-
ter (Lukasik et al., 2015).
</bodyText>
<sectionHeader confidence="0.950846" genericHeader="method">
3 Data &amp; Problem
</sectionHeader>
<bodyText confidence="0.947790617647059">
In this section we describe the data and we formal-
ize the problem of modeling tweet arrival times.
Data We consider the Ferguson rumour data set
(Zubiaga et al., 2015), consisting of tweets on ru-
mours around 2014 Ferguson unrest. It consists
of conversational threads that have been manually
labeled by annotators to correspond to rumours1.
Since some rumours have few posts, we consider
only those with at least 15 posts in the first hour as
they express interesting behaviour (Lukasik et al.,
2015). This results in 114 rumours consisting of a
total of 4098 tweets.
Problem Definition Let us consider a time in-
terval [0, 2] measured in hours, a set of rumours
R = {Ei}n i=1, where rumour Ei consists of a
set of mi posts Ei = {pij}mi
j=1. Posts are tuples
pij = (xij, tij), where xij is text (in our case a vec-
tor of Brown clusters counts, see section 5) and ti j
is time of occurrence of post pij, measured in time
since the first post on rumour Ei.
We introduce the problem of predicting the ex-
act time of posts in the future unobserved time in-
terval, which is studied as inter-arrival time pre-
diction. In our setting, we observe posts over
a target rumour i for one hour and over refer-
ence rumours (other than i) for two hours. Thus,
the training data set is RO = {EOi }ni=1, where
O
EOi = {pij }mi (m9 represents number of posts
observed for ith rumour). We query the model for
a complete set of times {tij}mi
mOi +1 of posts about
rumour i in the future one hour time interval.
</bodyText>
<footnote confidence="0.910322666666667">
1For a fully automated approach, a system for early detec-
tion of rumours (Zhao et al., 2015) could be run first and our
models then applied to the resulting rumours.
</footnote>
<page confidence="0.996918">
251
</page>
<sectionHeader confidence="0.994005" genericHeader="method">
4 Model
</sectionHeader>
<bodyText confidence="0.973237111111111">
The problem of modeling the inter-arrival times of
tweets can be solved using Poisson processes (Per-
era et al., 2010; Sakaki et al., 2010). A homo-
geneous Poisson process (HPP) assumes the in-
tensity to be constant (with respect to time and
the rumour statistics). It is not adequate to model
the inter-arrival times of tweets because it assumes
constant rate of point arrival across time. Inhomo-
geneous Poisson process (IPP) (Lee et al., 1991)
can model tweets occurring at a variable rate by
considering the intensity to be a function of time,
i.e. λ(t). For example, in Figure 1a we show in-
tensity functions learnt for two different IPP mod-
els. Notice how the generated arrival times vary
according to the intensity function values.
Log-Gaussian Cox process We consider a
log-Gaussian Cox process (LGCP) (Møller and
Syversveen, 1998), a special case of IPP, where
the intensity function is assumed to be stochas-
tic. The intensity function λ(t) is modeled using
a latent function f(t) sampled from a Gaussian
process (Rasmussen and Williams, 2005). To en-
sure positivity of the intensity function, we con-
sider λ(t) = exp (f(t)). This provides a non-
parametric Bayesian approach to model the inten-
sity function, where the complexity of the model
is learnt from the training data. Moreover, we can
define the functional form of the intensity function
through appropriate GP priors.
Modeling inter-arrival time Inhomogeneous
Poisson process (unlike HPP) uses a time vary-
ing intensity function and hence, the distribution
of inter-arrival times is not independent and iden-
tically distributed (Ross, 2010). In IPP, the number
of tweets y occurring in an interval [s, e] is Poisson
distributed with rate fse λ(t)dt.
</bodyText>
<equation confidence="0.978864">
e
t s,e]) = Poisson(y |λ(t)dt)
is
(fse λ(t)dt)y exp(− fse λ(t)dt) =(1)
y!
</equation>
<bodyText confidence="0.9999565">
Assume that nth tweet occurred at time En = s
and we are interested in the inter-arrival time Tn
of the next tweet. The arrival time of next tweet
En+1 can be obtained as En+1 = En + Tn. The
cumulative distribution for Tn, which provides the
probability that a tweet occurs by time s + u can
</bodyText>
<equation confidence="0.96442">
be obtained as2
p(Tn &lt; u) = 1 − p(Tn &gt; u|λ(t), En = s)
= 1 − p(0 events in [s, s + u]|λ(t))
fs+n
= 1 − exp(− J A(t)dt)
fs
U
= 1 − exp(− J A(s + t)dt) (2)
0
</equation>
<bodyText confidence="0.911232571428571">
The derivation is obtained by considering a
Poisson probability for 0 counts with rate parame-
ter given by f s+u
s λ(t)dt and applying integration
by substitution to obtain (2). The probability den-
sity function of the random variable Tn is obtained
by taking the derivative of (2) with respect to u:
</bodyText>
<equation confidence="0.997773666666667">
p(Tn = u) = λ(s + u) exp(− J n λ(s + t)dt).
0
(3)
</equation>
<bodyText confidence="0.9983372">
The computational difficulties arising from inte-
gration are dealt by assuming the intensity func-
tion to be constant in an interval and approximat-
ing the inter-arrival time density as (Møller and
Syversveen, 1998; Vanhatalo et al., 2013)
</bodyText>
<equation confidence="0.9461855">
u
p(Tn = u) = λ(s + u) exp(−uλ(s + 2 )). (4)
</equation>
<bodyText confidence="0.999982090909091">
We associate a distinct intensity function
λi(t) = exp(fi(t)) with each rumour Ei as
they have varying temporal profiles. The la-
tent function fi is modelled to come from a
zero mean Gaussian process (GP) (Rasmussen
and Williams, 2005) prior with covariance de-
fined by a squared exponential (SE) kernel over
time, ktime(t, t&apos;) = a exp(−(t − t&apos;)2/l). We con-
sider the likelihood of posts EOi over the entire
training period to be product of Poisson distri-
bution (1) over equal length sub-intervals with
the rate in a sub-interval [s, e] approximated as
(e − s) exp(fi(12(s + e))). The likelihood of posts
in the rumour data is obtained by taking the prod-
uct of the likelihoods over individual rumours.
The distribution of the posterior p(fi|EOi ) is
intractable and a Laplace approximation (Ras-
mussen and Williams, 2005) is used to obtain the
posterior. The predictive distribution fi(ti�) at time
ti� is obtained using the approximated posterior.
The intensity function value at the point ti� is then
obtained as
</bodyText>
<equation confidence="0.679605">
λi(t*|E°) = J exp (fi (t&apos;)) p (fi (t*)|EiO) dfi(t*).
</equation>
<footnote confidence="0.979017">
2We suppress the conditioning variables for brevity.
</footnote>
<page confidence="0.994408">
252
</page>
<bodyText confidence="0.58435">
Algorithm 1 Importance sampling for predicting
the next arrival time
</bodyText>
<listItem confidence="0.985639857142857">
1: Input: Intensity function A(t), previous ar-
rival time s, proposal distribution
q(t) = exp(t; 2), number of samples N
2: for i = 1 to N do
3: Sample ui ∼ q(t).
4: Obtain weights wi = p(ui),
q(ui)
</listItem>
<bodyText confidence="0.737919">
where p(t) is given by (4).
</bodyText>
<listItem confidence="0.575907">
5: end for
6: Predict expected inter-arrival time as
</listItem>
<equation confidence="0.279210333333333">
u¯= ENN wi
1 ui N
�.j=1 wj
</equation>
<listItem confidence="0.978713">
7: Predict the next arrival time as t = s + ¯u.
8: Return: t¯
</listItem>
<bodyText confidence="0.98573121875">
Importance sampling We are interested in pre-
dicting the next arrival time of a tweet given the
time at which the previous tweet was posted. This
is achieved by sampling the inter-arrival time of
occurrence of the next tweet using equation (4).
We use the importance sampling scheme (Gelman
et al., 2003) where an exponential distribution is
used as the proposal density. We set the rate pa-
rameter of this exponential distribution to 2 which
generates points with a mean value around 0.5.
Assuming the previous tweet occurred at time s,
we obtain the arrival time of next tweet as outlined
in Algorithm 1. We run this algorithm sequen-
tially, i.e. the time t¯ returned from Algorithm 1
becomes starting time s in the next iteration. We
stop at the end of the interval of interest, for which
a user wants to find times of post occurrences.
Incorporating text We consider adding the
kernel over text from posts to the previously
introduced kernel over time. We join text
from the observed posts together, so a dif-
ferent component is added to kernel values
across different rumours. The full kernel then
takes form kTXT((t, i), (t&apos;, i&apos;)) = ktime(t, t&apos;) +
ktext (Epij EEO xij , Epi�
j EEOi� x�) . We compare
text via linear kernel with additive underlying base
similarity, expressed by ktext(x, x&apos;) = b + cxT x&apos;.
Optimization All model parameters (a, l, b, c)
are obtained by maximizing the marginal likeli-
hood p(EOi ) = f p(EOi |fi)p(fi)dfi over all ru-
mour data sets.
</bodyText>
<sectionHeader confidence="0.998693" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999923370370371">
Data preprocessing In our experiments, we
consider the first two hours of each rumour lifes-
pan. The posts from the first hour of a target ru-
mour is considered as observed (training data) and
we predict the arrival times of tweets in the sec-
ond hour. We consider observations over equal
sized time intervals of length six minutes in the
rumour lifespan for learning the intensity func-
tion. The text in the tweets is represented by using
Brown cluster ids associated with the words. This
is obtained using 1000 clusters acquired on a large
scale Twitter corpus (Owoputi et al., 2013).
Evaluation metrics Let the arrival times pre-
dicted by a model be (ˆt1, ... , ˆtM) and let the
actual arrival times be (t1, ... , tN). We intro-
duce two metrics based on root mean squared er-
ror (RMSE) for evaluating predicted inter-arrival
times. First is aligned root mean squared er-
ror (ARMSE), where we align the initial K =
min(M, N) arrival times and calculate the RMSE
between such two subsequences. The sec-
ond is called penalized root mean squared error
(PRMSE). In this metric we penalize approaches
which predict a different number of inter-arrival
times than the actual number. The PRMSE met-
ric is defined as the square root of the following
expression.
</bodyText>
<equation confidence="0.996586">
M
(ˆti − ti)2 + I[M &gt; N] (T − ˆti)2
i=N+1
N
+I[M &lt; N] (T − ti)2 (5)
i=M+1
</equation>
<bodyText confidence="0.999930733333333">
The second and third term in (5) respectively pe-
nalize for the excessive or insufficient number of
points predicted by the model.
Baselines We consider a homogeneous Poisson
process (HPP) (Perera et al., 2010) as a baseline
which results in exponentially distributed inter-
arrival times with rate A. The rate parameter is
set to the maximum likelihood estimate, the recip-
rocal of the mean of the inter-arrival times in the
training data. The second baseline is a GP with
a linear kernel (GPLIN), where the inter-arrival
time is modeled as a function of time of occur-
rence of last tweet. This model tends to predict
small inter-arrival times yielding a huge number
of points. We limit the number of predicted points
</bodyText>
<equation confidence="0.9856395">
1 K
K i=1
</equation>
<page confidence="0.995593">
253
</page>
<table confidence="0.995877142857143">
method ARMSE PRMSE
GPLIN 20.60±22.01* 1279.78±903.90*
HPP 21.85±22.82* 431.4±96.5*
HP 15.94±18.20 363.70±59.01*
LGCP 13.31±14.28 261.26±92.97*
LGCP Pooled 19.18±20.36* 183.25±102.20*
LGCPTXT 15.52±18.79 154.05±115.70
</table>
<tableCaption confidence="0.998557">
Table 1: ARMSE and PRMSE between the true
</tableCaption>
<bodyText confidence="0.998157471428572">
event times and the predicted event times ex-
pressed in minutes (lower is better) over the 114
Ferguson rumours, showing mean ± std. dev.
Key * denotes significantly worse than LGCPTXT
method according to one-sided Wilcoxon signed
rank test (p &lt; 0.05). In case of ARMSE, LGCP is
not significantly better than LGCP TXT according
to Wilcoxon test.
to 1000 (above the maximum count yielded by any
rumour from our dataset), thus reducing the error
from this method.
We also compare against Hawkes Process
(HP) (Yang and Zha, 2013), a self exciting point
process where an occurrence of a tweet increases
the probability of tweets arriving soon after-
wards. We consider a univariate Hawkes pro-
cess where the intensity function is modeled as
λi(t) = µ + Eti&lt;t ktime(ti, t). The kernel pa-
rameters and µ are learnt by maximizing the like-
lihood. We apply the importance sampling algo-
rithm discussed in Algorithm 1 for generating ar-
rival times for Hawkess process. We consider this
baseline only in the single-task setting, where ref-
erence rumours are not considered.
LGCP settings In the case of LGCP, the model
parameters of the intensity function associated
with a rumour are learnt from the observed inter-
arrival times from that rumour alone. LGCP
Pooled and LGCPTXT consider a different setting
where this is learnt additionally using the inter-
arrival times of all other rumours observed over
the entire two hour life-span.
Results Table 1 reports the results of predicting
arrival times of tweets in the second hour of the
rumour lifecycle. In terms of ARMSE, LGCP is
the best method, performing better than LGCP-
TXT (though not statistically significantly) and
outperforming other approaches. However, this
metric does not penalize for the wrong number
of predicted arrival times. Figure 1b depicts an
example rumour, where LGCP greatly overesti-
mates the number of points in the interval of inter-
est. Here, the three points from the ground truth
(denoted by black crosses) and the initial three
points predicted by the LGCP model (denoted by
red pluses), happen to lie very close, yielding a
low ARMSE error. However, LGCP predicts a
large number of arrivals in this interval making it a
bad model compared to LGCPTXT which predicts
only four points (denoted by blue dots). ARMSE
fails to capture this and hence we use PRMSE.
Note that Hawkes Process is performing worse
than the LGCP approach.
According to PRMSE, LGCPTXT is the most
successful method, significantly outperforming all
other according to Wilcoxon signed rank test. Fig-
ure 1a depicts the behavior of LGCP and LGCP-
TXT on rumour 39 with a larger number of points
from the ground truth. Here, LGCPTXT predicts
relatively less number of arrivals than LGCP. The
performance of Hawkes Process is again worse
than the LGCP approach. The self excitory nature
of Hawkes process may not be appropriate for this
dataset and setting, where in the second hour the
number of points tends to decrease as time passes.
We also note, that GPLIN performs very poorly
according to PRMSE. This is because the inter-
arrival times predicted by GPLIN for several ru-
mours become smaller as time grows resulting in
a large number of arrival times.
</bodyText>
<sectionHeader confidence="0.999625" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999945555555555">
This paper introduced the log-Gaussian Cox pro-
cesses for the problem of predicting the inter-
arrival times of tweets. We showed how text from
posts helps to achieve significant improvements.
Evaluation on a set of rumours from Ferguson ri-
ots showed efficacy of our methods comparing to
baselines. The proposed approaches are generaliz-
able to problems other than rumours, e.g. disaster
management and advertisement campaigns.
</bodyText>
<sectionHeader confidence="0.998315" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9863835">
Work partially supported by the European Union
under grant agreement No. 611233 PHEME.
</bodyText>
<sectionHeader confidence="0.998908" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994486">
Christian Doerr, Norbert Blenn, and Piet Van
Mieghem. 2013. Lognormal infection times of on-
line information spread. PLOS ONE, 8.
</reference>
<page confidence="0.991994">
254
</page>
<reference confidence="0.999676633802817">
J. Esteban, A. Ortega, S. McPherson, and M. Sathi-
amoorthy. 2012. Analysis of Twitter Traffic based
on Renewal Densities. ArXiv e-prints.
Andrew Gelman, John B. Carlin, Hal S. Stern, and
Donald B. Rubin. 2003. Bayesian Data Analysis.
Chapman and Hall/CRC.
Roberto Gonzalez, Alfonso Mu˜noz, Jos´e Alberto
Hern´andez, and Ruben Cuevas. 2014. On the tweet
arrival process at twitter: analysis and applications.
Trans. Emerging Telecommunications Technologies,
25(2):273–282.
S. H. Lee, M. M. Crawford, and J. R. Wilson. 1991.
Modeling and simulation of a nonhomogeneous
poisson process having cyclic behavior. Communi-
cations in Statistics Simulation, 20(2):777–809.
Michal Lukasik, Trevor Cohn, and Kalina Bontcheva.
2015. Point process modelling of rumour dynamics
in social media. In Proceedings of the 53rd Annual
Meeting of the Association for Computational Lin-
guistics and the 7th International Joint Conference
on Natural Language Processing of the Asian Fed-
eration of Natural Language Processing, ACL 2015,
pages 518–523.
Jesper Møller and Anne Randi Syversveen. 1998. Log
Gaussian Cox processes. Scandinavian Journal of
Statistics, pages 451–482.
Olutobi Owoputi, Chris Dyer, Kevin Gimpel, Nathan
Schneider, and Noah A. Smith. 2013. Improved
part-of-speech tagging for online conversational text
with word clusters. In In Proceedings of NAACL.
Rohan DW Perera, Sruthy Anand, KP Subbalakshmi,
and R Chandramouli. 2010. Twitter analytics: Ar-
chitecture, tools and analysis. In Military Commu-
nications Conference, 2010-MILCOM 2010, pages
2186–2191.
Carl Edward Rasmussen and Christopher K. I.
Williams. 2005. Gaussian Processes for Ma-
chine Learning (Adaptive Computation and Ma-
chine Learning). The MIT Press.
Sheldon M. Ross. 2010. Introduction to Probability
Models, Tenth Edition. Academic Press, Inc., Or-
lando, FL, USA.
Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo.
2010. Earthquake shakes twitter users: Real-time
event detection by social sensors. In Proceedings
of the 19th International Conference on World Wide
Web, WWW ’10, pages 851–860.
Aleksandr Simma and Michael I. Jordan. 2010. Mod-
eling events with cascades of poisson processes. In
UAI, pages 546–555.
Jarno Vanhatalo, Jaakko Riihim¨aki, Jouni Hartikainen,
Pasi Jyl¨anki, Ville Tolvanen, and Aki Vehtari. 2013.
Gpstuff: Bayesian modeling with gaussian pro-
cesses. J. Mach. Learn. Res., 14(1):1175–1179.
Shuang-Hong Yang and Hongyuan Zha. 2013. Mix-
ture of mutually exciting processes for viral diffu-
sion. In ICML (2), volume 28 of JMLR Proceedings,
pages 1–9.
Andrew Zammit-Mangion, Michael Dewar, Visakan
Kadirkamanathan, and Guido Sanguinetti. 2012.
Point process modelling of the afghan war diary. In
Proceedings of the National Academy of Sciences,
Vol. 109, No. 31, pages 12414–12419.
Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015.
Early detection of rumors in social media from en-
quiry posts. In International World Wide Web Con-
ference Committee (IW3C2).
Arkaitz Zubiaga, Maria Liakata, Rob Procter, Kalina
Bontcheva, and Peter Tolmie. 2015. Towards de-
tecting rumours in social media. In AAAI Workshop
on AI for Cities.
</reference>
<page confidence="0.998396">
255
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.176735">
<title confidence="0.996727">Modeling Tweet Arrival Times using Log-Gaussian Cox Processes</title>
<affiliation confidence="0.66107625">of Computer The University of of Computing and Information The University of</affiliation>
<email confidence="0.7954915">pk.srijith,t.cohn@unimelb.edu.au</email>
<abstract confidence="0.995034944444444">Research on modeling time series text corpora has typically focused on predicting what text will come next, but less well studied is predicting when the next text event will occur. In this paper we address the latter case, framed as modeling continuous inter-arrival times under a log- Gaussian Cox process, a form of inhomogeneous Poisson process which captures the varying rate at which the tweets arrive over time. In an application to rumour modeling of tweets surrounding the 2014 Ferguson riots, we show how interarrival times between tweets can be accurately predicted, and that incorporating textual features further improves predictions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christian Doerr</author>
<author>Norbert Blenn</author>
<author>Piet Van Mieghem</author>
</authors>
<title>Lognormal infection times of online information spread.</title>
<date>2013</date>
<journal>PLOS ONE,</journal>
<volume>8</volume>
<marker>Doerr, Blenn, Van Mieghem, 2013</marker>
<rawString>Christian Doerr, Norbert Blenn, and Piet Van Mieghem. 2013. Lognormal infection times of online information spread. PLOS ONE, 8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Esteban</author>
<author>A Ortega</author>
<author>S McPherson</author>
<author>M Sathiamoorthy</author>
</authors>
<title>Analysis of Twitter Traffic based on Renewal Densities. ArXiv e-prints.</title>
<date>2012</date>
<contexts>
<context position="3709" citStr="Esteban et al., 2012" startWordPosition="564" endWordPosition="567">Poisson Process, Gaussian Process regression and univariate Hawkes Process. Even though the central application is rumours, one could apply the proposed approaches to model the arrival times of tweets corresponding to other types of memes, e.g. discussions about politics. This paper makes the following contributions: 1. Introduces log-Gaussian Cox process to predict tweet arrival times. 2. Demonstrates how incorporating text improves results of inter-arrival time prediction. 2 Related Work Previous approaches to modeling inter-arrival times of tweets (Perera et al., 2010; Sakaki et al., 2010; Esteban et al., 2012; Doerr et al., 2013) were not complex enough to consider their time varying characteristics. Perera et al. (2010) modeled 250 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 250–255, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Intensity function values 15 10 5 0 Intensity function values 1h 2h Time (a) rumour #39 1h 2h Time (b) rumour #60 15 10 5 0 LGCPTXT LGCP LGCPTXT LGCP Figure 1: Intensity functions and corresponding predicted arrival times for different methods across example Ferguson rumours. Arr</context>
</contexts>
<marker>Esteban, Ortega, McPherson, Sathiamoorthy, 2012</marker>
<rawString>J. Esteban, A. Ortega, S. McPherson, and M. Sathiamoorthy. 2012. Analysis of Twitter Traffic based on Renewal Densities. ArXiv e-prints.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Gelman</author>
<author>John B Carlin</author>
<author>Hal S Stern</author>
<author>Donald B Rubin</author>
</authors>
<title>Bayesian Data Analysis. Chapman and Hall/CRC.</title>
<date>2003</date>
<contexts>
<context position="12095" citStr="Gelman et al., 2003" startWordPosition="2031" endWordPosition="2034"> time s, proposal distribution q(t) = exp(t; 2), number of samples N 2: for i = 1 to N do 3: Sample ui ∼ q(t). 4: Obtain weights wi = p(ui), q(ui) where p(t) is given by (4). 5: end for 6: Predict expected inter-arrival time as u¯= ENN wi 1 ui N �.j=1 wj 7: Predict the next arrival time as t = s + ¯u. 8: Return: t¯ Importance sampling We are interested in predicting the next arrival time of a tweet given the time at which the previous tweet was posted. This is achieved by sampling the inter-arrival time of occurrence of the next tweet using equation (4). We use the importance sampling scheme (Gelman et al., 2003) where an exponential distribution is used as the proposal density. We set the rate parameter of this exponential distribution to 2 which generates points with a mean value around 0.5. Assuming the previous tweet occurred at time s, we obtain the arrival time of next tweet as outlined in Algorithm 1. We run this algorithm sequentially, i.e. the time t¯ returned from Algorithm 1 becomes starting time s in the next iteration. We stop at the end of the interval of interest, for which a user wants to find times of post occurrences. Incorporating text We consider adding the kernel over text from po</context>
</contexts>
<marker>Gelman, Carlin, Stern, Rubin, 2003</marker>
<rawString>Andrew Gelman, John B. Carlin, Hal S. Stern, and Donald B. Rubin. 2003. Bayesian Data Analysis. Chapman and Hall/CRC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Gonzalez</author>
<author>Alfonso Mu˜noz</author>
<author>Jos´e Alberto Hern´andez</author>
<author>Ruben Cuevas</author>
</authors>
<title>On the tweet arrival process at twitter: analysis and applications. Trans. Emerging Telecommunications Technologies,</title>
<date>2014</date>
<pages>25--2</pages>
<marker>Gonzalez, Mu˜noz, Hern´andez, Cuevas, 2014</marker>
<rawString>Roberto Gonzalez, Alfonso Mu˜noz, Jos´e Alberto Hern´andez, and Ruben Cuevas. 2014. On the tweet arrival process at twitter: analysis and applications. Trans. Emerging Telecommunications Technologies, 25(2):273–282.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S H Lee</author>
<author>M M Crawford</author>
<author>J R Wilson</author>
</authors>
<title>Modeling and simulation of a nonhomogeneous poisson process having cyclic behavior.</title>
<date>1991</date>
<journal>Communications in Statistics Simulation,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="7815" citStr="Lee et al., 1991" startWordPosition="1265" endWordPosition="1268">r a fully automated approach, a system for early detection of rumours (Zhao et al., 2015) could be run first and our models then applied to the resulting rumours. 251 4 Model The problem of modeling the inter-arrival times of tweets can be solved using Poisson processes (Perera et al., 2010; Sakaki et al., 2010). A homogeneous Poisson process (HPP) assumes the intensity to be constant (with respect to time and the rumour statistics). It is not adequate to model the inter-arrival times of tweets because it assumes constant rate of point arrival across time. Inhomogeneous Poisson process (IPP) (Lee et al., 1991) can model tweets occurring at a variable rate by considering the intensity to be a function of time, i.e. λ(t). For example, in Figure 1a we show intensity functions learnt for two different IPP models. Notice how the generated arrival times vary according to the intensity function values. Log-Gaussian Cox process We consider a log-Gaussian Cox process (LGCP) (Møller and Syversveen, 1998), a special case of IPP, where the intensity function is assumed to be stochastic. The intensity function λ(t) is modeled using a latent function f(t) sampled from a Gaussian process (Rasmussen and Williams, </context>
</contexts>
<marker>Lee, Crawford, Wilson, 1991</marker>
<rawString>S. H. Lee, M. M. Crawford, and J. R. Wilson. 1991. Modeling and simulation of a nonhomogeneous poisson process having cyclic behavior. Communications in Statistics Simulation, 20(2):777–809.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Lukasik</author>
<author>Trevor Cohn</author>
<author>Kalina Bontcheva</author>
</authors>
<title>Point process modelling of rumour dynamics in social media.</title>
<date>2015</date>
<booktitle>In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL</booktitle>
<pages>518--523</pages>
<contexts>
<context position="5691" citStr="Lukasik et al., 2015" startWordPosition="875" endWordPosition="878">Poisson and Hawkess process have been used for spatio-temporal modeling of meme spread in social networks (Yang and Zha, 2013; Simma and Jordan, 2010). Hawkes processes (Yang and Zha, 2013) were also found to be useful for modeling the underlying network structure. These models capture relevant network information in the underlying intensity function. We use a log-Gaussian cox process which provides a Bayesian method to capture relevant information through the prior. It has been found to be useful e.g. for conflict mapping (Zammit-Mangion et al., 2012) and for frequency prediction in Twitter (Lukasik et al., 2015). 3 Data &amp; Problem In this section we describe the data and we formalize the problem of modeling tweet arrival times. Data We consider the Ferguson rumour data set (Zubiaga et al., 2015), consisting of tweets on rumours around 2014 Ferguson unrest. It consists of conversational threads that have been manually labeled by annotators to correspond to rumours1. Since some rumours have few posts, we consider only those with at least 15 posts in the first hour as they express interesting behaviour (Lukasik et al., 2015). This results in 114 rumours consisting of a total of 4098 tweets. Problem Defin</context>
</contexts>
<marker>Lukasik, Cohn, Bontcheva, 2015</marker>
<rawString>Michal Lukasik, Trevor Cohn, and Kalina Bontcheva. 2015. Point process modelling of rumour dynamics in social media. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing of the Asian Federation of Natural Language Processing, ACL 2015, pages 518–523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jesper Møller</author>
<author>Anne Randi Syversveen</author>
</authors>
<title>Log Gaussian Cox processes.</title>
<date>1998</date>
<journal>Scandinavian Journal of Statistics,</journal>
<pages>451--482</pages>
<contexts>
<context position="8207" citStr="Møller and Syversveen, 1998" startWordPosition="1329" endWordPosition="1332">nstant (with respect to time and the rumour statistics). It is not adequate to model the inter-arrival times of tweets because it assumes constant rate of point arrival across time. Inhomogeneous Poisson process (IPP) (Lee et al., 1991) can model tweets occurring at a variable rate by considering the intensity to be a function of time, i.e. λ(t). For example, in Figure 1a we show intensity functions learnt for two different IPP models. Notice how the generated arrival times vary according to the intensity function values. Log-Gaussian Cox process We consider a log-Gaussian Cox process (LGCP) (Møller and Syversveen, 1998), a special case of IPP, where the intensity function is assumed to be stochastic. The intensity function λ(t) is modeled using a latent function f(t) sampled from a Gaussian process (Rasmussen and Williams, 2005). To ensure positivity of the intensity function, we consider λ(t) = exp (f(t)). This provides a nonparametric Bayesian approach to model the intensity function, where the complexity of the model is learnt from the training data. Moreover, we can define the functional form of the intensity function through appropriate GP priors. Modeling inter-arrival time Inhomogeneous Poisson proces</context>
<context position="10163" citStr="Møller and Syversveen, 1998" startWordPosition="1686" endWordPosition="1689">)) fs+n = 1 − exp(− J A(t)dt) fs U = 1 − exp(− J A(s + t)dt) (2) 0 The derivation is obtained by considering a Poisson probability for 0 counts with rate parameter given by f s+u s λ(t)dt and applying integration by substitution to obtain (2). The probability density function of the random variable Tn is obtained by taking the derivative of (2) with respect to u: p(Tn = u) = λ(s + u) exp(− J n λ(s + t)dt). 0 (3) The computational difficulties arising from integration are dealt by assuming the intensity function to be constant in an interval and approximating the inter-arrival time density as (Møller and Syversveen, 1998; Vanhatalo et al., 2013) u p(Tn = u) = λ(s + u) exp(−uλ(s + 2 )). (4) We associate a distinct intensity function λi(t) = exp(fi(t)) with each rumour Ei as they have varying temporal profiles. The latent function fi is modelled to come from a zero mean Gaussian process (GP) (Rasmussen and Williams, 2005) prior with covariance defined by a squared exponential (SE) kernel over time, ktime(t, t&apos;) = a exp(−(t − t&apos;)2/l). We consider the likelihood of posts EOi over the entire training period to be product of Poisson distribution (1) over equal length sub-intervals with the rate in a sub-interval [s</context>
</contexts>
<marker>Møller, Syversveen, 1998</marker>
<rawString>Jesper Møller and Anne Randi Syversveen. 1998. Log Gaussian Cox processes. Scandinavian Journal of Statistics, pages 451–482.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olutobi Owoputi</author>
<author>Chris Dyer</author>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Noah A Smith</author>
</authors>
<title>Improved part-of-speech tagging for online conversational text with word clusters. In</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="13850" citStr="Owoputi et al., 2013" startWordPosition="2340" endWordPosition="2343">ver all rumour data sets. 5 Experiments Data preprocessing In our experiments, we consider the first two hours of each rumour lifespan. The posts from the first hour of a target rumour is considered as observed (training data) and we predict the arrival times of tweets in the second hour. We consider observations over equal sized time intervals of length six minutes in the rumour lifespan for learning the intensity function. The text in the tweets is represented by using Brown cluster ids associated with the words. This is obtained using 1000 clusters acquired on a large scale Twitter corpus (Owoputi et al., 2013). Evaluation metrics Let the arrival times predicted by a model be (ˆt1, ... , ˆtM) and let the actual arrival times be (t1, ... , tN). We introduce two metrics based on root mean squared error (RMSE) for evaluating predicted inter-arrival times. First is aligned root mean squared error (ARMSE), where we align the initial K = min(M, N) arrival times and calculate the RMSE between such two subsequences. The second is called penalized root mean squared error (PRMSE). In this metric we penalize approaches which predict a different number of inter-arrival times than the actual number. The PRMSE me</context>
</contexts>
<marker>Owoputi, Dyer, Gimpel, Schneider, Smith, 2013</marker>
<rawString>Olutobi Owoputi, Chris Dyer, Kevin Gimpel, Nathan Schneider, and Noah A. Smith. 2013. Improved part-of-speech tagging for online conversational text with word clusters. In In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohan DW Perera</author>
<author>Sruthy Anand</author>
<author>KP Subbalakshmi</author>
<author>R Chandramouli</author>
</authors>
<title>Twitter analytics: Architecture, tools and analysis.</title>
<date>2010</date>
<booktitle>In Military Communications Conference, 2010-MILCOM 2010,</booktitle>
<pages>2186--2191</pages>
<contexts>
<context position="3666" citStr="Perera et al., 2010" startWordPosition="556" endWordPosition="559">s, beating the baselines e.g. homogeneous Poisson Process, Gaussian Process regression and univariate Hawkes Process. Even though the central application is rumours, one could apply the proposed approaches to model the arrival times of tweets corresponding to other types of memes, e.g. discussions about politics. This paper makes the following contributions: 1. Introduces log-Gaussian Cox process to predict tweet arrival times. 2. Demonstrates how incorporating text improves results of inter-arrival time prediction. 2 Related Work Previous approaches to modeling inter-arrival times of tweets (Perera et al., 2010; Sakaki et al., 2010; Esteban et al., 2012; Doerr et al., 2013) were not complex enough to consider their time varying characteristics. Perera et al. (2010) modeled 250 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 250–255, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Intensity function values 15 10 5 0 Intensity function values 1h 2h Time (a) rumour #39 1h 2h Time (b) rumour #60 15 10 5 0 LGCPTXT LGCP LGCPTXT LGCP Figure 1: Intensity functions and corresponding predicted arrival times for different m</context>
<context position="7489" citStr="Perera et al., 2010" startWordPosition="1209" endWordPosition="1213"> i for one hour and over reference rumours (other than i) for two hours. Thus, the training data set is RO = {EOi }ni=1, where O EOi = {pij }mi (m9 represents number of posts observed for ith rumour). We query the model for a complete set of times {tij}mi mOi +1 of posts about rumour i in the future one hour time interval. 1For a fully automated approach, a system for early detection of rumours (Zhao et al., 2015) could be run first and our models then applied to the resulting rumours. 251 4 Model The problem of modeling the inter-arrival times of tweets can be solved using Poisson processes (Perera et al., 2010; Sakaki et al., 2010). A homogeneous Poisson process (HPP) assumes the intensity to be constant (with respect to time and the rumour statistics). It is not adequate to model the inter-arrival times of tweets because it assumes constant rate of point arrival across time. Inhomogeneous Poisson process (IPP) (Lee et al., 1991) can model tweets occurring at a variable rate by considering the intensity to be a function of time, i.e. λ(t). For example, in Figure 1a we show intensity functions learnt for two different IPP models. Notice how the generated arrival times vary according to the intensity</context>
<context position="14797" citStr="Perera et al., 2010" startWordPosition="2511" endWordPosition="2514"> min(M, N) arrival times and calculate the RMSE between such two subsequences. The second is called penalized root mean squared error (PRMSE). In this metric we penalize approaches which predict a different number of inter-arrival times than the actual number. The PRMSE metric is defined as the square root of the following expression. M (ˆti − ti)2 + I[M &gt; N] (T − ˆti)2 i=N+1 N +I[M &lt; N] (T − ti)2 (5) i=M+1 The second and third term in (5) respectively penalize for the excessive or insufficient number of points predicted by the model. Baselines We consider a homogeneous Poisson process (HPP) (Perera et al., 2010) as a baseline which results in exponentially distributed interarrival times with rate A. The rate parameter is set to the maximum likelihood estimate, the reciprocal of the mean of the inter-arrival times in the training data. The second baseline is a GP with a linear kernel (GPLIN), where the inter-arrival time is modeled as a function of time of occurrence of last tweet. This model tends to predict small inter-arrival times yielding a huge number of points. We limit the number of predicted points 1 K K i=1 253 method ARMSE PRMSE GPLIN 20.60±22.01* 1279.78±903.90* HPP 21.85±22.82* 431.4±96.5</context>
</contexts>
<marker>Perera, Anand, Subbalakshmi, Chandramouli, 2010</marker>
<rawString>Rohan DW Perera, Sruthy Anand, KP Subbalakshmi, and R Chandramouli. 2010. Twitter analytics: Architecture, tools and analysis. In Military Communications Conference, 2010-MILCOM 2010, pages 2186–2191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Edward Rasmussen</author>
<author>Christopher K I Williams</author>
</authors>
<date>2005</date>
<booktitle>Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning).</booktitle>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="8420" citStr="Rasmussen and Williams, 2005" startWordPosition="1364" endWordPosition="1367">(IPP) (Lee et al., 1991) can model tweets occurring at a variable rate by considering the intensity to be a function of time, i.e. λ(t). For example, in Figure 1a we show intensity functions learnt for two different IPP models. Notice how the generated arrival times vary according to the intensity function values. Log-Gaussian Cox process We consider a log-Gaussian Cox process (LGCP) (Møller and Syversveen, 1998), a special case of IPP, where the intensity function is assumed to be stochastic. The intensity function λ(t) is modeled using a latent function f(t) sampled from a Gaussian process (Rasmussen and Williams, 2005). To ensure positivity of the intensity function, we consider λ(t) = exp (f(t)). This provides a nonparametric Bayesian approach to model the intensity function, where the complexity of the model is learnt from the training data. Moreover, we can define the functional form of the intensity function through appropriate GP priors. Modeling inter-arrival time Inhomogeneous Poisson process (unlike HPP) uses a time varying intensity function and hence, the distribution of inter-arrival times is not independent and identically distributed (Ross, 2010). In IPP, the number of tweets y occurring in an </context>
<context position="10468" citStr="Rasmussen and Williams, 2005" startWordPosition="1742" endWordPosition="1745">is obtained by taking the derivative of (2) with respect to u: p(Tn = u) = λ(s + u) exp(− J n λ(s + t)dt). 0 (3) The computational difficulties arising from integration are dealt by assuming the intensity function to be constant in an interval and approximating the inter-arrival time density as (Møller and Syversveen, 1998; Vanhatalo et al., 2013) u p(Tn = u) = λ(s + u) exp(−uλ(s + 2 )). (4) We associate a distinct intensity function λi(t) = exp(fi(t)) with each rumour Ei as they have varying temporal profiles. The latent function fi is modelled to come from a zero mean Gaussian process (GP) (Rasmussen and Williams, 2005) prior with covariance defined by a squared exponential (SE) kernel over time, ktime(t, t&apos;) = a exp(−(t − t&apos;)2/l). We consider the likelihood of posts EOi over the entire training period to be product of Poisson distribution (1) over equal length sub-intervals with the rate in a sub-interval [s, e] approximated as (e − s) exp(fi(12(s + e))). The likelihood of posts in the rumour data is obtained by taking the product of the likelihoods over individual rumours. The distribution of the posterior p(fi|EOi ) is intractable and a Laplace approximation (Rasmussen and Williams, 2005) is used to obtai</context>
</contexts>
<marker>Rasmussen, Williams, 2005</marker>
<rawString>Carl Edward Rasmussen and Christopher K. I. Williams. 2005. Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning). The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheldon M Ross</author>
</authors>
<title>Introduction to Probability Models, Tenth Edition.</title>
<date>2010</date>
<publisher>Academic Press, Inc.,</publisher>
<location>Orlando, FL, USA.</location>
<contexts>
<context position="8971" citStr="Ross, 2010" startWordPosition="1452" endWordPosition="1453">mpled from a Gaussian process (Rasmussen and Williams, 2005). To ensure positivity of the intensity function, we consider λ(t) = exp (f(t)). This provides a nonparametric Bayesian approach to model the intensity function, where the complexity of the model is learnt from the training data. Moreover, we can define the functional form of the intensity function through appropriate GP priors. Modeling inter-arrival time Inhomogeneous Poisson process (unlike HPP) uses a time varying intensity function and hence, the distribution of inter-arrival times is not independent and identically distributed (Ross, 2010). In IPP, the number of tweets y occurring in an interval [s, e] is Poisson distributed with rate fse λ(t)dt. e t s,e]) = Poisson(y |λ(t)dt) is (fse λ(t)dt)y exp(− fse λ(t)dt) =(1) y! Assume that nth tweet occurred at time En = s and we are interested in the inter-arrival time Tn of the next tweet. The arrival time of next tweet En+1 can be obtained as En+1 = En + Tn. The cumulative distribution for Tn, which provides the probability that a tweet occurs by time s + u can be obtained as2 p(Tn &lt; u) = 1 − p(Tn &gt; u|λ(t), En = s) = 1 − p(0 events in [s, s + u]|λ(t)) fs+n = 1 − exp(− J A(t)dt) fs U </context>
</contexts>
<marker>Ross, 2010</marker>
<rawString>Sheldon M. Ross. 2010. Introduction to Probability Models, Tenth Edition. Academic Press, Inc., Orlando, FL, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takeshi Sakaki</author>
<author>Makoto Okazaki</author>
<author>Yutaka Matsuo</author>
</authors>
<title>Earthquake shakes twitter users: Real-time event detection by social sensors.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th International Conference on World Wide Web, WWW ’10,</booktitle>
<pages>851--860</pages>
<contexts>
<context position="1362" citStr="Sakaki et al., 2010" startWordPosition="201" endWordPosition="204">ets arrive over time. In an application to rumour modeling of tweets surrounding the 2014 Ferguson riots, we show how interarrival times between tweets can be accurately predicted, and that incorporating textual features further improves predictions. 1 Introduction Twitter is a popular micro-blogging service which provides real-time information on events happening across the world. Evolution of events over time can be monitored there with applications to disaster management, journalism etc. For example, Twitter has been used to detect the occurrence of earthquakes in Japan through user posts (Sakaki et al., 2010). Modeling the temporal dynamics of tweets provides useful information about the evolution of events. Inter-arrival time prediction is a type of such modeling and has application in many settings featuring continuous time streaming text corpora, including journalism for event monitoring, real-time disaster monitoring and advertising on social media. For example, journalists track several rumours related to an event. Predicted arrival times of tweets can be applied for ranking rumours according to their activity and narrow the interest to investigate a rumour with a short interarrival time over</context>
<context position="3687" citStr="Sakaki et al., 2010" startWordPosition="560" endWordPosition="563">nes e.g. homogeneous Poisson Process, Gaussian Process regression and univariate Hawkes Process. Even though the central application is rumours, one could apply the proposed approaches to model the arrival times of tweets corresponding to other types of memes, e.g. discussions about politics. This paper makes the following contributions: 1. Introduces log-Gaussian Cox process to predict tweet arrival times. 2. Demonstrates how incorporating text improves results of inter-arrival time prediction. 2 Related Work Previous approaches to modeling inter-arrival times of tweets (Perera et al., 2010; Sakaki et al., 2010; Esteban et al., 2012; Doerr et al., 2013) were not complex enough to consider their time varying characteristics. Perera et al. (2010) modeled 250 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 250–255, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Intensity function values 15 10 5 0 Intensity function values 1h 2h Time (a) rumour #39 1h 2h Time (b) rumour #60 15 10 5 0 LGCPTXT LGCP LGCPTXT LGCP Figure 1: Intensity functions and corresponding predicted arrival times for different methods across example</context>
<context position="7511" citStr="Sakaki et al., 2010" startWordPosition="1214" endWordPosition="1217">ver reference rumours (other than i) for two hours. Thus, the training data set is RO = {EOi }ni=1, where O EOi = {pij }mi (m9 represents number of posts observed for ith rumour). We query the model for a complete set of times {tij}mi mOi +1 of posts about rumour i in the future one hour time interval. 1For a fully automated approach, a system for early detection of rumours (Zhao et al., 2015) could be run first and our models then applied to the resulting rumours. 251 4 Model The problem of modeling the inter-arrival times of tweets can be solved using Poisson processes (Perera et al., 2010; Sakaki et al., 2010). A homogeneous Poisson process (HPP) assumes the intensity to be constant (with respect to time and the rumour statistics). It is not adequate to model the inter-arrival times of tweets because it assumes constant rate of point arrival across time. Inhomogeneous Poisson process (IPP) (Lee et al., 1991) can model tweets occurring at a variable rate by considering the intensity to be a function of time, i.e. λ(t). For example, in Figure 1a we show intensity functions learnt for two different IPP models. Notice how the generated arrival times vary according to the intensity function values. Log-</context>
</contexts>
<marker>Sakaki, Okazaki, Matsuo, 2010</marker>
<rawString>Takeshi Sakaki, Makoto Okazaki, and Yutaka Matsuo. 2010. Earthquake shakes twitter users: Real-time event detection by social sensors. In Proceedings of the 19th International Conference on World Wide Web, WWW ’10, pages 851–860.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aleksandr Simma</author>
<author>Michael I Jordan</author>
</authors>
<title>Modeling events with cascades of poisson processes.</title>
<date>2010</date>
<booktitle>In UAI,</booktitle>
<pages>546--555</pages>
<contexts>
<context position="5220" citStr="Simma and Jordan, 2010" startWordPosition="801" endWordPosition="804">kaki et al. (2010) to monitor the tweets related to earthquakes. The renewal process model used by Esteban et al. (2012) assumes the inter-arrival times to be independent and identically distributed. Gonzalez et al. (2014) attempts to model arrival times of tweets using a Gaussian process but assumes the tweet arrivals to be independent every hour. These approaches do not take into account the varying characteristics of arrival times of tweets. Point processes such as Poisson and Hawkess process have been used for spatio-temporal modeling of meme spread in social networks (Yang and Zha, 2013; Simma and Jordan, 2010). Hawkes processes (Yang and Zha, 2013) were also found to be useful for modeling the underlying network structure. These models capture relevant network information in the underlying intensity function. We use a log-Gaussian cox process which provides a Bayesian method to capture relevant information through the prior. It has been found to be useful e.g. for conflict mapping (Zammit-Mangion et al., 2012) and for frequency prediction in Twitter (Lukasik et al., 2015). 3 Data &amp; Problem In this section we describe the data and we formalize the problem of modeling tweet arrival times. Data We con</context>
</contexts>
<marker>Simma, Jordan, 2010</marker>
<rawString>Aleksandr Simma and Michael I. Jordan. 2010. Modeling events with cascades of poisson processes. In UAI, pages 546–555.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jarno Vanhatalo</author>
<author>Jaakko Riihim¨aki</author>
<author>Jouni Hartikainen</author>
<author>Pasi Jyl¨anki</author>
<author>Ville Tolvanen</author>
<author>Aki Vehtari</author>
</authors>
<title>Gpstuff: Bayesian modeling with gaussian processes.</title>
<date>2013</date>
<journal>J. Mach. Learn. Res.,</journal>
<volume>14</volume>
<issue>1</issue>
<marker>Vanhatalo, Riihim¨aki, Hartikainen, Jyl¨anki, Tolvanen, Vehtari, 2013</marker>
<rawString>Jarno Vanhatalo, Jaakko Riihim¨aki, Jouni Hartikainen, Pasi Jyl¨anki, Ville Tolvanen, and Aki Vehtari. 2013. Gpstuff: Bayesian modeling with gaussian processes. J. Mach. Learn. Res., 14(1):1175–1179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuang-Hong Yang</author>
<author>Hongyuan Zha</author>
</authors>
<title>Mixture of mutually exciting processes for viral diffusion.</title>
<date>2013</date>
<booktitle>In ICML (2), volume 28 of JMLR Proceedings,</booktitle>
<pages>1--9</pages>
<contexts>
<context position="5195" citStr="Yang and Zha, 2013" startWordPosition="797" endWordPosition="800"> model is used by Sakaki et al. (2010) to monitor the tweets related to earthquakes. The renewal process model used by Esteban et al. (2012) assumes the inter-arrival times to be independent and identically distributed. Gonzalez et al. (2014) attempts to model arrival times of tweets using a Gaussian process but assumes the tweet arrivals to be independent every hour. These approaches do not take into account the varying characteristics of arrival times of tweets. Point processes such as Poisson and Hawkess process have been used for spatio-temporal modeling of meme spread in social networks (Yang and Zha, 2013; Simma and Jordan, 2010). Hawkes processes (Yang and Zha, 2013) were also found to be useful for modeling the underlying network structure. These models capture relevant network information in the underlying intensity function. We use a log-Gaussian cox process which provides a Bayesian method to capture relevant information through the prior. It has been found to be useful e.g. for conflict mapping (Zammit-Mangion et al., 2012) and for frequency prediction in Twitter (Lukasik et al., 2015). 3 Data &amp; Problem In this section we describe the data and we formalize the problem of modeling tweet a</context>
<context position="16100" citStr="Yang and Zha, 2013" startWordPosition="2722" endWordPosition="2725">6* 183.25±102.20* LGCPTXT 15.52±18.79 154.05±115.70 Table 1: ARMSE and PRMSE between the true event times and the predicted event times expressed in minutes (lower is better) over the 114 Ferguson rumours, showing mean ± std. dev. Key * denotes significantly worse than LGCPTXT method according to one-sided Wilcoxon signed rank test (p &lt; 0.05). In case of ARMSE, LGCP is not significantly better than LGCP TXT according to Wilcoxon test. to 1000 (above the maximum count yielded by any rumour from our dataset), thus reducing the error from this method. We also compare against Hawkes Process (HP) (Yang and Zha, 2013), a self exciting point process where an occurrence of a tweet increases the probability of tweets arriving soon afterwards. We consider a univariate Hawkes process where the intensity function is modeled as λi(t) = µ + Eti&lt;t ktime(ti, t). The kernel parameters and µ are learnt by maximizing the likelihood. We apply the importance sampling algorithm discussed in Algorithm 1 for generating arrival times for Hawkess process. We consider this baseline only in the single-task setting, where reference rumours are not considered. LGCP settings In the case of LGCP, the model parameters of the intensi</context>
</contexts>
<marker>Yang, Zha, 2013</marker>
<rawString>Shuang-Hong Yang and Hongyuan Zha. 2013. Mixture of mutually exciting processes for viral diffusion. In ICML (2), volume 28 of JMLR Proceedings, pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Zammit-Mangion</author>
<author>Michael Dewar</author>
<author>Visakan Kadirkamanathan</author>
<author>Guido Sanguinetti</author>
</authors>
<title>Point process modelling of the afghan war diary.</title>
<date>2012</date>
<booktitle>In Proceedings of the National Academy of Sciences,</booktitle>
<volume>109</volume>
<pages>12414--12419</pages>
<contexts>
<context position="5628" citStr="Zammit-Mangion et al., 2012" startWordPosition="864" endWordPosition="867">g characteristics of arrival times of tweets. Point processes such as Poisson and Hawkess process have been used for spatio-temporal modeling of meme spread in social networks (Yang and Zha, 2013; Simma and Jordan, 2010). Hawkes processes (Yang and Zha, 2013) were also found to be useful for modeling the underlying network structure. These models capture relevant network information in the underlying intensity function. We use a log-Gaussian cox process which provides a Bayesian method to capture relevant information through the prior. It has been found to be useful e.g. for conflict mapping (Zammit-Mangion et al., 2012) and for frequency prediction in Twitter (Lukasik et al., 2015). 3 Data &amp; Problem In this section we describe the data and we formalize the problem of modeling tweet arrival times. Data We consider the Ferguson rumour data set (Zubiaga et al., 2015), consisting of tweets on rumours around 2014 Ferguson unrest. It consists of conversational threads that have been manually labeled by annotators to correspond to rumours1. Since some rumours have few posts, we consider only those with at least 15 posts in the first hour as they express interesting behaviour (Lukasik et al., 2015). This results in </context>
</contexts>
<marker>Zammit-Mangion, Dewar, Kadirkamanathan, Sanguinetti, 2012</marker>
<rawString>Andrew Zammit-Mangion, Michael Dewar, Visakan Kadirkamanathan, and Guido Sanguinetti. 2012. Point process modelling of the afghan war diary. In Proceedings of the National Academy of Sciences, Vol. 109, No. 31, pages 12414–12419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhe Zhao</author>
<author>Paul Resnick</author>
<author>Qiaozhu Mei</author>
</authors>
<title>Early detection of rumors in social media from enquiry posts.</title>
<date>2015</date>
<booktitle>In International World Wide Web Conference Committee (IW3C2).</booktitle>
<contexts>
<context position="7287" citStr="Zhao et al., 2015" startWordPosition="1174" endWordPosition="1177">roduce the problem of predicting the exact time of posts in the future unobserved time interval, which is studied as inter-arrival time prediction. In our setting, we observe posts over a target rumour i for one hour and over reference rumours (other than i) for two hours. Thus, the training data set is RO = {EOi }ni=1, where O EOi = {pij }mi (m9 represents number of posts observed for ith rumour). We query the model for a complete set of times {tij}mi mOi +1 of posts about rumour i in the future one hour time interval. 1For a fully automated approach, a system for early detection of rumours (Zhao et al., 2015) could be run first and our models then applied to the resulting rumours. 251 4 Model The problem of modeling the inter-arrival times of tweets can be solved using Poisson processes (Perera et al., 2010; Sakaki et al., 2010). A homogeneous Poisson process (HPP) assumes the intensity to be constant (with respect to time and the rumour statistics). It is not adequate to model the inter-arrival times of tweets because it assumes constant rate of point arrival across time. Inhomogeneous Poisson process (IPP) (Lee et al., 1991) can model tweets occurring at a variable rate by considering the intens</context>
</contexts>
<marker>Zhao, Resnick, Mei, 2015</marker>
<rawString>Zhe Zhao, Paul Resnick, and Qiaozhu Mei. 2015. Early detection of rumors in social media from enquiry posts. In International World Wide Web Conference Committee (IW3C2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arkaitz Zubiaga</author>
<author>Maria Liakata</author>
<author>Rob Procter</author>
<author>Kalina Bontcheva</author>
<author>Peter Tolmie</author>
</authors>
<title>Towards detecting rumours in social media.</title>
<date>2015</date>
<booktitle>In AAAI Workshop on AI for Cities.</booktitle>
<contexts>
<context position="5877" citStr="Zubiaga et al., 2015" startWordPosition="909" endWordPosition="912">13) were also found to be useful for modeling the underlying network structure. These models capture relevant network information in the underlying intensity function. We use a log-Gaussian cox process which provides a Bayesian method to capture relevant information through the prior. It has been found to be useful e.g. for conflict mapping (Zammit-Mangion et al., 2012) and for frequency prediction in Twitter (Lukasik et al., 2015). 3 Data &amp; Problem In this section we describe the data and we formalize the problem of modeling tweet arrival times. Data We consider the Ferguson rumour data set (Zubiaga et al., 2015), consisting of tweets on rumours around 2014 Ferguson unrest. It consists of conversational threads that have been manually labeled by annotators to correspond to rumours1. Since some rumours have few posts, we consider only those with at least 15 posts in the first hour as they express interesting behaviour (Lukasik et al., 2015). This results in 114 rumours consisting of a total of 4098 tweets. Problem Definition Let us consider a time interval [0, 2] measured in hours, a set of rumours R = {Ei}n i=1, where rumour Ei consists of a set of mi posts Ei = {pij}mi j=1. Posts are tuples pij = (xi</context>
</contexts>
<marker>Zubiaga, Liakata, Procter, Bontcheva, Tolmie, 2015</marker>
<rawString>Arkaitz Zubiaga, Maria Liakata, Rob Procter, Kalina Bontcheva, and Peter Tolmie. 2015. Towards detecting rumours in social media. In AAAI Workshop on AI for Cities.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>