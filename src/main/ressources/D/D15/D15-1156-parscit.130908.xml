<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001428">
<title confidence="0.9981725">
Empty Category Detection
using Path Features and Distributed Case Frames
</title>
<author confidence="0.7979">
Shunsuke Takeno†, Masaaki Nagata$, Kazuhide Yamamoto††Nagaoka University of Technology,
</author>
<address confidence="0.595508">
1603-1 Kamitomioka, Nagaoka, Niigata, 940-2188 Japan
</address>
<email confidence="0.95119">
{takeno, yamamoto}@jnlp.org
</email>
<note confidence="0.723703">
$NTT Communication Science Laboratories, NTT Corporation,
</note>
<address confidence="0.957595">
2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan
</address>
<email confidence="0.998564">
nagata.masaaki@labs.ntt.co.jp
</email>
<sectionHeader confidence="0.997387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999871533333333">
We describe an approach for machine
learning-based empty category detection
that is based on the phrase structure analy-
sis of Japanese. The problem is formal-
ized as tree node classification, and we
find that the path feature, the sequence of
node labels from the current node to the
root, is highly effective. We also find that
the set of dot products between the word
embeddings for a verb and those for case
particles can be used as a substitution for
case frames. Experiments show that the
proposed method outperforms the previ-
ous state-of the art method by 68.6% to
73.2% in terms of F-measure.
</bodyText>
<sectionHeader confidence="0.999515" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993650877193">
Empty categories are phonetically null elements
that are used for representing dropped pro-
nouns (“pro” or “small pro”), controlled elements
(“PRO” or “big pro”) and traces of movement
(“T” or “trace”), such as WH-questions and rela-
tive clauses. They are important for pro-drop lan-
guages such as Japanese, in particular, for the ma-
chine translation from pro-drop languages to non-
pro-drop languages such as English. Chung and
Gildea (2010) reported their recover of empty cat-
egories improved the accuracy of machine trans-
lation both in Korean and in Chinese. Kudo et
al. (2014) showed that generating zero subjects in
Japanese improved the accuracy of preordering-
based translation.
State-of-the-art statistical syntactic parsers had
typically ignored empty categories. Although
Penn Treebank (Marcus et al., 1993) has annota-
tions on PRO and trace, they provide only labeled
bracketing. Johnson (2002) proposed a statistical
pattern-matching algorithm for post-processing
the results of syntactic parsing based on minimal
unlexicalized tree fragments from empty node to
its antecedent. Dienes and Dubey (2003) proposed
a machine learning-based “trace tagger” as a pre-
process of parsing. Campbell (2004) proposed a
rule-based post-processing method based on lin-
guistically motivated rules. Gabbard et al. (2006)
replaced the rules with machine learning-based
classifiers. Schmid (2006) and Cai et al. (2011)
integrated empty category detection with the syn-
tactic parsing.
Empty category detection for pro (dropped pro-
nouns or zero pronoun) has begun to receive at-
tention as the Chinese Penn Treebank (Xue et al.,
2005) has annotations for pro as well as PRO
and trace. Xue and Yang (2013) formalized the
problem as classifying each pair of the location
of empty category and its head word in the de-
pendency structure. Wang et al. (2015) pro-
posed a joint embedding of empty categories and
their contexts on dependency structure. Xiang et
al. (2013) formalized the problem as classifying
each IP node (roughly corresponds to S and SBAR
in Penn Treebank) in the phrase structure.
In this paper, we propose a novel method for
empty category detection for Japanese that uses
conjunction features on phrase structure and word
embeddings. We use the Keyaki Treebank (But-
ler et al., 2012), which is a recent development.
As it has annotations for pro and trace, we show
our method has substantial improvements over the
state-of-the-art machine learning-based method
(Xiang et al., 2013) for Chinese empty category
detection as well as linguistically-motivated man-
ually written rule-based method similar to (Camp-
bell, 2004).
</bodyText>
<sectionHeader confidence="0.97379" genericHeader="method">
2 Baseline systems
</sectionHeader>
<bodyText confidence="0.9946195">
The Keyaki Treebank annotates the phrase struc-
ture with functional information for Japanese sen-
tences following a scheme adapted from the Anno-
tation manual for the Penn Historical Corpora and
</bodyText>
<page confidence="0.928062">
1335
</page>
<note confidence="0.8567995">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1335–1340,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figure confidence="0.99732828">
IP-MAT IP-MAT:*pro*-SBJ@0
PP
NP P
IP-REL N を
wo
NP-SBJ VB VB0 AXD
娘
musume
a daughter
*T* 家出 し た
iede shi ta
NP-OB 1 VB VB2 modoshi ta VB VB2 AXD ta
*を * 連れ 戻し AXD PU PP P 連れ 戻し た PU
tsure た 。 NP tsure modoshi 。
brought-back . brought-back .
IP-REL:*T*-SBJ@0 N を
� wo
VB VB0 AXD 娘
musume
a daughter
家出 し た
iede shi ta
NP-SBJ
*pro*
who ran-away-from-home ran-away-from-home
</figure>
<figureCaption confidence="0.887068333333333">
Figure 1: An annotation example of 家出し た娘を 連れ戻し た。 (*pro* brought back a daughter who ran
away from home.) in Keyaki Treebank. (The left tree is the original tree and the right tree is a converted
tree based on Xiang et al.’s (2013) formalism)
</figureCaption>
<bodyText confidence="0.999726944444444">
the PCEEC (Santorini, 2010). There are some ma-
jor changes: the VP level of structure is typically
absent, function is marked on all clausal nodes
(such as IP-REL and CP-THT) and all NPs that
are clause level constituents (such as NP-SBJ).
Disambiguation tags are also used for clarifying
the functions of its immediately preceding node,
such as NP-OBJ *を *(wo) for PP, however, we re-
moved them in our experiment.
Keyaki Treebank has annotation for trace mark-
ers of relative clauses (*T*) and dropped pronouns
(*pro*), however, it deliberately has no annota-
tion for control dependencies (PRO) (Butler et al.,
2015). It has also fine grained empty categories
of *pro* such as *speaker* and *hearer*, but we
unified them into *pro* in our experiment.
HARUNIWA(Fang et al., 2014) is a Japanese
phrase structure parser trained on the treebank. It
has a rule-based post-processor for adding empty
categories, which is similar to (Campbell, 2004).
We call it RULE in later sections and use it as one
of two baselines.
We also use Xiang et al’s (2013) model as an-
other baseline. It formulates empty category de-
tection as the classification of IP nodes. For ex-
ample, in Figure 1, empty nodes in the left tree
are removed and encoded as additional labels with
its position information to IP nodes in the right
tree. As we can uniquely decode them from the
extended IP labels, the problem is to predict the
labels for the input tree that has no empty nodes.
Let T = t1t2 · · · tn be the sequence of nodes
produced by the post-order traversal from root
node, and ei be the empty category tag associated
with ti. The probability model of (Xiang et al.,
2013) is formulated as MaxEnt model:
</bodyText>
<equation confidence="0.999785166666667">
P(ei|ei−1
1 , T)
exp(θ · φ(ei, ei−1
1 , T)) (1)
Z(ei−1
1 , T )
</equation>
<bodyText confidence="0.926454333333333">
where φ is a feature vector, θ is a weight vector to
φ and Z is normalization factor:
exp(θ · φ(e, ei−1
1 , T))
where £ represents the set of all empty category
types to be detected.
Xiang et al. (2013) grouped their features into
four types: tree label features, lexical features,
empty category features and conjunction features
as shown in Table 1. As the features for (Xiang et
al., 2013) were developed for Chinese Penn Tree-
bank, we modify their features for Keyaki Tree-
bank: First, the traversal order is changed from
post-order (bottom-up) to pre-order (top-down).
As PROs are implicit in Keyaki Treebank, the de-
cisions on IPs in lower levels depend on those on
higher levels in the tree. Second, empty category
features are extracted from ancestor IP nodes, not
from descendant IP nodes, in accordance with the
first change.
Table 2 shows the accuracies of Japanese empty
category detection, using the original and our
modification of the (Xiang et al., 2013) with ab-
lation test. We find that the conjunction features
</bodyText>
<equation confidence="0.9918961">
n
P(en1|T) =
i=1
n
ri
i=1
�
Z(ei−1
1 , T) =
e∈E
</equation>
<page confidence="0.966658">
1336
</page>
<table confidence="0.995688931034483">
Tree label features
1 current node label
2 parent node label
3 grand-parent node label
4 left-most child label or POS tag
5 right-most child label or POS tag
6 label or POS tag of the head child
7 the number of child nodes
8 one level CFG rule
9 left-sibling label or POS tag (up to two siblings)
10 right-sibling label or POS tag (up to two siblings)
Lexical features
11 left-most word under the current node
12 right-most word under the current node
13 word immediately left to the span of the current node
14 word immediately right to the span of the current node
15 head word of the current node
16 head word of the parent node
17 is the current node head child of its parent? (binary)
Empty category features
18 predicted empty categories of the left sibling
19* the set of detected empty categories of ancestor nodes
Conjunction features
20 current node label with parent node label
21* current node label with features computed from ances-
22 tor nodes
23 current node label with features computed from left-
sibling nodes
current node label with lexical features
</table>
<tableCaption confidence="0.769269">
Table 1: List of features of Xiang et al.’s (2013). (*
indicates the features we changed for the Keyaki
Treebank)
</tableCaption>
<table confidence="0.999887">
Features F(Gold) A
original (Xiang et al., 2013) 68.2 −0.40
modified (Xiang et al., 2013) 68.6 -
− Tree label 68.6 −0.00
− Empty category 68.3 −0.30
− Lexicon 68.6 −0.00
− Conjunction 58.5 −10.1
</table>
<tableCaption confidence="0.999526">
Table 2: Ablation result of (Xiang et al., 2013)
</tableCaption>
<bodyText confidence="0.994508666666667">
are highly effective compared to the three other
features. This observation leads to the model pro-
posed in the next section.
</bodyText>
<sectionHeader confidence="0.998848" genericHeader="method">
3 Proposed model
</sectionHeader>
<bodyText confidence="0.997435931034483">
In the proposed model, we use combinations of
path features and three other features, namely head
word feature, child feature and empty category
feature. Path feature (PATH) is a sequence of non-
terminal labels from the current node to the ances-
tor nodes up to either the root node or the nearest
CP node. For example, in Figure 1, if the current
node is IP-REL, four paths are extracted; IP-REL,
IP-REL —* NP, IP-REL —* NP —* PP and IP-REL
—* NP —* PP —* IP-MAT.
Head word feature (HEAD) is the surface form
of the lexical head of the current node. Child fea-
ture (CHILD) is the set of labels for the children of
the current node. The label is augmented with the
surface form of the rightmost terminal node if it is
a function word. In the example of Figure 1, if the
current node is IP-MAT, HEAD is 連れ (tsure) and
CHILD includes: PP-を (wo), VB, VB2, AXD-た
(ta) and PU-。 . Empty category feature (EC) is a
set of empty categories detected in the ancestor IP
nodes. For example in Figure 1, if the current node
is IP-REL, EC is *pro*.
We then combine the PATH with others. If the
current node is the IP-MAT node in right-half of
Figure 1, the combination of PATH and HEAD
is:IP-MATx 連れ (tsure) and the combinations
of PATH and CHILD are: IP-MATxPP-を (wo),
IP-MATxVB, IP-MATxVB2, IP-MATxAXD-た
(ta) and IP-MATxPU-。 .
</bodyText>
<subsectionHeader confidence="0.9937575">
3.1 Using Word Embedding to approximate
Case Frame Lexicon
</subsectionHeader>
<bodyText confidence="0.999489647058824">
A case frame lexicon would be obviously useful
for empty category detection because it provides
information on the type of argument the verb in
question takes. The problem is that case frame lex-
icon is not usually readily available. We propose
a novel method to approximate case frame lexicon
for languages with explicit case marking such as
Japanese using word embeddings. According to
(Pennington et al., 2014), they designed their em-
bedding model GloVe so that the dot product of
two word embeddings approximates the logarithm
of their co-occurrence counts. Using this charac-
teristic, we can easily make a feature that approxi-
mate the case frame of a verb. Given a set of word
embeddings for case particles q1, q2, · · · , qN E Q,
the distributed case frame feature (DCF) for a verb
wi is defined as:
</bodyText>
<equation confidence="0.98447575">
˜vi = wi · (q1, q2, ··· , qN) (2)
˜vi
(3)
 ||˜vi||
</equation>
<bodyText confidence="0.999623333333333">
In our experiment, we used a set of high frequency
case particles が (ga), は (ha), も (mo), の (no), を
(wo), に (ni), へ (he) and から (kara) as Q.
</bodyText>
<sectionHeader confidence="0.999296" genericHeader="evaluation">
4 Experiment
</sectionHeader>
<subsectionHeader confidence="0.751304">
4.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999319">
We divided the Keyaki Treebank into training, de-
velopment and test sets. As of May 8, 2015, there
</bodyText>
<equation confidence="0.757873">
vi =
</equation>
<page confidence="0.946433">
1337
</page>
<figure confidence="0.9701385625">
development/test
transcript blog newswire
#pro SBJ 13343 598 187 346
43 1 27
2 0 0
0 0 8
9 7 7
0 11 35
0 1 2
5 40 266
0 0 3
0 1 4
0 0 0
32.1 69.5 96.5
591 109 303
1129 544 1841
</figure>
<tableCaption confidence="0.986029">
Table 3: Statistics of Keyaki Treebank
</tableCaption>
<bodyText confidence="0.999831133333333">
are 22,639 sentences in Keyaki Treebank. We used
1,000 sentences as the development set, 1,003
sentences as the test set. They were taken from
the files blog KNB.psd (blog), spoken CIAIR.psd
(transcript), newswire MAINICHI-1995.psd
(newswire) to balance the domain. The remaining
20,646 sentences are used for training. Further
statistics are shown in Table 3.
We used GloVe as word embedding, Wikipedia
articles in Japanese as of January 18, 2015, are
used for training, which amounted to 660 million
words and 23.4 million sentences. By using the
development set, we set the dimension of word
embedding and the window size for co-occurrence
counts as 200 and 10, respectively.
</bodyText>
<subsectionHeader confidence="0.9523">
4.2 Result and Discussion
</subsectionHeader>
<bodyText confidence="0.9997876">
We tested in two conditions: gold parse and sys-
tem parse. In gold parse condition, we used
the trees of Keyaki Treebank without empty cat-
egories as input to the systems. In system parse
condition, we used the output of the Berkeley
Parser model of HARUNIWA before rule-based
empty category detection1. We evaluated them us-
ing the word-position-level identification metrics
described in (Xiang et al., 2013). It projects the
predicted empty category tags to the surface level.
An empty node is regarded as correctly predicted
surface position in the sentence, type (T or pro)
and function (SBJ, OB1 and so on) are matched
with the reference.
To evaluate the effectiveness of the proposed
</bodyText>
<footnote confidence="0.901230666666667">
1There are two models available in HARUNIWA, namely
the BitPar model (Schmid, 2004) and Berkeley Parser binary
branching model (Petrov and Klein, 2007). The output of
the later is first flattened, then added disambiguation tags and
empty categories using tsurgeon script (Levy and Andrew,
2006).
</footnote>
<bodyText confidence="0.998821358974359">
distributed case frame (DCF), we used an exist-
ing case frame lexicon (Kawahara and Kurohashi,
2006) and tested three different ways of encod-
ing the case frame information: BIN encodes each
case as binary features. SET encodes each combi-
nation of required cases as a binary feature. DIST
is a vector of co-occurrence counts for each case
particle, which can be thought of an unsmoothed
version of our DCF.
Table 4 shows the accuracies of various empty
category detection methods, for both gold parse
and system parse. In the gold parse condition, the
two baselines, the rule-based method (RULE) and
the modified (Xiang et al., 2013) method, achieved
the F-measure of 62.6% and 68.6% respectively.
We also implemented the third baseline based
on (Johnson, 2002). Minimal unlexicalized tree
fragments from empty node to its antecedent were
extracted as pattern rules based on corpus statis-
tics. For *pro*, which has no antecedent, we used
the statistics from empty node to the root. Al-
though the precision of the method is high, the re-
call is very low, which results in the F-measure of
38.1%.
Among the proposed models, the combination
of path feature and child feature (PATH x CHILD)
even outperformed the baselines. It reached 73.2%
with all features. As for the result of system-
parse condition, the F-measure dropped consider-
ably from 73.2% to 54.7% mostly due to the pars-
ing errors on the IP nodes and its function.
We find that there are no significant differences
among the different encodings of the case frame
lexicon, and the improvement brought by the pro-
posed distributed case frame is comparable to the
existing case frame lexicon.
Table 5 shows the ablation result of the pro-
posed model. It indicates conjunction between
PATH and CHILD feature is most effective.
</bodyText>
<equation confidence="0.392954">
F(Gold) A F(System) A
</equation>
<table confidence="0.996981">
Proposed 72.1 - 53.9 -
−CHILD 47.4 −24.7 33.7 −20.2
−EC 70.8 −1.3 52.4 −1.5
−HEAD 70.0 −2.1 51.6 −2.3
</table>
<tableCaption confidence="0.767149">
Table 5: Ablation result of PATH x (CHILD + EC
+ HEAD) model
</tableCaption>
<table confidence="0.989199807692308">
ALL
OB1 1568
OB2 59
#T ADT 97
LOC 164
OB1 755
OB2 15
SBJ 3788
TMP 53
MSR 14
TPC 10
char/sent. 32.0
#sent. 22649
#IP node 46684
1338
Models Gold parse System parse
CF P R F P R F #nonZ
RULE - 54.4 73.7 62.6 57.4 50.5 53.7 -
modified (Xiang et al., 2013) - 76.8 62.0 68.6 57.4 46.9 51.6 321k
modified (Johnson, 2002) - 81.3 25.0 38.1 66.8 18.1 28.6 -
PATH x CHILD - 71.0 67.7 69.3 55.9 49.1 52.3 108k
PATH x (CHILD + HEAD + EC) - 74.8 69.5 72.1 56.2 51.8 53.9 123k
PATH x (CHILD + HEAD + EC) +DCF 78.0 68.9 73.2 59.7 50.5 54.7 124k
PATH x (CHILD + HEAD + EC) +BIN 77.1 70.2 73.5 58.8 51.6 55.0 124k
PATH x (CHILD + HEAD + EC) +SET 77.5 70.0 73.6 58.5 51.4 54.7 126k
PATH x (CHILD + HEAD + EC) +DIST 77.5 68.3 72.6 60.4 50.6 55.1 124k
</table>
<tableCaption confidence="0.999592">
Table 4: Result of our models with baselines. #nonZ means the amount of non-zero weight of model
</tableCaption>
<sectionHeader confidence="0.998941" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999932692307692">
In this paper, we proposed a novel model for
empty category detection in Japanese using path
features and the distributed case frames. Although
it achieved fairly high accuracy for the gold parse,
there is much room for improvement when applied
to the output of a syntactic parser. Since the accu-
racy of the empty category detection implemented
as a post-process highly depends on that of the un-
derlying parser, we want to explore models that
can solve them jointly, such as the lattice parsing
approach of (Cai et al., 2011). We would like to
report the results in the future version of this pa-
per.
</bodyText>
<sectionHeader confidence="0.99916" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999733629032258">
Alastair Butler, Tomoko Hotta, Ruriko Otomo, Kei
Yoshimoto, Zhen Zhou, and Hong Zhu. 2012.
Keyaki Treebank : phrase structure with functional
information for Japanese. In Proceedings of Text
Annotation Workshop.
Alastair Butler, Shota Hhiyama, and Kei Yoshimoto.
2015. Coindexed null elements for a Japanese
parsed corpus. In Proceedings of the 21th Annual
Meeting of the Association for Natural Language
Processing, pages 708–711.
Shu Cai, David Chiang, and Yoav Goldberg. 2011.
Language-Independent Parsing with Empty Ele-
ments. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies: short papers,
volume 2, pages 212–216.
Richard Campbell. 2004. Using linguistic principles
to recover empty categories. In Proceedings of the
42nd Meeting of the Association for Computational
Linguistics (ACL’04), Main Volume, pages 645–652.
Tagyoung Chung and Daniel Gildea. 2010. Effects of
Empty Categories on Machine Translation. In Pro-
ceedings of the 2010 Conference on Empirical Meth-
ods in Natural Language Processing, pages 636–
645.
P´eter Dienes and Amit Dubey. 2003. Deep Syntactic
Processing by Combining Shallow Methods. In Pro-
ceedings of the 41st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 431–438.
Tsaiwei Fang, Alastair Butler, and Kei Yoshimoto.
2014. Parsing Japanese with a PCFG treebank
grammar. In Proceedings of The Twentieth Meeting
of the Association for Natural Language Processing,
volume C, pages 432–435.
Ryan Gabbard, M Marcus, and Seth Kulick. 2006.
Fully Parsing the Penn Treebank. In Proceedings of
the main conference on Human Language Technol-
ogy of the North American Chapter of the Associa-
tion of Computational Linguistics, pages 184–191.
Mark Johnson. 2002. A simple pattern-matching al-
gorithm for recovering empty nodes and their an-
tecedents. In Proceedings of the 40th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 136–143.
Daisuke Kawahara and Sadao Kurohashi. 2006.
Case frame compilation from the web using high-
performance computing. In Proceedings of the 5th
International Conference on Language Resources
and Evaluation, pages 1344–1347.
Taku Kudo, Hiroshi Ichikawa, and Hideto Kazawa.
2014. A joint inference of deep case analysis and
zero subject generation for Japanese-to-English sta-
tistical machine translation. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics, pages 557–562.
Roger Levy and Galen Andrew. 2006. Tregex and
Tsurgeon: tools for querying and manipulating tree
data structures. In Proceedings of 5th International
Conference on Language Resources and Evaluation,
pages 2231–2234.
Mitchell P Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a Large Annotated
</reference>
<page confidence="0.884638">
1339
</page>
<reference confidence="0.999856975609756">
Corpus of English: The Penn Treebank. Computa-
tional Linguistics, 19(2):313–330.
Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. GloVe: Global Vectors for Word
Representation. In Proceedings of the 2014 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1532–1543.
Slav Petrov and Dan Klein. 2007. Improved Infer-
encing for Unlexicalized Parsing. In Proceedings
of HLT-NAACL 2007 - Human Language Technol-
ogy Conference of the North American Chapter of
the Association of Computational Linguistics, pages
404–411.
Santorini. 2010. Annotation Manual for the Penn His-
torical Corpora and the PCEEC (Release 2).
Helmut Schmid. 2004. Efficient parsing of highly am-
biguous context-free grammars with bit vectors. In
Proceedings of the 20th International Conference on
Computational Linguistics, pages 162–168.
Helmut Schmid. 2006. Trace Prediction and Recovery
with Unlexicalized PCFGs and Slash Features. In
Proceedings of the 21st International Conference on
Computational Linguistics and 44th Annual Meet-
ing of the Association for Computational Linguis-
tics, pages 177–184.
Bing Xiang, Xiaoqiang Luo, and Bowen Zhou. 2013.
Enlisting the ghost: Modeling empty categories for
machine translation. In Proceedings of the 48th An-
nual Meeting of the Association for Computational
Linguistics, pages 822–831.
Nianwen Xue and Yaqin Yang. 2013. Dependency-
based empty category detection via phrase structure
trees. In Proceedings of HLT-NAACL 2013, Hu-
man Language Technology Conference of the North
American Chapter of the Association of Computa-
tional Linguistics, Proceedings of the Main Confer-
ence, pages 1051–1060.
Naiwen Xue, Fei Xia, Fu-Dong Chiou, and Marta
Palmer. 2005. The Penn Chinese TreeBank: Phrase
structure annotation of a large corpus. Natural Lan-
guage Engineering, 11(2):207–238.
</reference>
<page confidence="0.989794">
1340
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.169740">
<title confidence="0.8020135">Empty Category Detection using Path Features and Distributed Case Frames</title>
<affiliation confidence="0.950247">Masaaki Kazuhide University of Technology,</affiliation>
<address confidence="0.993371">1603-1 Kamitomioka, Nagaoka, Niigata, 940-2188 Japan</address>
<affiliation confidence="0.519614">Communication Science Laboratories, NTT</affiliation>
<address confidence="0.909204">2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan</address>
<email confidence="0.960331">nagata.masaaki@labs.ntt.co.jp</email>
<abstract confidence="0.972514625">We describe an approach for machine learning-based empty category detection that is based on the phrase structure analysis of Japanese. The problem is formalized as tree node classification, and we find that the path feature, the sequence of node labels from the current node to the root, is highly effective. We also find that the set of dot products between the word embeddings for a verb and those for case particles can be used as a substitution for case frames. Experiments show that the proposed method outperforms the previous state-of the art method by 68.6% to 73.2% in terms of F-measure.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alastair Butler</author>
<author>Tomoko Hotta</author>
<author>Ruriko Otomo</author>
<author>Kei Yoshimoto</author>
<author>Zhen Zhou</author>
<author>Hong Zhu</author>
</authors>
<title>Keyaki Treebank : phrase structure with functional information for Japanese.</title>
<date>2012</date>
<booktitle>In Proceedings of Text Annotation Workshop.</booktitle>
<contexts>
<context position="3289" citStr="Butler et al., 2012" startWordPosition="499" endWordPosition="503">d trace. Xue and Yang (2013) formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure. Wang et al. (2015) proposed a joint embedding of empty categories and their contexts on dependency structure. Xiang et al. (2013) formalized the problem as classifying each IP node (roughly corresponds to S and SBAR in Penn Treebank) in the phrase structure. In this paper, we propose a novel method for empty category detection for Japanese that uses conjunction features on phrase structure and word embeddings. We use the Keyaki Treebank (Butler et al., 2012), which is a recent development. As it has annotations for pro and trace, we show our method has substantial improvements over the state-of-the-art machine learning-based method (Xiang et al., 2013) for Chinese empty category detection as well as linguistically-motivated manually written rule-based method similar to (Campbell, 2004). 2 Baseline systems The Keyaki Treebank annotates the phrase structure with functional information for Japanese sentences following a scheme adapted from the Annotation manual for the Penn Historical Corpora and 1335 Proceedings of the 2015 Conference on Empirical </context>
</contexts>
<marker>Butler, Hotta, Otomo, Yoshimoto, Zhou, Zhu, 2012</marker>
<rawString>Alastair Butler, Tomoko Hotta, Ruriko Otomo, Kei Yoshimoto, Zhen Zhou, and Hong Zhu. 2012. Keyaki Treebank : phrase structure with functional information for Japanese. In Proceedings of Text Annotation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alastair Butler</author>
<author>Shota Hhiyama</author>
<author>Kei Yoshimoto</author>
</authors>
<title>Coindexed null elements for a Japanese parsed corpus.</title>
<date>2015</date>
<booktitle>In Proceedings of the 21th Annual Meeting of the Association for Natural Language Processing,</booktitle>
<pages>708--711</pages>
<contexts>
<context position="5266" citStr="Butler et al., 2015" startWordPosition="833" endWordPosition="836">alism) the PCEEC (Santorini, 2010). There are some major changes: the VP level of structure is typically absent, function is marked on all clausal nodes (such as IP-REL and CP-THT) and all NPs that are clause level constituents (such as NP-SBJ). Disambiguation tags are also used for clarifying the functions of its immediately preceding node, such as NP-OBJ *を *(wo) for PP, however, we removed them in our experiment. Keyaki Treebank has annotation for trace markers of relative clauses (*T*) and dropped pronouns (*pro*), however, it deliberately has no annotation for control dependencies (PRO) (Butler et al., 2015). It has also fine grained empty categories of *pro* such as *speaker* and *hearer*, but we unified them into *pro* in our experiment. HARUNIWA(Fang et al., 2014) is a Japanese phrase structure parser trained on the treebank. It has a rule-based post-processor for adding empty categories, which is similar to (Campbell, 2004). We call it RULE in later sections and use it as one of two baselines. We also use Xiang et al’s (2013) model as another baseline. It formulates empty category detection as the classification of IP nodes. For example, in Figure 1, empty nodes in the left tree are removed a</context>
</contexts>
<marker>Butler, Hhiyama, Yoshimoto, 2015</marker>
<rawString>Alastair Butler, Shota Hhiyama, and Kei Yoshimoto. 2015. Coindexed null elements for a Japanese parsed corpus. In Proceedings of the 21th Annual Meeting of the Association for Natural Language Processing, pages 708–711.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shu Cai</author>
<author>David Chiang</author>
<author>Yoav Goldberg</author>
</authors>
<title>Language-Independent Parsing with Empty Elements.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association</booktitle>
<volume>2</volume>
<pages>212--216</pages>
<contexts>
<context position="2416" citStr="Cai et al. (2011)" startWordPosition="352" endWordPosition="355">ank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for pro (dropped pronouns or zero pronoun) has begun to receive attention as the Chinese Penn Treebank (Xue et al., 2005) has annotations for pro as well as PRO and trace. Xue and Yang (2013) formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure. Wang et al. (2015) proposed a joint embedding of empty categories and their contexts on dependency structure. Xiang et al. (2013) formalized the problem as classifying each IP node (roughly</context>
</contexts>
<marker>Cai, Chiang, Goldberg, 2011</marker>
<rawString>Shu Cai, David Chiang, and Yoav Goldberg. 2011. Language-Independent Parsing with Empty Elements. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers, volume 2, pages 212–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Campbell</author>
</authors>
<title>Using linguistic principles to recover empty categories.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume,</booktitle>
<pages>645--652</pages>
<contexts>
<context position="2212" citStr="Campbell (2004)" startWordPosition="325" endWordPosition="326">hat generating zero subjects in Japanese improved the accuracy of preorderingbased translation. State-of-the-art statistical syntactic parsers had typically ignored empty categories. Although Penn Treebank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for pro (dropped pronouns or zero pronoun) has begun to receive attention as the Chinese Penn Treebank (Xue et al., 2005) has annotations for pro as well as PRO and trace. Xue and Yang (2013) formalized the problem as classifying each pair of the location of empty category and its head word in the depende</context>
<context position="3623" citStr="Campbell, 2004" startWordPosition="550" endWordPosition="552">(roughly corresponds to S and SBAR in Penn Treebank) in the phrase structure. In this paper, we propose a novel method for empty category detection for Japanese that uses conjunction features on phrase structure and word embeddings. We use the Keyaki Treebank (Butler et al., 2012), which is a recent development. As it has annotations for pro and trace, we show our method has substantial improvements over the state-of-the-art machine learning-based method (Xiang et al., 2013) for Chinese empty category detection as well as linguistically-motivated manually written rule-based method similar to (Campbell, 2004). 2 Baseline systems The Keyaki Treebank annotates the phrase structure with functional information for Japanese sentences following a scheme adapted from the Annotation manual for the Penn Historical Corpora and 1335 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1335–1340, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. IP-MAT IP-MAT:*pro*-SBJ@0 PP NP P IP-REL N を wo NP-SBJ VB VB0 AXD 娘 musume a daughter *T* 家出 し た iede shi ta NP-OB 1 VB VB2 modoshi ta VB VB2 AXD ta *を * 連れ 戻し AXD PU PP P 連れ 戻し た PU tsur</context>
<context position="5592" citStr="Campbell, 2004" startWordPosition="887" endWordPosition="888">ceding node, such as NP-OBJ *を *(wo) for PP, however, we removed them in our experiment. Keyaki Treebank has annotation for trace markers of relative clauses (*T*) and dropped pronouns (*pro*), however, it deliberately has no annotation for control dependencies (PRO) (Butler et al., 2015). It has also fine grained empty categories of *pro* such as *speaker* and *hearer*, but we unified them into *pro* in our experiment. HARUNIWA(Fang et al., 2014) is a Japanese phrase structure parser trained on the treebank. It has a rule-based post-processor for adding empty categories, which is similar to (Campbell, 2004). We call it RULE in later sections and use it as one of two baselines. We also use Xiang et al’s (2013) model as another baseline. It formulates empty category detection as the classification of IP nodes. For example, in Figure 1, empty nodes in the left tree are removed and encoded as additional labels with its position information to IP nodes in the right tree. As we can uniquely decode them from the extended IP labels, the problem is to predict the labels for the input tree that has no empty nodes. Let T = t1t2 · · · tn be the sequence of nodes produced by the post-order traversal from roo</context>
</contexts>
<marker>Campbell, 2004</marker>
<rawString>Richard Campbell. 2004. Using linguistic principles to recover empty categories. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume, pages 645–652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tagyoung Chung</author>
<author>Daniel Gildea</author>
</authors>
<title>Effects of Empty Categories on Machine Translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>636--645</pages>
<contexts>
<context position="1450" citStr="Chung and Gildea (2010)" startWordPosition="213" endWordPosition="216">sed as a substitution for case frames. Experiments show that the proposed method outperforms the previous state-of the art method by 68.6% to 73.2% in terms of F-measure. 1 Introduction Empty categories are phonetically null elements that are used for representing dropped pronouns (“pro” or “small pro”), controlled elements (“PRO” or “big pro”) and traces of movement (“T” or “trace”), such as WH-questions and relative clauses. They are important for pro-drop languages such as Japanese, in particular, for the machine translation from pro-drop languages to nonpro-drop languages such as English. Chung and Gildea (2010) reported their recover of empty categories improved the accuracy of machine translation both in Korean and in Chinese. Kudo et al. (2014) showed that generating zero subjects in Japanese improved the accuracy of preorderingbased translation. State-of-the-art statistical syntactic parsers had typically ignored empty categories. Although Penn Treebank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree</context>
</contexts>
<marker>Chung, Gildea, 2010</marker>
<rawString>Tagyoung Chung and Daniel Gildea. 2010. Effects of Empty Categories on Machine Translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 636– 645.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P´eter Dienes</author>
<author>Amit Dubey</author>
</authors>
<title>Deep Syntactic Processing by Combining Shallow Methods.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>431--438</pages>
<contexts>
<context position="2119" citStr="Dienes and Dubey (2003)" startWordPosition="309" endWordPosition="312">proved the accuracy of machine translation both in Korean and in Chinese. Kudo et al. (2014) showed that generating zero subjects in Japanese improved the accuracy of preorderingbased translation. State-of-the-art statistical syntactic parsers had typically ignored empty categories. Although Penn Treebank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for pro (dropped pronouns or zero pronoun) has begun to receive attention as the Chinese Penn Treebank (Xue et al., 2005) has annotations for pro as well as PRO and trace. Xue and Yang (2013) formalized the proble</context>
</contexts>
<marker>Dienes, Dubey, 2003</marker>
<rawString>P´eter Dienes and Amit Dubey. 2003. Deep Syntactic Processing by Combining Shallow Methods. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 431–438.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tsaiwei Fang</author>
<author>Alastair Butler</author>
<author>Kei Yoshimoto</author>
</authors>
<title>Parsing Japanese with a PCFG treebank grammar.</title>
<date>2014</date>
<booktitle>In Proceedings of The Twentieth Meeting of the Association for Natural Language Processing,</booktitle>
<volume>volume C,</volume>
<pages>432--435</pages>
<contexts>
<context position="5428" citStr="Fang et al., 2014" startWordPosition="860" endWordPosition="863">-REL and CP-THT) and all NPs that are clause level constituents (such as NP-SBJ). Disambiguation tags are also used for clarifying the functions of its immediately preceding node, such as NP-OBJ *を *(wo) for PP, however, we removed them in our experiment. Keyaki Treebank has annotation for trace markers of relative clauses (*T*) and dropped pronouns (*pro*), however, it deliberately has no annotation for control dependencies (PRO) (Butler et al., 2015). It has also fine grained empty categories of *pro* such as *speaker* and *hearer*, but we unified them into *pro* in our experiment. HARUNIWA(Fang et al., 2014) is a Japanese phrase structure parser trained on the treebank. It has a rule-based post-processor for adding empty categories, which is similar to (Campbell, 2004). We call it RULE in later sections and use it as one of two baselines. We also use Xiang et al’s (2013) model as another baseline. It formulates empty category detection as the classification of IP nodes. For example, in Figure 1, empty nodes in the left tree are removed and encoded as additional labels with its position information to IP nodes in the right tree. As we can uniquely decode them from the extended IP labels, the probl</context>
</contexts>
<marker>Fang, Butler, Yoshimoto, 2014</marker>
<rawString>Tsaiwei Fang, Alastair Butler, and Kei Yoshimoto. 2014. Parsing Japanese with a PCFG treebank grammar. In Proceedings of The Twentieth Meeting of the Association for Natural Language Processing, volume C, pages 432–435.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Gabbard</author>
<author>M Marcus</author>
<author>Seth Kulick</author>
</authors>
<title>Fully Parsing the Penn Treebank.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>184--191</pages>
<contexts>
<context position="2320" citStr="Gabbard et al. (2006)" startWordPosition="338" endWordPosition="341">of-the-art statistical syntactic parsers had typically ignored empty categories. Although Penn Treebank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for pro (dropped pronouns or zero pronoun) has begun to receive attention as the Chinese Penn Treebank (Xue et al., 2005) has annotations for pro as well as PRO and trace. Xue and Yang (2013) formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure. Wang et al. (2015) proposed a joint embedding of empty categories and their contexts on depen</context>
</contexts>
<marker>Gabbard, Marcus, Kulick, 2006</marker>
<rawString>Ryan Gabbard, M Marcus, and Seth Kulick. 2006. Fully Parsing the Penn Treebank. In Proceedings of the main conference on Human Language Technology of the North American Chapter of the Association of Computational Linguistics, pages 184–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>A simple pattern-matching algorithm for recovering empty nodes and their antecedents.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>136--143</pages>
<contexts>
<context position="1911" citStr="Johnson (2002)" startWordPosition="283" endWordPosition="284">es such as Japanese, in particular, for the machine translation from pro-drop languages to nonpro-drop languages such as English. Chung and Gildea (2010) reported their recover of empty categories improved the accuracy of machine translation both in Korean and in Chinese. Kudo et al. (2014) showed that generating zero subjects in Japanese improved the accuracy of preorderingbased translation. State-of-the-art statistical syntactic parsers had typically ignored empty categories. Although Penn Treebank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for p</context>
<context position="14202" citStr="Johnson, 2002" startWordPosition="2423" endWordPosition="2424">he case frame information: BIN encodes each case as binary features. SET encodes each combination of required cases as a binary feature. DIST is a vector of co-occurrence counts for each case particle, which can be thought of an unsmoothed version of our DCF. Table 4 shows the accuracies of various empty category detection methods, for both gold parse and system parse. In the gold parse condition, the two baselines, the rule-based method (RULE) and the modified (Xiang et al., 2013) method, achieved the F-measure of 62.6% and 68.6% respectively. We also implemented the third baseline based on (Johnson, 2002). Minimal unlexicalized tree fragments from empty node to its antecedent were extracted as pattern rules based on corpus statistics. For *pro*, which has no antecedent, we used the statistics from empty node to the root. Although the precision of the method is high, the recall is very low, which results in the F-measure of 38.1%. Among the proposed models, the combination of path feature and child feature (PATH x CHILD) even outperformed the baselines. It reached 73.2% with all features. As for the result of systemparse condition, the F-measure dropped considerably from 73.2% to 54.7% mostly d</context>
<context position="15716" citStr="Johnson, 2002" startWordPosition="2700" endWordPosition="2701"> ablation result of the proposed model. It indicates conjunction between PATH and CHILD feature is most effective. F(Gold) A F(System) A Proposed 72.1 - 53.9 - −CHILD 47.4 −24.7 33.7 −20.2 −EC 70.8 −1.3 52.4 −1.5 −HEAD 70.0 −2.1 51.6 −2.3 Table 5: Ablation result of PATH x (CHILD + EC + HEAD) model ALL OB1 1568 OB2 59 #T ADT 97 LOC 164 OB1 755 OB2 15 SBJ 3788 TMP 53 MSR 14 TPC 10 char/sent. 32.0 #sent. 22649 #IP node 46684 1338 Models Gold parse System parse CF P R F P R F #nonZ RULE - 54.4 73.7 62.6 57.4 50.5 53.7 - modified (Xiang et al., 2013) - 76.8 62.0 68.6 57.4 46.9 51.6 321k modified (Johnson, 2002) - 81.3 25.0 38.1 66.8 18.1 28.6 - PATH x CHILD - 71.0 67.7 69.3 55.9 49.1 52.3 108k PATH x (CHILD + HEAD + EC) - 74.8 69.5 72.1 56.2 51.8 53.9 123k PATH x (CHILD + HEAD + EC) +DCF 78.0 68.9 73.2 59.7 50.5 54.7 124k PATH x (CHILD + HEAD + EC) +BIN 77.1 70.2 73.5 58.8 51.6 55.0 124k PATH x (CHILD + HEAD + EC) +SET 77.5 70.0 73.6 58.5 51.4 54.7 126k PATH x (CHILD + HEAD + EC) +DIST 77.5 68.3 72.6 60.4 50.6 55.1 124k Table 4: Result of our models with baselines. #nonZ means the amount of non-zero weight of model 5 Conclusion In this paper, we proposed a novel model for empty category detection in</context>
</contexts>
<marker>Johnson, 2002</marker>
<rawString>Mark Johnson. 2002. A simple pattern-matching algorithm for recovering empty nodes and their antecedents. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 136–143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>Case frame compilation from the web using highperformance computing.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation,</booktitle>
<pages>1344--1347</pages>
<contexts>
<context position="13542" citStr="Kawahara and Kurohashi, 2006" startWordPosition="2312" endWordPosition="2315"> to the surface level. An empty node is regarded as correctly predicted surface position in the sentence, type (T or pro) and function (SBJ, OB1 and so on) are matched with the reference. To evaluate the effectiveness of the proposed 1There are two models available in HARUNIWA, namely the BitPar model (Schmid, 2004) and Berkeley Parser binary branching model (Petrov and Klein, 2007). The output of the later is first flattened, then added disambiguation tags and empty categories using tsurgeon script (Levy and Andrew, 2006). distributed case frame (DCF), we used an existing case frame lexicon (Kawahara and Kurohashi, 2006) and tested three different ways of encoding the case frame information: BIN encodes each case as binary features. SET encodes each combination of required cases as a binary feature. DIST is a vector of co-occurrence counts for each case particle, which can be thought of an unsmoothed version of our DCF. Table 4 shows the accuracies of various empty category detection methods, for both gold parse and system parse. In the gold parse condition, the two baselines, the rule-based method (RULE) and the modified (Xiang et al., 2013) method, achieved the F-measure of 62.6% and 68.6% respectively. We </context>
</contexts>
<marker>Kawahara, Kurohashi, 2006</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi. 2006. Case frame compilation from the web using highperformance computing. In Proceedings of the 5th International Conference on Language Resources and Evaluation, pages 1344–1347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Hiroshi Ichikawa</author>
<author>Hideto Kazawa</author>
</authors>
<title>A joint inference of deep case analysis and zero subject generation for Japanese-to-English statistical machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>557--562</pages>
<contexts>
<context position="1588" citStr="Kudo et al. (2014)" startWordPosition="237" endWordPosition="240">3.2% in terms of F-measure. 1 Introduction Empty categories are phonetically null elements that are used for representing dropped pronouns (“pro” or “small pro”), controlled elements (“PRO” or “big pro”) and traces of movement (“T” or “trace”), such as WH-questions and relative clauses. They are important for pro-drop languages such as Japanese, in particular, for the machine translation from pro-drop languages to nonpro-drop languages such as English. Chung and Gildea (2010) reported their recover of empty categories improved the accuracy of machine translation both in Korean and in Chinese. Kudo et al. (2014) showed that generating zero subjects in Japanese improved the accuracy of preorderingbased translation. State-of-the-art statistical syntactic parsers had typically ignored empty categories. Although Penn Treebank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of </context>
</contexts>
<marker>Kudo, Ichikawa, Kazawa, 2014</marker>
<rawString>Taku Kudo, Hiroshi Ichikawa, and Hideto Kazawa. 2014. A joint inference of deep case analysis and zero subject generation for Japanese-to-English statistical machine translation. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 557–562.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Levy</author>
<author>Galen Andrew</author>
</authors>
<title>Tregex and Tsurgeon: tools for querying and manipulating tree data structures.</title>
<date>2006</date>
<booktitle>In Proceedings of 5th International Conference on Language Resources and Evaluation,</booktitle>
<pages>2231--2234</pages>
<contexts>
<context position="13441" citStr="Levy and Andrew, 2006" startWordPosition="2296" endWordPosition="2299">ation metrics described in (Xiang et al., 2013). It projects the predicted empty category tags to the surface level. An empty node is regarded as correctly predicted surface position in the sentence, type (T or pro) and function (SBJ, OB1 and so on) are matched with the reference. To evaluate the effectiveness of the proposed 1There are two models available in HARUNIWA, namely the BitPar model (Schmid, 2004) and Berkeley Parser binary branching model (Petrov and Klein, 2007). The output of the later is first flattened, then added disambiguation tags and empty categories using tsurgeon script (Levy and Andrew, 2006). distributed case frame (DCF), we used an existing case frame lexicon (Kawahara and Kurohashi, 2006) and tested three different ways of encoding the case frame information: BIN encodes each case as binary features. SET encodes each combination of required cases as a binary feature. DIST is a vector of co-occurrence counts for each case particle, which can be thought of an unsmoothed version of our DCF. Table 4 shows the accuracies of various empty category detection methods, for both gold parse and system parse. In the gold parse condition, the two baselines, the rule-based method (RULE) and </context>
</contexts>
<marker>Levy, Andrew, 2006</marker>
<rawString>Roger Levy and Galen Andrew. 2006. Tregex and Tsurgeon: tools for querying and manipulating tree data structures. In Proceedings of 5th International Conference on Language Resources and Evaluation, pages 2231–2234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="1824" citStr="Marcus et al., 1993" startWordPosition="267" endWordPosition="270"> “trace”), such as WH-questions and relative clauses. They are important for pro-drop languages such as Japanese, in particular, for the machine translation from pro-drop languages to nonpro-drop languages such as English. Chung and Gildea (2010) reported their recover of empty categories improved the accuracy of machine translation both in Korean and in Chinese. Kudo et al. (2014) showed that generating zero subjects in Japanese improved the accuracy of preorderingbased translation. State-of-the-art statistical syntactic parsers had typically ignored empty categories. Although Penn Treebank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integra</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a Large Annotated Corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Pennington</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>GloVe: Global Vectors for Word Representation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1532--1543</pages>
<contexts>
<context position="10823" citStr="Pennington et al., 2014" startWordPosition="1830" endWordPosition="1833"> and HEAD is:IP-MATx 連れ (tsure) and the combinations of PATH and CHILD are: IP-MATxPP-を (wo), IP-MATxVB, IP-MATxVB2, IP-MATxAXD-た (ta) and IP-MATxPU-。 . 3.1 Using Word Embedding to approximate Case Frame Lexicon A case frame lexicon would be obviously useful for empty category detection because it provides information on the type of argument the verb in question takes. The problem is that case frame lexicon is not usually readily available. We propose a novel method to approximate case frame lexicon for languages with explicit case marking such as Japanese using word embeddings. According to (Pennington et al., 2014), they designed their embedding model GloVe so that the dot product of two word embeddings approximates the logarithm of their co-occurrence counts. Using this characteristic, we can easily make a feature that approximate the case frame of a verb. Given a set of word embeddings for case particles q1, q2, · · · , qN E Q, the distributed case frame feature (DCF) for a verb wi is defined as: ˜vi = wi · (q1, q2, ··· , qN) (2) ˜vi (3) ||˜vi|| In our experiment, we used a set of high frequency case particles が (ga), は (ha), も (mo), の (no), を (wo), に (ni), へ (he) and から (kara) as Q. 4 Experiment 4.1 </context>
</contexts>
<marker>Pennington, Socher, Manning, 2014</marker>
<rawString>Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. GloVe: Global Vectors for Word Representation. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing, pages 1532–1543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved Inferencing for Unlexicalized Parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of HLT-NAACL 2007 - Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="13298" citStr="Petrov and Klein, 2007" startWordPosition="2274" endWordPosition="2277"> of the Berkeley Parser model of HARUNIWA before rule-based empty category detection1. We evaluated them using the word-position-level identification metrics described in (Xiang et al., 2013). It projects the predicted empty category tags to the surface level. An empty node is regarded as correctly predicted surface position in the sentence, type (T or pro) and function (SBJ, OB1 and so on) are matched with the reference. To evaluate the effectiveness of the proposed 1There are two models available in HARUNIWA, namely the BitPar model (Schmid, 2004) and Berkeley Parser binary branching model (Petrov and Klein, 2007). The output of the later is first flattened, then added disambiguation tags and empty categories using tsurgeon script (Levy and Andrew, 2006). distributed case frame (DCF), we used an existing case frame lexicon (Kawahara and Kurohashi, 2006) and tested three different ways of encoding the case frame information: BIN encodes each case as binary features. SET encodes each combination of required cases as a binary feature. DIST is a vector of co-occurrence counts for each case particle, which can be thought of an unsmoothed version of our DCF. Table 4 shows the accuracies of various empty cate</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved Inferencing for Unlexicalized Parsing. In Proceedings of HLT-NAACL 2007 - Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Santorini</author>
</authors>
<title>Annotation Manual for the Penn Historical</title>
<date>2010</date>
<journal>Corpora and the PCEEC (Release</journal>
<volume>2</volume>
<contexts>
<context position="4680" citStr="Santorini, 2010" startWordPosition="738" endWordPosition="739"> NP P IP-REL N を wo NP-SBJ VB VB0 AXD 娘 musume a daughter *T* 家出 し た iede shi ta NP-OB 1 VB VB2 modoshi ta VB VB2 AXD ta *を * 連れ 戻し AXD PU PP P 連れ 戻し た PU tsure た 。 NP tsure modoshi 。 brought-back . brought-back . IP-REL:*T*-SBJ@0 N を � wo VB VB0 AXD 娘 musume a daughter 家出 し た iede shi ta NP-SBJ *pro* who ran-away-from-home ran-away-from-home Figure 1: An annotation example of 家出し た娘を 連れ戻し た。 (*pro* brought back a daughter who ran away from home.) in Keyaki Treebank. (The left tree is the original tree and the right tree is a converted tree based on Xiang et al.’s (2013) formalism) the PCEEC (Santorini, 2010). There are some major changes: the VP level of structure is typically absent, function is marked on all clausal nodes (such as IP-REL and CP-THT) and all NPs that are clause level constituents (such as NP-SBJ). Disambiguation tags are also used for clarifying the functions of its immediately preceding node, such as NP-OBJ *を *(wo) for PP, however, we removed them in our experiment. Keyaki Treebank has annotation for trace markers of relative clauses (*T*) and dropped pronouns (*pro*), however, it deliberately has no annotation for control dependencies (PRO) (Butler et al., 2015). It has also </context>
</contexts>
<marker>Santorini, 2010</marker>
<rawString>Santorini. 2010. Annotation Manual for the Penn Historical Corpora and the PCEEC (Release 2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Efficient parsing of highly ambiguous context-free grammars with bit vectors.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>162--168</pages>
<contexts>
<context position="13230" citStr="Schmid, 2004" startWordPosition="2266" endWordPosition="2267">the systems. In system parse condition, we used the output of the Berkeley Parser model of HARUNIWA before rule-based empty category detection1. We evaluated them using the word-position-level identification metrics described in (Xiang et al., 2013). It projects the predicted empty category tags to the surface level. An empty node is regarded as correctly predicted surface position in the sentence, type (T or pro) and function (SBJ, OB1 and so on) are matched with the reference. To evaluate the effectiveness of the proposed 1There are two models available in HARUNIWA, namely the BitPar model (Schmid, 2004) and Berkeley Parser binary branching model (Petrov and Klein, 2007). The output of the later is first flattened, then added disambiguation tags and empty categories using tsurgeon script (Levy and Andrew, 2006). distributed case frame (DCF), we used an existing case frame lexicon (Kawahara and Kurohashi, 2006) and tested three different ways of encoding the case frame information: BIN encodes each case as binary features. SET encodes each combination of required cases as a binary feature. DIST is a vector of co-occurrence counts for each case particle, which can be thought of an unsmoothed ve</context>
</contexts>
<marker>Schmid, 2004</marker>
<rawString>Helmut Schmid. 2004. Efficient parsing of highly ambiguous context-free grammars with bit vectors. In Proceedings of the 20th International Conference on Computational Linguistics, pages 162–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Trace Prediction and Recovery with Unlexicalized PCFGs and Slash Features.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>177--184</pages>
<contexts>
<context position="2394" citStr="Schmid (2006)" startWordPosition="349" endWordPosition="350">lthough Penn Treebank (Marcus et al., 1993) has annotations on PRO and trace, they provide only labeled bracketing. Johnson (2002) proposed a statistical pattern-matching algorithm for post-processing the results of syntactic parsing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for pro (dropped pronouns or zero pronoun) has begun to receive attention as the Chinese Penn Treebank (Xue et al., 2005) has annotations for pro as well as PRO and trace. Xue and Yang (2013) formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure. Wang et al. (2015) proposed a joint embedding of empty categories and their contexts on dependency structure. Xiang et al. (2013) formalized the problem as classifying</context>
</contexts>
<marker>Schmid, 2006</marker>
<rawString>Helmut Schmid. 2006. Trace Prediction and Recovery with Unlexicalized PCFGs and Slash Features. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 177–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Xiang</author>
<author>Xiaoqiang Luo</author>
<author>Bowen Zhou</author>
</authors>
<title>Enlisting the ghost: Modeling empty categories for machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>822--831</pages>
<contexts>
<context position="2956" citStr="Xiang et al. (2013)" startWordPosition="445" endWordPosition="448">es with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for pro (dropped pronouns or zero pronoun) has begun to receive attention as the Chinese Penn Treebank (Xue et al., 2005) has annotations for pro as well as PRO and trace. Xue and Yang (2013) formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure. Wang et al. (2015) proposed a joint embedding of empty categories and their contexts on dependency structure. Xiang et al. (2013) formalized the problem as classifying each IP node (roughly corresponds to S and SBAR in Penn Treebank) in the phrase structure. In this paper, we propose a novel method for empty category detection for Japanese that uses conjunction features on phrase structure and word embeddings. We use the Keyaki Treebank (Butler et al., 2012), which is a recent development. As it has annotations for pro and trace, we show our method has substantial improvements over the state-of-the-art machine learning-based method (Xiang et al., 2013) for Chinese empty category detection as well as linguistically-motiv</context>
<context position="6298" citStr="Xiang et al., 2013" startWordPosition="1020" endWordPosition="1023">ng et al’s (2013) model as another baseline. It formulates empty category detection as the classification of IP nodes. For example, in Figure 1, empty nodes in the left tree are removed and encoded as additional labels with its position information to IP nodes in the right tree. As we can uniquely decode them from the extended IP labels, the problem is to predict the labels for the input tree that has no empty nodes. Let T = t1t2 · · · tn be the sequence of nodes produced by the post-order traversal from root node, and ei be the empty category tag associated with ti. The probability model of (Xiang et al., 2013) is formulated as MaxEnt model: P(ei|ei−1 1 , T) exp(θ · φ(ei, ei−1 1 , T)) (1) Z(ei−1 1 , T ) where φ is a feature vector, θ is a weight vector to φ and Z is normalization factor: exp(θ · φ(e, ei−1 1 , T)) where £ represents the set of all empty category types to be detected. Xiang et al. (2013) grouped their features into four types: tree label features, lexical features, empty category features and conjunction features as shown in Table 1. As the features for (Xiang et al., 2013) were developed for Chinese Penn Treebank, we modify their features for Keyaki Treebank: First, the traversal ord</context>
<context position="8701" citStr="Xiang et al., 2013" startWordPosition="1453" endWordPosition="1456">rd of the parent node 17 is the current node head child of its parent? (binary) Empty category features 18 predicted empty categories of the left sibling 19* the set of detected empty categories of ancestor nodes Conjunction features 20 current node label with parent node label 21* current node label with features computed from ances22 tor nodes 23 current node label with features computed from leftsibling nodes current node label with lexical features Table 1: List of features of Xiang et al.’s (2013). (* indicates the features we changed for the Keyaki Treebank) Features F(Gold) A original (Xiang et al., 2013) 68.2 −0.40 modified (Xiang et al., 2013) 68.6 - − Tree label 68.6 −0.00 − Empty category 68.3 −0.30 − Lexicon 68.6 −0.00 − Conjunction 58.5 −10.1 Table 2: Ablation result of (Xiang et al., 2013) are highly effective compared to the three other features. This observation leads to the model proposed in the next section. 3 Proposed model In the proposed model, we use combinations of path features and three other features, namely head word feature, child feature and empty category feature. Path feature (PATH) is a sequence of nonterminal labels from the current node to the ancestor nodes up to ei</context>
<context position="12866" citStr="Xiang et al., 2013" startWordPosition="2204" endWordPosition="2207">0 million words and 23.4 million sentences. By using the development set, we set the dimension of word embedding and the window size for co-occurrence counts as 200 and 10, respectively. 4.2 Result and Discussion We tested in two conditions: gold parse and system parse. In gold parse condition, we used the trees of Keyaki Treebank without empty categories as input to the systems. In system parse condition, we used the output of the Berkeley Parser model of HARUNIWA before rule-based empty category detection1. We evaluated them using the word-position-level identification metrics described in (Xiang et al., 2013). It projects the predicted empty category tags to the surface level. An empty node is regarded as correctly predicted surface position in the sentence, type (T or pro) and function (SBJ, OB1 and so on) are matched with the reference. To evaluate the effectiveness of the proposed 1There are two models available in HARUNIWA, namely the BitPar model (Schmid, 2004) and Berkeley Parser binary branching model (Petrov and Klein, 2007). The output of the later is first flattened, then added disambiguation tags and empty categories using tsurgeon script (Levy and Andrew, 2006). distributed case frame </context>
<context position="15654" citStr="Xiang et al., 2013" startWordPosition="2687" endWordPosition="2690">is comparable to the existing case frame lexicon. Table 5 shows the ablation result of the proposed model. It indicates conjunction between PATH and CHILD feature is most effective. F(Gold) A F(System) A Proposed 72.1 - 53.9 - −CHILD 47.4 −24.7 33.7 −20.2 −EC 70.8 −1.3 52.4 −1.5 −HEAD 70.0 −2.1 51.6 −2.3 Table 5: Ablation result of PATH x (CHILD + EC + HEAD) model ALL OB1 1568 OB2 59 #T ADT 97 LOC 164 OB1 755 OB2 15 SBJ 3788 TMP 53 MSR 14 TPC 10 char/sent. 32.0 #sent. 22649 #IP node 46684 1338 Models Gold parse System parse CF P R F P R F #nonZ RULE - 54.4 73.7 62.6 57.4 50.5 53.7 - modified (Xiang et al., 2013) - 76.8 62.0 68.6 57.4 46.9 51.6 321k modified (Johnson, 2002) - 81.3 25.0 38.1 66.8 18.1 28.6 - PATH x CHILD - 71.0 67.7 69.3 55.9 49.1 52.3 108k PATH x (CHILD + HEAD + EC) - 74.8 69.5 72.1 56.2 51.8 53.9 123k PATH x (CHILD + HEAD + EC) +DCF 78.0 68.9 73.2 59.7 50.5 54.7 124k PATH x (CHILD + HEAD + EC) +BIN 77.1 70.2 73.5 58.8 51.6 55.0 124k PATH x (CHILD + HEAD + EC) +SET 77.5 70.0 73.6 58.5 51.4 54.7 126k PATH x (CHILD + HEAD + EC) +DIST 77.5 68.3 72.6 60.4 50.6 55.1 124k Table 4: Result of our models with baselines. #nonZ means the amount of non-zero weight of model 5 Conclusion In this pa</context>
</contexts>
<marker>Xiang, Luo, Zhou, 2013</marker>
<rawString>Bing Xiang, Xiaoqiang Luo, and Bowen Zhou. 2013. Enlisting the ghost: Modeling empty categories for machine translation. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 822–831.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Yaqin Yang</author>
</authors>
<title>Dependencybased empty category detection via phrase structure trees.</title>
<date>2013</date>
<booktitle>In Proceedings of HLT-NAACL 2013, Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings of the Main Conference,</booktitle>
<pages>1051--1060</pages>
<contexts>
<context position="2697" citStr="Xue and Yang (2013)" startWordPosition="401" endWordPosition="404">o its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for pro (dropped pronouns or zero pronoun) has begun to receive attention as the Chinese Penn Treebank (Xue et al., 2005) has annotations for pro as well as PRO and trace. Xue and Yang (2013) formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure. Wang et al. (2015) proposed a joint embedding of empty categories and their contexts on dependency structure. Xiang et al. (2013) formalized the problem as classifying each IP node (roughly corresponds to S and SBAR in Penn Treebank) in the phrase structure. In this paper, we propose a novel method for empty category detection for Japanese that uses conjunction features on phrase structure and word embeddings. We use the Keyaki Treebank (Butler et al., 2012), which </context>
</contexts>
<marker>Xue, Yang, 2013</marker>
<rawString>Nianwen Xue and Yaqin Yang. 2013. Dependencybased empty category detection via phrase structure trees. In Proceedings of HLT-NAACL 2013, Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, Proceedings of the Main Conference, pages 1051–1060.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naiwen Xue</author>
<author>Fei Xia</author>
<author>Fu-Dong Chiou</author>
<author>Marta Palmer</author>
</authors>
<title>The Penn Chinese TreeBank: Phrase structure annotation of a large corpus.</title>
<date>2005</date>
<journal>Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="2627" citStr="Xue et al., 2005" startWordPosition="387" endWordPosition="390">sing based on minimal unlexicalized tree fragments from empty node to its antecedent. Dienes and Dubey (2003) proposed a machine learning-based “trace tagger” as a preprocess of parsing. Campbell (2004) proposed a rule-based post-processing method based on linguistically motivated rules. Gabbard et al. (2006) replaced the rules with machine learning-based classifiers. Schmid (2006) and Cai et al. (2011) integrated empty category detection with the syntactic parsing. Empty category detection for pro (dropped pronouns or zero pronoun) has begun to receive attention as the Chinese Penn Treebank (Xue et al., 2005) has annotations for pro as well as PRO and trace. Xue and Yang (2013) formalized the problem as classifying each pair of the location of empty category and its head word in the dependency structure. Wang et al. (2015) proposed a joint embedding of empty categories and their contexts on dependency structure. Xiang et al. (2013) formalized the problem as classifying each IP node (roughly corresponds to S and SBAR in Penn Treebank) in the phrase structure. In this paper, we propose a novel method for empty category detection for Japanese that uses conjunction features on phrase structure and wor</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Naiwen Xue, Fei Xia, Fu-Dong Chiou, and Marta Palmer. 2005. The Penn Chinese TreeBank: Phrase structure annotation of a large corpus. Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>