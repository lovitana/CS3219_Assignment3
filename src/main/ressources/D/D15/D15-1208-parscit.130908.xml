<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.999002">
Personality Profiling of Fictional Characters using Sense-Level Links
between Lexical Resources
</title>
<author confidence="0.968191">
Lucie Flekova† and Iryna Gurevych†‡† Ubiquitous Knowledge Processing Lab (UKP-TUDA)
</author>
<affiliation confidence="0.909596333333333">
Department of Computer Science, Technische Universit¨at Darmstadt
‡ Ubiquitous Knowledge Processing Lab (UKP-DIPF)
German Institute for Educational Research
</affiliation>
<email confidence="0.59362">
www.ukp.tu-darmstadt.de
</email>
<bodyText confidence="0.412746333333333">
“Always be yourself, unless you can
be Batman. Then always be Batman.”
– Bill Murray
</bodyText>
<sectionHeader confidence="0.967101" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999939">
This study focuses on personality predic-
tion of protagonists in novels based on
the Five-Factor Model of personality. We
present and publish a novel collaboratively
built dataset of fictional character person-
ality and design our task as a text classifi-
cation problem. We incorporate a range
of semantic features, including WordNet
and VerbNet sense-level information and
word vector representations. We evalu-
ate three machine learning models based
on the speech, actions and predicatives of
the main characters, and show that espe-
cially the lexical-semantic features signifi-
cantly outperform the baselines. The most
predictive features correspond to reported
findings in personality psychology.
</bodyText>
<sectionHeader confidence="0.998989" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994050909091">
Recent progress in NLP has given rise to the field
of personality profiling - automated classification
of personality traits based on written, verbal and
multimodal behavior of an individual. This re-
search builds upon findings from classical person-
ality psychology and has applications in a wide
range of areas from medicine (suicide prevention)
across security (forensics, paedophile detection,
cyberbullying) to marketing and sales (recommen-
dation systems, target group profiles). The gold
standard labels for an objective evaluation of per-
sonality are mostly obtained by means of personal-
ity tests of the Five Factor Model (FFM) (McCrae
and Costa, 1987; Goldberg, 1990), which is well-
known and widely accepted in psychology and
other research fields. The FFM defines personality
along five bipolar scales: Extraversion (sociable
vs. reserved), Emotional stability (secure vs. neu-
rotic), Agreeableness (friendly vs. unsympathic),
Conscientiousness (organized vs. careless) and
Openness to experience (insightful vs. unimagi-
native). Psychologists have shown that these five
personality traits are stable across individual lifes-
pan, demographical and cultural differences (John
and Srivastava, 1999) and affect many life aspects.
(Terracciano et al., 2008; Rentfrow et al., 2011).
It has been shown that the personality traits of
readers impact their literature preferences (Tirre
and Dixit, 1995; Mar et al., 2009). Psychology
researchers also found that perceived similarity
is predictive of interpersonal attraction (Montoya
et al., 2008; Byrne, 1961; Chartrand and Bargh,
1999). More explicitly, recent research (Kaufman
and Libby, 2012) shows that readers of a narrative
develop more favorable attitudes and less stereo-
type application towards a character, if his differ-
ence (e.g. racial) is revealed only later in the story.
We therefore hypothesize that readers might have
a preference for reading novels depicting fictional
characters that are similar to themselves. Finding a
direct link between reader’s and protagonist’s per-
sonality traits would advance the development of
content-based recommendation systems. As a first
step to explore this hypothesis further, it needs to
be determined if we are able to construct a per-
sonality profile of a fictional character in a similar
way as it is done for humans, and which aspects
of personality profiling can be exploited to autom-
atize such procedure.
In this paper, we open this research topic by
presenting a novel collaboratively built dataset
of fictional character personality in Section 3,
which we make available on our website.1 Fram-
ing the personality prediction as a text classifica-
tion task, we incorporate features of both lexical-
</bodyText>
<footnote confidence="0.9907325">
1https://www.ukp.tu-darmstadt.de/data/
personality-profiling/
</footnote>
<page confidence="0.861071">
1805
</page>
<note confidence="0.985661">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1805–1816,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999307818181818">
resource-based and vector space semantics, in-
cluding WordNet and VerbNet sense-level infor-
mation and vectorial word representations. We
evaluate three machine learning models based on
the speech (Section 4), actions (Section 5) and
predicatives (Section 6) of the protagonists, and
show that especially on the direct speech and
action data the lexical-semantic features signifi-
cantly outperform the baselines. Qualitative anal-
ysis reveals that the most predictive features corre-
spond to reported findings in psychology and NLP.
</bodyText>
<sectionHeader confidence="0.999622" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999855101123596">
Research in the the area of content-based recom-
mendation systems have shown that incorporat-
ing semantic information is valuable for the user
and leads to measurable improvements (Passant,
2010; Di Noia et al., 2012; Heitmann and Hayes,
2010). De Clercq et al. (2014) incorporated se-
mantic frames from FrameNet into the recommen-
dation system for books. They represent the plot
of each book with a sequence of ca. 200 seman-
tic frames and has shown that the frame informa-
tion (such as Killing - Revenge - Death) outper-
forms the bag-of-words approach.Recent NLP ex-
periments begin to reveal the importance of entity-
centric models in a variety of tasks. Chambers
(2013) show improvement in event schema induc-
tion by learning entity-centric rules (e.g., a victim
is likely to be a person). Bamman et al. (2014) and
Smith et al. (2013) present latent variable models
for unsupervised learning of latent character types
in movie plot summaries and in English novels,
taking authorial style into account. However, even
the state-of-the-art NLP work rather describes per-
sonas of fictional characters by their role in the
story - e.g., action hero, valley girl, best friend,
villain etc. - or by their relations to other char-
acters, such as mother or daughter (Elson et al.,
2010; Kokkinakis and Malm, 2011), rather than
by their inner preferences and motivations. It is
important to note here that determining a person-
ality of a character is a very different task from
determining its role in the story. Psychological
understanding of personality, in contrast to role at-
tribution requires a certain detached objectivity -
even outright villains may have traits considered
desirable in real life. For example, the devil has
in many tales a very high aspiration level, appear-
ing highly conscientious and agreeable. We hy-
pothesize that these deeper personality aspects are
those which drive reader’s affiliation to the char-
acter, thus deserve to be examined closer.
Also literary scholars formulate ad hoc person-
ality descriptions for their experiments, for exam-
ple to test hypotheses from evolutionary psychol-
ogy (Johnson et al., 2011) or examine fictional
portrayals of physicists (Dotson, 2009). These de-
scriptions are usually adjusted to the experiment
focus (e.g. emotions, relationships, ambitions).
As McCrae et al. () point out, a standard set of
personality traits, that encompass the full range of
characteristics found in all characters in literature
(p.77), is needed for a better comparison.
Hence we base our present study primarily on
the previous NLP research on personality predic-
tion of human individuals. Correlations between
lexical and stylistic aspects of text and the five
FFM personality traits of the author have been
found in numerous experiments, with extraver-
sion receiving the most attention (Pennebaker and
King, 1999; Dewaele and Furnham, 1999; Gill and
Oberlander, 2002; Mehl et al., 2006; Aran and
Gatica-Perez, 2013; Lepri et al., 2010). The LIWC
lexicon (Pennebaker et al., 2001) established its
position as a powerful mean of such analysis.
The first machine learning experiments in this
area were conducted by Argamon et al. (2005),
Oberlander and Nowson (2006) and Mairesse
et al. (2007). Researchers predicted the five
personality traits of the authors of stream-of-
conscientiousness essays, blog posts and recorded
conversation snippets. Given balanced data sets,
Mairesse et al. (2007) report binary classification
accuracy of 50-56% on extraversion in text and
47-57% in speech, using word ngrams, LIWC,
MRC psycholinguistic database (Coltheart, 1981)
and prosodic features. Additional improvement
is reported when the extraversion was labeled by
external judges rather than by self-testing. Ex-
tended studies on larger datasets achieve accu-
racies around 55% (Nowson, 2007; Estival et
al., 2007). More recent work in this area fo-
cuses on the personality prediction in social net-
works (Kosinski et al., 2013; Kosinski et al.,
2014) and multimodal personality prediction (Biel
and Gatica-Perez, 2013; Aran and Gatica-Perez,
2013). These trends emphasized the correlation of
network features and audiovisual features with ex-
traversion, giving rise to the Workshop on Compu-
tational Personality Recognition (for an overview
see (Celli et al., 2013; Celli et al., 2014).
</bodyText>
<page confidence="0.995002">
1806
</page>
<sectionHeader confidence="0.950797" genericHeader="method">
3 Data set construction
</sectionHeader>
<bodyText confidence="0.999988886363636">
Traditionally, the gold standard for this supervised
classification task is obtained by the means of per-
sonality questionnaires, used for the Five-Factor
Model, taken by each of the individuals assessed.
This poses a challenge for fictional characters.
However, strong correlations have been found be-
tween the self-reported and perceived personality
traits (Mehl et al., 2006). Our gold standard bene-
fits from the fact that readers enjoy discussing the
personality of their favourite book character on-
line. A popular layman instrument for personal-
ity classification is the Myers-Brigggs Type Indi-
cator (Myers et al., 1985), shortly MBTI, which
sorts personal preferences into four opposite pairs,
or dichotomies, such as Thinking vs. Feeling or
Judging vs. Perceiving. While the MBTI validity
has been questioned by the research community
(Pittenger, 2005), the Extraversion scale is show-
ing rather strong validity and correlation to similar
trait in the Five-Factor Model (McCrae and Costa,
1989; MacDonald et al., 1994). Our study hence
focuses on the Extraversion scale.
Our data was collected from the collabora-
tively constructed Personality Databank2 where
the readers can vote if a book character is, among
other aspects, introverted or extraverted. While the
readers used codes based on the MBTI typology,
they did not apply the MBTI assessment strate-
gies. There was no explicit annotation guideline
and the interpretation was left to readers’ intuition
and knowledge.3 This approach of gold standard
collection has several obvious drawbacks. First,
the question is posed as dichotomic, while in real-
ity the extraversion is a normally distributed trait
in human population (Goldberg, 1990). Second,
users can view the vote of previous participants,
which may influence their decision. While we ad-
dress both of these issues in our ongoing data col-
lection project based on the Five-Factor Model, we
consider them acceptable for this study due to the
exploratory character of our pilot research.
We have collected extraversion ratings for 298
book characters, of which 129 (43%) are rather ex-
traverted and 166 (56%) rather introverted. Rated
</bodyText>
<footnote confidence="0.495345142857143">
2http://www.mbti-databank.com/
3MBTI defines extraversion as “getting energy from ac-
tive involvement in events, having a lot of different activities,
enjoying being around people.” In the NEO Five-Factor In-
ventory (Costa and McCrae, 1992), underlying facets of ex-
traversion are warmth, gregariousness, assertiveness, activity,
excitement seeking and positive emotion.
</footnote>
<bodyText confidence="0.9998415">
characters come from a wide range of novels that
the online users are familiar with, often covering
classical literature which is part of the high school
syllabus, as well as the most popular modern fic-
tion, such as the Harry Potter series, Twilight, Star
Wars or A Game of Thrones. A sample of the most
rated introverts and extraverts is given in table 1.
The rating distribution in our data is strongly U-
shaped. The percentage agreement of voters in our
data is 84.9%, calculated as:
</bodyText>
<equation confidence="0.9676765">
nij(nij − 1)
n(n − 1)
</equation>
<bodyText confidence="0.999921833333333">
where k = 2 (introvert, extravert), N is the num-
ber of book characters and n the number of votes
per character. Voters on the website were anony-
mous and cannot be uniquely identified for addi-
tional corrections. There is no correlation between
the extraversion and the gender of the character.
</bodyText>
<table confidence="0.99813180952381">
Character Book E I
Tyrion Lannister Game of Thrones 52 1
Cersei Lannister Game of Thrones 48 7
Joffrey Baratheon Game of Thrones 41 1
Ron Weasley Harry Potter series 37 4
Jamie Lannister Game of Thrones 38 9
Draco Malfoy Harry Potter series 33 4
Anakin Skywalker Star Wars series 30 6
Robert Baratheon Game of Thrones 28 2
Gimli Lord of the Rings 19 2
Jar Jar Binks Star Wars series 12 2
Harry Potter Harry Potter series 1 71
Severus Snape Harry Potter series 1 65
Gandalf Lord of the Rings 1 59
Yoda Star Wars series 0 58
Jon Snow Game of Thrones 1 47
Albus Dumbledore Harry Potter series 4 46
Ned Stark Game of Thrones 0 41
Aragorn Lord of the Rings 1 41
Frodo Lord of the Rings 1 40
Bran Stark Game of Thrones 1 36
</table>
<tableCaption confidence="0.9823955">
Table 1: Extraverts (E) and introverts (I) with the highest
number of user votes.
</tableCaption>
<bodyText confidence="0.991797333333333">
Our set of English e-books covered 220 of the
characters from our gold standard. We have built
three systems to assess the following:
</bodyText>
<listItem confidence="0.999715428571429">
1. Direct speech: Does the style and content of
character’s utterances predict his extraversion
in a similar way as it was shown for living
individuals?
2. Actions: Is the behavior, of which a character
is an agent, predictive for extraversion?
3. Predicatives and adverbs: Are the explicit
</listItem>
<bodyText confidence="0.601053333333333">
(John was an exhibitionist) or implicit (John
shouted abruptly) descriptions of the charac-
ter in the book predictive for extraversion?
</bodyText>
<equation confidence="0.996526714285714">
1
P=
N
N
i=1
k
j=1
</equation>
<page confidence="0.951792">
1807
</page>
<bodyText confidence="0.9999765">
In the next three sections we present the experi-
mental settings and results for each of the systems.
</bodyText>
<sectionHeader confidence="0.797547" genericHeader="method">
4 Direct speech of fictional characters
</sectionHeader>
<bodyText confidence="0.999996545454545">
The system for the direct speech resembles the
most to the previous systems developed for author
personality profiling, e.g. on stream of conscious-
ness essays (Mairesse et al., 2007) or social media
posts (Celli et al., 2013) and therefore provides
the best opportunity for comparison between hu-
man individuals and fictional characters. On top
of the comparison to previous research, we exploit
the sense links between WordNet and VerbNet to
extract additional features - an approach which is
novel for this type of task.
</bodyText>
<subsectionHeader confidence="0.984972">
4.1 Extraction and assignment of speech
</subsectionHeader>
<bodyText confidence="0.984821348837209">
We process the book text using freely available
components of the DKPro framework (Gurevych
et al., 2007). The most challenging task in build-
ing the direct speech data set is assigning to the di-
rect speech utterance the correct speaker. We ben-
efit from the epub format of the e-books which
defines a paragraph structure in such a way, that
only the indirect speech chunk immediately sur-
rounding the direct speech can be considered:
&lt;p&gt; John turned to Harry.
&amp;quot;Let’s go,&amp;quot; he said.&lt;/p&gt;
Given the large amount of text available in the
books we focus on precision and discard all utter-
ances with no explicit speaker (i.e., 30-70% of the
utterances, dependent on the book), as the perfor-
mance of current systems on such utterance types
is still fairly low (O’Keefe et al., 2012; He et al.,
2013; Iosif and Mishra, 2014). Similarly, conven-
tional coreference resolution systems did not per-
form well on this type of data and were therefore
not used in the final setup. We adapt the Stanford
Named Entity Recognizer(Finkel et al., 2005) to
consider titles (Mr., Mrs., Sir...) as a part of the
name and to treat the first person I as a named en-
tity. However, identifying only the named entity
PERSON in this way is not sufficient. On our eval-
uation sample consisting of A Game of Thrones
and Pride and Prejudice books (the former anno-
tated by us, the latter by He et al. (2013)), 20%
of utterances with explicit named speaker were
not recognized. Of those correctly identified as a
Person in the adjacent indirect speech, 17% were
not the speakers. Therefore we implemented a
custom heuristics (Algorithm 1), which addition-
ally benefits from the WordNet semantic classes
of verbs, enriching the speaker detection by grab-
bing the nouns . With this method we retrieve
89% of known speakers, of which 92% is assigned
correctly. Retrieved names are grouped based on
string overlap (e.g. Ser Jaime and Jaime Lannis-
ter), excluding the match on last name, and cor-
rected for non-obvious groupings (such as Mar-
garet and Peggy).
</bodyText>
<listItem confidence="0.929722611111111">
Algorithm 1 Assign speaker
1: nsubj ← subjects in adjacent indirect speech
2: if count(nsubj(i) = PERSON) = 1 then speaker ←
nsubj
3: else if count(nsubj(i) = PERSON) ≥ 1 then
speaker ← the nearest one to directSpeech
4: else if directSpeech preceded by
VERB.COMMUNICATION then speaker ← the
preceding noun(s)
5: else if directSpeech followed by
VERB.COMMUNICATION then speaker ← the
following noun(s)
6: else if directSpeech followed by gap &amp;
VERB.COMMUNICATION then speaker ← the noun(s)
in gap
7: else if directSpeech preceded by gap &amp;
VERB.COMMUNICATION then speaker ← the noun(s)
in gap
</listItem>
<bodyText confidence="0.914043333333333">
return speaker
Our experimental data consists of usable direct
speech sets of 175 characters - 80 extraverts (E)
and 95 introverts (I) - containing 289 274 words in
21 857 utterances (on average 111 utterances for
E and 136 for I, as I are often central in books).4
</bodyText>
<subsectionHeader confidence="0.996636">
4.2 Classification approach for direct speech
</subsectionHeader>
<bodyText confidence="0.999896333333333">
All speech utterances of one book character are
represented as one instance in our system. We
use the leave-one-out classification setup due to
the relatively small dataset size, using the support
vector machines (SVM-SMO) classifier, which
performs well on comparable tasks (Celli et al.,
2013). The classification is performed through the
DKPro TC Framework (Daxenberger et al., 2014).
Lexical features As a bottom-up approach we
use the 1000 most frequent word uni-, bi- and tri-
grams, 1000 dependency word pairs, 1000 charac-
ter trigrams and 500 most frequent verbs, adverbs,
adjectives and interjections as binary features.
Semantic features Since the top-down ap-
proach, i.e. not focusing on individual words, has
</bodyText>
<footnote confidence="0.998317">
4The data set size is comparable to ongoing personality
profiling challenges - see http://pan.webis.de
</footnote>
<page confidence="0.994344">
1808
</page>
<bodyText confidence="0.999905583333334">
been found more suitable for the personality pro-
filing task on smaller data sets (Celli et al., 2013),
we aim on capturing additional phenomena on a
higher level of abstraction. The main part of our
features is extracted on sense level. We use the
most frequent sense of WordNet (Miller, 1995)
to annotate all verbs in the direct speech (a sim-
ple but well performing approach for books). We
then label the disambiguated verbs with their se-
mantic field given in WordNet (WordNet defines
14 semantic classes of verbs which group verbs
by their semantic field) and we measure frequency
and occurence of each of these classes (e.g. cogni-
tion, communication, motion, perception)5. Ad-
ditionally, we use the lexical-semantic resource
UBY (Gurevych et al., 2012) to access the Word-
Net and VerbNet information, and to exploit the
VerbNet sense-level links which connects Word-
Net senses with the corresponding 273 main Verb-
Net classes (Kipper-Schuler, 2005). These are
more fine-grained (e.g. pay, conspire, neglect, dis-
cover) than the WordNet semantic fields. WordNet
covered 90% and VerbNet 86% of all the verb oc-
curences.
On word level, we extract 81 additional fea-
tures using the Linguistic Inquiry and Word Count
(LIWC) tools (Pennebaker et al., 2001), which
consists of lexicons related to psychological pro-
cesses (cognitive, perceptual, social, biological,
affective) and personal concerns (achievement, re-
ligion, death...) and other categories such as fillers,
disfluencies or swear words6. Additionally, since
emotion detection has been found predictive in
previous personality work (Mohammad and Kir-
itchenko, 2013), we measure overall positive and
negative sentiment expressed per character, using
SentiWordNet (Esuli and Sebastiani, 2006) and
NRC Emotion Lexicon (Mohammad and Turney,
2010) for the word lookup, inverting sentiment
scores for negated dependency sub-tree given by
the Stanford Parser.
Stylistic features Features of this group cap-
ture the syntactic and stylistic properties of the ut-
terances of a character, disregarding the content.
Starting from the surfacial properties, we measure
the sentence, utterance and word length, including
the proportion of words shorter than 4 or longer
than 6 letters, frequency of each punctuation mark,
</bodyText>
<footnote confidence="0.999701333333333">
5https://wordnet.princeton.edu/man/
lexnames.5WN.html
6For complete overview refer to www.liwc.net
</footnote>
<bodyText confidence="0.999972677419355">
and endings of each adjective as per Corney et al.
(2002). On the syntax level we measure the fre-
quency of each part of speech as well as the 500
most frequent part-of-speech bi-, tri- and quadri-
grams, and the frequency of each dependency ob-
tained from the Stanford Parser. We additionally
capture the frequency of superlatives, compara-
tives and modal verbs, the proportion of verbs in
present, past and future tense, and the formality of
the language as per the part-of-speech-based for-
mality coefficient (Heylighen and Dewaele, 2002),
and measure the average depth of the parse trees.
Word embeddings as features Since vector
space semantics has been beneficial for predicting
author’s personality in previous work (Neuman
and Cohen, 2014), we use a pre-trained word vec-
tor model created by the GloVe algorithm (Pen-
nington et al., 2014) on English Wikipedia. GloVe
employs a global log-bilinear regression model
that combines the advantages of the global matrix
factorization and local context window methods.
We assign the resulting 300-dimensional vectors
to the words in character’s direct speech, exclud-
ing stopwords, and calculate an average vector for
each character. We calculate for each test charac-
ter the cosine similarity to the mean vector of ex-
travert, resp. introvert, in the training data, and to
each character in the training set individually us-
ing the DL4J NLP package7. We consider both the
final scalar outcome and the difference of each of
the individual vector dimensions as features.
</bodyText>
<subsectionHeader confidence="0.995409">
4.3 Classification results on direct speech
</subsectionHeader>
<bodyText confidence="0.996908">
Table 2 shows the precision, recall, Fl-score and
accuracy for extraversion and introversion as a
weighted average of the two class values.
</bodyText>
<table confidence="0.999417090909091">
ID Feature set P R F A
1 - (baseline) .295 .543 .382 .543
2 Ngrams .519 .514 .515 .514
3 LIWC .555 .560 .552 .560
4 WordNet .527 .548 .528 .548
5 VerbNet .649 .617 .572 .617
6 Style .560 .581 .558 .581
7 Sentiment .524 .543 .419 .543
8 Vectors .295 .543 .382 .543
9 All .550 632. .588 .632
Percentage human agreement: .849
</table>
<tableCaption confidence="0.674334857142857">
Table 2: Weighted precision (P), recall (R), F-score (F) and
accuracy (A) for a direct speech system, in each line us-
ing only the given group of features. WordNet stands for
WordNet semantic labels, VerbNet setup uses the WordNet-
VerbNet links to retrieve VerbNet labels. Highlighted F-
scores differ from the majority baseline significantly
(p &lt;0.05), using an approximate randomization test.
</tableCaption>
<footnote confidence="0.970947">
7http://deeplearning4j.org/
</footnote>
<page confidence="0.894216">
1809
</page>
<table confidence="0.999864611111111">
Introvert Features Merit
Feat.group
unigrams reason, trouble, strange, indeed .24-.19
bigrams this time, tell me, I hope .19-.16
LIWC Negate, Discrepancy, .18-.13
Insight, Exclusion
WordNet stative, creation, cognition .15-.09
VerbNet lodge, hunt, defend .23-.19
Style modal verbs, neg, sbar, articles .19-.14
Extravert
Feat.group Features Merit
ngrams we, hurry, fat, dirty .24-.19
LIWC We, Inclusion, Pronoun, Body .18-.09
WordNet motion, contact, communication, .14-.07
body, perception, change
VerbNet get, talk, substance emission .18-.15
Style pronoun We, whadjp, .20-.14
type-token ratio., interjections
</table>
<tableCaption confidence="0.599962">
Table 3: The most predictive features for each group for
speaker’s extraversion and introversion. Correlation merit,
as per the correlation feature selection in WEKA, evaluates
Pearson’s correlation between the feature and the class
</tableCaption>
<bodyText confidence="0.9942091875">
Similarly to previous research (Mairesse et al.,
2007; Celli et al., 2013), the bottom-up word
based approach is outperformed by top-down se-
mantic approaches which employ a more abstract
feature representation. As in previous work,
LIWC features exhibit good performance. How-
ever, the highest performance is achieved employ-
ing the VerbNet verb classes with WordNet word-
sense disambiguation. Also stylistic features con-
tribute substantially to the classification despite
the mixture of genres in our book corpus - es-
pecially frequencies of modal verbs and part-of-
speech ratios were particularly informative. The
most predictive features from each group are listed
in Table 3 together with their correlation merit
(Hall, 1999), and compared with previous work in
</bodyText>
<tableCaption confidence="0.894369">
Table 4.
</tableCaption>
<table confidence="0.9766196875">
Feature I/E Ref Feature I/E Ref
Predictive also in our data: No effect in our data:
Pronoun ’we’ -/+ [3] Neg. emot. +/- [1]
Tentative, unsure +/- [1] Pos. emot. -/+ [1]
Exclusive +/- [1] Self-ref. -/+ [1]
Inclusive -/+ [1] Formality +/- [2]
Insight +/- [1] Elaborated +/- [3]
Nouns, articles +/- Long sent. +/-
Lexical richness +/- Social -/+
Negations +/- [2]
Body functions -/+ [2]
Interjections -/+ [3]
Source ID Author
[1] Pennebaker and King (1999)
[2] Dewaele and Furnham (1999)
[3] Mairesse et al. (2007)
</table>
<tableCaption confidence="0.98140525">
Table 4: Comparison of our results to previously reported
predictive features for speaker’s extraversion (E), resp. intro-
version (I). We list publications where these features were, to
our knowledge, reported as novel.
</tableCaption>
<bodyText confidence="0.999926490196079">
In accordance with the experiments of Pen-
nebaker and King (1999), we observe more fre-
quent exclusions (e.g. without, but), hedging and
negation expressed by introverts, and inclusion
(e.g. with, and) by extraverts. Extraverts talk more
in first person plural, use more back-channels and
interjections, and talk more about aspects related
to their body. Introverts show more rationalization
through insight words and more factual speech us-
ing less pronouns.
Additionally, the semantic features in Table 3
confirm the broad psychological characteristics of
both types in general, i.e., for introverts the ra-
tionalization, uncertainty and preference for indi-
vidual or rather static activities, and for extraverts
their spontaneity, talkativeness and preference for
motion. Furthermore, we observe certain direct-
ness in extraverts’ speech - note the predictive
words fat and dirty and frequent descriptions of
body functions.
Discussion Exploiting the links between lexical-
semantic resources (performing WordNet word-
sense disambiguation and using VerbNet verb
classes linked to the disambiguated senses) was
particularly beneficial for this task. WordNet
semantic fields for verbs alone are too coarse-
grained to capture the nuances in direct speech,
and experiments with fine-grained VerbNet classes
without WSD resulted in noisy labels. We did not
confirm the previously reported findings on emo-
tional polarity - we observe that the genre of the
books (e.g. love romance vs horror story) have
blurred the subtle differences between individual
characters, unfortunately the dataset size did not
allow for genre distinctions. Furthermore, a per-
ceived extravert in our case can be a pure villain
(Draco Malfoy, Joffrey Baratheon...) as well as a
friendly companion (Gimli, Ron Weasley...), while
the evil extravert types are possibly rarer in the ex-
periments on human writing, or are more likely to
fit under the MBTI definition of extraversion than
FFM facets. Another potential cause, based on the
error analysis, is the different target of the same
sentiment for extraverts and introverts. For exam-
ple, the ngram ”I fear” is highly predictive for an
introvert in our data while extraverts would rather
use formulations to imply that others should fear.
Similarly to Nowson et al. (2005), we did not find
any difference in the formality measure of Hey-
lighen and Dewaele (2002). Neither we did in the
complexity of sentences as per the parse tree depth
</bodyText>
<page confidence="0.977084">
1810
</page>
<bodyText confidence="0.999971333333333">
and sentence length. It is probable that these as-
pects were also impacted by our broad variety of
author style (F. Dostoyevsky vs J. K. Rowling).
Our basic vector-based features carried no useful
information in our case, in contrast to the person-
ality research of Neuman and Cohen (2014). We
observed that the factual content of the stories con-
tributed to the character similarity measure more
than the subtle personality differences.
</bodyText>
<sectionHeader confidence="0.827315" genericHeader="method">
5 Actions of fictional characters
</sectionHeader>
<bodyText confidence="0.999957777777778">
While psycholinguists and consequenlty NLP re-
searchers analyzed the relation between speech,
resp. writing, and personality of an individual,
psychologists often evaluate extraversion through
behavioral personality questionnaries (Costa and
McCrae, 1992; Goldberg et al., 2006). We hypoth-
esize that similar behavior shall be predictive for
extraversion of fictional characters as perceived by
the readers.
</bodyText>
<subsectionHeader confidence="0.995591">
5.1 Action extraction
</subsectionHeader>
<bodyText confidence="0.99870275">
For our purpose we define actions as the subject,
verb and context of a sentence, where the subject
is a named entity Person and the context is either
a direct object in relation dobj to the verb or a first
child of the adjacent verb phrase in a parse tree.
After grouping the actions per character, the sub-
ject name is removed. For example, a sample of
actions of the character Eddard Stark of Game of
Thrones would be: X paused a moment, X studied
his face, X changed his mind, X unrolled the paper,
X said etc., visualized in Figure 1. We obtained 22
030 actions for 205 characters (102 E, 116 I), with
on average 100 actions for E and 101 for I. Note
that also actions for those characters who do not
talk enough in the books (often first-person per-
spectives) could be used.
</bodyText>
<figureCaption confidence="0.998728666666667">
Figure 1: A revealing word cloud of the most frequent words
from the actions of which Eddard Stark (Game of Thrones) is
a subject. Size is proportional to the frequency of a word.
</figureCaption>
<subsectionHeader confidence="0.998119">
5.2 Action classification setup
</subsectionHeader>
<bodyText confidence="0.999987">
In the system based on actions we use only a sub-
set of the features described in 4.2. From the lex-
ical features we focus on the 500 most frequent
verbs and dependency word pairs. Semantic fea-
tures are used the same way as in 4.2, profiting
from LIWC, WordNet, Verbnet and the sentiment
lexicons. Word embedding vectors for book char-
acters are in this case computed by taking only the
verbs into account rather than all content words.
From the stylistic features we use the part-of-
speech bigrams and trigrams, verb modality and
verb tense.
</bodyText>
<subsectionHeader confidence="0.994593">
5.3 Classification results on actions
</subsectionHeader>
<bodyText confidence="0.99734525">
Table 5 shows the performance of the classifica-
tion models based on the protagonists’ actions, us-
ing different feature groups. The overall perfor-
mance is higher than for the direct speech model.
</bodyText>
<table confidence="0.956070636363636">
ID Feature set P R F A
1 - (baseline) .267 .517 .352 .517
2 Ngrams .539 .506 .505 .507
3 LIWC .600 .577 .567 .577
4 WordNet .517 .518 .517 .518
5 VerbNet .599 .583 .578 .583
6 Style .573 .601 .553 .601
7 Sentiment .357 .453 .382 .453
8 Vectors .504 .497 .451 .497
9 All .600 .623 .598 .623
Percentage human agreement: .849
</table>
<tableCaption confidence="0.7556805">
Table 5: Weighted precision (P), recall (R), F-score (F) and
accuracy (A) for actions - in each line for a system using only
the given group of features. WordNet stands for WordNet
semantic labels, VerbNet setup uses the WordNet-VerbNet
links. Highlighted F-scores differ from the majority baseline
significantly (p &lt;0.05), using an approx. randomization test.
</tableCaption>
<bodyText confidence="0.999974882352942">
Due to the lack of previous NLP experiments
on this task, we compare our features to the ac-
tions measured in the International Personality
Item Pool (Goldberg et al., 2006), frequently used
personality assesment questionnaire (Table 6).
The most predictive features of this model cap-
ture the activity and excitement seeking facets
of extraversion. Stylistic features reflect the
complexity difference of the verb phrases (John
jumped vs. John thought about it), extraverts be-
ing characterized by plain verbs. Semantic fea-
tures exhibit higher precision than stylistic ones.
Sense-linked semantic classes of VerbNet demon-
strate the preference of extraverts for being ac-
tive and expressing themselves - they jump, fight,
shout, run in and run out, eat and drink, see and
hear and get easily bored. Extraverts in books also
</bodyText>
<page confidence="0.973983">
1811
</page>
<table confidence="0.959431583333333">
Extravert
International Personality Item Pool:
likes to party, feels comfortable around people,
starts conversations, talks to many people, enjoys being
a center of attention, makes friends easily, takes charge,
captivates people, feels at ease with a company,
is skilled in handling social situations
Our experiment:
bring (VN), consume (VN), contiguous location(VN),
holding (VN), social (WN), motion (WN), emotion (WN)
Leisure (LIWC), Home (LIWC), Family (LIWC), fight,
march, care, take, jump, shriek, clear throat, bore, get to,
come in, agree, hold, hear, inform, sell, come forward
Introvert
International Personality Item Pool:
Doesn’t talk much, stays in the background, has little
to say, does not draw attention, has difficulties to
approach others, is quiet around strangers, feels
uncomfortable around others,does not show feelings,
is a private person, waits to be lead
Our experiment:
snooze (VN), conceal (VN), wish (VN), stative (WN),
creation (WN), walk, sleep, lay, know, maintain, expect,
hope, find out, might, help, explain
</table>
<tableCaption confidence="0.987472">
Table 6: Characteristic actions for extraverts and introverts
</tableCaption>
<bodyText confidence="0.9883045">
as assessed in the IPIP personality questionaire, compared to
our most informative features
often bring or hold something. Introverts, on the
other hand, seem to favor slow movements - while
they are thinking, reflecting, creating, looking for
explanations and find out solutions, they tend to lie
down, sit or walk, eventually even sleep or snooze.
The uncertainty typical for introverts is also no-
table in their actions, as they often hope or wish
for something they might like to do. Addition-
ally, semantic classes Social and Family, reported
as correlated to extraversion by Pennebaker and
King (1999) and not confirmed in our first model,
became predictive in protaonists’ actions.
</bodyText>
<subsectionHeader confidence="0.861444">
5.4 Discussion
</subsectionHeader>
<bodyText confidence="0.999971785714286">
Also in this task, the VerbNet classes brought sig-
nificant improvement in performance. The clas-
sification model based on actions outperforms
not only the direct speech model, but also the
state-of-the-art systems predicting authors’ ex-
traversion from the stream-of-consciousness es-
says (Mairesse et al., 2007; Celli et al., 2013;
Neuman and Cohen, 2014). While surely not
directly comparable, this result hints to the fact
that the personality is easier to detect from be-
havior than from person’s verbal expression. This
would correspond to the findings of Mairesse et
al. (2007), Biel and Gatica-Perez (2013) and Aran
and Gatica-Perez (2013) on multimodal data sets.
</bodyText>
<sectionHeader confidence="0.72518" genericHeader="method">
6 Predicatives of fictional characters
</sectionHeader>
<bodyText confidence="0.999976125">
Our third extraversion prediction system is sub-
ordinate to how fictional characters are described
and to the manners in which they behave. We are
not aware of a previous NLP work predicting ex-
traversion using descriptive adjectives of the per-
sons in question. We thus juxtapose the most pre-
dictive features of our system to the adjectival ex-
traversion markers developed by Goldberg (1992).
</bodyText>
<subsectionHeader confidence="0.999922">
6.1 Extraction of descriptive properties
</subsectionHeader>
<bodyText confidence="0.999559625">
In this setup we extract predicatives of the named
entities PERSON in the books - relations amod
(angry John) and cop (John was smart). As these
explicit statements are very sparse in modern nov-
els, we additionally include adverbial modifiers
(advmod) related to person’s actions (John said
angrily). We extract data for 205 characters, with
on average 43 words per character.
</bodyText>
<figure confidence="0.81206">
(a) Master Yoda (b) Sansa Stark
(Star Wars) (Game of Thrones)
</figure>
<figureCaption confidence="0.996742">
Figure 2: Frequency word clouds for character descriptions
</figureCaption>
<subsectionHeader confidence="0.999584">
6.2 Classification setup
</subsectionHeader>
<bodyText confidence="0.9999818">
This system uses similar set of lexical, semantic
and vectorial features similarly as in 5.2, this time
with the focus on adjectives, nouns and adverbs
instead of verbs. Stylistic and VerbNet features
are hence not included, word vectors are as in 4.2.
</bodyText>
<subsectionHeader confidence="0.995623">
6.3 Classification results on descriptions
</subsectionHeader>
<tableCaption confidence="0.528348333333333">
Table 7 reports on the performance of individual
feature groups. With only few words per character
semantic lexicons are less powerful than ngrams.
</tableCaption>
<table confidence="0.998562333333333">
ID Feature set P R F A
1 - (baseline) .267 .517 .352 .517
2 Ngrams .686 .657 .648 .657
3 LIWC .645 .601 .586 .601
4 WordNet .518 .545 .528 .545
5 Sentiment .375 .463 .384 .463
6 Vectors .267 .517 .352 .517
7 All .692 .698 .693 .698
Percentage human agreement: .849
</table>
<tableCaption confidence="0.994017333333333">
Table 7: Weighted precision, recall, F-score and accuracy.
Highlighted F-scores differ from the majority baseline sig-
nificantly (p &lt;0.05).
</tableCaption>
<page confidence="0.992966">
1812
</page>
<tableCaption confidence="0.8261595">
Table 8 displays the most predictive features in
our system contrasted to the adjectival markers.
</tableCaption>
<table confidence="0.997829428571429">
Extravert
Goldberg (1992) :
adventurous,mischievous, playful, rambunctious,
dominant, forceful, demonstrative, exhibitionistic,
flamboyant, brave, courageous, daring, assured,...
Our experiment :
excited, restlessly, stubbornly, restless, beloved, eager,
abruptly, defiantly, darkly, eagerly, loudly, reluctant,
stubborn, unwise, ruthless, quickly, abruptly, right,
change (WN), social (WN)
Introvert
Goldberg (1992) :
bashful, shy, timid, inhibited, restrained
unadventurous, unaggressive, uncompetitive
bitter, joyless, melancholic, moody, morose,...
Our experiment :
anxious, patiently, hesitantly, backward, softly,
warily, coldly, helplessly, respectfully, slowly,
politely, thoughtfully, nervously, silent, carefully,
gratefully, dryly, sheepishly, politely, weary, calm,
gently, sadly, sideways, stative (WN)
</table>
<tableCaption confidence="0.983596">
Table 8: Characteristic adjectives for extraverts and intro-
verts as reported by L. Goldberg, compared to our most in-
formative features as per the correlation merit
</tableCaption>
<subsectionHeader confidence="0.993971">
6.4 Discussion on errors
</subsectionHeader>
<bodyText confidence="0.9999953">
All our systems had issues with characters rated by
less than five readers and with protagonists with
low agreement. Other challenges arise from au-
thorial style, age of the novel and speech individ-
uality of characters (e.g. Yoda). Varied length of
information for different characters poses issues in
measuring normally distributed features (e.g. ra-
tio of jumping verbs), being in shorter texts less
reliable. Ongoing and future work on this task ad-
dresses the limitations of these initial experiments,
especially the data set size and the gold standard
quality. Extending the data will also enable us to
examine different book genres as variables for the
personality distribution and feature impact. It will
be worth examining the relations between charac-
ters, since we observed certain patterns in our data,
such as the main introvert character supported by
his best friend extravert. Additionally, we want
to verify if the system in Section 6 is overly opti-
mistic due to the data size.
</bodyText>
<sectionHeader confidence="0.903469" genericHeader="conclusions">
7 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.9999795">
Automated personality profiling of fictional char-
acters, based on rigorous models from personal-
ity psychology, has a potential to impact numer-
ous domains. We framed it as a text classifica-
tion problem and presented a novel collaboratively
built dataset of fictional personality. We incor-
porate features of both lexical resource-based and
vectorial semantics, including WordNet and Verb-
Net sense-level information and vectorial word
representations. In models based on the speech
and actions of the protagonists, we demonstrated
that the sense-linked lexical-semantic features sig-
nificantly outperform the baselines. The most pre-
dictive features correspond to the reported find-
ings in personality psychology and NLP experi-
ments on human personality. Our systems based
on actions and appearance of characters demon-
strate higher performance than systems based on
direct speech, which is in accordance with recent
research on personality in social networks (Kosin-
ski et al., 2014; Biel and Gatica-Perez, 2013), re-
vealing the importance of the metadata. We have
shown that exploiting the links between lexical re-
sources to leverage more accurate semantic infor-
mation can be beneficial for this type of tasks, ori-
ented to actions performed by the entity. How-
ever, the human annotator agreement in our task
stays high above the performance achieved. Con-
sidering that most of the sucessful novels were
produced as movies, we cannot exclude that our
annotators based their decision on the multimodal
representation of the protagonists. In the future we
aim on collecting a more detail and rigorous gold
standard through gamification and expanding our
work on all five personality traits from the Five-
Factor Model and their facets, and ultimately ex-
tend our system to a semi-supervised model deal-
ing with notably larger amount of data. We also
plan to examine closer the differences between
perceived human and fictional personality, and the
relationship between the personality of the reader
and the characters.
</bodyText>
<sectionHeader confidence="0.9844" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999845615384615">
This work has been supported by the Volkswa-
gen Foundation as part of the Lichtenberg Pro-
fessorship Program under grant No. I/82806 and
by the German Research Foundation under grant
No. GU 798/14-1. Additional support was pro-
vided by the German Federal Ministry of Educa-
tion and Research (BMBF) as a part of the Soft-
ware Campus program under the promotional ref-
erence 01-S12054 and by the German Institute
for Educational Research (DIPF). We also warmly
thank Holtzbrinck Digital GmbH for providing a
substantial part of the e-book resources, and the
EMNLP reviewers for their helpful comments.
</bodyText>
<page confidence="0.984735">
1813
</page>
<sectionHeader confidence="0.98423" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996768867924529">
Oya Aran and Daniel Gatica-Perez. 2013. Cross-
domain personality prediction: from video blogs to
small group meetings. In Proceedings of the 15th
ACM on International conference on multimodal in-
teraction.
Shlomo Argamon, Sushant Dhawle, Moshe Koppel,
and James W. Pennebaker. 2005. Lexical predictors
of personality type. In Proceedings of the Joint An-
nual Meeting of the Interface and the Classification
Society of North America.
David Bamman, Ted Underwood, and Noah A. Smith.
2014. A bayesian mixed effects model of literary
character. In Proceedings of the 52nd Annual Meet-
ing of the Association for Computational Linguis-
tics.
Joan-Isaac Biel and Daniel Gatica-Perez. 2013. The
youtube lens: Crowdsourced personality impres-
sions and audiovisual analysis of vlogs. Multimedia,
IEEE Transactions on, 15(1):41–55.
Donn Byrne. 1961. Interpersonal attraction and atti-
tude similarity. The Journal ofAbnormal and Social
Psychology, 62(3):713.
Fabio Celli, Fabio Pianesi, David Stillwell, and Michal
Kosinski. 2013. Workshop on computational per-
sonality recognition (shared task). In Proceedings of
the Workshop on Computational Personality Recog-
nition.
Fabio Celli, Bruno Lepri, Joan-Isaac Biel, Daniel
Gatica-Perez, Giuseppe Riccardi, and Fabio Pianesi.
2014. The workshop on computational personality
recognition 2014. In Proceedings of the ACM Inter-
national Conference on Multimedia. ACM.
Nathanael Chambers. 2013. Event schema induction
with a probabilistic entity-driven model. In EMNLP,
volume 13, pages 1797–1807.
Tanya L. Chartrand and John A. Bargh. 1999. The
chameleon effect: the perception–behavior link and
social interaction. Journal of personality and social
psychology, 76(6):893.
Max Coltheart. 1981. The mrc psycholinguistic
database. The Quarterly Journal of Experimental
Psychology, 33(4):497–505.
Malcolm Corney, Olivier de Vel, Alison Anderson, and
George Mohay. 2002. Gender-preferential text min-
ing of e-mail discourse. In Proceedings of 18th
Annual Computer Security Applications Conference.
IEEE.
Paul T. Costa and Robert R. McCrae. 1992. Profes-
sional manual: revised NEO personality inventory
(NEO-PI-R) and NEO five-factor inventory (NEO-
FFI). Odessa, FL: Psychological Assessment Re-
sources.
Johannes Daxenberger, Oliver Ferschke, Iryna
Gurevych, and Torsten Zesch. 2014. Dkpro tc:
A java-based framework for supervised learning
experiments on textual data. In Proceedings of
the 52nd Annual Meeting of the Association for
Computational Linguistics. System Demonstrations,
pages 61–66.
Orph´ee De Clercq, Michael Schuhmacher, Si-
mone Paolo Ponzetto, and Veronique Hoste. 2014.
Exploiting framenet for content-based book recom-
mendation. In CBRecSys at ACM RecSys, number
1613-0073, pages 14–21. CEUR-WS.
Jean-Marc Dewaele and Adrian Furnham. 1999. Ex-
traversion: The unloved variable in applied linguis-
tic research. Language Learning, 49(3):509–544.
Tommaso Di Noia, Roberto Mirizzi, Vito Claudio Os-
tuni, Davide Romito, and Markus Zanker. 2012.
Linked open data to support content-based recom-
mender systems. In Proceedings of the 8th In-
ternational Conference on Semantic Systems, I-
SEMANTICS, pages 1–8.
Daniel Dotson. 2009. Portrayal of physicists in fic-
tional works. CLCWeb: Comparative Literature and
Culture, 11(2):5.
David K. Elson, Nicholas Dames, and Kathleen R.
McKeown. 2010. Extracting social networks from
literary fiction. In Proceedings of the 48th Annual
Meeting of the Association for Computational Lin-
guistics.
Dominique Estival, Tanja Gaustad, Son Bao Pham,
Will Radford, and Ben Hutchinson. 2007. Author
profiling for english emails. In Proceedings of the
10th Conference of the Pacific Association for Com-
putational Linguistics.
Andrea Esuli and Fabrizio Sebastiani. 2006. Senti-
WordNet: a publicly available lexical resource for
opinion mining. In Proceedings of LREC, volume 6.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local informa-
tion into information extraction systems by gibbs
sampling. In Proceedings of the 43rd Annual Meet-
ing on Association for Computational Linguistics,
pages 363–370. Association for Computational Lin-
guistics.
Alastair J. Gill and Jon Oberlander. 2002. Taking care
of the linguistic features of extraversion. In Pro-
ceedings of the 24th Annual Conference of the Cog-
nitive Science Society.
Lewis R. Goldberg, John A. Johnson, Herbert W.
Eber, Robert Hogan, Michael C. Ashton, C. Robert
Cloninger, and Harrison G. Gough. 2006. The in-
ternational personality item pool and the future of
public-domain personality measures. Journal of Re-
search in personality, 40(1):84–96.
</reference>
<page confidence="0.997453">
1814
</page>
<bodyText confidence="0.958423166666667">
Karin Kipper-Schuler. 2005. VerbNet: A broad-
coverage, comprehensive verb lexicon. Ph.D. thesis,
University of Pennsylvania.
Lewis R Goldberg. 1990. An alternative description of
personality: the Big-Five factor structure. Journal
ofpersonality and social psychology, 59(6):1216.
</bodyText>
<reference confidence="0.987325980582524">
Lewis R Goldberg. 1992. The development of mark-
ers for the Big-Five factor structure. Psychological
assessment, 4(1):26.
Iryna Gurevych, Max M¨uhlh¨auser, Christof M¨uller,
J¨urgen Steimle, Markus Weimer, and Torsten Zesch.
2007. Darmstadt Knowledge Processing Repository
Based on UIMA. In Proceedings of the First Work-
shop on Unstructured Information Management Ar-
chitecture at Biannual Conference of the Society for
Computational Linguistics and Language Technol-
ogy, T¨ubingen, Germany.
Iryna Gurevych, Judith Eckle-Kohler, Silvana Hart-
mann, Michael Matuschek, Christian M. Meyer, and
Christian Wirth. 2012. Uby: A large-scale unified
lexical-semantic resource based on LMF. In Pro-
ceedings of the 13th Conference of the European
Chapter of the Association for Computational Lin-
guistics. Association for Computational Linguistics.
Mark A. Hall. 1999. Correlation-based feature selec-
tion for machine learning. Ph.D. thesis, The Univer-
sity of Waikato.
Hua He, Denilson Barbosa, and Grzegorz Kondrak.
2013. Identification of speakers in novels. In Pro-
ceedings of the 51st Annual Meeting on Association
for Computational Linguistics, pages 1312–1320.
Benjamin Heitmann and Conor Hayes. 2010. Us-
ing linked data to build open, collaborative recom-
mender systems. In AAAI symposium Linked data
meets artificial intelligence.
Francis Heylighen and Jean-Marc Dewaele. 2002.
Variation in the Contextuality of Language: An Em-
pirical Measure. Foundations of Science, 7(3):293–
340.
Elias Iosif and Taniya Mishra. 2014. From speaker
identification to affective analysis: A multi-step sys-
tem for analyzing children stories. EACL 2014,
pages 40–49.
Oliver P. John and Sanjay Srivastava. 1999. The
Big Five trait taxonomy: History, measurement, and
theoretical perspectives. Handbook of personality:
Theory and research, 2(1999):102–138.
John A. Johnson, Joseph Carroll, Jonathan Gottschall,
and Daniel Kruger. 2011. Portrayal of personal-
ity in victorian novels reflects modern research find-
ings but amplifies the significance of agreeableness.
Journal of Research in Personality, 45(1):50–58.
Geoff F. Kaufman and Lisa K. Libby. 2012.
Changing beliefs and behavior through experience-
taking. Journal of personality and social psychol-
ogy, 103(1):1.
Dimitrios Kokkinakis and Mats Malm. 2011. Charac-
ter profiling in 19th century fiction. Language Tech-
nologies for Digital Humanities and Cultural Her-
itage.
Michal Kosinski, David Stillwell, and Thore Grae-
pel. 2013. Private traits and attributes are pre-
dictable from digital records of human behavior.
Proceedings of the National Academy of Sciences,
110(15):5802–5805.
Michal Kosinski, Yoram Bachrach, Pushmeet Kohli,
David Stillwell, and Thore Graepel. 2014. Manifes-
tations of user personality in website choice and be-
haviour on online social networks. Machine learn-
ing, 95(3):357–380.
Bruno Lepri, Ramanathan Subramanian, Kyriaki
Kalimeri, Jacopo Staiano, Fabio Pianesi, and Nicu
Sebe. 2010. Employing social gaze and speak-
ing activity for automatic determination of the ex-
traversion trait. In International Conference on Mul-
timodal Interfaces and the Workshop on Machine
Learning for Multimodal Interaction, ICMI-MLMI
’10, New York, NY, USA. ACM.
Douglas A. MacDonald, Peter E. Anderson, Cather-
ine I. Tsagarakis, and Cornelius J. Holland. 1994.
Examination of the relationship between the Myers-
Briggs Type Indicator and the NEO personality in-
ventory. Psychological Reports, 74(1):339–344.
Franc¸ois Mairesse, Marilyn A. Walker, Matthias R.
Mehl, and Roger K. Moore. 2007. Using linguis-
tic cues for the automatic recognition of personality
in conversation and text. Journal of artificial intelli-
gence research.
Raymond A. Mar, Keith Oatley, and Jordan B. Peter-
son. 2009. Exploring the link between reading fic-
tion and empathy: Ruling out individual differences
and examining outcomes. Communications Journal,
34(4):407–428.
Robert R. McCrae and Paul T. Costa. 1987. Validation
of the five-factor model of personality across instru-
ments and observers. Journal ofpersonality and so-
cial psychology, 52(1):81.
Robert R. McCrae and Paul T. Costa. 1989. Rein-
terpreting the myers-briggs type indicator from the
perspective of the five-factor model of personality.
Journal ofpersonality, 57(1):17–40.
Robert R. McCrae, James F. Gaines, and Marie A.
Wellington. The five-factor model in fact and fic-
tion. Handbook of Psychology.
Matthias R. Mehl, Samuel D. Gosling, and James W.
Pennebaker. 2006. Personality in its natural habitat:
manifestations and implicit folk theories of person-
ality in daily life. Journal of personality and social
psychology, 90(5):862.
</reference>
<page confidence="0.921979">
1815
</page>
<bodyText confidence="0.708712">
George A. Miller. 1995. WordNet: a lexical
database for English. Communications of the ACM,
38(11):39–41.
</bodyText>
<note confidence="0.777027">
James W. Pennebaker, Martha E. Francis, and Roger J.
Booth. 2001. Linguistic inquiry and word count:
LIWC 2001. Mahway: Lawrence Erlbaum Asso-
ciates, 71.
</note>
<reference confidence="0.998066893333333">
Saif M. Mohammad and Svetlana Kiritchenko. 2013.
Using nuances of emotion to identify personality.
AAAI Technical Report WS-13-01 Computational
Personality Recognition (Shared Task).
Saif M. Mohammad and Peter D. Turney. 2010. Emo-
tions evoked by common words and phrases: Using
Mechanical Turk to create an emotion lexicon. In
Proceedings of the NAACL HLT 2010 Workshop on
Computational Approaches to Analysis and Genera-
tion of Emotion in Text, pages 26–34.
R. Matthew Montoya, Robert S. Horton, and Jeffrey
Kirchner. 2008. Is actual similarity necessary for
attraction? a meta-analysis of actual and perceived
similarity. Journal of Social and Personal Relation-
ships, 25(6):889–922.
Isabel Briggs Myers, Mary H. McCaulley, and Robert
Most. 1985. Manual, a guide to the development
and use of the Myers-Briggs type indicator. Con-
sulting Psychologists Press.
Yair Neuman and Yochai Cohen. 2014. A vectorial
semantics approach to personality assessment. Sci-
entific reports, 4.
Scott Nowson, Jon Oberlander, and Alastair J. Gill.
2005. Weblogs, genres and individual differences.
In Proceedings of the 27th Annual Conference of the
Cognitive Science Society, volume 1666, page 1671.
Citeseer.
Scott Nowson. 2007. Identifying more bloggers: To-
wards large scale personality classification of per-
sonal weblogs. In In Proceedings of the Interna-
tional Conference on Weblogs and Social.
Jon Oberlander and Scott Nowson. 2006. Whose
thumb is it anyway? classifying author personal-
ity from weblog text. In Proceedings of the COL-
ING/ACL on Main conference poster sessions.
Tim O’Keefe, Silvia Pareti, James R. Curran, Irena
Koprinska, and Matthew Honnibal. 2012. A se-
quence labelling approach to quote attribution. In
Proceedings of the 2012 Joint Conference on Empir-
ical Methods in Natural Language Processing and
Computational Natural Language Learning, pages
790–799. Association for Computational Linguis-
tics.
Alexandre Passant. 2010. dbrec music recommenda-
tions using DBpedia. In The Semantic Web–ISWC
2010, pages 209–224.
James W. Pennebaker and Laura A. King. 1999. Lin-
guistic styles: language use as an individual differ-
ence. Journal of personality and social psychology,
77(6):1296.
Jeffrey Pennington, Richard Socher, and Christopher D
Manning. 2014. Glove: Global vectors for
word representation. Proceedings of the Empiricial
Methods in Natural Language Processing (EMNLP
2014), 12.
David J. Pittenger. 2005. Cautionary comments re-
garding the myers-briggs type indicator. Consult-
ing Psychology Journal: Practice and Research,
57(3):210.
Peter J. Rentfrow, Lewis R. Goldberg, and Daniel J.
Levitin. 2011. The structure of musical preferences:
a five-factor model. Journal of personality and so-
cial psychology, 100(6):1139.
Noah A. Smith, David Bamman, and Brendan OCon-
nor. 2013. Learning latent personas of film charac-
ters. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics.
Antonio Terracciano, Corinna E. L¨ockenhoff, Rosa M.
Crum, O .Joseph Bienvenu, and Paul T. Costa. 2008.
Five-factor model personality profiles of drug users.
BMC Psychiatry, 8(1):22.
William C. Tirre and Sharvari Dixit. 1995. Reading
interests: Their dimensionality and correlation with
personality and cognitive factors. Personality and
Individual Differences, 18(6):731–738.
</reference>
<page confidence="0.993075">
1816
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.719217">
<title confidence="0.994597">Personality Profiling of Fictional Characters using Sense-Level between Lexical Resources</title>
<author confidence="0.94767">Iryna Knowledge Processing Lab</author>
<affiliation confidence="0.997512">Department of Computer Science, Technische Universit¨at Knowledge Processing Lab German Institute for Educational</affiliation>
<email confidence="0.943741">www.ukp.tu-darmstadt.de</email>
<author confidence="0.934474333333333">Then always be Batman ”</author>
<abstract confidence="0.995630111111111">This study focuses on personality prediction of protagonists in novels based on the Five-Factor Model of personality. We present and publish a novel collaboratively built dataset of fictional character personality and design our task as a text classification problem. We incorporate a range of semantic features, including WordNet and VerbNet sense-level information and word vector representations. We evaluate three machine learning models based on the speech, actions and predicatives of the main characters, and show that especially the lexical-semantic features significantly outperform the baselines. The most predictive features correspond to reported findings in personality psychology.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Oya Aran</author>
<author>Daniel Gatica-Perez</author>
</authors>
<title>Crossdomain personality prediction: from video blogs to small group meetings.</title>
<date>2013</date>
<booktitle>In Proceedings of the 15th ACM on International conference on multimodal interaction.</booktitle>
<contexts>
<context position="7603" citStr="Aran and Gatica-Perez, 2013" startWordPosition="1133" endWordPosition="1136"> () point out, a standard set of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison. Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC </context>
<context position="34339" citStr="Aran and Gatica-Perez (2013)" startWordPosition="5410" endWordPosition="5413">ask, the VerbNet classes brought significant improvement in performance. The classification model based on actions outperforms not only the direct speech model, but also the state-of-the-art systems predicting authors’ extraversion from the stream-of-consciousness essays (Mairesse et al., 2007; Celli et al., 2013; Neuman and Cohen, 2014). While surely not directly comparable, this result hints to the fact that the personality is easier to detect from behavior than from person’s verbal expression. This would correspond to the findings of Mairesse et al. (2007), Biel and Gatica-Perez (2013) and Aran and Gatica-Perez (2013) on multimodal data sets. 6 Predicatives of fictional characters Our third extraversion prediction system is subordinate to how fictional characters are described and to the manners in which they behave. We are not aware of a previous NLP work predicting extraversion using descriptive adjectives of the persons in question. We thus juxtapose the most predictive features of our system to the adjectival extraversion markers developed by Goldberg (1992). 6.1 Extraction of descriptive properties In this setup we extract predicatives of the named entities PERSON in the books - relations amod (angry </context>
</contexts>
<marker>Aran, Gatica-Perez, 2013</marker>
<rawString>Oya Aran and Daniel Gatica-Perez. 2013. Crossdomain personality prediction: from video blogs to small group meetings. In Proceedings of the 15th ACM on International conference on multimodal interaction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shlomo Argamon</author>
<author>Sushant Dhawle</author>
<author>Moshe Koppel</author>
<author>James W Pennebaker</author>
</authors>
<title>Lexical predictors of personality type.</title>
<date>2005</date>
<booktitle>In Proceedings of the Joint Annual Meeting of the Interface and the Classification Society of</booktitle>
<publisher>North America.</publisher>
<contexts>
<context position="7822" citStr="Argamon et al. (2005)" startWordPosition="1169" endWordPosition="1172">on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets</context>
</contexts>
<marker>Argamon, Dhawle, Koppel, Pennebaker, 2005</marker>
<rawString>Shlomo Argamon, Sushant Dhawle, Moshe Koppel, and James W. Pennebaker. 2005. Lexical predictors of personality type. In Proceedings of the Joint Annual Meeting of the Interface and the Classification Society of North America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Bamman</author>
<author>Ted Underwood</author>
<author>Noah A Smith</author>
</authors>
<title>A bayesian mixed effects model of literary character.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5471" citStr="Bamman et al. (2014)" startWordPosition="799" endWordPosition="802">ant, 2010; Di Noia et al., 2012; Heitmann and Hayes, 2010). De Clercq et al. (2014) incorporated semantic frames from FrameNet into the recommendation system for books. They represent the plot of each book with a sequence of ca. 200 semantic frames and has shown that the frame information (such as Killing - Revenge - Death) outperforms the bag-of-words approach.Recent NLP experiments begin to reveal the importance of entitycentric models in a variety of tasks. Chambers (2013) show improvement in event schema induction by learning entity-centric rules (e.g., a victim is likely to be a person). Bamman et al. (2014) and Smith et al. (2013) present latent variable models for unsupervised learning of latent character types in movie plot summaries and in English novels, taking authorial style into account. However, even the state-of-the-art NLP work rather describes personas of fictional characters by their role in the story - e.g., action hero, valley girl, best friend, villain etc. - or by their relations to other characters, such as mother or daughter (Elson et al., 2010; Kokkinakis and Malm, 2011), rather than by their inner preferences and motivations. It is important to note here that determining a pe</context>
</contexts>
<marker>Bamman, Underwood, Smith, 2014</marker>
<rawString>David Bamman, Ted Underwood, and Noah A. Smith. 2014. A bayesian mixed effects model of literary character. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan-Isaac Biel</author>
<author>Daniel Gatica-Perez</author>
</authors>
<title>The youtube lens: Crowdsourced personality impressions and audiovisual analysis of vlogs. Multimedia,</title>
<date>2013</date>
<journal>IEEE Transactions on,</journal>
<volume>15</volume>
<issue>1</issue>
<contexts>
<context position="8691" citStr="Biel and Gatica-Perez, 2013" startWordPosition="1296" endWordPosition="1299">e et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007). More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013). These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014). 1806 3 Data set construction Traditionally, the gold standard for this supervised classification task is obtained by the means of personality questionnaires, used for the Five-Factor Model, taken by each of the individuals assessed. This poses a challenge for fictional characters. However, strong correlations have been found betwe</context>
<context position="34306" citStr="Biel and Gatica-Perez (2013)" startWordPosition="5405" endWordPosition="5408">ns. 5.4 Discussion Also in this task, the VerbNet classes brought significant improvement in performance. The classification model based on actions outperforms not only the direct speech model, but also the state-of-the-art systems predicting authors’ extraversion from the stream-of-consciousness essays (Mairesse et al., 2007; Celli et al., 2013; Neuman and Cohen, 2014). While surely not directly comparable, this result hints to the fact that the personality is easier to detect from behavior than from person’s verbal expression. This would correspond to the findings of Mairesse et al. (2007), Biel and Gatica-Perez (2013) and Aran and Gatica-Perez (2013) on multimodal data sets. 6 Predicatives of fictional characters Our third extraversion prediction system is subordinate to how fictional characters are described and to the manners in which they behave. We are not aware of a previous NLP work predicting extraversion using descriptive adjectives of the persons in question. We thus juxtapose the most predictive features of our system to the adjectival extraversion markers developed by Goldberg (1992). 6.1 Extraction of descriptive properties In this setup we extract predicatives of the named entities PERSON in t</context>
<context position="39337" citStr="Biel and Gatica-Perez, 2013" startWordPosition="6160" endWordPosition="6163">and VerbNet sense-level information and vectorial word representations. In models based on the speech and actions of the protagonists, we demonstrated that the sense-linked lexical-semantic features significantly outperform the baselines. The most predictive features correspond to the reported findings in personality psychology and NLP experiments on human personality. Our systems based on actions and appearance of characters demonstrate higher performance than systems based on direct speech, which is in accordance with recent research on personality in social networks (Kosinski et al., 2014; Biel and Gatica-Perez, 2013), revealing the importance of the metadata. We have shown that exploiting the links between lexical resources to leverage more accurate semantic information can be beneficial for this type of tasks, oriented to actions performed by the entity. However, the human annotator agreement in our task stays high above the performance achieved. Considering that most of the sucessful novels were produced as movies, we cannot exclude that our annotators based their decision on the multimodal representation of the protagonists. In the future we aim on collecting a more detail and rigorous gold standard th</context>
</contexts>
<marker>Biel, Gatica-Perez, 2013</marker>
<rawString>Joan-Isaac Biel and Daniel Gatica-Perez. 2013. The youtube lens: Crowdsourced personality impressions and audiovisual analysis of vlogs. Multimedia, IEEE Transactions on, 15(1):41–55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donn Byrne</author>
</authors>
<title>Interpersonal attraction and attitude similarity.</title>
<date>1961</date>
<journal>The Journal ofAbnormal and Social Psychology,</journal>
<volume>62</volume>
<issue>3</issue>
<contexts>
<context position="2718" citStr="Byrne, 1961" startWordPosition="380" endWordPosition="381">ousness (organized vs. careless) and Openness to experience (insightful vs. unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008; Rentfrow et al., 2011). It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009). Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999). More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is revealed only later in the story. We therefore hypothesize that readers might have a preference for reading novels depicting fictional characters that are similar to themselves. Finding a direct link between reader’s and protagonist’s personality traits would advance the development of content-based recommendation systems. As a first step to explore this</context>
</contexts>
<marker>Byrne, 1961</marker>
<rawString>Donn Byrne. 1961. Interpersonal attraction and attitude similarity. The Journal ofAbnormal and Social Psychology, 62(3):713.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Celli</author>
<author>Fabio Pianesi</author>
<author>David Stillwell</author>
<author>Michal Kosinski</author>
</authors>
<title>Workshop on computational personality recognition (shared task).</title>
<date>2013</date>
<booktitle>In Proceedings of the Workshop on Computational Personality Recognition.</booktitle>
<contexts>
<context position="8936" citStr="Celli et al., 2013" startWordPosition="1332" endWordPosition="1335">aversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007). More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013). These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014). 1806 3 Data set construction Traditionally, the gold standard for this supervised classification task is obtained by the means of personality questionnaires, used for the Five-Factor Model, taken by each of the individuals assessed. This poses a challenge for fictional characters. However, strong correlations have been found between the self-reported and perceived personality traits (Mehl et al., 2006). Our gold standard benefits from the fact that readers enjoy discussing the personality of their favourite book character online. A popular layman instrument for personali</context>
<context position="14053" citStr="Celli et al., 2013" startWordPosition="2179" endWordPosition="2182">acter is an agent, predictive for extraversion? 3. Predicatives and adverbs: Are the explicit (John was an exhibitionist) or implicit (John shouted abruptly) descriptions of the character in the book predictive for extraversion? 1 P= N N i=1 k j=1 1807 In the next three sections we present the experimental settings and results for each of the systems. 4 Direct speech of fictional characters The system for the direct speech resembles the most to the previous systems developed for author personality profiling, e.g. on stream of consciousness essays (Mairesse et al., 2007) or social media posts (Celli et al., 2013) and therefore provides the best opportunity for comparison between human individuals and fictional characters. On top of the comparison to previous research, we exploit the sense links between WordNet and VerbNet to extract additional features - an approach which is novel for this type of task. 4.1 Extraction and assignment of speech We process the book text using freely available components of the DKPro framework (Gurevych et al., 2007). The most challenging task in building the direct speech data set is assigning to the direct speech utterance the correct speaker. We benefit from the epub f</context>
<context position="17597" citStr="Celli et al., 2013" startWordPosition="2775" endWordPosition="2778">n(s) in gap return speaker Our experimental data consists of usable direct speech sets of 175 characters - 80 extraverts (E) and 95 introverts (I) - containing 289 274 words in 21 857 utterances (on average 111 utterances for E and 136 for I, as I are often central in books).4 4.2 Classification approach for direct speech All speech utterances of one book character are represented as one instance in our system. We use the leave-one-out classification setup due to the relatively small dataset size, using the support vector machines (SVM-SMO) classifier, which performs well on comparable tasks (Celli et al., 2013). The classification is performed through the DKPro TC Framework (Daxenberger et al., 2014). Lexical features As a bottom-up approach we use the 1000 most frequent word uni-, bi- and trigrams, 1000 dependency word pairs, 1000 character trigrams and 500 most frequent verbs, adverbs, adjectives and interjections as binary features. Semantic features Since the top-down approach, i.e. not focusing on individual words, has 4The data set size is comparable to ongoing personality profiling challenges - see http://pan.webis.de 1808 been found more suitable for the personality profiling task on smaller</context>
<context position="23838" citStr="Celli et al., 2013" startWordPosition="3733" endWordPosition="3736">es .19-.14 Extravert Feat.group Features Merit ngrams we, hurry, fat, dirty .24-.19 LIWC We, Inclusion, Pronoun, Body .18-.09 WordNet motion, contact, communication, .14-.07 body, perception, change VerbNet get, talk, substance emission .18-.15 Style pronoun We, whadjp, .20-.14 type-token ratio., interjections Table 3: The most predictive features for each group for speaker’s extraversion and introversion. Correlation merit, as per the correlation feature selection in WEKA, evaluates Pearson’s correlation between the feature and the class Similarly to previous research (Mairesse et al., 2007; Celli et al., 2013), the bottom-up word based approach is outperformed by top-down semantic approaches which employ a more abstract feature representation. As in previous work, LIWC features exhibit good performance. However, the highest performance is achieved employing the VerbNet verb classes with WordNet wordsense disambiguation. Also stylistic features contribute substantially to the classification despite the mixture of genres in our book corpus - especially frequencies of modal verbs and part-ofspeech ratios were particularly informative. The most predictive features from each group are listed in Table 3 </context>
<context position="34025" citStr="Celli et al., 2013" startWordPosition="5360" endWordPosition="5363">r actions, as they often hope or wish for something they might like to do. Additionally, semantic classes Social and Family, reported as correlated to extraversion by Pennebaker and King (1999) and not confirmed in our first model, became predictive in protaonists’ actions. 5.4 Discussion Also in this task, the VerbNet classes brought significant improvement in performance. The classification model based on actions outperforms not only the direct speech model, but also the state-of-the-art systems predicting authors’ extraversion from the stream-of-consciousness essays (Mairesse et al., 2007; Celli et al., 2013; Neuman and Cohen, 2014). While surely not directly comparable, this result hints to the fact that the personality is easier to detect from behavior than from person’s verbal expression. This would correspond to the findings of Mairesse et al. (2007), Biel and Gatica-Perez (2013) and Aran and Gatica-Perez (2013) on multimodal data sets. 6 Predicatives of fictional characters Our third extraversion prediction system is subordinate to how fictional characters are described and to the manners in which they behave. We are not aware of a previous NLP work predicting extraversion using descriptive </context>
</contexts>
<marker>Celli, Pianesi, Stillwell, Kosinski, 2013</marker>
<rawString>Fabio Celli, Fabio Pianesi, David Stillwell, and Michal Kosinski. 2013. Workshop on computational personality recognition (shared task). In Proceedings of the Workshop on Computational Personality Recognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Celli</author>
<author>Bruno Lepri</author>
<author>Joan-Isaac Biel</author>
<author>Daniel Gatica-Perez</author>
<author>Giuseppe Riccardi</author>
<author>Fabio Pianesi</author>
</authors>
<title>The workshop on computational personality recognition</title>
<date>2014</date>
<booktitle>In Proceedings of the ACM International Conference on Multimedia.</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="8957" citStr="Celli et al., 2014" startWordPosition="1336" endWordPosition="1339"> by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007). More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013). These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014). 1806 3 Data set construction Traditionally, the gold standard for this supervised classification task is obtained by the means of personality questionnaires, used for the Five-Factor Model, taken by each of the individuals assessed. This poses a challenge for fictional characters. However, strong correlations have been found between the self-reported and perceived personality traits (Mehl et al., 2006). Our gold standard benefits from the fact that readers enjoy discussing the personality of their favourite book character online. A popular layman instrument for personality classification is </context>
</contexts>
<marker>Celli, Lepri, Biel, Gatica-Perez, Riccardi, Pianesi, 2014</marker>
<rawString>Fabio Celli, Bruno Lepri, Joan-Isaac Biel, Daniel Gatica-Perez, Giuseppe Riccardi, and Fabio Pianesi. 2014. The workshop on computational personality recognition 2014. In Proceedings of the ACM International Conference on Multimedia. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
</authors>
<title>Event schema induction with a probabilistic entity-driven model.</title>
<date>2013</date>
<booktitle>In EMNLP,</booktitle>
<volume>13</volume>
<pages>1797--1807</pages>
<contexts>
<context position="5331" citStr="Chambers (2013)" startWordPosition="777" endWordPosition="778">endation systems have shown that incorporating semantic information is valuable for the user and leads to measurable improvements (Passant, 2010; Di Noia et al., 2012; Heitmann and Hayes, 2010). De Clercq et al. (2014) incorporated semantic frames from FrameNet into the recommendation system for books. They represent the plot of each book with a sequence of ca. 200 semantic frames and has shown that the frame information (such as Killing - Revenge - Death) outperforms the bag-of-words approach.Recent NLP experiments begin to reveal the importance of entitycentric models in a variety of tasks. Chambers (2013) show improvement in event schema induction by learning entity-centric rules (e.g., a victim is likely to be a person). Bamman et al. (2014) and Smith et al. (2013) present latent variable models for unsupervised learning of latent character types in movie plot summaries and in English novels, taking authorial style into account. However, even the state-of-the-art NLP work rather describes personas of fictional characters by their role in the story - e.g., action hero, valley girl, best friend, villain etc. - or by their relations to other characters, such as mother or daughter (Elson et al., </context>
</contexts>
<marker>Chambers, 2013</marker>
<rawString>Nathanael Chambers. 2013. Event schema induction with a probabilistic entity-driven model. In EMNLP, volume 13, pages 1797–1807.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tanya L Chartrand</author>
<author>John A Bargh</author>
</authors>
<title>The chameleon effect: the perception–behavior link and social interaction. Journal of personality and social psychology,</title>
<date>1999</date>
<pages>76--6</pages>
<contexts>
<context position="2746" citStr="Chartrand and Bargh, 1999" startWordPosition="382" endWordPosition="385">nized vs. careless) and Openness to experience (insightful vs. unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008; Rentfrow et al., 2011). It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009). Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999). More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is revealed only later in the story. We therefore hypothesize that readers might have a preference for reading novels depicting fictional characters that are similar to themselves. Finding a direct link between reader’s and protagonist’s personality traits would advance the development of content-based recommendation systems. As a first step to explore this hypothesis further, it need</context>
</contexts>
<marker>Chartrand, Bargh, 1999</marker>
<rawString>Tanya L. Chartrand and John A. Bargh. 1999. The chameleon effect: the perception–behavior link and social interaction. Journal of personality and social psychology, 76(6):893.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max Coltheart</author>
</authors>
<title>The mrc psycholinguistic database.</title>
<date>1981</date>
<journal>The Quarterly Journal of Experimental Psychology,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="8246" citStr="Coltheart, 1981" startWordPosition="1230" endWordPosition="1231">LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007). More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013). These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the </context>
</contexts>
<marker>Coltheart, 1981</marker>
<rawString>Max Coltheart. 1981. The mrc psycholinguistic database. The Quarterly Journal of Experimental Psychology, 33(4):497–505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malcolm Corney</author>
<author>Olivier de Vel</author>
<author>Alison Anderson</author>
<author>George Mohay</author>
</authors>
<title>Gender-preferential text mining of e-mail discourse.</title>
<date>2002</date>
<booktitle>In Proceedings of 18th Annual Computer Security Applications Conference.</booktitle>
<publisher>IEEE.</publisher>
<marker>Corney, de Vel, Anderson, Mohay, 2002</marker>
<rawString>Malcolm Corney, Olivier de Vel, Alison Anderson, and George Mohay. 2002. Gender-preferential text mining of e-mail discourse. In Proceedings of 18th Annual Computer Security Applications Conference. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul T Costa</author>
<author>Robert R McCrae</author>
</authors>
<title>Professional manual: revised NEO personality inventory (NEO-PI-R) and NEO five-factor inventory (NEOFFI). Odessa, FL: Psychological Assessment Resources.</title>
<date>1992</date>
<contexts>
<context position="11372" citStr="Costa and McCrae, 1992" startWordPosition="1704" endWordPosition="1707"> may influence their decision. While we address both of these issues in our ongoing data collection project based on the Five-Factor Model, we consider them acceptable for this study due to the exploratory character of our pilot research. We have collected extraversion ratings for 298 book characters, of which 129 (43%) are rather extraverted and 166 (56%) rather introverted. Rated 2http://www.mbti-databank.com/ 3MBTI defines extraversion as “getting energy from active involvement in events, having a lot of different activities, enjoying being around people.” In the NEO Five-Factor Inventory (Costa and McCrae, 1992), underlying facets of extraversion are warmth, gregariousness, assertiveness, activity, excitement seeking and positive emotion. characters come from a wide range of novels that the online users are familiar with, often covering classical literature which is part of the high school syllabus, as well as the most popular modern fiction, such as the Harry Potter series, Twilight, Star Wars or A Game of Thrones. A sample of the most rated introverts and extraverts is given in table 1. The rating distribution in our data is strongly Ushaped. The percentage agreement of voters in our data is 84.9%,</context>
<context position="28440" citStr="Costa and McCrae, 1992" startWordPosition="4445" endWordPosition="4448">thor style (F. Dostoyevsky vs J. K. Rowling). Our basic vector-based features carried no useful information in our case, in contrast to the personality research of Neuman and Cohen (2014). We observed that the factual content of the stories contributed to the character similarity measure more than the subtle personality differences. 5 Actions of fictional characters While psycholinguists and consequenlty NLP researchers analyzed the relation between speech, resp. writing, and personality of an individual, psychologists often evaluate extraversion through behavioral personality questionnaries (Costa and McCrae, 1992; Goldberg et al., 2006). We hypothesize that similar behavior shall be predictive for extraversion of fictional characters as perceived by the readers. 5.1 Action extraction For our purpose we define actions as the subject, verb and context of a sentence, where the subject is a named entity Person and the context is either a direct object in relation dobj to the verb or a first child of the adjacent verb phrase in a parse tree. After grouping the actions per character, the subject name is removed. For example, a sample of actions of the character Eddard Stark of Game of Thrones would be: X pa</context>
</contexts>
<marker>Costa, McCrae, 1992</marker>
<rawString>Paul T. Costa and Robert R. McCrae. 1992. Professional manual: revised NEO personality inventory (NEO-PI-R) and NEO five-factor inventory (NEOFFI). Odessa, FL: Psychological Assessment Resources.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Daxenberger</author>
<author>Oliver Ferschke</author>
<author>Iryna Gurevych</author>
<author>Torsten Zesch</author>
</authors>
<title>Dkpro tc: A java-based framework for supervised learning experiments on textual data.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. System Demonstrations,</booktitle>
<pages>61--66</pages>
<contexts>
<context position="17688" citStr="Daxenberger et al., 2014" startWordPosition="2788" endWordPosition="2791">s of 175 characters - 80 extraverts (E) and 95 introverts (I) - containing 289 274 words in 21 857 utterances (on average 111 utterances for E and 136 for I, as I are often central in books).4 4.2 Classification approach for direct speech All speech utterances of one book character are represented as one instance in our system. We use the leave-one-out classification setup due to the relatively small dataset size, using the support vector machines (SVM-SMO) classifier, which performs well on comparable tasks (Celli et al., 2013). The classification is performed through the DKPro TC Framework (Daxenberger et al., 2014). Lexical features As a bottom-up approach we use the 1000 most frequent word uni-, bi- and trigrams, 1000 dependency word pairs, 1000 character trigrams and 500 most frequent verbs, adverbs, adjectives and interjections as binary features. Semantic features Since the top-down approach, i.e. not focusing on individual words, has 4The data set size is comparable to ongoing personality profiling challenges - see http://pan.webis.de 1808 been found more suitable for the personality profiling task on smaller data sets (Celli et al., 2013), we aim on capturing additional phenomena on a higher level</context>
</contexts>
<marker>Daxenberger, Ferschke, Gurevych, Zesch, 2014</marker>
<rawString>Johannes Daxenberger, Oliver Ferschke, Iryna Gurevych, and Torsten Zesch. 2014. Dkpro tc: A java-based framework for supervised learning experiments on textual data. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics. System Demonstrations, pages 61–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Orph´ee De Clercq</author>
<author>Michael Schuhmacher</author>
<author>Simone Paolo Ponzetto</author>
<author>Veronique Hoste</author>
</authors>
<title>Exploiting framenet for content-based book recommendation.</title>
<date>2014</date>
<journal>In CBRecSys at ACM RecSys, number</journal>
<pages>1613--0073</pages>
<publisher>CEUR-WS.</publisher>
<marker>De Clercq, Schuhmacher, Ponzetto, Hoste, 2014</marker>
<rawString>Orph´ee De Clercq, Michael Schuhmacher, Simone Paolo Ponzetto, and Veronique Hoste. 2014. Exploiting framenet for content-based book recommendation. In CBRecSys at ACM RecSys, number 1613-0073, pages 14–21. CEUR-WS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Marc Dewaele</author>
<author>Adrian Furnham</author>
</authors>
<title>Extraversion: The unloved variable in applied linguistic research.</title>
<date>1999</date>
<journal>Language Learning,</journal>
<volume>49</volume>
<issue>3</issue>
<contexts>
<context position="7528" citStr="Dewaele and Furnham, 1999" startWordPosition="1121" endWordPosition="1124">eriment focus (e.g. emotions, relationships, ambitions). As McCrae et al. () point out, a standard set of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison. Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% </context>
<context position="25018" citStr="Dewaele and Furnham (1999)" startWordPosition="3922" endWordPosition="3925">eatures from each group are listed in Table 3 together with their correlation merit (Hall, 1999), and compared with previous work in Table 4. Feature I/E Ref Feature I/E Ref Predictive also in our data: No effect in our data: Pronoun ’we’ -/+ [3] Neg. emot. +/- [1] Tentative, unsure +/- [1] Pos. emot. -/+ [1] Exclusive +/- [1] Self-ref. -/+ [1] Inclusive -/+ [1] Formality +/- [2] Insight +/- [1] Elaborated +/- [3] Nouns, articles +/- Long sent. +/- Lexical richness +/- Social -/+ Negations +/- [2] Body functions -/+ [2] Interjections -/+ [3] Source ID Author [1] Pennebaker and King (1999) [2] Dewaele and Furnham (1999) [3] Mairesse et al. (2007) Table 4: Comparison of our results to previously reported predictive features for speaker’s extraversion (E), resp. introversion (I). We list publications where these features were, to our knowledge, reported as novel. In accordance with the experiments of Pennebaker and King (1999), we observe more frequent exclusions (e.g. without, but), hedging and negation expressed by introverts, and inclusion (e.g. with, and) by extraverts. Extraverts talk more in first person plural, use more back-channels and interjections, and talk more about aspects related to their body. </context>
</contexts>
<marker>Dewaele, Furnham, 1999</marker>
<rawString>Jean-Marc Dewaele and Adrian Furnham. 1999. Extraversion: The unloved variable in applied linguistic research. Language Learning, 49(3):509–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tommaso Di Noia</author>
<author>Roberto Mirizzi</author>
<author>Vito Claudio Ostuni</author>
<author>Davide Romito</author>
<author>Markus Zanker</author>
</authors>
<title>Linked open data to support content-based recommender systems.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Semantic Systems, ISEMANTICS,</booktitle>
<pages>1--8</pages>
<marker>Di Noia, Mirizzi, Ostuni, Romito, Zanker, 2012</marker>
<rawString>Tommaso Di Noia, Roberto Mirizzi, Vito Claudio Ostuni, Davide Romito, and Markus Zanker. 2012. Linked open data to support content-based recommender systems. In Proceedings of the 8th International Conference on Semantic Systems, ISEMANTICS, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Dotson</author>
</authors>
<title>Portrayal of physicists in fictional works. CLCWeb: Comparative Literature and Culture,</title>
<date>2009</date>
<contexts>
<context position="6851" citStr="Dotson, 2009" startWordPosition="1019" endWordPosition="1020">equires a certain detached objectivity - even outright villains may have traits considered desirable in real life. For example, the devil has in many tales a very high aspiration level, appearing highly conscientious and agreeable. We hypothesize that these deeper personality aspects are those which drive reader’s affiliation to the character, thus deserve to be examined closer. Also literary scholars formulate ad hoc personality descriptions for their experiments, for example to test hypotheses from evolutionary psychology (Johnson et al., 2011) or examine fictional portrayals of physicists (Dotson, 2009). These descriptions are usually adjusted to the experiment focus (e.g. emotions, relationships, ambitions). As McCrae et al. () point out, a standard set of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison. Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion recei</context>
</contexts>
<marker>Dotson, 2009</marker>
<rawString>Daniel Dotson. 2009. Portrayal of physicists in fictional works. CLCWeb: Comparative Literature and Culture, 11(2):5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David K Elson</author>
<author>Nicholas Dames</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extracting social networks from literary fiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5935" citStr="Elson et al., 2010" startWordPosition="875" endWordPosition="878">hambers (2013) show improvement in event schema induction by learning entity-centric rules (e.g., a victim is likely to be a person). Bamman et al. (2014) and Smith et al. (2013) present latent variable models for unsupervised learning of latent character types in movie plot summaries and in English novels, taking authorial style into account. However, even the state-of-the-art NLP work rather describes personas of fictional characters by their role in the story - e.g., action hero, valley girl, best friend, villain etc. - or by their relations to other characters, such as mother or daughter (Elson et al., 2010; Kokkinakis and Malm, 2011), rather than by their inner preferences and motivations. It is important to note here that determining a personality of a character is a very different task from determining its role in the story. Psychological understanding of personality, in contrast to role attribution requires a certain detached objectivity - even outright villains may have traits considered desirable in real life. For example, the devil has in many tales a very high aspiration level, appearing highly conscientious and agreeable. We hypothesize that these deeper personality aspects are those wh</context>
</contexts>
<marker>Elson, Dames, McKeown, 2010</marker>
<rawString>David K. Elson, Nicholas Dames, and Kathleen R. McKeown. 2010. Extracting social networks from literary fiction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominique Estival</author>
<author>Tanja Gaustad</author>
<author>Son Bao Pham</author>
<author>Will Radford</author>
<author>Ben Hutchinson</author>
</authors>
<title>Author profiling for english emails.</title>
<date>2007</date>
<booktitle>In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8489" citStr="Estival et al., 2007" startWordPosition="1264" endWordPosition="1267"> al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007). More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013). These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014). 1806 3 Data set construction Traditionally, the gold standard for this supervised classification task is obtained by the means of </context>
</contexts>
<marker>Estival, Gaustad, Pham, Radford, Hutchinson, 2007</marker>
<rawString>Dominique Estival, Tanja Gaustad, Son Bao Pham, Will Radford, and Ben Hutchinson. 2007. Author profiling for english emails. In Proceedings of the 10th Conference of the Pacific Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet: a publicly available lexical resource for opinion mining.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<contexts>
<context position="19866" citStr="Esuli and Sebastiani, 2006" startWordPosition="3123" endWordPosition="3126">s. On word level, we extract 81 additional features using the Linguistic Inquiry and Word Count (LIWC) tools (Pennebaker et al., 2001), which consists of lexicons related to psychological processes (cognitive, perceptual, social, biological, affective) and personal concerns (achievement, religion, death...) and other categories such as fillers, disfluencies or swear words6. Additionally, since emotion detection has been found predictive in previous personality work (Mohammad and Kiritchenko, 2013), we measure overall positive and negative sentiment expressed per character, using SentiWordNet (Esuli and Sebastiani, 2006) and NRC Emotion Lexicon (Mohammad and Turney, 2010) for the word lookup, inverting sentiment scores for negated dependency sub-tree given by the Stanford Parser. Stylistic features Features of this group capture the syntactic and stylistic properties of the utterances of a character, disregarding the content. Starting from the surfacial properties, we measure the sentence, utterance and word length, including the proportion of words shorter than 4 or longer than 6 letters, frequency of each punctuation mark, 5https://wordnet.princeton.edu/man/ lexnames.5WN.html 6For complete overview refer to</context>
</contexts>
<marker>Esuli, Sebastiani, 2006</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2006. SentiWordNet: a publicly available lexical resource for opinion mining. In Proceedings of LREC, volume 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15416" citStr="Finkel et al., 2005" startWordPosition="2409" endWordPosition="2412">speech can be considered: &lt;p&gt; John turned to Harry. &amp;quot;Let’s go,&amp;quot; he said.&lt;/p&gt; Given the large amount of text available in the books we focus on precision and discard all utterances with no explicit speaker (i.e., 30-70% of the utterances, dependent on the book), as the performance of current systems on such utterance types is still fairly low (O’Keefe et al., 2012; He et al., 2013; Iosif and Mishra, 2014). Similarly, conventional coreference resolution systems did not perform well on this type of data and were therefore not used in the final setup. We adapt the Stanford Named Entity Recognizer(Finkel et al., 2005) to consider titles (Mr., Mrs., Sir...) as a part of the name and to treat the first person I as a named entity. However, identifying only the named entity PERSON in this way is not sufficient. On our evaluation sample consisting of A Game of Thrones and Pride and Prejudice books (the former annotated by us, the latter by He et al. (2013)), 20% of utterances with explicit named speaker were not recognized. Of those correctly identified as a Person in the adjacent indirect speech, 17% were not the speakers. Therefore we implemented a custom heuristics (Algorithm 1), which additionally benefits </context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 363–370. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alastair J Gill</author>
<author>Jon Oberlander</author>
</authors>
<title>Taking care of the linguistic features of extraversion.</title>
<date>2002</date>
<booktitle>In Proceedings of the 24th Annual Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="7555" citStr="Gill and Oberlander, 2002" startWordPosition="1125" endWordPosition="1128">s, relationships, ambitions). As McCrae et al. () point out, a standard set of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison. Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and</context>
</contexts>
<marker>Gill, Oberlander, 2002</marker>
<rawString>Alastair J. Gill and Jon Oberlander. 2002. Taking care of the linguistic features of extraversion. In Proceedings of the 24th Annual Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lewis R Goldberg</author>
<author>John A Johnson</author>
<author>Herbert W Eber</author>
<author>Robert Hogan</author>
<author>Michael C Ashton</author>
<author>C Robert Cloninger</author>
<author>Harrison G Gough</author>
</authors>
<title>The international personality item pool and the future of public-domain personality measures.</title>
<date>2006</date>
<journal>Journal of Research</journal>
<note>in personality, 40(1):84–96.</note>
<contexts>
<context position="28464" citStr="Goldberg et al., 2006" startWordPosition="4449" endWordPosition="4452">ky vs J. K. Rowling). Our basic vector-based features carried no useful information in our case, in contrast to the personality research of Neuman and Cohen (2014). We observed that the factual content of the stories contributed to the character similarity measure more than the subtle personality differences. 5 Actions of fictional characters While psycholinguists and consequenlty NLP researchers analyzed the relation between speech, resp. writing, and personality of an individual, psychologists often evaluate extraversion through behavioral personality questionnaries (Costa and McCrae, 1992; Goldberg et al., 2006). We hypothesize that similar behavior shall be predictive for extraversion of fictional characters as perceived by the readers. 5.1 Action extraction For our purpose we define actions as the subject, verb and context of a sentence, where the subject is a named entity Person and the context is either a direct object in relation dobj to the verb or a first child of the adjacent verb phrase in a parse tree. After grouping the actions per character, the subject name is removed. For example, a sample of actions of the character Eddard Stark of Game of Thrones would be: X paused a moment, X studied</context>
<context position="31234" citStr="Goldberg et al., 2006" startWordPosition="4939" endWordPosition="4942">8 Vectors .504 .497 .451 .497 9 All .600 .623 .598 .623 Percentage human agreement: .849 Table 5: Weighted precision (P), recall (R), F-score (F) and accuracy (A) for actions - in each line for a system using only the given group of features. WordNet stands for WordNet semantic labels, VerbNet setup uses the WordNet-VerbNet links. Highlighted F-scores differ from the majority baseline significantly (p &lt;0.05), using an approx. randomization test. Due to the lack of previous NLP experiments on this task, we compare our features to the actions measured in the International Personality Item Pool (Goldberg et al., 2006), frequently used personality assesment questionnaire (Table 6). The most predictive features of this model capture the activity and excitement seeking facets of extraversion. Stylistic features reflect the complexity difference of the verb phrases (John jumped vs. John thought about it), extraverts being characterized by plain verbs. Semantic features exhibit higher precision than stylistic ones. Sense-linked semantic classes of VerbNet demonstrate the preference of extraverts for being active and expressing themselves - they jump, fight, shout, run in and run out, eat and drink, see and hear</context>
</contexts>
<marker>Goldberg, Johnson, Eber, Hogan, Ashton, Cloninger, Gough, 2006</marker>
<rawString>Lewis R. Goldberg, John A. Johnson, Herbert W. Eber, Robert Hogan, Michael C. Ashton, C. Robert Cloninger, and Harrison G. Gough. 2006. The international personality item pool and the future of public-domain personality measures. Journal of Research in personality, 40(1):84–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lewis R Goldberg</author>
</authors>
<title>The development of markers for the Big-Five factor structure. Psychological assessment,</title>
<date>1992</date>
<pages>4--1</pages>
<contexts>
<context position="34792" citStr="Goldberg (1992)" startWordPosition="5485" endWordPosition="5486">an from person’s verbal expression. This would correspond to the findings of Mairesse et al. (2007), Biel and Gatica-Perez (2013) and Aran and Gatica-Perez (2013) on multimodal data sets. 6 Predicatives of fictional characters Our third extraversion prediction system is subordinate to how fictional characters are described and to the manners in which they behave. We are not aware of a previous NLP work predicting extraversion using descriptive adjectives of the persons in question. We thus juxtapose the most predictive features of our system to the adjectival extraversion markers developed by Goldberg (1992). 6.1 Extraction of descriptive properties In this setup we extract predicatives of the named entities PERSON in the books - relations amod (angry John) and cop (John was smart). As these explicit statements are very sparse in modern novels, we additionally include adverbial modifiers (advmod) related to person’s actions (John said angrily). We extract data for 205 characters, with on average 43 words per character. (a) Master Yoda (b) Sansa Stark (Star Wars) (Game of Thrones) Figure 2: Frequency word clouds for character descriptions 6.2 Classification setup This system uses similar set of le</context>
<context position="36334" citStr="Goldberg (1992)" startWordPosition="5735" endWordPosition="5736">With only few words per character semantic lexicons are less powerful than ngrams. ID Feature set P R F A 1 - (baseline) .267 .517 .352 .517 2 Ngrams .686 .657 .648 .657 3 LIWC .645 .601 .586 .601 4 WordNet .518 .545 .528 .545 5 Sentiment .375 .463 .384 .463 6 Vectors .267 .517 .352 .517 7 All .692 .698 .693 .698 Percentage human agreement: .849 Table 7: Weighted precision, recall, F-score and accuracy. Highlighted F-scores differ from the majority baseline significantly (p &lt;0.05). 1812 Table 8 displays the most predictive features in our system contrasted to the adjectival markers. Extravert Goldberg (1992) : adventurous,mischievous, playful, rambunctious, dominant, forceful, demonstrative, exhibitionistic, flamboyant, brave, courageous, daring, assured,... Our experiment : excited, restlessly, stubbornly, restless, beloved, eager, abruptly, defiantly, darkly, eagerly, loudly, reluctant, stubborn, unwise, ruthless, quickly, abruptly, right, change (WN), social (WN) Introvert Goldberg (1992) : bashful, shy, timid, inhibited, restrained unadventurous, unaggressive, uncompetitive bitter, joyless, melancholic, moody, morose,... Our experiment : anxious, patiently, hesitantly, backward, softly, waril</context>
</contexts>
<marker>Goldberg, 1992</marker>
<rawString>Lewis R Goldberg. 1992. The development of markers for the Big-Five factor structure. Psychological assessment, 4(1):26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Max M¨uhlh¨auser</author>
<author>Christof M¨uller</author>
<author>J¨urgen Steimle</author>
<author>Markus Weimer</author>
<author>Torsten Zesch</author>
</authors>
<title>Darmstadt Knowledge Processing Repository Based on UIMA.</title>
<date>2007</date>
<booktitle>In Proceedings of the First Workshop on Unstructured Information Management Architecture at Biannual Conference of the Society for Computational Linguistics and Language Technology,</booktitle>
<location>T¨ubingen, Germany.</location>
<marker>Gurevych, M¨uhlh¨auser, M¨uller, Steimle, Weimer, Zesch, 2007</marker>
<rawString>Iryna Gurevych, Max M¨uhlh¨auser, Christof M¨uller, J¨urgen Steimle, Markus Weimer, and Torsten Zesch. 2007. Darmstadt Knowledge Processing Repository Based on UIMA. In Proceedings of the First Workshop on Unstructured Information Management Architecture at Biannual Conference of the Society for Computational Linguistics and Language Technology, T¨ubingen, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iryna Gurevych</author>
<author>Judith Eckle-Kohler</author>
<author>Silvana Hartmann</author>
<author>Michael Matuschek</author>
<author>Christian M Meyer</author>
<author>Christian Wirth</author>
</authors>
<title>Uby: A large-scale unified lexical-semantic resource based on LMF.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="18881" citStr="Gurevych et al., 2012" startWordPosition="2980" endWordPosition="2983">l phenomena on a higher level of abstraction. The main part of our features is extracted on sense level. We use the most frequent sense of WordNet (Miller, 1995) to annotate all verbs in the direct speech (a simple but well performing approach for books). We then label the disambiguated verbs with their semantic field given in WordNet (WordNet defines 14 semantic classes of verbs which group verbs by their semantic field) and we measure frequency and occurence of each of these classes (e.g. cognition, communication, motion, perception)5. Additionally, we use the lexical-semantic resource UBY (Gurevych et al., 2012) to access the WordNet and VerbNet information, and to exploit the VerbNet sense-level links which connects WordNet senses with the corresponding 273 main VerbNet classes (Kipper-Schuler, 2005). These are more fine-grained (e.g. pay, conspire, neglect, discover) than the WordNet semantic fields. WordNet covered 90% and VerbNet 86% of all the verb occurences. On word level, we extract 81 additional features using the Linguistic Inquiry and Word Count (LIWC) tools (Pennebaker et al., 2001), which consists of lexicons related to psychological processes (cognitive, perceptual, social, biological, </context>
</contexts>
<marker>Gurevych, Eckle-Kohler, Hartmann, Matuschek, Meyer, Wirth, 2012</marker>
<rawString>Iryna Gurevych, Judith Eckle-Kohler, Silvana Hartmann, Michael Matuschek, Christian M. Meyer, and Christian Wirth. 2012. Uby: A large-scale unified lexical-semantic resource based on LMF. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark A Hall</author>
</authors>
<title>Correlation-based feature selection for machine learning.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>The University of Waikato.</institution>
<contexts>
<context position="24488" citStr="Hall, 1999" startWordPosition="3832" endWordPosition="3833">outperformed by top-down semantic approaches which employ a more abstract feature representation. As in previous work, LIWC features exhibit good performance. However, the highest performance is achieved employing the VerbNet verb classes with WordNet wordsense disambiguation. Also stylistic features contribute substantially to the classification despite the mixture of genres in our book corpus - especially frequencies of modal verbs and part-ofspeech ratios were particularly informative. The most predictive features from each group are listed in Table 3 together with their correlation merit (Hall, 1999), and compared with previous work in Table 4. Feature I/E Ref Feature I/E Ref Predictive also in our data: No effect in our data: Pronoun ’we’ -/+ [3] Neg. emot. +/- [1] Tentative, unsure +/- [1] Pos. emot. -/+ [1] Exclusive +/- [1] Self-ref. -/+ [1] Inclusive -/+ [1] Formality +/- [2] Insight +/- [1] Elaborated +/- [3] Nouns, articles +/- Long sent. +/- Lexical richness +/- Social -/+ Negations +/- [2] Body functions -/+ [2] Interjections -/+ [3] Source ID Author [1] Pennebaker and King (1999) [2] Dewaele and Furnham (1999) [3] Mairesse et al. (2007) Table 4: Comparison of our results to prev</context>
</contexts>
<marker>Hall, 1999</marker>
<rawString>Mark A. Hall. 1999. Correlation-based feature selection for machine learning. Ph.D. thesis, The University of Waikato.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua He</author>
<author>Denilson Barbosa</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Identification of speakers in novels.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>1312--1320</pages>
<contexts>
<context position="15178" citStr="He et al., 2013" startWordPosition="2370" endWordPosition="2373">s assigning to the direct speech utterance the correct speaker. We benefit from the epub format of the e-books which defines a paragraph structure in such a way, that only the indirect speech chunk immediately surrounding the direct speech can be considered: &lt;p&gt; John turned to Harry. &amp;quot;Let’s go,&amp;quot; he said.&lt;/p&gt; Given the large amount of text available in the books we focus on precision and discard all utterances with no explicit speaker (i.e., 30-70% of the utterances, dependent on the book), as the performance of current systems on such utterance types is still fairly low (O’Keefe et al., 2012; He et al., 2013; Iosif and Mishra, 2014). Similarly, conventional coreference resolution systems did not perform well on this type of data and were therefore not used in the final setup. We adapt the Stanford Named Entity Recognizer(Finkel et al., 2005) to consider titles (Mr., Mrs., Sir...) as a part of the name and to treat the first person I as a named entity. However, identifying only the named entity PERSON in this way is not sufficient. On our evaluation sample consisting of A Game of Thrones and Pride and Prejudice books (the former annotated by us, the latter by He et al. (2013)), 20% of utterances w</context>
</contexts>
<marker>He, Barbosa, Kondrak, 2013</marker>
<rawString>Hua He, Denilson Barbosa, and Grzegorz Kondrak. 2013. Identification of speakers in novels. In Proceedings of the 51st Annual Meeting on Association for Computational Linguistics, pages 1312–1320.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Heitmann</author>
<author>Conor Hayes</author>
</authors>
<title>Using linked data to build open, collaborative recommender systems.</title>
<date>2010</date>
<booktitle>In AAAI symposium Linked data meets artificial intelligence.</booktitle>
<contexts>
<context position="4909" citStr="Heitmann and Hayes, 2010" startWordPosition="702" endWordPosition="705">learning models based on the speech (Section 4), actions (Section 5) and predicatives (Section 6) of the protagonists, and show that especially on the direct speech and action data the lexical-semantic features significantly outperform the baselines. Qualitative analysis reveals that the most predictive features correspond to reported findings in psychology and NLP. 2 Related work Research in the the area of content-based recommendation systems have shown that incorporating semantic information is valuable for the user and leads to measurable improvements (Passant, 2010; Di Noia et al., 2012; Heitmann and Hayes, 2010). De Clercq et al. (2014) incorporated semantic frames from FrameNet into the recommendation system for books. They represent the plot of each book with a sequence of ca. 200 semantic frames and has shown that the frame information (such as Killing - Revenge - Death) outperforms the bag-of-words approach.Recent NLP experiments begin to reveal the importance of entitycentric models in a variety of tasks. Chambers (2013) show improvement in event schema induction by learning entity-centric rules (e.g., a victim is likely to be a person). Bamman et al. (2014) and Smith et al. (2013) present laten</context>
</contexts>
<marker>Heitmann, Hayes, 2010</marker>
<rawString>Benjamin Heitmann and Conor Hayes. 2010. Using linked data to build open, collaborative recommender systems. In AAAI symposium Linked data meets artificial intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Heylighen</author>
<author>Jean-Marc Dewaele</author>
</authors>
<title>Variation in the Contextuality of Language: An Empirical Measure.</title>
<date>2002</date>
<journal>Foundations of Science,</journal>
<volume>7</volume>
<issue>3</issue>
<pages>340</pages>
<contexts>
<context position="21015" citStr="Heylighen and Dewaele, 2002" startWordPosition="3298" endWordPosition="3301">://wordnet.princeton.edu/man/ lexnames.5WN.html 6For complete overview refer to www.liwc.net and endings of each adjective as per Corney et al. (2002). On the syntax level we measure the frequency of each part of speech as well as the 500 most frequent part-of-speech bi-, tri- and quadrigrams, and the frequency of each dependency obtained from the Stanford Parser. We additionally capture the frequency of superlatives, comparatives and modal verbs, the proportion of verbs in present, past and future tense, and the formality of the language as per the part-of-speech-based formality coefficient (Heylighen and Dewaele, 2002), and measure the average depth of the parse trees. Word embeddings as features Since vector space semantics has been beneficial for predicting author’s personality in previous work (Neuman and Cohen, 2014), we use a pre-trained word vector model created by the GloVe algorithm (Pennington et al., 2014) on English Wikipedia. GloVe employs a global log-bilinear regression model that combines the advantages of the global matrix factorization and local context window methods. We assign the resulting 300-dimensional vectors to the words in character’s direct speech, excluding stopwords, and calcula</context>
<context position="27637" citStr="Heylighen and Dewaele (2002)" startWordPosition="4322" endWordPosition="4326">ndly companion (Gimli, Ron Weasley...), while the evil extravert types are possibly rarer in the experiments on human writing, or are more likely to fit under the MBTI definition of extraversion than FFM facets. Another potential cause, based on the error analysis, is the different target of the same sentiment for extraverts and introverts. For example, the ngram ”I fear” is highly predictive for an introvert in our data while extraverts would rather use formulations to imply that others should fear. Similarly to Nowson et al. (2005), we did not find any difference in the formality measure of Heylighen and Dewaele (2002). Neither we did in the complexity of sentences as per the parse tree depth 1810 and sentence length. It is probable that these aspects were also impacted by our broad variety of author style (F. Dostoyevsky vs J. K. Rowling). Our basic vector-based features carried no useful information in our case, in contrast to the personality research of Neuman and Cohen (2014). We observed that the factual content of the stories contributed to the character similarity measure more than the subtle personality differences. 5 Actions of fictional characters While psycholinguists and consequenlty NLP researc</context>
</contexts>
<marker>Heylighen, Dewaele, 2002</marker>
<rawString>Francis Heylighen and Jean-Marc Dewaele. 2002. Variation in the Contextuality of Language: An Empirical Measure. Foundations of Science, 7(3):293– 340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elias Iosif</author>
<author>Taniya Mishra</author>
</authors>
<title>From speaker identification to affective analysis: A multi-step system for analyzing children stories. EACL</title>
<date>2014</date>
<pages>40--49</pages>
<contexts>
<context position="15203" citStr="Iosif and Mishra, 2014" startWordPosition="2374" endWordPosition="2377">e direct speech utterance the correct speaker. We benefit from the epub format of the e-books which defines a paragraph structure in such a way, that only the indirect speech chunk immediately surrounding the direct speech can be considered: &lt;p&gt; John turned to Harry. &amp;quot;Let’s go,&amp;quot; he said.&lt;/p&gt; Given the large amount of text available in the books we focus on precision and discard all utterances with no explicit speaker (i.e., 30-70% of the utterances, dependent on the book), as the performance of current systems on such utterance types is still fairly low (O’Keefe et al., 2012; He et al., 2013; Iosif and Mishra, 2014). Similarly, conventional coreference resolution systems did not perform well on this type of data and were therefore not used in the final setup. We adapt the Stanford Named Entity Recognizer(Finkel et al., 2005) to consider titles (Mr., Mrs., Sir...) as a part of the name and to treat the first person I as a named entity. However, identifying only the named entity PERSON in this way is not sufficient. On our evaluation sample consisting of A Game of Thrones and Pride and Prejudice books (the former annotated by us, the latter by He et al. (2013)), 20% of utterances with explicit named speake</context>
</contexts>
<marker>Iosif, Mishra, 2014</marker>
<rawString>Elias Iosif and Taniya Mishra. 2014. From speaker identification to affective analysis: A multi-step system for analyzing children stories. EACL 2014, pages 40–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver P John</author>
<author>Sanjay Srivastava</author>
</authors>
<title>The Big Five trait taxonomy: History, measurement, and theoretical perspectives. Handbook of personality: Theory and research,</title>
<date>1999</date>
<pages>2--1999</pages>
<contexts>
<context position="2364" citStr="John and Srivastava, 1999" startWordPosition="325" endWordPosition="328"> means of personality tests of the Five Factor Model (FFM) (McCrae and Costa, 1987; Goldberg, 1990), which is wellknown and widely accepted in psychology and other research fields. The FFM defines personality along five bipolar scales: Extraversion (sociable vs. reserved), Emotional stability (secure vs. neurotic), Agreeableness (friendly vs. unsympathic), Conscientiousness (organized vs. careless) and Openness to experience (insightful vs. unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008; Rentfrow et al., 2011). It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009). Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999). More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is re</context>
</contexts>
<marker>John, Srivastava, 1999</marker>
<rawString>Oliver P. John and Sanjay Srivastava. 1999. The Big Five trait taxonomy: History, measurement, and theoretical perspectives. Handbook of personality: Theory and research, 2(1999):102–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Johnson</author>
<author>Joseph Carroll</author>
<author>Jonathan Gottschall</author>
<author>Daniel Kruger</author>
</authors>
<title>Portrayal of personality in victorian novels reflects modern research findings but amplifies the significance of agreeableness.</title>
<date>2011</date>
<journal>Journal of Research in Personality,</journal>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="6790" citStr="Johnson et al., 2011" startWordPosition="1009" endWordPosition="1012">gical understanding of personality, in contrast to role attribution requires a certain detached objectivity - even outright villains may have traits considered desirable in real life. For example, the devil has in many tales a very high aspiration level, appearing highly conscientious and agreeable. We hypothesize that these deeper personality aspects are those which drive reader’s affiliation to the character, thus deserve to be examined closer. Also literary scholars formulate ad hoc personality descriptions for their experiments, for example to test hypotheses from evolutionary psychology (Johnson et al., 2011) or examine fictional portrayals of physicists (Dotson, 2009). These descriptions are usually adjusted to the experiment focus (e.g. emotions, relationships, ambitions). As McCrae et al. () point out, a standard set of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison. Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author hav</context>
</contexts>
<marker>Johnson, Carroll, Gottschall, Kruger, 2011</marker>
<rawString>John A. Johnson, Joseph Carroll, Jonathan Gottschall, and Daniel Kruger. 2011. Portrayal of personality in victorian novels reflects modern research findings but amplifies the significance of agreeableness. Journal of Research in Personality, 45(1):50–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoff F Kaufman</author>
<author>Lisa K Libby</author>
</authors>
<title>Changing beliefs and behavior through experiencetaking.</title>
<date>2012</date>
<journal>Journal of personality and social psychology,</journal>
<pages>103--1</pages>
<contexts>
<context position="2806" citStr="Kaufman and Libby, 2012" startWordPosition="390" endWordPosition="393"> unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008; Rentfrow et al., 2011). It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009). Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999). More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is revealed only later in the story. We therefore hypothesize that readers might have a preference for reading novels depicting fictional characters that are similar to themselves. Finding a direct link between reader’s and protagonist’s personality traits would advance the development of content-based recommendation systems. As a first step to explore this hypothesis further, it needs to be determined if we are able to construct a personality</context>
</contexts>
<marker>Kaufman, Libby, 2012</marker>
<rawString>Geoff F. Kaufman and Lisa K. Libby. 2012. Changing beliefs and behavior through experiencetaking. Journal of personality and social psychology, 103(1):1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dimitrios Kokkinakis</author>
<author>Mats Malm</author>
</authors>
<title>Character profiling in 19th century fiction. Language Technologies for Digital Humanities and Cultural Heritage.</title>
<date>2011</date>
<contexts>
<context position="5963" citStr="Kokkinakis and Malm, 2011" startWordPosition="879" endWordPosition="882">improvement in event schema induction by learning entity-centric rules (e.g., a victim is likely to be a person). Bamman et al. (2014) and Smith et al. (2013) present latent variable models for unsupervised learning of latent character types in movie plot summaries and in English novels, taking authorial style into account. However, even the state-of-the-art NLP work rather describes personas of fictional characters by their role in the story - e.g., action hero, valley girl, best friend, villain etc. - or by their relations to other characters, such as mother or daughter (Elson et al., 2010; Kokkinakis and Malm, 2011), rather than by their inner preferences and motivations. It is important to note here that determining a personality of a character is a very different task from determining its role in the story. Psychological understanding of personality, in contrast to role attribution requires a certain detached objectivity - even outright villains may have traits considered desirable in real life. For example, the devil has in many tales a very high aspiration level, appearing highly conscientious and agreeable. We hypothesize that these deeper personality aspects are those which drive reader’s affiliati</context>
</contexts>
<marker>Kokkinakis, Malm, 2011</marker>
<rawString>Dimitrios Kokkinakis and Mats Malm. 2011. Character profiling in 19th century fiction. Language Technologies for Digital Humanities and Cultural Heritage.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Kosinski</author>
<author>David Stillwell</author>
<author>Thore Graepel</author>
</authors>
<title>Private traits and attributes are predictable from digital records of human behavior.</title>
<date>2013</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>110</volume>
<issue>15</issue>
<contexts>
<context position="8600" citStr="Kosinski et al., 2013" startWordPosition="1284" endWordPosition="1287">ays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007). More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013). These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014). 1806 3 Data set construction Traditionally, the gold standard for this supervised classification task is obtained by the means of personality questionnaires, used for the Five-Factor Model, taken by each of the individuals assessed. This pos</context>
</contexts>
<marker>Kosinski, Stillwell, Graepel, 2013</marker>
<rawString>Michal Kosinski, David Stillwell, and Thore Graepel. 2013. Private traits and attributes are predictable from digital records of human behavior. Proceedings of the National Academy of Sciences, 110(15):5802–5805.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Kosinski</author>
<author>Yoram Bachrach</author>
<author>Pushmeet Kohli</author>
<author>David Stillwell</author>
<author>Thore Graepel</author>
</authors>
<title>Manifestations of user personality in website choice and behaviour on online social networks.</title>
<date>2014</date>
<booktitle>Machine learning,</booktitle>
<pages>95--3</pages>
<contexts>
<context position="8624" citStr="Kosinski et al., 2014" startWordPosition="1288" endWordPosition="1291">orded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007). More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013). These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014). 1806 3 Data set construction Traditionally, the gold standard for this supervised classification task is obtained by the means of personality questionnaires, used for the Five-Factor Model, taken by each of the individuals assessed. This poses a challenge for ficti</context>
<context position="39307" citStr="Kosinski et al., 2014" startWordPosition="6155" endWordPosition="6159">ics, including WordNet and VerbNet sense-level information and vectorial word representations. In models based on the speech and actions of the protagonists, we demonstrated that the sense-linked lexical-semantic features significantly outperform the baselines. The most predictive features correspond to the reported findings in personality psychology and NLP experiments on human personality. Our systems based on actions and appearance of characters demonstrate higher performance than systems based on direct speech, which is in accordance with recent research on personality in social networks (Kosinski et al., 2014; Biel and Gatica-Perez, 2013), revealing the importance of the metadata. We have shown that exploiting the links between lexical resources to leverage more accurate semantic information can be beneficial for this type of tasks, oriented to actions performed by the entity. However, the human annotator agreement in our task stays high above the performance achieved. Considering that most of the sucessful novels were produced as movies, we cannot exclude that our annotators based their decision on the multimodal representation of the protagonists. In the future we aim on collecting a more detail</context>
</contexts>
<marker>Kosinski, Bachrach, Kohli, Stillwell, Graepel, 2014</marker>
<rawString>Michal Kosinski, Yoram Bachrach, Pushmeet Kohli, David Stillwell, and Thore Graepel. 2014. Manifestations of user personality in website choice and behaviour on online social networks. Machine learning, 95(3):357–380.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruno Lepri</author>
<author>Ramanathan Subramanian</author>
<author>Kyriaki Kalimeri</author>
<author>Jacopo Staiano</author>
<author>Fabio Pianesi</author>
<author>Nicu Sebe</author>
</authors>
<title>Employing social gaze and speaking activity for automatic determination of the extraversion trait.</title>
<date>2010</date>
<booktitle>In International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction, ICMI-MLMI ’10,</booktitle>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="7624" citStr="Lepri et al., 2010" startWordPosition="1137" endWordPosition="1140"> of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison. Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic data</context>
</contexts>
<marker>Lepri, Subramanian, Kalimeri, Staiano, Pianesi, Sebe, 2010</marker>
<rawString>Bruno Lepri, Ramanathan Subramanian, Kyriaki Kalimeri, Jacopo Staiano, Fabio Pianesi, and Nicu Sebe. 2010. Employing social gaze and speaking activity for automatic determination of the extraversion trait. In International Conference on Multimodal Interfaces and the Workshop on Machine Learning for Multimodal Interaction, ICMI-MLMI ’10, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas A MacDonald</author>
<author>Peter E Anderson</author>
<author>Catherine I Tsagarakis</author>
<author>Cornelius J Holland</author>
</authors>
<title>Examination of the relationship between the MyersBriggs Type Indicator and the NEO personality inventory.</title>
<date>1994</date>
<journal>Psychological Reports,</journal>
<volume>74</volume>
<issue>1</issue>
<contexts>
<context position="10009" citStr="MacDonald et al., 1994" startWordPosition="1495" endWordPosition="1498">nefits from the fact that readers enjoy discussing the personality of their favourite book character online. A popular layman instrument for personality classification is the Myers-Brigggs Type Indicator (Myers et al., 1985), shortly MBTI, which sorts personal preferences into four opposite pairs, or dichotomies, such as Thinking vs. Feeling or Judging vs. Perceiving. While the MBTI validity has been questioned by the research community (Pittenger, 2005), the Extraversion scale is showing rather strong validity and correlation to similar trait in the Five-Factor Model (McCrae and Costa, 1989; MacDonald et al., 1994). Our study hence focuses on the Extraversion scale. Our data was collected from the collaboratively constructed Personality Databank2 where the readers can vote if a book character is, among other aspects, introverted or extraverted. While the readers used codes based on the MBTI typology, they did not apply the MBTI assessment strategies. There was no explicit annotation guideline and the interpretation was left to readers’ intuition and knowledge.3 This approach of gold standard collection has several obvious drawbacks. First, the question is posed as dichotomic, while in reality the extrav</context>
</contexts>
<marker>MacDonald, Anderson, Tsagarakis, Holland, 1994</marker>
<rawString>Douglas A. MacDonald, Peter E. Anderson, Catherine I. Tsagarakis, and Cornelius J. Holland. 1994. Examination of the relationship between the MyersBriggs Type Indicator and the NEO personality inventory. Psychological Reports, 74(1):339–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franc¸ois Mairesse</author>
<author>Marilyn A Walker</author>
<author>Matthias R Mehl</author>
<author>Roger K Moore</author>
</authors>
<title>Using linguistic cues for the automatic recognition of personality in conversation and text.</title>
<date>2007</date>
<journal>Journal of artificial intelligence research.</journal>
<contexts>
<context position="7879" citStr="Mairesse et al. (2007)" startWordPosition="1178" endWordPosition="1181">f human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et </context>
<context position="14010" citStr="Mairesse et al., 2007" startWordPosition="2171" endWordPosition="2174">? 2. Actions: Is the behavior, of which a character is an agent, predictive for extraversion? 3. Predicatives and adverbs: Are the explicit (John was an exhibitionist) or implicit (John shouted abruptly) descriptions of the character in the book predictive for extraversion? 1 P= N N i=1 k j=1 1807 In the next three sections we present the experimental settings and results for each of the systems. 4 Direct speech of fictional characters The system for the direct speech resembles the most to the previous systems developed for author personality profiling, e.g. on stream of consciousness essays (Mairesse et al., 2007) or social media posts (Celli et al., 2013) and therefore provides the best opportunity for comparison between human individuals and fictional characters. On top of the comparison to previous research, we exploit the sense links between WordNet and VerbNet to extract additional features - an approach which is novel for this type of task. 4.1 Extraction and assignment of speech We process the book text using freely available components of the DKPro framework (Gurevych et al., 2007). The most challenging task in building the direct speech data set is assigning to the direct speech utterance the </context>
<context position="23817" citStr="Mairesse et al., 2007" startWordPosition="3729" endWordPosition="3732">erbs, neg, sbar, articles .19-.14 Extravert Feat.group Features Merit ngrams we, hurry, fat, dirty .24-.19 LIWC We, Inclusion, Pronoun, Body .18-.09 WordNet motion, contact, communication, .14-.07 body, perception, change VerbNet get, talk, substance emission .18-.15 Style pronoun We, whadjp, .20-.14 type-token ratio., interjections Table 3: The most predictive features for each group for speaker’s extraversion and introversion. Correlation merit, as per the correlation feature selection in WEKA, evaluates Pearson’s correlation between the feature and the class Similarly to previous research (Mairesse et al., 2007; Celli et al., 2013), the bottom-up word based approach is outperformed by top-down semantic approaches which employ a more abstract feature representation. As in previous work, LIWC features exhibit good performance. However, the highest performance is achieved employing the VerbNet verb classes with WordNet wordsense disambiguation. Also stylistic features contribute substantially to the classification despite the mixture of genres in our book corpus - especially frequencies of modal verbs and part-ofspeech ratios were particularly informative. The most predictive features from each group a</context>
<context position="25045" citStr="Mairesse et al. (2007)" startWordPosition="3927" endWordPosition="3930">ted in Table 3 together with their correlation merit (Hall, 1999), and compared with previous work in Table 4. Feature I/E Ref Feature I/E Ref Predictive also in our data: No effect in our data: Pronoun ’we’ -/+ [3] Neg. emot. +/- [1] Tentative, unsure +/- [1] Pos. emot. -/+ [1] Exclusive +/- [1] Self-ref. -/+ [1] Inclusive -/+ [1] Formality +/- [2] Insight +/- [1] Elaborated +/- [3] Nouns, articles +/- Long sent. +/- Lexical richness +/- Social -/+ Negations +/- [2] Body functions -/+ [2] Interjections -/+ [3] Source ID Author [1] Pennebaker and King (1999) [2] Dewaele and Furnham (1999) [3] Mairesse et al. (2007) Table 4: Comparison of our results to previously reported predictive features for speaker’s extraversion (E), resp. introversion (I). We list publications where these features were, to our knowledge, reported as novel. In accordance with the experiments of Pennebaker and King (1999), we observe more frequent exclusions (e.g. without, but), hedging and negation expressed by introverts, and inclusion (e.g. with, and) by extraverts. Extraverts talk more in first person plural, use more back-channels and interjections, and talk more about aspects related to their body. Introverts show more ration</context>
<context position="34005" citStr="Mairesse et al., 2007" startWordPosition="5356" endWordPosition="5359">is also notable in their actions, as they often hope or wish for something they might like to do. Additionally, semantic classes Social and Family, reported as correlated to extraversion by Pennebaker and King (1999) and not confirmed in our first model, became predictive in protaonists’ actions. 5.4 Discussion Also in this task, the VerbNet classes brought significant improvement in performance. The classification model based on actions outperforms not only the direct speech model, but also the state-of-the-art systems predicting authors’ extraversion from the stream-of-consciousness essays (Mairesse et al., 2007; Celli et al., 2013; Neuman and Cohen, 2014). While surely not directly comparable, this result hints to the fact that the personality is easier to detect from behavior than from person’s verbal expression. This would correspond to the findings of Mairesse et al. (2007), Biel and Gatica-Perez (2013) and Aran and Gatica-Perez (2013) on multimodal data sets. 6 Predicatives of fictional characters Our third extraversion prediction system is subordinate to how fictional characters are described and to the manners in which they behave. We are not aware of a previous NLP work predicting extraversio</context>
</contexts>
<marker>Mairesse, Walker, Mehl, Moore, 2007</marker>
<rawString>Franc¸ois Mairesse, Marilyn A. Walker, Matthias R. Mehl, and Roger K. Moore. 2007. Using linguistic cues for the automatic recognition of personality in conversation and text. Journal of artificial intelligence research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raymond A Mar</author>
<author>Keith Oatley</author>
<author>Jordan B Peterson</author>
</authors>
<title>Exploring the link between reading fiction and empathy: Ruling out individual differences and examining outcomes.</title>
<date>2009</date>
<journal>Communications Journal,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="2580" citStr="Mar et al., 2009" startWordPosition="360" endWordPosition="363">ar scales: Extraversion (sociable vs. reserved), Emotional stability (secure vs. neurotic), Agreeableness (friendly vs. unsympathic), Conscientiousness (organized vs. careless) and Openness to experience (insightful vs. unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008; Rentfrow et al., 2011). It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009). Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999). More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is revealed only later in the story. We therefore hypothesize that readers might have a preference for reading novels depicting fictional characters that are similar to themselves. Finding a direct link between reader’s a</context>
</contexts>
<marker>Mar, Oatley, Peterson, 2009</marker>
<rawString>Raymond A. Mar, Keith Oatley, and Jordan B. Peterson. 2009. Exploring the link between reading fiction and empathy: Ruling out individual differences and examining outcomes. Communications Journal, 34(4):407–428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert R McCrae</author>
<author>Paul T Costa</author>
</authors>
<title>Validation of the five-factor model of personality across instruments and observers. Journal ofpersonality and social psychology,</title>
<date>1987</date>
<pages>52--1</pages>
<contexts>
<context position="1820" citStr="McCrae and Costa, 1987" startWordPosition="254" endWordPosition="257">rise to the field of personality profiling - automated classification of personality traits based on written, verbal and multimodal behavior of an individual. This research builds upon findings from classical personality psychology and has applications in a wide range of areas from medicine (suicide prevention) across security (forensics, paedophile detection, cyberbullying) to marketing and sales (recommendation systems, target group profiles). The gold standard labels for an objective evaluation of personality are mostly obtained by means of personality tests of the Five Factor Model (FFM) (McCrae and Costa, 1987; Goldberg, 1990), which is wellknown and widely accepted in psychology and other research fields. The FFM defines personality along five bipolar scales: Extraversion (sociable vs. reserved), Emotional stability (secure vs. neurotic), Agreeableness (friendly vs. unsympathic), Conscientiousness (organized vs. careless) and Openness to experience (insightful vs. unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008</context>
</contexts>
<marker>McCrae, Costa, 1987</marker>
<rawString>Robert R. McCrae and Paul T. Costa. 1987. Validation of the five-factor model of personality across instruments and observers. Journal ofpersonality and social psychology, 52(1):81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert R McCrae</author>
<author>Paul T Costa</author>
</authors>
<title>Reinterpreting the myers-briggs type indicator from the perspective of the five-factor model of personality.</title>
<date>1989</date>
<journal>Journal ofpersonality,</journal>
<pages>57--1</pages>
<contexts>
<context position="9984" citStr="McCrae and Costa, 1989" startWordPosition="1491" endWordPosition="1494">6). Our gold standard benefits from the fact that readers enjoy discussing the personality of their favourite book character online. A popular layman instrument for personality classification is the Myers-Brigggs Type Indicator (Myers et al., 1985), shortly MBTI, which sorts personal preferences into four opposite pairs, or dichotomies, such as Thinking vs. Feeling or Judging vs. Perceiving. While the MBTI validity has been questioned by the research community (Pittenger, 2005), the Extraversion scale is showing rather strong validity and correlation to similar trait in the Five-Factor Model (McCrae and Costa, 1989; MacDonald et al., 1994). Our study hence focuses on the Extraversion scale. Our data was collected from the collaboratively constructed Personality Databank2 where the readers can vote if a book character is, among other aspects, introverted or extraverted. While the readers used codes based on the MBTI typology, they did not apply the MBTI assessment strategies. There was no explicit annotation guideline and the interpretation was left to readers’ intuition and knowledge.3 This approach of gold standard collection has several obvious drawbacks. First, the question is posed as dichotomic, wh</context>
</contexts>
<marker>McCrae, Costa, 1989</marker>
<rawString>Robert R. McCrae and Paul T. Costa. 1989. Reinterpreting the myers-briggs type indicator from the perspective of the five-factor model of personality. Journal ofpersonality, 57(1):17–40.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Robert R McCrae</author>
<author>James F Gaines</author>
<author>Marie A Wellington</author>
</authors>
<title>The five-factor model in fact and fiction. Handbook of Psychology.</title>
<marker>McCrae, Gaines, Wellington, </marker>
<rawString>Robert R. McCrae, James F. Gaines, and Marie A. Wellington. The five-factor model in fact and fiction. Handbook of Psychology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias R Mehl</author>
<author>Samuel D Gosling</author>
<author>James W Pennebaker</author>
</authors>
<title>Personality in its natural habitat: manifestations and implicit folk theories of personality in daily life. Journal of personality and social psychology,</title>
<date>2006</date>
<pages>90--5</pages>
<contexts>
<context position="7574" citStr="Mehl et al., 2006" startWordPosition="1129" endWordPosition="1132">). As McCrae et al. () point out, a standard set of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison. Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, </context>
<context position="9364" citStr="Mehl et al., 2006" startWordPosition="1396" endWordPosition="1399"> the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014). 1806 3 Data set construction Traditionally, the gold standard for this supervised classification task is obtained by the means of personality questionnaires, used for the Five-Factor Model, taken by each of the individuals assessed. This poses a challenge for fictional characters. However, strong correlations have been found between the self-reported and perceived personality traits (Mehl et al., 2006). Our gold standard benefits from the fact that readers enjoy discussing the personality of their favourite book character online. A popular layman instrument for personality classification is the Myers-Brigggs Type Indicator (Myers et al., 1985), shortly MBTI, which sorts personal preferences into four opposite pairs, or dichotomies, such as Thinking vs. Feeling or Judging vs. Perceiving. While the MBTI validity has been questioned by the research community (Pittenger, 2005), the Extraversion scale is showing rather strong validity and correlation to similar trait in the Five-Factor Model (Mc</context>
</contexts>
<marker>Mehl, Gosling, Pennebaker, 2006</marker>
<rawString>Matthias R. Mehl, Samuel D. Gosling, and James W. Pennebaker. 2006. Personality in its natural habitat: manifestations and implicit folk theories of personality in daily life. Journal of personality and social psychology, 90(5):862.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Svetlana Kiritchenko</author>
</authors>
<title>Using nuances of emotion to identify personality. AAAI</title>
<date>2013</date>
<tech>Technical Report WS-13-01 Computational Personality Recognition (Shared Task).</tech>
<contexts>
<context position="19741" citStr="Mohammad and Kiritchenko, 2013" startWordPosition="3106" endWordPosition="3110">pay, conspire, neglect, discover) than the WordNet semantic fields. WordNet covered 90% and VerbNet 86% of all the verb occurences. On word level, we extract 81 additional features using the Linguistic Inquiry and Word Count (LIWC) tools (Pennebaker et al., 2001), which consists of lexicons related to psychological processes (cognitive, perceptual, social, biological, affective) and personal concerns (achievement, religion, death...) and other categories such as fillers, disfluencies or swear words6. Additionally, since emotion detection has been found predictive in previous personality work (Mohammad and Kiritchenko, 2013), we measure overall positive and negative sentiment expressed per character, using SentiWordNet (Esuli and Sebastiani, 2006) and NRC Emotion Lexicon (Mohammad and Turney, 2010) for the word lookup, inverting sentiment scores for negated dependency sub-tree given by the Stanford Parser. Stylistic features Features of this group capture the syntactic and stylistic properties of the utterances of a character, disregarding the content. Starting from the surfacial properties, we measure the sentence, utterance and word length, including the proportion of words shorter than 4 or longer than 6 lette</context>
</contexts>
<marker>Mohammad, Kiritchenko, 2013</marker>
<rawString>Saif M. Mohammad and Svetlana Kiritchenko. 2013. Using nuances of emotion to identify personality. AAAI Technical Report WS-13-01 Computational Personality Recognition (Shared Task).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon.</title>
<date>2010</date>
<booktitle>In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text,</booktitle>
<pages>26--34</pages>
<contexts>
<context position="19918" citStr="Mohammad and Turney, 2010" startWordPosition="3131" endWordPosition="3134">sing the Linguistic Inquiry and Word Count (LIWC) tools (Pennebaker et al., 2001), which consists of lexicons related to psychological processes (cognitive, perceptual, social, biological, affective) and personal concerns (achievement, religion, death...) and other categories such as fillers, disfluencies or swear words6. Additionally, since emotion detection has been found predictive in previous personality work (Mohammad and Kiritchenko, 2013), we measure overall positive and negative sentiment expressed per character, using SentiWordNet (Esuli and Sebastiani, 2006) and NRC Emotion Lexicon (Mohammad and Turney, 2010) for the word lookup, inverting sentiment scores for negated dependency sub-tree given by the Stanford Parser. Stylistic features Features of this group capture the syntactic and stylistic properties of the utterances of a character, disregarding the content. Starting from the surfacial properties, we measure the sentence, utterance and word length, including the proportion of words shorter than 4 or longer than 6 letters, frequency of each punctuation mark, 5https://wordnet.princeton.edu/man/ lexnames.5WN.html 6For complete overview refer to www.liwc.net and endings of each adjective as per C</context>
</contexts>
<marker>Mohammad, Turney, 2010</marker>
<rawString>Saif M. Mohammad and Peter D. Turney. 2010. Emotions evoked by common words and phrases: Using Mechanical Turk to create an emotion lexicon. In Proceedings of the NAACL HLT 2010 Workshop on Computational Approaches to Analysis and Generation of Emotion in Text, pages 26–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Matthew Montoya</author>
<author>Robert S Horton</author>
<author>Jeffrey Kirchner</author>
</authors>
<title>Is actual similarity necessary for attraction? a meta-analysis of actual and perceived similarity.</title>
<date>2008</date>
<journal>Journal of Social and Personal Relationships,</journal>
<volume>25</volume>
<issue>6</issue>
<contexts>
<context position="2705" citStr="Montoya et al., 2008" startWordPosition="376" endWordPosition="379">sympathic), Conscientiousness (organized vs. careless) and Openness to experience (insightful vs. unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008; Rentfrow et al., 2011). It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009). Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999). More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is revealed only later in the story. We therefore hypothesize that readers might have a preference for reading novels depicting fictional characters that are similar to themselves. Finding a direct link between reader’s and protagonist’s personality traits would advance the development of content-based recommendation systems. As a first step to</context>
</contexts>
<marker>Montoya, Horton, Kirchner, 2008</marker>
<rawString>R. Matthew Montoya, Robert S. Horton, and Jeffrey Kirchner. 2008. Is actual similarity necessary for attraction? a meta-analysis of actual and perceived similarity. Journal of Social and Personal Relationships, 25(6):889–922.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Isabel Briggs Myers</author>
<author>Mary H McCaulley</author>
<author>Robert Most</author>
</authors>
<title>Manual, a guide to the development and use of the Myers-Briggs type indicator. Consulting</title>
<date>1985</date>
<publisher>Psychologists Press.</publisher>
<contexts>
<context position="9610" citStr="Myers et al., 1985" startWordPosition="1435" endWordPosition="1438">ditionally, the gold standard for this supervised classification task is obtained by the means of personality questionnaires, used for the Five-Factor Model, taken by each of the individuals assessed. This poses a challenge for fictional characters. However, strong correlations have been found between the self-reported and perceived personality traits (Mehl et al., 2006). Our gold standard benefits from the fact that readers enjoy discussing the personality of their favourite book character online. A popular layman instrument for personality classification is the Myers-Brigggs Type Indicator (Myers et al., 1985), shortly MBTI, which sorts personal preferences into four opposite pairs, or dichotomies, such as Thinking vs. Feeling or Judging vs. Perceiving. While the MBTI validity has been questioned by the research community (Pittenger, 2005), the Extraversion scale is showing rather strong validity and correlation to similar trait in the Five-Factor Model (McCrae and Costa, 1989; MacDonald et al., 1994). Our study hence focuses on the Extraversion scale. Our data was collected from the collaboratively constructed Personality Databank2 where the readers can vote if a book character is, among other asp</context>
</contexts>
<marker>Myers, McCaulley, Most, 1985</marker>
<rawString>Isabel Briggs Myers, Mary H. McCaulley, and Robert Most. 1985. Manual, a guide to the development and use of the Myers-Briggs type indicator. Consulting Psychologists Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yair Neuman</author>
<author>Yochai Cohen</author>
</authors>
<title>A vectorial semantics approach to personality assessment. Scientific reports,</title>
<date>2014</date>
<pages>4</pages>
<contexts>
<context position="21221" citStr="Neuman and Cohen, 2014" startWordPosition="3329" endWordPosition="3332">f speech as well as the 500 most frequent part-of-speech bi-, tri- and quadrigrams, and the frequency of each dependency obtained from the Stanford Parser. We additionally capture the frequency of superlatives, comparatives and modal verbs, the proportion of verbs in present, past and future tense, and the formality of the language as per the part-of-speech-based formality coefficient (Heylighen and Dewaele, 2002), and measure the average depth of the parse trees. Word embeddings as features Since vector space semantics has been beneficial for predicting author’s personality in previous work (Neuman and Cohen, 2014), we use a pre-trained word vector model created by the GloVe algorithm (Pennington et al., 2014) on English Wikipedia. GloVe employs a global log-bilinear regression model that combines the advantages of the global matrix factorization and local context window methods. We assign the resulting 300-dimensional vectors to the words in character’s direct speech, excluding stopwords, and calculate an average vector for each character. We calculate for each test character the cosine similarity to the mean vector of extravert, resp. introvert, in the training data, and to each character in the train</context>
<context position="28005" citStr="Neuman and Cohen (2014)" startWordPosition="4387" endWordPosition="4390">” is highly predictive for an introvert in our data while extraverts would rather use formulations to imply that others should fear. Similarly to Nowson et al. (2005), we did not find any difference in the formality measure of Heylighen and Dewaele (2002). Neither we did in the complexity of sentences as per the parse tree depth 1810 and sentence length. It is probable that these aspects were also impacted by our broad variety of author style (F. Dostoyevsky vs J. K. Rowling). Our basic vector-based features carried no useful information in our case, in contrast to the personality research of Neuman and Cohen (2014). We observed that the factual content of the stories contributed to the character similarity measure more than the subtle personality differences. 5 Actions of fictional characters While psycholinguists and consequenlty NLP researchers analyzed the relation between speech, resp. writing, and personality of an individual, psychologists often evaluate extraversion through behavioral personality questionnaries (Costa and McCrae, 1992; Goldberg et al., 2006). We hypothesize that similar behavior shall be predictive for extraversion of fictional characters as perceived by the readers. 5.1 Action e</context>
<context position="34050" citStr="Neuman and Cohen, 2014" startWordPosition="5364" endWordPosition="5367">ften hope or wish for something they might like to do. Additionally, semantic classes Social and Family, reported as correlated to extraversion by Pennebaker and King (1999) and not confirmed in our first model, became predictive in protaonists’ actions. 5.4 Discussion Also in this task, the VerbNet classes brought significant improvement in performance. The classification model based on actions outperforms not only the direct speech model, but also the state-of-the-art systems predicting authors’ extraversion from the stream-of-consciousness essays (Mairesse et al., 2007; Celli et al., 2013; Neuman and Cohen, 2014). While surely not directly comparable, this result hints to the fact that the personality is easier to detect from behavior than from person’s verbal expression. This would correspond to the findings of Mairesse et al. (2007), Biel and Gatica-Perez (2013) and Aran and Gatica-Perez (2013) on multimodal data sets. 6 Predicatives of fictional characters Our third extraversion prediction system is subordinate to how fictional characters are described and to the manners in which they behave. We are not aware of a previous NLP work predicting extraversion using descriptive adjectives of the persons</context>
</contexts>
<marker>Neuman, Cohen, 2014</marker>
<rawString>Yair Neuman and Yochai Cohen. 2014. A vectorial semantics approach to personality assessment. Scientific reports, 4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Nowson</author>
<author>Jon Oberlander</author>
<author>Alastair J Gill</author>
</authors>
<title>Weblogs, genres and individual differences.</title>
<date>2005</date>
<booktitle>In Proceedings of the 27th Annual Conference of the Cognitive Science Society,</booktitle>
<volume>1666</volume>
<pages>1671</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="27548" citStr="Nowson et al. (2005)" startWordPosition="4307" endWordPosition="4310">case can be a pure villain (Draco Malfoy, Joffrey Baratheon...) as well as a friendly companion (Gimli, Ron Weasley...), while the evil extravert types are possibly rarer in the experiments on human writing, or are more likely to fit under the MBTI definition of extraversion than FFM facets. Another potential cause, based on the error analysis, is the different target of the same sentiment for extraverts and introverts. For example, the ngram ”I fear” is highly predictive for an introvert in our data while extraverts would rather use formulations to imply that others should fear. Similarly to Nowson et al. (2005), we did not find any difference in the formality measure of Heylighen and Dewaele (2002). Neither we did in the complexity of sentences as per the parse tree depth 1810 and sentence length. It is probable that these aspects were also impacted by our broad variety of author style (F. Dostoyevsky vs J. K. Rowling). Our basic vector-based features carried no useful information in our case, in contrast to the personality research of Neuman and Cohen (2014). We observed that the factual content of the stories contributed to the character similarity measure more than the subtle personality differen</context>
</contexts>
<marker>Nowson, Oberlander, Gill, 2005</marker>
<rawString>Scott Nowson, Jon Oberlander, and Alastair J. Gill. 2005. Weblogs, genres and individual differences. In Proceedings of the 27th Annual Conference of the Cognitive Science Society, volume 1666, page 1671. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Nowson</author>
</authors>
<title>Identifying more bloggers: Towards large scale personality classification of personal weblogs. In</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Weblogs and Social.</booktitle>
<contexts>
<context position="8466" citStr="Nowson, 2007" startWordPosition="1262" endWordPosition="1263">nd Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55% (Nowson, 2007; Estival et al., 2007). More recent work in this area focuses on the personality prediction in social networks (Kosinski et al., 2013; Kosinski et al., 2014) and multimodal personality prediction (Biel and Gatica-Perez, 2013; Aran and Gatica-Perez, 2013). These trends emphasized the correlation of network features and audiovisual features with extraversion, giving rise to the Workshop on Computational Personality Recognition (for an overview see (Celli et al., 2013; Celli et al., 2014). 1806 3 Data set construction Traditionally, the gold standard for this supervised classification task is ob</context>
</contexts>
<marker>Nowson, 2007</marker>
<rawString>Scott Nowson. 2007. Identifying more bloggers: Towards large scale personality classification of personal weblogs. In In Proceedings of the International Conference on Weblogs and Social.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Oberlander</author>
<author>Scott Nowson</author>
</authors>
<title>Whose thumb is it anyway? classifying author personality from weblog text.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster</booktitle>
<pages>sessions.</pages>
<contexts>
<context position="7852" citStr="Oberlander and Nowson (2006)" startWordPosition="1173" endWordPosition="1176">earch on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classification accuracy of 50-56% on extraversion in text and 47-57% in speech, using word ngrams, LIWC, MRC psycholinguistic database (Coltheart, 1981) and prosodic features. Additional improvement is reported when the extraversion was labeled by external judges rather than by self-testing. Extended studies on larger datasets achieve accuracies around 55%</context>
</contexts>
<marker>Oberlander, Nowson, 2006</marker>
<rawString>Jon Oberlander and Scott Nowson. 2006. Whose thumb is it anyway? classifying author personality from weblog text. In Proceedings of the COLING/ACL on Main conference poster sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim O’Keefe</author>
<author>Silvia Pareti</author>
<author>James R Curran</author>
<author>Irena Koprinska</author>
<author>Matthew Honnibal</author>
</authors>
<title>A sequence labelling approach to quote attribution.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>790--799</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>O’Keefe, Pareti, Curran, Koprinska, Honnibal, 2012</marker>
<rawString>Tim O’Keefe, Silvia Pareti, James R. Curran, Irena Koprinska, and Matthew Honnibal. 2012. A sequence labelling approach to quote attribution. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 790–799. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Passant</author>
</authors>
<title>dbrec music recommendations using DBpedia.</title>
<date>2010</date>
<booktitle>In The Semantic Web–ISWC</booktitle>
<pages>209--224</pages>
<contexts>
<context position="4860" citStr="Passant, 2010" startWordPosition="695" endWordPosition="696">entations. We evaluate three machine learning models based on the speech (Section 4), actions (Section 5) and predicatives (Section 6) of the protagonists, and show that especially on the direct speech and action data the lexical-semantic features significantly outperform the baselines. Qualitative analysis reveals that the most predictive features correspond to reported findings in psychology and NLP. 2 Related work Research in the the area of content-based recommendation systems have shown that incorporating semantic information is valuable for the user and leads to measurable improvements (Passant, 2010; Di Noia et al., 2012; Heitmann and Hayes, 2010). De Clercq et al. (2014) incorporated semantic frames from FrameNet into the recommendation system for books. They represent the plot of each book with a sequence of ca. 200 semantic frames and has shown that the frame information (such as Killing - Revenge - Death) outperforms the bag-of-words approach.Recent NLP experiments begin to reveal the importance of entitycentric models in a variety of tasks. Chambers (2013) show improvement in event schema induction by learning entity-centric rules (e.g., a victim is likely to be a person). Bamman et</context>
</contexts>
<marker>Passant, 2010</marker>
<rawString>Alexandre Passant. 2010. dbrec music recommendations using DBpedia. In The Semantic Web–ISWC 2010, pages 209–224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Laura A King</author>
</authors>
<title>Linguistic styles: language use as an individual difference. Journal of personality and social psychology,</title>
<date>1999</date>
<pages>77--6</pages>
<contexts>
<context position="7501" citStr="Pennebaker and King, 1999" startWordPosition="1117" endWordPosition="1120">usually adjusted to the experiment focus (e.g. emotions, relationships, ambitions). As McCrae et al. () point out, a standard set of personality traits, that encompass the full range of characteristics found in all characters in literature (p.77), is needed for a better comparison. Hence we base our present study primarily on the previous NLP research on personality prediction of human individuals. Correlations between lexical and stylistic aspects of text and the five FFM personality traits of the author have been found in numerous experiments, with extraversion receiving the most attention (Pennebaker and King, 1999; Dewaele and Furnham, 1999; Gill and Oberlander, 2002; Mehl et al., 2006; Aran and Gatica-Perez, 2013; Lepri et al., 2010). The LIWC lexicon (Pennebaker et al., 2001) established its position as a powerful mean of such analysis. The first machine learning experiments in this area were conducted by Argamon et al. (2005), Oberlander and Nowson (2006) and Mairesse et al. (2007). Researchers predicted the five personality traits of the authors of stream-ofconscientiousness essays, blog posts and recorded conversation snippets. Given balanced data sets, Mairesse et al. (2007) report binary classif</context>
<context position="24987" citStr="Pennebaker and King (1999)" startWordPosition="3917" endWordPosition="3920">ormative. The most predictive features from each group are listed in Table 3 together with their correlation merit (Hall, 1999), and compared with previous work in Table 4. Feature I/E Ref Feature I/E Ref Predictive also in our data: No effect in our data: Pronoun ’we’ -/+ [3] Neg. emot. +/- [1] Tentative, unsure +/- [1] Pos. emot. -/+ [1] Exclusive +/- [1] Self-ref. -/+ [1] Inclusive -/+ [1] Formality +/- [2] Insight +/- [1] Elaborated +/- [3] Nouns, articles +/- Long sent. +/- Lexical richness +/- Social -/+ Negations +/- [2] Body functions -/+ [2] Interjections -/+ [3] Source ID Author [1] Pennebaker and King (1999) [2] Dewaele and Furnham (1999) [3] Mairesse et al. (2007) Table 4: Comparison of our results to previously reported predictive features for speaker’s extraversion (E), resp. introversion (I). We list publications where these features were, to our knowledge, reported as novel. In accordance with the experiments of Pennebaker and King (1999), we observe more frequent exclusions (e.g. without, but), hedging and negation expressed by introverts, and inclusion (e.g. with, and) by extraverts. Extraverts talk more in first person plural, use more back-channels and interjections, and talk more about </context>
<context position="33600" citStr="Pennebaker and King (1999)" startWordPosition="5297" endWordPosition="5300">verts and introverts as assessed in the IPIP personality questionaire, compared to our most informative features often bring or hold something. Introverts, on the other hand, seem to favor slow movements - while they are thinking, reflecting, creating, looking for explanations and find out solutions, they tend to lie down, sit or walk, eventually even sleep or snooze. The uncertainty typical for introverts is also notable in their actions, as they often hope or wish for something they might like to do. Additionally, semantic classes Social and Family, reported as correlated to extraversion by Pennebaker and King (1999) and not confirmed in our first model, became predictive in protaonists’ actions. 5.4 Discussion Also in this task, the VerbNet classes brought significant improvement in performance. The classification model based on actions outperforms not only the direct speech model, but also the state-of-the-art systems predicting authors’ extraversion from the stream-of-consciousness essays (Mairesse et al., 2007; Celli et al., 2013; Neuman and Cohen, 2014). While surely not directly comparable, this result hints to the fact that the personality is easier to detect from behavior than from person’s verbal</context>
</contexts>
<marker>Pennebaker, King, 1999</marker>
<rawString>James W. Pennebaker and Laura A. King. 1999. Linguistic styles: language use as an individual difference. Journal of personality and social psychology, 77(6):1296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Pennington</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
</authors>
<title>Glove: Global vectors for word representation.</title>
<date>2014</date>
<booktitle>Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014),</booktitle>
<pages>12</pages>
<contexts>
<context position="21318" citStr="Pennington et al., 2014" startWordPosition="3346" endWordPosition="3350">uency of each dependency obtained from the Stanford Parser. We additionally capture the frequency of superlatives, comparatives and modal verbs, the proportion of verbs in present, past and future tense, and the formality of the language as per the part-of-speech-based formality coefficient (Heylighen and Dewaele, 2002), and measure the average depth of the parse trees. Word embeddings as features Since vector space semantics has been beneficial for predicting author’s personality in previous work (Neuman and Cohen, 2014), we use a pre-trained word vector model created by the GloVe algorithm (Pennington et al., 2014) on English Wikipedia. GloVe employs a global log-bilinear regression model that combines the advantages of the global matrix factorization and local context window methods. We assign the resulting 300-dimensional vectors to the words in character’s direct speech, excluding stopwords, and calculate an average vector for each character. We calculate for each test character the cosine similarity to the mean vector of extravert, resp. introvert, in the training data, and to each character in the training set individually using the DL4J NLP package7. We consider both the final scalar outcome and t</context>
</contexts>
<marker>Pennington, Socher, Manning, 2014</marker>
<rawString>Jeffrey Pennington, Richard Socher, and Christopher D Manning. 2014. Glove: Global vectors for word representation. Proceedings of the Empiricial Methods in Natural Language Processing (EMNLP 2014), 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David J Pittenger</author>
</authors>
<title>Cautionary comments regarding the myers-briggs type indicator.</title>
<date>2005</date>
<journal>Consulting Psychology Journal: Practice and Research,</journal>
<volume>57</volume>
<issue>3</issue>
<contexts>
<context position="9844" citStr="Pittenger, 2005" startWordPosition="1471" endWordPosition="1472"> characters. However, strong correlations have been found between the self-reported and perceived personality traits (Mehl et al., 2006). Our gold standard benefits from the fact that readers enjoy discussing the personality of their favourite book character online. A popular layman instrument for personality classification is the Myers-Brigggs Type Indicator (Myers et al., 1985), shortly MBTI, which sorts personal preferences into four opposite pairs, or dichotomies, such as Thinking vs. Feeling or Judging vs. Perceiving. While the MBTI validity has been questioned by the research community (Pittenger, 2005), the Extraversion scale is showing rather strong validity and correlation to similar trait in the Five-Factor Model (McCrae and Costa, 1989; MacDonald et al., 1994). Our study hence focuses on the Extraversion scale. Our data was collected from the collaboratively constructed Personality Databank2 where the readers can vote if a book character is, among other aspects, introverted or extraverted. While the readers used codes based on the MBTI typology, they did not apply the MBTI assessment strategies. There was no explicit annotation guideline and the interpretation was left to readers’ intui</context>
</contexts>
<marker>Pittenger, 2005</marker>
<rawString>David J. Pittenger. 2005. Cautionary comments regarding the myers-briggs type indicator. Consulting Psychology Journal: Practice and Research, 57(3):210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter J Rentfrow</author>
<author>Lewis R Goldberg</author>
<author>Daniel J Levitin</author>
</authors>
<title>The structure of musical preferences: a five-factor model. Journal of personality and social psychology,</title>
<date>2011</date>
<pages>100--6</pages>
<contexts>
<context position="2444" citStr="Rentfrow et al., 2011" startWordPosition="338" endWordPosition="341">Goldberg, 1990), which is wellknown and widely accepted in psychology and other research fields. The FFM defines personality along five bipolar scales: Extraversion (sociable vs. reserved), Emotional stability (secure vs. neurotic), Agreeableness (friendly vs. unsympathic), Conscientiousness (organized vs. careless) and Openness to experience (insightful vs. unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008; Rentfrow et al., 2011). It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009). Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999). More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is revealed only later in the story. We therefore hypothesize that readers might have</context>
</contexts>
<marker>Rentfrow, Goldberg, Levitin, 2011</marker>
<rawString>Peter J. Rentfrow, Lewis R. Goldberg, and Daniel J. Levitin. 2011. The structure of musical preferences: a five-factor model. Journal of personality and social psychology, 100(6):1139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>David Bamman</author>
<author>Brendan OConnor</author>
</authors>
<title>Learning latent personas of film characters.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5495" citStr="Smith et al. (2013)" startWordPosition="804" endWordPosition="807">, 2012; Heitmann and Hayes, 2010). De Clercq et al. (2014) incorporated semantic frames from FrameNet into the recommendation system for books. They represent the plot of each book with a sequence of ca. 200 semantic frames and has shown that the frame information (such as Killing - Revenge - Death) outperforms the bag-of-words approach.Recent NLP experiments begin to reveal the importance of entitycentric models in a variety of tasks. Chambers (2013) show improvement in event schema induction by learning entity-centric rules (e.g., a victim is likely to be a person). Bamman et al. (2014) and Smith et al. (2013) present latent variable models for unsupervised learning of latent character types in movie plot summaries and in English novels, taking authorial style into account. However, even the state-of-the-art NLP work rather describes personas of fictional characters by their role in the story - e.g., action hero, valley girl, best friend, villain etc. - or by their relations to other characters, such as mother or daughter (Elson et al., 2010; Kokkinakis and Malm, 2011), rather than by their inner preferences and motivations. It is important to note here that determining a personality of a character</context>
</contexts>
<marker>Smith, Bamman, OConnor, 2013</marker>
<rawString>Noah A. Smith, David Bamman, and Brendan OConnor. 2013. Learning latent personas of film characters. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Terracciano</author>
<author>Corinna E L¨ockenhoff</author>
<author>Rosa M Crum</author>
<author>O Joseph Bienvenu</author>
<author>Paul T Costa</author>
</authors>
<title>Five-factor model personality profiles of drug users.</title>
<date>2008</date>
<journal>BMC Psychiatry,</journal>
<volume>8</volume>
<issue>1</issue>
<marker>Terracciano, L¨ockenhoff, Crum, Bienvenu, Costa, 2008</marker>
<rawString>Antonio Terracciano, Corinna E. L¨ockenhoff, Rosa M. Crum, O .Joseph Bienvenu, and Paul T. Costa. 2008. Five-factor model personality profiles of drug users. BMC Psychiatry, 8(1):22.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Tirre</author>
<author>Sharvari Dixit</author>
</authors>
<title>Reading interests: Their dimensionality and correlation with personality and cognitive factors. Personality and Individual Differences,</title>
<date>1995</date>
<contexts>
<context position="2561" citStr="Tirre and Dixit, 1995" startWordPosition="356" endWordPosition="359">nality along five bipolar scales: Extraversion (sociable vs. reserved), Emotional stability (secure vs. neurotic), Agreeableness (friendly vs. unsympathic), Conscientiousness (organized vs. careless) and Openness to experience (insightful vs. unimaginative). Psychologists have shown that these five personality traits are stable across individual lifespan, demographical and cultural differences (John and Srivastava, 1999) and affect many life aspects. (Terracciano et al., 2008; Rentfrow et al., 2011). It has been shown that the personality traits of readers impact their literature preferences (Tirre and Dixit, 1995; Mar et al., 2009). Psychology researchers also found that perceived similarity is predictive of interpersonal attraction (Montoya et al., 2008; Byrne, 1961; Chartrand and Bargh, 1999). More explicitly, recent research (Kaufman and Libby, 2012) shows that readers of a narrative develop more favorable attitudes and less stereotype application towards a character, if his difference (e.g. racial) is revealed only later in the story. We therefore hypothesize that readers might have a preference for reading novels depicting fictional characters that are similar to themselves. Finding a direct link</context>
</contexts>
<marker>Tirre, Dixit, 1995</marker>
<rawString>William C. Tirre and Sharvari Dixit. 1995. Reading interests: Their dimensionality and correlation with personality and cognitive factors. Personality and Individual Differences, 18(6):731–738.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>