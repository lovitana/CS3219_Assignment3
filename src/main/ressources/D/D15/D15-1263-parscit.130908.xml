<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002314">
<title confidence="0.984275">
Better Document-level Sentiment Analysis from RST Discourse Parsing∗
</title>
<author confidence="0.990357">
Parminder Bhatia and Yangfeng Ji and Jacob Eisenstein
</author>
<affiliation confidence="0.9983575">
School of Interactive Computing
Georgia Institute of Technology
</affiliation>
<address confidence="0.984033">
Atlanta, GA 30308
</address>
<email confidence="0.998744">
parminder.bhatia243@gmail.com, {jiyfeng,jacobe}@gatech.edu
</email>
<sectionHeader confidence="0.99387" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999888882352941">
Discourse structure is the hidden link be-
tween surface features and document-level
properties, such as sentiment polarity. We
show that the discourse analyses produced
by Rhetorical Structure Theory (RST)
parsers can improve document-level senti-
ment analysis, via composition of local in-
formation up the discourse tree. First, we
show that reweighting discourse units ac-
cording to their position in a dependency
representation of the rhetorical structure
can yield substantial improvements on
lexicon-based sentiment analysis. Next,
we present a recursive neural network
over the RST structure, which offers sig-
nificant improvements over classification-
based methods.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99625165">
Sentiment analysis and opinion mining are among
the most widely-used applications of language
technology, impacting both industry and a vari-
ety of other academic disciplines (Feldman, 2013;
Liu, 2012; Pang and Lee, 2008). Yet senti-
ment analysis is still dominated by bag-of-words
approaches, and attempts to include additional
linguistic context typically stop at the sentence
level (Socher et al., 2013). Since document-level
opinion mining inherently involves multi-sentence
texts, it seems that analysis of document-level
structure should have a role to play.
A classic example of the potential relevance of
discourse to sentiment analysis is shown in Fig-
ure 1. In this review of the film The Last Samu-
rai, the positive sentiment words far outnumber
the✿✿✿✿✿✿✿✿
negative✿✿✿✿✿✿✿✿✿ sentiment words. But the discourse
structure — indicated here with Rhetorical Struc-
ture Theory (RST; Mann and Thompson, 1988) —
</bodyText>
<footnote confidence="0.793676">
∗Code is available at https://github.com/
parry2403/R2N2
</footnote>
<sectionHeader confidence="0.9678765" genericHeader="introduction">
CONCESSION
CONJUNCTION
</sectionHeader>
<bodyText confidence="0.897592">
[It could have been a great movie]1A [It does have
beautiful sceneryj1B [some of the best since Lord of
the Rings.]1C [The acting is well donej1D [and I really
liked the son of the leader of the Samurai.]1E [He was
a likable chapj1F [and I ✿✿✿✿
hated to see him die.]1G [But,
other than all that, this movie is ✿✿✿✿✿✿
nothing more than hid-
</bodyText>
<equation confidence="0.355879">
den✿✿✿✿✿
rip-offs.]1H
</equation>
<figureCaption confidence="0.999054">
Figure 1: Example adapted from Voll and Taboada
</figureCaption>
<bodyText confidence="0.986905421052632">
(2007).
clearly favors the final sentence, whose polarity
is negative. This example is illustrative in more
than one way: it was originally identified by Voll
and Taboada (2007), who found that manually-
annotated RST parse trees improved lexicon-
based sentiment analysis, but that automatically-
generated parses from the SPADE parser (Soricut
and Marcu, 2003), which was then state-of-the-art,
did not.
Since this time, RST discourse parsing has im-
proved considerably, with the best systems now
yielding 5-10% greater raw accuracy than SPADE,
depending on the metric. The time is therefore
right to reconsider the effectiveness of RST for
document-level sentiment analysis. In this pa-
per, we present two different ways of combin-
ing RST discourse parses with sentiment analy-
sis. The methods are both relatively simple, and
</bodyText>
<figure confidence="0.978710307692308">
1A
❘
JUSTIFY
✠
1H
ELABORATION
1D
JUSTIFY
✠
✠
1B 1C
1E CONJUNCTION
1F 1G
</figure>
<page confidence="0.9501">
2212
</page>
<note confidence="0.671373">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2212–2218,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.502910333333333">
can be used in combination with an “off the shelf”
discourse parser. We consider the following two
architectures:
</bodyText>
<listItem confidence="0.9977769">
• Reweighting the contribution of each dis-
course unit, based on its position in a
dependency-like representation of the dis-
course structure. Such weights can be de-
fined using a simple function, or learned from
a small of data.
• Recursively propagating sentiment up
through the RST parse, in an architecture in-
spired by recursive neural networks (Smolen-
sky, 1990; Socher et al., 2011).
</listItem>
<bodyText confidence="0.99929425">
Both architectures can be used in combination
with either a lexicon-based sentiment analyzer, or
a trained classifier. Indeed, for users whose start-
ing point is a lexicon-based approach, a simple
RST-based reweighting function can offer signif-
icant improvements. For those who are willing
to train a sentiment classifier, the recursive model
yields further gains.
</bodyText>
<sectionHeader confidence="0.993724" genericHeader="method">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.999362">
2.1 Rhetorical Structure Theory
</subsectionHeader>
<bodyText confidence="0.999977047619047">
RST is a compositional model of discourse struc-
ture, in which elementary discourse units (EDUs)
are combined intro progressively larger discourse
units, ultimately covering the entire document.
Discourse relations may involve a nucleus and a
satellite, or they may be multinuclear. In the ex-
ample in Figure 1, the unit 1C is the satellite of
a relationship with its nucleus 1B; together they
form a larger discourse unit, which is involved in
a multinuclear CONJUNCTION relation.
The nuclearity structure of RST trees suggests
a natural approach to evaluating the importance
of segments of text: satellites tend to be less
important, and nucleii tend to be more impor-
tant (Marcu, 1999). This idea has been leveraged
extensively in document summarization (Gerani
et al., 2014; Uzˆeda et al., 2010; Yoshida et
al., 2014), and was the inspiration for Voll and
Taboada (2007), who examined intra-sentential re-
lations, eliminating all words except those in the
top-most nucleus within each sentence. More re-
cent work focuses on reweighting each discourse
unit depending on the relations in which it partic-
ipates (Heerschop et al., 2011; Hogenboom et al.,
2015). We consider such an approach, and com-
pare it with a compositional method, in which sen-
timent polarity is propagated up the discourse tree.
Marcu (1997) provides the seminal work on
automatic RST parsing, but there has been a re-
cent spike of interest in this task, with contempo-
rary approaches employing discriminative learn-
ing (Hernault et al., 2010), rich features (Feng
and Hirst, 2012), structured prediction (Joty et al.,
2015), and representation learning (Ji and Eisen-
stein, 2014; Li et al., 2014). With many strong
systems to choose from, we employ the publicly-
available DPLP parser (Ji and Eisenstein, 2014),1.
To our knowledge, this system currently gives the
best F-measure on relation identification, the most
difficult subtask of RST parsing. DPLP is a shift-
reduce parser (Sagae, 2009), and its time complex-
ity is linear in the length of the document.
</bodyText>
<subsectionHeader confidence="0.999963">
2.2 Sentiment analysis
</subsectionHeader>
<bodyText confidence="0.999937933333333">
There is a huge literature on sentiment analy-
sis (Pang and Lee, 2008; Liu, 2012), with partic-
ular interest in determining the overall sentiment
polarity (positive or negative) of a document. Bag-
of-words models are widely used for this task, as
they offer accuracy that is often very competitive
with more complex approaches. Given labeled
data, supervised learning can be applied to obtain
sentiment weights for each word. However, the
effectiveness of supervised sentiment analysis de-
pends on having training data in the same domain
as the target, and this is not always possible. More-
over, in social science applications, the desired
labels may not correspond directly to positive or
negative sentiment, but may focus on other cat-
egories, such as politeness (Danescu-Niculescu-
Mizil et al., 2013), narrative frames (Jurafsky et
al., 2014), or a multidimensional spectrum of emo-
tions (Kim et al., 2012). In these cases, labeled
documents may not be available, so users of-
ten employ a simpler method: counting matches
against lists of words associated with each cate-
gory. Such lists may be built manually from intro-
spection, as in LIWC (Tausczik and Pennebaker,
2010) and the General Inquirer (Stone, 1966). Al-
ternatively, they may be induced by bootstrapping
from a seed set of words (Hatzivassiloglou and
McKeown, 1997; Taboada et al., 2011). While
lexicon-based methods may be less accurate than
supervised classifiers, they are easier to apply to
</bodyText>
<footnote confidence="0.962244">
1https://github.com/jiyfeng/DPLP
</footnote>
<page confidence="0.966484">
2213
</page>
<figure confidence="0.9683735">
1H
1A
</figure>
<figureCaption confidence="0.905448">
Figure 2: Dependency-based discourse tree repre-
sentation of the discourse in Figure 1
</figureCaption>
<bodyText confidence="0.999315">
new domains and problem settings. Our proposed
approach can be used in combination with either
method for sentiment analysis, and in principle,
could be directly applied to other document-level
categories, such as politeness.
</bodyText>
<subsectionHeader confidence="0.985724">
2.3 Datasets
</subsectionHeader>
<bodyText confidence="0.999972785714286">
We evaluate on two review datasets. In both cases,
the goal is to correctly classify the opinion po-
larity as positive or negative. The first dataset
is comprised of 2000 movie reviews, gathered by
Pang and Lee (2004). We perform ten-fold cross-
validation on this data. The second dataset is
larger, consisting of 50,000 movie reviews, gath-
ered by Socher et al. (2013), with a predefined
50/50 split into training and test sets. Documents
are scored on a 1-10 scale, and we treat scores
G 4 as negative, &gt; 7 as positive, and ignore scores
of 5-6 as neutral — although in principle nothing
prevents extension of our approaches to more than
two sentiment classes.
</bodyText>
<sectionHeader confidence="0.966047" genericHeader="method">
3 Discourse depth reweighting
</sectionHeader>
<bodyText confidence="0.999821038461538">
Our first approach to incorporating discourse in-
formation into sentiment analysis is based on
quantifying the importance of each unit of text in
terms of its discourse depth. To do this, we em-
ploy the dependency-based discourse tree (DEP-
DT) formulation from prior work on summariza-
tion (Hirao et al., 2013). The DEP-DT formal-
ism converts the constituent-like RST tree into
a directed graph over elementary discourse units
(EDUs), in a process that is a close analogue of the
transformation of a headed syntactic constituent
parse to a syntactic dependency graph (K¨ubler et
al., 2009).
The DEP-DT representation of the discourse in
Figure 1 in shown in Figure 2. The graph is con-
structed by propagating “head” information up the
RST tree; if the elementary discourse unit ei is the
satellite in a discourse relation headed by ej, then
there is an edge from ej to ei. Thus, the “depth”
of each EDU is the number of times in which it is
embedded in the satellite of a discourse relation.
The exact algorithm for constructing DEP-DTs is
given by Hirao et al. (2013).
Given this representation, we construct a simple
linear function for weighting the contribution of
the EDU at depth di:
</bodyText>
<equation confidence="0.989918">
λi = max(0.5,1 − di/6). (1)
</equation>
<bodyText confidence="0.999657428571428">
Thus, at di = 0, we have λi = 1, and at di &gt; 3, we
have λi = 0.5. Now assume each elementary dis-
course unit contributes a prediction Oi = θTwi,
where wi is the bag-of-words vector, and θ is a
vector of weights, which may be either learned or
specified by a sentiment lexicon. Then the overall
prediction for a document is given by,
</bodyText>
<equation confidence="0.991775">
Y: Ψ = Y: λi(θ�wi) = θ�( λiwi). (2)
i i
</equation>
<bodyText confidence="0.999859181818182">
Evaluation We apply this approach in combi-
nation with both lexicon-based and classification-
based sentiment analysis. We use the lexicon of
Wilson et al. (2005), and set θj = 1 for words
marked “positive”, and θj = −1 for words marked
negative. For classification-based analysis, we set
θ equal to the weights obtained by training a logis-
tic regression classifier, tuning the regularization
coefficient on held-out data.
Results are shown in Table 1. As seen in
the comparison between lines B1 and D1, dis-
course depth weighting offers substantial improve-
ments over the bag-of-words approach for lexicon-
based sentiment analysis, with raw improvements
of 4−5%. Given the simplicity of this approach —
which requires only a sentiment lexicon and a dis-
course parser — we strongly recommend the ap-
plication of discourse depth weighting for lexicon-
based sentiment analysis at the document level.
However, the improvements for the classification-
based models are considerably smaller, less than
1% in both datasets.
</bodyText>
<sectionHeader confidence="0.997106" genericHeader="method">
4 Rhetorical Recursive Neural Networks
</sectionHeader>
<bodyText confidence="0.999770714285714">
Discourse-depth reweighting offers significant im-
provements for lexicon-based sentiment analy-
sis, but the improvements over the more accurate
classification-based method are meager. We there-
fore turn to a data-driven approach for combining
sentiment analysis with rhetorical structure theory,
based on recursive neural networks (Socher et al.,
</bodyText>
<equation confidence="0.8047965">
1D 1E
1F 1G
1B
1C
</equation>
<page confidence="0.859511">
2214
</page>
<table confidence="0.9798511">
Pang &amp; Lee Socher et al.
Baselines
B1. Lexicon 68.3 74.9
B2. Classifier 82.4 81.5
Discourse depth weighting
D1. Lexicon 72.6 78.9
D2. Classifier 82.9 82.0
Rhetorical recursive neural network
R1. No relations 83.4 85.5
R2. With relations 84.1 85.6
</table>
<tableCaption confidence="0.808532333333333">
Table 1: Sentiment classification accuracies on
two movie review datasets (Pang and Lee, 2004;
Socher et al., 2013), described in Section 2.3.
</tableCaption>
<bodyText confidence="0.9988855">
2011). The idea is simple: recursively propagate
sentiment scores up the RST tree, until the root of
the document is reached. For nucleus-satellite dis-
course relations, we have:
</bodyText>
<equation confidence="0.996955666666667">
IFi = tanh(K(ri)
n IFn(i) + K(ri)
s IFs(i)), (3)
</equation>
<bodyText confidence="0.7886832">
where i indexes a discourse unit composed from
relation ri, n(i) indicates its nucleus, and s(i) in-
dicates its satellite. Returning to the example in
Figure 1, the sentiment score for the discourse unit
obtained by combining 1B and 1C is obtained
</bodyText>
<equation confidence="0.840813">
(elaboration) (elaboration)
</equation>
<bodyText confidence="0.7847605">
from tanh(Kn IF 1B + Ks IF1C).
Similarly, for multinuclear relations, we have,
</bodyText>
<equation confidence="0.988146666666667">
IFi = tanh( � K(ri)
n IFj). (4)
j∈n(i)
</equation>
<bodyText confidence="0.999996756756756">
In the base case, each elementary discourse unit’s
sentiment is constructed from its bag-of-words,
IFi = θTwi. Because the structure of each doc-
ument is different, the network architecture varies
in each example; nonetheless, the parameters can
be reused across all instances.
This approach, which we call a Rhetorical Re-
cursive Neural Network (R2N2), is reminiscent of
the compositional model proposed by Socher et al.
(2013), where composition is over the constituents
of the syntactic parse of a sentence, rather than
the units of a discourse. However, a crucial differ-
ence is that in R2N2s, the elements IF and K are
scalars: we do not attempt to learn a latent dis-
tributed representation of the sub-document units.
This is because discourse units typically comprise
multiple words, so that accurate analysis of the
sentiment for elementary discourse units is not so
difficult as accurate analysis of individual words.
The scores for individual discourse units can be
computed from a bag-of-words classifier, or, in fu-
ture work, from a more complex model such as a
recursive or recurrent neural network.
While this neural network structure captures
the idea of compositionality over the RST tree,
the most deeply embedded discourse units can be
heavily down-weighted by the recursive compo-
sition (assuming Ks &lt; Kn): in the most ex-
treme case of a right-branching or left-branching
structure, the recursive operator may be applied N
times to the most deeply embedded EDU. In con-
trast, discourse depth reweighting applies a uni-
form weight of 0.5 to all discourse units with depth
&gt; 3. In the spirit of this approach, we add an addi-
tional component to the network architecture, cap-
turing the bag-of-words for the entire document.
Thus, at the root node we have:
</bodyText>
<equation confidence="0.995619">
�IFdoc = γθ�( wi) + IFrst-root, (5)
i
</equation>
<bodyText confidence="0.9997841">
with IFrst-root defined recursively from Equations 3
and 4, θ indicating the vector of per-word weights,
and the scalar γ controlling the tradeoff between
these two components.
Learning R2N2 is trained by backpropagating
from a hinge loss objective; assuming yt E
1−1, 11 for each document t, we have the loss
Lt = (1 − ytIFdoc,t)+. From this loss, we
use backpropagation through structure to obtain
gradients on the parameters (Goller and Kuch-
ler, 1996). Training is performed using stochas-
tic gradient descent. For simplicity, we fol-
low Zirn et al. (2011) and focus on the dis-
tinction between contrastive and non-contrastive
relations. The set of contrastive relations in-
cludes CONTRAST, COMPARISON, ANTITHE-
SIS, ANTITHESIS-E, CONSEQUENCE-S, CON-
CESSION, and PROBLEM-SOLUTION.
Evaluation Results for this approach are shown
in lines R1 and R2 of Table 1. Even without dis-
tinguishing between discourse relations, we get an
improvement of more than 3% accuracy on the
Stanford data, and 0.5% on the smaller Pang &amp;
Lee dataset. Adding sensitivity to discourse rela-
tions (distinguishing K(r) for contrastive and non-
contrastive relations) offers further improvements
on the Pang &amp; Lee data, outperforming the base-
line classifier (D2) by 1.3%.
The accuracy of discourse relation detection is
only 60% for even the best systems (Ji and Eisen-
</bodyText>
<page confidence="0.969054">
2215
</page>
<bodyText confidence="0.9999685">
stein, 2014), which may help to explain why re-
lations do not offer a more substantial boost. An
anonymous reviewer recommended evaluating on
gold RST parse trees to determine the extent to
which improvements in RST parsing might trans-
fer to downstream document analysis. Such an
evaluation would seem to require a large corpus of
texts with both gold RST parse trees and sentiment
polarity labels; the SFU Review Corpus (Taboada,
2008) of 30 review texts offers a starting point, but
is probably too small to train a competitive senti-
ment analysis system.
</bodyText>
<sectionHeader confidence="0.999927" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999864509090909">
Section 2 mentions some especially relevant prior
work. Other efforts to incorporate RST into
sentiment analysis have often focused on intra-
sentential discourse relations (Heerschop et al.,
2011; Zhou et al., 2011; Chenlo et al., 2014),
rather than relations over the entire document.
Wang et al. (2012) address sentiment analysis in
Chinese. Lacking a discourse parser, they focus
on explicit connectives, using a strategy that is re-
lated to our discourse depth reweighting. Wang
and Wu (2013) use manually-annotated discourse
parses in combination with a sentiment lexicon,
which is automatically updated based on the dis-
course structure. Zirn et al. (2011) use an RST
parser in a Markov Logic Network, with the goal
of making polarity predictions at the sub-sentence
level, rather than improving document-level pre-
diction. None of the prior work considers the sort
of recurrent compositional model presented here.
An alternative to RST is to incorporate “shal-
low” discourse structure, such as the relations
from the Penn Discourse Treebank (PDTB).
PDTB relations were shown to improve sentence-
level sentiment analysis by Somasundaran et al.
(2009), and were incorporated in a model of sen-
timent flow by Wachsmuth et al. (2014). PDTB
relations are often signaled with explicit discourse
connectives, and these may be used as a fea-
ture (Trivedi and Eisenstein, 2013; Lazaridou et
al., 2013) or as posterior constraints (Yang and
Cardie, 2014). This prior work on discourse rela-
tions within sentences and between adjacent sen-
tences can be viewed as complementary to our fo-
cus on higher-level discourse relations across the
entire document.
There are unfortunately few possibilities for
direct comparison of our approach against prior
work. Heerschop et al. (2011) and Wachsmuth et
al. (2014) also employ the Pang and Lee (2004)
dataset, but neither of their results are directly
comparable: Heerschop et al. (2011) exclude doc-
uments that SPADE fails to parse, and Wachsmuth
et al. (2014) evaluates only on individual sentences
rather than entire documents. The only possi-
ble direct comparison is with very recent work
from Hogenboom et al. (2015), who employ a
weighting scheme that is similar to the approach
described in Section 3. They evaluate on the Pang
and Lee data, and consider only lexicon-based
sentiment analysis, obtaining document-level ac-
curacies between 65% (for the baseline) and 72%
(for their best discourse-augmented system). Ta-
ble 1 shows that fully supervised methods give
much stronger performance on this dataset, with
accuracies more than 10% higher.
</bodyText>
<sectionHeader confidence="0.997497" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.994384933333333">
Sentiment polarity analysis has typically relied
on a “preponderance of evidence” strategy, hop-
ing that the words or sentences representing the
overall polarity will outweigh those representing
counterpoints or rhetorical concessions. How-
ever, with the availability of off-the-shelf RST dis-
course parsers, it is now easy to include document-
level structure in sentiment analysis. We show
that a simple reweighting approach offers robust
advantages in lexicon-based sentiment analysis,
and that a recursive neural network can substan-
tially outperform a bag-of-words classifier. Future
work will focus on combining models of discourse
structure with richer models at the sentence level.
Acknowledgments Thanks to the anonymous review-
ers for their helpful suggestions on how to improve the paper.
The following members of the Georgia Tech Computational
Linguistics Laboratory offered feedback throughout the re-
search process: Naman Goyal, Vinodh Krishan, Umashanthi
Pavalanathan, Ana Smith, Yijie Wang, and Yi Yang. Several
class projects in Georgia Tech CS 4650/7650 took alternative
approaches to the application of discourse parsing to senti-
ment analysis, which was informative to this work; thanks
particularly to Julia Cochran, Rohit Pathak, Pavan Kumar
Ramnath, and Bharadwaj Tanikella. This research was sup-
ported by a Google Faculty Research Award, by the National
Institutes of Health under award number R01GM112697-01,
and by the Air Force Office of Scientific Research. The con-
tent is solely the responsibility of the authors and does not
necessarily represent the official views of these sponsors.
</bodyText>
<page confidence="0.988858">
2216
</page>
<sectionHeader confidence="0.946321" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.991050877358491">
Jos´e M Chenlo, Alexander Hogenboom, and David E
Losada. 2014. Rhetorical structure theory for po-
larity estimation: An experimental study. Data &amp;
Knowledge Engineering.
Cristian Danescu-Niculescu-Mizil, Moritz Sudhof,
Dan Jurafsky, Jure Leskovec, and Christopher Potts.
2013. A computational approach to politeness with
application to social factors. In Proceedings of the
Association for Computational Linguistics (ACL),
pages 250–259, Sophia, Bulgaria.
Ronen Feldman. 2013. Techniques and applica-
tions for sentiment analysis. Communications of the
ACM, 56(4):82–89.
Vanessa Wei Feng and Graeme Hirst. 2012. Text-level
Discourse Parsing with Rich Linguistic Features. In
Proceedings of the Association for Computational
Linguistics (ACL), Jeju, Korea.
Shima Gerani, Yashar Mehdad, Giuseppe Carenini,
Raymond T Ng, and Bita Nejat. 2014. Abstractive
summarization of product reviews using discourse
structure. In Proceedings of the Association for
Computational Linguistics (ACL), Baltimore, MD.
Christoph Goller and Andreas Kuchler. 1996. Learn-
ing task-dependent distributed representations by
backpropagation through structure. In Neural Net-
works, IEEE International Conference on, pages
347–352. IEEE.
Vasileios Hatzivassiloglou and Kathleen R. McKeown.
1997. Predicting the semantic orientation of adjec-
tives. In Proceedings of the Association for Compu-
tational Linguistics (ACL), pages 174–181, Madrid,
Spain.
Bas Heerschop, Frank Goossen, Alexander Hogen-
boom, Flavius Frasincar, Uzay Kaymak, and Fran-
ciska de Jong. 2011. Polarity analysis of texts using
discourse structure. In Proceedings of the 20th ACM
international conference on Information and knowl-
edge management, pages 1061–1070. ACM.
Hugo Hernault, Helmut Prendinger, David A. duVerle,
and Mitsuru Ishizuka. 2010. HILDA: A Discourse
Parser Using Support Vector Machine Classification.
Dialogue and Discourse, 1(3):1–33.
Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,
Norihito Yasuda, and Masaaki Nagata. 2013.
Single-document summarization as a tree knapsack
problem. In Proceedings of Empirical Methods
for Natural Language Processing (EMNLP), pages
1515–1520.
Alexander Hogenboom, Flavius Frasincar, Franciska
de Jong, and Uzay Kaymak. 2015. Using rhetorical
structure in sentiment analysis. Communications of
the ACM, 58(7):69–77.
Yangfeng Ji and Jacob Eisenstein. 2014. Represen-
tation learning for text-level discourse parsing. In
Proceedings of the Association for Computational
Linguistics (ACL), Baltimore, MD.
Shafiq Joty, Giuseppe Carenini, and Raymond Ng.
2015. CODRA: A novel discriminative framework
for rhetorical analysis. Computational Linguistics,
41(3).
Dan Jurafsky, Victor Chahuneau, Bryan R Routledge,
and Noah A Smith. 2014. Narrative framing of con-
sumer sentiment in online restaurant reviews. First
Monday, 19(4).
Suin Kim, JinYeong Bak, and Alice Haeyun Oh. 2012.
Do you feel what i feel? social aspects of emotions
in twitter conversations. In Proceedings of the In-
ternational Conference on Web and Social Media
(ICWSM), Menlo Park, California. AAAI Publica-
tions.
Sandra K¨ubler, Ryan McDonald, and Joakim Nivre.
2009. Dependency parsing. Synthesis Lectures on
Human Language Technologies, 1(1):1–127.
Angeliki Lazaridou, Ivan Titov, and Caroline
Sporleder. 2013. A bayesian model for joint
unsupervised induction of sentiment, aspect and
discourse representations. In Proceedings of the
Association for Computational Linguistics (ACL),
pages 1630–1639, Sophia, Bulgaria.
Jiwei Li, Rumeng Li, and Eduard Hovy. 2014. Recur-
sive deep models for discourse parsing. In Proceed-
ings of Empirical Methods for Natural Language
Processing (EMNLP).
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
William Mann. 1984. Discourse structures for text
generation. In Proceedings of the 10th International
Conference on Computational Linguistics and 22nd
annual meeting on Association for Computational
Linguistics, pages 367–375. Association for Com-
putational Linguistics.
Daniel Marcu. 1997. The rhetorical parsing of natu-
ral language texts. In Proceedings of the European
Chapter of the Association for Computational Lin-
guistics (EACL), pages 96–103.
Daniel Marcu. 1999. The automatic construction of
large-scale corpora for summarization research. In
Proceedings of the 22nd annual international ACM
SIGIR conference on Research and development in
information retrieval, pages 137–144. ACM.
Bo Pang and Lillian Lee. 2004. A sentimental edu-
cation: Sentiment analysis using subjectivity sum-
marization based on minimum cuts. In Proceed-
ings of the Association for Computational Linguis-
tics (ACL), pages 271–278.
</reference>
<page confidence="0.920117">
2217
</page>
<reference confidence="0.998918101851852">
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.
Kenji Sagae. 2009. Analysis of Discourse Struc-
ture with Syntactic Dependencies and Data-Driven
Shift-Reduce Parsing. In Proceedings of the 11th
International Conference on Parsing Technologies
(IWPT’09), pages 81–84, Paris, France, October.
Association for Computational Linguistics.
Paul Smolensky. 1990. Tensor product variable bind-
ing and the representation of symbolic structures
in connectionist systems. Artificial intelligence,
46(1):159–216.
Richard Socher, Cliff C. Lin, Andrew Y. Ng, and
Christopher D. Manning. 2011. Parsing Natural
Scenes and Natural Language with Recursive Neu-
ral Networks. In Proceedings of the International
Conference on Machine Learning (ICML), Seattle,
WA.
Richard Socher, Alex Perelygin, Jean Y Wu, Jason
Chuang, Christopher D Manning, Andrew Y Ng,
and Christopher Potts. 2013. Recursive deep mod-
els for semantic compositionality over a sentiment
treebank. In Proceedings of Empirical Methods for
Natural Language Processing (EMNLP).
Swapna Somasundaran, Galileo Namata, Janyce
Wiebe, and Lise Getoor. 2009. Supervised and
unsupervised methods in employing discourse rela-
tions for improving opinion polarity classification.
In Proceedings of Empirical Methods for Natural
Language Processing (EMNLP), Singapore.
Radu Soricut and Daniel Marcu. 2003. Sentence
level discourse parsing using syntactic and lexical
information. In Proceedings of the North American
Chapter of the Association for Computational Lin-
guistics (NAACL), pages 149–156.
Philip J. Stone. 1966. The General Inquirer: A
Computer Approach to Content Analysis. The MIT
Press.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional linguistics, 37(2):267–307.
Maite Taboada. 2008. SFU review cor-
pus. http://www.sfu.ca/˜mtaboada/
research/SFU_Review_Corpus.html.
Yla R Tausczik and James W Pennebaker. 2010. The
psychological meaning of words: LIWC and com-
puterized text analysis methods. Journal of Lan-
guage and Social Psychology, 29(1):24–54.
Rakshit Trivedi and Jacob Eisenstein. 2013. Discourse
connectors for latent subjectivity in sentiment anal-
ysis. In Proceedings of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL), pages 808–813, Stroudsburg, Pennsylva-
nia. Association for Computational Linguistics.
Vin´ıcius Rodrigues Uzˆeda, Thiago Alexan-
dre Salgueiro Pardo, and Maria Das Grac¸as Volpe
Nunes. 2010. A comprehensive comparative eval-
uation of rst-based summarization methods. ACM
Transactions on Speech and Language Processing
(TSLP), 6(4):4.
Kimberly Voll and Maite Taboada. 2007. Not all
words are created equal: Extracting semantic orien-
tation as a function of adjective relevance. In Pro-
ceedings of Australian Conference on Artificial In-
telligence.
Henning Wachsmuth, Martin Trenkmann, Benno Stein,
and Gregor Engels. 2014. Modeling review argu-
mentation for robust sentiment analysis. In Proceed-
ings of the International Conference on Computa-
tional Linguistics (COLING).
Fei Wang and Yunfang Wu. 2013. Exploiting hierar-
chical discourse structure for review sentiment anal-
ysis. In Proceedings of the Conference on Asian
Language Processing (IALP), pages 121–124.
Fei Wang, Yunfang Wu, and Likun Qiu. 2012. Ex-
ploiting discourse relations for sentiment analysis.
In Proceedings of the International Conference on
Computational Linguistics (COLING), pages 1311–
1320, Mumbai, India.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In Proceedings of Em-
pirical Methods for Natural Language Processing
(EMNLP), pages 347–354.
Bishan Yang and Claire Cardie. 2014. Context-aware
learning for sentence-level sentiment analysis with
posterior regularization. In Proceedings of the As-
sociation for Computational Linguistics (ACL), Bal-
timore, MD.
Yasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao, and
Masaaki Nagata. 2014. Dependency-based Dis-
course Parser for Single-Document Summarization.
In Proceedings of Empirical Methods for Natural
Language Processing (EMNLP).
Lanjun Zhou, Binyang Li, Wei Gao, Zhongyu Wei,
and Kam-Fai Wong. 2011. Unsupervised dis-
covery of discourse relations for eliminating intra-
sentence polarity ambiguities. In Proceedings of
Empirical Methods for Natural Language Process-
ing (EMNLP), pages 162–171.
C¨acilia Zirn, Mathias Niepert, Heiner Stuckenschmidt,
and Michael Strube. 2011. Fine-grained sentiment
analysis with structural features. In Proceedings of
the International Joint Conference on Natural Lan-
guage Processing (IJCNLP), pages 336–344, Chi-
ang Mai, Thailand.
</reference>
<page confidence="0.991812">
2218
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.937002">
<title confidence="0.997276">Document-level Sentiment Analysis from RST Discourse</title>
<author confidence="0.999971">Bhatia Ji</author>
<affiliation confidence="0.999498">School of Interactive Georgia Institute of</affiliation>
<address confidence="0.969061">Atlanta, GA</address>
<abstract confidence="0.998314277777778">Discourse structure is the hidden link between surface features and document-level properties, such as sentiment polarity. We show that the discourse analyses produced by Rhetorical Structure Theory (RST) parsers can improve document-level sentiment analysis, via composition of local information up the discourse tree. First, we show that reweighting discourse units according to their position in a dependency representation of the rhetorical structure can yield substantial improvements on lexicon-based sentiment analysis. Next, we present a recursive neural network over the RST structure, which offers significant improvements over classificationbased methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jos´e M Chenlo</author>
<author>Alexander Hogenboom</author>
<author>David E Losada</author>
</authors>
<title>Rhetorical structure theory for polarity estimation: An experimental study.</title>
<date>2014</date>
<journal>Data &amp; Knowledge Engineering.</journal>
<contexts>
<context position="16860" citStr="Chenlo et al., 2014" startWordPosition="2695" endWordPosition="2698">to which improvements in RST parsing might transfer to downstream document analysis. Such an evaluation would seem to require a large corpus of texts with both gold RST parse trees and sentiment polarity labels; the SFU Review Corpus (Taboada, 2008) of 30 review texts offers a starting point, but is probably too small to train a competitive sentiment analysis system. 5 Related Work Section 2 mentions some especially relevant prior work. Other efforts to incorporate RST into sentiment analysis have often focused on intrasentential discourse relations (Heerschop et al., 2011; Zhou et al., 2011; Chenlo et al., 2014), rather than relations over the entire document. Wang et al. (2012) address sentiment analysis in Chinese. Lacking a discourse parser, they focus on explicit connectives, using a strategy that is related to our discourse depth reweighting. Wang and Wu (2013) use manually-annotated discourse parses in combination with a sentiment lexicon, which is automatically updated based on the discourse structure. Zirn et al. (2011) use an RST parser in a Markov Logic Network, with the goal of making polarity predictions at the sub-sentence level, rather than improving document-level prediction. None of t</context>
</contexts>
<marker>Chenlo, Hogenboom, Losada, 2014</marker>
<rawString>Jos´e M Chenlo, Alexander Hogenboom, and David E Losada. 2014. Rhetorical structure theory for polarity estimation: An experimental study. Data &amp; Knowledge Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristian Danescu-Niculescu-Mizil</author>
<author>Moritz Sudhof</author>
<author>Dan Jurafsky</author>
<author>Jure Leskovec</author>
<author>Christopher Potts</author>
</authors>
<title>A computational approach to politeness with application to social factors.</title>
<date>2013</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>250--259</pages>
<location>Sophia, Bulgaria.</location>
<marker>Danescu-Niculescu-Mizil, Sudhof, Jurafsky, Leskovec, Potts, 2013</marker>
<rawString>Cristian Danescu-Niculescu-Mizil, Moritz Sudhof, Dan Jurafsky, Jure Leskovec, and Christopher Potts. 2013. A computational approach to politeness with application to social factors. In Proceedings of the Association for Computational Linguistics (ACL), pages 250–259, Sophia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronen Feldman</author>
</authors>
<title>Techniques and applications for sentiment analysis.</title>
<date>2013</date>
<journal>Communications of the ACM,</journal>
<volume>56</volume>
<issue>4</issue>
<contexts>
<context position="1143" citStr="Feldman, 2013" startWordPosition="151" endWordPosition="152">s, via composition of local information up the discourse tree. First, we show that reweighting discourse units according to their position in a dependency representation of the rhetorical structure can yield substantial improvements on lexicon-based sentiment analysis. Next, we present a recursive neural network over the RST structure, which offers significant improvements over classificationbased methods. 1 Introduction Sentiment analysis and opinion mining are among the most widely-used applications of language technology, impacting both industry and a variety of other academic disciplines (Feldman, 2013; Liu, 2012; Pang and Lee, 2008). Yet sentiment analysis is still dominated by bag-of-words approaches, and attempts to include additional linguistic context typically stop at the sentence level (Socher et al., 2013). Since document-level opinion mining inherently involves multi-sentence texts, it seems that analysis of document-level structure should have a role to play. A classic example of the potential relevance of discourse to sentiment analysis is shown in Figure 1. In this review of the film The Last Samurai, the positive sentiment words far outnumber the✿✿✿✿✿✿✿✿ negative✿✿✿✿✿✿✿✿✿ senti</context>
</contexts>
<marker>Feldman, 2013</marker>
<rawString>Ronen Feldman. 2013. Techniques and applications for sentiment analysis. Communications of the ACM, 56(4):82–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vanessa Wei Feng</author>
<author>Graeme Hirst</author>
</authors>
<title>Text-level Discourse Parsing with Rich Linguistic Features.</title>
<date>2012</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL), Jeju,</booktitle>
<contexts>
<context position="5900" citStr="Feng and Hirst, 2012" startWordPosition="900" endWordPosition="903">g all words except those in the top-most nucleus within each sentence. More recent work focuses on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a recent spike of interest in this task, with contemporary approaches employing discriminative learning (Hernault et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shiftreduce parser (Sagae, 2009), and its time complexity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analysis (Pang and Lee, 2008; Liu, 2012), with particular int</context>
</contexts>
<marker>Feng, Hirst, 2012</marker>
<rawString>Vanessa Wei Feng and Graeme Hirst. 2012. Text-level Discourse Parsing with Rich Linguistic Features. In Proceedings of the Association for Computational Linguistics (ACL), Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shima Gerani</author>
<author>Yashar Mehdad</author>
<author>Giuseppe Carenini</author>
<author>Raymond T Ng</author>
<author>Bita Nejat</author>
</authors>
<title>Abstractive summarization of product reviews using discourse structure.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<location>Baltimore, MD.</location>
<contexts>
<context position="5129" citStr="Gerani et al., 2014" startWordPosition="774" endWordPosition="777">timately covering the entire document. Discourse relations may involve a nucleus and a satellite, or they may be multinuclear. In the example in Figure 1, the unit 1C is the satellite of a relationship with its nucleus 1B; together they form a larger discourse unit, which is involved in a multinuclear CONJUNCTION relation. The nuclearity structure of RST trees suggests a natural approach to evaluating the importance of segments of text: satellites tend to be less important, and nucleii tend to be more important (Marcu, 1999). This idea has been leveraged extensively in document summarization (Gerani et al., 2014; Uzˆeda et al., 2010; Yoshida et al., 2014), and was the inspiration for Voll and Taboada (2007), who examined intra-sentential relations, eliminating all words except those in the top-most nucleus within each sentence. More recent work focuses on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has</context>
</contexts>
<marker>Gerani, Mehdad, Carenini, Ng, Nejat, 2014</marker>
<rawString>Shima Gerani, Yashar Mehdad, Giuseppe Carenini, Raymond T Ng, and Bita Nejat. 2014. Abstractive summarization of product reviews using discourse structure. In Proceedings of the Association for Computational Linguistics (ACL), Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christoph Goller</author>
<author>Andreas Kuchler</author>
</authors>
<title>Learning task-dependent distributed representations by backpropagation through structure.</title>
<date>1996</date>
<booktitle>In Neural Networks, IEEE International Conference on,</booktitle>
<pages>347--352</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="15169" citStr="Goller and Kuchler, 1996" startWordPosition="2424" endWordPosition="2428">dditional component to the network architecture, capturing the bag-of-words for the entire document. Thus, at the root node we have: �IFdoc = γθ�( wi) + IFrst-root, (5) i with IFrst-root defined recursively from Equations 3 and 4, θ indicating the vector of per-word weights, and the scalar γ controlling the tradeoff between these two components. Learning R2N2 is trained by backpropagating from a hinge loss objective; assuming yt E 1−1, 11 for each document t, we have the loss Lt = (1 − ytIFdoc,t)+. From this loss, we use backpropagation through structure to obtain gradients on the parameters (Goller and Kuchler, 1996). Training is performed using stochastic gradient descent. For simplicity, we follow Zirn et al. (2011) and focus on the distinction between contrastive and non-contrastive relations. The set of contrastive relations includes CONTRAST, COMPARISON, ANTITHESIS, ANTITHESIS-E, CONSEQUENCE-S, CONCESSION, and PROBLEM-SOLUTION. Evaluation Results for this approach are shown in lines R1 and R2 of Table 1. Even without distinguishing between discourse relations, we get an improvement of more than 3% accuracy on the Stanford data, and 0.5% on the smaller Pang &amp; Lee dataset. Adding sensitivity to discour</context>
</contexts>
<marker>Goller, Kuchler, 1996</marker>
<rawString>Christoph Goller and Andreas Kuchler. 1996. Learning task-dependent distributed representations by backpropagation through structure. In Neural Networks, IEEE International Conference on, pages 347–352. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasileios Hatzivassiloglou</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Predicting the semantic orientation of adjectives.</title>
<date>1997</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>174--181</pages>
<location>Madrid,</location>
<contexts>
<context position="7718" citStr="Hatzivassiloglou and McKeown, 1997" startWordPosition="1192" endWordPosition="1195"> negative sentiment, but may focus on other categories, such as politeness (Danescu-NiculescuMizil et al., 2013), narrative frames (Jurafsky et al., 2014), or a multidimensional spectrum of emotions (Kim et al., 2012). In these cases, labeled documents may not be available, so users often employ a simpler method: counting matches against lists of words associated with each category. Such lists may be built manually from introspection, as in LIWC (Tausczik and Pennebaker, 2010) and the General Inquirer (Stone, 1966). Alternatively, they may be induced by bootstrapping from a seed set of words (Hatzivassiloglou and McKeown, 1997; Taboada et al., 2011). While lexicon-based methods may be less accurate than supervised classifiers, they are easier to apply to 1https://github.com/jiyfeng/DPLP 2213 1H 1A Figure 2: Dependency-based discourse tree representation of the discourse in Figure 1 new domains and problem settings. Our proposed approach can be used in combination with either method for sentiment analysis, and in principle, could be directly applied to other document-level categories, such as politeness. 2.3 Datasets We evaluate on two review datasets. In both cases, the goal is to correctly classify the opinion pol</context>
</contexts>
<marker>Hatzivassiloglou, McKeown, 1997</marker>
<rawString>Vasileios Hatzivassiloglou and Kathleen R. McKeown. 1997. Predicting the semantic orientation of adjectives. In Proceedings of the Association for Computational Linguistics (ACL), pages 174–181, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bas Heerschop</author>
<author>Frank Goossen</author>
<author>Alexander Hogenboom</author>
<author>Flavius Frasincar</author>
<author>Uzay Kaymak</author>
<author>Franciska de Jong</author>
</authors>
<title>Polarity analysis of texts using discourse structure.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM international conference on Information and knowledge management,</booktitle>
<pages>1061--1070</pages>
<publisher>ACM.</publisher>
<marker>Heerschop, Goossen, Hogenboom, Frasincar, Kaymak, de Jong, 2011</marker>
<rawString>Bas Heerschop, Frank Goossen, Alexander Hogenboom, Flavius Frasincar, Uzay Kaymak, and Franciska de Jong. 2011. Polarity analysis of texts using discourse structure. In Proceedings of the 20th ACM international conference on Information and knowledge management, pages 1061–1070. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Hernault</author>
<author>Helmut Prendinger</author>
<author>David A duVerle</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>HILDA: A Discourse Parser Using Support Vector Machine Classification. Dialogue and Discourse,</title>
<date>2010</date>
<contexts>
<context position="5862" citStr="Hernault et al., 2010" startWordPosition="894" endWordPosition="897"> intra-sentential relations, eliminating all words except those in the top-most nucleus within each sentence. More recent work focuses on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a recent spike of interest in this task, with contemporary approaches employing discriminative learning (Hernault et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shiftreduce parser (Sagae, 2009), and its time complexity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analysis (Pang and Lee,</context>
</contexts>
<marker>Hernault, Prendinger, duVerle, Ishizuka, 2010</marker>
<rawString>Hugo Hernault, Helmut Prendinger, David A. duVerle, and Mitsuru Ishizuka. 2010. HILDA: A Discourse Parser Using Support Vector Machine Classification. Dialogue and Discourse, 1(3):1–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tsutomu Hirao</author>
<author>Yasuhisa Yoshida</author>
<author>Masaaki Nishino</author>
<author>Norihito Yasuda</author>
<author>Masaaki Nagata</author>
</authors>
<title>Single-document summarization as a tree knapsack problem.</title>
<date>2013</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>1515--1520</pages>
<contexts>
<context position="9214" citStr="Hirao et al., 2013" startWordPosition="1434" endWordPosition="1437">edefined 50/50 split into training and test sets. Documents are scored on a 1-10 scale, and we treat scores G 4 as negative, &gt; 7 as positive, and ignore scores of 5-6 as neutral — although in principle nothing prevents extension of our approaches to more than two sentiment classes. 3 Discourse depth reweighting Our first approach to incorporating discourse information into sentiment analysis is based on quantifying the importance of each unit of text in terms of its discourse depth. To do this, we employ the dependency-based discourse tree (DEPDT) formulation from prior work on summarization (Hirao et al., 2013). The DEP-DT formalism converts the constituent-like RST tree into a directed graph over elementary discourse units (EDUs), in a process that is a close analogue of the transformation of a headed syntactic constituent parse to a syntactic dependency graph (K¨ubler et al., 2009). The DEP-DT representation of the discourse in Figure 1 in shown in Figure 2. The graph is constructed by propagating “head” information up the RST tree; if the elementary discourse unit ei is the satellite in a discourse relation headed by ej, then there is an edge from ej to ei. Thus, the “depth” of each EDU is the nu</context>
</contexts>
<marker>Hirao, Yoshida, Nishino, Yasuda, Nagata, 2013</marker>
<rawString>Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino, Norihito Yasuda, and Masaaki Nagata. 2013. Single-document summarization as a tree knapsack problem. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP), pages 1515–1520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Hogenboom</author>
<author>Flavius Frasincar</author>
<author>Franciska de Jong</author>
<author>Uzay Kaymak</author>
</authors>
<title>Using rhetorical structure in sentiment analysis.</title>
<date>2015</date>
<journal>Communications of the ACM,</journal>
<volume>58</volume>
<issue>7</issue>
<marker>Hogenboom, Frasincar, de Jong, Kaymak, 2015</marker>
<rawString>Alexander Hogenboom, Flavius Frasincar, Franciska de Jong, and Uzay Kaymak. 2015. Using rhetorical structure in sentiment analysis. Communications of the ACM, 58(7):69–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yangfeng Ji</author>
<author>Jacob Eisenstein</author>
</authors>
<title>Representation learning for text-level discourse parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<location>Baltimore, MD.</location>
<contexts>
<context position="5997" citStr="Ji and Eisenstein, 2014" startWordPosition="913" endWordPosition="917"> on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a recent spike of interest in this task, with contemporary approaches employing discriminative learning (Hernault et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shiftreduce parser (Sagae, 2009), and its time complexity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analysis (Pang and Lee, 2008; Liu, 2012), with particular interest in determining the overall sentiment polarity (positive or negative) of a document. Bagof-w</context>
</contexts>
<marker>Ji, Eisenstein, 2014</marker>
<rawString>Yangfeng Ji and Jacob Eisenstein. 2014. Representation learning for text-level discourse parsing. In Proceedings of the Association for Computational Linguistics (ACL), Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shafiq Joty</author>
<author>Giuseppe Carenini</author>
<author>Raymond Ng</author>
</authors>
<title>CODRA: A novel discriminative framework for rhetorical analysis.</title>
<date>2015</date>
<journal>Computational Linguistics,</journal>
<volume>41</volume>
<issue>3</issue>
<contexts>
<context position="5943" citStr="Joty et al., 2015" startWordPosition="906" endWordPosition="909">us within each sentence. More recent work focuses on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a recent spike of interest in this task, with contemporary approaches employing discriminative learning (Hernault et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shiftreduce parser (Sagae, 2009), and its time complexity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analysis (Pang and Lee, 2008; Liu, 2012), with particular interest in determining the overall sentiment </context>
</contexts>
<marker>Joty, Carenini, Ng, 2015</marker>
<rawString>Shafiq Joty, Giuseppe Carenini, and Raymond Ng. 2015. CODRA: A novel discriminative framework for rhetorical analysis. Computational Linguistics, 41(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Jurafsky</author>
<author>Victor Chahuneau</author>
<author>Bryan R Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>Narrative framing of consumer sentiment in online restaurant reviews.</title>
<date>2014</date>
<journal>First Monday,</journal>
<volume>19</volume>
<issue>4</issue>
<contexts>
<context position="7238" citStr="Jurafsky et al., 2014" startWordPosition="1113" endWordPosition="1116">ely used for this task, as they offer accuracy that is often very competitive with more complex approaches. Given labeled data, supervised learning can be applied to obtain sentiment weights for each word. However, the effectiveness of supervised sentiment analysis depends on having training data in the same domain as the target, and this is not always possible. Moreover, in social science applications, the desired labels may not correspond directly to positive or negative sentiment, but may focus on other categories, such as politeness (Danescu-NiculescuMizil et al., 2013), narrative frames (Jurafsky et al., 2014), or a multidimensional spectrum of emotions (Kim et al., 2012). In these cases, labeled documents may not be available, so users often employ a simpler method: counting matches against lists of words associated with each category. Such lists may be built manually from introspection, as in LIWC (Tausczik and Pennebaker, 2010) and the General Inquirer (Stone, 1966). Alternatively, they may be induced by bootstrapping from a seed set of words (Hatzivassiloglou and McKeown, 1997; Taboada et al., 2011). While lexicon-based methods may be less accurate than supervised classifiers, they are easier t</context>
</contexts>
<marker>Jurafsky, Chahuneau, Routledge, Smith, 2014</marker>
<rawString>Dan Jurafsky, Victor Chahuneau, Bryan R Routledge, and Noah A Smith. 2014. Narrative framing of consumer sentiment in online restaurant reviews. First Monday, 19(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suin Kim</author>
<author>JinYeong Bak</author>
<author>Alice Haeyun Oh</author>
</authors>
<title>Do you feel what i feel? social aspects of emotions in twitter conversations.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Web and Social Media (ICWSM), Menlo Park,</booktitle>
<publisher>AAAI Publications.</publisher>
<location>California.</location>
<contexts>
<context position="7301" citStr="Kim et al., 2012" startWordPosition="1124" endWordPosition="1127">mpetitive with more complex approaches. Given labeled data, supervised learning can be applied to obtain sentiment weights for each word. However, the effectiveness of supervised sentiment analysis depends on having training data in the same domain as the target, and this is not always possible. Moreover, in social science applications, the desired labels may not correspond directly to positive or negative sentiment, but may focus on other categories, such as politeness (Danescu-NiculescuMizil et al., 2013), narrative frames (Jurafsky et al., 2014), or a multidimensional spectrum of emotions (Kim et al., 2012). In these cases, labeled documents may not be available, so users often employ a simpler method: counting matches against lists of words associated with each category. Such lists may be built manually from introspection, as in LIWC (Tausczik and Pennebaker, 2010) and the General Inquirer (Stone, 1966). Alternatively, they may be induced by bootstrapping from a seed set of words (Hatzivassiloglou and McKeown, 1997; Taboada et al., 2011). While lexicon-based methods may be less accurate than supervised classifiers, they are easier to apply to 1https://github.com/jiyfeng/DPLP 2213 1H 1A Figure 2</context>
</contexts>
<marker>Kim, Bak, Oh, 2012</marker>
<rawString>Suin Kim, JinYeong Bak, and Alice Haeyun Oh. 2012. Do you feel what i feel? social aspects of emotions in twitter conversations. In Proceedings of the International Conference on Web and Social Media (ICWSM), Menlo Park, California. AAAI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<date>2009</date>
<booktitle>Dependency parsing. Synthesis Lectures on Human Language Technologies,</booktitle>
<volume>1</volume>
<issue>1</issue>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>Sandra K¨ubler, Ryan McDonald, and Joakim Nivre. 2009. Dependency parsing. Synthesis Lectures on Human Language Technologies, 1(1):1–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angeliki Lazaridou</author>
<author>Ivan Titov</author>
<author>Caroline Sporleder</author>
</authors>
<title>A bayesian model for joint unsupervised induction of sentiment, aspect and discourse representations.</title>
<date>2013</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1630--1639</pages>
<location>Sophia, Bulgaria.</location>
<contexts>
<context position="18016" citStr="Lazaridou et al., 2013" startWordPosition="2877" endWordPosition="2880">e level, rather than improving document-level prediction. None of the prior work considers the sort of recurrent compositional model presented here. An alternative to RST is to incorporate “shallow” discourse structure, such as the relations from the Penn Discourse Treebank (PDTB). PDTB relations were shown to improve sentencelevel sentiment analysis by Somasundaran et al. (2009), and were incorporated in a model of sentiment flow by Wachsmuth et al. (2014). PDTB relations are often signaled with explicit discourse connectives, and these may be used as a feature (Trivedi and Eisenstein, 2013; Lazaridou et al., 2013) or as posterior constraints (Yang and Cardie, 2014). This prior work on discourse relations within sentences and between adjacent sentences can be viewed as complementary to our focus on higher-level discourse relations across the entire document. There are unfortunately few possibilities for direct comparison of our approach against prior work. Heerschop et al. (2011) and Wachsmuth et al. (2014) also employ the Pang and Lee (2004) dataset, but neither of their results are directly comparable: Heerschop et al. (2011) exclude documents that SPADE fails to parse, and Wachsmuth et al. (2014) eva</context>
</contexts>
<marker>Lazaridou, Titov, Sporleder, 2013</marker>
<rawString>Angeliki Lazaridou, Ivan Titov, and Caroline Sporleder. 2013. A bayesian model for joint unsupervised induction of sentiment, aspect and discourse representations. In Proceedings of the Association for Computational Linguistics (ACL), pages 1630–1639, Sophia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiwei Li</author>
<author>Rumeng Li</author>
<author>Eduard Hovy</author>
</authors>
<title>Recursive deep models for discourse parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="6015" citStr="Li et al., 2014" startWordPosition="918" endWordPosition="921">ourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a recent spike of interest in this task, with contemporary approaches employing discriminative learning (Hernault et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shiftreduce parser (Sagae, 2009), and its time complexity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analysis (Pang and Lee, 2008; Liu, 2012), with particular interest in determining the overall sentiment polarity (positive or negative) of a document. Bagof-words models are wi</context>
</contexts>
<marker>Li, Li, Hovy, 2014</marker>
<rawString>Jiwei Li, Rumeng Li, and Eduard Hovy. 2014. Recursive deep models for discourse parsing. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="1154" citStr="Liu, 2012" startWordPosition="153" endWordPosition="154">ion of local information up the discourse tree. First, we show that reweighting discourse units according to their position in a dependency representation of the rhetorical structure can yield substantial improvements on lexicon-based sentiment analysis. Next, we present a recursive neural network over the RST structure, which offers significant improvements over classificationbased methods. 1 Introduction Sentiment analysis and opinion mining are among the most widely-used applications of language technology, impacting both industry and a variety of other academic disciplines (Feldman, 2013; Liu, 2012; Pang and Lee, 2008). Yet sentiment analysis is still dominated by bag-of-words approaches, and attempts to include additional linguistic context typically stop at the sentence level (Socher et al., 2013). Since document-level opinion mining inherently involves multi-sentence texts, it seems that analysis of document-level structure should have a role to play. A classic example of the potential relevance of discourse to sentiment analysis is shown in Figure 1. In this review of the film The Last Samurai, the positive sentiment words far outnumber the✿✿✿✿✿✿✿✿ negative✿✿✿✿✿✿✿✿✿ sentiment words.</context>
<context position="6479" citStr="Liu, 2012" startWordPosition="997" endWordPosition="998">features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shiftreduce parser (Sagae, 2009), and its time complexity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analysis (Pang and Lee, 2008; Liu, 2012), with particular interest in determining the overall sentiment polarity (positive or negative) of a document. Bagof-words models are widely used for this task, as they offer accuracy that is often very competitive with more complex approaches. Given labeled data, supervised learning can be applied to obtain sentiment weights for each word. However, the effectiveness of supervised sentiment analysis depends on having training data in the same domain as the target, and this is not always possible. Moreover, in social science applications, the desired labels may not correspond directly to positi</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Mann</author>
</authors>
<title>Discourse structures for text generation.</title>
<date>1984</date>
<booktitle>In Proceedings of the 10th International Conference on Computational Linguistics and 22nd annual meeting on Association for Computational Linguistics,</booktitle>
<pages>367--375</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Mann, 1984</marker>
<rawString>William Mann. 1984. Discourse structures for text generation. In Proceedings of the 10th International Conference on Computational Linguistics and 22nd annual meeting on Association for Computational Linguistics, pages 367–375. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The rhetorical parsing of natural language texts.</title>
<date>1997</date>
<booktitle>In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL),</booktitle>
<pages>96--103</pages>
<contexts>
<context position="5663" citStr="Marcu (1997)" startWordPosition="863" endWordPosition="864"> has been leveraged extensively in document summarization (Gerani et al., 2014; Uzˆeda et al., 2010; Yoshida et al., 2014), and was the inspiration for Voll and Taboada (2007), who examined intra-sentential relations, eliminating all words except those in the top-most nucleus within each sentence. More recent work focuses on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a recent spike of interest in this task, with contemporary approaches employing discriminative learning (Hernault et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsi</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Daniel Marcu. 1997. The rhetorical parsing of natural language texts. In Proceedings of the European Chapter of the Association for Computational Linguistics (EACL), pages 96–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The automatic construction of large-scale corpora for summarization research.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>137--144</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="5040" citStr="Marcu, 1999" startWordPosition="763" endWordPosition="764">discourse units (EDUs) are combined intro progressively larger discourse units, ultimately covering the entire document. Discourse relations may involve a nucleus and a satellite, or they may be multinuclear. In the example in Figure 1, the unit 1C is the satellite of a relationship with its nucleus 1B; together they form a larger discourse unit, which is involved in a multinuclear CONJUNCTION relation. The nuclearity structure of RST trees suggests a natural approach to evaluating the importance of segments of text: satellites tend to be less important, and nucleii tend to be more important (Marcu, 1999). This idea has been leveraged extensively in document summarization (Gerani et al., 2014; Uzˆeda et al., 2010; Yoshida et al., 2014), and was the inspiration for Voll and Taboada (2007), who examined intra-sentential relations, eliminating all words except those in the top-most nucleus within each sentence. More recent work focuses on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the disco</context>
</contexts>
<marker>Marcu, 1999</marker>
<rawString>Daniel Marcu. 1999. The automatic construction of large-scale corpora for summarization research. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 137–144. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<pages>271--278</pages>
<contexts>
<context position="8434" citStr="Pang and Lee (2004)" startWordPosition="1302" endWordPosition="1305">iers, they are easier to apply to 1https://github.com/jiyfeng/DPLP 2213 1H 1A Figure 2: Dependency-based discourse tree representation of the discourse in Figure 1 new domains and problem settings. Our proposed approach can be used in combination with either method for sentiment analysis, and in principle, could be directly applied to other document-level categories, such as politeness. 2.3 Datasets We evaluate on two review datasets. In both cases, the goal is to correctly classify the opinion polarity as positive or negative. The first dataset is comprised of 2000 movie reviews, gathered by Pang and Lee (2004). We perform ten-fold crossvalidation on this data. The second dataset is larger, consisting of 50,000 movie reviews, gathered by Socher et al. (2013), with a predefined 50/50 split into training and test sets. Documents are scored on a 1-10 scale, and we treat scores G 4 as negative, &gt; 7 as positive, and ignore scores of 5-6 as neutral — although in principle nothing prevents extension of our approaches to more than two sentiment classes. 3 Discourse depth reweighting Our first approach to incorporating discourse information into sentiment analysis is based on quantifying the importance of ea</context>
<context position="12245" citStr="Pang and Lee, 2004" startWordPosition="1941" endWordPosition="1944">nalysis, but the improvements over the more accurate classification-based method are meager. We therefore turn to a data-driven approach for combining sentiment analysis with rhetorical structure theory, based on recursive neural networks (Socher et al., 1D 1E 1F 1G 1B 1C 2214 Pang &amp; Lee Socher et al. Baselines B1. Lexicon 68.3 74.9 B2. Classifier 82.4 81.5 Discourse depth weighting D1. Lexicon 72.6 78.9 D2. Classifier 82.9 82.0 Rhetorical recursive neural network R1. No relations 83.4 85.5 R2. With relations 84.1 85.6 Table 1: Sentiment classification accuracies on two movie review datasets (Pang and Lee, 2004; Socher et al., 2013), described in Section 2.3. 2011). The idea is simple: recursively propagate sentiment scores up the RST tree, until the root of the document is reached. For nucleus-satellite discourse relations, we have: IFi = tanh(K(ri) n IFn(i) + K(ri) s IFs(i)), (3) where i indexes a discourse unit composed from relation ri, n(i) indicates its nucleus, and s(i) indicates its satellite. Returning to the example in Figure 1, the sentiment score for the discourse unit obtained by combining 1B and 1C is obtained (elaboration) (elaboration) from tanh(Kn IF 1B + Ks IF1C). Similarly, for mu</context>
<context position="18452" citStr="Pang and Lee (2004)" startWordPosition="2946" endWordPosition="2949">chsmuth et al. (2014). PDTB relations are often signaled with explicit discourse connectives, and these may be used as a feature (Trivedi and Eisenstein, 2013; Lazaridou et al., 2013) or as posterior constraints (Yang and Cardie, 2014). This prior work on discourse relations within sentences and between adjacent sentences can be viewed as complementary to our focus on higher-level discourse relations across the entire document. There are unfortunately few possibilities for direct comparison of our approach against prior work. Heerschop et al. (2011) and Wachsmuth et al. (2014) also employ the Pang and Lee (2004) dataset, but neither of their results are directly comparable: Heerschop et al. (2011) exclude documents that SPADE fails to parse, and Wachsmuth et al. (2014) evaluates only on individual sentences rather than entire documents. The only possible direct comparison is with very recent work from Hogenboom et al. (2015), who employ a weighting scheme that is similar to the approach described in Section 3. They evaluate on the Pang and Lee data, and consider only lexicon-based sentiment analysis, obtaining document-level accuracies between 65% (for the baseline) and 72% (for their best discourse-</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the Association for Computational Linguistics (ACL), pages 271–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="1175" citStr="Pang and Lee, 2008" startWordPosition="155" endWordPosition="158">l information up the discourse tree. First, we show that reweighting discourse units according to their position in a dependency representation of the rhetorical structure can yield substantial improvements on lexicon-based sentiment analysis. Next, we present a recursive neural network over the RST structure, which offers significant improvements over classificationbased methods. 1 Introduction Sentiment analysis and opinion mining are among the most widely-used applications of language technology, impacting both industry and a variety of other academic disciplines (Feldman, 2013; Liu, 2012; Pang and Lee, 2008). Yet sentiment analysis is still dominated by bag-of-words approaches, and attempts to include additional linguistic context typically stop at the sentence level (Socher et al., 2013). Since document-level opinion mining inherently involves multi-sentence texts, it seems that analysis of document-level structure should have a role to play. A classic example of the potential relevance of discourse to sentiment analysis is shown in Figure 1. In this review of the film The Last Samurai, the positive sentiment words far outnumber the✿✿✿✿✿✿✿✿ negative✿✿✿✿✿✿✿✿✿ sentiment words. But the discourse st</context>
<context position="6467" citStr="Pang and Lee, 2008" startWordPosition="993" endWordPosition="996">et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shiftreduce parser (Sagae, 2009), and its time complexity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analysis (Pang and Lee, 2008; Liu, 2012), with particular interest in determining the overall sentiment polarity (positive or negative) of a document. Bagof-words models are widely used for this task, as they offer accuracy that is often very competitive with more complex approaches. Given labeled data, supervised learning can be applied to obtain sentiment weights for each word. However, the effectiveness of supervised sentiment analysis depends on having training data in the same domain as the target, and this is not always possible. Moreover, in social science applications, the desired labels may not correspond direct</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
</authors>
<title>Analysis of Discourse Structure with Syntactic Dependencies and Data-Driven Shift-Reduce Parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>81--84</pages>
<location>Paris, France,</location>
<contexts>
<context position="6309" citStr="Sagae, 2009" startWordPosition="966" endWordPosition="967">matic RST parsing, but there has been a recent spike of interest in this task, with contemporary approaches employing discriminative learning (Hernault et al., 2010), rich features (Feng and Hirst, 2012), structured prediction (Joty et al., 2015), and representation learning (Ji and Eisenstein, 2014; Li et al., 2014). With many strong systems to choose from, we employ the publiclyavailable DPLP parser (Ji and Eisenstein, 2014),1. To our knowledge, this system currently gives the best F-measure on relation identification, the most difficult subtask of RST parsing. DPLP is a shiftreduce parser (Sagae, 2009), and its time complexity is linear in the length of the document. 2.2 Sentiment analysis There is a huge literature on sentiment analysis (Pang and Lee, 2008; Liu, 2012), with particular interest in determining the overall sentiment polarity (positive or negative) of a document. Bagof-words models are widely used for this task, as they offer accuracy that is often very competitive with more complex approaches. Given labeled data, supervised learning can be applied to obtain sentiment weights for each word. However, the effectiveness of supervised sentiment analysis depends on having training </context>
</contexts>
<marker>Sagae, 2009</marker>
<rawString>Kenji Sagae. 2009. Analysis of Discourse Structure with Syntactic Dependencies and Data-Driven Shift-Reduce Parsing. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages 81–84, Paris, France, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Smolensky</author>
</authors>
<title>Tensor product variable binding and the representation of symbolic structures in connectionist systems.</title>
<date>1990</date>
<journal>Artificial intelligence,</journal>
<volume>46</volume>
<issue>1</issue>
<contexts>
<context position="3922" citStr="Smolensky, 1990" startWordPosition="588" endWordPosition="590">in Natural Language Processing, pages 2212–2218, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. can be used in combination with an “off the shelf” discourse parser. We consider the following two architectures: • Reweighting the contribution of each discourse unit, based on its position in a dependency-like representation of the discourse structure. Such weights can be defined using a simple function, or learned from a small of data. • Recursively propagating sentiment up through the RST parse, in an architecture inspired by recursive neural networks (Smolensky, 1990; Socher et al., 2011). Both architectures can be used in combination with either a lexicon-based sentiment analyzer, or a trained classifier. Indeed, for users whose starting point is a lexicon-based approach, a simple RST-based reweighting function can offer significant improvements. For those who are willing to train a sentiment classifier, the recursive model yields further gains. 2 Background 2.1 Rhetorical Structure Theory RST is a compositional model of discourse structure, in which elementary discourse units (EDUs) are combined intro progressively larger discourse units, ultimately cov</context>
</contexts>
<marker>Smolensky, 1990</marker>
<rawString>Paul Smolensky. 1990. Tensor product variable binding and the representation of symbolic structures in connectionist systems. Artificial intelligence, 46(1):159–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Cliff C Lin</author>
<author>Andrew Y Ng</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing Natural Scenes and Natural Language with Recursive Neural Networks.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Conference on Machine Learning (ICML),</booktitle>
<location>Seattle, WA.</location>
<contexts>
<context position="3944" citStr="Socher et al., 2011" startWordPosition="591" endWordPosition="594">ge Processing, pages 2212–2218, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. can be used in combination with an “off the shelf” discourse parser. We consider the following two architectures: • Reweighting the contribution of each discourse unit, based on its position in a dependency-like representation of the discourse structure. Such weights can be defined using a simple function, or learned from a small of data. • Recursively propagating sentiment up through the RST parse, in an architecture inspired by recursive neural networks (Smolensky, 1990; Socher et al., 2011). Both architectures can be used in combination with either a lexicon-based sentiment analyzer, or a trained classifier. Indeed, for users whose starting point is a lexicon-based approach, a simple RST-based reweighting function can offer significant improvements. For those who are willing to train a sentiment classifier, the recursive model yields further gains. 2 Background 2.1 Rhetorical Structure Theory RST is a compositional model of discourse structure, in which elementary discourse units (EDUs) are combined intro progressively larger discourse units, ultimately covering the entire docum</context>
</contexts>
<marker>Socher, Lin, Ng, Manning, 2011</marker>
<rawString>Richard Socher, Cliff C. Lin, Andrew Y. Ng, and Christopher D. Manning. 2011. Parsing Natural Scenes and Natural Language with Recursive Neural Networks. In Proceedings of the International Conference on Machine Learning (ICML), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Alex Perelygin</author>
<author>Jean Y Wu</author>
<author>Jason Chuang</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
<author>Christopher Potts</author>
</authors>
<title>Recursive deep models for semantic compositionality over a sentiment treebank.</title>
<date>2013</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="1359" citStr="Socher et al., 2013" startWordPosition="182" endWordPosition="185">ubstantial improvements on lexicon-based sentiment analysis. Next, we present a recursive neural network over the RST structure, which offers significant improvements over classificationbased methods. 1 Introduction Sentiment analysis and opinion mining are among the most widely-used applications of language technology, impacting both industry and a variety of other academic disciplines (Feldman, 2013; Liu, 2012; Pang and Lee, 2008). Yet sentiment analysis is still dominated by bag-of-words approaches, and attempts to include additional linguistic context typically stop at the sentence level (Socher et al., 2013). Since document-level opinion mining inherently involves multi-sentence texts, it seems that analysis of document-level structure should have a role to play. A classic example of the potential relevance of discourse to sentiment analysis is shown in Figure 1. In this review of the film The Last Samurai, the positive sentiment words far outnumber the✿✿✿✿✿✿✿✿ negative✿✿✿✿✿✿✿✿✿ sentiment words. But the discourse structure — indicated here with Rhetorical Structure Theory (RST; Mann and Thompson, 1988) — ∗Code is available at https://github.com/ parry2403/R2N2 CONCESSION CONJUNCTION [It could hav</context>
<context position="8584" citStr="Socher et al. (2013)" startWordPosition="1327" endWordPosition="1330">se in Figure 1 new domains and problem settings. Our proposed approach can be used in combination with either method for sentiment analysis, and in principle, could be directly applied to other document-level categories, such as politeness. 2.3 Datasets We evaluate on two review datasets. In both cases, the goal is to correctly classify the opinion polarity as positive or negative. The first dataset is comprised of 2000 movie reviews, gathered by Pang and Lee (2004). We perform ten-fold crossvalidation on this data. The second dataset is larger, consisting of 50,000 movie reviews, gathered by Socher et al. (2013), with a predefined 50/50 split into training and test sets. Documents are scored on a 1-10 scale, and we treat scores G 4 as negative, &gt; 7 as positive, and ignore scores of 5-6 as neutral — although in principle nothing prevents extension of our approaches to more than two sentiment classes. 3 Discourse depth reweighting Our first approach to incorporating discourse information into sentiment analysis is based on quantifying the importance of each unit of text in terms of its discourse depth. To do this, we employ the dependency-based discourse tree (DEPDT) formulation from prior work on summ</context>
<context position="12267" citStr="Socher et al., 2013" startWordPosition="1945" endWordPosition="1948">rovements over the more accurate classification-based method are meager. We therefore turn to a data-driven approach for combining sentiment analysis with rhetorical structure theory, based on recursive neural networks (Socher et al., 1D 1E 1F 1G 1B 1C 2214 Pang &amp; Lee Socher et al. Baselines B1. Lexicon 68.3 74.9 B2. Classifier 82.4 81.5 Discourse depth weighting D1. Lexicon 72.6 78.9 D2. Classifier 82.9 82.0 Rhetorical recursive neural network R1. No relations 83.4 85.5 R2. With relations 84.1 85.6 Table 1: Sentiment classification accuracies on two movie review datasets (Pang and Lee, 2004; Socher et al., 2013), described in Section 2.3. 2011). The idea is simple: recursively propagate sentiment scores up the RST tree, until the root of the document is reached. For nucleus-satellite discourse relations, we have: IFi = tanh(K(ri) n IFn(i) + K(ri) s IFs(i)), (3) where i indexes a discourse unit composed from relation ri, n(i) indicates its nucleus, and s(i) indicates its satellite. Returning to the example in Figure 1, the sentiment score for the discourse unit obtained by combining 1B and 1C is obtained (elaboration) (elaboration) from tanh(Kn IF 1B + Ks IF1C). Similarly, for multinuclear relations, </context>
</contexts>
<marker>Socher, Perelygin, Wu, Chuang, Manning, Ng, Potts, 2013</marker>
<rawString>Richard Socher, Alex Perelygin, Jean Y Wu, Jason Chuang, Christopher D Manning, Andrew Y Ng, and Christopher Potts. 2013. Recursive deep models for semantic compositionality over a sentiment treebank. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>Galileo Namata</author>
<author>Janyce Wiebe</author>
<author>Lise Getoor</author>
</authors>
<title>Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification.</title>
<date>2009</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<contexts>
<context position="17775" citStr="Somasundaran et al. (2009)" startWordPosition="2836" endWordPosition="2839">rse parses in combination with a sentiment lexicon, which is automatically updated based on the discourse structure. Zirn et al. (2011) use an RST parser in a Markov Logic Network, with the goal of making polarity predictions at the sub-sentence level, rather than improving document-level prediction. None of the prior work considers the sort of recurrent compositional model presented here. An alternative to RST is to incorporate “shallow” discourse structure, such as the relations from the Penn Discourse Treebank (PDTB). PDTB relations were shown to improve sentencelevel sentiment analysis by Somasundaran et al. (2009), and were incorporated in a model of sentiment flow by Wachsmuth et al. (2014). PDTB relations are often signaled with explicit discourse connectives, and these may be used as a feature (Trivedi and Eisenstein, 2013; Lazaridou et al., 2013) or as posterior constraints (Yang and Cardie, 2014). This prior work on discourse relations within sentences and between adjacent sentences can be viewed as complementary to our focus on higher-level discourse relations across the entire document. There are unfortunately few possibilities for direct comparison of our approach against prior work. Heerschop </context>
</contexts>
<marker>Somasundaran, Namata, Wiebe, Getoor, 2009</marker>
<rawString>Swapna Somasundaran, Galileo Namata, Janyce Wiebe, and Lise Getoor. 2009. Supervised and unsupervised methods in employing discourse relations for improving opinion polarity classification. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP), Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>149--156</pages>
<contexts>
<context position="2711" citStr="Soricut and Marcu, 2003" startWordPosition="395" endWordPosition="398">ej1D [and I really liked the son of the leader of the Samurai.]1E [He was a likable chapj1F [and I ✿✿✿✿ hated to see him die.]1G [But, other than all that, this movie is ✿✿✿✿✿✿ nothing more than hidden✿✿✿✿✿ rip-offs.]1H Figure 1: Example adapted from Voll and Taboada (2007). clearly favors the final sentence, whose polarity is negative. This example is illustrative in more than one way: it was originally identified by Voll and Taboada (2007), who found that manuallyannotated RST parse trees improved lexiconbased sentiment analysis, but that automaticallygenerated parses from the SPADE parser (Soricut and Marcu, 2003), which was then state-of-the-art, did not. Since this time, RST discourse parsing has improved considerably, with the best systems now yielding 5-10% greater raw accuracy than SPADE, depending on the metric. The time is therefore right to reconsider the effectiveness of RST for document-level sentiment analysis. In this paper, we present two different ways of combining RST discourse parses with sentiment analysis. The methods are both relatively simple, and 1A ❘ JUSTIFY ✠ 1H ELABORATION 1D JUSTIFY ✠ ✠ 1B 1C 1E CONJUNCTION 1F 1G 2212 Proceedings of the 2015 Conference on Empirical Methods in N</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>Radu Soricut and Daniel Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 149–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip J Stone</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="7604" citStr="Stone, 1966" startWordPosition="1176" endWordPosition="1177">n social science applications, the desired labels may not correspond directly to positive or negative sentiment, but may focus on other categories, such as politeness (Danescu-NiculescuMizil et al., 2013), narrative frames (Jurafsky et al., 2014), or a multidimensional spectrum of emotions (Kim et al., 2012). In these cases, labeled documents may not be available, so users often employ a simpler method: counting matches against lists of words associated with each category. Such lists may be built manually from introspection, as in LIWC (Tausczik and Pennebaker, 2010) and the General Inquirer (Stone, 1966). Alternatively, they may be induced by bootstrapping from a seed set of words (Hatzivassiloglou and McKeown, 1997; Taboada et al., 2011). While lexicon-based methods may be less accurate than supervised classifiers, they are easier to apply to 1https://github.com/jiyfeng/DPLP 2213 1H 1A Figure 2: Dependency-based discourse tree representation of the discourse in Figure 1 new domains and problem settings. Our proposed approach can be used in combination with either method for sentiment analysis, and in principle, could be directly applied to other document-level categories, such as politeness.</context>
</contexts>
<marker>Stone, 1966</marker>
<rawString>Philip J. Stone. 1966. The General Inquirer: A Computer Approach to Content Analysis. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexiconbased methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational linguistics,</journal>
<pages>37--2</pages>
<contexts>
<context position="7741" citStr="Taboada et al., 2011" startWordPosition="1196" endWordPosition="1199">n other categories, such as politeness (Danescu-NiculescuMizil et al., 2013), narrative frames (Jurafsky et al., 2014), or a multidimensional spectrum of emotions (Kim et al., 2012). In these cases, labeled documents may not be available, so users often employ a simpler method: counting matches against lists of words associated with each category. Such lists may be built manually from introspection, as in LIWC (Tausczik and Pennebaker, 2010) and the General Inquirer (Stone, 1966). Alternatively, they may be induced by bootstrapping from a seed set of words (Hatzivassiloglou and McKeown, 1997; Taboada et al., 2011). While lexicon-based methods may be less accurate than supervised classifiers, they are easier to apply to 1https://github.com/jiyfeng/DPLP 2213 1H 1A Figure 2: Dependency-based discourse tree representation of the discourse in Figure 1 new domains and problem settings. Our proposed approach can be used in combination with either method for sentiment analysis, and in principle, could be directly applied to other document-level categories, such as politeness. 2.3 Datasets We evaluate on two review datasets. In both cases, the goal is to correctly classify the opinion polarity as positive or ne</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexiconbased methods for sentiment analysis. Computational linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
</authors>
<title>SFU review corpus.</title>
<date>2008</date>
<note>http://www.sfu.ca/˜mtaboada/ research/SFU_Review_Corpus.html.</note>
<contexts>
<context position="16489" citStr="Taboada, 2008" startWordPosition="2637" endWordPosition="2638">s on the Pang &amp; Lee data, outperforming the baseline classifier (D2) by 1.3%. The accuracy of discourse relation detection is only 60% for even the best systems (Ji and Eisen2215 stein, 2014), which may help to explain why relations do not offer a more substantial boost. An anonymous reviewer recommended evaluating on gold RST parse trees to determine the extent to which improvements in RST parsing might transfer to downstream document analysis. Such an evaluation would seem to require a large corpus of texts with both gold RST parse trees and sentiment polarity labels; the SFU Review Corpus (Taboada, 2008) of 30 review texts offers a starting point, but is probably too small to train a competitive sentiment analysis system. 5 Related Work Section 2 mentions some especially relevant prior work. Other efforts to incorporate RST into sentiment analysis have often focused on intrasentential discourse relations (Heerschop et al., 2011; Zhou et al., 2011; Chenlo et al., 2014), rather than relations over the entire document. Wang et al. (2012) address sentiment analysis in Chinese. Lacking a discourse parser, they focus on explicit connectives, using a strategy that is related to our discourse depth r</context>
</contexts>
<marker>Taboada, 2008</marker>
<rawString>Maite Taboada. 2008. SFU review corpus. http://www.sfu.ca/˜mtaboada/ research/SFU_Review_Corpus.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yla R Tausczik</author>
<author>James W Pennebaker</author>
</authors>
<title>The psychological meaning of words: LIWC and computerized text analysis methods.</title>
<date>2010</date>
<journal>Journal of Language and Social Psychology,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="7565" citStr="Tausczik and Pennebaker, 2010" startWordPosition="1168" endWordPosition="1171"> the target, and this is not always possible. Moreover, in social science applications, the desired labels may not correspond directly to positive or negative sentiment, but may focus on other categories, such as politeness (Danescu-NiculescuMizil et al., 2013), narrative frames (Jurafsky et al., 2014), or a multidimensional spectrum of emotions (Kim et al., 2012). In these cases, labeled documents may not be available, so users often employ a simpler method: counting matches against lists of words associated with each category. Such lists may be built manually from introspection, as in LIWC (Tausczik and Pennebaker, 2010) and the General Inquirer (Stone, 1966). Alternatively, they may be induced by bootstrapping from a seed set of words (Hatzivassiloglou and McKeown, 1997; Taboada et al., 2011). While lexicon-based methods may be less accurate than supervised classifiers, they are easier to apply to 1https://github.com/jiyfeng/DPLP 2213 1H 1A Figure 2: Dependency-based discourse tree representation of the discourse in Figure 1 new domains and problem settings. Our proposed approach can be used in combination with either method for sentiment analysis, and in principle, could be directly applied to other documen</context>
</contexts>
<marker>Tausczik, Pennebaker, 2010</marker>
<rawString>Yla R Tausczik and James W Pennebaker. 2010. The psychological meaning of words: LIWC and computerized text analysis methods. Journal of Language and Social Psychology, 29(1):24–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rakshit Trivedi</author>
<author>Jacob Eisenstein</author>
</authors>
<title>Discourse connectors for latent subjectivity in sentiment analysis.</title>
<date>2013</date>
<booktitle>In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<pages>808--813</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, Pennsylvania.</location>
<contexts>
<context position="17991" citStr="Trivedi and Eisenstein, 2013" startWordPosition="2873" endWordPosition="2876">predictions at the sub-sentence level, rather than improving document-level prediction. None of the prior work considers the sort of recurrent compositional model presented here. An alternative to RST is to incorporate “shallow” discourse structure, such as the relations from the Penn Discourse Treebank (PDTB). PDTB relations were shown to improve sentencelevel sentiment analysis by Somasundaran et al. (2009), and were incorporated in a model of sentiment flow by Wachsmuth et al. (2014). PDTB relations are often signaled with explicit discourse connectives, and these may be used as a feature (Trivedi and Eisenstein, 2013; Lazaridou et al., 2013) or as posterior constraints (Yang and Cardie, 2014). This prior work on discourse relations within sentences and between adjacent sentences can be viewed as complementary to our focus on higher-level discourse relations across the entire document. There are unfortunately few possibilities for direct comparison of our approach against prior work. Heerschop et al. (2011) and Wachsmuth et al. (2014) also employ the Pang and Lee (2004) dataset, but neither of their results are directly comparable: Heerschop et al. (2011) exclude documents that SPADE fails to parse, and Wa</context>
</contexts>
<marker>Trivedi, Eisenstein, 2013</marker>
<rawString>Rakshit Trivedi and Jacob Eisenstein. 2013. Discourse connectors for latent subjectivity in sentiment analysis. In Proceedings of the North American Chapter of the Association for Computational Linguistics (NAACL), pages 808–813, Stroudsburg, Pennsylvania. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vin´ıcius Rodrigues Uzˆeda</author>
</authors>
<title>Thiago Alexandre Salgueiro Pardo, and Maria Das Grac¸as Volpe Nunes.</title>
<date>2010</date>
<journal>ACM Transactions on Speech and Language Processing (TSLP),</journal>
<volume>6</volume>
<issue>4</issue>
<marker>Uzˆeda, 2010</marker>
<rawString>Vin´ıcius Rodrigues Uzˆeda, Thiago Alexandre Salgueiro Pardo, and Maria Das Grac¸as Volpe Nunes. 2010. A comprehensive comparative evaluation of rst-based summarization methods. ACM Transactions on Speech and Language Processing (TSLP), 6(4):4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kimberly Voll</author>
<author>Maite Taboada</author>
</authors>
<title>Not all words are created equal: Extracting semantic orientation as a function of adjective relevance.</title>
<date>2007</date>
<booktitle>In Proceedings of Australian Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="2361" citStr="Voll and Taboada (2007)" startWordPosition="342" endWordPosition="345">sentiment words. But the discourse structure — indicated here with Rhetorical Structure Theory (RST; Mann and Thompson, 1988) — ∗Code is available at https://github.com/ parry2403/R2N2 CONCESSION CONJUNCTION [It could have been a great movie]1A [It does have beautiful sceneryj1B [some of the best since Lord of the Rings.]1C [The acting is well donej1D [and I really liked the son of the leader of the Samurai.]1E [He was a likable chapj1F [and I ✿✿✿✿ hated to see him die.]1G [But, other than all that, this movie is ✿✿✿✿✿✿ nothing more than hidden✿✿✿✿✿ rip-offs.]1H Figure 1: Example adapted from Voll and Taboada (2007). clearly favors the final sentence, whose polarity is negative. This example is illustrative in more than one way: it was originally identified by Voll and Taboada (2007), who found that manuallyannotated RST parse trees improved lexiconbased sentiment analysis, but that automaticallygenerated parses from the SPADE parser (Soricut and Marcu, 2003), which was then state-of-the-art, did not. Since this time, RST discourse parsing has improved considerably, with the best systems now yielding 5-10% greater raw accuracy than SPADE, depending on the metric. The time is therefore right to reconsider</context>
<context position="5226" citStr="Voll and Taboada (2007)" startWordPosition="791" endWordPosition="794">ite, or they may be multinuclear. In the example in Figure 1, the unit 1C is the satellite of a relationship with its nucleus 1B; together they form a larger discourse unit, which is involved in a multinuclear CONJUNCTION relation. The nuclearity structure of RST trees suggests a natural approach to evaluating the importance of segments of text: satellites tend to be less important, and nucleii tend to be more important (Marcu, 1999). This idea has been leveraged extensively in document summarization (Gerani et al., 2014; Uzˆeda et al., 2010; Yoshida et al., 2014), and was the inspiration for Voll and Taboada (2007), who examined intra-sentential relations, eliminating all words except those in the top-most nucleus within each sentence. More recent work focuses on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a recent spike of interest in this task, with contemporary approaches employing discriminat</context>
</contexts>
<marker>Voll, Taboada, 2007</marker>
<rawString>Kimberly Voll and Maite Taboada. 2007. Not all words are created equal: Extracting semantic orientation as a function of adjective relevance. In Proceedings of Australian Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henning Wachsmuth</author>
<author>Martin Trenkmann</author>
<author>Benno Stein</author>
<author>Gregor Engels</author>
</authors>
<title>Modeling review argumentation for robust sentiment analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING).</booktitle>
<contexts>
<context position="17854" citStr="Wachsmuth et al. (2014)" startWordPosition="2851" endWordPosition="2854"> based on the discourse structure. Zirn et al. (2011) use an RST parser in a Markov Logic Network, with the goal of making polarity predictions at the sub-sentence level, rather than improving document-level prediction. None of the prior work considers the sort of recurrent compositional model presented here. An alternative to RST is to incorporate “shallow” discourse structure, such as the relations from the Penn Discourse Treebank (PDTB). PDTB relations were shown to improve sentencelevel sentiment analysis by Somasundaran et al. (2009), and were incorporated in a model of sentiment flow by Wachsmuth et al. (2014). PDTB relations are often signaled with explicit discourse connectives, and these may be used as a feature (Trivedi and Eisenstein, 2013; Lazaridou et al., 2013) or as posterior constraints (Yang and Cardie, 2014). This prior work on discourse relations within sentences and between adjacent sentences can be viewed as complementary to our focus on higher-level discourse relations across the entire document. There are unfortunately few possibilities for direct comparison of our approach against prior work. Heerschop et al. (2011) and Wachsmuth et al. (2014) also employ the Pang and Lee (2004) d</context>
</contexts>
<marker>Wachsmuth, Trenkmann, Stein, Engels, 2014</marker>
<rawString>Henning Wachsmuth, Martin Trenkmann, Benno Stein, and Gregor Engels. 2014. Modeling review argumentation for robust sentiment analysis. In Proceedings of the International Conference on Computational Linguistics (COLING).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wang</author>
<author>Yunfang Wu</author>
</authors>
<title>Exploiting hierarchical discourse structure for review sentiment analysis.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Asian Language Processing (IALP),</booktitle>
<pages>121--124</pages>
<contexts>
<context position="17119" citStr="Wang and Wu (2013)" startWordPosition="2736" endWordPosition="2739">w texts offers a starting point, but is probably too small to train a competitive sentiment analysis system. 5 Related Work Section 2 mentions some especially relevant prior work. Other efforts to incorporate RST into sentiment analysis have often focused on intrasentential discourse relations (Heerschop et al., 2011; Zhou et al., 2011; Chenlo et al., 2014), rather than relations over the entire document. Wang et al. (2012) address sentiment analysis in Chinese. Lacking a discourse parser, they focus on explicit connectives, using a strategy that is related to our discourse depth reweighting. Wang and Wu (2013) use manually-annotated discourse parses in combination with a sentiment lexicon, which is automatically updated based on the discourse structure. Zirn et al. (2011) use an RST parser in a Markov Logic Network, with the goal of making polarity predictions at the sub-sentence level, rather than improving document-level prediction. None of the prior work considers the sort of recurrent compositional model presented here. An alternative to RST is to incorporate “shallow” discourse structure, such as the relations from the Penn Discourse Treebank (PDTB). PDTB relations were shown to improve senten</context>
</contexts>
<marker>Wang, Wu, 2013</marker>
<rawString>Fei Wang and Yunfang Wu. 2013. Exploiting hierarchical discourse structure for review sentiment analysis. In Proceedings of the Conference on Asian Language Processing (IALP), pages 121–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wang</author>
<author>Yunfang Wu</author>
<author>Likun Qiu</author>
</authors>
<title>Exploiting discourse relations for sentiment analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1311--1320</pages>
<location>Mumbai, India.</location>
<contexts>
<context position="16928" citStr="Wang et al. (2012)" startWordPosition="2706" endWordPosition="2709">ment analysis. Such an evaluation would seem to require a large corpus of texts with both gold RST parse trees and sentiment polarity labels; the SFU Review Corpus (Taboada, 2008) of 30 review texts offers a starting point, but is probably too small to train a competitive sentiment analysis system. 5 Related Work Section 2 mentions some especially relevant prior work. Other efforts to incorporate RST into sentiment analysis have often focused on intrasentential discourse relations (Heerschop et al., 2011; Zhou et al., 2011; Chenlo et al., 2014), rather than relations over the entire document. Wang et al. (2012) address sentiment analysis in Chinese. Lacking a discourse parser, they focus on explicit connectives, using a strategy that is related to our discourse depth reweighting. Wang and Wu (2013) use manually-annotated discourse parses in combination with a sentiment lexicon, which is automatically updated based on the discourse structure. Zirn et al. (2011) use an RST parser in a Markov Logic Network, with the goal of making polarity predictions at the sub-sentence level, rather than improving document-level prediction. None of the prior work considers the sort of recurrent compositional model pr</context>
</contexts>
<marker>Wang, Wu, Qiu, 2012</marker>
<rawString>Fei Wang, Yunfang Wu, and Likun Qiu. 2012. Exploiting discourse relations for sentiment analysis. In Proceedings of the International Conference on Computational Linguistics (COLING), pages 1311– 1320, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>347--354</pages>
<contexts>
<context position="10651" citStr="Wilson et al. (2005)" startWordPosition="1694" endWordPosition="1697">ction for weighting the contribution of the EDU at depth di: λi = max(0.5,1 − di/6). (1) Thus, at di = 0, we have λi = 1, and at di &gt; 3, we have λi = 0.5. Now assume each elementary discourse unit contributes a prediction Oi = θTwi, where wi is the bag-of-words vector, and θ is a vector of weights, which may be either learned or specified by a sentiment lexicon. Then the overall prediction for a document is given by, Y: Ψ = Y: λi(θ�wi) = θ�( λiwi). (2) i i Evaluation We apply this approach in combination with both lexicon-based and classificationbased sentiment analysis. We use the lexicon of Wilson et al. (2005), and set θj = 1 for words marked “positive”, and θj = −1 for words marked negative. For classification-based analysis, we set θ equal to the weights obtained by training a logistic regression classifier, tuning the regularization coefficient on held-out data. Results are shown in Table 1. As seen in the comparison between lines B1 and D1, discourse depth weighting offers substantial improvements over the bag-of-words approach for lexiconbased sentiment analysis, with raw improvements of 4−5%. Given the simplicity of this approach — which requires only a sentiment lexicon and a discourse parse</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP), pages 347–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bishan Yang</author>
<author>Claire Cardie</author>
</authors>
<title>Context-aware learning for sentence-level sentiment analysis with posterior regularization.</title>
<date>2014</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL),</booktitle>
<location>Baltimore, MD.</location>
<contexts>
<context position="18068" citStr="Yang and Cardie, 2014" startWordPosition="2885" endWordPosition="2888">ion. None of the prior work considers the sort of recurrent compositional model presented here. An alternative to RST is to incorporate “shallow” discourse structure, such as the relations from the Penn Discourse Treebank (PDTB). PDTB relations were shown to improve sentencelevel sentiment analysis by Somasundaran et al. (2009), and were incorporated in a model of sentiment flow by Wachsmuth et al. (2014). PDTB relations are often signaled with explicit discourse connectives, and these may be used as a feature (Trivedi and Eisenstein, 2013; Lazaridou et al., 2013) or as posterior constraints (Yang and Cardie, 2014). This prior work on discourse relations within sentences and between adjacent sentences can be viewed as complementary to our focus on higher-level discourse relations across the entire document. There are unfortunately few possibilities for direct comparison of our approach against prior work. Heerschop et al. (2011) and Wachsmuth et al. (2014) also employ the Pang and Lee (2004) dataset, but neither of their results are directly comparable: Heerschop et al. (2011) exclude documents that SPADE fails to parse, and Wachsmuth et al. (2014) evaluates only on individual sentences rather than enti</context>
</contexts>
<marker>Yang, Cardie, 2014</marker>
<rawString>Bishan Yang and Claire Cardie. 2014. Context-aware learning for sentence-level sentiment analysis with posterior regularization. In Proceedings of the Association for Computational Linguistics (ACL), Baltimore, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuhisa Yoshida</author>
<author>Jun Suzuki</author>
<author>Tsutomu Hirao</author>
<author>Masaaki Nagata</author>
</authors>
<title>Dependency-based Discourse Parser for Single-Document Summarization.</title>
<date>2014</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="5173" citStr="Yoshida et al., 2014" startWordPosition="782" endWordPosition="785">course relations may involve a nucleus and a satellite, or they may be multinuclear. In the example in Figure 1, the unit 1C is the satellite of a relationship with its nucleus 1B; together they form a larger discourse unit, which is involved in a multinuclear CONJUNCTION relation. The nuclearity structure of RST trees suggests a natural approach to evaluating the importance of segments of text: satellites tend to be less important, and nucleii tend to be more important (Marcu, 1999). This idea has been leveraged extensively in document summarization (Gerani et al., 2014; Uzˆeda et al., 2010; Yoshida et al., 2014), and was the inspiration for Voll and Taboada (2007), who examined intra-sentential relations, eliminating all words except those in the top-most nucleus within each sentence. More recent work focuses on reweighting each discourse unit depending on the relations in which it participates (Heerschop et al., 2011; Hogenboom et al., 2015). We consider such an approach, and compare it with a compositional method, in which sentiment polarity is propagated up the discourse tree. Marcu (1997) provides the seminal work on automatic RST parsing, but there has been a recent spike of interest in this tas</context>
</contexts>
<marker>Yoshida, Suzuki, Hirao, Nagata, 2014</marker>
<rawString>Yasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao, and Masaaki Nagata. 2014. Dependency-based Discourse Parser for Single-Document Summarization. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lanjun Zhou</author>
<author>Binyang Li</author>
<author>Wei Gao</author>
<author>Zhongyu Wei</author>
<author>Kam-Fai Wong</author>
</authors>
<title>Unsupervised discovery of discourse relations for eliminating intrasentence polarity ambiguities.</title>
<date>2011</date>
<booktitle>In Proceedings of Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>162--171</pages>
<contexts>
<context position="16838" citStr="Zhou et al., 2011" startWordPosition="2691" endWordPosition="2694">termine the extent to which improvements in RST parsing might transfer to downstream document analysis. Such an evaluation would seem to require a large corpus of texts with both gold RST parse trees and sentiment polarity labels; the SFU Review Corpus (Taboada, 2008) of 30 review texts offers a starting point, but is probably too small to train a competitive sentiment analysis system. 5 Related Work Section 2 mentions some especially relevant prior work. Other efforts to incorporate RST into sentiment analysis have often focused on intrasentential discourse relations (Heerschop et al., 2011; Zhou et al., 2011; Chenlo et al., 2014), rather than relations over the entire document. Wang et al. (2012) address sentiment analysis in Chinese. Lacking a discourse parser, they focus on explicit connectives, using a strategy that is related to our discourse depth reweighting. Wang and Wu (2013) use manually-annotated discourse parses in combination with a sentiment lexicon, which is automatically updated based on the discourse structure. Zirn et al. (2011) use an RST parser in a Markov Logic Network, with the goal of making polarity predictions at the sub-sentence level, rather than improving document-level</context>
</contexts>
<marker>Zhou, Li, Gao, Wei, Wong, 2011</marker>
<rawString>Lanjun Zhou, Binyang Li, Wei Gao, Zhongyu Wei, and Kam-Fai Wong. 2011. Unsupervised discovery of discourse relations for eliminating intrasentence polarity ambiguities. In Proceedings of Empirical Methods for Natural Language Processing (EMNLP), pages 162–171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C¨acilia Zirn</author>
<author>Mathias Niepert</author>
<author>Heiner Stuckenschmidt</author>
<author>Michael Strube</author>
</authors>
<title>Fine-grained sentiment analysis with structural features.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP),</booktitle>
<pages>336--344</pages>
<location>Chiang Mai, Thailand.</location>
<contexts>
<context position="15272" citStr="Zirn et al. (2011)" startWordPosition="2442" endWordPosition="2445">the root node we have: �IFdoc = γθ�( wi) + IFrst-root, (5) i with IFrst-root defined recursively from Equations 3 and 4, θ indicating the vector of per-word weights, and the scalar γ controlling the tradeoff between these two components. Learning R2N2 is trained by backpropagating from a hinge loss objective; assuming yt E 1−1, 11 for each document t, we have the loss Lt = (1 − ytIFdoc,t)+. From this loss, we use backpropagation through structure to obtain gradients on the parameters (Goller and Kuchler, 1996). Training is performed using stochastic gradient descent. For simplicity, we follow Zirn et al. (2011) and focus on the distinction between contrastive and non-contrastive relations. The set of contrastive relations includes CONTRAST, COMPARISON, ANTITHESIS, ANTITHESIS-E, CONSEQUENCE-S, CONCESSION, and PROBLEM-SOLUTION. Evaluation Results for this approach are shown in lines R1 and R2 of Table 1. Even without distinguishing between discourse relations, we get an improvement of more than 3% accuracy on the Stanford data, and 0.5% on the smaller Pang &amp; Lee dataset. Adding sensitivity to discourse relations (distinguishing K(r) for contrastive and noncontrastive relations) offers further improvem</context>
<context position="17284" citStr="Zirn et al. (2011)" startWordPosition="2760" endWordPosition="2763">nt prior work. Other efforts to incorporate RST into sentiment analysis have often focused on intrasentential discourse relations (Heerschop et al., 2011; Zhou et al., 2011; Chenlo et al., 2014), rather than relations over the entire document. Wang et al. (2012) address sentiment analysis in Chinese. Lacking a discourse parser, they focus on explicit connectives, using a strategy that is related to our discourse depth reweighting. Wang and Wu (2013) use manually-annotated discourse parses in combination with a sentiment lexicon, which is automatically updated based on the discourse structure. Zirn et al. (2011) use an RST parser in a Markov Logic Network, with the goal of making polarity predictions at the sub-sentence level, rather than improving document-level prediction. None of the prior work considers the sort of recurrent compositional model presented here. An alternative to RST is to incorporate “shallow” discourse structure, such as the relations from the Penn Discourse Treebank (PDTB). PDTB relations were shown to improve sentencelevel sentiment analysis by Somasundaran et al. (2009), and were incorporated in a model of sentiment flow by Wachsmuth et al. (2014). PDTB relations are often sig</context>
</contexts>
<marker>Zirn, Niepert, Stuckenschmidt, Strube, 2011</marker>
<rawString>C¨acilia Zirn, Mathias Niepert, Heiner Stuckenschmidt, and Michael Strube. 2011. Fine-grained sentiment analysis with structural features. In Proceedings of the International Joint Conference on Natural Language Processing (IJCNLP), pages 336–344, Chiang Mai, Thailand.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>