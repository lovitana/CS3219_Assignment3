<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002240">
<title confidence="0.995177">
Hierarchical Incremental Adaptation for Statistical Machine Translation
</title>
<author confidence="0.987831">
Joern Wuebker Spence Green John DeNero
</author>
<affiliation confidence="0.973769">
Lilt Inc. Lilt Inc. Lilt Inc.
</affiliation>
<email confidence="0.997533">
joern@lilt.com spence@lilt.com john@lilt.com
</email>
<sectionHeader confidence="0.998592" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999994230769231">
We present an incremental adaptation ap-
proach for statistical machine translation
that maintains a flexible hierarchical do-
main structure within a single consistent
model. Both weights and rules are updated
incrementally on a stream of post-edits. Our
multi-level domain hierarchy allows the sys-
tem to adapt simultaneously towards local
context at different levels of granularity, in-
cluding genres and individual documents.
Our experiments show consistent improve-
ments in translation quality from all com-
ponents of our approach.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953282608696">
Suggestions from a machine translation system can
increase the speed and quality of professional hu-
man translators (Guerberof, 2009; Plitt and Mas-
selot, 2010; Green et al., 2013a, inter alia). How-
ever, querying a single fixed model for all different
documents fails to incorporate contextual informa-
tion that can potentially improve suggestion quality.
We describe a model architecture that adapts simul-
taneously to multiple genres and individual docu-
ments, so that translation suggestions are informed
by two levels of contextual information.
Our primary technical contribution is a hierarchi-
cal adaptation technique for a post-editing scenario
with incremental adaptation, in which users request
translations of sentences in corpus order and pro-
vide corrected translations of each sentence back
to the system (Ortiz-Martínez et al., 2010). Our
learning approach resembles Hierarchical Bayesian
Domain Adaptation (Finkel and Manning, 2009),
but updates both the model weights and translation
rules in real time based on these corrected transla-
tions (Mathur et al., 2013; Denkowski et al., 2014).
Our adapted system can provide on-demand trans-
lations for any genre and document to which it has
ever been exposed, using weights and rules for do-
mains associated with each translation request.
Our weight adaptation is performed using a hier-
archical extension to fast and adaptive online train-
ing (Green et al., 2013b), a technique based on Ada-
Grad (Duchi et al., 2011) and forward-backward
splitting (Duchi and Singer, 2009) that can accu-
rately set weights for both dense and sparse fea-
tures (Green et al., 2014b). Rather than adjusting
all weights based on each example, our extension
adjusts offsets to a fixed baseline system. In this
way, the system can adapt to multiple genres while
preventing cross-genre contamination.
In large-scale experiments, we adapt a multi-
genre baseline system to patents, lectures, and news
articles. Our experiments show that sparse mod-
els, hierarchical updates, and rule adaptation all
contribute consistent improvements. We observe
quality gains in all genres, validating our hypothe-
sis that document and genre context are important
additional inputs to a machine translation system
used for post-editing.
</bodyText>
<sectionHeader confidence="0.996999" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.99958">
The log-linear appoach to statistical machine trans-
lation models the predictive translation distribution
p(eIf; w) directly in log-linear form (Och and Ney,
2004):
</bodyText>
<equation confidence="0.998879333333333">
Z1f) exp I
wTφ(r; c)] (1)
p(e|f; w) = �
</equation>
<page confidence="0.87283725">
r:
src(r)=f
tgt(r)=e
1059
</page>
<note confidence="0.9849895">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1059–1065,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.998633363636363">
where f E F is a string in the set of all source
language strings F, e E £ is a string in the set of
all target language strings £, r is a phrasal deriva-
tion with source and target projections src(r) and
tgt(r), w E Rd is the vector of model parameters,
0(·) E Rd is a feature map computed using corpus
c, and Z(f) is an appropriate normalizing constant.
During search, the maximum approximation is ap-
plied rather than summing over the derivations r.
Model. We extend a phrase-based system for which
0(r; c) includes 16 dense features:
</bodyText>
<listItem confidence="0.998036384615385">
• Two phrasal channel models and two lexical
channel models (Koehn et al., 2003), the (log)
count of the rule in the training corpus c, and
an indicator for singleton rules in c.
• Six orientation models that score ordering con-
figurations in r by their frequency in c (Koehn
et al., 2007).
• A linear distortion penalty that promotes
monotonic translation.
• An n-gram language model score, p(e), which
scores the target language projection of r using
statistics from a monolingual corpus.
• Fixed-value phrase and word penalties.
</listItem>
<bodyText confidence="0.999936666666667">
The elements of 0(r; c) may also include sparse
features that have non-zero values for only a subset
of rules, but typically do not depend on c (Liang
et al., 2006). In this paper, we use four types of
sparse features: rule indicators, discriminative lexi-
calized reordering indicators, rule shape indicators
and alignment features (Green et al., 2014b).
The model parameters w are chosen to maximize
translation quality on a tuning set.
Adaptation. Domain adaptation for machine trans-
lation has improved quality using a variety of ap-
proaches, including data selection (Ceau§fu et al.,
2011), regularized online learning (Simianer et al.,
2012; Green et al., 2013b), and input classification
(Xu et al., 2007; Banerjee et al., 2010; Wang et
al., 2012) and has also been investigated for multi-
domain tasks (Sennrich et al., 2013; Cui et al., 2013;
Simianer and Riezler, 2013). Even without domain
labels at either training or test time, multi-task learn-
ing can boost translation quality in a batch setting
(Duh et al., 2010; Song et al., 2011).
Post-editing with incremental adaptation de-
scribes a particular mixed-initiative setting (Ortiz-
Martínez et al., 2010; Hardt and Elming, 2010). For
each f in a corpus, the machine generates a hypothe-
sis e, then a human provides a corrected translation
e∗ to the machine. Observing e∗ can affect both the
</bodyText>
<figure confidence="0.762843">
Root Domain
</figure>
<figureCaption confidence="0.900987">
Figure 1: The weights used to translate a document
in the patent genre include three domains.
</figureCaption>
<bodyText confidence="0.999963">
model weights w and corpus c used for rule extrac-
tion and dense feature estimation.1 To translate the
ith sentence fi, the system uses weights wi−1 and
corpus ci−1. The new corpus ci results from adding
(fi, e∗i) to ci−1. For incremental adaptation, speed
is essential, and so wi is typically computed with
a single online update from wi−1 using (fi, e∗i) as
the tuning example.
To alleviate the need for human intervention in
the experiment cycle, simulated post-editing (Hardt
and Elming, 2010; Denkowski et al., 2014) replaces
each e∗ with a reference that is not a corrected vari-
ant of e. Thus, a standard test corpus can be used as
an adaptation corpus. Prior work on online learn-
ing from post-edits has demonstrated the benefit of
adjusting only c (Ortiz-Martínez et al., 2010; Hardt
and Elming, 2010) and further benefit from adjust-
ing both c and w (Mathur et al., 2013; Denkowski
et al., 2014). Incremental adaptation of both c and
the weights w for sparse features is reported to yield
large quality gains by Wäschle et al. (2013).2
</bodyText>
<sectionHeader confidence="0.989792" genericHeader="method">
3 Hierarchical Incremental Adaptation
</sectionHeader>
<bodyText confidence="0.998127818181818">
Our hierachical approach to incremental adaptation
uses document and genre information to adapt ap-
propriately to multiple contexts. We assume that
each sentence fi has a known set Di of domains,
which identify the genre and individual document
origin of the sentence. This set could be extended
to include topics, individual translators, etc.
Figure 1 shows the domains that we apply in
experiments. All sentences in the baseline training
corpus, the tuning corpus, and the adaptation corpus
share a ROOT domain.
</bodyText>
<footnote confidence="0.999055428571429">
1For the purpose of our description, the corpus c is equiva-
lent to the set of phrases and their scores in the rule table. We
prefer this notation because it is consistent with our stream-
based rule table, where the models are computed on-the-fly
from the indexed training corpus c.
2Language model adaptation also has a rich literature, but
it is beyond the scope of this paper.
</footnote>
<table confidence="0.5482805">
Each document has 3 domains: root, its genre, &amp; the document itself
Patents Genre News Genre Lectures Genre
</table>
<page confidence="0.880895">
1060
</page>
<bodyText confidence="0.999899333333333">
Our adaptation is conceptually similar to hier-
archical Bayesian domain adaptation (Finkel and
Manning, 2009), but both weights and feature val-
ues depend on Di, and we use L1 regularization.
Weight Updates. Model tuning and adaptation are
performed with AdaGrad, an online subgradient
method with an adaptive learning rate that comes
with good theoretical guarantees. AdaGrad makes
the following update:
</bodyText>
<equation confidence="0.999886875">
wt = wt−1 − ηΣ1/2
t V`t(wt−1) (2)
Σ−1
t = Σ−1
t−1 + V`t(wt−1)V`t(wt−1)T
t
= V`i(wi−1)V`i(wi−1)T (3)
i=1
</equation>
<bodyText confidence="0.9999098">
The loss function ` reflects the pairwise ordering
between hypotheses. For feature selection, we ap-
ply an L1 penalty via forward-backward splitting
(Duchi and Singer, 2009). η is the initial learning
rate. See (Green et al., 2013b) for details.
Our adaptation schema is an extension offrustrat-
ingly easy domain adaptation (FEDA) (Daumé III,
2007) to multiple domains with different regular-
ization parameters, similar to (Finkel and Manning,
2009). Each feature value is replicated for each do-
main. Let D denote the set of all domains present in
the adaptation set. Given an original feature vector
φ(r; c) for derivation r of sentence fi with Di C D,
the replicated feature vector includes |D |copies of
φ(r; c), one for each d E |D|, such that
</bodyText>
<equation confidence="0.911215666666667">
�
φ(r; c), d E Di
φd(r; c) = (4)
</equation>
<bodyText confidence="0.85288375">
0, otherwise.
The weights of this replicated feature space are ini-
tialized using the weights w tuned for the baseline
φ(r; c).
</bodyText>
<equation confidence="0.9255805">
w, d is ROOT
wd = �0, otherwise. (5)
</equation>
<bodyText confidence="0.999635491803279">
In this way, the ROOT domain corresponds to the un-
adapted baseline weights, denoted as Θ* in (Finkel
and Manning, 2009). The idea is that we simultane-
ously maintain a generic set of weights that applies
to all domains as well as their domain-specific “off-
sets”, describing how a domain differs from the
generic case. Model updates during adaptation are
performed according to the same procedure as tun-
ing updates, but now in the replicated space.
Different from (Finkel and Manning, 2009), this
generalized FEDA model does not restrict the do-
mains to be strictly hierarchically structured. We
could, for example, include a domain for each trans-
lator that crossed different genres. However, all of
our experimental evaluations maintain a hierarchi-
cal domain structure, leaving more general setups
to future work.
Rules and Feature Values. A derivation r of sen-
tence fi has features that are computed from the
combination of the baseline training corpus c0 and
a genre-specific corpus that includes all sentence
pairs from the tuning corpus as well as from the
adaptation corpus (fj, ej*) with j &lt; i sharing fi&apos;s
genre. We refer to this combined corpus as ci. The
tuning corpus is the same that is used for parameter
tuning in the baseline system. The adaptation cor-
pus is our test set. Note that in our evaluation, each
sentence is translated before it is used for adaptation,
so that there is no contamination of results.
In order to extend the model efficiently within
a streaming data environment, we make use of a
suffix-array implementation for our phrase table
(Levenberg et al., 2010).
Rather than combining corpus counts across
these different sources, separate rules extracted
from the baseline corpus and the genre-specific
corpus exist independently in the derivation space,
and features of each are computed only with one
corpus. In this configuration, a large amount of out-
of-domain evidence from the baseline model will
not dampen the feature value adaptation effects of
adding new sentence pairs from the adaptation cor-
pus. The genre-specific phrases are distinguished
by an additional binary provenance feature.
In order to extract features from the genre-
specific corpus, a word-level alignment must be
computed for each (fj, e*j). We force decode using
the adapted translation model for fj. In order to
avoid decoding failures, we insert high-cost single-
word translation rules that allow any word in fj to
align to any word in e*j.
Sparse Features. Applying a large number of
sparse features would compromise responsiveness
of our translation system and is thus a poor fit
for real-time adaptive computer-assisted transla-
tion. However, features that can be learned on a
single document are limited in number and can be
discarded after the document has been processed.
Therefore, document-level sparse features are a
powerful means to fit our model to local context
with a comparatively small impact on efficiency.
</bodyText>
<page confidence="0.982194">
1061
</page>
<sectionHeader confidence="0.999668" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999829041666667">
We performed two sets of German→English exper-
iments; Table 1 contains the results for both. Our
first set of experiments was performed on the PatTR
corpus (Wäschle and Riezler, 2012). We divided
the corpus into training and development data by
date and selected 2.4M parallel segments dated be-
fore 2000 from the “claims” section as bilingual
training data, taking equal parts from each of the
eight patent types A–H as classified by the Cooper-
ative Patent Classification (CPC). From each type
we further drew separate test sets and a single tune
set, selecting documents with at least 10 segments
and a maximum of 150 source words per segment,
with around 2,100 sentences per test set and 400
sentences per type for the tune set. The “claims”
section of this corpus is highly repetitive, which
makes it ideal for observing the effects of incremen-
tal adaptation techniques.
To train the language and translation model we
additionally leveraged all available bilingual and
monolingual data provided for the EMNLP 2015
Tenth Workshop on Machine Translation3. The to-
tal size of the bitext used for rule extraction and
feature estimation was 6.4M sentence pairs. We
trained a standard 5-gram language model with
modified Kneser-Ney smoothing (Kneser and Ney,
1995; Chen and Goodman, 1998) using the KenLM
toolkit (Heafield et al., 2013) on 4 billion running
words. The bitext was word-aligned with mgiza
(Och and Ney, 2003), and we used the phrasal de-
coder (Green et al., 2014a) with standard German-
English settings for experimentation.
Our second set of experiments was performed on
a mixed-genre corpus containing lectures, patents,
and news articles. The standard dev and test sets
of the IWSLT 2014 shared task4 were used for
the lecture genre. Each document corresponded
to an entire lecture. For the news genre, we used
newstest2012 for tuning, newstest2013 for meta-
parameter optimization, and newstest2014 for test-
ing. The tune set for the patent genre is identical
to the first set of experiments, while the test set
consists of the first 300 sentence pairs of each of
the patent type specific test sets of the previous ex-
periment. The documents in the news and patent
genres contain around 20 segments on average.
Our evaluation proceeded in multiple stages. We
first trained a set of background weights on the
</bodyText>
<footnote confidence="0.9998625">
3http://www.statmt.org/wmt15/
4http://workshop2014.iwslt.org/
</footnote>
<table confidence="0.986276571428571">
heterogeneous data
repetition rate 27.80
baseline
+ genre weights
+ genre TM
+ doc. weights
+ sparse features
</table>
<tableCaption confidence="0.999756">
Table 1: Results in uncased BLEU [%]. Each com-
</tableCaption>
<bodyText confidence="0.973276162162162">
ponent is added on top of the previous line. All
results in line + genre TM and below are statisti-
cally significant improvements over the baseline
with 95% confidence. We also report the repetition
rate of the test corpora as propsed by Bertoldi et al.
(2013).
concatenated tune sets (baseline). Keeping these
weights fixed, we performed an additional tun-
ing run to estimate genre-level weights (+ genre
weights).5 In the patent-only setup, we used patent
CPC type as genre. Next, we trained a genre-
specific translation model for each genre by first
feeding the tune set and then the test set into our
incremental adaptation learning method as a contin-
uous stream of simulated post edits (+ genre TM).
After each sentence, we performed an update on the
genre-specific weights. In separate experiments, we
also included document-level weights as an addi-
tional domain (+ doc. weights) and included sparse
features at the document level (+ sparse features).6
Table 1 demonstrates that each component of
this approach offered consistent incremental qual-
ity gains, but with varying magnitudes. For the
patent experiments we report the average over our
eight test sets (A-H) due to lack of space, but to-
tal improvement varied from +4.92 to +6.46 BLEU.
In the mixed-genre experiments, BLEU increased
by +2.27 on lectures, +0.97 on news, and +5.33
on patents. On all tasks, we observed statistically
significant improvements over the baseline (95%
confidence level) in the + genre TM, + doc. weights
and + sparse features experiments using bootstrap
resampling (Koehn, 2004).
These results demonstrate the efficacy of hierar-
chical incremental adaptation, although we would
like to stress that the patent data was selected specif-
ically for its high level of repetitiveness, and the
</bodyText>
<footnote confidence="0.99941625">
5Learning rates and regularization weights for this step
were selected on newstest2013.
6Learning rates and regularization weights for each genre
were selected on the genre-specific tune sets.
</footnote>
<table confidence="0.548898555555556">
PatTR
avg
48.89
49.05
53.25
53.56
54.53
lecture news patent
5.46 3.13 27.42
25.82 24.92 48.97
26.64 25.12 49.39
27.67 25.66 53.22
27.98 25.71 53.40
28.09 25.89 54.30
1062
BLEU [%] difference to baseline
2 4 6 8 10 12 14 16 18 20
i-th sentence in document
</table>
<figureCaption confidence="0.858931833333333">
Figure 2: BLEU difference between baseline + genre
weights and our incremental adaptation approach,
computed on a single segment from each document
according to their order, i.e. the first segment from
each document, then the second segment from each
document, etc.
</figureCaption>
<bodyText confidence="0.9997939375">
large improvement in this genre would only be ex-
pected to arise in similarly structured domains. This
property is quantified by the repetition rate mea-
sure (RR) (Bertoldi et al., 2013) reported in Table 1,
which confirms the finding by Cettolo et al. (2014)
that RR correlates with the effectiveness of adapta-
tion.
Analysis. Figure 2 shows BLEU score differences
to the baseline + genre weights system for different
subsets of the news and patent test sets. Each point
is computed by document slicing, i.e. on a single
segment from each document. The rightmost data
point is the BLEU score we obtain by evaluating on
the 20th segment of each document, grouped into a
pseudo-corpus. Note that this group does not cor-
respond to any number in Table 1, which reports
BLEU on the entire test sets. Thus, we evaluate on all
sentences that have learned from exactly (i−1) seg-
ments of the same document, with i = 1, ... ,19.
Although the graph is naturally very noisy (each
score is computed on roughly 150 segments), we
can clearly see that incremental adaptation learns
on the document level: on average, the improve-
ment over the baseline increases when proceeding
further into the document.
Decoding speed. In our real-time computer-
assisted translation scenario, a certain translation
speed is required to allow for responsive user in-
teraction. Table 2 reports the speed in words per
second on the lecture data. Adding a genre-specific
translation model results in a speed reduction by a
factor of 12.6 due to the additional (forced) decod-
</bodyText>
<table confidence="0.996711666666667">
words / sec
baseline 177.6
+ genre weights 58.5
+ genre TM 14.1
+ doc. weights 9.8
+ sparse features 5.8
</table>
<tableCaption confidence="0.999799">
Table 2: Decoding speed on the lecture data.
</tableCaption>
<bodyText confidence="0.999322285714286">
ing run and weight updates. Sparse features slows
the system down further by a factor of 2.4. However,
the largest part of the computation time incurs only
when the user has finalized collaborative translation
of one sentence and is busy reading the next source
sentence. Further, the speed/quality tradeoff can be
adjusted with pruning parameters.
</bodyText>
<sectionHeader confidence="0.997768" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999995333333333">
We have presented an incremental learning ap-
proach for MT that maintains a flexible hierarchical
domain structure within a single consistent model.
In our experiments, we define a three-level hierar-
chy with a global root domain as well as genre- and
document-level domains. Further, we perform in-
cremental adaptation by training a genre-specific
translation model on the stream of incoming post-
edits and adding document-level sparse features that
do not significantly compromise efficiency. Our re-
sults show consistent contributions from each level
of adaptation across multiple genres.
</bodyText>
<sectionHeader confidence="0.992372" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.972703263157895">
Pratyush Banerjee, Jinhua Du, Baoli Li, Sudip Kr.
Naskar, Andy Way, and Josef van Genabith. 2010.
Combining multi-domain statistical machine transla-
tion models using automatic classifiers. In Proceed-
ings of the Association for Machine Translation in
the Americas, Denver, Colorado, October.
Nicola Bertoldi, Mauro Cettolo, and Marcello Federico.
2013. Cache-based online adaptation for machine
translation enhanced computer assisted translation.
In Proceedings of the XIV Machine Translation Sum-
mit, pages 36–42, Nice, France, September.
Alexandru Ceau§fu, John Tinsley, Jian Zhang, and
Andy Way. 2011. Experiments on domain adap-
tation for patent machine translation in the PLuTO
project. In Mikel L. Forcada, Heidi Depraetere, and
Vincent Vandeghinste, editors, Proceedings of the
15th International Conference of the European Asso-
ciation for Machine Translation (EAMT), pages 21–
28, Leuven, Belgium.
</reference>
<figure confidence="0.9724875">
12
10
-2
8
4
2
6
0
</figure>
<bodyText confidence="0.987957666666667">
news + genre TM
news + doc. weights
news + sparse features
patent + genre TM
patent + doc. weights
patent + sparse features
</bodyText>
<page confidence="0.939397">
1063
</page>
<reference confidence="0.997908702702702">
Mauro Cettolo, Nicola Bertoldi, and Marcello Federico.
2014. The repetition rate of text as a predictor of the
effectiveness of machine translation adaptation. In
Conference of the Association for Machine Transla-
tion in the Americas (AMTA), pages 166–179, Van-
couver, Canada, October.
Stanley F. Chen and Joshuo Goodman. 1998. An
Empirical Study of Smoothing Techniques for Lan-
guage Modeling. Technical Report TR-10-98, Com-
puter Science Group, Harvard University, Cam-
bridge, MA, August.
Lei Cui, Xilun Chen, Dongdong Zhang, Shujie Liu,
Mu Li, and Ming Zhou. 2013. Multi-domain adapta-
tion for SMT using multi-task learning. In Proceed-
ings of the 2013 Conference on Empirical Methods
in Natural Language Processing, pages 1055–1065,
Seattle, Washington, USA, October.
Hal Daumé III. 2007. Frustratingly easy domain adap-
tation. In Proceedings of the 45th Annual Meeting of
the Association of Computational Linguistics, pages
256–263, Prague, Czech Republic, June.
Michael Denkowski, Chris Dyer, and Alon Lavie. 2014.
Learning from post-editing: Online model adapta-
tion for statistical machine translation. In Proceed-
ings of the 14th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 395–404, Gothenburg, Sweden, April.
John Duchi and Yoram Singer. 2009. Efficient online
and batch learning using forward backward splitting.
Journal of Machine Learning Research, 10:2899–
2934, December.
John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. Journal of Machine
Learning Research, 12:2121–2159, July.
Kevin Duh, Katsuhito Sudoh, Hajime Tsukada, Hideki
Isozaki, and Masaaki Nagata. 2010. N-best rerank-
ing by multitask learning. In Proceedings of the
Joint Fifth Workshop on Statistical Machine Trans-
lation and MetricsMATR, pages 375–383, Uppsala,
Sweden, July.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Hierarchical bayesian domain adaptation. In Pro-
ceedings of Human Language Technologies: The
2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 602–610, Boulder, Colorado.
Spence Green, Sida Wang, Daniel Cer, and Christo-
pher D. Manning. 2013a. The efficacy of human
post-editing for language translation. In ACM CHI
Conference on Human Factors in Computing Sys-
tems, Paris, France, April.
Spence Green, Sida Wang, Daniel Cer, and Christo-
pher D. Manning. 2013b. Fast and adaptive on-
line training of feature-rich translation models. In
51st Annual Meeting of the Association for Compu-
tational Linguistics, pages 311–321, Sofia, Bulgaria,
August.
Spence Green, Daniel Cer, , and Christopher D. Man-
ning. 2014a. Phrasal: A Toolkit for New Directions
in Statistical Machine Translation. In Proceedings
of the Ninth Workshop on Statistical Machine Trans-
lation, pages 114–121, Baltimore, Maryland USA,
June.
Spence Green, Daniel Cer, and Christopher D. Man-
ning. 2014b. An empirical comparison of features
and tuning for phrase-based machine translation. In
Proceedings of the Ninth Workshop on Statistical Ma-
chine Translation, pages 466–476, Baltimore, Mary-
land, USA, June.
A. Guerberof. 2009. Productivity and quality in the
post-editing of outputs from translation memories
and machine translation. International Journal of
Localization, 7(1):11–21.
Daniel Hardt and Jakob Elming. 2010. Incremental
re-training for post-editing SMT. In Proceedings of
the Ninth Conference of the Association for Machine
Translation in the Americas, Denver, Colorado, Oc-
tober.
Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H.
Clark, and Philipp Koehn. 2013. Scalable modi-
fied Kneser-Ney language model estimation. In Pro-
ceedings of the 51st Annual Meeting of the Associa-
tion for Computational Linguistics, pages 690–696,
Sofia, Bulgaria, August.
Reinerd Kneser and Hermann Ney. 1995. Improved
backing-off for M-gram language modeling. In Pro-
ceedings of the International Conference on Acous-
tics, Speech, and Signal Processing, volume 1, pages
181–184, May.
Philipp Koehn, Franz Joseph Och, and Daniel Marcu.
2003. Statistical Phrase-Based Translation. In
Proc. of the Human Language Technology Conf.
(HLT-NAACL), pages 127–133, Edmonton, Canada,
May/June.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ond&amp;quot;rej Bojar, Alexandra
Constantine, and Evan Herbst. 2007. Moses: Open
Source Toolkit for Statistical Machine Translation.
pages 177–180, Prague, Czech Republic, June.
Philipp Koehn. 2004. Statistical Significance Tests
for Machine Translation Evaluation. In Proc. of the
Conf. on Empirical Methods for Natural Language
Processing (EMNLP), pages 388–395, Barcelona,
Spain, July.
Abby Levenberg, Chris Callison-Burch, and Miles Os-
borne. 2010. Stream-based translation models for
statistical machine translation. In Human Language
Technologies: The 2010 Annual Conference of the
</reference>
<page confidence="0.592663">
1064
</page>
<reference confidence="0.999793297297297">
North American Chapter of the Association for Com-
putational Linguistics, pages 394–402, Los Angeles,
California, June.
Percy Liang, Alexandre Buchard-Côté, Dan Klein, and
Ben Taskar. 2006. An End-to-End Discriminative
Approach to Machine Translation. In Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the As-
sociation for Computational Linguistics, pages 761–
768, Sydney, Australia.
Prashant Mathur, Cettolo Mauro, and Marcello Fed-
erico. 2013. Online learning approaches in com-
puter assisted translation. In Proceedings of the
Eighth Workshop on Statistical Machine Translation,
pages 301–308, Sofia, Bulgaria, August.
Franz Josef Och and Hermann Ney. 2003. A Sys-
tematic Comparison of Various Statistical Alignment
Models. Computational Linguistics, 29(1):19–51,
March.
F. J. Och and H. Ney. 2004. The Alignment Template
Approach to Statistical Machine Translation. Com-
putational Linguistics,, 30(4):417–450.
Daniel Ortiz-Martínez, Ismael García-Varea, and Fran-
cisco Casacuberta. 2010. Online learning for inter-
active statistical machine translation. In Human Lan-
guage Technologies: The 2010Annual Conference of
the North American Chapter of the Association for
Computational Linguistics, pages 546–554, Los An-
geles, California, June.
M. Plitt and F. Masselot. 2010. A productivity test of
statistical machine translation post-editing in a typ-
ical localisation context. The Prague Bulletin of
Mathematical Linguistics, 93:7–16.
Rico Sennrich, Holger Schwenk, and Walid Aransa.
2013. A multi-domain translation model framework
for statistical machine translation. In Proceedings of
the 51st Annual Meeting of the Association for Com-
putational Linguistics, pages 832–840, Sofia, Bul-
garia, August.
Patrick Simianer and Stefan Riezler. 2013. Multi-
task learning for improved discriminative training in
SMT. In Proceedings of the Eighth Workshop on Sta-
tistical Machine Translation, pages 292–300, Sofia,
Bulgaria, August.
Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012.
Joint Feature Selection in Distributed Stochastic
Learning for Large-Scale Discriminative Training in
SMT. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics, pages
11–21, Jeju Island, Korea, July.
Linfeng Song, Haitao Mi, Yajuan Lü, and Qun Liu.
2011. Bagging-based system combination for do-
main adaption. In Proceedings of the 13th Machine
Translation Summit (MT Summit XIII), pages 293–
299, Xiamen, China.
Wei Wang, Klaus Macherey, Wolfgang Macherey,
Franz Och, and Peng Xu. 2012. Improved domain
adaptation for statistical machine translation. In Pro-
ceedings of the Tenth Conference of the Association
for Machine Translation in the Americas (AMTA),
San Diego, California.
Katharina Wäschle and Stefan Riezler. 2012. Ana-
lyzing Parallelism and Domain Similarities in the
MAREC Patent Corpus. Multidisciplinary Informa-
tion Retrieval, pages 12–27.
Katharina Wäschle, Patrick Simianer, Nicola Bertoldi,
Stefan Riezler, and Marcello Federico. 2013. Gener-
ative and Discriminative Methods for Online Adapta-
tion in SMT. In Proceedings of Machine Translation
Summit XIV, Nice, France.
Jia Xu, Yonggang Deng, Yuqing Gao, and Hermann
Ney. 2007. Domain dependent statistical machine
translation. In Proceedings of the MT Summit, pages
515–520, Copenhagen, Denmark, September.
</reference>
<page confidence="0.974141">
1065
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.934924">
<title confidence="0.999954">Hierarchical Incremental Adaptation for Statistical Machine Translation</title>
<author confidence="0.999335">Joern Wuebker Spence Green John DeNero</author>
<affiliation confidence="0.999738">Lilt Inc. Lilt Inc. Lilt Inc.</affiliation>
<email confidence="0.99702">joern@lilt.comspence@lilt.comjohn@lilt.com</email>
<abstract confidence="0.9940225">We present an incremental adaptation approach for statistical machine translation that maintains a flexible hierarchical domain structure within a single consistent model. Both weights and rules are updated incrementally on a stream of post-edits. Our multi-level domain hierarchy allows the system to adapt simultaneously towards local context at different levels of granularity, including genres and individual documents. Our experiments show consistent improvements in translation quality from all components of our approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andy Way Naskar</author>
<author>Josef van Genabith</author>
</authors>
<title>Combining multi-domain statistical machine translation models using automatic classifiers.</title>
<date>2010</date>
<booktitle>In Proceedings of the Association for Machine Translation in the Americas,</booktitle>
<location>Denver, Colorado,</location>
<marker>Naskar, van Genabith, 2010</marker>
<rawString>Pratyush Banerjee, Jinhua Du, Baoli Li, Sudip Kr. Naskar, Andy Way, and Josef van Genabith. 2010. Combining multi-domain statistical machine translation models using automatic classifiers. In Proceedings of the Association for Machine Translation in the Americas, Denver, Colorado, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Bertoldi</author>
<author>Mauro Cettolo</author>
<author>Marcello Federico</author>
</authors>
<title>Cache-based online adaptation for machine translation enhanced computer assisted translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the XIV Machine Translation Summit,</booktitle>
<pages>36--42</pages>
<location>Nice, France,</location>
<contexts>
<context position="15210" citStr="Bertoldi et al. (2013)" startWordPosition="2462" endWordPosition="2465">t genres contain around 20 segments on average. Our evaluation proceeded in multiple stages. We first trained a set of background weights on the 3http://www.statmt.org/wmt15/ 4http://workshop2014.iwslt.org/ heterogeneous data repetition rate 27.80 baseline + genre weights + genre TM + doc. weights + sparse features Table 1: Results in uncased BLEU [%]. Each component is added on top of the previous line. All results in line + genre TM and below are statistically significant improvements over the baseline with 95% confidence. We also report the repetition rate of the test corpora as propsed by Bertoldi et al. (2013). concatenated tune sets (baseline). Keeping these weights fixed, we performed an additional tuning run to estimate genre-level weights (+ genre weights).5 In the patent-only setup, we used patent CPC type as genre. Next, we trained a genrespecific translation model for each genre by first feeding the tune set and then the test set into our incremental adaptation learning method as a continuous stream of simulated post edits (+ genre TM). After each sentence, we performed an update on the genre-specific weights. In separate experiments, we also included document-level weights as an additional </context>
<context position="17622" citStr="Bertoldi et al., 2013" startWordPosition="2849" endWordPosition="2852">4.92 48.97 26.64 25.12 49.39 27.67 25.66 53.22 27.98 25.71 53.40 28.09 25.89 54.30 1062 BLEU [%] difference to baseline 2 4 6 8 10 12 14 16 18 20 i-th sentence in document Figure 2: BLEU difference between baseline + genre weights and our incremental adaptation approach, computed on a single segment from each document according to their order, i.e. the first segment from each document, then the second segment from each document, etc. large improvement in this genre would only be expected to arise in similarly structured domains. This property is quantified by the repetition rate measure (RR) (Bertoldi et al., 2013) reported in Table 1, which confirms the finding by Cettolo et al. (2014) that RR correlates with the effectiveness of adaptation. Analysis. Figure 2 shows BLEU score differences to the baseline + genre weights system for different subsets of the news and patent test sets. Each point is computed by document slicing, i.e. on a single segment from each document. The rightmost data point is the BLEU score we obtain by evaluating on the 20th segment of each document, grouped into a pseudo-corpus. Note that this group does not correspond to any number in Table 1, which reports BLEU on the entire te</context>
</contexts>
<marker>Bertoldi, Cettolo, Federico, 2013</marker>
<rawString>Nicola Bertoldi, Mauro Cettolo, and Marcello Federico. 2013. Cache-based online adaptation for machine translation enhanced computer assisted translation. In Proceedings of the XIV Machine Translation Summit, pages 36–42, Nice, France, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandru Ceau§fu</author>
<author>John Tinsley</author>
<author>Jian Zhang</author>
<author>Andy Way</author>
</authors>
<title>Experiments on domain adaptation for patent machine translation in the PLuTO project.</title>
<date>2011</date>
<booktitle>Proceedings of the 15th International Conference of the European Association for Machine Translation (EAMT),</booktitle>
<pages>21--28</pages>
<editor>In Mikel L. Forcada, Heidi Depraetere, and Vincent Vandeghinste, editors,</editor>
<location>Leuven, Belgium.</location>
<marker>Ceau§fu, Tinsley, Zhang, Way, 2011</marker>
<rawString>Alexandru Ceau§fu, John Tinsley, Jian Zhang, and Andy Way. 2011. Experiments on domain adaptation for patent machine translation in the PLuTO project. In Mikel L. Forcada, Heidi Depraetere, and Vincent Vandeghinste, editors, Proceedings of the 15th International Conference of the European Association for Machine Translation (EAMT), pages 21– 28, Leuven, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mauro Cettolo</author>
<author>Nicola Bertoldi</author>
<author>Marcello Federico</author>
</authors>
<title>The repetition rate of text as a predictor of the effectiveness of machine translation adaptation.</title>
<date>2014</date>
<booktitle>In Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<pages>166--179</pages>
<location>Vancouver, Canada,</location>
<contexts>
<context position="17695" citStr="Cettolo et al. (2014)" startWordPosition="2862" endWordPosition="2865">89 54.30 1062 BLEU [%] difference to baseline 2 4 6 8 10 12 14 16 18 20 i-th sentence in document Figure 2: BLEU difference between baseline + genre weights and our incremental adaptation approach, computed on a single segment from each document according to their order, i.e. the first segment from each document, then the second segment from each document, etc. large improvement in this genre would only be expected to arise in similarly structured domains. This property is quantified by the repetition rate measure (RR) (Bertoldi et al., 2013) reported in Table 1, which confirms the finding by Cettolo et al. (2014) that RR correlates with the effectiveness of adaptation. Analysis. Figure 2 shows BLEU score differences to the baseline + genre weights system for different subsets of the news and patent test sets. Each point is computed by document slicing, i.e. on a single segment from each document. The rightmost data point is the BLEU score we obtain by evaluating on the 20th segment of each document, grouped into a pseudo-corpus. Note that this group does not correspond to any number in Table 1, which reports BLEU on the entire test sets. Thus, we evaluate on all sentences that have learned from exactl</context>
</contexts>
<marker>Cettolo, Bertoldi, Federico, 2014</marker>
<rawString>Mauro Cettolo, Nicola Bertoldi, and Marcello Federico. 2014. The repetition rate of text as a predictor of the effectiveness of machine translation adaptation. In Conference of the Association for Machine Translation in the Americas (AMTA), pages 166–179, Vancouver, Canada, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley F Chen</author>
<author>Joshuo Goodman</author>
</authors>
<title>An Empirical Study of Smoothing Techniques for Language Modeling.</title>
<date>1998</date>
<tech>Technical Report TR-10-98,</tech>
<institution>Computer Science Group, Harvard University,</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="13701" citStr="Chen and Goodman, 1998" startWordPosition="2215" endWordPosition="2218">0 sentences per test set and 400 sentences per type for the tune set. The “claims” section of this corpus is highly repetitive, which makes it ideal for observing the effects of incremental adaptation techniques. To train the language and translation model we additionally leveraged all available bilingual and monolingual data provided for the EMNLP 2015 Tenth Workshop on Machine Translation3. The total size of the bitext used for rule extraction and feature estimation was 6.4M sentence pairs. We trained a standard 5-gram language model with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) using the KenLM toolkit (Heafield et al., 2013) on 4 billion running words. The bitext was word-aligned with mgiza (Och and Ney, 2003), and we used the phrasal decoder (Green et al., 2014a) with standard GermanEnglish settings for experimentation. Our second set of experiments was performed on a mixed-genre corpus containing lectures, patents, and news articles. The standard dev and test sets of the IWSLT 2014 shared task4 were used for the lecture genre. Each document corresponded to an entire lecture. For the news genre, we used newstest2012 for tuning, newstest2013 for metaparameter optimi</context>
</contexts>
<marker>Chen, Goodman, 1998</marker>
<rawString>Stanley F. Chen and Joshuo Goodman. 1998. An Empirical Study of Smoothing Techniques for Language Modeling. Technical Report TR-10-98, Computer Science Group, Harvard University, Cambridge, MA, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Cui</author>
<author>Xilun Chen</author>
<author>Dongdong Zhang</author>
<author>Shujie Liu</author>
<author>Mu Li</author>
<author>Ming Zhou</author>
</authors>
<title>Multi-domain adaptation for SMT using multi-task learning.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1055--1065</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="5328" citStr="Cui et al., 2013" startWordPosition="830" endWordPosition="833">cators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human provides a corrected translation e∗ to the machine. Observing e∗ can affect both the Root Domain Figure 1: The weights used to translate a document in the patent genre include three d</context>
</contexts>
<marker>Cui, Chen, Zhang, Liu, Li, Zhou, 2013</marker>
<rawString>Lei Cui, Xilun Chen, Dongdong Zhang, Shujie Liu, Mu Li, and Ming Zhou. 2013. Multi-domain adaptation for SMT using multi-task learning. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1055–1065, Seattle, Washington, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daumé</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>256--263</pages>
<location>Prague, Czech Republic,</location>
<marker>Daumé, 2007</marker>
<rawString>Hal Daumé III. 2007. Frustratingly easy domain adaptation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 256–263, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Denkowski</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
</authors>
<title>Learning from post-editing: Online model adaptation for statistical machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>395--404</pages>
<location>Gothenburg, Sweden,</location>
<contexts>
<context position="1834" citStr="Denkowski et al., 2014" startWordPosition="260" endWordPosition="263">ation suggestions are informed by two levels of contextual information. Our primary technical contribution is a hierarchical adaptation technique for a post-editing scenario with incremental adaptation, in which users request translations of sentences in corpus order and provide corrected translations of each sentence back to the system (Ortiz-Martínez et al., 2010). Our learning approach resembles Hierarchical Bayesian Domain Adaptation (Finkel and Manning, 2009), but updates both the model weights and translation rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on AdaGrad (Duchi et al., 2011) and forward-backward splitting (Duchi and Singer, 2009) that can accurately set weights for both dense and sparse features (Green et al., 2014b). Rather than adjusting all weights based on each example, our extension adjusts off</context>
<context position="6456" citStr="Denkowski et al., 2014" startWordPosition="1017" endWordPosition="1020">t Domain Figure 1: The weights used to translate a document in the patent genre include three domains. model weights w and corpus c used for rule extraction and dense feature estimation.1 To translate the ith sentence fi, the system uses weights wi−1 and corpus ci−1. The new corpus ci results from adding (fi, e∗i) to ci−1. For incremental adaptation, speed is essential, and so wi is typically computed with a single online update from wi−1 using (fi, e∗i) as the tuning example. To alleviate the need for human intervention in the experiment cycle, simulated post-editing (Hardt and Elming, 2010; Denkowski et al., 2014) replaces each e∗ with a reference that is not a corrected variant of e. Thus, a standard test corpus can be used as an adaptation corpus. Prior work on online learning from post-edits has demonstrated the benefit of adjusting only c (Ortiz-Martínez et al., 2010; Hardt and Elming, 2010) and further benefit from adjusting both c and w (Mathur et al., 2013; Denkowski et al., 2014). Incremental adaptation of both c and the weights w for sparse features is reported to yield large quality gains by Wäschle et al. (2013).2 3 Hierarchical Incremental Adaptation Our hierachical approach to incremental </context>
</contexts>
<marker>Denkowski, Dyer, Lavie, 2014</marker>
<rawString>Michael Denkowski, Chris Dyer, and Alon Lavie. 2014. Learning from post-editing: Online model adaptation for statistical machine translation. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 395–404, Gothenburg, Sweden, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Duchi</author>
<author>Yoram Singer</author>
</authors>
<title>Efficient online and batch learning using forward backward splitting.</title>
<date>2009</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>10</volume>
<pages>2934</pages>
<contexts>
<context position="2261" citStr="Duchi and Singer, 2009" startWordPosition="330" endWordPosition="333">ain Adaptation (Finkel and Manning, 2009), but updates both the model weights and translation rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on AdaGrad (Duchi et al., 2011) and forward-backward splitting (Duchi and Singer, 2009) that can accurately set weights for both dense and sparse features (Green et al., 2014b). Rather than adjusting all weights based on each example, our extension adjusts offsets to a fixed baseline system. In this way, the system can adapt to multiple genres while preventing cross-genre contamination. In large-scale experiments, we adapt a multigenre baseline system to patents, lectures, and news articles. Our experiments show that sparse models, hierarchical updates, and rule adaptation all contribute consistent improvements. We observe quality gains in all genres, validating our hypothesis t</context>
<context position="8699" citStr="Duchi and Singer, 2009" startWordPosition="1387" endWordPosition="1390">ayesian domain adaptation (Finkel and Manning, 2009), but both weights and feature values depend on Di, and we use L1 regularization. Weight Updates. Model tuning and adaptation are performed with AdaGrad, an online subgradient method with an adaptive learning rate that comes with good theoretical guarantees. AdaGrad makes the following update: wt = wt−1 − ηΣ1/2 t V`t(wt−1) (2) Σ−1 t = Σ−1 t−1 + V`t(wt−1)V`t(wt−1)T t = V`i(wi−1)V`i(wi−1)T (3) i=1 The loss function ` reflects the pairwise ordering between hypotheses. For feature selection, we apply an L1 penalty via forward-backward splitting (Duchi and Singer, 2009). η is the initial learning rate. See (Green et al., 2013b) for details. Our adaptation schema is an extension offrustratingly easy domain adaptation (FEDA) (Daumé III, 2007) to multiple domains with different regularization parameters, similar to (Finkel and Manning, 2009). Each feature value is replicated for each domain. Let D denote the set of all domains present in the adaptation set. Given an original feature vector φ(r; c) for derivation r of sentence fi with Di C D, the replicated feature vector includes |D |copies of φ(r; c), one for each d E |D|, such that � φ(r; c), d E Di φd(r; c) </context>
</contexts>
<marker>Duchi, Singer, 2009</marker>
<rawString>John Duchi and Yoram Singer. 2009. Efficient online and batch learning using forward backward splitting. Journal of Machine Learning Research, 10:2899– 2934, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Duchi</author>
<author>Elad Hazan</author>
<author>Yoram Singer</author>
</authors>
<title>Adaptive subgradient methods for online learning and stochastic optimization.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2121</pages>
<contexts>
<context position="2205" citStr="Duchi et al., 2011" startWordPosition="323" endWordPosition="326">earning approach resembles Hierarchical Bayesian Domain Adaptation (Finkel and Manning, 2009), but updates both the model weights and translation rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on AdaGrad (Duchi et al., 2011) and forward-backward splitting (Duchi and Singer, 2009) that can accurately set weights for both dense and sparse features (Green et al., 2014b). Rather than adjusting all weights based on each example, our extension adjusts offsets to a fixed baseline system. In this way, the system can adapt to multiple genres while preventing cross-genre contamination. In large-scale experiments, we adapt a multigenre baseline system to patents, lectures, and news articles. Our experiments show that sparse models, hierarchical updates, and rule adaptation all contribute consistent improvements. We observe </context>
</contexts>
<marker>Duchi, Hazan, Singer, 2011</marker>
<rawString>John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12:2121–2159, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Katsuhito Sudoh</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
<author>Masaaki Nagata</author>
</authors>
<title>N-best reranking by multitask learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>375--383</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="5505" citStr="Duh et al., 2010" startWordPosition="859" endWordPosition="862">lation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human provides a corrected translation e∗ to the machine. Observing e∗ can affect both the Root Domain Figure 1: The weights used to translate a document in the patent genre include three domains. model weights w and corpus c used for rule extraction and dense feature estimation.1 To translate the ith sentence fi, the system uses weights wi−1 and corpus ci−1. The </context>
</contexts>
<marker>Duh, Sudoh, Tsukada, Isozaki, Nagata, 2010</marker>
<rawString>Kevin Duh, Katsuhito Sudoh, Hajime Tsukada, Hideki Isozaki, and Masaaki Nagata. 2010. N-best reranking by multitask learning. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 375–383, Uppsala, Sweden, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Hierarchical bayesian domain adaptation.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>602--610</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="1679" citStr="Finkel and Manning, 2009" startWordPosition="234" endWordPosition="237">tentially improve suggestion quality. We describe a model architecture that adapts simultaneously to multiple genres and individual documents, so that translation suggestions are informed by two levels of contextual information. Our primary technical contribution is a hierarchical adaptation technique for a post-editing scenario with incremental adaptation, in which users request translations of sentences in corpus order and provide corrected translations of each sentence back to the system (Ortiz-Martínez et al., 2010). Our learning approach resembles Hierarchical Bayesian Domain Adaptation (Finkel and Manning, 2009), but updates both the model weights and translation rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on AdaGrad (Duchi et al., 2011) and forward-backward splitting (Duchi and Singer, 2009) that can accurate</context>
<context position="8128" citStr="Finkel and Manning, 2009" startWordPosition="1296" endWordPosition="1299">rpus share a ROOT domain. 1For the purpose of our description, the corpus c is equivalent to the set of phrases and their scores in the rule table. We prefer this notation because it is consistent with our streambased rule table, where the models are computed on-the-fly from the indexed training corpus c. 2Language model adaptation also has a rich literature, but it is beyond the scope of this paper. Each document has 3 domains: root, its genre, &amp; the document itself Patents Genre News Genre Lectures Genre 1060 Our adaptation is conceptually similar to hierarchical Bayesian domain adaptation (Finkel and Manning, 2009), but both weights and feature values depend on Di, and we use L1 regularization. Weight Updates. Model tuning and adaptation are performed with AdaGrad, an online subgradient method with an adaptive learning rate that comes with good theoretical guarantees. AdaGrad makes the following update: wt = wt−1 − ηΣ1/2 t V`t(wt−1) (2) Σ−1 t = Σ−1 t−1 + V`t(wt−1)V`t(wt−1)T t = V`i(wi−1)V`i(wi−1)T (3) i=1 The loss function ` reflects the pairwise ordering between hypotheses. For feature selection, we apply an L1 penalty via forward-backward splitting (Duchi and Singer, 2009). η is the initial learning r</context>
<context position="9588" citStr="Finkel and Manning, 2009" startWordPosition="1548" endWordPosition="1551">ing, 2009). Each feature value is replicated for each domain. Let D denote the set of all domains present in the adaptation set. Given an original feature vector φ(r; c) for derivation r of sentence fi with Di C D, the replicated feature vector includes |D |copies of φ(r; c), one for each d E |D|, such that � φ(r; c), d E Di φd(r; c) = (4) 0, otherwise. The weights of this replicated feature space are initialized using the weights w tuned for the baseline φ(r; c). w, d is ROOT wd = �0, otherwise. (5) In this way, the ROOT domain corresponds to the unadapted baseline weights, denoted as Θ* in (Finkel and Manning, 2009). The idea is that we simultaneously maintain a generic set of weights that applies to all domains as well as their domain-specific “offsets”, describing how a domain differs from the generic case. Model updates during adaptation are performed according to the same procedure as tuning updates, but now in the replicated space. Different from (Finkel and Manning, 2009), this generalized FEDA model does not restrict the domains to be strictly hierarchically structured. We could, for example, include a domain for each translator that crossed different genres. However, all of our experimental evalu</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2009. Hierarchical bayesian domain adaptation. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 602–610, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Sida Wang</author>
<author>Daniel Cer</author>
<author>Christopher D Manning</author>
</authors>
<title>The efficacy of human post-editing for language translation.</title>
<date>2013</date>
<booktitle>In ACM CHI Conference on Human Factors in Computing Systems,</booktitle>
<location>Paris, France,</location>
<contexts>
<context position="916" citStr="Green et al., 2013" startWordPosition="126" endWordPosition="129">ible hierarchical domain structure within a single consistent model. Both weights and rules are updated incrementally on a stream of post-edits. Our multi-level domain hierarchy allows the system to adapt simultaneously towards local context at different levels of granularity, including genres and individual documents. Our experiments show consistent improvements in translation quality from all components of our approach. 1 Introduction Suggestions from a machine translation system can increase the speed and quality of professional human translators (Guerberof, 2009; Plitt and Masselot, 2010; Green et al., 2013a, inter alia). However, querying a single fixed model for all different documents fails to incorporate contextual information that can potentially improve suggestion quality. We describe a model architecture that adapts simultaneously to multiple genres and individual documents, so that translation suggestions are informed by two levels of contextual information. Our primary technical contribution is a hierarchical adaptation technique for a post-editing scenario with incremental adaptation, in which users request translations of sentences in corpus order and provide corrected translations of</context>
<context position="2152" citStr="Green et al., 2013" startWordPosition="313" endWordPosition="316">k to the system (Ortiz-Martínez et al., 2010). Our learning approach resembles Hierarchical Bayesian Domain Adaptation (Finkel and Manning, 2009), but updates both the model weights and translation rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on AdaGrad (Duchi et al., 2011) and forward-backward splitting (Duchi and Singer, 2009) that can accurately set weights for both dense and sparse features (Green et al., 2014b). Rather than adjusting all weights based on each example, our extension adjusts offsets to a fixed baseline system. In this way, the system can adapt to multiple genres while preventing cross-genre contamination. In large-scale experiments, we adapt a multigenre baseline system to patents, lectures, and news articles. Our experiments show that sparse models, hierarchical updates, and rule adaptatio</context>
<context position="5146" citStr="Green et al., 2013" startWordPosition="798" endWordPosition="801">rse features that have non-zero values for only a subset of rules, but typically do not depend on c (Liang et al., 2006). In this paper, we use four types of sparse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human p</context>
<context position="8756" citStr="Green et al., 2013" startWordPosition="1398" endWordPosition="1401"> weights and feature values depend on Di, and we use L1 regularization. Weight Updates. Model tuning and adaptation are performed with AdaGrad, an online subgradient method with an adaptive learning rate that comes with good theoretical guarantees. AdaGrad makes the following update: wt = wt−1 − ηΣ1/2 t V`t(wt−1) (2) Σ−1 t = Σ−1 t−1 + V`t(wt−1)V`t(wt−1)T t = V`i(wi−1)V`i(wi−1)T (3) i=1 The loss function ` reflects the pairwise ordering between hypotheses. For feature selection, we apply an L1 penalty via forward-backward splitting (Duchi and Singer, 2009). η is the initial learning rate. See (Green et al., 2013b) for details. Our adaptation schema is an extension offrustratingly easy domain adaptation (FEDA) (Daumé III, 2007) to multiple domains with different regularization parameters, similar to (Finkel and Manning, 2009). Each feature value is replicated for each domain. Let D denote the set of all domains present in the adaptation set. Given an original feature vector φ(r; c) for derivation r of sentence fi with Di C D, the replicated feature vector includes |D |copies of φ(r; c), one for each d E |D|, such that � φ(r; c), d E Di φd(r; c) = (4) 0, otherwise. The weights of this replicated featur</context>
</contexts>
<marker>Green, Wang, Cer, Manning, 2013</marker>
<rawString>Spence Green, Sida Wang, Daniel Cer, and Christopher D. Manning. 2013a. The efficacy of human post-editing for language translation. In ACM CHI Conference on Human Factors in Computing Systems, Paris, France, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Sida Wang</author>
<author>Daniel Cer</author>
<author>Christopher D Manning</author>
</authors>
<title>Fast and adaptive online training of feature-rich translation models.</title>
<date>2013</date>
<booktitle>In 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--321</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="916" citStr="Green et al., 2013" startWordPosition="126" endWordPosition="129">ible hierarchical domain structure within a single consistent model. Both weights and rules are updated incrementally on a stream of post-edits. Our multi-level domain hierarchy allows the system to adapt simultaneously towards local context at different levels of granularity, including genres and individual documents. Our experiments show consistent improvements in translation quality from all components of our approach. 1 Introduction Suggestions from a machine translation system can increase the speed and quality of professional human translators (Guerberof, 2009; Plitt and Masselot, 2010; Green et al., 2013a, inter alia). However, querying a single fixed model for all different documents fails to incorporate contextual information that can potentially improve suggestion quality. We describe a model architecture that adapts simultaneously to multiple genres and individual documents, so that translation suggestions are informed by two levels of contextual information. Our primary technical contribution is a hierarchical adaptation technique for a post-editing scenario with incremental adaptation, in which users request translations of sentences in corpus order and provide corrected translations of</context>
<context position="2152" citStr="Green et al., 2013" startWordPosition="313" endWordPosition="316">k to the system (Ortiz-Martínez et al., 2010). Our learning approach resembles Hierarchical Bayesian Domain Adaptation (Finkel and Manning, 2009), but updates both the model weights and translation rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on AdaGrad (Duchi et al., 2011) and forward-backward splitting (Duchi and Singer, 2009) that can accurately set weights for both dense and sparse features (Green et al., 2014b). Rather than adjusting all weights based on each example, our extension adjusts offsets to a fixed baseline system. In this way, the system can adapt to multiple genres while preventing cross-genre contamination. In large-scale experiments, we adapt a multigenre baseline system to patents, lectures, and news articles. Our experiments show that sparse models, hierarchical updates, and rule adaptatio</context>
<context position="5146" citStr="Green et al., 2013" startWordPosition="798" endWordPosition="801">rse features that have non-zero values for only a subset of rules, but typically do not depend on c (Liang et al., 2006). In this paper, we use four types of sparse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human p</context>
<context position="8756" citStr="Green et al., 2013" startWordPosition="1398" endWordPosition="1401"> weights and feature values depend on Di, and we use L1 regularization. Weight Updates. Model tuning and adaptation are performed with AdaGrad, an online subgradient method with an adaptive learning rate that comes with good theoretical guarantees. AdaGrad makes the following update: wt = wt−1 − ηΣ1/2 t V`t(wt−1) (2) Σ−1 t = Σ−1 t−1 + V`t(wt−1)V`t(wt−1)T t = V`i(wi−1)V`i(wi−1)T (3) i=1 The loss function ` reflects the pairwise ordering between hypotheses. For feature selection, we apply an L1 penalty via forward-backward splitting (Duchi and Singer, 2009). η is the initial learning rate. See (Green et al., 2013b) for details. Our adaptation schema is an extension offrustratingly easy domain adaptation (FEDA) (Daumé III, 2007) to multiple domains with different regularization parameters, similar to (Finkel and Manning, 2009). Each feature value is replicated for each domain. Let D denote the set of all domains present in the adaptation set. Given an original feature vector φ(r; c) for derivation r of sentence fi with Di C D, the replicated feature vector includes |D |copies of φ(r; c), one for each d E |D|, such that � φ(r; c), d E Di φd(r; c) = (4) 0, otherwise. The weights of this replicated featur</context>
</contexts>
<marker>Green, Wang, Cer, Manning, 2013</marker>
<rawString>Spence Green, Sida Wang, Daniel Cer, and Christopher D. Manning. 2013b. Fast and adaptive online training of feature-rich translation models. In 51st Annual Meeting of the Association for Computational Linguistics, pages 311–321, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Daniel Cer</author>
</authors>
<title>Phrasal: A Toolkit for New Directions in Statistical Machine Translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth Workshop on Statistical Machine Translation,</booktitle>
<pages>114--121</pages>
<location>Baltimore, Maryland USA,</location>
<marker>Green, Cer, 2014</marker>
<rawString>Spence Green, Daniel Cer, , and Christopher D. Manning. 2014a. Phrasal: A Toolkit for New Directions in Statistical Machine Translation. In Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 114–121, Baltimore, Maryland USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Daniel Cer</author>
<author>Christopher D Manning</author>
</authors>
<title>An empirical comparison of features and tuning for phrase-based machine translation.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth Workshop on Statistical Machine Translation,</booktitle>
<pages>466--476</pages>
<location>Baltimore, Maryland, USA,</location>
<contexts>
<context position="2348" citStr="Green et al., 2014" startWordPosition="347" endWordPosition="350">n rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on AdaGrad (Duchi et al., 2011) and forward-backward splitting (Duchi and Singer, 2009) that can accurately set weights for both dense and sparse features (Green et al., 2014b). Rather than adjusting all weights based on each example, our extension adjusts offsets to a fixed baseline system. In this way, the system can adapt to multiple genres while preventing cross-genre contamination. In large-scale experiments, we adapt a multigenre baseline system to patents, lectures, and news articles. Our experiments show that sparse models, hierarchical updates, and rule adaptation all contribute consistent improvements. We observe quality gains in all genres, validating our hypothesis that document and genre context are important additional inputs to a machine translation</context>
<context position="4834" citStr="Green et al., 2014" startWordPosition="750" endWordPosition="753">in c (Koehn et al., 2007). • A linear distortion penalty that promotes monotonic translation. • An n-gram language model score, p(e), which scores the target language projection of r using statistics from a monolingual corpus. • Fixed-value phrase and word penalties. The elements of 0(r; c) may also include sparse features that have non-zero values for only a subset of rules, but typically do not depend on c (Liang et al., 2006). In this paper, we use four types of sparse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task lear</context>
<context position="13889" citStr="Green et al., 2014" startWordPosition="2249" endWordPosition="2252">ptation techniques. To train the language and translation model we additionally leveraged all available bilingual and monolingual data provided for the EMNLP 2015 Tenth Workshop on Machine Translation3. The total size of the bitext used for rule extraction and feature estimation was 6.4M sentence pairs. We trained a standard 5-gram language model with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) using the KenLM toolkit (Heafield et al., 2013) on 4 billion running words. The bitext was word-aligned with mgiza (Och and Ney, 2003), and we used the phrasal decoder (Green et al., 2014a) with standard GermanEnglish settings for experimentation. Our second set of experiments was performed on a mixed-genre corpus containing lectures, patents, and news articles. The standard dev and test sets of the IWSLT 2014 shared task4 were used for the lecture genre. Each document corresponded to an entire lecture. For the news genre, we used newstest2012 for tuning, newstest2013 for metaparameter optimization, and newstest2014 for testing. The tune set for the patent genre is identical to the first set of experiments, while the test set consists of the first 300 sentence pairs of each of</context>
</contexts>
<marker>Green, Cer, Manning, 2014</marker>
<rawString>Spence Green, Daniel Cer, and Christopher D. Manning. 2014b. An empirical comparison of features and tuning for phrase-based machine translation. In Proceedings of the Ninth Workshop on Statistical Machine Translation, pages 466–476, Baltimore, Maryland, USA, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Guerberof</author>
</authors>
<title>Productivity and quality in the post-editing of outputs from translation memories and machine translation.</title>
<date>2009</date>
<journal>International Journal of Localization,</journal>
<volume>7</volume>
<issue>1</issue>
<contexts>
<context position="870" citStr="Guerberof, 2009" startWordPosition="119" endWordPosition="120">l machine translation that maintains a flexible hierarchical domain structure within a single consistent model. Both weights and rules are updated incrementally on a stream of post-edits. Our multi-level domain hierarchy allows the system to adapt simultaneously towards local context at different levels of granularity, including genres and individual documents. Our experiments show consistent improvements in translation quality from all components of our approach. 1 Introduction Suggestions from a machine translation system can increase the speed and quality of professional human translators (Guerberof, 2009; Plitt and Masselot, 2010; Green et al., 2013a, inter alia). However, querying a single fixed model for all different documents fails to incorporate contextual information that can potentially improve suggestion quality. We describe a model architecture that adapts simultaneously to multiple genres and individual documents, so that translation suggestions are informed by two levels of contextual information. Our primary technical contribution is a hierarchical adaptation technique for a post-editing scenario with incremental adaptation, in which users request translations of sentences in corp</context>
</contexts>
<marker>Guerberof, 2009</marker>
<rawString>A. Guerberof. 2009. Productivity and quality in the post-editing of outputs from translation memories and machine translation. International Journal of Localization, 7(1):11–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Hardt</author>
<author>Jakob Elming</author>
</authors>
<title>Incremental re-training for post-editing SMT.</title>
<date>2010</date>
<booktitle>In Proceedings of the Ninth Conference of the Association for Machine Translation in the Americas,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="5668" citStr="Hardt and Elming, 2010" startWordPosition="882" endWordPosition="885">ection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human provides a corrected translation e∗ to the machine. Observing e∗ can affect both the Root Domain Figure 1: The weights used to translate a document in the patent genre include three domains. model weights w and corpus c used for rule extraction and dense feature estimation.1 To translate the ith sentence fi, the system uses weights wi−1 and corpus ci−1. The new corpus ci results from adding (fi, e∗i) to ci−1. For incremental adaptation, speed is essential, and so wi is typically computed with a single online update fr</context>
</contexts>
<marker>Hardt, Elming, 2010</marker>
<rawString>Daniel Hardt and Jakob Elming. 2010. Incremental re-training for post-editing SMT. In Proceedings of the Ninth Conference of the Association for Machine Translation in the Americas, Denver, Colorado, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Ivan Pouzyrevsky</author>
<author>Jonathan H Clark</author>
<author>Philipp Koehn</author>
</authors>
<title>Scalable modified Kneser-Ney language model estimation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>690--696</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="13749" citStr="Heafield et al., 2013" startWordPosition="2223" endWordPosition="2226">pe for the tune set. The “claims” section of this corpus is highly repetitive, which makes it ideal for observing the effects of incremental adaptation techniques. To train the language and translation model we additionally leveraged all available bilingual and monolingual data provided for the EMNLP 2015 Tenth Workshop on Machine Translation3. The total size of the bitext used for rule extraction and feature estimation was 6.4M sentence pairs. We trained a standard 5-gram language model with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) using the KenLM toolkit (Heafield et al., 2013) on 4 billion running words. The bitext was word-aligned with mgiza (Och and Ney, 2003), and we used the phrasal decoder (Green et al., 2014a) with standard GermanEnglish settings for experimentation. Our second set of experiments was performed on a mixed-genre corpus containing lectures, patents, and news articles. The standard dev and test sets of the IWSLT 2014 shared task4 were used for the lecture genre. Each document corresponded to an entire lecture. For the news genre, we used newstest2012 for tuning, newstest2013 for metaparameter optimization, and newstest2014 for testing. The tune s</context>
</contexts>
<marker>Heafield, Pouzyrevsky, Clark, Koehn, 2013</marker>
<rawString>Kenneth Heafield, Ivan Pouzyrevsky, Jonathan H. Clark, and Philipp Koehn. 2013. Scalable modified Kneser-Ney language model estimation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 690–696, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinerd Kneser</author>
<author>Hermann Ney</author>
</authors>
<title>Improved backing-off for M-gram language modeling.</title>
<date>1995</date>
<booktitle>In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing,</booktitle>
<volume>1</volume>
<pages>181--184</pages>
<contexts>
<context position="13676" citStr="Kneser and Ney, 1995" startWordPosition="2211" endWordPosition="2214">ment, with around 2,100 sentences per test set and 400 sentences per type for the tune set. The “claims” section of this corpus is highly repetitive, which makes it ideal for observing the effects of incremental adaptation techniques. To train the language and translation model we additionally leveraged all available bilingual and monolingual data provided for the EMNLP 2015 Tenth Workshop on Machine Translation3. The total size of the bitext used for rule extraction and feature estimation was 6.4M sentence pairs. We trained a standard 5-gram language model with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) using the KenLM toolkit (Heafield et al., 2013) on 4 billion running words. The bitext was word-aligned with mgiza (Och and Ney, 2003), and we used the phrasal decoder (Green et al., 2014a) with standard GermanEnglish settings for experimentation. Our second set of experiments was performed on a mixed-genre corpus containing lectures, patents, and news articles. The standard dev and test sets of the IWSLT 2014 shared task4 were used for the lecture genre. Each document corresponded to an entire lecture. For the news genre, we used newstest2012 for tuning, newstest2013</context>
</contexts>
<marker>Kneser, Ney, 1995</marker>
<rawString>Reinerd Kneser and Hermann Ney. 1995. Improved backing-off for M-gram language modeling. In Proceedings of the International Conference on Acoustics, Speech, and Signal Processing, volume 1, pages 181–184, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Joseph Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical Phrase-Based Translation.</title>
<date>2003</date>
<booktitle>In Proc. of the Human Language Technology Conf. (HLT-NAACL),</booktitle>
<pages>127--133</pages>
<location>Edmonton, Canada, May/June.</location>
<contexts>
<context position="4033" citStr="Koehn et al., 2003" startWordPosition="617" endWordPosition="620">s. where f E F is a string in the set of all source language strings F, e E £ is a string in the set of all target language strings £, r is a phrasal derivation with source and target projections src(r) and tgt(r), w E Rd is the vector of model parameters, 0(·) E Rd is a feature map computed using corpus c, and Z(f) is an appropriate normalizing constant. During search, the maximum approximation is applied rather than summing over the derivations r. Model. We extend a phrase-based system for which 0(r; c) includes 16 dense features: • Two phrasal channel models and two lexical channel models (Koehn et al., 2003), the (log) count of the rule in the training corpus c, and an indicator for singleton rules in c. • Six orientation models that score ordering configurations in r by their frequency in c (Koehn et al., 2007). • A linear distortion penalty that promotes monotonic translation. • An n-gram language model score, p(e), which scores the target language projection of r using statistics from a monolingual corpus. • Fixed-value phrase and word penalties. The elements of 0(r; c) may also include sparse features that have non-zero values for only a subset of rules, but typically do not depend on c (Lian</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Joseph Och, and Daniel Marcu. 2003. Statistical Phrase-Based Translation. In Proc. of the Human Language Technology Conf. (HLT-NAACL), pages 127–133, Edmonton, Canada, May/June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open Source Toolkit for Statistical Machine Translation.</title>
<date>2007</date>
<pages>177--180</pages>
<location>Christine Moran, Richard Zens, Chris Dyer, Ond&amp;quot;rej Bojar, Alexandra Constantine, and</location>
<contexts>
<context position="4241" citStr="Koehn et al., 2007" startWordPosition="656" endWordPosition="659">gt(r), w E Rd is the vector of model parameters, 0(·) E Rd is a feature map computed using corpus c, and Z(f) is an appropriate normalizing constant. During search, the maximum approximation is applied rather than summing over the derivations r. Model. We extend a phrase-based system for which 0(r; c) includes 16 dense features: • Two phrasal channel models and two lexical channel models (Koehn et al., 2003), the (log) count of the rule in the training corpus c, and an indicator for singleton rules in c. • Six orientation models that score ordering configurations in r by their frequency in c (Koehn et al., 2007). • A linear distortion penalty that promotes monotonic translation. • An n-gram language model score, p(e), which scores the target language projection of r using statistics from a monolingual corpus. • Fixed-value phrase and word penalties. The elements of 0(r; c) may also include sparse features that have non-zero values for only a subset of rules, but typically do not depend on c (Liang et al., 2006). In this paper, we use four types of sparse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ond&amp;quot;rej Bojar, Alexandra Constantine, and Evan Herbst. 2007. Moses: Open Source Toolkit for Statistical Machine Translation. pages 177–180, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Statistical Significance Tests for Machine Translation Evaluation.</title>
<date>2004</date>
<booktitle>In Proc. of the Conf. on Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>388--395</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="16517" citStr="Koehn, 2004" startWordPosition="2672" endWordPosition="2673">6 Table 1 demonstrates that each component of this approach offered consistent incremental quality gains, but with varying magnitudes. For the patent experiments we report the average over our eight test sets (A-H) due to lack of space, but total improvement varied from +4.92 to +6.46 BLEU. In the mixed-genre experiments, BLEU increased by +2.27 on lectures, +0.97 on news, and +5.33 on patents. On all tasks, we observed statistically significant improvements over the baseline (95% confidence level) in the + genre TM, + doc. weights and + sparse features experiments using bootstrap resampling (Koehn, 2004). These results demonstrate the efficacy of hierarchical incremental adaptation, although we would like to stress that the patent data was selected specifically for its high level of repetitiveness, and the 5Learning rates and regularization weights for this step were selected on newstest2013. 6Learning rates and regularization weights for each genre were selected on the genre-specific tune sets. PatTR avg 48.89 49.05 53.25 53.56 54.53 lecture news patent 5.46 3.13 27.42 25.82 24.92 48.97 26.64 25.12 49.39 27.67 25.66 53.22 27.98 25.71 53.40 28.09 25.89 54.30 1062 BLEU [%] difference to baseli</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Statistical Significance Tests for Machine Translation Evaluation. In Proc. of the Conf. on Empirical Methods for Natural Language Processing (EMNLP), pages 388–395, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abby Levenberg</author>
<author>Chris Callison-Burch</author>
<author>Miles Osborne</author>
</authors>
<title>Stream-based translation models for statistical machine translation.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>394--402</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="11059" citStr="Levenberg et al., 2010" startWordPosition="1794" endWordPosition="1797">specific corpus that includes all sentence pairs from the tuning corpus as well as from the adaptation corpus (fj, ej*) with j &lt; i sharing fi&apos;s genre. We refer to this combined corpus as ci. The tuning corpus is the same that is used for parameter tuning in the baseline system. The adaptation corpus is our test set. Note that in our evaluation, each sentence is translated before it is used for adaptation, so that there is no contamination of results. In order to extend the model efficiently within a streaming data environment, we make use of a suffix-array implementation for our phrase table (Levenberg et al., 2010). Rather than combining corpus counts across these different sources, separate rules extracted from the baseline corpus and the genre-specific corpus exist independently in the derivation space, and features of each are computed only with one corpus. In this configuration, a large amount of outof-domain evidence from the baseline model will not dampen the feature value adaptation effects of adding new sentence pairs from the adaptation corpus. The genre-specific phrases are distinguished by an additional binary provenance feature. In order to extract features from the genrespecific corpus, a w</context>
</contexts>
<marker>Levenberg, Callison-Burch, Osborne, 2010</marker>
<rawString>Abby Levenberg, Chris Callison-Burch, and Miles Osborne. 2010. Stream-based translation models for statistical machine translation. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 394–402, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Alexandre Buchard-Côté</author>
<author>Dan Klein</author>
<author>Ben Taskar</author>
</authors>
<title>An End-to-End Discriminative Approach to Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>761--768</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="4648" citStr="Liang et al., 2006" startWordPosition="723" endWordPosition="726">003), the (log) count of the rule in the training corpus c, and an indicator for singleton rules in c. • Six orientation models that score ordering configurations in r by their frequency in c (Koehn et al., 2007). • A linear distortion penalty that promotes monotonic translation. • An n-gram language model score, p(e), which scores the target language projection of r using statistics from a monolingual corpus. • Fixed-value phrase and word penalties. The elements of 0(r; c) may also include sparse features that have non-zero values for only a subset of rules, but typically do not depend on c (Liang et al., 2006). In this paper, we use four types of sparse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also </context>
</contexts>
<marker>Liang, Buchard-Côté, Klein, Taskar, 2006</marker>
<rawString>Percy Liang, Alexandre Buchard-Côté, Dan Klein, and Ben Taskar. 2006. An End-to-End Discriminative Approach to Machine Translation. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 761– 768, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prashant Mathur</author>
<author>Cettolo Mauro</author>
<author>Marcello Federico</author>
</authors>
<title>Online learning approaches in computer assisted translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<pages>301--308</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="1809" citStr="Mathur et al., 2013" startWordPosition="256" endWordPosition="259">ments, so that translation suggestions are informed by two levels of contextual information. Our primary technical contribution is a hierarchical adaptation technique for a post-editing scenario with incremental adaptation, in which users request translations of sentences in corpus order and provide corrected translations of each sentence back to the system (Ortiz-Martínez et al., 2010). Our learning approach resembles Hierarchical Bayesian Domain Adaptation (Finkel and Manning, 2009), but updates both the model weights and translation rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on AdaGrad (Duchi et al., 2011) and forward-backward splitting (Duchi and Singer, 2009) that can accurately set weights for both dense and sparse features (Green et al., 2014b). Rather than adjusting all weights based on each example, </context>
<context position="6812" citStr="Mathur et al., 2013" startWordPosition="1082" endWordPosition="1085">s essential, and so wi is typically computed with a single online update from wi−1 using (fi, e∗i) as the tuning example. To alleviate the need for human intervention in the experiment cycle, simulated post-editing (Hardt and Elming, 2010; Denkowski et al., 2014) replaces each e∗ with a reference that is not a corrected variant of e. Thus, a standard test corpus can be used as an adaptation corpus. Prior work on online learning from post-edits has demonstrated the benefit of adjusting only c (Ortiz-Martínez et al., 2010; Hardt and Elming, 2010) and further benefit from adjusting both c and w (Mathur et al., 2013; Denkowski et al., 2014). Incremental adaptation of both c and the weights w for sparse features is reported to yield large quality gains by Wäschle et al. (2013).2 3 Hierarchical Incremental Adaptation Our hierachical approach to incremental adaptation uses document and genre information to adapt appropriately to multiple contexts. We assume that each sentence fi has a known set Di of domains, which identify the genre and individual document origin of the sentence. This set could be extended to include topics, individual translators, etc. Figure 1 shows the domains that we apply in experimen</context>
</contexts>
<marker>Mathur, Mauro, Federico, 2013</marker>
<rawString>Prashant Mathur, Cettolo Mauro, and Marcello Federico. 2013. Online learning approaches in computer assisted translation. In Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 301–308, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Systematic Comparison of Various Statistical Alignment Models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="13836" citStr="Och and Ney, 2003" startWordPosition="2238" endWordPosition="2241">it ideal for observing the effects of incremental adaptation techniques. To train the language and translation model we additionally leveraged all available bilingual and monolingual data provided for the EMNLP 2015 Tenth Workshop on Machine Translation3. The total size of the bitext used for rule extraction and feature estimation was 6.4M sentence pairs. We trained a standard 5-gram language model with modified Kneser-Ney smoothing (Kneser and Ney, 1995; Chen and Goodman, 1998) using the KenLM toolkit (Heafield et al., 2013) on 4 billion running words. The bitext was word-aligned with mgiza (Och and Ney, 2003), and we used the phrasal decoder (Green et al., 2014a) with standard GermanEnglish settings for experimentation. Our second set of experiments was performed on a mixed-genre corpus containing lectures, patents, and news articles. The standard dev and test sets of the IWSLT 2014 shared task4 were used for the lecture genre. Each document corresponded to an entire lecture. For the news genre, we used newstest2012 for tuning, newstest2013 for metaparameter optimization, and newstest2014 for testing. The tune set for the patent genre is identical to the first set of experiments, while the test se</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A Systematic Comparison of Various Statistical Alignment Models. Computational Linguistics, 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>The Alignment Template Approach to Statistical Machine Translation.</title>
<date>2004</date>
<journal>Computational Linguistics,,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="3154" citStr="Och and Ney, 2004" startWordPosition="464" endWordPosition="467"> cross-genre contamination. In large-scale experiments, we adapt a multigenre baseline system to patents, lectures, and news articles. Our experiments show that sparse models, hierarchical updates, and rule adaptation all contribute consistent improvements. We observe quality gains in all genres, validating our hypothesis that document and genre context are important additional inputs to a machine translation system used for post-editing. 2 Background The log-linear appoach to statistical machine translation models the predictive translation distribution p(eIf; w) directly in log-linear form (Och and Ney, 2004): Z1f) exp I wTφ(r; c)] (1) p(e|f; w) = � r: src(r)=f tgt(r)=e 1059 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1059–1065, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. where f E F is a string in the set of all source language strings F, e E £ is a string in the set of all target language strings £, r is a phrasal derivation with source and target projections src(r) and tgt(r), w E Rd is the vector of model parameters, 0(·) E Rd is a feature map computed using corpus c, and Z(f) is an appropriate norm</context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>F. J. Och and H. Ney. 2004. The Alignment Template Approach to Statistical Machine Translation. Computational Linguistics,, 30(4):417–450.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ortiz-Martínez</author>
<author>Ismael García-Varea</author>
<author>Francisco Casacuberta</author>
</authors>
<title>Online learning for interactive statistical machine translation.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>546--554</pages>
<location>Los Angeles, California,</location>
<contexts>
<context position="1579" citStr="Ortiz-Martínez et al., 2010" startWordPosition="222" endWordPosition="225"> single fixed model for all different documents fails to incorporate contextual information that can potentially improve suggestion quality. We describe a model architecture that adapts simultaneously to multiple genres and individual documents, so that translation suggestions are informed by two levels of contextual information. Our primary technical contribution is a hierarchical adaptation technique for a post-editing scenario with incremental adaptation, in which users request translations of sentences in corpus order and provide corrected translations of each sentence back to the system (Ortiz-Martínez et al., 2010). Our learning approach resembles Hierarchical Bayesian Domain Adaptation (Finkel and Manning, 2009), but updates both the model weights and translation rules in real time based on these corrected translations (Mathur et al., 2013; Denkowski et al., 2014). Our adapted system can provide on-demand translations for any genre and document to which it has ever been exposed, using weights and rules for domains associated with each translation request. Our weight adaptation is performed using a hierarchical extension to fast and adaptive online training (Green et al., 2013b), a technique based on Ad</context>
<context position="6718" citStr="Ortiz-Martínez et al., 2010" startWordPosition="1064" endWordPosition="1067">pus ci−1. The new corpus ci results from adding (fi, e∗i) to ci−1. For incremental adaptation, speed is essential, and so wi is typically computed with a single online update from wi−1 using (fi, e∗i) as the tuning example. To alleviate the need for human intervention in the experiment cycle, simulated post-editing (Hardt and Elming, 2010; Denkowski et al., 2014) replaces each e∗ with a reference that is not a corrected variant of e. Thus, a standard test corpus can be used as an adaptation corpus. Prior work on online learning from post-edits has demonstrated the benefit of adjusting only c (Ortiz-Martínez et al., 2010; Hardt and Elming, 2010) and further benefit from adjusting both c and w (Mathur et al., 2013; Denkowski et al., 2014). Incremental adaptation of both c and the weights w for sparse features is reported to yield large quality gains by Wäschle et al. (2013).2 3 Hierarchical Incremental Adaptation Our hierachical approach to incremental adaptation uses document and genre information to adapt appropriately to multiple contexts. We assume that each sentence fi has a known set Di of domains, which identify the genre and individual document origin of the sentence. This set could be extended to incl</context>
</contexts>
<marker>Ortiz-Martínez, García-Varea, Casacuberta, 2010</marker>
<rawString>Daniel Ortiz-Martínez, Ismael García-Varea, and Francisco Casacuberta. 2010. Online learning for interactive statistical machine translation. In Human Language Technologies: The 2010Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 546–554, Los Angeles, California, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Plitt</author>
<author>F Masselot</author>
</authors>
<title>A productivity test of statistical machine translation post-editing in a typical localisation context. The Prague Bulletin of Mathematical Linguistics,</title>
<date>2010</date>
<pages>93--7</pages>
<contexts>
<context position="896" citStr="Plitt and Masselot, 2010" startWordPosition="121" endWordPosition="125">tion that maintains a flexible hierarchical domain structure within a single consistent model. Both weights and rules are updated incrementally on a stream of post-edits. Our multi-level domain hierarchy allows the system to adapt simultaneously towards local context at different levels of granularity, including genres and individual documents. Our experiments show consistent improvements in translation quality from all components of our approach. 1 Introduction Suggestions from a machine translation system can increase the speed and quality of professional human translators (Guerberof, 2009; Plitt and Masselot, 2010; Green et al., 2013a, inter alia). However, querying a single fixed model for all different documents fails to incorporate contextual information that can potentially improve suggestion quality. We describe a model architecture that adapts simultaneously to multiple genres and individual documents, so that translation suggestions are informed by two levels of contextual information. Our primary technical contribution is a hierarchical adaptation technique for a post-editing scenario with incremental adaptation, in which users request translations of sentences in corpus order and provide corre</context>
</contexts>
<marker>Plitt, Masselot, 2010</marker>
<rawString>M. Plitt and F. Masselot. 2010. A productivity test of statistical machine translation post-editing in a typical localisation context. The Prague Bulletin of Mathematical Linguistics, 93:7–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rico Sennrich</author>
<author>Holger Schwenk</author>
<author>Walid Aransa</author>
</authors>
<title>A multi-domain translation model framework for statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>832--840</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="5310" citStr="Sennrich et al., 2013" startWordPosition="826" endWordPosition="829">rse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human provides a corrected translation e∗ to the machine. Observing e∗ can affect both the Root Domain Figure 1: The weights used to translate a document in the patent gen</context>
</contexts>
<marker>Sennrich, Schwenk, Aransa, 2013</marker>
<rawString>Rico Sennrich, Holger Schwenk, and Walid Aransa. 2013. A multi-domain translation model framework for statistical machine translation. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 832–840, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Simianer</author>
<author>Stefan Riezler</author>
</authors>
<title>Multitask learning for improved discriminative training in SMT.</title>
<date>2013</date>
<booktitle>In Proceedings of the Eighth Workshop on Statistical Machine Translation,</booktitle>
<pages>292--300</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="5357" citStr="Simianer and Riezler, 2013" startWordPosition="834" endWordPosition="837">tive lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human provides a corrected translation e∗ to the machine. Observing e∗ can affect both the Root Domain Figure 1: The weights used to translate a document in the patent genre include three domains. model weights w and c</context>
</contexts>
<marker>Simianer, Riezler, 2013</marker>
<rawString>Patrick Simianer and Stefan Riezler. 2013. Multitask learning for improved discriminative training in SMT. In Proceedings of the Eighth Workshop on Statistical Machine Translation, pages 292–300, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Simianer</author>
<author>Stefan Riezler</author>
<author>Chris Dyer</author>
</authors>
<title>Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>11--21</pages>
<location>Jeju Island, Korea,</location>
<contexts>
<context position="5126" citStr="Simianer et al., 2012" startWordPosition="794" endWordPosition="797">c) may also include sparse features that have non-zero values for only a subset of rules, but typically do not depend on c (Liang et al., 2006). In this paper, we use four types of sparse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothes</context>
</contexts>
<marker>Simianer, Riezler, Dyer, 2012</marker>
<rawString>Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012. Joint Feature Selection in Distributed Stochastic Learning for Large-Scale Discriminative Training in SMT. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 11–21, Jeju Island, Korea, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linfeng Song</author>
<author>Haitao Mi</author>
<author>Yajuan Lü</author>
<author>Qun Liu</author>
</authors>
<title>Bagging-based system combination for domain adaption.</title>
<date>2011</date>
<booktitle>In Proceedings of the 13th Machine Translation Summit (MT Summit XIII),</booktitle>
<pages>293--299</pages>
<location>Xiamen, China.</location>
<contexts>
<context position="5525" citStr="Song et al., 2011" startWordPosition="863" endWordPosition="866">a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human provides a corrected translation e∗ to the machine. Observing e∗ can affect both the Root Domain Figure 1: The weights used to translate a document in the patent genre include three domains. model weights w and corpus c used for rule extraction and dense feature estimation.1 To translate the ith sentence fi, the system uses weights wi−1 and corpus ci−1. The new corpus ci result</context>
</contexts>
<marker>Song, Mi, Lü, Liu, 2011</marker>
<rawString>Linfeng Song, Haitao Mi, Yajuan Lü, and Qun Liu. 2011. Bagging-based system combination for domain adaption. In Proceedings of the 13th Machine Translation Summit (MT Summit XIII), pages 293– 299, Xiamen, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wang</author>
<author>Klaus Macherey</author>
<author>Wolfgang Macherey</author>
<author>Franz Och</author>
<author>Peng Xu</author>
</authors>
<title>Improved domain adaptation for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Tenth Conference of the Association for Machine Translation in the Americas (AMTA),</booktitle>
<location>San Diego, California.</location>
<contexts>
<context position="5234" citStr="Wang et al., 2012" startWordPosition="813" endWordPosition="816">depend on c (Liang et al., 2006). In this paper, we use four types of sparse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human provides a corrected translation e∗ to the machine. Observing e∗ can affect both the Root</context>
</contexts>
<marker>Wang, Macherey, Macherey, Och, Xu, 2012</marker>
<rawString>Wei Wang, Klaus Macherey, Wolfgang Macherey, Franz Och, and Peng Xu. 2012. Improved domain adaptation for statistical machine translation. In Proceedings of the Tenth Conference of the Association for Machine Translation in the Americas (AMTA), San Diego, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina Wäschle</author>
<author>Stefan Riezler</author>
</authors>
<title>Analyzing Parallelism and Domain Similarities in the MAREC Patent Corpus. Multidisciplinary Information Retrieval,</title>
<date>2012</date>
<pages>12--27</pages>
<contexts>
<context position="12600" citStr="Wäschle and Riezler, 2012" startWordPosition="2036" endWordPosition="2039">es would compromise responsiveness of our translation system and is thus a poor fit for real-time adaptive computer-assisted translation. However, features that can be learned on a single document are limited in number and can be discarded after the document has been processed. Therefore, document-level sparse features are a powerful means to fit our model to local context with a comparatively small impact on efficiency. 1061 4 Experiments We performed two sets of German→English experiments; Table 1 contains the results for both. Our first set of experiments was performed on the PatTR corpus (Wäschle and Riezler, 2012). We divided the corpus into training and development data by date and selected 2.4M parallel segments dated before 2000 from the “claims” section as bilingual training data, taking equal parts from each of the eight patent types A–H as classified by the Cooperative Patent Classification (CPC). From each type we further drew separate test sets and a single tune set, selecting documents with at least 10 segments and a maximum of 150 source words per segment, with around 2,100 sentences per test set and 400 sentences per type for the tune set. The “claims” section of this corpus is highly repeti</context>
</contexts>
<marker>Wäschle, Riezler, 2012</marker>
<rawString>Katharina Wäschle and Stefan Riezler. 2012. Analyzing Parallelism and Domain Similarities in the MAREC Patent Corpus. Multidisciplinary Information Retrieval, pages 12–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharina Wäschle</author>
<author>Patrick Simianer</author>
<author>Nicola Bertoldi</author>
<author>Stefan Riezler</author>
<author>Marcello Federico</author>
</authors>
<title>Generative and Discriminative Methods for Online Adaptation in SMT.</title>
<date>2013</date>
<booktitle>In Proceedings of Machine Translation Summit XIV,</booktitle>
<location>Nice, France.</location>
<contexts>
<context position="6975" citStr="Wäschle et al. (2013)" startWordPosition="1110" endWordPosition="1113">ntion in the experiment cycle, simulated post-editing (Hardt and Elming, 2010; Denkowski et al., 2014) replaces each e∗ with a reference that is not a corrected variant of e. Thus, a standard test corpus can be used as an adaptation corpus. Prior work on online learning from post-edits has demonstrated the benefit of adjusting only c (Ortiz-Martínez et al., 2010; Hardt and Elming, 2010) and further benefit from adjusting both c and w (Mathur et al., 2013; Denkowski et al., 2014). Incremental adaptation of both c and the weights w for sparse features is reported to yield large quality gains by Wäschle et al. (2013).2 3 Hierarchical Incremental Adaptation Our hierachical approach to incremental adaptation uses document and genre information to adapt appropriately to multiple contexts. We assume that each sentence fi has a known set Di of domains, which identify the genre and individual document origin of the sentence. This set could be extended to include topics, individual translators, etc. Figure 1 shows the domains that we apply in experiments. All sentences in the baseline training corpus, the tuning corpus, and the adaptation corpus share a ROOT domain. 1For the purpose of our description, the corpu</context>
</contexts>
<marker>Wäschle, Simianer, Bertoldi, Riezler, Federico, 2013</marker>
<rawString>Katharina Wäschle, Patrick Simianer, Nicola Bertoldi, Stefan Riezler, and Marcello Federico. 2013. Generative and Discriminative Methods for Online Adaptation in SMT. In Proceedings of Machine Translation Summit XIV, Nice, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jia Xu</author>
<author>Yonggang Deng</author>
<author>Yuqing Gao</author>
<author>Hermann Ney</author>
</authors>
<title>Domain dependent statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the MT Summit,</booktitle>
<pages>515--520</pages>
<location>Copenhagen, Denmark,</location>
<contexts>
<context position="5191" citStr="Xu et al., 2007" startWordPosition="805" endWordPosition="808">a subset of rules, but typically do not depend on c (Liang et al., 2006). In this paper, we use four types of sparse features: rule indicators, discriminative lexicalized reordering indicators, rule shape indicators and alignment features (Green et al., 2014b). The model parameters w are chosen to maximize translation quality on a tuning set. Adaptation. Domain adaptation for machine translation has improved quality using a variety of approaches, including data selection (Ceau§fu et al., 2011), regularized online learning (Simianer et al., 2012; Green et al., 2013b), and input classification (Xu et al., 2007; Banerjee et al., 2010; Wang et al., 2012) and has also been investigated for multidomain tasks (Sennrich et al., 2013; Cui et al., 2013; Simianer and Riezler, 2013). Even without domain labels at either training or test time, multi-task learning can boost translation quality in a batch setting (Duh et al., 2010; Song et al., 2011). Post-editing with incremental adaptation describes a particular mixed-initiative setting (OrtizMartínez et al., 2010; Hardt and Elming, 2010). For each f in a corpus, the machine generates a hypothesis e, then a human provides a corrected translation e∗ to the mac</context>
</contexts>
<marker>Xu, Deng, Gao, Ney, 2007</marker>
<rawString>Jia Xu, Yonggang Deng, Yuqing Gao, and Hermann Ney. 2007. Domain dependent statistical machine translation. In Proceedings of the MT Summit, pages 515–520, Copenhagen, Denmark, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>