<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.972519">
Broad-coverage CCG Semantic Parsing with AMR
</title>
<author confidence="0.92528">
Yoav Artzi∗ Kenton Lee Luke Zettlemoyer
</author>
<affiliation confidence="0.99879">
Dept. of Computer Science and Cornell Tech Computer Science &amp; Engineering
Cornell University University of Washington
</affiliation>
<address confidence="0.974553">
New York, NY 10011 Seattle, WA 98195
</address>
<email confidence="0.993867">
yoav@cs.cornell.edu {kentonl, lsz}@cs.washington.edu
</email>
<sectionHeader confidence="0.993669" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999989117647059">
We propose a grammar induction tech-
nique for AMR semantic parsing. While
previous grammar induction techniques
were designed to re-learn a new parser for
each target application, the recently anno-
tated AMR Bank provides a unique op-
portunity to induce a single model for un-
derstanding broad-coverage newswire text
and support a wide range of applications.
We present a new model that combines
CCG parsing to recover compositional
aspects of meaning and a factor graph
to model non-compositional phenomena,
such as anaphoric dependencies. Our ap-
proach achieves 66.2 Smatch F1 score on
the AMR bank, significantly outperform-
ing the previous state of the art.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999222360655738">
Semantic parsers map sentences to formal repre-
sentations of their meaning (Zelle and Mooney,
1996; Zettlemoyer and Collins, 2005; Liang et al.,
2011). Existing learning algorithms have primar-
ily focused on building actionable meaning repre-
sentations which can, for example, directly query
a database (Liang et al., 2011; Kwiatkowski et al.,
2013) or instruct a robotic agent (Chen, 2012;
Artzi and Zettlemoyer, 2013b). However, due to
their end-to-end nature, such models must be re-
learned for each new target application and have
only been used to parse restricted styles of text,
such as questions and imperatives.
Recently, AMR (Banarescu et al., 2013) was
proposed as a general-purpose meaning represen-
tation language for broad-coverage text, and work
is ongoing to study its use for variety of appli-
cations such as machine translation (Jones et al.,
2012) and summarization (Liu et al., 2015). The
∗Work done at the University of Washington.
AMR meaning bank provides a large new corpus
that, for the first time, enables us to study the
problem of grammar induction for broad-coverage
semantic parsing. However, it also presents sig-
nificant challenges for existing algorithms, in-
cluding much longer sentences, more complex
syntactic phenomena and increased use of non-
compositional semantics, such as within-sentence
coreference. In this paper, we introduce a new,
scalable Combinatory Categorial Grammar (CCG;
Steedman, 1996, 2000) induction approach that
solves these challenges with a learned joint model
of both compositional and non-compositional se-
mantics, and achieves state-of-the-art performance
on AMR Bank parsing.
We map sentences to AMR structures in a two-
stage process (Section 5). First, we use CCG to
construct lambda-calculus representations of the
compositional aspects of AMR. CCG is designed
to capture a wide range of linguistic phenomena,
such as coordination and long-distance dependen-
cies, and has been used extensively for semantic
parsing. To use CCG for AMR parsing we define a
simple encoding for AMRs in lambda calculus, for
example, as seen with the logical form z and AMR
a in Figure 1 for the sentence Pyongyang officials
denied their involvement. However, using CCG to
construct such logical forms requires a new mech-
anism for non-compositional reasoning, for exam-
ple to model the long-range anaphoric dependency
introduced by their in Figure 1.
To represent such dependencies while main-
taining a relatively compact grammar, we fol-
low Steedman’s (2011) use of generalized Skolem
terms, a mechanism to allow global references in
lambda calculus. We then allow the CCG deriva-
tion to mark when non-compositional reasoning is
required with underspecified placeholders. For ex-
ample, Figure 1 shows an underspecified logical
form u that would be constructed by the grammar
with the bolded placeholder ID indicating an un-
</bodyText>
<page confidence="0.979265">
1699
</page>
<note confidence="0.984967">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1699–1710,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999851163265306">
resolved anaphoric reference. These placeholders
are resolved by a factor graph model that is defined
over the output logical form and models which
part of it they refer to, for example to find the ref-
erent for a pronoun. Although primarily motivated
by non-compositional reasoning, we also use this
mechanism to underspecify certain relations dur-
ing parsing, allowing for more effective search.
Following most work in semantic parsing, we
consider two learning challenges: grammar in-
duction, which assigns meaning representations
to words and phrases, and parameter estimation,
where we learn a model for combining these
pieces to analyze full sentences. We introduce a
new CCG grammar induction algorithm which in-
corporates ideas from previous algorithms (Zettle-
moyer and Collins, 2005; Kwiatkowski et al.,
2010) in a way that scales to the longer sentences
and more varied syntactic constructions observed
in newswire text. During lexical generation (Sec-
tion 6.1), the algorithm first attempts to use a set
of templates to hypothesize new lexical entries. It
then attempts to combine bottom-up parsing with
top-down recursive splitting to select the best en-
tries and learn new templates for complex syntac-
tic and semantic phenomena, which are re-used in
later sentences to hypothesize new entries.
Finally, while previous algorithms (e.g., Zettle-
moyer and Collins, 2005) have assumed the ex-
istence of a grammar that can parse nearly every
sentence to update its parameters, this does not
hold for AMR Bank. Due to sentence complex-
ity and search errors, our model cannot produce
fully correct logical forms for a significant portion
of the training data. To learn from as much of the
data as possible and accelerate learning, we adopt
an early update strategy to generate effective up-
dates from partially correct analyses (Section 6.2).
We evaluate performance on the publicly avail-
able AMR Bank (Banarescu et al., 2013) and
demonstrate that our modeling and learning con-
tributions are crucial for grammar induction at this
scale and achieve new state-of-the-art results for
AMR parsing (Section 8). In addition, we also
present, for the first time, results without surface-
form alignment heuristics, which demonstrates the
need for future work, especially to generalize to
other languages. The source code and learned
models are available online.1
</bodyText>
<footnote confidence="0.975613">
1http://yoavartzi.com/amr
</footnote>
<note confidence="0.668241">
x: Pyongyang officials denied their involvement.
</note>
<equation confidence="0.9902758">
a: (d/deny-01
:ARG0 (p/person
:ARG0-of (h/have-org-role-91
:ARG1 (c/city
: name (n/name :op1“Pyongyang”))
:ARG2(o/official)))
:ARG1 (i/involve-01 :ARG1 p))
u: A1(Ad.deny-01(d) ∧
ARG0(d, A2(Ap.person(p) ∧
REL-of(p, A3(Ah.have-org-role-91(h) ∧
ARG1(h, A4(Ac.city(c) ∧
name(c, A5(An.name(n) ∧
op1(n, PYONGYANG))))) ∧
REL(h, A6(Ao.official(o)))))) ∧
ARG1(d, A7(Ai.involve-01(i) ∧
ARG1(i, R(ID))))))
z: A1(Ad.deny-01(d) ∧
ARG0(d, A2(Ap.person(p) ∧
ARG0-of(p, A3(Ah.have-org-role-91(h) ∧
ARG1(h, A4(Ac.city(c) ∧
name(c, A5(An.name(n) ∧
op1(n, PYONGYANG))))) ∧
ARG2(h, A6(Ao.official(o)))))) ∧
ARG1(d, A7(Ai.involve-01(i) ∧
ARG1(i, R(2))))))
</equation>
<figureCaption confidence="0.90783375">
Figure 1: A sentence (x) paired with its AMR (a), un-
derspecified logical form (u), which contains under-
specified constants in bold that are mapped to AMR re-
lations to generate the fully specified logical form (z).
</figureCaption>
<sectionHeader confidence="0.948059" genericHeader="introduction">
2 Technical Overview
</sectionHeader>
<bodyText confidence="0.999082269230769">
Task Let X be the set of all possible sentences
and A the set of all AMR structures. Given a sen-
tence x E X, we aim to generate an AMR a E A.
We define a simple, deterministic and invertible
conversion process between AMRs and lambda-
calculus logical forms; roughly speaking, each
AMR variable gets its own lambda term, which
is scoped as low as possible, and each AMR role
becomes a binary predicate applied to these vari-
ables. Figure 1 shows an example, and the full de-
tails are provided in the supplementary materials.
Therefore, henceforth we discuss the task of map-
ping a sentence x E X to a logical form z E i,
where i is the set of all logical forms. For ex-
ample, in Figure 1, we would map the sentence x
to the logical form z. We evaluate system perfor-
mance using SMATCH (Cai and Knight, 2013).
Model Given a sentence x and lexicon A, we
generate the set of possible derivations GEN(x, A)
using a two-stage process (Section 5). First,
we use a weighted CCG to map x to an under-
specified logical form u (Section 5.1), a logical
form with placeholder constants for unresolved el-
ements. For example, in the underspecified log-
ical form u in Figure 1, the constants REL-of,
REL and ID are placeholders. We then resolve
</bodyText>
<page confidence="0.975786">
1700
</page>
<bodyText confidence="0.999325882352941">
these placeholders by defining a factor graph to
find their optimal mapping and generate the final
logical form z. In the figure, REL-of is mapped to
ARG0-of, REL to ARG2 and ID to 2.
Learning We assume access to a training set of
N examples {(xi, zi) : i = 1... N}, each con-
taining a sentence xi and a logical form zi. Our
goal is to learn a CCG, which constitutes learn-
ing the lexicon and estimating the parameters of
both the grammar and the factor graph. We de-
fine a learning procedure (Section 6) that alter-
nates between expanding the lexicon and updating
the parameters. Learning new lexical entries relies
on a two-pass process that combines learning the
meaning of words and new syntactic structures,
and supports learning with and without alignment
heuristics (e.g., from Flanigan et al., 2014).
</bodyText>
<sectionHeader confidence="0.999965" genericHeader="related work">
3 Related Work
</sectionHeader>
<bodyText confidence="0.9999021875">
The problem of learning semantic parsers has re-
ceived significant attention. Algorithms have been
developed for learning from different forms of
supervision, including logical forms (Wong and
Mooney, 2007; Muresan, 2011), question-answer
pairs (Clarke et al., 2010; Liang et al., 2011; Cai
and Yates, 2013; Kwiatkowski et al., 2013), sen-
tences paired with demonstrations (Goldwasser
and Roth, 2011; Chen and Mooney, 2011), con-
versational logs (Artzi and Zettlemoyer, 2011),
distant supervision (Krishnamurthy and Mitchell,
2012, 2015; Reddy et al., 2014) and without ex-
plicit semantic supervision (Poon, 2013).
Although we are first to consider using CCG to
build AMR representations, our work is closely re-
lated to existing methods for CCG semantic pars-
ing. Previous CCG induction techniques have ei-
ther used hand-engineered lexical templates (e.g.,
Zettlemoyer and Collins, 2005) or learned tem-
plates from the data directly (e.g., Kwiatkowski
et al., 2010, 2012). Our two-pass reasoning for
lexical generation combines ideas from both meth-
ods in a way that greatly improves scalability to
long, newswire-style sentences. CCG has also
been used for broad-coverage recovery of first-
order logic representations (Bos, 2008; Lewis and
Steedman, 2013). However, this work lacked cor-
pora to evaluate the logical forms recovered.
AMR (Banarescu et al., 2013) is a general-
purpose meaning representation and has been used
in a number of applications (Pan et al., 2015; Liu
et al., 2015). There is also work on recovering
</bodyText>
<equation confidence="0.965481909090909">
Happy people dance
N[x]/N[x] N[pl] S\NP[pl]
λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d)
A(λc.content-01(c))) ∧ARG0(d, x)
&gt;
NP[pl]
A(λp.people(p) ∧ ARG1-of(x,
A(λc.content-01(c))))
S
λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x,
A(λc.content-01(c)))))
</equation>
<figureCaption confidence="0.969434666666667">
Figure 2: Example CCG tree with three lexical entries,
two forward applications (&gt;) and type-shifting of a plu-
ral noun to a noun phrase.
</figureCaption>
<bodyText confidence="0.999263">
AMRs, including graph parsing (Flanigan et al.,
2014), methods to build AMRs from dependency
trees (Wang et al., 2015) and algorithms for align-
ing words to AMRs (Pourdamghani et al., 2014).
</bodyText>
<sectionHeader confidence="0.997502" genericHeader="method">
4 Background
</sectionHeader>
<bodyText confidence="0.999090055555555">
Combinatory Categorial Grammar CCG is a
categorial formalism that provides a transparent
interface between syntax and semantics (Steed-
man, 1996, 2000). Section 7 details our instan-
tiation of CCG. In CCG trees, each node is a
category. Figure 2 shows a simple CCG tree.
For example, S\NP[pl] : Ax.Ad.dance-01(d) n
ARG0(d, x) is a category for an intransitive verb
phrase. The syntactic type S\NP[pl] indicates that
an argument of type NP[pl] is expected and the
returned syntactic type will be S. The backward
slash \ indicates the argument is expected on the
left, while a forward slash / indicates it is ex-
pected on the right. The syntactic attribute pl spec-
ifies that the argument must be plural. Attribute
variables enforce agreement between syntactic at-
tributes. For example, as in Figure 2, adjectives
are assigned the syntax N[x]/N[x], where x is used
to indicate that the attribute of the argument will
determine the attribute of the returned category.
The simply-typed lambda calculus logical form in
the category represents its semantic meaning. The
typing system includes basic types (e.g., entity e,
truth value t) and functional types (e.g., (e, t) is
the type of a function from e to t). In the example
category, Ax.Ad.dance-01(d) n ARG0(d, x) is a
(e, (e, t))-typed function expecting an ARG0 ar-
gument, and the conjunction specifies the roles of
the dance-01 frame.
A CCG is defined by a lexicon and a set of com-
binators. The lexicon pairs words and phrases with
their categorial meaning. For example, dance �-
Ax.Ad.dance-01(d) n ARG0(d, x) pairs dance
with the category above. We adopt a factored
representation of the lexicon (Kwiatkowski et al.,
2011), where entries are dynamically generated by
</bodyText>
<equation confidence="0.974993666666667">
N[pl]
λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))
&gt;
</equation>
<page confidence="0.880517">
1701
</page>
<bodyText confidence="0.999710166666667">
combining lexemes and templates. For example,
the above lexical entry can be generated by pair-
ing the lexeme (dance, {dance-01}) with the tem-
plate Av1.[S\NP : Ax.Aa.v1(a) n ARG0(a, x)].
Skolem Terms and IDs Generalized Skolem
terms (henceforth, Skolem terms) for CCG were
introduced by Steedman (2011) to capture com-
plex dependencies with relatively local quantifi-
cation. We define here a simplified version of
the theory to represent entities and allow distant
references. Let A be a ((e, t), e)-typed predi-
cate. Given a (e, t)-typed logical expression C,
the logical form An(C) is a Skolem term with
the Skolem ID n. For example, A2(Ay.boy(y))
is a Skolem term that could represent the noun
phrase the boy, which introduces a new entity.
Skolem IDs are globally scoped, i.e., they can
be referred from anywhere in the logical form
without scoping constraints. To refer to Skolem
terms, we define the (id, e)-typed predicate R.
For example, the sentence the boy loves him-
self may be represented with A1(Ax.love-01(x) n
ARG0(x, A2(Ay.boy(y))) n ARG1(x, R(2))),
where R(2) references A2(Ay.boy(y)).
</bodyText>
<sectionHeader confidence="0.827991" genericHeader="method">
5 Mapping Sentences to Logical Form
</sectionHeader>
<bodyText confidence="0.999966833333333">
Given a sentence x and lexicon Λ, the function
GEN(x, Λ) defines the set of possible derivations.
Each derivation d is a tuple (y, M), where y is a
CCG parse tree and M is a mapping of constants
from u, the underspecified logical form at the root
of y, to their fully specified form.
</bodyText>
<subsectionHeader confidence="0.993474">
5.1 Underspecified Logical Forms
</subsectionHeader>
<bodyText confidence="0.998197433333334">
An underspecified logical form represents multi-
ple logical forms via a mapping function that maps
its constants to sets of constants and Skolem IDs.
For example, consider the underspecified logical
form u at the top of Figure 3b. If, for example,
REL can be mapped to manner or ARG2, then
the sub-expression REL(h, A6(Ao.official(o)))
represents manner(h, A6(Ao.official(o))) or
ARG2(h, A6(Ao.official(o))). During learning,
we assume access to fully specified logical forms,
which we convert to underspecified form as
needed. In practice, all binary relations, except
ARG0 and ARG1, and all Skolem ID references
are underspecified.
Formally, let C be the set of all constants and
Z(u) the set of all Skolem IDs in the logical form
u. Let Su : C → 2C∪I(u) be a specification func-
tion, such that its inverse is deterministic. We call
a constant c a placeholder if |Su(c) |&gt; 1. Given
an underspecified logical form u, applying Su to
all constants u contains, generates a set of fully
specified logical forms.
We define Su to be (a) Su(ID) = Z(u),
the set of Skolem IDs in u, (b) Su(REL) =
{part, ARG2,... }, all 67 active AMR relations
except ARG0 and ARG1, (c) Su(REL-of) =
{part-of, ARG0-of,... }, all 33 passive relations,
and otherwise (d) Su(c) = c. For example, in u in
Figure 3b, the set of assignments to the ID place-
holder is Z(u) = {1, 2, 3, 4, 5, 6, 7}.
</bodyText>
<subsectionHeader confidence="0.992217">
5.2 Derivations
</subsectionHeader>
<bodyText confidence="0.999992769230769">
The first part of a derivation d = (y, M) is a CCG
parse tree y with an underspecified logical form u
at its root. For example, Figure 3a shows such a
CCG parse tree, where the logical form contains
the placeholders REL, REL-of and ID.
The second part of the derivation is a func-
tion M : CONSTS(u) → C U Z(u), where
CONSTS(u) is the set of all occurrences of con-
stants in u. For example, in Figure 3b, CONSTS(u)
contains, among others, three different occur-
rences of ARG1 and one of ID, and M maps
REL to ARG2, REL-of to ARG0-of and ID to
the Skolem ID 2. The set of potential assignments
for each occurrence of constant c is Su(c), and M,
which returns a single element for each constant,
is a disambiguation of Su. Applying M to all con-
stants in u results in the final logical form z.
Decomposing the derivation provides two ad-
vantages. First, we are able to defer decisions from
the CCG parse to the factor graph, thereby consid-
ering fewer hypotheses during parsing and sim-
plifying the computation. Second, we can repre-
sent distant references while avoiding the complex
parse trees that would have been required to repre-
sent these dependencies with scoped variables in-
stead of Skolem IDs.2
</bodyText>
<subsectionHeader confidence="0.995948">
5.3 Model
</subsectionHeader>
<bodyText confidence="0.99986">
Given a sentence x, we use a weighted log-linear
CCG (Lafferty et al., 2001; Clark and Curran,
2007) to rank the space of possible parses under
the grammar Λ. At the root of each CCG deriva-
tion is the underspecified logical form u.
To represent a probability distribution over M,
we build for each u a factor graph Gu = (V, F, E),
</bodyText>
<footnote confidence="0.9937485">
2Similar to mention clustering methods for co-reference
resolution (Ng, 2010), IDs can be viewed as creating clusters.
</footnote>
<page confidence="0.995671">
1702
</page>
<figure confidence="0.878401181818182">
(a) CCG parse y: Maps the sentence x to an underspecified logical form u (Section 5.1) with placeholders for
unresolved decisions: ID for reference identifiers and the predicates REL and REL-of for unresolved relations.
x: Pyongyang officials denied their involvement
NP[sg] N[pl]\(N[pl]/N[pl]) S\NP/NP NP[pl] N[nb]
A1(λc.city(c)∧ λf.λp.person(p)∧ λx.λy.λd.deny-01(d)∧ R(ID) λi.involve-01(i)
name(c, A2(λn.name(n)∧ REL-of(p A3(f(λh.have-or -role-91(h)∧ ARG0(d, y)∧
op(n, PYONGYANG)))) REL(h,. 14(λo.official(o))))�) ARG1(d, x)
&lt; &gt;
&gt;
&lt;
A
u: A1(λd.deny-01(d) ∧ ARG0(d, A2(λp.person(p) ∧ REL-of(p, A3(λh.have-org-role-91(h) ∧ ARG1(h, A4(λc.city(c) ∧ name(c,
A5(λn.name(n) ∧ op(n, PYONGYANG))))) ∧ REL(h, A6(λo.official(o)))))) ∧ ARG1(d, A7(λi.involve-01(i) ∧ ARG1(i, R(ID))))))
(b) Constant mapping M: Each constant in u, the logical form at the root of y, is mapped to a Skolem ID or a
logical constant to create the fully specified logical form z, which can be converted to an AMR. Only mappings
that modify constants are illustrated.
u: A1(Ad.deny-01(d) n ARG0(d, A2(Ap.person(p) n REL-of(p, A3(Ah.have-org-role-91(h) n
ARG1(h, A4(Ac.city(c) n name(c, A5(An.name(n) n op(n, PYONGYANG))))) n
REL(h, A6(Ao.official(o)))))) n ARG1(d, A7(Ai.involve-01(i) n ARG1(i, R(ID))))))
z: A1(Ad.deny-01(d) n ARG0(d, A2(Ap.person(p) n ARG0-of(p, A3(Ah.have-org-role-91(h) n
ARG1(h, A4(Ac.city(c) n name(c, A5(An.name(n) n op(n, PYONGYANG))))) n
ARG2(h, A6(Ao.official(o)))))) n ARG1(d, A7(Ai.involve-01(i) n ARG1(i, R(2))))))
</figure>
<figureCaption confidence="0.98633075">
Figure 3: A complete derivation for the sentence Pyongyang officials denied their involvement.
Figure 4: A visualization of the factor graph constructed for the derivation in Figure 3. Variables are marked with
gray background. The set of possible assignments, marked with a dashed arrow, is only specified for placeholders
(REL-of, REL and ID). Only a subset of the factors are included (A, B, C2 and C3). Solid lines represent edges.
Factor A captures selectional preference between the types have-org-role-91 and official to determine the relation
REL. Factor B does the same for person and have-org-role-91 to determine REF-of. Factors C2 and C3 account
for selectional preferences when resolving ID. In C2, we consider the assignment 2, which will create a relation
of type ARG1 between the types involve-01 and person. C3 similarly considers the assignment 3.
</figureCaption>
<figure confidence="0.984066045454545">
A
B
nit,prep ith,fre ency,
prep against, compared to,
employed by, ARG2,...
1,2,3,4,5,6,7
A1(Ad.deny 01(d)^
ARG0(d, A2(ap.
ARG1(d,A7(Ai.involve 01
REL of(p,A3(Ah.have org role 91(h)^
ARG1(h, A4(Ac.city(c)^
name(c, A5(An.name(n) ^ op(n, G A G))))) ^
REL(h, As(Jto.
ARG1(i,R(ID))))))
person(p)^
(i)^
C3
official(o))))))^
nit of, prep ith of, fre ency of,
prep against of, compared to of,
employed by of, ARG0 of,...
C2
</figure>
<bodyText confidence="0.99992746875">
where V = CONSTS(u) is the set of variables,
F is the set of factors and E is the set of edges.
Each edge is of the form (v, f) where v E V and
f E F. Figure 4 shows the factor graph used in
generating the derivation in Figure 3, including all
the variables and a subset of the factors. For each
variable vc E V such that c E CONSTS(u) the set
of possible assignments is determined by Su(c).
To generate the factors F and edges E we use
the function Φ(V &apos;) that maps a set of variables
V &apos; C_ V to a factor f and a set of edges, each
one of the form (v, f), where v E V &apos;. Factors ex-
press various features (Section 7), such as selec-
tional preferences and control structures. In the
figure, Factor A captures the selectional prefer-
ence for the assignment of the relation REL be-
tween have-org-role-91 and official. Factor B
captures a similar preference, this time to resolve
REL-of. Factor C2 captures a selectional pref-
erence triplet involve-01/ARG1/person that will
be created if ID is resolved to the Skolem ID 2.
Finally, C3 captures a similar preference for re-
solving ID to 3. Since the assignment of many of
the variables is fixed, i.e., they are fully specified
constants, in practice our factor graph representa-
tion simply conditions on them.
Derivations are scored using a log-linear model
that includes both CCG parse features and those
defined by the factor graph. Let D(z) be the sub-
set of derivations with the final logical form z and
θ E 1R,l be a l-dimensional parameter vector. We
define the probability of the logical form z as
</bodyText>
<equation confidence="0.982529">
p(zjx; 0, Λ) = � p(djx; 0, Λ) ,
d∈D(z)
</equation>
<bodyText confidence="0.917055">
and the probability of a derivation d is defined as
</bodyText>
<equation confidence="0.991566666666667">
p(djx; 0, Λ) = eθ·φ(x,d&apos;) , (1)
�d ∈ GEN(x,Λ)
eθ·φ(x,d)
</equation>
<page confidence="0.672631">
1703
</page>
<bodyText confidence="0.989888">
where O(x, d) ∈ Rl is a feature vector (Section 7).
</bodyText>
<sectionHeader confidence="0.600271" genericHeader="method">
5.4 Inference
</sectionHeader>
<bodyText confidence="0.999928866666667">
To compute the set of derivations GEN(x, A) we
define a two-stage process. We first run the
CCG parser to generate underspecified logical
forms. Following previous work (Zettlemoyer and
Collins, 2005), we use CKY parsing to enumer-
ate the top-K underspecified logical forms.3 Dur-
ing the CKY chart construction, we ignore Skolem
IDs when comparing categories. This allows us to
properly combine partial derivations and to fully
benefit from the dynamic programming. We dy-
namically generate lexical entries for numbers and
dates using regular expression patterns and for
named-entities using a recognizer. For every un-
derspecified logical form u, we construct a factor
graph and use beam search to find the top-L con-
figurations of the graph.4
During learning, we use the function
GENMAX(x, z, 0, A) to get all derivations
that map the sentence x to the logical form z,
given parameters 0 and lexicon A. To compute
GENMAX, we follow Zettlemoyer and Collins
(2005) and collect constant co-occurrence counts
from z to prune from the CKY chart any category
that cannot participate in a derivation leading to
z. Since only constant names are changed during
the second stage, setting the factor graph to get
z is trivial: if the underspecified logical form is
identical to z except the placeholders, we replace
the placeholders with the correct final assignment,
otherwise the derivation cannot result in z.
</bodyText>
<sectionHeader confidence="0.99638" genericHeader="method">
6 Learning
</sectionHeader>
<bodyText confidence="0.999890583333333">
Learning the two-stage model requires inducing
the entries of the CCG lexicon A and estimating
the parameters 0, which score both stages of the
derivation. We assume access to a training set
of N examples D = {(xi, zi) : i = 1... N},
each containing a sentence xi and a logical form
zi. This data does not include information about
the lexical entries and CCG parsing operations re-
quired to construct the correct derivations. We
consider all these decisions as latent.
The main learning algorithm (Algorithm 1)
starts by initializing the lexicon (line 1) and then
</bodyText>
<footnote confidence="0.99790825">
3See Artzi et al. (2014) for a description of this process
and how to approximate the partition function in Equation 1.
4Experiments with loopy belief propagation showed it to
be slower and less effective for our task.
</footnote>
<construct confidence="0.298909">
Algorithm 1 The main learning algorithm.
</construct>
<bodyText confidence="0.974190307692308">
Input: Training set D = {(xi, zi) : i = 1 ... N}, number
of iterations T, mini-batch size M, seed lexicon A0 and
learning rate µ.
Definitions: SUB(D, i, j) is the set of the next j sam-
ples from D starting at i. GENMAX(x, z, 0, A) is
the set of viterbi derivations from x with the final re-
sult z given parameters 0 and lexicon A. LEX(d)
is the set of lexical entries used in the derivation d.
COMPUTEGRAD(x, z, 0, A) computes the gradient for
sentence x and logical form z, given the parame-
ters 0 and lexicon A, and it described in Section 6.2.
ADAGRAD(Δ) applies a per-feature learning rate to the
gradient Δ (Duchi et al., 2011).
</bodyText>
<listItem confidence="0.951220333333333">
Output: Lexicon A and model parameters 0.
1: A +— A0
2: fort = 1 to T do
3: » Generate entries and update the lexicon.
4: for i = 1 to N do
5: Anew +— Anew U GENENTRIES(xi, zi, 0, A)
6: A +— A U Anew
7: » Compute and apply mini-batch gradient updates.
8: for i=1to[NM]do
9: Δ +— 0�
10: for (x, z) in SUB(D, i, M) do
11: » Compute and aggregate the gradient.
</listItem>
<equation confidence="0.33422225">
12: Δ +— Δ + COMPUTEGRAD(x, z, 0, A)
13: 0 +— 0 + µADAGRAD(Δ)
14: » Get all correct viterbi derivations.
V +— �
</equation>
<listItem confidence="0.4000895">
15: (x,z)ED GENMAX(x, z, 0, A)
16: » Retain only entries from derivations in V .
17: A +— UdEV LEX(d)
18: return A and 0
</listItem>
<construct confidence="0.676614">
Algorithm 2 GENENTRIES: Procedure to generate lexical
entries from one training sample. See Section 6.1 for details.
Input: Sample (x, z), model parameters 0 and lexicon A.
Definitions: GENLEX(x, z, A) and
RECSPLIT(z, z, 0, A) are defined in Section 6.1.
Output: Set of lexical entries A.
</construct>
<listItem confidence="0.9442046">
1: » Augment lexicon with sample-specific entries.
2: A+ +— A U GENLEX(x, z, A)
3: » Get max-scoring correct derivations.
4: D+ +— GENMAX(x, z, A+, 0)
5: if |D+ |&gt; 0 then
6: » Return entries from max-scoring derivations.
7: return UdED+ LEX(d)
8: else
9: » Top-down splitting to generate new entries.
10: return RECSPLIT(x, z, 0, A+)
</listItem>
<bodyText confidence="0.999852833333334">
processes the data T times (line 2), each time al-
ternating between batch expansion of the lexicon
and a sequence of mini-batch parameter updates.
An iteration starts with a batch pass to expand the
lexicon. The subroutine GENENTRIES, described
in Section 6.1 and Algorithm 2, is called to gener-
ate a set of new entries for each sample (line 5).
Next, we update the parameters 0 with mini-
batch updates. Given a mini-batch size of M,
we use the procedure SUB(D, i, M) to get the
i-th segment of the data D of size M. We pro-
cess this segment (line 10) to accumulate the
</bodyText>
<page confidence="0.991641">
1704
</page>
<bodyText confidence="0.99995075">
mini-batch gradient Δ by calling the procedure
COMPUTEGRAD(x, z, 0, A) (line 12), which com-
putes the gradient for x and z given 0 and A, as
described in Section 6.2. We use AdaGrad (Duchi
et al., 2011) parameter updates (line 13).
Each iteration concludes with removing all lexi-
cal entries not used in max-scoring correct deriva-
tions, to correct for overgeneration (lines 14-17).
</bodyText>
<subsectionHeader confidence="0.996722">
6.1 Lexicon Expansion: GENENTRIES
</subsectionHeader>
<bodyText confidence="0.992277981132075">
Given a sentence x, a logical form z, parameters 0
and a lexicon A, GENENTRIES(x, z, 0, A) (Algo-
rithm 2) computes a set of lexical entries, such that
there exists at least one derivation d using these
entries from x to z. We first use GENLEX(x, z, A)
to generate a large set of potential lexical entries
from u, the underspecified form of z, by generat-
ing lexemes (Section 4) and pairing them with all
templates in A. We then use a two-pass process
to select the entries to return. The set of gener-
ated lexemes is a union of: (a) the set Ggen that
includes all pairings of subsets of constants from
z with spans in x up to length kgen and (b) the
set that is constructed by matching named-entity
constants5 in z with their corresponding mentions
in the text to create new lexemes with potentially
any other constant (for lexemes with multiple con-
stants). A is augmented with the generated set of
lexical entries to create A+ (line 2).
First Pass Given the augmented lexicon A+, we
compute the set D+ = GENMAX(x, z, 0, A+)
(line 4). Following Artzi and Zettlemoyer
(2013b), we constrain the set of derivations to in-
clude only those that use at most one lexeme from
Ggen. If generating new lexemes is sufficient to
derive z from x, D+ will contain these derivations
and we return their lexical entries to be added to
the lexicon A (lines 5-7). Otherwise, we proceed
to do a second pass, where we try to generate new
templates to parse the sentence.
Second Pass: RECSPLIT In this pass we try
to generate max-scoring derivations in a top-down
process. Starting from u, the underspecified form
of z, we search for CCG parsing steps that will
connect to existing partial derivations in the CKY
chart to create a complete parse tree. Since the
space of possible operations is extremely large,
5Named-entity constants are created from name instances
when converting from AMR to lambda calculus. See the sup-
plementary material for the exact procedure.
we use CCGBank (Hockenmaier and Steedman,
2007) categories to prune, as described below.
The second pass is executed by calling
RECSPLIT(x, z, 0, A+), which returns a set of lex-
ical entries to add to the model (line 10). We recur-
sively apply the splitting operation introduced by
Kwiatkowski et al. (2010). Given a CCG category,
splitting outputs all possible category pairs that
could have originally generated it. For example,
given the category 5\NP �- Ay.Ad.deny-01(d) ∧
ARG0(d, y) ∧ ARG1(d, A1(Ai.involve-01(i) ∧
ARG1(i, R(ID)))), one of the possi-
ble splits will include the categories
</bodyText>
<equation confidence="0.977919666666667">
5\NP/NP Ax.Ay.Ad.deny-01(d) ∧
ARG0(d, y) ∧ ARG1(d, x) and NP �
A1(Ai.involve-01(i) ∧ ARG1(i,R(ID))) which
</equation>
<bodyText confidence="0.999824466666667">
would combine with forward application (&gt;).
Kwiatkowski et al. (2010) present the full details.6
The process starts from u, the underspecified
form of z, and recursively applies the splitting
operation while ensuring that: (1) there is at most
one entry from Ggen or one entry where both the
template and lexemes are new in the derivation,
(2) each parsing step must have at least one child
that may be constructed from an existing partial
derivation, and (3) for each new parsing step, the
syntax of a newly generated child must match the
syntax of a CCGBank category for the same span.
To search the space of derivations we populate a
CKY chart and do a top-down beam search, where
in each step we split categories for smaller spans.
</bodyText>
<subsectionHeader confidence="0.997278">
6.2 Gradient Computation: COMPUTEGRAD
</subsectionHeader>
<bodyText confidence="0.9999875">
Given a sentence x, its labeled logical form
z, parameters 0 and lexicon A, the procedure
COMPUTEGRAD(x, z, 0, A) computes the gradi-
ent for the sample (x, z). Let D∗(z) =
GENMAX(x, z, 0, A), the set of max-scoring cor-
rect derivations. The hard gradient update is:
</bodyText>
<equation confidence="0.999173666666667">
1
* E φ(xi , d) − Ep(d, |xi;θ,Λ) [φ(xi, d)] , (2)
|D (z) |dED∗(z)
</equation>
<bodyText confidence="0.995460375">
where φ(x, d) E 1R,1 is a l-dimensional feature vec-
tor (Section 5.3) and the positive portion of the
gradient, rather than using expected features, av-
erages over all max-scoring correct derivations.
Early updates To generate an effective update
when no correct derivation is observed, we fol-
low Collins and Roark (2004) and do an early up-
date if D∗(z) is empty or if GEN(x, A), the set
</bodyText>
<footnote confidence="0.9720875">
6Unlike Kwiatkowski et al. (2010), we also introduce syn-
tactic attributes (e.g., pl, sg) when splitting.
</footnote>
<page confidence="0.993405">
1705
</page>
<bodyText confidence="0.99996625">
of derivations for x, does not contain a derivation
with the correct final logical form z. Given the par-
tial derivations, our gradient computation is identi-
cal to Equation 2. However, in contrast to Collins
and Roark (2004) our data does not include gold
derivations. Therefore, we attempt to identify
max-scoring partial derivations that may lead to
the correct derivation. We extract sub-expressions
from u,7 the underspecified form of z, and search
the CKY chart for the top-scoring non-overlapping
spans that contain categories with these logical
forms. We use the partial derivations leading to
these cells to compute the gradient.
The benefit of early updates is two-fold. First,
as expected, it leads to higher quality updates that
are focused on the errors the model makes. Sec-
ond, given the complexity of the data, it allows us
to have updates for many examples that would be
otherwise ignored. In our experiments, we observe
this behavior with nearly 40% of the training set.
</bodyText>
<sectionHeader confidence="0.991978" genericHeader="method">
7 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999823222222222">
Data, Tools and Metric For evaluation, we use
AMR Bank release 1.0 (LDC2014T12). We use
the proxy report portion, which includes newswire
articles from the English Gigaword corpus, and
follow the official split for training, development
and evaluation (6603/826/823 sentences). We use
EasyCCG (Lewis and Steedman, 2014) trained
with the re-banked CCGBank (Hockenmaier and
Steedman, 2007; Honnibal et al., 2010) to gener-
ate CCGBank categories, the Illinois Named En-
tity Tagger (Ratinov and Roth, 2009) for NER,
Stanford CoreNLP (Manning et al., 2014) for to-
kenization and part-of-speech tagging and UW
SPF (Artzi and Zettlemoyer, 2013a) to develop our
system. We use SMATCH (Cai and Knight, 2013)
to evaluate logical forms converted back to AMRs.
CCG We use three syntactic attributes: singular
sg, mass nouns nb and plural pl. When factor-
ing lexical entries, we avoid extracting binary re-
lations and references, and leave them in the tem-
plate. We use backward and forward binary com-
binators for application, composition and cross-
ing composition. We allow non-crossing compo-
sition up to the third order. We also add rules
to handle punctuation and unary rules for type-
shifting non-adjectives in adjectival positions and
verb phrases in adverbial positions. We allow
</bodyText>
<footnote confidence="0.8255255">
7We extract all sub-expressions of type e, (e, t),
(e, t), (e, t)) or (e, (e, t)) from u.
</footnote>
<bodyText confidence="0.99997286">
shifting of bare plurals, mass nouns and named
entities to noun phrases. To avoid spurious am-
biguity during parsing, we use normal-form con-
straints (Hockenmaier and Bisk, 2010). We use
five basic lambda calculus types: entity e, truth
value t, identifier id, quoted text txt and integer i.
Features During CCG parsing, we use indicator
features for unary type shifting, crossing compo-
sition, lexemes, templates and dynamically gen-
erated lexical entries. We also use indicators for
co-occurrence of part-of-speech tags and syntac-
tic attributes, repetitions in logical conjunctions
and attachments in the logical form. In the factor
graph, we use indicator features for control struc-
tures, parent-relation-child selectional preferences
and for mapping a relation to its final form. See the
supplementary material for a detailed description.
Initialization and Parameters We created the
seed lexicon from the training data by sampling
and annotating 50 sentences with lexical entries,
adding entries for pronouns and adding lexemes
for all alignments generated by JAMR (Flanigan
et al., 2014). We initialize features weights as fol-
lows: 10 for all lexeme feature for seed entries
and entries generated by named-entity matching
(Section 6.1), IBM Model 1 scores for all other
lexemes (Kwiatkowski et al., 2011), -3 for unary
type shifting and crossing composition features, 3
for features that pair singular and plural part-of-
speech tags with singular and plural attributes and
0 for all other features. We set the number of it-
erations T = 10 and select the best model based
on development results. We set the max number
of tokens for lexical generation kgen = 2, learning
rate µ = 0.1, CCG parsing beam K = 50, factor
graph beam L = 100, mini batch size M = 40
and use a beam of 100 for GENMAX.
Two-pass Inference During testing, we perform
two passes of inference for every sentence. First,
we run our inference procedure (Section 5.4). If no
derivations are generated, we run inference again,
allowing the parser to skip words at a fixed cost
and use the entries for related words if a word is
unknown. We find related words in the lexicon us-
ing case, plurality and inflection string transforma-
tions. Finally, if necessary, we heuristically trans-
form the logical forms at the root of the CCG parse
trees to valid AMR logical forms. We set the cost
of logical form transformation and word skipping
to 10 and the cost of using related entries to 5.
</bodyText>
<page confidence="0.992061">
1706
</page>
<sectionHeader confidence="0.999404" genericHeader="evaluation">
8 Results
</sectionHeader>
<bodyText confidence="0.999921081632653">
Table 1 shows SMATCH test results. We com-
pare our approach to the latest, fixed version of
JAMR (Flanigan et al., 2014) available online,8
the only system to report test results on the official
LDC release. Our approach outperforms JAMR
by 3 SMATCH F1 points, with a significant gain
in recall. Given consensus inter-annotator agree-
ment of 83 SMATCH F1 (Flanigan et al., 2014),
this improvement reduces the gap between auto-
mated methods and human performance by 15%.
Although not strictly comparable, Table 1 also in-
cludes results on the pre-release AMR Bank cor-
pus, including the published JAMR results, their
fixed results and the results of Wang et al. (2015).
Table 2 shows SMATCH scores for the devel-
opments set, with ablations. The supplementary
material includes example output derivations and
qualitative comparison to JAMR outputs. We first
remove underspecifying constants, which leaves
the factor graph to resolve only references. While
the expressivity of the model remains the same,
more decisions are considered during parsing,
modestly impacting performance.
We also study the different methods for lexical
generation. Skipping the second recursive split-
ting pass in GENENTRIES creates an interesting
tradeoff. As we are unable to learn templates with-
out splitting, we induce a significantly smaller lex-
icon (500K vs. 1.6M entries). Although we are
unable to recover many syntactic constructions,
our search problem is in general much simpler. We
therefore see a relatively mild drop in overall per-
formance (1.1 F1). Removing Ggen during lexi-
cal generation (Section 6.1) creates a more signif-
icant drop in performance (3.4 F1), demonstrating
how considering all possible lexemes allows the
system to recover entries that are not covered by
heuristic alignments. We are also able for the first
time to report AMR parsing results without any
surface-form similarity heuristics, by removing
both JAMR alignments and named-entity match-
ing lexical generation (Section 6.1). The signifi-
cant drop in performance (20 points F1) demon-
strates the need for better alignment algorithm.
Finally, Figure 5 plots development SMATCH
F1 with and without early updates. As expected,
early updates increase the learning rate signifi-
cantly and have a large impact on overall perfor-
mance. Without early updates we are unable to
</bodyText>
<footnote confidence="0.98615">
8JAMR is available at http://tiny.cc/jamr.
</footnote>
<table confidence="0.999683714285714">
P R F1
JAMR (fixed) 67.8 59.2 63.2
Our approach 66.8 65.7 66.3
Pre-release corpus results
JAMR (Flanigan et al., 2014) 52.0 66.0 58.0
JAMR (fixed) 66.8 58.3 62.3
Wang et al. (2015) 64.0 62.0 63.0
</table>
<tableCaption confidence="0.964961">
Table 1: Test SMATCH results.
</tableCaption>
<table confidence="0.980184375">
P R F1
Full system 67.2 65.1 66.1
w/o underspecified constants 66.9 64.2 65.5
Lexical learning ablations
w/o splitting 65.0 65.0 65.0
w/o Ggen 62.6 62.7 62.6
w/o surface-form similarity 55.9 38.5 45.6
Iteration number
</table>
<figureCaption confidence="0.920369">
Figure 5: Development SMATCH F1 without early up-
dates (•) and with early updates (■).
</figureCaption>
<bodyText confidence="0.9982645">
learn from almost half of the data, and perfor-
mance drops by nearly 15 points.
</bodyText>
<sectionHeader confidence="0.996151" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999983111111111">
We described an approach for broad-coverage
CCG induction for semantic parsing, including
a joint representation of compositional and non-
compositional semantics, a new grammar induc-
tion technique and an early update procedure. We
used AMR as the target representation and present
new state-of-the-art AMR parsing results.
While we focused on recovering non-
compositional dependencies, other non-
compositional phenomena remain to be studied.
Although our technique is able to learn certain id-
ioms as multi-word phrases, learning to recognize
discontinuous idioms remains open. Similarly,
resolving cross-sentence references, which are not
annotated in AMR Bank, is important future work.
Finally, we would like to reduce the dependency
on surface-form heuristics, for example to better
generalize to other languages.
</bodyText>
<sectionHeader confidence="0.996515" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999743125">
This research was supported in part by a Mi-
crosoft Research PhD Fellowship, the NSF (IIS-
1252835), DARPA under the DEFT program
through the AFRL (FA8750-13-2-0019), an Allen
Distinguished Investigator Award and a gift from
Google. The authors thank Mark Yatskar, Tom
Kwiatkowski, Chloé Kiddon, Eunsol Choi, Mike
Lewis and the reviewers for their helpful advice.
</bodyText>
<figure confidence="0.93044625">
Table 2: Development SMATCH results.
1 2 3 4 5 6 7 8 9 10
SMATCH F1
65
60
55
50
45
</figure>
<page confidence="0.986775">
1707
</page>
<sectionHeader confidence="0.986224" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.887872319148936">
Artzi, Y., Das, D., and Petrov, S. (2014). Learn-
ing compact lexicons for CCG semantic pars-
ing. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Process-
ing.
Artzi, Y. and Zettlemoyer, L. S. (2011). Boot-
strapping semantic parsers from conversations.
In Proceedings of the Conference on Empirical
Methods in Natural Language Processing.
Artzi, Y. and Zettlemoyer, L. S. (2013a). UW SPF:
The University of Washington Semantic Parsing
Framework.
Artzi, Y. and Zettlemoyer, L. S. (2013b). Weakly
supervised learning of semantic parsers for
mapping instructions to actions. Transactions
of the Association for Computational Linguis-
tics, 1(1):49–62.
Banarescu, L., Bonial, C., Cai, S., Georgescu, M.,
Griffitt, K., Hermjakob, U., Knight, K., Koehn,
P., Palmer, M., and Schneider, N. (2013). Ab-
stract meaning representation for sembanking.
In Proceedings of the Linguistic Annotation
Workshop.
Bos, J. (2008). Wide-coverage semantic analysis
with Boxer. In Proceedings of the Conference
on Semantics in Text Processing.
Cai, Q. and Yates, A. (2013). Semantic parsing
Freebase: Towards open-domain semantic pars-
ing. In Proceedings of the Joint Conference on
Lexical and Computational Semantics.
Cai, S. and Knight, K. (2013). Smatch: an evalu-
ation metric for semantic feature structures. In
Proceedings of the Conference of the Associa-
tion of Computational Linguistics.
Chen, D. (2012). Fast online lexicon learning for
grounded language acquisition. In Proceedings
of the Annual Meeting of the Association for
Computational Linguistics.
Chen, D. L. and Mooney, R. J. (2011). Learning
to interpret natural language navigation instruc-
tions from observations. In Proceedings of the
National Conference on Artificial Intelligence.
Clark, S. and Curran, J. R. (2007). Wide-
coverage efficient statistical parsing with CCG
and log-linear models. Computational Linguis-
tics, 33(4):493–552.
Clarke, J., Goldwasser, D., Chang, M., and Roth,
D. (2010). Driving semantic parsing from the
world’s response. In Proceedings of the Con-
ference on Computational Natural Language
Learning.
Collins, M. and Roark, B. (2004). Incremental
parsing with the perceptron algorithm. In Pro-
ceedings of the Annual Meeting on Association
for Computational Linguistics.
Duchi, J., Hazan, E., and Singer, Y. (2011). Adap-
tive subgradient methods for online learning
and stochastic optimization. The Journal of Ma-
chine Learning Research, pages 2121–2159.
Flanigan, J., Thomson, S., Carbonell, J., Dyer,
C., and Smith, N. A. (2014). A discriminative
graph-based parser for the Abstract Meaning
Representation. In Proceedings of the Confer-
ence of the Association of Computational Lin-
guistics.
Goldwasser, D. and Roth, D. (2011). Learning
from natural instructions. In Proceedings of the
International Joint Conference on Artificial In-
telligence.
Hockenmaier, J. and Bisk, Y. (2010). Normal-
form parsing for combinatory categorial gram-
mars with generalized composition and type-
raising. In Proceedings of the International
Conference on Computational Linguistics.
Hockenmaier, J. and Steedman, M. (2007). CCG-
Bank: A corpus of CCG derivations and depen-
dency structures extracted from the Penn Tree-
bank. Computational Linguistics, pages 355–
396.
Honnibal, M., Curran, J. R., and Bos, J. (2010).
Rebanking CCGBank for Improved NP Inter-
pretation. In Proceedings of the Annual Meeting
of the Association for Computational Linguis-
tics.
Jones, B., Andreas, J., Bauer, D., Hermann, K. M.,
and Knight, K. (2012). Semantics-based ma-
chine translation with hyperedge replacement
grammars. In Proceedings of the International
Conference on Computational Linguistics.
Krishnamurthy, J. and Mitchell, T. (2012). Weakly
supervised training of semantic parsers. In Pro-
ceedings of the Joint Conference on Empirical
Methods in Natural Language Processing and
Computational Natural Language Learning.
</reference>
<page confidence="0.853719">
1708
</page>
<reference confidence="0.976221226804124">
Krishnamurthy, J. and Mitchell, T. M. (2015).
Learning a compositional semantics for Free-
base with an open predicate vocabulary. Trans-
actions of the Association for Computational
Linguistics, 3.
Kwiatkowski, T., Choi, E., Artzi, Y., and Zettle-
moyer, L. S. (2013). Scaling semantic parsers
with on-the-fly ontology matching. In Proceed-
ings of the Conference on Empirical Methods in
Natural Language Processing.
Kwiatkowski, T., Goldwater, S., Zettlemoyer,
L. S., and Steedman, M. (2012). A probabilis-
tic model of syntactic and semantic acquisition
from child-directed utterances and their mean-
ings. Proceedings of the Conference of the Eu-
ropean Chapter of the Association of Computa-
tional Linguistics.
Kwiatkowski, T., Zettlemoyer, L. S., Goldwater,
S., and Steedman, M. (2010). Inducing proba-
bilistic CCG grammars from logical form with
higher-order unification. In Proceedings of the
Conference on Empirical Methods in Natural
Language Processing.
Kwiatkowski, T., Zettlemoyer, L. S., Goldwater,
S., and Steedman, M. (2011). Lexical general-
ization in CCG grammar induction for semantic
parsing. In Proceedings of the Conference on
Empirical Methods in Natural Language Pro-
cessing.
Lafferty, J., McCallum, A., and Pereira, F. (2001).
Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data.
In Proceedings of the International Conference
on Machine Learning.
Lewis, M. and Steedman, M. (2013). Combined
distributional and logical semantics. Transac-
tions of the Association for Computational Lin-
guistics, 1.
Lewis, M. and Steedman, M. (2014). A* CCG
parsing with a supertag-factored model. In Pro-
ceedings of the Conference on Empirical Meth-
ods in Natural Language Processing.
Liang, P., Jordan, M., and Klein, D. (2011).
Learning dependency-based compositional se-
mantics. In Proceedings of the Conference of
the Association for Computational Linguistics.
Liu, F., Flanigan, J., Thomson, S., Sadeh, N., and
Smith, N. A. (2015). Toward abstractive sum-
marization using semantic representations. In
Proceedings of the North American Association
for Computational Linguistics.
Manning, C. D., Surdeanu, M., Bauer, J., Finkel,
J., Bethard, S. J., and McClosky, D. (2014). The
Stanford CoreNLP natural language processing
toolkit. In Proceedings of the Annual Meeting of
the Association for Computational Linguistics.
Muresan, S. (2011). Learning for deep language
understanding. In Proceedings of the Inter-
national Joint Conference on Artificial Intelli-
gence.
Ng, V. (2010). Supervised noun phrase corefer-
ence research: The first fifteen years. In Pro-
ceedings of the annual meeting of the associa-
tion for computational linguistics.
Pan, X., Cassidy, T., Hermjakob, U., Ji, H., and
Knight, K. (2015). Unsupervised entity linking
with Abstract Meaning Representation. In Pro-
ceedings of the North American Association for
Computational Linguistics.
Poon, H. (2013). Grounded unsupervised seman-
tic parsing. In Association for Computational
Linguistics (ACL).
Pourdamghani, N., Gao, Y., Hermjakob, U., and
Knight, K. (2014). Aligning English strings
with Abstract Meaning Representation graphs.
In Proceedings of the Conference on Empirical
Methods in Natural Language Processing.
Ratinov, L. and Roth, D. (2009). Design chal-
lenges and misconceptions in named entity
recognition. In Proceedings of the Conference
on Computational Natural Language Learning.
Reddy, S., Lapata, M., and Steedman, M. (2014).
Large-scale semantic parsing without question-
answer pairs. Transactions of the Association
for Computational Linguistics, 2.
Steedman, M. (1996). Surface Structure and In-
terpretation. The MIT Press.
Steedman, M. (2000). The Syntactic Process. The
MIT Press.
Steedman, M. (2011). Taking Scope. The MIT
Press.
Wang, C., Xue, N., Pradhan, S., and Pradhan, S.
(2015). A transition-based algorithm for AMR
parsing. In Proceedings of the North American
Association for Computational Linguistics.
Wong, Y. and Mooney, R. J. (2007). Learning syn-
chronous grammars for semantic parsing with
</reference>
<page confidence="0.899311">
1709
</page>
<reference confidence="0.992671">
lambda calculus. In Proceedings of the Confer-
ence of the Association for Computational Lin-
guistics.
Zelle, J. and Mooney, R. J. (1996). Learning
to parse database queries using inductive logic
programming. In Proceedings of the National
Conference on Artificial Intelligence.
Zettlemoyer, L. S. and Collins, M. (2005). Learn-
ing to map sentences to logical form: Struc-
tured classification with probabilistic categorial
grammars. In Proceedings of the Conference on
Uncertainty in Artificial Intelligence.
</reference>
<page confidence="0.989287">
1710
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.944349">
<title confidence="0.992421">Broad-coverage CCG Semantic Parsing with AMR</title>
<author confidence="0.999935">Lee Luke Zettlemoyer</author>
<affiliation confidence="0.996786">Dept. of Computer Science and Cornell Tech Computer Science &amp; Engineering Cornell University University of Washington</affiliation>
<address confidence="0.99631">New York, NY 10011 Seattle, WA</address>
<email confidence="0.999842">yoav@cs.cornell.edu{kentonl,lsz}@cs.washington.edu</email>
<abstract confidence="0.997480333333334">We propose a grammar induction technique for AMR semantic parsing. While previous grammar induction techniques were designed to re-learn a new parser for each target application, the recently annotated AMR Bank provides a unique opportunity to induce a single model for understanding broad-coverage newswire text and support a wide range of applications. We present a new model that combines CCG parsing to recover compositional aspects of meaning and a factor graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Artzi</author>
<author>D Das</author>
<author>S Petrov</author>
</authors>
<title>Learning compact lexicons for CCG semantic parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="24303" citStr="Artzi et al. (2014)" startWordPosition="3912" endWordPosition="3915">cannot result in z. 6 Learning Learning the two-stage model requires inducing the entries of the CCG lexicon A and estimating the parameters 0, which score both stages of the derivation. We assume access to a training set of N examples D = {(xi, zi) : i = 1... N}, each containing a sentence xi and a logical form zi. This data does not include information about the lexical entries and CCG parsing operations required to construct the correct derivations. We consider all these decisions as latent. The main learning algorithm (Algorithm 1) starts by initializing the lexicon (line 1) and then 3See Artzi et al. (2014) for a description of this process and how to approximate the partition function in Equation 1. 4Experiments with loopy belief propagation showed it to be slower and less effective for our task. Algorithm 1 The main learning algorithm. Input: Training set D = {(xi, zi) : i = 1 ... N}, number of iterations T, mini-batch size M, seed lexicon A0 and learning rate µ. Definitions: SUB(D, i, j) is the set of the next j samples from D starting at i. GENMAX(x, z, 0, A) is the set of viterbi derivations from x with the final result z given parameters 0 and lexicon A. LEX(d) is the set of lexical entrie</context>
</contexts>
<marker>Artzi, Das, Petrov, 2014</marker>
<rawString>Artzi, Y., Das, D., and Petrov, S. (2014). Learning compact lexicons for CCG semantic parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Artzi</author>
<author>L S Zettlemoyer</author>
</authors>
<title>Bootstrapping semantic parsers from conversations.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="9837" citStr="Artzi and Zettlemoyer, 2011" startWordPosition="1534" endWordPosition="1537">aning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly impro</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2011</marker>
<rawString>Artzi, Y. and Zettlemoyer, L. S. (2011). Bootstrapping semantic parsers from conversations. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Artzi</author>
<author>L S Zettlemoyer</author>
</authors>
<title>UW SPF: The University of Washington Semantic Parsing Framework.</title>
<date>2013</date>
<contexts>
<context position="1388" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="204" endWordPosition="207">r graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art. 1 Introduction Semantic parsers map sentences to formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011). Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, and work is ongoing to study its use for variety of applications such as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015). The ∗Work done at the University of Washington. AMR meaning bank provides a large new corpus that, for the first tim</context>
<context position="28439" citStr="Artzi and Zettlemoyer (2013" startWordPosition="4683" endWordPosition="4686">rocess to select the entries to return. The set of generated lexemes is a union of: (a) the set Ggen that includes all pairings of subsets of constants from z with spans in x up to length kgen and (b) the set that is constructed by matching named-entity constants5 in z with their corresponding mentions in the text to create new lexemes with potentially any other constant (for lexemes with multiple constants). A is augmented with the generated set of lexical entries to create A+ (line 2). First Pass Given the augmented lexicon A+, we compute the set D+ = GENMAX(x, z, 0, A+) (line 4). Following Artzi and Zettlemoyer (2013b), we constrain the set of derivations to include only those that use at most one lexeme from Ggen. If generating new lexemes is sufficient to derive z from x, D+ will contain these derivations and we return their lexical entries to be added to the lexicon A (lines 5-7). Otherwise, we proceed to do a second pass, where we try to generate new templates to parse the sentence. Second Pass: RECSPLIT In this pass we try to generate max-scoring derivations in a top-down process. Starting from u, the underspecified form of z, we search for CCG parsing steps that will connect to existing partial deri</context>
<context position="33250" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="5482" endWordPosition="5485">Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system. We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs. CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factoring lexical entries, we avoid extracting binary relations and references, and leave them in the template. We use backward and forward binary combinators for application, composition and crossing composition. We allow non-crossing composition up to the third order. We also add rules to handle punctuation and unary rules for typeshifting non-adjectives in adjectival positions and verb phrases i</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2013</marker>
<rawString>Artzi, Y. and Zettlemoyer, L. S. (2013a). UW SPF: The University of Washington Semantic Parsing Framework.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Artzi</author>
<author>L S Zettlemoyer</author>
</authors>
<title>Weakly supervised learning of semantic parsers for mapping instructions to actions.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="1388" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="204" endWordPosition="207">r graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art. 1 Introduction Semantic parsers map sentences to formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011). Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, and work is ongoing to study its use for variety of applications such as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015). The ∗Work done at the University of Washington. AMR meaning bank provides a large new corpus that, for the first tim</context>
<context position="28439" citStr="Artzi and Zettlemoyer (2013" startWordPosition="4683" endWordPosition="4686">rocess to select the entries to return. The set of generated lexemes is a union of: (a) the set Ggen that includes all pairings of subsets of constants from z with spans in x up to length kgen and (b) the set that is constructed by matching named-entity constants5 in z with their corresponding mentions in the text to create new lexemes with potentially any other constant (for lexemes with multiple constants). A is augmented with the generated set of lexical entries to create A+ (line 2). First Pass Given the augmented lexicon A+, we compute the set D+ = GENMAX(x, z, 0, A+) (line 4). Following Artzi and Zettlemoyer (2013b), we constrain the set of derivations to include only those that use at most one lexeme from Ggen. If generating new lexemes is sufficient to derive z from x, D+ will contain these derivations and we return their lexical entries to be added to the lexicon A (lines 5-7). Otherwise, we proceed to do a second pass, where we try to generate new templates to parse the sentence. Second Pass: RECSPLIT In this pass we try to generate max-scoring derivations in a top-down process. Starting from u, the underspecified form of z, we search for CCG parsing steps that will connect to existing partial deri</context>
<context position="33250" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="5482" endWordPosition="5485">Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system. We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs. CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factoring lexical entries, we avoid extracting binary relations and references, and leave them in the template. We use backward and forward binary combinators for application, composition and crossing composition. We allow non-crossing composition up to the third order. We also add rules to handle punctuation and unary rules for typeshifting non-adjectives in adjectival positions and verb phrases i</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2013</marker>
<rawString>Artzi, Y. and Zettlemoyer, L. S. (2013b). Weakly supervised learning of semantic parsers for mapping instructions to actions. Transactions of the Association for Computational Linguistics, 1(1):49–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Banarescu</author>
<author>C Bonial</author>
<author>S Cai</author>
<author>M Georgescu</author>
<author>K Griffitt</author>
<author>U Hermjakob</author>
<author>K Knight</author>
<author>P Koehn</author>
<author>M Palmer</author>
<author>N Schneider</author>
</authors>
<title>Abstract meaning representation for sembanking.</title>
<date>2013</date>
<booktitle>In Proceedings of the Linguistic Annotation Workshop.</booktitle>
<contexts>
<context position="1628" citStr="Banarescu et al., 2013" startWordPosition="243" endWordPosition="246">o formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011). Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, and work is ongoing to study its use for variety of applications such as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015). The ∗Work done at the University of Washington. AMR meaning bank provides a large new corpus that, for the first time, enables us to study the problem of grammar induction for broad-coverage semantic parsing. However, it also presents significant challenges for existing algorithms, including much longer sentences, more complex syntactic phenomena and inc</context>
<context position="5946" citStr="Banarescu et al., 2013" startWordPosition="912" endWordPosition="915">. Finally, while previous algorithms (e.g., Zettlemoyer and Collins, 2005) have assumed the existence of a grammar that can parse nearly every sentence to update its parameters, this does not hold for AMR Bank. Due to sentence complexity and search errors, our model cannot produce fully correct logical forms for a significant portion of the training data. To learn from as much of the data as possible and accelerate learning, we adopt an early update strategy to generate effective updates from partially correct analyses (Section 6.2). We evaluate performance on the publicly available AMR Bank (Banarescu et al., 2013) and demonstrate that our modeling and learning contributions are crucial for grammar induction at this scale and achieve new state-of-the-art results for AMR parsing (Section 8). In addition, we also present, for the first time, results without surfaceform alignment heuristics, which demonstrates the need for future work, especially to generalize to other languages. The source code and learned models are available online.1 1http://yoavartzi.com/amr x: Pyongyang officials denied their involvement. a: (d/deny-01 :ARG0 (p/person :ARG0-of (h/have-org-role-91 :ARG1 (c/city : name (n/name :op1“Pyon</context>
<context position="10717" citStr="Banarescu et al., 2013" startWordPosition="1668" endWordPosition="1671">ods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of firstorder logic representations (Bos, 2008; Lewis and Steedman, 2013). However, this work lacked corpora to evaluate the logical forms recovered. AMR (Banarescu et al., 2013) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015). There is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; NP[pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three lexical entries, two forward applications (&gt;) and type-shifting of a plural noun to a noun phrase. AMRs, including graph parsing (Fl</context>
</contexts>
<marker>Banarescu, Bonial, Cai, Georgescu, Griffitt, Hermjakob, Knight, Koehn, Palmer, Schneider, 2013</marker>
<rawString>Banarescu, L., Bonial, C., Cai, S., Georgescu, M., Griffitt, K., Hermjakob, U., Knight, K., Koehn, P., Palmer, M., and Schneider, N. (2013). Abstract meaning representation for sembanking. In Proceedings of the Linguistic Annotation Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bos</author>
</authors>
<title>Wide-coverage semantic analysis with Boxer.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Semantics in Text Processing.</booktitle>
<contexts>
<context position="10585" citStr="Bos, 2008" startWordPosition="1649" endWordPosition="1650">Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of firstorder logic representations (Bos, 2008; Lewis and Steedman, 2013). However, this work lacked corpora to evaluate the logical forms recovered. AMR (Banarescu et al., 2013) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015). There is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; NP[pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three </context>
</contexts>
<marker>Bos, 2008</marker>
<rawString>Bos, J. (2008). Wide-coverage semantic analysis with Boxer. In Proceedings of the Conference on Semantics in Text Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Cai</author>
<author>A Yates</author>
</authors>
<title>Semantic parsing Freebase: Towards open-domain semantic parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the Joint Conference on Lexical and Computational Semantics.</booktitle>
<contexts>
<context position="9670" citStr="Cai and Yates, 2013" startWordPosition="1510" endWordPosition="1513"> alternates between expanding the lexicon and updating the parameters. Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates fr</context>
</contexts>
<marker>Cai, Yates, 2013</marker>
<rawString>Cai, Q. and Yates, A. (2013). Semantic parsing Freebase: Towards open-domain semantic parsing. In Proceedings of the Joint Conference on Lexical and Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Cai</author>
<author>K Knight</author>
</authors>
<title>Smatch: an evaluation metric for semantic feature structures.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="8119" citStr="Cai and Knight, 2013" startWordPosition="1246" endWordPosition="1249"> invertible conversion process between AMRs and lambdacalculus logical forms; roughly speaking, each AMR variable gets its own lambda term, which is scoped as low as possible, and each AMR role becomes a binary predicate applied to these variables. Figure 1 shows an example, and the full details are provided in the supplementary materials. Therefore, henceforth we discuss the task of mapping a sentence x E X to a logical form z E i, where i is the set of all logical forms. For example, in Figure 1, we would map the sentence x to the logical form z. We evaluate system performance using SMATCH (Cai and Knight, 2013). Model Given a sentence x and lexicon A, we generate the set of possible derivations GEN(x, A) using a two-stage process (Section 5). First, we use a weighted CCG to map x to an underspecified logical form u (Section 5.1), a logical form with placeholder constants for unresolved elements. For example, in the underspecified logical form u in Figure 1, the constants REL-of, REL and ID are placeholders. We then resolve 1700 these placeholders by defining a factor graph to find their optimal mapping and generate the final logical form z. In the figure, REL-of is mapped to ARG0-of, REL to ARG2 and</context>
<context position="33312" citStr="Cai and Knight, 2013" startWordPosition="5493" endWordPosition="5496">4T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system. We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs. CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factoring lexical entries, we avoid extracting binary relations and references, and leave them in the template. We use backward and forward binary combinators for application, composition and crossing composition. We allow non-crossing composition up to the third order. We also add rules to handle punctuation and unary rules for typeshifting non-adjectives in adjectival positions and verb phrases in adverbial positions. We allow 7We extract all sub-expression</context>
</contexts>
<marker>Cai, Knight, 2013</marker>
<rawString>Cai, S. and Knight, K. (2013). Smatch: an evaluation metric for semantic feature structures. In Proceedings of the Conference of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chen</author>
</authors>
<title>Fast online lexicon learning for grounded language acquisition.</title>
<date>2012</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1359" citStr="Chen, 2012" startWordPosition="202" endWordPosition="203"> and a factor graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art. 1 Introduction Semantic parsers map sentences to formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011). Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, and work is ongoing to study its use for variety of applications such as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015). The ∗Work done at the University of Washington. AMR meaning bank provides a large new c</context>
</contexts>
<marker>Chen, 2012</marker>
<rawString>Chen, D. (2012). Fast online lexicon learning for grounded language acquisition. In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Chen</author>
<author>R J Mooney</author>
</authors>
<title>Learning to interpret natural language navigation instructions from observations.</title>
<date>2011</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="9786" citStr="Chen and Mooney, 2011" startWordPosition="1527" endWordPosition="1530">wo-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines </context>
</contexts>
<marker>Chen, Mooney, 2011</marker>
<rawString>Chen, D. L. and Mooney, R. J. (2011). Learning to interpret natural language navigation instructions from observations. In Proceedings of the National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>J R Curran</author>
</authors>
<title>Widecoverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="17394" citStr="Clark and Curran, 2007" startWordPosition="2793" endWordPosition="2796">constant, is a disambiguation of Su. Applying M to all constants in u results in the final logical form z. Decomposing the derivation provides two advantages. First, we are able to defer decisions from the CCG parse to the factor graph, thereby considering fewer hypotheses during parsing and simplifying the computation. Second, we can represent distant references while avoiding the complex parse trees that would have been required to represent these dependencies with scoped variables instead of Skolem IDs.2 5.3 Model Given a sentence x, we use a weighted log-linear CCG (Lafferty et al., 2001; Clark and Curran, 2007) to rank the space of possible parses under the grammar Λ. At the root of each CCG derivation is the underspecified logical form u. To represent a probability distribution over M, we build for each u a factor graph Gu = (V, F, E), 2Similar to mention clustering methods for co-reference resolution (Ng, 2010), IDs can be viewed as creating clusters. 1702 (a) CCG parse y: Maps the sentence x to an underspecified logical form u (Section 5.1) with placeholders for unresolved decisions: ID for reference identifiers and the predicates REL and REL-of for unresolved relations. x: Pyongyang officials de</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Clark, S. and Curran, J. R. (2007). Widecoverage efficient statistical parsing with CCG and log-linear models. Computational Linguistics, 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>D Goldwasser</author>
<author>M Chang</author>
<author>D Roth</author>
</authors>
<title>Driving semantic parsing from the world’s response.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="9629" citStr="Clarke et al., 2010" startWordPosition="1502" endWordPosition="1505">ine a learning procedure (Section 6) that alternates between expanding the lexicon and updating the parameters. Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer a</context>
</contexts>
<marker>Clarke, Goldwasser, Chang, Roth, 2010</marker>
<rawString>Clarke, J., Goldwasser, D., Chang, M., and Roth, D. (2010). Driving semantic parsing from the world’s response. In Proceedings of the Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>B Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of the Annual Meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="31433" citStr="Collins and Roark (2004)" startWordPosition="5189" endWordPosition="5192">abeled logical form z, parameters 0 and lexicon A, the procedure COMPUTEGRAD(x, z, 0, A) computes the gradient for the sample (x, z). Let D∗(z) = GENMAX(x, z, 0, A), the set of max-scoring correct derivations. The hard gradient update is: 1 * E φ(xi , d) − Ep(d, |xi;θ,Λ) [φ(xi, d)] , (2) |D (z) |dED∗(z) where φ(x, d) E 1R,1 is a l-dimensional feature vector (Section 5.3) and the positive portion of the gradient, rather than using expected features, averages over all max-scoring correct derivations. Early updates To generate an effective update when no correct derivation is observed, we follow Collins and Roark (2004) and do an early update if D∗(z) is empty or if GEN(x, A), the set 6Unlike Kwiatkowski et al. (2010), we also introduce syntactic attributes (e.g., pl, sg) when splitting. 1705 of derivations for x, does not contain a derivation with the correct final logical form z. Given the partial derivations, our gradient computation is identical to Equation 2. However, in contrast to Collins and Roark (2004) our data does not include gold derivations. Therefore, we attempt to identify max-scoring partial derivations that may lead to the correct derivation. We extract sub-expressions from u,7 the underspe</context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Collins, M. and Roark, B. (2004). Incremental parsing with the perceptron algorithm. In Proceedings of the Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Duchi</author>
<author>E Hazan</author>
<author>Y Singer</author>
</authors>
<title>Adaptive subgradient methods for online learning and stochastic optimization.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>2121--2159</pages>
<contexts>
<context position="25168" citStr="Duchi et al., 2011" startWordPosition="4073" endWordPosition="4076">ining set D = {(xi, zi) : i = 1 ... N}, number of iterations T, mini-batch size M, seed lexicon A0 and learning rate µ. Definitions: SUB(D, i, j) is the set of the next j samples from D starting at i. GENMAX(x, z, 0, A) is the set of viterbi derivations from x with the final result z given parameters 0 and lexicon A. LEX(d) is the set of lexical entries used in the derivation d. COMPUTEGRAD(x, z, 0, A) computes the gradient for sentence x and logical form z, given the parameters 0 and lexicon A, and it described in Section 6.2. ADAGRAD(Δ) applies a per-feature learning rate to the gradient Δ (Duchi et al., 2011). Output: Lexicon A and model parameters 0. 1: A +— A0 2: fort = 1 to T do 3: » Generate entries and update the lexicon. 4: for i = 1 to N do 5: Anew +— Anew U GENENTRIES(xi, zi, 0, A) 6: A +— A U Anew 7: » Compute and apply mini-batch gradient updates. 8: for i=1to[NM]do 9: Δ +— 0� 10: for (x, z) in SUB(D, i, M) do 11: » Compute and aggregate the gradient. 12: Δ +— Δ + COMPUTEGRAD(x, z, 0, A) 13: 0 +— 0 + µADAGRAD(Δ) 14: » Get all correct viterbi derivations. V +— � 15: (x,z)ED GENMAX(x, z, 0, A) 16: » Retain only entries from derivations in V . 17: A +— UdEV LEX(d) 18: return A and 0 Algorit</context>
<context position="27157" citStr="Duchi et al., 2011" startWordPosition="4456" endWordPosition="4459">tion starts with a batch pass to expand the lexicon. The subroutine GENENTRIES, described in Section 6.1 and Algorithm 2, is called to generate a set of new entries for each sample (line 5). Next, we update the parameters 0 with minibatch updates. Given a mini-batch size of M, we use the procedure SUB(D, i, M) to get the i-th segment of the data D of size M. We process this segment (line 10) to accumulate the 1704 mini-batch gradient Δ by calling the procedure COMPUTEGRAD(x, z, 0, A) (line 12), which computes the gradient for x and z given 0 and A, as described in Section 6.2. We use AdaGrad (Duchi et al., 2011) parameter updates (line 13). Each iteration concludes with removing all lexical entries not used in max-scoring correct derivations, to correct for overgeneration (lines 14-17). 6.1 Lexicon Expansion: GENENTRIES Given a sentence x, a logical form z, parameters 0 and a lexicon A, GENENTRIES(x, z, 0, A) (Algorithm 2) computes a set of lexical entries, such that there exists at least one derivation d using these entries from x to z. We first use GENLEX(x, z, A) to generate a large set of potential lexical entries from u, the underspecified form of z, by generating lexemes (Section 4) and pairing</context>
</contexts>
<marker>Duchi, Hazan, Singer, 2011</marker>
<rawString>Duchi, J., Hazan, E., and Singer, Y. (2011). Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, pages 2121–2159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Flanigan</author>
<author>S Thomson</author>
<author>J Carbonell</author>
<author>C Dyer</author>
<author>N A Smith</author>
</authors>
<title>A discriminative graph-based parser for the Abstract Meaning Representation.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="9348" citStr="Flanigan et al., 2014" startWordPosition="1462" endWordPosition="1465">2. Learning We assume access to a training set of N examples {(xi, zi) : i = 1... N}, each containing a sentence xi and a logical form zi. Our goal is to learn a CCG, which constitutes learning the lexicon and estimating the parameters of both the grammar and the factor graph. We define a learning procedure (Section 6) that alternates between expanding the lexicon and updating the parameters. Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semanti</context>
<context position="11337" citStr="Flanigan et al., 2014" startWordPosition="1757" endWordPosition="1760">3) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015). There is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; NP[pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three lexical entries, two forward applications (&gt;) and type-shifting of a plural noun to a noun phrase. AMRs, including graph parsing (Flanigan et al., 2014), methods to build AMRs from dependency trees (Wang et al., 2015) and algorithms for aligning words to AMRs (Pourdamghani et al., 2014). 4 Background Combinatory Categorial Grammar CCG is a categorial formalism that provides a transparent interface between syntax and semantics (Steedman, 1996, 2000). Section 7 details our instantiation of CCG. In CCG trees, each node is a category. Figure 2 shows a simple CCG tree. For example, S\NP[pl] : Ax.Ad.dance-01(d) n ARG0(d, x) is a category for an intransitive verb phrase. The syntactic type S\NP[pl] indicates that an argument of type NP[pl] is expect</context>
<context position="35061" citStr="Flanigan et al., 2014" startWordPosition="5768" endWordPosition="5771">ndicators for co-occurrence of part-of-speech tags and syntactic attributes, repetitions in logical conjunctions and attachments in the logical form. In the factor graph, we use indicator features for control structures, parent-relation-child selectional preferences and for mapping a relation to its final form. See the supplementary material for a detailed description. Initialization and Parameters We created the seed lexicon from the training data by sampling and annotating 50 sentences with lexical entries, adding entries for pronouns and adding lexemes for all alignments generated by JAMR (Flanigan et al., 2014). We initialize features weights as follows: 10 for all lexeme feature for seed entries and entries generated by named-entity matching (Section 6.1), IBM Model 1 scores for all other lexemes (Kwiatkowski et al., 2011), -3 for unary type shifting and crossing composition features, 3 for features that pair singular and plural part-ofspeech tags with singular and plural attributes and 0 for all other features. We set the number of iterations T = 10 and select the best model based on development results. We set the max number of tokens for lexical generation kgen = 2, learning rate µ = 0.1, CCG pa</context>
<context position="36552" citStr="Flanigan et al., 2014" startWordPosition="6035" endWordPosition="6038">enerated, we run inference again, allowing the parser to skip words at a fixed cost and use the entries for related words if a word is unknown. We find related words in the lexicon using case, plurality and inflection string transformations. Finally, if necessary, we heuristically transform the logical forms at the root of the CCG parse trees to valid AMR logical forms. We set the cost of logical form transformation and word skipping to 10 and the cost of using related entries to 5. 1706 8 Results Table 1 shows SMATCH test results. We compare our approach to the latest, fixed version of JAMR (Flanigan et al., 2014) available online,8 the only system to report test results on the official LDC release. Our approach outperforms JAMR by 3 SMATCH F1 points, with a significant gain in recall. Given consensus inter-annotator agreement of 83 SMATCH F1 (Flanigan et al., 2014), this improvement reduces the gap between automated methods and human performance by 15%. Although not strictly comparable, Table 1 also includes results on the pre-release AMR Bank corpus, including the published JAMR results, their fixed results and the results of Wang et al. (2015). Table 2 shows SMATCH scores for the developments set, w</context>
<context position="38916" citStr="Flanigan et al., 2014" startWordPosition="6403" endWordPosition="6406">e-form similarity heuristics, by removing both JAMR alignments and named-entity matching lexical generation (Section 6.1). The significant drop in performance (20 points F1) demonstrates the need for better alignment algorithm. Finally, Figure 5 plots development SMATCH F1 with and without early updates. As expected, early updates increase the learning rate significantly and have a large impact on overall performance. Without early updates we are unable to 8JAMR is available at http://tiny.cc/jamr. P R F1 JAMR (fixed) 67.8 59.2 63.2 Our approach 66.8 65.7 66.3 Pre-release corpus results JAMR (Flanigan et al., 2014) 52.0 66.0 58.0 JAMR (fixed) 66.8 58.3 62.3 Wang et al. (2015) 64.0 62.0 63.0 Table 1: Test SMATCH results. P R F1 Full system 67.2 65.1 66.1 w/o underspecified constants 66.9 64.2 65.5 Lexical learning ablations w/o splitting 65.0 65.0 65.0 w/o Ggen 62.6 62.7 62.6 w/o surface-form similarity 55.9 38.5 45.6 Iteration number Figure 5: Development SMATCH F1 without early updates (•) and with early updates (■). learn from almost half of the data, and performance drops by nearly 15 points. 9 Conclusion We described an approach for broad-coverage CCG induction for semantic parsing, including a join</context>
</contexts>
<marker>Flanigan, Thomson, Carbonell, Dyer, Smith, 2014</marker>
<rawString>Flanigan, J., Thomson, S., Carbonell, J., Dyer, C., and Smith, N. A. (2014). A discriminative graph-based parser for the Abstract Meaning Representation. In Proceedings of the Conference of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goldwasser</author>
<author>D Roth</author>
</authors>
<title>Learning from natural instructions.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="9762" citStr="Goldwasser and Roth, 2011" startWordPosition="1523" endWordPosition="1526">xical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexi</context>
</contexts>
<marker>Goldwasser, Roth, 2011</marker>
<rawString>Goldwasser, D. and Roth, D. (2011). Learning from natural instructions. In Proceedings of the International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hockenmaier</author>
<author>Y Bisk</author>
</authors>
<title>Normalform parsing for combinatory categorial grammars with generalized composition and typeraising.</title>
<date>2010</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="34148" citStr="Hockenmaier and Bisk, 2010" startWordPosition="5632" endWordPosition="5635">rences, and leave them in the template. We use backward and forward binary combinators for application, composition and crossing composition. We allow non-crossing composition up to the third order. We also add rules to handle punctuation and unary rules for typeshifting non-adjectives in adjectival positions and verb phrases in adverbial positions. We allow 7We extract all sub-expressions of type e, (e, t), (e, t), (e, t)) or (e, (e, t)) from u. shifting of bare plurals, mass nouns and named entities to noun phrases. To avoid spurious ambiguity during parsing, we use normal-form constraints (Hockenmaier and Bisk, 2010). We use five basic lambda calculus types: entity e, truth value t, identifier id, quoted text txt and integer i. Features During CCG parsing, we use indicator features for unary type shifting, crossing composition, lexemes, templates and dynamically generated lexical entries. We also use indicators for co-occurrence of part-of-speech tags and syntactic attributes, repetitions in logical conjunctions and attachments in the logical form. In the factor graph, we use indicator features for control structures, parent-relation-child selectional preferences and for mapping a relation to its final fo</context>
</contexts>
<marker>Hockenmaier, Bisk, 2010</marker>
<rawString>Hockenmaier, J. and Bisk, Y. (2010). Normalform parsing for combinatory categorial grammars with generalized composition and typeraising. In Proceedings of the International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hockenmaier</author>
<author>M Steedman</author>
</authors>
<title>CCGBank: A corpus of CCG derivations and dependency structures extracted from the Penn Treebank. Computational Linguistics,</title>
<date>2007</date>
<pages>355--396</pages>
<contexts>
<context position="29360" citStr="Hockenmaier and Steedman, 2007" startWordPosition="4838" endWordPosition="4841">ceed to do a second pass, where we try to generate new templates to parse the sentence. Second Pass: RECSPLIT In this pass we try to generate max-scoring derivations in a top-down process. Starting from u, the underspecified form of z, we search for CCG parsing steps that will connect to existing partial derivations in the CKY chart to create a complete parse tree. Since the space of possible operations is extremely large, 5Named-entity constants are created from name instances when converting from AMR to lambda calculus. See the supplementary material for the exact procedure. we use CCGBank (Hockenmaier and Steedman, 2007) categories to prune, as described below. The second pass is executed by calling RECSPLIT(x, z, 0, A+), which returns a set of lexical entries to add to the model (line 10). We recursively apply the splitting operation introduced by Kwiatkowski et al. (2010). Given a CCG category, splitting outputs all possible category pairs that could have originally generated it. For example, given the category 5\NP �- Ay.Ad.deny-01(d) ∧ ARG0(d, y) ∧ ARG1(d, A1(Ai.involve-01(i) ∧ ARG1(i, R(ID)))), one of the possible splits will include the categories 5\NP/NP Ax.Ay.Ad.deny-01(d) ∧ ARG0(d, y) ∧ ARG1(d, x) an</context>
<context position="33003" citStr="Hockenmaier and Steedman, 2007" startWordPosition="5442" endWordPosition="5445">s the model makes. Second, given the complexity of the data, it allows us to have updates for many examples that would be otherwise ignored. In our experiments, we observe this behavior with nearly 40% of the training set. 7 Experimental Setup Data, Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system. We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs. CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factoring lexical entries, we avoid extracting binary relations and references, and leave them in the template. We use backward and forward binary combina</context>
</contexts>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Hockenmaier, J. and Steedman, M. (2007). CCGBank: A corpus of CCG derivations and dependency structures extracted from the Penn Treebank. Computational Linguistics, pages 355– 396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Honnibal</author>
<author>J R Curran</author>
<author>J Bos</author>
</authors>
<title>Rebanking CCGBank for Improved NP Interpretation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="33027" citStr="Honnibal et al., 2010" startWordPosition="5446" endWordPosition="5449"> the complexity of the data, it allows us to have updates for many examples that would be otherwise ignored. In our experiments, we observe this behavior with nearly 40% of the training set. 7 Experimental Setup Data, Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system. We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs. CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factoring lexical entries, we avoid extracting binary relations and references, and leave them in the template. We use backward and forward binary combinators for application, co</context>
</contexts>
<marker>Honnibal, Curran, Bos, 2010</marker>
<rawString>Honnibal, M., Curran, J. R., and Bos, J. (2010). Rebanking CCGBank for Improved NP Interpretation. In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Jones</author>
<author>J Andreas</author>
<author>D Bauer</author>
<author>K M Hermann</author>
<author>K Knight</author>
</authors>
<title>Semantics-based machine translation with hyperedge replacement grammars.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="1833" citStr="Jones et al., 2012" startWordPosition="276" endWordPosition="279">ntations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, and work is ongoing to study its use for variety of applications such as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015). The ∗Work done at the University of Washington. AMR meaning bank provides a large new corpus that, for the first time, enables us to study the problem of grammar induction for broad-coverage semantic parsing. However, it also presents significant challenges for existing algorithms, including much longer sentences, more complex syntactic phenomena and increased use of noncompositional semantics, such as within-sentence coreference. In this paper, we introduce a new, scalable Combinatory Categorial Grammar (CCG; Steedman, 1996, 2000) induction approach that</context>
</contexts>
<marker>Jones, Andreas, Bauer, Hermann, Knight, 2012</marker>
<rawString>Jones, B., Andreas, J., Bauer, D., Hermann, K. M., and Knight, K. (2012). Semantics-based machine translation with hyperedge replacement grammars. In Proceedings of the International Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Krishnamurthy</author>
<author>T Mitchell</author>
</authors>
<title>Weakly supervised training of semantic parsers.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="9892" citStr="Krishnamurthy and Mitchell, 2012" startWordPosition="1540" endWordPosition="1543">pports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG </context>
</contexts>
<marker>Krishnamurthy, Mitchell, 2012</marker>
<rawString>Krishnamurthy, J. and Mitchell, T. (2012). Weakly supervised training of semantic parsers. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Krishnamurthy</author>
<author>T M Mitchell</author>
</authors>
<title>Learning a compositional semantics for Freebase with an open predicate vocabulary.</title>
<date>2015</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>3</volume>
<marker>Krishnamurthy, Mitchell, 2015</marker>
<rawString>Krishnamurthy, J. and Mitchell, T. M. (2015). Learning a compositional semantics for Freebase with an open predicate vocabulary. Transactions of the Association for Computational Linguistics, 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>E Choi</author>
<author>Y Artzi</author>
<author>L S Zettlemoyer</author>
</authors>
<title>Scaling semantic parsers with on-the-fly ontology matching.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1319" citStr="Kwiatkowski et al., 2013" startWordPosition="193" endWordPosition="196">CCG parsing to recover compositional aspects of meaning and a factor graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art. 1 Introduction Semantic parsers map sentences to formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011). Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, and work is ongoing to study its use for variety of applications such as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015). The ∗Work done at the University of Washington.</context>
<context position="9697" citStr="Kwiatkowski et al., 2013" startWordPosition="1514" endWordPosition="1517">xpanding the lexicon and updating the parameters. Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g.,</context>
</contexts>
<marker>Kwiatkowski, Choi, Artzi, Zettlemoyer, 2013</marker>
<rawString>Kwiatkowski, T., Choi, E., Artzi, Y., and Zettlemoyer, L. S. (2013). Scaling semantic parsers with on-the-fly ontology matching. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>S Goldwater</author>
<author>L S Zettlemoyer</author>
<author>M Steedman</author>
</authors>
<title>A probabilistic model of syntactic and semantic acquisition from child-directed utterances and their meanings.</title>
<date>2012</date>
<booktitle>Proceedings of the Conference of the European Chapter of the Association of Computational Linguistics.</booktitle>
<marker>Kwiatkowski, Goldwater, Zettlemoyer, Steedman, 2012</marker>
<rawString>Kwiatkowski, T., Goldwater, S., Zettlemoyer, L. S., and Steedman, M. (2012). A probabilistic model of syntactic and semantic acquisition from child-directed utterances and their meanings. Proceedings of the Conference of the European Chapter of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>L S Zettlemoyer</author>
<author>S Goldwater</author>
<author>M Steedman</author>
</authors>
<title>Inducing probabilistic CCG grammars from logical form with higher-order unification.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="4838" citStr="Kwiatkowski et al., 2010" startWordPosition="732" endWordPosition="735">find the referent for a pronoun. Although primarily motivated by non-compositional reasoning, we also use this mechanism to underspecify certain relations during parsing, allowing for more effective search. Following most work in semantic parsing, we consider two learning challenges: grammar induction, which assigns meaning representations to words and phrases, and parameter estimation, where we learn a model for combining these pieces to analyze full sentences. We introduce a new CCG grammar induction algorithm which incorporates ideas from previous algorithms (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) in a way that scales to the longer sentences and more varied syntactic constructions observed in newswire text. During lexical generation (Section 6.1), the algorithm first attempts to use a set of templates to hypothesize new lexical entries. It then attempts to combine bottom-up parsing with top-down recursive splitting to select the best entries and learn new templates for complex syntactic and semantic phenomena, which are re-used in later sentences to hypothesize new entries. Finally, while previous algorithms (e.g., Zettlemoyer and Collins, 2005) have assumed the existence of a grammar </context>
<context position="10322" citStr="Kwiatkowski et al., 2010" startWordPosition="1608" endWordPosition="1611"> sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of firstorder logic representations (Bos, 2008; Lewis and Steedman, 2013). However, this work lacked corpora to evaluate the logical forms recovered. AMR (Banarescu et al., 2013) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015). There is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] </context>
<context position="29618" citStr="Kwiatkowski et al. (2010)" startWordPosition="4883" endWordPosition="4886">eps that will connect to existing partial derivations in the CKY chart to create a complete parse tree. Since the space of possible operations is extremely large, 5Named-entity constants are created from name instances when converting from AMR to lambda calculus. See the supplementary material for the exact procedure. we use CCGBank (Hockenmaier and Steedman, 2007) categories to prune, as described below. The second pass is executed by calling RECSPLIT(x, z, 0, A+), which returns a set of lexical entries to add to the model (line 10). We recursively apply the splitting operation introduced by Kwiatkowski et al. (2010). Given a CCG category, splitting outputs all possible category pairs that could have originally generated it. For example, given the category 5\NP �- Ay.Ad.deny-01(d) ∧ ARG0(d, y) ∧ ARG1(d, A1(Ai.involve-01(i) ∧ ARG1(i, R(ID)))), one of the possible splits will include the categories 5\NP/NP Ax.Ay.Ad.deny-01(d) ∧ ARG0(d, y) ∧ ARG1(d, x) and NP � A1(Ai.involve-01(i) ∧ ARG1(i,R(ID))) which would combine with forward application (&gt;). Kwiatkowski et al. (2010) present the full details.6 The process starts from u, the underspecified form of z, and recursively applies the splitting operation while </context>
<context position="31533" citStr="Kwiatkowski et al. (2010)" startWordPosition="5210" endWordPosition="5213">he gradient for the sample (x, z). Let D∗(z) = GENMAX(x, z, 0, A), the set of max-scoring correct derivations. The hard gradient update is: 1 * E φ(xi , d) − Ep(d, |xi;θ,Λ) [φ(xi, d)] , (2) |D (z) |dED∗(z) where φ(x, d) E 1R,1 is a l-dimensional feature vector (Section 5.3) and the positive portion of the gradient, rather than using expected features, averages over all max-scoring correct derivations. Early updates To generate an effective update when no correct derivation is observed, we follow Collins and Roark (2004) and do an early update if D∗(z) is empty or if GEN(x, A), the set 6Unlike Kwiatkowski et al. (2010), we also introduce syntactic attributes (e.g., pl, sg) when splitting. 1705 of derivations for x, does not contain a derivation with the correct final logical form z. Given the partial derivations, our gradient computation is identical to Equation 2. However, in contrast to Collins and Roark (2004) our data does not include gold derivations. Therefore, we attempt to identify max-scoring partial derivations that may lead to the correct derivation. We extract sub-expressions from u,7 the underspecified form of z, and search the CKY chart for the top-scoring non-overlapping spans that contain ca</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>Kwiatkowski, T., Zettlemoyer, L. S., Goldwater, S., and Steedman, M. (2010). Inducing probabilistic CCG grammars from logical form with higher-order unification. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>L S Zettlemoyer</author>
<author>S Goldwater</author>
<author>M Steedman</author>
</authors>
<title>Lexical generalization in CCG grammar induction for semantic parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="13156" citStr="Kwiatkowski et al., 2011" startWordPosition="2059" endWordPosition="2062">c meaning. The typing system includes basic types (e.g., entity e, truth value t) and functional types (e.g., (e, t) is the type of a function from e to t). In the example category, Ax.Ad.dance-01(d) n ARG0(d, x) is a (e, (e, t))-typed function expecting an ARG0 argument, and the conjunction specifies the roles of the dance-01 frame. A CCG is defined by a lexicon and a set of combinators. The lexicon pairs words and phrases with their categorial meaning. For example, dance �- Ax.Ad.dance-01(d) n ARG0(d, x) pairs dance with the category above. We adopt a factored representation of the lexicon (Kwiatkowski et al., 2011), where entries are dynamically generated by N[pl] λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))) &gt; 1701 combining lexemes and templates. For example, the above lexical entry can be generated by pairing the lexeme (dance, {dance-01}) with the template Av1.[S\NP : Ax.Aa.v1(a) n ARG0(a, x)]. Skolem Terms and IDs Generalized Skolem terms (henceforth, Skolem terms) for CCG were introduced by Steedman (2011) to capture complex dependencies with relatively local quantification. We define here a simplified version of the theory to represent entities and allow distant references. Let A be a ((e, t), e</context>
<context position="35278" citStr="Kwiatkowski et al., 2011" startWordPosition="5803" endWordPosition="5806">tures, parent-relation-child selectional preferences and for mapping a relation to its final form. See the supplementary material for a detailed description. Initialization and Parameters We created the seed lexicon from the training data by sampling and annotating 50 sentences with lexical entries, adding entries for pronouns and adding lexemes for all alignments generated by JAMR (Flanigan et al., 2014). We initialize features weights as follows: 10 for all lexeme feature for seed entries and entries generated by named-entity matching (Section 6.1), IBM Model 1 scores for all other lexemes (Kwiatkowski et al., 2011), -3 for unary type shifting and crossing composition features, 3 for features that pair singular and plural part-ofspeech tags with singular and plural attributes and 0 for all other features. We set the number of iterations T = 10 and select the best model based on development results. We set the max number of tokens for lexical generation kgen = 2, learning rate µ = 0.1, CCG parsing beam K = 50, factor graph beam L = 100, mini batch size M = 40 and use a beam of 100 for GENMAX. Two-pass Inference During testing, we perform two passes of inference for every sentence. First, we run our infere</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2011</marker>
<rawString>Kwiatkowski, T., Zettlemoyer, L. S., Goldwater, S., and Steedman, M. (2011). Lexical generalization in CCG grammar induction for semantic parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Machine Learning.</booktitle>
<contexts>
<context position="17369" citStr="Lafferty et al., 2001" startWordPosition="2789" endWordPosition="2792">ingle element for each constant, is a disambiguation of Su. Applying M to all constants in u results in the final logical form z. Decomposing the derivation provides two advantages. First, we are able to defer decisions from the CCG parse to the factor graph, thereby considering fewer hypotheses during parsing and simplifying the computation. Second, we can represent distant references while avoiding the complex parse trees that would have been required to represent these dependencies with scoped variables instead of Skolem IDs.2 5.3 Model Given a sentence x, we use a weighted log-linear CCG (Lafferty et al., 2001; Clark and Curran, 2007) to rank the space of possible parses under the grammar Λ. At the root of each CCG derivation is the underspecified logical form u. To represent a probability distribution over M, we build for each u a factor graph Gu = (V, F, E), 2Similar to mention clustering methods for co-reference resolution (Ng, 2010), IDs can be viewed as creating clusters. 1702 (a) CCG parse y: Maps the sentence x to an underspecified logical form u (Section 5.1) with placeholders for unresolved decisions: ID for reference identifiers and the predicates REL and REL-of for unresolved relations. </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>Lafferty, J., McCallum, A., and Pereira, F. (2001). Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lewis</author>
<author>M Steedman</author>
</authors>
<title>Combined distributional and logical semantics.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>1</volume>
<contexts>
<context position="10612" citStr="Lewis and Steedman, 2013" startWordPosition="1651" endWordPosition="1654"> are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of firstorder logic representations (Bos, 2008; Lewis and Steedman, 2013). However, this work lacked corpora to evaluate the logical forms recovered. AMR (Banarescu et al., 2013) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015). There is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; NP[pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three lexical entries, two forwar</context>
</contexts>
<marker>Lewis, Steedman, 2013</marker>
<rawString>Lewis, M. and Steedman, M. (2013). Combined distributional and logical semantics. Transactions of the Association for Computational Linguistics, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Lewis</author>
<author>M Steedman</author>
</authors>
<title>A* CCG parsing with a supertag-factored model.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="32936" citStr="Lewis and Steedman, 2014" startWordPosition="5433" endWordPosition="5436"> leads to higher quality updates that are focused on the errors the model makes. Second, given the complexity of the data, it allows us to have updates for many examples that would be otherwise ignored. In our experiments, we observe this behavior with nearly 40% of the training set. 7 Experimental Setup Data, Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system. We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs. CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factoring lexical entries, we avoid extracting binary relations and references, and lea</context>
</contexts>
<marker>Lewis, Steedman, 2014</marker>
<rawString>Lewis, M. and Steedman, M. (2014). A* CCG parsing with a supertag-factored model. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>M Jordan</author>
<author>D Klein</author>
</authors>
<title>Learning dependency-based compositional semantics.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1122" citStr="Liang et al., 2011" startWordPosition="164" endWordPosition="167"> AMR Bank provides a unique opportunity to induce a single model for understanding broad-coverage newswire text and support a wide range of applications. We present a new model that combines CCG parsing to recover compositional aspects of meaning and a factor graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art. 1 Introduction Semantic parsers map sentences to formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011). Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, an</context>
<context position="9649" citStr="Liang et al., 2011" startWordPosition="1506" endWordPosition="1509">ure (Section 6) that alternates between expanding the lexicon and updating the parameters. Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or</context>
</contexts>
<marker>Liang, Jordan, Klein, 2011</marker>
<rawString>Liang, P., Jordan, M., and Klein, D. (2011). Learning dependency-based compositional semantics. In Proceedings of the Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Liu</author>
<author>J Flanigan</author>
<author>S Thomson</author>
<author>N Sadeh</author>
<author>N A Smith</author>
</authors>
<title>Toward abstractive summarization using semantic representations.</title>
<date>2015</date>
<booktitle>In Proceedings of the North American Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1870" citStr="Liu et al., 2015" startWordPosition="282" endWordPosition="285">ly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for broad-coverage text, and work is ongoing to study its use for variety of applications such as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015). The ∗Work done at the University of Washington. AMR meaning bank provides a large new corpus that, for the first time, enables us to study the problem of grammar induction for broad-coverage semantic parsing. However, it also presents significant challenges for existing algorithms, including much longer sentences, more complex syntactic phenomena and increased use of noncompositional semantics, such as within-sentence coreference. In this paper, we introduce a new, scalable Combinatory Categorial Grammar (CCG; Steedman, 1996, 2000) induction approach that solves these challenges with a learn</context>
<context position="10843" citStr="Liu et al., 2015" startWordPosition="1691" endWordPosition="1694">r and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of firstorder logic representations (Bos, 2008; Lewis and Steedman, 2013). However, this work lacked corpora to evaluate the logical forms recovered. AMR (Banarescu et al., 2013) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015). There is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; NP[pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three lexical entries, two forward applications (&gt;) and type-shifting of a plural noun to a noun phrase. AMRs, including graph parsing (Flanigan et al., 2014), methods to build AMRs from dependency trees (Wang et al., 2015) and algorithms for aligning words to AMR</context>
</contexts>
<marker>Liu, Flanigan, Thomson, Sadeh, Smith, 2015</marker>
<rawString>Liu, F., Flanigan, J., Thomson, S., Sadeh, N., and Smith, N. A. (2015). Toward abstractive summarization using semantic representations. In Proceedings of the North American Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>M Surdeanu</author>
<author>J Bauer</author>
<author>J Finkel</author>
<author>S J Bethard</author>
<author>D McClosky</author>
</authors>
<title>The Stanford CoreNLP natural language processing toolkit.</title>
<date>2014</date>
<booktitle>In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="33166" citStr="Manning et al., 2014" startWordPosition="5469" endWordPosition="5472">this behavior with nearly 40% of the training set. 7 Experimental Setup Data, Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system. We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs. CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factoring lexical entries, we avoid extracting binary relations and references, and leave them in the template. We use backward and forward binary combinators for application, composition and crossing composition. We allow non-crossing composition up to the third order. We also add rules to handle punctuation and un</context>
</contexts>
<marker>Manning, Surdeanu, Bauer, Finkel, Bethard, McClosky, 2014</marker>
<rawString>Manning, C. D., Surdeanu, M., Bauer, J., Finkel, J., Bethard, S. J., and McClosky, D. (2014). The Stanford CoreNLP natural language processing toolkit. In Proceedings of the Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Muresan</author>
</authors>
<title>Learning for deep language understanding.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="9585" citStr="Muresan, 2011" startWordPosition="1498" endWordPosition="1499">he grammar and the factor graph. We define a learning procedure (Section 6) that alternates between expanding the lexicon and updating the parameters. Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engin</context>
</contexts>
<marker>Muresan, 2011</marker>
<rawString>Muresan, S. (2011). Learning for deep language understanding. In Proceedings of the International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ng</author>
</authors>
<title>Supervised noun phrase coreference research: The first fifteen years.</title>
<date>2010</date>
<booktitle>In Proceedings of the annual</booktitle>
<contexts>
<context position="17702" citStr="Ng, 2010" startWordPosition="2850" endWordPosition="2851">Second, we can represent distant references while avoiding the complex parse trees that would have been required to represent these dependencies with scoped variables instead of Skolem IDs.2 5.3 Model Given a sentence x, we use a weighted log-linear CCG (Lafferty et al., 2001; Clark and Curran, 2007) to rank the space of possible parses under the grammar Λ. At the root of each CCG derivation is the underspecified logical form u. To represent a probability distribution over M, we build for each u a factor graph Gu = (V, F, E), 2Similar to mention clustering methods for co-reference resolution (Ng, 2010), IDs can be viewed as creating clusters. 1702 (a) CCG parse y: Maps the sentence x to an underspecified logical form u (Section 5.1) with placeholders for unresolved decisions: ID for reference identifiers and the predicates REL and REL-of for unresolved relations. x: Pyongyang officials denied their involvement NP[sg] N[pl]\(N[pl]/N[pl]) S\NP/NP NP[pl] N[nb] A1(λc.city(c)∧ λf.λp.person(p)∧ λx.λy.λd.deny-01(d)∧ R(ID) λi.involve-01(i) name(c, A2(λn.name(n)∧ REL-of(p A3(f(λh.have-or -role-91(h)∧ ARG0(d, y)∧ op(n, PYONGYANG)))) REL(h,. 14(λo.official(o))))�) ARG1(d, x) &lt; &gt; &gt; &lt; A u: A1(λd.deny-01</context>
</contexts>
<marker>Ng, 2010</marker>
<rawString>Ng, V. (2010). Supervised noun phrase coreference research: The first fifteen years. In Proceedings of the annual meeting of the association for computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Pan</author>
<author>T Cassidy</author>
<author>U Hermjakob</author>
<author>H Ji</author>
<author>K Knight</author>
</authors>
<title>Unsupervised entity linking with Abstract Meaning Representation.</title>
<date>2015</date>
<booktitle>In Proceedings of the North American Association for Computational Linguistics.</booktitle>
<contexts>
<context position="10824" citStr="Pan et al., 2015" startWordPosition="1687" endWordPosition="1690"> (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of firstorder logic representations (Bos, 2008; Lewis and Steedman, 2013). However, this work lacked corpora to evaluate the logical forms recovered. AMR (Banarescu et al., 2013) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015). There is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; NP[pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three lexical entries, two forward applications (&gt;) and type-shifting of a plural noun to a noun phrase. AMRs, including graph parsing (Flanigan et al., 2014), methods to build AMRs from dependency trees (Wang et al., 2015) and algorithms for al</context>
</contexts>
<marker>Pan, Cassidy, Hermjakob, Ji, Knight, 2015</marker>
<rawString>Pan, X., Cassidy, T., Hermjakob, U., Ji, H., and Knight, K. (2015). Unsupervised entity linking with Abstract Meaning Representation. In Proceedings of the North American Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Poon</author>
</authors>
<title>Grounded unsupervised semantic parsing.</title>
<date>2013</date>
<booktitle>In Association for Computational Linguistics (ACL).</booktitle>
<contexts>
<context position="9974" citStr="Poon, 2013" startWordPosition="1555" endWordPosition="1556">k The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of firstorder logic representations</context>
</contexts>
<marker>Poon, 2013</marker>
<rawString>Poon, H. (2013). Grounded unsupervised semantic parsing. In Association for Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Pourdamghani</author>
<author>Y Gao</author>
<author>U Hermjakob</author>
<author>K Knight</author>
</authors>
<title>Aligning English strings with Abstract Meaning Representation graphs.</title>
<date>2014</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="11472" citStr="Pourdamghani et al., 2014" startWordPosition="1780" endWordPosition="1783">here is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; NP[pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three lexical entries, two forward applications (&gt;) and type-shifting of a plural noun to a noun phrase. AMRs, including graph parsing (Flanigan et al., 2014), methods to build AMRs from dependency trees (Wang et al., 2015) and algorithms for aligning words to AMRs (Pourdamghani et al., 2014). 4 Background Combinatory Categorial Grammar CCG is a categorial formalism that provides a transparent interface between syntax and semantics (Steedman, 1996, 2000). Section 7 details our instantiation of CCG. In CCG trees, each node is a category. Figure 2 shows a simple CCG tree. For example, S\NP[pl] : Ax.Ad.dance-01(d) n ARG0(d, x) is a category for an intransitive verb phrase. The syntactic type S\NP[pl] indicates that an argument of type NP[pl] is expected and the returned syntactic type will be S. The backward slash \ indicates the argument is expected on the left, while a forward slas</context>
</contexts>
<marker>Pourdamghani, Gao, Hermjakob, Knight, 2014</marker>
<rawString>Pourdamghani, N., Gao, Y., Hermjakob, U., and Knight, K. (2014). Aligning English strings with Abstract Meaning Representation graphs. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Ratinov</author>
<author>D Roth</author>
</authors>
<title>Design challenges and misconceptions in named entity recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="33117" citStr="Ratinov and Roth, 2009" startWordPosition="5461" endWordPosition="5464"> otherwise ignored. In our experiments, we observe this behavior with nearly 40% of the training set. 7 Experimental Setup Data, Tools and Metric For evaluation, we use AMR Bank release 1.0 (LDC2014T12). We use the proxy report portion, which includes newswire articles from the English Gigaword corpus, and follow the official split for training, development and evaluation (6603/826/823 sentences). We use EasyCCG (Lewis and Steedman, 2014) trained with the re-banked CCGBank (Hockenmaier and Steedman, 2007; Honnibal et al., 2010) to generate CCGBank categories, the Illinois Named Entity Tagger (Ratinov and Roth, 2009) for NER, Stanford CoreNLP (Manning et al., 2014) for tokenization and part-of-speech tagging and UW SPF (Artzi and Zettlemoyer, 2013a) to develop our system. We use SMATCH (Cai and Knight, 2013) to evaluate logical forms converted back to AMRs. CCG We use three syntactic attributes: singular sg, mass nouns nb and plural pl. When factoring lexical entries, we avoid extracting binary relations and references, and leave them in the template. We use backward and forward binary combinators for application, composition and crossing composition. We allow non-crossing composition up to the third orde</context>
</contexts>
<marker>Ratinov, Roth, 2009</marker>
<rawString>Ratinov, L. and Roth, D. (2009). Design challenges and misconceptions in named entity recognition. In Proceedings of the Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Reddy</author>
<author>M Lapata</author>
<author>M Steedman</author>
</authors>
<title>Large-scale semantic parsing without questionanswer pairs.</title>
<date>2014</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>2</volume>
<contexts>
<context position="9919" citStr="Reddy et al., 2014" startWordPosition="1545" endWordPosition="1548">nt heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broa</context>
</contexts>
<marker>Reddy, Lapata, Steedman, 2014</marker>
<rawString>Reddy, S., Lapata, M., and Steedman, M. (2014). Large-scale semantic parsing without questionanswer pairs. Transactions of the Association for Computational Linguistics, 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Surface Structure and Interpretation.</title>
<date>1996</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2402" citStr="Steedman, 1996" startWordPosition="362" endWordPosition="363">h as machine translation (Jones et al., 2012) and summarization (Liu et al., 2015). The ∗Work done at the University of Washington. AMR meaning bank provides a large new corpus that, for the first time, enables us to study the problem of grammar induction for broad-coverage semantic parsing. However, it also presents significant challenges for existing algorithms, including much longer sentences, more complex syntactic phenomena and increased use of noncompositional semantics, such as within-sentence coreference. In this paper, we introduce a new, scalable Combinatory Categorial Grammar (CCG; Steedman, 1996, 2000) induction approach that solves these challenges with a learned joint model of both compositional and non-compositional semantics, and achieves state-of-the-art performance on AMR Bank parsing. We map sentences to AMR structures in a twostage process (Section 5). First, we use CCG to construct lambda-calculus representations of the compositional aspects of AMR. CCG is designed to capture a wide range of linguistic phenomena, such as coordination and long-distance dependencies, and has been used extensively for semantic parsing. To use CCG for AMR parsing we define a simple encoding for </context>
<context position="11630" citStr="Steedman, 1996" startWordPosition="1803" endWordPosition="1805">l] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three lexical entries, two forward applications (&gt;) and type-shifting of a plural noun to a noun phrase. AMRs, including graph parsing (Flanigan et al., 2014), methods to build AMRs from dependency trees (Wang et al., 2015) and algorithms for aligning words to AMRs (Pourdamghani et al., 2014). 4 Background Combinatory Categorial Grammar CCG is a categorial formalism that provides a transparent interface between syntax and semantics (Steedman, 1996, 2000). Section 7 details our instantiation of CCG. In CCG trees, each node is a category. Figure 2 shows a simple CCG tree. For example, S\NP[pl] : Ax.Ad.dance-01(d) n ARG0(d, x) is a category for an intransitive verb phrase. The syntactic type S\NP[pl] indicates that an argument of type NP[pl] is expected and the returned syntactic type will be S. The backward slash \ indicates the argument is expected on the left, while a forward slash / indicates it is expected on the right. The syntactic attribute pl specifies that the argument must be plural. Attribute variables enforce agreement betwee</context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>Steedman, M. (1996). Surface Structure and Interpretation. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>The MIT Press.</publisher>
<marker>Steedman, 2000</marker>
<rawString>Steedman, M. (2000). The Syntactic Process. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Taking Scope.</title>
<date>2011</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="13562" citStr="Steedman (2011)" startWordPosition="2121" endWordPosition="2122">and phrases with their categorial meaning. For example, dance �- Ax.Ad.dance-01(d) n ARG0(d, x) pairs dance with the category above. We adopt a factored representation of the lexicon (Kwiatkowski et al., 2011), where entries are dynamically generated by N[pl] λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))) &gt; 1701 combining lexemes and templates. For example, the above lexical entry can be generated by pairing the lexeme (dance, {dance-01}) with the template Av1.[S\NP : Ax.Aa.v1(a) n ARG0(a, x)]. Skolem Terms and IDs Generalized Skolem terms (henceforth, Skolem terms) for CCG were introduced by Steedman (2011) to capture complex dependencies with relatively local quantification. We define here a simplified version of the theory to represent entities and allow distant references. Let A be a ((e, t), e)-typed predicate. Given a (e, t)-typed logical expression C, the logical form An(C) is a Skolem term with the Skolem ID n. For example, A2(Ay.boy(y)) is a Skolem term that could represent the noun phrase the boy, which introduces a new entity. Skolem IDs are globally scoped, i.e., they can be referred from anywhere in the logical form without scoping constraints. To refer to Skolem terms, we define the</context>
</contexts>
<marker>Steedman, 2011</marker>
<rawString>Steedman, M. (2011). Taking Scope. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wang</author>
<author>N Xue</author>
<author>S Pradhan</author>
<author>S Pradhan</author>
</authors>
<title>A transition-based algorithm for AMR parsing.</title>
<date>2015</date>
<booktitle>In Proceedings of the North American Association for Computational Linguistics.</booktitle>
<contexts>
<context position="11402" citStr="Wang et al., 2015" startWordPosition="1768" endWordPosition="1771">number of applications (Pan et al., 2015; Liu et al., 2015). There is also work on recovering Happy people dance N[x]/N[x] N[pl] S\NP[pl] λf.λx.f(x) ∧ ARG1-of(x, λp.people(p) λx.λd.dance-01(d) A(λc.content-01(c))) ∧ARG0(d, x) &gt; NP[pl] A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c)))) S λd.dance-01(d) ∧ ARG0(d, A(λp.people(p) ∧ ARG1-of(x, A(λc.content-01(c))))) Figure 2: Example CCG tree with three lexical entries, two forward applications (&gt;) and type-shifting of a plural noun to a noun phrase. AMRs, including graph parsing (Flanigan et al., 2014), methods to build AMRs from dependency trees (Wang et al., 2015) and algorithms for aligning words to AMRs (Pourdamghani et al., 2014). 4 Background Combinatory Categorial Grammar CCG is a categorial formalism that provides a transparent interface between syntax and semantics (Steedman, 1996, 2000). Section 7 details our instantiation of CCG. In CCG trees, each node is a category. Figure 2 shows a simple CCG tree. For example, S\NP[pl] : Ax.Ad.dance-01(d) n ARG0(d, x) is a category for an intransitive verb phrase. The syntactic type S\NP[pl] indicates that an argument of type NP[pl] is expected and the returned syntactic type will be S. The backward slash </context>
<context position="37095" citStr="Wang et al. (2015)" startWordPosition="6124" endWordPosition="6127">e our approach to the latest, fixed version of JAMR (Flanigan et al., 2014) available online,8 the only system to report test results on the official LDC release. Our approach outperforms JAMR by 3 SMATCH F1 points, with a significant gain in recall. Given consensus inter-annotator agreement of 83 SMATCH F1 (Flanigan et al., 2014), this improvement reduces the gap between automated methods and human performance by 15%. Although not strictly comparable, Table 1 also includes results on the pre-release AMR Bank corpus, including the published JAMR results, their fixed results and the results of Wang et al. (2015). Table 2 shows SMATCH scores for the developments set, with ablations. The supplementary material includes example output derivations and qualitative comparison to JAMR outputs. We first remove underspecifying constants, which leaves the factor graph to resolve only references. While the expressivity of the model remains the same, more decisions are considered during parsing, modestly impacting performance. We also study the different methods for lexical generation. Skipping the second recursive splitting pass in GENENTRIES creates an interesting tradeoff. As we are unable to learn templates </context>
<context position="38978" citStr="Wang et al. (2015)" startWordPosition="6415" endWordPosition="6418"> named-entity matching lexical generation (Section 6.1). The significant drop in performance (20 points F1) demonstrates the need for better alignment algorithm. Finally, Figure 5 plots development SMATCH F1 with and without early updates. As expected, early updates increase the learning rate significantly and have a large impact on overall performance. Without early updates we are unable to 8JAMR is available at http://tiny.cc/jamr. P R F1 JAMR (fixed) 67.8 59.2 63.2 Our approach 66.8 65.7 66.3 Pre-release corpus results JAMR (Flanigan et al., 2014) 52.0 66.0 58.0 JAMR (fixed) 66.8 58.3 62.3 Wang et al. (2015) 64.0 62.0 63.0 Table 1: Test SMATCH results. P R F1 Full system 67.2 65.1 66.1 w/o underspecified constants 66.9 64.2 65.5 Lexical learning ablations w/o splitting 65.0 65.0 65.0 w/o Ggen 62.6 62.7 62.6 w/o surface-form similarity 55.9 38.5 45.6 Iteration number Figure 5: Development SMATCH F1 without early updates (•) and with early updates (■). learn from almost half of the data, and performance drops by nearly 15 points. 9 Conclusion We described an approach for broad-coverage CCG induction for semantic parsing, including a joint representation of compositional and noncompositional semanti</context>
</contexts>
<marker>Wang, Xue, Pradhan, Pradhan, 2015</marker>
<rawString>Wang, C., Xue, N., Pradhan, S., and Pradhan, S. (2015). A transition-based algorithm for AMR parsing. In Proceedings of the North American Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Wong</author>
<author>R J Mooney</author>
</authors>
<title>Learning synchronous grammars for semantic parsing with lambda calculus.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="9569" citStr="Wong and Mooney, 2007" startWordPosition="1494" endWordPosition="1497">he parameters of both the grammar and the factor graph. We define a learning procedure (Section 6) that alternates between expanding the lexicon and updating the parameters. Learning new lexical entries relies on a two-pass process that combines learning the meaning of words and new syntactic structures, and supports learning with and without alignment heuristics (e.g., from Flanigan et al., 2014). 3 Related Work The problem of learning semantic parsers has received significant attention. Algorithms have been developed for learning from different forms of supervision, including logical forms (Wong and Mooney, 2007; Muresan, 2011), question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Wong, Y. and Mooney, R. J. (2007). Learning synchronous grammars for semantic parsing with lambda calculus. In Proceedings of the Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zelle</author>
<author>R J Mooney</author>
</authors>
<title>Learning to parse database queries using inductive logic programming.</title>
<date>1996</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="1070" citStr="Zelle and Mooney, 1996" startWordPosition="156" endWordPosition="159">ser for each target application, the recently annotated AMR Bank provides a unique opportunity to induce a single model for understanding broad-coverage newswire text and support a wide range of applications. We present a new model that combines CCG parsing to recover compositional aspects of meaning and a factor graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art. 1 Introduction Semantic parsers map sentences to formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011). Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning</context>
</contexts>
<marker>Zelle, Mooney, 1996</marker>
<rawString>Zelle, J. and Mooney, R. J. (1996). Learning to parse database queries using inductive logic programming. In Proceedings of the National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="1101" citStr="Zettlemoyer and Collins, 2005" startWordPosition="160" endWordPosition="163">ication, the recently annotated AMR Bank provides a unique opportunity to induce a single model for understanding broad-coverage newswire text and support a wide range of applications. We present a new model that combines CCG parsing to recover compositional aspects of meaning and a factor graph to model non-compositional phenomena, such as anaphoric dependencies. Our approach achieves 66.2 Smatch F1 score on the AMR bank, significantly outperforming the previous state of the art. 1 Introduction Semantic parsers map sentences to formal representations of their meaning (Zelle and Mooney, 1996; Zettlemoyer and Collins, 2005; Liang et al., 2011). Existing learning algorithms have primarily focused on building actionable meaning representations which can, for example, directly query a database (Liang et al., 2011; Kwiatkowski et al., 2013) or instruct a robotic agent (Chen, 2012; Artzi and Zettlemoyer, 2013b). However, due to their end-to-end nature, such models must be relearned for each new target application and have only been used to parse restricted styles of text, such as questions and imperatives. Recently, AMR (Banarescu et al., 2013) was proposed as a general-purpose meaning representation language for br</context>
<context position="4811" citStr="Zettlemoyer and Collins, 2005" startWordPosition="727" endWordPosition="731"> they refer to, for example to find the referent for a pronoun. Although primarily motivated by non-compositional reasoning, we also use this mechanism to underspecify certain relations during parsing, allowing for more effective search. Following most work in semantic parsing, we consider two learning challenges: grammar induction, which assigns meaning representations to words and phrases, and parameter estimation, where we learn a model for combining these pieces to analyze full sentences. We introduce a new CCG grammar induction algorithm which incorporates ideas from previous algorithms (Zettlemoyer and Collins, 2005; Kwiatkowski et al., 2010) in a way that scales to the longer sentences and more varied syntactic constructions observed in newswire text. During lexical generation (Section 6.1), the algorithm first attempts to use a set of templates to hypothesize new lexical entries. It then attempts to combine bottom-up parsing with top-down recursive splitting to select the best entries and learn new templates for complex syntactic and semantic phenomena, which are re-used in later sentences to hypothesize new entries. Finally, while previous algorithms (e.g., Zettlemoyer and Collins, 2005) have assumed </context>
<context position="10246" citStr="Zettlemoyer and Collins, 2005" startWordPosition="1595" endWordPosition="1598"> et al., 2010; Liang et al., 2011; Cai and Yates, 2013; Kwiatkowski et al., 2013), sentences paired with demonstrations (Goldwasser and Roth, 2011; Chen and Mooney, 2011), conversational logs (Artzi and Zettlemoyer, 2011), distant supervision (Krishnamurthy and Mitchell, 2012, 2015; Reddy et al., 2014) and without explicit semantic supervision (Poon, 2013). Although we are first to consider using CCG to build AMR representations, our work is closely related to existing methods for CCG semantic parsing. Previous CCG induction techniques have either used hand-engineered lexical templates (e.g., Zettlemoyer and Collins, 2005) or learned templates from the data directly (e.g., Kwiatkowski et al., 2010, 2012). Our two-pass reasoning for lexical generation combines ideas from both methods in a way that greatly improves scalability to long, newswire-style sentences. CCG has also been used for broad-coverage recovery of firstorder logic representations (Bos, 2008; Lewis and Steedman, 2013). However, this work lacked corpora to evaluate the logical forms recovered. AMR (Banarescu et al., 2013) is a generalpurpose meaning representation and has been used in a number of applications (Pan et al., 2015; Liu et al., 2015). T</context>
<context position="22505" citStr="Zettlemoyer and Collins, 2005" startWordPosition="3612" endWordPosition="3615">res and those defined by the factor graph. Let D(z) be the subset of derivations with the final logical form z and θ E 1R,l be a l-dimensional parameter vector. We define the probability of the logical form z as p(zjx; 0, Λ) = � p(djx; 0, Λ) , d∈D(z) and the probability of a derivation d is defined as p(djx; 0, Λ) = eθ·φ(x,d&apos;) , (1) �d ∈ GEN(x,Λ) eθ·φ(x,d) 1703 where O(x, d) ∈ Rl is a feature vector (Section 7). 5.4 Inference To compute the set of derivations GEN(x, A) we define a two-stage process. We first run the CCG parser to generate underspecified logical forms. Following previous work (Zettlemoyer and Collins, 2005), we use CKY parsing to enumerate the top-K underspecified logical forms.3 During the CKY chart construction, we ignore Skolem IDs when comparing categories. This allows us to properly combine partial derivations and to fully benefit from the dynamic programming. We dynamically generate lexical entries for numbers and dates using regular expression patterns and for named-entities using a recognizer. For every underspecified logical form u, we construct a factor graph and use beam search to find the top-L configurations of the graph.4 During learning, we use the function GENMAX(x, z, 0, A) to g</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>Zettlemoyer, L. S. and Collins, M. (2005). Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of the Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>