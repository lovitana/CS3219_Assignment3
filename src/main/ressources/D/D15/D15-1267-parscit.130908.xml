<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009915">
<title confidence="0.9986775">
On the Role of Discourse Markers for Discriminating Claims and
Premises in Argumentative Discourse
</title>
<author confidence="0.976735">
Judith Eckle-Kohler1 Roland Kluge3 Iryna Gurevych1,2
</author>
<affiliation confidence="0.396026">
1 UKP Lab, Technische Universit¨at Darmstadt
2 UKP Lab, German Institute for Educational Research
3 Real-Time Systems Lab, Technische Universit¨at Darmstadt
</affiliation>
<email confidence="0.821805">
http://www.ukp.tu-darmstadt.de
</email>
<sectionHeader confidence="0.99" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999961076923077">
This paper presents a study on the role
of discourse markers in argumentative dis-
course. We annotated a German cor-
pus with arguments according to the com-
mon claim-premise model of argumen-
tation and performed various statistical
analyses regarding the discriminative na-
ture of discourse markers for claims and
premises. Our experiments show that
particular semantic groups of discourse
markers are indicative of either claims or
premises and constitute highly predictive
features for discriminating between them.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999368727272727">
The growing field of argumentation mining in
NLP develops methods to automatically analyze
argumentative discourse for enhanced Information
Extraction.
Terminology: We understand argumentation as a
rhetorical arrangement of arguments with the in-
tent to convince or persuade the reader of a par-
ticular state of affairs. Following previous work
in argumentation mining (e.g., (Palau and Moens,
2009; Florou et al., 2013; Peldszus and Stede,
2013a; Stab and Gurevych, 2014)), we define an
argument as the pairing of a single claim (an ar-
guable text unit) and a (possibly empty) set of
premises, which each either support or attack the
claim (Besnard and Hunter, 2008). We subsume
claims and premises under the term argument unit
(AU).
Discourse markers in argumentative discourse:
Since an argumentation line can only be captured
in the context of a coherent text, argumentation
mining is closely related to automated discourse
analysis (Cabrio et al., 2013), which aims at iden-
tifying discourse functions of text segments, and
discourse relations (DRs) between adjacent text
segments (Webber et al., 2012). Often, so-called
discourse markers (DMs) are used to signal DRs.
The following example shows that DMs act as lex-
ical markers in argumentative discourse as well:
the DM however (marking the DR contrast) po-
sitions the claim in (1) in the overall argumenta-
tion line, while in (2), the DMs as (marking rea-
son) and also (marking elaboration) connect the
premises with each other and with the claim.
</bodyText>
<listItem confidence="0.998946857142857">
(1) However, staying down is pointless
from a pedagogic point of view.
(2) As the students get frustrated, their
performance generally does not im-
prove. Also, the point of repeating all
courses because of only one or two bad
grades is arguable.
</listItem>
<bodyText confidence="0.993176625">
DMs belong to the word classes of conjunctions
and adverbs (also called discourse particles) and
are semantically characterized in traditional gram-
mar books. The correspondence between DM se-
mantics and DR semantics has received consid-
erable attention in previous research in linguis-
tics, most of which is based on corpora annotated
with DRs (Carlson et al., 2003; Wolf and Gibson,
2005; Prasad et al., 2008). In contrast, the role
of DMs as potential lexical signals in argumenta-
tive discourse is not well-understood, yet. While
Stab and Gurevych (2014) used DMs as features
for classifying AUs into different types, they did
not analyze the semantics of DMs with respect to
AU classification or considered different DM re-
sources.
As far as we are aware, there is no prior work
performing a detailed investigation on the role of
DMs as lexical signals for discriminating between
the two fundamental argumentative roles of AUs,
i.e., between claims and premises.
Our contribution: In this paper, we address this
gap by analyzing the role of DMs for the auto-
matic discrimination of claims and premises in a
</bodyText>
<page confidence="0.889905">
2236
</page>
<note confidence="0.641808">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2236–2242,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999116363636364">
new dataset of argumentative texts annotated with
arguments. More specifically, we (i) present the
results of an annotation study that we performed
to annotate a German dataset of news documents
with arguments, and (ii) performed a detailed in-
vestigation of the role of DMs in our annotated
dataset which highlights correspondences between
DM semantics and semantic properties of claims
and premises, and shows that DMs are highly pre-
dictive features for automatically discriminating
premises and claims.
</bodyText>
<sectionHeader confidence="0.999723" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999453">
Related to our work are prior investigations (i) on
the relationship of DMs and DRs, and (ii) on the
role of DMs in classification tasks.
</bodyText>
<subsectionHeader confidence="0.998078">
2.1 Relation of DMs and DRs
</subsectionHeader>
<bodyText confidence="0.999821828571429">
Previous work on the relation between DMs and
DRs is mostly based on corpora annotated with
DRs (Wolf et al., 2004; Taboada, 2006; Prasad et
al., 2008), most notably the Penn Discourse Tree-
bank (PDTB) for English (Prasad et al., 2008).
The PDTB is annotated with DRs, such as con-
trast or result, and the corresponding DMs, even
if they were not realized in the text. For instance,
the contrast relation can be expressed by the DMs
however and but. DRs that are lexically signaled
by DMs in the text are called explicit DRs. Some
DMs are highly polysemous, e.g., while appears in
12 DRs in the PDTB.
Asr and Demberg (2013) analyzed the DMs and
their corresponding DRs annotated in the PDTB
and addressed the question, which information is
conveyed by discourse connectives in the context
of human sentence processing, i.e., how they con-
tribute in the process of inferring a particular DR.
Taboada (2006) performed a corpus-based anal-
ysis of DRs annotated in the Rhetorical Structure
Theory (RST) Discourse Treebank (Carlson et al.,
2003). The most frequent relation in the RST Dis-
course Treebank is concession, and this relation
also received particular attention in the corpus lin-
guistics literature: Taboada and G´omez-Gonz´alez
(2012) present a corpus-based comparative study
of DMs that express concession across English
and Spanish in different genres. A classification
of DMs signaling concession across English and
German is presented by Grote et al. (1997). They
also point out the importance of concession in ar-
gumentative discourse: DMs expressing conces-
sion are often used to introduce counter-arguments
in an argumentation line.
</bodyText>
<subsectionHeader confidence="0.997392">
2.2 DMs in Classification
</subsectionHeader>
<bodyText confidence="0.999988857142857">
There is previous work in sentiment classification
and argumentation mining using DMs as features,
as well as work in predicting DMs for natural lan-
guage generation tasks, such as abstractive sum-
marization. Taboada et al. (2011) successfully em-
ployed discourse particles as features for the cal-
culation of polarity scores in automated sentiment
analysis. They focused on particles acting as in-
tensifiers, which modify the semantic intensity of
the lexical item they refer to.1 Mukherjee and
Bhattacharyya (2012) demonstrated that using dis-
course connectives as features in a system for sen-
timent classification of Twitter posts significantly
improves classification accuracy over state-of-the
art systems not considering DMs as features.
In argumentation mining, Stab and Gurevych
(2014) experimented with different types of fea-
tures, including DMs from the PDTB annota-
tion guidelines, to classify text units into the
classes non-argumentative, major claim, claim,
and premise. While the PDTB DMs appeared to
be not helpful for discriminating between argu-
mentative and non-argumentative text units, they
were useful to distinguish between the classes
premise and claim.
Patterson and Kehler (2013) describe a classi-
fication model, trained and evaluated on PDTB
data, for predicting whether or not a DR is sig-
naled by an explicit DM. The most predictive
features in their model are discourse level fea-
tures that encode dependencies between neighbor-
ing DRs given by the overall discourse structure.
Other highly predictive features turned out to be
the DMs themselves, because DMs vary as to their
rates of being realized explicitly.2
</bodyText>
<sectionHeader confidence="0.890575" genericHeader="method">
3 Annotation Study
</sectionHeader>
<bodyText confidence="0.999818428571429">
For our study, we used a dataset of 88 documents
in German – mainly news (ca. 83% of the docu-
ments) – from seven current topics related to the
German educational system (e.g., mainstreaming,
staying down at school). The documents were
manually selected from a focused crawl and the
top 100 search engine hits per topic (Vovk, 2013).
</bodyText>
<footnote confidence="0.994827">
1Amplifiers such as very increase the semantic intensity,
while downtoners such as slightly decrease it.
2In the PDTB, DMs are also given for implicit DRs.
</footnote>
<page confidence="0.99245">
2237
</page>
<figureCaption confidence="0.999651">
Figure 1: Claim-Premise scheme.
</figureCaption>
<subsectionHeader confidence="0.999933">
3.1 Annotation Scheme
</subsectionHeader>
<bodyText confidence="0.999976228571429">
Since argumentation theory offers a wide range of
models, we performed a pre-study on a held-out
development set to develop the annotation scheme.
We found that most arguments consisted of adja-
cent claims and premises, related by a support or
attack relation; premises and claims were rarely
nested. Therefore, we decided to use a simplified
claim-premises scheme (see Figure 1), using the
terminology set up in Section 1.
Our scheme models an argument as a linked
set of AUs and encodes the argumentative support
and attack relations by assigning an argumentative
role to non-nested (e.g., adjacent) AUs. The non-
nested structure in combination with the pre- and
post- prefixes of premises (indicating if a premise
precedes or follows the claim) makes sure that all
premises are correctly attached to their respective
claims.
For claims, we also annotated whether the
claim is a restatement. In total, we distinguish
six argumentative roles as shown in Figure 1:
claim, restatement, pre-claim support, post-claim
support, pre-claim attack and post-claim attack.
Annotators could freely select annotation bound-
aries, but we encouraged them to annotate clauses
or sentences.
In the main study, three annotators annotated
the remaining 80 documents (3 863 sentences) be-
longing to six topics. On average, each annotator
marked 1708 AUs (53 % premises, 47 % claims)
and 783 arguments (2.2 AUs per argument). An
average claim spans 1.1 sentences, whereas an av-
erage premise spans 2.2 sentences. On average,
74 % of the tokens are covered by an AU, indicat-
ing that the documents are highly argumentative.
</bodyText>
<table confidence="0.9710025">
Ao,t nt Ao,s ns αu
all 61.0 44.2 60.9 45.2 40.2
prem. / 62.7 45.1 62.6 46.3 41.7
claims
AU / 79.0 50.0 77.0 50.0 56.6
non-AU
</table>
<tableCaption confidence="0.99271425">
Table 1: Inter-annotator agreement scores (per-
centages): Ao – observed agreement, nt– token-
based kappa; ns– sentence-based kappa; αu– uni-
tized alpha.
</tableCaption>
<subsectionHeader confidence="0.884404">
3.2 Inter-annotator Agreement
</subsectionHeader>
<bodyText confidence="0.99991612">
Like in other discourse annotation tasks, there is
no straightforward way to compute inter-annotator
agreement (IAA) due to free annotation bound-
aries, see for instance (Miltsakaki et al., 2004;
Wilson and Wiebe, 2003). We selected sentence-
based kappa ns, token-based kappa nt and Krip-
pendorff’s unitized alpha αu as IAA metrics.3 The
token-based kappa nt metric treats each token as
annotation item and, thereon, calculates Fleiss’
kappa (Fleiss, 1971). The tokens are labeled with
the IOB scheme, i.e., every token is annotated as
inside an AU (I), beginning of an AU (B) or out-
side an AU (O). In contrast, Krippendorff’s uni-
tized alpha αu operates on whole annotation spans
instead of isolated tokens. For comparison, we
also calculated the observed agreement Ao (token-
based and sentence-based).
Table 1 summarizes the IAA scores for three
scenarios: (i) considering all six labels and non-
AUs, (ii) only premise, claim and non-AUs, and
(iii) AUs versus non-AUs. The IAA scores are
in line with previous results: Peldszus and Stede
(2013b) report n=38.4 % and α=42.5 % for their
sentence-level annotation study, which used artifi-
cially created documents.
</bodyText>
<sectionHeader confidence="0.999806" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999437166666667">
This section describes the experiments we per-
formed to understand the role of DMs for the
automatic discrimination of claims and premises.
Since the IAA was not substantial, we performed
all experiments on three separate datasets, one per
annotator.
</bodyText>
<footnote confidence="0.989605">
3We calculated the metrics using DKPro Statistics (Meyer
et al., 2014).
</footnote>
<page confidence="0.983843">
2238
</page>
<subsectionHeader confidence="0.974816">
4.1 Semantically Categorized DMs
</subsectionHeader>
<bodyText confidence="0.999902157894737">
Our first set of experiments aimed at understand-
ing the correspondence of DM semantics and se-
mantic aspects of claims and premises. For this,
we used semantically characterized lists of DMs
compiled from three different sources: (i) 28 se-
mantically categorized particles from a German
grammar (Helbig and Buscha, 1996, pp. 481–
484), (ii) 51 discourse connectives based on a
manual translation of the DMs in Appendix B of
the PDTB annotation guidelines, and (iii) a large
German lexicon of about 170 DMs called DiM-
Lex4 (Stede, 2002).
First, we applied a two-sample statistical test to
find out if the two classes claim and premise are
significantly different regarding the number of oc-
currences of individual DMs and semantic groups
of DMs (based on the semantic information given
in our lists). We chose Fisher’s exact test (Fisher,
1932), a non-parametric randomization test that
makes no assumptions about the underlying prob-
ability distribution of the DMs.5 Lacking DR an-
notations, we counted surface word forms of sin-
gle word and continuous multi-word DMs in the
AUs annotated in our dataset.6 For each semanti-
cally categorized DM, we computed a contingency
table containing the number of observed occur-
rences in the two samples of claims and premises.
For each semantic group of DMs given in DiM-
Lex and PDTB, we calculated the per-group con-
tingency table by adding up the contingency tables
for each DM in that particular group.
The results of the significance tests revealed
both single DMs and semantic groups of DMs
that occur with significantly different frequency
in claims or premises. The following individual
DMs and semantic groups of DMs appeared to be
indicative for claims and premises (note that the
sentence-initial variants are counted separately):
</bodyText>
<listItem confidence="0.887017714285714">
Claims: four DMs expressing result, compari-
son, contrast:
• also (therefore), Doch (However), je-
doch (though), sondern (but), as well as the
amplifier ganz (quite);
• semantic groups of DMs from PDTB: com-
parison (expressing concession and contrast)
</listItem>
<footnote confidence="0.986923833333333">
4https://github.com/discourse-lab/dimlex
5We used the implementation given in http:
//stat.ethz.ch/R-manual/R-patched/library/stats/
html/fisher.test.html and a p-value of 0.05.
6Sentence initial DMs were counted separately to capture
DRs being signaled by a sentence initial position.
</footnote>
<bodyText confidence="0.48809">
and result.
</bodyText>
<listItem confidence="0.990411">
Premises: three DMs expressing cause, reason,
elaboration, alternative:
• Denn (As), oder (or), und (and), as well as
the downtoner etwa (roughly);
• semantic groups of DMs from PDTB: al-
ternative (e.g., or), reason (e.g., because),
and from DiMLex, the group sequence (e.g.,
then).
</listItem>
<bodyText confidence="0.999959133333333">
In the group of high-frequent but non-
indicative DMs are DMs expressing elabora-
tion (Auch (Also), Und (And), So (There-
fore)), sequence (dann (then)), and contrast
(aber/Aber (but/But)), as well as some highly am-
biguous particles (e.g., immer (always), schon (al-
ready)).
Second, we ranked the DMs according to their
Information Gain (IG) using Weka (Hall et al.,
2009). For this, we mapped each DM to a boolean
feature indicating if it is present in an AU or not.
We considered all the DMs from the three re-
sources as features and ranked them by IG sepa-
rately for each annotator. The resulting ranking
revealed additional DMs indicative for premises,
e.g. further DMs expressing elaboration and the
downtoner nur (only).
Our findings are in accordance to the ability of
a claim to act as conclusion or result of an ar-
gument, and to the role of premises as providing
support for a claim by giving reasons and elabo-
rating on them. Moreover, we found that particu-
lar intensifying discourse particles play an impor-
tant role in discriminating claims and premises:
Downtoners seem to be significant for premises,
amplifiers for claims. Finally, semantic groups of
DMs expressing concession appeared to be sig-
nificant for claims, since claims often introduce
a counter-argument in the overall argumentation
structure (Grote et al., 1997).
</bodyText>
<subsectionHeader confidence="0.946075">
4.2 Classification
</subsectionHeader>
<bodyText confidence="0.999992444444444">
The significance test and the IG ranking evalu-
ated the DMs in isolation. In order to exam-
ine the predictiveness of all DMs in combination
for claims vs. premises, we used a classification
model. Given an AU, the model predicts its ar-
gumentative role, i.e., claim vs. premise. In this
experiment, we used a list of single word DMs,
extracted from the three DM resources described
above, as boolean features (DMres).
</bodyText>
<page confidence="0.983975">
2239
</page>
<bodyText confidence="0.999985976190476">
For comparison, we used two sets of data-driven
DMs extracted from the Tiger corpus (Brants et
al., 2004), a German newspaper corpus: one set
containing the 350 most frequent conjunctions
and adverbs (DMtiger), and another set contain-
ing the 300 most frequent non-open-class words
(NOCtiger, excluding the word classes of nouns,
main verbs and adjectives).7 In addition, we con-
sidered the top 1800 unigrams (with minimum
frequency 5) as baseline features.
We trained three Machine Learning algorithms
(Naive Bayes (NB), Random Forests (RF) and
Support Vector Machine (SVM)) on the three
datasets annotated by the annotators A1, A2 and
A3, using 10-fold cross-validation and the DKPro
TC framework (Daxenberger et al., 2014). For the
classification experiments, we used all 88 docu-
ments in the annotated corpus (including the doc-
uments from the pre-study).
Table 2 summarizes the results. All classifiers
show significant improvement compared to the
majority class baseline (MC), indicating that DMs
might be useful as predictive features for discrim-
inating claims and premises. The DMs extracted
from Tiger did not improve the performance con-
sistently for all three datasets, showing that the
coverage of the manually compiled DMs is good.
Using the NOCtiger set, however, improved the
performance by up to 4 pp., compared to DMres;
the improvement of NOCtiger over DMres is sta-
tistically significant for NB across all datasets A1
- A3 (using Fisher’s exact test and a p-value of
0.05). These results suggest that not only DMs,
but also other function words, as well as auxil-
iaries and modals, play an important role in dis-
criminating claims and premises.
While the unigram baseline also outperforms
DMres, it is on par with NOCtiger (no significant
improvement for any of NB, RF, SVM across the
three datasets), but at the cost of a much larger
feature space and a model less able to generalize
to other datasets from the news domain.
</bodyText>
<sectionHeader confidence="0.994579" genericHeader="conclusions">
5 Summary
</sectionHeader>
<bodyText confidence="0.999706">
Our goal was to understand some of the lexical-
semantic characteristics of claims and premises
with a focus on DMs acting as lexical signals for
the argumentative role of AUs. Such insights into
the way claims and premises are signaled by lexi-
</bodyText>
<footnote confidence="0.995148">
7We used DKPro Core (Eckart de Castilho and Gurevych,
2014) to pre-process Tiger.
</footnote>
<table confidence="0.999730714285714">
A1 A2 A3
MC 53.04 52.05 51.71
DMres-NB 64.74 65.21 64.53
DMres-RF 64.89 63.61 63.50
DMres-SVM 68.50 66.31 67.06
DMtiger-NB 67.81 65.65 66.65
DMtiger-RF 64.65 61.12 63.44
DMtiger-SVM 70.37 65.59 67.57
NOCtiger-NB 70.86 68.80 68.87
NOCtiger-RF 67.06 64.71 65.51
NOCtiger-SVM 71.80 68.25 68.41
unigram-NB 72.79 69.69 69.60
unigram-RF 70.32 68.75 68.15
unigram-SVM 71.21 69.97 71.14
</table>
<tableCaption confidence="0.915744">
Table 2: Accuracy (percent) using different feature
sets.
</tableCaption>
<bodyText confidence="0.998675470588235">
cal markers can be exploited not only for the auto-
matic analysis of argumentative discourse, but also
for language generation tasks such as creating ab-
stractive summaries of argumentative documents.
We investigated the role of a large set of DMs
in argumentative discourse based on a German
dataset annotated with arguments and identified
semantic groups of DMs that are indicative of ei-
ther claims or premises. These semantic groups
also shed light on semantic aspects of claims and
premises. Our classification model shows that
DMs are important features for the discrimination
of claims and premises. In order to foster fur-
ther research on DMs in argumentative discourse,
we publicly released the annotation guidelines, as
well as the semantically categorized DM lists used
in our experiments.8
</bodyText>
<sectionHeader confidence="0.984401" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999864888888889">
This work has been supported by the Volkswagen
Foundation as part of the Lichtenberg-Professor-
ship Program under grant No. I/82806, by the Ger-
man Institute for Educational Research (DIPF),
and by the German Research Foundation under
grant No. GU 798/17-1. We thank the anonymous
reviewers for their valuable comments. We also
thank Georg Weber for his contributions to the an-
notation study.
</bodyText>
<footnote confidence="0.981067333333333">
8https://www.ukp.tu-darmstadt.
de/data/argumentation-mining/
argument-annotated-news-articles/
</footnote>
<page confidence="0.991366">
2240
</page>
<sectionHeader confidence="0.981298" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996515157407407">
Fatemeh Torabi Asr and Vera Demberg. 2013. On
the Information Conveyed by Discourse Markers.
In Proceedings of the Fourth Annual Workshop on
Cognitive Modeling and Computational Linguistics
(CMCL), pages 84–93, Sofia, Bulgaria.
Philippe Besnard and Anthony Hunter. 2008. El-
ements of argumentation, volume 47. MIT press
Cambridge.
Sabine Brants, Stefanie Dipper, Peter Eisenberg, Sil-
via Hansen, Esther K¨onig, Wolfgang Lezius, Chris-
tian Rohrer, George Smith, and Hans Uszkoreit.
2004. TIGER: linguistic interpretation of a German
corpus. Research on Language and Computation,
2(4):597–620.
Elena Cabrio, Sara Tonelli, and Serena Villata. 2013.
From discourse analysis to argumentation schemes
and back: Relations and differences. In Jo˜ao Leite,
TranCao Son, Paolo Torroni, Leon Torre, and Ste-
fan Woltran, editors, Computational Logic in Multi-
Agent Systems, volume 8143 of Lecture Notes in
Computer Science, pages 1–17. Springer Berlin Hei-
delberg.
Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski, 2003. Building a discourse-tagged cor-
pus in the framework of rhetorical structure theory,
chapter 5, pages 85–112. Springer Berlin Heidel-
berg.
Johannes Daxenberger, Oliver Ferschke, Iryna
Gurevych, and Torsten Zesch. 2014. DKPro TC:
A Java-based Framework for Supervised Learning
Experiments on Textual Data. In Proceedings of
52nd Annual Meeting of the Association for Compu-
tational Linguistics (ACL): System Demonstrations,
pages 61–66, Baltimore, MD, USA.
Richard Eckart de Castilho and Iryna Gurevych. 2014.
A broad-coverage collection of portable NLP com-
ponents for building shareable analysis pipelines.
In Proceedings of the Workshop on Open In-
frastructures and Analysis Frameworks for HLT
(OIAF4HLT) at COLING 2014, pages 1–11, Dublin,
Ireland.
Ronald Aylmer Fisher. 1932. Statistical Methods for
Research Workers. Oliver and Boyd, London.
Joseph L. Fleiss. 1971. Measuring nominal scale
agreement among many raters. Psychological Bul-
letin, 76(5):378–382.
Eirini Florou, Stasinos Konstantopoulos, Antonis
Koukourikos, and Pythagoras Karampiperis. 2013.
Argument extraction for supporting public policy
formulation. In Proceedings of the 7th Workshop
on Language Technology for Cultural Heritage, So-
cial Sciences, and Humanities, pages 49–54, Sofia,
Bulgaria.
Brigitte Grote, Nils Lenke, and Manfred Stede. 1997.
Ma(r)king concessions in English and German. Dis-
course Processes, 24(1):87–118.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H Witten.
2009. The WEKA data mining software: an update.
ACM SIGKDD explorations newsletter, 11(1):10–
18.
Gerhard Helbig and Joachim Buscha. 1996.
Deutsche Grammatik. Ein Handbuch f¨ur den
Ausl¨anderunterricht. Langenscheidt.
Christian M. Meyer, Margot Mieskes, Christian Stab,
and Iryna Gurevych. 2014. DKPro Agreement:
An Open-Source Java Library for Measuring Inter-
Rater Agreement. In Proceedings of the 25th In-
ternational Conference on Computational Linguis-
tics (COLING): System Demonstrations, pages 105–
109, Dublin, Ireland.
Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and
Bonnie Webber. 2004. Annotating discourse con-
nectives and their arguments. In Proceedings of the
HLT/NAACL Workshop on Frontiers in Corpus An-
notation, pages 9–16, Boston, Massachusetts, USA.
Subhabrata Mukherjee and Pushpak Bhattacharyya.
2012. Sentiment analysis in twitter with lightweight
discourse analysis. In Proceedings of the 24th Inter-
national Conference on Computational Linguistics
(COLING), pages 1847–1864, Mumbai, India.
Raquel Mochales Palau and Marie-Francine Moens.
2009. Argumentation mining: The detection, clas-
sification and structure of arguments in text. In
Proceedings of the 12th international conference on
artificial intelligence and law, pages 98–107, New
York, NY, USA.
Gary Patterson and Andrew Kehler. 2013. Predicting
the Presence of Discourse Connectives. In Proceed-
ings of the 2013 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
914–923, Seattle, Washington, USA.
Andreas Peldszus and Manfred Stede. 2013a. From
Argument Diagrams to Argumentation Mining in
Texts: A Survey. International Journal of Cogni-
tive Informatics and Natural Intelligence (IJCINI),
7(1):1–31.
Andreas Peldszus and Manfred Stede. 2013b. Ranking
the annotators: An agreement study on argumenta-
tion structure. In Proceedings of the 7th Linguistic
Annotation Workshop and Interoperability with Dis-
course, pages 196–204, Sofia, Bulgaria.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Milt-
sakaki, Livio Robaldo, Aravind Joshi, and Bonnie
Webber. 2008. The Penn Discourse TreeBank 2.0.
In Proceedings of the Sixth International Conference
on Language Resources and Evaluation (LREC),
pages 28–30, Marrakech, Morocco.
</reference>
<page confidence="0.753584">
2241
</page>
<reference confidence="0.999829358974359">
Christian Stab and Iryna Gurevych. 2014. Identify-
ing Argumentative Discourse Structures in Persua-
sive Essays. In Conference on Empirical Methods in
Natural Language Processing (EMNLP), pages 46–
56, Doha, Qatar.
Manfred Stede. 2002. DiMLex: A Lexical Approach
to Discourse Markers. In Alessandro Lenci and
Vittorio Di Tomaso, editors, Exploring the Lexi-
con. Theory and Computation. Edizioni Dell’Orso,
Alessandria.
Maite Taboada and Mar´ıa de los Angeles G´omez-
Gonz´alez. 2012. Discourse markers and coherence
relations: Comparison across markers, languages
and modalities. Linguistics and the Human Sci-
ences, 6(1-3):17–41.
Maite Taboada, Julian Brooke, Milan Tofiloski, Kim-
berly Voll, and Manfred Stede. 2011. Lexicon-
based methods for sentiment analysis. Computa-
tional Linguistics, 37(2):267–307.
Maite Taboada. 2006. Discourse Markers as Sig-
nals (or Not) of Rhetorical Relationsteu. Journal of
Pragmatics, 38(4):567–592.
Artem Vovk. 2013. Discovery and Analysis of Public
Opinions on Controversial Topics in the Educational
Domain. Master’s thesis, Ubiquitious Knowledge
Processing Lab, TU Darmstadt.
Bonnie Webber, Mark Egg, and Valia Kordoni. 2012.
Discourse structure and language technology. Natu-
ral Language Engineering, 18:437–490, 10.
Theresa Wilson and Janyce Wiebe. 2003. Annotating
opinions in the world press. In Proceedings of the
4th SIGdial Workshop on Discourse and Dialogue,
pages 13–22, Hannover, Germany.
Florian Wolf and Edward Gibson. 2005. Represent-
ing Discourse Coherence: A Corpus-Based Study.
Computational Linguistics, 31(2):249–288.
Florian Wolf, Edward Gibson, Amy Fisher, and Mered-
ith Knight. 2004. Discourse Graphbank. Linguistic
Data Consortium.
</reference>
<page confidence="0.993417">
2242
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.666255">
<title confidence="0.9918695">On the Role of Discourse Markers for Discriminating Claims Premises in Argumentative Discourse</title>
<author confidence="0.995943">Roland Iryna</author>
<note confidence="0.808771333333333">1UKP Lab, Technische Universit¨at 2UKP Lab, German Institute for Educational 3Real-Time Systems Lab, Technische Universit¨at</note>
<web confidence="0.984365">http://www.ukp.tu-darmstadt.de</web>
<abstract confidence="0.999293642857143">This paper presents a study on the role of discourse markers in argumentative discourse. We annotated a German corpus with arguments according to the common claim-premise model of argumentation and performed various statistical analyses regarding the discriminative nature of discourse markers for claims and premises. Our experiments show that particular semantic groups of discourse markers are indicative of either claims or premises and constitute highly predictive features for discriminating between them.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Fatemeh Torabi Asr</author>
<author>Vera Demberg</author>
</authors>
<title>On the Information Conveyed by Discourse Markers.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Annual Workshop on Cognitive Modeling and Computational Linguistics (CMCL),</booktitle>
<pages>84--93</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="5232" citStr="Asr and Demberg (2013)" startWordPosition="825" endWordPosition="828"> Previous work on the relation between DMs and DRs is mostly based on corpora annotated with DRs (Wolf et al., 2004; Taboada, 2006; Prasad et al., 2008), most notably the Penn Discourse Treebank (PDTB) for English (Prasad et al., 2008). The PDTB is annotated with DRs, such as contrast or result, and the corresponding DMs, even if they were not realized in the text. For instance, the contrast relation can be expressed by the DMs however and but. DRs that are lexically signaled by DMs in the text are called explicit DRs. Some DMs are highly polysemous, e.g., while appears in 12 DRs in the PDTB. Asr and Demberg (2013) analyzed the DMs and their corresponding DRs annotated in the PDTB and addressed the question, which information is conveyed by discourse connectives in the context of human sentence processing, i.e., how they contribute in the process of inferring a particular DR. Taboada (2006) performed a corpus-based analysis of DRs annotated in the Rhetorical Structure Theory (RST) Discourse Treebank (Carlson et al., 2003). The most frequent relation in the RST Discourse Treebank is concession, and this relation also received particular attention in the corpus linguistics literature: Taboada and G´omez-G</context>
</contexts>
<marker>Asr, Demberg, 2013</marker>
<rawString>Fatemeh Torabi Asr and Vera Demberg. 2013. On the Information Conveyed by Discourse Markers. In Proceedings of the Fourth Annual Workshop on Cognitive Modeling and Computational Linguistics (CMCL), pages 84–93, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Besnard</author>
<author>Anthony Hunter</author>
</authors>
<title>Elements of argumentation, volume 47.</title>
<date>2008</date>
<publisher>MIT press</publisher>
<location>Cambridge.</location>
<contexts>
<context position="1540" citStr="Besnard and Hunter, 2008" startWordPosition="221" endWordPosition="224">ng in NLP develops methods to automatically analyze argumentative discourse for enhanced Information Extraction. Terminology: We understand argumentation as a rhetorical arrangement of arguments with the intent to convince or persuade the reader of a particular state of affairs. Following previous work in argumentation mining (e.g., (Palau and Moens, 2009; Florou et al., 2013; Peldszus and Stede, 2013a; Stab and Gurevych, 2014)), we define an argument as the pairing of a single claim (an arguable text unit) and a (possibly empty) set of premises, which each either support or attack the claim (Besnard and Hunter, 2008). We subsume claims and premises under the term argument unit (AU). Discourse markers in argumentative discourse: Since an argumentation line can only be captured in the context of a coherent text, argumentation mining is closely related to automated discourse analysis (Cabrio et al., 2013), which aims at identifying discourse functions of text segments, and discourse relations (DRs) between adjacent text segments (Webber et al., 2012). Often, so-called discourse markers (DMs) are used to signal DRs. The following example shows that DMs act as lexical markers in argumentative discourse as well</context>
</contexts>
<marker>Besnard, Hunter, 2008</marker>
<rawString>Philippe Besnard and Anthony Hunter. 2008. Elements of argumentation, volume 47. MIT press Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Brants</author>
<author>Stefanie Dipper</author>
<author>Peter Eisenberg</author>
<author>Silvia Hansen</author>
<author>Esther K¨onig</author>
<author>Wolfgang Lezius</author>
<author>Christian Rohrer</author>
<author>George Smith</author>
<author>Hans Uszkoreit</author>
</authors>
<title>TIGER: linguistic interpretation of a German corpus.</title>
<date>2004</date>
<journal>Research on Language and Computation,</journal>
<volume>2</volume>
<issue>4</issue>
<marker>Brants, Dipper, Eisenberg, Hansen, K¨onig, Lezius, Rohrer, Smith, Uszkoreit, 2004</marker>
<rawString>Sabine Brants, Stefanie Dipper, Peter Eisenberg, Silvia Hansen, Esther K¨onig, Wolfgang Lezius, Christian Rohrer, George Smith, and Hans Uszkoreit. 2004. TIGER: linguistic interpretation of a German corpus. Research on Language and Computation, 2(4):597–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Cabrio</author>
<author>Sara Tonelli</author>
<author>Serena Villata</author>
</authors>
<title>From discourse analysis to argumentation schemes and back: Relations and differences.</title>
<date>2013</date>
<booktitle>Computational Logic in MultiAgent Systems,</booktitle>
<volume>8143</volume>
<pages>1--17</pages>
<editor>In Jo˜ao Leite, TranCao Son, Paolo Torroni, Leon Torre, and Stefan Woltran, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="1831" citStr="Cabrio et al., 2013" startWordPosition="265" endWordPosition="268">us work in argumentation mining (e.g., (Palau and Moens, 2009; Florou et al., 2013; Peldszus and Stede, 2013a; Stab and Gurevych, 2014)), we define an argument as the pairing of a single claim (an arguable text unit) and a (possibly empty) set of premises, which each either support or attack the claim (Besnard and Hunter, 2008). We subsume claims and premises under the term argument unit (AU). Discourse markers in argumentative discourse: Since an argumentation line can only be captured in the context of a coherent text, argumentation mining is closely related to automated discourse analysis (Cabrio et al., 2013), which aims at identifying discourse functions of text segments, and discourse relations (DRs) between adjacent text segments (Webber et al., 2012). Often, so-called discourse markers (DMs) are used to signal DRs. The following example shows that DMs act as lexical markers in argumentative discourse as well: the DM however (marking the DR contrast) positions the claim in (1) in the overall argumentation line, while in (2), the DMs as (marking reason) and also (marking elaboration) connect the premises with each other and with the claim. (1) However, staying down is pointless from a pedagogic </context>
</contexts>
<marker>Cabrio, Tonelli, Villata, 2013</marker>
<rawString>Elena Cabrio, Sara Tonelli, and Serena Villata. 2013. From discourse analysis to argumentation schemes and back: Relations and differences. In Jo˜ao Leite, TranCao Son, Paolo Torroni, Leon Torre, and Stefan Woltran, editors, Computational Logic in MultiAgent Systems, volume 8143 of Lecture Notes in Computer Science, pages 1–17. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynn Carlson</author>
<author>Daniel Marcu</author>
<author>Mary Ellen Okurowski</author>
</authors>
<title>Building a discourse-tagged corpus in the framework of rhetorical structure theory, chapter 5,</title>
<date>2003</date>
<pages>85--112</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="2982" citStr="Carlson et al., 2003" startWordPosition="454" endWordPosition="457">h the claim. (1) However, staying down is pointless from a pedagogic point of view. (2) As the students get frustrated, their performance generally does not improve. Also, the point of repeating all courses because of only one or two bad grades is arguable. DMs belong to the word classes of conjunctions and adverbs (also called discourse particles) and are semantically characterized in traditional grammar books. The correspondence between DM semantics and DR semantics has received considerable attention in previous research in linguistics, most of which is based on corpora annotated with DRs (Carlson et al., 2003; Wolf and Gibson, 2005; Prasad et al., 2008). In contrast, the role of DMs as potential lexical signals in argumentative discourse is not well-understood, yet. While Stab and Gurevych (2014) used DMs as features for classifying AUs into different types, they did not analyze the semantics of DMs with respect to AU classification or considered different DM resources. As far as we are aware, there is no prior work performing a detailed investigation on the role of DMs as lexical signals for discriminating between the two fundamental argumentative roles of AUs, i.e., between claims and premises. </context>
<context position="5647" citStr="Carlson et al., 2003" startWordPosition="889" endWordPosition="892">ssed by the DMs however and but. DRs that are lexically signaled by DMs in the text are called explicit DRs. Some DMs are highly polysemous, e.g., while appears in 12 DRs in the PDTB. Asr and Demberg (2013) analyzed the DMs and their corresponding DRs annotated in the PDTB and addressed the question, which information is conveyed by discourse connectives in the context of human sentence processing, i.e., how they contribute in the process of inferring a particular DR. Taboada (2006) performed a corpus-based analysis of DRs annotated in the Rhetorical Structure Theory (RST) Discourse Treebank (Carlson et al., 2003). The most frequent relation in the RST Discourse Treebank is concession, and this relation also received particular attention in the corpus linguistics literature: Taboada and G´omez-Gonz´alez (2012) present a corpus-based comparative study of DMs that express concession across English and Spanish in different genres. A classification of DMs signaling concession across English and German is presented by Grote et al. (1997). They also point out the importance of concession in argumentative discourse: DMs expressing concession are often used to introduce counter-arguments in an argumentation li</context>
</contexts>
<marker>Carlson, Marcu, Okurowski, 2003</marker>
<rawString>Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski, 2003. Building a discourse-tagged corpus in the framework of rhetorical structure theory, chapter 5, pages 85–112. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Daxenberger</author>
<author>Oliver Ferschke</author>
<author>Iryna Gurevych</author>
<author>Torsten Zesch</author>
</authors>
<title>DKPro TC: A Java-based Framework for Supervised Learning Experiments on Textual Data.</title>
<date>2014</date>
<booktitle>In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations,</booktitle>
<pages>61--66</pages>
<location>Baltimore, MD, USA.</location>
<contexts>
<context position="17002" citStr="Daxenberger et al., 2014" startWordPosition="2681" endWordPosition="2684">, 2004), a German newspaper corpus: one set containing the 350 most frequent conjunctions and adverbs (DMtiger), and another set containing the 300 most frequent non-open-class words (NOCtiger, excluding the word classes of nouns, main verbs and adjectives).7 In addition, we considered the top 1800 unigrams (with minimum frequency 5) as baseline features. We trained three Machine Learning algorithms (Naive Bayes (NB), Random Forests (RF) and Support Vector Machine (SVM)) on the three datasets annotated by the annotators A1, A2 and A3, using 10-fold cross-validation and the DKPro TC framework (Daxenberger et al., 2014). For the classification experiments, we used all 88 documents in the annotated corpus (including the documents from the pre-study). Table 2 summarizes the results. All classifiers show significant improvement compared to the majority class baseline (MC), indicating that DMs might be useful as predictive features for discriminating claims and premises. The DMs extracted from Tiger did not improve the performance consistently for all three datasets, showing that the coverage of the manually compiled DMs is good. Using the NOCtiger set, however, improved the performance by up to 4 pp., compared </context>
</contexts>
<marker>Daxenberger, Ferschke, Gurevych, Zesch, 2014</marker>
<rawString>Johannes Daxenberger, Oliver Ferschke, Iryna Gurevych, and Torsten Zesch. 2014. DKPro TC: A Java-based Framework for Supervised Learning Experiments on Textual Data. In Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics (ACL): System Demonstrations, pages 61–66, Baltimore, MD, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Eckart de Castilho</author>
<author>Iryna Gurevych</author>
</authors>
<title>A broad-coverage collection of portable NLP components for building shareable analysis pipelines.</title>
<date>2014</date>
<booktitle>In Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT (OIAF4HLT) at COLING 2014,</booktitle>
<pages>1--11</pages>
<location>Dublin, Ireland.</location>
<marker>de Castilho, Gurevych, 2014</marker>
<rawString>Richard Eckart de Castilho and Iryna Gurevych. 2014. A broad-coverage collection of portable NLP components for building shareable analysis pipelines. In Proceedings of the Workshop on Open Infrastructures and Analysis Frameworks for HLT (OIAF4HLT) at COLING 2014, pages 1–11, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald Aylmer Fisher</author>
</authors>
<title>Statistical Methods for Research Workers.</title>
<date>1932</date>
<publisher>Oliver and Boyd,</publisher>
<location>London.</location>
<contexts>
<context position="12750" citStr="Fisher, 1932" startWordPosition="2014" endWordPosition="2015">s: (i) 28 semantically categorized particles from a German grammar (Helbig and Buscha, 1996, pp. 481– 484), (ii) 51 discourse connectives based on a manual translation of the DMs in Appendix B of the PDTB annotation guidelines, and (iii) a large German lexicon of about 170 DMs called DiMLex4 (Stede, 2002). First, we applied a two-sample statistical test to find out if the two classes claim and premise are significantly different regarding the number of occurrences of individual DMs and semantic groups of DMs (based on the semantic information given in our lists). We chose Fisher’s exact test (Fisher, 1932), a non-parametric randomization test that makes no assumptions about the underlying probability distribution of the DMs.5 Lacking DR annotations, we counted surface word forms of single word and continuous multi-word DMs in the AUs annotated in our dataset.6 For each semantically categorized DM, we computed a contingency table containing the number of observed occurrences in the two samples of claims and premises. For each semantic group of DMs given in DiMLex and PDTB, we calculated the per-group contingency table by adding up the contingency tables for each DM in that particular group. The </context>
</contexts>
<marker>Fisher, 1932</marker>
<rawString>Ronald Aylmer Fisher. 1932. Statistical Methods for Research Workers. Oliver and Boyd, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph L Fleiss</author>
</authors>
<title>Measuring nominal scale agreement among many raters.</title>
<date>1971</date>
<journal>Psychological Bulletin,</journal>
<volume>76</volume>
<issue>5</issue>
<contexts>
<context position="10833" citStr="Fleiss, 1971" startWordPosition="1703" endWordPosition="1704">ator agreement scores (percentages): Ao – observed agreement, nt– tokenbased kappa; ns– sentence-based kappa; αu– unitized alpha. 3.2 Inter-annotator Agreement Like in other discourse annotation tasks, there is no straightforward way to compute inter-annotator agreement (IAA) due to free annotation boundaries, see for instance (Miltsakaki et al., 2004; Wilson and Wiebe, 2003). We selected sentencebased kappa ns, token-based kappa nt and Krippendorff’s unitized alpha αu as IAA metrics.3 The token-based kappa nt metric treats each token as annotation item and, thereon, calculates Fleiss’ kappa (Fleiss, 1971). The tokens are labeled with the IOB scheme, i.e., every token is annotated as inside an AU (I), beginning of an AU (B) or outside an AU (O). In contrast, Krippendorff’s unitized alpha αu operates on whole annotation spans instead of isolated tokens. For comparison, we also calculated the observed agreement Ao (tokenbased and sentence-based). Table 1 summarizes the IAA scores for three scenarios: (i) considering all six labels and nonAUs, (ii) only premise, claim and non-AUs, and (iii) AUs versus non-AUs. The IAA scores are in line with previous results: Peldszus and Stede (2013b) report n=38</context>
</contexts>
<marker>Fleiss, 1971</marker>
<rawString>Joseph L. Fleiss. 1971. Measuring nominal scale agreement among many raters. Psychological Bulletin, 76(5):378–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eirini Florou</author>
<author>Stasinos Konstantopoulos</author>
<author>Antonis Koukourikos</author>
<author>Pythagoras Karampiperis</author>
</authors>
<title>Argument extraction for supporting public policy formulation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities,</booktitle>
<pages>49--54</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="1293" citStr="Florou et al., 2013" startWordPosition="178" endWordPosition="181">periments show that particular semantic groups of discourse markers are indicative of either claims or premises and constitute highly predictive features for discriminating between them. 1 Introduction The growing field of argumentation mining in NLP develops methods to automatically analyze argumentative discourse for enhanced Information Extraction. Terminology: We understand argumentation as a rhetorical arrangement of arguments with the intent to convince or persuade the reader of a particular state of affairs. Following previous work in argumentation mining (e.g., (Palau and Moens, 2009; Florou et al., 2013; Peldszus and Stede, 2013a; Stab and Gurevych, 2014)), we define an argument as the pairing of a single claim (an arguable text unit) and a (possibly empty) set of premises, which each either support or attack the claim (Besnard and Hunter, 2008). We subsume claims and premises under the term argument unit (AU). Discourse markers in argumentative discourse: Since an argumentation line can only be captured in the context of a coherent text, argumentation mining is closely related to automated discourse analysis (Cabrio et al., 2013), which aims at identifying discourse functions of text segmen</context>
</contexts>
<marker>Florou, Konstantopoulos, Koukourikos, Karampiperis, 2013</marker>
<rawString>Eirini Florou, Stasinos Konstantopoulos, Antonis Koukourikos, and Pythagoras Karampiperis. 2013. Argument extraction for supporting public policy formulation. In Proceedings of the 7th Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 49–54, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Grote</author>
<author>Nils Lenke</author>
<author>Manfred Stede</author>
</authors>
<date>1997</date>
<booktitle>Ma(r)king concessions in English and German. Discourse Processes,</booktitle>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="6074" citStr="Grote et al. (1997)" startWordPosition="952" endWordPosition="955">n the process of inferring a particular DR. Taboada (2006) performed a corpus-based analysis of DRs annotated in the Rhetorical Structure Theory (RST) Discourse Treebank (Carlson et al., 2003). The most frequent relation in the RST Discourse Treebank is concession, and this relation also received particular attention in the corpus linguistics literature: Taboada and G´omez-Gonz´alez (2012) present a corpus-based comparative study of DMs that express concession across English and Spanish in different genres. A classification of DMs signaling concession across English and German is presented by Grote et al. (1997). They also point out the importance of concession in argumentative discourse: DMs expressing concession are often used to introduce counter-arguments in an argumentation line. 2.2 DMs in Classification There is previous work in sentiment classification and argumentation mining using DMs as features, as well as work in predicting DMs for natural language generation tasks, such as abstractive summarization. Taboada et al. (2011) successfully employed discourse particles as features for the calculation of polarity scores in automated sentiment analysis. They focused on particles acting as intens</context>
<context position="15838" citStr="Grote et al., 1997" startWordPosition="2495" endWordPosition="2498">r (only). Our findings are in accordance to the ability of a claim to act as conclusion or result of an argument, and to the role of premises as providing support for a claim by giving reasons and elaborating on them. Moreover, we found that particular intensifying discourse particles play an important role in discriminating claims and premises: Downtoners seem to be significant for premises, amplifiers for claims. Finally, semantic groups of DMs expressing concession appeared to be significant for claims, since claims often introduce a counter-argument in the overall argumentation structure (Grote et al., 1997). 4.2 Classification The significance test and the IG ranking evaluated the DMs in isolation. In order to examine the predictiveness of all DMs in combination for claims vs. premises, we used a classification model. Given an AU, the model predicts its argumentative role, i.e., claim vs. premise. In this experiment, we used a list of single word DMs, extracted from the three DM resources described above, as boolean features (DMres). 2239 For comparison, we used two sets of data-driven DMs extracted from the Tiger corpus (Brants et al., 2004), a German newspaper corpus: one set containing the 35</context>
</contexts>
<marker>Grote, Lenke, Stede, 1997</marker>
<rawString>Brigitte Grote, Nils Lenke, and Manfred Stede. 1997. Ma(r)king concessions in English and German. Discourse Processes, 24(1):87–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The WEKA data mining software: an update.</title>
<date>2009</date>
<journal>ACM SIGKDD explorations newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<pages>18</pages>
<contexts>
<context position="14876" citStr="Hall et al., 2009" startWordPosition="2335" endWordPosition="2338"> cause, reason, elaboration, alternative: • Denn (As), oder (or), und (and), as well as the downtoner etwa (roughly); • semantic groups of DMs from PDTB: alternative (e.g., or), reason (e.g., because), and from DiMLex, the group sequence (e.g., then). In the group of high-frequent but nonindicative DMs are DMs expressing elaboration (Auch (Also), Und (And), So (Therefore)), sequence (dann (then)), and contrast (aber/Aber (but/But)), as well as some highly ambiguous particles (e.g., immer (always), schon (already)). Second, we ranked the DMs according to their Information Gain (IG) using Weka (Hall et al., 2009). For this, we mapped each DM to a boolean feature indicating if it is present in an AU or not. We considered all the DMs from the three resources as features and ranked them by IG separately for each annotator. The resulting ranking revealed additional DMs indicative for premises, e.g. further DMs expressing elaboration and the downtoner nur (only). Our findings are in accordance to the ability of a claim to act as conclusion or result of an argument, and to the role of premises as providing support for a claim by giving reasons and elaborating on them. Moreover, we found that particular inte</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The WEKA data mining software: an update. ACM SIGKDD explorations newsletter, 11(1):10– 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Helbig</author>
<author>Joachim Buscha</author>
</authors>
<title>Deutsche Grammatik. Ein Handbuch f¨ur den Ausl¨anderunterricht.</title>
<date>1996</date>
<publisher>Langenscheidt.</publisher>
<contexts>
<context position="12228" citStr="Helbig and Buscha, 1996" startWordPosition="1924" endWordPosition="1927"> understand the role of DMs for the automatic discrimination of claims and premises. Since the IAA was not substantial, we performed all experiments on three separate datasets, one per annotator. 3We calculated the metrics using DKPro Statistics (Meyer et al., 2014). 2238 4.1 Semantically Categorized DMs Our first set of experiments aimed at understanding the correspondence of DM semantics and semantic aspects of claims and premises. For this, we used semantically characterized lists of DMs compiled from three different sources: (i) 28 semantically categorized particles from a German grammar (Helbig and Buscha, 1996, pp. 481– 484), (ii) 51 discourse connectives based on a manual translation of the DMs in Appendix B of the PDTB annotation guidelines, and (iii) a large German lexicon of about 170 DMs called DiMLex4 (Stede, 2002). First, we applied a two-sample statistical test to find out if the two classes claim and premise are significantly different regarding the number of occurrences of individual DMs and semantic groups of DMs (based on the semantic information given in our lists). We chose Fisher’s exact test (Fisher, 1932), a non-parametric randomization test that makes no assumptions about the unde</context>
</contexts>
<marker>Helbig, Buscha, 1996</marker>
<rawString>Gerhard Helbig and Joachim Buscha. 1996. Deutsche Grammatik. Ein Handbuch f¨ur den Ausl¨anderunterricht. Langenscheidt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian M Meyer</author>
<author>Margot Mieskes</author>
<author>Christian Stab</author>
<author>Iryna Gurevych</author>
</authors>
<title>DKPro Agreement: An Open-Source Java Library for Measuring InterRater Agreement.</title>
<date>2014</date>
<booktitle>In Proceedings of the 25th International Conference on Computational Linguistics (COLING): System Demonstrations,</booktitle>
<pages>105--109</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="11871" citStr="Meyer et al., 2014" startWordPosition="1869" endWordPosition="1872">l six labels and nonAUs, (ii) only premise, claim and non-AUs, and (iii) AUs versus non-AUs. The IAA scores are in line with previous results: Peldszus and Stede (2013b) report n=38.4 % and α=42.5 % for their sentence-level annotation study, which used artificially created documents. 4 Experiments This section describes the experiments we performed to understand the role of DMs for the automatic discrimination of claims and premises. Since the IAA was not substantial, we performed all experiments on three separate datasets, one per annotator. 3We calculated the metrics using DKPro Statistics (Meyer et al., 2014). 2238 4.1 Semantically Categorized DMs Our first set of experiments aimed at understanding the correspondence of DM semantics and semantic aspects of claims and premises. For this, we used semantically characterized lists of DMs compiled from three different sources: (i) 28 semantically categorized particles from a German grammar (Helbig and Buscha, 1996, pp. 481– 484), (ii) 51 discourse connectives based on a manual translation of the DMs in Appendix B of the PDTB annotation guidelines, and (iii) a large German lexicon of about 170 DMs called DiMLex4 (Stede, 2002). First, we applied a two-sa</context>
</contexts>
<marker>Meyer, Mieskes, Stab, Gurevych, 2014</marker>
<rawString>Christian M. Meyer, Margot Mieskes, Christian Stab, and Iryna Gurevych. 2014. DKPro Agreement: An Open-Source Java Library for Measuring InterRater Agreement. In Proceedings of the 25th International Conference on Computational Linguistics (COLING): System Demonstrations, pages 105– 109, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleni Miltsakaki</author>
<author>Rashmi Prasad</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>Annotating discourse connectives and their arguments.</title>
<date>2004</date>
<booktitle>In Proceedings of the HLT/NAACL Workshop on Frontiers in Corpus Annotation,</booktitle>
<pages>9--16</pages>
<location>Boston, Massachusetts, USA.</location>
<contexts>
<context position="10573" citStr="Miltsakaki et al., 2004" startWordPosition="1661" endWordPosition="1664"> 2.2 sentences. On average, 74 % of the tokens are covered by an AU, indicating that the documents are highly argumentative. Ao,t nt Ao,s ns αu all 61.0 44.2 60.9 45.2 40.2 prem. / 62.7 45.1 62.6 46.3 41.7 claims AU / 79.0 50.0 77.0 50.0 56.6 non-AU Table 1: Inter-annotator agreement scores (percentages): Ao – observed agreement, nt– tokenbased kappa; ns– sentence-based kappa; αu– unitized alpha. 3.2 Inter-annotator Agreement Like in other discourse annotation tasks, there is no straightforward way to compute inter-annotator agreement (IAA) due to free annotation boundaries, see for instance (Miltsakaki et al., 2004; Wilson and Wiebe, 2003). We selected sentencebased kappa ns, token-based kappa nt and Krippendorff’s unitized alpha αu as IAA metrics.3 The token-based kappa nt metric treats each token as annotation item and, thereon, calculates Fleiss’ kappa (Fleiss, 1971). The tokens are labeled with the IOB scheme, i.e., every token is annotated as inside an AU (I), beginning of an AU (B) or outside an AU (O). In contrast, Krippendorff’s unitized alpha αu operates on whole annotation spans instead of isolated tokens. For comparison, we also calculated the observed agreement Ao (tokenbased and sentence-ba</context>
</contexts>
<marker>Miltsakaki, Prasad, Joshi, Webber, 2004</marker>
<rawString>Eleni Miltsakaki, Rashmi Prasad, Aravind Joshi, and Bonnie Webber. 2004. Annotating discourse connectives and their arguments. In Proceedings of the HLT/NAACL Workshop on Frontiers in Corpus Annotation, pages 9–16, Boston, Massachusetts, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Subhabrata Mukherjee</author>
<author>Pushpak Bhattacharyya</author>
</authors>
<title>Sentiment analysis in twitter with lightweight discourse analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of the 24th International Conference on Computational Linguistics (COLING),</booktitle>
<pages>1847--1864</pages>
<location>Mumbai, India.</location>
<contexts>
<context position="6788" citStr="Mukherjee and Bhattacharyya (2012)" startWordPosition="1060" endWordPosition="1063">Ms expressing concession are often used to introduce counter-arguments in an argumentation line. 2.2 DMs in Classification There is previous work in sentiment classification and argumentation mining using DMs as features, as well as work in predicting DMs for natural language generation tasks, such as abstractive summarization. Taboada et al. (2011) successfully employed discourse particles as features for the calculation of polarity scores in automated sentiment analysis. They focused on particles acting as intensifiers, which modify the semantic intensity of the lexical item they refer to.1 Mukherjee and Bhattacharyya (2012) demonstrated that using discourse connectives as features in a system for sentiment classification of Twitter posts significantly improves classification accuracy over state-of-the art systems not considering DMs as features. In argumentation mining, Stab and Gurevych (2014) experimented with different types of features, including DMs from the PDTB annotation guidelines, to classify text units into the classes non-argumentative, major claim, claim, and premise. While the PDTB DMs appeared to be not helpful for discriminating between argumentative and non-argumentative text units, they were us</context>
</contexts>
<marker>Mukherjee, Bhattacharyya, 2012</marker>
<rawString>Subhabrata Mukherjee and Pushpak Bhattacharyya. 2012. Sentiment analysis in twitter with lightweight discourse analysis. In Proceedings of the 24th International Conference on Computational Linguistics (COLING), pages 1847–1864, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raquel Mochales Palau</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Argumentation mining: The detection, classification and structure of arguments in text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th international conference on artificial intelligence and law,</booktitle>
<pages>98--107</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="1272" citStr="Palau and Moens, 2009" startWordPosition="174" endWordPosition="177">ms and premises. Our experiments show that particular semantic groups of discourse markers are indicative of either claims or premises and constitute highly predictive features for discriminating between them. 1 Introduction The growing field of argumentation mining in NLP develops methods to automatically analyze argumentative discourse for enhanced Information Extraction. Terminology: We understand argumentation as a rhetorical arrangement of arguments with the intent to convince or persuade the reader of a particular state of affairs. Following previous work in argumentation mining (e.g., (Palau and Moens, 2009; Florou et al., 2013; Peldszus and Stede, 2013a; Stab and Gurevych, 2014)), we define an argument as the pairing of a single claim (an arguable text unit) and a (possibly empty) set of premises, which each either support or attack the claim (Besnard and Hunter, 2008). We subsume claims and premises under the term argument unit (AU). Discourse markers in argumentative discourse: Since an argumentation line can only be captured in the context of a coherent text, argumentation mining is closely related to automated discourse analysis (Cabrio et al., 2013), which aims at identifying discourse fun</context>
</contexts>
<marker>Palau, Moens, 2009</marker>
<rawString>Raquel Mochales Palau and Marie-Francine Moens. 2009. Argumentation mining: The detection, classification and structure of arguments in text. In Proceedings of the 12th international conference on artificial intelligence and law, pages 98–107, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gary Patterson</author>
<author>Andrew Kehler</author>
</authors>
<title>Predicting the Presence of Discourse Connectives.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>914--923</pages>
<location>Seattle, Washington, USA.</location>
<contexts>
<context position="7474" citStr="Patterson and Kehler (2013)" startWordPosition="1159" endWordPosition="1162">in a system for sentiment classification of Twitter posts significantly improves classification accuracy over state-of-the art systems not considering DMs as features. In argumentation mining, Stab and Gurevych (2014) experimented with different types of features, including DMs from the PDTB annotation guidelines, to classify text units into the classes non-argumentative, major claim, claim, and premise. While the PDTB DMs appeared to be not helpful for discriminating between argumentative and non-argumentative text units, they were useful to distinguish between the classes premise and claim. Patterson and Kehler (2013) describe a classification model, trained and evaluated on PDTB data, for predicting whether or not a DR is signaled by an explicit DM. The most predictive features in their model are discourse level features that encode dependencies between neighboring DRs given by the overall discourse structure. Other highly predictive features turned out to be the DMs themselves, because DMs vary as to their rates of being realized explicitly.2 3 Annotation Study For our study, we used a dataset of 88 documents in German – mainly news (ca. 83% of the documents) – from seven current topics related to the Ge</context>
</contexts>
<marker>Patterson, Kehler, 2013</marker>
<rawString>Gary Patterson and Andrew Kehler. 2013. Predicting the Presence of Discourse Connectives. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 914–923, Seattle, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Peldszus</author>
<author>Manfred Stede</author>
</authors>
<title>From Argument Diagrams to Argumentation Mining in Texts: A Survey.</title>
<date>2013</date>
<journal>International Journal of Cognitive Informatics and Natural Intelligence (IJCINI),</journal>
<volume>7</volume>
<issue>1</issue>
<contexts>
<context position="1319" citStr="Peldszus and Stede, 2013" startWordPosition="182" endWordPosition="185">articular semantic groups of discourse markers are indicative of either claims or premises and constitute highly predictive features for discriminating between them. 1 Introduction The growing field of argumentation mining in NLP develops methods to automatically analyze argumentative discourse for enhanced Information Extraction. Terminology: We understand argumentation as a rhetorical arrangement of arguments with the intent to convince or persuade the reader of a particular state of affairs. Following previous work in argumentation mining (e.g., (Palau and Moens, 2009; Florou et al., 2013; Peldszus and Stede, 2013a; Stab and Gurevych, 2014)), we define an argument as the pairing of a single claim (an arguable text unit) and a (possibly empty) set of premises, which each either support or attack the claim (Besnard and Hunter, 2008). We subsume claims and premises under the term argument unit (AU). Discourse markers in argumentative discourse: Since an argumentation line can only be captured in the context of a coherent text, argumentation mining is closely related to automated discourse analysis (Cabrio et al., 2013), which aims at identifying discourse functions of text segments, and discourse relation</context>
<context position="11419" citStr="Peldszus and Stede (2013" startWordPosition="1800" endWordPosition="1803">alculates Fleiss’ kappa (Fleiss, 1971). The tokens are labeled with the IOB scheme, i.e., every token is annotated as inside an AU (I), beginning of an AU (B) or outside an AU (O). In contrast, Krippendorff’s unitized alpha αu operates on whole annotation spans instead of isolated tokens. For comparison, we also calculated the observed agreement Ao (tokenbased and sentence-based). Table 1 summarizes the IAA scores for three scenarios: (i) considering all six labels and nonAUs, (ii) only premise, claim and non-AUs, and (iii) AUs versus non-AUs. The IAA scores are in line with previous results: Peldszus and Stede (2013b) report n=38.4 % and α=42.5 % for their sentence-level annotation study, which used artificially created documents. 4 Experiments This section describes the experiments we performed to understand the role of DMs for the automatic discrimination of claims and premises. Since the IAA was not substantial, we performed all experiments on three separate datasets, one per annotator. 3We calculated the metrics using DKPro Statistics (Meyer et al., 2014). 2238 4.1 Semantically Categorized DMs Our first set of experiments aimed at understanding the correspondence of DM semantics and semantic aspects </context>
</contexts>
<marker>Peldszus, Stede, 2013</marker>
<rawString>Andreas Peldszus and Manfred Stede. 2013a. From Argument Diagrams to Argumentation Mining in Texts: A Survey. International Journal of Cognitive Informatics and Natural Intelligence (IJCINI), 7(1):1–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Peldszus</author>
<author>Manfred Stede</author>
</authors>
<title>Ranking the annotators: An agreement study on argumentation structure.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse,</booktitle>
<pages>196--204</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="1319" citStr="Peldszus and Stede, 2013" startWordPosition="182" endWordPosition="185">articular semantic groups of discourse markers are indicative of either claims or premises and constitute highly predictive features for discriminating between them. 1 Introduction The growing field of argumentation mining in NLP develops methods to automatically analyze argumentative discourse for enhanced Information Extraction. Terminology: We understand argumentation as a rhetorical arrangement of arguments with the intent to convince or persuade the reader of a particular state of affairs. Following previous work in argumentation mining (e.g., (Palau and Moens, 2009; Florou et al., 2013; Peldszus and Stede, 2013a; Stab and Gurevych, 2014)), we define an argument as the pairing of a single claim (an arguable text unit) and a (possibly empty) set of premises, which each either support or attack the claim (Besnard and Hunter, 2008). We subsume claims and premises under the term argument unit (AU). Discourse markers in argumentative discourse: Since an argumentation line can only be captured in the context of a coherent text, argumentation mining is closely related to automated discourse analysis (Cabrio et al., 2013), which aims at identifying discourse functions of text segments, and discourse relation</context>
<context position="11419" citStr="Peldszus and Stede (2013" startWordPosition="1800" endWordPosition="1803">alculates Fleiss’ kappa (Fleiss, 1971). The tokens are labeled with the IOB scheme, i.e., every token is annotated as inside an AU (I), beginning of an AU (B) or outside an AU (O). In contrast, Krippendorff’s unitized alpha αu operates on whole annotation spans instead of isolated tokens. For comparison, we also calculated the observed agreement Ao (tokenbased and sentence-based). Table 1 summarizes the IAA scores for three scenarios: (i) considering all six labels and nonAUs, (ii) only premise, claim and non-AUs, and (iii) AUs versus non-AUs. The IAA scores are in line with previous results: Peldszus and Stede (2013b) report n=38.4 % and α=42.5 % for their sentence-level annotation study, which used artificially created documents. 4 Experiments This section describes the experiments we performed to understand the role of DMs for the automatic discrimination of claims and premises. Since the IAA was not substantial, we performed all experiments on three separate datasets, one per annotator. 3We calculated the metrics using DKPro Statistics (Meyer et al., 2014). 2238 4.1 Semantically Categorized DMs Our first set of experiments aimed at understanding the correspondence of DM semantics and semantic aspects </context>
</contexts>
<marker>Peldszus, Stede, 2013</marker>
<rawString>Andreas Peldszus and Manfred Stede. 2013b. Ranking the annotators: An agreement study on argumentation structure. In Proceedings of the 7th Linguistic Annotation Workshop and Interoperability with Discourse, pages 196–204, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The Penn Discourse TreeBank 2.0.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>28--30</pages>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="3027" citStr="Prasad et al., 2008" startWordPosition="462" endWordPosition="465">ntless from a pedagogic point of view. (2) As the students get frustrated, their performance generally does not improve. Also, the point of repeating all courses because of only one or two bad grades is arguable. DMs belong to the word classes of conjunctions and adverbs (also called discourse particles) and are semantically characterized in traditional grammar books. The correspondence between DM semantics and DR semantics has received considerable attention in previous research in linguistics, most of which is based on corpora annotated with DRs (Carlson et al., 2003; Wolf and Gibson, 2005; Prasad et al., 2008). In contrast, the role of DMs as potential lexical signals in argumentative discourse is not well-understood, yet. While Stab and Gurevych (2014) used DMs as features for classifying AUs into different types, they did not analyze the semantics of DMs with respect to AU classification or considered different DM resources. As far as we are aware, there is no prior work performing a detailed investigation on the role of DMs as lexical signals for discriminating between the two fundamental argumentative roles of AUs, i.e., between claims and premises. Our contribution: In this paper, we address t</context>
<context position="4762" citStr="Prasad et al., 2008" startWordPosition="740" endWordPosition="743">i) performed a detailed investigation of the role of DMs in our annotated dataset which highlights correspondences between DM semantics and semantic properties of claims and premises, and shows that DMs are highly predictive features for automatically discriminating premises and claims. 2 Related Work Related to our work are prior investigations (i) on the relationship of DMs and DRs, and (ii) on the role of DMs in classification tasks. 2.1 Relation of DMs and DRs Previous work on the relation between DMs and DRs is mostly based on corpora annotated with DRs (Wolf et al., 2004; Taboada, 2006; Prasad et al., 2008), most notably the Penn Discourse Treebank (PDTB) for English (Prasad et al., 2008). The PDTB is annotated with DRs, such as contrast or result, and the corresponding DMs, even if they were not realized in the text. For instance, the contrast relation can be expressed by the DMs however and but. DRs that are lexically signaled by DMs in the text are called explicit DRs. Some DMs are highly polysemous, e.g., while appears in 12 DRs in the PDTB. Asr and Demberg (2013) analyzed the DMs and their corresponding DRs annotated in the PDTB and addressed the question, which information is conveyed by d</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse TreeBank 2.0. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC), pages 28–30, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Stab</author>
<author>Iryna Gurevych</author>
</authors>
<title>Identifying Argumentative Discourse Structures in Persuasive Essays.</title>
<date>2014</date>
<booktitle>In Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>46--56</pages>
<location>Doha, Qatar.</location>
<contexts>
<context position="1346" citStr="Stab and Gurevych, 2014" startWordPosition="186" endWordPosition="189">f discourse markers are indicative of either claims or premises and constitute highly predictive features for discriminating between them. 1 Introduction The growing field of argumentation mining in NLP develops methods to automatically analyze argumentative discourse for enhanced Information Extraction. Terminology: We understand argumentation as a rhetorical arrangement of arguments with the intent to convince or persuade the reader of a particular state of affairs. Following previous work in argumentation mining (e.g., (Palau and Moens, 2009; Florou et al., 2013; Peldszus and Stede, 2013a; Stab and Gurevych, 2014)), we define an argument as the pairing of a single claim (an arguable text unit) and a (possibly empty) set of premises, which each either support or attack the claim (Besnard and Hunter, 2008). We subsume claims and premises under the term argument unit (AU). Discourse markers in argumentative discourse: Since an argumentation line can only be captured in the context of a coherent text, argumentation mining is closely related to automated discourse analysis (Cabrio et al., 2013), which aims at identifying discourse functions of text segments, and discourse relations (DRs) between adjacent te</context>
<context position="3173" citStr="Stab and Gurevych (2014)" startWordPosition="485" endWordPosition="488">peating all courses because of only one or two bad grades is arguable. DMs belong to the word classes of conjunctions and adverbs (also called discourse particles) and are semantically characterized in traditional grammar books. The correspondence between DM semantics and DR semantics has received considerable attention in previous research in linguistics, most of which is based on corpora annotated with DRs (Carlson et al., 2003; Wolf and Gibson, 2005; Prasad et al., 2008). In contrast, the role of DMs as potential lexical signals in argumentative discourse is not well-understood, yet. While Stab and Gurevych (2014) used DMs as features for classifying AUs into different types, they did not analyze the semantics of DMs with respect to AU classification or considered different DM resources. As far as we are aware, there is no prior work performing a detailed investigation on the role of DMs as lexical signals for discriminating between the two fundamental argumentative roles of AUs, i.e., between claims and premises. Our contribution: In this paper, we address this gap by analyzing the role of DMs for the automatic discrimination of claims and premises in a 2236 Proceedings of the 2015 Conference on Empir</context>
<context position="7064" citStr="Stab and Gurevych (2014)" startWordPosition="1098" endWordPosition="1101">n tasks, such as abstractive summarization. Taboada et al. (2011) successfully employed discourse particles as features for the calculation of polarity scores in automated sentiment analysis. They focused on particles acting as intensifiers, which modify the semantic intensity of the lexical item they refer to.1 Mukherjee and Bhattacharyya (2012) demonstrated that using discourse connectives as features in a system for sentiment classification of Twitter posts significantly improves classification accuracy over state-of-the art systems not considering DMs as features. In argumentation mining, Stab and Gurevych (2014) experimented with different types of features, including DMs from the PDTB annotation guidelines, to classify text units into the classes non-argumentative, major claim, claim, and premise. While the PDTB DMs appeared to be not helpful for discriminating between argumentative and non-argumentative text units, they were useful to distinguish between the classes premise and claim. Patterson and Kehler (2013) describe a classification model, trained and evaluated on PDTB data, for predicting whether or not a DR is signaled by an explicit DM. The most predictive features in their model are discou</context>
</contexts>
<marker>Stab, Gurevych, 2014</marker>
<rawString>Christian Stab and Iryna Gurevych. 2014. Identifying Argumentative Discourse Structures in Persuasive Essays. In Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 46– 56, Doha, Qatar.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Stede</author>
</authors>
<title>DiMLex: A Lexical Approach to Discourse Markers.</title>
<date>2002</date>
<booktitle>Exploring the Lexicon. Theory and Computation. Edizioni Dell’Orso,</booktitle>
<editor>In Alessandro Lenci and Vittorio Di Tomaso, editors,</editor>
<location>Alessandria.</location>
<contexts>
<context position="12443" citStr="Stede, 2002" startWordPosition="1964" endWordPosition="1965">ng DKPro Statistics (Meyer et al., 2014). 2238 4.1 Semantically Categorized DMs Our first set of experiments aimed at understanding the correspondence of DM semantics and semantic aspects of claims and premises. For this, we used semantically characterized lists of DMs compiled from three different sources: (i) 28 semantically categorized particles from a German grammar (Helbig and Buscha, 1996, pp. 481– 484), (ii) 51 discourse connectives based on a manual translation of the DMs in Appendix B of the PDTB annotation guidelines, and (iii) a large German lexicon of about 170 DMs called DiMLex4 (Stede, 2002). First, we applied a two-sample statistical test to find out if the two classes claim and premise are significantly different regarding the number of occurrences of individual DMs and semantic groups of DMs (based on the semantic information given in our lists). We chose Fisher’s exact test (Fisher, 1932), a non-parametric randomization test that makes no assumptions about the underlying probability distribution of the DMs.5 Lacking DR annotations, we counted surface word forms of single word and continuous multi-word DMs in the AUs annotated in our dataset.6 For each semantically categorized</context>
</contexts>
<marker>Stede, 2002</marker>
<rawString>Manfred Stede. 2002. DiMLex: A Lexical Approach to Discourse Markers. In Alessandro Lenci and Vittorio Di Tomaso, editors, Exploring the Lexicon. Theory and Computation. Edizioni Dell’Orso, Alessandria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Mar´ıa de los Angeles G´omezGonz´alez</author>
</authors>
<title>Discourse markers and coherence relations: Comparison across markers, languages and modalities. Linguistics and the Human Sciences,</title>
<date>2012</date>
<pages>6--1</pages>
<marker>Taboada, G´omezGonz´alez, 2012</marker>
<rawString>Maite Taboada and Mar´ıa de los Angeles G´omezGonz´alez. 2012. Discourse markers and coherence relations: Comparison across markers, languages and modalities. Linguistics and the Human Sciences, 6(1-3):17–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
<author>Julian Brooke</author>
<author>Milan Tofiloski</author>
<author>Kimberly Voll</author>
<author>Manfred Stede</author>
</authors>
<title>Lexiconbased methods for sentiment analysis.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>2</issue>
<contexts>
<context position="6505" citStr="Taboada et al. (2011)" startWordPosition="1018" endWordPosition="1021">tudy of DMs that express concession across English and Spanish in different genres. A classification of DMs signaling concession across English and German is presented by Grote et al. (1997). They also point out the importance of concession in argumentative discourse: DMs expressing concession are often used to introduce counter-arguments in an argumentation line. 2.2 DMs in Classification There is previous work in sentiment classification and argumentation mining using DMs as features, as well as work in predicting DMs for natural language generation tasks, such as abstractive summarization. Taboada et al. (2011) successfully employed discourse particles as features for the calculation of polarity scores in automated sentiment analysis. They focused on particles acting as intensifiers, which modify the semantic intensity of the lexical item they refer to.1 Mukherjee and Bhattacharyya (2012) demonstrated that using discourse connectives as features in a system for sentiment classification of Twitter posts significantly improves classification accuracy over state-of-the art systems not considering DMs as features. In argumentation mining, Stab and Gurevych (2014) experimented with different types of fea</context>
</contexts>
<marker>Taboada, Brooke, Tofiloski, Voll, Stede, 2011</marker>
<rawString>Maite Taboada, Julian Brooke, Milan Tofiloski, Kimberly Voll, and Manfred Stede. 2011. Lexiconbased methods for sentiment analysis. Computational Linguistics, 37(2):267–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maite Taboada</author>
</authors>
<title>Discourse Markers as Signals (or Not) of Rhetorical Relationsteu.</title>
<date>2006</date>
<journal>Journal of Pragmatics,</journal>
<volume>38</volume>
<issue>4</issue>
<contexts>
<context position="4740" citStr="Taboada, 2006" startWordPosition="738" endWordPosition="739">guments, and (ii) performed a detailed investigation of the role of DMs in our annotated dataset which highlights correspondences between DM semantics and semantic properties of claims and premises, and shows that DMs are highly predictive features for automatically discriminating premises and claims. 2 Related Work Related to our work are prior investigations (i) on the relationship of DMs and DRs, and (ii) on the role of DMs in classification tasks. 2.1 Relation of DMs and DRs Previous work on the relation between DMs and DRs is mostly based on corpora annotated with DRs (Wolf et al., 2004; Taboada, 2006; Prasad et al., 2008), most notably the Penn Discourse Treebank (PDTB) for English (Prasad et al., 2008). The PDTB is annotated with DRs, such as contrast or result, and the corresponding DMs, even if they were not realized in the text. For instance, the contrast relation can be expressed by the DMs however and but. DRs that are lexically signaled by DMs in the text are called explicit DRs. Some DMs are highly polysemous, e.g., while appears in 12 DRs in the PDTB. Asr and Demberg (2013) analyzed the DMs and their corresponding DRs annotated in the PDTB and addressed the question, which inform</context>
</contexts>
<marker>Taboada, 2006</marker>
<rawString>Maite Taboada. 2006. Discourse Markers as Signals (or Not) of Rhetorical Relationsteu. Journal of Pragmatics, 38(4):567–592.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Artem Vovk</author>
</authors>
<title>Discovery and Analysis of Public Opinions on Controversial Topics in the Educational Domain. Master’s thesis, Ubiquitious Knowledge Processing Lab,</title>
<date>2013</date>
<location>TU Darmstadt.</location>
<contexts>
<context position="8260" citStr="Vovk, 2013" startWordPosition="1294" endWordPosition="1295">odel are discourse level features that encode dependencies between neighboring DRs given by the overall discourse structure. Other highly predictive features turned out to be the DMs themselves, because DMs vary as to their rates of being realized explicitly.2 3 Annotation Study For our study, we used a dataset of 88 documents in German – mainly news (ca. 83% of the documents) – from seven current topics related to the German educational system (e.g., mainstreaming, staying down at school). The documents were manually selected from a focused crawl and the top 100 search engine hits per topic (Vovk, 2013). 1Amplifiers such as very increase the semantic intensity, while downtoners such as slightly decrease it. 2In the PDTB, DMs are also given for implicit DRs. 2237 Figure 1: Claim-Premise scheme. 3.1 Annotation Scheme Since argumentation theory offers a wide range of models, we performed a pre-study on a held-out development set to develop the annotation scheme. We found that most arguments consisted of adjacent claims and premises, related by a support or attack relation; premises and claims were rarely nested. Therefore, we decided to use a simplified claim-premises scheme (see Figure 1), usi</context>
</contexts>
<marker>Vovk, 2013</marker>
<rawString>Artem Vovk. 2013. Discovery and Analysis of Public Opinions on Controversial Topics in the Educational Domain. Master’s thesis, Ubiquitious Knowledge Processing Lab, TU Darmstadt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
<author>Mark Egg</author>
<author>Valia Kordoni</author>
</authors>
<title>Discourse structure and language technology.</title>
<date>2012</date>
<journal>Natural Language Engineering,</journal>
<volume>18</volume>
<pages>10</pages>
<contexts>
<context position="1979" citStr="Webber et al., 2012" startWordPosition="287" endWordPosition="290">an argument as the pairing of a single claim (an arguable text unit) and a (possibly empty) set of premises, which each either support or attack the claim (Besnard and Hunter, 2008). We subsume claims and premises under the term argument unit (AU). Discourse markers in argumentative discourse: Since an argumentation line can only be captured in the context of a coherent text, argumentation mining is closely related to automated discourse analysis (Cabrio et al., 2013), which aims at identifying discourse functions of text segments, and discourse relations (DRs) between adjacent text segments (Webber et al., 2012). Often, so-called discourse markers (DMs) are used to signal DRs. The following example shows that DMs act as lexical markers in argumentative discourse as well: the DM however (marking the DR contrast) positions the claim in (1) in the overall argumentation line, while in (2), the DMs as (marking reason) and also (marking elaboration) connect the premises with each other and with the claim. (1) However, staying down is pointless from a pedagogic point of view. (2) As the students get frustrated, their performance generally does not improve. Also, the point of repeating all courses because of</context>
</contexts>
<marker>Webber, Egg, Kordoni, 2012</marker>
<rawString>Bonnie Webber, Mark Egg, and Valia Kordoni. 2012. Discourse structure and language technology. Natural Language Engineering, 18:437–490, 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
</authors>
<title>Annotating opinions in the world press.</title>
<date>2003</date>
<booktitle>In Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>13--22</pages>
<location>Hannover, Germany.</location>
<contexts>
<context position="10598" citStr="Wilson and Wiebe, 2003" startWordPosition="1665" endWordPosition="1668">e, 74 % of the tokens are covered by an AU, indicating that the documents are highly argumentative. Ao,t nt Ao,s ns αu all 61.0 44.2 60.9 45.2 40.2 prem. / 62.7 45.1 62.6 46.3 41.7 claims AU / 79.0 50.0 77.0 50.0 56.6 non-AU Table 1: Inter-annotator agreement scores (percentages): Ao – observed agreement, nt– tokenbased kappa; ns– sentence-based kappa; αu– unitized alpha. 3.2 Inter-annotator Agreement Like in other discourse annotation tasks, there is no straightforward way to compute inter-annotator agreement (IAA) due to free annotation boundaries, see for instance (Miltsakaki et al., 2004; Wilson and Wiebe, 2003). We selected sentencebased kappa ns, token-based kappa nt and Krippendorff’s unitized alpha αu as IAA metrics.3 The token-based kappa nt metric treats each token as annotation item and, thereon, calculates Fleiss’ kappa (Fleiss, 1971). The tokens are labeled with the IOB scheme, i.e., every token is annotated as inside an AU (I), beginning of an AU (B) or outside an AU (O). In contrast, Krippendorff’s unitized alpha αu operates on whole annotation spans instead of isolated tokens. For comparison, we also calculated the observed agreement Ao (tokenbased and sentence-based). Table 1 summarizes </context>
</contexts>
<marker>Wilson, Wiebe, 2003</marker>
<rawString>Theresa Wilson and Janyce Wiebe. 2003. Annotating opinions in the world press. In Proceedings of the 4th SIGdial Workshop on Discourse and Dialogue, pages 13–22, Hannover, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Wolf</author>
<author>Edward Gibson</author>
</authors>
<title>Representing Discourse Coherence: A Corpus-Based Study.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="3005" citStr="Wolf and Gibson, 2005" startWordPosition="458" endWordPosition="461">er, staying down is pointless from a pedagogic point of view. (2) As the students get frustrated, their performance generally does not improve. Also, the point of repeating all courses because of only one or two bad grades is arguable. DMs belong to the word classes of conjunctions and adverbs (also called discourse particles) and are semantically characterized in traditional grammar books. The correspondence between DM semantics and DR semantics has received considerable attention in previous research in linguistics, most of which is based on corpora annotated with DRs (Carlson et al., 2003; Wolf and Gibson, 2005; Prasad et al., 2008). In contrast, the role of DMs as potential lexical signals in argumentative discourse is not well-understood, yet. While Stab and Gurevych (2014) used DMs as features for classifying AUs into different types, they did not analyze the semantics of DMs with respect to AU classification or considered different DM resources. As far as we are aware, there is no prior work performing a detailed investigation on the role of DMs as lexical signals for discriminating between the two fundamental argumentative roles of AUs, i.e., between claims and premises. Our contribution: In th</context>
</contexts>
<marker>Wolf, Gibson, 2005</marker>
<rawString>Florian Wolf and Edward Gibson. 2005. Representing Discourse Coherence: A Corpus-Based Study. Computational Linguistics, 31(2):249–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Wolf</author>
<author>Edward Gibson</author>
<author>Amy Fisher</author>
<author>Meredith Knight</author>
</authors>
<title>Discourse Graphbank. Linguistic Data Consortium.</title>
<date>2004</date>
<contexts>
<context position="4725" citStr="Wolf et al., 2004" startWordPosition="734" endWordPosition="737">s documents with arguments, and (ii) performed a detailed investigation of the role of DMs in our annotated dataset which highlights correspondences between DM semantics and semantic properties of claims and premises, and shows that DMs are highly predictive features for automatically discriminating premises and claims. 2 Related Work Related to our work are prior investigations (i) on the relationship of DMs and DRs, and (ii) on the role of DMs in classification tasks. 2.1 Relation of DMs and DRs Previous work on the relation between DMs and DRs is mostly based on corpora annotated with DRs (Wolf et al., 2004; Taboada, 2006; Prasad et al., 2008), most notably the Penn Discourse Treebank (PDTB) for English (Prasad et al., 2008). The PDTB is annotated with DRs, such as contrast or result, and the corresponding DMs, even if they were not realized in the text. For instance, the contrast relation can be expressed by the DMs however and but. DRs that are lexically signaled by DMs in the text are called explicit DRs. Some DMs are highly polysemous, e.g., while appears in 12 DRs in the PDTB. Asr and Demberg (2013) analyzed the DMs and their corresponding DRs annotated in the PDTB and addressed the questio</context>
</contexts>
<marker>Wolf, Gibson, Fisher, Knight, 2004</marker>
<rawString>Florian Wolf, Edward Gibson, Amy Fisher, and Meredith Knight. 2004. Discourse Graphbank. Linguistic Data Consortium.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>