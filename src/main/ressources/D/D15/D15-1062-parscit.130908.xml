<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.041083">
<title confidence="0.9986035">
Semantic Relation Classification via Convolutional Neural Networks with
Simple Negative Sampling
</title>
<author confidence="0.99901">
Kun Xu1, Yansong Feng∗1, Songfang Huang2 and Dongyan Zhao1
</author>
<affiliation confidence="0.878655">
1ICST, Peking University, Beijing, China
2IBM China Research Lab, Beijing, China
</affiliation>
<email confidence="0.97005">
{xukun,fengyansong,zhaodongyan}@pku.edu.cn
huangsf@cn.ibm.com
</email>
<sectionHeader confidence="0.993807" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999324888888889">
Syntactic features play an essential role in
identifying relationship in a sentence. Pre-
vious neural network models directly work
on raw word sequences or constituent
parse trees, thus often suffer from irrele-
vant information introduced when subjects
and objects are in a long distance. In this
paper, we propose to learn more robust re-
lation representations from shortest depen-
dency paths through a convolution neu-
ral network. We further take the relation
directionality into account and propose a
straightforward negative sampling strategy
to improve the assignment of subjects and
objects. Experimental results show that
our method outperforms the state-of-the-
art approaches on the SemEval-2010 Task
8 dataset.
</bodyText>
<sectionHeader confidence="0.998971" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999992081967214">
The relation extraction (RE) task can be defined as
follows: given a sentence S with a pair of nomi-
nals e1 and e2, we aim to identify the relationship
between e1 and e2. RE is typically investigated
in a classification style, where many features have
been proposed, e.g., Hendrickx et al. (2010) de-
signed 16 types of features including POS, Word-
Net, FrameNet, dependency parse features, etc.
Among them, syntactic features are considered to
bring significant improvements in extraction accu-
racy (Bunescu and Mooney, 2005a). Earlier at-
tempts to encode syntactic information are mainly
kernel-based methods, such as the convolution tree
kernel (Qian et al., 2008), subsequence kernel
(Bunescu and Mooney, 2005b), and dependency
tree kernel (Bunescu and Mooney, 2005a).
With the recent success of neural networks in
natural language processing, different neural net-
work models are proposed to learn syntactic fea-
tures from raw sequences of words or constituent
parse trees (Zeng et al., 2014; Socher et al., 2012),
which have been proved effective, but, often suf-
fer from irrelevant subsequences or clauses, espe-
cially when subjects and objects are in a longer
distance. For example, in the sentence, “The
[singer]e1 , who performed three of the nominated
songs, also caused a [commotion]e2 on the red
carpet”, the who clause is used to modify subject
e1, but is unrelated to the Cause-Effect relation-
ship between singer and commotion. Incorporat-
ing such information into the model will hurt the
extraction performance. We therefore propose to
learn a more robust relation representation from
a convolution neural network (CNN) model that
works on the simple dependency path between
subjects and objects, which naturally characterizes
the relationship between two nominals and avoids
negative effects from other irrelevant chunks or
clauses.
Our second contribution is the introduction of
a negative sampling strategy into the CNN mod-
els to address the relation directionality, i.e., prop-
erly assigning the subject and object within a re-
lationship. In the above singer example, (singer,
commotion) hold the Cause-Effect relation, while
(commotion, singer) not. Previous works (Liu
et al., 2015) do not fully investigate the differ-
ences between subjects and objects in the utter-
ance, and simply transform a (K+1)-relation task
into a (2×K+1) classification task, where 1 is the
other relation. Interestingly, we find that depen-
dency paths naturally offer the relative positions
of subjects and objects through the path directions.
In this paper, we propose to model the relation di-
rectionality by exploiting the dependency path to
learn the assignments of subjects and objects us-
ing a straightforward negative sampling method,
which adopts the shortest dependency path from
the object to the subject as a negative sample. Ex-
perimental results show that the negative sampling
method significantly improves the performance,
</bodyText>
<page confidence="0.977042">
536
</page>
<note confidence="0.6632175">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 536–540,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.9823095">
and our model outperforms the-state-of-the-art
methods on the SemEval-2010 Task 8 dataset.
</bodyText>
<sectionHeader confidence="0.921029" genericHeader="method">
2 The Shortest Path Hypothesis
</sectionHeader>
<bodyText confidence="0.998836647058823">
If e1 and e2 are two nominals mentioned in the
same sentence, we assume that the shortest path
between e1 and e2 describes their relationship.
This is because (1) if e1 and e2 are arguments of
the same predicate, then their shortest path should
pass through that predicate; (2) if e1 and e2 belong
to different predicate-argument structures, their
shortest path will pass through a sequence of pred-
icates, and any consecutive predicates will share
a common argument. Note that, the order of the
predicates on the path indicates the proper assign-
ments of subjects and objects for that relation. For
example, in Figure 1, the dependency path consec-
utively passes through carried and receives, which
together implies that in the Instrument-Agency re-
lation, the subject and object play a sender and re-
ceiver role, respectively.
</bodyText>
<figureCaption confidence="0.8651805">
Figure 2: Architecture of the convolution neural
network.
</figureCaption>
<sectionHeader confidence="0.963656" genericHeader="method">
3 A Convolutional Neural Network
Model
</sectionHeader>
<bodyText confidence="0.99181687037037">
Our model successively takes the shortest depen-
dency path (i.e, the words, dependency edge direc-
tions, and dependency labels) from the subject to
the object as input, passes it through the lookup
table layer, produces local features around each
node on the dependency path, and combines these
features into a global feature vector that are then
fed to a softmax classifier. Each dimension of the
output vector indicates the confidence score of the
corresponding relation.
In the lookup table step, each node (i.e. word,
label or arrow) in the dependency path is trans-
formed into a vector by looking up the embedding
matrix We E Rd×|V|, where d is the dimension of
a vector and V is a set of all nodes we consider.
Convolution To capture the local features
around each node of the dependency path, we con-
sider a fixed size window of nodes around each
node in the window processing component, pro-
ducing a matrix of node features of fixed size
d,,, x 1, where d,,, = d x w and w is the window
size. This matrix can be built by concatenating
the vectors of nodes within the window, which are
then fed to the convolutional layer.
In the convolutional layer, we use a linear trans-
formation W1 E Rn1×d,,, to extract local features
around each window of the given sequence, where
n1 is the size of hidden layer 1. The resulting ma-
trix Z has size of n1 x t, where t is the number of
nodes in the input dependency path.
We can see that Z captures local contextual in-
formation in the dependency path. However, iden-
tifying a relationship requires considerations for
the whole dependency path. We therefore perform
a max pooling over Z to produce a global feature
vector in order to capture the most useful local
features produced by the convolutional layer (Col-
lobert et al., 2011), which has a fixed size of n1,
independent of the dependency path length.
Dependency based Relation Representation
To extract more meaningful features, we choose
hyperbolic tanh as the non-linearity function in the
second hidden layer, which has the advantage of
being slightly cheaper to compute, while leaving
the generalization performance unchanged. W2 E
Rn2×n1 is the linear transformation matrix, where
n2 is the size of hidden layer 2. The output vec-
tor can be considered as higher level syntactic fea-
tures, which is then fed to a softmax classifier.
Objective Function and Learning The softmax
classifier is used to predict a K-class distribution
d(x), where K is the size of all possible rela-
tion types, and the transformation matrix is W3 E
RK×n2. We denote t(x) E RK×1 as the target
</bodyText>
<figure confidence="0.974600411764706">
burst nsubjpass caused prep by dobj pressure
Input
Hidden layer 2
Dependency Feature
Window Processing
Hidden layer 1
Output
Convolution
Lookup Table
W1 x
tanh(W2 x )
max pooling
W3 x
537
The recipient receives the call through a miniature radio receiver carried on his person
receiver Instrument-Agency recipient
receiver carried radio through receives recipient
</figure>
<figureCaption confidence="0.997393">
Figure 1: The shortest dependency path representation for an example sentence from SemEval-08.
</figureCaption>
<table confidence="0.9998005">
Train Strategy Test Strategy F1(%)
Blind Blind 79.3
Sighted Blind 81.3
Sighted Sighted 89.2
</table>
<tableCaption confidence="0.807712">
Table 1: Performances on the development set
with different train and testing strategies.
</tableCaption>
<bodyText confidence="0.9989576">
distribution vector1: the entry tk(x) is the proba-
bility that the dependency path describes the k-th
relation. We compute the cross entropy error be-
tween t(x) and d(x), and further define the objec-
tive function over all training data:
</bodyText>
<equation confidence="0.999582333333333">
K
J(0) = − 1: 1: tk(x) log dk(x) + A||0||2
x k=1
</equation>
<bodyText confidence="0.999851285714286">
where 0 = (We, W1, W2, W3) is the set of model
parameters to be learned, and A is a vector of reg-
ularization parameters. The model parameters 0
can be efficiently computed via backpropagation
through network structures. To minimize J(0),
we apply stochastic gradient descent (SGD) with
AdaGrad (Duchi et al., 2011) in our experiments.
</bodyText>
<sectionHeader confidence="0.996512" genericHeader="method">
4 Negative Sampling
</sectionHeader>
<bodyText confidence="0.985522583333333">
We start by presenting three pilot experiments on
the development set. In the first one, we assume
that the assignment of the subject and object for
a relation is not given (blind), we simply extract
features from e1 to e2, and test it in a blind set-
ting as well. In the second one, we assume that
the assignment is given (sighted) during training,
but still blind in the test phase. The last one is as-
sumed to give the assignment during both training
and test steps. The results are listed in Table 1.
The third experiment can be seen as an upper
bound, where we do not need to worry about the
assignments of subjects and objects. By com-
paring the first and the second one, we can see
that when adding assignment information during
training, our model can be significantly improved,
1Note that, there may be more than one relation existing
between two nominals. A dependency path thus may corre-
spond to multiple relations.
indicating that our dependency based representa-
tion can be used to learn the assignments of sub-
jects/objects, and injecting better understandings
of such assignments during training is crucial to
the performance. We admit that models with more
complex structures can better handle these con-
siderations. However, we find that this can be
achieved by simply feeding typical negative sam-
ples to the model and let the model learn from such
negative examples to correctly choose the right as-
signments of subjects and objects. In practice, we
can treat the opposite assignments of subjects and
the objects as negative examples. Note that, the
dependency path of the wrong assignment is dif-
ferent from that of the correct assignment, which
essentially offers the information for the model to
learn to distinguish the subject and the object.
</bodyText>
<sectionHeader confidence="0.997756" genericHeader="method">
5 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.99999184">
We evaluate our model on the SemEval-2010 Task
8 (Hendrickx et al., 2010), which contains 10,717
annotated examples, including 8,000 instances for
training and 2,717 for test. We randomly sampled
2,182 samples from the training data for valida-
tion.
Given a sentence, we first find the shortest de-
pendency path connecting two marked nominals,
resulting in two dependency paths corresponding
to two opposite subject/object directions, and then
make predictions for the two paths, respectively.
We choose the relation other if and only if both
predictions are other. And for the rest cases, we
choose the non-other relation with highest confi-
dence as the output, since ideally, for a non-other
instance, our model will output the correct label
for the right subject/object direction and an other
label for the wrong direction. We evaluate our
models by macro-averaged F1 using the official
evaluation script.
We initialized We with 50-dimensional word
vectors trained by Turian et al. (2010). We tuned
the hyper parameters using the development set for
each experimental setting. The hyper parameters
include w, n1, n2, and regularization parameters
</bodyText>
<page confidence="0.99513">
538
</page>
<table confidence="0.9998715">
Method Feature Sets F1
SVM 16 types of features 82.2
RNN - 74.8
+POS, NER, WordNet 77.6
MVRNN - 79.1
+POS, NER, WordNet 82.4
CNN - 78.9
(Zeng et al., 2014) +WordNet,words around nominals 82.7
DepNN +NER 83.6
depCNN - 81.3
depLCNN - 81.9
depLCNN +WordNet,words around nominals 83.7
depLCNN+NS - 84.0
+WordNet,words around nominals 85.6
</table>
<tableCaption confidence="0.9942125">
Table 2: Comparisons of our models with other
methods on the SemEval 2010 task 8.
</tableCaption>
<table confidence="0.997039">
Negative sampling schemes F1
No negative examples 81.3
Randomly sampled negative examples from NYT 83.5
Dependency paths from the object to subject 85.4
</table>
<tableCaption confidence="0.863178">
Table 3: Comparisons of different negtive sam-
pling methods on the development set.
</tableCaption>
<bodyText confidence="0.999331178082192">
for We, W1, W2 and W3. The best setting was ob-
tained with the values: 3, 200, 100, 10−4, 10−3,
10−4 and 2 × 10−3, respectively.
Results and Discussion Table 2 summarizes the
performances of our model, depLCNN+NS(+),
and state-of-the-art models, SVM (Hendrickx et
al., 2010), RNN, MV-RNN (Socher et al., 2012),
CNN (Zeng et al., 2014) and DepNN (Liu et al.,
2015). For fair comparisons, we also add two
types of lexical features, WordNet hypernyms and
words around nominals, as part of input vector to
the final softmax layer.
We can see that our vanilla depLCNN+NS,
without extra lexical features, still outperforms, by
a large margin, previously reported best systems,
MVRNN+ and CNN+, both of which have taken
extra lexical features into account, showing that
our treatment to dependency path can learn a ro-
bust and effective relation representation. When
augmented with similar lexical features, our de-
pLCNN+NS further improves by 1.6%, signifi-
cantly better than any other systems.
Let us first see the comparisons among plain
versions of depLCNN (taking both dependency di-
rections and labels into account), depCNN (con-
sidering the directions of dependency edges only),
MVRNN and CNN, which all work in a 2×K+1
fashion. We can see that the both of our depCNN
and depLCNN outperforms MVRNN and CNN by
at least 2.2%, indicating that our treatment is better
than previous conventions in capturing syntactic
structures for relation extraction. And note that de-
pLCNN, with extra considerations for dependency
labels, performs even better than depCNN, show-
ing that dependency labels offer more discrimina-
tive information that benefits the relation extrac-
tion task.
And when we compare plain depLCNN and
depLCNN+NS (without lexical features), we can
see that our Negative Sampling strategy brings an
improvement of 2.1% in F1. When both of the
two models are augmented with extra lexical fea-
tures, our NS strategy still gives an improvement
of 1.9%. These comparisons further show that our
NS strategy can drive our model to learn proper
assignments of subjects/objects for a relation.
Next, we will have a close look at the effect
of our Negative Sampling method. We conduct
additional experiments on the development set to
compare two different negative sampling methods.
As a baseline, we randomly sampled 8,000 nega-
tive examples from the NYT dataset (Chen et al.,
2014). For our proposed NS, we create a nega-
tive example from each non-other instance in the
training set, 6,586 in total. As shown in Table 2,
it is no doubt that introducing more negative ex-
amples improves the performances. We can see
that our model still benefits from the randomly
sampled negative examples, which may help our
model learn to refine the margin between the pos-
itive and negative examples. However, with sim-
ilar amount of negative examples, treating the re-
versed dependency paths from objects to subjects
as negative examples can achieve a better perfor-
mance (85.4% F1), improving random samples by
1.9%. This again proves that dependency paths
provide useful clues to reveal the assignments of
subjects and objects, and a model can learn from
such reversed paths as negative examples to make
correct assignments. Beyond the relation extrac-
tion task, we believed the proposed Negative Sam-
pling method has the potential to benefit other
NLP tasks, which we leave for future work.
</bodyText>
<sectionHeader confidence="0.999486" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9998835">
In this paper, we exploit a convolution neural net-
work model to learn more robust and effective re-
lation representations from shortest dependency
paths for relation extraction. We further pro-
pose a simple negative sampling method to help
make correct assignments for subjects and objects
</bodyText>
<page confidence="0.994375">
539
</page>
<bodyText confidence="0.9997726">
within a relationship. Experimental results show
that our model significantly outperforms state-of-
the-art systems and our treatment to dependency
paths can well capture the syntactic features for
relation extraction.
</bodyText>
<sectionHeader confidence="0.995491" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.992437222222222">
We would like to Sheng Zhang, Weiwei Sun
and Liwei Chen for their helpful discussions.
This work was supported by National High
Technology R&amp;D Program of China (Grant No.
2015AA015403, 2014AA015102), Natural Sci-
ence Foundation of China (Grant No. 61202233,
61272344, 61370055) and the joint project with
IBM Research. Any correspondence please refer
to Yansong Feng.
</bodyText>
<sectionHeader confidence="0.998108" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996871445945946">
Razvan C. Bunescu and Raymond J. Mooney. 2005a.
A shortest path dependency kernel for relation ex-
traction. In HLT/EMNLP 2005, Human Language
Technology Conference and Conference on Empiri-
cal Methods in Natural Language Processing, Pro-
ceedings of the Conference, 6-8 October 2005, Van-
couver, British Columbia, Canada.
Razvan C. Bunescu and Raymond J. Mooney. 2005b.
Subsequence kernels for relation extraction. In
Advances in Neural Information Processing Sys-
tems 18 [Neural Information Processing Systems,
NIPS 2005, December 5-8, 2005, Vancouver, British
Columbia, Canada], pages 171–178.
Liwei Chen, Yansong Feng, Songfang Huang, Yong
Qin, and Dongyan Zhao. 2014. Encoding relation
requirements for relation extraction via joint infer-
ence. In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics, ACL
2014, June 22-27, 2014, Baltimore, MD, USA, Vol-
ume 1: Long Papers, pages 818–827.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel P. Kuksa.
2011. Natural language processing (almost) from
scratch. Journal of Machine Learning Research,
12:2493–2537.
John C. Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. Journal of Machine
Learning Research, 12:2121–2159.
Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva,
Preslav Nakov, Diarmuid O´ S´eaghdha, Sebastian
Pad´o, Marco Pennacchiotti, Lorenza Romano, and
Stan Szpakowicz. 2010. Semeval-2010 task
8: Multi-way classification of semantic relations
between pairs of nominals. In Proceedings of
SemEval-2, Uppsala, Sweden.
Yang Liu, Furu Wei, Sujian Li, Heng Ji, Ming Zhou,
and Houfeng WANG. 2015. A dependency-based
neural network for relation classification. In Pro-
ceedings of the 53rd Annual Meeting of the Associ-
ation for Computational Linguistics and the 7th In-
ternational Joint Conference on Natural Language
Processing (Volume 2: Short Papers), pages 285–
290, Beijing, China, July. Association for Computa-
tional Linguistics.
Longhua Qian, Guodong Zhou, Fang Kong, Qiaom-
ing Zhu, and Peide Qian. 2008. Exploiting con-
stituent dependencies for tree kernel-based semantic
relation extraction. In COLING 2008, 22nd Inter-
national Conference on Computational Linguistics,
Proceedings of the Conference, 18-22 August 2008,
Manchester, UK, pages 697–704.
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic com-
positionality through recursive matrix-vector spaces.
In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learn-
ing, EMNLP-CoNLL 2012, July 12-14, 2012, Jeju
Island, Korea, pages 1201–1211.
Joseph P. Turian, Lev-Arie Ratinov, and Yoshua Ben-
gio. 2010. Word representations: A simple and gen-
eral method for semi-supervised learning. In ACL
2010, Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics, July 11-
16, 2010, Uppsala, Sweden, pages 384–394.
Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou,
and Jun Zhao. 2014. Relation classification via con-
volutional deep neural network. In Proceedings of
COLING 2014, the 25th International Conference
on Computational Linguistics: Technical Papers,
pages 2335–2344, Dublin, Ireland, August. Dublin
City University and Association for Computational
Linguistics.
</reference>
<page confidence="0.996981">
540
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.264619">
<title confidence="0.998462">Semantic Relation Classification via Convolutional Neural Networks with Simple Negative Sampling</title>
<author confidence="0.97778">Yansong Songfang</author>
<author confidence="0.97778">Dongyan</author>
<affiliation confidence="0.999959">Peking University, Beijing,</affiliation>
<address confidence="0.493615">China Research Lab, Beijing,</address>
<email confidence="0.999734">huangsf@cn.ibm.com</email>
<abstract confidence="0.966214263157895">Syntactic features play an essential role in identifying relationship in a sentence. Previous neural network models directly work on raw word sequences or constituent parse trees, thus often suffer from irrelevant information introduced when subjects and objects are in a long distance. In this paper, we propose to learn more robust relation representations from shortest dependency paths through a convolution neural network. We further take the relation directionality into account and propose a straightforward negative sampling strategy to improve the assignment of subjects and objects. Experimental results show that our method outperforms the state-of-theart approaches on the SemEval-2010 Task 8 dataset.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference,</booktitle>
<pages>6--8</pages>
<location>Vancouver, British Columbia, Canada.</location>
<contexts>
<context position="1557" citStr="Bunescu and Mooney, 2005" startWordPosition="224" endWordPosition="227">ur method outperforms the state-of-theart approaches on the SemEval-2010 Task 8 dataset. 1 Introduction The relation extraction (RE) task can be defined as follows: given a sentence S with a pair of nominals e1 and e2, we aim to identify the relationship between e1 and e2. RE is typically investigated in a classification style, where many features have been proposed, e.g., Hendrickx et al. (2010) designed 16 types of features including POS, WordNet, FrameNet, dependency parse features, etc. Among them, syntactic features are considered to bring significant improvements in extraction accuracy (Bunescu and Mooney, 2005a). Earlier attempts to encode syntactic information are mainly kernel-based methods, such as the convolution tree kernel (Qian et al., 2008), subsequence kernel (Bunescu and Mooney, 2005b), and dependency tree kernel (Bunescu and Mooney, 2005a). With the recent success of neural networks in natural language processing, different neural network models are proposed to learn syntactic features from raw sequences of words or constituent parse trees (Zeng et al., 2014; Socher et al., 2012), which have been proved effective, but, often suffer from irrelevant subsequences or clauses, especially when</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2005a. A shortest path dependency kernel for relation extraction. In HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference, 6-8 October 2005, Vancouver, British Columbia, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Raymond J Mooney</author>
</authors>
<title>Subsequence kernels for relation extraction.</title>
<date>2005</date>
<booktitle>In Advances in Neural Information Processing Systems 18 [Neural Information Processing Systems, NIPS</booktitle>
<pages>171--178</pages>
<location>Vancouver, British Columbia, Canada],</location>
<contexts>
<context position="1557" citStr="Bunescu and Mooney, 2005" startWordPosition="224" endWordPosition="227">ur method outperforms the state-of-theart approaches on the SemEval-2010 Task 8 dataset. 1 Introduction The relation extraction (RE) task can be defined as follows: given a sentence S with a pair of nominals e1 and e2, we aim to identify the relationship between e1 and e2. RE is typically investigated in a classification style, where many features have been proposed, e.g., Hendrickx et al. (2010) designed 16 types of features including POS, WordNet, FrameNet, dependency parse features, etc. Among them, syntactic features are considered to bring significant improvements in extraction accuracy (Bunescu and Mooney, 2005a). Earlier attempts to encode syntactic information are mainly kernel-based methods, such as the convolution tree kernel (Qian et al., 2008), subsequence kernel (Bunescu and Mooney, 2005b), and dependency tree kernel (Bunescu and Mooney, 2005a). With the recent success of neural networks in natural language processing, different neural network models are proposed to learn syntactic features from raw sequences of words or constituent parse trees (Zeng et al., 2014; Socher et al., 2012), which have been proved effective, but, often suffer from irrelevant subsequences or clauses, especially when</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>Razvan C. Bunescu and Raymond J. Mooney. 2005b. Subsequence kernels for relation extraction. In Advances in Neural Information Processing Systems 18 [Neural Information Processing Systems, NIPS 2005, December 5-8, 2005, Vancouver, British Columbia, Canada], pages 171–178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liwei Chen</author>
<author>Yansong Feng</author>
<author>Songfang Huang</author>
<author>Yong Qin</author>
<author>Dongyan Zhao</author>
</authors>
<title>Encoding relation requirements for relation extraction via joint inference.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL</booktitle>
<volume>Volume</volume>
<pages>818--827</pages>
<location>Baltimore, MD, USA,</location>
<contexts>
<context position="14996" citStr="Chen et al., 2014" startWordPosition="2410" endWordPosition="2413">hat our Negative Sampling strategy brings an improvement of 2.1% in F1. When both of the two models are augmented with extra lexical features, our NS strategy still gives an improvement of 1.9%. These comparisons further show that our NS strategy can drive our model to learn proper assignments of subjects/objects for a relation. Next, we will have a close look at the effect of our Negative Sampling method. We conduct additional experiments on the development set to compare two different negative sampling methods. As a baseline, we randomly sampled 8,000 negative examples from the NYT dataset (Chen et al., 2014). For our proposed NS, we create a negative example from each non-other instance in the training set, 6,586 in total. As shown in Table 2, it is no doubt that introducing more negative examples improves the performances. We can see that our model still benefits from the randomly sampled negative examples, which may help our model learn to refine the margin between the positive and negative examples. However, with similar amount of negative examples, treating the reversed dependency paths from objects to subjects as negative examples can achieve a better performance (85.4% F1), improving random</context>
</contexts>
<marker>Chen, Feng, Huang, Qin, Zhao, 2014</marker>
<rawString>Liwei Chen, Yansong Feng, Songfang Huang, Yong Qin, and Dongyan Zhao. 2014. Encoding relation requirements for relation extraction via joint inference. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, ACL 2014, June 22-27, 2014, Baltimore, MD, USA, Volume 1: Long Papers, pages 818–827.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel P Kuksa</author>
</authors>
<title>Natural language processing (almost) from scratch.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2493</pages>
<contexts>
<context position="6964" citStr="Collobert et al., 2011" startWordPosition="1099" endWordPosition="1103">layer, we use a linear transformation W1 E Rn1×d,,, to extract local features around each window of the given sequence, where n1 is the size of hidden layer 1. The resulting matrix Z has size of n1 x t, where t is the number of nodes in the input dependency path. We can see that Z captures local contextual information in the dependency path. However, identifying a relationship requires considerations for the whole dependency path. We therefore perform a max pooling over Z to produce a global feature vector in order to capture the most useful local features produced by the convolutional layer (Collobert et al., 2011), which has a fixed size of n1, independent of the dependency path length. Dependency based Relation Representation To extract more meaningful features, we choose hyperbolic tanh as the non-linearity function in the second hidden layer, which has the advantage of being slightly cheaper to compute, while leaving the generalization performance unchanged. W2 E Rn2×n1 is the linear transformation matrix, where n2 is the size of hidden layer 2. The output vector can be considered as higher level syntactic features, which is then fed to a softmax classifier. Objective Function and Learning The softm</context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel P. Kuksa. 2011. Natural language processing (almost) from scratch. Journal of Machine Learning Research, 12:2493–2537.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Duchi</author>
<author>Elad Hazan</author>
<author>Yoram Singer</author>
</authors>
<title>Adaptive subgradient methods for online learning and stochastic optimization.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2121</pages>
<contexts>
<context position="8998" citStr="Duchi et al., 2011" startWordPosition="1431" endWordPosition="1434"> testing strategies. distribution vector1: the entry tk(x) is the probability that the dependency path describes the k-th relation. We compute the cross entropy error between t(x) and d(x), and further define the objective function over all training data: K J(0) = − 1: 1: tk(x) log dk(x) + A||0||2 x k=1 where 0 = (We, W1, W2, W3) is the set of model parameters to be learned, and A is a vector of regularization parameters. The model parameters 0 can be efficiently computed via backpropagation through network structures. To minimize J(0), we apply stochastic gradient descent (SGD) with AdaGrad (Duchi et al., 2011) in our experiments. 4 Negative Sampling We start by presenting three pilot experiments on the development set. In the first one, we assume that the assignment of the subject and object for a relation is not given (blind), we simply extract features from e1 to e2, and test it in a blind setting as well. In the second one, we assume that the assignment is given (sighted) during training, but still blind in the test phase. The last one is assumed to give the assignment during both training and test steps. The results are listed in Table 1. The third experiment can be seen as an upper bound, wher</context>
</contexts>
<marker>Duchi, Hazan, Singer, 2011</marker>
<rawString>John C. Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. Journal of Machine Learning Research, 12:2121–2159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Iris Hendrickx</author>
<author>Su Nam Kim</author>
<author>Zornitsa Kozareva</author>
<author>Preslav Nakov</author>
<author>Diarmuid O´ S´eaghdha</author>
<author>Sebastian Pad´o</author>
<author>Marco Pennacchiotti</author>
<author>Lorenza Romano</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals.</title>
<date>2010</date>
<booktitle>In Proceedings of SemEval-2,</booktitle>
<location>Uppsala,</location>
<marker>Hendrickx, Kim, Kozareva, Nakov, S´eaghdha, Pad´o, Pennacchiotti, Romano, Szpakowicz, 2010</marker>
<rawString>Iris Hendrickx, Su Nam Kim, Zornitsa Kozareva, Preslav Nakov, Diarmuid O´ S´eaghdha, Sebastian Pad´o, Marco Pennacchiotti, Lorenza Romano, and Stan Szpakowicz. 2010. Semeval-2010 task 8: Multi-way classification of semantic relations between pairs of nominals. In Proceedings of SemEval-2, Uppsala, Sweden.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yang Liu</author>
<author>Furu Wei</author>
<author>Sujian Li</author>
<author>Heng Ji</author>
<author>Ming Zhou</author>
<author>Houfeng WANG</author>
</authors>
<title>A dependency-based neural network for relation classification.</title>
<date>2015</date>
<booktitle>In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers),</booktitle>
<pages>285--290</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Beijing, China,</location>
<contexts>
<context position="3228" citStr="Liu et al., 2015" startWordPosition="480" endWordPosition="483">esentation from a convolution neural network (CNN) model that works on the simple dependency path between subjects and objects, which naturally characterizes the relationship between two nominals and avoids negative effects from other irrelevant chunks or clauses. Our second contribution is the introduction of a negative sampling strategy into the CNN models to address the relation directionality, i.e., properly assigning the subject and object within a relationship. In the above singer example, (singer, commotion) hold the Cause-Effect relation, while (commotion, singer) not. Previous works (Liu et al., 2015) do not fully investigate the differences between subjects and objects in the utterance, and simply transform a (K+1)-relation task into a (2×K+1) classification task, where 1 is the other relation. Interestingly, we find that dependency paths naturally offer the relative positions of subjects and objects through the path directions. In this paper, we propose to model the relation directionality by exploiting the dependency path to learn the assignments of subjects and objects using a straightforward negative sampling method, which adopts the shortest dependency path from the object to the sub</context>
<context position="12989" citStr="Liu et al., 2015" startWordPosition="2089" endWordPosition="2092">mEval 2010 task 8. Negative sampling schemes F1 No negative examples 81.3 Randomly sampled negative examples from NYT 83.5 Dependency paths from the object to subject 85.4 Table 3: Comparisons of different negtive sampling methods on the development set. for We, W1, W2 and W3. The best setting was obtained with the values: 3, 200, 100, 10−4, 10−3, 10−4 and 2 × 10−3, respectively. Results and Discussion Table 2 summarizes the performances of our model, depLCNN+NS(+), and state-of-the-art models, SVM (Hendrickx et al., 2010), RNN, MV-RNN (Socher et al., 2012), CNN (Zeng et al., 2014) and DepNN (Liu et al., 2015). For fair comparisons, we also add two types of lexical features, WordNet hypernyms and words around nominals, as part of input vector to the final softmax layer. We can see that our vanilla depLCNN+NS, without extra lexical features, still outperforms, by a large margin, previously reported best systems, MVRNN+ and CNN+, both of which have taken extra lexical features into account, showing that our treatment to dependency path can learn a robust and effective relation representation. When augmented with similar lexical features, our depLCNN+NS further improves by 1.6%, significantly better t</context>
</contexts>
<marker>Liu, Wei, Li, Ji, Zhou, WANG, 2015</marker>
<rawString>Yang Liu, Furu Wei, Sujian Li, Heng Ji, Ming Zhou, and Houfeng WANG. 2015. A dependency-based neural network for relation classification. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 2: Short Papers), pages 285– 290, Beijing, China, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Longhua Qian</author>
<author>Guodong Zhou</author>
<author>Fang Kong</author>
<author>Qiaoming Zhu</author>
<author>Peide Qian</author>
</authors>
<title>Exploiting constituent dependencies for tree kernel-based semantic relation extraction.</title>
<date>2008</date>
<booktitle>In COLING 2008, 22nd International Conference on Computational Linguistics, Proceedings of the Conference,</booktitle>
<pages>18--22</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="1698" citStr="Qian et al., 2008" startWordPosition="245" endWordPosition="248">fined as follows: given a sentence S with a pair of nominals e1 and e2, we aim to identify the relationship between e1 and e2. RE is typically investigated in a classification style, where many features have been proposed, e.g., Hendrickx et al. (2010) designed 16 types of features including POS, WordNet, FrameNet, dependency parse features, etc. Among them, syntactic features are considered to bring significant improvements in extraction accuracy (Bunescu and Mooney, 2005a). Earlier attempts to encode syntactic information are mainly kernel-based methods, such as the convolution tree kernel (Qian et al., 2008), subsequence kernel (Bunescu and Mooney, 2005b), and dependency tree kernel (Bunescu and Mooney, 2005a). With the recent success of neural networks in natural language processing, different neural network models are proposed to learn syntactic features from raw sequences of words or constituent parse trees (Zeng et al., 2014; Socher et al., 2012), which have been proved effective, but, often suffer from irrelevant subsequences or clauses, especially when subjects and objects are in a longer distance. For example, in the sentence, “The [singer]e1 , who performed three of the nominated songs, a</context>
</contexts>
<marker>Qian, Zhou, Kong, Zhu, Qian, 2008</marker>
<rawString>Longhua Qian, Guodong Zhou, Fang Kong, Qiaoming Zhu, and Peide Qian. 2008. Exploiting constituent dependencies for tree kernel-based semantic relation extraction. In COLING 2008, 22nd International Conference on Computational Linguistics, Proceedings of the Conference, 18-22 August 2008, Manchester, UK, pages 697–704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL 2012,</booktitle>
<pages>1201--1211</pages>
<location>Jeju Island,</location>
<contexts>
<context position="2047" citStr="Socher et al., 2012" startWordPosition="299" endWordPosition="302">. Among them, syntactic features are considered to bring significant improvements in extraction accuracy (Bunescu and Mooney, 2005a). Earlier attempts to encode syntactic information are mainly kernel-based methods, such as the convolution tree kernel (Qian et al., 2008), subsequence kernel (Bunescu and Mooney, 2005b), and dependency tree kernel (Bunescu and Mooney, 2005a). With the recent success of neural networks in natural language processing, different neural network models are proposed to learn syntactic features from raw sequences of words or constituent parse trees (Zeng et al., 2014; Socher et al., 2012), which have been proved effective, but, often suffer from irrelevant subsequences or clauses, especially when subjects and objects are in a longer distance. For example, in the sentence, “The [singer]e1 , who performed three of the nominated songs, also caused a [commotion]e2 on the red carpet”, the who clause is used to modify subject e1, but is unrelated to the Cause-Effect relationship between singer and commotion. Incorporating such information into the model will hurt the extraction performance. We therefore propose to learn a more robust relation representation from a convolution neural</context>
<context position="12935" citStr="Socher et al., 2012" startWordPosition="2078" endWordPosition="2081">2: Comparisons of our models with other methods on the SemEval 2010 task 8. Negative sampling schemes F1 No negative examples 81.3 Randomly sampled negative examples from NYT 83.5 Dependency paths from the object to subject 85.4 Table 3: Comparisons of different negtive sampling methods on the development set. for We, W1, W2 and W3. The best setting was obtained with the values: 3, 200, 100, 10−4, 10−3, 10−4 and 2 × 10−3, respectively. Results and Discussion Table 2 summarizes the performances of our model, depLCNN+NS(+), and state-of-the-art models, SVM (Hendrickx et al., 2010), RNN, MV-RNN (Socher et al., 2012), CNN (Zeng et al., 2014) and DepNN (Liu et al., 2015). For fair comparisons, we also add two types of lexical features, WordNet hypernyms and words around nominals, as part of input vector to the final softmax layer. We can see that our vanilla depLCNN+NS, without extra lexical features, still outperforms, by a large margin, previously reported best systems, MVRNN+ and CNN+, both of which have taken extra lexical features into account, showing that our treatment to dependency path can learn a robust and effective relation representation. When augmented with similar lexical features, our depLC</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL 2012, July 12-14, 2012, Jeju Island, Korea, pages 1201–1211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph P Turian</author>
<author>Lev-Arie Ratinov</author>
<author>Yoshua Bengio</author>
</authors>
<title>Word representations: A simple and general method for semi-supervised learning.</title>
<date>2010</date>
<booktitle>In ACL 2010, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>384--394</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="11811" citStr="Turian et al. (2010)" startWordPosition="1895" endWordPosition="1898">y paths corresponding to two opposite subject/object directions, and then make predictions for the two paths, respectively. We choose the relation other if and only if both predictions are other. And for the rest cases, we choose the non-other relation with highest confidence as the output, since ideally, for a non-other instance, our model will output the correct label for the right subject/object direction and an other label for the wrong direction. We evaluate our models by macro-averaged F1 using the official evaluation script. We initialized We with 50-dimensional word vectors trained by Turian et al. (2010). We tuned the hyper parameters using the development set for each experimental setting. The hyper parameters include w, n1, n2, and regularization parameters 538 Method Feature Sets F1 SVM 16 types of features 82.2 RNN - 74.8 +POS, NER, WordNet 77.6 MVRNN - 79.1 +POS, NER, WordNet 82.4 CNN - 78.9 (Zeng et al., 2014) +WordNet,words around nominals 82.7 DepNN +NER 83.6 depCNN - 81.3 depLCNN - 81.9 depLCNN +WordNet,words around nominals 83.7 depLCNN+NS - 84.0 +WordNet,words around nominals 85.6 Table 2: Comparisons of our models with other methods on the SemEval 2010 task 8. Negative sampling sc</context>
</contexts>
<marker>Turian, Ratinov, Bengio, 2010</marker>
<rawString>Joseph P. Turian, Lev-Arie Ratinov, and Yoshua Bengio. 2010. Word representations: A simple and general method for semi-supervised learning. In ACL 2010, Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, July 11-16, 2010, Uppsala, Sweden, pages 384–394.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daojian Zeng</author>
<author>Kang Liu</author>
<author>Siwei Lai</author>
<author>Guangyou Zhou</author>
<author>Jun Zhao</author>
</authors>
<title>Relation classification via convolutional deep neural network.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,</booktitle>
<pages>2335--2344</pages>
<institution>Dublin City University and Association for Computational Linguistics.</institution>
<location>Dublin, Ireland,</location>
<contexts>
<context position="2025" citStr="Zeng et al., 2014" startWordPosition="295" endWordPosition="298">parse features, etc. Among them, syntactic features are considered to bring significant improvements in extraction accuracy (Bunescu and Mooney, 2005a). Earlier attempts to encode syntactic information are mainly kernel-based methods, such as the convolution tree kernel (Qian et al., 2008), subsequence kernel (Bunescu and Mooney, 2005b), and dependency tree kernel (Bunescu and Mooney, 2005a). With the recent success of neural networks in natural language processing, different neural network models are proposed to learn syntactic features from raw sequences of words or constituent parse trees (Zeng et al., 2014; Socher et al., 2012), which have been proved effective, but, often suffer from irrelevant subsequences or clauses, especially when subjects and objects are in a longer distance. For example, in the sentence, “The [singer]e1 , who performed three of the nominated songs, also caused a [commotion]e2 on the red carpet”, the who clause is used to modify subject e1, but is unrelated to the Cause-Effect relationship between singer and commotion. Incorporating such information into the model will hurt the extraction performance. We therefore propose to learn a more robust relation representation fro</context>
<context position="12129" citStr="Zeng et al., 2014" startWordPosition="1950" endWordPosition="1953">er instance, our model will output the correct label for the right subject/object direction and an other label for the wrong direction. We evaluate our models by macro-averaged F1 using the official evaluation script. We initialized We with 50-dimensional word vectors trained by Turian et al. (2010). We tuned the hyper parameters using the development set for each experimental setting. The hyper parameters include w, n1, n2, and regularization parameters 538 Method Feature Sets F1 SVM 16 types of features 82.2 RNN - 74.8 +POS, NER, WordNet 77.6 MVRNN - 79.1 +POS, NER, WordNet 82.4 CNN - 78.9 (Zeng et al., 2014) +WordNet,words around nominals 82.7 DepNN +NER 83.6 depCNN - 81.3 depLCNN - 81.9 depLCNN +WordNet,words around nominals 83.7 depLCNN+NS - 84.0 +WordNet,words around nominals 85.6 Table 2: Comparisons of our models with other methods on the SemEval 2010 task 8. Negative sampling schemes F1 No negative examples 81.3 Randomly sampled negative examples from NYT 83.5 Dependency paths from the object to subject 85.4 Table 3: Comparisons of different negtive sampling methods on the development set. for We, W1, W2 and W3. The best setting was obtained with the values: 3, 200, 100, 10−4, 10−3, 10−4 an</context>
</contexts>
<marker>Zeng, Liu, Lai, Zhou, Zhao, 2014</marker>
<rawString>Daojian Zeng, Kang Liu, Siwei Lai, Guangyou Zhou, and Jun Zhao. 2014. Relation classification via convolutional deep neural network. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 2335–2344, Dublin, Ireland, August. Dublin City University and Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>