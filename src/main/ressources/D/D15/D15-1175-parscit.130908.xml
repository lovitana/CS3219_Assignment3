<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.998097">
A Utility Model of Authors in the Scientific Community
</title>
<author confidence="0.995102">
Yanchuan Sim
</author>
<affiliation confidence="0.887423">
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998416">
ysim@cs.cmu.edu
</email>
<author confidence="0.886392">
Bryan R. Routledge
</author>
<affiliation confidence="0.811502333333333">
Tepper School of Business
Carnegie Mellon University
Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.998127">
routledge@cmu.edu
</email>
<author confidence="0.943415">
Noah A. Smith
</author>
<affiliation confidence="0.9880655">
Computer Science &amp; Engineering
University of Washington
</affiliation>
<address confidence="0.579025">
Seattle, WA 98195, USA
</address>
<email confidence="0.997796">
nasmith@cs.washington.edu
</email>
<sectionHeader confidence="0.994775" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999193125">
Authoring a scientific paper is a complex
process involving many decisions. We in-
troduce a probabilistic model of some of
the important aspects of that process: that
authors have individual preferences, that
writing a paper requires trading off among
the preferences of authors as well as ex-
trinsic rewards in the form of commu-
nity response to their papers, that prefer-
ences (of individuals and the community)
and tradeoffs vary over time. Variants of
our model lead to improved predictive ac-
curacy of citations given texts and texts
given authors. Further, our model’s pos-
terior suggests an interesting relationship
between seniority and author choices.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999946322580645">
Why do we write? As researchers, we write pa-
pers to report new scientific findings, but this is
not the whole story. Authoring a paper involves
a huge amount of decision-making that may be
influenced by factors such as institutional incen-
tives, attention-seeking, and pleasure derived from
research on topics that excite us.
We propose that text collections and associated
metadata can be analyzed to reveal optimizing be-
havior by authors. Specifically, we consider the
ACL Anthology Network Corpus (Radev et al.,
2013), along with author and citation metadata.
Our main contribution is a method that infers two
kinds of quantities about an author: her associ-
ations with interpretable research topics, which
might correspond to relative expertise or merely
to preferences among topics to write about; and
a tradeoff coefficient that estimates the extent to
which she writes papers that will be cited versus
papers close to her preferences.
The method is based on a probabilistic model
that incorporates assumptions about how authors
decide what to write, how joint decisions work
when papers are coauthored, and how individual
and community preferences shift over time. Cen-
tral to our model is a low-dimensional topic rep-
resentation shared by authors (in defining prefer-
ences), papers (i.e., what they are “about”), and
the community as a whole (in responding with ci-
tations). This method can be used to make predic-
tions; empirically, we find that:
</bodyText>
<listItem confidence="0.9081459">
1. topics discovered by generative models out-
perform a strong text regression baseline (Yo-
gatama et al., 2011) for citation count predic-
tion;
2. such models do better at that task without mod-
eling author utility as we propose; and
3. the author utility model leads to better pre-
dictive accuracy when answering the question,
“given a set of authors, what are they likely to
write?”
</listItem>
<bodyText confidence="0.9999145">
This method can also be used for exploration
and to generate hypotheses. We provide an in-
triguing example relating author tradeoffs to age
within the research community.
</bodyText>
<sectionHeader confidence="0.799507" genericHeader="introduction">
2 Notation and Representations
</sectionHeader>
<bodyText confidence="0.999959285714286">
In the following, a document d will be represented
by a vector θd ∈ RK. The dimensions of this vec-
tor might correspond to elements of a vocabulary,
giving a “bag of words” encoding; in this work
they correspond to latent topics.
Document d is assumed to elicit from the scien-
tific community an observable response yd, which
might correspond to the number of citations (or
downloads) of the paper.
Each author a is associated with a vector ηa ∈
RK, with dimensions indexed the same as docu-
ments. Below, we will refer to this vector as a’s
“preferences,” though it is important to remember
that they could also capture an author’s expertise,
</bodyText>
<page confidence="0.909606">
1510
</page>
<note confidence="0.9847415">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1510–1519,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.984216666666667">
and the model makes no attempt to distinguish be-
tween them. We use “preferences” because it is a
weaker theoretical commitment.
</bodyText>
<sectionHeader confidence="0.993426" genericHeader="method">
3 Author Utility Model
</sectionHeader>
<bodyText confidence="0.99990375">
We describe the components of our model—
author utility (§3.1), coauthorship (§3.2), topics
(§3.3), and temporal dynamics (§3.4)—then give
the full form in §3.5.
</bodyText>
<subsectionHeader confidence="0.999613">
3.1 Modeling Utility
</subsectionHeader>
<bodyText confidence="0.999822">
Our main assumption about author a is that she is
an optimizer: when writing document d she seeks
to increase the response yd while keeping the con-
tents of d, θd, “close” to her preferences ηa. We
encode her objectives as a utility function to be
maximized with respect to θd:
</bodyText>
<equation confidence="0.999637666666667">
U(θd) = Kayd − 21θd − (ηa + Ed,a)12
1
2 (1)
</equation>
<bodyText confidence="0.9999219375">
where Cd,a is an author-paper-specific idiosyn-
cratic randomness that is unobserved to us but as-
sumed known to the author. (This is a common
assumption in discrete choice models. It is often
called a “random utility model.”)
Notice the tradeoff between maximizing the re-
sponse yd and staying close to one’s preferences.
We capture these competing objectives by formu-
lating the latter as a squared Euclidean distance
between ηa and θd, and encoding the tradeoff
between extrinsic (citation-seeking) and intrinsic
(preference-satisfying) objectives as the (positive)
coefficient Ka. If Ka is large, a might be un-
derstood as a citation-maximizing agent; if Ka is
small, a might appear to care much more about
certain kinds of papers (ηa) than about citation.
This utility function considers only two partic-
ular facets of author writing behavior; it does not
take into account other factors that may contribute
to an author’s objective. For this reason, some care
is required in interpreting quantities like Ka. For
example, divergence between a particular ηa and
θd might suggest that a is open to new topics, not
merely hungry for citations. Other motivations,
such as reputation (notoriously difficult to mea-
sure), funding maintenance, and the preferences of
peer referees are not captured in this model. Sim-
ilarly for preferences ηa, a large value in this vec-
tor might reflect a’s skill or the preferences of a’s
sponsors rather than a’s personal interest the topic.
Next, we model the response yd. We assume
that responses are driven largely by topics, with
</bodyText>
<equation confidence="0.984679">
some noise, so that
yd = β&gt;θd + ξd (2)
</equation>
<bodyText confidence="0.998954">
where ξd ∼ N(0,1). Because the community’s
interest in different topics varies over time, β is
given temporal dynamics, discussed in §3.4.
Under this assumption, the author’s expected
utility assuming she is aware of β (often called
“rational expectations” in discrete choice models),
is:
</bodyText>
<equation confidence="0.894828111111111">
E[U(θd)] = Kaβ&gt;θd− 121θd−(ηa+Cd,a)122 (3)
(This is obtained by plugging the expected value
of yd, from Eq. 2, into Eq. 1.)
An author’s decision will therefore be
ˆθd = arg max Kaβ&gt;θ− 1 21θ−(ηa+�d,a)12 2 (4)
θ
Optimality implies that ˆθd solves the first-order
equations
KaQj − (ˆ0d,j − (ηa,j + Ed,a,j)) = 0, b1 G j G K
</equation>
<bodyText confidence="0.9437565">
(5)
Eq. 5 highlights the tradeoff the author faces:
when Qj &gt; 0, the author will write more on 0d,j,
while straying too far from ηa,j incurs a penalty.
</bodyText>
<subsectionHeader confidence="0.999911">
3.2 Modeling Coauthorship
</subsectionHeader>
<bodyText confidence="0.9999494">
Matters become more complicated when multiple
authors write a paper together. Suppose the docu-
ment d is authored by set of authors ad. We model
the joint expected utility of ad in writing θd as the
average of the group’s utility.1
</bodyText>
<equation confidence="0.966170333333333">
� E[U(θd)] =  |ad  |a∈ad (Kaβ&gt;
θd
2 cd,a 1 θd − (ηa + Ed,a) 1 2) (6)
</equation>
<bodyText confidence="0.9995298">
where the “cost” term is scaled by cd,a, denoting
the fractional “contribution” of author a to docu-
ment d. Thus, Ea∈ad cd,a = 1, and we treat cd as
a latent categorical distribution to be inferred. The
first-order equation becomes
</bodyText>
<equation confidence="0.497828">
� Kaβ − cd,a(θd − (ηa + Cd,a)) = 0 (7)
a∈ad
</equation>
<footnote confidence="0.986208428571429">
1This assumption is a convenient starting place, but we
can imagine revisiting it in future work. For example, an
economist and a linguist with different expertise might de-
rive “utility” from the collaboration that is non-linear in each
one’s individual preferences (Anderson, 2012). Further, con-
tributions by complementary authors are not expected to be
independent of each other.
</footnote>
<page confidence="0.989971">
1511
</page>
<subsectionHeader confidence="0.997616">
3.3 Modeling Document Content
</subsectionHeader>
<bodyText confidence="0.993159181818182">
As noted before, there are many possible ways to
represent and model document content θd. We
treat θd as (an encoding of) a mixture of topics.
Following considerable past work, a “topic” is de-
fined as a categorical distribution over observable
tokens (Blei et al., 2003; Hofmann, 1999). Let wd
be the observed bag of tokens constituting docu-
ment d. We assume each token is drawn from a
mixture over topics:
ing a multivariate Gaussian distribution. Follow-
ing Yogatama et al. (2011), we assume the prior
</bodyText>
<equation confidence="0.994300666666667">
for β(·)
j = (Q(1)
j ,... , Q(T)
j ) has a tridiagonal pre-
cision matrix A(A, α) E RT×T:
1 + α −α 0 0 .. .
−α 1 + 2α −α 0 ...
0 −α 1 + 2α −α ...
0 0 −α 1 + 2α .. .
...
. ...
. .
⎞
⎠⎟⎟⎟⎟⎟
....
. .
A(A, α) = A
⎛
⎜ ⎜ ⎜ ⎜ ⎜ ⎝
p(wd  |θd) = E Nd p(zd,i  |θd)p(wd,i  |φzd,i)
xd i=1
</equation>
<bodyText confidence="0.999949866666667">
where Nd is the number of tokens in document d,
zd,i is the topic assignment for d’s ith token wd,i,
and φ1, ... , φK are topic-term distributions. Note
that θd E RK; we define p(z  |θd) as a categorical
draw from the softmax-transformed θd (Blei and
Lafferty, 2007).
Using topic mixtures instead of a bag of words
provides us with a low-dimensional interpretable
representation that is useful for analyzing authors’
behaviors and preferences. Each dimension j of
an author’s preference is grounded in topic j. If
we ignore document responses, this component of
model closely resembles the author-topic model
(Rosen-Zvi et al., 2004), except that we assume
a different prior for the topic mixtures.
</bodyText>
<subsectionHeader confidence="0.998769">
3.4 Modeling Temporal Dynamics
</subsectionHeader>
<bodyText confidence="0.992133428571429">
Individual preferences shift over time, as do those
of the research community. We extend our model
to allow variation at different timesteps. Let t E
(1, ... , T) index timesteps (in our experiments,
each t is a calendar year). We let β(t), η(t)
a , and
Ka denote the community’s response coefficients,
</bodyText>
<equation confidence="0.583057">
(t)
</equation>
<bodyText confidence="0.984622357142857">
author a’s preferences, and author a’s tradeoff co-
efficient at timestep t.
Again, we must take care in interpreting these
quantities. Do changes in community interest
drive authors to adjust their preferences or exper-
tise? Or do changing author preferences aggregate
into community-wide shifts? Or do changes in the
economy or funding availability change authors’
tradeoffs? Our model cannot differentiate among
these different causal patterns. Our method is use-
ful for tracking these changes, but it does not pro-
vide an explanation for why they take place.
Modeling the temporal dynamics of a vector-
valued random variable can be accomplished us-
The two hyperparameters α and A capture, respec-
tively, autocorrelation (the tendency of Q(t+1)
j to
be similar to Q(t)
j ) and overall variance. This ap-
proach to modeling time series allows us to cap-
ture temporal dynamics while sharing statistical
strength of evidence across all time steps.
We use the notation T (A, α) - N(0, A(A, α))
for this multivariate Gaussian distribution, in-
stances of which are used as priors over response
coefficients β, author preferences ηa, and (trans-
formed) author tradeoffs log Ka.
.
</bodyText>
<subsectionHeader confidence="0.573775">
Observed evidence
</subsectionHeader>
<bodyText confidence="0.9996668">
wd,i ith token in document d
V vocabulary size
Nd number of tokens in document d
yd
A
ad
T
Dt
D
response to document d
the set of authors
set of authors of document d (C A)
number of timesteps
the set of documents from timestep t
the set of all documents (= UTt=1 Dt)
</bodyText>
<subsectionHeader confidence="0.848775">
Latent variables
</subsectionHeader>
<bodyText confidence="0.928043407407407">
,0(t) response coefficients at time t (E RK)
71(t)
a
�(t)
a
ed
cd,a
Ok
zd,i
author a’s topic preferences at time t
(E RK)
author a’s tradeoff coefficient at time t
(E R≥0)
document d topic associations (E RK)
author a contrtibution to document d
(Ea∈., cd,a = 1)
distribution over terms for topic k
topic assignment of wd,i
Constants and hyperparameters
K number of topics
ρ symmetric Dirichlet hyperparameter
σ2 c for Ok
{λ(β), α(β)}, variance hyperparameter for author
{λ(η), α(η)}, contributions cd
{λ(κ), α(κ)}
hyperparameters for priors of ,0, 71,
and log κ respectively
</bodyText>
<tableCaption confidence="0.996676">
Table 1: Table of notation.
</tableCaption>
<page confidence="0.991813">
1512
</page>
<sectionHeader confidence="0.703285" genericHeader="method">
3.5 Full Model
</sectionHeader>
<bodyText confidence="0.9503405">
Table 1 summarizes all of the notation. The log-
likelihood of our model is:
</bodyText>
<equation confidence="0.9957182">
L = log p(β) + � log p(cd)
dED
logp(yd  |θd, β) + log p(wd  |θd)
log p(ηa) + log p(κa)
log p(θd  |β, ηa, κa, cd,a) (8)
</equation>
<bodyText confidence="0.999202">
We adopt a Bayesian approach to parameter esti-
mation. The generative story, including all priors,
is as follows. Recall that T (·, ·) denotes the time
series prior discussed in §3.4. See also the plate
diagram for the graphical model in Fig. 1.
</bodyText>
<listItem confidence="0.9947515">
1. For each topic k ∈ {1,... , K}:
(a) Draw response coefficients β(·) k∼
T (λ(β), α(β)) and term distribution φk ∼
Dirichlet(ρ).
(b) For each author a ∈ A, draw pref-
erence strengths for topic k over time,
</listItem>
<equation confidence="0.944001875">
hη(1)
a,k, ... , η(t)
a,ki ∼ T (λ(η), α(η)).
2. For each author a ∈ A, draw (transformed)
tradeoff parameters hlog κ(1)
a , ... , log κ(T)
a i ∼
T (λ(κ), α(κ)).
</equation>
<listItem confidence="0.992005888888889">
3. For each timestep t ∈ {1, ... , T}, and each
document d ∈ Dt:
(a) Draw author contributions cd ∼
Softmax(N(0, σ2cI)). This is known
as a logistic normal distribution (Aitchi-
son, 1986).
(b) Draw d’s topic distributions (this distribu-
tion is discussed further below):
(c) For each token i
</listItem>
<figure confidence="0.661911785714286">
Nd}, draw
and term
(d) Draw response yd
N
1);
note that it collapses out
which is
drawn from a stan
∈{1,...,
zd,i∼Categorical(Softmax(θd))
wd,i∼Categorical(φzd,i).
∼
(β(td)Tθd,
ξd,
</figure>
<bodyText confidence="0.968104">
dard normal.
Assuming that the Ed,as
are i.i.d. and Gaussian, fr
</bodyText>
<equation confidence="0.84876">
θd.
om Eq. 7, we get
�θd = κaβ + cd,aηa + cd,aEd,a,
aEad
</equation>
<bodyText confidence="0.9354122">
time steps of
and
β,η
κ are omitted for clarity.
and the linear additive property of Gaussian
</bodyText>
<equation confidence="0.808654384615385">
s gives
us
1:
θd ∼ N
aEad �κaβ
+ cd,aηa, kcdk22I
(9)
topic
Eq. 9 captures the choice by authors ad of a dis-
tribution over topics
κ
p
T
</equation>
<figureCaption confidence="0.892351">
Figure 1: Plate diagram for author utility model.
Hyperparameters and edges between consecutive
</figureCaption>
<bodyText confidence="0.98664975">
In §3.1 we described a utility function for each
author. The model we are estimating is similar
to those estimated in discrete choice economet-
rics (McFadden, 1974). We assumed that authors
are utility maximizing (optimizing) and that their
optimal topic distribution satisfies the first-order
conditions (Eq. 7). However, we cannot see the
idiosyncratic component, 6d,a, which is assumed
to be Gaussian; as noted, this is known as a ran-
dom utility model. Together, these assumptions
give the structure of the distri
bution over topics
in terms of (estimated) utility, which allows us to
naturally incorporate the utility function into our
probabilistic model in a familiar way (Sim et al.,
2015).
</bodyText>
<sectionHeader confidence="0.76965" genericHeader="method">
4 Learning and Inference
</sectionHeader>
<bodyText confidence="0.994713583333333">
Exact inference in our model is intractable, so
we resort to an approximate inference technique
based on Monte Carlo EM (Wei and Tanner,
1990). During the E-step, we perform Bayesian
inference over latent parameters
z,
c,
using aMetropolis-Hastings within Gibbs algo-
rithm (Tierney, 1994), and in the M-step, we
compute maximum a posteriori estimates of
by directly optimizing the log-likelihood function.
Since we are using conjugate priors for
</bodyText>
<footnote confidence="0.66418325">
we can
integrate it out. We did not perform Bayesian pos-
terior inference over
because the coupling of
</footnote>
<figure confidence="0.8844892">
(η,κ,
θ,
φ)
β
φ,
β
β
w z θ y
φ
K
N
η
c
A
A
D
�
+
dED
�
+
aEA
�
+
dED
�
aEad
θd ∼ N E κ(t)β(t) + cd,aη(t), �Jcd1122I
⎛
⎝a∈ad
</figure>
<page confidence="0.811959">
1513
</page>
<bodyText confidence="0.965686272727273">
would slow mixing of the MCMC chain.
E-step. We sample each 77(td)
a , cd, log K(·)
a , and
ed blockwise using the Metropolis-Hastings algo-
rithm with a multivariate Gaussian proposal distri-
bution, tuning the diagonal covariance matrix to a
target acceptance rate of 15-45% (see appendix §A
for sampling equations).
For z, we integrate out O and sample each zd,i
directly from
</bodyText>
<equation confidence="0.9921975">
C−d,i
k,wd,i + ρ
C−d,i
k,· + V ρ
</equation>
<bodyText confidence="0.957454">
where C−d,i
k,w and C−d,i
k,· are the number of times
w is associated with topic k, and the number of
tokens associated with topic k respectively.
We run the E-step Gibbs sampler to collect
3,500 samples, discarding the first 500 samples for
burn-in and only saving samples at every third it-
eration.
M-step. We approximate the expectations of our
latent variables using the samples collected dur-
ing the E-step, and directly optimize)3(t) using L-
BFGS (Liu and Nocedal, 1989),2 which requires a
gradient. The gradient of the log-likelihood with
respect to β(t)
</bodyText>
<equation confidence="0.9153165">
j is
= −2λ(β)β(t)
j
− 2λ(β)α(β)1{t &gt; 1}(β(t) j − β(t−1)
j )
− 2λ(β)α(β)1{t &lt; T}(β(t)
j − β(t+1)
j )
</equation>
<bodyText confidence="0.998535571428571">
where κ(dt) = ad EaEad κ(t)
We ran L-BFGS until convergence3 and slice
sampled the hyperparameters λ(η), α(η), λ(κ), α(κ)
(with vague priors) at the end of the M-step. We
fix the symmetric Dirichlet hyperparameter ρ =
1/V , and tuned λ(β), α(β) on a held-out develope-
ment dataset by grid search over {0.01, 0.1,1,10}.
</bodyText>
<footnote confidence="0.998617666666667">
2We used libLBFGS, an open source C++ implementation
(https://github.com/chokkan/liblbfgs).
3Relative tolerance of 10−4.
</footnote>
<bodyText confidence="0.999669">
During initialization, we randomly set the topic as-
signments, while the other latent parameters are
set to 0. We ran the model for 10 EM iterations.
Inference. During inference, we fix the model
parameters and only sample (e, z) for each doc-
ument. As in the E-step, we discard the first 500
samples, and save samples at every third iteration,
until we have 500 posterior samples. In our ex-
periments, we found the posterior samples to be
reasonably stable after the initial burn in.
</bodyText>
<sectionHeader confidence="0.999467" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9998899">
Data. The ACL Anthology Network Corpus
contains 21,212 papers published in the field of
computational linguistics between 1965 and 2013
and written by 17,792 authors. Additionally, the
corpus provides metadata such as authors, venue
and in-community citation networks. For our ex-
periments, we focused on conference papers pub-
lished between 1980 and 2010.4 We tokenized the
texts, tagged the tokens using the Stanford POS
tagger (Toutanova et al., 2003), and extracted n-
grams with tags that follow the simple (but effec-
tive) pattern of (Adj|Noun)∗ Noun (Justeson
and Katz, 1995), representing the dth document
as a bag of phrases (wd). Note that phrases can
also be unigrams. We pruned phrases that appear
in &lt; 1% or &gt; 95% of the documents, obtaining
a vocabulary of V = 6,868 types. The pruned
corpus contains 5,498 documents and 2,643,946
phrase tokens written by 5,575 authors. We let re-
sponses
</bodyText>
<equation confidence="0.715906">
yd = log(1 + # of incoming citations in 3 years)
</equation>
<bodyText confidence="0.999898833333333">
For our experiments, we used 3 different ran-
dom splits of our data (70% train, 20% test, and
10% development) and averaged quantities of in-
terest. Furthermore, we remove an author from a
paper in the development or test set if we have not
seen him before in the training data.
</bodyText>
<subsectionHeader confidence="0.999526">
5.1 Examples of Authors and Topics
</subsectionHeader>
<bodyText confidence="0.997816">
Table 2 illustrates ten manually selected topics
(out of 64) learned by the author utility model.
Each topic is labeled with the top 10 words most
likely to be generated conditioned on the topic
</bodyText>
<footnote confidence="0.86672075">
4The conferences we included are: ACL, CoNLL, EACL,
EMNLP, HLT, and NAACL. We ignored journal papers, as
well as workshop papers, since they are characteristically dif-
ferent from conference papers.
</footnote>
<equation confidence="0.953627421052632">
p(zd,i = k  |ed, Ok) ∝ exp(θd,k)
∂L
∂β(t)
j
� θd,j(yd − β(t)
+ 2 j θd,j)
dEDt
�
κdt) θ(d,j − κdt)β(t)
j −
�
+ 2
dEDt
�
η(t)
a,j
|ad|
(10)
aEad
</equation>
<page confidence="0.939512">
1514
</page>
<bodyText confidence="0.9655475">
(hik). For each topic, we compute an author’s topic
preference score:
</bodyText>
<equation confidence="0.90216225">
�
TPS(a, k) = (tk)
�
dEDa
</equation>
<bodyText confidence="0.973465352941177">
where Softmax(x) = exp(x)
Ei exp(xi). The TPS scales
the author’s 77 preferences by the relative num-
ber of citations that the author received for the
topic. This way, we can account for different
77s over time, and reduce variance due to authors
who publish less frequently.5 For each topic, the
five authors with the highest TPS are displayed
in the rightmost column of Table 2. These top-
ics were among the roughly one third (out of 64)
that seemed to coherently map to research topics
within NLP. Some others corresponded to parts of
a paper (e.g., explaining notation and formulae,
experiments) or to stylistic groups (e.g., “ratio-
nal words” including rather, fact, clearly, argue,
clear, perhaps). Others were not interpretable to
us.
</bodyText>
<subsectionHeader confidence="0.999648">
5.2 Predicting Responses
</subsectionHeader>
<bodyText confidence="0.999959047619048">
We compare against two baselines for predicting
in-community citations. Yogatama et al. (2011) is
a strong baseline for predicting responses; they in-
corporated n-gram features and metadata features
in a generalized linear model with the time series
prior discussed in §3.4.6 We also compare against
a version of our model without the author utility
component. This equates to replacing Yogatama
et al.’s features with LDA topic mixtures, and per-
forming joint learning of the topics and citations;
we therefore call it “TimeLDA.” Without the time
series component, TimeLDA would instantiate su-
pervised LDA (McAuliffe and Blei, 2008). Fig-
ure 2 shows the mean absolute error (MAE) for
the three models.
With sufficiently many topics (K &gt; 16), topic
representations achieve lower error than surface
features. Removing the author utility component
from our model leads to better predictive perfor-
mance. This is unsurprising, since our model
forces β to explain both the responses (what is
</bodyText>
<footnote confidence="0.980682">
5The TPS is only a measure of an author’s propensity to
write papers in a specific topic area and is not meant to be
a measure of an author’s reputation in a particular research
sub-field.
6For the ACL dataset, Yogatama et al. (2011)’s model
predicts whether a paper will receive at least 1 citation
within three years, while here, we train it to predict log(1 +
#citations) instead.
</footnote>
<figureCaption confidence="0.982495">
Figure 2: Mean absolute error (in citation counts)
</figureCaption>
<bodyText confidence="0.987122785714286">
for predicted citation counts (y-axis) against the
number of topics K (x-axis). Errors are in ac-
tual citation counts, while the models are trained
with log counts. TimeLDA significantly outper-
forms Yogatama et al. (2011) for K &gt; 64 (paired
t-test, p &lt; 0.01), while the differences between
Yogatama et al. (2011) and author utility are not
significant. The MAE is calculated over 3 random
splits of the data with 809, 812, and 811 docu-
ments in the test set respectively.
evaluated here) and the divergence between author
preferences 77a and what is actually written. The
utility model is nonetheless competitive with the
Yogatama et al. baseline.
</bodyText>
<subsectionHeader confidence="0.998407">
5.3 Predicting Words
</subsectionHeader>
<bodyText confidence="0.99996025">
“Given a set of authors, what are they likely to
write?” — we use perplexity as a proxy to mea-
sure the content predictive ability of our model.
Perplexity on a test set is commonly used to quan-
tify the generalization ability of probabilistic mod-
els and make comparisons among models over the
same observation space. For a document wd writ-
ten by authors ad, perplexity is defined as
</bodyText>
<equation confidence="0.881043">
perplexity(wd  |ad) = exp C_ log p(wd  |ad)1
Nd J
</equation>
<bodyText confidence="0.999919">
and a lower perplexity indicates better generaliza-
tion performance. Using S samples from the in-
ference step, we can compute
</bodyText>
<equation confidence="0.9505045">
1 �
|ad |aEad,k
</equation>
<bodyText confidence="0.939154444444444">
where 0s is the sth sample of 0, and his is the
topic-word distribution estimated from the sth
sample of z.
We compared the Author-Topic model of
Rosen-Zvi et al. (2004). The AT model is simi-
lar to setting Ka = 0 for all authors, cd = 1
|ad|,
and using a Dirichlet prior instead of logistic nor-
mal on 77a. Figure 3 present the perplexity of these
</bodyText>
<figure confidence="0.907271117647059">
3.4
3.2
3.0
2.8
2.6
Yogatama et al (2011)
Author utility
TimeLDA
8 16 32 64 128
[Softmax(0d)]k X yd
S
1
p(wd  |ad) = S
s=1
Nd
i=1
Bsd,kOsk,wdi
</figure>
<page confidence="0.952835">
1515
</page>
<table confidence="0.999749523809524">
Topic Top words Authors
“MT” alignment, translation, align, decode, phrase, och, Philipp Koehn, Chris Dyer, Qun Liu, Hermann
bleu, ney, bleu score, target language Ney, David Chiang
“Empirical model, parameter, learn, iteration, maximize, prior, Noah Smith, Dan Klein, Percy Liang, John DeN-
methods” initialize, distribution, weight, crf ero, Andrew McCallum
“Parsing” parse, sentence, parser, accuracy, collins, depen- Michael Collins, Joakim Nivre, Jens Nilsson, Dan
dency, tree, parse tree, head, charniak Klein, Ryan McDonald
“Dialogue speak, speech, utterance, user, speaker, dialogue Diane Litman, Marilyn Walker, Julia Hirschberg,
systems” system, turn, act, recognition, transcription Oliver Lemon, Amanda Stent
“NER” name, entity, identify, person, location, list, organi- Jenny Rose Finkel, Satoshi Sekine, Rion Snow,
zation, system, entity recognition, mention Christopher Manning, Abraham Ittycheriah
“Semantics” argument, verb, predicate, syntactic, relation, se- Martha Palmer, Alessandro Moschitti, Daniel Ju-
mantic role, annotated, frame, assign rafsky, Sanda Harabagiu, Mirella Lapata
“Lexical wordnet, noun, sense, concept, context, sens, rela- Rion Snow, Rob Koeling, Eneko Agirre, Ido Da-
semantics” tion, meaning, pair, disambiguate gan, Patrick Pantel
“Tagging &amp; method, sentence, propose, japanese, noun phrase, Yuji Matsumoto, Hitoshi Isahara, Junichi Tsujii,
chunking” extract, table, analyze, precision, technology Sadao Kurohashi, Kentaro Torisawa
“Coreference” mention, instance, create, approach, report, due, Vincent Ng, Aria Haghighi, Xiaofeng Yang, Claire
text, pair, exist, system Cardie, Pascal Denis
“Sentiment classify, label, accuracy, positive, classification, an- Janyce Wiebe, Soo Min Kim, Eduard Hovy, Car-
classification” notated, annotator, classifier, review, negative men Banea, Ryan McDonald
</table>
<tableCaption confidence="0.936335">
Table 2: Top words from selected topics and authors with preferences in those topics. We manually
labeled each of these topics.
</tableCaption>
<figureCaption confidence="0.955051">
Figure 3: Held-out perplexity (×103, y-axis) with
</figureCaption>
<bodyText confidence="0.920444909090909">
varying number of topics K (x-axis). The differ-
ences are significant between all models at K ≥
64 (paired t-test, p &lt; 0.01). There are 523,381,
529,397, 533,792 phrase tokens in the random test
sets.
models at different values of K. We include a ver-
sion of our author utility model that ignores tem-
poral information (“–time”), i.e., setting T = 1
and collapsing all timesteps. We find that perplex-
ity improves with the addition of the utility model
as well as the temporal dynamics.
</bodyText>
<subsectionHeader confidence="0.997332">
5.4 Exploration: Tradeoffs and Seniority
</subsectionHeader>
<bodyText confidence="0.999654875">
Recall that κa encodes author a’s tradeoff between
increasing citations (high κa) and writing papers
on topics a prefers (low κa). We do not claim
that individual κa values consistently represent
authors’ tradeoffs between citations and writing
about preferred topics. We have noted a number
of potentially confounding factors that affect au-
thors’ choices, for which our data do not allow us
</bodyText>
<figure confidence="0.998592166666667">
Median r, values 0.20 8 Mean citations/paper
0.15 6
0.10 4
0.05 2
0
1 5 10 15 20 25 30
</figure>
<figureCaption confidence="0.98440925">
Figure 4: Plot of authors’ median κ (blue,
solid) and mean citation counts (magenta, dashed)
against their academic age in this dataset (see text
for explanation).
</figureCaption>
<bodyText confidence="0.9789029375">
to control.
However, in aggregate, κa values can be ex-
plored in relation to other quantities. Given our
model’s posterior, one question we can ask is:
do an author’s tradeoffs tend to change over the
course of her career? In Figure 4, we plot the me-
dian of κ (and 95% credible intervals) for authors
at different “ages.” Here, “age” is defined as the
number of years since an author’s first publication
in this dataset.7
A general trend over the long term is observed:
researchers appear to move from higher to lower
κa. Statistically, there is significant dependence
between κ of an author and her age; the Spear-
man’s rank correlation coefficient is ρ = −0.870
with p-value &lt; 10−5. This finding is consis-
</bodyText>
<footnote confidence="0.746369333333333">
7This means that larger ages correspond to seniority, but
smaller ages are a blend of junior researchers and researchers
of any seniority new to this publication community.
</footnote>
<figure confidence="0.99548125">
8 16 32 64 128
3.0
2.6
2.2
1.8
Author-Topic
Author utility (-Time)
Author utility
</figure>
<page confidence="0.988717">
1516
</page>
<bodyText confidence="0.999960125">
tent with the idea that greater seniority brings
increased and more stable resources and greater
freedom to pursue idiosyncratic interests with less
concern about extrinsic payoff. It is also consistent
with decreased flexibility or openness to shifting
topics over time.
To illustrate the importance of our model in
making these observations, we also plot the mean
number of citations per paper published (across
all authors) against their academic age (magenta
lines). There is no clear statistical trend between
the two variables (p = −0.017). This suggests
that through n, our model is able to pick up evi-
dence of author’s optimizing behaviors, which is
not possible using simple citation counts.
There is a noticeable effect during years 5–10,
in which n tends to rise by around 40% and then
fall back. (Note that the model maintains consider-
able uncertainty—wider intervals—about this ef-
fect.) Recall that, for a researcher trained within
the field and whose primary publication venue is
in the ACL community, our measure of age cor-
responds roughly to academic age. Years 5–10
would correspond to the later part of a Ph.D. pro-
gram and early postgraduate life, when many re-
searchers begin faculty careers. Insofar as it re-
flects a true effect, this rise and fall suggests a
stage during which a researcher focuses more on
writing papers that will attract citations. How-
ever, more in-depth study based on data that is not
merely observational is required to quantify this
effect and, if it persists under scrutiny, determine
its cause.
The effect in year 24 of mean citations per paper
(magenta line) can be attributed to well cited pa-
pers co-authored by senior researchers in the field
who published very few papers in their 24th year.
Since there are relatively few authors in the dataset
at that academic age, there is more variance in
mean citations counts.
</bodyText>
<sectionHeader confidence="0.999971" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.965260396551724">
Previous work on modeling author interests
mostly focused on characterizing authors by their
style (Holmes and Forsyth, 1995, inter alia),8
through latent topic mixtures of documents they
have co-authored (Rosen-Zvi et al., 2004) and
their collaboration networks (Johri et al., 2011).
8A closely related problem is that of authorship attribu-
tion. There has been extensive research on authorship attri-
bution focusing mainly on learning “stylometric” features of
authors; see Stamatatos (2009) for a detailed review.
Like our paper, the latter two are based on topic
models, which have been popular for modeling the
content of scientific articles. For instance, Gerrish
and Blei (2010) measured scholarly impact using
dynamic topic models, while Hall et al. (2008) an-
alyzed the output of topic models to study the “his-
tory of ideas.”
Predicting responses to scientific articles was
explored in two shared tasks at KDD Cup 2003
(Brank and Leskovec, 2003; McGovern et al.,
2003) and by Yogatama et al. (2011), which served
as a baseline for our experiments and whose time-
series prior we used in our model. Furthermore,
there has been considerable research using topic
models to predict (or recommend) citations (in-
stead of aggregate counts), such as modeling link
probabilities within the LDA framework (Cohn
and Hofmann, 2000; Erosheva et al., 2004; Nal-
lapati and Cohen, 2008; Kataria et al., 2010; Zhu
et al., 2013) and augmenting topics with discrimi-
native author features (Liu et al., 2009; Tanner and
Charniak, 2015).
We modeled both interests of authors and re-
sponses to their articles jointly, by assuming
authors’ text production is an expected utility-
maximizing decision. This approach is similar
to our earlier work (Sim et al., 2015), where au-
thors are rational agents writing texts to maximize
the chance of a favorable decision by a judicial
court. In that study, we did not consider the unique
preferences of each decision making agent, nor
the extrinsic-intrinsic reward tradeoffs that these
agents face when authoring a document.
Our utility model can also be viewed as a form
of natural language generator, where we take into
account the context of an author (i.e., his prefer-
ences, the tradeoff coefficient, and what is popu-
lar) to generate his document. This is related to
natural language pragmatics, where text is influ-
enced by context.9 Hovy (1990) approached the
problem of generating text under pragmatic cir-
cumstances from a planning and goal-orientation
perspective, while Vogel et al. (2013) used multi-
agent decision-theoretic models to show cooper-
ative pragmatic behavior. Vogel et al.’s models
suggest an interesting extension of ours for future
work: modeling cooperation among co-authors
and, perhaps, in the larger scientific discourse.
</bodyText>
<footnote confidence="0.997421">
9The β vectors can be seen as a naive representation of
world knowledge that motivates an author to select content
that reflects his behavioral preferences and intentions.
</footnote>
<page confidence="0.99469">
1517
</page>
<sectionHeader confidence="0.998964" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999778545454545">
We presented a model of scientific authorship in
which authors trade off between seeking citation
by others and staying true to their individual pref-
erences among research topics. We find that topic
modeling improves over state-of-the-art text re-
gression models for predicting citation counts, and
that the author utility model generalizes better than
simpler models when predicting what a particular
group of authors will write. Inspecting our model
suggests interesting patterns in behavior across a
researcher’s career.
</bodyText>
<sectionHeader confidence="0.994002" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999981875">
The authors thank the anonymous reviewers for
their thoughtful feedback and members of the
ARK group at CMU for their valuable com-
ments. This research was supported in part by an
A*STAR fellowship to Y. Sim, by a Google re-
search award, and by computing resources from
the Pittsburgh Supercomputing Center; it was
completed while NAS was at CMU.
</bodyText>
<sectionHeader confidence="0.553509" genericHeader="references">
A Appendix: Sampling equations
</sectionHeader>
<bodyText confidence="0.9999505">
We sample each ηa,j, for j = 1... K, and
κa blockwise across time steps using Metropolis-
Hastings algorithm with a multivariate Gaussian
proposal distribution and likelihood:
</bodyText>
<equation confidence="0.979516625">
p(ηa,j  |η−(a,j),θ, c, κ, β, Λ(η))
�
−1
∝ exp 2ηa,jΛ(η)η&gt; a,j
X− � ~2 ⎞
t∈T θd,j − P a0∈ad κ(t) ⎠ ⎟
d∈Dt a0 β(t)
j + cd,a0η(t)
a0,j
2kcdk22
p(κa  |κ−(a), θ, c, η,β, Λ(κ))
∝ exp (−2 log(κa)Λ(κ) log(κ&gt;a )
kθd − Pa0∈ad κ(t)
a0 β(t) + cd,a0η(t)
a0 k22
2kcdk22
</equation>
<bodyText confidence="0.8251135">
Λ(η) and Λ(κ) are shorthands for the precision ma-
trices Λ(λ(η), α(η)) and Λ(λ(κ), α(κ)) respectively.
Likewise, θd is sampled blockwise for each docu-
ment with a multivariate Gaussian distribution and
</bodyText>
<equation confidence="0.907804888888889">
likelihood:
p(θd  |cd, η, κ, β)
−(yd − β(td)&gt;θd)2
∝ exp
2
kθd − Pa∈ad κ(td)
a β(td) + cd,aη(td)
a k22
2kcdk22
</equation>
<bodyText confidence="0.99869075">
For cd, we first sampled each cd from a multivari-
ate Gaussian distribution, and applied a logistic
transformation to map it onto the simplex. The
likelihood for cd is:
</bodyText>
<equation confidence="0.889452818181818">
p(cd  |θd, η, κ, β)
� ��
� cd �
1 � 2
� �
log �
cd,|ad |2
kθd − Pa∈ad κ(td)
a β(td)+ cd,aη(td)
a k22
2kcdk22
</equation>
<sectionHeader confidence="0.980895" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999044535714286">
John Aitchison. 1986. The Statistical Analysis of Com-
positional Data. Chapman &amp; Hall.
Katharine A. Anderson. 2012. Specialists and gen-
eralists: Equilibrium skill acquisition decisions in
problem-solving populations. Journal of Economic
Behavior &amp; Organization, 84(1):463–473.
David M. Blei and John D. Lafferty. 2007. A corre-
lated topic model of science. The Annals of Applied
Statistics, pages 17–35.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022, March.
Janez Brank and Jure Leskovec. 2003. The download
estimation task on KDD Cup 2003. SIGKDD Explo-
rations Newsletter, 5(2):160–162, December.
David A. Cohn and Thomas Hofmann. 2000. The
missing link – a probabilistic model of document
content and hypertext connectivity. In NIPS.
Elena Erosheva, Stephen Fienberg, and John Lafferty.
2004. Mixed-membership models of scientific pub-
lications. Proceedings of the National Academy of
Sciences, 101(suppl. 1):5220–5227.
Sean Gerrish and David M. Blei. 2010. A language-
based approach to measuring scholarly impact. In
Proc. of ICML.
David Hall, Daniel Jurafsky, and Christopher D. Man-
ning. 2008. Studying the history of ideas using
topic models. In Proc. of EMNLP.
</reference>
<figure confidence="0.9948935">
X−
t∈T
d∈Dt
⎞
⎠⎟
!
∝ exp 2σ2 c
!
</figure>
<page confidence="0.888552">
1518
</page>
<reference confidence="0.999942548780488">
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proc. of SIGIR.
D. I. Holmes and R. S. Forsyth. 1995. The federalist
revisited: New directions in authorship attribution.
Literary and Linguistic Computing, 10(2):111–127.
Eduard H. Hovy. 1990. Pragmatics and natural lan-
guage generation. Artificial Intelligence, 43(2):153–
197, May.
Nikhil Johri, Daniel Ramage, Daniel A. McFarland,
and Daniel Jurafsky. 2011. A study of academic
collaboration in computational linguistics with la-
tent mixtures of authors. In Proc. of the Workshop
on Language Technology for Cultural Heritage, So-
cial Sciences, and Humanities.
John S. Justeson and Slava M. Katz. 1995. Technical
terminology: Some linguistic properties and an al-
gorithm for identification in text. Natural Language
Engineering, 1:9–27, March.
Saurabh Kataria, Prasenjit Mitra, and Sumit Bhatia.
2010. Utilizing context in generative Bayesian mod-
els for linked corpus. In Proc. of AAAI.
Dong C. Liu and Jorge Nocedal. 1989. On the limited
memory BFGS method for large scale optimization.
Mathematical Programming, 45(1-3):503–528.
Yan Liu, Alexandru Niculescu-Mizil, and Wojciech
Gryc. 2009. Topic-link LDA: Joint models of topic
and author community. In Proc. of ICML.
Jon D. McAuliffe and David M. Blei. 2008. Super-
vised topic models. In NIPS.
Daniel McFadden. 1974. Conditional logit analysis of
qualitative choice behavior. In Frontiers in Econo-
metrics, pages 105–142. Academic Press.
Amy McGovern, Lisa Friedland, Michael Hay, Brian
Gallagher, Andrew Fast, Jennifer Neville, and
David Jensen. 2003. Exploiting relational struc-
ture to understand publication patterns in high-
energy physics. SIGKDD Exploration Newsletter,
5(2):165–172, December.
Ramesh Nallapati and William W. Cohen. 2008. Link-
PLSA-LDA: A new unsupervised model for topics
and influence of blogs. In Proc. of ICWSM.
Dragomir R. Radev, Pradeep Muthukrishnan, Vahed
Qazvinian, and Amjad Abu-Jbara. 2013. The ACL
anthology network corpus. Language Resources
and Evaluation, pages 1–26. Data available at
http://clair.eecs.umich.edu/aan/.
Michal Rosen-Zvi, Thomas Griffiths, Mark Steyvers,
and Padhraic Smyth. 2004. The author-topic model
for authors and documents. In Proc. of UAI.
Yanchuan Sim, Bryan Routledge, and Noah A. Smith.
2015. The utility of text: The case of amicus briefs
and the Supreme Court. In Proc. of AAAI.
Efstathios Stamatatos. 2009. A survey of modern au-
thorship attribution methods. Journal of the Ameri-
can Society for Information Science and Technology,
60(3):538–556.
Chris Tanner and Eugene Charniak. 2015. A hybrid
generative/discriminative approach to citation pre-
diction. In Proc. of NAACL.
Luke Tierney. 1994. Markov chains for exploring
posterior distributions. The Annals of Statistics,
22(4):pp. 1701–1728.
Kristina Toutanova, Dan Klein, Christopher D. Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proc. of NAACL.
Adam Vogel, Max Bodoia, Christopher Potts, and
Daniel Jurafsky. 2013. Emergence of Gricean max-
ims from multi-agent decision theory. In Proc. of
NAACL.
Greg C. G. Wei and Martin A. Tanner. 1990. A Monte
Carlo implementation of the EM algorithm and the
poor man’s data augmentation algorithms. Journal
of the American Statistical Association, 85(411):pp.
699–704.
Dani Yogatama, Michael Heilman, Brendan O’Connor,
Chris Dyer, Bryan R. Routledge, and Noah A.
Smith. 2011. Predicting a scientific community’s
response to an article. In Proc. of EMNLP.
Yaojia Zhu, Xiaoran Yan, Lise Getoor, and Cristopher
Moore. 2013. Scalable text and link analysis with
mixed-topic link models. In Proc. of KDD.
</reference>
<page confidence="0.995742">
1519
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.932674">
<title confidence="0.999744">A Utility Model of Authors in the Scientific Community</title>
<author confidence="0.999277">Yanchuan Sim</author>
<affiliation confidence="0.9998745">School of Computer Science Carnegie Mellon University</affiliation>
<address confidence="0.996987">Pittsburgh, PA 15213, USA</address>
<email confidence="0.999572">ysim@cs.cmu.edu</email>
<author confidence="0.999801">Bryan R Routledge</author>
<affiliation confidence="0.9918915">Tepper School of Business Carnegie Mellon University</affiliation>
<address confidence="0.998065">Pittsburgh, PA 15213, USA</address>
<email confidence="0.999804">routledge@cmu.edu</email>
<author confidence="0.961211">A Noah</author>
<affiliation confidence="0.9998185">Computer Science &amp; University of</affiliation>
<address confidence="0.998572">Seattle, WA 98195,</address>
<email confidence="0.99957">nasmith@cs.washington.edu</email>
<abstract confidence="0.999719117647059">Authoring a scientific paper is a complex process involving many decisions. We introduce a probabilistic model of some of the important aspects of that process: that authors have individual preferences, that writing a paper requires trading off among the preferences of authors as well as extrinsic rewards in the form of community response to their papers, that preferences (of individuals and the community) and tradeoffs vary over time. Variants of our model lead to improved predictive accuracy of citations given texts and texts given authors. Further, our model’s posterior suggests an interesting relationship between seniority and author choices.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Aitchison</author>
</authors>
<title>The Statistical Analysis of Compositional Data.</title>
<date>1986</date>
<publisher>Chapman &amp; Hall.</publisher>
<contexts>
<context position="12866" citStr="Aitchison, 1986" startWordPosition="2201" endWordPosition="2203"> See also the plate diagram for the graphical model in Fig. 1. 1. For each topic k ∈ {1,... , K}: (a) Draw response coefficients β(·) k∼ T (λ(β), α(β)) and term distribution φk ∼ Dirichlet(ρ). (b) For each author a ∈ A, draw preference strengths for topic k over time, hη(1) a,k, ... , η(t) a,ki ∼ T (λ(η), α(η)). 2. For each author a ∈ A, draw (transformed) tradeoff parameters hlog κ(1) a , ... , log κ(T) a i ∼ T (λ(κ), α(κ)). 3. For each timestep t ∈ {1, ... , T}, and each document d ∈ Dt: (a) Draw author contributions cd ∼ Softmax(N(0, σ2cI)). This is known as a logistic normal distribution (Aitchison, 1986). (b) Draw d’s topic distributions (this distribution is discussed further below): (c) For each token i Nd}, draw and term (d) Draw response yd N 1); note that it collapses out which is drawn from a stan ∈{1,..., zd,i∼Categorical(Softmax(θd)) wd,i∼Categorical(φzd,i). ∼ (β(td)Tθd, ξd, dard normal. Assuming that the Ed,as are i.i.d. and Gaussian, fr θd. om Eq. 7, we get �θd = κaβ + cd,aηa + cd,aEd,a, aEad time steps of and β,η κ are omitted for clarity. and the linear additive property of Gaussian s gives us 1: θd ∼ N aEad �κaβ + cd,aηa, kcdk22I (9) topic Eq. 9 captures the choice by authors ad </context>
</contexts>
<marker>Aitchison, 1986</marker>
<rawString>John Aitchison. 1986. The Statistical Analysis of Compositional Data. Chapman &amp; Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katharine A Anderson</author>
</authors>
<title>Specialists and generalists: Equilibrium skill acquisition decisions in problem-solving populations.</title>
<date>2012</date>
<journal>Journal of Economic Behavior &amp; Organization,</journal>
<volume>84</volume>
<issue>1</issue>
<contexts>
<context position="7842" citStr="Anderson, 2012" startWordPosition="1291" endWordPosition="1292">] = |ad |a∈ad (Kaβ&gt; θd 2 cd,a 1 θd − (ηa + Ed,a) 1 2) (6) where the “cost” term is scaled by cd,a, denoting the fractional “contribution” of author a to document d. Thus, Ea∈ad cd,a = 1, and we treat cd as a latent categorical distribution to be inferred. The first-order equation becomes � Kaβ − cd,a(θd − (ηa + Cd,a)) = 0 (7) a∈ad 1This assumption is a convenient starting place, but we can imagine revisiting it in future work. For example, an economist and a linguist with different expertise might derive “utility” from the collaboration that is non-linear in each one’s individual preferences (Anderson, 2012). Further, contributions by complementary authors are not expected to be independent of each other. 1511 3.3 Modeling Document Content As noted before, there are many possible ways to represent and model document content θd. We treat θd as (an encoding of) a mixture of topics. Following considerable past work, a “topic” is defined as a categorical distribution over observable tokens (Blei et al., 2003; Hofmann, 1999). Let wd be the observed bag of tokens constituting document d. We assume each token is drawn from a mixture over topics: ing a multivariate Gaussian distribution. Following Yogata</context>
</contexts>
<marker>Anderson, 2012</marker>
<rawString>Katharine A. Anderson. 2012. Specialists and generalists: Equilibrium skill acquisition decisions in problem-solving populations. Journal of Economic Behavior &amp; Organization, 84(1):463–473.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>John D Lafferty</author>
</authors>
<title>A correlated topic model of science. The Annals of Applied Statistics,</title>
<date>2007</date>
<pages>17--35</pages>
<contexts>
<context position="9016" citStr="Blei and Lafferty, 2007" startWordPosition="1526" endWordPosition="1529">ltivariate Gaussian distribution. Following Yogatama et al. (2011), we assume the prior for β(·) j = (Q(1) j ,... , Q(T) j ) has a tridiagonal precision matrix A(A, α) E RT×T: 1 + α −α 0 0 .. . −α 1 + 2α −α 0 ... 0 −α 1 + 2α −α ... 0 0 −α 1 + 2α .. . ... . ... . . ⎞ ⎠⎟⎟⎟⎟⎟ .... . . A(A, α) = A ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ p(wd |θd) = E Nd p(zd,i |θd)p(wd,i |φzd,i) xd i=1 where Nd is the number of tokens in document d, zd,i is the topic assignment for d’s ith token wd,i, and φ1, ... , φK are topic-term distributions. Note that θd E RK; we define p(z |θd) as a categorical draw from the softmax-transformed θd (Blei and Lafferty, 2007). Using topic mixtures instead of a bag of words provides us with a low-dimensional interpretable representation that is useful for analyzing authors’ behaviors and preferences. Each dimension j of an author’s preference is grounded in topic j. If we ignore document responses, this component of model closely resembles the author-topic model (Rosen-Zvi et al., 2004), except that we assume a different prior for the topic mixtures. 3.4 Modeling Temporal Dynamics Individual preferences shift over time, as do those of the research community. We extend our model to allow variation at different times</context>
</contexts>
<marker>Blei, Lafferty, 2007</marker>
<rawString>David M. Blei and John D. Lafferty. 2007. A correlated topic model of science. The Annals of Applied Statistics, pages 17–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="8246" citStr="Blei et al., 2003" startWordPosition="1355" endWordPosition="1358">evisiting it in future work. For example, an economist and a linguist with different expertise might derive “utility” from the collaboration that is non-linear in each one’s individual preferences (Anderson, 2012). Further, contributions by complementary authors are not expected to be independent of each other. 1511 3.3 Modeling Document Content As noted before, there are many possible ways to represent and model document content θd. We treat θd as (an encoding of) a mixture of topics. Following considerable past work, a “topic” is defined as a categorical distribution over observable tokens (Blei et al., 2003; Hofmann, 1999). Let wd be the observed bag of tokens constituting document d. We assume each token is drawn from a mixture over topics: ing a multivariate Gaussian distribution. Following Yogatama et al. (2011), we assume the prior for β(·) j = (Q(1) j ,... , Q(T) j ) has a tridiagonal precision matrix A(A, α) E RT×T: 1 + α −α 0 0 .. . −α 1 + 2α −α 0 ... 0 −α 1 + 2α −α ... 0 0 −α 1 + 2α .. . ... . ... . . ⎞ ⎠⎟⎟⎟⎟⎟ .... . . A(A, α) = A ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ p(wd |θd) = E Nd p(zd,i |θd)p(wd,i |φzd,i) xd i=1 where Nd is the number of tokens in document d, zd,i is the topic assignment for d’s ith token </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet allocation. Journal of Machine Learning Research, 3:993–1022, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janez Brank</author>
<author>Jure Leskovec</author>
</authors>
<title>The download estimation task on KDD Cup</title>
<date>2003</date>
<journal>SIGKDD Explorations Newsletter,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="29780" citStr="Brank and Leskovec, 2003" startWordPosition="5007" endWordPosition="5010">horship attribution. There has been extensive research on authorship attribution focusing mainly on learning “stylometric” features of authors; see Stamatatos (2009) for a detailed review. Like our paper, the latter two are based on topic models, which have been popular for modeling the content of scientific articles. For instance, Gerrish and Blei (2010) measured scholarly impact using dynamic topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of au</context>
</contexts>
<marker>Brank, Leskovec, 2003</marker>
<rawString>Janez Brank and Jure Leskovec. 2003. The download estimation task on KDD Cup 2003. SIGKDD Explorations Newsletter, 5(2):160–162, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Cohn</author>
<author>Thomas Hofmann</author>
</authors>
<title>The missing link – a probabilistic model of document content and hypertext connectivity.</title>
<date>2000</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="30152" citStr="Cohn and Hofmann, 2000" startWordPosition="5067" endWordPosition="5070">ly impact using dynamic topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to their articles jointly, by assuming authors’ text production is an expected utilitymaximizing decision. This approach is similar to our earlier work (Sim et al., 2015), where authors are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of eac</context>
</contexts>
<marker>Cohn, Hofmann, 2000</marker>
<rawString>David A. Cohn and Thomas Hofmann. 2000. The missing link – a probabilistic model of document content and hypertext connectivity. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Erosheva</author>
<author>Stephen Fienberg</author>
<author>John Lafferty</author>
</authors>
<title>Mixed-membership models of scientific publications.</title>
<date>2004</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>101</volume>
<pages>1--5220</pages>
<contexts>
<context position="30175" citStr="Erosheva et al., 2004" startWordPosition="5071" endWordPosition="5074">topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to their articles jointly, by assuming authors’ text production is an expected utilitymaximizing decision. This approach is similar to our earlier work (Sim et al., 2015), where authors are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of each decision making agent</context>
</contexts>
<marker>Erosheva, Fienberg, Lafferty, 2004</marker>
<rawString>Elena Erosheva, Stephen Fienberg, and John Lafferty. 2004. Mixed-membership models of scientific publications. Proceedings of the National Academy of Sciences, 101(suppl. 1):5220–5227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sean Gerrish</author>
<author>David M Blei</author>
</authors>
<title>A languagebased approach to measuring scholarly impact.</title>
<date>2010</date>
<booktitle>In Proc. of ICML.</booktitle>
<contexts>
<context position="29513" citStr="Gerrish and Blei (2010)" startWordPosition="4962" endWordPosition="4965"> characterizing authors by their style (Holmes and Forsyth, 1995, inter alia),8 through latent topic mixtures of documents they have co-authored (Rosen-Zvi et al., 2004) and their collaboration networks (Johri et al., 2011). 8A closely related problem is that of authorship attribution. There has been extensive research on authorship attribution focusing mainly on learning “stylometric” features of authors; see Stamatatos (2009) for a detailed review. Like our paper, the latter two are based on topic models, which have been popular for modeling the content of scientific articles. For instance, Gerrish and Blei (2010) measured scholarly impact using dynamic topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within th</context>
</contexts>
<marker>Gerrish, Blei, 2010</marker>
<rawString>Sean Gerrish and David M. Blei. 2010. A languagebased approach to measuring scholarly impact. In Proc. of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hall</author>
<author>Daniel Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Studying the history of ideas using topic models.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="29592" citStr="Hall et al. (2008)" startWordPosition="4974" endWordPosition="4977">ugh latent topic mixtures of documents they have co-authored (Rosen-Zvi et al., 2004) and their collaboration networks (Johri et al., 2011). 8A closely related problem is that of authorship attribution. There has been extensive research on authorship attribution focusing mainly on learning “stylometric” features of authors; see Stamatatos (2009) for a detailed review. Like our paper, the latter two are based on topic models, which have been popular for modeling the content of scientific articles. For instance, Gerrish and Blei (2010) measured scholarly impact using dynamic topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and C</context>
</contexts>
<marker>Hall, Jurafsky, Manning, 2008</marker>
<rawString>David Hall, Daniel Jurafsky, and Christopher D. Manning. 2008. Studying the history of ideas using topic models. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proc. of SIGIR.</booktitle>
<contexts>
<context position="8262" citStr="Hofmann, 1999" startWordPosition="1359" endWordPosition="1360">ure work. For example, an economist and a linguist with different expertise might derive “utility” from the collaboration that is non-linear in each one’s individual preferences (Anderson, 2012). Further, contributions by complementary authors are not expected to be independent of each other. 1511 3.3 Modeling Document Content As noted before, there are many possible ways to represent and model document content θd. We treat θd as (an encoding of) a mixture of topics. Following considerable past work, a “topic” is defined as a categorical distribution over observable tokens (Blei et al., 2003; Hofmann, 1999). Let wd be the observed bag of tokens constituting document d. We assume each token is drawn from a mixture over topics: ing a multivariate Gaussian distribution. Following Yogatama et al. (2011), we assume the prior for β(·) j = (Q(1) j ,... , Q(T) j ) has a tridiagonal precision matrix A(A, α) E RT×T: 1 + α −α 0 0 .. . −α 1 + 2α −α 0 ... 0 −α 1 + 2α −α ... 0 0 −α 1 + 2α .. . ... . ... . . ⎞ ⎠⎟⎟⎟⎟⎟ .... . . A(A, α) = A ⎛ ⎜ ⎜ ⎜ ⎜ ⎜ ⎝ p(wd |θd) = E Nd p(zd,i |θd)p(wd,i |φzd,i) xd i=1 where Nd is the number of tokens in document d, zd,i is the topic assignment for d’s ith token wd,i, and φ1, ..</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proc. of SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D I Holmes</author>
<author>R S Forsyth</author>
</authors>
<title>The federalist revisited: New directions in authorship attribution.</title>
<date>1995</date>
<booktitle>Literary and Linguistic Computing,</booktitle>
<pages>10--2</pages>
<contexts>
<context position="28954" citStr="Holmes and Forsyth, 1995" startWordPosition="4877" endWordPosition="4880">ore in-depth study based on data that is not merely observational is required to quantify this effect and, if it persists under scrutiny, determine its cause. The effect in year 24 of mean citations per paper (magenta line) can be attributed to well cited papers co-authored by senior researchers in the field who published very few papers in their 24th year. Since there are relatively few authors in the dataset at that academic age, there is more variance in mean citations counts. 6 Related Work Previous work on modeling author interests mostly focused on characterizing authors by their style (Holmes and Forsyth, 1995, inter alia),8 through latent topic mixtures of documents they have co-authored (Rosen-Zvi et al., 2004) and their collaboration networks (Johri et al., 2011). 8A closely related problem is that of authorship attribution. There has been extensive research on authorship attribution focusing mainly on learning “stylometric” features of authors; see Stamatatos (2009) for a detailed review. Like our paper, the latter two are based on topic models, which have been popular for modeling the content of scientific articles. For instance, Gerrish and Blei (2010) measured scholarly impact using dynamic </context>
</contexts>
<marker>Holmes, Forsyth, 1995</marker>
<rawString>D. I. Holmes and R. S. Forsyth. 1995. The federalist revisited: New directions in authorship attribution. Literary and Linguistic Computing, 10(2):111–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
</authors>
<title>Pragmatics and natural language generation.</title>
<date>1990</date>
<journal>Artificial Intelligence,</journal>
<volume>43</volume>
<issue>2</issue>
<pages>197</pages>
<contexts>
<context position="31196" citStr="Hovy (1990)" startWordPosition="5242" endWordPosition="5243"> are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of each decision making agent, nor the extrinsic-intrinsic reward tradeoffs that these agents face when authoring a document. Our utility model can also be viewed as a form of natural language generator, where we take into account the context of an author (i.e., his preferences, the tradeoff coefficient, and what is popular) to generate his document. This is related to natural language pragmatics, where text is influenced by context.9 Hovy (1990) approached the problem of generating text under pragmatic circumstances from a planning and goal-orientation perspective, while Vogel et al. (2013) used multiagent decision-theoretic models to show cooperative pragmatic behavior. Vogel et al.’s models suggest an interesting extension of ours for future work: modeling cooperation among co-authors and, perhaps, in the larger scientific discourse. 9The β vectors can be seen as a naive representation of world knowledge that motivates an author to select content that reflects his behavioral preferences and intentions. 1517 7 Conclusions We present</context>
</contexts>
<marker>Hovy, 1990</marker>
<rawString>Eduard H. Hovy. 1990. Pragmatics and natural language generation. Artificial Intelligence, 43(2):153– 197, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikhil Johri</author>
<author>Daniel Ramage</author>
<author>Daniel A McFarland</author>
<author>Daniel Jurafsky</author>
</authors>
<title>A study of academic collaboration in computational linguistics with latent mixtures of authors.</title>
<date>2011</date>
<booktitle>In Proc. of the Workshop on Language Technology</booktitle>
<contexts>
<context position="29113" citStr="Johri et al., 2011" startWordPosition="4900" endWordPosition="4903">ffect in year 24 of mean citations per paper (magenta line) can be attributed to well cited papers co-authored by senior researchers in the field who published very few papers in their 24th year. Since there are relatively few authors in the dataset at that academic age, there is more variance in mean citations counts. 6 Related Work Previous work on modeling author interests mostly focused on characterizing authors by their style (Holmes and Forsyth, 1995, inter alia),8 through latent topic mixtures of documents they have co-authored (Rosen-Zvi et al., 2004) and their collaboration networks (Johri et al., 2011). 8A closely related problem is that of authorship attribution. There has been extensive research on authorship attribution focusing mainly on learning “stylometric” features of authors; see Stamatatos (2009) for a detailed review. Like our paper, the latter two are based on topic models, which have been popular for modeling the content of scientific articles. For instance, Gerrish and Blei (2010) measured scholarly impact using dynamic topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was exp</context>
</contexts>
<marker>Johri, Ramage, McFarland, Jurafsky, 2011</marker>
<rawString>Nikhil Johri, Daniel Ramage, Daniel A. McFarland, and Daniel Jurafsky. 2011. A study of academic collaboration in computational linguistics with latent mixtures of authors. In Proc. of the Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John S Justeson</author>
<author>Slava M Katz</author>
</authors>
<title>Technical terminology: Some linguistic properties and an algorithm for identification in text. Natural Language Engineering,</title>
<date>1995</date>
<contexts>
<context position="17576" citStr="Justeson and Katz, 1995" startWordPosition="3004" endWordPosition="3007">table after the initial burn in. 5 Experiments Data. The ACL Anthology Network Corpus contains 21,212 papers published in the field of computational linguistics between 1965 and 2013 and written by 17,792 authors. Additionally, the corpus provides metadata such as authors, venue and in-community citation networks. For our experiments, we focused on conference papers published between 1980 and 2010.4 We tokenized the texts, tagged the tokens using the Stanford POS tagger (Toutanova et al., 2003), and extracted ngrams with tags that follow the simple (but effective) pattern of (Adj|Noun)∗ Noun (Justeson and Katz, 1995), representing the dth document as a bag of phrases (wd). Note that phrases can also be unigrams. We pruned phrases that appear in &lt; 1% or &gt; 95% of the documents, obtaining a vocabulary of V = 6,868 types. The pruned corpus contains 5,498 documents and 2,643,946 phrase tokens written by 5,575 authors. We let responses yd = log(1 + # of incoming citations in 3 years) For our experiments, we used 3 different random splits of our data (70% train, 20% test, and 10% development) and averaged quantities of interest. Furthermore, we remove an author from a paper in the development or test set if we h</context>
</contexts>
<marker>Justeson, Katz, 1995</marker>
<rawString>John S. Justeson and Slava M. Katz. 1995. Technical terminology: Some linguistic properties and an algorithm for identification in text. Natural Language Engineering, 1:9–27, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saurabh Kataria</author>
<author>Prasenjit Mitra</author>
<author>Sumit Bhatia</author>
</authors>
<title>Utilizing context in generative Bayesian models for linked corpus.</title>
<date>2010</date>
<booktitle>In Proc. of AAAI.</booktitle>
<contexts>
<context position="30224" citStr="Kataria et al., 2010" startWordPosition="5080" endWordPosition="5083">e output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to their articles jointly, by assuming authors’ text production is an expected utilitymaximizing decision. This approach is similar to our earlier work (Sim et al., 2015), where authors are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of each decision making agent, nor the extrinsic-intrinsic reward tradeoffs th</context>
</contexts>
<marker>Kataria, Mitra, Bhatia, 2010</marker>
<rawString>Saurabh Kataria, Prasenjit Mitra, and Sumit Bhatia. 2010. Utilizing context in generative Bayesian models for linked corpus. In Proc. of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory BFGS method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical Programming,</booktitle>
<pages>45--1</pages>
<contexts>
<context position="15878" citStr="Liu and Nocedal, 1989" startWordPosition="2724" endWordPosition="2727">te of 15-45% (see appendix §A for sampling equations). For z, we integrate out O and sample each zd,i directly from C−d,i k,wd,i + ρ C−d,i k,· + V ρ where C−d,i k,w and C−d,i k,· are the number of times w is associated with topic k, and the number of tokens associated with topic k respectively. We run the E-step Gibbs sampler to collect 3,500 samples, discarding the first 500 samples for burn-in and only saving samples at every third iteration. M-step. We approximate the expectations of our latent variables using the samples collected during the E-step, and directly optimize)3(t) using LBFGS (Liu and Nocedal, 1989),2 which requires a gradient. The gradient of the log-likelihood with respect to β(t) j is = −2λ(β)β(t) j − 2λ(β)α(β)1{t &gt; 1}(β(t) j − β(t−1) j ) − 2λ(β)α(β)1{t &lt; T}(β(t) j − β(t+1) j ) where κ(dt) = ad EaEad κ(t) We ran L-BFGS until convergence3 and slice sampled the hyperparameters λ(η), α(η), λ(κ), α(κ) (with vague priors) at the end of the M-step. We fix the symmetric Dirichlet hyperparameter ρ = 1/V , and tuned λ(β), α(β) on a held-out developement dataset by grid search over {0.01, 0.1,1,10}. 2We used libLBFGS, an open source C++ implementation (https://github.com/chokkan/liblbfgs). 3Rel</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C. Liu and Jorge Nocedal. 1989. On the limited memory BFGS method for large scale optimization. Mathematical Programming, 45(1-3):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Liu</author>
<author>Alexandru Niculescu-Mizil</author>
<author>Wojciech Gryc</author>
</authors>
<title>Topic-link LDA: Joint models of topic and author community.</title>
<date>2009</date>
<booktitle>In Proc. of ICML.</booktitle>
<contexts>
<context position="30319" citStr="Liu et al., 2009" startWordPosition="5096" endWordPosition="5099">es was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to their articles jointly, by assuming authors’ text production is an expected utilitymaximizing decision. This approach is similar to our earlier work (Sim et al., 2015), where authors are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of each decision making agent, nor the extrinsic-intrinsic reward tradeoffs that these agents face when authoring a document. Our utility model can also be viewed as a form </context>
</contexts>
<marker>Liu, Niculescu-Mizil, Gryc, 2009</marker>
<rawString>Yan Liu, Alexandru Niculescu-Mizil, and Wojciech Gryc. 2009. Topic-link LDA: Joint models of topic and author community. In Proc. of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon D McAuliffe</author>
<author>David M Blei</author>
</authors>
<title>Supervised topic models.</title>
<date>2008</date>
<booktitle>In NIPS.</booktitle>
<contexts>
<context position="20288" citStr="McAuliffe and Blei, 2008" startWordPosition="3471" endWordPosition="3474">pare against two baselines for predicting in-community citations. Yogatama et al. (2011) is a strong baseline for predicting responses; they incorporated n-gram features and metadata features in a generalized linear model with the time series prior discussed in §3.4.6 We also compare against a version of our model without the author utility component. This equates to replacing Yogatama et al.’s features with LDA topic mixtures, and performing joint learning of the topics and citations; we therefore call it “TimeLDA.” Without the time series component, TimeLDA would instantiate supervised LDA (McAuliffe and Blei, 2008). Figure 2 shows the mean absolute error (MAE) for the three models. With sufficiently many topics (K &gt; 16), topic representations achieve lower error than surface features. Removing the author utility component from our model leads to better predictive performance. This is unsurprising, since our model forces β to explain both the responses (what is 5The TPS is only a measure of an author’s propensity to write papers in a specific topic area and is not meant to be a measure of an author’s reputation in a particular research sub-field. 6For the ACL dataset, Yogatama et al. (2011)’s model predi</context>
</contexts>
<marker>McAuliffe, Blei, 2008</marker>
<rawString>Jon D. McAuliffe and David M. Blei. 2008. Supervised topic models. In NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel McFadden</author>
</authors>
<title>Conditional logit analysis of qualitative choice behavior.</title>
<date>1974</date>
<booktitle>In Frontiers in Econometrics,</booktitle>
<pages>105--142</pages>
<publisher>Academic Press.</publisher>
<contexts>
<context position="13761" citStr="McFadden, 1974" startWordPosition="2359" endWordPosition="2360"> ξd, dard normal. Assuming that the Ed,as are i.i.d. and Gaussian, fr θd. om Eq. 7, we get �θd = κaβ + cd,aηa + cd,aEd,a, aEad time steps of and β,η κ are omitted for clarity. and the linear additive property of Gaussian s gives us 1: θd ∼ N aEad �κaβ + cd,aηa, kcdk22I (9) topic Eq. 9 captures the choice by authors ad of a distribution over topics κ p T Figure 1: Plate diagram for author utility model. Hyperparameters and edges between consecutive In §3.1 we described a utility function for each author. The model we are estimating is similar to those estimated in discrete choice econometrics (McFadden, 1974). We assumed that authors are utility maximizing (optimizing) and that their optimal topic distribution satisfies the first-order conditions (Eq. 7). However, we cannot see the idiosyncratic component, 6d,a, which is assumed to be Gaussian; as noted, this is known as a random utility model. Together, these assumptions give the structure of the distri bution over topics in terms of (estimated) utility, which allows us to naturally incorporate the utility function into our probabilistic model in a familiar way (Sim et al., 2015). 4 Learning and Inference Exact inference in our model is intractab</context>
</contexts>
<marker>McFadden, 1974</marker>
<rawString>Daniel McFadden. 1974. Conditional logit analysis of qualitative choice behavior. In Frontiers in Econometrics, pages 105–142. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy McGovern</author>
<author>Lisa Friedland</author>
<author>Michael Hay</author>
<author>Brian Gallagher</author>
<author>Andrew Fast</author>
<author>Jennifer Neville</author>
<author>David Jensen</author>
</authors>
<title>Exploiting relational structure to understand publication patterns in highenergy physics.</title>
<date>2003</date>
<journal>SIGKDD Exploration Newsletter,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="29804" citStr="McGovern et al., 2003" startWordPosition="5011" endWordPosition="5014"> has been extensive research on authorship attribution focusing mainly on learning “stylometric” features of authors; see Stamatatos (2009) for a detailed review. Like our paper, the latter two are based on topic models, which have been popular for modeling the content of scientific articles. For instance, Gerrish and Blei (2010) measured scholarly impact using dynamic topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to t</context>
</contexts>
<marker>McGovern, Friedland, Hay, Gallagher, Fast, Neville, Jensen, 2003</marker>
<rawString>Amy McGovern, Lisa Friedland, Michael Hay, Brian Gallagher, Andrew Fast, Jennifer Neville, and David Jensen. 2003. Exploiting relational structure to understand publication patterns in highenergy physics. SIGKDD Exploration Newsletter, 5(2):165–172, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramesh Nallapati</author>
<author>William W Cohen</author>
</authors>
<title>LinkPLSA-LDA: A new unsupervised model for topics and influence of blogs.</title>
<date>2008</date>
<booktitle>In Proc. of ICWSM.</booktitle>
<contexts>
<context position="30202" citStr="Nallapati and Cohen, 2008" startWordPosition="5075" endWordPosition="5079">l et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to their articles jointly, by assuming authors’ text production is an expected utilitymaximizing decision. This approach is similar to our earlier work (Sim et al., 2015), where authors are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of each decision making agent, nor the extrinsic-intrins</context>
</contexts>
<marker>Nallapati, Cohen, 2008</marker>
<rawString>Ramesh Nallapati and William W. Cohen. 2008. LinkPLSA-LDA: A new unsupervised model for topics and influence of blogs. In Proc. of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Pradeep Muthukrishnan</author>
<author>Vahed Qazvinian</author>
<author>Amjad Abu-Jbara</author>
</authors>
<title>The ACL anthology network corpus. Language Resources and Evaluation,</title>
<date>2013</date>
<pages>1--26</pages>
<note>Data available at http://clair.eecs.umich.edu/aan/.</note>
<contexts>
<context position="1597" citStr="Radev et al., 2013" startWordPosition="239" endWordPosition="242">posterior suggests an interesting relationship between seniority and author choices. 1 Introduction Why do we write? As researchers, we write papers to report new scientific findings, but this is not the whole story. Authoring a paper involves a huge amount of decision-making that may be influenced by factors such as institutional incentives, attention-seeking, and pleasure derived from research on topics that excite us. We propose that text collections and associated metadata can be analyzed to reveal optimizing behavior by authors. Specifically, we consider the ACL Anthology Network Corpus (Radev et al., 2013), along with author and citation metadata. Our main contribution is a method that infers two kinds of quantities about an author: her associations with interpretable research topics, which might correspond to relative expertise or merely to preferences among topics to write about; and a tradeoff coefficient that estimates the extent to which she writes papers that will be cited versus papers close to her preferences. The method is based on a probabilistic model that incorporates assumptions about how authors decide what to write, how joint decisions work when papers are coauthored, and how ind</context>
</contexts>
<marker>Radev, Muthukrishnan, Qazvinian, Abu-Jbara, 2013</marker>
<rawString>Dragomir R. Radev, Pradeep Muthukrishnan, Vahed Qazvinian, and Amjad Abu-Jbara. 2013. The ACL anthology network corpus. Language Resources and Evaluation, pages 1–26. Data available at http://clair.eecs.umich.edu/aan/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Rosen-Zvi</author>
<author>Thomas Griffiths</author>
<author>Mark Steyvers</author>
<author>Padhraic Smyth</author>
</authors>
<title>The author-topic model for authors and documents.</title>
<date>2004</date>
<booktitle>In Proc. of UAI.</booktitle>
<contexts>
<context position="9383" citStr="Rosen-Zvi et al., 2004" startWordPosition="1581" endWordPosition="1584">is the number of tokens in document d, zd,i is the topic assignment for d’s ith token wd,i, and φ1, ... , φK are topic-term distributions. Note that θd E RK; we define p(z |θd) as a categorical draw from the softmax-transformed θd (Blei and Lafferty, 2007). Using topic mixtures instead of a bag of words provides us with a low-dimensional interpretable representation that is useful for analyzing authors’ behaviors and preferences. Each dimension j of an author’s preference is grounded in topic j. If we ignore document responses, this component of model closely resembles the author-topic model (Rosen-Zvi et al., 2004), except that we assume a different prior for the topic mixtures. 3.4 Modeling Temporal Dynamics Individual preferences shift over time, as do those of the research community. We extend our model to allow variation at different timesteps. Let t E (1, ... , T) index timesteps (in our experiments, each t is a calendar year). We let β(t), η(t) a , and Ka denote the community’s response coefficients, (t) author a’s preferences, and author a’s tradeoff coefficient at timestep t. Again, we must take care in interpreting these quantities. Do changes in community interest drive authors to adjust their</context>
<context position="22482" citStr="Rosen-Zvi et al. (2004)" startWordPosition="3848" endWordPosition="3851">ctive ability of our model. Perplexity on a test set is commonly used to quantify the generalization ability of probabilistic models and make comparisons among models over the same observation space. For a document wd written by authors ad, perplexity is defined as perplexity(wd |ad) = exp C_ log p(wd |ad)1 Nd J and a lower perplexity indicates better generalization performance. Using S samples from the inference step, we can compute 1 � |ad |aEad,k where 0s is the sth sample of 0, and his is the topic-word distribution estimated from the sth sample of z. We compared the Author-Topic model of Rosen-Zvi et al. (2004). The AT model is similar to setting Ka = 0 for all authors, cd = 1 |ad|, and using a Dirichlet prior instead of logistic normal on 77a. Figure 3 present the perplexity of these 3.4 3.2 3.0 2.8 2.6 Yogatama et al (2011) Author utility TimeLDA 8 16 32 64 128 [Softmax(0d)]k X yd S 1 p(wd |ad) = S s=1 Nd i=1 Bsd,kOsk,wdi 1515 Topic Top words Authors “MT” alignment, translation, align, decode, phrase, och, Philipp Koehn, Chris Dyer, Qun Liu, Hermann bleu, ney, bleu score, target language Ney, David Chiang “Empirical model, parameter, learn, iteration, maximize, prior, Noah Smith, Dan Klein, Percy </context>
<context position="29059" citStr="Rosen-Zvi et al., 2004" startWordPosition="4892" endWordPosition="4895"> if it persists under scrutiny, determine its cause. The effect in year 24 of mean citations per paper (magenta line) can be attributed to well cited papers co-authored by senior researchers in the field who published very few papers in their 24th year. Since there are relatively few authors in the dataset at that academic age, there is more variance in mean citations counts. 6 Related Work Previous work on modeling author interests mostly focused on characterizing authors by their style (Holmes and Forsyth, 1995, inter alia),8 through latent topic mixtures of documents they have co-authored (Rosen-Zvi et al., 2004) and their collaboration networks (Johri et al., 2011). 8A closely related problem is that of authorship attribution. There has been extensive research on authorship attribution focusing mainly on learning “stylometric” features of authors; see Stamatatos (2009) for a detailed review. Like our paper, the latter two are based on topic models, which have been popular for modeling the content of scientific articles. For instance, Gerrish and Blei (2010) measured scholarly impact using dynamic topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas</context>
</contexts>
<marker>Rosen-Zvi, Griffiths, Steyvers, Smyth, 2004</marker>
<rawString>Michal Rosen-Zvi, Thomas Griffiths, Mark Steyvers, and Padhraic Smyth. 2004. The author-topic model for authors and documents. In Proc. of UAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yanchuan Sim</author>
<author>Bryan Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>The utility of text: The case of amicus briefs and the Supreme Court.</title>
<date>2015</date>
<booktitle>In Proc. of AAAI.</booktitle>
<contexts>
<context position="14293" citStr="Sim et al., 2015" startWordPosition="2440" endWordPosition="2443">mating is similar to those estimated in discrete choice econometrics (McFadden, 1974). We assumed that authors are utility maximizing (optimizing) and that their optimal topic distribution satisfies the first-order conditions (Eq. 7). However, we cannot see the idiosyncratic component, 6d,a, which is assumed to be Gaussian; as noted, this is known as a random utility model. Together, these assumptions give the structure of the distri bution over topics in terms of (estimated) utility, which allows us to naturally incorporate the utility function into our probabilistic model in a familiar way (Sim et al., 2015). 4 Learning and Inference Exact inference in our model is intractable, so we resort to an approximate inference technique based on Monte Carlo EM (Wei and Tanner, 1990). During the E-step, we perform Bayesian inference over latent parameters z, c, using aMetropolis-Hastings within Gibbs algorithm (Tierney, 1994), and in the M-step, we compute maximum a posteriori estimates of by directly optimizing the log-likelihood function. Since we are using conjugate priors for we can integrate it out. We did not perform Bayesian posterior inference over because the coupling of (η,κ, θ, φ) β φ, β β w z θ</context>
<context position="30570" citStr="Sim et al., 2015" startWordPosition="5136" endWordPosition="5139">s been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to their articles jointly, by assuming authors’ text production is an expected utilitymaximizing decision. This approach is similar to our earlier work (Sim et al., 2015), where authors are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of each decision making agent, nor the extrinsic-intrinsic reward tradeoffs that these agents face when authoring a document. Our utility model can also be viewed as a form of natural language generator, where we take into account the context of an author (i.e., his preferences, the tradeoff coefficient, and what is popular) to generate his document. This is related to natural language pragmatics, where text is influence</context>
</contexts>
<marker>Sim, Routledge, Smith, 2015</marker>
<rawString>Yanchuan Sim, Bryan Routledge, and Noah A. Smith. 2015. The utility of text: The case of amicus briefs and the Supreme Court. In Proc. of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Efstathios Stamatatos</author>
</authors>
<title>A survey of modern authorship attribution methods.</title>
<date>2009</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>60</volume>
<issue>3</issue>
<contexts>
<context position="29321" citStr="Stamatatos (2009)" startWordPosition="4932" endWordPosition="4933">e relatively few authors in the dataset at that academic age, there is more variance in mean citations counts. 6 Related Work Previous work on modeling author interests mostly focused on characterizing authors by their style (Holmes and Forsyth, 1995, inter alia),8 through latent topic mixtures of documents they have co-authored (Rosen-Zvi et al., 2004) and their collaboration networks (Johri et al., 2011). 8A closely related problem is that of authorship attribution. There has been extensive research on authorship attribution focusing mainly on learning “stylometric” features of authors; see Stamatatos (2009) for a detailed review. Like our paper, the latter two are based on topic models, which have been popular for modeling the content of scientific articles. For instance, Gerrish and Blei (2010) measured scholarly impact using dynamic topic models, while Hall et al. (2008) analyzed the output of topic models to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in </context>
</contexts>
<marker>Stamatatos, 2009</marker>
<rawString>Efstathios Stamatatos. 2009. A survey of modern authorship attribution methods. Journal of the American Society for Information Science and Technology, 60(3):538–556.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Tanner</author>
<author>Eugene Charniak</author>
</authors>
<title>A hybrid generative/discriminative approach to citation prediction.</title>
<date>2015</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="30347" citStr="Tanner and Charniak, 2015" startWordPosition="5100" endWordPosition="5103"> two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to their articles jointly, by assuming authors’ text production is an expected utilitymaximizing decision. This approach is similar to our earlier work (Sim et al., 2015), where authors are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of each decision making agent, nor the extrinsic-intrinsic reward tradeoffs that these agents face when authoring a document. Our utility model can also be viewed as a form of natural language generato</context>
</contexts>
<marker>Tanner, Charniak, 2015</marker>
<rawString>Chris Tanner and Eugene Charniak. 2015. A hybrid generative/discriminative approach to citation prediction. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke Tierney</author>
</authors>
<title>Markov chains for exploring posterior distributions.</title>
<date>1994</date>
<journal>The Annals of Statistics,</journal>
<volume>22</volume>
<issue>4</issue>
<pages>1701--1728</pages>
<contexts>
<context position="14607" citStr="Tierney, 1994" startWordPosition="2490" endWordPosition="2491">aussian; as noted, this is known as a random utility model. Together, these assumptions give the structure of the distri bution over topics in terms of (estimated) utility, which allows us to naturally incorporate the utility function into our probabilistic model in a familiar way (Sim et al., 2015). 4 Learning and Inference Exact inference in our model is intractable, so we resort to an approximate inference technique based on Monte Carlo EM (Wei and Tanner, 1990). During the E-step, we perform Bayesian inference over latent parameters z, c, using aMetropolis-Hastings within Gibbs algorithm (Tierney, 1994), and in the M-step, we compute maximum a posteriori estimates of by directly optimizing the log-likelihood function. Since we are using conjugate priors for we can integrate it out. We did not perform Bayesian posterior inference over because the coupling of (η,κ, θ, φ) β φ, β β w z θ y φ K N η c A A D � + dED � + aEA � + dED � aEad θd ∼ N E κ(t)β(t) + cd,aη(t), �Jcd1122I ⎛ ⎝a∈ad 1513 would slow mixing of the MCMC chain. E-step. We sample each 77(td) a , cd, log K(·) a , and ed blockwise using the Metropolis-Hastings algorithm with a multivariate Gaussian proposal distribution, tuning the dia</context>
</contexts>
<marker>Tierney, 1994</marker>
<rawString>Luke Tierney. 1994. Markov chains for exploring posterior distributions. The Annals of Statistics, 22(4):pp. 1701–1728.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network. In</title>
<date>2003</date>
<booktitle>Proc. of NAACL.</booktitle>
<contexts>
<context position="17451" citStr="Toutanova et al., 2003" startWordPosition="2983" endWordPosition="2986"> third iteration, until we have 500 posterior samples. In our experiments, we found the posterior samples to be reasonably stable after the initial burn in. 5 Experiments Data. The ACL Anthology Network Corpus contains 21,212 papers published in the field of computational linguistics between 1965 and 2013 and written by 17,792 authors. Additionally, the corpus provides metadata such as authors, venue and in-community citation networks. For our experiments, we focused on conference papers published between 1980 and 2010.4 We tokenized the texts, tagged the tokens using the Stanford POS tagger (Toutanova et al., 2003), and extracted ngrams with tags that follow the simple (but effective) pattern of (Adj|Noun)∗ Noun (Justeson and Katz, 1995), representing the dth document as a bag of phrases (wd). Note that phrases can also be unigrams. We pruned phrases that appear in &lt; 1% or &gt; 95% of the documents, obtaining a vocabulary of V = 6,868 types. The pruned corpus contains 5,498 documents and 2,643,946 phrase tokens written by 5,575 authors. We let responses yd = log(1 + # of incoming citations in 3 years) For our experiments, we used 3 different random splits of our data (70% train, 20% test, and 10% developme</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D. Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Vogel</author>
<author>Max Bodoia</author>
<author>Christopher Potts</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Emergence of Gricean maxims from multi-agent decision theory.</title>
<date>2013</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="31344" citStr="Vogel et al. (2013)" startWordPosition="5261" endWordPosition="5264">e unique preferences of each decision making agent, nor the extrinsic-intrinsic reward tradeoffs that these agents face when authoring a document. Our utility model can also be viewed as a form of natural language generator, where we take into account the context of an author (i.e., his preferences, the tradeoff coefficient, and what is popular) to generate his document. This is related to natural language pragmatics, where text is influenced by context.9 Hovy (1990) approached the problem of generating text under pragmatic circumstances from a planning and goal-orientation perspective, while Vogel et al. (2013) used multiagent decision-theoretic models to show cooperative pragmatic behavior. Vogel et al.’s models suggest an interesting extension of ours for future work: modeling cooperation among co-authors and, perhaps, in the larger scientific discourse. 9The β vectors can be seen as a naive representation of world knowledge that motivates an author to select content that reflects his behavioral preferences and intentions. 1517 7 Conclusions We presented a model of scientific authorship in which authors trade off between seeking citation by others and staying true to their individual preferences a</context>
</contexts>
<marker>Vogel, Bodoia, Potts, Jurafsky, 2013</marker>
<rawString>Adam Vogel, Max Bodoia, Christopher Potts, and Daniel Jurafsky. 2013. Emergence of Gricean maxims from multi-agent decision theory. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg C G Wei</author>
<author>Martin A Tanner</author>
</authors>
<title>A Monte Carlo implementation of the EM algorithm and the poor man’s data augmentation algorithms.</title>
<date>1990</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>85</volume>
<issue>411</issue>
<pages>699--704</pages>
<contexts>
<context position="14462" citStr="Wei and Tanner, 1990" startWordPosition="2468" endWordPosition="2471">imal topic distribution satisfies the first-order conditions (Eq. 7). However, we cannot see the idiosyncratic component, 6d,a, which is assumed to be Gaussian; as noted, this is known as a random utility model. Together, these assumptions give the structure of the distri bution over topics in terms of (estimated) utility, which allows us to naturally incorporate the utility function into our probabilistic model in a familiar way (Sim et al., 2015). 4 Learning and Inference Exact inference in our model is intractable, so we resort to an approximate inference technique based on Monte Carlo EM (Wei and Tanner, 1990). During the E-step, we perform Bayesian inference over latent parameters z, c, using aMetropolis-Hastings within Gibbs algorithm (Tierney, 1994), and in the M-step, we compute maximum a posteriori estimates of by directly optimizing the log-likelihood function. Since we are using conjugate priors for we can integrate it out. We did not perform Bayesian posterior inference over because the coupling of (η,κ, θ, φ) β φ, β β w z θ y φ K N η c A A D � + dED � + aEA � + dED � aEad θd ∼ N E κ(t)β(t) + cd,aη(t), �Jcd1122I ⎛ ⎝a∈ad 1513 would slow mixing of the MCMC chain. E-step. We sample each 77(td)</context>
</contexts>
<marker>Wei, Tanner, 1990</marker>
<rawString>Greg C. G. Wei and Martin A. Tanner. 1990. A Monte Carlo implementation of the EM algorithm and the poor man’s data augmentation algorithms. Journal of the American Statistical Association, 85(411):pp. 699–704.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dani Yogatama</author>
<author>Michael Heilman</author>
<author>Brendan O’Connor</author>
<author>Chris Dyer</author>
<author>Bryan R Routledge</author>
<author>Noah A Smith</author>
</authors>
<title>Predicting a scientific community’s response to an article.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<marker>Yogatama, Heilman, O’Connor, Dyer, Routledge, Smith, 2011</marker>
<rawString>Dani Yogatama, Michael Heilman, Brendan O’Connor, Chris Dyer, Bryan R. Routledge, and Noah A. Smith. 2011. Predicting a scientific community’s response to an article. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yaojia Zhu</author>
<author>Xiaoran Yan</author>
<author>Lise Getoor</author>
<author>Cristopher Moore</author>
</authors>
<title>Scalable text and link analysis with mixed-topic link models.</title>
<date>2013</date>
<booktitle>In Proc. of KDD.</booktitle>
<contexts>
<context position="30243" citStr="Zhu et al., 2013" startWordPosition="5084" endWordPosition="5087">ls to study the “history of ideas.” Predicting responses to scientific articles was explored in two shared tasks at KDD Cup 2003 (Brank and Leskovec, 2003; McGovern et al., 2003) and by Yogatama et al. (2011), which served as a baseline for our experiments and whose timeseries prior we used in our model. Furthermore, there has been considerable research using topic models to predict (or recommend) citations (instead of aggregate counts), such as modeling link probabilities within the LDA framework (Cohn and Hofmann, 2000; Erosheva et al., 2004; Nallapati and Cohen, 2008; Kataria et al., 2010; Zhu et al., 2013) and augmenting topics with discriminative author features (Liu et al., 2009; Tanner and Charniak, 2015). We modeled both interests of authors and responses to their articles jointly, by assuming authors’ text production is an expected utilitymaximizing decision. This approach is similar to our earlier work (Sim et al., 2015), where authors are rational agents writing texts to maximize the chance of a favorable decision by a judicial court. In that study, we did not consider the unique preferences of each decision making agent, nor the extrinsic-intrinsic reward tradeoffs that these agents fac</context>
</contexts>
<marker>Zhu, Yan, Getoor, Moore, 2013</marker>
<rawString>Yaojia Zhu, Xiaoran Yan, Lise Getoor, and Cristopher Moore. 2013. Scalable text and link analysis with mixed-topic link models. In Proc. of KDD.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>