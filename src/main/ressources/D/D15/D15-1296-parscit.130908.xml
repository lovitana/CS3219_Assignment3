<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.998719">
A Tableau Prover for Natural Logic and Language
</title>
<author confidence="0.978286">
Lasha Abzianidze
</author>
<affiliation confidence="0.99145">
TiLPS, Tilburg University, the Netherlands
</affiliation>
<email confidence="0.972395">
L.Abzianidze@uvt.nl
</email>
<sectionHeader confidence="0.997139" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999880294117647">
Modeling the entailment relation over sen-
tences is one of the generic problems of
natural language understanding. In or-
der to account for this problem, we de-
sign a theorem prover for Natural Logic,
a logic whose terms resemble natural lan-
guage expressions. The prover is based on
an analytic tableau method and employs
syntactically and semantically motivated
schematic rules. Pairing the prover with a
preprocessor, which generates formulas of
Natural Logic from linguistic expressions,
results in a proof system for natural lan-
guage. It is shown that the system obtains
a comparable accuracy (≈81%) on the un-
seen SICK data while achieving the state-
of-the-art precision (≈98%).
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999985854166666">
A problem of recognizing textual entailments
(RTE)—given two text fragments T (for a text)
and H (for a hypothesis), determine whether T
entails, contradicts or is neutral to H—is consid-
ered as a complex and, at the same time, funda-
mental problem for several NLP tasks (Dagan et
al., 2005). For more than a decade, RTE chal-
lenges have been held, where systems are compet-
ing to each other with respect to human annotated
RTE test data; but there are few systems that try
to solve RTE problems by computing meanings
of linguistic expressions and employing inference
engines similar to proof procedures of formal log-
ics. Moreover, those few systems are usually used
in combination with shallow classifiers since the
systems’ performances alone are poor.
The current paper advocates that purely deduc-
tive inference engines over linguistic representa-
tions backed up with a simple lexical knowledge
base could be solely and successfully used for the
RTE task. Our work builds on the theory of an
analytic tableau system for Natural Logic (Natural
Tableau) introduced by Muskens (2010). The the-
ory offers to employ a tableau method—a proof
procedure used for many formal logics—for the
version of Natural Logic that employs Lambda
Logical Forms (LLFs)—certain terms of simply
typed A-calculus—as Logical Forms (LFs) of lin-
guistic expressions. The merits of the current ap-
proach are several and they can be grouped in two
categories: virtues attributed to the tableau prover
are (i) the high precision for the RTE task charac-
teristic to proof procedures, (ii) the transparency
of the reasoning process, and (iii) ability for solv-
ing problems with several premises; and those
concerning LLFs are (iv) an evidence for LFs that
are reminiscent of Surface Forms but still retaining
complex semantics, and (v) an automatized way of
obtaining LLFs from wide-coverage texts.
The rest of the paper is organized as follows.
First, Natural Tableau is introduced, and then a
method of obtaining LLFs from raw text is de-
scribed. We outline the architecture of an imple-
mented theorem prover that is based on the the-
ory of Natural Tableau. The power of the prover is
evaluated against the SICK data; the results are an-
alyzed and compared to related RTE systems. The
paper concludes with future work.
</bodyText>
<sectionHeader confidence="0.958564" genericHeader="method">
2 Natural Tableau for Natural Logic
</sectionHeader>
<bodyText confidence="0.999265363636364">
Natural Logic is a vague notion and refers to log-
ics that account for valid inferences of natural
languages, where reasoning and the grammar are
strongly related to each other and LFs resemble
surface forms (Lakoff, 1972). On the other hand,
a tableau method (Beth, 1955) is a popular proof
procedure and nowadays many formal logics have
their own version of it (D’Agostino et al., 1999).
A combination of these two devices is offered by
Muskens (2010), where the language of Natural
Logic is considered to be a part of simply typed
</bodyText>
<page confidence="0.938024">
2492
</page>
<note confidence="0.99244">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2492–2502,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figure confidence="0.99038464">
XAB: [] : F
A : [c] : T
B : [c] : F
s.t. X E {all, every}
and c is afresh term
A B : [★✕C] : X
★✕
A : [B, C] : X
★✕
A : [B, C] : X
A B : [★✕C] : X
A : [★✕C] : T
B : [★✕C] : F
X
s.t. A &lt; B
PUSH
PULL
VF
XAB: [] : F IF
A : [d] : F B : [d] : F
s.t. X E {some, a} and d is an old term
not A : [★✕C] : X
A : [★✕C] : X
&lt;X
NOT
</figure>
<figureCaption confidence="0.999615">
Figure 1: Tableau rules for quantifiers (VF and IF), Boolean operators (NOT), formatting (PUSH and
</figureCaption>
<bodyText confidence="0.671723666666667">
★✕
PULL) and inconsistency (&lt;X). The relation &lt; stands for entailment, C and X are meta-variables over
sequences of terms and truth signs (T and F), respectively; the bar operator X negates a sign.
</bodyText>
<equation confidence="0.947470166666667">
1 : not all bird fly: [] : T
2 : some bird (not fly) : [] : F
3PUSH[1] :not all bird : [fly] : T
4PUSH[3] : not all : [bird, fly] : T
5NOT[4] : all: [bird, fly] : F
6PULL[5] : all bird: [fly] : F
</equation>
<bodyText confidence="0.9918386">
λ-terms that are built up from variables and lexi-
cal constant terms with the help of application and
lambda abstraction. The terms of the language
are called LLFs and resemble linguistic surface
forms:1
</bodyText>
<equation confidence="0.288338333333333">
a(et)(et)t birdet flyet
some(et)(et)t birdet (not(et)et flyet)
not((et)(et)t)(et)(et)t all(et)(et)t birdet flyet
</equation>
<bodyText confidence="0.999857956521739">
Note that common nouns and intransitive verbs
are typed as properties (i.e. functions from enti-
ties to truth values) and quantifiers as binary rela-
tions over properties; the latter typing treats quan-
tified noun phrases (QNPs) as generalized quanti-
fiers (GQs)—a term of type properties over prop-
erties (et)t.
A Natural Tableau entry is a tuple containing
a term, a sequence of terms representing an argu-
ment list, and a truth sign. The entries are such that
when a term is applied to all arguments from an ar-
gument list in the order of the list, the resulted term
is of type truth value. For example, Aeetce:[de]:T
is a valid tableau entry (i.e. a node) since it con-
sists of a term Aeetce, an argument list [de] and
a truth sign T standing for true, and additionally,
Aeetcede is a term of type t.
A tableau method is a refutation method and it
proves an argument by searching a counterexam-
ple. The search process is guided by applications
of certain set of rules. A tableau rule is a schema
with a set of antecedent nodes above a line and a
set of precedent branches below a line, where each
</bodyText>
<footnote confidence="0.979185818181818">
7PUL
1Since modeling intensionality is beyond the scope of
the paper, we present LLFs typed with extensional seman-
tic types, i.e. types are built up from basic e (for entities) and
t (for truth values) types. We use the comma as a type con-
structor, e.g., (e, t) stands for a functional type from entities
to truth values. The comma is omitted when types are de-
noted by single letters, e.g., et stands for (e, t). Taking into
account right-associativity of the type constructor we often
drop parentheses for better readability. Terms are optionally
annotated with their types in a subscript.
</footnote>
<page confidence="0.987083">
2493
</page>
<bodyText confidence="0.995647333333333">
that none of the situations for the counterexample
were consistent.
An advantage of Natural Tableau is that it treats
both single and multi-premised arguments in the
same fashion and represents a deductive procedure
in an intuitive and transparent way.
</bodyText>
<equation confidence="0.554437">
lx[N
</equation>
<sectionHeader confidence="0.86791" genericHeader="method">
3 Obtaining LLFs for Natural Tableau
</sectionHeader>
<subsectionHeader confidence="0.993816">
3.1 CCG and the C&amp;C Parser
</subsectionHeader>
<bodyText confidence="0.994424928571429">
Combinatory Categorial Grammar (CCG) is a lex-
icalized grammar formalism that assigns a syntac-
tic category and a semantic interpretation to lexi-
cal items, where the items are combined via com-
binatory rules (Steedman, 2000; Steedman and
Baldridge, 2011). The CCG category A/B (or
A\B) is a category of an item that becomes of cat-
egory A when it is combined with an item of cat-
egory B on its right (or left, respectively) side. In
the example below, the sentence every man walks
is analyzed in the CCG formalism, where lexical
items are combined via the forward application
rule and unspecified semantic interpretations are
written in a boldface:
</bodyText>
<equation confidence="0.9898685">
every man
(S/(S\NP))/N : every N : man
S/(S\NP) : every man
S : (every man) walk
</equation>
<bodyText confidence="0.997736736842105">
The CCG derivation trees are suitable structures
for obtaining LLFs for at least two reasons. First,
the CCG framework is characterized by a trans-
parent interface between syntactic categories and
semantic types; second, there exist efficient and
robust CCG parsers for wide-coverage texts.
During obtaining LLFs, we employ the C&amp;C
CCG parser of Clark and Curran (2007) and Easy-
CCG of Lewis and Steedman (2014). While the
C&amp;C parser is a pipeline of several NLP sys-
tems: POS-tagger, chunker, named entity recog-
nizer (NER), lemmatizer (Minnen et al., 2001)
supertagger and sub-parser, EasyCCG is an ex-
tremely simple but still comparably accurate CCG
parser based on A* parsing.2 These two parsers
use different settings for supertagging and parsing;
therefore, it is interesting to test both parsers for
our application.
t$I4igure 3, there is a CCG derivation by the
</bodyText>
<footnote confidence="0.5792655">
2The employed C&amp;C parser is trained on rebanked CCG-
bank (Honnibal et al., 2010)—an updated version of CCG-
bank (Hockenmaier and Steedman, 2007) with improved
analyses for predicate-argument structures and nominal mod-
ifiers. For EasyCCG, input sentences are already processed
by the POS-tagger and the NER of the C&amp;C parser.
</footnote>
<figure confidence="0.891635846153846">
ba[S&amp;l]
fa[S&amp;t\NPth,]
f a
ba
walks
S\NP : walk
2494
Sdcl
npthr, sdcl There
npthr
np there
EX
n
</figure>
<bodyText confidence="0.998970444444444">
tifier is replaced with (n, (np, s), s), and the re-
sulted new NP is applied to the smallest clause it
occurs in; but if there are other QNPs too, then
it also applies to the clauses where other QNPs
are situated. This operation is not deterministic
and can return several terms due to multi-options
in quantifier scope ordering. As an example, two
A-terms, (9) and (10), are obtained from the CCG
term (8) of Figure 5.3
</bodyText>
<equation confidence="0.700504">
b(no(w(b(c(a t)))p))th (8)
no (w(b(Ax. a t(Ay. cyx)))p)(Az. b zth) (9)
a t(Ax. no (w(b(cx))p) (Az. b z th)) (10)
</equation>
<bodyText confidence="0.999737777777778">
Eventually the final A-terms, analogous to (9)
and (10), obtained from CCG trees will be con-
sidered as LLFs that will be used in the wide-
coverage theorem prover. It has to be stressed that
generated LLFs are theory-independent abstract
semantic representation. Any work obtaining se-
mantic representations from CCG derivations can
combine its lexicon with (already corrected) LLFs
and produce more adequate semantics in this way.
</bodyText>
<subsectionHeader confidence="0.999151">
3.3 Extending the Type System
</subsectionHeader>
<bodyText confidence="0.9066235">
An obvious and simple way to integrate the LLFs,
obtained in Subsection 3.2, in Natural Tableau is
to translate their types into semantic types built up
from e and t.4 We will not do so, because this
means the information loss since the information
about syntactic types are erased; for example, usu-
ally syntactic types pp, n and (np, s) are trans-
lated as et type. Retaining syntactic types also
contributes to fine-grained matching of nodes dur-
ing rule application in the prover. For instance,
without syntactic types it is more complex to de-
termine the context in which a term game occurs
and find an appropriate tableau rule when consid-
ering the following LLFs, gamen,ntheory and
gamepp,n(of X), as both (n, n) and (pp, n) are
usually translated into (et)et type, like it is done
by (Bos, 2009).
In order to accommodate the LLFs with syntac-
tic types in LLFs of (Muskens, 2010), we extend
the semantic type system with np, n, s, pp basic
syntactic types corresponding to basic CCG cate-
3We use initial letters of lemmas to abbreviate a term cor-
responding to a lexical entry. Note that (9) represents a read-
ing with no one having a wide scope while, in (10), a tomato
has a wide scope.
4The similar translation is carried out in (Bos, 2009) for
Boxer (Bos, 2008), where basic CCG categories are mapped
to semantic types and the mapping is isomorphically ex-
tended to complex categories.
gories. Thus complex types are now built up from
the set {e, t, np, n, s, pp} of types. The extension
automatically licenses LLFs with syntactic types
as terms of the extended language.
We go further and establish interaction between
semantic and syntactic types in terms of a subtyp-
ing C relation. The relation is defined as a partial
order over types and satisfies the following condi-
tions for any α1, α2, 01, and 02 types:
</bodyText>
<figure confidence="0.3622535">
(a) e C np, s C t, n C et, pp C et;
(b) (α1, α2)C(01, 02) iff 01 Cα1 and α2 C02;
</figure>
<bodyText confidence="0.999956">
Moreover, we add an additional typing rule to the
calculus: a term is of type 0 if it is already of type
α and α C 0. According to this typing rule, now a
term can be of multiple types. For example, both
walknp,s and mann terms are also of type et, and
all terms of type s are of type t too. From this
point on we will use a boldface style for lexical
constants of syntactic types.
Initially it may seem that the lexicon of con-
stant terms is doubled in size, but this is not
the case as several syntactic constants can mir-
ror their semantic counterparts. This is achieved
by multiple typing which enables to put seman-
tic and syntactic terms in the same term. For in-
stance, lovenp,np,s ce johnnp and atnp,pp ce de are
well-formed LLFs of type t that combine terms
of syntactic and semantic types, and there is no
need of introducing semantic terms (e.g., ateet or
loveeet) in order to have a well-formed term. In
the end, the extension of the language is conserva-
tive in the sense that LLFs and the tableau proof
of Section 2 are preserved. The latter is the case
since the tableau rules are naturally extensible to
match new LLFs.
</bodyText>
<sectionHeader confidence="0.858236" genericHeader="method">
4 Implementation of the Prover
</sectionHeader>
<bodyText confidence="0.999953846153846">
In order to further develop and evaluate Natural
Tableau, we implement the prover, LangPro, based
on the extended theory. Its general architecture
is based on the first-order logic (FOL) prover of
Fitting (1990). The prover also contains a mod-
ule for A-calculus that roughly follows (Blackburn
and Bos, 2005).
Setup of the inventory of rules is a crucial for ef-
ficiency of the prover. There is a priority order for
the categories of rules according to their computa-
tional efficiency. The prover most prefers to em-
ploy non-branching rules that introduce no fresh
terms and antecedents of which can be ignored af-
</bodyText>
<page confidence="0.942047">
2496
</page>
<bodyText confidence="0.99997235">
ter the application (e.g., NOT). Less preferred and
inefficient rules are the ones that branch, produce
new terms or antecedents of which are kept after
the application (e.g., ∀F and IF). In order to en-
courage finding short proofs, admissible rules rep-
resenting shortcuts of several rule applications are
also introduced (e.g., FUNT and ARG in Figure 9).
The inventory consists of about 50 rules, where
most of them are manually designed based on RTE
problems (see Section 5.1) and the rest represents
the essential part of the rules found in (Muskens,
2010).
The LLF generator (LLFgen) is a procedure that
generates LLFs from a CCG derivation in the way
described in Subsection 3.2. We also implement
an LLF-aligner that serves as an optional prepro-
cessor between LLFgen and the prover itself; it
aligns identical chunks of LLFs and treats them as
a constant (i.e. having no internal structure). This
treatment often leads to smaller tableau proofs.
The example of aligned LLFs is given in Figure 8.
LangPro uses only the antonymy relation and
a transitive closure of the hyponymy/hypernymy
relations from WordNet 3.0 (Fellbaum, 1998) as
its knowledge base (KB). The entailment &lt; (con-
tradiction ⊥) relation between lexical constants of
the same type A &lt; B (A⊥B) holds if there ex-
ists a WordNet sense of A that is a transitive hy-
ponym (an antonym) of some WordNet sense of
B. Note that there is no word sense disambigua-
tion (WSD) used by the prover; therefore, adopt-
ing these interpretations of entailment and contra-
diction amounts to considering all senses of the
words. For example, a man is crying entails a man
is screaming as there are senses of cry and scream
that are in the entailment relation.
All in all, chaining a CCG parser, LLFgen, the
LLF-aligner, the prover and KB results in an au-
tomatized tableau prover LangPro which operates
directly over natural language text.
</bodyText>
<sectionHeader confidence="0.962926" genericHeader="evaluation">
5 Learning and Evaluation
</sectionHeader>
<subsectionHeader confidence="0.981192">
5.1 Learning
</subsectionHeader>
<bodyText confidence="0.999964833333333">
For learning and evaluation purposes, we use the
SICK data (Marelli et al., 2014b). The data con-
sists of problems that are rich in the lexical, syn-
tactic and semantic phenomena that compositional
distributional semantic models (Mitchell and La-
pata, 2010) are expected to account for.5 The
</bodyText>
<footnote confidence="0.994944">
5SICK is partitioned in three parts (trail, train and test)
and used as a benchmark for RTE14 (Marelli et al., 2014a).
</footnote>
<bodyText confidence="0.9637765">
SICK data contains around 10K text-hypothesis
pairs that are classified in three categories: entail-
ment, contradiction, and neutral.
During learning we used only the trial portion
of the data, SICK-trial, including 500 problems.
The learning process consists of improving the
components of the prover while solving the RTE
problems: designing fixing procedures of LLFgen,
adding new sound rules to the inventory, and intro-
ducing valid relations in KB that were not found
in WordNet (e.g., woman&lt;lady, note&lt;paper and
food&lt;meal). During learning, each RTE problem
is processed as follows:
input: (T, H, answer);
</bodyText>
<listItem confidence="0.841220545454545">
1: t = the first LLF of llf(T);
2: h = the first LLF of llf(H);
3: case answer, tab{t:T, h:F}, tab{t:T, h:T}
ENTAILMENT, CLOSED, OPEN: HALT;
CONTRADICTION, OPEN, CLOSED: HALT;
NEUTRAL, OPEN, OPEN: HALT;
4: otherwise
5: if t or h is incorrect then try to amend llf; go to 1
6: else if a rule is missing then add it; go to 3
7: else if a relation is missing then add it; go to 3
8: else HALT;
</listItem>
<bodyText confidence="0.983456285714286">
A function llf denotes the combination of
LLFgen and a CCG parser; for learning
we use only the C&amp;C parser. A function
tab: 5 → {CLOSED, OPEN} returns CLOSED if
one of the tableaux initiated with aligned or non-
aligned set 5 of nodes closes; otherwise it re-
turns OPEN. For instance, while checking a prob-
lem (T, H) on entailment (contradiction), tableau
starts with a counterexample: T being true and H
false (true, respectively). Note that 5-7 procedures
are carried out manually while the phase is signifi-
cantly facilitated by graphical proofs produced by
LangPro.6
As a result, there were collected around 30 new
rules where about a third of them are admissible
ones; the new rules cover phenomena like noun
and adverbial modifiers, prepositional phrases,
passive constructions, expletive sentences, verb-
particle constructions, auxiliaries, light verb con-
structions, etc. Most of the new rules are discussed
in more details in (Abzianidze, 2015).
The data and the system results of RTE14 are available at
http://alt.qcri.org/semeval2014/task1/
6Automating a tableau rule extraction is quite hard for the
following reasons: it is unclear how to determine automat-
ically whether a CCG derivation is wrong, a tableau rule is
missing, or lexical knowledge is lacking; and the general for-
mat of a rule makes search procedure extremely inefficient.
</bodyText>
<page confidence="0.984251">
2497
</page>
<table confidence="0.95792825">
ID Gold/LP Problem (premise ? conclusion)
3670 E/N It is raining on a walking man ? A man is walking in the rain
219 E/N There is no girl in white dancing ? A girl in white is dancing
5248 N/E Someone is playing with a toad ? Someone is playing with a frog
8490 N/C A man with a shirt is holding a football ? A man with no shirt is holding a football
7402 N/C There is no man and child kayaking through gentle waters ? A man and a young boy are riding in a yellow kayak
1431 C/C A man is playing a guitar ? A man is not playing a guitar
8913 N/C A couple is not looking at a map ? A couple is looking at a map
</table>
<tableCaption confidence="0.999927">
Table 1: Problems from SICK-trial and SICK-train with gold and LangPro judgments.
</tableCaption>
<figure confidence="0.996711260869565">
SICK test (4927 problems)
LangPro❳❳❳Prec%
Rec% Acc%
Baseline (majority) - - 56.36
+C&amp;C+50 98.03 53.75 79.52
+EasyCCG+50 98.03 51.41 78.53
LangPro Hybrid-50 97.99 57.03 80.90
+C&amp;C+800 97.99 54.73 79.93
+EasyCCG+800 98.00 52.67 79.05
LangPro Hybrid-800 97.95 58.11 81.35
1
.98
.8
.75
.55
.5
.45
# 10 20 50 100 200 400 800 1600
mins. 2 5 9 14 23 38 60 115
Acc
Rec
Prec
#Rule applications &amp; runtime for 2.4GHz CPU
</figure>
<figureCaption confidence="0.981557">
Figure 6: Performance of LangPro on SICK-train
(4500) using CCG derivations of the C&amp;C parser.
</figureCaption>
<bodyText confidence="0.998716">
LangPro was unable to prove several problems
requiring complex background knowledge (e.g.,
SICK-3670 in Table 1) or having wrong CCG
derivations from the C&amp;C parser (e.g., in SICK-
219, white dancing is a noun constituent).
</bodyText>
<subsectionHeader confidence="0.99614">
5.2 Development
</subsectionHeader>
<bodyText confidence="0.999922695652174">
The part of the SICK data, SICK-train, issued for
training at RTE14 was used for development. Af-
ter running LangPro on SICK-train, we only an-
alyzed false positives, i.e. neutral problems that
were identified either as entailment or contradic-
tion by the prover. The analysis reveals that the
parsers and WordNet are responsible for almost
all these errors. For example, in Table 1, SICK-
5248 is classified as entailment since toad and
frog might have synonymous senses; this problem
shows the advantage of not using WSD, where a
proof search also searches for word senses that
might give rise to a logical relation. SICK-7402
was falsely identified as contradiction because of
the wrong analyses of the premise by both CCG
parsers: no man and child... are in coordination,
which implies there is no man, and hence, contra-
dicts the conclusion. SICK-8490 is proved as con-
tradiction since the prover considers LLFs where
shirt takes a wide scope. With the help of Lang-
Pro, we also identified inconsistency in the annota-
tions of problems, e.g., SICK-1431, 8913 are sim-
ilar problems but classified differently; it is also
</bodyText>
<tableCaption confidence="0.991449">
Table 2: Evaluation of the versions of LangPro
</tableCaption>
<bodyText confidence="0.99980725">
surprising that SICK-5248 is classified as neutral.
During this phase, also the effective (800) and
efficient (50) upper bounds for the rule application
number were determined (see Figure 6). More-
over, 97.4% of proofs found in 1600 rule appli-
cations are actually attainable in at most 50 rule
applications; this shows that the rule application
strategy of LangPro is quite efficient.
</bodyText>
<subsectionHeader confidence="0.986031">
5.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.8786091">
We evaluate LangPro on the unseen portion of the
SICK data, SICK-test, which was used as a bench-
mark at RTE14; the data was also held out from
the process of designing LLFgen. The prover clas-
sifies each SICK problem as follows:
input: (T, H);
try t = the first LLF of llf(T);
h = the first LLF of llf(H)
if no error then
case tab{t:T, h:FI, tab{t:T, h:TI
</bodyText>
<tableCaption confidence="0.4425248">
CLOSED, OPEN: classify as ENTAILMENT;
OPEN, CLOSED: classify as CONTRADICTION;
OPEN, OPEN: classify as NEUTRAL;
CLOSED, CLOSED: classify as ENTAILMENT; report it;
else classify as NEUTRAL; report it;
</tableCaption>
<bodyText confidence="0.9990715">
The results, in Table 2, show evaluation of
LangPro on SICK-test using both parsers sepa-
rately with the efficient and effective rule applica-
tion upper bounds. Slightly better results with the
C&amp;C parser is explained by employing the parser
in the learning phase. The difference of .5% in
</bodyText>
<page confidence="0.978682">
2498
</page>
<table confidence="0.999961153846154">
Measure+ Prec% Rec% Acc% (+LP)
❳❳❳❳❳❳❳❳❳❳❳
System
Illinois-LH 81.56 81.87 84.57 (+0.55)
ECNU 84.37 74.37 83.64 (+1.69)
UNAL-NLP 81.99 76.80 83.05 (+1.44)
SemantiKLUE 85.40 69.63 82.32 (+2.78)
The Meaning Factory 93.63 60.64 81.59 (+2.72)
LangPro Hybrid-800 97.95 58.11 81.35
UTexas 97.87 38.71 73.23 (+8.97)
Prob-FOL - - 76.52
Nutcracker - - 78.40
Baseline (majority) - - 56.69
</table>
<tableCaption confidence="0.9394015">
Table 3: Comparing LangPro to the top or related
RTE systems and combining their answers7
</tableCaption>
<bodyText confidence="0.999552870967742">
accuracy between the C&amp;C-based and EasyCCG-
based provers show that LLFgen was not fitted to
the C&amp;C parser’s output during the learning phase.
In order to eliminate at some extent errors com-
ing from the parsers, hybrid provers are designed
that simply combine answers of two systems—if
one of the systems proves a relation then it is an
answer. Both hybrid versions of LangPro show
more than 80% of accuracy while only 5 systems
were able to do so at RTE14, where 77.1% was a
median accuracy. The prover turns out to be ex-
tremely reliable with its state-of-the-art precision
being almost 98%. A high precision is conditioned
by the formal deductive proof nature of LangPro
and by the sound rules it employs.
In Table 3, we compare the best version of hy-
brid LangPro to the top 5 systems of RTE14 on
SICK-test and show the improvement it gives to
each system when blindly adopting its positive an-
swers (i.e. entailment and contradiction).
The decision procedure of the prover is com-
pletely rule-based and easy to comprehend since
it follows the intuitive deductive rules. Tableaux
proofs by LangPro for SICK-247 (in Figure 7) and
SICK-2895 (in Figure 8) show step by step how T
contradicts and entails, respectively, H.8 Several
new rules employed in these tableaux are given in
Figure 9. Note that the both problems, SICK-247,
2895, were wrongly classified by all the top 7 sys-
tems of the RTE14. Taking into account that solv-
ing SICK-247 requires a sort of De Morgan’s law
</bodyText>
<footnote confidence="0.996745">
7The top 5 systems of RTE14 are Illinois-LH (Lai and
Hockenmaier, 2014), ECNU (Zhao et al., 2014), UNAL-NLP
(Jimenez et al., 2014), SemantiKLUE (Proisl et al., 2014) and
The Meaning Factory (Bjerva et al., 2014).
8In the tableaux, due to lack of space, several constants
are denoted with initial characters of their lemmas and some
intermediate nodes are omitted. Some of the nodes are anno-
tated with a sequence of source rule applications.
</footnote>
<bodyText confidence="0.999868625">
for negation and disjunction, this demonstrates
where LangPro, a purely logic-based system, out-
performs non-logic-based systems.9 The another
problem, SICK-2895, is an evidence how unreli-
able the state-of-the-art and non-logic-based RTE
systems might be since solving the problem only
requires a lexical knowledge barbell ≤ weight,
which is available in WordNet.
</bodyText>
<sectionHeader confidence="0.99992" genericHeader="conclusions">
6 Related Work
</sectionHeader>
<bodyText confidence="0.975280044444445">
Using formal logic tools for a wide-coverage RTE
task goes back to the Nutcracker system (Bos and
Markert, 2005), where a wide-coverage semantic
processing tool Boxer (Bos, 2008), in combination
with the C&amp;C tools, first produces discourse rep-
resentation structures of (Kamp and Reyle, 1993)
and then FOL semantic representations (Curran et
al., 2007). Reasoning over FOL formulas is car-
ried by off-the-shelf theorem provers and model
builders for FOL.10 Our approach differs from
the latter in several main aspects: (i) the under-
ling logic of LLFs (i.e. higher-order logic) is
more expressive than FOL (e.g., it can properly
model GQs and subsective adjectives), (ii) LLFs
are cheap to get as they are easily obtained from
CCG derivations, and (iii) we develop a com-
pletely new proof procedure and a prover for a ver-
sion of Natural Logic.
The other related works are (MacCartney and
Manning, 2008) and (Angeli and Manning, 2014).
Both works contribute to Natural Logic and are
based on the same methodology.11 The approach
has two main shortcomings compared to Natural
Tableau; namely, it is unable to process multi-
premised problems, and its underling logic is
weaker (e.g., according to (MacCartney, 2009), it
cannot capture the entailment in Figure 2).
9Even a shallow heuristic—if H has a named entity that
does not appear in T, then there is no entailment—is not suf-
ficient for showing that SICK-247 is contradiction. We thank
our reviewer for mentioning this heuristic w.r.t. SICK-247.
10Nutcracker obtains 3% lower accuracy on SICK than our
prover (Pavlick et al., 2015). The Meaning Factory (Bjerva
et al., 2014) that is a brother system of Nutcracker, instead
of solely relying on decisions of theorem provers and model
builders, uses machine learning methods over the features ex-
tracted from these tools; this method results in a more ro-
bust system. RTE systems UTexas (Beltagy et al., 2014) and
Prob-FOL (Beltagy and Erk, 2015) also use Boxer FOL rep-
resentations but employ probabilistic FOL. For comparison
purposes, the results of these systems on the SICK data are
given in Table 3.
11They relate two sentences by a sequence of string edits;
the final logical relation between the sentences is computed
by composing logical relations associated with these edits.
</bodyText>
<page confidence="0.941027">
2499
</page>
<equation confidence="0.764962142857143">
1 : the w (not (be (Ax.or (a hd) (s gl) (Ay.wear y x)))) : [ ] : T
2 : a w (be (Ax.a (Eg hd) (Ay.wear y x))) : [ ] : T
33T [2] : w : [c] : T
43T [2] : be (Ax.a (Eg hd) (Ay.wear y x)) : [c] : T
5AUX[4] : Ax.a (Eg hd) (Ay.wear y x) : [c] : T
6λPULL[5] : a (Eg hd) (Ay.wear y c) : [ ] : T
7THE
</equation>
<page confidence="0.975648">
2500
</page>
<sectionHeader confidence="0.995811" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999531">
Lasha Abzianidze. 2015. Towards a wide-coverage
tableau method for natural logic. In Tsuyoshi
Murata, Koji Mineshima, and Daisuke Bekki, edi-
tors, New Frontiers in Artificial Intelligence, volume
9067 of Lecture Notes in Artificial Intelligence, page
Forthcoming. Springer-Verlag Berlin Heidelberg.
Gabor Angeli and Christopher D. Manning. 2014.
Naturalli: Natural logic inference for common sense
reasoning. In Proceedings of the 2014 Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP), pages 534–545, Doha, Qatar, Oc-
tober. Association for Computational Linguistics.
Jon Barwise and Robin Cooper. 1981. Generalized
quantifiers and natural language. Linguistics and
Philosophy, 4(2):159–219.
Islam Beltagy and Katrin Erk. 2015. On the proper
treatment of quantifiers in probabilistic logic seman-
tics. In Proceedings of the 11th International Con-
ference on Computational Semantics (IWCS-2015),
London, UK, April.
Islam Beltagy, Stephen Roller, Gemma Boleda, Katrin
Erk, and Raymond Mooney. 2014. Utexas: Natu-
ral language semantics using distributional seman-
tics and probabilistic logic. In Proceedings of the
8th International Workshop on Semantic Evaluation
(SemEval 2014), pages 796–801, Dublin, Ireland,
August. Association for Computational Linguistics
and Dublin City University.
Evert W. Beth. 1955. Semantic Entailment and Formal
Derivability. Koninklijke Nederlandse Akademie
van Wentenschappen, Proceedings of the Section of
Sciences, 18:309–342.
Johannes Bjerva, Johan Bos, Rob Van der Goot, and
Malvina Nissim. 2014. The meaning factory: For-
mal semantics for recognizing textual entailment
and determining semantic similarity. In Proceedings
of the 8th International Workshop on Semantic Eval-
uation (SemEval 2014), pages 642–646, Dublin, Ire-
land.
Patrick Blackburn and Johan Bos. 2005. Represen-
tation and Inference for Natural Language: A First
Course in Computational Semantics. CSLI Press.
Johan Bos and Katja Markert. 2005. Recognising tex-
tual entailment with logical inference. In Proceed-
ings of the 2005 Conference on Empirical Methods
in Natural Language Processing (EMNLP 2005),
pages 628–635.
Johan Bos. 2008. Wide-coverage semantic analy-
sis with boxer. In Johan Bos and Rodolfo Del-
monte, editors, Semantics in Text Processing. STEP
2008 Conference Proceedings, Research in Compu-
tational Semantics, pages 277–286. College Publi-
cations.
Johan Bos. 2009. Towards a large-scale formal se-
mantic lexicon for text processing. In C. Chiarcos,
R. Eckart de Castilho, and Manfred Stede, editors,
From Form to Meaning: Processing Texts Automati-
cally. Proceedings of the Biennal GSCL Conference
2009, pages 3–14.
Stephen Clark and James R. Curran. 2007. Wide-
coverage efficient statistical parsing with ccg and
log-linear models. Computational Linguistics, 33.
The Fracas Consortium, Robin Cooper, Dick Crouch,
Jan Van Eijck, Chris Fox, Josef Van Genabith,
Jan Jaspars, Hans Kamp, David Milward, Man-
fred Pinkal, Massimo Poesio, Steve Pulman, Ted
Briscoe, Holger Maier, and Karsten Konrad. 1996.
Using the framework.
James Curran, Stephen Clark, and Johan Bos. 2007.
Linguistically motivated large-scale nlp with c&amp;c
and boxer. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguis-
tics Companion Volume Proceedings of the Demo
and Poster Sessions, pages 33–36, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
Ido Dagan, Oren Glickman, and Bernardo Magnini.
2005. The pascal recognising textual entailment
challenge. In Proceedings of the PASCAL Chal-
lenges Workshop on Recognising Textual Entail-
ment.
Marcello D’Agostino, Dov M. Gabbay, Reiner Hhnle,
and Joachim Posegga, editors. 1999. Handbook of
Tableau Methods. Springer.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Melvin Fitting. 1990. First-order Logic and Au-
tomated Theorem Proving. Springer-Verlag New
York, Inc., New York, NY, USA.
Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2013. PPDB: The paraphrase
database. In Proceedings of NAACL-HLT, pages
758–764, Atlanta, Georgia, June. Association for
Computational Linguistics.
Julia Hockenmaier and Mark Steedman. 2007. Ccg-
bank: A corpus of ccg derivations and dependency
structures extracted from the penn treebank. Com-
put. Linguist., 33(3):355–396, September.
Matthew Honnibal, James R. Curran, and Johan Bos.
2010. Rebanking ccgbank for improved np inter-
pretation. In Proceedings of the 48th Meeting of
the Association for Computational Linguistics (ACL
2010), pages 207–215, Uppsala, Sweden.
Sergio Jimenez, George Due˜nas, Julia Baquero, and
Alexander Gelbukh. 2014. Unal-nlp: Combining
soft cardinality features for semantic textual similar-
ity, relatedness and entailment. In Proceedings of
</reference>
<page confidence="0.691821">
2501
</page>
<reference confidence="0.999784515463917">
the 8th International Workshop on Semantic Evalu-
ation (SemEval 2014), pages 732–742, Dublin, Ire-
land, August. Association for Computational Lin-
guistics and Dublin City University.
Hans Kamp and Uwe Reyle. 1993. From discourse to
logic; an introduction to modeltheoretic semantics
of natural language, formal logic and DRT. Dor-
drecht: Kluwer.
Alice Lai and Julia Hockenmaier. 2014. Illinois-lh: A
denotational and distributional approach to seman-
tics. In Proceedings of the 8th International Work-
shop on Semantic Evaluation (SemEval 2014), pages
329–334, Dublin, Ireland, August. Association for
Computational Linguistics and Dublin City Univer-
sity.
George Lakoff. 1972. Linguistics and natural logic. In
Donald Davidson and Gilbert Harman, editors, Se-
mantics of Natural Language, volume 40 of Syn-
these Library, pages 545–665. Springer Nether-
lands.
Mike Lewis and Mark Steedman. 2014. A* ccg pars-
ing with a supertag-factored model. In Proceed-
ings of the 2014 Conference on Empirical Methods
in Natural Language Processing (EMNLP), pages
990–1000, Doha, Qatar, October. Association for
Computational Linguistics.
Bill MacCartney and Christopher D. Manning. 2008.
Modeling semantic containment and exclusion in
natural language inference. In Donia Scott and Hans
Uszkoreit, editors, COLING, pages 521–528.
Bill MacCartney. 2009. Natural language inference.
Phd thesis, Stanford University.
Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014a. Semeval-2014 task 1: Evaluation of
compositional distributional semantic models on full
sentences through semantic relatedness and textual
entailment. In Proceedings of SemEval 2014 (Inter-
national Workshop on Semantic Evaluation), pages
1–8, East Stroudsburg PA. ACL.
Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Roberto Zam-
parelli. 2014b. A sick cure for the evaluation of
compositional distributional semantic models. In
Nicoletta Calzolari, Khalid Choukri, Thierry De-
clerck, Hrafn Loftsson, Bente Maegaard, Joseph
Mariani, Asuncion Moreno, Jan Odijk, and Stelios
Piperidis, editors, Proceedings of the Ninth Inter-
national Conference on Language Resources and
Evaluation (LREC’14), Reykjavik, Iceland. Euro-
pean Language Resources Association (ELRA).
Guido Minnen, John Carroll, and Darren Pearce. 2001.
Applied morphological processing of english. Nat-
ural Language Engineering, 7(3):207–223, Septem-
ber.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1439.
Richard Montague. 1974. English as a Formal Lan-
guage. In Richmond H. Thomason, editor, Formal
philosophy: Selected Papers of Richard Montague,
chapter 6, pages 188–221. Yale University Press.
Reinhard Muskens. 2010. An analytic tableau sys-
tem for natural logic. In Maria Aloni, Harald Bas-
tiaanse, Tikitu de Jager, and Katrin Schulz, editors,
Logic, Language and Meaning, volume 6042 of Lec-
ture Notes in Computer Science, pages 104–113.
Springer Berlin Heidelberg.
Ellie Pavlick, Johan Bos, Malvina Nissim, Charley
Beller, Benjamin Van Durme, and Chris Callison-
Burch. 2015. Adding semantics to data-driven para-
phrasing. In Proceedings of the 53rd Annual Meet-
ing of the Association for Computational Linguistics
(ACL 2015), pages 1512–1522.
Thomas Proisl, Stefan Evert, Paul Greiner, and Besim
Kabashi. 2014. Semantiklue: Robust semantic
similarity at multiple levels using maximum weight
matching. In Proceedings of the 8th International
Workshop on Semantic Evaluation (SemEval 2014),
pages 532–540, Dublin, Ireland, August. Associa-
tion for Computational Linguistics and Dublin City
University.
Mark Steedman and Jason Baldridge. 2011. Combina-
tory categorial grammar. In D. Borsley, Robert and
Kersti Brjars, editors, Non-Transformational Syn-
tax: Formal and Explicit Models of Grammar, pages
181–224. Wiley-Blackwell.
Mark Steedman. 2000. The Syntactic Process. MIT
Press, Cambridge, MA, USA.
Jiang Zhao, Tiantian Zhu, and Man Lan. 2014. Ecnu:
One stone two birds: Ensemble of heterogenous
measures for semantic relatedness and textual entail-
ment. In Proceedings of the 8th International Work-
shop on Semantic Evaluation (SemEval 2014), pages
271–277, Dublin, Ireland, August. Association for
Computational Linguistics and Dublin City Univer-
sity.
</reference>
<page confidence="0.994617">
2502
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.130014">
<title confidence="0.995987">A Tableau Prover for Natural Logic and Language</title>
<author confidence="0.504838">Lasha Abzianidze</author>
<degree confidence="0.368105">TiLPS, Tilburg University, the</degree>
<email confidence="0.813738">L.Abzianidze@uvt.nl</email>
<abstract confidence="0.999120411764706">Modeling the entailment relation over sentences is one of the generic problems of natural language understanding. In order to account for this problem, we design a theorem prover for Natural Logic, a logic whose terms resemble natural language expressions. The prover is based on an analytic tableau method and employs syntactically and semantically motivated schematic rules. Pairing the prover with a preprocessor, which generates formulas of Natural Logic from linguistic expressions, results in a proof system for natural language. It is shown that the system obtains comparable accuracy on the unseen SICK data while achieving the state-</abstract>
<intro confidence="0.977103">precision</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lasha Abzianidze</author>
</authors>
<title>Towards a wide-coverage tableau method for natural logic.</title>
<date>2015</date>
<booktitle>In Tsuyoshi Murata, Koji Mineshima, and Daisuke Bekki, editors, New Frontiers in Artificial Intelligence,</booktitle>
<volume>9067</volume>
<pages>page</pages>
<publisher>Springer-Verlag</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="17963" citStr="Abzianidze, 2015" startWordPosition="3114" endWordPosition="3115">ontradiction), tableau starts with a counterexample: T being true and H false (true, respectively). Note that 5-7 procedures are carried out manually while the phase is significantly facilitated by graphical proofs produced by LangPro.6 As a result, there were collected around 30 new rules where about a third of them are admissible ones; the new rules cover phenomena like noun and adverbial modifiers, prepositional phrases, passive constructions, expletive sentences, verbparticle constructions, auxiliaries, light verb constructions, etc. Most of the new rules are discussed in more details in (Abzianidze, 2015). The data and the system results of RTE14 are available at http://alt.qcri.org/semeval2014/task1/ 6Automating a tableau rule extraction is quite hard for the following reasons: it is unclear how to determine automatically whether a CCG derivation is wrong, a tableau rule is missing, or lexical knowledge is lacking; and the general format of a rule makes search procedure extremely inefficient. 2497 ID Gold/LP Problem (premise ? conclusion) 3670 E/N It is raining on a walking man ? A man is walking in the rain 219 E/N There is no girl in white dancing ? A girl in white is dancing 5248 N/E Someo</context>
</contexts>
<marker>Abzianidze, 2015</marker>
<rawString>Lasha Abzianidze. 2015. Towards a wide-coverage tableau method for natural logic. In Tsuyoshi Murata, Koji Mineshima, and Daisuke Bekki, editors, New Frontiers in Artificial Intelligence, volume 9067 of Lecture Notes in Artificial Intelligence, page Forthcoming. Springer-Verlag Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabor Angeli</author>
<author>Christopher D Manning</author>
</authors>
<title>Naturalli: Natural logic inference for common sense reasoning.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>534--545</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Doha, Qatar,</location>
<contexts>
<context position="25897" citStr="Angeli and Manning, 2014" startWordPosition="4455" endWordPosition="4458"> semantic representations (Curran et al., 2007). Reasoning over FOL formulas is carried by off-the-shelf theorem provers and model builders for FOL.10 Our approach differs from the latter in several main aspects: (i) the underling logic of LLFs (i.e. higher-order logic) is more expressive than FOL (e.g., it can properly model GQs and subsective adjectives), (ii) LLFs are cheap to get as they are easily obtained from CCG derivations, and (iii) we develop a completely new proof procedure and a prover for a version of Natural Logic. The other related works are (MacCartney and Manning, 2008) and (Angeli and Manning, 2014). Both works contribute to Natural Logic and are based on the same methodology.11 The approach has two main shortcomings compared to Natural Tableau; namely, it is unable to process multipremised problems, and its underling logic is weaker (e.g., according to (MacCartney, 2009), it cannot capture the entailment in Figure 2). 9Even a shallow heuristic—if H has a named entity that does not appear in T, then there is no entailment—is not sufficient for showing that SICK-247 is contradiction. We thank our reviewer for mentioning this heuristic w.r.t. SICK-247. 10Nutcracker obtains 3% lower accurac</context>
</contexts>
<marker>Angeli, Manning, 2014</marker>
<rawString>Gabor Angeli and Christopher D. Manning. 2014. Naturalli: Natural logic inference for common sense reasoning. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 534–545, Doha, Qatar, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Barwise</author>
<author>Robin Cooper</author>
</authors>
<title>Generalized quantifiers and natural language.</title>
<date>1981</date>
<journal>Linguistics and Philosophy,</journal>
<volume>4</volume>
<issue>2</issue>
<marker>Barwise, Cooper, 1981</marker>
<rawString>Jon Barwise and Robin Cooper. 1981. Generalized quantifiers and natural language. Linguistics and Philosophy, 4(2):159–219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Islam Beltagy</author>
<author>Katrin Erk</author>
</authors>
<title>On the proper treatment of quantifiers in probabilistic logic semantics.</title>
<date>2015</date>
<booktitle>In Proceedings of the 11th International Conference on Computational Semantics (IWCS-2015),</booktitle>
<location>London, UK,</location>
<contexts>
<context position="26906" citStr="Beltagy and Erk, 2015" startWordPosition="4619" endWordPosition="4622">not appear in T, then there is no entailment—is not sufficient for showing that SICK-247 is contradiction. We thank our reviewer for mentioning this heuristic w.r.t. SICK-247. 10Nutcracker obtains 3% lower accuracy on SICK than our prover (Pavlick et al., 2015). The Meaning Factory (Bjerva et al., 2014) that is a brother system of Nutcracker, instead of solely relying on decisions of theorem provers and model builders, uses machine learning methods over the features extracted from these tools; this method results in a more robust system. RTE systems UTexas (Beltagy et al., 2014) and Prob-FOL (Beltagy and Erk, 2015) also use Boxer FOL representations but employ probabilistic FOL. For comparison purposes, the results of these systems on the SICK data are given in Table 3. 11They relate two sentences by a sequence of string edits; the final logical relation between the sentences is computed by composing logical relations associated with these edits. 2499 1 : the w (not (be (Ax.or (a hd) (s gl) (Ay.wear y x)))) : [ ] : T 2 : a w (be (Ax.a (Eg hd) (Ay.wear y x))) : [ ] : T 33T [2] : w : [c] : T 43T [2] : be (Ax.a (Eg hd) (Ay.wear y x)) : [c] : T 5AUX[4] : Ax.a (Eg hd) (Ay.wear y x) : [c] : T 6λPULL[5] : a (E</context>
</contexts>
<marker>Beltagy, Erk, 2015</marker>
<rawString>Islam Beltagy and Katrin Erk. 2015. On the proper treatment of quantifiers in probabilistic logic semantics. In Proceedings of the 11th International Conference on Computational Semantics (IWCS-2015), London, UK, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Islam Beltagy</author>
<author>Stephen Roller</author>
<author>Gemma Boleda</author>
<author>Katrin Erk</author>
<author>Raymond Mooney</author>
</authors>
<title>Utexas: Natural language semantics using distributional semantics and probabilistic logic.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>796--801</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics and Dublin City University.</institution>
<location>Dublin, Ireland,</location>
<contexts>
<context position="26869" citStr="Beltagy et al., 2014" startWordPosition="4613" endWordPosition="4616">c—if H has a named entity that does not appear in T, then there is no entailment—is not sufficient for showing that SICK-247 is contradiction. We thank our reviewer for mentioning this heuristic w.r.t. SICK-247. 10Nutcracker obtains 3% lower accuracy on SICK than our prover (Pavlick et al., 2015). The Meaning Factory (Bjerva et al., 2014) that is a brother system of Nutcracker, instead of solely relying on decisions of theorem provers and model builders, uses machine learning methods over the features extracted from these tools; this method results in a more robust system. RTE systems UTexas (Beltagy et al., 2014) and Prob-FOL (Beltagy and Erk, 2015) also use Boxer FOL representations but employ probabilistic FOL. For comparison purposes, the results of these systems on the SICK data are given in Table 3. 11They relate two sentences by a sequence of string edits; the final logical relation between the sentences is computed by composing logical relations associated with these edits. 2499 1 : the w (not (be (Ax.or (a hd) (s gl) (Ay.wear y x)))) : [ ] : T 2 : a w (be (Ax.a (Eg hd) (Ay.wear y x))) : [ ] : T 33T [2] : w : [c] : T 43T [2] : be (Ax.a (Eg hd) (Ay.wear y x)) : [c] : T 5AUX[4] : Ax.a (Eg hd) (Ay</context>
</contexts>
<marker>Beltagy, Roller, Boleda, Erk, Mooney, 2014</marker>
<rawString>Islam Beltagy, Stephen Roller, Gemma Boleda, Katrin Erk, and Raymond Mooney. 2014. Utexas: Natural language semantics using distributional semantics and probabilistic logic. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 796–801, Dublin, Ireland, August. Association for Computational Linguistics and Dublin City University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evert W Beth</author>
</authors>
<title>Semantic Entailment and Formal Derivability. Koninklijke Nederlandse Akademie van Wentenschappen,</title>
<date>1955</date>
<booktitle>Proceedings of the Section of Sciences,</booktitle>
<pages>18--309</pages>
<contexts>
<context position="3416" citStr="Beth, 1955" startWordPosition="554" endWordPosition="555">g LLFs from raw text is described. We outline the architecture of an implemented theorem prover that is based on the theory of Natural Tableau. The power of the prover is evaluated against the SICK data; the results are analyzed and compared to related RTE systems. The paper concludes with future work. 2 Natural Tableau for Natural Logic Natural Logic is a vague notion and refers to logics that account for valid inferences of natural languages, where reasoning and the grammar are strongly related to each other and LFs resemble surface forms (Lakoff, 1972). On the other hand, a tableau method (Beth, 1955) is a popular proof procedure and nowadays many formal logics have their own version of it (D’Agostino et al., 1999). A combination of these two devices is offered by Muskens (2010), where the language of Natural Logic is considered to be a part of simply typed 2492 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2492–2502, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. XAB: [] : F A : [c] : T B : [c] : F s.t. X E {all, every} and c is afresh term A B : [★✕C] : X ★✕ A : [B, C] : X ★✕ A : [B, C] : X A B : [</context>
</contexts>
<marker>Beth, 1955</marker>
<rawString>Evert W. Beth. 1955. Semantic Entailment and Formal Derivability. Koninklijke Nederlandse Akademie van Wentenschappen, Proceedings of the Section of Sciences, 18:309–342.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Bjerva</author>
<author>Johan Bos</author>
<author>Rob Van der Goot</author>
<author>Malvina Nissim</author>
</authors>
<title>The meaning factory: Formal semantics for recognizing textual entailment and determining semantic similarity.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>642--646</pages>
<location>Dublin, Ireland.</location>
<marker>Bjerva, Bos, Van der Goot, Nissim, 2014</marker>
<rawString>Johannes Bjerva, Johan Bos, Rob Van der Goot, and Malvina Nissim. 2014. The meaning factory: Formal semantics for recognizing textual entailment and determining semantic similarity. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 642–646, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Blackburn</author>
<author>Johan Bos</author>
</authors>
<title>Representation and Inference for Natural Language: A First Course in Computational Semantics.</title>
<date>2005</date>
<publisher>CSLI Press.</publisher>
<contexts>
<context position="13379" citStr="Blackburn and Bos, 2005" startWordPosition="2339" endWordPosition="2342"> (e.g., ateet or loveeet) in order to have a well-formed term. In the end, the extension of the language is conservative in the sense that LLFs and the tableau proof of Section 2 are preserved. The latter is the case since the tableau rules are naturally extensible to match new LLFs. 4 Implementation of the Prover In order to further develop and evaluate Natural Tableau, we implement the prover, LangPro, based on the extended theory. Its general architecture is based on the first-order logic (FOL) prover of Fitting (1990). The prover also contains a module for A-calculus that roughly follows (Blackburn and Bos, 2005). Setup of the inventory of rules is a crucial for efficiency of the prover. There is a priority order for the categories of rules according to their computational efficiency. The prover most prefers to employ non-branching rules that introduce no fresh terms and antecedents of which can be ignored af2496 ter the application (e.g., NOT). Less preferred and inefficient rules are the ones that branch, produce new terms or antecedents of which are kept after the application (e.g., ∀F and IF). In order to encourage finding short proofs, admissible rules representing shortcuts of several rule appli</context>
</contexts>
<marker>Blackburn, Bos, 2005</marker>
<rawString>Patrick Blackburn and Johan Bos. 2005. Representation and Inference for Natural Language: A First Course in Computational Semantics. CSLI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Katja Markert</author>
</authors>
<title>Recognising textual entailment with logical inference.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>628--635</pages>
<contexts>
<context position="25080" citStr="Bos and Markert, 2005" startWordPosition="4322" endWordPosition="4325"> their lemmas and some intermediate nodes are omitted. Some of the nodes are annotated with a sequence of source rule applications. for negation and disjunction, this demonstrates where LangPro, a purely logic-based system, outperforms non-logic-based systems.9 The another problem, SICK-2895, is an evidence how unreliable the state-of-the-art and non-logic-based RTE systems might be since solving the problem only requires a lexical knowledge barbell ≤ weight, which is available in WordNet. 6 Related Work Using formal logic tools for a wide-coverage RTE task goes back to the Nutcracker system (Bos and Markert, 2005), where a wide-coverage semantic processing tool Boxer (Bos, 2008), in combination with the C&amp;C tools, first produces discourse representation structures of (Kamp and Reyle, 1993) and then FOL semantic representations (Curran et al., 2007). Reasoning over FOL formulas is carried by off-the-shelf theorem provers and model builders for FOL.10 Our approach differs from the latter in several main aspects: (i) the underling logic of LLFs (i.e. higher-order logic) is more expressive than FOL (e.g., it can properly model GQs and subsective adjectives), (ii) LLFs are cheap to get as they are easily ob</context>
</contexts>
<marker>Bos, Markert, 2005</marker>
<rawString>Johan Bos and Katja Markert. 2005. Recognising textual entailment with logical inference. In Proceedings of the 2005 Conference on Empirical Methods in Natural Language Processing (EMNLP 2005), pages 628–635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Wide-coverage semantic analysis with boxer.</title>
<date>2008</date>
<booktitle>Semantics in Text Processing. STEP 2008 Conference Proceedings, Research in Computational Semantics,</booktitle>
<pages>277--286</pages>
<editor>In Johan Bos and Rodolfo Delmonte, editors,</editor>
<publisher>College Publications.</publisher>
<contexts>
<context position="11278" citStr="Bos, 2008" startWordPosition="1955" endWordPosition="1956">lowing LLFs, gamen,ntheory and gamepp,n(of X), as both (n, n) and (pp, n) are usually translated into (et)et type, like it is done by (Bos, 2009). In order to accommodate the LLFs with syntactic types in LLFs of (Muskens, 2010), we extend the semantic type system with np, n, s, pp basic syntactic types corresponding to basic CCG cate3We use initial letters of lemmas to abbreviate a term corresponding to a lexical entry. Note that (9) represents a reading with no one having a wide scope while, in (10), a tomato has a wide scope. 4The similar translation is carried out in (Bos, 2009) for Boxer (Bos, 2008), where basic CCG categories are mapped to semantic types and the mapping is isomorphically extended to complex categories. gories. Thus complex types are now built up from the set {e, t, np, n, s, pp} of types. The extension automatically licenses LLFs with syntactic types as terms of the extended language. We go further and establish interaction between semantic and syntactic types in terms of a subtyping C relation. The relation is defined as a partial order over types and satisfies the following conditions for any α1, α2, 01, and 02 types: (a) e C np, s C t, n C et, pp C et; (b) (α1, α2)C(</context>
<context position="25146" citStr="Bos, 2008" startWordPosition="4333" endWordPosition="4334">nnotated with a sequence of source rule applications. for negation and disjunction, this demonstrates where LangPro, a purely logic-based system, outperforms non-logic-based systems.9 The another problem, SICK-2895, is an evidence how unreliable the state-of-the-art and non-logic-based RTE systems might be since solving the problem only requires a lexical knowledge barbell ≤ weight, which is available in WordNet. 6 Related Work Using formal logic tools for a wide-coverage RTE task goes back to the Nutcracker system (Bos and Markert, 2005), where a wide-coverage semantic processing tool Boxer (Bos, 2008), in combination with the C&amp;C tools, first produces discourse representation structures of (Kamp and Reyle, 1993) and then FOL semantic representations (Curran et al., 2007). Reasoning over FOL formulas is carried by off-the-shelf theorem provers and model builders for FOL.10 Our approach differs from the latter in several main aspects: (i) the underling logic of LLFs (i.e. higher-order logic) is more expressive than FOL (e.g., it can properly model GQs and subsective adjectives), (ii) LLFs are cheap to get as they are easily obtained from CCG derivations, and (iii) we develop a completely new</context>
</contexts>
<marker>Bos, 2008</marker>
<rawString>Johan Bos. 2008. Wide-coverage semantic analysis with boxer. In Johan Bos and Rodolfo Delmonte, editors, Semantics in Text Processing. STEP 2008 Conference Proceedings, Research in Computational Semantics, pages 277–286. College Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Towards a large-scale formal semantic lexicon for text processing.</title>
<date>2009</date>
<booktitle>From Form to Meaning: Processing Texts Automatically. Proceedings of the Biennal GSCL Conference</booktitle>
<pages>3--14</pages>
<editor>In C. Chiarcos, R. Eckart de Castilho, and Manfred Stede, editors,</editor>
<contexts>
<context position="10813" citStr="Bos, 2009" startWordPosition="1869" endWordPosition="1870">because this means the information loss since the information about syntactic types are erased; for example, usually syntactic types pp, n and (np, s) are translated as et type. Retaining syntactic types also contributes to fine-grained matching of nodes during rule application in the prover. For instance, without syntactic types it is more complex to determine the context in which a term game occurs and find an appropriate tableau rule when considering the following LLFs, gamen,ntheory and gamepp,n(of X), as both (n, n) and (pp, n) are usually translated into (et)et type, like it is done by (Bos, 2009). In order to accommodate the LLFs with syntactic types in LLFs of (Muskens, 2010), we extend the semantic type system with np, n, s, pp basic syntactic types corresponding to basic CCG cate3We use initial letters of lemmas to abbreviate a term corresponding to a lexical entry. Note that (9) represents a reading with no one having a wide scope while, in (10), a tomato has a wide scope. 4The similar translation is carried out in (Bos, 2009) for Boxer (Bos, 2008), where basic CCG categories are mapped to semantic types and the mapping is isomorphically extended to complex categories. gories. Thu</context>
</contexts>
<marker>Bos, 2009</marker>
<rawString>Johan Bos. 2009. Towards a large-scale formal semantic lexicon for text processing. In C. Chiarcos, R. Eckart de Castilho, and Manfred Stede, editors, From Form to Meaning: Processing Texts Automatically. Proceedings of the Biennal GSCL Conference 2009, pages 3–14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Widecoverage efficient statistical parsing with ccg and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<contexts>
<context position="8109" citStr="Clark and Curran (2007)" startWordPosition="1409" endWordPosition="1412">walks is analyzed in the CCG formalism, where lexical items are combined via the forward application rule and unspecified semantic interpretations are written in a boldface: every man (S/(S\NP))/N : every N : man S/(S\NP) : every man S : (every man) walk The CCG derivation trees are suitable structures for obtaining LLFs for at least two reasons. First, the CCG framework is characterized by a transparent interface between syntactic categories and semantic types; second, there exist efficient and robust CCG parsers for wide-coverage texts. During obtaining LLFs, we employ the C&amp;C CCG parser of Clark and Curran (2007) and EasyCCG of Lewis and Steedman (2014). While the C&amp;C parser is a pipeline of several NLP systems: POS-tagger, chunker, named entity recognizer (NER), lemmatizer (Minnen et al., 2001) supertagger and sub-parser, EasyCCG is an extremely simple but still comparably accurate CCG parser based on A* parsing.2 These two parsers use different settings for supertagging and parsing; therefore, it is interesting to test both parsers for our application. t$I4igure 3, there is a CCG derivation by the 2The employed C&amp;C parser is trained on rebanked CCGbank (Honnibal et al., 2010)—an updated version of C</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James R. Curran. 2007. Widecoverage efficient statistical parsing with ccg and log-linear models. Computational Linguistics, 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>The Fracas Consortium</author>
<author>Robin Cooper</author>
<author>Dick Crouch</author>
<author>Jan Van Eijck</author>
<author>Chris Fox</author>
<author>Josef Van Genabith</author>
<author>Jan Jaspars</author>
<author>Hans Kamp</author>
<author>David Milward</author>
<author>Manfred Pinkal</author>
<author>Massimo Poesio</author>
<author>Steve Pulman</author>
<author>Ted Briscoe</author>
<author>Holger Maier</author>
<author>Karsten Konrad</author>
</authors>
<title>Using the framework.</title>
<date>1996</date>
<marker>Consortium, Cooper, Crouch, Van Eijck, Fox, Van Genabith, Jaspars, Kamp, Milward, Pinkal, Poesio, Pulman, Briscoe, Maier, Konrad, 1996</marker>
<rawString>The Fracas Consortium, Robin Cooper, Dick Crouch, Jan Van Eijck, Chris Fox, Josef Van Genabith, Jan Jaspars, Hans Kamp, David Milward, Manfred Pinkal, Massimo Poesio, Steve Pulman, Ted Briscoe, Holger Maier, and Karsten Konrad. 1996. Using the framework.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Curran</author>
<author>Stephen Clark</author>
<author>Johan Bos</author>
</authors>
<title>Linguistically motivated large-scale nlp with c&amp;c and boxer.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>33--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="25319" citStr="Curran et al., 2007" startWordPosition="4357" endWordPosition="4360">ogic-based systems.9 The another problem, SICK-2895, is an evidence how unreliable the state-of-the-art and non-logic-based RTE systems might be since solving the problem only requires a lexical knowledge barbell ≤ weight, which is available in WordNet. 6 Related Work Using formal logic tools for a wide-coverage RTE task goes back to the Nutcracker system (Bos and Markert, 2005), where a wide-coverage semantic processing tool Boxer (Bos, 2008), in combination with the C&amp;C tools, first produces discourse representation structures of (Kamp and Reyle, 1993) and then FOL semantic representations (Curran et al., 2007). Reasoning over FOL formulas is carried by off-the-shelf theorem provers and model builders for FOL.10 Our approach differs from the latter in several main aspects: (i) the underling logic of LLFs (i.e. higher-order logic) is more expressive than FOL (e.g., it can properly model GQs and subsective adjectives), (ii) LLFs are cheap to get as they are easily obtained from CCG derivations, and (iii) we develop a completely new proof procedure and a prover for a version of Natural Logic. The other related works are (MacCartney and Manning, 2008) and (Angeli and Manning, 2014). Both works contribut</context>
</contexts>
<marker>Curran, Clark, Bos, 2007</marker>
<rawString>James Curran, Stephen Clark, and Johan Bos. 2007. Linguistically motivated large-scale nlp with c&amp;c and boxer. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 33–36, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Oren Glickman</author>
<author>Bernardo Magnini</author>
</authors>
<title>The pascal recognising textual entailment challenge.</title>
<date>2005</date>
<booktitle>In Proceedings of the PASCAL Challenges Workshop on Recognising Textual Entailment.</booktitle>
<contexts>
<context position="1120" citStr="Dagan et al., 2005" startWordPosition="173" endWordPosition="176">matic rules. Pairing the prover with a preprocessor, which generates formulas of Natural Logic from linguistic expressions, results in a proof system for natural language. It is shown that the system obtains a comparable accuracy (≈81%) on the unseen SICK data while achieving the stateof-the-art precision (≈98%). 1 Introduction A problem of recognizing textual entailments (RTE)—given two text fragments T (for a text) and H (for a hypothesis), determine whether T entails, contradicts or is neutral to H—is considered as a complex and, at the same time, fundamental problem for several NLP tasks (Dagan et al., 2005). For more than a decade, RTE challenges have been held, where systems are competing to each other with respect to human annotated RTE test data; but there are few systems that try to solve RTE problems by computing meanings of linguistic expressions and employing inference engines similar to proof procedures of formal logics. Moreover, those few systems are usually used in combination with shallow classifiers since the systems’ performances alone are poor. The current paper advocates that purely deductive inference engines over linguistic representations backed up with a simple lexical knowle</context>
</contexts>
<marker>Dagan, Glickman, Magnini, 2005</marker>
<rawString>Ido Dagan, Oren Glickman, and Bernardo Magnini. 2005. The pascal recognising textual entailment challenge. In Proceedings of the PASCAL Challenges Workshop on Recognising Textual Entailment.</rawString>
</citation>
<citation valid="true">
<date>1999</date>
<booktitle>Handbook of Tableau Methods.</booktitle>
<editor>Marcello D’Agostino, Dov M. Gabbay, Reiner Hhnle, and Joachim Posegga, editors.</editor>
<publisher>Springer.</publisher>
<marker>1999</marker>
<rawString>Marcello D’Agostino, Dov M. Gabbay, Reiner Hhnle, and Joachim Posegga, editors. 1999. Handbook of Tableau Methods. Springer.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Melvin Fitting</author>
</authors>
<title>First-order Logic and Automated Theorem Proving.</title>
<date>1990</date>
<publisher>Springer-Verlag</publisher>
<location>New York,</location>
<contexts>
<context position="13282" citStr="Fitting (1990)" startWordPosition="2325" endWordPosition="2326">rms of syntactic and semantic types, and there is no need of introducing semantic terms (e.g., ateet or loveeet) in order to have a well-formed term. In the end, the extension of the language is conservative in the sense that LLFs and the tableau proof of Section 2 are preserved. The latter is the case since the tableau rules are naturally extensible to match new LLFs. 4 Implementation of the Prover In order to further develop and evaluate Natural Tableau, we implement the prover, LangPro, based on the extended theory. Its general architecture is based on the first-order logic (FOL) prover of Fitting (1990). The prover also contains a module for A-calculus that roughly follows (Blackburn and Bos, 2005). Setup of the inventory of rules is a crucial for efficiency of the prover. There is a priority order for the categories of rules according to their computational efficiency. The prover most prefers to employ non-branching rules that introduce no fresh terms and antecedents of which can be ignored af2496 ter the application (e.g., NOT). Less preferred and inefficient rules are the ones that branch, produce new terms or antecedents of which are kept after the application (e.g., ∀F and IF). In order</context>
</contexts>
<marker>Fitting, 1990</marker>
<rawString>Melvin Fitting. 1990. First-order Logic and Automated Theorem Proving. Springer-Verlag New York, Inc., New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Benjamin Van Durme</author>
<author>Chris Callison-Burch</author>
</authors>
<title>PPDB: The paraphrase database.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>758--764</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia,</location>
<marker>Ganitkevitch, Van Durme, Callison-Burch, 2013</marker>
<rawString>Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch. 2013. PPDB: The paraphrase database. In Proceedings of NAACL-HLT, pages 758–764, Atlanta, Georgia, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Ccgbank: A corpus of ccg derivations and dependency structures extracted from the penn treebank.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="8748" citStr="Hockenmaier and Steedman, 2007" startWordPosition="1513" endWordPosition="1516">yCCG of Lewis and Steedman (2014). While the C&amp;C parser is a pipeline of several NLP systems: POS-tagger, chunker, named entity recognizer (NER), lemmatizer (Minnen et al., 2001) supertagger and sub-parser, EasyCCG is an extremely simple but still comparably accurate CCG parser based on A* parsing.2 These two parsers use different settings for supertagging and parsing; therefore, it is interesting to test both parsers for our application. t$I4igure 3, there is a CCG derivation by the 2The employed C&amp;C parser is trained on rebanked CCGbank (Honnibal et al., 2010)—an updated version of CCGbank (Hockenmaier and Steedman, 2007) with improved analyses for predicate-argument structures and nominal modifiers. For EasyCCG, input sentences are already processed by the POS-tagger and the NER of the C&amp;C parser. ba[S&amp;l] fa[S&amp;t\NPth,] f a ba walks S\NP : walk 2494 Sdcl npthr, sdcl There npthr np there EX n tifier is replaced with (n, (np, s), s), and the resulted new NP is applied to the smallest clause it occurs in; but if there are other QNPs too, then it also applies to the clauses where other QNPs are situated. This operation is not deterministic and can return several terms due to multi-options in quantifier scope order</context>
</contexts>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2007. Ccgbank: A corpus of ccg derivations and dependency structures extracted from the penn treebank. Comput. Linguist., 33(3):355–396, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Honnibal</author>
<author>James R Curran</author>
<author>Johan Bos</author>
</authors>
<title>Rebanking ccgbank for improved np interpretation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Meeting of the Association for Computational Linguistics (ACL 2010),</booktitle>
<pages>207--215</pages>
<location>Uppsala,</location>
<contexts>
<context position="8685" citStr="Honnibal et al., 2010" startWordPosition="1504" endWordPosition="1507"> the C&amp;C CCG parser of Clark and Curran (2007) and EasyCCG of Lewis and Steedman (2014). While the C&amp;C parser is a pipeline of several NLP systems: POS-tagger, chunker, named entity recognizer (NER), lemmatizer (Minnen et al., 2001) supertagger and sub-parser, EasyCCG is an extremely simple but still comparably accurate CCG parser based on A* parsing.2 These two parsers use different settings for supertagging and parsing; therefore, it is interesting to test both parsers for our application. t$I4igure 3, there is a CCG derivation by the 2The employed C&amp;C parser is trained on rebanked CCGbank (Honnibal et al., 2010)—an updated version of CCGbank (Hockenmaier and Steedman, 2007) with improved analyses for predicate-argument structures and nominal modifiers. For EasyCCG, input sentences are already processed by the POS-tagger and the NER of the C&amp;C parser. ba[S&amp;l] fa[S&amp;t\NPth,] f a ba walks S\NP : walk 2494 Sdcl npthr, sdcl There npthr np there EX n tifier is replaced with (n, (np, s), s), and the resulted new NP is applied to the smallest clause it occurs in; but if there are other QNPs too, then it also applies to the clauses where other QNPs are situated. This operation is not deterministic and can retu</context>
</contexts>
<marker>Honnibal, Curran, Bos, 2010</marker>
<rawString>Matthew Honnibal, James R. Curran, and Johan Bos. 2010. Rebanking ccgbank for improved np interpretation. In Proceedings of the 48th Meeting of the Association for Computational Linguistics (ACL 2010), pages 207–215, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergio Jimenez</author>
<author>George Due˜nas</author>
<author>Julia Baquero</author>
<author>Alexander Gelbukh</author>
</authors>
<title>Unal-nlp: Combining soft cardinality features for semantic textual similarity, relatedness and entailment.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>732--742</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics and Dublin City University.</institution>
<location>Dublin, Ireland,</location>
<marker>Jimenez, Due˜nas, Baquero, Gelbukh, 2014</marker>
<rawString>Sergio Jimenez, George Due˜nas, Julia Baquero, and Alexander Gelbukh. 2014. Unal-nlp: Combining soft cardinality features for semantic textual similarity, relatedness and entailment. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 732–742, Dublin, Ireland, August. Association for Computational Linguistics and Dublin City University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From discourse to logic; an introduction to modeltheoretic semantics of natural language, formal logic and DRT.</title>
<date>1993</date>
<publisher>Dordrecht: Kluwer.</publisher>
<contexts>
<context position="25259" citStr="Kamp and Reyle, 1993" startWordPosition="4348" endWordPosition="4351">where LangPro, a purely logic-based system, outperforms non-logic-based systems.9 The another problem, SICK-2895, is an evidence how unreliable the state-of-the-art and non-logic-based RTE systems might be since solving the problem only requires a lexical knowledge barbell ≤ weight, which is available in WordNet. 6 Related Work Using formal logic tools for a wide-coverage RTE task goes back to the Nutcracker system (Bos and Markert, 2005), where a wide-coverage semantic processing tool Boxer (Bos, 2008), in combination with the C&amp;C tools, first produces discourse representation structures of (Kamp and Reyle, 1993) and then FOL semantic representations (Curran et al., 2007). Reasoning over FOL formulas is carried by off-the-shelf theorem provers and model builders for FOL.10 Our approach differs from the latter in several main aspects: (i) the underling logic of LLFs (i.e. higher-order logic) is more expressive than FOL (e.g., it can properly model GQs and subsective adjectives), (ii) LLFs are cheap to get as they are easily obtained from CCG derivations, and (iii) we develop a completely new proof procedure and a prover for a version of Natural Logic. The other related works are (MacCartney and Manning</context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Hans Kamp and Uwe Reyle. 1993. From discourse to logic; an introduction to modeltheoretic semantics of natural language, formal logic and DRT. Dordrecht: Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alice Lai</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Illinois-lh: A denotational and distributional approach to semantics.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>329--334</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics and Dublin City University.</institution>
<location>Dublin, Ireland,</location>
<contexts>
<context position="24220" citStr="Lai and Hockenmaier, 2014" startWordPosition="4188" endWordPosition="4191">and contradiction). The decision procedure of the prover is completely rule-based and easy to comprehend since it follows the intuitive deductive rules. Tableaux proofs by LangPro for SICK-247 (in Figure 7) and SICK-2895 (in Figure 8) show step by step how T contradicts and entails, respectively, H.8 Several new rules employed in these tableaux are given in Figure 9. Note that the both problems, SICK-247, 2895, were wrongly classified by all the top 7 systems of the RTE14. Taking into account that solving SICK-247 requires a sort of De Morgan’s law 7The top 5 systems of RTE14 are Illinois-LH (Lai and Hockenmaier, 2014), ECNU (Zhao et al., 2014), UNAL-NLP (Jimenez et al., 2014), SemantiKLUE (Proisl et al., 2014) and The Meaning Factory (Bjerva et al., 2014). 8In the tableaux, due to lack of space, several constants are denoted with initial characters of their lemmas and some intermediate nodes are omitted. Some of the nodes are annotated with a sequence of source rule applications. for negation and disjunction, this demonstrates where LangPro, a purely logic-based system, outperforms non-logic-based systems.9 The another problem, SICK-2895, is an evidence how unreliable the state-of-the-art and non-logic-bas</context>
</contexts>
<marker>Lai, Hockenmaier, 2014</marker>
<rawString>Alice Lai and Julia Hockenmaier. 2014. Illinois-lh: A denotational and distributional approach to semantics. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 329–334, Dublin, Ireland, August. Association for Computational Linguistics and Dublin City University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<title>Linguistics and natural logic.</title>
<date>1972</date>
<journal>Semantics of Natural Language,</journal>
<booktitle>of Synthese Library,</booktitle>
<volume>40</volume>
<pages>545--665</pages>
<editor>In Donald Davidson and Gilbert Harman, editors,</editor>
<publisher>Springer Netherlands.</publisher>
<contexts>
<context position="3366" citStr="Lakoff, 1972" startWordPosition="545" endWordPosition="546">Tableau is introduced, and then a method of obtaining LLFs from raw text is described. We outline the architecture of an implemented theorem prover that is based on the theory of Natural Tableau. The power of the prover is evaluated against the SICK data; the results are analyzed and compared to related RTE systems. The paper concludes with future work. 2 Natural Tableau for Natural Logic Natural Logic is a vague notion and refers to logics that account for valid inferences of natural languages, where reasoning and the grammar are strongly related to each other and LFs resemble surface forms (Lakoff, 1972). On the other hand, a tableau method (Beth, 1955) is a popular proof procedure and nowadays many formal logics have their own version of it (D’Agostino et al., 1999). A combination of these two devices is offered by Muskens (2010), where the language of Natural Logic is considered to be a part of simply typed 2492 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2492–2502, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. XAB: [] : F A : [c] : T B : [c] : F s.t. X E {all, every} and c is afresh term A B : [★✕</context>
</contexts>
<marker>Lakoff, 1972</marker>
<rawString>George Lakoff. 1972. Linguistics and natural logic. In Donald Davidson and Gilbert Harman, editors, Semantics of Natural Language, volume 40 of Synthese Library, pages 545–665. Springer Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>A* ccg parsing with a supertag-factored model.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>990--1000</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Doha, Qatar,</location>
<contexts>
<context position="8150" citStr="Lewis and Steedman (2014)" startWordPosition="1417" endWordPosition="1420"> where lexical items are combined via the forward application rule and unspecified semantic interpretations are written in a boldface: every man (S/(S\NP))/N : every N : man S/(S\NP) : every man S : (every man) walk The CCG derivation trees are suitable structures for obtaining LLFs for at least two reasons. First, the CCG framework is characterized by a transparent interface between syntactic categories and semantic types; second, there exist efficient and robust CCG parsers for wide-coverage texts. During obtaining LLFs, we employ the C&amp;C CCG parser of Clark and Curran (2007) and EasyCCG of Lewis and Steedman (2014). While the C&amp;C parser is a pipeline of several NLP systems: POS-tagger, chunker, named entity recognizer (NER), lemmatizer (Minnen et al., 2001) supertagger and sub-parser, EasyCCG is an extremely simple but still comparably accurate CCG parser based on A* parsing.2 These two parsers use different settings for supertagging and parsing; therefore, it is interesting to test both parsers for our application. t$I4igure 3, there is a CCG derivation by the 2The employed C&amp;C parser is trained on rebanked CCGbank (Honnibal et al., 2010)—an updated version of CCGbank (Hockenmaier and Steedman, 2007) w</context>
</contexts>
<marker>Lewis, Steedman, 2014</marker>
<rawString>Mike Lewis and Mark Steedman. 2014. A* ccg parsing with a supertag-factored model. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 990–1000, Doha, Qatar, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Modeling semantic containment and exclusion in natural language inference.</title>
<date>2008</date>
<pages>521--528</pages>
<editor>In Donia Scott and Hans Uszkoreit, editors, COLING,</editor>
<contexts>
<context position="25866" citStr="MacCartney and Manning, 2008" startWordPosition="4450" endWordPosition="4453">(Kamp and Reyle, 1993) and then FOL semantic representations (Curran et al., 2007). Reasoning over FOL formulas is carried by off-the-shelf theorem provers and model builders for FOL.10 Our approach differs from the latter in several main aspects: (i) the underling logic of LLFs (i.e. higher-order logic) is more expressive than FOL (e.g., it can properly model GQs and subsective adjectives), (ii) LLFs are cheap to get as they are easily obtained from CCG derivations, and (iii) we develop a completely new proof procedure and a prover for a version of Natural Logic. The other related works are (MacCartney and Manning, 2008) and (Angeli and Manning, 2014). Both works contribute to Natural Logic and are based on the same methodology.11 The approach has two main shortcomings compared to Natural Tableau; namely, it is unable to process multipremised problems, and its underling logic is weaker (e.g., according to (MacCartney, 2009), it cannot capture the entailment in Figure 2). 9Even a shallow heuristic—if H has a named entity that does not appear in T, then there is no entailment—is not sufficient for showing that SICK-247 is contradiction. We thank our reviewer for mentioning this heuristic w.r.t. SICK-247. 10Nutc</context>
</contexts>
<marker>MacCartney, Manning, 2008</marker>
<rawString>Bill MacCartney and Christopher D. Manning. 2008. Modeling semantic containment and exclusion in natural language inference. In Donia Scott and Hans Uszkoreit, editors, COLING, pages 521–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bill MacCartney</author>
</authors>
<title>Natural language inference. Phd thesis,</title>
<date>2009</date>
<institution>Stanford University.</institution>
<contexts>
<context position="26175" citStr="MacCartney, 2009" startWordPosition="4500" endWordPosition="4501">ive than FOL (e.g., it can properly model GQs and subsective adjectives), (ii) LLFs are cheap to get as they are easily obtained from CCG derivations, and (iii) we develop a completely new proof procedure and a prover for a version of Natural Logic. The other related works are (MacCartney and Manning, 2008) and (Angeli and Manning, 2014). Both works contribute to Natural Logic and are based on the same methodology.11 The approach has two main shortcomings compared to Natural Tableau; namely, it is unable to process multipremised problems, and its underling logic is weaker (e.g., according to (MacCartney, 2009), it cannot capture the entailment in Figure 2). 9Even a shallow heuristic—if H has a named entity that does not appear in T, then there is no entailment—is not sufficient for showing that SICK-247 is contradiction. We thank our reviewer for mentioning this heuristic w.r.t. SICK-247. 10Nutcracker obtains 3% lower accuracy on SICK than our prover (Pavlick et al., 2015). The Meaning Factory (Bjerva et al., 2014) that is a brother system of Nutcracker, instead of solely relying on decisions of theorem provers and model builders, uses machine learning methods over the features extracted from these</context>
</contexts>
<marker>MacCartney, 2009</marker>
<rawString>Bill MacCartney. 2009. Natural language inference. Phd thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Marelli</author>
<author>Stefano Menini</author>
<author>Marco Baroni</author>
<author>Luisa Bentivogli</author>
<author>Raffaella Bernardi</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment.</title>
<date>2014</date>
<booktitle>In Proceedings of SemEval 2014 (International Workshop on Semantic Evaluation),</booktitle>
<pages>1--8</pages>
<publisher>ACL.</publisher>
<location>East Stroudsburg PA.</location>
<contexts>
<context position="15687" citStr="Marelli et al., 2014" startWordPosition="2732" endWordPosition="2735">that there is no word sense disambiguation (WSD) used by the prover; therefore, adopting these interpretations of entailment and contradiction amounts to considering all senses of the words. For example, a man is crying entails a man is screaming as there are senses of cry and scream that are in the entailment relation. All in all, chaining a CCG parser, LLFgen, the LLF-aligner, the prover and KB results in an automatized tableau prover LangPro which operates directly over natural language text. 5 Learning and Evaluation 5.1 Learning For learning and evaluation purposes, we use the SICK data (Marelli et al., 2014b). The data consists of problems that are rich in the lexical, syntactic and semantic phenomena that compositional distributional semantic models (Mitchell and Lapata, 2010) are expected to account for.5 The 5SICK is partitioned in three parts (trail, train and test) and used as a benchmark for RTE14 (Marelli et al., 2014a). SICK data contains around 10K text-hypothesis pairs that are classified in three categories: entailment, contradiction, and neutral. During learning we used only the trial portion of the data, SICK-trial, including 500 problems. The learning process consists of improving </context>
</contexts>
<marker>Marelli, Menini, Baroni, Bentivogli, Bernardi, Zamparelli, 2014</marker>
<rawString>Marco Marelli, Stefano Menini, Marco Baroni, Luisa Bentivogli, Raffaella Bernardi, and Roberto Zamparelli. 2014a. Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment. In Proceedings of SemEval 2014 (International Workshop on Semantic Evaluation), pages 1–8, East Stroudsburg PA. ACL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marco Marelli</author>
<author>Stefano Menini</author>
<author>Marco Baroni</author>
<author>Luisa Bentivogli</author>
<author>Raffaella Bernardi</author>
<author>Roberto Zamparelli</author>
</authors>
<title>A sick cure for the evaluation of compositional distributional semantic models.</title>
<date>2014</date>
<booktitle>Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland. European Language Resources Association (ELRA).</booktitle>
<editor>In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors,</editor>
<contexts>
<context position="15687" citStr="Marelli et al., 2014" startWordPosition="2732" endWordPosition="2735">that there is no word sense disambiguation (WSD) used by the prover; therefore, adopting these interpretations of entailment and contradiction amounts to considering all senses of the words. For example, a man is crying entails a man is screaming as there are senses of cry and scream that are in the entailment relation. All in all, chaining a CCG parser, LLFgen, the LLF-aligner, the prover and KB results in an automatized tableau prover LangPro which operates directly over natural language text. 5 Learning and Evaluation 5.1 Learning For learning and evaluation purposes, we use the SICK data (Marelli et al., 2014b). The data consists of problems that are rich in the lexical, syntactic and semantic phenomena that compositional distributional semantic models (Mitchell and Lapata, 2010) are expected to account for.5 The 5SICK is partitioned in three parts (trail, train and test) and used as a benchmark for RTE14 (Marelli et al., 2014a). SICK data contains around 10K text-hypothesis pairs that are classified in three categories: entailment, contradiction, and neutral. During learning we used only the trial portion of the data, SICK-trial, including 500 problems. The learning process consists of improving </context>
</contexts>
<marker>Marelli, Menini, Baroni, Bentivogli, Bernardi, Zamparelli, 2014</marker>
<rawString>Marco Marelli, Stefano Menini, Marco Baroni, Luisa Bentivogli, Raffaella Bernardi, and Roberto Zamparelli. 2014b. A sick cure for the evaluation of compositional distributional semantic models. In Nicoletta Calzolari, Khalid Choukri, Thierry Declerck, Hrafn Loftsson, Bente Maegaard, Joseph Mariani, Asuncion Moreno, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC’14), Reykjavik, Iceland. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guido Minnen</author>
<author>John Carroll</author>
<author>Darren Pearce</author>
</authors>
<title>Applied morphological processing of english.</title>
<date>2001</date>
<journal>Natural Language Engineering,</journal>
<volume>7</volume>
<issue>3</issue>
<contexts>
<context position="8295" citStr="Minnen et al., 2001" startWordPosition="1441" endWordPosition="1444">\NP))/N : every N : man S/(S\NP) : every man S : (every man) walk The CCG derivation trees are suitable structures for obtaining LLFs for at least two reasons. First, the CCG framework is characterized by a transparent interface between syntactic categories and semantic types; second, there exist efficient and robust CCG parsers for wide-coverage texts. During obtaining LLFs, we employ the C&amp;C CCG parser of Clark and Curran (2007) and EasyCCG of Lewis and Steedman (2014). While the C&amp;C parser is a pipeline of several NLP systems: POS-tagger, chunker, named entity recognizer (NER), lemmatizer (Minnen et al., 2001) supertagger and sub-parser, EasyCCG is an extremely simple but still comparably accurate CCG parser based on A* parsing.2 These two parsers use different settings for supertagging and parsing; therefore, it is interesting to test both parsers for our application. t$I4igure 3, there is a CCG derivation by the 2The employed C&amp;C parser is trained on rebanked CCGbank (Honnibal et al., 2010)—an updated version of CCGbank (Hockenmaier and Steedman, 2007) with improved analyses for predicate-argument structures and nominal modifiers. For EasyCCG, input sentences are already processed by the POS-tagg</context>
</contexts>
<marker>Minnen, Carroll, Pearce, 2001</marker>
<rawString>Guido Minnen, John Carroll, and Darren Pearce. 2001. Applied morphological processing of english. Natural Language Engineering, 7(3):207–223, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="15861" citStr="Mitchell and Lapata, 2010" startWordPosition="2758" endWordPosition="2762">l senses of the words. For example, a man is crying entails a man is screaming as there are senses of cry and scream that are in the entailment relation. All in all, chaining a CCG parser, LLFgen, the LLF-aligner, the prover and KB results in an automatized tableau prover LangPro which operates directly over natural language text. 5 Learning and Evaluation 5.1 Learning For learning and evaluation purposes, we use the SICK data (Marelli et al., 2014b). The data consists of problems that are rich in the lexical, syntactic and semantic phenomena that compositional distributional semantic models (Mitchell and Lapata, 2010) are expected to account for.5 The 5SICK is partitioned in three parts (trail, train and test) and used as a benchmark for RTE14 (Marelli et al., 2014a). SICK data contains around 10K text-hypothesis pairs that are classified in three categories: entailment, contradiction, and neutral. During learning we used only the trial portion of the data, SICK-trial, including 500 problems. The learning process consists of improving the components of the prover while solving the RTE problems: designing fixing procedures of LLFgen, adding new sound rules to the inventory, and introducing valid relations i</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Montague</author>
</authors>
<title>English as a Formal Language. In</title>
<date>1974</date>
<booktitle>Formal philosophy: Selected Papers of Richard Montague, chapter 6,</booktitle>
<pages>188--221</pages>
<editor>Richmond H. Thomason, editor,</editor>
<publisher>Yale University Press.</publisher>
<marker>Montague, 1974</marker>
<rawString>Richard Montague. 1974. English as a Formal Language. In Richmond H. Thomason, editor, Formal philosophy: Selected Papers of Richard Montague, chapter 6, pages 188–221. Yale University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Muskens</author>
</authors>
<title>An analytic tableau system for natural logic.</title>
<date>2010</date>
<booktitle>Logic, Language and Meaning,</booktitle>
<volume>6042</volume>
<pages>104--113</pages>
<editor>In Maria Aloni, Harald Bastiaanse, Tikitu de Jager, and Katrin Schulz, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="1909" citStr="Muskens (2010)" startWordPosition="302" endWordPosition="303">t try to solve RTE problems by computing meanings of linguistic expressions and employing inference engines similar to proof procedures of formal logics. Moreover, those few systems are usually used in combination with shallow classifiers since the systems’ performances alone are poor. The current paper advocates that purely deductive inference engines over linguistic representations backed up with a simple lexical knowledge base could be solely and successfully used for the RTE task. Our work builds on the theory of an analytic tableau system for Natural Logic (Natural Tableau) introduced by Muskens (2010). The theory offers to employ a tableau method—a proof procedure used for many formal logics—for the version of Natural Logic that employs Lambda Logical Forms (LLFs)—certain terms of simply typed A-calculus—as Logical Forms (LFs) of linguistic expressions. The merits of the current approach are several and they can be grouped in two categories: virtues attributed to the tableau prover are (i) the high precision for the RTE task characteristic to proof procedures, (ii) the transparency of the reasoning process, and (iii) ability for solving problems with several premises; and those concerning </context>
<context position="3597" citStr="Muskens (2010)" startWordPosition="585" endWordPosition="586">ed against the SICK data; the results are analyzed and compared to related RTE systems. The paper concludes with future work. 2 Natural Tableau for Natural Logic Natural Logic is a vague notion and refers to logics that account for valid inferences of natural languages, where reasoning and the grammar are strongly related to each other and LFs resemble surface forms (Lakoff, 1972). On the other hand, a tableau method (Beth, 1955) is a popular proof procedure and nowadays many formal logics have their own version of it (D’Agostino et al., 1999). A combination of these two devices is offered by Muskens (2010), where the language of Natural Logic is considered to be a part of simply typed 2492 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2492–2502, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. XAB: [] : F A : [c] : T B : [c] : F s.t. X E {all, every} and c is afresh term A B : [★✕C] : X ★✕ A : [B, C] : X ★✕ A : [B, C] : X A B : [★✕C] : X A : [★✕C] : T B : [★✕C] : F X s.t. A &lt; B PUSH PULL VF XAB: [] : F IF A : [d] : F B : [d] : F s.t. X E {some, a} and d is an old term not A : [★✕C] : X A : [★✕C] : X &lt;X NOT </context>
<context position="10895" citStr="Muskens, 2010" startWordPosition="1884" endWordPosition="1885">types are erased; for example, usually syntactic types pp, n and (np, s) are translated as et type. Retaining syntactic types also contributes to fine-grained matching of nodes during rule application in the prover. For instance, without syntactic types it is more complex to determine the context in which a term game occurs and find an appropriate tableau rule when considering the following LLFs, gamen,ntheory and gamepp,n(of X), as both (n, n) and (pp, n) are usually translated into (et)et type, like it is done by (Bos, 2009). In order to accommodate the LLFs with syntactic types in LLFs of (Muskens, 2010), we extend the semantic type system with np, n, s, pp basic syntactic types corresponding to basic CCG cate3We use initial letters of lemmas to abbreviate a term corresponding to a lexical entry. Note that (9) represents a reading with no one having a wide scope while, in (10), a tomato has a wide scope. 4The similar translation is carried out in (Bos, 2009) for Boxer (Bos, 2008), where basic CCG categories are mapped to semantic types and the mapping is isomorphically extended to complex categories. gories. Thus complex types are now built up from the set {e, t, np, n, s, pp} of types. The e</context>
<context position="14244" citStr="Muskens, 2010" startWordPosition="2488" endWordPosition="2489">sh terms and antecedents of which can be ignored af2496 ter the application (e.g., NOT). Less preferred and inefficient rules are the ones that branch, produce new terms or antecedents of which are kept after the application (e.g., ∀F and IF). In order to encourage finding short proofs, admissible rules representing shortcuts of several rule applications are also introduced (e.g., FUNT and ARG in Figure 9). The inventory consists of about 50 rules, where most of them are manually designed based on RTE problems (see Section 5.1) and the rest represents the essential part of the rules found in (Muskens, 2010). The LLF generator (LLFgen) is a procedure that generates LLFs from a CCG derivation in the way described in Subsection 3.2. We also implement an LLF-aligner that serves as an optional preprocessor between LLFgen and the prover itself; it aligns identical chunks of LLFs and treats them as a constant (i.e. having no internal structure). This treatment often leads to smaller tableau proofs. The example of aligned LLFs is given in Figure 8. LangPro uses only the antonymy relation and a transitive closure of the hyponymy/hypernymy relations from WordNet 3.0 (Fellbaum, 1998) as its knowledge base </context>
</contexts>
<marker>Muskens, 2010</marker>
<rawString>Reinhard Muskens. 2010. An analytic tableau system for natural logic. In Maria Aloni, Harald Bastiaanse, Tikitu de Jager, and Katrin Schulz, editors, Logic, Language and Meaning, volume 6042 of Lecture Notes in Computer Science, pages 104–113. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellie Pavlick</author>
<author>Johan Bos</author>
<author>Malvina Nissim</author>
<author>Charley Beller</author>
<author>Benjamin Van Durme</author>
<author>Chris CallisonBurch</author>
</authors>
<title>Adding semantics to data-driven paraphrasing.</title>
<date>2015</date>
<booktitle>In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>1512--1522</pages>
<marker>Pavlick, Bos, Nissim, Beller, Van Durme, CallisonBurch, 2015</marker>
<rawString>Ellie Pavlick, Johan Bos, Malvina Nissim, Charley Beller, Benjamin Van Durme, and Chris CallisonBurch. 2015. Adding semantics to data-driven paraphrasing. In Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics (ACL 2015), pages 1512–1522.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Proisl</author>
<author>Stefan Evert</author>
<author>Paul Greiner</author>
<author>Besim Kabashi</author>
</authors>
<title>Semantiklue: Robust semantic similarity at multiple levels using maximum weight matching.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>532--540</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics and Dublin City University.</institution>
<location>Dublin, Ireland,</location>
<contexts>
<context position="24314" citStr="Proisl et al., 2014" startWordPosition="4203" endWordPosition="4206">hend since it follows the intuitive deductive rules. Tableaux proofs by LangPro for SICK-247 (in Figure 7) and SICK-2895 (in Figure 8) show step by step how T contradicts and entails, respectively, H.8 Several new rules employed in these tableaux are given in Figure 9. Note that the both problems, SICK-247, 2895, were wrongly classified by all the top 7 systems of the RTE14. Taking into account that solving SICK-247 requires a sort of De Morgan’s law 7The top 5 systems of RTE14 are Illinois-LH (Lai and Hockenmaier, 2014), ECNU (Zhao et al., 2014), UNAL-NLP (Jimenez et al., 2014), SemantiKLUE (Proisl et al., 2014) and The Meaning Factory (Bjerva et al., 2014). 8In the tableaux, due to lack of space, several constants are denoted with initial characters of their lemmas and some intermediate nodes are omitted. Some of the nodes are annotated with a sequence of source rule applications. for negation and disjunction, this demonstrates where LangPro, a purely logic-based system, outperforms non-logic-based systems.9 The another problem, SICK-2895, is an evidence how unreliable the state-of-the-art and non-logic-based RTE systems might be since solving the problem only requires a lexical knowledge barbell ≤ </context>
</contexts>
<marker>Proisl, Evert, Greiner, Kabashi, 2014</marker>
<rawString>Thomas Proisl, Stefan Evert, Paul Greiner, and Besim Kabashi. 2014. Semantiklue: Robust semantic similarity at multiple levels using maximum weight matching. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 532–540, Dublin, Ireland, August. Association for Computational Linguistics and Dublin City University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
<author>Jason Baldridge</author>
</authors>
<title>Combinatory categorial grammar. In</title>
<date>2011</date>
<booktitle>Non-Transformational Syntax: Formal and Explicit Models of Grammar,</booktitle>
<pages>181--224</pages>
<editor>D. Borsley, Robert and Kersti Brjars, editors,</editor>
<publisher>Wiley-Blackwell.</publisher>
<contexts>
<context position="7267" citStr="Steedman and Baldridge, 2011" startWordPosition="1265" endWordPosition="1268">ionally annotated with their types in a subscript. 2493 that none of the situations for the counterexample were consistent. An advantage of Natural Tableau is that it treats both single and multi-premised arguments in the same fashion and represents a deductive procedure in an intuitive and transparent way. lx[N 3 Obtaining LLFs for Natural Tableau 3.1 CCG and the C&amp;C Parser Combinatory Categorial Grammar (CCG) is a lexicalized grammar formalism that assigns a syntactic category and a semantic interpretation to lexical items, where the items are combined via combinatory rules (Steedman, 2000; Steedman and Baldridge, 2011). The CCG category A/B (or A\B) is a category of an item that becomes of category A when it is combined with an item of category B on its right (or left, respectively) side. In the example below, the sentence every man walks is analyzed in the CCG formalism, where lexical items are combined via the forward application rule and unspecified semantic interpretations are written in a boldface: every man (S/(S\NP))/N : every N : man S/(S\NP) : every man S : (every man) walk The CCG derivation trees are suitable structures for obtaining LLFs for at least two reasons. First, the CCG framework is char</context>
</contexts>
<marker>Steedman, Baldridge, 2011</marker>
<rawString>Mark Steedman and Jason Baldridge. 2011. Combinatory categorial grammar. In D. Borsley, Robert and Kersti Brjars, editors, Non-Transformational Syntax: Formal and Explicit Models of Grammar, pages 181–224. Wiley-Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="7236" citStr="Steedman, 2000" startWordPosition="1263" endWordPosition="1264">y. Terms are optionally annotated with their types in a subscript. 2493 that none of the situations for the counterexample were consistent. An advantage of Natural Tableau is that it treats both single and multi-premised arguments in the same fashion and represents a deductive procedure in an intuitive and transparent way. lx[N 3 Obtaining LLFs for Natural Tableau 3.1 CCG and the C&amp;C Parser Combinatory Categorial Grammar (CCG) is a lexicalized grammar formalism that assigns a syntactic category and a semantic interpretation to lexical items, where the items are combined via combinatory rules (Steedman, 2000; Steedman and Baldridge, 2011). The CCG category A/B (or A\B) is a category of an item that becomes of category A when it is combined with an item of category B on its right (or left, respectively) side. In the example below, the sentence every man walks is analyzed in the CCG formalism, where lexical items are combined via the forward application rule and unspecified semantic interpretations are written in a boldface: every man (S/(S\NP))/N : every N : man S/(S\NP) : every man S : (every man) walk The CCG derivation trees are suitable structures for obtaining LLFs for at least two reasons. F</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiang Zhao</author>
<author>Tiantian Zhu</author>
<author>Man Lan</author>
</authors>
<title>Ecnu: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>271--277</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics and Dublin City University.</institution>
<location>Dublin, Ireland,</location>
<contexts>
<context position="24246" citStr="Zhao et al., 2014" startWordPosition="4193" endWordPosition="4196">rocedure of the prover is completely rule-based and easy to comprehend since it follows the intuitive deductive rules. Tableaux proofs by LangPro for SICK-247 (in Figure 7) and SICK-2895 (in Figure 8) show step by step how T contradicts and entails, respectively, H.8 Several new rules employed in these tableaux are given in Figure 9. Note that the both problems, SICK-247, 2895, were wrongly classified by all the top 7 systems of the RTE14. Taking into account that solving SICK-247 requires a sort of De Morgan’s law 7The top 5 systems of RTE14 are Illinois-LH (Lai and Hockenmaier, 2014), ECNU (Zhao et al., 2014), UNAL-NLP (Jimenez et al., 2014), SemantiKLUE (Proisl et al., 2014) and The Meaning Factory (Bjerva et al., 2014). 8In the tableaux, due to lack of space, several constants are denoted with initial characters of their lemmas and some intermediate nodes are omitted. Some of the nodes are annotated with a sequence of source rule applications. for negation and disjunction, this demonstrates where LangPro, a purely logic-based system, outperforms non-logic-based systems.9 The another problem, SICK-2895, is an evidence how unreliable the state-of-the-art and non-logic-based RTE systems might be si</context>
</contexts>
<marker>Zhao, Zhu, Lan, 2014</marker>
<rawString>Jiang Zhao, Tiantian Zhu, and Man Lan. 2014. Ecnu: One stone two birds: Ensemble of heterogenous measures for semantic relatedness and textual entailment. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 271–277, Dublin, Ireland, August. Association for Computational Linguistics and Dublin City University.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>