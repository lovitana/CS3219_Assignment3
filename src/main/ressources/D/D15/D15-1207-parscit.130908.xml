<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002184">
<title confidence="0.976501">
A Computational Cognitive Model of Novel Word Generalization
</title>
<author confidence="0.998791">
Aida Nematzadeh, Erin Grant, and Suzanne Stevenson
</author>
<affiliation confidence="0.998588">
Department of Computer Science
University of Toronto
</affiliation>
<email confidence="0.992045">
faida,eringrant,suzannel@cs.toronto.edu
</email>
<sectionHeader confidence="0.994603" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999952058823529">
A key challenge in vocabulary acquisition
is learning which of the many possible
meanings is appropriate for a word. The
word generalization problem refers to how
children associate a word such as dog with
a meaning at the appropriate category level
in a taxonomy of objects, such as Dalma-
tians, dogs, or animals. We present the
first computational study of word general-
ization integrated within a word-learning
model. The model simulates child and
adult patterns of word generalization in a
word-learning task. These patterns arise
due to the interaction of type and token
frequencies in the input data, an influence
often observed in people’s generalization
of linguistic categories.
</bodyText>
<sectionHeader confidence="0.998782" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999941524590164">
Learning word meanings is a challenging early
step in child language acquisition. Imagine a
child hears the word dax for the first time while
observing a white rabbit jumping around – dax
might mean WHITE RABBIT, RABBIT, ANIMAL,
CUTE, LOOK, etc. (Quine, 1960). How does the
child learn the correct meaning of a word from
a large pool of potential meanings? A possi-
ble explanation is that children infer a word’s
meaning by identifying the commonalities across
the situations in which the word occurs (Pinker,
1989). One mechanism for achieving this is cross-
situational learning (e.g., Siskind, 1996; Frank
et al., 2007; Fazly et al., 2010; Kachergis et al.,
2012). Recent word learning experiments con-
firm that both adults and children infer the cor-
rect word-meaning mappings by keeping track of
cross-situational statistics across individually am-
biguous learning trials (Yu and Smith, 2007; Smith
and Yu, 2008; Yurovsky et al., 2014).
Although cross-situational learning is a general
mechanism for narrowing down the meaning of a
word, it does not explain how children overcome
an interesting challenge in word learning: deter-
mining the correct level of a hierarchical taxon-
omy that a word refers to. For example, children
learn that the word dog refers to all kinds of dogs,
and not to a specific breed, such as Dalmatians,
or to a more general category, such as animals –
even though some of these choices (e.g., animals)
are compatible with all the cross-situational evi-
dence available for dog (because all dogs are also
animals). We use the term “word generalization”
to refer to this problem of associating a word with
the meaning at an appropriate category level, given
some sample of experiences with the word.
Previous research has argued that children use
a specific bias or constraint – the basic-level as-
sumption – to focus their word generalizations
appropriately (Markman, 1991; Golinkoff et al.,
1994). According to this bias, children prefer to
associate a word to a set of objects that form a
basic-level category, such as dogs or trucks, and
that share a significant number of attributes. It
is less preferred to associate a new word to much
more specific subordinate categories, such as Dal-
matians or bulldozers, or to more general superor-
dinate ones, like animals or vehicles, whose mem-
bers share fewer attributes (Rosch, 1973; Rosch et
al., 1976). It remains an important open question
of whether a word learner requires such a bias to
acquire appropriate mappings.
Xu and Tenenbaum (2007) (X&amp;T henceforth)
studied the word generalization problem in a set
of experiments in which children and adults were
asked to determine which level of a taxonomy a
novel word referred to. X&amp;T further examined
this behavioral data through computational mod-
elling. They proposed a Bayesian model that,
given a few exemplars of a novel word, matches
human behaviour in how it maps the word to its
</bodyText>
<page confidence="0.924697">
1795
</page>
<note confidence="0.984901">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1795–1804,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999252275">
meanings in a taxonomic category.
The Bayesian model of X&amp;T is important in
providing insight into how people might reason
about samples of data that exemplify categories.
However, it relies on having complete, built-in
knowledge about the taxonomic hierarchy, includ-
ing both the detailed composition of categories
and the values for between-object similarities,
drawn from adult similarity judgments. Further-
more, the X&amp;T model does not address the issue
of word generalization in the broader context of
word learning: While their model reasons over
samples of data associated with a word label, it
does not develop a meaning representation of the
word over time, as a child must do. It is impor-
tant to understand how word generalization occurs
when embedded in the natural process of learning
a word meaning and in the context of more limited
category knowledge.
We address these issues by providing a uni-
fied account of word learning and word gener-
alization within a computational model of cross-
situational learning. Unlike the X&amp;T model, our
model is an incremental learner that gradually ac-
quires the meaning of words, and uses these devel-
oping meanings in determining the appropriate ex-
tension of a word to elements of a taxonomy. Our
model has general knowledge of category struc-
ture without having an elaborated taxonomy en-
coding known object similarities. Moreover, in the
absence of any bias toward generalization to par-
ticular kinds of categories, the model exhibits the
observed “basic-level bias” due to general mech-
anisms of productivity that have been proposed
to apply to many aspects of linguistic knowledge
(e.g., Bybee, 1985; Croft and Cruse, 2004).1
In what follows, we first describe the human ex-
periments of X&amp;T, and then present our computa-
tional model and the experiments that simulate the
X&amp;T data.
</bodyText>
<sectionHeader confidence="0.910802" genericHeader="method">
2 Novel Word Generalization in People
</sectionHeader>
<bodyText confidence="0.99778945945946">
X&amp;T perform a set of empirical studies to inves-
tigate how children and adults generalize novel
words learned from a few examples to the appro-
1Computational cognitive models are often categorized
with respect to Marr’s levels of analysis, i.e., their degree
of abstraction (Marr, 1982). The model of X&amp;T is at the
computational level, providing a Bayesian framework for the
problem of word generalization. In contrast, our model in-
vestigates more detailed mechanisms and thus lies between
the algorithmic and computational levels of analysis.
priate level of meaning in a taxonomy. In each
training trial of an experiment, participants hear a
novel word (such as fep) and observe one or more
instances exemplifying the word (in the form of
pictures for adults and toy objects for children).
The conditions vary in that the make-up of the set
of training instances is representative of different
levels of a taxonomy (e.g., all Dalmatians vs. var-
ious kinds of dogs vs. various kinds of animals).
In the testing phase, participants are asked to se-
lect all objects that they think are feps from a set
of test items. Both children and adults make var-
ious inferences about what a fep is depending on
the levels of the taxonomy from which the training
instances are drawn.
Specifically, X&amp;T use a taxonomy with ani-
mals, vehicles, and vegetables, from which in-
stances are drawn to produce the training condi-
tions in Fig. 1(a). For example, in one training
condition, participants are shown a Dalmatian, a
poodle, and a beagle in three consecutive trials,
hearing the word fep to refer to each object. Af-
ter training, participants are asked to select all feps
from the set of test objects, which includes items
from all 3 superordinate categories. As illustrated
in Fig. 1(b), each test object is assessed as one of
the following types of match to the training data:
</bodyText>
<listItem confidence="0.986695583333333">
• a subordinate match: an object of the
same subordinate category as a training ob-
ject (e.g., Dalmatians in Fig. 1)
• a basic-level match: an object of the same
basic-level category as a training object (e.g.,
a dog, but not the same breed as one in train-
ing [which would be a subordinate match])
• a superordinate match: an object of the
same superordinate category as the training
objects (e.g., another kind of animal, but not
one seen in training [which would be a sub-
ordinate or basic-level match])
</listItem>
<bodyText confidence="0.994878272727273">
X&amp;T report the percentage of test objects of each
type of match that are selected by participants
within each training condition; see Fig. 2. (For
example, the reported value for “super. match”
would be 75% if participants on average chose 3
of the 4 superordinate matches in the test set.)
Consider first the data from adults. After see-
ing a single object (1-example condition – e.g., a
Dalmatian), adults show a strong basic-level bias
– i.e., they tend to generalize the word fep to refer
to both Dalmatians (subordinate matches) and to
</bodyText>
<page confidence="0.988099">
1796
</page>
<figure confidence="0.993831842105263">
Training
condition:
1 example
3 subord.
3 basic
3 super.
Example Trials:
Trial 1 Trial 2 Trial 3
Dalmatian 0 0
Dalmatian Dalmatian Dalmatian
Dalmatian poodle beagle
Dalmatian penguin sheep
Example test Type of
object selected: test match:
Dalmatian subordinate match
bulldog basic match
cat superordinate match
(b) An example of the test responses.
(a) An example of the training conditions.
</figure>
<figureCaption confidence="0.999997">
Figure 1: The training and testing conditions of X&amp;T; see text in Section 2.
</figureCaption>
<bodyText confidence="0.999880944444444">
other dogs (basic-level matches), but not to other
animals (superordinate matches). But with 3 in-
stances of a Dalmatian (3-subordinate condition),
this behaviour is attenuated – the number of basic-
level matches is much lower. For the 3-basic-level
and 3-superordinate conditions, the adults show
generalization up to categories consistent with the
evidence – i.e., at the basic and superordinate lev-
els, respectively.
Interestingly, children also show a basic-level
bias, but differ from adults in that it is less pro-
nounced – e.g., they are less likely than adults
to select basic-level matches (other dogs) having
seen a single Dalmatian or having seen 3 Dalma-
tians. In the other conditions, children’s behaviour
is similar to adults, but shows somewhat less gen-
eralization to unseen types of objects (e.g., other
kinds of dogs/animals than those in training).
</bodyText>
<figure confidence="0.9806625">
(a) Adult data:
(b) Child data:
</figure>
<figureCaption confidence="0.982764333333333">
Figure 2: X&amp;T data for (a) adults and (b) children. Each
bar is the percentage of chosen test objects of a type of test
match: i.e., subord(inate), basic(-level), or super(ordinate).
</figureCaption>
<sectionHeader confidence="0.97407" genericHeader="method">
3 The Word Learning Framework
</sectionHeader>
<bodyText confidence="0.999978714285714">
Our computational model is based on the cross-
situational word learner of Fazly et al. (2010)
(henceforth, FAS), which accounts for a range of
observed patterns in child and adult vocabulary ac-
quisition. Here we give an overview of the FAS
model; the next section explains extensions to han-
dle the novel word generalization task.
A naturalistic language learning scenario con-
sists of both linguistic data (what a child a hears)
and non-linguistic data (what a child perceives).
This input is modeled as a sequence of utterance–
scene (U–5) pairs, where an utterance is a group
of words and a scene is a set of semantic features
representing the meaning of those words:
</bodyText>
<equation confidence="0.8542705">
U: { look, a, fep, ... }
S: { PERCEPTION, LOOK, ... , DALMATIAN, DOG, ... }
</equation>
<bodyText confidence="0.999472388888889">
Given such input, for each word w, the model
of FAS learns a probability distribution over all
semantic features, Pt(.|w), which represents the
word’s meaning at time t. Initially, at time t =
0, P0(.|w) is a uniform distribution. The word
meanings are incrementally learned using an algo-
rithm that implements cross-situational learning:
for each pair of a word w and a semantic feature f,
the model learns Pt(f|w) from co-occurrences of
w and f across all the utterance–scene pairs seen
up to time t, as follows.
Given an utterance–scene pair U–5 at time t,
and drawing on its learned knowledge of word
meanings up to time t−1, the model of FAS calcu-
lates an alignment probability for each wj–fi pair.
This probability reflects how strongly the feature
fi is associated with wj compared to its associa-
tion with other words in U:
</bodyText>
<equation confidence="0.998432333333333">
Pt(aij|U, fi) = Pt−1(fi|wj) (1)
E Pt−1(fi|w&apos;)
w&apos;EU
</equation>
<bodyText confidence="0.9999834">
where aij indicates the mapping between the word
wj and the semantic feature fi.
These probabilities are incrementally accumu-
lated for each wj–fi pair, capturing the overall
strength of association of wj and fi at time t:
</bodyText>
<equation confidence="0.970393">
assoct(fi, wj) = assoct−1(fi, wj)
+ Pt(aij|U, fi) (2)
</equation>
<page confidence="0.834669">
1797
</page>
<bodyText confidence="0.99959425">
The (normalized) association scores then serve as
the basis for the incremental adjustment of the
meaning probabilities of all features fi for each
word wj seen in the input at time t:
</bodyText>
<equation confidence="0.997015666666667">
assoct(fi, wj) + -y
Pt(fi|wj) = E assoct(fm, wj) + k -y (3)
fmEM
</equation>
<bodyText confidence="0.985072125">
Here M is the group of all features that the model
has observed, k is the expected number of such
features, and -y is a small smoothing parameter,
which determines the prior probability of observ-
ing a new feature.
Smoothing entails that features previously un-
seen with a word (all fi such that assoct(fi, wj) =
0) have a small but non-zero probability. That is,
</bodyText>
<equation confidence="0.94563925">
when fi is unseen with wj, Eqn. (3) reduces to:
-y
Ptu (fi|wj) =E assoct(fm,wj) + k-y (4)
fmEM
</equation>
<bodyText confidence="0.999736125">
This unseen probability, Ptu, reflects the learner’s
“openness” to the word being associated with new
features (Nematzadeh et al., 2011): a higher or
lower Ptu (fi|wj) will affect how strongly a pre-
viously unseen fi can be associated with wj in the
alignment process (Eqn. (1)). We return to this
property of the model below, as it relates to the
behaviour of our model in making generalizations.
</bodyText>
<sectionHeader confidence="0.893177" genericHeader="method">
4 Extensions to the Model
</sectionHeader>
<bodyText confidence="0.999983183098592">
We assume that the representation of meaning
can be abstracted to features that correspond to
different levels of categorization. For example,
a Dalmatian in an input scene is represented as
{DALMATIAN, DOG, ANIMAL} and a Bulldog as
{BULLDOG, DOG, ANIMAL}, where we use FEA-
TURENAME to refer to all the features that are spe-
cific to that level of object category. (Note that we
could replace each of these features with the ap-
propriate “true” set of features, but use the more
compact representation for simplicity.) To acquire
the meaning of the word Dalmatian, the model
must learn a probability distribution in which
P(f|Dalmatian) is relatively high for the features
DALMATIAN, DOG, and ANIMAL, and low for fea-
tures such as BULLDOG, CAT, and VEGETABLE.
Introducing Feature Groups. In the FAS
model, all the features for a word are dependent:
increasing the probability of any feature results in
decreasing the probability of others. However, this
interaction is not always desirable, as many fea-
tures regularly co-occur in the world. This is es-
pecially an issue for features from a category hi-
erarchy, where features of a subordinate category
should not compete with features of the parent.
That is, while a higher probability of DALMATIAN
features (e.g., black spotted coat) may lessen the
likelihood of BULLDOG features (e.g., wrinkles),
it should not decrease the probability of DOG fea-
tures (e.g., having 4 legs).
To address this, we extend the model by using
feature groups that collect together sets of features
that sensibly compete. Each feature group is com-
prised of all features at the same level of specificity
in the category hierarchy, which are therefore mu-
tually exclusive, such as DOG, CAT, and BIRD (i.e.,
different kinds of animals). Instead of learning a
single probability distribution over all features as
the meaning of a word, the extended model learns
a set of probability distributions for a word, one
for each feature group (i.e., one per level of the hi-
erarchy). Features within a group thereby compete
for the probability mass associated with a word,
but those from across groups (e.g., DALMATIAN
and DOG) can freely co-occur without competing.
The model does not know a priori all the
features in a group, but when presented with
a newly observed feature, it can identify the
appropriate group for it. In taking this ap-
proach, we assume the learner can distinguish
the level of specificity of features perceived in
the scene. For example, in the scene rep-
resentations {DALMATIAN, DOG, ANIMAL} and
{SIAMESE, CAT, ANIMAL}, the learner can recog-
nize that DOG and CAT are at the same level of
the hierarchy (kinds of animals) and that DALMA-
TIAN and SIAMESE are at the same, more specific
level in the hierarchy (finer-grained breeds of an-
imals). Our assumption is that children (at this
stage in their development) can identify a degree
of similarity among concepts that enables them to
recognize that Dalmatians and Siamese are distin-
guished by similar properties (such as fur color),
which differ from more distinguishing properties
at higher taxonomic levels (such as number of
legs). The model has no other prior knowledge of
the category structure. For example, it is not built
into the model that DALMATIAN is a type of DOG,
only that it is more specific than DOG; any asso-
ciation between them would be learned from their
pattern of co-occurrence with a word over time.
</bodyText>
<page confidence="0.965522">
1798
</page>
<bodyText confidence="0.981638071428571">
Note that, in contrast to the model of X&amp;T, our
model does not start with a full taxonomy (it does
not know, for example, that Dalmatians and poo-
dles are hyponyms of dogs) and it does not have
built-in knowledge of similarities among concepts.
Still, it encodes some taxonomic knowledge in the
feature groups, and an important future direction
will be to show that this knowledge is learnable
from the input.
Calculating Feature Group Probabilities. To
appropriately split the probability mass within a
feature group !9 (but not across feature groups),
we use a new formulation of Eqn. (3) to update
the meaning probabilities for fi E !9 as follows:
</bodyText>
<equation confidence="0.9602685">
assoct(fi, wj) + γG
Pt(fi|wj) = (5)
E assoct(fm, wj) + kGγG
fnEg
</equation>
<bodyText confidence="0.999737">
where kG is the expected number of features in
!9, and the smoothing factor γG reflects the prior
belief in observing a feature f in !9.2
With this new formulation, the probability of a
feature fi previously unseen with word wj now re-
duces to (cf. Eqn. (4)):
</bodyText>
<equation confidence="0.953716">
γG
Ptu (fi|wj) =E (6)
assoct(fm, wj) + kGγG
fnEg
</equation>
<bodyText confidence="0.987730142857143">
for fi E !9. Note that the smoothing factor γG
depends on !9, and thus the openness of the word
to be associated with new (previously unseen) fea-
tures can vary depending on the feature group.
This unseen probability is very important to the
model’s generalization behaviour. Generalization
involves the model accepting that a learned word
can refer to objects not seen with it before: e.g.,
in the experiments here, we would expect that the
learned meaning for fep after seeing three animals
such as a dog, a penguin, and a sheep could also
accommodate the meaning of a different animal
such as a cat. This ability of the model to asso-
ciate new meaning features with a word depends
precisely on the unseen probability formulation:
the higher the unseen probability for a feature and
a word, the more the feature will be acceptable as
a generalization of the word.
Type-Token Effects on Generalization. The
unseen probability is sensitive to how many in-
stances of features from a group have already been
</bodyText>
<footnote confidence="0.9924938">
2Each feature group forms a Categorical distribution with
kg categories (Cat(θ1, ..., θk. )), where the θi are drawn from
a prior Dirichlet distribution Dir(γ1, ..., γk.) at time t = 0,
and the θi are updated at time t to be the expected value of the
posterior Dirichlet distribution, given in Eqn. (5) or Eqn. (6).
</footnote>
<bodyText confidence="0.999739571428572">
seen with a word wj: As the model observes more
instances (tokens) of features from !9 with wj, the
corresponding assoct score(s) increase, thereby
increasing the denominator in Eqn. (6) and de-
creasing Ptu. Thus the tendency to generalize wj
to more features in !9 – i.e., to accept additional
features as part of the meaning of wj – will de-
crease as the model has more evidence of (ob-
served) features in that group occurring with wj.
Generalization of a category to include new
kinds of items is typically a function of both token
and type frequency (e.g., Bybee, 1985; Croft and
Cruse, 2004): a category with more diverse types
is more easily extended to new cases. While the
evolving association scores capture the effect of
observing more feature tokens, our model as given
does not distinguish the number of different types
of features seen within a group (e.g., two DOGs vs.
one DOG and one CAT).
We address this issue by having γG depend on
the number of observed types of features in the
</bodyText>
<equation confidence="0.732549">
group: γtG = γG0 x type(!9, t)2 (7)
</equation>
<bodyText confidence="0.999984416666667">
where type(!9, t) is the number of different kinds
of features seen in that group (e.g., DOG and
CAT are two different feature types from the same
group) up through time t. In this way, the Ptu of a
feature that occurs in a group with more observed
feature types is higher than the Ptu in a group with
fewer observed types.
Thus both the type frequency of features in !9
and their token frequency of co-occurrence with
word wj will influence – the first positively and
the second negatively – how readily wj can refer
to objects with previously unseen features from !9.
</bodyText>
<sectionHeader confidence="0.999374" genericHeader="method">
5 Experimental Set-up
</sectionHeader>
<bodyText confidence="0.999942083333333">
We model X&amp;T’s behavioural experiments with
our computational word learner as extended
above.3 Following X&amp;T, we use a three-tiered cat-
egory hierarchy, and the four training conditions
and assessment of three types of test matches as
described in Figure 1.
Training the model. In each condition, the
model processes a sequence of 3 utterance-scene
pairs, and updates Pt(fi|wj) after each pair using
Eqns. (5) and (6). The utterance-scene pair in each
trial consists of the novel word coupled with the
scene representation of a training object from the
</bodyText>
<footnote confidence="0.9195805">
3Link to our code/data: github.com/eringrant/
word_learning/tree/hypothesis-space.
</footnote>
<page confidence="0.99605">
1799
</page>
<bodyText confidence="0.999700888888889">
category hierarchy. The object’s scene representa-
tion is given as a set of four features, each taken
from one of four feature groups: one feature cor-
responding to each of the subordinate, basic, and
superordinate levels of the hierarchy, and a unique
“instance” feature, as shown in Table 1. (The “in-
stance” feature is added to simulate the variations
in the different objects of the same subordinate
category in the X&amp;T experiments.)
</bodyText>
<table confidence="0.999385666666667">
1 U: { fep }
2 S: { INSTANCE1, DALMATIAN, DOG, ANIMAL }
3 U: { fep }
S: { INSTANCE2, TABBY, CAT, ANIMAL }
U: { fep }
S: { INSTANCE3, POLAR BEAR, BEAR, ANIMAL }
</table>
<tableCaption confidence="0.9927165">
Table 1: An example of a sequence of utterance-scene pair
trials in the 3-super. condition.
</tableCaption>
<bodyText confidence="0.997659625">
Testing the model. After training on a novel
word, in order to assess its level of generaliza-
tion within the category hierarchy, we compare
the model’s learned meaning of the word to test
objects that constitute various types of matches to
the training conditions: i.e., subordinate matches,
basic-level matches, and superordinate matches.
Table 2 gives an example of each type of match:
</bodyText>
<table confidence="0.410384666666667">
subord.: { INSTANCE4, DALMATIAN, DOG, ANIMAL }
basic: { INSTANCE5, POODLE, DOG, ANIMAL }
super.: { INSTANCE6, TOUCAN, BIRD, ANIMAL }
</table>
<tableCaption confidence="0.974858">
Table 2: An example of each level match from the test ob-
jects, given the training condition in Table 1.
</tableCaption>
<bodyText confidence="0.9982744">
To assess whether the model generalizes the
learned meaning of a word w to the various types
of test matches, we first consider the probability of
a test object Y at time t given the learned meaning
of w:
</bodyText>
<equation confidence="0.994994">
Pt(Y |w) = 11 Pt(yi|w) (8)
ydEY
</equation>
<bodyText confidence="0.991134315789474">
where yi are the features in Y , and Pt(yi|w) is
calculated using Eqn. (5) for features yi observed
with w during training, and using Eqn. (6) for yi
not observed with w. (Recall that Eqn. (5) reduces
to Eqn. (6) when a feature has not been seen with
the word.) From Pt(Y |w), we subtract the predic-
tive probability of the test object before the model
has observed any data, P0(Y |w), which gives us
its increase in preference attributable to the word
learning trials.4
Calculating Pt(Y |w) − P0(Y |w) is informative
about one test object, but we need to measure gen-
eralization of the learned word to all the objects of
a certain type of match – i.e., subordinate, basic-
level, or superordinate. We formulate the proba-
bility of generalization to a type of test match as
the relative average increase in preference for test
items of that type of match, using the Shepard-
Luce choice rule (Shepard, 1958; Luce, 1959):
</bodyText>
<equation confidence="0.949159333333333">
avgY Em [Pt(Y |w)-P0(Y |w)]
Pgen(m|w) = EavgY&apos;Em&apos; [Pt(Y &apos;|w)-P0(Y &apos;|w)]
m&apos;
</equation>
<bodyText confidence="0.999875033333333">
where m is the set of test objects at a certain level
of match, and m&apos; ranges over subordinate matches,
basic-level matches, and superordinate matches.
Using Pgen(m|w) to communicate our models
results has the advantage of using the learned word
meanings in a very direct way to assess the pref-
erence for the various types of test matches in the
X&amp;T experiments. However, the disadvantage is
that this measure is not directly comparable to the
reported figures from the human data, which are
the percentage of test objects selected of a particu-
lar type of match. Hence, in presenting our results
below, we focus on the general patterns of prefer-
ences indicated by the different measures.
Parameters. To model children, whom we as-
sume to have no bias towards generalization to
specific category levels, we equate all parameters
k g and -y g across all feature groups, reflecting that
all category levels are treated equivalently. Here
we use values of k g = 100 and initial values
of -y g = 0.5 for all G as the “child” parame-
ter settings.5 In contrast, we assume that adults,
through word learning experience, have accumu-
lated biases that reflect observed differences in
feature groups. More specifically, we assume that
the probability of observing a new feature for a
group G depends on the degree of specificity of
that group: That is, over time, it is less likely to ob-
serve a completely new kind of animal, e.g., than a
new breed of dog. We simulate these biases by us-
</bodyText>
<equation confidence="0.799718">
4P0(Y |w) = jjc k&apos; is the prior probability of any object
</equation>
<bodyText confidence="0.605737875">
instance, given parameters drawn from the Dirichlet prior, be-
cause Eqn. (6) yields the value kG1 when all assoct scores are
0 – i.e., no features from g have been observed with the word.
5To determine the parameters for the “child” learner, we
examined a number of settings with equal parameter values
for all the feature groups, and observed similar results in these
settings. (We did not perform an exhaustive search over the
parameter space.)
</bodyText>
<page confidence="0.985134">
1800
</page>
<bodyText confidence="0.947429636363636">
ing various values for the parameter -y g, which de-
termines the prior probability of a word being ob-
served with new (previously unseen) features in !9
(cf. Eqn. (6)). We assume that the expected num-
ber of features (k g) is the same across groups. We
perform a non-exhaustive search on the parameter
space of -y g to select a set of values that yield the
patterns of X&amp;T’s adult experiments. The “adult”
parameter values are given in Table 3:6
-&apos;inst = 1.2 -&apos;subord = 1.0 -&apos;basic = 0.5 -&apos;super = 0.2
k inst = 100 k subord = 100 k basic = 100 k super = 100
</bodyText>
<tableCaption confidence="0.996693">
Table 3: “Adult” parameter settings.
</tableCaption>
<sectionHeader confidence="0.997089" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<bodyText confidence="0.999991846153846">
We present results of the model using both child
settings (Figure 3b) and adult settings (Figure 3a).
Recall that these values do not correspond to the
percentages reported in the human data; to evalu-
ate the patterns of generalization, we look at the
relative preference for the various types of test
match. Note also that since the generalization
probabilities sum to 1.0 within each of the 4 train-
ing conditions, we can only compare the pattern of
generalization across conditions (and not the ac-
tual value of the probabilities).
We discuss each of the child and adult sets of
results in detail below.
</bodyText>
<subsectionHeader confidence="0.996435">
6.1 The Child Learner
</subsectionHeader>
<bodyText confidence="0.9999751875">
Recall that in the simulations of a child, we use
equal values across all feature groups for the k g
and initial -y g parameter settings, to reflect that the
learner has no bias towards generalization to spe-
cific category levels.
Looking at the results in Figure 3b, we can see
that the child learner generally replicates the pat-
terns of results observed in X&amp;T’s experiment on
children (cf. Figure 2b). Given multiple training
items (the 3-subord., 3-basic, and 3-super. con-
ditions), the model, like children, generalizes to
the lowest level category in the hierarchy that is
consistent with the training items, roughly equally
preferring items from that category or lower, with
slight preference for the lower categories. In con-
trast, after seeing a single training example (the
</bodyText>
<footnote confidence="0.810324333333333">
6For a certain range of such parameter settings – i.e., with
gradually decreasing -&apos; g , which determines the prior proba-
bility of a word being observed with new (previously unseen)
features in 9 (cf. Eqn. (6)). for feature groups at successively
higher levels in the hierarchy — the model produces similar
results to the presented adult learner.
</footnote>
<figure confidence="0.9669398">
(a) Adult data:
1 ex. 3 subord. 3 basic 3 super.
training condition
1 ex. 3 subord. 3 basic 3 super.
training condition
</figure>
<figureCaption confidence="0.997963666666667">
Figure 3: Our model data for (a) adults and (b) children.
Each bar is the probability of a type of test match: i.e., sub-
ord(inate), basic(-level), or super(ordinate).
</figureCaption>
<bodyText confidence="0.999840566666666">
1-ex. condition), the model shows some tendency
to generalize to the basic-level, demonstrating a
small but notable basic-level bias — e.g., the ten-
dency to consider the word as referring to any dogs
(but less so to other animals) after seeing just a
single example of a particular kind of dog. As in
children, the difference in the model between the
preference for subordinate vs. basic-level matches
is much smaller when trained on 1 instance as op-
posed to 3 subordinates. (In Figure 3b, compare
the difference between the 1st bar [subord. match]
and 2nd bar [basic match] of the 1-ex. training
condition to that of the 3-subord. training condi-
tion.)
Interestingly, our child learner exhibits the ob-
served basic-level bias in the absence of any dif-
ference in the model in how it treats different cat-
egory levels. The observed pattern arises from a
type/token frequency interaction of the kind often
noted to influence generalization of linguistic cate-
gories (e.g., Bybee, 1985; Croft and Cruse, 2004):
here, the interaction between the token frequency
of word–feature pairs in the input and the type
frequency of different features within a group of
dependent features. For example, having seen 3
types of animals (“3 super.” condition), the model
can readily accommodate that fep refers to another
kind of animal, in contrast to the “3 basic” con-
dition, where it has seen the same number of to-
kens but only a single feature type from the feature
</bodyText>
<figure confidence="0.998597266666667">
1
generalization probability
0.5
0
subord. match
basic match
super. match
(b) Child data:
subord. match
basic match
super. match
1
generalization probability
0.5
0
</figure>
<page confidence="0.988698">
1801
</page>
<bodyText confidence="0.999872294117647">
group at that level (3 dogs). We can also clearly
see the inverse impact of token frequencies on gen-
eralization: the more examples of a single subor-
dinate type are seen, the less the model accepts
that fep refers to a different kind of subordinate
(the “3-subord.” vs. “1-ex.” conditions). That is,
with only 1 token of DALMATIAN, the model can
generalize to other types of dogs more readily than
when it has seen 3 tokens of DALMATIAN.
In general, interactions between the type and to-
ken frequencies of the different feature groups in-
teract to yield the observed patterns in the model.
These results indicate that properties of the input
data coupled with the model’s handling of feature
groups can account for children’s word general-
ization behaviour, without the need for an explicit
basic-level bias.
</bodyText>
<subsectionHeader confidence="0.999345">
6.2 The Adult Learner
</subsectionHeader>
<bodyText confidence="0.999986590909091">
Adult participants in X&amp;T exhibited a stronger
tendency than children to generalize to the basic-
level category, especially after seeing a single ex-
emplar. We explore whether the model can simu-
late an adult learner as well. As discussed in Sec-
tion 5, by varying the parameters -y g , we can in-
corporate biases towards different category levels
that we assume an adult has learned. More specif-
ically, we set -y g to successively larger values for
more specific feature groups !9, to ensure succes-
sively greater generalization in lower levels of the
hierarchy (see Table 3). As shown in Figure 3a,
our model (using such settings of the parameters)
replicates the patterns of X&amp;T’s adult experiments
(cf. Figure 2a), including a stronger basic-level
bias than that shown by children. That is, in the
1-ex. and 3-subord. conditions, the difference be-
tween the 1st bar [subord. match] and 2nd bar [ba-
sic match] is smaller for the adult settings of the
model (Figure 3a) than for the child settings (Fig-
ure 3b), mimicking the stronger basic-level bias
found in adults.
</bodyText>
<subsectionHeader confidence="0.999365">
6.3 Variations in Basic-level Generalization
</subsectionHeader>
<bodyText confidence="0.999165566666667">
Research shows that people’s degree of basic-level
generalization depends on the overall category of
the objects. Specifically, Abbott et al. (2012) per-
form the same set of experiments as X&amp;T on
adults, exploring three additional superordinate
categories (clothing, containers, and seats). Their
results are shown in Figure 4; for space reasons,
we focus here on the training conditions with 1-
example or 3-subordinates, which are the locus
of the basic-level effect. The results show that
people exhibit no basic-level generalization for
containers, moderate generalization for clothing,
and strong generalization for seats (compare Fig-
ures 4a, 4b and 4c).
Interestingly, the computational experiments of
Abbott et al. (2012) also reveal that the Bayesian
model of X&amp;T mimics varying levels of basic-
level generalization in the 1-example cases, but
does not capture the differences that people exhibit
across the categories in the 3-subordinate condi-
tion (compare “3 subord.” in Figures 4 and 5):
unlike people, here the X&amp;T model does not ex-
hibit basic-level generalization for any of the cate-
gories.
Abbott et al. (2012) note that a domain like con-
tainers may not follow a “natural taxonomy” in
having a clear basic-level category. This sugges-
tion is compatible with our view that a basic-level
bias arises in response to the particular pattern
of co-occurrence of features across the category
hierarchy. We looked more closely at the train-
ing stimuli of their experiment, and observe that
the examples of the category “containers” (with
the least basic-level generalization) vary greatly,
while those of “clothing” and “seats” are less dif-
ferentiated. Examples from “containers” include a
cigar box, trash can, and mailbox, whereas “seats”
are restricted to different types of chair (such as a
dining chair and an armchair; see Table 1 in Ab-
bott et al. (2012)).
Based on this observation, we hypothesize that
people generalize less to a basic-level category
when their mental representations for that cat-
egory’s instances have more distinguishing fea-
tures. Specifically, we assume that people dif-
ferentiate the given instances of the category
“containers” more than those for “clothing” and
“seats”. We model this difference in the granu-
larity of representations by varying the number of
feature groups used in representing an object. Re-
call that in our earlier experiments, each object
was represented as a set of features drawn from
4 different feature groups. We take this represen-
tation as the least fine-grained representation and
use it for the category “seats”. We assume that the
objects from the categories “clothing” and “con-
tainers” (that exhibit less basic-level generaliza-
tion) are represented with more feature groups (8
and 12, respectively).
Figure 6 shows the results of running our model
</bodyText>
<page confidence="0.988453">
1802
</page>
<figure confidence="0.998515">
generalization probability
(a) Containers (b) Clothing (c) Seats
</figure>
<figureCaption confidence="0.986115">
Figure 4: Abbott et al. (2012) subject response data.
</figureCaption>
<figure confidence="0.9977895">
generalization probability
(a) Containers (b) Clothing (c) Seats
</figure>
<figureCaption confidence="0.999915">
Figure 5: Abbott et al. (2012) model data.
</figureCaption>
<bodyText confidence="0.999967769230769">
on these three categories using the “adult” pa-
rameter settings. As expected, the generalization
to the basic-level category is high for the least
distinguished category “seats”, moderate for the
category “clothing”, and low for the most distin-
guished category “containers”.7
Our results suggest that the observed varia-
tion across categories in basic-level generalization
could arise from differences in the granularity of
representations of categories. This is particularly
interesting since the model of X&amp;T, despite encod-
ing an elaborated taxonomy, does not capture the
observed behaviour across all training conditions.
</bodyText>
<sectionHeader confidence="0.999124" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999919666666667">
A key challenge faced by children in vocabulary
acquisition is learning which of many possible
meanings is appropriate for a word, based largely
on ambiguous situational evidence. One aspect
of this is what we term the “word generalization”
problem, which refers to how children associate a
word such as dog with a meaning at the appropri-
ate category level in a taxonomy of objects, such
as Dalmatians, dogs, or animals.
We present extensions to a cross-situational
learner that enable the first computational study
of word generalization that is integrated within a
word learning model. The model mimics child
behavior found by Xu and Tenenbaum (2007):
it shows a “basic-level” bias – a preference for
word meanings that refer to basic-level objects
(like dogs), in contrast to higher-level (animals) or
lower-level (Dalmatians) categories – and does so
</bodyText>
<footnote confidence="0.9705425">
7Similar results obtain using “child” parameter settings,
but (as expected) the basic-level generalization is lower.
</footnote>
<figure confidence="0.979201">
(a) Containers (b) Clothing (c) Seats
</figure>
<figureCaption confidence="0.999877">
Figure 6: Data from our model.
</figureCaption>
<bodyText confidence="0.999867219512195">
under parameter settings that treat all levels of cat-
egory the same in the model (i.e., with no built-in
basic-level bias). Other (unequal) parameter set-
tings, which could reflect learned knowledge lead-
ing to differential treatment of categories, yield
behavior that mimics that of adults, who show
a stronger basic-level bias. Moreover, similarly
to people (Abbott et al., 2012), our model ex-
hibits variations in generalization to the basic level
for different types of objects, a behavior that the
model of Xu and Tenenbaum (2007) does not fully
replicate.
Overall, the results of our model arise from the
interaction of type and token frequencies of fea-
tures in the input data, which impact the model’s
evolving word representations. This mechanism
in the model captures the type-token influence of-
ten observed to underlie people’s generalization of
linguistic categories – i.e., their linguistic produc-
tivity (e.g., Bybee, 1985; Croft and Cruse, 2004).
One shortcoming of the current model is its
built-in ability to “detect” in the input that DOG
and CAT features are more specific than ANIMAL
features. The next step is to consider how the
model might learn these relationships from its
evolving knowledge of co-occurring features.
Finally, a similar problem to that of word gen-
eralization in humans arises in computational lin-
guistics: how to appropriately generalize a set of
concepts to an overarching concept that subsumes
the set. For example, this problem underlies one
way to determine the selectional preferences of a
verb: extract the set of nouns that occur as objects
of the verb, map them to the concept nodes in a hi-
erarchy such as WordNet, and then determine the
best overarching WordNet category for capturing
the salient properties of the object nouns overall
(e.g., Li and Abe, 1998; Clark and Weir, 2001).
An interesting future direction is to explore how
an extension of our work can be applied to such
problems in computational linguistics.
</bodyText>
<figure confidence="0.9964388125">
generalization probability
0.5
0
1
1 ex. 3
subord.
0.5
0
1
1 ex. 3
subord.
0.5
0
1
1 ex. 3
subord.
</figure>
<page confidence="0.967776">
1803
</page>
<sectionHeader confidence="0.994255" genericHeader="acknowledgments">
8 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999874">
We would like to thank Jackie Chi Kit Cheung and
the anonymous reviewers for their valuable feed-
back. We gratefully acknowledge the support of
NSERC of Canada, and of an Ontario Graduate
Scholarship to the first author.
</bodyText>
<sectionHeader confidence="0.998897" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999900358024691">
Joshua T. Abbott, Joseph L. Austerweil, and Thomas L.
Griffiths. 2012. Constructing a hypothesis space
from the web for large-scale bayesian word learning.
Proceedings of the 34th Annual Conference of the
Cognitive Science Society.
Joan L. Bybee. 1985. Morphology: A study of the
relation between meaning and form. Benjamins,
Philadelphia.
Stephen Clark and David Weir. 2001. Class-based
probability estimation using a semantic hierarchy.
In Proceedings of the second meeting of the North
American Chapter of the Association for Computa-
tional Linguistics on Language technologies, pages
1–8. Association for Computational Linguistics.
William Croft and Alan Cruse. 2004. Cognitive lin-
guistics. Cambridge University Press.
Afsaneh Fazly, Afra Alishahi, and Suzanne Steven-
son. 2010. A probabilistic computational model of
cross-situational word learning. Cognitive Science,
34(6):1017–1063.
Michael C. Frank, Noah D. Goodman, and Joshua B.
Tenenbaum. 2007. A Bayesian framework for
cross-situational word-learning. In NIPS’07, vol-
ume 20.
Roberta M. Golinkoff, Carolyn B. Mervis, and Kathryn
Hirsh-Pasek. 1994. Early object labels: The case
for a developmental lexical principles framework.
Journal of child language, 21(01):125–155.
George Kachergis, Chen Yu, and Richard M. Shiffrin.
2012. An associative model of adaptive inference
for learning word–referent mappings. Psychonomic
Bulletin &amp; Review, pages 1–8.
Hang Li and Naoki Abe. 1998. Word clustering and
disambiguation based on co-occurrence data. In
Proceedings of the 17th International Conference
on Computational Linguistics - Volume 2, COLING
’98, pages 749–755. Association for Computational
Linguistics.
Robert D. Luce. 1959. Individual choice behaviour.
Wiley, NY.
Ellen M. Markman. 1991. Categorization and naming
in children: Problems of induction. Mit Press.
David Marr. 1982. Vision: A computational investiga-
tion into the human representation and processing of
visual information.
Aida Nematzadeh, Afsaneh Fazly, and Suzanne
Stevenson. 2011. A computational study of late
talking in word-meaning acquisition. In Proceed-
ings of the 33th Annual Conference of the Cognitive
Science Society, pages 705–710.
Steven Pinker. 1989. Learnability and Cognition:
The acquisition of Argument Structure. Cambridge,
Mass.: MIT Press.
Willard Van Orman Quine. 1960. Word and Object.
MIT Press.
Eleanor Rosch, Carolyn B. Mervis, Wayne D. Gray,
David M, and Penny Boyes-Braem. 1976. Basic
objects in natural categories. Cognitive Psychology.
Eleanor Rosch, 1973. On the Internal Structure of Per-
ceptual and Semantic Categories, pages 111–144.
Academic Press, New York, NY.
Roger N. Shepard. 1958. Stimulus and response gen-
eralization: Tests of a model relating generalization
to distance in psychological space. Journal of Ex-
perimental Psychology, 55(6):509.
Jeffery M. Siskind. 1996. A computational study
of cross-situational techniques for learning word-to-
meaning mappings. Cognition, 61:39–91.
Linda B. Smith and Chen Yu. 2008. Infants rapidly
learn word-referent mappings via cross-situational
statistics. Cognition, 106(3):1558–1568.
Fei Xu and Joshua B. Tenenbaum. 2007. Word learn-
ing as Bayesian inference. Psychological Review,
114(2):245–272.
Chen Yu and Linda B. Smith. 2007. Rapid word learn-
ing under uncertainty via cross-situational statistics.
Psychological Science, 18(5):414–420.
Daniel Yurovsky, Damian C. Fricker, Chen Yu, and
Linda B. Smith. 2014. The role of partial knowl-
edge in statistical word learning. Psychonomic bul-
letin &amp; review, 21(1):1–22.
</reference>
<page confidence="0.996753">
1804
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.977874">
<title confidence="0.999903">A Computational Cognitive Model of Novel Word Generalization</title>
<author confidence="0.99521">Aida Nematzadeh</author>
<author confidence="0.99521">Erin Grant</author>
<author confidence="0.99521">Suzanne</author>
<affiliation confidence="0.9981045">Department of Computer University of</affiliation>
<abstract confidence="0.999221722222222">A key challenge in vocabulary acquisition is learning which of the many possible meanings is appropriate for a word. The word generalization problem refers to how associate a word such as a meaning at the appropriate category level in a taxonomy of objects, such as Dalmatians, dogs, or animals. We present the first computational study of word generalization integrated within a word-learning model. The model simulates child and adult patterns of word generalization in a word-learning task. These patterns arise due to the interaction of type and token frequencies in the input data, an influence often observed in people’s generalization of linguistic categories.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Joshua T Abbott</author>
<author>Joseph L Austerweil</author>
<author>Thomas L Griffiths</author>
</authors>
<title>Constructing a hypothesis space from the web for large-scale bayesian word learning.</title>
<date>2012</date>
<booktitle>Proceedings of the 34th Annual Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="32291" citStr="Abbott et al. (2012)" startWordPosition="5449" endWordPosition="5452">rameters) replicates the patterns of X&amp;T’s adult experiments (cf. Figure 2a), including a stronger basic-level bias than that shown by children. That is, in the 1-ex. and 3-subord. conditions, the difference between the 1st bar [subord. match] and 2nd bar [basic match] is smaller for the adult settings of the model (Figure 3a) than for the child settings (Figure 3b), mimicking the stronger basic-level bias found in adults. 6.3 Variations in Basic-level Generalization Research shows that people’s degree of basic-level generalization depends on the overall category of the objects. Specifically, Abbott et al. (2012) perform the same set of experiments as X&amp;T on adults, exploring three additional superordinate categories (clothing, containers, and seats). Their results are shown in Figure 4; for space reasons, we focus here on the training conditions with 1- example or 3-subordinates, which are the locus of the basic-level effect. The results show that people exhibit no basic-level generalization for containers, moderate generalization for clothing, and strong generalization for seats (compare Figures 4a, 4b and 4c). Interestingly, the computational experiments of Abbott et al. (2012) also reveal that the</context>
<context position="34006" citStr="Abbott et al. (2012)" startWordPosition="5721" endWordPosition="5725">gestion is compatible with our view that a basic-level bias arises in response to the particular pattern of co-occurrence of features across the category hierarchy. We looked more closely at the training stimuli of their experiment, and observe that the examples of the category “containers” (with the least basic-level generalization) vary greatly, while those of “clothing” and “seats” are less differentiated. Examples from “containers” include a cigar box, trash can, and mailbox, whereas “seats” are restricted to different types of chair (such as a dining chair and an armchair; see Table 1 in Abbott et al. (2012)). Based on this observation, we hypothesize that people generalize less to a basic-level category when their mental representations for that category’s instances have more distinguishing features. Specifically, we assume that people differentiate the given instances of the category “containers” more than those for “clothing” and “seats”. We model this difference in the granularity of representations by varying the number of feature groups used in representing an object. Recall that in our earlier experiments, each object was represented as a set of features drawn from 4 different feature grou</context>
<context position="37242" citStr="Abbott et al., 2012" startWordPosition="6216" endWordPosition="6219">) or lower-level (Dalmatians) categories – and does so 7Similar results obtain using “child” parameter settings, but (as expected) the basic-level generalization is lower. (a) Containers (b) Clothing (c) Seats Figure 6: Data from our model. under parameter settings that treat all levels of category the same in the model (i.e., with no built-in basic-level bias). Other (unequal) parameter settings, which could reflect learned knowledge leading to differential treatment of categories, yield behavior that mimics that of adults, who show a stronger basic-level bias. Moreover, similarly to people (Abbott et al., 2012), our model exhibits variations in generalization to the basic level for different types of objects, a behavior that the model of Xu and Tenenbaum (2007) does not fully replicate. Overall, the results of our model arise from the interaction of type and token frequencies of features in the input data, which impact the model’s evolving word representations. This mechanism in the model captures the type-token influence often observed to underlie people’s generalization of linguistic categories – i.e., their linguistic productivity (e.g., Bybee, 1985; Croft and Cruse, 2004). One shortcoming of the</context>
</contexts>
<marker>Abbott, Austerweil, Griffiths, 2012</marker>
<rawString>Joshua T. Abbott, Joseph L. Austerweil, and Thomas L. Griffiths. 2012. Constructing a hypothesis space from the web for large-scale bayesian word learning. Proceedings of the 34th Annual Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joan L Bybee</author>
</authors>
<title>Morphology: A study of the relation between meaning and form.</title>
<date>1985</date>
<location>Benjamins, Philadelphia.</location>
<contexts>
<context position="5661" citStr="Bybee, 1985" startWordPosition="900" endWordPosition="901">&amp;T model, our model is an incremental learner that gradually acquires the meaning of words, and uses these developing meanings in determining the appropriate extension of a word to elements of a taxonomy. Our model has general knowledge of category structure without having an elaborated taxonomy encoding known object similarities. Moreover, in the absence of any bias toward generalization to particular kinds of categories, the model exhibits the observed “basic-level bias” due to general mechanisms of productivity that have been proposed to apply to many aspects of linguistic knowledge (e.g., Bybee, 1985; Croft and Cruse, 2004).1 In what follows, we first describe the human experiments of X&amp;T, and then present our computational model and the experiments that simulate the X&amp;T data. 2 Novel Word Generalization in People X&amp;T perform a set of empirical studies to investigate how children and adults generalize novel words learned from a few examples to the appro1Computational cognitive models are often categorized with respect to Marr’s levels of analysis, i.e., their degree of abstraction (Marr, 1982). The model of X&amp;T is at the computational level, providing a Bayesian framework for the problem </context>
<context position="19720" citStr="Bybee, 1985" startWordPosition="3294" endWordPosition="3295">tribution, given in Eqn. (5) or Eqn. (6). seen with a word wj: As the model observes more instances (tokens) of features from !9 with wj, the corresponding assoct score(s) increase, thereby increasing the denominator in Eqn. (6) and decreasing Ptu. Thus the tendency to generalize wj to more features in !9 – i.e., to accept additional features as part of the meaning of wj – will decrease as the model has more evidence of (observed) features in that group occurring with wj. Generalization of a category to include new kinds of items is typically a function of both token and type frequency (e.g., Bybee, 1985; Croft and Cruse, 2004): a category with more diverse types is more easily extended to new cases. While the evolving association scores capture the effect of observing more feature tokens, our model as given does not distinguish the number of different types of features seen within a group (e.g., two DOGs vs. one DOG and one CAT). We address this issue by having γG depend on the number of observed types of features in the group: γtG = γG0 x type(!9, t)2 (7) where type(!9, t) is the number of different kinds of features seen in that group (e.g., DOG and CAT are two different feature types from</context>
<context position="29569" citStr="Bybee, 1985" startWordPosition="4997" endWordPosition="4998">ubordinate vs. basic-level matches is much smaller when trained on 1 instance as opposed to 3 subordinates. (In Figure 3b, compare the difference between the 1st bar [subord. match] and 2nd bar [basic match] of the 1-ex. training condition to that of the 3-subord. training condition.) Interestingly, our child learner exhibits the observed basic-level bias in the absence of any difference in the model in how it treats different category levels. The observed pattern arises from a type/token frequency interaction of the kind often noted to influence generalization of linguistic categories (e.g., Bybee, 1985; Croft and Cruse, 2004): here, the interaction between the token frequency of word–feature pairs in the input and the type frequency of different features within a group of dependent features. For example, having seen 3 types of animals (“3 super.” condition), the model can readily accommodate that fep refers to another kind of animal, in contrast to the “3 basic” condition, where it has seen the same number of tokens but only a single feature type from the feature 1 generalization probability 0.5 0 subord. match basic match super. match (b) Child data: subord. match basic match super. match </context>
<context position="37794" citStr="Bybee, 1985" startWordPosition="6305" endWordPosition="6306">l bias. Moreover, similarly to people (Abbott et al., 2012), our model exhibits variations in generalization to the basic level for different types of objects, a behavior that the model of Xu and Tenenbaum (2007) does not fully replicate. Overall, the results of our model arise from the interaction of type and token frequencies of features in the input data, which impact the model’s evolving word representations. This mechanism in the model captures the type-token influence often observed to underlie people’s generalization of linguistic categories – i.e., their linguistic productivity (e.g., Bybee, 1985; Croft and Cruse, 2004). One shortcoming of the current model is its built-in ability to “detect” in the input that DOG and CAT features are more specific than ANIMAL features. The next step is to consider how the model might learn these relationships from its evolving knowledge of co-occurring features. Finally, a similar problem to that of word generalization in humans arises in computational linguistics: how to appropriately generalize a set of concepts to an overarching concept that subsumes the set. For example, this problem underlies one way to determine the selectional preferences of a</context>
</contexts>
<marker>Bybee, 1985</marker>
<rawString>Joan L. Bybee. 1985. Morphology: A study of the relation between meaning and form. Benjamins, Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>David Weir</author>
</authors>
<title>Class-based probability estimation using a semantic hierarchy.</title>
<date>2001</date>
<booktitle>In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Clark, Weir, 2001</marker>
<rawString>Stephen Clark and David Weir. 2001. Class-based probability estimation using a semantic hierarchy. In Proceedings of the second meeting of the North American Chapter of the Association for Computational Linguistics on Language technologies, pages 1–8. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Croft</author>
<author>Alan Cruse</author>
</authors>
<title>Cognitive linguistics.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5685" citStr="Croft and Cruse, 2004" startWordPosition="902" endWordPosition="905"> model is an incremental learner that gradually acquires the meaning of words, and uses these developing meanings in determining the appropriate extension of a word to elements of a taxonomy. Our model has general knowledge of category structure without having an elaborated taxonomy encoding known object similarities. Moreover, in the absence of any bias toward generalization to particular kinds of categories, the model exhibits the observed “basic-level bias” due to general mechanisms of productivity that have been proposed to apply to many aspects of linguistic knowledge (e.g., Bybee, 1985; Croft and Cruse, 2004).1 In what follows, we first describe the human experiments of X&amp;T, and then present our computational model and the experiments that simulate the X&amp;T data. 2 Novel Word Generalization in People X&amp;T perform a set of empirical studies to investigate how children and adults generalize novel words learned from a few examples to the appro1Computational cognitive models are often categorized with respect to Marr’s levels of analysis, i.e., their degree of abstraction (Marr, 1982). The model of X&amp;T is at the computational level, providing a Bayesian framework for the problem of word generalization. </context>
<context position="19744" citStr="Croft and Cruse, 2004" startWordPosition="3296" endWordPosition="3299">ven in Eqn. (5) or Eqn. (6). seen with a word wj: As the model observes more instances (tokens) of features from !9 with wj, the corresponding assoct score(s) increase, thereby increasing the denominator in Eqn. (6) and decreasing Ptu. Thus the tendency to generalize wj to more features in !9 – i.e., to accept additional features as part of the meaning of wj – will decrease as the model has more evidence of (observed) features in that group occurring with wj. Generalization of a category to include new kinds of items is typically a function of both token and type frequency (e.g., Bybee, 1985; Croft and Cruse, 2004): a category with more diverse types is more easily extended to new cases. While the evolving association scores capture the effect of observing more feature tokens, our model as given does not distinguish the number of different types of features seen within a group (e.g., two DOGs vs. one DOG and one CAT). We address this issue by having γG depend on the number of observed types of features in the group: γtG = γG0 x type(!9, t)2 (7) where type(!9, t) is the number of different kinds of features seen in that group (e.g., DOG and CAT are two different feature types from the same group) up thro</context>
<context position="29593" citStr="Croft and Cruse, 2004" startWordPosition="4999" endWordPosition="5002">. basic-level matches is much smaller when trained on 1 instance as opposed to 3 subordinates. (In Figure 3b, compare the difference between the 1st bar [subord. match] and 2nd bar [basic match] of the 1-ex. training condition to that of the 3-subord. training condition.) Interestingly, our child learner exhibits the observed basic-level bias in the absence of any difference in the model in how it treats different category levels. The observed pattern arises from a type/token frequency interaction of the kind often noted to influence generalization of linguistic categories (e.g., Bybee, 1985; Croft and Cruse, 2004): here, the interaction between the token frequency of word–feature pairs in the input and the type frequency of different features within a group of dependent features. For example, having seen 3 types of animals (“3 super.” condition), the model can readily accommodate that fep refers to another kind of animal, in contrast to the “3 basic” condition, where it has seen the same number of tokens but only a single feature type from the feature 1 generalization probability 0.5 0 subord. match basic match super. match (b) Child data: subord. match basic match super. match 1 generalization probabi</context>
<context position="37818" citStr="Croft and Cruse, 2004" startWordPosition="6307" endWordPosition="6310">ver, similarly to people (Abbott et al., 2012), our model exhibits variations in generalization to the basic level for different types of objects, a behavior that the model of Xu and Tenenbaum (2007) does not fully replicate. Overall, the results of our model arise from the interaction of type and token frequencies of features in the input data, which impact the model’s evolving word representations. This mechanism in the model captures the type-token influence often observed to underlie people’s generalization of linguistic categories – i.e., their linguistic productivity (e.g., Bybee, 1985; Croft and Cruse, 2004). One shortcoming of the current model is its built-in ability to “detect” in the input that DOG and CAT features are more specific than ANIMAL features. The next step is to consider how the model might learn these relationships from its evolving knowledge of co-occurring features. Finally, a similar problem to that of word generalization in humans arises in computational linguistics: how to appropriately generalize a set of concepts to an overarching concept that subsumes the set. For example, this problem underlies one way to determine the selectional preferences of a verb: extract the set o</context>
</contexts>
<marker>Croft, Cruse, 2004</marker>
<rawString>William Croft and Alan Cruse. 2004. Cognitive linguistics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Afra Alishahi</author>
<author>Suzanne Stevenson</author>
</authors>
<title>A probabilistic computational model of cross-situational word learning.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>6</issue>
<contexts>
<context position="1553" citStr="Fazly et al., 2010" startWordPosition="236" endWordPosition="239">gs is a challenging early step in child language acquisition. Imagine a child hears the word dax for the first time while observing a white rabbit jumping around – dax might mean WHITE RABBIT, RABBIT, ANIMAL, CUTE, LOOK, etc. (Quine, 1960). How does the child learn the correct meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014). Although cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word learning: determining the correct level of a hierarchical taxonomy that a word refers to. For example, children learn that the</context>
<context position="10456" citStr="Fazly et al. (2010)" startWordPosition="1698" endWordPosition="1701">-level matches (other dogs) having seen a single Dalmatian or having seen 3 Dalmatians. In the other conditions, children’s behaviour is similar to adults, but shows somewhat less generalization to unseen types of objects (e.g., other kinds of dogs/animals than those in training). (a) Adult data: (b) Child data: Figure 2: X&amp;T data for (a) adults and (b) children. Each bar is the percentage of chosen test objects of a type of test match: i.e., subord(inate), basic(-level), or super(ordinate). 3 The Word Learning Framework Our computational model is based on the crosssituational word learner of Fazly et al. (2010) (henceforth, FAS), which accounts for a range of observed patterns in child and adult vocabulary acquisition. Here we give an overview of the FAS model; the next section explains extensions to handle the novel word generalization task. A naturalistic language learning scenario consists of both linguistic data (what a child a hears) and non-linguistic data (what a child perceives). This input is modeled as a sequence of utterance– scene (U–5) pairs, where an utterance is a group of words and a scene is a set of semantic features representing the meaning of those words: U: { look, a, fep, ... }</context>
</contexts>
<marker>Fazly, Alishahi, Stevenson, 2010</marker>
<rawString>Afsaneh Fazly, Afra Alishahi, and Suzanne Stevenson. 2010. A probabilistic computational model of cross-situational word learning. Cognitive Science, 34(6):1017–1063.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C Frank</author>
<author>Noah D Goodman</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>A Bayesian framework for cross-situational word-learning.</title>
<date>2007</date>
<booktitle>In NIPS’07,</booktitle>
<volume>20</volume>
<contexts>
<context position="1533" citStr="Frank et al., 2007" startWordPosition="232" endWordPosition="235">Learning word meanings is a challenging early step in child language acquisition. Imagine a child hears the word dax for the first time while observing a white rabbit jumping around – dax might mean WHITE RABBIT, RABBIT, ANIMAL, CUTE, LOOK, etc. (Quine, 1960). How does the child learn the correct meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014). Although cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word learning: determining the correct level of a hierarchical taxonomy that a word refers to. For example, chi</context>
</contexts>
<marker>Frank, Goodman, Tenenbaum, 2007</marker>
<rawString>Michael C. Frank, Noah D. Goodman, and Joshua B. Tenenbaum. 2007. A Bayesian framework for cross-situational word-learning. In NIPS’07, volume 20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberta M Golinkoff</author>
<author>Carolyn B Mervis</author>
<author>Kathryn Hirsh-Pasek</author>
</authors>
<title>Early object labels: The case for a developmental lexical principles framework.</title>
<date>1994</date>
<journal>Journal of child language,</journal>
<volume>21</volume>
<issue>01</issue>
<contexts>
<context position="2831" citStr="Golinkoff et al., 1994" startWordPosition="443" endWordPosition="446">cific breed, such as Dalmatians, or to a more general category, such as animals – even though some of these choices (e.g., animals) are compatible with all the cross-situational evidence available for dog (because all dogs are also animals). We use the term “word generalization” to refer to this problem of associating a word with the meaning at an appropriate category level, given some sample of experiences with the word. Previous research has argued that children use a specific bias or constraint – the basic-level assumption – to focus their word generalizations appropriately (Markman, 1991; Golinkoff et al., 1994). According to this bias, children prefer to associate a word to a set of objects that form a basic-level category, such as dogs or trucks, and that share a significant number of attributes. It is less preferred to associate a new word to much more specific subordinate categories, such as Dalmatians or bulldozers, or to more general superordinate ones, like animals or vehicles, whose members share fewer attributes (Rosch, 1973; Rosch et al., 1976). It remains an important open question of whether a word learner requires such a bias to acquire appropriate mappings. Xu and Tenenbaum (2007) (X&amp;T </context>
</contexts>
<marker>Golinkoff, Mervis, Hirsh-Pasek, 1994</marker>
<rawString>Roberta M. Golinkoff, Carolyn B. Mervis, and Kathryn Hirsh-Pasek. 1994. Early object labels: The case for a developmental lexical principles framework. Journal of child language, 21(01):125–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Kachergis</author>
<author>Chen Yu</author>
<author>Richard M Shiffrin</author>
</authors>
<title>An associative model of adaptive inference for learning word–referent mappings. Psychonomic Bulletin &amp; Review,</title>
<date>2012</date>
<pages>1--8</pages>
<contexts>
<context position="1578" citStr="Kachergis et al., 2012" startWordPosition="240" endWordPosition="243">early step in child language acquisition. Imagine a child hears the word dax for the first time while observing a white rabbit jumping around – dax might mean WHITE RABBIT, RABBIT, ANIMAL, CUTE, LOOK, etc. (Quine, 1960). How does the child learn the correct meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014). Although cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word learning: determining the correct level of a hierarchical taxonomy that a word refers to. For example, children learn that the word dog refers to all k</context>
</contexts>
<marker>Kachergis, Yu, Shiffrin, 2012</marker>
<rawString>George Kachergis, Chen Yu, and Richard M. Shiffrin. 2012. An associative model of adaptive inference for learning word–referent mappings. Psychonomic Bulletin &amp; Review, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<title>Word clustering and disambiguation based on co-occurrence data.</title>
<date>1998</date>
<booktitle>In Proceedings of the 17th International Conference on Computational Linguistics - Volume 2, COLING ’98,</booktitle>
<pages>749--755</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Li, Abe, 1998</marker>
<rawString>Hang Li and Naoki Abe. 1998. Word clustering and disambiguation based on co-occurrence data. In Proceedings of the 17th International Conference on Computational Linguistics - Volume 2, COLING ’98, pages 749–755. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert D Luce</author>
</authors>
<title>Individual choice behaviour.</title>
<date>1959</date>
<publisher>Wiley, NY.</publisher>
<contexts>
<context position="23876" citStr="Luce, 1959" startWordPosition="4016" endWordPosition="4017">ve probability of the test object before the model has observed any data, P0(Y |w), which gives us its increase in preference attributable to the word learning trials.4 Calculating Pt(Y |w) − P0(Y |w) is informative about one test object, but we need to measure generalization of the learned word to all the objects of a certain type of match – i.e., subordinate, basiclevel, or superordinate. We formulate the probability of generalization to a type of test match as the relative average increase in preference for test items of that type of match, using the ShepardLuce choice rule (Shepard, 1958; Luce, 1959): avgY Em [Pt(Y |w)-P0(Y |w)] Pgen(m|w) = EavgY&apos;Em&apos; [Pt(Y &apos;|w)-P0(Y &apos;|w)] m&apos; where m is the set of test objects at a certain level of match, and m&apos; ranges over subordinate matches, basic-level matches, and superordinate matches. Using Pgen(m|w) to communicate our models results has the advantage of using the learned word meanings in a very direct way to assess the preference for the various types of test matches in the X&amp;T experiments. However, the disadvantage is that this measure is not directly comparable to the reported figures from the human data, which are the percentage of test objects </context>
</contexts>
<marker>Luce, 1959</marker>
<rawString>Robert D. Luce. 1959. Individual choice behaviour. Wiley, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Markman</author>
</authors>
<title>Categorization and naming in children: Problems of induction.</title>
<date>1991</date>
<publisher>Mit Press.</publisher>
<contexts>
<context position="2806" citStr="Markman, 1991" startWordPosition="441" endWordPosition="442">nd not to a specific breed, such as Dalmatians, or to a more general category, such as animals – even though some of these choices (e.g., animals) are compatible with all the cross-situational evidence available for dog (because all dogs are also animals). We use the term “word generalization” to refer to this problem of associating a word with the meaning at an appropriate category level, given some sample of experiences with the word. Previous research has argued that children use a specific bias or constraint – the basic-level assumption – to focus their word generalizations appropriately (Markman, 1991; Golinkoff et al., 1994). According to this bias, children prefer to associate a word to a set of objects that form a basic-level category, such as dogs or trucks, and that share a significant number of attributes. It is less preferred to associate a new word to much more specific subordinate categories, such as Dalmatians or bulldozers, or to more general superordinate ones, like animals or vehicles, whose members share fewer attributes (Rosch, 1973; Rosch et al., 1976). It remains an important open question of whether a word learner requires such a bias to acquire appropriate mappings. Xu a</context>
</contexts>
<marker>Markman, 1991</marker>
<rawString>Ellen M. Markman. 1991. Categorization and naming in children: Problems of induction. Mit Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Marr</author>
</authors>
<title>Vision: A computational investigation into the human representation and processing of visual information.</title>
<date>1982</date>
<contexts>
<context position="6164" citStr="Marr, 1982" startWordPosition="982" endWordPosition="983"> of productivity that have been proposed to apply to many aspects of linguistic knowledge (e.g., Bybee, 1985; Croft and Cruse, 2004).1 In what follows, we first describe the human experiments of X&amp;T, and then present our computational model and the experiments that simulate the X&amp;T data. 2 Novel Word Generalization in People X&amp;T perform a set of empirical studies to investigate how children and adults generalize novel words learned from a few examples to the appro1Computational cognitive models are often categorized with respect to Marr’s levels of analysis, i.e., their degree of abstraction (Marr, 1982). The model of X&amp;T is at the computational level, providing a Bayesian framework for the problem of word generalization. In contrast, our model investigates more detailed mechanisms and thus lies between the algorithmic and computational levels of analysis. priate level of meaning in a taxonomy. In each training trial of an experiment, participants hear a novel word (such as fep) and observe one or more instances exemplifying the word (in the form of pictures for adults and toy objects for children). The conditions vary in that the make-up of the set of training instances is representative of </context>
</contexts>
<marker>Marr, 1982</marker>
<rawString>David Marr. 1982. Vision: A computational investigation into the human representation and processing of visual information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aida Nematzadeh</author>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>A computational study of late talking in word-meaning acquisition.</title>
<date>2011</date>
<booktitle>In Proceedings of the 33th Annual Conference of the Cognitive Science Society,</booktitle>
<pages>705--710</pages>
<contexts>
<context position="13113" citStr="Nematzadeh et al., 2011" startWordPosition="2160" endWordPosition="2163">assoct(fm, wj) + k -y (3) fmEM Here M is the group of all features that the model has observed, k is the expected number of such features, and -y is a small smoothing parameter, which determines the prior probability of observing a new feature. Smoothing entails that features previously unseen with a word (all fi such that assoct(fi, wj) = 0) have a small but non-zero probability. That is, when fi is unseen with wj, Eqn. (3) reduces to: -y Ptu (fi|wj) =E assoct(fm,wj) + k-y (4) fmEM This unseen probability, Ptu, reflects the learner’s “openness” to the word being associated with new features (Nematzadeh et al., 2011): a higher or lower Ptu (fi|wj) will affect how strongly a previously unseen fi can be associated with wj in the alignment process (Eqn. (1)). We return to this property of the model below, as it relates to the behaviour of our model in making generalizations. 4 Extensions to the Model We assume that the representation of meaning can be abstracted to features that correspond to different levels of categorization. For example, a Dalmatian in an input scene is represented as {DALMATIAN, DOG, ANIMAL} and a Bulldog as {BULLDOG, DOG, ANIMAL}, where we use FEATURENAME to refer to all the features th</context>
</contexts>
<marker>Nematzadeh, Fazly, Stevenson, 2011</marker>
<rawString>Aida Nematzadeh, Afsaneh Fazly, and Suzanne Stevenson. 2011. A computational study of late talking in word-meaning acquisition. In Proceedings of the 33th Annual Conference of the Cognitive Science Society, pages 705–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Pinker</author>
</authors>
<title>Learnability and Cognition: The acquisition of Argument Structure.</title>
<date>1989</date>
<publisher>MIT Press.</publisher>
<location>Cambridge, Mass.:</location>
<contexts>
<context position="1429" citStr="Pinker, 1989" startWordPosition="218" endWordPosition="219">a, an influence often observed in people’s generalization of linguistic categories. 1 Introduction Learning word meanings is a challenging early step in child language acquisition. Imagine a child hears the word dax for the first time while observing a white rabbit jumping around – dax might mean WHITE RABBIT, RABBIT, ANIMAL, CUTE, LOOK, etc. (Quine, 1960). How does the child learn the correct meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014). Although cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word le</context>
</contexts>
<marker>Pinker, 1989</marker>
<rawString>Steven Pinker. 1989. Learnability and Cognition: The acquisition of Argument Structure. Cambridge, Mass.: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Willard Van Orman Quine</author>
</authors>
<title>Word and Object.</title>
<date>1960</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1174" citStr="Quine, 1960" startWordPosition="175" endWordPosition="176"> study of word generalization integrated within a word-learning model. The model simulates child and adult patterns of word generalization in a word-learning task. These patterns arise due to the interaction of type and token frequencies in the input data, an influence often observed in people’s generalization of linguistic categories. 1 Introduction Learning word meanings is a challenging early step in child language acquisition. Imagine a child hears the word dax for the first time while observing a white rabbit jumping around – dax might mean WHITE RABBIT, RABBIT, ANIMAL, CUTE, LOOK, etc. (Quine, 1960). How does the child learn the correct meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous lear</context>
</contexts>
<marker>Quine, 1960</marker>
<rawString>Willard Van Orman Quine. 1960. Word and Object. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleanor Rosch</author>
<author>Carolyn B Mervis</author>
<author>Wayne D Gray</author>
<author>M David</author>
<author>Penny Boyes-Braem</author>
</authors>
<title>Basic objects in natural categories.</title>
<date>1976</date>
<publisher>Cognitive Psychology.</publisher>
<contexts>
<context position="3282" citStr="Rosch et al., 1976" startWordPosition="520" endWordPosition="523">that children use a specific bias or constraint – the basic-level assumption – to focus their word generalizations appropriately (Markman, 1991; Golinkoff et al., 1994). According to this bias, children prefer to associate a word to a set of objects that form a basic-level category, such as dogs or trucks, and that share a significant number of attributes. It is less preferred to associate a new word to much more specific subordinate categories, such as Dalmatians or bulldozers, or to more general superordinate ones, like animals or vehicles, whose members share fewer attributes (Rosch, 1973; Rosch et al., 1976). It remains an important open question of whether a word learner requires such a bias to acquire appropriate mappings. Xu and Tenenbaum (2007) (X&amp;T henceforth) studied the word generalization problem in a set of experiments in which children and adults were asked to determine which level of a taxonomy a novel word referred to. X&amp;T further examined this behavioral data through computational modelling. They proposed a Bayesian model that, given a few exemplars of a novel word, matches human behaviour in how it maps the word to its 1795 Proceedings of the 2015 Conference on Empirical Methods in </context>
</contexts>
<marker>Rosch, Mervis, Gray, David, Boyes-Braem, 1976</marker>
<rawString>Eleanor Rosch, Carolyn B. Mervis, Wayne D. Gray, David M, and Penny Boyes-Braem. 1976. Basic objects in natural categories. Cognitive Psychology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleanor Rosch</author>
</authors>
<title>On the Internal Structure of Perceptual and Semantic Categories,</title>
<date>1973</date>
<pages>111--144</pages>
<publisher>Academic Press,</publisher>
<location>New York, NY.</location>
<contexts>
<context position="3261" citStr="Rosch, 1973" startWordPosition="518" endWordPosition="519">h has argued that children use a specific bias or constraint – the basic-level assumption – to focus their word generalizations appropriately (Markman, 1991; Golinkoff et al., 1994). According to this bias, children prefer to associate a word to a set of objects that form a basic-level category, such as dogs or trucks, and that share a significant number of attributes. It is less preferred to associate a new word to much more specific subordinate categories, such as Dalmatians or bulldozers, or to more general superordinate ones, like animals or vehicles, whose members share fewer attributes (Rosch, 1973; Rosch et al., 1976). It remains an important open question of whether a word learner requires such a bias to acquire appropriate mappings. Xu and Tenenbaum (2007) (X&amp;T henceforth) studied the word generalization problem in a set of experiments in which children and adults were asked to determine which level of a taxonomy a novel word referred to. X&amp;T further examined this behavioral data through computational modelling. They proposed a Bayesian model that, given a few exemplars of a novel word, matches human behaviour in how it maps the word to its 1795 Proceedings of the 2015 Conference on </context>
</contexts>
<marker>Rosch, 1973</marker>
<rawString>Eleanor Rosch, 1973. On the Internal Structure of Perceptual and Semantic Categories, pages 111–144. Academic Press, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger N Shepard</author>
</authors>
<title>Stimulus and response generalization: Tests of a model relating generalization to distance in psychological space.</title>
<date>1958</date>
<journal>Journal of Experimental Psychology,</journal>
<volume>55</volume>
<issue>6</issue>
<contexts>
<context position="23863" citStr="Shepard, 1958" startWordPosition="4014" endWordPosition="4015">ct the predictive probability of the test object before the model has observed any data, P0(Y |w), which gives us its increase in preference attributable to the word learning trials.4 Calculating Pt(Y |w) − P0(Y |w) is informative about one test object, but we need to measure generalization of the learned word to all the objects of a certain type of match – i.e., subordinate, basiclevel, or superordinate. We formulate the probability of generalization to a type of test match as the relative average increase in preference for test items of that type of match, using the ShepardLuce choice rule (Shepard, 1958; Luce, 1959): avgY Em [Pt(Y |w)-P0(Y |w)] Pgen(m|w) = EavgY&apos;Em&apos; [Pt(Y &apos;|w)-P0(Y &apos;|w)] m&apos; where m is the set of test objects at a certain level of match, and m&apos; ranges over subordinate matches, basic-level matches, and superordinate matches. Using Pgen(m|w) to communicate our models results has the advantage of using the learned word meanings in a very direct way to assess the preference for the various types of test matches in the X&amp;T experiments. However, the disadvantage is that this measure is not directly comparable to the reported figures from the human data, which are the percentage of </context>
</contexts>
<marker>Shepard, 1958</marker>
<rawString>Roger N. Shepard. 1958. Stimulus and response generalization: Tests of a model relating generalization to distance in psychological space. Journal of Experimental Psychology, 55(6):509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffery M Siskind</author>
</authors>
<title>A computational study of cross-situational techniques for learning word-tomeaning mappings.</title>
<date>1996</date>
<journal>Cognition,</journal>
<pages>61--39</pages>
<contexts>
<context position="1513" citStr="Siskind, 1996" startWordPosition="230" endWordPosition="231">1 Introduction Learning word meanings is a challenging early step in child language acquisition. Imagine a child hears the word dax for the first time while observing a white rabbit jumping around – dax might mean WHITE RABBIT, RABBIT, ANIMAL, CUTE, LOOK, etc. (Quine, 1960). How does the child learn the correct meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014). Although cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word learning: determining the correct level of a hierarchical taxonomy that a word refers </context>
</contexts>
<marker>Siskind, 1996</marker>
<rawString>Jeffery M. Siskind. 1996. A computational study of cross-situational techniques for learning word-tomeaning mappings. Cognition, 61:39–91.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linda B Smith</author>
<author>Chen Yu</author>
</authors>
<title>Infants rapidly learn word-referent mappings via cross-situational statistics.</title>
<date>2008</date>
<journal>Cognition,</journal>
<volume>106</volume>
<issue>3</issue>
<contexts>
<context position="1825" citStr="Smith and Yu, 2008" startWordPosition="277" endWordPosition="280">rrect meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014). Although cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word learning: determining the correct level of a hierarchical taxonomy that a word refers to. For example, children learn that the word dog refers to all kinds of dogs, and not to a specific breed, such as Dalmatians, or to a more general category, such as animals – even though some of these choices (e.g., animals) are compatible with all the cross-situational evidence available for dog (because all</context>
</contexts>
<marker>Smith, Yu, 2008</marker>
<rawString>Linda B. Smith and Chen Yu. 2008. Infants rapidly learn word-referent mappings via cross-situational statistics. Cognition, 106(3):1558–1568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Xu</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Word learning as Bayesian inference.</title>
<date>2007</date>
<journal>Psychological Review,</journal>
<volume>114</volume>
<issue>2</issue>
<contexts>
<context position="3425" citStr="Xu and Tenenbaum (2007)" startWordPosition="543" endWordPosition="546">1991; Golinkoff et al., 1994). According to this bias, children prefer to associate a word to a set of objects that form a basic-level category, such as dogs or trucks, and that share a significant number of attributes. It is less preferred to associate a new word to much more specific subordinate categories, such as Dalmatians or bulldozers, or to more general superordinate ones, like animals or vehicles, whose members share fewer attributes (Rosch, 1973; Rosch et al., 1976). It remains an important open question of whether a word learner requires such a bias to acquire appropriate mappings. Xu and Tenenbaum (2007) (X&amp;T henceforth) studied the word generalization problem in a set of experiments in which children and adults were asked to determine which level of a taxonomy a novel word referred to. X&amp;T further examined this behavioral data through computational modelling. They proposed a Bayesian model that, given a few exemplars of a novel word, matches human behaviour in how it maps the word to its 1795 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1795–1804, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. meaning</context>
<context position="36474" citStr="Xu and Tenenbaum (2007)" startWordPosition="6099" endWordPosition="6102">dren in vocabulary acquisition is learning which of many possible meanings is appropriate for a word, based largely on ambiguous situational evidence. One aspect of this is what we term the “word generalization” problem, which refers to how children associate a word such as dog with a meaning at the appropriate category level in a taxonomy of objects, such as Dalmatians, dogs, or animals. We present extensions to a cross-situational learner that enable the first computational study of word generalization that is integrated within a word learning model. The model mimics child behavior found by Xu and Tenenbaum (2007): it shows a “basic-level” bias – a preference for word meanings that refer to basic-level objects (like dogs), in contrast to higher-level (animals) or lower-level (Dalmatians) categories – and does so 7Similar results obtain using “child” parameter settings, but (as expected) the basic-level generalization is lower. (a) Containers (b) Clothing (c) Seats Figure 6: Data from our model. under parameter settings that treat all levels of category the same in the model (i.e., with no built-in basic-level bias). Other (unequal) parameter settings, which could reflect learned knowledge leading to di</context>
</contexts>
<marker>Xu, Tenenbaum, 2007</marker>
<rawString>Fei Xu and Joshua B. Tenenbaum. 2007. Word learning as Bayesian inference. Psychological Review, 114(2):245–272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Yu</author>
<author>Linda B Smith</author>
</authors>
<title>Rapid word learning under uncertainty via cross-situational statistics.</title>
<date>2007</date>
<journal>Psychological Science,</journal>
<volume>18</volume>
<issue>5</issue>
<contexts>
<context position="1805" citStr="Yu and Smith, 2007" startWordPosition="273" endWordPosition="276">e child learn the correct meaning of a word from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014). Although cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word learning: determining the correct level of a hierarchical taxonomy that a word refers to. For example, children learn that the word dog refers to all kinds of dogs, and not to a specific breed, such as Dalmatians, or to a more general category, such as animals – even though some of these choices (e.g., animals) are compatible with all the cross-situational evidence available </context>
</contexts>
<marker>Yu, Smith, 2007</marker>
<rawString>Chen Yu and Linda B. Smith. 2007. Rapid word learning under uncertainty via cross-situational statistics. Psychological Science, 18(5):414–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Yurovsky</author>
<author>Damian C Fricker</author>
<author>Chen Yu</author>
<author>Linda B Smith</author>
</authors>
<title>The role of partial knowledge in statistical word learning.</title>
<date>2014</date>
<booktitle>Psychonomic bulletin &amp; review,</booktitle>
<pages>21--1</pages>
<contexts>
<context position="1849" citStr="Yurovsky et al., 2014" startWordPosition="281" endWordPosition="284">ord from a large pool of potential meanings? A possible explanation is that children infer a word’s meaning by identifying the commonalities across the situations in which the word occurs (Pinker, 1989). One mechanism for achieving this is crosssituational learning (e.g., Siskind, 1996; Frank et al., 2007; Fazly et al., 2010; Kachergis et al., 2012). Recent word learning experiments confirm that both adults and children infer the correct word-meaning mappings by keeping track of cross-situational statistics across individually ambiguous learning trials (Yu and Smith, 2007; Smith and Yu, 2008; Yurovsky et al., 2014). Although cross-situational learning is a general mechanism for narrowing down the meaning of a word, it does not explain how children overcome an interesting challenge in word learning: determining the correct level of a hierarchical taxonomy that a word refers to. For example, children learn that the word dog refers to all kinds of dogs, and not to a specific breed, such as Dalmatians, or to a more general category, such as animals – even though some of these choices (e.g., animals) are compatible with all the cross-situational evidence available for dog (because all dogs are also animals).</context>
</contexts>
<marker>Yurovsky, Fricker, Yu, Smith, 2014</marker>
<rawString>Daniel Yurovsky, Damian C. Fricker, Chen Yu, and Linda B. Smith. 2014. The role of partial knowledge in statistical word learning. Psychonomic bulletin &amp; review, 21(1):1–22.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>