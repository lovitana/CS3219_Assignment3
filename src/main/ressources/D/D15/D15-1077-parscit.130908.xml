<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.962575">
Name List Only? Target Entity Disambiguation in Short Texts
</title>
<author confidence="0.992116">
Yixin Cao1, Juanzi Li1, Xiaofei Guo1, Shuanhu Bai2, Heng Ji3, Jie Tang1
</author>
<affiliation confidence="0.91971875">
1 Tsinghua National Laboratory for Information Science and Technology
Dept. of Computer Science and Technology, Tsinghua University, China 100084
2 Sina Corporation, China 100084
3 Dept. of Computer Science, Rensselaer Polytechnic Institute, USA 12180
</affiliation>
<email confidence="0.9814315">
{caoyixin2011,lijuanzi2008,sophiaguo.thu,jery.tang}@gmail.com
shuanhu@staff.sina.com.cn, jih@rpi.edu
</email>
<sectionHeader confidence="0.994739" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999900684210526">
Target entity disambiguation (TED), the
task of identifying target entities of the
same domain, has been recognized as a
critical step in various important applica-
tions. In this paper, we propose a graph-
based model called TremenRank to collec-
tively identify target entities in short texts
given a name list only. TremenRank prop-
agates trust within the graph, allowing for
an arbitrary number of target entities and
texts using inverted index technology. Fur-
thermore, we design a multi-layer direct-
ed graph to assign different trust levels to
short texts for better performance. The
experimental results demonstrate that our
model outperforms state-of-the-art meth-
ods with an average gain of 24.8% in accu-
racy and 15.2% in the F1-measure on three
datasets in different domains.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999976862068966">
Currently, a growing number of people prefer to
express their views and comments online. These
messages, which are updated at the rate of mil-
lions per day, become a potentially rich source of
information. From such a large number of texts,
entity disambiguation is a critical step when ex-
tracting text information from these messages, and
for various applications, such as natural language
processing and knowledge acquisition (Dredze et
al., 2010). Take the application of customer feed-
back analysis (CFA) as an example. An enterprise
is typically interested in public reviews of its own
products as well as those of its competitors’; the
identification of these entities is thus critical for
further analysis.
The product names comprise a list of entities
to be identified. We refer to these entities of the
same domain as target entities, and the identifica-
tion process is called target entity disambigua-
tion (Wang et al., 2012). All of target entities (e.g.,
car brands) share a common domain, which we re-
fer to as the target domain. The target domain is
the only constraint to target entities, which implies
that the entities are in a specific domain, rather
than being general things. In the case of entity
recognition from short texts, the disambiguation
can be performed on the document level. Given a
collection of short documents, our goal is to deter-
mine which documents contain the target entities.
</bodyText>
<subsectionHeader confidence="0.537131">
Challenge and Related Work
</subsectionHeader>
<bodyText confidence="0.999377185185185">
In contrast to traditional entity disambiguation
tasks, TED in short texts can require as little in-
formation as a name list. There are three types of
information that are utilized in Named Entity Dis-
ambiguation related tasks: knowledge resources,
the context in which a target word occurs and sta-
tistical information (Navigli, 2009). However, the
lack of the first two types of information makes
this problem more challenging.
Knowledge Sparsity A large number of meth-
ods focus on using knowledge bases (KBs) like
Wikipedia or YAGO to enrich the named enti-
ties (e.g., in-links and out-links) (Hoffart et al.,
2011; Bunescu and Pasca, 2006; Milne and Wit-
ten, 2008; Kulkarni et al., 2009; Han et al., 2011;
Mihalcea and Csomai, 2007; Shen et al., 2012).
These methods compared the context of the enti-
ties and their reference pages in the KBs through a
similarity measurement. However, we tested 32 d-
ifferent names of General Motors (GM) car brand-
s, and only four of the brands exist in Wikipedi-
a. This circumstance is not unusual. For another
larger dataset that included 2468 stock names, we
found only 340 of them had their reference pages
in Wikipedia. Thus, the methods that rely heavily
on KBs might not be appropriate here.
Shortness of the Texts The context in which a
</bodyText>
<page confidence="0.985729">
654
</page>
<note confidence="0.9850785">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 654–664,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999919710526316">
target entity occurs plays an important role in dis-
ambiguation. (Cassidy et al., 2012; Li et al., 2013)
applied the underlying topical coherence informa-
tion to a set of mentions for entity linking. In
(Wang et al., 2012), mentionRank leverages some
additional features, such as co-mention; however,
people prefer to share their comments in brief or
even informal words on social media platforms,
such as Twitter, which becomes increasingly im-
portant as an information source. We have count-
ed 350,498 microblogs, 37,379 tweets and 34,018
text snippets in various domains in Chinese and
English from Twitter, Sina Weibo and Google. Af-
ter preprocessing, their average length are 16, 5
and 11 words, respectively. To alleviate the short-
ness issue, additional information has been used
to expand the context, such as the user’s interest
(Shen et al., 2013) and related documents (Guo et
al., 2013). Such information is still sparse or un-
available in this case, and thus, the existing meth-
ods might not be suitable.
Large Scale Hundreds of millions of tweets are
posted daily on Twitter (Liu et al., 2013). When
scaling to a large document collection, the disam-
biguation task becomes increasingly important as
the ambiguity increases (Cucerzan, 2007). Men-
tionRank, the only state-of-the-art method for T-
ED, is a graph-based model that focuses on a s-
mall set of entities (e.g., 50 or 100 entities) and
conducts experiments on thousands of documents
(Wang et al., 2012). However, the graph has a
quadratic growth as the number of documents in-
creases. In our experiments, a dataset that includ-
ed 2,468 target entities and 350,498 microblogs
generated a directed graph with billions of edges,
which required more computer memory than was
available even when using a sparse matrix. There-
fore, the scalability remains a challenge.
</bodyText>
<sectionHeader confidence="0.607062" genericHeader="introduction">
Contributions
</sectionHeader>
<bodyText confidence="0.9998525">
To address these challenges, we propose a
collective method called TremenRank to disam-
biguate the target entities simultaneously. The
main idea is to propagate trust within a graph
based on our observations that true mentions are
more similar in context than false mentions in a
specific domain. Specifically, inverted indexes is
used to construct the graph locally that allows for
an arbitrary number of target entities and docu-
ments. Furthermore, a multi-layer directed graph
is designed to assign different trust levels to doc-
uments, which significantly improves the perfor-
mance. The contributions of our work can be sum-
marized as follows:
</bodyText>
<listItem confidence="0.984302357142857">
• We propose a novel graph-based method,
TremenRank, to collectively identify target
entities in short texts. This method construct-
s the graph locally to avoid storing the entire
graph in memory, which provides a linear s-
cale up with respect to the number of target
entities and documents.
• We design a multi-layer directed (MLD)
graph for modeling short texts that pos-
sess different trust levels during propaga-
tion, which significantly improves the perfor-
mance.
• We conduct a series of experiments on three
practical datasets from different domains.
</listItem>
<bodyText confidence="0.5229008">
The experimental results demonstrate that
TremenRank has a similar performance to
the state-of-the-art when addressing the TED
problem at a large scale, and the use of MLD
graph significantly improves our method.
</bodyText>
<sectionHeader confidence="0.734524" genericHeader="method">
2 Problem Definition
</sectionHeader>
<bodyText confidence="0.96381984">
Example Suppose that GM wants to collect tweets
that talk about its cars. As shown in Figure 1, we
take (i) a list of car brands (target entities), and (i-
i) a collection of tweets (i.e., short texts) as inputs.
“Car” is the target domain, and “Sonic” appears
in documents d1 and d2, which can be character-
ized as two mentions and the latter is a true men-
tion. The goal is to find as many true mentions as
possible.
Our method models the collection of documents
as a directed graph and outputs a trust score for
each document via propagation. The trust score
indicates the likelihood of a document containing
a true mention. For flexibility, the trust scores
lie within the range of 0 to 1 and are globally
comparable; thus, we can obtain the top-k doc-
uments or choose an appropriate cut-off value to
balance the precision and recall for different ap-
plication requirements. For example, in the appli-
cation of CFA, a company expects a higher recall
to achieve a comprehensive understanding of its
product, whereas a recommendation system must
provide as many precise microblogs as possible.
Formally, the problem of TED in short texts is
defined as follows:
</bodyText>
<page confidence="0.996826">
655
</page>
<figure confidence="0.983516666666667">
Mentions in short texts Input Output
r1:0.1
Target Entity
Late night thoughts express life d3
I recently added Spark and
Chevrolet Express to inventory d4
A single spark can start a
prairie fire d5
d6
</figure>
<figureCaption confidence="0.835264">
Figure 1: Illustration of TED. True mentions are
shown as solid arrows, and the underlined words
are their overlapping context.
</figureCaption>
<bodyText confidence="0.998989216216216">
Target Entity Disambiguation in Short Texts
Given a list of target entities E = {ei|i =
1, ... ,M}, and a collection of text documents
D = {dj|j = 1, ... , n}, Edi = {ej1, ... , ejk} is
the set of target entities contained in dj. The goal
is to output the trust score rj ∈ [0, 1] for each doc-
ument dj ∈ D. All the target entities in Edi share
the same trust score rj.
All of the mentions in one document have the
same score because they share a common context.
In the graph, the context similarity between doc-
uments is computed and used as the edges nor-
mally, where the width of the context window that
surround the target entity in the document is typ-
ically chosen to be 10, 20 or 50 words. Howev-
er, the documents considered here are limited in
length, and a user seldom changes the topic in so
few words; thus, we regard the entire document as
the context of its target entities. When multiple
target entities occur in one document, all of them
are more likely to refer to the entities in the target
domain. Thus, the trust score for the document is
higher, as indicated by d4 (Figure 1).
The only constraint for the target entities is that
they are in the same target domain. This constraint
is reasonable in practice. The majority of applica-
tions identify a set of entities in one domain at a
time. For example, a computer company focuses
its attentions on the brands in the computer area,
whereas an investment company is mainly inter-
ested in stocks. Additionally, even if the target
domain is general and contains several small do-
mains, an intuitive solution is to split it into sev-
eral subproblems, where each subproblem focuses
on the target entities in one small domain. Then,
the task can be achieved by solving the subprob-
lems individually.
</bodyText>
<sectionHeader confidence="0.957546" genericHeader="method">
3 Our Approach
</sectionHeader>
<bodyText confidence="0.999977769230769">
TremenRank is a graph-based method that identi-
fies target entities collectively. It propagates trust
scores on the graph where each vertex denotes one
document and an edge indicates the similarity be-
tween them. Considering the large scale of the
problem, we obtain the neighbors of one vertex
when propagating by searching two indexes in-
stead of storing the entire graph in memory. This
approach allows an arbitrary number of target en-
tities and documents to be processed. To further
improve the performance, a multi-layer directed
graph is designed to treat the documents at differ-
ent trust levels based on prior estimations.
</bodyText>
<subsectionHeader confidence="0.988945">
3.1 Hypotheses
</subsectionHeader>
<bodyText confidence="0.9979139375">
The documents within a domain share the char-
acteristic of unitary similarity. This characteristic
implies that all of the true mentions have a sim-
ilar context due to the target domain constraint
and that false mentions are distinct because their
meanings belong to diversified domains. We in-
vestigated the ambiguity of 2468 stock names (tar-
get entities in experiments), and manually labeled
301 of those names. As shown in Figure 2, there
are many different meanings for these names out-
side of the target domain, such as plant, bank, me-
dia and animal. The distribution of meanings are
long-tailed; thus, we gathered a group of meanings
together (the class “others”).
Based on the statistical results, we can make the
following hypotheses:
</bodyText>
<listItem confidence="0.995697833333333">
• The context of true mentions are similar to
one another.
• The context of a false mention is different
from any of the true mention.
• False mentions have distinct contexts across
different entities.
</listItem>
<bodyText confidence="0.999078">
For example, the true mentions in d2, d4 and d6
(Figure 1) describe car brands of GM and share
common pieces of text: “drive” or “Chevrolet”.
However, “sonic”, “express” and “spark” in d1,
d3 and d5 are all false mentions; in their contexts,
they refer to sound, giving opinions, and a small
amount of fire, respectively. These false mentions
are different in context from one another and from
any true mention.
</bodyText>
<figure confidence="0.998645642857143">
Express
Spark
Sonic
Entity
I drive Chevrolet Sonic today
Don’t drink and drive Spark
There is too much sonic
d1
d2
r4:0.9
r5:0.1
r2:0.9
r3:0.1
r6:0.8
</figure>
<page confidence="0.994988">
656
</page>
<bodyText confidence="0.979379538461539">
The assumptions resemble the main insight of
MentionRank except the co-mention (multiple en-
tities occur in one document). Co-mention sel-
dom happens in short texts, and can be treated
as the same because they share a common con-
text. In conclusion, the assumptions suggest that
a collective method could perform better than a
method that disambiguates entities separately, be-
cause more comprehensive information on the en-
tities from multiple “collaborators” (i.e., the men-
tions have similar contexts) has been used (Chen
and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti
and Pantel, 2009; Will et al., 2010; Fernandez et
</bodyText>
<figureCaption confidence="0.72769275">
al., 2010; Cucerzan, 2011; Guo et al., 2011; Han
and Sun, 2011; Ratinov et al., 2011; Kozareva et
al., 2011; Dalton and Dietz, 2013).
Figure 2: Statistics on the ambiguity in stocks.
</figureCaption>
<subsectionHeader confidence="0.996706">
3.2 Graph-based Method
</subsectionHeader>
<bodyText confidence="0.99997725">
Based on these assumptions, we build a graph to
represent the documents and their relations, and
we perform a TrustRank-like algorithm on the
graph. We are given a graph G = (V, £) that con-
sists of a set V of N documents (vertices) and a set
£ of directed edges, where each edge (di, dj) E £
denotes that di points to dj, and o(di) is the out-
neighbors of di.
</bodyText>
<subsectionHeader confidence="0.562857">
3.2.1 Similarity Measurement
</subsectionHeader>
<bodyText confidence="0.9989045">
We constructed the edges of the graph accord-
ing to the similarity relations between docu-
ments. Most similarity measurements (Artiles et
al., 2010; Miller, 1995) could be used in the pro-
posed method. After some exploration, we found
that Jaccard similarity performs better. It can be
efficiently calculated through simple set opera-
tions:
</bodyText>
<equation confidence="0.5474925">
Wdi n WdjI 1
Wdi U Wdj I ( )
</equation>
<bodyText confidence="0.999680444444444">
where ωJ ijdenotes the weight of edge (di, dj) us-
ing Jaccard similarity, and Wdi is the set of words
contained in di. ωij varies from 0 to 1, where a val-
ue closer to 1 indicates that its two nodes are more
similar. We link only similar nodes by choosing an
appropriate threshold 77. In other words, we have
(di, dj) E £, only if ωJ ij&gt; 77. This is the founda-
tion to construct the graph locally using inverted
indexes.
</bodyText>
<subsubsectionHeader confidence="0.841053">
3.2.2 Inverted Index
</subsubsectionHeader>
<bodyText confidence="0.99971">
When the scale becomes excessively large, such
as the 350,000 pieces in our dataset, the number
of edges will increase into the billions, produc-
ing computational and storage-based difficulties.
Considering that the propagation begins with doc-
ument di and that we are required to find all of
its out-neighbors o(di) through a traversal of the
entire dataset, then the complexity is O(n2). Al-
ternatively, we can represent the entire graph with
a matrix; however, its billions of elements would
be difficult to store and calculate.
To address the large scale problem, we con-
struct the graph locally via inverted index tech-
nology. During propagation, the neighbors of
the documents are obtained by searching the in-
dexes in real time. Two types of indexes are
used: the document-to-word index and the word-
to-document index. The former index records Wdi
of each document di E D; the latter index record-
s the occurrence of each word Dwk = {dj|wk E
W}, where W = {w1, ... , wN} is the word dic-
tionary. Combining these two indexes, the total
out-neighbors of a document can be obtained in
constant time as follows:
</bodyText>
<listItem confidence="0.993774545454546">
1. Obtain all of the words Wdi of di via search-
ing the document-to-word index.
2. Find the occurrences of each word wk E
Wdi in the word-to-document index: Ddi =
{dj |uwt∈Wdi Dwt}. Each document dj E
Ddi shares at least one common word with
di.
3. Count the frequency of dj, which indicates
the number of overlapping words between di
and dj. Then, the frequency fij = |Wdi n
Wdj|, i =� j and Equation 1 becomes:
</listItem>
<figure confidence="0.990471333333333">
50%
45%
40%
35%
30%
25%
20%
15%
10%
5%
0%
ωJij = J(di, dj) =
</figure>
<page confidence="0.861855">
657
</page>
<bodyText confidence="0.584565">
fij
</bodyText>
<equation confidence="0.981185">
ωJ ij = (2)
|Wdi |+ |Wdj |− fij
</equation>
<listItem confidence="0.579492">
4. Calculate the similarity weight. We obtain
</listItem>
<bodyText confidence="0.727335">
the out-neighbors o(di) = {dj|ωJ ij≥ η}.
</bodyText>
<subsubsectionHeader confidence="0.812817">
3.2.3 Trust Propagation
</subsubsectionHeader>
<bodyText confidence="0.976793294117647">
Similar to TrustRank, an individual documen-
t propagates the trust score to its neighbors and
those who have more neighbors will receive more
trust. Intuitively, trust attenuates along the edge.
There are several ways for attenuation to take
place, such as trust dampening, trust splitting, and
a combination of them (Gy¨ongyi et al., 2004). For
example, each document di ∈ D has a trust score
ri, and its out-neighbors obtain α · ri (or ri )
|o(di)|
through trust dampening (or splitting). We adopt
the third method, in which a document dampens
its split trust with the attenuation coefficient α.
The final trust score is determined by two parts:
the trust from a document’s neighbors and its pri-
or estimation. Then, TremenRank can iteratively
propagate via the following function:
</bodyText>
<equation confidence="0.999951">
�ri = α · rj
o(di) |o(dj) |+ (1 − α) · T (di) (3)
</equation>
<bodyText confidence="0.975098964285715">
where T (di) is the prior estimation of the docu-
ment di and is a constant during iterative propaga-
tion. Here we simply assign a uniform distribution
to all of the documents T (di) = 1
|D|. A more pre-
cise estimation will be discussed later.
At the beginning of the propagation, we initial-
ize the trust scores of the documents with the pri-
or estimation. Then, the trust scores of the docu-
ments are updated iteratively until convergence1.
True mentions receive high scores because they
are likely to connect with more trustworthy doc-
uments and thus receive more trust through the
first term in Equation 3. In contrast, false men-
tions are dissimilar to most other documents; thus,
their scores gradually attenuate (the second term
in Equation 3). These scores are globally compa-
rable. One can normalize the final scores by di-
viding them by the largest score, but the relative
ordering of the documents will not change. Thus,
one document that is more likely to contain any
1We select the attenuation coefficient α = 0.85 and the
number of iterations to be 20, which have been regarded as
the standards in the PageRank literature(Page et al., 1999;
Krishnan and Raj, 2006). Our experiments also show that 20
iterations are sufficient to achieve convergence.
true mention will receive a higher trust score and
be ranked higher.
</bodyText>
<subsectionHeader confidence="0.998153">
3.3 Multi-layer Directed Graph
</subsectionHeader>
<bodyText confidence="0.999980625">
During propagation, all of the documents are ini-
tialized with the same trust score and attenuate
their trust at the same level. However, different
documents should be treated differently. For ex-
ample, the tweet “I drive a big car suburban” is
more trustworthy than “doctors use GMC report
system to process harmful patients”, because the
former tweet contains the credible context feature
“car”, which is the name of the target domain. The
latter clearly irrelevant text should not be trusted or
even be regarded as noise. In this subsection, we
first discuss how to make more precise prior esti-
mation of documents based on some of the charac-
teristics of the target domain. Additionally, based
on the prior estimation, an MLD graph is built to
assign different trust levels to the documents.
</bodyText>
<subsubsectionHeader confidence="0.537033">
3.3.1 Prior Estimation
</subsubsectionHeader>
<bodyText confidence="0.9735517">
Ideally, a true mention is similar to true mentions
only. To take advantage of the approximate isola-
tion of true mentions, we first extract a set of true
mentions to start the propagation. The documents
that contain these true mentions are called seeds.
Formally, the entire set of documents D
is divided into two groups: (i) the seed set
Ds = {d1, ... , ds}, and (ii) a subset D∗ =
{ds+1, ... , dn}. We estimate a prior trust score
for each document via the function T :
</bodyText>
<equation confidence="0.9871095">
� 1 * di ∈ D∗,
T (di) =|D 1 (4)
|Ds |di ∈ Ds.
�
</equation>
<bodyText confidence="0.999912769230769">
where |Ds |and |D∗ |represent the size of the two
sets for normalization. c ∈ (0, 1] is used for s-
moothing and indicates the likelihood that we can
trust the seeds that actually contain true mentions.
In the experiments, we set c = 0.9 based on the
accuracy of the seeds extraction method.
There are several methods for extracting seed-
s, such as manual annotation and pattern-based
method. Patterns could be easily derived from the
characteristics of the target domain, such as the
domain name, product type or unique ID2. These
methods can typically identify entities with a high
accuracy, but their low recall limits the portion of
</bodyText>
<footnote confidence="0.997872">
2The exact patterns used in our datasets are detailed in
Section 4
</footnote>
<page confidence="0.992661">
658
</page>
<bodyText confidence="0.9996792">
true mentions that can be found. We use the result-
s of the pattern-based method as our seeds, which
have an accuracy higher than 90%. We do not
present the experimental results here due to space
limitations.
</bodyText>
<subsubsectionHeader confidence="0.498843">
3.3.2 Graph Construction
</subsubsectionHeader>
<bodyText confidence="0.999501133333333">
The similarity measurement does not consider di-
rections, and thus, the documents are mutually
connected. In this section, we construct a layered
structure in the graph, where each layer denotes a
document trust level that contains any true men-
tion. Thus, we define that the propagation direc-
tion from the high trust level to the low trust level.
Figure 3 shows an example of an MLD graph.
The blue nodes of the seeds in the top layer are
the most trustworthy, and the other white nodes in
the higher layer are less similar to the seeds which
implies that they are at lower trust levels. Thus, as
we move farther away from the seeds, trust atten-
uates at a constant speed α along with the layers.
The nodes in the same layer are also connected.
</bodyText>
<figureCaption confidence="0.99817">
Figure 3: Example of an MLD graph.
</figureCaption>
<bodyText confidence="0.994368230769231">
The construction algorithm3 is presented in Al-
gorithm 1, where Dl = {dl�|l &gt; 01 is the set of
nodes in layer l, and the nodes in D¯ = {¯d;|¯d; E/
Dl, l &gt; 01 are not connected. To simplify our no-
tation, the seeds are set to be in layer 0. Note that
(nl≥0Dl) n D¯ = D.
TremenRank is different from the standard
TrustRank and MentionRank in several respect-
s. First, TremenRank is designed to process short
texts at a large scale. Second, through a well-
designed MLD graph, we consider documents to
consist of different trust levels rather than be repre-
sented by a unified distribution. Third, TrustRank
</bodyText>
<footnote confidence="0.961898">
3A key parameter for the structure of MLD Graph is η,
which will be discussed in Section 4.2.
</footnote>
<table confidence="0.4080762">
Algorithm 1: Construction of an MLD graph.
Input: D3, D*,η, indexes WD, DW
Output: 9
Initialize seeds in layer l = 0, D¯ = D*;
foreach layer l &gt; 0 do
</table>
<bodyText confidence="0.926711">
Find the out-neighbors of Dl from ¯D;
foreach document dl� E Dl do
</bodyText>
<equation confidence="0.970797">
put o(dl�) in the next layer Dl+1;
update D¯ = D¯ − Dl+1;
end
if  |¯D |= 0 or |Dl+1 |= 0 then
break;
else
l = l + 1;
end
end
</equation>
<bodyText confidence="0.9999009">
randomly samples a set of seeds and checks them
manually, which limits the number of seeds avail-
able; however, the proposed method extracts the
seeds automatically and uses large amounts of
seeds to produce better prior estimations. Final-
ly, disambiguation occurs at the document level in
the proposed method; we assign the same scores
to the entities that occur in one document, because
they typically share common context features in
short texts.
</bodyText>
<sectionHeader confidence="0.993613" genericHeader="method">
4 Empirical Evaluation
</sectionHeader>
<subsectionHeader confidence="0.969365">
4.1 Data Preparation
</subsectionHeader>
<bodyText confidence="0.9571052">
Because there is no publicly available benchmark
dataset for TED, we constructed three datasets of
different domains: Stock, Car and Herb4. Al-
l of these datasets came from the needs of real-life
projects.
</bodyText>
<listItem confidence="0.67996725">
1. Stock - We collected 2,468 stock names
from a stock exchange website, and identified their
candidate mentions by string matching from Sina
Weibo (Counterpart of Twitter in China). Each s-
tock has a unique ID, which has little ambiguity.
Thus, we used this regular expression pattern to
extract seeds.
2. Car - We collected 32 car brands of General
Motors and a group of tweets that contain at least
one mention of these brands via the Twitter API. In
the seeds extraction step, we use the domain name
“car” as the patterns.
</listItem>
<footnote confidence="0.9724355">
4All of the dataset related sources used in this study are
listed at http://newsminer.org/TEDs.
</footnote>
<figure confidence="0.990881666666666">
Layer-2
. . .
d6
. . .
dZ dZ
� a
°
d, ° dZ ° d�
. . .
Seeds
d°
d2
α
d3
. . . Layer-1
d4
ds
α
</figure>
<page confidence="0.983937">
659
</page>
<listItem confidence="0.83615">
3. Herb - We randomly selected 1,119 Chinese
</listItem>
<bodyText confidence="0.969712">
herb names and collected 40 pieces of text descrip-
tions in the search results per entity from Google.
To extract the seeds, we simply added the domain
name to the key words (e.g., “UÁ(Worms) IP4
</bodyText>
<note confidence="0.773494">
9-(Chinese Medical Herb)”).
</note>
<tableCaption confidence="0.999785">
Table 1: Statistics on the datasets.
</tableCaption>
<table confidence="0.99740775">
E D #edges Positive(%)
Stock 2,468 350,498 2.049B 43
Car 32 37,379 4.91M 7
Herb 1,119 34,018 9.66M 68
</table>
<tableCaption confidence="0.743694">
Table 1 shows some of the statistics of the
</tableCaption>
<bodyText confidence="0.99936525">
datasets created. We chose these datasets because
(i) the identification of entities in these domains
meets the practical requirements of many applica-
tions, (ii) the target entities are ambiguous and (iii)
there is little information in the existing KBs. Be-
fore applying TremenRank, we preprocessed the
plain texts through word segmentation, low fre-
quency words filtering and stop words filtering.
</bodyText>
<subsectionHeader confidence="0.936343">
4.2 Experiment
</subsectionHeader>
<bodyText confidence="0.999600181818182">
Baseline Methods TED in short texts is a relative-
ly new problem, and there are few specific meth-
ods for solving it. To validate the performance of
TremenRank and the improvement produced by
the MLD graph, we selected the baseline from
three different perspectives: (i) a context-based
method that identifies target entities separately; (i-
i) a classic supervised method SVM to classify a
document by whether it contains any true mention-
s; and (iii) the only state-of-the-art MentionRank
for TED, which is a collective ranking method.
</bodyText>
<listItem confidence="0.952502461538461">
• The Context-based method mines a fre-
quent item set of true mentions and identi-
fies the documents that contain more frequent
items.
• SVM classifies the documents into two class-
es: documents that are in the target domain
and those that are not. Using context word-
s as features, we train and test SVM on the
labeled set with a 10-fold cross validation.
• MentionRank is a graph-based method that
disambiguates at the entity level. Difficult to
apply to the entire large datasets directly, it
has been applied to the labeled set.
</listItem>
<bodyText confidence="0.998991153846154">
Evaluation Metrics The performance of the dis-
ambiguation task is typically evaluated by accura-
cy, but in TEDs we are also interested in precision,
recall and the F1-measure because different appli-
cations focus on different aspects. For example, in
the application of CFA, a company expects a high-
er recall to collect as many reviews as possible,
while in financial news recommendations, users
prefer to read more accurate microblogs. Because
the entire dataset is too large to evaluate direct-
ly, we randomly sampled 800 mentions for each
dataset and labelled them manually to calculate the
performance metrics5.
</bodyText>
<sectionHeader confidence="0.585619" genericHeader="evaluation">
Results and Analysis
</sectionHeader>
<bodyText confidence="0.9992985">
The overall performances of TremenRank and
those of the baseline methods on all of the datasets
are shown in Table 2. The following is indicated
in the results:
</bodyText>
<listItem confidence="0.991930470588235">
• TremenRank+MLD outperforms all of the
baselines with all of the datasets, because it
collectively identifies target entities and treats
the documents differently based on a precise
prior estimation.
• The collective methods tend to perform bet-
ter. Although, on the Car dataset, SVM
achieves the second best performance, the
use of MLD graph in TremenRank outper-
forms all of the methods tested. This is
because false mentions that occupy a large
proportion of the dataset produce too much
noise, whose negative impacts can be reduced
through the train set in the supervised method
or a precise prior estimations.
• Compared with MentionRank, TremenRank
processes a larger number of entities and
</listItem>
<bodyText confidence="0.986689636363636">
documents while achieving a similar per-
formance. Combined with a MLD graph,
TremenRank shows significant improve-
ments including an average gain of 24.8% in
accuracy and 15.2% in the F1-measure on the
three datasets.
We also investigate the influence of the main el-
ements in TremenRank below.
Similarity Threshold Different similarity thresh-
olds result in various structures of the MLD graph,
and have a great impact on the performance of our
</bodyText>
<footnote confidence="0.997938">
5A detailed explanation about these metrics can be found
in http://en.wikipedia.org/wiki/Precision and Recall.
</footnote>
<page confidence="0.996427">
660
</page>
<tableCaption confidence="0.990535">
Table 2: Overall results on the three datasets
</tableCaption>
<table confidence="0.951398111111111">
Method Accu Stock F-score Accu Prec Car F-score Accu Herb F-score
Prec Recall Recall Prec Recall
Context 0.704 0.332 0.545 0.410 0.733 0.333 0.256 0.476 0.670 0.200 0.074 0.108
SVM 0.746 0.377 0.998 0.547 0.839 0.371 0.923 0.529 0.567 0.988 0.564 0.718
MentionRank 0.458 0.424 0.828 0.561 0.464 0.301 0.715 0.423 0.644 0.691 0.824 0.752
TremenRank 0.477 0.424 0.803 0.555 0.542 0.310 0.720 0.433 0.737 0.736 0.827 0.779
TremenRank+MLD 0.683 0.575 0.844 0.684 0.827 0.624 0.731 0.673 0.800 0.774 0.908 0.836
Accuracy Precision Recall F1-measure
0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40
</table>
<figure confidence="0.99786624137931">
0.80
0.70
0.60
0.50
0.40
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Car(%)
1.0
0.90
0.9
0.8
%
0.7
0.6
0.5
0.4
0.3
Accuracy Precision Recall F1-measure
Coverage(%)
0.9
0.8
0.7
0.6
0.5
1.0
coverage
layer
0.05 0.1 0.15 0.2 0.25 0.3 0.35 0.4
η
</figure>
<figureCaption confidence="0.999554">
Figure 4: Selection of the Similarity Threshold
</figureCaption>
<figure confidence="0.994255333333333">
0.70
0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
seeds scale(%)
</figure>
<figureCaption confidence="0.997129">
Figure 5: Influence of Seed Scale
</figureCaption>
<figure confidence="0.999038454545454">
6 #Layers Herb(%)
5
4
3
2
1
0
0.90
0.85
0.80
0.75
</figure>
<bodyText confidence="0.999065730769231">
method. In this subsection, we study a heuristical
method that help choose the best eta according t-
wo factors (Both of them can be obtained before
propagation). Figure 4 presents the experimental
results for different values of q on the dataset of
Herb. The performance of TremenRank is showed
on the top, and the bottom is the corresponding
graph structure represented by two factors: the
graph coverage and the number of layers. We
can see that precision increases until it becomes
steady with the growth of q, and other measure-
ments reach their peaks when q = 0.1.
This is in accordance with the change of the
graph structure. On one hand, the number of lay-
ers l declines sharply when q is less than 0.1, this
indicates little difference in the trust level of doc-
uments in the propagation. On the other hand, our
method has no effect on the vertices outside of the
graph, so the performance is directly proportional
to the graph coverage rate. Therefore, a proper q
should ensure a high coverage as well as adequate
layers. In experiments, we choose q as 0.1, 0.15,
0.1 for the datasets of Stock, Car and Herb respec-
tively.
Influence of the Seed Scale As the basis of the
prior estimation, the seeds have significant influ-
ence on the performance of the proposed method
via the MLD graph. Intuitively, a larger set of
seeds should lead to a more precise estimation and
thus better performance. In the experiments on the
Car and Herb datasets, we split their seed set into
ten parts, and add one part each time. As Fig-
ure 5 shows, when increasing the percentage of
the seeds gradually, the performance has an over-
all upward trend (e.g., a 14.6% and 4.4% gain in
the F1-measure for the Car and Herb datasets, re-
spectively). This trend occurs because the poten-
tial context features of the seeds utilized for prop-
agation increase as the absolute number of seed
documents rises. For example, the tweet “Cadil-
lac Uber airport is classy” obtains a low score of
0.013 with 50% of the seeds, whereas it is identi-
fied successfully with the score of 0.588 when all
of the seeds are used for propagation because more
context features are introduced, such as “airport”
and “Uber”. Thus, the proposed method achieves
better performance as the seed set grows. This ar-
rangement is helpful for a company that seldom
changes its business area and then accumulates
seeds continuously to improve performance.
Robustness to Noise Because seeds play an im-
portant role in the MLD graph, we further test the
</bodyText>
<page confidence="0.970078">
661
</page>
<figure confidence="0.99921072">
1.0
0.9
0.8
0.7
0.6
0.5
0.4
High Precision
Max F1
.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9 1.0
Cut-off Value(%)
1.0
Stock Car Herb
Accuracy Precision Recall F1 noise
Herb(%)
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.10
Accuracy Precision Recall F1-measure
</figure>
<figureCaption confidence="0.999948">
Figure 6: Robustness to Noise Figure 7: Cut-off Value
</figureCaption>
<bodyText confidence="0.999969926829268">
robustness of our method with respect to the qual-
ity of the seeds. We randomly sample documents
outside of the seed set (considered as noise) to re-
place 20% of the seeds on all the datasets; these re-
sults are shown in Figure 6. The introduced noise
only leads to a limited decrease in performance
(average 1.3%, 1% and 1% in the F1), which is
much better than when only using TremenRank
(Table 2). More specifically, the experiments that
use artificial noise occasionally achieve a high-
er recall (e.g., on the Stock dataset); this result
could occur because the unknown true mentions
add some useful edges to the graph, which is help-
ful when finding more true mentions of the target
entities.
Cut-off Value According to the globally compa-
rable trust scores, we can (i) rank all of the doc-
uments, and trade off the performance metrics by
choosing an appropriate cut-off value -y for various
applications, or (ii) rank the documents of an indi-
vidual entity separately and obtain its top-k men-
tions.
In the experiments, we set -y as different per-
centage of the ranked documents. As Figure 7
shows, the recommendation system could use -y =
30% to achieve a 93.2% precision and a 64.2% re-
call, or a company could use -y = 60% for more
reviews that have a relatively high precision.
Efficiency We implemented TremenRank in Java
and ran it on a single PC with the Windows 8.1 64-
bit operation system. With an Intel(R) Core(TM)
i3-3240 (3.40GHz) CPU and 4GB memory, our
program converges within 5 iterations, and on-
ly consumes approximately 700MB of memory
when running steadily. The overall identification
times of the Stock, Car and Herb datasets are 12h,
5min and 18min, respectively. The computation
time increases exponentially with the increase of
the amount of data due to the excessive computa-
tions required to search the indexes, which can be
optimized in future work.
</bodyText>
<sectionHeader confidence="0.99759" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.98094">
In this paper, we addressed a new and increasing-
ly important problem in social content analysis in
a challenging scenario: disambiguation of a list
of homogenous entities in short texts using names
only. We proposed a graph-based method called
TremenRank to identify target entities collective-
ly; this method can also hold an arbitrary number
of target entities and documents. The performance
of this method can be further improved via a well-
designed MLD graph. The experimental results
show that the proposed method has a significant
improvement compared to other approaches.
In the future, we are interested in refining the
prior estimation by using the ontology and extend-
ing this work to detect the target entities that are
not in a list while performing the disambiguation
task.
Acknowledgments We’d like to acknowledge Lei
Hou, Chi Wang and Hongzhao Huang for their im-
pressive discussions on this paper. The work is
supported by 973 Program (No. 2014CB340504),
NSFC-ANR (No. 61261130588), Tsinghua Uni-
versity Initiative Scientific Research Program (No.
20131089256), Science and Technology Support
Program (No. 2014BAK04B00), and THU-NUS
NExT Co-Lab.
</bodyText>
<page confidence="0.996034">
662
</page>
<sectionHeader confidence="0.983147" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999812813084113">
Javier Artiles, Andrew Borthwick, Julio Gonzalo,
Satoshi Sekine, and Enrique Amig´o. 2010. Weps-3
evaluation campaign: Overview of the web people
search clustering and attribute extraction tasks. In
CLEF (Notebook Papers/LABs/Workshops).
Razvan C Bunescu and Marius Pasca. 2006. Using en-
cyclopedic knowledge for named entity disambigua-
tion. In EACL, volume 6, pages 9–16.
Taylor Cassidy, Heng Ji, Lev-Arie Ratinov, Arkaitz Zu-
biaga, and Hongzhao Huang. 2012. Analysis and
enhancement of wikification for microblogs with
context expansion. In COLING, volume 12, pages
441–456. Citeseer.
Zheng Chen and Heng Ji. 2011. Collaborative rank-
ing: A case study on entity linking. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 771–781. Association
for Computational Linguistics.
Silviu Cucerzan. 2007. Large-scale named entity dis-
ambiguation based on wikipedia data. In EMNLP-
CoNLL, pages 708–716.
Silviu Cucerzan. 2011. Tac entity linking by perform-
ing full-document entity extraction and disambigua-
tion. In Proceedings of the Text Analysis Confer-
ence, volume 2011.
Jeffrey Dalton and Laura Dietz. 2013. A neighbor-
hood relevance model for entity linking. In Proceed-
ings of the 10th Conference on Open Research Areas
in Information Retrieval, pages 149–156. LE CEN-
TRE DE HAUTES ETUDES INTERNATIONALES
D’INFORMATIQUE DOCUMENTAIRE.
Mark Dredze, Paul McNamee, Delip Rao, Adam Ger-
ber, and Tim Finin. 2010. Entity disambiguation
for knowledge base population. In Proceedings of
the 23rd International Conference on Computation-
al Linguistics, pages 277–285. Association for Com-
putational Linguistics.
Norberto Fernandez, Jesus A Fisteus, Luis Sanchez,
and Eduardo Martin. 2010. Webtlab: A cooc-
curencebased approach to kbp 2010 entity-linking
task. In Proc. TAC 2010 Workshop.
Yuhang Guo, Wanxiang Che, Ting Liu, and Sheng Li.
2011. A graph-based method for entity linking. In
IJCNLP, pages 1010–1018. Citeseer.
Weiwei Guo, Hao Li, Heng Ji, and Mona T Diab. 2013.
Linking tweets to news: A framework to enrich short
text data in social media. In ACL (1), pages 239–
249. Citeseer.
Zolt´an Gy¨ongyi, Hector Garcia-Molina, and Jan Ped-
ersen. 2004. Combating web spam with trustrank.
In Proceedings of the Thirtieth international con-
ference on Very large data bases-Volume 30, pages
576–587.
Xianpei Han and Le Sun. 2011. A generative entity-
mention model for linking entities with knowledge
base. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies-Volume 1, pages 945–
954. Association for Computational Linguistics.
Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective
entity linking in web text: a graph-based method. In
Proceedings of the 34th international ACM SIGIR
conference on Research and development in Infor-
mation Retrieval, pages 765–774. ACM.
Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bor-
dino, Hagen F¨urstenau, Manfred Pinkal, Marc S-
paniol, Bilyana Taneva, Stefan Thater, and Gerhard
Weikum. 2011. Robust disambiguation of named
entities in text. In Proceedings of the Conference on
Empirical Methods in Natural Language Process-
ing, pages 782–792. Association for Computational
Linguistics.
Zornitsa Kozareva, Konstantin Voevodski, and Shang-
Hua Teng. 2011. Class label enhancement via re-
lated instances. In Proceedings of the conference on
empirical methods in natural language processing,
pages 118–128. Association for Computational Lin-
guistics.
Vijay Krishnan and Rashmi Raj. 2006. Web spam de-
tection with anti-trust rank. In AIRWeb, volume 6,
pages 37–40.
Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan,
and Soumen Chakrabarti. 2009. Collective annota-
tion of wikipedia entities in web text. In Proceed-
ings of the 15th ACM SIGKDD international con-
ference on Knowledge discovery and data mining,
pages 457–466. ACM.
Yang Li, Chi Wang, Fangqiu Han, Jiawei Han, Dan
Roth, and Xifeng Yan. 2013. Mining evidences
for named entity disambiguation. In KDD’13, pages
1070–1078.
Xiaohua Liu, Yitong Li, Haocheng Wu, Ming Zhou,
Furu Wei, and Yi Lu. 2013. Entity linking for tweet-
s. In ACL (1), pages 1304–1311.
Rada Mihalcea and Andras Csomai. 2007. Wiki-
fy!: linking documents to encyclopedic knowledge.
In Proceedings of the sixteenth ACM conference on
Conference on information and knowledge manage-
ment, pages 233–242. ACM.
George A. Miller. 1995. Wordnet: A lexical database
for english. Commun. ACM, 38(11):39–41.
David Milne and Ian H Witten. 2008. Learning to link
with wikipedia. In Proceedings of the 17th ACM
conference on Information and knowledge manage-
ment, pages 509–518. ACM.
Roberto Navigli. 2009. Word sense disambiguation: A
survey. ACM Computing Surveys (CSUR), 41(2):10.
</reference>
<page confidence="0.985823">
663
</page>
<reference confidence="0.999787911764706">
Lawrence Page, Sergey Brin, Rajeev Motwani, and
Terry Winograd. 1999. The pagerank citation rank-
ing: Bringing order to the web.
Marco Pennacchiotti and Patrick Pantel. 2009. Entity
extraction via ensemble semantics. In Proceedings
of the 2009 Conference on Empirical Methods in
Natural Language Processing: Volume 1-Volume 1,
pages 238–247. Association for Computational Lin-
guistics.
Lev Ratinov, Dan Roth, Doug Downey, and Mike
Anderson. 2011. Local and global algorithm-
s for disambiguation to wikipedia. In Proceed-
ings of the 49th Annual Meeting of the Association
for Computational Linguistics: Human Language
Technologies-Volume 1, pages 1375–1384. Associ-
ation for Computational Linguistics.
Wei Shen, Jianyong Wang, Ping Luo, and Min Wang.
2012. Linden: linking named entities with knowl-
edge base via semantic knowledge. In Proceedings
of the 21st international conference on World Wide
Web, pages 449–458. ACM.
Wei Shen, Jianyong Wang, Ping Luo, and Min Wang.
2013. Linking named entities in tweets with knowl-
edge base via user interest modeling. In KDD, pages
68–76.
Chi Wang, Kaushik Chakrabarti, Tao Cheng, and Sura-
jit Chaudhuri. 2012. Targeted disambiguation of ad-
hoc, homogeneous sets of named entities. In WWW,
pages 719–728.
Radford Will, Hachey Ben, Nothman Joel, Honnibal
Matthew, and R.Curran James. 2010. Cmcrc at
tac10: Document-level entity linking with graph-
based re-ranking. In In Proc. Text Analysis Confer-
ence (TAC 2010).
</reference>
<page confidence="0.998114">
664
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.636535">
<title confidence="0.999462">Name List Only? Target Entity Disambiguation in Short Texts</title>
<author confidence="0.992401">Juanzi Xiaofei Shuanhu Heng Jie</author>
<affiliation confidence="0.999706">National Laboratory for Information Science and Dept. of Computer Science and Technology, Tsinghua University, China</affiliation>
<address confidence="0.8064375">Corporation, China of Computer Science, Rensselaer Polytechnic Institute, USA</address>
<email confidence="0.999904">shuanhu@staff.sina.com.cn,jih@rpi.edu</email>
<abstract confidence="0.99924295">Target entity disambiguation (TED), the task of identifying target entities of the same domain, has been recognized as a critical step in various important applications. In this paper, we propose a graphbased model called TremenRank to collectively identify target entities in short texts given a name list only. TremenRank propagates trust within the graph, allowing for an arbitrary number of target entities and texts using inverted index technology. Furthermore, we design a multi-layer directed graph to assign different trust levels to short texts for better performance. The experimental results demonstrate that our model outperforms state-of-the-art methods with an average gain of 24.8% in accuracy and 15.2% in the F1-measure on three datasets in different domains.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Javier Artiles</author>
<author>Andrew Borthwick</author>
<author>Julio Gonzalo</author>
<author>Satoshi Sekine</author>
<author>Enrique Amig´o</author>
</authors>
<title>Weps-3 evaluation campaign: Overview of the web people search clustering and attribute extraction tasks.</title>
<date>2010</date>
<booktitle>In CLEF (Notebook Papers/LABs/Workshops).</booktitle>
<marker>Artiles, Borthwick, Gonzalo, Sekine, Amig´o, 2010</marker>
<rawString>Javier Artiles, Andrew Borthwick, Julio Gonzalo, Satoshi Sekine, and Enrique Amig´o. 2010. Weps-3 evaluation campaign: Overview of the web people search clustering and attribute extraction tasks. In CLEF (Notebook Papers/LABs/Workshops).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan C Bunescu</author>
<author>Marius Pasca</author>
</authors>
<title>Using encyclopedic knowledge for named entity disambiguation.</title>
<date>2006</date>
<booktitle>In EACL,</booktitle>
<volume>6</volume>
<pages>9--16</pages>
<contexts>
<context position="3362" citStr="Bunescu and Pasca, 2006" startWordPosition="520" endWordPosition="523">traditional entity disambiguation tasks, TED in short texts can require as little information as a name list. There are three types of information that are utilized in Named Entity Disambiguation related tasks: knowledge resources, the context in which a target word occurs and statistical information (Navigli, 2009). However, the lack of the first two types of information makes this problem more challenging. Knowledge Sparsity A large number of methods focus on using knowledge bases (KBs) like Wikipedia or YAGO to enrich the named entities (e.g., in-links and out-links) (Hoffart et al., 2011; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Han et al., 2011; Mihalcea and Csomai, 2007; Shen et al., 2012). These methods compared the context of the entities and their reference pages in the KBs through a similarity measurement. However, we tested 32 different names of General Motors (GM) car brands, and only four of the brands exist in Wikipedia. This circumstance is not unusual. For another larger dataset that included 2468 stock names, we found only 340 of them had their reference pages in Wikipedia. Thus, the methods that rely heavily on KBs might not be appropriate here. Shortness </context>
</contexts>
<marker>Bunescu, Pasca, 2006</marker>
<rawString>Razvan C Bunescu and Marius Pasca. 2006. Using encyclopedic knowledge for named entity disambiguation. In EACL, volume 6, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taylor Cassidy</author>
<author>Heng Ji</author>
<author>Lev-Arie Ratinov</author>
<author>Arkaitz Zubiaga</author>
<author>Hongzhao Huang</author>
</authors>
<title>Analysis and enhancement of wikification for microblogs with context expansion.</title>
<date>2012</date>
<booktitle>In COLING,</booktitle>
<volume>12</volume>
<pages>441--456</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="4280" citStr="Cassidy et al., 2012" startWordPosition="672" endWordPosition="675">ar brands, and only four of the brands exist in Wikipedia. This circumstance is not unusual. For another larger dataset that included 2468 stock names, we found only 340 of them had their reference pages in Wikipedia. Thus, the methods that rely heavily on KBs might not be appropriate here. Shortness of the Texts The context in which a 654 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 654–664, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. target entity occurs plays an important role in disambiguation. (Cassidy et al., 2012; Li et al., 2013) applied the underlying topical coherence information to a set of mentions for entity linking. In (Wang et al., 2012), mentionRank leverages some additional features, such as co-mention; however, people prefer to share their comments in brief or even informal words on social media platforms, such as Twitter, which becomes increasingly important as an information source. We have counted 350,498 microblogs, 37,379 tweets and 34,018 text snippets in various domains in Chinese and English from Twitter, Sina Weibo and Google. After preprocessing, their average length are 16, 5 and</context>
</contexts>
<marker>Cassidy, Ji, Ratinov, Zubiaga, Huang, 2012</marker>
<rawString>Taylor Cassidy, Heng Ji, Lev-Arie Ratinov, Arkaitz Zubiaga, and Hongzhao Huang. 2012. Analysis and enhancement of wikification for microblogs with context expansion. In COLING, volume 12, pages 441–456. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Heng Ji</author>
</authors>
<title>Collaborative ranking: A case study on entity linking.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>771--781</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="13394" citStr="Chen and Ji, 2011" startWordPosition="2206" endWordPosition="2209"> and drive Spark There is too much sonic d1 d2 r4:0.9 r5:0.1 r2:0.9 r3:0.1 r6:0.8 656 The assumptions resemble the main insight of MentionRank except the co-mention (multiple entities occur in one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that </context>
</contexts>
<marker>Chen, Ji, 2011</marker>
<rawString>Zheng Chen and Heng Ji. 2011. Collaborative ranking: A case study on entity linking. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 771–781. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-scale named entity disambiguation based on wikipedia data. In EMNLPCoNLL,</title>
<date>2007</date>
<pages>708--716</pages>
<contexts>
<context position="5439" citStr="Cucerzan, 2007" startWordPosition="861" endWordPosition="862"> After preprocessing, their average length are 16, 5 and 11 words, respectively. To alleviate the shortness issue, additional information has been used to expand the context, such as the user’s interest (Shen et al., 2013) and related documents (Guo et al., 2013). Such information is still sparse or unavailable in this case, and thus, the existing methods might not be suitable. Large Scale Hundreds of millions of tweets are posted daily on Twitter (Liu et al., 2013). When scaling to a large document collection, the disambiguation task becomes increasingly important as the ambiguity increases (Cucerzan, 2007). MentionRank, the only state-of-the-art method for TED, is a graph-based model that focuses on a small set of entities (e.g., 50 or 100 entities) and conducts experiments on thousands of documents (Wang et al., 2012). However, the graph has a quadratic growth as the number of documents increases. In our experiments, a dataset that included 2,468 target entities and 350,498 microblogs generated a directed graph with billions of edges, which required more computer memory than was available even when using a sparse matrix. Therefore, the scalability remains a challenge. Contributions To address </context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. 2007. Large-scale named entity disambiguation based on wikipedia data. In EMNLPCoNLL, pages 708–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Tac entity linking by performing full-document entity extraction and disambiguation.</title>
<date>2011</date>
<booktitle>In Proceedings of the Text Analysis Conference,</booktitle>
<volume>volume</volume>
<contexts>
<context position="13508" citStr="Cucerzan, 2011" startWordPosition="2226" endWordPosition="2227">in insight of MentionRank except the co-mention (multiple entities occur in one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3.2.1 Similarity Measurement We constructed the edges of the</context>
</contexts>
<marker>Cucerzan, 2011</marker>
<rawString>Silviu Cucerzan. 2011. Tac entity linking by performing full-document entity extraction and disambiguation. In Proceedings of the Text Analysis Conference, volume 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Dalton</author>
<author>Laura Dietz</author>
</authors>
<title>A neighborhood relevance model for entity linking.</title>
<date>2013</date>
<booktitle>In Proceedings of the 10th Conference on Open Research Areas in Information Retrieval,</booktitle>
<pages>149--156</pages>
<contexts>
<context position="13615" citStr="Dalton and Dietz, 2013" startWordPosition="2244" endWordPosition="2247">ion seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3.2.1 Similarity Measurement We constructed the edges of the graph according to the similarity relations between documents. Most similarity measurements (Artiles et al</context>
</contexts>
<marker>Dalton, Dietz, 2013</marker>
<rawString>Jeffrey Dalton and Laura Dietz. 2013. A neighborhood relevance model for entity linking. In Proceedings of the 10th Conference on Open Research Areas in Information Retrieval, pages 149–156. LE CENTRE DE HAUTES ETUDES INTERNATIONALES D’INFORMATIQUE DOCUMENTAIRE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Dredze</author>
<author>Paul McNamee</author>
<author>Delip Rao</author>
<author>Adam Gerber</author>
<author>Tim Finin</author>
</authors>
<title>Entity disambiguation for knowledge base population.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>277--285</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1734" citStr="Dredze et al., 2010" startWordPosition="251" endWordPosition="254">our model outperforms state-of-the-art methods with an average gain of 24.8% in accuracy and 15.2% in the F1-measure on three datasets in different domains. 1 Introduction Currently, a growing number of people prefer to express their views and comments online. These messages, which are updated at the rate of millions per day, become a potentially rich source of information. From such a large number of texts, entity disambiguation is a critical step when extracting text information from these messages, and for various applications, such as natural language processing and knowledge acquisition (Dredze et al., 2010). Take the application of customer feedback analysis (CFA) as an example. An enterprise is typically interested in public reviews of its own products as well as those of its competitors’; the identification of these entities is thus critical for further analysis. The product names comprise a list of entities to be identified. We refer to these entities of the same domain as target entities, and the identification process is called target entity disambiguation (Wang et al., 2012). All of target entities (e.g., car brands) share a common domain, which we refer to as the target domain. The target</context>
</contexts>
<marker>Dredze, McNamee, Rao, Gerber, Finin, 2010</marker>
<rawString>Mark Dredze, Paul McNamee, Delip Rao, Adam Gerber, and Tim Finin. 2010. Entity disambiguation for knowledge base population. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 277–285. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norberto Fernandez</author>
<author>Jesus A Fisteus</author>
<author>Luis Sanchez</author>
<author>Eduardo Martin</author>
</authors>
<title>Webtlab: A cooccurencebased approach to kbp 2010 entity-linking task.</title>
<date>2010</date>
<booktitle>In Proc. TAC 2010 Workshop.</booktitle>
<contexts>
<context position="13492" citStr="Fernandez et al., 2010" startWordPosition="2222" endWordPosition="2225">umptions resemble the main insight of MentionRank except the co-mention (multiple entities occur in one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3.2.1 Similarity Measurement We constructed </context>
</contexts>
<marker>Fernandez, Fisteus, Sanchez, Martin, 2010</marker>
<rawString>Norberto Fernandez, Jesus A Fisteus, Luis Sanchez, and Eduardo Martin. 2010. Webtlab: A cooccurencebased approach to kbp 2010 entity-linking task. In Proc. TAC 2010 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuhang Guo</author>
<author>Wanxiang Che</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>A graph-based method for entity linking. In</title>
<date>2011</date>
<booktitle>IJCNLP,</booktitle>
<pages>1010--1018</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="13526" citStr="Guo et al., 2011" startWordPosition="2228" endWordPosition="2231">ntionRank except the co-mention (multiple entities occur in one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3.2.1 Similarity Measurement We constructed the edges of the graph according t</context>
</contexts>
<marker>Guo, Che, Liu, Li, 2011</marker>
<rawString>Yuhang Guo, Wanxiang Che, Ting Liu, and Sheng Li. 2011. A graph-based method for entity linking. In IJCNLP, pages 1010–1018. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weiwei Guo</author>
<author>Hao Li</author>
<author>Heng Ji</author>
<author>Mona T Diab</author>
</authors>
<title>Linking tweets to news: A framework to enrich short text data in social media.</title>
<date>2013</date>
<booktitle>In ACL (1),</booktitle>
<pages>239--249</pages>
<publisher>Citeseer.</publisher>
<contexts>
<context position="5087" citStr="Guo et al., 2013" startWordPosition="802" endWordPosition="805">as co-mention; however, people prefer to share their comments in brief or even informal words on social media platforms, such as Twitter, which becomes increasingly important as an information source. We have counted 350,498 microblogs, 37,379 tweets and 34,018 text snippets in various domains in Chinese and English from Twitter, Sina Weibo and Google. After preprocessing, their average length are 16, 5 and 11 words, respectively. To alleviate the shortness issue, additional information has been used to expand the context, such as the user’s interest (Shen et al., 2013) and related documents (Guo et al., 2013). Such information is still sparse or unavailable in this case, and thus, the existing methods might not be suitable. Large Scale Hundreds of millions of tweets are posted daily on Twitter (Liu et al., 2013). When scaling to a large document collection, the disambiguation task becomes increasingly important as the ambiguity increases (Cucerzan, 2007). MentionRank, the only state-of-the-art method for TED, is a graph-based model that focuses on a small set of entities (e.g., 50 or 100 entities) and conducts experiments on thousands of documents (Wang et al., 2012). However, the graph has a quad</context>
</contexts>
<marker>Guo, Li, Ji, Diab, 2013</marker>
<rawString>Weiwei Guo, Hao Li, Heng Ji, and Mona T Diab. 2013. Linking tweets to news: A framework to enrich short text data in social media. In ACL (1), pages 239– 249. Citeseer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zolt´an Gy¨ongyi</author>
<author>Hector Garcia-Molina</author>
<author>Jan Pedersen</author>
</authors>
<title>Combating web spam with trustrank.</title>
<date>2004</date>
<booktitle>In Proceedings of the Thirtieth international conference on Very large data bases-Volume 30,</booktitle>
<pages>576--587</pages>
<marker>Gy¨ongyi, Garcia-Molina, Pedersen, 2004</marker>
<rawString>Zolt´an Gy¨ongyi, Hector Garcia-Molina, and Jan Pedersen. 2004. Combating web spam with trustrank. In Proceedings of the Thirtieth international conference on Very large data bases-Volume 30, pages 576–587.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
</authors>
<title>A generative entitymention model for linking entities with knowledge base.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>945--954</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Han, Le Sun, 2011</marker>
<rawString>Xianpei Han and Le Sun. 2011. A generative entitymention model for linking entities with knowledge base. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 945– 954. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xianpei Han</author>
<author>Le Sun</author>
<author>Jun Zhao</author>
</authors>
<title>Collective entity linking in web text: a graph-based method.</title>
<date>2011</date>
<booktitle>In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval,</booktitle>
<pages>765--774</pages>
<publisher>ACM.</publisher>
<marker>Han, Le Sun, Zhao, 2011</marker>
<rawString>Xianpei Han, Le Sun, and Jun Zhao. 2011. Collective entity linking in web text: a graph-based method. In Proceedings of the 34th international ACM SIGIR conference on Research and development in Information Retrieval, pages 765–774. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed Amir Yosef</author>
<author>Ilaria Bordino</author>
<author>Hagen F¨urstenau</author>
<author>Manfred Pinkal</author>
<author>Marc Spaniol</author>
<author>Bilyana Taneva</author>
<author>Stefan Thater</author>
<author>Gerhard Weikum</author>
</authors>
<title>Robust disambiguation of named entities in text.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>782--792</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>Johannes Hoffart, Mohamed Amir Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. 2011. Robust disambiguation of named entities in text. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 782–792. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Konstantin Voevodski</author>
<author>ShangHua Teng</author>
</authors>
<title>Class label enhancement via related instances.</title>
<date>2011</date>
<booktitle>In Proceedings of the conference on empirical methods in natural language processing,</booktitle>
<pages>118--128</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="13590" citStr="Kozareva et al., 2011" startWordPosition="2240" endWordPosition="2243"> one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3.2.1 Similarity Measurement We constructed the edges of the graph according to the similarity relations between documents. Most similarity me</context>
</contexts>
<marker>Kozareva, Voevodski, Teng, 2011</marker>
<rawString>Zornitsa Kozareva, Konstantin Voevodski, and ShangHua Teng. 2011. Class label enhancement via related instances. In Proceedings of the conference on empirical methods in natural language processing, pages 118–128. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vijay Krishnan</author>
<author>Rashmi Raj</author>
</authors>
<title>Web spam detection with anti-trust rank.</title>
<date>2006</date>
<booktitle>In AIRWeb,</booktitle>
<volume>6</volume>
<pages>37--40</pages>
<contexts>
<context position="18611" citStr="Krishnan and Raj, 2006" startWordPosition="3137" endWordPosition="3140">s receive more trust through the first term in Equation 3. In contrast, false mentions are dissimilar to most other documents; thus, their scores gradually attenuate (the second term in Equation 3). These scores are globally comparable. One can normalize the final scores by dividing them by the largest score, but the relative ordering of the documents will not change. Thus, one document that is more likely to contain any 1We select the attenuation coefficient α = 0.85 and the number of iterations to be 20, which have been regarded as the standards in the PageRank literature(Page et al., 1999; Krishnan and Raj, 2006). Our experiments also show that 20 iterations are sufficient to achieve convergence. true mention will receive a higher trust score and be ranked higher. 3.3 Multi-layer Directed Graph During propagation, all of the documents are initialized with the same trust score and attenuate their trust at the same level. However, different documents should be treated differently. For example, the tweet “I drive a big car suburban” is more trustworthy than “doctors use GMC report system to process harmful patients”, because the former tweet contains the credible context feature “car”, which is the name </context>
</contexts>
<marker>Krishnan, Raj, 2006</marker>
<rawString>Vijay Krishnan and Rashmi Raj. 2006. Web spam detection with anti-trust rank. In AIRWeb, volume 6, pages 37–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sayali Kulkarni</author>
<author>Amit Singh</author>
<author>Ganesh Ramakrishnan</author>
<author>Soumen Chakrabarti</author>
</authors>
<title>Collective annotation of wikipedia entities in web text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>457--466</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3409" citStr="Kulkarni et al., 2009" startWordPosition="529" endWordPosition="532">hort texts can require as little information as a name list. There are three types of information that are utilized in Named Entity Disambiguation related tasks: knowledge resources, the context in which a target word occurs and statistical information (Navigli, 2009). However, the lack of the first two types of information makes this problem more challenging. Knowledge Sparsity A large number of methods focus on using knowledge bases (KBs) like Wikipedia or YAGO to enrich the named entities (e.g., in-links and out-links) (Hoffart et al., 2011; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Han et al., 2011; Mihalcea and Csomai, 2007; Shen et al., 2012). These methods compared the context of the entities and their reference pages in the KBs through a similarity measurement. However, we tested 32 different names of General Motors (GM) car brands, and only four of the brands exist in Wikipedia. This circumstance is not unusual. For another larger dataset that included 2468 stock names, we found only 340 of them had their reference pages in Wikipedia. Thus, the methods that rely heavily on KBs might not be appropriate here. Shortness of the Texts The context in which a 654 Proceed</context>
<context position="13417" citStr="Kulkarni et al., 2009" startWordPosition="2210" endWordPosition="2213">ere is too much sonic d1 d2 r4:0.9 r5:0.1 r2:0.9 r3:0.1 r6:0.8 656 The assumptions resemble the main insight of MentionRank except the co-mention (multiple entities occur in one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(</context>
</contexts>
<marker>Kulkarni, Singh, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and Soumen Chakrabarti. 2009. Collective annotation of wikipedia entities in web text. In Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 457–466. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Li</author>
<author>Chi Wang</author>
<author>Fangqiu Han</author>
<author>Jiawei Han</author>
<author>Dan Roth</author>
<author>Xifeng Yan</author>
</authors>
<title>Mining evidences for named entity disambiguation.</title>
<date>2013</date>
<booktitle>In KDD’13,</booktitle>
<pages>1070--1078</pages>
<contexts>
<context position="4298" citStr="Li et al., 2013" startWordPosition="676" endWordPosition="679">ur of the brands exist in Wikipedia. This circumstance is not unusual. For another larger dataset that included 2468 stock names, we found only 340 of them had their reference pages in Wikipedia. Thus, the methods that rely heavily on KBs might not be appropriate here. Shortness of the Texts The context in which a 654 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 654–664, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. target entity occurs plays an important role in disambiguation. (Cassidy et al., 2012; Li et al., 2013) applied the underlying topical coherence information to a set of mentions for entity linking. In (Wang et al., 2012), mentionRank leverages some additional features, such as co-mention; however, people prefer to share their comments in brief or even informal words on social media platforms, such as Twitter, which becomes increasingly important as an information source. We have counted 350,498 microblogs, 37,379 tweets and 34,018 text snippets in various domains in Chinese and English from Twitter, Sina Weibo and Google. After preprocessing, their average length are 16, 5 and 11 words, respect</context>
</contexts>
<marker>Li, Wang, Han, Han, Roth, Yan, 2013</marker>
<rawString>Yang Li, Chi Wang, Fangqiu Han, Jiawei Han, Dan Roth, and Xifeng Yan. 2013. Mining evidences for named entity disambiguation. In KDD’13, pages 1070–1078.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Yitong Li</author>
<author>Haocheng Wu</author>
<author>Ming Zhou</author>
<author>Furu Wei</author>
<author>Yi Lu</author>
</authors>
<title>Entity linking for tweets.</title>
<date>2013</date>
<journal>In ACL</journal>
<volume>1</volume>
<pages>1304--1311</pages>
<contexts>
<context position="5294" citStr="Liu et al., 2013" startWordPosition="839" endWordPosition="842">e counted 350,498 microblogs, 37,379 tweets and 34,018 text snippets in various domains in Chinese and English from Twitter, Sina Weibo and Google. After preprocessing, their average length are 16, 5 and 11 words, respectively. To alleviate the shortness issue, additional information has been used to expand the context, such as the user’s interest (Shen et al., 2013) and related documents (Guo et al., 2013). Such information is still sparse or unavailable in this case, and thus, the existing methods might not be suitable. Large Scale Hundreds of millions of tweets are posted daily on Twitter (Liu et al., 2013). When scaling to a large document collection, the disambiguation task becomes increasingly important as the ambiguity increases (Cucerzan, 2007). MentionRank, the only state-of-the-art method for TED, is a graph-based model that focuses on a small set of entities (e.g., 50 or 100 entities) and conducts experiments on thousands of documents (Wang et al., 2012). However, the graph has a quadratic growth as the number of documents increases. In our experiments, a dataset that included 2,468 target entities and 350,498 microblogs generated a directed graph with billions of edges, which required m</context>
</contexts>
<marker>Liu, Li, Wu, Zhou, Wei, Lu, 2013</marker>
<rawString>Xiaohua Liu, Yitong Li, Haocheng Wu, Ming Zhou, Furu Wei, and Yi Lu. 2013. Entity linking for tweets. In ACL (1), pages 1304–1311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Andras Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,</booktitle>
<pages>233--242</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3454" citStr="Mihalcea and Csomai, 2007" startWordPosition="537" endWordPosition="540">ion as a name list. There are three types of information that are utilized in Named Entity Disambiguation related tasks: knowledge resources, the context in which a target word occurs and statistical information (Navigli, 2009). However, the lack of the first two types of information makes this problem more challenging. Knowledge Sparsity A large number of methods focus on using knowledge bases (KBs) like Wikipedia or YAGO to enrich the named entities (e.g., in-links and out-links) (Hoffart et al., 2011; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Han et al., 2011; Mihalcea and Csomai, 2007; Shen et al., 2012). These methods compared the context of the entities and their reference pages in the KBs through a similarity measurement. However, we tested 32 different names of General Motors (GM) car brands, and only four of the brands exist in Wikipedia. This circumstance is not unusual. For another larger dataset that included 2468 stock names, we found only 340 of them had their reference pages in Wikipedia. Thus, the methods that rely heavily on KBs might not be appropriate here. Shortness of the Texts The context in which a 654 Proceedings of the 2015 Conference on Empirical Meth</context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>Rada Mihalcea and Andras Csomai. 2007. Wikify!: linking documents to encyclopedic knowledge. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pages 233–242. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: A lexical database for english.</title>
<date>1995</date>
<journal>Commun. ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="14237" citStr="Miller, 1995" startWordPosition="2357" endWordPosition="2358">2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3.2.1 Similarity Measurement We constructed the edges of the graph according to the similarity relations between documents. Most similarity measurements (Artiles et al., 2010; Miller, 1995) could be used in the proposed method. After some exploration, we found that Jaccard similarity performs better. It can be efficiently calculated through simple set operations: Wdi n WdjI 1 Wdi U Wdj I ( ) where ωJ ijdenotes the weight of edge (di, dj) using Jaccard similarity, and Wdi is the set of words contained in di. ωij varies from 0 to 1, where a value closer to 1 indicates that its two nodes are more similar. We link only similar nodes by choosing an appropriate threshold 77. In other words, we have (di, dj) E £, only if ωJ ij&gt; 77. This is the foundation to construct the graph locally </context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: A lexical database for english. Commun. ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to link with wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th ACM conference on Information and knowledge management,</booktitle>
<pages>509--518</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3386" citStr="Milne and Witten, 2008" startWordPosition="524" endWordPosition="528">iguation tasks, TED in short texts can require as little information as a name list. There are three types of information that are utilized in Named Entity Disambiguation related tasks: knowledge resources, the context in which a target word occurs and statistical information (Navigli, 2009). However, the lack of the first two types of information makes this problem more challenging. Knowledge Sparsity A large number of methods focus on using knowledge bases (KBs) like Wikipedia or YAGO to enrich the named entities (e.g., in-links and out-links) (Hoffart et al., 2011; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Han et al., 2011; Mihalcea and Csomai, 2007; Shen et al., 2012). These methods compared the context of the entities and their reference pages in the KBs through a similarity measurement. However, we tested 32 different names of General Motors (GM) car brands, and only four of the brands exist in Wikipedia. This circumstance is not unusual. For another larger dataset that included 2468 stock names, we found only 340 of them had their reference pages in Wikipedia. Thus, the methods that rely heavily on KBs might not be appropriate here. Shortness of the Texts The context</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H Witten. 2008. Learning to link with wikipedia. In Proceedings of the 17th ACM conference on Information and knowledge management, pages 509–518. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
</authors>
<title>Word sense disambiguation: A survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys (CSUR),</journal>
<volume>41</volume>
<issue>2</issue>
<contexts>
<context position="3056" citStr="Navigli, 2009" startWordPosition="471" endWordPosition="472"> rather than being general things. In the case of entity recognition from short texts, the disambiguation can be performed on the document level. Given a collection of short documents, our goal is to determine which documents contain the target entities. Challenge and Related Work In contrast to traditional entity disambiguation tasks, TED in short texts can require as little information as a name list. There are three types of information that are utilized in Named Entity Disambiguation related tasks: knowledge resources, the context in which a target word occurs and statistical information (Navigli, 2009). However, the lack of the first two types of information makes this problem more challenging. Knowledge Sparsity A large number of methods focus on using knowledge bases (KBs) like Wikipedia or YAGO to enrich the named entities (e.g., in-links and out-links) (Hoffart et al., 2011; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Han et al., 2011; Mihalcea and Csomai, 2007; Shen et al., 2012). These methods compared the context of the entities and their reference pages in the KBs through a similarity measurement. However, we tested 32 different names of General Motors (G</context>
</contexts>
<marker>Navigli, 2009</marker>
<rawString>Roberto Navigli. 2009. Word sense disambiguation: A survey. ACM Computing Surveys (CSUR), 41(2):10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<contexts>
<context position="18586" citStr="Page et al., 1999" startWordPosition="3133" endWordPosition="3136">y documents and thus receive more trust through the first term in Equation 3. In contrast, false mentions are dissimilar to most other documents; thus, their scores gradually attenuate (the second term in Equation 3). These scores are globally comparable. One can normalize the final scores by dividing them by the largest score, but the relative ordering of the documents will not change. Thus, one document that is more likely to contain any 1We select the attenuation coefficient α = 0.85 and the number of iterations to be 20, which have been regarded as the standards in the PageRank literature(Page et al., 1999; Krishnan and Raj, 2006). Our experiments also show that 20 iterations are sufficient to achieve convergence. true mention will receive a higher trust score and be ranked higher. 3.3 Multi-layer Directed Graph During propagation, all of the documents are initialized with the same trust score and attenuate their trust at the same level. However, different documents should be treated differently. For example, the tweet “I drive a big car suburban” is more trustworthy than “doctors use GMC report system to process harmful patients”, because the former tweet contains the credible context feature </context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Pennacchiotti</author>
<author>Patrick Pantel</author>
</authors>
<title>Entity extraction via ensemble semantics.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>1</volume>
<pages>238--247</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="13449" citStr="Pennacchiotti and Pantel, 2009" startWordPosition="2214" endWordPosition="2217">1 d2 r4:0.9 r5:0.1 r2:0.9 r3:0.1 r6:0.8 656 The assumptions resemble the main insight of MentionRank except the co-mention (multiple entities occur in one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3</context>
</contexts>
<marker>Pennacchiotti, Pantel, 2009</marker>
<rawString>Marco Pennacchiotti and Patrick Pantel. 2009. Entity extraction via ensemble semantics. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 1-Volume 1, pages 238–247. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and global algorithms for disambiguation to wikipedia.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1,</booktitle>
<pages>1375--1384</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="13567" citStr="Ratinov et al., 2011" startWordPosition="2236" endWordPosition="2239">iple entities occur in one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3.2.1 Similarity Measurement We constructed the edges of the graph according to the similarity relations between docume</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev Ratinov, Dan Roth, Doug Downey, and Mike Anderson. 2011. Local and global algorithms for disambiguation to wikipedia. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1, pages 1375–1384. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Shen</author>
<author>Jianyong Wang</author>
<author>Ping Luo</author>
<author>Min Wang</author>
</authors>
<title>Linden: linking named entities with knowledge base via semantic knowledge.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web,</booktitle>
<pages>449--458</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3474" citStr="Shen et al., 2012" startWordPosition="541" endWordPosition="544">re three types of information that are utilized in Named Entity Disambiguation related tasks: knowledge resources, the context in which a target word occurs and statistical information (Navigli, 2009). However, the lack of the first two types of information makes this problem more challenging. Knowledge Sparsity A large number of methods focus on using knowledge bases (KBs) like Wikipedia or YAGO to enrich the named entities (e.g., in-links and out-links) (Hoffart et al., 2011; Bunescu and Pasca, 2006; Milne and Witten, 2008; Kulkarni et al., 2009; Han et al., 2011; Mihalcea and Csomai, 2007; Shen et al., 2012). These methods compared the context of the entities and their reference pages in the KBs through a similarity measurement. However, we tested 32 different names of General Motors (GM) car brands, and only four of the brands exist in Wikipedia. This circumstance is not unusual. For another larger dataset that included 2468 stock names, we found only 340 of them had their reference pages in Wikipedia. Thus, the methods that rely heavily on KBs might not be appropriate here. Shortness of the Texts The context in which a 654 Proceedings of the 2015 Conference on Empirical Methods in Natural Langu</context>
</contexts>
<marker>Shen, Wang, Luo, Wang, 2012</marker>
<rawString>Wei Shen, Jianyong Wang, Ping Luo, and Min Wang. 2012. Linden: linking named entities with knowledge base via semantic knowledge. In Proceedings of the 21st international conference on World Wide Web, pages 449–458. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Shen</author>
<author>Jianyong Wang</author>
<author>Ping Luo</author>
<author>Min Wang</author>
</authors>
<title>Linking named entities in tweets with knowledge base via user interest modeling.</title>
<date>2013</date>
<booktitle>In KDD,</booktitle>
<pages>68--76</pages>
<contexts>
<context position="5046" citStr="Shen et al., 2013" startWordPosition="795" endWordPosition="798"> leverages some additional features, such as co-mention; however, people prefer to share their comments in brief or even informal words on social media platforms, such as Twitter, which becomes increasingly important as an information source. We have counted 350,498 microblogs, 37,379 tweets and 34,018 text snippets in various domains in Chinese and English from Twitter, Sina Weibo and Google. After preprocessing, their average length are 16, 5 and 11 words, respectively. To alleviate the shortness issue, additional information has been used to expand the context, such as the user’s interest (Shen et al., 2013) and related documents (Guo et al., 2013). Such information is still sparse or unavailable in this case, and thus, the existing methods might not be suitable. Large Scale Hundreds of millions of tweets are posted daily on Twitter (Liu et al., 2013). When scaling to a large document collection, the disambiguation task becomes increasingly important as the ambiguity increases (Cucerzan, 2007). MentionRank, the only state-of-the-art method for TED, is a graph-based model that focuses on a small set of entities (e.g., 50 or 100 entities) and conducts experiments on thousands of documents (Wang et </context>
</contexts>
<marker>Shen, Wang, Luo, Wang, 2013</marker>
<rawString>Wei Shen, Jianyong Wang, Ping Luo, and Min Wang. 2013. Linking named entities in tweets with knowledge base via user interest modeling. In KDD, pages 68–76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chi Wang</author>
<author>Kaushik Chakrabarti</author>
<author>Tao Cheng</author>
<author>Surajit Chaudhuri</author>
</authors>
<title>Targeted disambiguation of adhoc, homogeneous sets of named entities.</title>
<date>2012</date>
<booktitle>In WWW,</booktitle>
<pages>719--728</pages>
<contexts>
<context position="2217" citStr="Wang et al., 2012" startWordPosition="331" endWordPosition="334"> from these messages, and for various applications, such as natural language processing and knowledge acquisition (Dredze et al., 2010). Take the application of customer feedback analysis (CFA) as an example. An enterprise is typically interested in public reviews of its own products as well as those of its competitors’; the identification of these entities is thus critical for further analysis. The product names comprise a list of entities to be identified. We refer to these entities of the same domain as target entities, and the identification process is called target entity disambiguation (Wang et al., 2012). All of target entities (e.g., car brands) share a common domain, which we refer to as the target domain. The target domain is the only constraint to target entities, which implies that the entities are in a specific domain, rather than being general things. In the case of entity recognition from short texts, the disambiguation can be performed on the document level. Given a collection of short documents, our goal is to determine which documents contain the target entities. Challenge and Related Work In contrast to traditional entity disambiguation tasks, TED in short texts can require as lit</context>
<context position="4415" citStr="Wang et al., 2012" startWordPosition="696" endWordPosition="699">8 stock names, we found only 340 of them had their reference pages in Wikipedia. Thus, the methods that rely heavily on KBs might not be appropriate here. Shortness of the Texts The context in which a 654 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 654–664, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. target entity occurs plays an important role in disambiguation. (Cassidy et al., 2012; Li et al., 2013) applied the underlying topical coherence information to a set of mentions for entity linking. In (Wang et al., 2012), mentionRank leverages some additional features, such as co-mention; however, people prefer to share their comments in brief or even informal words on social media platforms, such as Twitter, which becomes increasingly important as an information source. We have counted 350,498 microblogs, 37,379 tweets and 34,018 text snippets in various domains in Chinese and English from Twitter, Sina Weibo and Google. After preprocessing, their average length are 16, 5 and 11 words, respectively. To alleviate the shortness issue, additional information has been used to expand the context, such as the user</context>
<context position="5656" citStr="Wang et al., 2012" startWordPosition="897" endWordPosition="900">., 2013) and related documents (Guo et al., 2013). Such information is still sparse or unavailable in this case, and thus, the existing methods might not be suitable. Large Scale Hundreds of millions of tweets are posted daily on Twitter (Liu et al., 2013). When scaling to a large document collection, the disambiguation task becomes increasingly important as the ambiguity increases (Cucerzan, 2007). MentionRank, the only state-of-the-art method for TED, is a graph-based model that focuses on a small set of entities (e.g., 50 or 100 entities) and conducts experiments on thousands of documents (Wang et al., 2012). However, the graph has a quadratic growth as the number of documents increases. In our experiments, a dataset that included 2,468 target entities and 350,498 microblogs generated a directed graph with billions of edges, which required more computer memory than was available even when using a sparse matrix. Therefore, the scalability remains a challenge. Contributions To address these challenges, we propose a collective method called TremenRank to disambiguate the target entities simultaneously. The main idea is to propagate trust within a graph based on our observations that true mentions ar</context>
</contexts>
<marker>Wang, Chakrabarti, Cheng, Chaudhuri, 2012</marker>
<rawString>Chi Wang, Kaushik Chakrabarti, Tao Cheng, and Surajit Chaudhuri. 2012. Targeted disambiguation of adhoc, homogeneous sets of named entities. In WWW, pages 719–728.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radford Will</author>
<author>Hachey Ben</author>
<author>Nothman Joel</author>
<author>Honnibal Matthew</author>
<author>R Curran James</author>
</authors>
<title>Cmcrc at tac10: Document-level entity linking with graphbased re-ranking.</title>
<date>2010</date>
<booktitle>In In Proc. Text Analysis Conference (TAC</booktitle>
<contexts>
<context position="13468" citStr="Will et al., 2010" startWordPosition="2218" endWordPosition="2221"> r6:0.8 656 The assumptions resemble the main insight of MentionRank except the co-mention (multiple entities occur in one document). Co-mention seldom happens in short texts, and can be treated as the same because they share a common context. In conclusion, the assumptions suggest that a collective method could perform better than a method that disambiguates entities separately, because more comprehensive information on the entities from multiple “collaborators” (i.e., the mentions have similar contexts) has been used (Chen and Ji, 2011; Kulkarni et al., 2009; Pennacchiotti and Pantel, 2009; Will et al., 2010; Fernandez et al., 2010; Cucerzan, 2011; Guo et al., 2011; Han and Sun, 2011; Ratinov et al., 2011; Kozareva et al., 2011; Dalton and Dietz, 2013). Figure 2: Statistics on the ambiguity in stocks. 3.2 Graph-based Method Based on these assumptions, we build a graph to represent the documents and their relations, and we perform a TrustRank-like algorithm on the graph. We are given a graph G = (V, £) that consists of a set V of N documents (vertices) and a set £ of directed edges, where each edge (di, dj) E £ denotes that di points to dj, and o(di) is the outneighbors of di. 3.2.1 Similarity Mea</context>
</contexts>
<marker>Will, Ben, Joel, Matthew, James, 2010</marker>
<rawString>Radford Will, Hachey Ben, Nothman Joel, Honnibal Matthew, and R.Curran James. 2010. Cmcrc at tac10: Document-level entity linking with graphbased re-ranking. In In Proc. Text Analysis Conference (TAC 2010).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>