<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000111">
<title confidence="0.989197">
Topical Coherence for Graph-based Extractive Summarization
</title>
<author confidence="0.820184">
Michael Strube†
</author>
<affiliation confidence="0.763849">
Daraksha Parveen† Hans-Martin Ramsl‡
†NLP Group and Research Training Group AIPHES
Heidelberg Institute for Theoretical Studies gGmbH
</affiliation>
<address confidence="0.661774">
Heidelberg, Germany
</address>
<email confidence="0.667101">
{daraksha.parveen|michael.strube}@h-its.org
</email>
<note confidence="0.601178">
‡SAP SE
Walldorf, Germany
</note>
<email confidence="0.972371">
hans-martin.ramsl@sap.com
</email>
<sectionHeader confidence="0.993119" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999867142857143">
We present an approach for extractive
single-document summarization. Our ap-
proach is based on a weighted graphical
representation of documents obtained by
topic modeling. We optimize importance,
coherence and non-redundancy simulta-
neously using ILP. We compare ROUGE
scores of our system with state-of-the-art
results on scientific articles from PLOS
Medicine and on DUC 2002 data. Hu-
man judges evaluate the coherence of sum-
maries generated by our system in com-
parision to two baselines. Our approach
obtains competitive performance.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999959115384616">
Summarization systems take a long document as
input and generate a concise document as out-
put. Several summarization variants exist such as
generic, query-based, multi-document and single
document, but the basic requirements for summa-
rization remain the same. Summaries should con-
tain salient information so that the reader will not
miss anything from the original document. Also,
the reader is not interested in repetitive informa-
tion, so summaries should not include redundant
information. Finally, summaries should be coher-
ent and of high readability.
We introduce a completely unsupervised graph-
based summarization using latent drichlet alloca-
tion (LDA, Blei and Lafferty (2009)). LDA is
a simple model for topic modeling where topic
probabilities are assigned words in documents.
The probabilities can be used to measure the se-
mantic relatedness between words and hence the
topical coherence of a document. We use topi-
cal coherence as a means to ensure the coherence
of extractive single-document summaries. Re-
mus and Biemann (2013) apply LDA to compute
lexical chains while Gorinski and Lapata (2015)
also develop a graph-based summarization system
which takes coherence into account.
Our work is based on the bipartite entity graph
introduced by Guinaudeau and Strube (2013).
However, in their graph one set of nodes corre-
sponds to entities whereas in our graph it corre-
sponds to topics. The entity graph has already
been used by Parveen and Strube (2015) for sum-
marization. Their graph is unweighted and sparse,
whereas our topical graph is weighted and dense.
We apply our topical graph on the dataset in-
troduced by Parveen and Strube (2015). This
dataset contains scientific articles from the jour-
nal PLOS Medicine1. Every PLOS Medicine ar-
ticle is accompanied by an editor’s summary and
an authors’ abstract. We use both as gold sum-
maries for evaluation. Results obtained on the
PLOS Medicine dataset using the topical graph are
as good as using the entity graph and significantly
better than several baselines and the graph-based
system TextRank (Mihalcea and Tarau, 2004). We
use the DUC 2002 dataset to compare our results
with state-of-the-art techniques. In contrast to the
PLOS Medicine data the DUC 2002 dataset con-
tains very small articles. Still, our technique gives
comparable results to the state-of-the-art. This
shows that our technique is flexible and scalable
despite being unsupervised.
</bodyText>
<sectionHeader confidence="0.996686" genericHeader="method">
2 Our Method
</sectionHeader>
<subsectionHeader confidence="0.999322">
2.1 Document Representation
</subsectionHeader>
<bodyText confidence="0.999839833333333">
A graph-based representation has been used
by well known summarization systems such as
LexRank (Erkan and Radev, 2004) and TextRank
(Mihalcea and Tarau, 2004). The graph used by
both is of one mode type where sentences are
nodes which are connected by weighted edges.
</bodyText>
<footnote confidence="0.9985605">
1http://journals.plos.org/
plosmedicine/
</footnote>
<page confidence="0.92269">
1949
</page>
<note confidence="0.6793585">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1949–1954,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.997300461538462">
Weights express sentence similarity.
We use a bipartite graph representation of doc-
uments (Figure 1). The bipartite graph, G =
(Vs, Vt, Et,s), has two sets of nodes where Vs rep-
resents sentences and Vt topics. The two sets of
nodes are connected with edge Et,s, if a word in a
sentence s is present in a topic t. If multiple words
are present in topic t of sentence s, then the edge
weight is the logarithmic sum of probabilities of
words in topic t. We normalize the edge weight by
dividing them by the length of the sentence. Hence
long sentences will not benefit from their lengths.
We call the resulting graph topical graph.
</bodyText>
<subsectionHeader confidence="0.999555">
2.2 Sentence Ranking
</subsectionHeader>
<bodyText confidence="0.999544833333333">
The final summary should contain only important
sentences. Therefore, we give a score to every
sentence in a document to obtain important sen-
tences. Following Parveen and Strube (2015) we
apply the HITS (Hyperlink Induced Topic Search)
(Kleinberg, 1999) algorithm for ranking sentences
by importance, since our graph is a bipartite graph.
It puts nodes of a graph in two sets: hub nodes and
authority nodes.
For the HITS algorithm the rank of nodes needs
to be initialized. We initialize the topic rank
Rankti = 1 and the sentence rank Ranksi =
1+sim(si, title). The title in the sentence rank is
the title of the article. sim(si, title) is the cosine
similarity between the sentence si and the title of
the article. After initialization of all nodes in the
weighted topical graph, the HITS algorithm is ap-
plied to obtain ranks of sentences.
</bodyText>
<subsectionHeader confidence="0.999078">
2.3 Coherence Measure
</subsectionHeader>
<bodyText confidence="0.998377176470588">
Guinaudeau and Strube (2013) represent a docu-
ment by the entity graph, a bipartite graph consist-
ing of sentence and entity nodes. They perform
a one-mode projection on sentence nodes, com-
pute the coherence of a document on the basis of
the one-mode projections and use the coherence
measure for summary coherence rating. Building
upon this work, Parveen and Strube (2015) inte-
grate this coherence measure to directly generate
coherent summaries. Instead of the entity graph
we here use the topical graph to incorporate the co-
herence measure. Parveen and Strube (2015) use
an unweighted projection graph whereas we use
a weighted projection graph of a topical graph to
compute the coherence. The weighted one mode
projection of the topical graph is shown in Figure
1, bottom right.
</bodyText>
<construct confidence="0.566326666666667">
weighted coh(si, P) = weighted Outdegree(si, P)
weighted coh(si, P)
norm weighted coh(si, P) = weighted coh(si, P)
</construct>
<bodyText confidence="0.998768428571429">
Equation 1 calculates the outdegree of every sen-
tence from the weighted projection graph. How-
ever weighted coh(si, P) in Equation 1 is not
a normalized value. The normalized coherence
value is in Equation 2. Afterwards, we use this
coherence value in the optimization phase for the
selection of sentences.
</bodyText>
<subsectionHeader confidence="0.99104">
2.4 Optimization
</subsectionHeader>
<bodyText confidence="0.998469105263158">
McDonald (2007) introduces summarization as an
optimization task which takes care of importance,
redundancy and coherence simultaneously. In this
paper, we also propose a model for single doc-
ument summarization which is based on integer
linear programming (ILP). We consider ranks ob-
tained by the HITS algorithm as sentence impor-
tance. The weighted coherence measure is cal-
culated using Equation 1 and Equation 2. PLOS
Medicine articles are very long and contain repeti-
tive information, so we have to deal with redun-
dancy even in single-document summarization.
Therefore we model non-redundancy as topic cov-
erage in the final summary: the more topics in a
summary, the less redundant the summary will be.
The ILP objective function is shown in Equation
3. fi(X) is the function which maximizes im-
portance, fc(X) maximizes coherence, and ft(Y )
maximizes topic coverage.
</bodyText>
<equation confidence="0.40853">
Objective function : max(fi(X) + fc(X) + ft(Y ))
X,Y
</equation>
<bodyText confidence="0.9170206">
X is a variable for sentences which contains
boolean variables xi, where 0 &lt; i &lt; n is the num-
ber of sentences. Y is a variable for topics which
contains boolean variables yj, where 0 &lt; j &lt; m
is the number of topics.
</bodyText>
<equation confidence="0.88352">
yj (4)
</equation>
<bodyText confidence="0.997428">
Constraints ensure that the system satisfies addi-
tional requirements such as summary length:
</bodyText>
<equation confidence="0.988867">
xi ≤ Len(summary) (5)
E yj ≥ |Topicsxi |· xi, for i = 1, ... ,n (6)
j∈Ti
M
E
j=1
ft(Y ) =
En
i=1
</equation>
<page confidence="0.96465">
1950
</page>
<tableCaption confidence="0.880925666666667">
S1 WHO recommends prompt diagnosis and quinine plus clindamycin for treatment of uncomplicated malaria in the first
trimester and artemisinin-based combination therapies in subsequent trimesters.
S2 We undertook a systematic review of women’s access to and healthcare provider adherence to WHO case management
policy for malaria in pregnant women.
S3 Data were appraised for quality and content.
S4 Determinants of women’s access and providers’ case management practices were extracted and compared across studies.
</tableCaption>
<table confidence="0.999597">
S1 - 0.3 0.46 0.50 0.23 0.55 0.89 0.56 0.09 - - 0.73
S2 0.3 0.29 0.3 - 0.66 0.35 0.36 0.63 - - 0.55 -
S3 - 0.28 - 0.43 - 0.39 - 0.42 0.65 - 0.12 0.58
S4 0.22 0.43 0.29 0.6 - - 0.14 0.26 - - - 0.41
</table>
<figureCaption confidence="0.992336">
Figure 1: Abstract from PLOS Medicine, topical grid, bipartite topical graph, one-mode projection
</figureCaption>
<equation confidence="0.86232">
E xi ≥ yj, for j = 1, ... , m (7)
i∈Sj
</equation>
<bodyText confidence="0.998558363636364">
The final summary should be shorter than the
original text and it should also have a length limit
(Equation 5). The results on PLOS medicine data
(Section 3) are limited to 5 sentences. We have
also experimented with multiple lengths. Increas-
ing the summary length increases ROUGE scores.
DUC 2002 summaries are limited to 100 words.
Equation 6 shows that topics present in sen-
tence xi are selected, when sentence xi is selected.
Therefore, xi = 1 and Ti = Topicsxi. The con-
straint holds, because E yj = |Topicsxi|. Fur-
</bodyText>
<subsubsectionHeader confidence="0.50233">
jETi
</subsubsectionHeader>
<bodyText confidence="0.952180333333333">
thermore, if sentence xi = 0, i.e., it is not se-
lected, then there must be topics which are al-
ready present in selected sentences. Hence, the
</bodyText>
<equation confidence="0.626389833333333">
constraint holds, E yj &gt; 0.
jETi
Equation 7 constrains the selection of topics. If
topic yj = 1, then at least one sentence containing
this topic has been selected. Therefore E xi &gt; 1,
iESj
</equation>
<bodyText confidence="0.9865635">
and the constraint holds. If topic yj = 0, then
sentences containing this topic are not selected, so
</bodyText>
<equation confidence="0.6263435">
E xi = 0, and the constraint holds.
iESj
</equation>
<sectionHeader confidence="0.998877" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999767666666667">
Following Parveen and Strube (2015), we evaluate
on the science genre, i.e. PLOS Medicine articles,
and on the news genre, i.e. DUC 2002 data.
</bodyText>
<subsectionHeader confidence="0.973919">
3.1 Datasets
</subsectionHeader>
<bodyText confidence="0.9946776">
PLOS Medicine articles are considerably longer
than DUC 2002 documents. The average num-
ber of sentences per document is 154 in PLOS
Medicine and 25 in DUC 2002. Benefits of using
PLOS Medicine articles for experiments are:
</bodyText>
<listItem confidence="0.994124">
• They are accompanied by an authors’ abstract.
• They have a summary written by an editor.
• They are formatted in XML.
• They contain explicit full forms of abbrevia-
tions.
</listItem>
<bodyText confidence="0.999763125">
Editor’s summaries have a different perspective,
writing style and length than authors’ abstracts.
We use both as gold summaries for evaluation.
Following Parveen and Strube (2015) we re-
port the results using editor’s summaries and au-
thor’s abstracts independently. To compare with
the state-of-the-art in single-document summa-
rization, we also evaluate on DUC 2002 data.
</bodyText>
<page confidence="0.970584">
1951
</page>
<subsectionHeader confidence="0.988154">
3.2 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.99998452">
We use the XML version of PLOS Medicine ar-
ticles. We extract the contents excluding figures,
tables and references. Editor’s summary and au-
thors’ abstract are separated from the content for
evaluation. The PLOS Medicine XML provides
explicit full forms when abbreviations are intro-
duced. We replace abbreviations with their full
form in the summary. We then remove non-
alphabetical characters. After this we parse ar-
ticles using the Stanford parser (Klein and Man-
ning, 2003). We perform pronoun resolution using
the coreference resolution system by Martschat
(2013)2. We use gensim to generate the topics.
For generating topics we use a dataset contain-
ing scientific articles from biology, which con-
tains 221,385 documents and about 50 million
sentences3. We also use Wikipedia to compare
with topics from a general domain.
The HITS algorithm is applied on the bipar-
tite graph for computing sentence importance. We
calculate the coherence values of sentences on
weighted one-mode projection graphs. The impor-
tance and coherence of a sentence is used in the
optimization phase4 which returns a binary value
for each sentence.
</bodyText>
<subsectionHeader confidence="0.806034">
3.3 Results
</subsectionHeader>
<bodyText confidence="0.995132888888889">
Results on PLOS Medicine are shown in Tables
1 and 2. We evaluate using ROUGE-SU4 and
ROUGE-2 (Lin, 2004). We limit the length of
the summaries to five sentences and the number
of topics to 2000 in the topical graph. We also
experimented with varying numbers of topics, i.e.
500, 1000 and 2000, and varying summary length
limits. The results changed only marginally. The
general trends remained the same.
We compare our system with four different
baselines and two versions of the entity graph.
Lead selects the top five sentences, Random five
sentences randomly. MMR is an implementation
of maximal marginal relevance (Carbonell and
Goldstein, 1998). TextRank is the graph-based
system by Mihalcea and Tarau (2004)5. Egraph
is the entity graph based system by Parveen and
Strube (2015). Egraph + Coh. is their system
</bodyText>
<footnote confidence="0.9412605">
2http://www.smartschat.de/software/
3http://www.datawrangling.com/
some-datasets-available-on-the-web/
4We use Gurobi, http://www.gurobi.com
5https://kenai.com/projects/
textsummarizer
</footnote>
<table confidence="0.999674909090909">
Systems R-SU4 R-2
Lead 0.067 0.055
Random 0.048 0.031
MMR 0.069 0.048
TextRank 0.068 0.048
Egraph 0.121 0.090
Egraph + Coh. 0.130 0.096
Egraph + Coh. + Pos. 0.131 0.098
Tgraph (n=2000) 0.123 0.091
Tgraph (n=2000) + Coh. 0.129 0.095
Tgraph (n=2000) + Coh. + Pos. 0.125 0.092
</table>
<tableCaption confidence="0.997176">
Table 1: PLOS Medicine, editor’s summaries
</tableCaption>
<table confidence="0.999921636363636">
Systems R-SU4 R-2
Lead 0.105 0.077
Random 0.093 0.589
MMR 0.118 0.098
TextRank 0.134 0.101
Egraph 0.200 0.170
Egraph + Coh. 0.219 0.175
Egraph + Coh. + Pos. 0.224 0.189
Tgraph (n=2000) 0.217 0.173
Tgraph (n=2000) + Coh. 0.221 0.179
Tgraph (n=2000) + Coh. + Pos. 0.215 0.174
</table>
<tableCaption confidence="0.999624">
Table 2: PLOS Medicine, authors’ abstracts
</tableCaption>
<bodyText confidence="0.999850275862069">
which includes a coherence measure, which is cal-
culated by using the unweighted projection graph.
Egraph + Coh. + Pos. combines the coherence
measure and positional information.
Our system outperforms all baselines substan-
tially, as shown in Tables 1 (editor’s summaries)
and 2 (authors’ abstracts). We observe improve-
ments in the results when including coherence in
the topical graph. We obtain best results with
Tgraph + Coh., where the number of topics is
2000. In Tgraph, penalizing coherence mea-
sures with positional information lowers ROUGE
scores. While including positional information
into the entity graph obtains the best results on
the PLOS Medicine dataset, positional informa-
tion does not appear to be beneficial for the topical
graph. Absolute ROUGE scores are higher when
using abstracts as gold summaries, because the ab-
stracts are shorter than editor’s summaries.
We compare results using biology journals (Ta-
ble 3) and Wikipedia (Table 4) to generate top-
ics. The topical graph is denser when using bi-
ology journals compared to the graph generated
from Wikipedia. Results using the in-domain bi-
ology journals as data to generate topics are better
than using general domain Wikipedia data. The
scores are highest with 2000 topics. For Bio topic
the differences are negligible, however.
We also compare results on DUC 2002 to
</bodyText>
<page confidence="0.981375">
1952
</page>
<table confidence="0.9997665">
Topics R-1 R-2 R-SU4
Tgraph (n=500) + Coh. 0.279 0.090 0.125
Tgraph (n=1000) + Coh. 0.289 0.093 0.128
Tgraph (n=2000) + Coh. 0.291 0.095 0.129
</table>
<tableCaption confidence="0.94771">
Table 3: PLOS Medicine, editor’s summ., Bio
topic
</tableCaption>
<table confidence="0.99986225">
Topics R-1 R-2 R-SU4
Tgraph (n=500) + Coh. 0.208 0.060 0.098
Tgraph (n=1000) + Coh. 0.258 0.073 0.106
Tgraph (n=2000) + Coh. 0.283 0.086 0.121
</table>
<tableCaption confidence="0.970158">
Table 4: PLOS Medicine, editor’s summ., Wiki
topic
</tableCaption>
<bodyText confidence="0.999763823529412">
check against the state-of-the-art on a well-known
dataset. Lead performs well on DUC 2002 as
shown in Table 5, because important information
appears in the initial lines of news articles. DUC
2002 Best is the result reported by the top perform-
ing system at DUC 2002. This system actually
obtains better results than TextRank (Mihalcea and
Tarau, 2004) and the more recent system Uniform-
Link (Wan and Xiao, 2010). Our system Tgraph
+ Coh. performs better than the well known best
systems on DUC 2002 and slightly better than
Egraph + Coh. However the difference between
the results of Tgraph and Egraph are not signifi-
cant. In contrast to the entity graph based system,
the coherence measure in our system is calculated
by using a topic-based weighted projection graph,
which is denser and hence more informative.
</bodyText>
<subsectionHeader confidence="0.995871">
3.4 Human Coherence Judgements
</subsectionHeader>
<bodyText confidence="0.999917555555556">
In addition to ROUGE scores, we use human
judgements for evaluating the coherence of our
summaries. We asked four PhD students in natural
language processing to evaluate our summaries on
the basis of coherence. We randomly selected ten
summaries of scientific articles from three differ-
ent systems, TextRank, Lead and Tgraph + Coh.
We asked the human judges to rank the summaries
according to their coherence. So, the summary
</bodyText>
<table confidence="0.999419">
Systems R-1 R-2 R-SU4
Lead 0.459 0.180 0.201
DUC 2002 Best 0.480 0.228
TextRank 0.470 0.195 0.217
UniformLink (k = 10) 0.471 0.201
Egraph + Coh. 0.479 0.238 0.230
Tgraph (n=2000) + Coh. 0.481 0.243 0.242
</table>
<tableCaption confidence="0.79013">
Table 5: DUC 2002, single-document summariza-
tion
</tableCaption>
<bodyText confidence="0.999862941176471">
which is best in coherence gets rank 1, second best
gets rank 2, and worst gets rank 3. We calculated
the Kendall concordance coefficient (W) (Siegel
and Castellan, 1988) to measure the judges’ agree-
ment. We obtain W = 0.61, which indicates a
relatively high agreement.
To compare the three systems, we take the aver-
age over the ranks. The overall rank of TextRank
is 2.625, Lead is 1.675 and Tgraph + Coh. is 1.8.
Lead performs best, because it selects the top five
consecutive sentences, which are coherent as the
original authors intended them to be. However, the
overall ranks of Lead and Tgraph + Coh. are not
significantly different, whereas TextRank’s over-
all rank is significantly worse than both. Hence,
Tgraph + Coh. performs very well in our human
judgement coherence experiment.
</bodyText>
<sectionHeader confidence="0.999863" genericHeader="discussions">
4 Discussion
</sectionHeader>
<bodyText confidence="0.99952025">
In this paper we introduced the topical graph
for single document summarization. We experi-
mented with multiple numbers of topics on the sci-
entific article dataset. Our system performs well
when including the weighted coherence measure
in the optimization phase. The results are compa-
rable with the entity graph. However, the entity
graph is less informative and very sparse as com-
pared to the topical graph. Our system does not
need annotated training data and, except for the
number of topics, no optimization of parameters.
Hence, we consider it unsupervised.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999947333333333">
This work has been funded by the Klaus Tschira
Foundation, Heidelberg, Germany. The first au-
thor has been supported by a Heidelberg Insti-
tute for Theoretical Studies Ph.D. scholarship.
This work has been supported by the German Re-
search Foundation as part of the Research Training
Group “Adaptive Preparation of Information from
Heterogeneous Sources” (AIPHES) under grant
No. GRK 1994/1. We would like to thank our
colleagues Sebastian Martschat, Nafise Moosavi,
Alex Judea and Mohsen Mesgar who served as hu-
man subjects and commented on earlier drafts.
</bodyText>
<sectionHeader confidence="0.998947" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9932865">
David M. Blei and John D. Lafferty. 2009. Topic
models. In A. Srivastava and M. Sahami, editors,
Text Mining: Classification, Clustering, and Appli-
cations. Chapman &amp; Hall, Boca Raton, Flo.
</reference>
<page confidence="0.854596">
1953
</page>
<reference confidence="0.994851972222222">
Jaime G. Carbonell and Jade Goldstein. 1998. The use
of MMR, diversity-based reranking for reordering
documents and producing summaries. In Proceed-
ings of the 21st Annual International ACM-SIGIR
Conference on Research and Development in Infor-
mation Retrieval, Melbourne, Australia, 24–28 Au-
gust 1998, pages 335–336.
G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank:
Graph-based lexical centrality as salience in text
summarization. Journal of Artificial Intelligence
Research, 22:457–479.
Philip John Gorinski and Mirella Lapata. 2015. Movie
script summarization as graph-based scene extrac-
tion. In Proceedings of the 2015 Conference of
the North American Chapter of the Association for
Computational Linguistics: Human Language Tech-
nologies, Denver, Col., 31 May – 5 June 2015, pages
1066–1076.
Camille Guinaudeau and Michael Strube. 2013.
Graph-based local coherence modeling. In Proceed-
ings of the 51st Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), Sofia, Bulgaria, 4–9 August 2013, pages 93–
103.
Dan Klein and Christopher D. Manning. 2003. Ac-
curate unlexicalized parsing. In Proceedings of the
41st Annual Meeting of the Association for Com-
putational Linguistics, Sapporo, Japan, 7–12 July
2003, pages 423–430.
Jon M. Kleinberg. 1999. Authoritative sources in
a hyperlinked environment. Journal of the ACM,
46(5):604–632.
Chin-Yew Lin. 2004. ROUGE: A package for auto-
matic evaluation of summaries. In Proceedings of
the Text Summarization Branches Out Workshop at
ACL ’04, Barcelona, Spain, 25–26 July 2004, pages
74–81.
Sebastian Martschat. 2013. Multigraph clustering for
unsupervised coreference resolution. In 51st Annual
Meeting of the Association for Computational Lin-
guistics: Proceedings of the Student Research Work-
shop, Sofia, Bulgaria, 5–7 August 2013, pages 81–
88.
Ryan McDonald. 2007. A study of global inference al-
gorithms in multi-document summarization. In Pro-
ceedings of the European Conference on Informa-
tion Retrieval, Rome, Italy, 2-5 April 2007.
Rada Mihalcea and Paul Tarau. 2004. TextRank:
Bringing order into texts. In Proceedings of the
2004 Conference on Empirical Methods in Natural
Language Processing, Barcelona, Spain, 25–26 July
2004, pages 404–411.
Daraksha Parveen and Michael Strube. 2015. Integrat-
ing importance, non-redundancy and coherence in
graph-based extractive summarization. In Proceed-
ings of the 24th International Joint Conference on
Artificial Intelligence, Buenos Aires, Argentina, 25–
31 July 2015, pages 1298–1304.
Steffen Remus and Chris Biemann. 2013. Three
knowledge-free methods for automatic lexical chain
extraction. In Proceedings of the 2013 Conference
of the North American Chapter of the Association
for Computational Linguistics: Human Language
Technologies, Atlanta, Georgia, 9–14 June 2013,
pages 989–999.
Sidney Siegel and N. John Castellan. 1988. Non-
parametric Statistics for the Behavioral Sciences.
McGraw-Hill, New York, 2nd edition.
Xiaojun Wan and Jianguo Xiao. 2010. Exploiting
neighborhood knowledge for single document sum-
marization and keyphrase extraction. ACM Transac-
tions on Information Systems, 28(2):8 pages.
</reference>
<page confidence="0.996184">
1954
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.231183">
<title confidence="0.640673">Topical Coherence for Graph-based Extractive Summarization Group and Research Training Group Heidelberg Institute for Theoretical Studies</title>
<author confidence="0.298204">Germany Heidelberg</author>
<affiliation confidence="0.68585">SE</affiliation>
<address confidence="0.900116">Walldorf, Germany</address>
<email confidence="0.99995">hans-martin.ramsl@sap.com</email>
<abstract confidence="0.999403133333333">We present an approach for extractive single-document summarization. Our approach is based on a weighted graphical representation of documents obtained by topic modeling. We optimize importance, coherence and non-redundancy simultaneously using ILP. We compare ROUGE scores of our system with state-of-the-art on scientific articles from on DUC 2002 data. Human judges evaluate the coherence of summaries generated by our system in comparision to two baselines. Our approach obtains competitive performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>John D Lafferty</author>
</authors>
<title>Topic models.</title>
<date>2009</date>
<editor>In A. Srivastava and M. Sahami, editors, Text Mining: Classification, Clustering, and Applications.</editor>
<publisher>Chapman &amp; Hall,</publisher>
<location>Boca Raton, Flo.</location>
<contexts>
<context position="1565" citStr="Blei and Lafferty (2009)" startWordPosition="212" endWordPosition="215">nerate a concise document as output. Several summarization variants exist such as generic, query-based, multi-document and single document, but the basic requirements for summarization remain the same. Summaries should contain salient information so that the reader will not miss anything from the original document. Also, the reader is not interested in repetitive information, so summaries should not include redundant information. Finally, summaries should be coherent and of high readability. We introduce a completely unsupervised graphbased summarization using latent drichlet allocation (LDA, Blei and Lafferty (2009)). LDA is a simple model for topic modeling where topic probabilities are assigned words in documents. The probabilities can be used to measure the semantic relatedness between words and hence the topical coherence of a document. We use topical coherence as a means to ensure the coherence of extractive single-document summaries. Remus and Biemann (2013) apply LDA to compute lexical chains while Gorinski and Lapata (2015) also develop a graph-based summarization system which takes coherence into account. Our work is based on the bipartite entity graph introduced by Guinaudeau and Strube (2013).</context>
</contexts>
<marker>Blei, Lafferty, 2009</marker>
<rawString>David M. Blei and John D. Lafferty. 2009. Topic models. In A. Srivastava and M. Sahami, editors, Text Mining: Classification, Clustering, and Applications. Chapman &amp; Hall, Boca Raton, Flo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime G Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The use of MMR, diversity-based reranking for reordering documents and producing summaries.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval,</booktitle>
<pages>335--336</pages>
<location>Melbourne, Australia, 24–28</location>
<contexts>
<context position="12520" citStr="Carbonell and Goldstein, 1998" startWordPosition="2040" endWordPosition="2043">cine are shown in Tables 1 and 2. We evaluate using ROUGE-SU4 and ROUGE-2 (Lin, 2004). We limit the length of the summaries to five sentences and the number of topics to 2000 in the topical graph. We also experimented with varying numbers of topics, i.e. 500, 1000 and 2000, and varying summary length limits. The results changed only marginally. The general trends remained the same. We compare our system with four different baselines and two versions of the entity graph. Lead selects the top five sentences, Random five sentences randomly. MMR is an implementation of maximal marginal relevance (Carbonell and Goldstein, 1998). TextRank is the graph-based system by Mihalcea and Tarau (2004)5. Egraph is the entity graph based system by Parveen and Strube (2015). Egraph + Coh. is their system 2http://www.smartschat.de/software/ 3http://www.datawrangling.com/ some-datasets-available-on-the-web/ 4We use Gurobi, http://www.gurobi.com 5https://kenai.com/projects/ textsummarizer Systems R-SU4 R-2 Lead 0.067 0.055 Random 0.048 0.031 MMR 0.069 0.048 TextRank 0.068 0.048 Egraph 0.121 0.090 Egraph + Coh. 0.130 0.096 Egraph + Coh. + Pos. 0.131 0.098 Tgraph (n=2000) 0.123 0.091 Tgraph (n=2000) + Coh. 0.129 0.095 Tgraph (n=2000)</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime G. Carbonell and Jade Goldstein. 1998. The use of MMR, diversity-based reranking for reordering documents and producing summaries. In Proceedings of the 21st Annual International ACM-SIGIR Conference on Research and Development in Information Retrieval, Melbourne, Australia, 24–28 August 1998, pages 335–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes¸ Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graph-based lexical centrality as salience in text summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>22--457</pages>
<contexts>
<context position="3455" citStr="Erkan and Radev, 2004" startWordPosition="515" endWordPosition="518">using the entity graph and significantly better than several baselines and the graph-based system TextRank (Mihalcea and Tarau, 2004). We use the DUC 2002 dataset to compare our results with state-of-the-art techniques. In contrast to the PLOS Medicine data the DUC 2002 dataset contains very small articles. Still, our technique gives comparable results to the state-of-the-art. This shows that our technique is flexible and scalable despite being unsupervised. 2 Our Method 2.1 Document Representation A graph-based representation has been used by well known summarization systems such as LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004). The graph used by both is of one mode type where sentences are nodes which are connected by weighted edges. 1http://journals.plos.org/ plosmedicine/ 1949 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1949–1954, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Weights express sentence similarity. We use a bipartite graph representation of documents (Figure 1). The bipartite graph, G = (Vs, Vt, Et,s), has two sets of nodes where Vs represents sentences and Vt topics.</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank: Graph-based lexical centrality as salience in text summarization. Journal of Artificial Intelligence Research, 22:457–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip John Gorinski</author>
<author>Mirella Lapata</author>
</authors>
<title>Movie script summarization as graph-based scene extraction.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver, Col., 31 May – 5</booktitle>
<pages>1066--1076</pages>
<contexts>
<context position="1989" citStr="Gorinski and Lapata (2015)" startWordPosition="281" endWordPosition="284">nformation. Finally, summaries should be coherent and of high readability. We introduce a completely unsupervised graphbased summarization using latent drichlet allocation (LDA, Blei and Lafferty (2009)). LDA is a simple model for topic modeling where topic probabilities are assigned words in documents. The probabilities can be used to measure the semantic relatedness between words and hence the topical coherence of a document. We use topical coherence as a means to ensure the coherence of extractive single-document summaries. Remus and Biemann (2013) apply LDA to compute lexical chains while Gorinski and Lapata (2015) also develop a graph-based summarization system which takes coherence into account. Our work is based on the bipartite entity graph introduced by Guinaudeau and Strube (2013). However, in their graph one set of nodes corresponds to entities whereas in our graph it corresponds to topics. The entity graph has already been used by Parveen and Strube (2015) for summarization. Their graph is unweighted and sparse, whereas our topical graph is weighted and dense. We apply our topical graph on the dataset introduced by Parveen and Strube (2015). This dataset contains scientific articles from the jou</context>
</contexts>
<marker>Gorinski, Lapata, 2015</marker>
<rawString>Philip John Gorinski and Mirella Lapata. 2015. Movie script summarization as graph-based scene extraction. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Denver, Col., 31 May – 5 June 2015, pages 1066–1076.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Camille Guinaudeau</author>
<author>Michael Strube</author>
</authors>
<title>Graph-based local coherence modeling.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>93--103</pages>
<location>Sofia, Bulgaria, 4–9</location>
<contexts>
<context position="2164" citStr="Guinaudeau and Strube (2013)" startWordPosition="307" endWordPosition="310">LDA, Blei and Lafferty (2009)). LDA is a simple model for topic modeling where topic probabilities are assigned words in documents. The probabilities can be used to measure the semantic relatedness between words and hence the topical coherence of a document. We use topical coherence as a means to ensure the coherence of extractive single-document summaries. Remus and Biemann (2013) apply LDA to compute lexical chains while Gorinski and Lapata (2015) also develop a graph-based summarization system which takes coherence into account. Our work is based on the bipartite entity graph introduced by Guinaudeau and Strube (2013). However, in their graph one set of nodes corresponds to entities whereas in our graph it corresponds to topics. The entity graph has already been used by Parveen and Strube (2015) for summarization. Their graph is unweighted and sparse, whereas our topical graph is weighted and dense. We apply our topical graph on the dataset introduced by Parveen and Strube (2015). This dataset contains scientific articles from the journal PLOS Medicine1. Every PLOS Medicine article is accompanied by an editor’s summary and an authors’ abstract. We use both as gold summaries for evaluation. Results obtained</context>
<context position="5388" citStr="Guinaudeau and Strube (2013)" startWordPosition="836" endWordPosition="839">for ranking sentences by importance, since our graph is a bipartite graph. It puts nodes of a graph in two sets: hub nodes and authority nodes. For the HITS algorithm the rank of nodes needs to be initialized. We initialize the topic rank Rankti = 1 and the sentence rank Ranksi = 1+sim(si, title). The title in the sentence rank is the title of the article. sim(si, title) is the cosine similarity between the sentence si and the title of the article. After initialization of all nodes in the weighted topical graph, the HITS algorithm is applied to obtain ranks of sentences. 2.3 Coherence Measure Guinaudeau and Strube (2013) represent a document by the entity graph, a bipartite graph consisting of sentence and entity nodes. They perform a one-mode projection on sentence nodes, compute the coherence of a document on the basis of the one-mode projections and use the coherence measure for summary coherence rating. Building upon this work, Parveen and Strube (2015) integrate this coherence measure to directly generate coherent summaries. Instead of the entity graph we here use the topical graph to incorporate the coherence measure. Parveen and Strube (2015) use an unweighted projection graph whereas we use a weighted</context>
</contexts>
<marker>Guinaudeau, Strube, 2013</marker>
<rawString>Camille Guinaudeau and Michael Strube. 2013. Graph-based local coherence modeling. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), Sofia, Bulgaria, 4–9 August 2013, pages 93– 103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate unlexicalized parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<location>Sapporo,</location>
<contexts>
<context position="11207" citStr="Klein and Manning, 2003" startWordPosition="1829" endWordPosition="1833">s independently. To compare with the state-of-the-art in single-document summarization, we also evaluate on DUC 2002 data. 1951 3.2 Experimental Setup We use the XML version of PLOS Medicine articles. We extract the contents excluding figures, tables and references. Editor’s summary and authors’ abstract are separated from the content for evaluation. The PLOS Medicine XML provides explicit full forms when abbreviations are introduced. We replace abbreviations with their full form in the summary. We then remove nonalphabetical characters. After this we parse articles using the Stanford parser (Klein and Manning, 2003). We perform pronoun resolution using the coreference resolution system by Martschat (2013)2. We use gensim to generate the topics. For generating topics we use a dataset containing scientific articles from biology, which contains 221,385 documents and about 50 million sentences3. We also use Wikipedia to compare with topics from a general domain. The HITS algorithm is applied on the bipartite graph for computing sentence importance. We calculate the coherence values of sentences on weighted one-mode projection graphs. The importance and coherence of a sentence is used in the optimization phas</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003. Accurate unlexicalized parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, Sapporo, Japan, 7–12 July 2003, pages 423–430.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon M Kleinberg</author>
</authors>
<title>Authoritative sources in a hyperlinked environment.</title>
<date>1999</date>
<journal>Journal of the ACM,</journal>
<volume>46</volume>
<issue>5</issue>
<contexts>
<context position="4749" citStr="Kleinberg, 1999" startWordPosition="727" endWordPosition="728"> is present in a topic t. If multiple words are present in topic t of sentence s, then the edge weight is the logarithmic sum of probabilities of words in topic t. We normalize the edge weight by dividing them by the length of the sentence. Hence long sentences will not benefit from their lengths. We call the resulting graph topical graph. 2.2 Sentence Ranking The final summary should contain only important sentences. Therefore, we give a score to every sentence in a document to obtain important sentences. Following Parveen and Strube (2015) we apply the HITS (Hyperlink Induced Topic Search) (Kleinberg, 1999) algorithm for ranking sentences by importance, since our graph is a bipartite graph. It puts nodes of a graph in two sets: hub nodes and authority nodes. For the HITS algorithm the rank of nodes needs to be initialized. We initialize the topic rank Rankti = 1 and the sentence rank Ranksi = 1+sim(si, title). The title in the sentence rank is the title of the article. sim(si, title) is the cosine similarity between the sentence si and the title of the article. After initialization of all nodes in the weighted topical graph, the HITS algorithm is applied to obtain ranks of sentences. 2.3 Coheren</context>
</contexts>
<marker>Kleinberg, 1999</marker>
<rawString>Jon M. Kleinberg. 1999. Authoritative sources in a hyperlinked environment. Journal of the ACM, 46(5):604–632.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>ROUGE: A package for automatic evaluation of summaries.</title>
<date>2004</date>
<booktitle>In Proceedings of the Text Summarization Branches Out Workshop at ACL ’04,</booktitle>
<pages>74--81</pages>
<location>Barcelona,</location>
<contexts>
<context position="11975" citStr="Lin, 2004" startWordPosition="1955" endWordPosition="1956">se a dataset containing scientific articles from biology, which contains 221,385 documents and about 50 million sentences3. We also use Wikipedia to compare with topics from a general domain. The HITS algorithm is applied on the bipartite graph for computing sentence importance. We calculate the coherence values of sentences on weighted one-mode projection graphs. The importance and coherence of a sentence is used in the optimization phase4 which returns a binary value for each sentence. 3.3 Results Results on PLOS Medicine are shown in Tables 1 and 2. We evaluate using ROUGE-SU4 and ROUGE-2 (Lin, 2004). We limit the length of the summaries to five sentences and the number of topics to 2000 in the topical graph. We also experimented with varying numbers of topics, i.e. 500, 1000 and 2000, and varying summary length limits. The results changed only marginally. The general trends remained the same. We compare our system with four different baselines and two versions of the entity graph. Lead selects the top five sentences, Random five sentences randomly. MMR is an implementation of maximal marginal relevance (Carbonell and Goldstein, 1998). TextRank is the graph-based system by Mihalcea and Ta</context>
</contexts>
<marker>Lin, 2004</marker>
<rawString>Chin-Yew Lin. 2004. ROUGE: A package for automatic evaluation of summaries. In Proceedings of the Text Summarization Branches Out Workshop at ACL ’04, Barcelona, Spain, 25–26 July 2004, pages 74–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Martschat</author>
</authors>
<title>Multigraph clustering for unsupervised coreference resolution.</title>
<date>2013</date>
<booktitle>In 51st Annual Meeting of the Association for Computational Linguistics: Proceedings of the Student Research Workshop,</booktitle>
<pages>81--88</pages>
<location>Sofia, Bulgaria, 5–7</location>
<contexts>
<context position="11298" citStr="Martschat (2013)" startWordPosition="1844" endWordPosition="1845">luate on DUC 2002 data. 1951 3.2 Experimental Setup We use the XML version of PLOS Medicine articles. We extract the contents excluding figures, tables and references. Editor’s summary and authors’ abstract are separated from the content for evaluation. The PLOS Medicine XML provides explicit full forms when abbreviations are introduced. We replace abbreviations with their full form in the summary. We then remove nonalphabetical characters. After this we parse articles using the Stanford parser (Klein and Manning, 2003). We perform pronoun resolution using the coreference resolution system by Martschat (2013)2. We use gensim to generate the topics. For generating topics we use a dataset containing scientific articles from biology, which contains 221,385 documents and about 50 million sentences3. We also use Wikipedia to compare with topics from a general domain. The HITS algorithm is applied on the bipartite graph for computing sentence importance. We calculate the coherence values of sentences on weighted one-mode projection graphs. The importance and coherence of a sentence is used in the optimization phase4 which returns a binary value for each sentence. 3.3 Results Results on PLOS Medicine are</context>
</contexts>
<marker>Martschat, 2013</marker>
<rawString>Sebastian Martschat. 2013. Multigraph clustering for unsupervised coreference resolution. In 51st Annual Meeting of the Association for Computational Linguistics: Proceedings of the Student Research Workshop, Sofia, Bulgaria, 5–7 August 2013, pages 81– 88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
</authors>
<title>A study of global inference algorithms in multi-document summarization.</title>
<date>2007</date>
<booktitle>In Proceedings of the European Conference on Information Retrieval,</booktitle>
<location>Rome,</location>
<contexts>
<context position="6594" citStr="McDonald (2007)" startWordPosition="1034" endWordPosition="1035"> weighted projection graph of a topical graph to compute the coherence. The weighted one mode projection of the topical graph is shown in Figure 1, bottom right. weighted coh(si, P) = weighted Outdegree(si, P) weighted coh(si, P) norm weighted coh(si, P) = weighted coh(si, P) Equation 1 calculates the outdegree of every sentence from the weighted projection graph. However weighted coh(si, P) in Equation 1 is not a normalized value. The normalized coherence value is in Equation 2. Afterwards, we use this coherence value in the optimization phase for the selection of sentences. 2.4 Optimization McDonald (2007) introduces summarization as an optimization task which takes care of importance, redundancy and coherence simultaneously. In this paper, we also propose a model for single document summarization which is based on integer linear programming (ILP). We consider ranks obtained by the HITS algorithm as sentence importance. The weighted coherence measure is calculated using Equation 1 and Equation 2. PLOS Medicine articles are very long and contain repetitive information, so we have to deal with redundancy even in single-document summarization. Therefore we model non-redundancy as topic coverage in</context>
</contexts>
<marker>McDonald, 2007</marker>
<rawString>Ryan McDonald. 2007. A study of global inference algorithms in multi-document summarization. In Proceedings of the European Conference on Information Retrieval, Rome, Italy, 2-5 April 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>TextRank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>404--411</pages>
<location>Barcelona,</location>
<contexts>
<context position="2966" citStr="Mihalcea and Tarau, 2004" startWordPosition="441" endWordPosition="444">015) for summarization. Their graph is unweighted and sparse, whereas our topical graph is weighted and dense. We apply our topical graph on the dataset introduced by Parveen and Strube (2015). This dataset contains scientific articles from the journal PLOS Medicine1. Every PLOS Medicine article is accompanied by an editor’s summary and an authors’ abstract. We use both as gold summaries for evaluation. Results obtained on the PLOS Medicine dataset using the topical graph are as good as using the entity graph and significantly better than several baselines and the graph-based system TextRank (Mihalcea and Tarau, 2004). We use the DUC 2002 dataset to compare our results with state-of-the-art techniques. In contrast to the PLOS Medicine data the DUC 2002 dataset contains very small articles. Still, our technique gives comparable results to the state-of-the-art. This shows that our technique is flexible and scalable despite being unsupervised. 2 Our Method 2.1 Document Representation A graph-based representation has been used by well known summarization systems such as LexRank (Erkan and Radev, 2004) and TextRank (Mihalcea and Tarau, 2004). The graph used by both is of one mode type where sentences are nodes </context>
<context position="12585" citStr="Mihalcea and Tarau (2004)" startWordPosition="2050" endWordPosition="2053">E-2 (Lin, 2004). We limit the length of the summaries to five sentences and the number of topics to 2000 in the topical graph. We also experimented with varying numbers of topics, i.e. 500, 1000 and 2000, and varying summary length limits. The results changed only marginally. The general trends remained the same. We compare our system with four different baselines and two versions of the entity graph. Lead selects the top five sentences, Random five sentences randomly. MMR is an implementation of maximal marginal relevance (Carbonell and Goldstein, 1998). TextRank is the graph-based system by Mihalcea and Tarau (2004)5. Egraph is the entity graph based system by Parveen and Strube (2015). Egraph + Coh. is their system 2http://www.smartschat.de/software/ 3http://www.datawrangling.com/ some-datasets-available-on-the-web/ 4We use Gurobi, http://www.gurobi.com 5https://kenai.com/projects/ textsummarizer Systems R-SU4 R-2 Lead 0.067 0.055 Random 0.048 0.031 MMR 0.069 0.048 TextRank 0.068 0.048 Egraph 0.121 0.090 Egraph + Coh. 0.130 0.096 Egraph + Coh. + Pos. 0.131 0.098 Tgraph (n=2000) 0.123 0.091 Tgraph (n=2000) + Coh. 0.129 0.095 Tgraph (n=2000) + Coh. + Pos. 0.125 0.092 Table 1: PLOS Medicine, editor’s summa</context>
<context position="15593" citStr="Mihalcea and Tarau, 2004" startWordPosition="2523" endWordPosition="2526">00) + Coh. 0.291 0.095 0.129 Table 3: PLOS Medicine, editor’s summ., Bio topic Topics R-1 R-2 R-SU4 Tgraph (n=500) + Coh. 0.208 0.060 0.098 Tgraph (n=1000) + Coh. 0.258 0.073 0.106 Tgraph (n=2000) + Coh. 0.283 0.086 0.121 Table 4: PLOS Medicine, editor’s summ., Wiki topic check against the state-of-the-art on a well-known dataset. Lead performs well on DUC 2002 as shown in Table 5, because important information appears in the initial lines of news articles. DUC 2002 Best is the result reported by the top performing system at DUC 2002. This system actually obtains better results than TextRank (Mihalcea and Tarau, 2004) and the more recent system UniformLink (Wan and Xiao, 2010). Our system Tgraph + Coh. performs better than the well known best systems on DUC 2002 and slightly better than Egraph + Coh. However the difference between the results of Tgraph and Egraph are not significant. In contrast to the entity graph based system, the coherence measure in our system is calculated by using a topic-based weighted projection graph, which is denser and hence more informative. 3.4 Human Coherence Judgements In addition to ROUGE scores, we use human judgements for evaluating the coherence of our summaries. We aske</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. TextRank: Bringing order into texts. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, Barcelona, Spain, 25–26 July 2004, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daraksha Parveen</author>
<author>Michael Strube</author>
</authors>
<title>Integrating importance, non-redundancy and coherence in graph-based extractive summarization.</title>
<date>2015</date>
<booktitle>In Proceedings of the 24th International Joint Conference on Artificial Intelligence, Buenos Aires, Argentina, 25– 31</booktitle>
<pages>1298--1304</pages>
<contexts>
<context position="2345" citStr="Parveen and Strube (2015)" startWordPosition="340" endWordPosition="343">c relatedness between words and hence the topical coherence of a document. We use topical coherence as a means to ensure the coherence of extractive single-document summaries. Remus and Biemann (2013) apply LDA to compute lexical chains while Gorinski and Lapata (2015) also develop a graph-based summarization system which takes coherence into account. Our work is based on the bipartite entity graph introduced by Guinaudeau and Strube (2013). However, in their graph one set of nodes corresponds to entities whereas in our graph it corresponds to topics. The entity graph has already been used by Parveen and Strube (2015) for summarization. Their graph is unweighted and sparse, whereas our topical graph is weighted and dense. We apply our topical graph on the dataset introduced by Parveen and Strube (2015). This dataset contains scientific articles from the journal PLOS Medicine1. Every PLOS Medicine article is accompanied by an editor’s summary and an authors’ abstract. We use both as gold summaries for evaluation. Results obtained on the PLOS Medicine dataset using the topical graph are as good as using the entity graph and significantly better than several baselines and the graph-based system TextRank (Miha</context>
<context position="4680" citStr="Parveen and Strube (2015)" startWordPosition="715" endWordPosition="718"> The two sets of nodes are connected with edge Et,s, if a word in a sentence s is present in a topic t. If multiple words are present in topic t of sentence s, then the edge weight is the logarithmic sum of probabilities of words in topic t. We normalize the edge weight by dividing them by the length of the sentence. Hence long sentences will not benefit from their lengths. We call the resulting graph topical graph. 2.2 Sentence Ranking The final summary should contain only important sentences. Therefore, we give a score to every sentence in a document to obtain important sentences. Following Parveen and Strube (2015) we apply the HITS (Hyperlink Induced Topic Search) (Kleinberg, 1999) algorithm for ranking sentences by importance, since our graph is a bipartite graph. It puts nodes of a graph in two sets: hub nodes and authority nodes. For the HITS algorithm the rank of nodes needs to be initialized. We initialize the topic rank Rankti = 1 and the sentence rank Ranksi = 1+sim(si, title). The title in the sentence rank is the title of the article. sim(si, title) is the cosine similarity between the sentence si and the title of the article. After initialization of all nodes in the weighted topical graph, th</context>
<context position="5927" citStr="Parveen and Strube (2015)" startWordPosition="924" endWordPosition="927">plied to obtain ranks of sentences. 2.3 Coherence Measure Guinaudeau and Strube (2013) represent a document by the entity graph, a bipartite graph consisting of sentence and entity nodes. They perform a one-mode projection on sentence nodes, compute the coherence of a document on the basis of the one-mode projections and use the coherence measure for summary coherence rating. Building upon this work, Parveen and Strube (2015) integrate this coherence measure to directly generate coherent summaries. Instead of the entity graph we here use the topical graph to incorporate the coherence measure. Parveen and Strube (2015) use an unweighted projection graph whereas we use a weighted projection graph of a topical graph to compute the coherence. The weighted one mode projection of the topical graph is shown in Figure 1, bottom right. weighted coh(si, P) = weighted Outdegree(si, P) weighted coh(si, P) norm weighted coh(si, P) = weighted coh(si, P) Equation 1 calculates the outdegree of every sentence from the weighted projection graph. However weighted coh(si, P) in Equation 1 is not a normalized value. The normalized coherence value is in Equation 2. Afterwards, we use this coherence value in the optimization pha</context>
<context position="9816" citStr="Parveen and Strube (2015)" startWordPosition="1605" endWordPosition="1608">lected. Therefore, xi = 1 and Ti = Topicsxi. The constraint holds, because E yj = |Topicsxi|. FurjETi thermore, if sentence xi = 0, i.e., it is not selected, then there must be topics which are already present in selected sentences. Hence, the constraint holds, E yj &gt; 0. jETi Equation 7 constrains the selection of topics. If topic yj = 1, then at least one sentence containing this topic has been selected. Therefore E xi &gt; 1, iESj and the constraint holds. If topic yj = 0, then sentences containing this topic are not selected, so E xi = 0, and the constraint holds. iESj 3 Experiments Following Parveen and Strube (2015), we evaluate on the science genre, i.e. PLOS Medicine articles, and on the news genre, i.e. DUC 2002 data. 3.1 Datasets PLOS Medicine articles are considerably longer than DUC 2002 documents. The average number of sentences per document is 154 in PLOS Medicine and 25 in DUC 2002. Benefits of using PLOS Medicine articles for experiments are: • They are accompanied by an authors’ abstract. • They have a summary written by an editor. • They are formatted in XML. • They contain explicit full forms of abbreviations. Editor’s summaries have a different perspective, writing style and length than aut</context>
<context position="12656" citStr="Parveen and Strube (2015)" startWordPosition="2062" endWordPosition="2065"> and the number of topics to 2000 in the topical graph. We also experimented with varying numbers of topics, i.e. 500, 1000 and 2000, and varying summary length limits. The results changed only marginally. The general trends remained the same. We compare our system with four different baselines and two versions of the entity graph. Lead selects the top five sentences, Random five sentences randomly. MMR is an implementation of maximal marginal relevance (Carbonell and Goldstein, 1998). TextRank is the graph-based system by Mihalcea and Tarau (2004)5. Egraph is the entity graph based system by Parveen and Strube (2015). Egraph + Coh. is their system 2http://www.smartschat.de/software/ 3http://www.datawrangling.com/ some-datasets-available-on-the-web/ 4We use Gurobi, http://www.gurobi.com 5https://kenai.com/projects/ textsummarizer Systems R-SU4 R-2 Lead 0.067 0.055 Random 0.048 0.031 MMR 0.069 0.048 TextRank 0.068 0.048 Egraph 0.121 0.090 Egraph + Coh. 0.130 0.096 Egraph + Coh. + Pos. 0.131 0.098 Tgraph (n=2000) 0.123 0.091 Tgraph (n=2000) + Coh. 0.129 0.095 Tgraph (n=2000) + Coh. + Pos. 0.125 0.092 Table 1: PLOS Medicine, editor’s summaries Systems R-SU4 R-2 Lead 0.105 0.077 Random 0.093 0.589 MMR 0.118 0.</context>
</contexts>
<marker>Parveen, Strube, 2015</marker>
<rawString>Daraksha Parveen and Michael Strube. 2015. Integrating importance, non-redundancy and coherence in graph-based extractive summarization. In Proceedings of the 24th International Joint Conference on Artificial Intelligence, Buenos Aires, Argentina, 25– 31 July 2015, pages 1298–1304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steffen Remus</author>
<author>Chris Biemann</author>
</authors>
<title>Three knowledge-free methods for automatic lexical chain extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>989--999</pages>
<location>Atlanta, Georgia, 9–14</location>
<contexts>
<context position="1920" citStr="Remus and Biemann (2013)" startWordPosition="269" endWordPosition="273">repetitive information, so summaries should not include redundant information. Finally, summaries should be coherent and of high readability. We introduce a completely unsupervised graphbased summarization using latent drichlet allocation (LDA, Blei and Lafferty (2009)). LDA is a simple model for topic modeling where topic probabilities are assigned words in documents. The probabilities can be used to measure the semantic relatedness between words and hence the topical coherence of a document. We use topical coherence as a means to ensure the coherence of extractive single-document summaries. Remus and Biemann (2013) apply LDA to compute lexical chains while Gorinski and Lapata (2015) also develop a graph-based summarization system which takes coherence into account. Our work is based on the bipartite entity graph introduced by Guinaudeau and Strube (2013). However, in their graph one set of nodes corresponds to entities whereas in our graph it corresponds to topics. The entity graph has already been used by Parveen and Strube (2015) for summarization. Their graph is unweighted and sparse, whereas our topical graph is weighted and dense. We apply our topical graph on the dataset introduced by Parveen and </context>
</contexts>
<marker>Remus, Biemann, 2013</marker>
<rawString>Steffen Remus and Chris Biemann. 2013. Three knowledge-free methods for automatic lexical chain extraction. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Atlanta, Georgia, 9–14 June 2013, pages 989–999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sidney Siegel</author>
<author>N John Castellan</author>
</authors>
<title>Nonparametric Statistics for the Behavioral Sciences.</title>
<date>1988</date>
<publisher>McGraw-Hill,</publisher>
<location>New York,</location>
<note>2nd edition.</note>
<contexts>
<context position="16935" citStr="Siegel and Castellan, 1988" startWordPosition="2746" endWordPosition="2749"> selected ten summaries of scientific articles from three different systems, TextRank, Lead and Tgraph + Coh. We asked the human judges to rank the summaries according to their coherence. So, the summary Systems R-1 R-2 R-SU4 Lead 0.459 0.180 0.201 DUC 2002 Best 0.480 0.228 TextRank 0.470 0.195 0.217 UniformLink (k = 10) 0.471 0.201 Egraph + Coh. 0.479 0.238 0.230 Tgraph (n=2000) + Coh. 0.481 0.243 0.242 Table 5: DUC 2002, single-document summarization which is best in coherence gets rank 1, second best gets rank 2, and worst gets rank 3. We calculated the Kendall concordance coefficient (W) (Siegel and Castellan, 1988) to measure the judges’ agreement. We obtain W = 0.61, which indicates a relatively high agreement. To compare the three systems, we take the average over the ranks. The overall rank of TextRank is 2.625, Lead is 1.675 and Tgraph + Coh. is 1.8. Lead performs best, because it selects the top five consecutive sentences, which are coherent as the original authors intended them to be. However, the overall ranks of Lead and Tgraph + Coh. are not significantly different, whereas TextRank’s overall rank is significantly worse than both. Hence, Tgraph + Coh. performs very well in our human judgement c</context>
</contexts>
<marker>Siegel, Castellan, 1988</marker>
<rawString>Sidney Siegel and N. John Castellan. 1988. Nonparametric Statistics for the Behavioral Sciences. McGraw-Hill, New York, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<title>Exploiting neighborhood knowledge for single document summarization and keyphrase extraction.</title>
<date>2010</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>28</volume>
<issue>2</issue>
<pages>pages.</pages>
<contexts>
<context position="15653" citStr="Wan and Xiao, 2010" startWordPosition="2534" endWordPosition="2537">., Bio topic Topics R-1 R-2 R-SU4 Tgraph (n=500) + Coh. 0.208 0.060 0.098 Tgraph (n=1000) + Coh. 0.258 0.073 0.106 Tgraph (n=2000) + Coh. 0.283 0.086 0.121 Table 4: PLOS Medicine, editor’s summ., Wiki topic check against the state-of-the-art on a well-known dataset. Lead performs well on DUC 2002 as shown in Table 5, because important information appears in the initial lines of news articles. DUC 2002 Best is the result reported by the top performing system at DUC 2002. This system actually obtains better results than TextRank (Mihalcea and Tarau, 2004) and the more recent system UniformLink (Wan and Xiao, 2010). Our system Tgraph + Coh. performs better than the well known best systems on DUC 2002 and slightly better than Egraph + Coh. However the difference between the results of Tgraph and Egraph are not significant. In contrast to the entity graph based system, the coherence measure in our system is calculated by using a topic-based weighted projection graph, which is denser and hence more informative. 3.4 Human Coherence Judgements In addition to ROUGE scores, we use human judgements for evaluating the coherence of our summaries. We asked four PhD students in natural language processing to evalua</context>
</contexts>
<marker>Wan, Xiao, 2010</marker>
<rawString>Xiaojun Wan and Jianguo Xiao. 2010. Exploiting neighborhood knowledge for single document summarization and keyphrase extraction. ACM Transactions on Information Systems, 28(2):8 pages.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>