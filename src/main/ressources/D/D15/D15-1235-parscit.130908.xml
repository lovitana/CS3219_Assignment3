<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003628">
<title confidence="0.939346">
EMNLP versus ACL: Analyzing NLP Research Over Time
</title>
<author confidence="0.98917">
Sujatha Das Gollapalli, Xiao-Li Li
</author>
<affiliation confidence="0.986183">
Institute for Infocomm Research, A*STAR, Singapore
</affiliation>
<email confidence="0.989874">
{gollapallis,xlli}@i2r.a-star.edu.sg
</email>
<sectionHeader confidence="0.997279" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999733105263158">
The conferences ACL (Association for
Computational Linguistics) and EMNLP
(Empirical Methods in Natural Language
Processing) rank among the premier
venues that track the research develop-
ments in Natural Language Processing and
Computational Linguistics. In this paper,
we present a study on the research pa-
pers of approximately two decades from
these two NLP conferences. We apply
keyphrase extraction and corpus analysis
tools to the proceedings from these venues
and propose probabilistic and vector-based
representations to represent the topics
published in a venue for a given year.
Next, similarity metrics are studied over
pairs of venue representations to capture
the progress of the two venues with respect
to each other and over time.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.942352916666667">
Scientific findings in a subject-area are typically
published in conferences, journals, patents, and
books in that domain. These research docu-
ments constitute valuable resources from the per-
spective of data mining applications. For in-
stance, the citation links among research docu-
ments are used in computing bibliometric quan-
tities for authors (Alonso et al., 2009) whereas
topic models on research corpora are used to
distinguish between influential and impactful re-
searchers (Kataria et al., 2011) and to capture tem-
poral topic trends (He et al., 2009).
Despite several potential benefits mentioned
above and the free availability of most research
proceedings in NLP through the ACL Anthology1,
the topical and temporal aspects of this corpus are
yet to be fully studied in current literature. In this
paper, we present our study on research proceed-
ings of approximately two decades from two lead-
ing NLP conferences, namely ACL and EMNLP,
to complement a previous study on this topic by
Hall et al (2008). To the best of our knowledge,
we are the first to characterize the developments
in the NLP domain using a comparative study of
two of its leading publication venues. Our contri-
butions are summarized below:
1. We represent the NLP research corpus from
approximately two decades as a keyphrase-
document matrix and apply Latent Dirichlet
Allocation (Blei et al., 2003) to extract co-
herent topics from it (Newman et al., 2010).
2. We propose two novel representations for
summarizing the venue proceedings in a
given year. (1) The probabilistic represen-
tation expresses each venue as a probability
distribution over topics, whereas (2) the TP-
ICP representation captures topics that are
the major focus in the venue for a particu-
lar year via Topic Proportion (TP) as well
as topic importance as measured with inverse
corpus proportion (ICP).
3. We apply Jensen-Shannon divergence and
cosine similarity on our proposed venue rep-
resentations to analyze the venues over time.
Specifically, we ask the following questions:
What are the popular topics in ACL and
EMNLP in a particular year? Is the topical
focus in EMNLP different from ACL? How
</bodyText>
<footnote confidence="0.992594">
1https://aclweb.org/anthology/
</footnote>
<page confidence="0.93099">
2002
</page>
<note confidence="0.671249">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2002–2006,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999276111111111">
did the topical focus in each venue change
over time?
Organization: We describe our novel venue rep-
resentations and the measures used to compare
them in Section 2. The details of our datasets and
experiments are presented in Section 3 along with
results and observations. We summarize related
research in Section 4 before concluding the paper
in Section 5.
</bodyText>
<sectionHeader confidence="0.994597" genericHeader="introduction">
2 Methods
</sectionHeader>
<bodyText confidence="0.998963111111111">
Let Y = {y1, y2 ... yT} be the consecutive years
in which the research proceedings are available
from V , set of publication venues under consider-
ation (V = {“ACL”, “EMNLP”} in this paper). If
D is the set of all documents over the years, each
document d E D is associated with {Kd, y, v}
where Kd refers to the content of d whereas v and
y refer to the venue and year in which d was pub-
lished.
</bodyText>
<subsectionHeader confidence="0.993533">
2.1 Venues as Probability Distributions
</subsectionHeader>
<bodyText confidence="0.99962025">
Let t1, t2 ... tk denote the topics capturing the
content of documents in D. Using probabilis-
tic topic modeling and dimension reduction tools
such as Latent Dirichlet Allocation or pLSA (Hof-
mann, 1999; Blei et al., 2003), we extract for each
d E D, P(ti|d), i = 1... k, the multinomial dis-
tribution over the topics associated with d.
The venue-topic probability distribution
P(ti|vy) for a given (venue, year) pair
(v = l, y = m) can be computed using
Dl,m, the set of documents published in venue l,
in the year m. That is,
</bodyText>
<equation confidence="0.972335666666667">
1
Pl,m(ti) =
|
</equation>
<bodyText confidence="0.9989975">
Note that the above probabilistic representation
facilitates a quantitative measure to compare
two venues: the divergence between the prob-
ability distributions of the two venues. The
Kullback−Leibler divergence (KLD) between two
(discrete) probability distributions P and Q is
</bodyText>
<equation confidence="0.714514875">
given by: DKL(P||Q) = P
i
to the unsymmetric nature of KLD, we use the
Jensen-Shannon divergence, a symmetric and fi-
nite measure (0 &lt; JSD(P||Q) &lt; 1) based on
KLD. Let M = 12(P + Q),
1
JSD(P||Q) = 2[DKL(P||M) + DKL(Q||M)]
</equation>
<subsectionHeader confidence="0.985699">
2.2 Venues as TP-ICP Vectors
</subsectionHeader>
<bodyText confidence="0.9999127">
Discrete probability distributions are often repre-
sented in computations as normalized vectors. For
instance, the P(ti|v) values comprise the compo-
nents of a k-dimensional vector. This topic pro-
portion (TP) vector is similar to the normalized
term frequency vector commonly used in Infor-
mation Retrieval (IR) (Manning et al., 2008). TP
values are fractions indicating the percentage of a
given topic among all topics covered in a partic-
ular year. Thus these values are higher for topics
that are the major focus in the venue for a particu-
lar year .
We also extend inverse document frequency, a
popular concept that is used to weigh terms in
IR (Manning et al., 2008) to describe Inverse Cor-
pus Proportion or ICP. Our objective in defin-
ing ICP is to capture the importance of a topic
by diminishing the effect of topics that are com-
mon across all years. Let TPv,y(i) represents the
proportion of topic ti in venue v for year y, then
</bodyText>
<equation confidence="0.9187655">
ICP(ti) =
k
since P TP(j) = 1, TP being a probability dis-
j=1
</equation>
<bodyText confidence="0.9982199">
tribution vector and |Y  |x |V  |= |D|. The TP-
ICP vector for a venue is defined as: [TP(1) x
ICP(1), ... TP(k) x ICP(k)] and captures in
each component the weighted proportion of a topic
in that venue for a year. This novel represen-
tation can be considered the topic-level counter-
part of the popular TF-IDF representation in IR.
Given two TP-ICP vectors P = [p1, p2, ... pk] and
Q = [q1, q2, . . . qk], the similarity between them
using the cosine measure is given by:
</bodyText>
<equation confidence="0.429046">
cosine(P, Q) =
</equation>
<subsectionHeader confidence="0.910295">
2.3 Keyphrases for representing documents
</subsectionHeader>
<bodyText confidence="0.9999586">
Corpus analysis tools often use bag-of-words
models and term frequencies for representing doc-
uments (Heinrich, 2005). However, research doc-
uments are often well-structured, and contain var-
ious sections with author information, citations,
</bodyText>
<equation confidence="0.993323321428572">
�log
P|Y |
y=1
P|Y |
y=1
P|V |
v=1
P|V |
v=1
k
P
j=1
) = (|Y  ||V |
D|
TPv y (i) P PT
y=1v=1
TPv,y(j)
�
Pv,y(i)
X
Dl,m |P(ti |d) (1)
d∈Dl,,
P(i)log P (i)
Q(i). Due
k
P pi.qi
i=1
||P||2.||Q||2
</equation>
<page confidence="0.936014">
2003
</page>
<table confidence="0.999287727272727">
Topic ID Top Words
0 System, Dialogue, Dialogue System, Information, Speech Recognition, Speech, Dialogue Manager, Data Collection, User Utterances
1 Model, Training Data, Language Model, Model Parameters, Models, Generative Model, Probabilistic Model
2 Noun Phrases, Other Hand, Head Noun, Future Work, Corpus, Sentence, Language, Method, Japanese Language, Syntactic Structure
3 Evaluation, Evaluation Metrics, Automatic Evaluation, Machine Translation, Human Judgments, Translation Quality
4 Error, Error Correction, Error Types, Spelling Errors, Category, Errors, Lexical Category, Error Rate, Ccg Parser
5 Sentence, First Sentence, Summarization, Sentence Length, Summarization Task, Document Summarization Text Summarization
6 Algorithm, Search Space, Objective Function, Function, Search Algorithm, Model, Optimization Problem, Large Number
7 Language, Information, Sentence, System, Results, Corpus, Approach, Research, Learning, Language Processing, Systems, Machine
8 Rules, Parse Tree, Grammar, Tree Structure, Root Node, Parse Trees, Grammar Rules, Rule Extraction, Rule Set, Elementary Tree
9 Natural Language, System, Language Generation, Information, Generation System, Language, Sentence, System Architecture
10 Sentiment Analysis, Sentiment, Event, Discourse, Sentiment Classification, Discourse Structure, Discourse Relations
11 Dependency Parsing, Dependency, Parsing, Parser, Dependency Tree, Parse Tree, Dependency Parser, Parsing Model, Dependency Trees
12 Words, Other Hand, Natural Language, Other Words, Corpus, Language Processing, Model, Information, TestSet, Language
13 Pos Tagging, Pos Tags, Word Segmentation, Pos Tag, Words, Model, Word Boundaries, Unknown Words, Chinese Word, Pos Tagger
14 Training Data, Training Set, Test Data, Training, Test Set, Data Sets, Data Set, Labeled Data, Training Examples, Unlabeled Data
15 Language, Target Language, Source Language, Machine Translation, Translation, Different Languages, Language Pairs
16 Features, Feature Set, Training Data, Feature Vector, Training Set, Lexical Features, Model, Feature Space, Test Data
17 Clustering Algorithm, Annotation, Same Cluster, Clustering, Clustering Method, Clustering Methods, Annotation Scheme
18 Query, Information Retrieval, Search Engine, Web Search, Search, Search Results, Information, Query Terms, Search Engines
19 Relation, Relation Extraction, Relations, Information Extraction, Semantic Relations, Relation Types, Semantic Relation
20 Topic, Topic Model, Topic Models, Topic Distribution, Same Topic, Topics, Model, Distribution, Topic Modeling, Word Distribution
21 Coreference Resolution, Entity, Same Entity, Coreference, Resolution System, Pronoun Resolution, Anaphora Resolution, Entity Type
22 Machine Translation, Translation, Language Model, Word Alignment, Translation Model, Target Language, Model, Translation Quality
23 Word Sense, Sense Disambiguation, Sense, Word Senses, Words, Different Senses, Target Word, Semantic Relations, Lexical Resources
24 Question, Question Answering, Answer, Questions, Correct Answer, Question Types, System, Textual Entailment, Answer Type
25 Semantic Role, Semantic Roles, Semantic Information, Syntactic Structure, Syntactic Information, Semantic, Parse Tree
26 Machine Learning, Learning, Classification Task, Features, Supervised Learning, Text Classification, Learning Algorithms, Feature
27 Semantic Similarity, Vector Space, Similarity Measure, Word Vectors, Vector, Similarity Measures, Similarity, Semantic Space
28 Language Model, Speech Recognition, Language Models, Word Error, Language, Model, Automatic Speech, Speech
29 Grammar, Language, Natural Language, Lexical Entries, Feature Structure, Feature Structures, Finite Set, Other Hand, Lexical Items
Topics ranked by Inverse Corpus Proportions: 3 7 4 17 24 20 21 27 9 28 0 19 6 10 23 2 5 18 15 25 26 29 8 13 14 11 16 1 22 12
Maximum ICP: 4.3533, Minimum ICP: 2.1809, Average ICP: 3.5591
</table>
<tableCaption confidence="0.9961665">
Table 1: The top words for each topic are shown here after modeling the ACL+EMNLP publications over the years with #topics=30. The topics ranked by their
ICP values are shown in the last row to illustrate that ICP values indeed capture the specificity of a topic across the years.
</tableCaption>
<bodyText confidence="0.999699">
and content-related sections such as abstract, re-
lated work, and experiments. To best represent
the topical content of these documents, we har-
ness the latest work on keyphrase extraction for
research documents and represent documents us-
ing keyphrases (Hasan and Ng, 2014).
We use the ExpandRank algorithm (Wan and
Xiao, 2008) to extract top n-grams bd E D. Ex-
pandRank effectively combines PageRank values
on word graphs with text similarity scores be-
tween documents to score n-grams for a document
and was shown to outperform other unsupervised
keyphrase extraction methods on research docu-
ments in absence of other information such as ci-
tations (Gollapalli and Caragea, 2014).
</bodyText>
<sectionHeader confidence="0.999798" genericHeader="background">
3 Experiments
</sectionHeader>
<bodyText confidence="0.9997795">
Datasets and setup: We crawled the ACLWeb
for research papers from EMNLP and ACL from
the year 1996 through 20142 using the Java-based
crawler, Heritrix3. The text from the PDF docu-
ments was extracted using the PDFBox software4
after which simple rules similar to the ones used
in CiteSeer (Li et al., 2006) were employed to ex-
tract the “body” of the research document5. The
numbers of papers for each year at the end of this
process are listed in Table 2. From these numbers,
</bodyText>
<footnote confidence="0.777448166666667">
2Since our goal is to compare the two venues, we start from 1996 when EMNLP
branched off into a full conference from a workshop on Very Large Corpora although ACL
proceedings are available from 1979.
3https://webarchive.jira.com/wiki/display/Heritrix/Heritrix
4https://pdfbox.apache.org/
5Processed data available upon request.
</footnote>
<bodyText confidence="0.999814473684211">
it appears that the paper “intake” in each confer-
ence has gone up overall during the last decade
although occasionally the increase is due to co-
location with related conferences such as IJCNLP
and HLT6.
We construct the keyphrase-document matrix
using top-100 keyphrases of each document ex-
tracted with ExpandRank. The LDA implemen-
tation provided in Mallet (McCallum, 2002) was
used to extract topics from this matrix. The
LDA algorithm was run along with hyperparame-
ter optimization (Minka, 2003) for different num-
bers of topics between 10 ... 100 in increments of
10. We use the average corpus likelihood over
ten randomly-initialized runs to choose the opti-
mal number of topics that best “explain” the cor-
pus (Heinrich, 2005). As indicated by the left plot
in Figure 1 this optimum is obtained when the
number of topics is 30.
</bodyText>
<subsectionHeader confidence="0.921275">
3.1 Results and Observations
</subsectionHeader>
<bodyText confidence="0.999965555555556">
The top phrases that reflect the “theme” captured
by a topic are shown in Table 1. As indicated
in this table, we are able to extract coherent top-
ics from the corpus using LDA on a document-
keyphrase matrix (AlSumait et al., 2009; Newman
et al., 2010).
Top research topics in NLP: We select
five timepoints {1996, 2000, 2005, 2010, 2014}
by splitting the 1996-2014 period into roughly-
</bodyText>
<footnote confidence="0.727057">
6ACL was co-located with related conferences in the years 1997, 1998, 2006,
2008, and 2009 and EMNLP in the years 2005, 2007, and 2012.
</footnote>
<page confidence="0.993426">
2004
</page>
<figure confidence="0.990718352941176">
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
JSD
Cosine
Year ACL EMNLP
2014 27, 10, 20 27, 10, 19
2010 0, 5, 6 20, 19, 18
2005 9, 0, 19 24, 18, 0
2000 7, 9, 5 18, 23, 20
1996 9, 2, 7 28, 2, 5
Average Likelihood
-5.748e+06
-5.752e+06
-5.754e+06
-5.756e+06
-5.758e+06
-5.762e+06
-5.764e+06
-5.766e+06
-5.768e+06
-5.75e+06
-5.76e+06
Divergence/Similarity
10 20 30 40 50 60 70 80 90 100 1996 1998 2000 2002 2004 2006 2008 2010 2012 2014
#Topics Year
</figure>
<figureCaption confidence="0.999652">
Figure 1: Left: #topics vs. Average Corpus Likelihood, Middle: EMNLP vs. ACL, Right: Top topics in EMNLP and ACL
</figureCaption>
<table confidence="0.999732">
Venue 2014 2013 2012 2011 2010 2009 2008 2007 2006 2005 2004 2003 2002 2001 2000 1999 1998 1997 1996
ACL 330 399 227 349 272 244 213 207 310 137 129 103 160 65 45 83 244 73 58
EMNLP 226 207 141 149 125 164 115 131 73 28 53 27 33 10 27 34 13 23 14
</table>
<tableCaption confidence="0.99829">
Table 2: Number of papers for each venue for different years
</tableCaption>
<figureCaption confidence="0.990869">
Figure 2: Comparing EMNLP and ACL over the years. Each point in the Left plot shows the JSD between a given year y and the year y − 1. The Middle (ACL)
and Right (EMNLP) plots show the JSD between a timepoint with preceding timepoints in the set {1996, 2000, 2005, 2010, 2014}.
</figureCaption>
<figure confidence="0.990170921052631">
JSD (year, previous year) ACL EMNLP
1996 1998 2000 2002 2004 2006 2008 2010 2012 2014 1996 2000 2005 2010 1996 2000 2005 2010
Year Starting Year Starting Year
JSD
0.18
0.16
0.14
0.12
0.08
0.06
0.04
0.02
0.1
0
EMNLP
ACL
JSD
0.25
0.15
0.05
0.2
0.1
0
2000
2005
2010
2014
JSD
0.25
0.15
0.05
0.2
0.1
0
2000
2005
2010
2014
</figure>
<bodyText confidence="0.992231166666667">
equal parts and examine the top topics for ACL
and EMNLP at these time points. We rank the
topics in each conference by their TP-ICP val-
ues and list the top 3 topics in the right table of
Figure 1. “Semantic relation extraction”, “sen-
timent analysis”, and “topic models” are the top
research topics in NLP last year (2014) whereas
in the year 1996, the topics “noun phrase extrac-
tion”, “summarization”, “corpus modeling”, and
“speech recognition” dominated the NLP research
arena. From the table, it can be seen that “infor-
mation retrieval” (topicID: 18) ranks among the
top topics in EMNLP for all three timepoints dur-
ing 2000-2010 whereas “natural language genera-
tion” (topicID: 9) was consistently addressed dur-
ing 1996-2005 in ACL.
EMNLP versus ACL: We compare the venues
using JSD and Cosine similarity measures in the
middle plot of Figure 1. The plot shows decreas-
ing divergence between the topical distributions
over the years and increasing cosine similarity be-
tween the TP-ICP vectors for the venues. These
trends indicate that over the two decades the two
venues ACL and EMNLP seem to have “become
like each other” although their topical focus was
different during the initial years. Increasingly,
both venues seem to publish papers on similar top-
ics. This behavior could be interpreted to mean
that the NLP research field is more stable now with
two of its leading conferences addressing prob-
lems on similar topics.
Changing topical focus over the years: In
the first plot of Figure 2, we show the Jensen-
Shannon divergence between the topic distribu-
tions of a particular venue for a given year y and
(y − 1), the year preceding it. The curve indi-
cates that in the years between 1997-2008, the rate
of change from year to year is higher than in the
years following 2008. We split the time period
1996-2014 into five roughly-equal parts to form
the set {1996, 2000, 2005, 2010, 2014}. The JSD
between the distribution in a particular year and
the years preceding it in the above set is shown for
ACL (middle plot) and EMNLP (right plot) in Fig-
ure 2. For example, the first cluster in the middle
plot, shows the JSD values between the distribu-
tions for the years 2000, 2005, 2010, 2014 with
the starting year 1996 for ACL. For both venues,
the divergences of a given year are higher with
the early starting years 1996 and 2000 than with
the later starting years 2005 and 2010, indicating
that the topics being addressed currently in NLP
research are significantly different from those ad-
dressed a decade back.
</bodyText>
<page confidence="0.987787">
2005
</page>
<sectionHeader confidence="0.99997" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.999860095238095">
Temporal analysis of corpora is an upcoming re-
search topic in text mining groups. Topic models
were particularly investigated for detecting activ-
ity patterns in corpora annotated with time infor-
mation (Huynh et al., 2008; Shen et al., 2009).
Evolution of topics and their trends were studied
on research corpora from NIPS (Wang and McCal-
lum, 2006) as well as CiteSeer (He et al., 2009).
In contrast with existing approaches that seek to
model the detection of new topics and their evo-
lution, we focus on representing different venues
pertaining to a research field and examine their de-
velopment over time by comparing them against
each other. In a similar study, Hall et al. (2008)
examined the emergence of topics in NLP litera-
ture. They proposed “topic entropy” to measure
the diversity in three conferences from the ACL
Anthology during the years 1978-2006. They also
noted that all the venues seem to converge in the
topics they cover over the years based on the JSD
between their topic distributions.
</bodyText>
<sectionHeader confidence="0.999575" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999995285714286">
We presented our study on research proceed-
ings of approximately two decades from the lead-
ing NLP conference venues: EMNLP and ACL.
We extracted coherent topics from this corpus
by applying topic modeling on the correspond-
ing keyphrase-document matrix. Next, the ex-
tracted topics were used to characterize each
venue through probabilistic and vector represen-
tations and compared against each other and over
the years using various similarity measures. To the
best of our knowledge, we are the first to present
insights related to the development of a research
field by studying two leading conferences in the
area using various techniques from NLP and IR.
</bodyText>
<sectionHeader confidence="0.999478" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999940693548387">
S. Alonso, F.J. Cabrerizo, E. Herrera-Viedma, and
F. Herrera. 2009. h-index: A review focused
in its variants, computation and standardization for
different scientific fields. Journal of Informetrics,
3(4):273 – 289.
Loulwah AlSumait, Daniel Barbar, James Gentle, and
Carlotta Domeniconi. 2009. Topic significance
ranking of lda generative models. In Machine
Learning and Knowledge Discovery in Databases,
Lecture Notes in Computer Science.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. J. Mach. Learn.
Res., pages 993–1022.
Sujatha Das Gollapalli and Cornelia Caragea. 2014.
Extracting keyphrases from research papers using
citation networks. In AAAI.
David Hall, Daniel Jurafsky, and Christopher D. Man-
ning. 2008. Studying the history of ideas using
topic models. In EMNLP.
Kazi Saidul Hasan and Vincent Ng. 2014. Automatic
keyphrase extraction: A survey of the state of the art.
ACL.
Qi He, Bi Chen, Jian Pei, Baojun Qiu, Prasenjit Mitra,
and C. Lee Giles. 2009. Detecting topic evolution
in scientific literature: how can citations help? In
CIKM, pages 957–966.
G. Heinrich. 2005. Parameter estimation for text anal-
ysis. Technical report.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In SIGIR, pages 50–57.
Tˆam Huynh, Mario Fritz, and Bernt Schiele. 2008.
Discovery of activity patterns using topic models. In
International Conference on Ubiquitous Computing.
Saurabh Kataria, Prasenjit Mitra, Cornelia Caragea,
and C. Lee Giles. 2011. Context sensitive topic
models for author influence in document networks.
In IJCAI, pages 2274–2280.
Huajing Li, Isaac G. Councill, Levent Bolelli, Ding
Zhou, Yang Song, Wang-Chien Lee, Anand Siva-
subramaniam, and C. Lee Giles. 2006. Citeseerx:
a scalable autonomous scientific digital library. In
InfoScale.
Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Schutze. 2008. Introduction to Information
Retrieval. Cambridge University Press.
Andrew Kachites McCallum. 2002. Mal-
let: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
Thomas P. Minka. 2003. Estimating a dirichlet distri-
bution. Technical report, Microsoft Research.
David Newman, Jey Han Lau, Karl Grieser, and Tim-
othy Baldwin. 2010. Automatic evaluation of topic
coherence. In Human Language Technologies.
Zhiyong Shen, Ping Luo, Yuhong Xiong, Jun Sun, and
Yidong Shen. 2009. Topic modeling for sequences
of temporal activities. In ICDM, pages 980–985.
Xiaojun Wan and Jianguo Xiao. 2008. Single
document keyphrase extraction using neighborhood
knowledge. In AAAI.
Xuerui Wang and Andrew McCallum. 2006. Topics
over time: A non-markov continuous-time model of
topical trends. In SIGKDD.
</reference>
<page confidence="0.992086">
2006
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.766101">
<title confidence="0.997134">EMNLP versus ACL: Analyzing NLP Research Over Time</title>
<author confidence="0.995474">Sujatha Das Gollapalli</author>
<author confidence="0.995474">Xiao-Li Li</author>
<affiliation confidence="0.966223">Institute for Infocomm Research, A*STAR, Singapore</affiliation>
<abstract confidence="0.97453615">The conferences ACL (Association for Computational Linguistics) and EMNLP (Empirical Methods in Natural Language Processing) rank among the premier venues that track the research developments in Natural Language Processing and Computational Linguistics. In this paper, we present a study on the research papers of approximately two decades from these two NLP conferences. We apply keyphrase extraction and corpus analysis tools to the proceedings from these venues and propose probabilistic and vector-based representations to represent the topics published in a venue for a given year. Next, similarity metrics are studied over pairs of venue representations to capture the progress of the two venues with respect to each other and over time.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Alonso</author>
<author>F J Cabrerizo</author>
<author>E Herrera-Viedma</author>
<author>F Herrera</author>
</authors>
<title>h-index: A review focused in its variants, computation and standardization for different scientific fields.</title>
<date>2009</date>
<journal>Journal of Informetrics,</journal>
<volume>3</volume>
<issue>4</issue>
<pages>289</pages>
<contexts>
<context position="1307" citStr="Alonso et al., 2009" startWordPosition="186" endWordPosition="189">sed representations to represent the topics published in a venue for a given year. Next, similarity metrics are studied over pairs of venue representations to capture the progress of the two venues with respect to each other and over time. 1 Introduction Scientific findings in a subject-area are typically published in conferences, journals, patents, and books in that domain. These research documents constitute valuable resources from the perspective of data mining applications. For instance, the citation links among research documents are used in computing bibliometric quantities for authors (Alonso et al., 2009) whereas topic models on research corpora are used to distinguish between influential and impactful researchers (Kataria et al., 2011) and to capture temporal topic trends (He et al., 2009). Despite several potential benefits mentioned above and the free availability of most research proceedings in NLP through the ACL Anthology1, the topical and temporal aspects of this corpus are yet to be fully studied in current literature. In this paper, we present our study on research proceedings of approximately two decades from two leading NLP conferences, namely ACL and EMNLP, to complement a previous</context>
</contexts>
<marker>Alonso, Cabrerizo, Herrera-Viedma, Herrera, 2009</marker>
<rawString>S. Alonso, F.J. Cabrerizo, E. Herrera-Viedma, and F. Herrera. 2009. h-index: A review focused in its variants, computation and standardization for different scientific fields. Journal of Informetrics, 3(4):273 – 289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Loulwah AlSumait</author>
<author>Daniel Barbar</author>
<author>James Gentle</author>
<author>Carlotta Domeniconi</author>
</authors>
<title>Topic significance ranking of lda generative models.</title>
<date>2009</date>
<booktitle>In Machine Learning and Knowledge Discovery in Databases, Lecture Notes in Computer Science.</booktitle>
<contexts>
<context position="13926" citStr="AlSumait et al., 2009" startWordPosition="2164" endWordPosition="2167">eter optimization (Minka, 2003) for different numbers of topics between 10 ... 100 in increments of 10. We use the average corpus likelihood over ten randomly-initialized runs to choose the optimal number of topics that best “explain” the corpus (Heinrich, 2005). As indicated by the left plot in Figure 1 this optimum is obtained when the number of topics is 30. 3.1 Results and Observations The top phrases that reflect the “theme” captured by a topic are shown in Table 1. As indicated in this table, we are able to extract coherent topics from the corpus using LDA on a documentkeyphrase matrix (AlSumait et al., 2009; Newman et al., 2010). Top research topics in NLP: We select five timepoints {1996, 2000, 2005, 2010, 2014} by splitting the 1996-2014 period into roughly6ACL was co-located with related conferences in the years 1997, 1998, 2006, 2008, and 2009 and EMNLP in the years 2005, 2007, and 2012. 2004 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 JSD Cosine Year ACL EMNLP 2014 27, 10, 20 27, 10, 19 2010 0, 5, 6 20, 19, 18 2005 9, 0, 19 24, 18, 0 2000 7, 9, 5 18, 23, 20 1996 9, 2, 7 28, 2, 5 Average Likelihood -5.748e+06 -5.752e+06 -5.754e+06 -5.756e+06 -5.758e+06 -5.762e+06 -5.764e+06 -5.766e+06 -5.768e+06</context>
</contexts>
<marker>AlSumait, Barbar, Gentle, Domeniconi, 2009</marker>
<rawString>Loulwah AlSumait, Daniel Barbar, James Gentle, and Carlotta Domeniconi. 2009. Topic significance ranking of lda generative models. In Machine Learning and Knowledge Discovery in Databases, Lecture Notes in Computer Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>993--1022</pages>
<contexts>
<context position="2314" citStr="Blei et al., 2003" startWordPosition="352" endWordPosition="355">o be fully studied in current literature. In this paper, we present our study on research proceedings of approximately two decades from two leading NLP conferences, namely ACL and EMNLP, to complement a previous study on this topic by Hall et al (2008). To the best of our knowledge, we are the first to characterize the developments in the NLP domain using a comparative study of two of its leading publication venues. Our contributions are summarized below: 1. We represent the NLP research corpus from approximately two decades as a keyphrasedocument matrix and apply Latent Dirichlet Allocation (Blei et al., 2003) to extract coherent topics from it (Newman et al., 2010). 2. We propose two novel representations for summarizing the venue proceedings in a given year. (1) The probabilistic representation expresses each venue as a probability distribution over topics, whereas (2) the TPICP representation captures topics that are the major focus in the venue for a particular year via Topic Proportion (TP) as well as topic importance as measured with inverse corpus proportion (ICP). 3. We apply Jensen-Shannon divergence and cosine similarity on our proposed venue representations to analyze the venues over tim</context>
<context position="4337" citStr="Blei et al., 2003" startWordPosition="689" endWordPosition="692">utive years in which the research proceedings are available from V , set of publication venues under consideration (V = {“ACL”, “EMNLP”} in this paper). If D is the set of all documents over the years, each document d E D is associated with {Kd, y, v} where Kd refers to the content of d whereas v and y refer to the venue and year in which d was published. 2.1 Venues as Probability Distributions Let t1, t2 ... tk denote the topics capturing the content of documents in D. Using probabilistic topic modeling and dimension reduction tools such as Latent Dirichlet Allocation or pLSA (Hofmann, 1999; Blei et al., 2003), we extract for each d E D, P(ti|d), i = 1... k, the multinomial distribution over the topics associated with d. The venue-topic probability distribution P(ti|vy) for a given (venue, year) pair (v = l, y = m) can be computed using Dl,m, the set of documents published in venue l, in the year m. That is, 1 Pl,m(ti) = | Note that the above probabilistic representation facilitates a quantitative measure to compare two venues: the divergence between the probability distributions of the two venues. The Kullback−Leibler divergence (KLD) between two (discrete) probability distributions P and Q is giv</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. J. Mach. Learn. Res., pages 993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujatha Das Gollapalli</author>
<author>Cornelia Caragea</author>
</authors>
<title>Extracting keyphrases from research papers using citation networks.</title>
<date>2014</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="12018" citStr="Gollapalli and Caragea, 2014" startWordPosition="1849" endWordPosition="1852">related work, and experiments. To best represent the topical content of these documents, we harness the latest work on keyphrase extraction for research documents and represent documents using keyphrases (Hasan and Ng, 2014). We use the ExpandRank algorithm (Wan and Xiao, 2008) to extract top n-grams bd E D. ExpandRank effectively combines PageRank values on word graphs with text similarity scores between documents to score n-grams for a document and was shown to outperform other unsupervised keyphrase extraction methods on research documents in absence of other information such as citations (Gollapalli and Caragea, 2014). 3 Experiments Datasets and setup: We crawled the ACLWeb for research papers from EMNLP and ACL from the year 1996 through 20142 using the Java-based crawler, Heritrix3. The text from the PDF documents was extracted using the PDFBox software4 after which simple rules similar to the ones used in CiteSeer (Li et al., 2006) were employed to extract the “body” of the research document5. The numbers of papers for each year at the end of this process are listed in Table 2. From these numbers, 2Since our goal is to compare the two venues, we start from 1996 when EMNLP branched off into a full confer</context>
</contexts>
<marker>Gollapalli, Caragea, 2014</marker>
<rawString>Sujatha Das Gollapalli and Cornelia Caragea. 2014. Extracting keyphrases from research papers using citation networks. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hall</author>
<author>Daniel Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Studying the history of ideas using topic models.</title>
<date>2008</date>
<booktitle>In EMNLP.</booktitle>
<contexts>
<context position="1948" citStr="Hall et al (2008)" startWordPosition="292" endWordPosition="295"> research corpora are used to distinguish between influential and impactful researchers (Kataria et al., 2011) and to capture temporal topic trends (He et al., 2009). Despite several potential benefits mentioned above and the free availability of most research proceedings in NLP through the ACL Anthology1, the topical and temporal aspects of this corpus are yet to be fully studied in current literature. In this paper, we present our study on research proceedings of approximately two decades from two leading NLP conferences, namely ACL and EMNLP, to complement a previous study on this topic by Hall et al (2008). To the best of our knowledge, we are the first to characterize the developments in the NLP domain using a comparative study of two of its leading publication venues. Our contributions are summarized below: 1. We represent the NLP research corpus from approximately two decades as a keyphrasedocument matrix and apply Latent Dirichlet Allocation (Blei et al., 2003) to extract coherent topics from it (Newman et al., 2010). 2. We propose two novel representations for summarizing the venue proceedings in a given year. (1) The probabilistic representation expresses each venue as a probability distr</context>
<context position="18899" citStr="Hall et al. (2008)" startWordPosition="3062" endWordPosition="3065">ext mining groups. Topic models were particularly investigated for detecting activity patterns in corpora annotated with time information (Huynh et al., 2008; Shen et al., 2009). Evolution of topics and their trends were studied on research corpora from NIPS (Wang and McCallum, 2006) as well as CiteSeer (He et al., 2009). In contrast with existing approaches that seek to model the detection of new topics and their evolution, we focus on representing different venues pertaining to a research field and examine their development over time by comparing them against each other. In a similar study, Hall et al. (2008) examined the emergence of topics in NLP literature. They proposed “topic entropy” to measure the diversity in three conferences from the ACL Anthology during the years 1978-2006. They also noted that all the venues seem to converge in the topics they cover over the years based on the JSD between their topic distributions. 5 Conclusions We presented our study on research proceedings of approximately two decades from the leading NLP conference venues: EMNLP and ACL. We extracted coherent topics from this corpus by applying topic modeling on the corresponding keyphrase-document matrix. Next, the</context>
</contexts>
<marker>Hall, Jurafsky, Manning, 2008</marker>
<rawString>David Hall, Daniel Jurafsky, and Christopher D. Manning. 2008. Studying the history of ideas using topic models. In EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazi Saidul Hasan</author>
<author>Vincent Ng</author>
</authors>
<title>Automatic keyphrase extraction: A survey of the state of the art.</title>
<date>2014</date>
<publisher>ACL.</publisher>
<contexts>
<context position="11613" citStr="Hasan and Ng, 2014" startWordPosition="1784" endWordPosition="1787">2 12 Maximum ICP: 4.3533, Minimum ICP: 2.1809, Average ICP: 3.5591 Table 1: The top words for each topic are shown here after modeling the ACL+EMNLP publications over the years with #topics=30. The topics ranked by their ICP values are shown in the last row to illustrate that ICP values indeed capture the specificity of a topic across the years. and content-related sections such as abstract, related work, and experiments. To best represent the topical content of these documents, we harness the latest work on keyphrase extraction for research documents and represent documents using keyphrases (Hasan and Ng, 2014). We use the ExpandRank algorithm (Wan and Xiao, 2008) to extract top n-grams bd E D. ExpandRank effectively combines PageRank values on word graphs with text similarity scores between documents to score n-grams for a document and was shown to outperform other unsupervised keyphrase extraction methods on research documents in absence of other information such as citations (Gollapalli and Caragea, 2014). 3 Experiments Datasets and setup: We crawled the ACLWeb for research papers from EMNLP and ACL from the year 1996 through 20142 using the Java-based crawler, Heritrix3. The text from the PDF do</context>
</contexts>
<marker>Hasan, Ng, 2014</marker>
<rawString>Kazi Saidul Hasan and Vincent Ng. 2014. Automatic keyphrase extraction: A survey of the state of the art. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qi He</author>
<author>Bi Chen</author>
<author>Jian Pei</author>
<author>Baojun Qiu</author>
<author>Prasenjit Mitra</author>
<author>C Lee Giles</author>
</authors>
<title>Detecting topic evolution in scientific literature: how can citations help? In</title>
<date>2009</date>
<booktitle>CIKM,</booktitle>
<pages>957--966</pages>
<contexts>
<context position="1496" citStr="He et al., 2009" startWordPosition="217" endWordPosition="220">nues with respect to each other and over time. 1 Introduction Scientific findings in a subject-area are typically published in conferences, journals, patents, and books in that domain. These research documents constitute valuable resources from the perspective of data mining applications. For instance, the citation links among research documents are used in computing bibliometric quantities for authors (Alonso et al., 2009) whereas topic models on research corpora are used to distinguish between influential and impactful researchers (Kataria et al., 2011) and to capture temporal topic trends (He et al., 2009). Despite several potential benefits mentioned above and the free availability of most research proceedings in NLP through the ACL Anthology1, the topical and temporal aspects of this corpus are yet to be fully studied in current literature. In this paper, we present our study on research proceedings of approximately two decades from two leading NLP conferences, namely ACL and EMNLP, to complement a previous study on this topic by Hall et al (2008). To the best of our knowledge, we are the first to characterize the developments in the NLP domain using a comparative study of two of its leading </context>
<context position="18603" citStr="He et al., 2009" startWordPosition="3012" endWordPosition="3015">tarting years 1996 and 2000 than with the later starting years 2005 and 2010, indicating that the topics being addressed currently in NLP research are significantly different from those addressed a decade back. 2005 4 Related Work Temporal analysis of corpora is an upcoming research topic in text mining groups. Topic models were particularly investigated for detecting activity patterns in corpora annotated with time information (Huynh et al., 2008; Shen et al., 2009). Evolution of topics and their trends were studied on research corpora from NIPS (Wang and McCallum, 2006) as well as CiteSeer (He et al., 2009). In contrast with existing approaches that seek to model the detection of new topics and their evolution, we focus on representing different venues pertaining to a research field and examine their development over time by comparing them against each other. In a similar study, Hall et al. (2008) examined the emergence of topics in NLP literature. They proposed “topic entropy” to measure the diversity in three conferences from the ACL Anthology during the years 1978-2006. They also noted that all the venues seem to converge in the topics they cover over the years based on the JSD between their </context>
</contexts>
<marker>He, Chen, Pei, Qiu, Mitra, Giles, 2009</marker>
<rawString>Qi He, Bi Chen, Jian Pei, Baojun Qiu, Prasenjit Mitra, and C. Lee Giles. 2009. Detecting topic evolution in scientific literature: how can citations help? In CIKM, pages 957–966.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Heinrich</author>
</authors>
<title>Parameter estimation for text analysis.</title>
<date>2005</date>
<tech>Technical report.</tech>
<contexts>
<context position="6817" citStr="Heinrich, 2005" startWordPosition="1129" endWordPosition="1130">x |V |= |D|. The TPICP vector for a venue is defined as: [TP(1) x ICP(1), ... TP(k) x ICP(k)] and captures in each component the weighted proportion of a topic in that venue for a year. This novel representation can be considered the topic-level counterpart of the popular TF-IDF representation in IR. Given two TP-ICP vectors P = [p1, p2, ... pk] and Q = [q1, q2, . . . qk], the similarity between them using the cosine measure is given by: cosine(P, Q) = 2.3 Keyphrases for representing documents Corpus analysis tools often use bag-of-words models and term frequencies for representing documents (Heinrich, 2005). However, research documents are often well-structured, and contain various sections with author information, citations, �log P|Y | y=1 P|Y | y=1 P|V | v=1 P|V | v=1 k P j=1 ) = (|Y ||V | D| TPv y (i) P PT y=1v=1 TPv,y(j) � Pv,y(i) X Dl,m |P(ti |d) (1) d∈Dl,, P(i)log P (i) Q(i). Due k P pi.qi i=1 ||P||2.||Q||2 2003 Topic ID Top Words 0 System, Dialogue, Dialogue System, Information, Speech Recognition, Speech, Dialogue Manager, Data Collection, User Utterances 1 Model, Training Data, Language Model, Model Parameters, Models, Generative Model, Probabilistic Model 2 Noun Phrases, Other Hand, He</context>
<context position="13567" citStr="Heinrich, 2005" startWordPosition="2099" endWordPosition="2100">nally the increase is due to colocation with related conferences such as IJCNLP and HLT6. We construct the keyphrase-document matrix using top-100 keyphrases of each document extracted with ExpandRank. The LDA implementation provided in Mallet (McCallum, 2002) was used to extract topics from this matrix. The LDA algorithm was run along with hyperparameter optimization (Minka, 2003) for different numbers of topics between 10 ... 100 in increments of 10. We use the average corpus likelihood over ten randomly-initialized runs to choose the optimal number of topics that best “explain” the corpus (Heinrich, 2005). As indicated by the left plot in Figure 1 this optimum is obtained when the number of topics is 30. 3.1 Results and Observations The top phrases that reflect the “theme” captured by a topic are shown in Table 1. As indicated in this table, we are able to extract coherent topics from the corpus using LDA on a documentkeyphrase matrix (AlSumait et al., 2009; Newman et al., 2010). Top research topics in NLP: We select five timepoints {1996, 2000, 2005, 2010, 2014} by splitting the 1996-2014 period into roughly6ACL was co-located with related conferences in the years 1997, 1998, 2006, 2008, and </context>
</contexts>
<marker>Heinrich, 2005</marker>
<rawString>G. Heinrich. 2005. Parameter estimation for text analysis. Technical report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In SIGIR,</booktitle>
<pages>50--57</pages>
<contexts>
<context position="4317" citStr="Hofmann, 1999" startWordPosition="686" endWordPosition="688">} be the consecutive years in which the research proceedings are available from V , set of publication venues under consideration (V = {“ACL”, “EMNLP”} in this paper). If D is the set of all documents over the years, each document d E D is associated with {Kd, y, v} where Kd refers to the content of d whereas v and y refer to the venue and year in which d was published. 2.1 Venues as Probability Distributions Let t1, t2 ... tk denote the topics capturing the content of documents in D. Using probabilistic topic modeling and dimension reduction tools such as Latent Dirichlet Allocation or pLSA (Hofmann, 1999; Blei et al., 2003), we extract for each d E D, P(ti|d), i = 1... k, the multinomial distribution over the topics associated with d. The venue-topic probability distribution P(ti|vy) for a given (venue, year) pair (v = l, y = m) can be computed using Dl,m, the set of documents published in venue l, in the year m. That is, 1 Pl,m(ti) = | Note that the above probabilistic representation facilitates a quantitative measure to compare two venues: the divergence between the probability distributions of the two venues. The Kullback−Leibler divergence (KLD) between two (discrete) probability distribu</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In SIGIR, pages 50–57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tˆam Huynh</author>
<author>Mario Fritz</author>
<author>Bernt Schiele</author>
</authors>
<title>Discovery of activity patterns using topic models.</title>
<date>2008</date>
<booktitle>In International Conference on Ubiquitous Computing.</booktitle>
<contexts>
<context position="18438" citStr="Huynh et al., 2008" startWordPosition="2982" endWordPosition="2985">he distributions for the years 2000, 2005, 2010, 2014 with the starting year 1996 for ACL. For both venues, the divergences of a given year are higher with the early starting years 1996 and 2000 than with the later starting years 2005 and 2010, indicating that the topics being addressed currently in NLP research are significantly different from those addressed a decade back. 2005 4 Related Work Temporal analysis of corpora is an upcoming research topic in text mining groups. Topic models were particularly investigated for detecting activity patterns in corpora annotated with time information (Huynh et al., 2008; Shen et al., 2009). Evolution of topics and their trends were studied on research corpora from NIPS (Wang and McCallum, 2006) as well as CiteSeer (He et al., 2009). In contrast with existing approaches that seek to model the detection of new topics and their evolution, we focus on representing different venues pertaining to a research field and examine their development over time by comparing them against each other. In a similar study, Hall et al. (2008) examined the emergence of topics in NLP literature. They proposed “topic entropy” to measure the diversity in three conferences from the A</context>
</contexts>
<marker>Huynh, Fritz, Schiele, 2008</marker>
<rawString>Tˆam Huynh, Mario Fritz, and Bernt Schiele. 2008. Discovery of activity patterns using topic models. In International Conference on Ubiquitous Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saurabh Kataria</author>
<author>Prasenjit Mitra</author>
<author>Cornelia Caragea</author>
<author>C Lee Giles</author>
</authors>
<title>Context sensitive topic models for author influence in document networks.</title>
<date>2011</date>
<booktitle>In IJCAI,</booktitle>
<pages>2274--2280</pages>
<contexts>
<context position="1441" citStr="Kataria et al., 2011" startWordPosition="206" endWordPosition="209"> venue representations to capture the progress of the two venues with respect to each other and over time. 1 Introduction Scientific findings in a subject-area are typically published in conferences, journals, patents, and books in that domain. These research documents constitute valuable resources from the perspective of data mining applications. For instance, the citation links among research documents are used in computing bibliometric quantities for authors (Alonso et al., 2009) whereas topic models on research corpora are used to distinguish between influential and impactful researchers (Kataria et al., 2011) and to capture temporal topic trends (He et al., 2009). Despite several potential benefits mentioned above and the free availability of most research proceedings in NLP through the ACL Anthology1, the topical and temporal aspects of this corpus are yet to be fully studied in current literature. In this paper, we present our study on research proceedings of approximately two decades from two leading NLP conferences, namely ACL and EMNLP, to complement a previous study on this topic by Hall et al (2008). To the best of our knowledge, we are the first to characterize the developments in the NLP </context>
</contexts>
<marker>Kataria, Mitra, Caragea, Giles, 2011</marker>
<rawString>Saurabh Kataria, Prasenjit Mitra, Cornelia Caragea, and C. Lee Giles. 2011. Context sensitive topic models for author influence in document networks. In IJCAI, pages 2274–2280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huajing Li</author>
<author>Isaac G Councill</author>
<author>Levent Bolelli</author>
<author>Ding Zhou</author>
<author>Yang Song</author>
<author>Wang-Chien Lee</author>
<author>Anand Sivasubramaniam</author>
<author>C Lee Giles</author>
</authors>
<title>Citeseerx: a scalable autonomous scientific digital library.</title>
<date>2006</date>
<booktitle>In InfoScale.</booktitle>
<contexts>
<context position="12341" citStr="Li et al., 2006" startWordPosition="1904" endWordPosition="1907">bines PageRank values on word graphs with text similarity scores between documents to score n-grams for a document and was shown to outperform other unsupervised keyphrase extraction methods on research documents in absence of other information such as citations (Gollapalli and Caragea, 2014). 3 Experiments Datasets and setup: We crawled the ACLWeb for research papers from EMNLP and ACL from the year 1996 through 20142 using the Java-based crawler, Heritrix3. The text from the PDF documents was extracted using the PDFBox software4 after which simple rules similar to the ones used in CiteSeer (Li et al., 2006) were employed to extract the “body” of the research document5. The numbers of papers for each year at the end of this process are listed in Table 2. From these numbers, 2Since our goal is to compare the two venues, we start from 1996 when EMNLP branched off into a full conference from a workshop on Very Large Corpora although ACL proceedings are available from 1979. 3https://webarchive.jira.com/wiki/display/Heritrix/Heritrix 4https://pdfbox.apache.org/ 5Processed data available upon request. it appears that the paper “intake” in each conference has gone up overall during the last decade altho</context>
</contexts>
<marker>Li, Councill, Bolelli, Zhou, Song, Lee, Sivasubramaniam, Giles, 2006</marker>
<rawString>Huajing Li, Isaac G. Councill, Levent Bolelli, Ding Zhou, Yang Song, Wang-Chien Lee, Anand Sivasubramaniam, and C. Lee Giles. 2006. Citeseerx: a scalable autonomous scientific digital library. In InfoScale.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Schutze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="5515" citStr="Manning et al., 2008" startWordPosition="887" endWordPosition="890">e) probability distributions P and Q is given by: DKL(P||Q) = P i to the unsymmetric nature of KLD, we use the Jensen-Shannon divergence, a symmetric and finite measure (0 &lt; JSD(P||Q) &lt; 1) based on KLD. Let M = 12(P + Q), 1 JSD(P||Q) = 2[DKL(P||M) + DKL(Q||M)] 2.2 Venues as TP-ICP Vectors Discrete probability distributions are often represented in computations as normalized vectors. For instance, the P(ti|v) values comprise the components of a k-dimensional vector. This topic proportion (TP) vector is similar to the normalized term frequency vector commonly used in Information Retrieval (IR) (Manning et al., 2008). TP values are fractions indicating the percentage of a given topic among all topics covered in a particular year. Thus these values are higher for topics that are the major focus in the venue for a particular year . We also extend inverse document frequency, a popular concept that is used to weigh terms in IR (Manning et al., 2008) to describe Inverse Corpus Proportion or ICP. Our objective in defining ICP is to capture the importance of a topic by diminishing the effect of topics that are common across all years. Let TPv,y(i) represents the proportion of topic ti in venue v for year y, then</context>
</contexts>
<marker>Manning, Raghavan, Schutze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schutze. 2008. Introduction to Information Retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="13212" citStr="McCallum, 2002" startWordPosition="2039" endWordPosition="2040">ff into a full conference from a workshop on Very Large Corpora although ACL proceedings are available from 1979. 3https://webarchive.jira.com/wiki/display/Heritrix/Heritrix 4https://pdfbox.apache.org/ 5Processed data available upon request. it appears that the paper “intake” in each conference has gone up overall during the last decade although occasionally the increase is due to colocation with related conferences such as IJCNLP and HLT6. We construct the keyphrase-document matrix using top-100 keyphrases of each document extracted with ExpandRank. The LDA implementation provided in Mallet (McCallum, 2002) was used to extract topics from this matrix. The LDA algorithm was run along with hyperparameter optimization (Minka, 2003) for different numbers of topics between 10 ... 100 in increments of 10. We use the average corpus likelihood over ten randomly-initialized runs to choose the optimal number of topics that best “explain” the corpus (Heinrich, 2005). As indicated by the left plot in Figure 1 this optimum is obtained when the number of topics is 30. 3.1 Results and Observations The top phrases that reflect the “theme” captured by a topic are shown in Table 1. As indicated in this table, we </context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas P Minka</author>
</authors>
<title>Estimating a dirichlet distribution.</title>
<date>2003</date>
<tech>Technical report, Microsoft Research.</tech>
<contexts>
<context position="13336" citStr="Minka, 2003" startWordPosition="2059" endWordPosition="2060">rchive.jira.com/wiki/display/Heritrix/Heritrix 4https://pdfbox.apache.org/ 5Processed data available upon request. it appears that the paper “intake” in each conference has gone up overall during the last decade although occasionally the increase is due to colocation with related conferences such as IJCNLP and HLT6. We construct the keyphrase-document matrix using top-100 keyphrases of each document extracted with ExpandRank. The LDA implementation provided in Mallet (McCallum, 2002) was used to extract topics from this matrix. The LDA algorithm was run along with hyperparameter optimization (Minka, 2003) for different numbers of topics between 10 ... 100 in increments of 10. We use the average corpus likelihood over ten randomly-initialized runs to choose the optimal number of topics that best “explain” the corpus (Heinrich, 2005). As indicated by the left plot in Figure 1 this optimum is obtained when the number of topics is 30. 3.1 Results and Observations The top phrases that reflect the “theme” captured by a topic are shown in Table 1. As indicated in this table, we are able to extract coherent topics from the corpus using LDA on a documentkeyphrase matrix (AlSumait et al., 2009; Newman e</context>
</contexts>
<marker>Minka, 2003</marker>
<rawString>Thomas P. Minka. 2003. Estimating a dirichlet distribution. Technical report, Microsoft Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Newman</author>
<author>Jey Han Lau</author>
<author>Karl Grieser</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatic evaluation of topic coherence. In Human Language Technologies.</title>
<date>2010</date>
<contexts>
<context position="2371" citStr="Newman et al., 2010" startWordPosition="363" endWordPosition="366">, we present our study on research proceedings of approximately two decades from two leading NLP conferences, namely ACL and EMNLP, to complement a previous study on this topic by Hall et al (2008). To the best of our knowledge, we are the first to characterize the developments in the NLP domain using a comparative study of two of its leading publication venues. Our contributions are summarized below: 1. We represent the NLP research corpus from approximately two decades as a keyphrasedocument matrix and apply Latent Dirichlet Allocation (Blei et al., 2003) to extract coherent topics from it (Newman et al., 2010). 2. We propose two novel representations for summarizing the venue proceedings in a given year. (1) The probabilistic representation expresses each venue as a probability distribution over topics, whereas (2) the TPICP representation captures topics that are the major focus in the venue for a particular year via Topic Proportion (TP) as well as topic importance as measured with inverse corpus proportion (ICP). 3. We apply Jensen-Shannon divergence and cosine similarity on our proposed venue representations to analyze the venues over time. Specifically, we ask the following questions: What are</context>
<context position="13948" citStr="Newman et al., 2010" startWordPosition="2168" endWordPosition="2171">a, 2003) for different numbers of topics between 10 ... 100 in increments of 10. We use the average corpus likelihood over ten randomly-initialized runs to choose the optimal number of topics that best “explain” the corpus (Heinrich, 2005). As indicated by the left plot in Figure 1 this optimum is obtained when the number of topics is 30. 3.1 Results and Observations The top phrases that reflect the “theme” captured by a topic are shown in Table 1. As indicated in this table, we are able to extract coherent topics from the corpus using LDA on a documentkeyphrase matrix (AlSumait et al., 2009; Newman et al., 2010). Top research topics in NLP: We select five timepoints {1996, 2000, 2005, 2010, 2014} by splitting the 1996-2014 period into roughly6ACL was co-located with related conferences in the years 1997, 1998, 2006, 2008, and 2009 and EMNLP in the years 2005, 2007, and 2012. 2004 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 JSD Cosine Year ACL EMNLP 2014 27, 10, 20 27, 10, 19 2010 0, 5, 6 20, 19, 18 2005 9, 0, 19 24, 18, 0 2000 7, 9, 5 18, 23, 20 1996 9, 2, 7 28, 2, 5 Average Likelihood -5.748e+06 -5.752e+06 -5.754e+06 -5.756e+06 -5.758e+06 -5.762e+06 -5.764e+06 -5.766e+06 -5.768e+06 -5.75e+06 -5.76e+06 D</context>
</contexts>
<marker>Newman, Lau, Grieser, Baldwin, 2010</marker>
<rawString>David Newman, Jey Han Lau, Karl Grieser, and Timothy Baldwin. 2010. Automatic evaluation of topic coherence. In Human Language Technologies.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyong Shen</author>
<author>Ping Luo</author>
<author>Yuhong Xiong</author>
<author>Jun Sun</author>
<author>Yidong Shen</author>
</authors>
<title>Topic modeling for sequences of temporal activities.</title>
<date>2009</date>
<booktitle>In ICDM,</booktitle>
<pages>980--985</pages>
<contexts>
<context position="18458" citStr="Shen et al., 2009" startWordPosition="2986" endWordPosition="2989"> the years 2000, 2005, 2010, 2014 with the starting year 1996 for ACL. For both venues, the divergences of a given year are higher with the early starting years 1996 and 2000 than with the later starting years 2005 and 2010, indicating that the topics being addressed currently in NLP research are significantly different from those addressed a decade back. 2005 4 Related Work Temporal analysis of corpora is an upcoming research topic in text mining groups. Topic models were particularly investigated for detecting activity patterns in corpora annotated with time information (Huynh et al., 2008; Shen et al., 2009). Evolution of topics and their trends were studied on research corpora from NIPS (Wang and McCallum, 2006) as well as CiteSeer (He et al., 2009). In contrast with existing approaches that seek to model the detection of new topics and their evolution, we focus on representing different venues pertaining to a research field and examine their development over time by comparing them against each other. In a similar study, Hall et al. (2008) examined the emergence of topics in NLP literature. They proposed “topic entropy” to measure the diversity in three conferences from the ACL Anthology during </context>
</contexts>
<marker>Shen, Luo, Xiong, Sun, Shen, 2009</marker>
<rawString>Zhiyong Shen, Ping Luo, Yuhong Xiong, Jun Sun, and Yidong Shen. 2009. Topic modeling for sequences of temporal activities. In ICDM, pages 980–985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<title>Single document keyphrase extraction using neighborhood knowledge.</title>
<date>2008</date>
<booktitle>In AAAI.</booktitle>
<contexts>
<context position="11667" citStr="Wan and Xiao, 2008" startWordPosition="1793" endWordPosition="1796"> ICP: 3.5591 Table 1: The top words for each topic are shown here after modeling the ACL+EMNLP publications over the years with #topics=30. The topics ranked by their ICP values are shown in the last row to illustrate that ICP values indeed capture the specificity of a topic across the years. and content-related sections such as abstract, related work, and experiments. To best represent the topical content of these documents, we harness the latest work on keyphrase extraction for research documents and represent documents using keyphrases (Hasan and Ng, 2014). We use the ExpandRank algorithm (Wan and Xiao, 2008) to extract top n-grams bd E D. ExpandRank effectively combines PageRank values on word graphs with text similarity scores between documents to score n-grams for a document and was shown to outperform other unsupervised keyphrase extraction methods on research documents in absence of other information such as citations (Gollapalli and Caragea, 2014). 3 Experiments Datasets and setup: We crawled the ACLWeb for research papers from EMNLP and ACL from the year 1996 through 20142 using the Java-based crawler, Heritrix3. The text from the PDF documents was extracted using the PDFBox software4 after</context>
</contexts>
<marker>Wan, Xiao, 2008</marker>
<rawString>Xiaojun Wan and Jianguo Xiao. 2008. Single document keyphrase extraction using neighborhood knowledge. In AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuerui Wang</author>
<author>Andrew McCallum</author>
</authors>
<title>Topics over time: A non-markov continuous-time model of topical trends.</title>
<date>2006</date>
<booktitle>In SIGKDD.</booktitle>
<contexts>
<context position="18565" citStr="Wang and McCallum, 2006" startWordPosition="3003" endWordPosition="3007">es of a given year are higher with the early starting years 1996 and 2000 than with the later starting years 2005 and 2010, indicating that the topics being addressed currently in NLP research are significantly different from those addressed a decade back. 2005 4 Related Work Temporal analysis of corpora is an upcoming research topic in text mining groups. Topic models were particularly investigated for detecting activity patterns in corpora annotated with time information (Huynh et al., 2008; Shen et al., 2009). Evolution of topics and their trends were studied on research corpora from NIPS (Wang and McCallum, 2006) as well as CiteSeer (He et al., 2009). In contrast with existing approaches that seek to model the detection of new topics and their evolution, we focus on representing different venues pertaining to a research field and examine their development over time by comparing them against each other. In a similar study, Hall et al. (2008) examined the emergence of topics in NLP literature. They proposed “topic entropy” to measure the diversity in three conferences from the ACL Anthology during the years 1978-2006. They also noted that all the venues seem to converge in the topics they cover over the</context>
</contexts>
<marker>Wang, McCallum, 2006</marker>
<rawString>Xuerui Wang and Andrew McCallum. 2006. Topics over time: A non-markov continuous-time model of topical trends. In SIGKDD.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>