<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<title confidence="0.992621">
Turn-taking phenomena in incremental dialogue systems
</title>
<author confidence="0.849535">
Hatim Khouzaimi
</author>
<affiliation confidence="0.583407">
Orange Labs
LIA-CERI, Univ. Avignon
</affiliation>
<email confidence="0.877382">
hatim.khouzaimi@orange.com
</email>
<author confidence="0.858705">
Romain Laroche
</author>
<affiliation confidence="0.545413666666667">
Orange Labs
Issy-les-Moulineaux
France
</affiliation>
<email confidence="0.970705">
romain.laroche@orange.com
</email>
<note confidence="0.73567375">
Fabrice Lef`evre
LIA-CERI, Univ. Avignon
Avignon
France
</note>
<email confidence="0.419725">
fabrice.lefevre@univ-avignon.fr
</email>
<sectionHeader confidence="0.977596" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999985764705882">
In this paper, a turn-taking phenomenon
taxonomy is introduced, organised accord-
ing to the level of information conveyed.
It is aimed to provide a better grasp of the
behaviours used by humans while talking
to each other, so that they can be method-
ically replicated in spoken dialogue sys-
tems. Five interesting phenomena have
been implemented in a simulated environ-
ment: the system barge-in with three vari-
ants (resulting from either an unclear, an
incoherent or a sufficient user message),
the feedback and the user barge-in. The
experiments reported in the paper illus-
trate that how such phenomena are imple-
mented is a delicate choice as their impact
on the system’s performance is variable.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999979461538461">
A spoken dialogue system is said to be incremen-
tal when it does not wait until the end of the user’s
utterance in order to process it (Dohsaka and Shi-
mazu, 1997; Allen et al., 2001; Schlangen and
Skantze, 2011). New audio information is cap-
tured by an incremental Automatic Speech Recog-
nition (ASR) at a certain frequency (Breslin et al.,
2013) and at each new step, the partial available
information is processed immediately. Therefore,
the system is able to replicate a rich set of turn-
taking phenomena (TTP) that are performed by
human beings when talking to each other (Sacks
et al., 1974; Clark, 1996). Replicating these TTP
in dialogue systems can help to make them more
efficient (e.g. (El Asri et al., 2014)) and enhance
their ability to recover from misunderstandings
(Skantze and Schlangen, 2009).
Several contributions already explored different
TTP like end-point detection (Raux and Eskenazi,
2008), backchannels (Meena et al., 2014; Visser
et al., 2014), feedback (Skantze and Schlangen,
2009) or barge-in (Selfridge et al., 2013; Ghigi
et al., 2014). However, these studies have been
performed separately with no unified view and no
comparison of respective merits, importance and
co-influence of the different TTP. In order to have
a better grasp on the concept of turn-taking in a di-
alogue and a guideline for the implementation, we
felt the need to introduce a taxonomy of these TTP.
Our motivation is to clarify which TTP are inter-
esting to implement given the task at hand. As an
illustration, five TTP (which we assume have the
best properties to improve the dialogue efficiency)
have been implemented and compared in a slot-
filling simulated environment.
Section 2 introduces the TTP taxonomy and
Section 3 describes the simulated environment, the
experimental setup and the results. We then con-
clude in Section 4.
</bodyText>
<sectionHeader confidence="0.5605" genericHeader="method">
2 Turn-taking phenomena taxonomy
</sectionHeader>
<bodyText confidence="0.9995632">
In linguistics and philosophy of language, a dis-
tinction is made between two different levels of a
speech act analysis: locutionary acts and illocu-
tionary acts (Austin, 1962; Searle, 1969). Loosely
speaking, a locutionary act refers to the act of ut-
tering sounds without taking their meaning into
account. When the semantic information is the ob-
ject of interest, it is an illocutionary act. In (Raux
and Eskenazi, 2009), four basic turn-taking transi-
tions are presented: the turn transitions with gap,
the turn transitions with overlap, the failed inter-
ruptions and the time outs where only the mechan-
ics of turn-taking are studied at a locutionary level.
In (Gravano and Hirschberg, 2011), the authors
propose a turn-taking labeling scheme, which is
a modified version of the original classification
of interruptions and smooth speaker-switches in-
troduced in (Beattie, 1982). This classification
is richer than the one in (Raux and Eskenazi,
2009) as the meaning of the turn-taker utterance
</bodyText>
<page confidence="0.920945">
1890
</page>
<note confidence="0.9323585">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1890–1895,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<tableCaption confidence="0.997698">
Table 1: Turn-taking phenomena taxonomy. The rows/columns correspond to the levels of information
added by the floor giver/taker. The phenomena in black have been implemented in the simulator.
</tableCaption>
<table confidence="0.996251142857143">
T REF IMPL T REF RAW T REF INTERP T MOVE
G NONE FLOOR TAKING IMPL INIT DIALOGUE
G FAIL FAIL IMPL FAIL RAW FAIL INTERP
G INCOHERENCE INCOHERENCE IMPL INCOHERENCE RAW INCOHERENCE INTERP
G INCOMPLETE BACKCHANNEL FEEDBACK RAW FEEDBACK INTERP
G SUFFICIENT REF IMPL REF RAW REF INTERP BARGE IN RESP
G COMPLETE REKINDLE END POINT
</table>
<bodyText confidence="0.996042277777778">
is taken into account. From a computational point
of view, it is more interesting to add high-level in-
formation to classify these behaviours as seman-
tics clearly influence turn-taking decisions (Dun-
can, 1972; Gravano and Hirschberg, 2011). In this
paper, a more fine-grained taxonomy of TTP is in-
troduced where utterances are considered both at
locutionary and illocutionary levels.
During a floor transition, the person who starts
speaking will be called T (Taker) whereas the per-
son that was speaking just before will be called
G (Giver). At the beginning of the dialogue, the
person that initiates the dialogue will be called T
and the other G by convention. We classify TTP
given two criteria: the quantity of information that
has been injected by G before the floor transition
(rows in Table 1) and the quantity of information
that T tries to add by taking the floor (columns in
</bodyText>
<tableCaption confidence="0.884170666666667">
Table 1). Table 2 gives the meaning of the differ-
ent criteria’s labels.
Table 2: Taxonomy labels
</tableCaption>
<figure confidence="0.902298272727273">
No information given
Failed trial
Incoherent information
Incomplete information
Insufficient information
Sufficient information
Complete utterance
Implicit ref. to G’s utterance
Raw ref. to G’s utterance
Reference with interpretation
Dialogue move (with improvement)
</figure>
<bodyText confidence="0.999747018867925">
At the beginning of the dialogue (G NONE),
T can implicitly announce that she wants to take
the floor by using hand gestures or by clearing her
throat for instance (FLOOR TAKING IMPL),
or she can directly initiate the dialogue
(INIT DIALOGUE). If G is already speak-
ing, her message can be not understandable by T
(G FAIL). T can warn G implicitly by frowning
for example (FAIL IMPL) or explicitly, in a
raw manner by saying Sorry? (FAIL RAW)
or by pointing out what has not been under-
stood (FAIL INTERP). In addition, even if the
meaning of the message has been understood,
it can be incoherent with the interaction context
(G INCOHERENT, e.g. trying to book a flight
from a city with no airport). Again, T can
warn G implicitly (INCOHERENCE IMPL) or
explicitly, either by explaining the reason of
the problem (INCOHERENCE INTERP) or not
(INCOHERENCE RAW).
In the case G’s utterance is not problematic
but yet incomplete (G INCOMPLETE), T can
let her understand that she understands what has
been said so far by performing a BACKCHAN-
NEL (Yes, uhum etc.), by repeating his words
exactly (FEEDBACK RAW) or by commenting
them (FEEDBACK INTERP), for example: Yes-
terday I went to this new Chinese restaurant in
town... / Yeah Fing Shui / ...and it was a pretty
good deal). If G utters enough information to
move the dialogue forward (G SUFFICIENT), T
can refer to an element in G’s utterance im-
plicitly (Aha) by reacting at the proper timing
(REF IMPL), or explicitly in a raw (REF RAW,
for example Ok, Sunday) or interpreted manner
(REF INTERP, for example Yeah, Sunday is the
only day when I am free). T can also interrupt
G to add some information that is relevant to the
course of the dialogue (BARGE IN RESP). Fi-
nally, she can wait until G has finished his ut-
terance (G COMPLETE) and warn him that he
should add more information (REKINDLE, for
example: And?) or start a new dialogue turn
(END POINT).
In the rest of this paper, five incremen-
tal TTP that are the more used in general,
and therefore studied, have been tested in a
simulated environment: FAIL RAW (Ghigi et
al., 2014), INCOHERENCE INTERP (DeVault
et al., 2011), FEEDBACK RAW (Skantze and
Schlangen, 2009) and BARGE IN RESP from
both sides, user (Selfridge et al., 2013) and system
interruptions (DeVault et al., 2011), along with
</bodyText>
<figure confidence="0.773854181818182">
G NONE
G FAIL
G INCOHERENT
G INCOMPLETE
G INSUFFICIENT
G SUFFICIENT
G COMPLETE
T REF IMPL
T REF RAW
T REF INTERP
T MOVE
</figure>
<page confidence="0.888497">
1891
</page>
<bodyText confidence="0.937066">
INIT DIALOGUE and END POINT that already
exist in traditional systems.
</bodyText>
<sectionHeader confidence="0.982805" genericHeader="method">
3 Simulation
</sectionHeader>
<subsectionHeader confidence="0.999435">
3.1 Service task
</subsectionHeader>
<bodyText confidence="0.999719142857143">
A personal agenda assistant task has been imple-
mented in the simulated dialogue system (referred
to as the service hereafter). The user can add
events to her agenda as long as they do not over-
lap with existing events. She can also move events
in the agenda or delete them (ADD, MODIFY and
DELETE actions). An event corresponds to a title,
a date, a time slot, a priority, and the list of alterna-
tive dates and time slots where the event can fit, in
the case the main date and slot are not available.
For example: {title: house cleaning, date: Jan-
uary 6th, slot: from 18 to 20, priority: 3, alterna-
tive 1: January 7th, from 18 to 20, alternative 2:
January 9th, from 10 to 12}.
</bodyText>
<subsectionHeader confidence="0.9971515">
3.2 User simulator
3.2.1 Overview
</subsectionHeader>
<bodyText confidence="0.928479">
The architecture of the User Simulator (US) is
built around five modules: the Natural Language
Understanding (NLU) module, the Intent Man-
ager, the Natural Language Generator (NLG), the
Verbosity Manager, the ASR Output Simulator,
and the Patience Manager. These modules are de-
scribed in the following.
NLU module: The NLU module is very simple
as the service’s utterances are totally known by the
US and no parsing is involved. Each one of them
is associated with a specific dialogue act.
Intent Manager: The Intent Manager is some-
how the brain of the US, as it determines its next
intent given the general goal and the last NLU re-
sult. The general goal depends on the scenario
at hand, which is in turn determined by two lists
of events: the initial list (InitList) and the list of
events to add to the agenda during the dialogue
(ToAddList). The Intent Manager tries to add each
event from the latter given the constraints imposed
by the former. If the events of both lists cannot be
kept, those with lower priorities are abandoned or
deleted until a solution is reached.
The service asks for the different slot values in
a mixed initiative way. At first, the user has the
initiative in the sense that she is asked to provide
all the slot values in the same utterance. If there
is still missing information (because the user did
not provide all the slot values or because of ASR
noise), the remaining slot values are asked for one
by one (system initiative).
NLG module: The NLG figures out the next
sentence to utter given the current Intent Man-
ager’s output. A straightforward sentence is com-
puted, for example, Add the event meeting Mary
on July 6th from 18:00 until 20:00.
Verbosity Manager: The Verbosity Manager
randomly expands the NLG output with some
usual prefixes (like I would like to...) and suffixes
(like please, if possible...). Also, a few sentences
are replaced with off-domain words or repeated
twice as it is the case in real dialogues (Ghigi et al.,
2014). For questions concerning a specific slot,
neither prefixes nor suffixes are added.
Patience Manager: When the dialogue lasts too
long, the US can get impatient and hang up. The
US patience corresponds to a threshold on each
task duration. It is randomly sampled around
a mean of 180 seconds for the experiments. A
speech rate of 200 words per minute is assumed
for the dialogue duration estimation (Yuan et al.,
2006). Moreover, a silence of one second is as-
sumed at each regular system/user transition and
a two second silence is assumed the other way
round. For interruptions and accurate end-point
detection, no silence is taken into account.
</bodyText>
<subsectionHeader confidence="0.992348">
3.3 ASR Output Simulator
</subsectionHeader>
<bodyText confidence="0.9999822">
The US can run either in a traditional mode in
the sense that it provides a complete utterance to
the system then it waits for a response, or in an
incremental mode where a growing utterance is
outputted at each new word. For example: I, I
want, I want to, I want to add...etc. In incremental
dialogue systems, the turn increment (called the
micro-turn in this case) could be different than the
word (a small duration for example).
The ASR output simulator can be used in both
modes, but as the traditional mode is a special
case of the incremental one, we describe the lat-
ter only. This module computes a noisy version of
each word (substitution, deletion, or insertion). It
also associates a confidence score with each new
partial utterance. Moreover, a word in the ASR
output can change later as new words pop in (Self-
ridge et al., 2011; McGraw and Gruenstein, 2012).
In the following, this mechanism is referred to as
the ASR instability. At each micro-turn, the sys-
</bodyText>
<page confidence="0.978259">
1892
</page>
<bodyText confidence="0.9062305">
tem can keep listening to the US or decide to take
the floor (see Section 3.4).
</bodyText>
<subsectionHeader confidence="0.843336">
3.4 Scheduler
</subsectionHeader>
<bodyText confidence="0.999813076923077">
The same architecture as in (Khouzaimi et al.,
2014) is used. A Scheduler module is inserted be-
tween the service and the user simulator. As the
ASR output utterance grows, the partial utterances
are sent, at each micro-turn, to the Scheduler. In
turn, the latter transfers them to the service and
waits for its responses.
The aim of this module is to make turn-taking
decisions. Given the last system’s response and
some other features and rules determined by the
designer, or learned from data, the Scheduler de-
cides whether or not to convey that response to the
client immediately or not.
</bodyText>
<subsectionHeader confidence="0.899128">
3.5 Dialogue example
</subsectionHeader>
<bodyText confidence="0.89537888">
In the following example, the user has to delete
an event, before adding another one (ASR noise is
not introduced here):
SYSTEM: Hi. Welcome to your agenda man-
agement service. How can I help you?
USER: I would like to add the event birthday
party on January 6th from 6 pm to 11 pm
if it is possible.
SYSTEM: The time slot from 6 pm to 11 pm
on January 6th overlaps with the event
house cleaning on January 6th from 7
pm to 9 pm. How can I help you?
USER: Delete the event house cleaning.
SYSTEM: Ok. So you want to delete the
event house cleaning that takes place on
January 6th from 7 pm to 9 pm. Right?
USER: Yes.
SYSTEM: Got it. Do you want to perform
some other action?
USER: Yes.
SYSTEM: Add the event birthday party on
January 6th from 6 pm to 11 pm.
USER: Ok. So you want to add the event
birthday party on January 6th from 6 pm
to 11 pm. Right?
</bodyText>
<sectionHeader confidence="0.234601" genericHeader="method">
USER: Yes.
</sectionHeader>
<bodyText confidence="0.50758325">
SYSTEM: Got it. Do you want to perform
some other action?
SYSTEM: No.
USER: Thank you. Bye!
</bodyText>
<subsectionHeader confidence="0.93981">
3.6 TTP implementation
</subsectionHeader>
<bodyText confidence="0.99815542">
Replicating some turn-taking phenomena like
backchannels makes the system seems more real-
istic (Meena et al., 2014). In this work, the fo-
cus is on dialogue efficiency, therefore, the fol-
lowing TTP have been chosen for the implemen-
tation: FAIL RAW, INCOHERENCE INTERP,
FEEDBACK RAW and BARGE IN RESP from
the user’s and the system’s point of view.
At each micro-turn, the system has to pick an
action among three options: to wait (WAIT), to
retrieve the last service’s response to the client
(SPEAK) or to repeat the word at position n − 2
(if n is the current number of words, because of
the ASR instability) in the current partial request
(REPEAT). To replicate each selected TTP, a set of
rules have been specified to make the proper de-
cision. We review the triggering features related
to each TTP accommodated to the task at hand
(agenda filling).
FAIL RAW: Depending on the last system’s di-
alogue act, a threshold relative to the number of
words without detecting a key concept in the ut-
terance has been set. In the case of an open ques-
tion (where the system waits for all the informa-
tion needed in one request), if no action type has
been detected after 6 words, a FAIL RAW event
is declared. The system waits for 3 words in the
case of a yes/no question, for 4 words in the case
of a date and for 6 words in the case of slots (some
concepts need more words to be detected and the
user may use additional off-domain words).
INCOHERENCE INTERP: This event is
useful to promptly react to partial requests that
would eventually lead to an error, not because they
were not correctly understood, but because they
are in conflict with the current dialogue state. If
such an inconsistency is detected, the system waits
for two words (ASR instability) and if it is main-
tained, it takes the floor to warn the user.
FEEDBACK RAW: If at time t, a new word
is added to the partial utterance and the ratio be-
tween the last partial utterance’s score and the one
before last (which corresponds to the score of the
last increment) is lower than 1/2, then the system
waits for two words (because of the ASR instabil-
ity), and if the word is still in the partial utterance,
a REPEAT action is performed.
BARGE IN RESP (System): This TTP de-
pends on the last system dialogue act as it deter-
mines which kind of NLU concept the system is
</bodyText>
<page confidence="0.97026">
1893
</page>
<figure confidence="0.79199">
WER
</figure>
<figureCaption confidence="0.995277">
Figure 1: Simulated dialogue duration for differ-
ent noise levels
</figureCaption>
<figure confidence="0.788902">
WER
</figure>
<figureCaption confidence="0.991181">
Figure 2: Simulated dialogue task completion for
different noise levels
</figureCaption>
<bodyText confidence="0.998256586206897">
waiting for. Once it is detected, the system waits
for two more words (ASR instability) and if the
concept is maintained, it performs a SPEAK.
USER BARGE RESP (User): This event is
triggered directly by the user (no system decision
is involved). For each system dialogue act, the mo-
ment when a familiar user would barge-in is man-
ually defined in the simulator.
Dialogue duration and task completion are used
as evaluation criteria. The task completion rate is
the ratio between the number of dialogues where
the user did not hang up (because of her patience
limit) and the total number of dialogues.
The five implemented TTP have been tested
single-handled and in an aggregated manner (re-
ferred to as All strategy). They have also been been
compared to a non-incremental baseline (see Fig-
ure 1 and 2). Three dialogue scenarios and differ-
ent WER levels were tested. For each strategy and
each WER, 1000 dialogues have been simulated
for each scenario. Figure 1 (resp. Figure 2) repre-
sents the mean duration (resp. the mean task com-
pletion), with the corresponding 95% confidence
intervals, for the different strategies and for WER
varying between 0 and 0.3.
The FEEDBACK RAW strategy performs best
whereas INCOHERENCE INTERP does not im-
prove over the baseline. This is due to the fact that
the system has to deal with an open slot (which set
of possible values is not closed and known a pri-
ori): the event’s description. The system mostly
performs ADD actions, so the description slot can
take any value and is never compared with exist-
ing data. This is the case of many application like
message dictation for example. However, in the
case of service at hand, an initial concept must be
detected (the action), therefore, FAIL RAW im-
proves the performance. BARGE IN RESP from
user’s side is also useful here as dialogues can be
long and may contain repetitive system dialogue
acts. The users get familiar with the systems and
may infer the end of the system’s question before
it ends. Obviously it is questionable that users
may be patient enough (up to several minutes) to
achieve such simple tasks in real life. But for the
sake of the simulation it was necessary to gener-
ate dialogues long enough to have the studied TTP
influence them. In a next step, increasing the ser-
vice capacities (and complexity) will remedy that
as a side effect. Finally, BARGE IN RESP from
the system’s side does not bring any improvement
either which is due to the fact that in this task and
because of input noise, in most cases, the response
to the initial open question is not enough to fill all
the slots. The responses to single-slot questions
do not contain suffixes which explains the ineffi-
ciency of the last strategy (the US stops speaking
as soon as the slot value is given).
</bodyText>
<sectionHeader confidence="0.988037" genericHeader="conclusions">
4 Conclusion and future work
</sectionHeader>
<bodyText confidence="0.999950230769231">
This paper introduces a new taxonomy of turn-
taking phenomena in human dialogue. Then an
experiment where five TTP are implemented has
been run in a simulated environment. It illustrates
the potentiality of the taxonomy and shows that
some TTP are worth replicating in some situations
but not all. In future work, we plan to perform
TTP analysis in the case of real users and to opti-
mise the hand-crafted rules introduced here to op-
erate the floor management in the system (when
to take/give the floor and according to which TTP
scheme) by using reinforcement learning (Sutton
and Barto, 1998; Lemon and Pietquin, 2012).
</bodyText>
<figure confidence="0.999035828571429">
0 0.06 0.12 0.18 0.24 0.3
330
300
270
240
210
180
150
120
90
60
Non-incremental
FAIL RAW
INCOHERENCE INTERP
FEEDBACK RAW
BARGE IN RESP (System)
BARGE IN RESP (User)
All
0 0.06 0.12 0.18 0.24 0.3
Non-incremental
FAIL RAW
INCOHERENCE INTERP
FEEDBACK RAW
BARGE IN RESP (System)
BARGE IN RESP (User)
All
1
Mean task completion ratio
0.9
0.8
0.7
0.6
0.5
0.4
Mean duration (sec)
</figure>
<page confidence="0.990893">
1894
</page>
<sectionHeader confidence="0.988751" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99984532">
James Allen, George Ferguson, and Amanda Stent.
2001. An architecture for more realistic conversa-
tional systems. In 6th international conference on
Intelligent user interfaces.
J.L. Austin. 1962. How to Do Things with Words. Ox-
ford.
Geoffrey Beattie. 1982. Turn-taking and interrup-
tion in political interviews: Margaret thatcher and
jim callaghan compared and contrasted. Semiotica,
39:93–114.
Catherine Breslin, Milica Gasic, Matthew Henderson,
Dongho Kim, Martin Szummer, Blaise Thomson,
Pirros Tsiakoulis, and Steve Young. 2013. Con-
tinuous asr for flexible incremental dialogue. In
ICASSP, pages 8362–8366.
Herbert H. Clark. 1996. Using Language. Cambridge
University Press.
David DeVault, Kenji Sagae, and David Traum. 2011.
Incremental interpretation and prediction of utter-
ance meaning for interactive dialogue. Dialogue
and Discourse, 2:143–170.
Kohji Dohsaka and Akira Shimazu. 1997. A system
architecture for spoken utterance production in col-
laborative dialogue. In IJCAI.
Starkey Duncan. 1972. Some signals and rules for
taking speaking turns in conversations. Journal of
Personality and Social Psychology, 23:283–292.
Layla El Asri, Remi Lemonnier, Romain Laroche,
Olivier Pietquin, and Hatim Khouzaimi. 2014.
NASTIA: Negotiating Appointment Setting Inter-
face. In Proceedings of LREC.
Fabrizio Ghigi, Maxine Eskenazi, M Ines Torres, and
Sungjin Lee. 2014. Incremental dialog processing
in a task-oriented dialog. In Fifteenth Annual Con-
ference of the International Speech Communication
Association.
Agustin Gravano and Julia Hirschberg. 2011. Turn-
taking cues in task-oriented dialogue. Comput.
Speech Lang., 25(3):601–634.
Hatim Khouzaimi, Romain Laroche, and Fabrice
Lef`evre. 2014. An easy method to make dialogue
systems incremental. In Proceedings of the 15th An-
nual Meeting of the Special Interest Group on Dis-
course and Dialogue (SIGDIAL).
Oliver Lemon and Olivier Pietquin. 2012. Data-
Driven Methods for Adaptive Spoken Dialogue Sys-
tems. Springer Publishing Company, Incorporated.
Ian McGraw and Alexander Gruenstein. 2012. Es-
timating word-stability during incremental speech
recognition. In Proceedings of the INTERSPEECH
2012 Conference.
Raveesh Meena, Johan Boye, Gabriel Skantze, and
Joakim Gustafson. 2014. Crowdsourcing street-
level geographic information using a spoken dia-
logue system. In Proceedings of the 15th Annual
Meeting of the Special Interest Group on Discourse
and Dialogue (SIGDIAL).
Antoine Raux and Maxine Eskenazi. 2008. Optimiz-
ing endpointing thresholds using dialogue features
in a spoken dialogue system. In SIGDIAL.
Antoine Raux and Maxine Eskenazi. 2009. A finite-
state turn-taking model for spoken dialog systems.
In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, NAACL ’09, pages 629–637.
Harvey Sacks, Emanuel A. Schegloff, and Gail Jeffer-
son. 1974. A simplest systematics for the organi-
zation of turn-taking for conversation. Language,
50:696–735.
David Schlangen and Gabriel Skantze. 2011. A gen-
eral, abstract model of incremental dialogue pro-
cessing. Dialogue and Discourse, 2:83–111.
John Searle. 1969. Speech Acts: An Essay in the Phi-
losophy of Language. Cambridge University Press,
UK.
Ethan O. Selfridge, Iker Arizmendi, Peter A. Heeman,
and Jason D. Williams. 2011. Stability and accu-
racy in incremental speech recognition. In Proceed-
ings of the SIGDIAL 2011 Conference.
Ethan Selfridge, Iker Arizmendi, Peter Heeman, and
Jason Williams. 2013. Continuously predicting and
processing barge-in during a live spoken dialogue
task. In Proceedings of the SIGDIAL 2013 Confer-
ence.
Gabriel Skantze and David Schlangen. 2009. Incre-
mental dialogue processing in a micro-domain. In
ACL.
Richard S. Sutton and Andrew G. Barto. 1998. Re-
inforcement Learning, An Introduction. The MIT
Press, Cambridge, Massachusetts, London, Eng-
land.
Thomas Visser, David Traum, David DeVault, and
Rieks op den Akker. 2014. A model for incremental
grounding in spoken dialogue systems. Journal on
Multimodal User Interfaces.
Jiahong Yuan, Mark Liberman, and Christopher Cieri.
2006. Towards an integrated understanding of
speaking rate in conversation. In INTERSPEECH
Proceedings.
</reference>
<page confidence="0.993144">
1895
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.075976">
<title confidence="0.8786725">Turn-taking phenomena in incremental dialogue systems Hatim</title>
<author confidence="0.656401">Orange Labs</author>
<affiliation confidence="0.986265">LIA-CERI, Univ. Avignon</affiliation>
<email confidence="0.999357">hatim.khouzaimi@orange.com</email>
<author confidence="0.945606">Romain</author>
<affiliation confidence="0.7910055">Orange France</affiliation>
<email confidence="0.999596">romain.laroche@orange.com</email>
<author confidence="0.387263">Fabrice</author>
<affiliation confidence="0.5981455">LIA-CERI, Univ. France</affiliation>
<email confidence="0.996254">fabrice.lefevre@univ-avignon.fr</email>
<abstract confidence="0.999717">In this paper, a turn-taking phenomenon taxonomy is introduced, organised according to the level of information conveyed. It is aimed to provide a better grasp of the behaviours used by humans while talking to each other, so that they can be methodically replicated in spoken dialogue systems. Five interesting phenomena have been implemented in a simulated environment: the system barge-in with three variants (resulting from either an unclear, an incoherent or a sufficient user message), the feedback and the user barge-in. The experiments reported in the paper illustrate that how such phenomena are implemented is a delicate choice as their impact on the system’s performance is variable.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>George Ferguson</author>
<author>Amanda Stent</author>
</authors>
<title>An architecture for more realistic conversational systems.</title>
<date>2001</date>
<booktitle>In 6th international conference on Intelligent user interfaces.</booktitle>
<contexts>
<context position="1199" citStr="Allen et al., 2001" startWordPosition="178" endWordPosition="181">oken dialogue systems. Five interesting phenomena have been implemented in a simulated environment: the system barge-in with three variants (resulting from either an unclear, an incoherent or a sufficient user message), the feedback and the user barge-in. The experiments reported in the paper illustrate that how such phenomena are implemented is a delicate choice as their impact on the system’s performance is variable. 1 Introduction A spoken dialogue system is said to be incremental when it does not wait until the end of the user’s utterance in order to process it (Dohsaka and Shimazu, 1997; Allen et al., 2001; Schlangen and Skantze, 2011). New audio information is captured by an incremental Automatic Speech Recognition (ASR) at a certain frequency (Breslin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Sk</context>
</contexts>
<marker>Allen, Ferguson, Stent, 2001</marker>
<rawString>James Allen, George Ferguson, and Amanda Stent. 2001. An architecture for more realistic conversational systems. In 6th international conference on Intelligent user interfaces.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Austin</author>
</authors>
<title>How to Do Things with Words.</title>
<date>1962</date>
<location>Oxford.</location>
<contexts>
<context position="3061" citStr="Austin, 1962" startWordPosition="478" endWordPosition="479"> which TTP are interesting to implement given the task at hand. As an illustration, five TTP (which we assume have the best properties to improve the dialogue efficiency) have been implemented and compared in a slotfilling simulated environment. Section 2 introduces the TTP taxonomy and Section 3 describes the simulated environment, the experimental setup and the results. We then conclude in Section 4. 2 Turn-taking phenomena taxonomy In linguistics and philosophy of language, a distinction is made between two different levels of a speech act analysis: locutionary acts and illocutionary acts (Austin, 1962; Searle, 1969). Loosely speaking, a locutionary act refers to the act of uttering sounds without taking their meaning into account. When the semantic information is the object of interest, it is an illocutionary act. In (Raux and Eskenazi, 2009), four basic turn-taking transitions are presented: the turn transitions with gap, the turn transitions with overlap, the failed interruptions and the time outs where only the mechanics of turn-taking are studied at a locutionary level. In (Gravano and Hirschberg, 2011), the authors propose a turn-taking labeling scheme, which is a modified version of </context>
</contexts>
<marker>Austin, 1962</marker>
<rawString>J.L. Austin. 1962. How to Do Things with Words. Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Beattie</author>
</authors>
<title>Turn-taking and interruption in political interviews: Margaret thatcher and jim callaghan compared and contrasted.</title>
<date>1982</date>
<booktitle>Semiotica,</booktitle>
<pages>39--93</pages>
<contexts>
<context position="3763" citStr="Beattie, 1982" startWordPosition="588" endWordPosition="589">s without taking their meaning into account. When the semantic information is the object of interest, it is an illocutionary act. In (Raux and Eskenazi, 2009), four basic turn-taking transitions are presented: the turn transitions with gap, the turn transitions with overlap, the failed interruptions and the time outs where only the mechanics of turn-taking are studied at a locutionary level. In (Gravano and Hirschberg, 2011), the authors propose a turn-taking labeling scheme, which is a modified version of the original classification of interruptions and smooth speaker-switches introduced in (Beattie, 1982). This classification is richer than the one in (Raux and Eskenazi, 2009) as the meaning of the turn-taker utterance 1890 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1890–1895, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Table 1: Turn-taking phenomena taxonomy. The rows/columns correspond to the levels of information added by the floor giver/taker. The phenomena in black have been implemented in the simulator. T REF IMPL T REF RAW T REF INTERP T MOVE G NONE FLOOR TAKING IMPL INIT DIALOGUE G FAIL FAI</context>
</contexts>
<marker>Beattie, 1982</marker>
<rawString>Geoffrey Beattie. 1982. Turn-taking and interruption in political interviews: Margaret thatcher and jim callaghan compared and contrasted. Semiotica, 39:93–114.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Breslin</author>
<author>Milica Gasic</author>
<author>Matthew Henderson</author>
<author>Dongho Kim</author>
<author>Martin Szummer</author>
</authors>
<title>Blaise Thomson, Pirros Tsiakoulis, and Steve Young.</title>
<date>2013</date>
<booktitle>In ICASSP,</booktitle>
<pages>8362--8366</pages>
<contexts>
<context position="1363" citStr="Breslin et al., 2013" startWordPosition="204" endWordPosition="207">r an unclear, an incoherent or a sufficient user message), the feedback and the user barge-in. The experiments reported in the paper illustrate that how such phenomena are implemented is a delicate choice as their impact on the system’s performance is variable. 1 Introduction A spoken dialogue system is said to be incremental when it does not wait until the end of the user’s utterance in order to process it (Dohsaka and Shimazu, 1997; Allen et al., 2001; Schlangen and Skantze, 2011). New audio information is captured by an incremental Automatic Speech Recognition (ASR) at a certain frequency (Breslin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Several contributions already explored different TTP like end-point detection (Raux and Eskenazi, 2008), backchannels (Meena et al., 201</context>
</contexts>
<marker>Breslin, Gasic, Henderson, Kim, Szummer, 2013</marker>
<rawString>Catherine Breslin, Milica Gasic, Matthew Henderson, Dongho Kim, Martin Szummer, Blaise Thomson, Pirros Tsiakoulis, and Steve Young. 2013. Continuous asr for flexible incremental dialogue. In ICASSP, pages 8362–8366.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Using Language.</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1625" citStr="Clark, 1996" startWordPosition="250" endWordPosition="251">ction A spoken dialogue system is said to be incremental when it does not wait until the end of the user’s utterance in order to process it (Dohsaka and Shimazu, 1997; Allen et al., 2001; Schlangen and Skantze, 2011). New audio information is captured by an incremental Automatic Speech Recognition (ASR) at a certain frequency (Breslin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Several contributions already explored different TTP like end-point detection (Raux and Eskenazi, 2008), backchannels (Meena et al., 2014; Visser et al., 2014), feedback (Skantze and Schlangen, 2009) or barge-in (Selfridge et al., 2013; Ghigi et al., 2014). However, these studies have been performed separately with no unified view and no comparison of respective merits, importance and co-influen</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>Herbert H. Clark. 1996. Using Language. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David DeVault</author>
<author>Kenji Sagae</author>
<author>David Traum</author>
</authors>
<title>Incremental interpretation and prediction of utterance meaning for interactive dialogue. Dialogue and Discourse,</title>
<date>2011</date>
<pages>2--143</pages>
<contexts>
<context position="7968" citStr="DeVault et al., 2011" startWordPosition="1291" endWordPosition="1294">y) or interpreted manner (REF INTERP, for example Yeah, Sunday is the only day when I am free). T can also interrupt G to add some information that is relevant to the course of the dialogue (BARGE IN RESP). Finally, she can wait until G has finished his utterance (G COMPLETE) and warn him that he should add more information (REKINDLE, for example: And?) or start a new dialogue turn (END POINT). In the rest of this paper, five incremental TTP that are the more used in general, and therefore studied, have been tested in a simulated environment: FAIL RAW (Ghigi et al., 2014), INCOHERENCE INTERP (DeVault et al., 2011), FEEDBACK RAW (Skantze and Schlangen, 2009) and BARGE IN RESP from both sides, user (Selfridge et al., 2013) and system interruptions (DeVault et al., 2011), along with G NONE G FAIL G INCOHERENT G INCOMPLETE G INSUFFICIENT G SUFFICIENT G COMPLETE T REF IMPL T REF RAW T REF INTERP T MOVE 1891 INIT DIALOGUE and END POINT that already exist in traditional systems. 3 Simulation 3.1 Service task A personal agenda assistant task has been implemented in the simulated dialogue system (referred to as the service hereafter). The user can add events to her agenda as long as they do not overlap with exi</context>
</contexts>
<marker>DeVault, Sagae, Traum, 2011</marker>
<rawString>David DeVault, Kenji Sagae, and David Traum. 2011. Incremental interpretation and prediction of utterance meaning for interactive dialogue. Dialogue and Discourse, 2:143–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kohji Dohsaka</author>
<author>Akira Shimazu</author>
</authors>
<title>A system architecture for spoken utterance production in collaborative dialogue.</title>
<date>1997</date>
<booktitle>In IJCAI.</booktitle>
<contexts>
<context position="1179" citStr="Dohsaka and Shimazu, 1997" startWordPosition="173" endWordPosition="177">thodically replicated in spoken dialogue systems. Five interesting phenomena have been implemented in a simulated environment: the system barge-in with three variants (resulting from either an unclear, an incoherent or a sufficient user message), the feedback and the user barge-in. The experiments reported in the paper illustrate that how such phenomena are implemented is a delicate choice as their impact on the system’s performance is variable. 1 Introduction A spoken dialogue system is said to be incremental when it does not wait until the end of the user’s utterance in order to process it (Dohsaka and Shimazu, 1997; Allen et al., 2001; Schlangen and Skantze, 2011). New audio information is captured by an incremental Automatic Speech Recognition (ASR) at a certain frequency (Breslin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from m</context>
</contexts>
<marker>Dohsaka, Shimazu, 1997</marker>
<rawString>Kohji Dohsaka and Akira Shimazu. 1997. A system architecture for spoken utterance production in collaborative dialogue. In IJCAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Starkey Duncan</author>
</authors>
<title>Some signals and rules for taking speaking turns in conversations.</title>
<date>1972</date>
<journal>Journal of Personality and Social Psychology,</journal>
<pages>23--283</pages>
<contexts>
<context position="4803" citStr="Duncan, 1972" startWordPosition="749" endWordPosition="751">floor giver/taker. The phenomena in black have been implemented in the simulator. T REF IMPL T REF RAW T REF INTERP T MOVE G NONE FLOOR TAKING IMPL INIT DIALOGUE G FAIL FAIL IMPL FAIL RAW FAIL INTERP G INCOHERENCE INCOHERENCE IMPL INCOHERENCE RAW INCOHERENCE INTERP G INCOMPLETE BACKCHANNEL FEEDBACK RAW FEEDBACK INTERP G SUFFICIENT REF IMPL REF RAW REF INTERP BARGE IN RESP G COMPLETE REKINDLE END POINT is taken into account. From a computational point of view, it is more interesting to add high-level information to classify these behaviours as semantics clearly influence turn-taking decisions (Duncan, 1972; Gravano and Hirschberg, 2011). In this paper, a more fine-grained taxonomy of TTP is introduced where utterances are considered both at locutionary and illocutionary levels. During a floor transition, the person who starts speaking will be called T (Taker) whereas the person that was speaking just before will be called G (Giver). At the beginning of the dialogue, the person that initiates the dialogue will be called T and the other G by convention. We classify TTP given two criteria: the quantity of information that has been injected by G before the floor transition (rows in Table 1) and the</context>
</contexts>
<marker>Duncan, 1972</marker>
<rawString>Starkey Duncan. 1972. Some signals and rules for taking speaking turns in conversations. Journal of Personality and Social Psychology, 23:283–292.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Layla El Asri</author>
<author>Remi Lemonnier</author>
<author>Romain Laroche</author>
<author>Olivier Pietquin</author>
<author>Hatim Khouzaimi</author>
</authors>
<title>NASTIA: Negotiating Appointment Setting Interface.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC.</booktitle>
<marker>El Asri, Lemonnier, Laroche, Pietquin, Khouzaimi, 2014</marker>
<rawString>Layla El Asri, Remi Lemonnier, Romain Laroche, Olivier Pietquin, and Hatim Khouzaimi. 2014. NASTIA: Negotiating Appointment Setting Interface. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabrizio Ghigi</author>
<author>Maxine Eskenazi</author>
<author>M Ines Torres</author>
<author>Sungjin Lee</author>
</authors>
<title>Incremental dialog processing in a task-oriented dialog.</title>
<date>2014</date>
<booktitle>In Fifteenth Annual Conference of the International Speech Communication Association.</booktitle>
<contexts>
<context position="2083" citStr="Ghigi et al., 2014" startWordPosition="316" endWordPosition="319">tem is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Several contributions already explored different TTP like end-point detection (Raux and Eskenazi, 2008), backchannels (Meena et al., 2014; Visser et al., 2014), feedback (Skantze and Schlangen, 2009) or barge-in (Selfridge et al., 2013; Ghigi et al., 2014). However, these studies have been performed separately with no unified view and no comparison of respective merits, importance and co-influence of the different TTP. In order to have a better grasp on the concept of turn-taking in a dialogue and a guideline for the implementation, we felt the need to introduce a taxonomy of these TTP. Our motivation is to clarify which TTP are interesting to implement given the task at hand. As an illustration, five TTP (which we assume have the best properties to improve the dialogue efficiency) have been implemented and compared in a slotfilling simulated e</context>
<context position="7925" citStr="Ghigi et al., 2014" startWordPosition="1285" endWordPosition="1288"> in a raw (REF RAW, for example Ok, Sunday) or interpreted manner (REF INTERP, for example Yeah, Sunday is the only day when I am free). T can also interrupt G to add some information that is relevant to the course of the dialogue (BARGE IN RESP). Finally, she can wait until G has finished his utterance (G COMPLETE) and warn him that he should add more information (REKINDLE, for example: And?) or start a new dialogue turn (END POINT). In the rest of this paper, five incremental TTP that are the more used in general, and therefore studied, have been tested in a simulated environment: FAIL RAW (Ghigi et al., 2014), INCOHERENCE INTERP (DeVault et al., 2011), FEEDBACK RAW (Skantze and Schlangen, 2009) and BARGE IN RESP from both sides, user (Selfridge et al., 2013) and system interruptions (DeVault et al., 2011), along with G NONE G FAIL G INCOHERENT G INCOMPLETE G INSUFFICIENT G SUFFICIENT G COMPLETE T REF IMPL T REF RAW T REF INTERP T MOVE 1891 INIT DIALOGUE and END POINT that already exist in traditional systems. 3 Simulation 3.1 Service task A personal agenda assistant task has been implemented in the simulated dialogue system (referred to as the service hereafter). The user can add events to her age</context>
<context position="11053" citStr="Ghigi et al., 2014" startWordPosition="1835" endWordPosition="1838">ues or because of ASR noise), the remaining slot values are asked for one by one (system initiative). NLG module: The NLG figures out the next sentence to utter given the current Intent Manager’s output. A straightforward sentence is computed, for example, Add the event meeting Mary on July 6th from 18:00 until 20:00. Verbosity Manager: The Verbosity Manager randomly expands the NLG output with some usual prefixes (like I would like to...) and suffixes (like please, if possible...). Also, a few sentences are replaced with off-domain words or repeated twice as it is the case in real dialogues (Ghigi et al., 2014). For questions concerning a specific slot, neither prefixes nor suffixes are added. Patience Manager: When the dialogue lasts too long, the US can get impatient and hang up. The US patience corresponds to a threshold on each task duration. It is randomly sampled around a mean of 180 seconds for the experiments. A speech rate of 200 words per minute is assumed for the dialogue duration estimation (Yuan et al., 2006). Moreover, a silence of one second is assumed at each regular system/user transition and a two second silence is assumed the other way round. For interruptions and accurate end-poi</context>
</contexts>
<marker>Ghigi, Eskenazi, Torres, Lee, 2014</marker>
<rawString>Fabrizio Ghigi, Maxine Eskenazi, M Ines Torres, and Sungjin Lee. 2014. Incremental dialog processing in a task-oriented dialog. In Fifteenth Annual Conference of the International Speech Communication Association.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Agustin Gravano</author>
<author>Julia Hirschberg</author>
</authors>
<title>Turntaking cues in task-oriented dialogue.</title>
<date>2011</date>
<journal>Comput. Speech Lang.,</journal>
<volume>25</volume>
<issue>3</issue>
<contexts>
<context position="3577" citStr="Gravano and Hirschberg, 2011" startWordPosition="560" endWordPosition="563">made between two different levels of a speech act analysis: locutionary acts and illocutionary acts (Austin, 1962; Searle, 1969). Loosely speaking, a locutionary act refers to the act of uttering sounds without taking their meaning into account. When the semantic information is the object of interest, it is an illocutionary act. In (Raux and Eskenazi, 2009), four basic turn-taking transitions are presented: the turn transitions with gap, the turn transitions with overlap, the failed interruptions and the time outs where only the mechanics of turn-taking are studied at a locutionary level. In (Gravano and Hirschberg, 2011), the authors propose a turn-taking labeling scheme, which is a modified version of the original classification of interruptions and smooth speaker-switches introduced in (Beattie, 1982). This classification is richer than the one in (Raux and Eskenazi, 2009) as the meaning of the turn-taker utterance 1890 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1890–1895, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. Table 1: Turn-taking phenomena taxonomy. The rows/columns correspond to the levels of information</context>
<context position="4834" citStr="Gravano and Hirschberg, 2011" startWordPosition="752" endWordPosition="755">ker. The phenomena in black have been implemented in the simulator. T REF IMPL T REF RAW T REF INTERP T MOVE G NONE FLOOR TAKING IMPL INIT DIALOGUE G FAIL FAIL IMPL FAIL RAW FAIL INTERP G INCOHERENCE INCOHERENCE IMPL INCOHERENCE RAW INCOHERENCE INTERP G INCOMPLETE BACKCHANNEL FEEDBACK RAW FEEDBACK INTERP G SUFFICIENT REF IMPL REF RAW REF INTERP BARGE IN RESP G COMPLETE REKINDLE END POINT is taken into account. From a computational point of view, it is more interesting to add high-level information to classify these behaviours as semantics clearly influence turn-taking decisions (Duncan, 1972; Gravano and Hirschberg, 2011). In this paper, a more fine-grained taxonomy of TTP is introduced where utterances are considered both at locutionary and illocutionary levels. During a floor transition, the person who starts speaking will be called T (Taker) whereas the person that was speaking just before will be called G (Giver). At the beginning of the dialogue, the person that initiates the dialogue will be called T and the other G by convention. We classify TTP given two criteria: the quantity of information that has been injected by G before the floor transition (rows in Table 1) and the quantity of information that T</context>
</contexts>
<marker>Gravano, Hirschberg, 2011</marker>
<rawString>Agustin Gravano and Julia Hirschberg. 2011. Turntaking cues in task-oriented dialogue. Comput. Speech Lang., 25(3):601–634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hatim Khouzaimi</author>
<author>Romain Laroche</author>
<author>Fabrice Lef`evre</author>
</authors>
<title>An easy method to make dialogue systems incremental.</title>
<date>2014</date>
<booktitle>In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL).</booktitle>
<marker>Khouzaimi, Laroche, Lef`evre, 2014</marker>
<rawString>Hatim Khouzaimi, Romain Laroche, and Fabrice Lef`evre. 2014. An easy method to make dialogue systems incremental. In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Olivier Pietquin</author>
</authors>
<title>DataDriven Methods for Adaptive Spoken Dialogue Systems.</title>
<date>2012</date>
<publisher>Springer Publishing Company, Incorporated.</publisher>
<marker>Lemon, Pietquin, 2012</marker>
<rawString>Oliver Lemon and Olivier Pietquin. 2012. DataDriven Methods for Adaptive Spoken Dialogue Systems. Springer Publishing Company, Incorporated.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian McGraw</author>
<author>Alexander Gruenstein</author>
</authors>
<title>Estimating word-stability during incremental speech recognition.</title>
<date>2012</date>
<booktitle>In Proceedings of the INTERSPEECH 2012 Conference.</booktitle>
<contexts>
<context position="12595" citStr="McGraw and Gruenstein, 2012" startWordPosition="2102" endWordPosition="2105">ant, I want to, I want to add...etc. In incremental dialogue systems, the turn increment (called the micro-turn in this case) could be different than the word (a small duration for example). The ASR output simulator can be used in both modes, but as the traditional mode is a special case of the incremental one, we describe the latter only. This module computes a noisy version of each word (substitution, deletion, or insertion). It also associates a confidence score with each new partial utterance. Moreover, a word in the ASR output can change later as new words pop in (Selfridge et al., 2011; McGraw and Gruenstein, 2012). In the following, this mechanism is referred to as the ASR instability. At each micro-turn, the sys1892 tem can keep listening to the US or decide to take the floor (see Section 3.4). 3.4 Scheduler The same architecture as in (Khouzaimi et al., 2014) is used. A Scheduler module is inserted between the service and the user simulator. As the ASR output utterance grows, the partial utterances are sent, at each micro-turn, to the Scheduler. In turn, the latter transfers them to the service and waits for its responses. The aim of this module is to make turn-taking decisions. Given the last system</context>
</contexts>
<marker>McGraw, Gruenstein, 2012</marker>
<rawString>Ian McGraw and Alexander Gruenstein. 2012. Estimating word-stability during incremental speech recognition. In Proceedings of the INTERSPEECH 2012 Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raveesh Meena</author>
<author>Johan Boye</author>
<author>Gabriel Skantze</author>
<author>Joakim Gustafson</author>
</authors>
<title>Crowdsourcing streetlevel geographic information using a spoken dialogue system.</title>
<date>2014</date>
<booktitle>In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL).</booktitle>
<contexts>
<context position="1964" citStr="Meena et al., 2014" startWordPosition="297" endWordPosition="300">lin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Several contributions already explored different TTP like end-point detection (Raux and Eskenazi, 2008), backchannels (Meena et al., 2014; Visser et al., 2014), feedback (Skantze and Schlangen, 2009) or barge-in (Selfridge et al., 2013; Ghigi et al., 2014). However, these studies have been performed separately with no unified view and no comparison of respective merits, importance and co-influence of the different TTP. In order to have a better grasp on the concept of turn-taking in a dialogue and a guideline for the implementation, we felt the need to introduce a taxonomy of these TTP. Our motivation is to clarify which TTP are interesting to implement given the task at hand. As an illustration, five TTP (which we assume have </context>
<context position="14501" citStr="Meena et al., 2014" startWordPosition="2453" endWordPosition="2456">se cleaning. SYSTEM: Ok. So you want to delete the event house cleaning that takes place on January 6th from 7 pm to 9 pm. Right? USER: Yes. SYSTEM: Got it. Do you want to perform some other action? USER: Yes. SYSTEM: Add the event birthday party on January 6th from 6 pm to 11 pm. USER: Ok. So you want to add the event birthday party on January 6th from 6 pm to 11 pm. Right? USER: Yes. SYSTEM: Got it. Do you want to perform some other action? SYSTEM: No. USER: Thank you. Bye! 3.6 TTP implementation Replicating some turn-taking phenomena like backchannels makes the system seems more realistic (Meena et al., 2014). In this work, the focus is on dialogue efficiency, therefore, the following TTP have been chosen for the implementation: FAIL RAW, INCOHERENCE INTERP, FEEDBACK RAW and BARGE IN RESP from the user’s and the system’s point of view. At each micro-turn, the system has to pick an action among three options: to wait (WAIT), to retrieve the last service’s response to the client (SPEAK) or to repeat the word at position n − 2 (if n is the current number of words, because of the ASR instability) in the current partial request (REPEAT). To replicate each selected TTP, a set of rules have been specifie</context>
</contexts>
<marker>Meena, Boye, Skantze, Gustafson, 2014</marker>
<rawString>Raveesh Meena, Johan Boye, Gabriel Skantze, and Joakim Gustafson. 2014. Crowdsourcing streetlevel geographic information using a spoken dialogue system. In Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Raux</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Optimizing endpointing thresholds using dialogue features in a spoken dialogue system.</title>
<date>2008</date>
<booktitle>In SIGDIAL.</booktitle>
<contexts>
<context position="1930" citStr="Raux and Eskenazi, 2008" startWordPosition="292" endWordPosition="295">ition (ASR) at a certain frequency (Breslin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Several contributions already explored different TTP like end-point detection (Raux and Eskenazi, 2008), backchannels (Meena et al., 2014; Visser et al., 2014), feedback (Skantze and Schlangen, 2009) or barge-in (Selfridge et al., 2013; Ghigi et al., 2014). However, these studies have been performed separately with no unified view and no comparison of respective merits, importance and co-influence of the different TTP. In order to have a better grasp on the concept of turn-taking in a dialogue and a guideline for the implementation, we felt the need to introduce a taxonomy of these TTP. Our motivation is to clarify which TTP are interesting to implement given the task at hand. As an illustratio</context>
</contexts>
<marker>Raux, Eskenazi, 2008</marker>
<rawString>Antoine Raux and Maxine Eskenazi. 2008. Optimizing endpointing thresholds using dialogue features in a spoken dialogue system. In SIGDIAL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Raux</author>
<author>Maxine Eskenazi</author>
</authors>
<title>A finitestate turn-taking model for spoken dialog systems.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL ’09,</booktitle>
<pages>629--637</pages>
<contexts>
<context position="3307" citStr="Raux and Eskenazi, 2009" startWordPosition="517" endWordPosition="520">nvironment. Section 2 introduces the TTP taxonomy and Section 3 describes the simulated environment, the experimental setup and the results. We then conclude in Section 4. 2 Turn-taking phenomena taxonomy In linguistics and philosophy of language, a distinction is made between two different levels of a speech act analysis: locutionary acts and illocutionary acts (Austin, 1962; Searle, 1969). Loosely speaking, a locutionary act refers to the act of uttering sounds without taking their meaning into account. When the semantic information is the object of interest, it is an illocutionary act. In (Raux and Eskenazi, 2009), four basic turn-taking transitions are presented: the turn transitions with gap, the turn transitions with overlap, the failed interruptions and the time outs where only the mechanics of turn-taking are studied at a locutionary level. In (Gravano and Hirschberg, 2011), the authors propose a turn-taking labeling scheme, which is a modified version of the original classification of interruptions and smooth speaker-switches introduced in (Beattie, 1982). This classification is richer than the one in (Raux and Eskenazi, 2009) as the meaning of the turn-taker utterance 1890 Proceedings of the 201</context>
</contexts>
<marker>Raux, Eskenazi, 2009</marker>
<rawString>Antoine Raux and Maxine Eskenazi. 2009. A finitestate turn-taking model for spoken dialog systems. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, NAACL ’09, pages 629–637.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harvey Sacks</author>
<author>Emanuel A Schegloff</author>
<author>Gail Jefferson</author>
</authors>
<title>A simplest systematics for the organization of turn-taking for conversation.</title>
<date>1974</date>
<journal>Language,</journal>
<pages>50--696</pages>
<contexts>
<context position="1611" citStr="Sacks et al., 1974" startWordPosition="246" endWordPosition="249"> variable. 1 Introduction A spoken dialogue system is said to be incremental when it does not wait until the end of the user’s utterance in order to process it (Dohsaka and Shimazu, 1997; Allen et al., 2001; Schlangen and Skantze, 2011). New audio information is captured by an incremental Automatic Speech Recognition (ASR) at a certain frequency (Breslin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Several contributions already explored different TTP like end-point detection (Raux and Eskenazi, 2008), backchannels (Meena et al., 2014; Visser et al., 2014), feedback (Skantze and Schlangen, 2009) or barge-in (Selfridge et al., 2013; Ghigi et al., 2014). However, these studies have been performed separately with no unified view and no comparison of respective merits, importance </context>
</contexts>
<marker>Sacks, Schegloff, Jefferson, 1974</marker>
<rawString>Harvey Sacks, Emanuel A. Schegloff, and Gail Jefferson. 1974. A simplest systematics for the organization of turn-taking for conversation. Language, 50:696–735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Schlangen</author>
<author>Gabriel Skantze</author>
</authors>
<title>A general, abstract model of incremental dialogue processing. Dialogue and Discourse,</title>
<date>2011</date>
<pages>2--83</pages>
<contexts>
<context position="1229" citStr="Schlangen and Skantze, 2011" startWordPosition="182" endWordPosition="185">s. Five interesting phenomena have been implemented in a simulated environment: the system barge-in with three variants (resulting from either an unclear, an incoherent or a sufficient user message), the feedback and the user barge-in. The experiments reported in the paper illustrate that how such phenomena are implemented is a delicate choice as their impact on the system’s performance is variable. 1 Introduction A spoken dialogue system is said to be incremental when it does not wait until the end of the user’s utterance in order to process it (Dohsaka and Shimazu, 1997; Allen et al., 2001; Schlangen and Skantze, 2011). New audio information is captured by an incremental Automatic Speech Recognition (ASR) at a certain frequency (Breslin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Se</context>
</contexts>
<marker>Schlangen, Skantze, 2011</marker>
<rawString>David Schlangen and Gabriel Skantze. 2011. A general, abstract model of incremental dialogue processing. Dialogue and Discourse, 2:83–111.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Searle</author>
</authors>
<title>Speech Acts: An Essay in the Philosophy of Language.</title>
<date>1969</date>
<publisher>Cambridge University Press, UK.</publisher>
<contexts>
<context position="3076" citStr="Searle, 1969" startWordPosition="480" endWordPosition="481"> interesting to implement given the task at hand. As an illustration, five TTP (which we assume have the best properties to improve the dialogue efficiency) have been implemented and compared in a slotfilling simulated environment. Section 2 introduces the TTP taxonomy and Section 3 describes the simulated environment, the experimental setup and the results. We then conclude in Section 4. 2 Turn-taking phenomena taxonomy In linguistics and philosophy of language, a distinction is made between two different levels of a speech act analysis: locutionary acts and illocutionary acts (Austin, 1962; Searle, 1969). Loosely speaking, a locutionary act refers to the act of uttering sounds without taking their meaning into account. When the semantic information is the object of interest, it is an illocutionary act. In (Raux and Eskenazi, 2009), four basic turn-taking transitions are presented: the turn transitions with gap, the turn transitions with overlap, the failed interruptions and the time outs where only the mechanics of turn-taking are studied at a locutionary level. In (Gravano and Hirschberg, 2011), the authors propose a turn-taking labeling scheme, which is a modified version of the original cl</context>
</contexts>
<marker>Searle, 1969</marker>
<rawString>John Searle. 1969. Speech Acts: An Essay in the Philosophy of Language. Cambridge University Press, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ethan O Selfridge</author>
<author>Iker Arizmendi</author>
<author>Peter A Heeman</author>
<author>Jason D Williams</author>
</authors>
<title>Stability and accuracy in incremental speech recognition.</title>
<date>2011</date>
<booktitle>In Proceedings of the SIGDIAL 2011 Conference.</booktitle>
<contexts>
<context position="12565" citStr="Selfridge et al., 2011" startWordPosition="2097" endWordPosition="2101">ord. For example: I, I want, I want to, I want to add...etc. In incremental dialogue systems, the turn increment (called the micro-turn in this case) could be different than the word (a small duration for example). The ASR output simulator can be used in both modes, but as the traditional mode is a special case of the incremental one, we describe the latter only. This module computes a noisy version of each word (substitution, deletion, or insertion). It also associates a confidence score with each new partial utterance. Moreover, a word in the ASR output can change later as new words pop in (Selfridge et al., 2011; McGraw and Gruenstein, 2012). In the following, this mechanism is referred to as the ASR instability. At each micro-turn, the sys1892 tem can keep listening to the US or decide to take the floor (see Section 3.4). 3.4 Scheduler The same architecture as in (Khouzaimi et al., 2014) is used. A Scheduler module is inserted between the service and the user simulator. As the ASR output utterance grows, the partial utterances are sent, at each micro-turn, to the Scheduler. In turn, the latter transfers them to the service and waits for its responses. The aim of this module is to make turn-taking de</context>
</contexts>
<marker>Selfridge, Arizmendi, Heeman, Williams, 2011</marker>
<rawString>Ethan O. Selfridge, Iker Arizmendi, Peter A. Heeman, and Jason D. Williams. 2011. Stability and accuracy in incremental speech recognition. In Proceedings of the SIGDIAL 2011 Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ethan Selfridge</author>
<author>Iker Arizmendi</author>
<author>Peter Heeman</author>
<author>Jason Williams</author>
</authors>
<title>Continuously predicting and processing barge-in during a live spoken dialogue task.</title>
<date>2013</date>
<booktitle>In Proceedings of the SIGDIAL 2013 Conference.</booktitle>
<contexts>
<context position="2062" citStr="Selfridge et al., 2013" startWordPosition="312" endWordPosition="315">tely. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Several contributions already explored different TTP like end-point detection (Raux and Eskenazi, 2008), backchannels (Meena et al., 2014; Visser et al., 2014), feedback (Skantze and Schlangen, 2009) or barge-in (Selfridge et al., 2013; Ghigi et al., 2014). However, these studies have been performed separately with no unified view and no comparison of respective merits, importance and co-influence of the different TTP. In order to have a better grasp on the concept of turn-taking in a dialogue and a guideline for the implementation, we felt the need to introduce a taxonomy of these TTP. Our motivation is to clarify which TTP are interesting to implement given the task at hand. As an illustration, five TTP (which we assume have the best properties to improve the dialogue efficiency) have been implemented and compared in a sl</context>
<context position="8077" citStr="Selfridge et al., 2013" startWordPosition="1309" endWordPosition="1312">interrupt G to add some information that is relevant to the course of the dialogue (BARGE IN RESP). Finally, she can wait until G has finished his utterance (G COMPLETE) and warn him that he should add more information (REKINDLE, for example: And?) or start a new dialogue turn (END POINT). In the rest of this paper, five incremental TTP that are the more used in general, and therefore studied, have been tested in a simulated environment: FAIL RAW (Ghigi et al., 2014), INCOHERENCE INTERP (DeVault et al., 2011), FEEDBACK RAW (Skantze and Schlangen, 2009) and BARGE IN RESP from both sides, user (Selfridge et al., 2013) and system interruptions (DeVault et al., 2011), along with G NONE G FAIL G INCOHERENT G INCOMPLETE G INSUFFICIENT G SUFFICIENT G COMPLETE T REF IMPL T REF RAW T REF INTERP T MOVE 1891 INIT DIALOGUE and END POINT that already exist in traditional systems. 3 Simulation 3.1 Service task A personal agenda assistant task has been implemented in the simulated dialogue system (referred to as the service hereafter). The user can add events to her agenda as long as they do not overlap with existing events. She can also move events in the agenda or delete them (ADD, MODIFY and DELETE actions). An even</context>
</contexts>
<marker>Selfridge, Arizmendi, Heeman, Williams, 2013</marker>
<rawString>Ethan Selfridge, Iker Arizmendi, Peter Heeman, and Jason Williams. 2013. Continuously predicting and processing barge-in during a live spoken dialogue task. In Proceedings of the SIGDIAL 2013 Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Skantze</author>
<author>David Schlangen</author>
</authors>
<title>Incremental dialogue processing in a micro-domain.</title>
<date>2009</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="1825" citStr="Skantze and Schlangen, 2009" startWordPosition="279" endWordPosition="282">01; Schlangen and Skantze, 2011). New audio information is captured by an incremental Automatic Speech Recognition (ASR) at a certain frequency (Breslin et al., 2013) and at each new step, the partial available information is processed immediately. Therefore, the system is able to replicate a rich set of turntaking phenomena (TTP) that are performed by human beings when talking to each other (Sacks et al., 1974; Clark, 1996). Replicating these TTP in dialogue systems can help to make them more efficient (e.g. (El Asri et al., 2014)) and enhance their ability to recover from misunderstandings (Skantze and Schlangen, 2009). Several contributions already explored different TTP like end-point detection (Raux and Eskenazi, 2008), backchannels (Meena et al., 2014; Visser et al., 2014), feedback (Skantze and Schlangen, 2009) or barge-in (Selfridge et al., 2013; Ghigi et al., 2014). However, these studies have been performed separately with no unified view and no comparison of respective merits, importance and co-influence of the different TTP. In order to have a better grasp on the concept of turn-taking in a dialogue and a guideline for the implementation, we felt the need to introduce a taxonomy of these TTP. Our </context>
<context position="8012" citStr="Skantze and Schlangen, 2009" startWordPosition="1297" endWordPosition="1300"> for example Yeah, Sunday is the only day when I am free). T can also interrupt G to add some information that is relevant to the course of the dialogue (BARGE IN RESP). Finally, she can wait until G has finished his utterance (G COMPLETE) and warn him that he should add more information (REKINDLE, for example: And?) or start a new dialogue turn (END POINT). In the rest of this paper, five incremental TTP that are the more used in general, and therefore studied, have been tested in a simulated environment: FAIL RAW (Ghigi et al., 2014), INCOHERENCE INTERP (DeVault et al., 2011), FEEDBACK RAW (Skantze and Schlangen, 2009) and BARGE IN RESP from both sides, user (Selfridge et al., 2013) and system interruptions (DeVault et al., 2011), along with G NONE G FAIL G INCOHERENT G INCOMPLETE G INSUFFICIENT G SUFFICIENT G COMPLETE T REF IMPL T REF RAW T REF INTERP T MOVE 1891 INIT DIALOGUE and END POINT that already exist in traditional systems. 3 Simulation 3.1 Service task A personal agenda assistant task has been implemented in the simulated dialogue system (referred to as the service hereafter). The user can add events to her agenda as long as they do not overlap with existing events. She can also move events in th</context>
</contexts>
<marker>Skantze, Schlangen, 2009</marker>
<rawString>Gabriel Skantze and David Schlangen. 2009. Incremental dialogue processing in a micro-domain. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard S Sutton</author>
<author>Andrew G Barto</author>
</authors>
<title>Reinforcement Learning, An Introduction.</title>
<date>1998</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, Massachusetts, London, England.</location>
<marker>Sutton, Barto, 1998</marker>
<rawString>Richard S. Sutton and Andrew G. Barto. 1998. Reinforcement Learning, An Introduction. The MIT Press, Cambridge, Massachusetts, London, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Visser</author>
<author>David Traum</author>
<author>David DeVault</author>
<author>Rieks op den Akker</author>
</authors>
<title>A model for incremental grounding in spoken dialogue systems.</title>
<date>2014</date>
<journal>Journal on Multimodal User Interfaces.</journal>
<marker>Visser, Traum, DeVault, den Akker, 2014</marker>
<rawString>Thomas Visser, David Traum, David DeVault, and Rieks op den Akker. 2014. A model for incremental grounding in spoken dialogue systems. Journal on Multimodal User Interfaces.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiahong Yuan</author>
<author>Mark Liberman</author>
<author>Christopher Cieri</author>
</authors>
<title>Towards an integrated understanding of speaking rate in conversation.</title>
<date>2006</date>
<booktitle>In INTERSPEECH Proceedings.</booktitle>
<contexts>
<context position="11472" citStr="Yuan et al., 2006" startWordPosition="1906" endWordPosition="1909">ike I would like to...) and suffixes (like please, if possible...). Also, a few sentences are replaced with off-domain words or repeated twice as it is the case in real dialogues (Ghigi et al., 2014). For questions concerning a specific slot, neither prefixes nor suffixes are added. Patience Manager: When the dialogue lasts too long, the US can get impatient and hang up. The US patience corresponds to a threshold on each task duration. It is randomly sampled around a mean of 180 seconds for the experiments. A speech rate of 200 words per minute is assumed for the dialogue duration estimation (Yuan et al., 2006). Moreover, a silence of one second is assumed at each regular system/user transition and a two second silence is assumed the other way round. For interruptions and accurate end-point detection, no silence is taken into account. 3.3 ASR Output Simulator The US can run either in a traditional mode in the sense that it provides a complete utterance to the system then it waits for a response, or in an incremental mode where a growing utterance is outputted at each new word. For example: I, I want, I want to, I want to add...etc. In incremental dialogue systems, the turn increment (called the micr</context>
</contexts>
<marker>Yuan, Liberman, Cieri, 2006</marker>
<rawString>Jiahong Yuan, Mark Liberman, and Christopher Cieri. 2006. Towards an integrated understanding of speaking rate in conversation. In INTERSPEECH Proceedings.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>