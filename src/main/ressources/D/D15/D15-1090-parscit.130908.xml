<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001239">
<title confidence="0.841783">
Predicting the Structure of Cooking Recipes
</title>
<author confidence="0.857906">
Jermsak Jermsurawong and Nizar Habash
</author>
<affiliation confidence="0.880176">
Computational Approaches to Modeling Language Lab
Computer Science
</affiliation>
<address confidence="0.544064">
New York University Abu Dhabi
United Arab Emirates
</address>
<email confidence="0.998251">
{jermsak.jermsurawong,nizar.habash}@nyu.edu
</email>
<sectionHeader confidence="0.997385" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999929133333333">
Cooking recipes exist in abundance; but
due to their unstructured text format, they
are hard to study quantitatively beyond
treating them as simple bags of words.
In this paper, we propose an ingredient-
instruction dependency tree data structure
to represent recipes. The proposed rep-
resentation allows for more refined com-
parison of recipes and recipe-parts, and is
a step towards semantic representation of
recipes. Furthermore, we build a parser
that maps recipes into the proposed rep-
resentation. The parser’s edge prediction
accuracy of 93.5% improves over a strong
baseline of 85.7% (54.5% error reduction).
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99989896969697">
Cooking recipes are a specific genre of how-to in-
structions which have been gaining interest in re-
cent years as they may allow us to discover in-
sights into culinary and cultural preferences. Most
of the work studying recipes relies on simple in-
gredient bag-of-word representations. While such
representations may suffice for many purposes,
they fail to capture much of the recipes’ internal
structure. A smaller number of efforts focus on se-
mantic representations of cooking recipes with an
eye toward more complex and deep understand-
ing. Natural language processing (NLP) tech-
niques have been used to interpret cooking instruc-
tions; however, the results have not been as suc-
cessful as other language genres due to the unique
aspects of cooking recipes.
This paper makes two contributions. First, we
propose an ingredient-instruction dependency tree
representation of recipe structure. This represen-
tation abstracts textual recipes more expressively
than bag-of-word representations; and it allows for
more nuanced comparisons of recipes. Second,
we present a cooking recipe parser that maps text
recipes into our proposed ingredient-instruction
tree structures. The overall accuracy of predicting
edges of our ingredient-instruction trees is 93.5%,
beating a strong baseline of 85.7%, and achieving
a relative error reduction of 54.5%.
We present next some related work (Section 2)
followed by a discussion of the structure of recipes
and our representation (Section 3). Section 4 de-
tails the recipe parser design, implementation and
evaluation.
</bodyText>
<sectionHeader confidence="0.999944" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999874387096774">
There have been many efforts on the processing of
cooking recipes using models that range from bags
of words to complex semantic representations.
Among the approaches to studying recipes as
ingredient bags of words, Ahn et al. (2011) con-
structed a data-driven flavor network relating in-
gredients together. Jain et al. (2015) adopted Ahn
et al. (2011)’s framework to further analyze culi-
nary practices of specific cultures. Nedovic (2013)
examined underlying ingredient groupings from
their recipe co-occurrences, using topic modeling
techniques (latent Dirichlet allocation), and fur-
ther improvised novel ingredient combinations us-
ing deep belief networks.
Among the structured representation ap-
proaches, Tasse and Smith (2008) proposed
MILK (Minimal Instruction Language for the
Kitchen), a formal language to describe actions
required in directive cooking instructions. They
used MILK in developing CURD (Carnegie
Mellon University Recipe Database), a corpus of
manually annotated recipes. Mori et al. (2014)
also manually annotated the procedural flow of
Japanese cooking recipes using directed acyclic
graphs (DAGs) where graph nodes correspond
to food ingredients, cooking instruments, and
actions. Tasse and Smith (2008) had limited
success in parsing into MILK; and Mori et al.
(2014) did not report on parsing experiments.
Other studies explored different machine learn-
ing and NLP techniques to processing recipes.
</bodyText>
<page confidence="0.97179">
781
</page>
<note confidence="0.8677265">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 781–786,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figure confidence="0.891056076923077">
Text Recipe SIMMR
ingredients inst9
0 6 (2 inch thick) slices French bread
1 1/4 cup ricotta cheese inst8
2 1/4 cup cottage cheese, whipped inst7
3 2 tablespoons lowfat cream cheese
4 2 teaspoons white sugar inst6
5 2 teaspoons vanilla extract
6 3 cups egg substitute
7 1/4 cup evaporated milk
instructions
0 Cut a pocket in each slice of bread. inst4 inst5
1 Open carefully ing6 ing7
</figure>
<listItem confidence="0.706647583333333">
2 In a large bowl, combine the ricotta, egg milk
cottage cheese and cream cheese.
3 Add the sugar and flavoring extract inst1 inst3
and beat until smooth.
4 Spread the mixture evenly into each inst0
bread pocket. ing0
5 Beat together the egg substitutes and milk. french inst2 ing4 ing5
6 Dip the slices of bread in the egg mixture. bread sugar vanilla
7 Heat a nonstick pan over medium-high heat.
8 Coat with cooking spray. ing1 ing2 ing3
9 Cook the toast on each side for about 3 ricotta cottage cream
to 4 minutes per side until golden brown. cheese
</listItem>
<figureCaption confidence="0.948552">
Figure 1: Example of a text recipe for Surprise-inside French Toast and its SIMMR representation.
ing&lt;index&gt; and inst&lt;index&gt; refer to specific ingredients and instructions, respectively.
</figureCaption>
<bodyText confidence="0.998657655172414">
Mori et al. (2012) applied word segmentation,
named entity recognition, and syntactic analy-
sis to extract predicate-argument structures from
Japanese recipe instructions as part of an effort
to develop complete recipe flow representations.
Malmaud et al. (2014) proposed a Markov Deci-
sion Process, in which the context of ingredients
and tools is propagated along the temporal order
of cooking instructions.
Most recently, Abend et al. (2015) proposed an
edge-factored model to determine the likely tem-
poral order of events based solely on the identity
of their predicates and arguments. They demon-
strated their approach on recipe text, under the
simplifying assumption that such text is also tem-
porally ordered.
In this paper, we present an ingredient-
instruction dependency tree representation of
recipe structure, which we call SIMMR (Simpli-
fied Ingredient Merging Map in Recipes). The
SIMMR representation captures the high-level
flow of ingredients but without modeling the se-
mantics in each individual instruction unlike other
efforts (Tasse and Smith, 2008; Mori et al., 2012;
Mori et al., 2014). We create a corpus in our rep-
resentation by converting the recipes in the CURD
corpus (Tasse and Smith, 2008) from MILK to
SIMMR. We also develop a parser to generate
SIMMR trees from input recipes.
</bodyText>
<sectionHeader confidence="0.97804" genericHeader="method">
3 Recipe Representation
</sectionHeader>
<subsectionHeader confidence="0.998265">
3.1 Text Recipes
</subsectionHeader>
<bodyText confidence="0.999989333333333">
The prototypical text recipe consists of two parts:
an ingredient list that declares the food items to
process, and a set of instructions that mostly de-
scribe the transformations of the ingredients or the
actions using the kitchen tools. The instructions
relocate, process, combine, and separate ingredi-
ents, as well as heat or cool utensils in the recipes.
For the most part, the output produced from one
instruction feeds as input into another instruction.
The list of ingredients can be generalized as spe-
cial fetch instructions whose output feeds as input
to one of the cooking instructions.
</bodyText>
<subsectionHeader confidence="0.995605">
3.2 SIMMR
</subsectionHeader>
<bodyText confidence="0.999960769230769">
Our proposed representation is SIMMR: Simpli-
fied Ingredient Merging Map in Recipes. SIMMR
represents a recipe as a dependency tree whose
leaves (terminal nodes) are the recipe ingredients,
and whose internal nodes are the recipe instruc-
tions. Figure 1 exemplifies the SIMMR tree of a
recipe for Surprise-inside French Toast. Indices
for all ingredients and instructions are provided
here to illustrate mapping between the different
parts of the text recipe and its SIMMR tree. The
subtree headed by inst2 indicates that ingredients
#1, #2 and #3 (three cheeses) are inputs to instruc-
tion #2, whose output is then an input to instruc-
</bodyText>
<page confidence="0.984289">
782
</page>
<bodyText confidence="0.999933333333333">
tion #3, together with ingredients #4 and #5 (sugar
and vanilla). The SIMMR tree provides additional
insights into the structure of recipes, suggesting
in the case of this example, that multiple actions
can take place in different orders without changing
the recipe so long as the order of combinations is
not changed. Some instructions simply transforms
their input to produce their output, e.g. instruc-
tions #1, #7, #8 and #9.
</bodyText>
<subsectionHeader confidence="0.997778">
3.3 From MILK to SIMMR
</subsectionHeader>
<bodyText confidence="0.999988025641026">
We use MILK commands from the CMU CURD
database (Tasse and Smith, 2008) to construct
a database of SIMMR trees. The MILK lan-
guage is a lot more expressive that SIMMR. For
example, instruction #2 in Figure 1 translates
into create tool(t0, “large bowl”); combine(ing1,
ing2, ing3, ing9, “cheeses”, “”); and put(ing9,
t0). These details of ingredient processing are ab-
stracted away in SIMMR. To accomplish SIMMR
instruction and ingredient linking, we process
MILK instructions in order, tracing with MILK id
numbers when each ingredient or its transformed
or combined form at one instruction node is called
for by a subsequent instruction node. The MILK
intermediate names for instruction outputs (e.g.,
“cheeses” above) are not adopted in SIMMR. Ad-
ditionally, food items that appear in instructions
but are not part of the recipe ingredient list text are
not included in SIMMR although MILK assigns
ingredient ids to them. For example, instruction
#8 mentions cooking spray, which is not on the in-
gredient list. As a result inst8 looks like it has no
ingredients coming into it other than the output of
inst7.
We assume in SIMMR that at most one output is
produced from each instruction. One MILK com-
mand, separate, violates this assumption. For ex-
ample, the instruction drain off the fat, and place
the mixture into a slow cooker is MILK-tagged
with a separate command to dispose fat, and re-
tain the mixture. We ignore the separate command
which occurs in 3% of all recipes (and 1.3% of the
time involves disposing of a separated ingredient,
such as draining offfat).
Instructions that do not interact with food, such
as those calling for preheating the oven or lining
the baking sheets, are considered to take the ingre-
dient mixture of the cooking instruction immedi-
ately prior and produce the same output.
</bodyText>
<sectionHeader confidence="0.993134" genericHeader="method">
4 Recipe Parser
</sectionHeader>
<bodyText confidence="0.999770818181818">
In this section, we present our SIMMR tree recipe
parser. The input and output of the parser cor-
respond to the left hand and right hand sides of
Figure 1. We split the parsing process into two
phases: first we link ingredients to instructions
where the ingredients are first used; then we link
instructions to other instructions, where the tar-
get instruction uses the source instruction’s output.
We present the different challenges and solutions
employed in each phase below and present evalu-
ation results.
</bodyText>
<subsectionHeader confidence="0.8539885">
4.1 Experimental Setup
4.1.1 Data
</subsectionHeader>
<bodyText confidence="0.999922615384615">
We use a total of 260 recipes downloaded from
CMU Recipe Database. MILK tags are used to
construct the SIMMR trees as mentioned above.
The dataset is randomly split (along recipe bound-
aries) into training, development, and test sets with
ratios of 50%, 20%, and 30%, respectively. The
development set is used for tuning parameters. We
report here on the test set only. We preprocess
the data using standard NLP packages to tokenize,
stem, and POS tag the words (De Marneffe et al.,
2006; Bird et al., 2009; De Smedt and Daelemans,
2012). We further remove stop words and quantity
measures.1
</bodyText>
<subsectionHeader confidence="0.569604">
4.1.2 Metrics
</subsectionHeader>
<bodyText confidence="0.999919571428571">
The evaluation metric is the accuracy of predict-
ing edges in the SIMMR tree. This is compara-
ble to the attachment score in dependency pars-
ing. The overall accuracy of the task is computed
at the edge level (counting all edges in the data
set), and at the recipe level (average accuracy over
all recipes).
</bodyText>
<subsectionHeader confidence="0.8967905">
4.2 Ingredient-Instruction Linking
4.2.1 Challenges
</subsectionHeader>
<bodyText confidence="0.865494230769231">
There are several characteristics of recipe text that
do not reveal explicit linking of ingredients to in-
structions that first use them. The ingredients are
sometimes referred to by their qualifiers or onto-
logical classes. For example, the ingredient 1 (15
oz) can sliced peaches, drained may be referred
to in the instruction as canned fruit. In addition,
1Since we start from the MILK representations, the set
of ingredients and instructions are clearly identified in each
recipe. However, we do not expect this to be the case when
starting from raw text recipes, which need to be processed to
segment the different ingredients and instructions. We do not
attempt this step in this paper and leave it as future work.
</bodyText>
<page confidence="0.996613">
783
</page>
<table confidence="0.999032">
Edge-level Recipe-level
Accuracy Accuracy
Baseline 84.3 84.8
SVMrank 95.3 95.8
</table>
<tableCaption confidence="0.9137345">
Table 1: Performance of different learning models
for ingredient-instruction linking
</tableCaption>
<bodyText confidence="0.893153">
a number of ingredients are sometimes referred to
as a group entity without specific mentions, e.g.,
Add the remaining ingredients, or mix together the
dry ingredients.
</bodyText>
<subsectionHeader confidence="0.583064">
4.2.2 Baseline
</subsectionHeader>
<bodyText confidence="0.9998775">
For each instruction, in order, we compute all the
maximum stemmed n-gram chunk matches against
all ingredients. For each matching token chunk of
the instruction, if it matches only one ingredient,
we link the ingredient to the instruction and mark
the ingredient as used. Otherwise, we compute the
Levenshtein distance between the unstemmed sur-
face text of both the ingredient candidate matches
and the instruction token chunk, and take the high-
est matching ingredient. Once an ingredient is
used, it is no longer available for linking with sub-
sequent instructions.
</bodyText>
<subsubsectionHeader confidence="0.618937">
4.2.3 Features and Linking
</subsubsectionHeader>
<bodyText confidence="0.99922275">
For each ingredient-instruction edge, we provide
1,136 features to classify whether the edge exists
or not. The following are some of the most impor-
tant features we use:
</bodyText>
<listItem confidence="0.982848707317073">
• The baseline decision for the ingredient-
instruction edge.
• The number of distinct unigram matches.
• The largest match size.
• The sum of the relative frequency (in the list
of instructions) of every word in the largest
match (henceforth SRFM).
• The degree of similarity between SRFM and
the instruction relative position (InstRP) in
the instruction list. The intuition for this fea-
ture is that if an ingredient is mentioned more
often in the recipe, its first mention is likely
to be in an earlier instruction. This feature is
computed as (1 − |SRFM − InstRP|).
• The degree of similarity between the ingredi-
ent relative position (IngRP) in the ingredient
list and the InstRP. This feature captures an
observation that earlier listed ingredients are
used by earlier instructions. We compute the
feature as (1 − |IngRP − InstRP|).
• To model the first word of each instruction
(i.e., the directive verb such as heat or mix),
we use a binary term vector whose vocab-
ulary is constructed from all the instruction
first words in the training data.
• We model the maximum ingredient-
instruction word match using a binary
term vector whose vocabulary covers
non-directive recipe words (NDRW). We
construct the NDRW vocabulary by taking
the union of the set of words from the
compiled food item list of Ahn et al. (2011)
and the non-first words of the instructions in
the training data.
• If there is a match, we model its surround-
ing words using a similar binary term vector
(NDRW vocabulary). If there is no match,
the vector will be empty.
• We use a binary term vector (NDRW vocabu-
lary also) to model the non-first words in the
instruction.
</listItem>
<bodyText confidence="0.99932725">
We train using Linear SVMrank (Joachims,
2006).2 The test set results are shown in Table 1.
Ranking edges using SVMrank and then picking
the best one significantly outperforms the baseline.
</bodyText>
<subsectionHeader confidence="0.939228">
4.2.4 Linking Errors
</subsectionHeader>
<bodyText confidence="0.999656714285714">
Among the linking errors, three patterns appear.
First, stemming reduces the specificity of some of
the terms, e.g., one prediction links baking powder
to an action bake for 30 minutes. Second, our ap-
proach does not handle negated mentions, e.g. the
instruction mix together the dry ingredients, ex-
cept the candies is incorrectly linked to ingredi-
ent candy. Finally, the ingredients flour and butter
are specifically part of many erroneous links be-
cause they are often used in small quantities to fa-
cilitate the cooking process such as board flouring
and pan greasing. MILK does not always account
for this trivial use of these ingredients and neither
does SIMMR.
</bodyText>
<subsectionHeader confidence="0.997712">
4.3 Instruction-Instruction Linking
4.3.1 Challenges
</subsectionHeader>
<bodyText confidence="0.9998515">
Although cooking instructions are written with an
implied temporal order, they are not linked in a
linear chain. Rather, the instructions describe dif-
ferent cooking stages, where the output of apply-
</bodyText>
<footnote confidence="0.9942184">
2We also experimented Linear SVM and Gaussian Kernel
SVM (Pedregosa et al., 2011). We used the distance from
the hyperplane to select the best edge among the set of edges
connecting an ingredient. However, these techniques under-
performed compared to SVMrank.
</footnote>
<page confidence="0.996689">
784
</page>
<bodyText confidence="0.99994825">
ing a number of instructions waits until other in-
structions are finished to be used again, e.g., the
output of instruction #1 in Figure 1 waits until in-
structions #2 and #3 are done. Sometimes stage
switching is explicitly stated as in Set aside the
flour mixture, and combine eggs and oil together;
however, this is not the common case. Further-
more, the waiting output of an earlier stage may
be referred to collectively or using the main ingre-
dient which makes linking harder, e.g., referring
to the output of an instruction combining chicken,
salt and pepper as chicken.
</bodyText>
<subsectionHeader confidence="0.917946">
4.3.2 Baseline
</subsectionHeader>
<bodyText confidence="0.999962333333333">
We link the instructions in a linear chain. In
the training set, 89% of the instruction-instruction
links are to the immediate neighbor.
</bodyText>
<subsubsectionHeader confidence="0.698491">
4.3.3 Features and Linking
</subsubsectionHeader>
<bodyText confidence="0.999845171428572">
For each possible instruction-instruction edge, we
provide 1,573 features to classify if the edge exists
or not. The features group into three categories.
First are words that suggest cooking stage
switching, e.g., ingredient mixture words such as
mixture, dough, and batter, or the simple men-
tion of new containers and utensils. They are
represented as binary features indicating whether
the words appear in either or both instructions
along the considered edge, as well as in imme-
diate neighboring instructions. Logic operations
(and, or) are further applied to all pairs of these
features. Another feature in this group is a binary
verb conjugation feature that marks the presence
of a past participle verb in the target instruction
and a non-past-participle form of the same verb in
the source instruction. The intuition here is that an
instruction that asks to chop an ingredient would
be followed later by an instruction containing the
word chopped when referring to the ingredient.
The second group consists of features that en-
code whether the n previous or future instructions
has m linked ingredients, where n ranges from 1
to 3 and m ranges from 0 to 4.
Finally, the third group deals with term vec-
tors describing the source and target instructions,
as well as, the instructions’ first words (the direc-
tives). The term vector vocabularies used are the
same as those discussed above in the ingredient-
instruction linking section.
We additionally consider decoupling the fea-
tures for the case of immediate neighboring in-
structions from the further apart instructions. In
the decoupled mode, we effectively double the
number of features for each edge with nils used
</bodyText>
<table confidence="0.9989042">
Edge-level Recipe-level
Accuracy Accuracy
Baseline 87.6 89.5
SVMrank 90.5 92.0
SVMrank - decoupled 91.3 92.4
</table>
<tableCaption confidence="0.8983065">
Table 2: Performance of different learning models
for instruction-instruction linking
</tableCaption>
<bodyText confidence="0.999278">
to fill in the gaps. This allows us to learn different
models for adjacent and apart instructions. The re-
sults are in Table 2 and show that decoupling fea-
tures in SVMrank is our best setting.
Examining the weights learned for adjacent and
long-distance edge features gives some interesting
insights. One example is that the verb conjuga-
tion feature has a higher weight for long-distance
edges compared to adjacent edges. This is un-
derstandable as most adjacent pairs of instructions
would not exhibit this feature to express cooking
progress: it is redundant to state, cook the pasta,
and immediately refer to that pasta as the cooked
pasta.
</bodyText>
<subsectionHeader confidence="0.906127">
4.3.4 Linking Errors
</subsectionHeader>
<bodyText confidence="0.999939428571428">
As the distance between linked instructions in-
creases, the likelihood of error also increases:
while long-distance (i.e., non-adjacent) links con-
stitute 12.3% of the reference, they are 91.7% of
the errors. We expect that more training examples
of long-distance linking can help address this is-
sue.
</bodyText>
<subsectionHeader confidence="0.997794">
4.4 Overall Accuracy
</subsectionHeader>
<bodyText confidence="0.99997675">
The overall edge-level accuracy of constructing
the full SIMMR tree is 93.5%, outperforming a
baseline of 85.7%, and achieving error reduction
of 54.5%.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999989769230769">
We proposed a new ingredient-instruction depen-
dency tree representation to capture the internal
structure of cooking recipes, and built a parser for
it. Our overall parsing accuracy is 93.5%, outper-
forming a strong baseline of 85.7%.
We will make our SIMMR database, and our
SIMMR parser publicly available. Further, we
plan to build on SIMMR to get closer to the MILK
representation. We also plan on parsing a large
corpus of text recipes to provide structural features
on a large scale that will allow us to discover new
patterns of similarity across and within cuisines,
as well as generate new recipes.
</bodyText>
<page confidence="0.997529">
785
</page>
<sectionHeader confidence="0.99834" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999919346153846">
Omri Abend, Shay B Cohen, and Mark Steedman.
2015. Lexical event ordering with an edge-factored
model. In Proceedings of NAACL.
Yong-Yeol Ahn, Sebastian E Ahnert, James P Bagrow,
and Albert-L´aszl´o Barab´asi. 2011. Flavor network
and the principles of food pairing. Scientific reports,
1.
Steven Bird, Ewan Klein, and Edward Loper.
2009. Natural language processing with Python.
”O’Reilly Media, Inc.”.
Marie-Catherine De Marneffe, Bill MacCartney,
Christopher D Manning, et al. 2006. Generat-
ing typed dependency parses from phrase structure
parses. In Proceedings of LREC, volume 6, pages
449–454.
Tom De Smedt and Walter Daelemans. 2012. Pattern
for python. The Journal of Machine Learning Re-
search, 13(1):2063–2067.
Anupam Jain, Ganesh Bagler, et al. 2015. Spices form
the basis of food pairing in indian cuisine. arXiv
preprint arXiv:1502.03815.
Thorsten Joachims. 2006. Training linear svms in lin-
ear time. In Proceedings of the 12th ACM SIGKDD
international conference on Knowledge discovery
and data mining, pages 217–226. ACM.
Jon Malmaud, Earl J Wagner, Nancy Chang, and Kevin
Murphy. 2014. Cooking with semantics. ACL 2014,
page 33.
Shinsuke Mori, Tetsuro Sasada, Yoko Yamakata, and
Koichiro Yoshino. 2012. A machine learning ap-
proach to recipe text processing. In Proc. of the 1st
Cooking with Computer Workshop, pages 29–34.
Shinsuke Mori, Hirokuni Maeta, Yoko Yamakata, and
Tetsuro Sasada. 2014. Flow graph corpus from
recipe texts. In Proceedings of the Nineth Interna-
tional Conference on Language Resources and Eval-
uation, pages 2370–2377.
V Nedovic. 2013. Learning recipe ingredient space
using generative probabilistic models. In Proceed-
ings of Cooking with Computers Workshop (CwC),
volume 1, pages 13–18.
F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel,
B. Thirion, O. Grisel, M. Blondel, P. Pretten-
hofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Pas-
sos, D. Cournapeau, M. Brucher, M. Perrot, and
E. Duchesnay. 2011. Scikit-learn: Machine learn-
ing in Python. Journal of Machine Learning Re-
search, 12:2825–2830.
Dan Tasse and Noah A Smith. 2008. Sour cream: To-
ward semantic processing of recipes. Technical re-
port, Technical Report CMU-LTI-08-005, Carnegie
Mellon University, Pittsburgh, PA.
</reference>
<page confidence="0.998411">
786
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.176748">
<title confidence="0.852972333333333">Predicting the Structure of Cooking Recipes Jermsurawong Computational Approaches to Modeling Language</title>
<note confidence="0.421519666666667">Computer New York University Abu United Arab Emirates</note>
<abstract confidence="0.99885425">Cooking recipes exist in abundance; but due to their unstructured text format, they are hard to study quantitatively beyond treating them as simple bags of words. In this paper, we propose an ingredientinstruction dependency tree data structure to represent recipes. The proposed representation allows for more refined comparison of recipes and recipe-parts, and is a step towards semantic representation of recipes. Furthermore, we build a parser that maps recipes into the proposed representation. The parser’s edge prediction accuracy of 93.5% improves over a strong baseline of 85.7% (54.5% error reduction).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Omri Abend</author>
<author>Shay B Cohen</author>
<author>Mark Steedman</author>
</authors>
<title>Lexical event ordering with an edge-factored model.</title>
<date>2015</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="5630" citStr="Abend et al. (2015)" startWordPosition="853" endWordPosition="856">Example of a text recipe for Surprise-inside French Toast and its SIMMR representation. ing&lt;index&gt; and inst&lt;index&gt; refer to specific ingredients and instructions, respectively. Mori et al. (2012) applied word segmentation, named entity recognition, and syntactic analysis to extract predicate-argument structures from Japanese recipe instructions as part of an effort to develop complete recipe flow representations. Malmaud et al. (2014) proposed a Markov Decision Process, in which the context of ingredients and tools is propagated along the temporal order of cooking instructions. Most recently, Abend et al. (2015) proposed an edge-factored model to determine the likely temporal order of events based solely on the identity of their predicates and arguments. They demonstrated their approach on recipe text, under the simplifying assumption that such text is also temporally ordered. In this paper, we present an ingredientinstruction dependency tree representation of recipe structure, which we call SIMMR (Simplified Ingredient Merging Map in Recipes). The SIMMR representation captures the high-level flow of ingredients but without modeling the semantics in each individual instruction unlike other efforts (T</context>
</contexts>
<marker>Abend, Cohen, Steedman, 2015</marker>
<rawString>Omri Abend, Shay B Cohen, and Mark Steedman. 2015. Lexical event ordering with an edge-factored model. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yong-Yeol Ahn</author>
<author>Sebastian E Ahnert</author>
<author>James P Bagrow</author>
<author>Albert-L´aszl´o Barab´asi</author>
</authors>
<title>Flavor network and the principles of food pairing. Scientific reports,</title>
<date>2011</date>
<pages>1</pages>
<marker>Ahn, Ahnert, Bagrow, Barab´asi, 2011</marker>
<rawString>Yong-Yeol Ahn, Sebastian E Ahnert, James P Bagrow, and Albert-L´aszl´o Barab´asi. 2011. Flavor network and the principles of food pairing. Scientific reports, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<title>Natural language processing with Python.</title>
<date>2009</date>
<publisher>O’Reilly Media, Inc.”.</publisher>
<contexts>
<context position="11096" citStr="Bird et al., 2009" startWordPosition="1756" endWordPosition="1759">es and solutions employed in each phase below and present evaluation results. 4.1 Experimental Setup 4.1.1 Data We use a total of 260 recipes downloaded from CMU Recipe Database. MILK tags are used to construct the SIMMR trees as mentioned above. The dataset is randomly split (along recipe boundaries) into training, development, and test sets with ratios of 50%, 20%, and 30%, respectively. The development set is used for tuning parameters. We report here on the test set only. We preprocess the data using standard NLP packages to tokenize, stem, and POS tag the words (De Marneffe et al., 2006; Bird et al., 2009; De Smedt and Daelemans, 2012). We further remove stop words and quantity measures.1 4.1.2 Metrics The evaluation metric is the accuracy of predicting edges in the SIMMR tree. This is comparable to the attachment score in dependency parsing. The overall accuracy of the task is computed at the edge level (counting all edges in the data set), and at the recipe level (average accuracy over all recipes). 4.2 Ingredient-Instruction Linking 4.2.1 Challenges There are several characteristics of recipe text that do not reveal explicit linking of ingredients to instructions that first use them. The in</context>
</contexts>
<marker>Bird, Klein, Loper, 2009</marker>
<rawString>Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural language processing with Python. ”O’Reilly Media, Inc.”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>6</volume>
<pages>449--454</pages>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill MacCartney, Christopher D Manning, et al. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of LREC, volume 6, pages 449–454.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom De Smedt</author>
<author>Walter Daelemans</author>
</authors>
<title>Pattern for python.</title>
<date>2012</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>13</volume>
<issue>1</issue>
<marker>De Smedt, Daelemans, 2012</marker>
<rawString>Tom De Smedt and Walter Daelemans. 2012. Pattern for python. The Journal of Machine Learning Research, 13(1):2063–2067.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anupam Jain</author>
<author>Ganesh Bagler</author>
</authors>
<title>Spices form the basis of food pairing in indian cuisine. arXiv preprint arXiv:1502.03815.</title>
<date>2015</date>
<marker>Jain, Bagler, 2015</marker>
<rawString>Anupam Jain, Ganesh Bagler, et al. 2015. Spices form the basis of food pairing in indian cuisine. arXiv preprint arXiv:1502.03815.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Joachims</author>
</authors>
<title>Training linear svms in linear time.</title>
<date>2006</date>
<booktitle>In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>217--226</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="15075" citStr="Joachims, 2006" startWordPosition="2417" endWordPosition="2418">ngredientinstruction word match using a binary term vector whose vocabulary covers non-directive recipe words (NDRW). We construct the NDRW vocabulary by taking the union of the set of words from the compiled food item list of Ahn et al. (2011) and the non-first words of the instructions in the training data. • If there is a match, we model its surrounding words using a similar binary term vector (NDRW vocabulary). If there is no match, the vector will be empty. • We use a binary term vector (NDRW vocabulary also) to model the non-first words in the instruction. We train using Linear SVMrank (Joachims, 2006).2 The test set results are shown in Table 1. Ranking edges using SVMrank and then picking the best one significantly outperforms the baseline. 4.2.4 Linking Errors Among the linking errors, three patterns appear. First, stemming reduces the specificity of some of the terms, e.g., one prediction links baking powder to an action bake for 30 minutes. Second, our approach does not handle negated mentions, e.g. the instruction mix together the dry ingredients, except the candies is incorrectly linked to ingredient candy. Finally, the ingredients flour and butter are specifically part of many erron</context>
</contexts>
<marker>Joachims, 2006</marker>
<rawString>Thorsten Joachims. 2006. Training linear svms in linear time. In Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 217–226. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Malmaud</author>
<author>Earl J Wagner</author>
<author>Nancy Chang</author>
<author>Kevin Murphy</author>
</authors>
<title>Cooking with semantics. ACL</title>
<date>2014</date>
<pages>33</pages>
<contexts>
<context position="5449" citStr="Malmaud et al. (2014)" startWordPosition="824" endWordPosition="827">medium-high heat. 8 Coat with cooking spray. ing1 ing2 ing3 9 Cook the toast on each side for about 3 ricotta cottage cream to 4 minutes per side until golden brown. cheese Figure 1: Example of a text recipe for Surprise-inside French Toast and its SIMMR representation. ing&lt;index&gt; and inst&lt;index&gt; refer to specific ingredients and instructions, respectively. Mori et al. (2012) applied word segmentation, named entity recognition, and syntactic analysis to extract predicate-argument structures from Japanese recipe instructions as part of an effort to develop complete recipe flow representations. Malmaud et al. (2014) proposed a Markov Decision Process, in which the context of ingredients and tools is propagated along the temporal order of cooking instructions. Most recently, Abend et al. (2015) proposed an edge-factored model to determine the likely temporal order of events based solely on the identity of their predicates and arguments. They demonstrated their approach on recipe text, under the simplifying assumption that such text is also temporally ordered. In this paper, we present an ingredientinstruction dependency tree representation of recipe structure, which we call SIMMR (Simplified Ingredient Me</context>
</contexts>
<marker>Malmaud, Wagner, Chang, Murphy, 2014</marker>
<rawString>Jon Malmaud, Earl J Wagner, Nancy Chang, and Kevin Murphy. 2014. Cooking with semantics. ACL 2014, page 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shinsuke Mori</author>
<author>Tetsuro Sasada</author>
<author>Yoko Yamakata</author>
<author>Koichiro Yoshino</author>
</authors>
<title>A machine learning approach to recipe text processing.</title>
<date>2012</date>
<booktitle>In Proc. of the 1st Cooking with Computer Workshop,</booktitle>
<pages>29--34</pages>
<contexts>
<context position="5206" citStr="Mori et al. (2012)" startWordPosition="791" endWordPosition="794"> until smooth. 4 Spread the mixture evenly into each inst0 bread pocket. ing0 5 Beat together the egg substitutes and milk. french inst2 ing4 ing5 6 Dip the slices of bread in the egg mixture. bread sugar vanilla 7 Heat a nonstick pan over medium-high heat. 8 Coat with cooking spray. ing1 ing2 ing3 9 Cook the toast on each side for about 3 ricotta cottage cream to 4 minutes per side until golden brown. cheese Figure 1: Example of a text recipe for Surprise-inside French Toast and its SIMMR representation. ing&lt;index&gt; and inst&lt;index&gt; refer to specific ingredients and instructions, respectively. Mori et al. (2012) applied word segmentation, named entity recognition, and syntactic analysis to extract predicate-argument structures from Japanese recipe instructions as part of an effort to develop complete recipe flow representations. Malmaud et al. (2014) proposed a Markov Decision Process, in which the context of ingredients and tools is propagated along the temporal order of cooking instructions. Most recently, Abend et al. (2015) proposed an edge-factored model to determine the likely temporal order of events based solely on the identity of their predicates and arguments. They demonstrated their approa</context>
</contexts>
<marker>Mori, Sasada, Yamakata, Yoshino, 2012</marker>
<rawString>Shinsuke Mori, Tetsuro Sasada, Yoko Yamakata, and Koichiro Yoshino. 2012. A machine learning approach to recipe text processing. In Proc. of the 1st Cooking with Computer Workshop, pages 29–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shinsuke Mori</author>
<author>Hirokuni Maeta</author>
<author>Yoko Yamakata</author>
<author>Tetsuro Sasada</author>
</authors>
<title>Flow graph corpus from recipe texts.</title>
<date>2014</date>
<booktitle>In Proceedings of the Nineth International Conference on Language Resources and Evaluation,</booktitle>
<pages>2370--2377</pages>
<contexts>
<context position="3453" citStr="Mori et al. (2014)" startWordPosition="504" endWordPosition="507">ractices of specific cultures. Nedovic (2013) examined underlying ingredient groupings from their recipe co-occurrences, using topic modeling techniques (latent Dirichlet allocation), and further improvised novel ingredient combinations using deep belief networks. Among the structured representation approaches, Tasse and Smith (2008) proposed MILK (Minimal Instruction Language for the Kitchen), a formal language to describe actions required in directive cooking instructions. They used MILK in developing CURD (Carnegie Mellon University Recipe Database), a corpus of manually annotated recipes. Mori et al. (2014) also manually annotated the procedural flow of Japanese cooking recipes using directed acyclic graphs (DAGs) where graph nodes correspond to food ingredients, cooking instruments, and actions. Tasse and Smith (2008) had limited success in parsing into MILK; and Mori et al. (2014) did not report on parsing experiments. Other studies explored different machine learning and NLP techniques to processing recipes. 781 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 781–786, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Lin</context>
<context position="6289" citStr="Mori et al., 2014" startWordPosition="955" endWordPosition="958">mine the likely temporal order of events based solely on the identity of their predicates and arguments. They demonstrated their approach on recipe text, under the simplifying assumption that such text is also temporally ordered. In this paper, we present an ingredientinstruction dependency tree representation of recipe structure, which we call SIMMR (Simplified Ingredient Merging Map in Recipes). The SIMMR representation captures the high-level flow of ingredients but without modeling the semantics in each individual instruction unlike other efforts (Tasse and Smith, 2008; Mori et al., 2012; Mori et al., 2014). We create a corpus in our representation by converting the recipes in the CURD corpus (Tasse and Smith, 2008) from MILK to SIMMR. We also develop a parser to generate SIMMR trees from input recipes. 3 Recipe Representation 3.1 Text Recipes The prototypical text recipe consists of two parts: an ingredient list that declares the food items to process, and a set of instructions that mostly describe the transformations of the ingredients or the actions using the kitchen tools. The instructions relocate, process, combine, and separate ingredients, as well as heat or cool utensils in the recipes. </context>
</contexts>
<marker>Mori, Maeta, Yamakata, Sasada, 2014</marker>
<rawString>Shinsuke Mori, Hirokuni Maeta, Yoko Yamakata, and Tetsuro Sasada. 2014. Flow graph corpus from recipe texts. In Proceedings of the Nineth International Conference on Language Resources and Evaluation, pages 2370–2377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Nedovic</author>
</authors>
<title>Learning recipe ingredient space using generative probabilistic models.</title>
<date>2013</date>
<booktitle>In Proceedings of Cooking with Computers Workshop (CwC),</booktitle>
<volume>1</volume>
<pages>13--18</pages>
<contexts>
<context position="2880" citStr="Nedovic (2013)" startWordPosition="429" endWordPosition="430">llowed by a discussion of the structure of recipes and our representation (Section 3). Section 4 details the recipe parser design, implementation and evaluation. 2 Related Work There have been many efforts on the processing of cooking recipes using models that range from bags of words to complex semantic representations. Among the approaches to studying recipes as ingredient bags of words, Ahn et al. (2011) constructed a data-driven flavor network relating ingredients together. Jain et al. (2015) adopted Ahn et al. (2011)’s framework to further analyze culinary practices of specific cultures. Nedovic (2013) examined underlying ingredient groupings from their recipe co-occurrences, using topic modeling techniques (latent Dirichlet allocation), and further improvised novel ingredient combinations using deep belief networks. Among the structured representation approaches, Tasse and Smith (2008) proposed MILK (Minimal Instruction Language for the Kitchen), a formal language to describe actions required in directive cooking instructions. They used MILK in developing CURD (Carnegie Mellon University Recipe Database), a corpus of manually annotated recipes. Mori et al. (2014) also manually annotated th</context>
</contexts>
<marker>Nedovic, 2013</marker>
<rawString>V Nedovic. 2013. Learning recipe ingredient space using generative probabilistic models. In Proceedings of Cooking with Computers Workshop (CwC), volume 1, pages 13–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pedregosa</author>
<author>G Varoquaux</author>
<author>A Gramfort</author>
<author>V Michel</author>
<author>B Thirion</author>
<author>O Grisel</author>
<author>M Blondel</author>
<author>P Prettenhofer</author>
<author>R Weiss</author>
<author>V Dubourg</author>
<author>J Vanderplas</author>
<author>A Passos</author>
<author>D Cournapeau</author>
<author>M Brucher</author>
<author>M Perrot</author>
<author>E Duchesnay</author>
</authors>
<title>Scikit-learn: Machine learning in Python.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--2825</pages>
<contexts>
<context position="16236" citStr="Pedregosa et al., 2011" startWordPosition="2599" endWordPosition="2602">gredients flour and butter are specifically part of many erroneous links because they are often used in small quantities to facilitate the cooking process such as board flouring and pan greasing. MILK does not always account for this trivial use of these ingredients and neither does SIMMR. 4.3 Instruction-Instruction Linking 4.3.1 Challenges Although cooking instructions are written with an implied temporal order, they are not linked in a linear chain. Rather, the instructions describe different cooking stages, where the output of apply2We also experimented Linear SVM and Gaussian Kernel SVM (Pedregosa et al., 2011). We used the distance from the hyperplane to select the best edge among the set of edges connecting an ingredient. However, these techniques underperformed compared to SVMrank. 784 ing a number of instructions waits until other instructions are finished to be used again, e.g., the output of instruction #1 in Figure 1 waits until instructions #2 and #3 are done. Sometimes stage switching is explicitly stated as in Set aside the flour mixture, and combine eggs and oil together; however, this is not the common case. Furthermore, the waiting output of an earlier stage may be referred to collectiv</context>
</contexts>
<marker>Pedregosa, Varoquaux, Gramfort, Michel, Thirion, Grisel, Blondel, Prettenhofer, Weiss, Dubourg, Vanderplas, Passos, Cournapeau, Brucher, Perrot, Duchesnay, 2011</marker>
<rawString>F. Pedregosa, G. Varoquaux, A. Gramfort, V. Michel, B. Thirion, O. Grisel, M. Blondel, P. Prettenhofer, R. Weiss, V. Dubourg, J. Vanderplas, A. Passos, D. Cournapeau, M. Brucher, M. Perrot, and E. Duchesnay. 2011. Scikit-learn: Machine learning in Python. Journal of Machine Learning Research, 12:2825–2830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Tasse</author>
<author>Noah A Smith</author>
</authors>
<title>Sour cream: Toward semantic processing of recipes.</title>
<date>2008</date>
<tech>Technical report, Technical Report CMU-LTI-08-005,</tech>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="3170" citStr="Tasse and Smith (2008)" startWordPosition="464" endWordPosition="467">rds to complex semantic representations. Among the approaches to studying recipes as ingredient bags of words, Ahn et al. (2011) constructed a data-driven flavor network relating ingredients together. Jain et al. (2015) adopted Ahn et al. (2011)’s framework to further analyze culinary practices of specific cultures. Nedovic (2013) examined underlying ingredient groupings from their recipe co-occurrences, using topic modeling techniques (latent Dirichlet allocation), and further improvised novel ingredient combinations using deep belief networks. Among the structured representation approaches, Tasse and Smith (2008) proposed MILK (Minimal Instruction Language for the Kitchen), a formal language to describe actions required in directive cooking instructions. They used MILK in developing CURD (Carnegie Mellon University Recipe Database), a corpus of manually annotated recipes. Mori et al. (2014) also manually annotated the procedural flow of Japanese cooking recipes using directed acyclic graphs (DAGs) where graph nodes correspond to food ingredients, cooking instruments, and actions. Tasse and Smith (2008) had limited success in parsing into MILK; and Mori et al. (2014) did not report on parsing experimen</context>
<context position="6250" citStr="Tasse and Smith, 2008" startWordPosition="947" endWordPosition="950">) proposed an edge-factored model to determine the likely temporal order of events based solely on the identity of their predicates and arguments. They demonstrated their approach on recipe text, under the simplifying assumption that such text is also temporally ordered. In this paper, we present an ingredientinstruction dependency tree representation of recipe structure, which we call SIMMR (Simplified Ingredient Merging Map in Recipes). The SIMMR representation captures the high-level flow of ingredients but without modeling the semantics in each individual instruction unlike other efforts (Tasse and Smith, 2008; Mori et al., 2012; Mori et al., 2014). We create a corpus in our representation by converting the recipes in the CURD corpus (Tasse and Smith, 2008) from MILK to SIMMR. We also develop a parser to generate SIMMR trees from input recipes. 3 Recipe Representation 3.1 Text Recipes The prototypical text recipe consists of two parts: an ingredient list that declares the food items to process, and a set of instructions that mostly describe the transformations of the ingredients or the actions using the kitchen tools. The instructions relocate, process, combine, and separate ingredients, as well as</context>
<context position="8296" citStr="Tasse and Smith, 2008" startWordPosition="1287" endWordPosition="1290">2 and #3 (three cheeses) are inputs to instruction #2, whose output is then an input to instruc782 tion #3, together with ingredients #4 and #5 (sugar and vanilla). The SIMMR tree provides additional insights into the structure of recipes, suggesting in the case of this example, that multiple actions can take place in different orders without changing the recipe so long as the order of combinations is not changed. Some instructions simply transforms their input to produce their output, e.g. instructions #1, #7, #8 and #9. 3.3 From MILK to SIMMR We use MILK commands from the CMU CURD database (Tasse and Smith, 2008) to construct a database of SIMMR trees. The MILK language is a lot more expressive that SIMMR. For example, instruction #2 in Figure 1 translates into create tool(t0, “large bowl”); combine(ing1, ing2, ing3, ing9, “cheeses”, “”); and put(ing9, t0). These details of ingredient processing are abstracted away in SIMMR. To accomplish SIMMR instruction and ingredient linking, we process MILK instructions in order, tracing with MILK id numbers when each ingredient or its transformed or combined form at one instruction node is called for by a subsequent instruction node. The MILK intermediate names </context>
</contexts>
<marker>Tasse, Smith, 2008</marker>
<rawString>Dan Tasse and Noah A Smith. 2008. Sour cream: Toward semantic processing of recipes. Technical report, Technical Report CMU-LTI-08-005, Carnegie Mellon University, Pittsburgh, PA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>