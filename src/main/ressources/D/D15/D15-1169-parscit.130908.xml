<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.991243">
Joint A∗ CCG Parsing and Semantic Role Labeling
</title>
<author confidence="0.986876">
Mike Lewis Luheng He Luke Zettlemoyer
</author>
<affiliation confidence="0.993172">
Computer Science &amp; Engineering
University of Washington
</affiliation>
<address confidence="0.886267">
Seattle, WA 98195
</address>
<email confidence="0.999077">
{mlewis,luheng,lsz}@cs.washington.edu
</email>
<sectionHeader confidence="0.997399" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99961465">
Joint models of syntactic and semantic
parsing have the potential to improve
performance on both tasks—but to date,
the best results have been achieved with
pipelines. We introduce a joint model us-
ing CCG, which is motivated by the close
link between CCG syntax and semantics.
Semantic roles are recovered by labelling
the deep dependency structures produced
by the grammar. Furthermore, because
CCG is lexicalized, we show it is possible
to factor the parsing model over words and
introduce a new A* parsing algorithm—
which we demonstrate is faster and more
accurate than adaptive supertagging. Our
joint model is the first to substantially im-
prove both syntactic and semantic accu-
racy over a comparable pipeline, and also
achieves state-of-the-art results for a non-
ensemble semantic role labelling model.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999710111111111">
Joint models of syntactic and semantic parsing
are attractive; they can potentially avoid the error
propagation that is inherent in pipelines by using
semantic models to inform syntactic attachments.
However, in practice, the performance of joint sys-
tems for semantic role labelling (SRL) has been
substantially beneath that of pipelines (Sutton and
McCallum, 2005; Lluís et al., 2009; Johansson,
2009; Titov et al., 2009; Naradowsky et al., 2012;
Lluís et al., 2013; Henderson et al., 2013). In
this paper, we present the first approach to break
this trend, by building on the close relationship of
syntax and semantics in CCG grammars to enable
both (1) a simple but highly effective joint model
and (2) an efficient A* parsing algorithm.
Semantic dependencies can span an unbounded
number of syntactic dependencies, causing signif-
icant inference and sparsity challenges for joint
</bodyText>
<figure confidence="0.671788">
ARG0
</figure>
<figureCaption confidence="0.9939065">
Figure 1: Mismatch between syntactic and se-
mantic dependencies.
</figureCaption>
<figure confidence="0.9842705">
He refused to confirm or deny reports
NP (S\NP)1(S\NP) SIS (S\NP)INP conj (S\NP)INP NP
∅
ARG0 ARG1
ARG0 ARG1
ARG0
</figure>
<figureCaption confidence="0.985626">
Figure 2: Dependencies produced by a CCG
</figureCaption>
<bodyText confidence="0.95534628">
parse. SRL dependencies can be recovered by la-
belling the edges with a semantic role or ∅. Figure
3 shows a CCG derivation for these dependencies.
models. For example, in the Figure 1, the se-
mantic dependency between He and deny spans
three syntactic edges. This fact makes it difficult
to jointly parse syntactic and semantic dependen-
cies with dynamic programs, and means that de-
pendency path features can be sparse. Syntactic
dependencies also often have ambiguous seman-
tic interpretations—for example in He opened the
door and The door opened, the syntactic subject
corresponds to different semantic roles.
We address these challenges with a new joint
model of CCG syntactic parsing and semantic
role labelling. The CCG formalism is particu-
larly well suited; it models both short- and long-
range syntactic dependencies which correspond
directly to the semantic roles we aim to recover.
The joint model simply involves labelling a subset
of these dependencies with the appropriate roles,
as seen in Figure 2. This labelling decision can
be easily integrated into existing parsing algo-
rithms. CCG also helps resolve cases where in-
terpretation depends on the valency of the pred-
</bodyText>
<figure confidence="0.997637909090909">
ARG0 ARG1
ARG1
ARG0
ARG1
He refused to confirm or deny the reports
markcc det
conj
nsubj
xcomp
dobj
ARG1
</figure>
<page confidence="0.958854">
1444
</page>
<note confidence="0.9933555">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1444–1454,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<figure confidence="0.886341966666667">
he refused to confirm or deny reports
NPhe (Srefuse\NPi)/(Sj\NPi)j Sz/Sz (Sconfirm\NPu)/NPv conj (Sdeny\NPx)/NPy NPreports
{} {refuse ? −→i, refuse ? −→j} {to?−→z} {confirm?−→u, confirm?−→v} {} {deny?−→x, deny?−→y} {}
&gt;
((Sp\NPx)/NPy)\((Sp\NPx)/NPy)
{deny?−→x, deny?−→y, p?−→x, p?−→y}
(Sconfirm\NPx)/NPy
{confirm?−→x, confirm?−→y, deny?−→x, deny?−→y}
Sconfirm\NPx
{confirm? −→x, confirmA1
−−→reports, deny? −→x, deny A1−−→reports}
&lt;
&gt;
Sconfirm\NPx
{confirm?−→x, confirmA1
−−→reports, deny ?−→x, denyA1
−−→reports, to∅−→confirm}
Srefuse\NPx
&gt;
&gt;
{refuse ?−→x, refuse A1
−−→confirm, confirm?−→x, confirmA1
−−→reports, deny ?−→x, denyA1
−−→reports, to∅−→confirm}
&lt;
Srefuse
re use�he refuse A1
−−→con irm confirm A0
−−→he con arm Amore orts deny AO,he den Amore orts to∅−→con f irm}
{ f ,f ,, f� p , � y p
</figure>
<figureCaption confidence="0.988999">
Figure 3: Jointly building a CCG parse and semantic dependencies representation. Subscripts beneath
</figureCaption>
<bodyText confidence="0.986354060606061">
categories denote heads, which are unified when spans combine. One dependency is created for each
argument of each lexical category. In our approach, dependency labels are initially underspecified (rep-
resented f ?−→a) until an attachment is determined by the derivation and a label is chosen by the model.
icate, such as ergative verbs, by learning lexical
entries that pair syntactic arguments with seman-
tic roles, such as open : S\NPARG1 and open :
(S\NPARG0)/NPARG1 . Figure 3 shows a de-
tailed trace of how the example from Figure 2 is
parsed with our model.
We also present a new A* algorithm for the joint
model. Because CCG is strongly lexicalized, we
are able to introduce a new type of extended lexi-
cal entries that allows us to factor the model over
words and develop effective new upper bounds on
the Viterbi outside parse score. A* parsing algo-
rithms have previously been developed for models
with tree-structured syntactic dependencies (Klein
and Manning, 2003; Auli and Lopez, 2011b), and
models with no bi-lexical dependencies, includ-
ing supertag-factored CCGs (Lewis and Steed-
man, 2014a). We generalize these techniques to
SRL-style graph-structured dependencies.
Experiments demonstrate that our model not
only outperforms pipeline semantic role labelling
models, but improves the quality of the syntactic
parser. PropBank SRL performance is 1.6 points
higher than comparable existing work, and se-
mantic features improve syntactic accuracy by 1.6
points. Our A* algorithm is 5 times faster than
CKY parsing, with no loss in accuracy. The com-
bination of CCG-based joint modelling and A* de-
coding gives an efficient, accurate, and linguisti-
cally principled parser.1
</bodyText>
<footnote confidence="0.992988">
1The parser is available from: https://github.com/
mikelewis0/EasySRL
</footnote>
<sectionHeader confidence="0.991676" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.995716">
2.1 CCG Dependencies
</subsectionHeader>
<bodyText confidence="0.9999604">
CCG parses define an implicit dependency graph,
by associating each argument of each category
with a dependency. In contrast to Stanford de-
pendency trees, CCG dependency graphs can be
non-projective, and words can have multiple par-
ents. For example, in Figure 2, He is an argument
of refuse, confirm and deny.
To create dependencies, categories are marked
with headedness information—which we denote
with subscripts. For example, in the category
(Sdeny\NPx)/NPy, the final head for the sentence
S will be deny, and that two dependencies will be
introduced from deny to unspecified arguments x
and y. During parsing, variables are unified with
heads, creating fully specified dependencies.
Re-using variables allows dependencies to
propagate. For example, the determiner category
NPi/Ni marks that the head of the resulting NP is
equal to the head of its N argument (e.g. the head
of the report is report), as in the following parse:
</bodyText>
<equation confidence="0.863195">
deny the report
(Sdeny\NPx)/NPy NPz/Nz Nreport
{deny−→x, deny−→y} {the−→z} {}
&gt;
Sdeny\NPx
{deny−→x, deny−→report, the−→report}
</equation>
<bodyText confidence="0.999441">
The same mechanism allows long-range argu-
ments to be propagated. Figure 3 shows several
long-range arguments, such as how co-indexation
</bodyText>
<figure confidence="0.759387666666667">
NPreport
{the−→report}
&gt;
</figure>
<page confidence="0.971703">
1445
</page>
<bodyText confidence="0.9899684">
propagates the subject of deny to he. For more de-
tails, see Hockenmaier (2003).
Now, we can define a log-linear model over
pairs of consistent CCG derivations d and SRL de-
pendencies 7r:
</bodyText>
<subsectionHeader confidence="0.998585">
2.2 A* CCG parsing
</subsectionHeader>
<bodyText confidence="0.999888423076923">
A* parsing searches for an optimal parse, with-
out building a complete chart (in contrast to CKY
parsing). This is particularly attractive for CCG,
because the formalism’s lexical and derivational
ambiguity causes the parse charts to be very dense,
in practice. Lewis and Steedman (2014a) showed
that A* CCG parsing can be highly efficient, but
used a restricted model without bi-lexical features.
In A* parsing, entries y are added to the chart
in order of their cost f(y) = g(y) + h(y), where
g(y) is the inside score for the entry, and h(y) is
an upper bound on the Viterbi outside score. Be-
cause partial parses are built in order of increasing
f(y), the first complete parse added to the chart is
guaranteed to be optimal. The key to making A*
parsing efficient is computing tight upper bounds
on the outside score. In Lewis and Steedman’s
supertag-factored model, the bound can be com-
puted as the sum of the highest-scoring supertags
in the outside parse.
The agenda is initialized with items represent-
ing every category for every word. Then, after
each item is added to the chart, the agenda is up-
dated with all binary and unary rules that can be
applied to the new item. For more details, see
Lewis and Steedman (2014a).
</bodyText>
<sectionHeader confidence="0.994967" genericHeader="method">
3 Model
</sectionHeader>
<bodyText confidence="0.981557941176471">
Our joint model of CCG and SRL parsing sim-
ply involves labelling CCG syntactic dependen-
cies (which are implicit in CCG parses), with SRL
roles (or null). This formulation allows us to easily
adapt the log-linear CCG parsing model of Clark
and Curran (2007) to the joint setting by working
with extended dependencies that including syntac-
tic and semantic information.
More formally, we can define a notion of con-
sistency to specify the labelling of syntactic de-
pendencies. A set of semantic dependencies 7r
is consistent with a CCG derivation d if each se-
mantic dependency corresponds to a single syntac-
tic dependency—for example, see the dependen-
cies in Figure 3. The CCG derivation in Figure 3
would also be consistent with the SRL dependency
refuse −−−−→he, but not refuse ARG1
</bodyText>
<footnote confidence="0.603491666666667">
ARG2 −−−−→reports
(because the derivation does not produce the re-
quired syntactic dependency).
</footnote>
<equation confidence="0.892564">
p(d, 7r|x) = E(d&apos;,π&apos;)∈GEN(x)
</equation>
<bodyText confidence="0.9852155">
where GEN(x) is the space of consistent pairs for
sentence x.
</bodyText>
<subsectionHeader confidence="0.996537">
3.1 Dependencies
</subsectionHeader>
<bodyText confidence="0.998066">
Because we enforce consistency, we can work
with joint dependencies that are a combination of
CCG and SRL dependencies. We denote a depen-
dency as a 6-tuple of functor f, lexical category c,
argument number n, preposition p, argument a and
semantic role r: (f, c, n, p, a, r). The first three of
these (f,c,n) are lexically specified, but a and r
are lexically underspecified until the attachment is
determined by the derivation, and a label is cho-
sen by the model. For example, in Figure 3, the
lexical entry for deny has two underspecified de-
</bodyText>
<construct confidence="0.5524064">
pendencies: (deny, (S\NP)/NP,1, 0, ?, ?) and
(deny, (S\NP)/NP, 2, 0, ?, ?).2 At the end of
the derivation, the dependencies are specified
as: (deny, (S\NP)/NP,1, 0, he, ARG0) and
(deny, (S\NP)/NP, 2, 0, reports, ARG1).
</construct>
<bodyText confidence="0.954983">
The preposition p is lexically underspecified for
PP arguments, but otherwise 0. Prepositions are
marked lexically on PP/∗ categories, and then
propagated, for example:
fly to Lisbon
</bodyText>
<equation confidence="0.959288875">
(Sfly\NPx)/PPpy PPto
. /NP. NPLisbon
{fly?−→x, fly?−→y} {to ?−→z}
PPto
Lisbon
{to ∅ −→Lisbon}
&lt;
Sfly\NPx
</equation>
<bodyText confidence="0.933618571428571">
{fly?−→x, fly ARG1 −−−−→Lisbon, to ∅ −→Lisbon}
In the above example, the dependency from
fly to Lisbon corresponds to the tuple:
(fly, (S\NP)/PP, 2, to, Lisbon, ARG1).
Propagating both the noun and preposition from
prepositional phrases allows the model to use both
for features, and improved results.
</bodyText>
<subsectionHeader confidence="0.990529">
3.2 Features
</subsectionHeader>
<bodyText confidence="0.829289">
We use the following feature classes, which de-
compose over categories, dependencies, and local
rule instantiations.
2Bold-face is used to highlight the argument of a category
corresponding to a dependency. For example (S\NP)/NP
denotes the first (subject) dependency of a transitive verb.
</bodyText>
<figure confidence="0.458551333333333">
eθ·φ(x,d,π)
{}
&lt;
</figure>
<page confidence="0.888013">
1446
</page>
<subsectionHeader confidence="0.89917">
3.2.1 Supertagging Features
</subsectionHeader>
<bodyText confidence="0.999458333333333">
Supertagging features φCAT score categories for
words. A single feature is used, which is the
(unnormalized) score from Lewis and Steedman
(2014b)’s supertagging model. The supertagger
outputs a distribution over categories for each
word independently. The model is trained on su-
pertags extracted from an adaptation of CCGre-
bank (Honnibal et al., 2010). The adaptation
makes minor changes to better match PropBank.
</bodyText>
<subsubsectionHeader confidence="0.640095">
3.2.2 Preposition Features
</subsubsectionHeader>
<bodyText confidence="0.9998744">
Preposition features φPP score whether the nth
argument of the word at index f with category c
should take a PP argument headed by preposition
p. We use features xf+p, lf+c and lf+c+n+p,
where xf is the fth word, and lf is its lemma.
</bodyText>
<subsectionHeader confidence="0.880077">
3.2.3 Labelling Features
</subsectionHeader>
<bodyText confidence="0.999076285714286">
Labelling features φROLE determine whether the
nth argument of a word with lemma l, and
category c should take a role r. We use
n+r, c+n+r, c+n+p+r, l+c+n+p+r, n+r, r,
l+p+r, c+n+r, l+r, h+r, where h is an indica-
tor of whether l is hyphenated, and p is the prepo-
sition of PP arguments.
</bodyText>
<subsectionHeader confidence="0.674057">
3.2.4 Dependency Features
</subsectionHeader>
<bodyText confidence="0.99949">
Dependency features φDEP score dependencies,
based on the functor index f, argument index a
and role r. We use lf+r+la, lf+r+ca, d+r,
cf+o+r, ca+o+r, where o is an offset from
−3... +3, d is the distance between f and a, ci is
a cluster or POS tag for word i, and li is the lemma
of word i. Clusters were created from pre-trained
word embeddings (Levy and Goldberg (2014)) us-
ing k-means, with k = 20, 50, 200,1000, 2500.
These features only apply when the role r =� ∅.
</bodyText>
<subsectionHeader confidence="0.817055">
3.2.5 Derivation Features
</subsectionHeader>
<bodyText confidence="0.999972125">
Derivation features φDERIV score properties of
the syntactic derivation. To simplify computation
of the upper bounds for the A* parsing algorithm
given in Section 5, the weights of these features
are constrained to be &lt; 0. For simplicity, we only
use features for unary rules—for example, a fea-
ture records when the unary rule N —* NP con-
verts a determiner-less N to a NP.
</bodyText>
<sectionHeader confidence="0.988189" genericHeader="method">
4 Lexical Factorization
</sectionHeader>
<bodyText confidence="0.999812764705882">
In this section, we show how to factor the model
into extended lexical entries. This factorization al-
lows us to efficiently compute upper bounds on the
scores of partial parses, which is crucial to the A*
algorithm described in Section 5.
The key observation is that our supertagging,
labelling and dependency features can each be as-
sociated with exactly one word (using the functor
for the dependency features). Therefore, we can
equivalently view the complete parse as a series of
extended lexical entries: y = y0...yN. Extended
lexical entries are composed of a lexical category,
and a role and attachment for each argument of
the category. The set of extended lexical entries
specifies the yield of the parse. For example, the
parse from Figure 2 can be represented as the
following extended lexical entries:
</bodyText>
<equation confidence="0.955403">
he NP
refused (S\NPARG0=he)/(S\NP)ARG1=confirm
to S/S∅=confirm
confirm (S\NPARG0=he)/NPARG1=reports
or conj
deny (S\NPARG0=he)/NPARG1=reports
reports NP
</equation>
<bodyText confidence="0.996612">
The score for a sentence x and joint SRL-CCG
parse y, θ·φ(x, y), can be decomposed into scores
of its extended lexical entries yi, plus a score for
the derivation features:
</bodyText>
<equation confidence="0.8725315">
θ · φ(x, y) = � θ · φ(x, yi) + θ · φDERIV (x, y)
yzEy
</equation>
<bodyText confidence="0.999977307692308">
The space of possible extended lexical entries
for word xi is defined by GENLEX (xi), which is
expressed with a CFG, as shown in Figure 4a.
The features defined in Section 3.2 decom-
pose over the rules of GENLEX—so it can be
weighted with the globally trained feature weights.
Expressing GENLEX (xi) as a CFG allows us
to efficiently compute upper bounds on the score
of yi when it is only partially specified, using the
Viterbi algorithm—which we will make use of in
Section 5. Making the attachment choice indepen-
dent of the syntactic category greatly improves the
efficiency of these calculations.
</bodyText>
<sectionHeader confidence="0.987044" genericHeader="method">
5 A* Parsing
</sectionHeader>
<bodyText confidence="0.99994125">
To efficiently decode our model, we introduce a
new A* parsing algorithm. As discussed in Sec-
tion 2.2, the key to efficient A* parsing is comput-
ing tight upper bounds on the Viterbi outside score
of partial parses, with the function h.
The intuition behind our algorithm is that we
can use the lexical factorization of Section 4 to
compute upper bounds for words individually,
</bodyText>
<page confidence="0.977566">
1447
</page>
<table confidence="0.985745111111111">
Lexical Category Choice
xi — NP  |S\NP  |(S\NP)/PP  |...
One dependency is created for every argument of the category
S\NP — S\NP
(S\NP)/PP — (S\NP)/PP, (S\NP)/PP
. . .
Preposition choice for PP arguments
(S\NP)/PP — (S\NP)/PPin  |(S\NP)/PPfor  |...
. . .
Semantic role label choice for the argument
S\NP — S\NPARG0  |S\NPARG1  |. . .
(S\NP)/PP — (S\NPARG0)/PP  |(S\NPARG1)/PP...
(S\NP)/PPX — (S\NP)/PPXARG0  |(S\NP)/PPXARG1 . . .
. . .
Attachment choice
ARG0 — x0  |...  |xi−1  |xi+1  |...  |xN
ARG1 — x0  |...  |xi−1  |xi+1  |...  |xN
. . .
</table>
<figure confidence="0.994895428571429">
(a) The grammar GENLEX (xi)
confirm
S\NP (S\NP)/NP NP
S\NP (S\NP)/NP (S\NP)/NP
ARG0 ARG1 ∅
He reports refused
(b) Visualization of a fragment of GENLEX (confirm)
</figure>
<figureCaption confidence="0.647819285714286">
Figure 4: (a) The grammar GENLEX (xi), which defines the space of extended lexical entries,
and (b) a visualization of a fragment of GENLEX(confirm). Extended lexical entries, including
confirm (S\NPARG0=he)/NPARG1=reports and confirm NP, are specified by choosing one cate-
gory (top level in both a and b), enumerating all arguments (second level), selecting the preposition for
PP arguments (when present), selecting a semantic role label for each, and finally choosing the argument
head word. The features are local to the grammar rules, enabling efficient dynamic programs for upper
bound computations on partially specified entries, such as confirm (S\NPr=a)/NPARG1=reports.
</figureCaption>
<bodyText confidence="0.999905428571429">
then create an upper bound for the parse as a sum
of upper bounds for words. The bound is not exact,
because the grammar may not allow the combina-
tion of the best lexical entry for each word.
Section 5.1 gives a declarative definition of h
for any partial parse, and 5.2 explains how to effi-
ciently compute h during parsing.
</bodyText>
<subsectionHeader confidence="0.945105">
5.1 Upper Bounds for Partial Parses
</subsectionHeader>
<bodyText confidence="0.99980825">
This section defines the upper bound on the Viterbi
outside score h(yi,j) for any partial parse yi,j of
span i ... j. For example, in the parse in Figure
3, y3,5 is the partial parse of confirm or deny with
category (S\NP)/NP.
As explained in Section 4, a parse can be de-
composed into a series of extended lexical entries.
Similarly, a partial parse can be viewed as a se-
ries of partially specified extended lexical entries
y0 ... yN. For example, in Figure 3, the partial
parse of the span confirm or deny reports, the ex-
tended lexical entries for the words outside the
span (He, refused and to) are completely unspeci-
fied. The extended lexical entries for words inside
the span have specified categories, but can contain
underspecified dependencies:
</bodyText>
<equation confidence="0.79284">
confirm (S\NPr=a)/NPARG1=reports
or conj
deny (S\NPr,= a/)/NPARG1=reports
reports NP
</equation>
<bodyText confidence="0.9992041">
Therefore, we can compute an upper bound for
the outside score of a partial parse as a sum of
the upper bounds of the unspecified components of
each extended lexical entry. Note that because the
derivation features are constrained to be ≤ 0, they
do not affect the calculation of the upper bound.
We can then find an upper bound for completely
unspecified spans using by summing the upper
bounds for the words. We can pre-compute an up-
per bound for the span hi,j for every span i, j as:
</bodyText>
<equation confidence="0.8775695">
max
ykEGENLEX (xk)
</equation>
<bodyText confidence="0.999296875">
The max can be efficiently computed using the
Viterbi algorithm on GENLEX (xk) (as described
in Section 4).
The upper bound on the outside score of a par-
tial parse is then the sum of the upper bounds of
the words outside the parse, and the sum of the
scores of the best possible specifications for each
underspecified dependency:
</bodyText>
<equation confidence="0.9983528">
h(yi,j) =
(f,c,n,?,?,?)Edeps(yi,j)
� a/,p/,r/
max
+ h0,i−1 + hj+1,N
</equation>
<bodyText confidence="0.9997794">
where deps(y) returns the underspecified depen-
dencies from partial parse.
For example, in Figure 3, the upper bound for
the outside score of the partial parse of confirm
or deny reports is the sum of the upper bounds
</bodyText>
<equation confidence="0.98343925">
hi,j = � j
k=i
θ · φ(x, yk)
θ · φ(�f, c, n, p&apos;, a&apos;, r&apos;))
</equation>
<page confidence="0.883451">
1448
</page>
<bodyText confidence="0.999249666666667">
for the other words independently (h0,3) added to
the score of the best attachments and roles for the
subjects of confirm and deny independently.
</bodyText>
<subsectionHeader confidence="0.996154">
5.2 Additive Updates
</subsectionHeader>
<bodyText confidence="0.9987935">
During parsing, the upper bound h can be ef-
ficiently computed recursively with additive up-
dates. Initially h is the sum of the upper bounds
for each word independently h0,N. Then, when
specifying categories or labelling dependencies,
the score is updated.
</bodyText>
<listItem confidence="0.9304116875">
• When specifying a category for a word xi, the
Viterbi score of GENLEX (xi) is subtracted
from h, and the sum of Viterbi scores for each
of the category’s (underspecified) dependen-
cies is added to h.
• When specifying a semantic role for a de-
pendency with functor f, causing the depen-
dency to be fully specified, the Viterbi score
for the node representing that dependency in
GENLEX (xf) is subtracted from h.
• When a binary rule combines two partial
parses yi,j and yj+1,k, the bound on the out-
side score is updated by summing the bounds
of the outside scores of the child parses, and
subtracting the overall upper bound for the
sentence (to avoid double-counting):
</listItem>
<equation confidence="0.855327">
h(yi,k) = h(yi,j) + h(yj+1,k) − h0,N
</equation>
<bodyText confidence="0.999400666666667">
This update can be derived from the defini-
tion of h.
These are the only cases where h is updated.
</bodyText>
<sectionHeader confidence="0.997719" genericHeader="method">
6 Training
</sectionHeader>
<bodyText confidence="0.9992694">
During training, we optimize parameters θ for
the marginal likelihood of the semantic depen-
dencies 7ri given a sentence xi, treating syntactic
derivations d as a latent variable and using L2
regularization.
</bodyText>
<equation confidence="0.991778">
pθ( i t xi ) − Pj
θ2j
�
2σ2
eθ·φ(xi,d,πi) [� 92
log PdEΔ(xi,πi) − L�j j
[[�� O*xi,d1,w1) 2
L�(d1,π1)EGEN(xi) 8 ZU
</equation>
<bodyText confidence="0.997143">
where GEN(xi) is the set of consistent CCG and
SRL parses for a sentence xi (see Section 3), and
A(xi, 7ri) is the set of CCG derivations that are
maximally consistent with gold SRL parses 7ri.
More formally, if labelled(y) returns the set of
labelled dependencies from parse y, then:
</bodyText>
<equation confidence="0.989691">
A(x, 7r) = arg max |7r n labelled(y)|
y∈GEN(x)
</equation>
<bodyText confidence="0.999965416666667">
The arguments of PropBank dependencies can
span multiple words, so CCG dependencies are
marked as equivalent if their argument is any-
where within the PropBank span.
The approach is closely related to the hy-
brid dependency model (Clark and Curran, 2007).
However the CCGbank dependencies used by
Clark and Curran’s model constrain all lexical
and attachment decisions (only allowing ‘spuri-
ous’ derivational ambiguity) whereas our use of
semantic dependencies models most of the syntac-
tic parse as latent.
</bodyText>
<subsectionHeader confidence="0.983548">
6.1 Hyperparameters
</subsectionHeader>
<bodyText confidence="0.999967384615385">
Calculating the gradient of the loss function re-
quires computing the marginal probability of the
correct parses. Computing marginal probabilities
exactly involves summing over all possible CCG
parses, which is intractable. Instead, following
Clark and Curran, we limit the size of training
charts using a variable-width supertagger beam β,
initially 10−3. If the chart size exceeds 100000
nodes, we double β and re-parse. For computing
A, we use a more restrictive beam of β = 0.01
to improve the quality of the positive training ex-
amples. We optimize using L-BFGS (Liu and No-
cedal, 1989), with σ2 = 0.06.
</bodyText>
<subsectionHeader confidence="0.99843">
6.2 Pruning
</subsectionHeader>
<bodyText confidence="0.999947">
To improve efficiency, we compute a number of
thresholds, by aligning gold CCGbank dependen-
cies with PropBank. If an argument of a cate-
gory occurs with a particular semantic role less
than 3 times in the aligned data, it is pruned from
the training and decoding charts. We also fil-
ter infrequent features before training. We count
the number of times each feature occurs in the
aligned data, and filter features occurring less than
3 times. During decoding, we prune lexical cate-
gories whose probability under the supertagging
model is less than a factor of 10−2 of that of
the best category for that word. If the chart size
exceeds 20000 nodes, we back off to a pipeline
model (roughly 3% of sentences). Finally, we
build and use a tag dictionary in the same way as
Lewis and Steedman (2014a).
</bodyText>
<equation confidence="0.9907804">
Y
L(θ) = log
i
X=
i
</equation>
<page confidence="0.99042">
1449
</page>
<sectionHeader confidence="0.999678" genericHeader="evaluation">
7 Experiments
</sectionHeader>
<subsectionHeader confidence="0.997053">
7.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999985285714286">
We used PropBank Section 00 for development,
Sections 02-21 for training, and Section 23 for
testing. The Pipeline baseline first parses with a
supertag-factored A* model, and chooses a seman-
tic role for each CCG dependency with a log-linear
classifier. The classifier uses the role and attach-
ment features used by the parser.
</bodyText>
<subsectionHeader confidence="0.998008">
7.2 Semantic Role Labelling
</subsectionHeader>
<bodyText confidence="0.9998788">
We evaluate our parser as a dependency-based
SRL model on PropBank, comparing with
CoNLL-2008 systems (Surdeanu et al., 2008).
Comparison systems Following Täckström et
al. (2015), we compare with the best ‘single
parser’ SRL models, which use only a single syn-
tactic parse.3
Much recent work has evaluated using gold
predicate identification (Hajiˇc et al., 2009;
FitzGerald et al., 2015). This setting is particu-
larly unrealistic for our joint model, where gold
predicate identification would be a highly useful
feature for the supertagger; we only compare with
models that use automatic predicate identification.
To the best of our knowledge, the best SRL re-
sults with automatic predicate identification were
achieved at CoNLL-2008.
A number of other models have been evaluated
on CoNLL-2008 data. While we cannot com-
pare directly on our metric, the best reported joint
model (Johansson, 2009) scored 1.4 points lower
than the Che et al. (2008) system we compare to
on the CoNLL metric on PropBank. Other joint
models, such as those of Titov et al. (2009) and
Lluís et al. (2013), achieve similar performance.
Evaluation Metric Comparing fairly with ex-
isting work is complicated by the mismatch be-
tween heads found by our model and those used in
other evaluations. Headedness decisions are often
arbitrary—for example, whether a prepositional
phrase is headed by the noun or preposition—and
different choices were made in the design of CCG-
bank and the CoNLL-2008 headedness rules.
To solve this problem, we introduce a new
within-constituent metric, which awards depen-
</bodyText>
<footnote confidence="0.9713152">
3The best models use reranking with powerful global features
(Toutanova et al., 2008; Johansson and Nugues, 2008) or en-
semble methods (Surdeanu et al., 2007; Punyakanok et al.,
2008). These techniques have the potential to improve any
SRL system, including ours, at some expense in speed.
</footnote>
<table confidence="0.999784">
PropBank Brown
Model P R F1 P R F1
Vickrey 87.3 77.3 82.0 74.0 64.5 68.9
Che 85.3 78.6 81.8 71.1 65.7 68.0
Zhao 82.4 79.8 81.1 66.6 64.9 65.7
Riedel 83.6 74.7 78.9 69.3 62.7 65.8
Pipeline 79.2 73.9 76.4 69.3 64.0 66.1
Joint 84.8 82.2 83.5 71.2 69.2 70.2
</table>
<tableCaption confidence="0.7220582">
Table 1: Comparison with the best single-parser
SRL models on PropBank from CoNLL-2008.
The comparison models are Vickrey and Koller
(2008), Che et al. (2008), Zhao and Kit (2008) and
Riedel and Meza-Ruiz (2008).
</tableCaption>
<bodyText confidence="0.999301851851852">
dencies as correct if they attach anywhere within
the original PropBank-annotated argument spans.
For example, if the PropBank annotates that the
ARGO of owned is by Google, a dependency to
either by or Google is judged correct. We com-
pute new scores for the CoNLL-2008 submissions
on our metric, filtering reference and continuation
arguments (which are artifacts of the CoNLL con-
version of PropBank, but not required by our met-
ric), and nominal predicates based on POS tag.
The ranking of the top 5 CoNLL-2008 open-track
models is identical under our metric and the orig-
inal one (up to statistical significance), suggesting
that our metric is equally discriminative. However,
perhaps interestingly, the ranking of Vickrey and
Koller (2008) does improve—likely due to the use
of a syntactic formalism with different headedness
rules. For simplicity, we do not include predicate
senses in the evaluation.
Results are given in Table 1 and show that our
joint model greatly outperforms the pipeline ver-
sion, demonstrating the value of joint reasoning.
It also scores 1.5 points higher than the best com-
parable models in-domain, and 1.3 points higher
out-of-domain. To the best of our knowledge, this
is the first joint syntax/SRL model to outperform
strong pipeline models.
</bodyText>
<subsectionHeader confidence="0.996782">
7.3 Efficiency Experiments
</subsectionHeader>
<bodyText confidence="0.999167166666667">
We explore whether our A* decoding is more ef-
ficient than alternatives, including both algorith-
mic and feature computation. While the A* search
builds very small charts, the features must be pre-
computed for the heuristic. In CKY parsing, fea-
tures can be computed lazily.
</bodyText>
<page confidence="0.961784">
1450
</page>
<table confidence="0.999265666666667">
Model Sentences PropBank
per second F1
Pipeline A* 38.3 76.4
Joint CKY 6.0 83.5
Joint AST 20.3 83.0
Joint A* 31.3 83.5
</table>
<tableCaption confidence="0.994165">
Table 2: Parser speed on PropBank Section 23
</tableCaption>
<table confidence="0.9994845">
Model P R F1
C&amp;C 81.8 81.2 81.5
Pipeline 76.6 77.7 77.2
Joint 78.3 79.4 78.8
</table>
<tableCaption confidence="0.940335">
Table 3: Labelled F1 for CCGbank dependencies
on CCGrebank Section 23
</tableCaption>
<bodyText confidence="0.999964875">
We compare with a CKY parsing over the same
space. If no parse is found, or the chart size ex-
ceeds 400000 nodes, we back off to the pipeline
(tuned so that the backoff is used roughly as often
as for the A* parser). We also compare with adap-
tive supertagging (AST, Clark and Curran (2007)),
which is the same except for first attempting to
parse with a restrictive supertagger beam Q = 0.1.
Table 2 shows the results. The A* pipeline is
fast, but inaccurate. CKY is 5 times slower than
A* in the same space, whereas adaptive supertag-
ging trades accuracy for speed. The best previ-
ously reported speed improvement using A* pars-
ing is a factor of 1.2 times faster (Auli and Lopez,
2011b). Our new A* algorithm dominates existing
alternatives in both speed and accuracy.
</bodyText>
<subsectionHeader confidence="0.997505">
7.4 Syntactic Parsing
</subsectionHeader>
<bodyText confidence="0.999965541666667">
We also evaluate our model for CCG parsing ac-
curacy, using CCGrebank (Honnibal et al., 2010),
and comparing with a C&amp;C parser model adapted
to this dataset. Results are shown in Table 3. Of
course, given our latent syntax, and the fact we
have no model of CCGbank dependencies, we do
not expect state-of-the-art accuracy. However, the
1.6 point improvement over the pipeline shows
that SRL dependencies are useful for disambiguat-
ing syntactic attachment decisions. Many errors
were caused by disagreements between CCGbank
and PropBank—PropBank is likely to be more ac-
curate as it was hand-annotated, rather than auto-
matically converted from the Penn Treebank. In
effect, our latent model of syntax is successfully
learning a grammar that better produces the cor-
rect semantics.
Table 4 shows the syntactic dependencies which
are improved most by modelling semantics. Un-
surprisingly, verb arguments and adjuncts rela-
tions show large improvements. However, we also
see more accurate attachment of relative clauses.
While we do not model relative clauses explicitly,
correctly attaching them is essential for propagat-
</bodyText>
<figure confidence="0.993912454545454">
Dependency Type A F1
((Sdcl\NP)/PP)/NP +12.6
((Sdcl\NP)/PP)/NP +11.0
((Sb\NP)/PP)/NP Verb +10.7
(Sdcl\NP)/PP arguments +8.1
(Sng\NP)/NP +7.6
(Spt\NP)/NP +6.8
((S\NP)\(S\NP))/NP Verb +16.9
((S\NP)\(S\NP))/Sdcl adjuncts +11.9
(N\N)/(Sdcl\NP) Relative +12.5
(NP\NP)/(Sdcl\NP) clauses +8.5
</figure>
<tableCaption confidence="0.897115">
Table 4: CCG syntactic dependencies with the
</tableCaption>
<bodyText confidence="0.9848308">
largest change in F1 between the Pipeline and
Joint models (of those occurring at least 100 times
in the development set).
ing certain verb arguments (e.g. the subject of
broke in the glass on the table that broke).
</bodyText>
<subsectionHeader confidence="0.943577">
7.5 Error Analysis
</subsectionHeader>
<bodyText confidence="0.9999512">
Table 5 gives an analysis of recall errors from the
first 100 sentences of PropBank Section 00. One
third of errors were syntactic attachment errors.
A further 14% were triggered by cases where the
parser found the correct attachment, but gave an
adjunct a core argument CCG category (or vice
versa). Many of these decisions are not obvious—
for example in rose sharply, PropBank considers
sharply to be an argument and not an adverb. 21%
of errors were caused by choosing the wrong SRL
</bodyText>
<table confidence="0.900784714285714">
Error Percentage
Attachment error 33%
Correct attachment, wrong label 21%
Correct attachment, unlabelled 20%
Argument/adjunct distinction 14%
Problematic constructions 9%
Dubious annotation 4%
</table>
<tableCaption confidence="0.992914">
Table 5: Error analysis of recall errors from 100
development set sentences.
</tableCaption>
<page confidence="0.992838">
1451
</page>
<bodyText confidence="0.999825727272727">
label. Another 20% were caused by predicates as-
signing arguments the null semantic role ∅. The
major cause of these errors is predicates that act
syntactically like adjectives (e.g. publishing in
Dutch publishing group) where syntactic cues are
weak. Finally, 9% involved long-range arguments
that our current grammar is unable to project. One
common case is constructions like X has a plan
to buy Y, where the grammar does not propagate
the subject of buy to X. Further improvements to
CCGbank may help to resolve these cases.
</bodyText>
<sectionHeader confidence="0.999825" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.999135107142857">
Joint syntactic and SRL models There have
been many proposals for jointly parsing syntac-
tic and semantic dependencies. Lluís et al. (2013)
introduce a joint arc-factored model for parsing
syntactic and semantic dependencies, using dual-
decomposition to maximize agreement between
the models. SRL performance is slightly worse
than a pipeline version. Naradowsky et al. (2012)
introduce a SRL model with latent syntax repre-
sentations, by modelling a latent dependency tree
during training, which is marginalized out at test
time. However, performance at English SRL is
roughly 7 points beneath state of the art. Other
notable models include those of Johansson (2009)
and Titov et al. (2009).
CCG parsing Our log-linear model is closely
related to that of Clark and Curran (2007), but
we model SRL dependencies instead of CCG de-
pendencies. The best CCG parsing results were
achieved by Auli and Lopez (2011a), who, like us,
score CCG parses based jointly on supertagging
and dependency model scores. Decoding their
model requires dual-decomposition, to maximize
agreement between the separate models. We avoid
the need for this technique by using a unigram su-
pertagging model, rather than a sequence model.
CCG semantics Work on semantic parsing has
mapped sentences onto semantic representations
with latent CCGs (Zettlemoyer and Collins, 2009;
Kwiatkowski et al., 2010; Kwiatkowski et al.,
2013) for restricted domains. Recent work has
scaled these techniques to wide-coverage datasets
(Artzi et al., 2015). Krishnamurthy and Mitchell
(2014) also explore joint CCG syntactic and se-
mantic parsing. They use a smaller semantic lex-
icon, containing 130 predicates, rather than the
3257 PropBank verbs. In contrast to our re-
sults, jointly modelling the semantics lowers their
model’s syntactic accuracy.
Other CCG-based SRL models haved used
CCG dependencies as features for predicting se-
mantic roles (Gildea and Hockenmaier, 2003;
Boxwell et al., 2009), but performance is limited
by relying on 1-best parses—a problem we re-
solved with a joint model.
A* parsing A* parsing has previously been ex-
plored for less general models than ours. Klein
and Manning (2003) and Auli and Lopez (2011b)
use A* parsing for models with tree-structured de-
pendencies. The best reported speed improvement
is parsing 1.2 times faster, whereas we improve
by a factor of 5. Our model also allows the more
complex graph-structured dependencies required
for semantic role labelling. Lewis and Steedman
(2014a) demonstrate an efficient A* algorithm for
CCG, but cannot model dependencies.
</bodyText>
<sectionHeader confidence="0.994123" genericHeader="conclusions">
9 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.9999804">
We have shown that using CCG can allow joint
models of syntax and semantics to outperform
pipelines, and achieve state-of-the-art results on
PropBank SRL. Our new A* parsing algorithm
is 5 times faster than CKY parsing, without
loss of accuracy. Using latent syntax allows us
to train the model purely from semantic depen-
dencies, enabling future work to train against
other annotations such as FrameNet (Baker et al.,
1998), Ontonotes (Hovy et al., 2006) or QA-
SRL (He et al., 2015). The semantic labels pro-
vided by PropBank can also be integrated into
wide-coverage CCG semantic parsers (Bos, 2008;
Lewis and Steedman, 2013) to improve perfor-
mance on downstream applications.
</bodyText>
<sectionHeader confidence="0.996492" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999766777777778">
This research was supported in part by the NSF
(IIS-1252835), DARPA under the DEFT program
through the AFRL (FA8750-13-2-0019), an Allen
Distinguished Investigator Award, and a gift from
Google. We thank Nicholas Fitzgerald, Dan Gar-
rette, Kenton Lee, Swabha Swayamdipta, Mark
Yatskar and the anonymous reviewers for their
helpful comments on earlier versions of this paper,
and Matthew Honnibal for useful discussions.
</bodyText>
<page confidence="0.994049">
1452
</page>
<sectionHeader confidence="0.989744" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998406275229358">
Yoav Artzi, Kenton Lee, and Luke Zettlemoyer. 2015.
Broad-coverage CCG Semantic Parsing with AMR.
In Proceedings of the 2015 Conference on Empirical
Methods in Natural Language Processing.
Michael Auli and Adam Lopez. 2011a. A Comparison
of Loopy Belief Propagation and Dual Decomposi-
tion for Integrated CCG Supertagging and Parsing.
In Proceedings of the 49th Annual Meeting of the
Association for Computational Linguistics: Human
Language Technologies-Volume 1.
Michael Auli and Adam Lopez. 2011b. Efficient CCG
parsing: A* versus Adaptive Supertagging. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies-Volume 1.
Collin F. Baker, Charles J. Fillmore, and John B. Lowe.
1998. The Berkeley FrameNet Project. In Pro-
ceedings of the 36th Annual Meeting of the Associ-
ation for Computational Linguistics and 17th Inter-
national Conference on Computational Linguistics -
Volume 1.
Johan Bos. 2008. Wide-coverage Semantic Analy-
sis with Boxer. In Johan Bos and Rodolfo Del-
monte, editors, Semantics in Text Processing. STEP
2008 Conference Proceedings, Research in Compu-
tational Semantics.
Stephen A. Boxwell, Dennis Mehay, and Chris Brew.
2009. Brutus: A Semantic Role Labeling System In-
corporating CCG, CFG, and Dependency Features.
In Proceedings of the Joint Conference of the 47th
Annual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing
of the AFNLP: Volume 1.
Wanxiang Che, Zhenghua Li, Yuxuan Hu, Yongqiang
Li, Bing Qin, Ting Liu, and Sheng Li. 2008. A cas-
caded Syntactic and Semantic Dependency Parsing
System. In Proceedings of the Twelfth Conference
on Computational Natural Language Learning.
Stephen Clark and James R Curran. 2007. Wide-
coverage Efficient Statistical Parsing with CCG and
Log-Linear Models. Computational Linguistics,
33(4).
Nicholas FitzGerald, Oscar Täckström, Kuzman
Ganchev, and Dipanjan Das. 2015. Semantic Role
Labeling with Neural Network Factors. In Proceed-
ings of the 2015 Conference on Empirical Methods
in Natural Language Processing.
Daniel Gildea and Julia Hockenmaier. 2003. Identify-
ing Semantic Roles Using Combinatory Categorial
Grammar. In Proceedings of the 2003 Conference
on Empirical Methods in Natural Language Pro-
cessing.
Jan Hajiˇc, Massimiliano Ciaramita, Richard Johans-
son, Daisuke Kawahara, Maria Antònia Martí, Lluís
Màrquez, Adam Meyers, Joakim Nivre, Sebastian
Padó, Jan Štˇepánek, Pavel Straˇnák, Mihai Surdeanu,
Nianwen Xue, and Yi Zhang. 2009. The CoNLL-
2009 Shared Task: Syntactic and Semantic Depen-
dencies in Multiple Languages. In Proceedings of
the Thirteenth Conference on Computational Natu-
ral Language Learning: Shared Task.
Luheng He, Mike Lewis, and Luke Zettlemoyer. 2015.
Question-answer driven semantic role labeling: Us-
ing natural language to annotate natural language.
In Proceedings of the 2015 Conference on Empiri-
cal Methods in Natural Language Processing.
James Henderson, Paola Merlo, Ivan Titov, and
Gabriele Musillo. 2013. Multi-lingual Joint Pars-
ing of Syntactic and Semantic Dependencies with a
Latent Variable Model. Computational Linguistics.
Julia Hockenmaier. 2003. Data and models for sta-
tistical parsing with Combinatory Categorial Gram-
mar. Ph.D. thesis, University of Edinburgh. College
of Science and Engineering. School of Informatics.
M. Honnibal, J.R. Curran, and J. Bos. 2010. Rebank-
ing CCGbank for Improved NP Interpretation. In
Proceedings of the 48th Annual Meeting of the As-
sociation for Computational Linguistics.
Eduard Hovy, Mitchell Marcus, Martha Palmer,
Lance Ramshaw, and Ralph Weischedel. 2006.
OntoNotes: The 90% Solution. In Proceedings of
the Human Language Technology Conference of the
NAACL, Companion Volume: Short Papers.
Richard Johansson and Pierre Nugues. 2008.
Dependency-based Syntactic-Semantic Analysis
with Propbank and Nombank. In Proceedings of
the Twelfth Conference on Computational Natural
Language Learning.
Richard Johansson. 2009. Statistical Bistratal Depen-
dency Parsing. In Proceedings of the 2009 Con-
ference on Empirical Methods in Natural Language
Processing: Volume 2.
Dan Klein and Christopher D Manning. 2003. A*
Parsing: Fast Exact Viterbi Parse Selection. In
Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1.
Jayant Krishnamurthy and Tom M. Mitchell. 2014.
Joint Syntactic and Semantic Parsing with Combi-
natory Categorial Grammar. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics.
Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwa-
ter, and Mark Steedman. 2010. Inducing Probabilis-
tic CCG Grammars from Logical Form with Higher-
order Unification. In Proceedings of the 2010 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1223–1233.
</reference>
<page confidence="0.598029">
1453
</page>
<reference confidence="0.99981886516854">
Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke
Zettlemoyer. 2013. Scaling Semantic Parsers with
On-the-Fly Ontology Matching. In Proceedings of
the 2013 Conference on Empirical Methods in Nat-
ural Language Processing.
Omer Levy and Yoav Goldberg. 2014. Dependency-
Based Word Embeddings. In Proceedings of the
52nd Annual Meeting of the Association for Com-
putational Linguistics (Volume 2: Short Papers).
Mike Lewis and Mark Steedman. 2013. Combined
Distributional and Logical Semantics. Transactions
of the Association for Computational Linguistics, 1.
Mike Lewis and Mark Steedman. 2014a. A* CCG
Parsing with a Supertag-factored Model. In Pro-
ceedings of the 2014 Conference on Empirical Meth-
ods in Natural Language Processing.
Mike Lewis and Mark Steedman. 2014b. Improved
CCG parsing with Semi-supervised Supertagging.
Transactions of the Association for Computational
Linguistics.
D. C. Liu and J. Nocedal. 1989. On the Limited
Memory BFGS Method for Large Scale Optimiza-
tion. Math. Program., 45(3).
Xavier Lluís, Stefan Bott, and Lluís Màrquez. 2009. A
Second-order Joint Eisner Model for Syntactic and
Semantic Dependency Parsing. In Proceedings of
the Thirteenth Conference on Computational Natu-
ral Language Learning: Shared Task.
Xavier Lluís, Xavier Carreras, and Lluís Màrquez.
2013. Joint Arc-factored Parsing of Syntactic and
Semantic Dependencies. Transactions of the As-
sociation of Computational Linguistics – Volume 1,
pages 219–230.
Jason Naradowsky, Sebastian Riedel, and David A.
Smith. 2012. Improving NLP Through Marginal-
ization of Hidden Syntactic Structure. In Proceed-
ings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning.
Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008.
The Importance of Syntactic Parsing and Inference
in Semantic Role Labeling. Computational Linguis-
tics, 34(2).
Sebastian Riedel and Ivan Meza-Ruiz. 2008. Collec-
tive Semantic Role Labelling with Markov Logic. In
Proceedings of the Twelfth Conference on Computa-
tional Natural Language Learning.
Mihai Surdeanu, Lluís Màrquez, Xavier Carreras, and
Pere R. Comas. 2007. Combination Strategies for
Semantic Role Labeling. Journal of Artificial Intel-
ligence Research, 29(1).
Mihai Surdeanu, Richard Johansson, Adam Meyers,
Lluís Màrquez, and Joakim Nivre. 2008. The
CoNLL-2008 Shared Task on Joint Parsing of Syn-
tactic and Semantic Dependencies. In Proceedings
of the Twelfth Conference on Computational Natural
Language Learning.
Charles Sutton and Andrew McCallum. 2005. Joint
Parsing and Semantic Role Labeling. In Proceed-
ings of the Ninth Conference on Computational Nat-
ural Language Learning.
Oscar Täckström, Kuzman Ganchev, and Dipanjan
Das. 2015. Efficient Inference and Structured
Learning for Semantic Role Labeling. Transactions
of the Association for Computational Linguistics,
3:29–41.
Ivan Titov, James Henderson, Paola Merlo, and
Gabriele Musillo. 2009. Online Projectivisation for
Synchronous Parsing of Semantic and Syntactic De-
pendencies. In In Proceedings of the International
Joint Conference on Artificial Intelligence.
Kristina Toutanova, Aria Haghighi, and Christopher D.
Manning. 2008. A Global Joint Model for Semantic
Role Labeling. Computational Linguistics, 34(2).
David Vickrey and Daphne Koller. 2008. Applying
Sentence Simplification to the CoNLL-2008 Shared
Task. In Proceedings of the Twelfth Conference on
Computational Natural Language Learning.
Luke Zettlemoyer and Michael Collins. 2009. Learn-
ing Context-dependent Mappings from Sentences to
Logical Form. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP: Volume 2.
Hai Zhao and Chunyu Kit. 2008. Parsing Syntactic
and Semantic Dependencies with Two Single-stage
Maximum Entropy Models. In Proceedings of the
Twelfth Conference on Computational Natural Lan-
guage Learning.
</reference>
<page confidence="0.995008">
1454
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.955012">
<title confidence="0.999988">Parsing and Semantic Role Labeling</title>
<author confidence="0.99969">Mike Lewis Luheng He Luke Zettlemoyer</author>
<affiliation confidence="0.9998195">Computer Science &amp; University of</affiliation>
<address confidence="0.982491">Seattle, WA</address>
<email confidence="0.999846">mlewis@cs.washington.edu</email>
<email confidence="0.999846">luheng@cs.washington.edu</email>
<email confidence="0.999846">lsz@cs.washington.edu</email>
<abstract confidence="0.998702238095238">Joint models of syntactic and semantic parsing have the potential to improve performance on both tasks—but to date, the best results have been achieved with pipelines. We introduce a joint model using CCG, which is motivated by the close link between CCG syntax and semantics. Semantic roles are recovered by labelling the deep dependency structures produced by the grammar. Furthermore, because CCG is lexicalized, we show it is possible to factor the parsing model over words and a new algorithm— which we demonstrate is faster and more accurate than adaptive supertagging. Our joint model is the first to substantially improve both syntactic and semantic accuracy over a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Kenton Lee</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Broad-coverage CCG Semantic Parsing with AMR.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="33232" citStr="Artzi et al., 2015" startWordPosition="5417" endWordPosition="5420">i and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representations with latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 2015). Krishnamurthy and Mitchell (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less</context>
</contexts>
<marker>Artzi, Lee, Zettlemoyer, 2015</marker>
<rawString>Yoav Artzi, Kenton Lee, and Luke Zettlemoyer. 2015. Broad-coverage CCG Semantic Parsing with AMR. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Auli</author>
<author>Adam Lopez</author>
</authors>
<title>A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1.</booktitle>
<contexts>
<context position="5514" citStr="Auli and Lopez, 2011" startWordPosition="849" endWordPosition="852"> syntactic arguments with semantic roles, such as open : S\NPARG1 and open : (S\NPARG0)/NPARG1 . Figure 3 shows a detailed trace of how the example from Figure 2 is parsed with our model. We also present a new A* algorithm for the joint model. Because CCG is strongly lexicalized, we are able to introduce a new type of extended lexical entries that allows us to factor the model over words and develop effective new upper bounds on the Viterbi outside parse score. A* parsing algorithms have previously been developed for models with tree-structured syntactic dependencies (Klein and Manning, 2003; Auli and Lopez, 2011b), and models with no bi-lexical dependencies, including supertag-factored CCGs (Lewis and Steedman, 2014a). We generalize these techniques to SRL-style graph-structured dependencies. Experiments demonstrate that our model not only outperforms pipeline semantic role labelling models, but improves the quality of the syntactic parser. PropBank SRL performance is 1.6 points higher than comparable existing work, and semantic features improve syntactic accuracy by 1.6 points. Our A* algorithm is 5 times faster than CKY parsing, with no loss in accuracy. The combination of CCG-based joint modelling</context>
<context position="28636" citStr="Auli and Lopez, 2011" startWordPosition="4710" endWordPosition="4713"> is found, or the chart size exceeds 400000 nodes, we back off to the pipeline (tuned so that the backoff is used roughly as often as for the A* parser). We also compare with adaptive supertagging (AST, Clark and Curran (2007)), which is the same except for first attempting to parse with a restrictive supertagger beam Q = 0.1. Table 2 shows the results. The A* pipeline is fast, but inaccurate. CKY is 5 times slower than A* in the same space, whereas adaptive supertagging trades accuracy for speed. The best previously reported speed improvement using A* parsing is a factor of 1.2 times faster (Auli and Lopez, 2011b). Our new A* algorithm dominates existing alternatives in both speed and accuracy. 7.4 Syntactic Parsing We also evaluate our model for CCG parsing accuracy, using CCGrebank (Honnibal et al., 2010), and comparing with a C&amp;C parser model adapted to this dataset. Results are shown in Table 3. Of course, given our latent syntax, and the fact we have no model of CCGbank dependencies, we do not expect state-of-the-art accuracy. However, the 1.6 point improvement over the pipeline shows that SRL dependencies are useful for disambiguating syntactic attachment decisions. Many errors were caused by d</context>
<context position="32630" citStr="Auli and Lopez (2011" startWordPosition="5329" endWordPosition="5332">models. SRL performance is slightly worse than a pipeline version. Naradowsky et al. (2012) introduce a SRL model with latent syntax representations, by modelling a latent dependency tree during training, which is marginalized out at test time. However, performance at English SRL is roughly 7 points beneath state of the art. Other notable models include those of Johansson (2009) and Titov et al. (2009). CCG parsing Our log-linear model is closely related to that of Clark and Curran (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representations with latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 201</context>
<context position="33908" citStr="Auli and Lopez (2011" startWordPosition="5525" endWordPosition="5528">CG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein and Manning (2003) and Auli and Lopez (2011b) use A* parsing for models with tree-structured dependencies. The best reported speed improvement is parsing 1.2 times faster, whereas we improve by a factor of 5. Our model also allows the more complex graph-structured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model dependencies. 9 Conclusions and Future Work We have shown that using CCG can allow joint models of syntax and semantics to outperform pipelines, and achieve state-of-the-art results on PropBank SRL. Our new A* parsing algorithm is 5 tim</context>
</contexts>
<marker>Auli, Lopez, 2011</marker>
<rawString>Michael Auli and Adam Lopez. 2011a. A Comparison of Loopy Belief Propagation and Dual Decomposition for Integrated CCG Supertagging and Parsing. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Auli</author>
<author>Adam Lopez</author>
</authors>
<title>Efficient CCG parsing: A* versus Adaptive Supertagging.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1.</booktitle>
<contexts>
<context position="5514" citStr="Auli and Lopez, 2011" startWordPosition="849" endWordPosition="852"> syntactic arguments with semantic roles, such as open : S\NPARG1 and open : (S\NPARG0)/NPARG1 . Figure 3 shows a detailed trace of how the example from Figure 2 is parsed with our model. We also present a new A* algorithm for the joint model. Because CCG is strongly lexicalized, we are able to introduce a new type of extended lexical entries that allows us to factor the model over words and develop effective new upper bounds on the Viterbi outside parse score. A* parsing algorithms have previously been developed for models with tree-structured syntactic dependencies (Klein and Manning, 2003; Auli and Lopez, 2011b), and models with no bi-lexical dependencies, including supertag-factored CCGs (Lewis and Steedman, 2014a). We generalize these techniques to SRL-style graph-structured dependencies. Experiments demonstrate that our model not only outperforms pipeline semantic role labelling models, but improves the quality of the syntactic parser. PropBank SRL performance is 1.6 points higher than comparable existing work, and semantic features improve syntactic accuracy by 1.6 points. Our A* algorithm is 5 times faster than CKY parsing, with no loss in accuracy. The combination of CCG-based joint modelling</context>
<context position="28636" citStr="Auli and Lopez, 2011" startWordPosition="4710" endWordPosition="4713"> is found, or the chart size exceeds 400000 nodes, we back off to the pipeline (tuned so that the backoff is used roughly as often as for the A* parser). We also compare with adaptive supertagging (AST, Clark and Curran (2007)), which is the same except for first attempting to parse with a restrictive supertagger beam Q = 0.1. Table 2 shows the results. The A* pipeline is fast, but inaccurate. CKY is 5 times slower than A* in the same space, whereas adaptive supertagging trades accuracy for speed. The best previously reported speed improvement using A* parsing is a factor of 1.2 times faster (Auli and Lopez, 2011b). Our new A* algorithm dominates existing alternatives in both speed and accuracy. 7.4 Syntactic Parsing We also evaluate our model for CCG parsing accuracy, using CCGrebank (Honnibal et al., 2010), and comparing with a C&amp;C parser model adapted to this dataset. Results are shown in Table 3. Of course, given our latent syntax, and the fact we have no model of CCGbank dependencies, we do not expect state-of-the-art accuracy. However, the 1.6 point improvement over the pipeline shows that SRL dependencies are useful for disambiguating syntactic attachment decisions. Many errors were caused by d</context>
<context position="32630" citStr="Auli and Lopez (2011" startWordPosition="5329" endWordPosition="5332">models. SRL performance is slightly worse than a pipeline version. Naradowsky et al. (2012) introduce a SRL model with latent syntax representations, by modelling a latent dependency tree during training, which is marginalized out at test time. However, performance at English SRL is roughly 7 points beneath state of the art. Other notable models include those of Johansson (2009) and Titov et al. (2009). CCG parsing Our log-linear model is closely related to that of Clark and Curran (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representations with latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 201</context>
<context position="33908" citStr="Auli and Lopez (2011" startWordPosition="5525" endWordPosition="5528">CG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein and Manning (2003) and Auli and Lopez (2011b) use A* parsing for models with tree-structured dependencies. The best reported speed improvement is parsing 1.2 times faster, whereas we improve by a factor of 5. Our model also allows the more complex graph-structured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model dependencies. 9 Conclusions and Future Work We have shown that using CCG can allow joint models of syntax and semantics to outperform pipelines, and achieve state-of-the-art results on PropBank SRL. Our new A* parsing algorithm is 5 tim</context>
</contexts>
<marker>Auli, Lopez, 2011</marker>
<rawString>Michael Auli and Adam Lopez. 2011b. Efficient CCG parsing: A* versus Adaptive Supertagging. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies-Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The Berkeley FrameNet Project.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics -Volume</booktitle>
<volume>1</volume>
<contexts>
<context position="34739" citStr="Baker et al., 1998" startWordPosition="5655" endWordPosition="5658">tructured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model dependencies. 9 Conclusions and Future Work We have shown that using CCG can allow joint models of syntax and semantics to outperform pipelines, and achieve state-of-the-art results on PropBank SRL. Our new A* parsing algorithm is 5 times faster than CKY parsing, without loss of accuracy. Using latent syntax allows us to train the model purely from semantic dependencies, enabling future work to train against other annotations such as FrameNet (Baker et al., 1998), Ontonotes (Hovy et al., 2006) or QASRL (He et al., 2015). The semantic labels provided by PropBank can also be integrated into wide-coverage CCG semantic parsers (Bos, 2008; Lewis and Steedman, 2013) to improve performance on downstream applications. Acknowledgements This research was supported in part by the NSF (IIS-1252835), DARPA under the DEFT program through the AFRL (FA8750-13-2-0019), an Allen Distinguished Investigator Award, and a gift from Google. We thank Nicholas Fitzgerald, Dan Garrette, Kenton Lee, Swabha Swayamdipta, Mark Yatskar and the anonymous reviewers for their helpful </context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The Berkeley FrameNet Project. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics -Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
</authors>
<title>Wide-coverage Semantic Analysis with Boxer.</title>
<date>2008</date>
<booktitle>Semantics in Text Processing. STEP 2008 Conference Proceedings, Research in Computational Semantics.</booktitle>
<editor>In Johan Bos and Rodolfo Delmonte, editors,</editor>
<marker>Bos, 2008</marker>
<rawString>Johan Bos. 2008. Wide-coverage Semantic Analysis with Boxer. In Johan Bos and Rodolfo Delmonte, editors, Semantics in Text Processing. STEP 2008 Conference Proceedings, Research in Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen A Boxwell</author>
<author>Dennis Mehay</author>
<author>Chris Brew</author>
</authors>
<title>Brutus: A Semantic Role Labeling System Incorporating CCG, CFG, and Dependency Features.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>1</volume>
<contexts>
<context position="33674" citStr="Boxwell et al., 2009" startWordPosition="5484" endWordPosition="5487">d Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 2015). Krishnamurthy and Mitchell (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein and Manning (2003) and Auli and Lopez (2011b) use A* parsing for models with tree-structured dependencies. The best reported speed improvement is parsing 1.2 times faster, whereas we improve by a factor of 5. Our model also allows the more complex graph-structured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model de</context>
</contexts>
<marker>Boxwell, Mehay, Brew, 2009</marker>
<rawString>Stephen A. Boxwell, Dennis Mehay, and Chris Brew. 2009. Brutus: A Semantic Role Labeling System Incorporating CCG, CFG, and Dependency Features. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Zhenghua Li</author>
<author>Yuxuan Hu</author>
<author>Yongqiang Li</author>
<author>Bing Qin</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>A cascaded Syntactic and Semantic Dependency Parsing System.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="24688" citStr="Che et al. (2008)" startWordPosition="4043" endWordPosition="4046">entification (Hajiˇc et al., 2009; FitzGerald et al., 2015). This setting is particularly unrealistic for our joint model, where gold predicate identification would be a highly useful feature for the supertagger; we only compare with models that use automatic predicate identification. To the best of our knowledge, the best SRL results with automatic predicate identification were achieved at CoNLL-2008. A number of other models have been evaluated on CoNLL-2008 data. While we cannot compare directly on our metric, the best reported joint model (Johansson, 2009) scored 1.4 points lower than the Che et al. (2008) system we compare to on the CoNLL metric on PropBank. Other joint models, such as those of Titov et al. (2009) and Lluís et al. (2013), achieve similar performance. Evaluation Metric Comparing fairly with existing work is complicated by the mismatch between heads found by our model and those used in other evaluations. Headedness decisions are often arbitrary—for example, whether a prepositional phrase is headed by the noun or preposition—and different choices were made in the design of CCGbank and the CoNLL-2008 headedness rules. To solve this problem, we introduce a new within-constituent me</context>
<context position="26013" citStr="Che et al. (2008)" startWordPosition="4265" endWordPosition="4268">; Johansson and Nugues, 2008) or ensemble methods (Surdeanu et al., 2007; Punyakanok et al., 2008). These techniques have the potential to improve any SRL system, including ours, at some expense in speed. PropBank Brown Model P R F1 P R F1 Vickrey 87.3 77.3 82.0 74.0 64.5 68.9 Che 85.3 78.6 81.8 71.1 65.7 68.0 Zhao 82.4 79.8 81.1 66.6 64.9 65.7 Riedel 83.6 74.7 78.9 69.3 62.7 65.8 Pipeline 79.2 73.9 76.4 69.3 64.0 66.1 Joint 84.8 82.2 83.5 71.2 69.2 70.2 Table 1: Comparison with the best single-parser SRL models on PropBank from CoNLL-2008. The comparison models are Vickrey and Koller (2008), Che et al. (2008), Zhao and Kit (2008) and Riedel and Meza-Ruiz (2008). dencies as correct if they attach anywhere within the original PropBank-annotated argument spans. For example, if the PropBank annotates that the ARGO of owned is by Google, a dependency to either by or Google is judged correct. We compute new scores for the CoNLL-2008 submissions on our metric, filtering reference and continuation arguments (which are artifacts of the CoNLL conversion of PropBank, but not required by our metric), and nominal predicates based on POS tag. The ranking of the top 5 CoNLL-2008 open-track models is identical un</context>
</contexts>
<marker>Che, Li, Hu, Li, Qin, Liu, Li, 2008</marker>
<rawString>Wanxiang Che, Zhenghua Li, Yuxuan Hu, Yongqiang Li, Bing Qin, Ting Liu, and Sheng Li. 2008. A cascaded Syntactic and Semantic Dependency Parsing System. In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Widecoverage Efficient Statistical Parsing with CCG and Log-Linear Models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="9226" citStr="Clark and Curran (2007)" startWordPosition="1445" endWordPosition="1448">the bound can be computed as the sum of the highest-scoring supertags in the outside parse. The agenda is initialized with items representing every category for every word. Then, after each item is added to the chart, the agenda is updated with all binary and unary rules that can be applied to the new item. For more details, see Lewis and Steedman (2014a). 3 Model Our joint model of CCG and SRL parsing simply involves labelling CCG syntactic dependencies (which are implicit in CCG parses), with SRL roles (or null). This formulation allows us to easily adapt the log-linear CCG parsing model of Clark and Curran (2007) to the joint setting by working with extended dependencies that including syntactic and semantic information. More formally, we can define a notion of consistency to specify the labelling of syntactic dependencies. A set of semantic dependencies 7r is consistent with a CCG derivation d if each semantic dependency corresponds to a single syntactic dependency—for example, see the dependencies in Figure 3. The CCG derivation in Figure 3 would also be consistent with the SRL dependency refuse −−−−→he, but not refuse ARG1 ARG2 −−−−→reports (because the derivation does not produce the required synt</context>
<context position="21639" citStr="Clark and Curran, 2007" startWordPosition="3544" endWordPosition="3547">� O*xi,d1,w1) 2 L�(d1,π1)EGEN(xi) 8 ZU where GEN(xi) is the set of consistent CCG and SRL parses for a sentence xi (see Section 3), and A(xi, 7ri) is the set of CCG derivations that are maximally consistent with gold SRL parses 7ri. More formally, if labelled(y) returns the set of labelled dependencies from parse y, then: A(x, 7r) = arg max |7r n labelled(y)| y∈GEN(x) The arguments of PropBank dependencies can span multiple words, so CCG dependencies are marked as equivalent if their argument is anywhere within the PropBank span. The approach is closely related to the hybrid dependency model (Clark and Curran, 2007). However the CCGbank dependencies used by Clark and Curran’s model constrain all lexical and attachment decisions (only allowing ‘spurious’ derivational ambiguity) whereas our use of semantic dependencies models most of the syntactic parse as latent. 6.1 Hyperparameters Calculating the gradient of the loss function requires computing the marginal probability of the correct parses. Computing marginal probabilities exactly involves summing over all possible CCG parses, which is intractable. Instead, following Clark and Curran, we limit the size of training charts using a variable-width supertag</context>
<context position="28242" citStr="Clark and Curran (2007)" startWordPosition="4639" endWordPosition="4642">e computed lazily. 1450 Model Sentences PropBank per second F1 Pipeline A* 38.3 76.4 Joint CKY 6.0 83.5 Joint AST 20.3 83.0 Joint A* 31.3 83.5 Table 2: Parser speed on PropBank Section 23 Model P R F1 C&amp;C 81.8 81.2 81.5 Pipeline 76.6 77.7 77.2 Joint 78.3 79.4 78.8 Table 3: Labelled F1 for CCGbank dependencies on CCGrebank Section 23 We compare with a CKY parsing over the same space. If no parse is found, or the chart size exceeds 400000 nodes, we back off to the pipeline (tuned so that the backoff is used roughly as often as for the A* parser). We also compare with adaptive supertagging (AST, Clark and Curran (2007)), which is the same except for first attempting to parse with a restrictive supertagger beam Q = 0.1. Table 2 shows the results. The A* pipeline is fast, but inaccurate. CKY is 5 times slower than A* in the same space, whereas adaptive supertagging trades accuracy for speed. The best previously reported speed improvement using A* parsing is a factor of 1.2 times faster (Auli and Lopez, 2011b). Our new A* algorithm dominates existing alternatives in both speed and accuracy. 7.4 Syntactic Parsing We also evaluate our model for CCG parsing accuracy, using CCGrebank (Honnibal et al., 2010), and c</context>
<context position="32503" citStr="Clark and Curran (2007)" startWordPosition="5307" endWordPosition="5310">int arc-factored model for parsing syntactic and semantic dependencies, using dualdecomposition to maximize agreement between the models. SRL performance is slightly worse than a pipeline version. Naradowsky et al. (2012) introduce a SRL model with latent syntax representations, by modelling a latent dependency tree during training, which is marginalized out at test time. However, performance at English SRL is roughly 7 points beneath state of the art. Other notable models include those of Johansson (2009) and Titov et al. (2009). CCG parsing Our log-linear model is closely related to that of Clark and Curran (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representations with latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatko</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James R Curran. 2007. Widecoverage Efficient Statistical Parsing with CCG and Log-Linear Models. Computational Linguistics, 33(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas FitzGerald</author>
<author>Oscar Täckström</author>
<author>Kuzman Ganchev</author>
<author>Dipanjan Das</author>
</authors>
<title>Semantic Role Labeling with Neural Network Factors.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="24130" citStr="FitzGerald et al., 2015" startWordPosition="3954" endWordPosition="3957">ine first parses with a supertag-factored A* model, and chooses a semantic role for each CCG dependency with a log-linear classifier. The classifier uses the role and attachment features used by the parser. 7.2 Semantic Role Labelling We evaluate our parser as a dependency-based SRL model on PropBank, comparing with CoNLL-2008 systems (Surdeanu et al., 2008). Comparison systems Following Täckström et al. (2015), we compare with the best ‘single parser’ SRL models, which use only a single syntactic parse.3 Much recent work has evaluated using gold predicate identification (Hajiˇc et al., 2009; FitzGerald et al., 2015). This setting is particularly unrealistic for our joint model, where gold predicate identification would be a highly useful feature for the supertagger; we only compare with models that use automatic predicate identification. To the best of our knowledge, the best SRL results with automatic predicate identification were achieved at CoNLL-2008. A number of other models have been evaluated on CoNLL-2008 data. While we cannot compare directly on our metric, the best reported joint model (Johansson, 2009) scored 1.4 points lower than the Che et al. (2008) system we compare to on the CoNLL metric </context>
</contexts>
<marker>FitzGerald, Täckström, Ganchev, Das, 2015</marker>
<rawString>Nicholas FitzGerald, Oscar Täckström, Kuzman Ganchev, and Dipanjan Das. 2015. Semantic Role Labeling with Neural Network Factors. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Identifying Semantic Roles Using Combinatory Categorial Grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="33651" citStr="Gildea and Hockenmaier, 2003" startWordPosition="5480" endWordPosition="5483">th latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 2015). Krishnamurthy and Mitchell (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein and Manning (2003) and Auli and Lopez (2011b) use A* parsing for models with tree-structured dependencies. The best reported speed improvement is parsing 1.2 times faster, whereas we improve by a factor of 5. Our model also allows the more complex graph-structured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for C</context>
</contexts>
<marker>Gildea, Hockenmaier, 2003</marker>
<rawString>Daniel Gildea and Julia Hockenmaier. 2003. Identifying Semantic Roles Using Combinatory Categorial Grammar. In Proceedings of the 2003 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jan Hajiˇc</author>
<author>Massimiliano Ciaramita</author>
<author>Richard Johansson</author>
<author>Daisuke Kawahara</author>
</authors>
<title>Maria Antònia Martí, Lluís Màrquez, Adam Meyers, Joakim Nivre, Sebastian Padó, Jan Štˇepánek, Pavel Straˇnák, Mihai Surdeanu, Nianwen Xue, and Yi Zhang.</title>
<date>2009</date>
<booktitle>The CoNLL2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task.</booktitle>
<marker>Hajiˇc, Ciaramita, Johansson, Kawahara, 2009</marker>
<rawString>Jan Hajiˇc, Massimiliano Ciaramita, Richard Johansson, Daisuke Kawahara, Maria Antònia Martí, Lluís Màrquez, Adam Meyers, Joakim Nivre, Sebastian Padó, Jan Štˇepánek, Pavel Straˇnák, Mihai Surdeanu, Nianwen Xue, and Yi Zhang. 2009. The CoNLL2009 Shared Task: Syntactic and Semantic Dependencies in Multiple Languages. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luheng He</author>
<author>Mike Lewis</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Question-answer driven semantic role labeling: Using natural language to annotate natural language.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="34797" citStr="He et al., 2015" startWordPosition="5667" endWordPosition="5670">Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model dependencies. 9 Conclusions and Future Work We have shown that using CCG can allow joint models of syntax and semantics to outperform pipelines, and achieve state-of-the-art results on PropBank SRL. Our new A* parsing algorithm is 5 times faster than CKY parsing, without loss of accuracy. Using latent syntax allows us to train the model purely from semantic dependencies, enabling future work to train against other annotations such as FrameNet (Baker et al., 1998), Ontonotes (Hovy et al., 2006) or QASRL (He et al., 2015). The semantic labels provided by PropBank can also be integrated into wide-coverage CCG semantic parsers (Bos, 2008; Lewis and Steedman, 2013) to improve performance on downstream applications. Acknowledgements This research was supported in part by the NSF (IIS-1252835), DARPA under the DEFT program through the AFRL (FA8750-13-2-0019), an Allen Distinguished Investigator Award, and a gift from Google. We thank Nicholas Fitzgerald, Dan Garrette, Kenton Lee, Swabha Swayamdipta, Mark Yatskar and the anonymous reviewers for their helpful comments on earlier versions of this paper, and Matthew Ho</context>
</contexts>
<marker>He, Lewis, Zettlemoyer, 2015</marker>
<rawString>Luheng He, Mike Lewis, and Luke Zettlemoyer. 2015. Question-answer driven semantic role labeling: Using natural language to annotate natural language. In Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Henderson</author>
<author>Paola Merlo</author>
<author>Ivan Titov</author>
<author>Gabriele Musillo</author>
</authors>
<title>Multi-lingual Joint Parsing of Syntactic and Semantic Dependencies with a Latent Variable Model. Computational Linguistics.</title>
<date>2013</date>
<contexts>
<context position="1521" citStr="Henderson et al., 2013" startWordPosition="228" endWordPosition="231">r a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model. 1 Introduction Joint models of syntactic and semantic parsing are attractive; they can potentially avoid the error propagation that is inherent in pipelines by using semantic models to inform syntactic attachments. However, in practice, the performance of joint systems for semantic role labelling (SRL) has been substantially beneath that of pipelines (Sutton and McCallum, 2005; Lluís et al., 2009; Johansson, 2009; Titov et al., 2009; Naradowsky et al., 2012; Lluís et al., 2013; Henderson et al., 2013). In this paper, we present the first approach to break this trend, by building on the close relationship of syntax and semantics in CCG grammars to enable both (1) a simple but highly effective joint model and (2) an efficient A* parsing algorithm. Semantic dependencies can span an unbounded number of syntactic dependencies, causing significant inference and sparsity challenges for joint ARG0 Figure 1: Mismatch between syntactic and semantic dependencies. He refused to confirm or deny reports NP (S\NP)1(S\NP) SIS (S\NP)INP conj (S\NP)INP NP ∅ ARG0 ARG1 ARG0 ARG1 ARG0 Figure 2: Dependencies pr</context>
</contexts>
<marker>Henderson, Merlo, Titov, Musillo, 2013</marker>
<rawString>James Henderson, Paola Merlo, Ivan Titov, and Gabriele Musillo. 2013. Multi-lingual Joint Parsing of Syntactic and Semantic Dependencies with a Latent Variable Model. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
</authors>
<title>Data and models for statistical parsing with Combinatory Categorial Grammar.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh. College of Science and Engineering. School of Informatics.</institution>
<contexts>
<context position="7608" citStr="Hockenmaier (2003)" startWordPosition="1164" endWordPosition="1165">s. Re-using variables allows dependencies to propagate. For example, the determiner category NPi/Ni marks that the head of the resulting NP is equal to the head of its N argument (e.g. the head of the report is report), as in the following parse: deny the report (Sdeny\NPx)/NPy NPz/Nz Nreport {deny−→x, deny−→y} {the−→z} {} &gt; Sdeny\NPx {deny−→x, deny−→report, the−→report} The same mechanism allows long-range arguments to be propagated. Figure 3 shows several long-range arguments, such as how co-indexation NPreport {the−→report} &gt; 1445 propagates the subject of deny to he. For more details, see Hockenmaier (2003). Now, we can define a log-linear model over pairs of consistent CCG derivations d and SRL dependencies 7r: 2.2 A* CCG parsing A* parsing searches for an optimal parse, without building a complete chart (in contrast to CKY parsing). This is particularly attractive for CCG, because the formalism’s lexical and derivational ambiguity causes the parse charts to be very dense, in practice. Lewis and Steedman (2014a) showed that A* CCG parsing can be highly efficient, but used a restricted model without bi-lexical features. In A* parsing, entries y are added to the chart in order of their cost f(y) </context>
<context position="33651" citStr="Hockenmaier, 2003" startWordPosition="5482" endWordPosition="5483">CGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 2015). Krishnamurthy and Mitchell (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein and Manning (2003) and Auli and Lopez (2011b) use A* parsing for models with tree-structured dependencies. The best reported speed improvement is parsing 1.2 times faster, whereas we improve by a factor of 5. Our model also allows the more complex graph-structured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for C</context>
</contexts>
<marker>Hockenmaier, 2003</marker>
<rawString>Julia Hockenmaier. 2003. Data and models for statistical parsing with Combinatory Categorial Grammar. Ph.D. thesis, University of Edinburgh. College of Science and Engineering. School of Informatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Honnibal</author>
<author>J R Curran</author>
<author>J Bos</author>
</authors>
<title>Rebanking CCGbank for Improved NP Interpretation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="12009" citStr="Honnibal et al., 2010" startWordPosition="1889" endWordPosition="1892">, dependencies, and local rule instantiations. 2Bold-face is used to highlight the argument of a category corresponding to a dependency. For example (S\NP)/NP denotes the first (subject) dependency of a transitive verb. eθ·φ(x,d,π) {} &lt; 1446 3.2.1 Supertagging Features Supertagging features φCAT score categories for words. A single feature is used, which is the (unnormalized) score from Lewis and Steedman (2014b)’s supertagging model. The supertagger outputs a distribution over categories for each word independently. The model is trained on supertags extracted from an adaptation of CCGrebank (Honnibal et al., 2010). The adaptation makes minor changes to better match PropBank. 3.2.2 Preposition Features Preposition features φPP score whether the nth argument of the word at index f with category c should take a PP argument headed by preposition p. We use features xf+p, lf+c and lf+c+n+p, where xf is the fth word, and lf is its lemma. 3.2.3 Labelling Features Labelling features φROLE determine whether the nth argument of a word with lemma l, and category c should take a role r. We use n+r, c+n+r, c+n+p+r, l+c+n+p+r, n+r, r, l+p+r, c+n+r, l+r, h+r, where h is an indicator of whether l is hyphenated, and p i</context>
<context position="28835" citStr="Honnibal et al., 2010" startWordPosition="4741" endWordPosition="4744">(AST, Clark and Curran (2007)), which is the same except for first attempting to parse with a restrictive supertagger beam Q = 0.1. Table 2 shows the results. The A* pipeline is fast, but inaccurate. CKY is 5 times slower than A* in the same space, whereas adaptive supertagging trades accuracy for speed. The best previously reported speed improvement using A* parsing is a factor of 1.2 times faster (Auli and Lopez, 2011b). Our new A* algorithm dominates existing alternatives in both speed and accuracy. 7.4 Syntactic Parsing We also evaluate our model for CCG parsing accuracy, using CCGrebank (Honnibal et al., 2010), and comparing with a C&amp;C parser model adapted to this dataset. Results are shown in Table 3. Of course, given our latent syntax, and the fact we have no model of CCGbank dependencies, we do not expect state-of-the-art accuracy. However, the 1.6 point improvement over the pipeline shows that SRL dependencies are useful for disambiguating syntactic attachment decisions. Many errors were caused by disagreements between CCGbank and PropBank—PropBank is likely to be more accurate as it was hand-annotated, rather than automatically converted from the Penn Treebank. In effect, our latent model of s</context>
</contexts>
<marker>Honnibal, Curran, Bos, 2010</marker>
<rawString>M. Honnibal, J.R. Curran, and J. Bos. 2010. Rebanking CCGbank for Improved NP Interpretation. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
<author>Mitchell Marcus</author>
<author>Martha Palmer</author>
<author>Lance Ramshaw</author>
<author>Ralph Weischedel</author>
</authors>
<title>OntoNotes: The 90% Solution.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers.</booktitle>
<contexts>
<context position="34770" citStr="Hovy et al., 2006" startWordPosition="5660" endWordPosition="5663">for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model dependencies. 9 Conclusions and Future Work We have shown that using CCG can allow joint models of syntax and semantics to outperform pipelines, and achieve state-of-the-art results on PropBank SRL. Our new A* parsing algorithm is 5 times faster than CKY parsing, without loss of accuracy. Using latent syntax allows us to train the model purely from semantic dependencies, enabling future work to train against other annotations such as FrameNet (Baker et al., 1998), Ontonotes (Hovy et al., 2006) or QASRL (He et al., 2015). The semantic labels provided by PropBank can also be integrated into wide-coverage CCG semantic parsers (Bos, 2008; Lewis and Steedman, 2013) to improve performance on downstream applications. Acknowledgements This research was supported in part by the NSF (IIS-1252835), DARPA under the DEFT program through the AFRL (FA8750-13-2-0019), an Allen Distinguished Investigator Award, and a gift from Google. We thank Nicholas Fitzgerald, Dan Garrette, Kenton Lee, Swabha Swayamdipta, Mark Yatskar and the anonymous reviewers for their helpful comments on earlier versions of</context>
</contexts>
<marker>Hovy, Marcus, Palmer, Ramshaw, Weischedel, 2006</marker>
<rawString>Eduard Hovy, Mitchell Marcus, Martha Palmer, Lance Ramshaw, and Ralph Weischedel. 2006. OntoNotes: The 90% Solution. In Proceedings of the Human Language Technology Conference of the NAACL, Companion Volume: Short Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Dependency-based Syntactic-Semantic Analysis with Propbank and Nombank.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="25425" citStr="Johansson and Nugues, 2008" startWordPosition="4160" endWordPosition="4163">) and Lluís et al. (2013), achieve similar performance. Evaluation Metric Comparing fairly with existing work is complicated by the mismatch between heads found by our model and those used in other evaluations. Headedness decisions are often arbitrary—for example, whether a prepositional phrase is headed by the noun or preposition—and different choices were made in the design of CCGbank and the CoNLL-2008 headedness rules. To solve this problem, we introduce a new within-constituent metric, which awards depen3The best models use reranking with powerful global features (Toutanova et al., 2008; Johansson and Nugues, 2008) or ensemble methods (Surdeanu et al., 2007; Punyakanok et al., 2008). These techniques have the potential to improve any SRL system, including ours, at some expense in speed. PropBank Brown Model P R F1 P R F1 Vickrey 87.3 77.3 82.0 74.0 64.5 68.9 Che 85.3 78.6 81.8 71.1 65.7 68.0 Zhao 82.4 79.8 81.1 66.6 64.9 65.7 Riedel 83.6 74.7 78.9 69.3 62.7 65.8 Pipeline 79.2 73.9 76.4 69.3 64.0 66.1 Joint 84.8 82.2 83.5 71.2 69.2 70.2 Table 1: Comparison with the best single-parser SRL models on PropBank from CoNLL-2008. The comparison models are Vickrey and Koller (2008), Che et al. (2008), Zhao and K</context>
</contexts>
<marker>Johansson, Nugues, 2008</marker>
<rawString>Richard Johansson and Pierre Nugues. 2008. Dependency-based Syntactic-Semantic Analysis with Propbank and Nombank. In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
</authors>
<title>Statistical Bistratal Dependency Parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume</booktitle>
<volume>2</volume>
<contexts>
<context position="1431" citStr="Johansson, 2009" startWordPosition="214" endWordPosition="215">del is the first to substantially improve both syntactic and semantic accuracy over a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model. 1 Introduction Joint models of syntactic and semantic parsing are attractive; they can potentially avoid the error propagation that is inherent in pipelines by using semantic models to inform syntactic attachments. However, in practice, the performance of joint systems for semantic role labelling (SRL) has been substantially beneath that of pipelines (Sutton and McCallum, 2005; Lluís et al., 2009; Johansson, 2009; Titov et al., 2009; Naradowsky et al., 2012; Lluís et al., 2013; Henderson et al., 2013). In this paper, we present the first approach to break this trend, by building on the close relationship of syntax and semantics in CCG grammars to enable both (1) a simple but highly effective joint model and (2) an efficient A* parsing algorithm. Semantic dependencies can span an unbounded number of syntactic dependencies, causing significant inference and sparsity challenges for joint ARG0 Figure 1: Mismatch between syntactic and semantic dependencies. He refused to confirm or deny reports NP (S\NP)1(</context>
<context position="24637" citStr="Johansson, 2009" startWordPosition="4035" endWordPosition="4036"> recent work has evaluated using gold predicate identification (Hajiˇc et al., 2009; FitzGerald et al., 2015). This setting is particularly unrealistic for our joint model, where gold predicate identification would be a highly useful feature for the supertagger; we only compare with models that use automatic predicate identification. To the best of our knowledge, the best SRL results with automatic predicate identification were achieved at CoNLL-2008. A number of other models have been evaluated on CoNLL-2008 data. While we cannot compare directly on our metric, the best reported joint model (Johansson, 2009) scored 1.4 points lower than the Che et al. (2008) system we compare to on the CoNLL metric on PropBank. Other joint models, such as those of Titov et al. (2009) and Lluís et al. (2013), achieve similar performance. Evaluation Metric Comparing fairly with existing work is complicated by the mismatch between heads found by our model and those used in other evaluations. Headedness decisions are often arbitrary—for example, whether a prepositional phrase is headed by the noun or preposition—and different choices were made in the design of CCGbank and the CoNLL-2008 headedness rules. To solve thi</context>
<context position="32391" citStr="Johansson (2009)" startWordPosition="5289" endWordPosition="5290">any proposals for jointly parsing syntactic and semantic dependencies. Lluís et al. (2013) introduce a joint arc-factored model for parsing syntactic and semantic dependencies, using dualdecomposition to maximize agreement between the models. SRL performance is slightly worse than a pipeline version. Naradowsky et al. (2012) introduce a SRL model with latent syntax representations, by modelling a latent dependency tree during training, which is marginalized out at test time. However, performance at English SRL is roughly 7 points beneath state of the art. Other notable models include those of Johansson (2009) and Titov et al. (2009). CCG parsing Our log-linear model is closely related to that of Clark and Curran (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences </context>
</contexts>
<marker>Johansson, 2009</marker>
<rawString>Richard Johansson. 2009. Statistical Bistratal Dependency Parsing. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing: Volume 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>A* Parsing: Fast Exact Viterbi Parse Selection.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language TechnologyVolume 1.</booktitle>
<contexts>
<context position="5492" citStr="Klein and Manning, 2003" startWordPosition="845" endWordPosition="848">lexical entries that pair syntactic arguments with semantic roles, such as open : S\NPARG1 and open : (S\NPARG0)/NPARG1 . Figure 3 shows a detailed trace of how the example from Figure 2 is parsed with our model. We also present a new A* algorithm for the joint model. Because CCG is strongly lexicalized, we are able to introduce a new type of extended lexical entries that allows us to factor the model over words and develop effective new upper bounds on the Viterbi outside parse score. A* parsing algorithms have previously been developed for models with tree-structured syntactic dependencies (Klein and Manning, 2003; Auli and Lopez, 2011b), and models with no bi-lexical dependencies, including supertag-factored CCGs (Lewis and Steedman, 2014a). We generalize these techniques to SRL-style graph-structured dependencies. Experiments demonstrate that our model not only outperforms pipeline semantic role labelling models, but improves the quality of the syntactic parser. PropBank SRL performance is 1.6 points higher than comparable existing work, and semantic features improve syntactic accuracy by 1.6 points. Our A* algorithm is 5 times faster than CKY parsing, with no loss in accuracy. The combination of CCG</context>
<context position="33883" citStr="Klein and Manning (2003)" startWordPosition="5520" endWordPosition="5523">l (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein and Manning (2003) and Auli and Lopez (2011b) use A* parsing for models with tree-structured dependencies. The best reported speed improvement is parsing 1.2 times faster, whereas we improve by a factor of 5. Our model also allows the more complex graph-structured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model dependencies. 9 Conclusions and Future Work We have shown that using CCG can allow joint models of syntax and semantics to outperform pipelines, and achieve state-of-the-art results on PropBank SRL. Our new A* p</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D Manning. 2003. A* Parsing: Fast Exact Viterbi Parse Selection. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language TechnologyVolume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jayant Krishnamurthy</author>
<author>Tom M Mitchell</author>
</authors>
<title>Joint Syntactic and Semantic Parsing with Combinatory Categorial Grammar.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="33267" citStr="Krishnamurthy and Mitchell (2014)" startWordPosition="5421" endWordPosition="5424">who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representations with latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 2015). Krishnamurthy and Mitchell (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein an</context>
</contexts>
<marker>Krishnamurthy, Mitchell, 2014</marker>
<rawString>Jayant Krishnamurthy and Tom M. Mitchell. 2014. Joint Syntactic and Semantic Parsing with Combinatory Categorial Grammar. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Luke Zettlemoyer</author>
<author>Sharon Goldwater</author>
<author>Mark Steedman</author>
</authors>
<title>Inducing Probabilistic CCG Grammars from Logical Form with Higherorder Unification.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1223--1233</pages>
<contexts>
<context position="33094" citStr="Kwiatkowski et al., 2010" startWordPosition="5397" endWordPosition="5400">o that of Clark and Curran (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representations with latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 2015). Krishnamurthy and Mitchell (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>Tom Kwiatkowski, Luke Zettlemoyer, Sharon Goldwater, and Mark Steedman. 2010. Inducing Probabilistic CCG Grammars from Logical Form with Higherorder Unification. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1223–1233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tom Kwiatkowski</author>
<author>Eunsol Choi</author>
<author>Yoav Artzi</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Scaling Semantic Parsers with On-the-Fly Ontology Matching.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="33121" citStr="Kwiatkowski et al., 2013" startWordPosition="5401" endWordPosition="5404"> (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representations with latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 2015). Krishnamurthy and Mitchell (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-be</context>
</contexts>
<marker>Kwiatkowski, Choi, Artzi, Zettlemoyer, 2013</marker>
<rawString>Tom Kwiatkowski, Eunsol Choi, Yoav Artzi, and Luke Zettlemoyer. 2013. Scaling Semantic Parsers with On-the-Fly Ontology Matching. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Omer Levy</author>
<author>Yoav Goldberg</author>
</authors>
<title>DependencyBased Word Embeddings.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics</booktitle>
<volume>2</volume>
<institution>Short Papers).</institution>
<contexts>
<context position="13041" citStr="Levy and Goldberg (2014)" startWordPosition="2074" endWordPosition="2077"> of a word with lemma l, and category c should take a role r. We use n+r, c+n+r, c+n+p+r, l+c+n+p+r, n+r, r, l+p+r, c+n+r, l+r, h+r, where h is an indicator of whether l is hyphenated, and p is the preposition of PP arguments. 3.2.4 Dependency Features Dependency features φDEP score dependencies, based on the functor index f, argument index a and role r. We use lf+r+la, lf+r+ca, d+r, cf+o+r, ca+o+r, where o is an offset from −3... +3, d is the distance between f and a, ci is a cluster or POS tag for word i, and li is the lemma of word i. Clusters were created from pre-trained word embeddings (Levy and Goldberg (2014)) using k-means, with k = 20, 50, 200,1000, 2500. These features only apply when the role r =� ∅. 3.2.5 Derivation Features Derivation features φDERIV score properties of the syntactic derivation. To simplify computation of the upper bounds for the A* parsing algorithm given in Section 5, the weights of these features are constrained to be &lt; 0. For simplicity, we only use features for unary rules—for example, a feature records when the unary rule N —* NP converts a determiner-less N to a NP. 4 Lexical Factorization In this section, we show how to factor the model into extended lexical entries.</context>
</contexts>
<marker>Levy, Goldberg, 2014</marker>
<rawString>Omer Levy and Yoav Goldberg. 2014. DependencyBased Word Embeddings. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>Combined Distributional and Logical Semantics.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>1</volume>
<marker>Lewis, Steedman, 2013</marker>
<rawString>Mike Lewis and Mark Steedman. 2013. Combined Distributional and Logical Semantics. Transactions of the Association for Computational Linguistics, 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>A* CCG Parsing with a Supertag-factored Model.</title>
<date>2014</date>
<booktitle>In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="5620" citStr="Lewis and Steedman, 2014" startWordPosition="863" endWordPosition="867">e 3 shows a detailed trace of how the example from Figure 2 is parsed with our model. We also present a new A* algorithm for the joint model. Because CCG is strongly lexicalized, we are able to introduce a new type of extended lexical entries that allows us to factor the model over words and develop effective new upper bounds on the Viterbi outside parse score. A* parsing algorithms have previously been developed for models with tree-structured syntactic dependencies (Klein and Manning, 2003; Auli and Lopez, 2011b), and models with no bi-lexical dependencies, including supertag-factored CCGs (Lewis and Steedman, 2014a). We generalize these techniques to SRL-style graph-structured dependencies. Experiments demonstrate that our model not only outperforms pipeline semantic role labelling models, but improves the quality of the syntactic parser. PropBank SRL performance is 1.6 points higher than comparable existing work, and semantic features improve syntactic accuracy by 1.6 points. Our A* algorithm is 5 times faster than CKY parsing, with no loss in accuracy. The combination of CCG-based joint modelling and A* decoding gives an efficient, accurate, and linguistically principled parser.1 1The parser is avail</context>
<context position="8020" citStr="Lewis and Steedman (2014" startWordPosition="1230" endWordPosition="1233">ange arguments to be propagated. Figure 3 shows several long-range arguments, such as how co-indexation NPreport {the−→report} &gt; 1445 propagates the subject of deny to he. For more details, see Hockenmaier (2003). Now, we can define a log-linear model over pairs of consistent CCG derivations d and SRL dependencies 7r: 2.2 A* CCG parsing A* parsing searches for an optimal parse, without building a complete chart (in contrast to CKY parsing). This is particularly attractive for CCG, because the formalism’s lexical and derivational ambiguity causes the parse charts to be very dense, in practice. Lewis and Steedman (2014a) showed that A* CCG parsing can be highly efficient, but used a restricted model without bi-lexical features. In A* parsing, entries y are added to the chart in order of their cost f(y) = g(y) + h(y), where g(y) is the inside score for the entry, and h(y) is an upper bound on the Viterbi outside score. Because partial parses are built in order of increasing f(y), the first complete parse added to the chart is guaranteed to be optimal. The key to making A* parsing efficient is computing tight upper bounds on the outside score. In Lewis and Steedman’s supertag-factored model, the bound can be </context>
<context position="11801" citStr="Lewis and Steedman (2014" startWordPosition="1858" endWordPosition="1861">ating both the noun and preposition from prepositional phrases allows the model to use both for features, and improved results. 3.2 Features We use the following feature classes, which decompose over categories, dependencies, and local rule instantiations. 2Bold-face is used to highlight the argument of a category corresponding to a dependency. For example (S\NP)/NP denotes the first (subject) dependency of a transitive verb. eθ·φ(x,d,π) {} &lt; 1446 3.2.1 Supertagging Features Supertagging features φCAT score categories for words. A single feature is used, which is the (unnormalized) score from Lewis and Steedman (2014b)’s supertagging model. The supertagger outputs a distribution over categories for each word independently. The model is trained on supertags extracted from an adaptation of CCGrebank (Honnibal et al., 2010). The adaptation makes minor changes to better match PropBank. 3.2.2 Preposition Features Preposition features φPP score whether the nth argument of the word at index f with category c should take a PP argument headed by preposition p. We use features xf+p, lf+c and lf+c+n+p, where xf is the fth word, and lf is its lemma. 3.2.3 Labelling Features Labelling features φROLE determine whether </context>
<context position="23320" citStr="Lewis and Steedman (2014" startWordPosition="3824" endWordPosition="3827">mantic role less than 3 times in the aligned data, it is pruned from the training and decoding charts. We also filter infrequent features before training. We count the number of times each feature occurs in the aligned data, and filter features occurring less than 3 times. During decoding, we prune lexical categories whose probability under the supertagging model is less than a factor of 10−2 of that of the best category for that word. If the chart size exceeds 20000 nodes, we back off to a pipeline model (roughly 3% of sentences). Finally, we build and use a tag dictionary in the same way as Lewis and Steedman (2014a). Y L(θ) = log i X= i 1449 7 Experiments 7.1 Experimental Setup We used PropBank Section 00 for development, Sections 02-21 for training, and Section 23 for testing. The Pipeline baseline first parses with a supertag-factored A* model, and chooses a semantic role for each CCG dependency with a log-linear classifier. The classifier uses the role and attachment features used by the parser. 7.2 Semantic Role Labelling We evaluate our parser as a dependency-based SRL model on PropBank, comparing with CoNLL-2008 systems (Surdeanu et al., 2008). Comparison systems Following Täckström et al. (2015)</context>
<context position="34205" citStr="Lewis and Steedman (2014" startWordPosition="5570" endWordPosition="5573">s features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein and Manning (2003) and Auli and Lopez (2011b) use A* parsing for models with tree-structured dependencies. The best reported speed improvement is parsing 1.2 times faster, whereas we improve by a factor of 5. Our model also allows the more complex graph-structured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model dependencies. 9 Conclusions and Future Work We have shown that using CCG can allow joint models of syntax and semantics to outperform pipelines, and achieve state-of-the-art results on PropBank SRL. Our new A* parsing algorithm is 5 times faster than CKY parsing, without loss of accuracy. Using latent syntax allows us to train the model purely from semantic dependencies, enabling future work to train against other annotations such as FrameNet (Baker et al., 1998), Ontonotes (Hovy et al., 2006) or QASRL (He et al., 2015). The se</context>
</contexts>
<marker>Lewis, Steedman, 2014</marker>
<rawString>Mike Lewis and Mark Steedman. 2014a. A* CCG Parsing with a Supertag-factored Model. In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Lewis</author>
<author>Mark Steedman</author>
</authors>
<title>Improved CCG parsing with Semi-supervised Supertagging. Transactions of the Association for Computational Linguistics.</title>
<date>2014</date>
<contexts>
<context position="5620" citStr="Lewis and Steedman, 2014" startWordPosition="863" endWordPosition="867">e 3 shows a detailed trace of how the example from Figure 2 is parsed with our model. We also present a new A* algorithm for the joint model. Because CCG is strongly lexicalized, we are able to introduce a new type of extended lexical entries that allows us to factor the model over words and develop effective new upper bounds on the Viterbi outside parse score. A* parsing algorithms have previously been developed for models with tree-structured syntactic dependencies (Klein and Manning, 2003; Auli and Lopez, 2011b), and models with no bi-lexical dependencies, including supertag-factored CCGs (Lewis and Steedman, 2014a). We generalize these techniques to SRL-style graph-structured dependencies. Experiments demonstrate that our model not only outperforms pipeline semantic role labelling models, but improves the quality of the syntactic parser. PropBank SRL performance is 1.6 points higher than comparable existing work, and semantic features improve syntactic accuracy by 1.6 points. Our A* algorithm is 5 times faster than CKY parsing, with no loss in accuracy. The combination of CCG-based joint modelling and A* decoding gives an efficient, accurate, and linguistically principled parser.1 1The parser is avail</context>
<context position="8020" citStr="Lewis and Steedman (2014" startWordPosition="1230" endWordPosition="1233">ange arguments to be propagated. Figure 3 shows several long-range arguments, such as how co-indexation NPreport {the−→report} &gt; 1445 propagates the subject of deny to he. For more details, see Hockenmaier (2003). Now, we can define a log-linear model over pairs of consistent CCG derivations d and SRL dependencies 7r: 2.2 A* CCG parsing A* parsing searches for an optimal parse, without building a complete chart (in contrast to CKY parsing). This is particularly attractive for CCG, because the formalism’s lexical and derivational ambiguity causes the parse charts to be very dense, in practice. Lewis and Steedman (2014a) showed that A* CCG parsing can be highly efficient, but used a restricted model without bi-lexical features. In A* parsing, entries y are added to the chart in order of their cost f(y) = g(y) + h(y), where g(y) is the inside score for the entry, and h(y) is an upper bound on the Viterbi outside score. Because partial parses are built in order of increasing f(y), the first complete parse added to the chart is guaranteed to be optimal. The key to making A* parsing efficient is computing tight upper bounds on the outside score. In Lewis and Steedman’s supertag-factored model, the bound can be </context>
<context position="11801" citStr="Lewis and Steedman (2014" startWordPosition="1858" endWordPosition="1861">ating both the noun and preposition from prepositional phrases allows the model to use both for features, and improved results. 3.2 Features We use the following feature classes, which decompose over categories, dependencies, and local rule instantiations. 2Bold-face is used to highlight the argument of a category corresponding to a dependency. For example (S\NP)/NP denotes the first (subject) dependency of a transitive verb. eθ·φ(x,d,π) {} &lt; 1446 3.2.1 Supertagging Features Supertagging features φCAT score categories for words. A single feature is used, which is the (unnormalized) score from Lewis and Steedman (2014b)’s supertagging model. The supertagger outputs a distribution over categories for each word independently. The model is trained on supertags extracted from an adaptation of CCGrebank (Honnibal et al., 2010). The adaptation makes minor changes to better match PropBank. 3.2.2 Preposition Features Preposition features φPP score whether the nth argument of the word at index f with category c should take a PP argument headed by preposition p. We use features xf+p, lf+c and lf+c+n+p, where xf is the fth word, and lf is its lemma. 3.2.3 Labelling Features Labelling features φROLE determine whether </context>
<context position="23320" citStr="Lewis and Steedman (2014" startWordPosition="3824" endWordPosition="3827">mantic role less than 3 times in the aligned data, it is pruned from the training and decoding charts. We also filter infrequent features before training. We count the number of times each feature occurs in the aligned data, and filter features occurring less than 3 times. During decoding, we prune lexical categories whose probability under the supertagging model is less than a factor of 10−2 of that of the best category for that word. If the chart size exceeds 20000 nodes, we back off to a pipeline model (roughly 3% of sentences). Finally, we build and use a tag dictionary in the same way as Lewis and Steedman (2014a). Y L(θ) = log i X= i 1449 7 Experiments 7.1 Experimental Setup We used PropBank Section 00 for development, Sections 02-21 for training, and Section 23 for testing. The Pipeline baseline first parses with a supertag-factored A* model, and chooses a semantic role for each CCG dependency with a log-linear classifier. The classifier uses the role and attachment features used by the parser. 7.2 Semantic Role Labelling We evaluate our parser as a dependency-based SRL model on PropBank, comparing with CoNLL-2008 systems (Surdeanu et al., 2008). Comparison systems Following Täckström et al. (2015)</context>
<context position="34205" citStr="Lewis and Steedman (2014" startWordPosition="5570" endWordPosition="5573">s features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al., 2009), but performance is limited by relying on 1-best parses—a problem we resolved with a joint model. A* parsing A* parsing has previously been explored for less general models than ours. Klein and Manning (2003) and Auli and Lopez (2011b) use A* parsing for models with tree-structured dependencies. The best reported speed improvement is parsing 1.2 times faster, whereas we improve by a factor of 5. Our model also allows the more complex graph-structured dependencies required for semantic role labelling. Lewis and Steedman (2014a) demonstrate an efficient A* algorithm for CCG, but cannot model dependencies. 9 Conclusions and Future Work We have shown that using CCG can allow joint models of syntax and semantics to outperform pipelines, and achieve state-of-the-art results on PropBank SRL. Our new A* parsing algorithm is 5 times faster than CKY parsing, without loss of accuracy. Using latent syntax allows us to train the model purely from semantic dependencies, enabling future work to train against other annotations such as FrameNet (Baker et al., 1998), Ontonotes (Hovy et al., 2006) or QASRL (He et al., 2015). The se</context>
</contexts>
<marker>Lewis, Steedman, 2014</marker>
<rawString>Mike Lewis and Mark Steedman. 2014b. Improved CCG parsing with Semi-supervised Supertagging. Transactions of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D C Liu</author>
<author>J Nocedal</author>
</authors>
<title>On the Limited Memory BFGS Method for Large Scale Optimization.</title>
<date>1989</date>
<journal>Math. Program.,</journal>
<volume>45</volume>
<issue>3</issue>
<contexts>
<context position="22499" citStr="Liu and Nocedal, 1989" startWordPosition="3677" endWordPosition="3681">se as latent. 6.1 Hyperparameters Calculating the gradient of the loss function requires computing the marginal probability of the correct parses. Computing marginal probabilities exactly involves summing over all possible CCG parses, which is intractable. Instead, following Clark and Curran, we limit the size of training charts using a variable-width supertagger beam β, initially 10−3. If the chart size exceeds 100000 nodes, we double β and re-parse. For computing A, we use a more restrictive beam of β = 0.01 to improve the quality of the positive training examples. We optimize using L-BFGS (Liu and Nocedal, 1989), with σ2 = 0.06. 6.2 Pruning To improve efficiency, we compute a number of thresholds, by aligning gold CCGbank dependencies with PropBank. If an argument of a category occurs with a particular semantic role less than 3 times in the aligned data, it is pruned from the training and decoding charts. We also filter infrequent features before training. We count the number of times each feature occurs in the aligned data, and filter features occurring less than 3 times. During decoding, we prune lexical categories whose probability under the supertagging model is less than a factor of 10−2 of that</context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>D. C. Liu and J. Nocedal. 1989. On the Limited Memory BFGS Method for Large Scale Optimization. Math. Program., 45(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Lluís</author>
<author>Stefan Bott</author>
<author>Lluís Màrquez</author>
</authors>
<title>A Second-order Joint Eisner Model for Syntactic and Semantic Dependency Parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task.</booktitle>
<contexts>
<context position="1414" citStr="Lluís et al., 2009" startWordPosition="210" endWordPosition="213">agging. Our joint model is the first to substantially improve both syntactic and semantic accuracy over a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model. 1 Introduction Joint models of syntactic and semantic parsing are attractive; they can potentially avoid the error propagation that is inherent in pipelines by using semantic models to inform syntactic attachments. However, in practice, the performance of joint systems for semantic role labelling (SRL) has been substantially beneath that of pipelines (Sutton and McCallum, 2005; Lluís et al., 2009; Johansson, 2009; Titov et al., 2009; Naradowsky et al., 2012; Lluís et al., 2013; Henderson et al., 2013). In this paper, we present the first approach to break this trend, by building on the close relationship of syntax and semantics in CCG grammars to enable both (1) a simple but highly effective joint model and (2) an efficient A* parsing algorithm. Semantic dependencies can span an unbounded number of syntactic dependencies, causing significant inference and sparsity challenges for joint ARG0 Figure 1: Mismatch between syntactic and semantic dependencies. He refused to confirm or deny re</context>
</contexts>
<marker>Lluís, Bott, Màrquez, 2009</marker>
<rawString>Xavier Lluís, Stefan Bott, and Lluís Màrquez. 2009. A Second-order Joint Eisner Model for Syntactic and Semantic Dependency Parsing. In Proceedings of the Thirteenth Conference on Computational Natural Language Learning: Shared Task.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Lluís</author>
<author>Xavier Carreras</author>
<author>Lluís Màrquez</author>
</authors>
<title>Joint Arc-factored Parsing of Syntactic and Semantic Dependencies.</title>
<date>2013</date>
<journal>Transactions of the Association of Computational Linguistics –</journal>
<volume>1</volume>
<pages>219--230</pages>
<contexts>
<context position="1496" citStr="Lluís et al., 2013" startWordPosition="224" endWordPosition="227">emantic accuracy over a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model. 1 Introduction Joint models of syntactic and semantic parsing are attractive; they can potentially avoid the error propagation that is inherent in pipelines by using semantic models to inform syntactic attachments. However, in practice, the performance of joint systems for semantic role labelling (SRL) has been substantially beneath that of pipelines (Sutton and McCallum, 2005; Lluís et al., 2009; Johansson, 2009; Titov et al., 2009; Naradowsky et al., 2012; Lluís et al., 2013; Henderson et al., 2013). In this paper, we present the first approach to break this trend, by building on the close relationship of syntax and semantics in CCG grammars to enable both (1) a simple but highly effective joint model and (2) an efficient A* parsing algorithm. Semantic dependencies can span an unbounded number of syntactic dependencies, causing significant inference and sparsity challenges for joint ARG0 Figure 1: Mismatch between syntactic and semantic dependencies. He refused to confirm or deny reports NP (S\NP)1(S\NP) SIS (S\NP)INP conj (S\NP)INP NP ∅ ARG0 ARG1 ARG0 ARG1 ARG0 </context>
<context position="24823" citStr="Lluís et al. (2013)" startWordPosition="4069" endWordPosition="4072"> predicate identification would be a highly useful feature for the supertagger; we only compare with models that use automatic predicate identification. To the best of our knowledge, the best SRL results with automatic predicate identification were achieved at CoNLL-2008. A number of other models have been evaluated on CoNLL-2008 data. While we cannot compare directly on our metric, the best reported joint model (Johansson, 2009) scored 1.4 points lower than the Che et al. (2008) system we compare to on the CoNLL metric on PropBank. Other joint models, such as those of Titov et al. (2009) and Lluís et al. (2013), achieve similar performance. Evaluation Metric Comparing fairly with existing work is complicated by the mismatch between heads found by our model and those used in other evaluations. Headedness decisions are often arbitrary—for example, whether a prepositional phrase is headed by the noun or preposition—and different choices were made in the design of CCGbank and the CoNLL-2008 headedness rules. To solve this problem, we introduce a new within-constituent metric, which awards depen3The best models use reranking with powerful global features (Toutanova et al., 2008; Johansson and Nugues, 200</context>
<context position="31865" citStr="Lluís et al. (2013)" startWordPosition="5208" endWordPosition="5211">ts the null semantic role ∅. The major cause of these errors is predicates that act syntactically like adjectives (e.g. publishing in Dutch publishing group) where syntactic cues are weak. Finally, 9% involved long-range arguments that our current grammar is unable to project. One common case is constructions like X has a plan to buy Y, where the grammar does not propagate the subject of buy to X. Further improvements to CCGbank may help to resolve these cases. 8 Related Work Joint syntactic and SRL models There have been many proposals for jointly parsing syntactic and semantic dependencies. Lluís et al. (2013) introduce a joint arc-factored model for parsing syntactic and semantic dependencies, using dualdecomposition to maximize agreement between the models. SRL performance is slightly worse than a pipeline version. Naradowsky et al. (2012) introduce a SRL model with latent syntax representations, by modelling a latent dependency tree during training, which is marginalized out at test time. However, performance at English SRL is roughly 7 points beneath state of the art. Other notable models include those of Johansson (2009) and Titov et al. (2009). CCG parsing Our log-linear model is closely rela</context>
</contexts>
<marker>Lluís, Carreras, Màrquez, 2013</marker>
<rawString>Xavier Lluís, Xavier Carreras, and Lluís Màrquez. 2013. Joint Arc-factored Parsing of Syntactic and Semantic Dependencies. Transactions of the Association of Computational Linguistics – Volume 1, pages 219–230.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Naradowsky</author>
<author>Sebastian Riedel</author>
<author>David A Smith</author>
</authors>
<title>Improving NLP Through Marginalization of Hidden Syntactic Structure.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="1476" citStr="Naradowsky et al., 2012" startWordPosition="220" endWordPosition="223">rove both syntactic and semantic accuracy over a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model. 1 Introduction Joint models of syntactic and semantic parsing are attractive; they can potentially avoid the error propagation that is inherent in pipelines by using semantic models to inform syntactic attachments. However, in practice, the performance of joint systems for semantic role labelling (SRL) has been substantially beneath that of pipelines (Sutton and McCallum, 2005; Lluís et al., 2009; Johansson, 2009; Titov et al., 2009; Naradowsky et al., 2012; Lluís et al., 2013; Henderson et al., 2013). In this paper, we present the first approach to break this trend, by building on the close relationship of syntax and semantics in CCG grammars to enable both (1) a simple but highly effective joint model and (2) an efficient A* parsing algorithm. Semantic dependencies can span an unbounded number of syntactic dependencies, causing significant inference and sparsity challenges for joint ARG0 Figure 1: Mismatch between syntactic and semantic dependencies. He refused to confirm or deny reports NP (S\NP)1(S\NP) SIS (S\NP)INP conj (S\NP)INP NP ∅ ARG0 </context>
<context position="32101" citStr="Naradowsky et al. (2012)" startWordPosition="5241" endWordPosition="5244">that our current grammar is unable to project. One common case is constructions like X has a plan to buy Y, where the grammar does not propagate the subject of buy to X. Further improvements to CCGbank may help to resolve these cases. 8 Related Work Joint syntactic and SRL models There have been many proposals for jointly parsing syntactic and semantic dependencies. Lluís et al. (2013) introduce a joint arc-factored model for parsing syntactic and semantic dependencies, using dualdecomposition to maximize agreement between the models. SRL performance is slightly worse than a pipeline version. Naradowsky et al. (2012) introduce a SRL model with latent syntax representations, by modelling a latent dependency tree during training, which is marginalized out at test time. However, performance at English SRL is roughly 7 points beneath state of the art. Other notable models include those of Johansson (2009) and Titov et al. (2009). CCG parsing Our log-linear model is closely related to that of Clark and Curran (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and de</context>
</contexts>
<marker>Naradowsky, Riedel, Smith, 2012</marker>
<rawString>Jason Naradowsky, Sebastian Riedel, and David A. Smith. 2012. Improving NLP Through Marginalization of Hidden Syntactic Structure. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wen-tau Yih</author>
</authors>
<date>2008</date>
<booktitle>The Importance of Syntactic Parsing and Inference in Semantic Role Labeling. Computational Linguistics,</booktitle>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="25494" citStr="Punyakanok et al., 2008" startWordPosition="4172" endWordPosition="4175">c Comparing fairly with existing work is complicated by the mismatch between heads found by our model and those used in other evaluations. Headedness decisions are often arbitrary—for example, whether a prepositional phrase is headed by the noun or preposition—and different choices were made in the design of CCGbank and the CoNLL-2008 headedness rules. To solve this problem, we introduce a new within-constituent metric, which awards depen3The best models use reranking with powerful global features (Toutanova et al., 2008; Johansson and Nugues, 2008) or ensemble methods (Surdeanu et al., 2007; Punyakanok et al., 2008). These techniques have the potential to improve any SRL system, including ours, at some expense in speed. PropBank Brown Model P R F1 P R F1 Vickrey 87.3 77.3 82.0 74.0 64.5 68.9 Che 85.3 78.6 81.8 71.1 65.7 68.0 Zhao 82.4 79.8 81.1 66.6 64.9 65.7 Riedel 83.6 74.7 78.9 69.3 62.7 65.8 Pipeline 79.2 73.9 76.4 69.3 64.0 66.1 Joint 84.8 82.2 83.5 71.2 69.2 70.2 Table 1: Comparison with the best single-parser SRL models on PropBank from CoNLL-2008. The comparison models are Vickrey and Koller (2008), Che et al. (2008), Zhao and Kit (2008) and Riedel and Meza-Ruiz (2008). dencies as correct if they</context>
</contexts>
<marker>Punyakanok, Roth, Yih, 2008</marker>
<rawString>Vasin Punyakanok, Dan Roth, and Wen-tau Yih. 2008. The Importance of Syntactic Parsing and Inference in Semantic Role Labeling. Computational Linguistics, 34(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Ivan Meza-Ruiz</author>
</authors>
<title>Collective Semantic Role Labelling with Markov Logic.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="26066" citStr="Riedel and Meza-Ruiz (2008)" startWordPosition="4274" endWordPosition="4277">ethods (Surdeanu et al., 2007; Punyakanok et al., 2008). These techniques have the potential to improve any SRL system, including ours, at some expense in speed. PropBank Brown Model P R F1 P R F1 Vickrey 87.3 77.3 82.0 74.0 64.5 68.9 Che 85.3 78.6 81.8 71.1 65.7 68.0 Zhao 82.4 79.8 81.1 66.6 64.9 65.7 Riedel 83.6 74.7 78.9 69.3 62.7 65.8 Pipeline 79.2 73.9 76.4 69.3 64.0 66.1 Joint 84.8 82.2 83.5 71.2 69.2 70.2 Table 1: Comparison with the best single-parser SRL models on PropBank from CoNLL-2008. The comparison models are Vickrey and Koller (2008), Che et al. (2008), Zhao and Kit (2008) and Riedel and Meza-Ruiz (2008). dencies as correct if they attach anywhere within the original PropBank-annotated argument spans. For example, if the PropBank annotates that the ARGO of owned is by Google, a dependency to either by or Google is judged correct. We compute new scores for the CoNLL-2008 submissions on our metric, filtering reference and continuation arguments (which are artifacts of the CoNLL conversion of PropBank, but not required by our metric), and nominal predicates based on POS tag. The ranking of the top 5 CoNLL-2008 open-track models is identical under our metric and the original one (up to statistica</context>
</contexts>
<marker>Riedel, Meza-Ruiz, 2008</marker>
<rawString>Sebastian Riedel and Ivan Meza-Ruiz. 2008. Collective Semantic Role Labelling with Markov Logic. In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Lluís Màrquez</author>
<author>Xavier Carreras</author>
<author>Pere R Comas</author>
</authors>
<title>Combination Strategies for Semantic Role Labeling.</title>
<date>2007</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="25468" citStr="Surdeanu et al., 2007" startWordPosition="4168" endWordPosition="4171">mance. Evaluation Metric Comparing fairly with existing work is complicated by the mismatch between heads found by our model and those used in other evaluations. Headedness decisions are often arbitrary—for example, whether a prepositional phrase is headed by the noun or preposition—and different choices were made in the design of CCGbank and the CoNLL-2008 headedness rules. To solve this problem, we introduce a new within-constituent metric, which awards depen3The best models use reranking with powerful global features (Toutanova et al., 2008; Johansson and Nugues, 2008) or ensemble methods (Surdeanu et al., 2007; Punyakanok et al., 2008). These techniques have the potential to improve any SRL system, including ours, at some expense in speed. PropBank Brown Model P R F1 P R F1 Vickrey 87.3 77.3 82.0 74.0 64.5 68.9 Che 85.3 78.6 81.8 71.1 65.7 68.0 Zhao 82.4 79.8 81.1 66.6 64.9 65.7 Riedel 83.6 74.7 78.9 69.3 62.7 65.8 Pipeline 79.2 73.9 76.4 69.3 64.0 66.1 Joint 84.8 82.2 83.5 71.2 69.2 70.2 Table 1: Comparison with the best single-parser SRL models on PropBank from CoNLL-2008. The comparison models are Vickrey and Koller (2008), Che et al. (2008), Zhao and Kit (2008) and Riedel and Meza-Ruiz (2008). </context>
</contexts>
<marker>Surdeanu, Màrquez, Carreras, Comas, 2007</marker>
<rawString>Mihai Surdeanu, Lluís Màrquez, Xavier Carreras, and Pere R. Comas. 2007. Combination Strategies for Semantic Role Labeling. Journal of Artificial Intelligence Research, 29(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Richard Johansson</author>
<author>Adam Meyers</author>
<author>Lluís Màrquez</author>
<author>Joakim Nivre</author>
</authors>
<date>2008</date>
<booktitle>The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="23866" citStr="Surdeanu et al., 2008" startWordPosition="3913" endWordPosition="3916">e build and use a tag dictionary in the same way as Lewis and Steedman (2014a). Y L(θ) = log i X= i 1449 7 Experiments 7.1 Experimental Setup We used PropBank Section 00 for development, Sections 02-21 for training, and Section 23 for testing. The Pipeline baseline first parses with a supertag-factored A* model, and chooses a semantic role for each CCG dependency with a log-linear classifier. The classifier uses the role and attachment features used by the parser. 7.2 Semantic Role Labelling We evaluate our parser as a dependency-based SRL model on PropBank, comparing with CoNLL-2008 systems (Surdeanu et al., 2008). Comparison systems Following Täckström et al. (2015), we compare with the best ‘single parser’ SRL models, which use only a single syntactic parse.3 Much recent work has evaluated using gold predicate identification (Hajiˇc et al., 2009; FitzGerald et al., 2015). This setting is particularly unrealistic for our joint model, where gold predicate identification would be a highly useful feature for the supertagger; we only compare with models that use automatic predicate identification. To the best of our knowledge, the best SRL results with automatic predicate identification were achieved at C</context>
</contexts>
<marker>Surdeanu, Johansson, Meyers, Màrquez, Nivre, 2008</marker>
<rawString>Mihai Surdeanu, Richard Johansson, Adam Meyers, Lluís Màrquez, and Joakim Nivre. 2008. The CoNLL-2008 Shared Task on Joint Parsing of Syntactic and Semantic Dependencies. In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Joint Parsing and Semantic Role Labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="1394" citStr="Sutton and McCallum, 2005" startWordPosition="206" endWordPosition="209">curate than adaptive supertagging. Our joint model is the first to substantially improve both syntactic and semantic accuracy over a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model. 1 Introduction Joint models of syntactic and semantic parsing are attractive; they can potentially avoid the error propagation that is inherent in pipelines by using semantic models to inform syntactic attachments. However, in practice, the performance of joint systems for semantic role labelling (SRL) has been substantially beneath that of pipelines (Sutton and McCallum, 2005; Lluís et al., 2009; Johansson, 2009; Titov et al., 2009; Naradowsky et al., 2012; Lluís et al., 2013; Henderson et al., 2013). In this paper, we present the first approach to break this trend, by building on the close relationship of syntax and semantics in CCG grammars to enable both (1) a simple but highly effective joint model and (2) an efficient A* parsing algorithm. Semantic dependencies can span an unbounded number of syntactic dependencies, causing significant inference and sparsity challenges for joint ARG0 Figure 1: Mismatch between syntactic and semantic dependencies. He refused t</context>
</contexts>
<marker>Sutton, McCallum, 2005</marker>
<rawString>Charles Sutton and Andrew McCallum. 2005. Joint Parsing and Semantic Role Labeling. In Proceedings of the Ninth Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar Täckström</author>
<author>Kuzman Ganchev</author>
<author>Dipanjan Das</author>
</authors>
<title>Efficient Inference and Structured Learning for Semantic Role Labeling.</title>
<date>2015</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>3--29</pages>
<contexts>
<context position="23920" citStr="Täckström et al. (2015)" startWordPosition="3920" endWordPosition="3923">ewis and Steedman (2014a). Y L(θ) = log i X= i 1449 7 Experiments 7.1 Experimental Setup We used PropBank Section 00 for development, Sections 02-21 for training, and Section 23 for testing. The Pipeline baseline first parses with a supertag-factored A* model, and chooses a semantic role for each CCG dependency with a log-linear classifier. The classifier uses the role and attachment features used by the parser. 7.2 Semantic Role Labelling We evaluate our parser as a dependency-based SRL model on PropBank, comparing with CoNLL-2008 systems (Surdeanu et al., 2008). Comparison systems Following Täckström et al. (2015), we compare with the best ‘single parser’ SRL models, which use only a single syntactic parse.3 Much recent work has evaluated using gold predicate identification (Hajiˇc et al., 2009; FitzGerald et al., 2015). This setting is particularly unrealistic for our joint model, where gold predicate identification would be a highly useful feature for the supertagger; we only compare with models that use automatic predicate identification. To the best of our knowledge, the best SRL results with automatic predicate identification were achieved at CoNLL-2008. A number of other models have been evaluate</context>
</contexts>
<marker>Täckström, Ganchev, Das, 2015</marker>
<rawString>Oscar Täckström, Kuzman Ganchev, and Dipanjan Das. 2015. Efficient Inference and Structured Learning for Semantic Role Labeling. Transactions of the Association for Computational Linguistics, 3:29–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>James Henderson</author>
<author>Paola Merlo</author>
<author>Gabriele Musillo</author>
</authors>
<title>Online Projectivisation for Synchronous Parsing of Semantic and Syntactic Dependencies. In</title>
<date>2009</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="1451" citStr="Titov et al., 2009" startWordPosition="216" endWordPosition="219">to substantially improve both syntactic and semantic accuracy over a comparable pipeline, and also achieves state-of-the-art results for a nonensemble semantic role labelling model. 1 Introduction Joint models of syntactic and semantic parsing are attractive; they can potentially avoid the error propagation that is inherent in pipelines by using semantic models to inform syntactic attachments. However, in practice, the performance of joint systems for semantic role labelling (SRL) has been substantially beneath that of pipelines (Sutton and McCallum, 2005; Lluís et al., 2009; Johansson, 2009; Titov et al., 2009; Naradowsky et al., 2012; Lluís et al., 2013; Henderson et al., 2013). In this paper, we present the first approach to break this trend, by building on the close relationship of syntax and semantics in CCG grammars to enable both (1) a simple but highly effective joint model and (2) an efficient A* parsing algorithm. Semantic dependencies can span an unbounded number of syntactic dependencies, causing significant inference and sparsity challenges for joint ARG0 Figure 1: Mismatch between syntactic and semantic dependencies. He refused to confirm or deny reports NP (S\NP)1(S\NP) SIS (S\NP)INP </context>
<context position="24799" citStr="Titov et al. (2009)" startWordPosition="4064" endWordPosition="4067"> joint model, where gold predicate identification would be a highly useful feature for the supertagger; we only compare with models that use automatic predicate identification. To the best of our knowledge, the best SRL results with automatic predicate identification were achieved at CoNLL-2008. A number of other models have been evaluated on CoNLL-2008 data. While we cannot compare directly on our metric, the best reported joint model (Johansson, 2009) scored 1.4 points lower than the Che et al. (2008) system we compare to on the CoNLL metric on PropBank. Other joint models, such as those of Titov et al. (2009) and Lluís et al. (2013), achieve similar performance. Evaluation Metric Comparing fairly with existing work is complicated by the mismatch between heads found by our model and those used in other evaluations. Headedness decisions are often arbitrary—for example, whether a prepositional phrase is headed by the noun or preposition—and different choices were made in the design of CCGbank and the CoNLL-2008 headedness rules. To solve this problem, we introduce a new within-constituent metric, which awards depen3The best models use reranking with powerful global features (Toutanova et al., 2008; J</context>
<context position="32415" citStr="Titov et al. (2009)" startWordPosition="5292" endWordPosition="5295">ntly parsing syntactic and semantic dependencies. Lluís et al. (2013) introduce a joint arc-factored model for parsing syntactic and semantic dependencies, using dualdecomposition to maximize agreement between the models. SRL performance is slightly worse than a pipeline version. Naradowsky et al. (2012) introduce a SRL model with latent syntax representations, by modelling a latent dependency tree during training, which is marginalized out at test time. However, performance at English SRL is roughly 7 points beneath state of the art. Other notable models include those of Johansson (2009) and Titov et al. (2009). CCG parsing Our log-linear model is closely related to that of Clark and Curran (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representa</context>
</contexts>
<marker>Titov, Henderson, Merlo, Musillo, 2009</marker>
<rawString>Ivan Titov, James Henderson, Paola Merlo, and Gabriele Musillo. 2009. Online Projectivisation for Synchronous Parsing of Semantic and Syntactic Dependencies. In In Proceedings of the International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Aria Haghighi</author>
<author>Christopher D Manning</author>
</authors>
<title>A Global Joint Model for Semantic Role Labeling.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>2</issue>
<contexts>
<context position="25396" citStr="Toutanova et al., 2008" startWordPosition="4156" endWordPosition="4159">se of Titov et al. (2009) and Lluís et al. (2013), achieve similar performance. Evaluation Metric Comparing fairly with existing work is complicated by the mismatch between heads found by our model and those used in other evaluations. Headedness decisions are often arbitrary—for example, whether a prepositional phrase is headed by the noun or preposition—and different choices were made in the design of CCGbank and the CoNLL-2008 headedness rules. To solve this problem, we introduce a new within-constituent metric, which awards depen3The best models use reranking with powerful global features (Toutanova et al., 2008; Johansson and Nugues, 2008) or ensemble methods (Surdeanu et al., 2007; Punyakanok et al., 2008). These techniques have the potential to improve any SRL system, including ours, at some expense in speed. PropBank Brown Model P R F1 P R F1 Vickrey 87.3 77.3 82.0 74.0 64.5 68.9 Che 85.3 78.6 81.8 71.1 65.7 68.0 Zhao 82.4 79.8 81.1 66.6 64.9 65.7 Riedel 83.6 74.7 78.9 69.3 62.7 65.8 Pipeline 79.2 73.9 76.4 69.3 64.0 66.1 Joint 84.8 82.2 83.5 71.2 69.2 70.2 Table 1: Comparison with the best single-parser SRL models on PropBank from CoNLL-2008. The comparison models are Vickrey and Koller (2008), </context>
</contexts>
<marker>Toutanova, Haghighi, Manning, 2008</marker>
<rawString>Kristina Toutanova, Aria Haghighi, and Christopher D. Manning. 2008. A Global Joint Model for Semantic Role Labeling. Computational Linguistics, 34(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vickrey</author>
<author>Daphne Koller</author>
</authors>
<title>Applying Sentence Simplification to the CoNLL-2008 Shared Task.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="25994" citStr="Vickrey and Koller (2008)" startWordPosition="4261" endWordPosition="4264">res (Toutanova et al., 2008; Johansson and Nugues, 2008) or ensemble methods (Surdeanu et al., 2007; Punyakanok et al., 2008). These techniques have the potential to improve any SRL system, including ours, at some expense in speed. PropBank Brown Model P R F1 P R F1 Vickrey 87.3 77.3 82.0 74.0 64.5 68.9 Che 85.3 78.6 81.8 71.1 65.7 68.0 Zhao 82.4 79.8 81.1 66.6 64.9 65.7 Riedel 83.6 74.7 78.9 69.3 62.7 65.8 Pipeline 79.2 73.9 76.4 69.3 64.0 66.1 Joint 84.8 82.2 83.5 71.2 69.2 70.2 Table 1: Comparison with the best single-parser SRL models on PropBank from CoNLL-2008. The comparison models are Vickrey and Koller (2008), Che et al. (2008), Zhao and Kit (2008) and Riedel and Meza-Ruiz (2008). dencies as correct if they attach anywhere within the original PropBank-annotated argument spans. For example, if the PropBank annotates that the ARGO of owned is by Google, a dependency to either by or Google is judged correct. We compute new scores for the CoNLL-2008 submissions on our metric, filtering reference and continuation arguments (which are artifacts of the CoNLL conversion of PropBank, but not required by our metric), and nominal predicates based on POS tag. The ranking of the top 5 CoNLL-2008 open-track mod</context>
</contexts>
<marker>Vickrey, Koller, 2008</marker>
<rawString>David Vickrey and Daphne Koller. 2008. Applying Sentence Simplification to the CoNLL-2008 Shared Task. In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luke Zettlemoyer</author>
<author>Michael Collins</author>
</authors>
<title>Learning Context-dependent Mappings from Sentences to Logical Form.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP:</booktitle>
<volume>2</volume>
<contexts>
<context position="33068" citStr="Zettlemoyer and Collins, 2009" startWordPosition="5393" endWordPosition="5396">near model is closely related to that of Clark and Curran (2007), but we model SRL dependencies instead of CCG dependencies. The best CCG parsing results were achieved by Auli and Lopez (2011a), who, like us, score CCG parses based jointly on supertagging and dependency model scores. Decoding their model requires dual-decomposition, to maximize agreement between the separate models. We avoid the need for this technique by using a unigram supertagging model, rather than a sequence model. CCG semantics Work on semantic parsing has mapped sentences onto semantic representations with latent CCGs (Zettlemoyer and Collins, 2009; Kwiatkowski et al., 2010; Kwiatkowski et al., 2013) for restricted domains. Recent work has scaled these techniques to wide-coverage datasets (Artzi et al., 2015). Krishnamurthy and Mitchell (2014) also explore joint CCG syntactic and semantic parsing. They use a smaller semantic lexicon, containing 130 predicates, rather than the 3257 PropBank verbs. In contrast to our results, jointly modelling the semantics lowers their model’s syntactic accuracy. Other CCG-based SRL models haved used CCG dependencies as features for predicting semantic roles (Gildea and Hockenmaier, 2003; Boxwell et al.,</context>
</contexts>
<marker>Zettlemoyer, Collins, 2009</marker>
<rawString>Luke Zettlemoyer and Michael Collins. 2009. Learning Context-dependent Mappings from Sentences to Logical Form. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Chunyu Kit</author>
</authors>
<title>Parsing Syntactic and Semantic Dependencies with Two Single-stage Maximum Entropy Models.</title>
<date>2008</date>
<booktitle>In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="26034" citStr="Zhao and Kit (2008)" startWordPosition="4269" endWordPosition="4272">ues, 2008) or ensemble methods (Surdeanu et al., 2007; Punyakanok et al., 2008). These techniques have the potential to improve any SRL system, including ours, at some expense in speed. PropBank Brown Model P R F1 P R F1 Vickrey 87.3 77.3 82.0 74.0 64.5 68.9 Che 85.3 78.6 81.8 71.1 65.7 68.0 Zhao 82.4 79.8 81.1 66.6 64.9 65.7 Riedel 83.6 74.7 78.9 69.3 62.7 65.8 Pipeline 79.2 73.9 76.4 69.3 64.0 66.1 Joint 84.8 82.2 83.5 71.2 69.2 70.2 Table 1: Comparison with the best single-parser SRL models on PropBank from CoNLL-2008. The comparison models are Vickrey and Koller (2008), Che et al. (2008), Zhao and Kit (2008) and Riedel and Meza-Ruiz (2008). dencies as correct if they attach anywhere within the original PropBank-annotated argument spans. For example, if the PropBank annotates that the ARGO of owned is by Google, a dependency to either by or Google is judged correct. We compute new scores for the CoNLL-2008 submissions on our metric, filtering reference and continuation arguments (which are artifacts of the CoNLL conversion of PropBank, but not required by our metric), and nominal predicates based on POS tag. The ranking of the top 5 CoNLL-2008 open-track models is identical under our metric and th</context>
</contexts>
<marker>Zhao, Kit, 2008</marker>
<rawString>Hai Zhao and Chunyu Kit. 2008. Parsing Syntactic and Semantic Dependencies with Two Single-stage Maximum Entropy Models. In Proceedings of the Twelfth Conference on Computational Natural Language Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>