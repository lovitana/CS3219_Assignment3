<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.015002">
<title confidence="0.87083">
Recognizing Biographical Sections in Wikipedia
</title>
<note confidence="0.54817025">
Alessio Palmero Aprosio
Fondazione Bruno Kessler
Via Sommarive, 18
38123 Trento, Italy
</note>
<email confidence="0.981361">
aprosio@fbk.eu
</email>
<sectionHeader confidence="0.993474" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999697">
Wikipedia is the largest collection of ency-
clopedic data ever written in the history of
humanity. Thanks to its coverage and its
availability in machine-readable format, it
has become a primary resource for large-
scale research in historical and cultural
studies. In this work, we focus on the
subset of pages describing persons, and
we investigate the task of recognizing bi-
ographical sections from them: given a
person’s page, we identify the list of sec-
tions where information about her/his life
is present. We model this as a sequence
classification problem, and propose a su-
pervised setting, in which the training data
are acquired automatically. Besides, we
show that six simple features extracted
only from the section titles are very infor-
mative and yield good results well above a
strong baseline.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999922166666667">
In the last years, several projects have started
to address the mechanisms behind cultural de-
velopment, borrowing techniques and algorithms
from computer science and natural language pro-
cessing to serve historical investigation. Efforts
such as BiographyNet1, Pantheon2 or the Aus-
trian Prosopographical Information System3 prove
an increasing interest in automatically extracting
biographical descriptions from large amounts of
data and combining them in a more general pic-
ture, taking advantage of the availability of such
descriptions on the web. Wikipedia has been
</bodyText>
<footnote confidence="0.979150833333333">
1http://www.biographynet.nl
2http://pantheon.media.mit.edu/
treemap/country_exports/IQ/all/-4000/
2010/H15/pantheon
3http://www.oeaw.ac.at/acdh/de/node/
188
</footnote>
<note confidence="0.97769525">
Sara Tonelli
Fondazione Bruno Kessler
Via Sommarive, 18
38123 Trento, Italy
</note>
<email confidence="0.914501">
satonelli@fbk.eu
</email>
<bodyText confidence="0.999341536585366">
the main source of information for research in
this direction despite its many biases, for in-
stance its well-known English, Western and gen-
der bias (Wikipedia Contributors, 2014). In fact,
Wikipedia coverage both in terms of pages and in
terms of languages, as well as the structured in-
formation that can be leveraged through DBpedia,
has made it the primary resource for large-scale
analyses on biographies. However, the lack of a
consistent template for describing persons’ lives
led to the creation of a plethora of page types,
where biographical information is displayed in di-
verse ways.
Based on a random sample of 100 persons’
pages, we noticed that only 20% of them includes
a section called Biography or Life, typically con-
taining a set of subsections describing the main
periods in a person’s life from birth to death (see
for instance https://en.wikipedia.org/
wiki/Leonard_Bernstein). The other
pages in our sample do not follow a pre-defined
pattern and present the person’s biography in
one or several sections at the same level of the
other ones (see for instance https://en.
wikipedia.org/wiki/Judy_Holliday,
with the Filmography and Discography sections
at the same level of Early Life and Career).
Given this high variability, it is very difficult to
extract all and only those sections that describe a
biography, and that build all together in sequence
the description of a person’s life. This depends
also on the different types of non-biographical
sections available, which in the case of promi-
nent persons typically include main themes,
reception, style, influences, legacy, work titles,
etc. (see for instance Will to power, Eternal
return, Perspectivism, Critique on mass culture
in https://en.wikipedia.org/wiki/
Friedrich_Nietzsche).
In this work, we present a simple methodology
that, given a person’s page in Wikipedia, recog-
</bodyText>
<page confidence="0.972811">
811
</page>
<note confidence="0.6579645">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 811–816,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.999680352941177">
nizes all sections that deal with his/her life even if
no Biography section is present. The problem is
modeled as a classification task using Conditional
Random Fields, which are particularly suitable for
our study because the biographical sections tend
to follow a chronological order and present typical
sequential patterns (for instance, the section Early
Life is often followed by Early Career). While
a simple token-based baseline is very difficult to
beat when the task is performed at section level
(i.e. deciding whether a section is biographical or
not), our method performs best when the evalu-
ation is performed at page level, recognizing all
sections that describe a person’s life. This is cru-
cial if the task under investigation is meant as a
preliminary step towards the automatic extraction
of all events that compose a person’s biography.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999994653846154">
To our knowledge, this is the first attempt to ex-
tract biographical sections from Wikipedia. Other
past works focused on the recognition of biograph-
ical sentences (Biadsy et al., 2008; Zhou et al.,
2004; Biryukov et al., 2005). However the two
tasks have different goals: in our case, we aim
at extracting all biographical sections, so that all
events of a person’s life from birth to death are
present. The other approach, instead, is used to
generate biography summaries, which was a task
of the DUC2004 evaluation exercise4. Besides,
while approaches for sentence selection look for
textual features such as typical unigrams or bi-
grams that characterize biographical descriptions
(Filatova and Prager, 2005), we adopt a much sim-
pler approach by considering only section titles.
Other works focused on the analysis of typical
events in selected articles from Wikipedia biogra-
phies by looking for a particular list of predefined
events (Bamman and Smith, 2014). Our approach
may complement such works by introducing a pre-
processing step that extracts all and only the sec-
tions describing the biographies, upon which event
extraction experiments can be performed. This
would increase both the precision and the recall
of the extracted information.
</bodyText>
<sectionHeader confidence="0.997927" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.99956">
In this section we detail the data used for our ex-
periments and the classification task.
</bodyText>
<footnote confidence="0.927665">
4http://duc.nist.gov/duc2004/
</footnote>
<subsectionHeader confidence="0.999311">
3.1 Data set
</subsectionHeader>
<bodyText confidence="0.999971510638298">
Since our goal is to distinguish between biograph-
ical and non biographical sections, we focus only
on Wikipedia pages describing persons. We de-
rive our development, training and test data from
the Pantheon data set (Yu et al., 2015), freely
available for download.5 The data set includes a
list of 11,340 notable individuals with the link to
their Wikipedia page in multiple languages, plus
a number of additional information such as date
and place of birth, category and language editions,
which we do not consider for our study. Only the
persons whose Wikipedia page is translated in at
least 25 languages are included in Pantheon, as a
proxy of prominent world personalities.
For each person in the list, we download the
corresponding Wikipedia page in English and pre-
process it using TheWikiMachine library6. Over-
all, we collect 11,075 pages, while 265 pages
could not be retrieved because of problems with
the links (mainly redirection links). We randomly
select 100 pages as development set, 500 pages
for test and the remaining 10,475 for building the
training set.
For each page in the development and test set,
we ask an annotator to assign a yes/no label to
each section, to mark if it describes part of the
person’s life or not. We involve also a second
annotator to label manually the development set
(100 pages containing 834 sections). We compute
Cohen’s Kappa, which corresponds to 0.88. As
a rule of thumb, this is considered an almost per-
fect agreement, which shows the clear-cut differ-
ence between biographical and non-biographical
sections. The annotators use the Wikipedia origi-
nal page to decide whether a section is biograph-
ical or not, therefore they can see both title and
content of sections.
For the training set, we devise a novel method-
ology to acquire it completely automatically. We
first extract from our collection of 10,475 pages
the subset of pages containing a section called Life
or Biography, which amount to 2,547. We con-
sider such pages as a gold standard, since the pres-
ence of Life or Biography shows that their editors
paid attention to the structure of the page, distin-
guishing between what belonged to the person’s
biography and what not. Therefore, all subsec-
</bodyText>
<footnote confidence="0.999649333333333">
5http://thedata.harvard.edu/dvn/dv/
pantheon
6https://bitbucket.org/fbk/twm-lib
</footnote>
<page confidence="0.991577">
812
</page>
<figure confidence="0.8644885">
}
}
</figure>
<figureCaption confidence="0.8400312">
Figure 1: Extraction of training instances,
from the Wikipedia page of Antoine Lavoisier
(https://en.wikipedia.org/wiki/Antoine_
Lavoisier). Sections are annotated in IOB2
format.
</figureCaption>
<bodyText confidence="0.999240571428571">
tions of Life or Biography are included as positive
examples in the training set, because we assume
that they all have biographical content. Instead,
the remaining sections in the same pages repre-
sent our negative examples (see Figure 1). For the
negative cases, we do not consider subsections be-
cause this level of detail is not needed for the clas-
sification, i.e. non-biographical sections contain
only non-biographical subsections, and the clas-
sification of the first level is enough to propagate
the corresponding label to the lower levels. Over-
all, the training set includes 2,547 sequences of
sections (22,499 sections in total: 6,861 positive,
15,638 negative).
</bodyText>
<subsectionHeader confidence="0.998042">
3.2 Classification experiment
</subsectionHeader>
<bodyText confidence="0.999896571428571">
We cast the problem as a supervised learning clas-
sification task, with the goal to label sequences of
Wikipedia sections as describing a person’s biog-
raphy or not. As discussed in the introduction,
we use Conditional Random Fields, since they are
particularly suitable for sequence labelling (Laf-
ferty et al., 2001). We use the implementation
provided by CRFsuite7 (Okazaki, 2007) for both
training and classification tasks. The algorithm pa-
rameters are tuned on the development set.
In order to compare our approach with a non-
sequential one, we perform the classification task
also using Support Vector Machines (Vapnik,
1998). We use YAMCHA8, a tool developed for
</bodyText>
<footnote confidence="0.996071">
7http://www.chokkan.org/software/
crfsuite/
8http://chasen.org/˜taku/software/
yamcha/
</footnote>
<bodyText confidence="0.999629107142857">
chunking tasks, in which SVMs are easily com-
bined with different context window sizes and dy-
namic features (Kudo and Matsumoto, 2001).
Since this work is only a preliminary step
towards the automatic identification and extrac-
tion of biographical information from Wikipedia,
we first experiment with the simplest approach.
Therefore, we consider a small set of shallow fea-
tures extracted only from section titles, and we ig-
nore the content of the sections. Our six features
are: the whole title, the tokens (lowercased), the
bigrams, the first token of the section title, the first
bigram, the position of the section with respect to
the other sections in the same page (first, last, in-
side). We also use a sliding window of size 1 (both
with CRF and SVM), so that the features extracted
from the previous and the next sections are also
considered to classify the current one. We exper-
imented with window sizes &gt; 1 on the develop-
ment set, but they led to worse results.
Other features we implemented include the last
word of the section, and a binary feature indicat-
ing whether the section title contains a year which
is included between the date of birth and date of
death of the person of interest. However, both
pieces of information led to a performance drop on
the development set, so we did not include them in
the final feature set.
</bodyText>
<subsectionHeader confidence="0.981548">
3.3 Baseline
</subsectionHeader>
<bodyText confidence="0.9998967">
To assess the performance of our system, we com-
pare it with a baseline approach considering only
the most frequent words in section titles. As
shown in the evaluation (Section 4), this is in-
deed a very strong baseline. We identify the four
most frequent tokens included in section titles, i.e.
“Biography”, “Life”, “Death” and “Career”, and
we extract all sections that contain at least one
of them (ignoring upper/lowercase). Finally, we
consider as a positive example the smallest se-
quence of consecutive sections containing all of
them. For instance, giving the sequence “Early
life”, “Career”, “Presidency”, “Death”, “Legacy”,
“Awards”, and “References”, the first four sections
are selected by the baseline as biographical sec-
tions: even if the “Presidency” word is not in-
cluded in the tokens set, it is added as a conse-
quence of its inclusion between “Early life” and
“Death”, both containing a token from the most
frequent set.
</bodyText>
<figure confidence="0.99719415">
Biographical
information
Non biographical
information
Training set
B-SEC Early life and education
I-SEC Early scientific work
I-SEC Ferme générale and marriage
I-SEC Oxygen theory of combustion
I-SEC Gunpowder Commission
I-SEC Pioneer of stoichiometry
I-SEC Chemical nomenclature
I-SEC Elementary Treatise of Chemistry
I-SEC Physiological work
I-SEC Final days and execution
Legacy
Selected writings
Notes
Further reading
External links
</figure>
<page confidence="0.997312">
813
</page>
<sectionHeader confidence="0.998069" genericHeader="method">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999458">
We evaluate our system based on two different
metrics, accounting for both exact and partial
matches.
</bodyText>
<listItem confidence="0.992552571428571">
• In the Exact setting, a true positive is scored
when all and only those sections with bio-
graphical information in a Wikipedia page
are extracted. This measure is useful to un-
derstand how often it is possible to extract
the complete and exact biographical text con-
cerning a person.
</listItem>
<table confidence="0.9995592">
P R F1
CRFsuite
Exact 0.694 0.662 0.677
Intersection 0.933 0.863 0.897
Yamcha SVM
Exact 0.605 0.630 0.617
Intersection 0.857 0.942 0.898
Baseline
Exact 0.584 0.548 0.566
Intersection 0.882 0.809 0.844
</table>
<tableCaption confidence="0.96464">
Table 1: Classification results using the Exact and
Intersection settings
</tableCaption>
<bodyText confidence="0.985877861111111">
• The Intersection measure, instead, assigns a
score between 0 and 1 for every predicted
sequence of sections based on how much it
overlaps with the gold standard sequence (Jo-
hansson and Moschitti, 2013).
Evaluation results are reported in Table 1. The
CRF-based approach outperforms the baseline in
both configurations, with the highest improve-
ment in the exact setting (+0.111 F1). Compared
with the classification performance obtained with
SVMs, CRFs yield better results only in the exact
setting, while the intersection-based performance
does not show substantial differences. In general,
CRFs achieves a better precision but a lower re-
call than SVMs. If we look at the average length
(in sections) of the false positive sequences, it is
3.72 for SVMs and 2.71 for CRFs. This differ-
ence confirms the behaviour of the SVM-based ap-
proach, which tends to overestimate the amount of
biographical sections that should be tagged in se-
quence.
The results in Table 1 show also that a sim-
ple baseline relying on the four most frequent to-
kens in section titles achieves surprisingly good re-
sults, especially with the intersection-based met-
rics. This means that this basic approach tends
to recognize correctly at least some of the sec-
tions describing a person’s biography, because
they present some recurrent patterns in their ti-
tles. In general, we observe that section titles alone
are good indicators of their content, also with-
out the need of more complex features. Although
Wikipedia editors are free to name the sections and
decide how to arrange them, there are some pat-
terns that can be easily recognized automatically,
especially by means of CRF.
</bodyText>
<sectionHeader confidence="0.998896" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.9998136875">
We manually inspected the output of the classi-
fier to identify possible issues. Apart from sin-
gle classification mistakes, mainly due to unusual
section titles that do not appear in the training set
(such as “Anathematization” in Pope Honorius I
page)9, we found that some wrong classifications
depended on specific types of persons in our data
set. In particular, the classifier tends to assign a
positive label to sections in the pages of mytho-
logical characters, even if they cannot have a bi-
ography because they did not exist. For instance,
in the page of Apollo10 there are sections entitled
“Birth”, “Youth”, “Consorts and Children”, which
led the classifier to label them as biographical. Al-
though mythological characters were included in
the original Pantheon data set, we believe that they
should be discarded, for instance by filtering them
out a priori based on their Wikipedia categories.
Other false positives were found in pages of
historical characters whose life was uncertain and
was transmitted by others. For instance, the page
of the geographer Pytheas11 reports what the Ro-
man author Pliny told about him, as well as what
was said by other sources. These sections are very
similar to those found in biographies, and are la-
belled as such.
We also performed additional experiments in
order to investigate the impact of the size of the
training data on the classification task. In particu-
lar, we extended our training data by creating new
training sets based on 25,000, 50,000, 75,000 and
100,000 Wikipedia pages. These were obtained by
</bodyText>
<footnote confidence="0.99944475">
9https://en.wikipedia.org/wiki/Pope_
Honorius_I
10https://en.wikipedia.org/wiki/Apollo
11https://en.wikipedia.org/wiki/Pytheas
</footnote>
<page confidence="0.996707">
814
</page>
<bodyText confidence="0.999990444444445">
ranking all pages with the PERSONDATA metadata
according to the number of languages in which
they are available, and then looking for the Biog-
raphy and Life sections in the n top-ranked ones.
Our evaluation shows that increasing the training
size does not lead to a better performance, with an
improvement of 0.01 with 100,000 pages over the
results in Table 1 at the cost of a significant drop
in processing speed.
</bodyText>
<sectionHeader confidence="0.998464" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.985955365853658">
In this work we presented a simple yet effective
approach to extract sequences of biographical sec-
tions from Wikipedia persons’ pages. We model
this task as a sequence classification problem us-
ing CRF and show that the section title alone con-
veys enough information to achieve a good classi-
fication result both in a supervised setting and with
a rule-based baseline. Our contribution is three-
fold: i) we introduce the novel task of annotat-
ing the sequence of all sections describing a per-
son’s biography. This can be used as a preliminary
step towards the extraction of all events character-
izing a person’s life; ii) we shed light on the reg-
ularities in Wikipedia persons’ pages. Although
Wikipedia is seen as a resource lacking consis-
tency, with a flawed structure, our results show
that at least persons’ pages often present recurring
patterns that are consistent across different biogra-
phies. The fact that only the most prominent fig-
ures have been included in the Pantheon data set
is only a partial explanation of the good quality of
such pages, because the English pages in our data
set are often a reduced version of more extensive
and edited pages in other languages. Finally, iii)
we present an original approach to automatically
acquire training data, using the pages with a Biog-
raphy or Life section as gold data.
In the future, we plan to compare our approach
based on section titles with more sophisticated ap-
proaches considering also the sections’ content, to
assess whether the latter improves over our sim-
ple methodology. Besides, we will build upon the
outcome of this study by extracting the event se-
quence in a person’s life starting from the com-
plete biographies retrieved from Wikipedia.
The ongoing work is available as an open source
project on GitHub12 and is released under the
GPLv3 license. In the project wiki one can find
12https://github.com/dkmfbk/biographies
the dataset, the gold annotation and all the mate-
rial needed to replicate the experiments.
</bodyText>
<sectionHeader confidence="0.995491" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999838">
The research leading to this paper was partially
supported by the European Union’s 7th Frame-
work Programme via the NewsReader Project
(ICT-316404). We would like to thank Naoaki
Okazaki for the useful insight into CRFSuite.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999888095238095">
David Bamman and Noah Smith. 2014. Unsu-
pervised Discovery of Biographical Structure from
Text. Transactions of the Association for Computa-
tional Linguistics, 2:363–376.
Fadi Biadsy, Julia Hirschberg, and Elena Filatova.
2008. An unsupervised approach to biography pro-
duction using Wikipedia. In In Proceedings of the
46th Annual Meeting of the Association for Compu-
tational Linguistics (ACL-2008).
Maria Biryukov, Roxana Angheluta, and Marie-
Francine Moens. 2005. Multidocument question
answering text summarization using topic signa-
tures. Journal of Digital Information Management,
3(1):27–33.
Elena Filatova and John M. Prager. 2005. Tell me
what you do and i’ll tell you what you are: Learn-
ing occupation-related activities for biographies. In
HLT/EMNLP 2005, Human Language Technology
Conference and Conference on Empirical Methods
in Natural Language Processing, Proceedings of the
Conference, 6-8 October 2005, Vancouver, British
Columbia, Canada.
Richard Johansson and Alessandro Moschitti. 2013.
Relational features in fine-grained opinion analysis.
Computational Linguistics, 39(3):473–509.
Taku Kudo and Yuji Matsumoto. 2001. Chunking
with support vector machines. In Second Meeting
of the North American Chapter of the Association
for Computational Linguistics.
John D. Lafferty, Andrew McCallum, and Fernando
C. N. Pereira. 2001. Conditional random fields:
Probabilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth Inter-
national Conference on Machine Learning, ICML
’01, pages 282–289, San Francisco, CA, USA. Mor-
gan Kaufmann Publishers Inc.
Naoaki Okazaki. 2007. CRFsuite: a fast imple-
mentation of Conditional Random Fields (CRFs).
http://www.chokkan.org/software/
crfsuite/.
Vladimir N. Vapnik. 1998. Statistical Learning The-
ory. Wiley-Interscience.
</reference>
<page confidence="0.985654">
815
</page>
<reference confidence="0.99853675">
Wikipedia Contributors. 2014. Wikipedia: Sys-
tematicbias. https://en.wikipedia.org/
wiki/Wikipedia:Systemic_bias. Ac-
cessed: 2015-06-14.
Amy Zhao Yu, Shahar Ronen, Kevin Zeng Hu, Tiffany
Lu, and C´esar A. Hidalgo. 2015. Pantheon: A
Dataset for the Study of Global Cultural Production.
CoRR, abs/1502.07310.
Liang Zhou, Miruna Ticrea, and Eduard H. Hovy.
2004. Multi-document biography summarization.
In Proceedings of the 2004 Conference on Empirical
Methods in Natural Language Processing, EMNLP
2004, A meeting of SIGDAT, a Special Interest
Group of the ACL, held in conjunction with ACL
2004, 25-26 July 2004, Barcelona, Spain, pages
434–441.
</reference>
<page confidence="0.998823">
816
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.748087">
<title confidence="0.999379">Recognizing Biographical Sections in Wikipedia</title>
<author confidence="0.925553">Alessio Palmero Aprosio Fondazione Bruno Kessler</author>
<address confidence="0.9468115">Via Sommarive, 18 38123 Trento, Italy</address>
<email confidence="0.996423">aprosio@fbk.eu</email>
<abstract confidence="0.999275857142857">Wikipedia is the largest collection of encyclopedic data ever written in the history of humanity. Thanks to its coverage and its availability in machine-readable format, it has become a primary resource for largescale research in historical and cultural studies. In this work, we focus on the subset of pages describing persons, and we investigate the task of recognizing biographical sections from them: given a person’s page, we identify the list of sections where information about her/his life is present. We model this as a sequence classification problem, and propose a supervised setting, in which the training data are acquired automatically. Besides, we show that six simple features extracted only from the section titles are very informative and yield good results well above a strong baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Bamman</author>
<author>Noah Smith</author>
</authors>
<date>2014</date>
<booktitle>Unsupervised Discovery of Biographical Structure from Text. Transactions of the Association for Computational Linguistics,</booktitle>
<pages>2--363</pages>
<contexts>
<context position="5676" citStr="Bamman and Smith, 2014" startWordPosition="852" endWordPosition="855">at all events of a person’s life from birth to death are present. The other approach, instead, is used to generate biography summaries, which was a task of the DUC2004 evaluation exercise4. Besides, while approaches for sentence selection look for textual features such as typical unigrams or bigrams that characterize biographical descriptions (Filatova and Prager, 2005), we adopt a much simpler approach by considering only section titles. Other works focused on the analysis of typical events in selected articles from Wikipedia biographies by looking for a particular list of predefined events (Bamman and Smith, 2014). Our approach may complement such works by introducing a preprocessing step that extracts all and only the sections describing the biographies, upon which event extraction experiments can be performed. This would increase both the precision and the recall of the extracted information. 3 Experimental Setup In this section we detail the data used for our experiments and the classification task. 4http://duc.nist.gov/duc2004/ 3.1 Data set Since our goal is to distinguish between biographical and non biographical sections, we focus only on Wikipedia pages describing persons. We derive our developm</context>
</contexts>
<marker>Bamman, Smith, 2014</marker>
<rawString>David Bamman and Noah Smith. 2014. Unsupervised Discovery of Biographical Structure from Text. Transactions of the Association for Computational Linguistics, 2:363–376.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fadi Biadsy</author>
<author>Julia Hirschberg</author>
<author>Elena Filatova</author>
</authors>
<title>An unsupervised approach to biography production using Wikipedia. In</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-2008).</booktitle>
<contexts>
<context position="4898" citStr="Biadsy et al., 2008" startWordPosition="728" endWordPosition="731">ne is very difficult to beat when the task is performed at section level (i.e. deciding whether a section is biographical or not), our method performs best when the evaluation is performed at page level, recognizing all sections that describe a person’s life. This is crucial if the task under investigation is meant as a preliminary step towards the automatic extraction of all events that compose a person’s biography. 2 Related Work To our knowledge, this is the first attempt to extract biographical sections from Wikipedia. Other past works focused on the recognition of biographical sentences (Biadsy et al., 2008; Zhou et al., 2004; Biryukov et al., 2005). However the two tasks have different goals: in our case, we aim at extracting all biographical sections, so that all events of a person’s life from birth to death are present. The other approach, instead, is used to generate biography summaries, which was a task of the DUC2004 evaluation exercise4. Besides, while approaches for sentence selection look for textual features such as typical unigrams or bigrams that characterize biographical descriptions (Filatova and Prager, 2005), we adopt a much simpler approach by considering only section titles. Ot</context>
</contexts>
<marker>Biadsy, Hirschberg, Filatova, 2008</marker>
<rawString>Fadi Biadsy, Julia Hirschberg, and Elena Filatova. 2008. An unsupervised approach to biography production using Wikipedia. In In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics (ACL-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Biryukov</author>
<author>Roxana Angheluta</author>
<author>MarieFrancine Moens</author>
</authors>
<title>Multidocument question answering text summarization using topic signatures.</title>
<date>2005</date>
<journal>Journal of Digital Information Management,</journal>
<volume>3</volume>
<issue>1</issue>
<contexts>
<context position="4941" citStr="Biryukov et al., 2005" startWordPosition="736" endWordPosition="739">sk is performed at section level (i.e. deciding whether a section is biographical or not), our method performs best when the evaluation is performed at page level, recognizing all sections that describe a person’s life. This is crucial if the task under investigation is meant as a preliminary step towards the automatic extraction of all events that compose a person’s biography. 2 Related Work To our knowledge, this is the first attempt to extract biographical sections from Wikipedia. Other past works focused on the recognition of biographical sentences (Biadsy et al., 2008; Zhou et al., 2004; Biryukov et al., 2005). However the two tasks have different goals: in our case, we aim at extracting all biographical sections, so that all events of a person’s life from birth to death are present. The other approach, instead, is used to generate biography summaries, which was a task of the DUC2004 evaluation exercise4. Besides, while approaches for sentence selection look for textual features such as typical unigrams or bigrams that characterize biographical descriptions (Filatova and Prager, 2005), we adopt a much simpler approach by considering only section titles. Other works focused on the analysis of typica</context>
</contexts>
<marker>Biryukov, Angheluta, Moens, 2005</marker>
<rawString>Maria Biryukov, Roxana Angheluta, and MarieFrancine Moens. 2005. Multidocument question answering text summarization using topic signatures. Journal of Digital Information Management, 3(1):27–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elena Filatova</author>
<author>John M Prager</author>
</authors>
<title>Tell me what you do and i’ll tell you what you are: Learning occupation-related activities for biographies.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference,</booktitle>
<pages>6--8</pages>
<location>Vancouver, British Columbia, Canada.</location>
<contexts>
<context position="5425" citStr="Filatova and Prager, 2005" startWordPosition="811" endWordPosition="814">kipedia. Other past works focused on the recognition of biographical sentences (Biadsy et al., 2008; Zhou et al., 2004; Biryukov et al., 2005). However the two tasks have different goals: in our case, we aim at extracting all biographical sections, so that all events of a person’s life from birth to death are present. The other approach, instead, is used to generate biography summaries, which was a task of the DUC2004 evaluation exercise4. Besides, while approaches for sentence selection look for textual features such as typical unigrams or bigrams that characterize biographical descriptions (Filatova and Prager, 2005), we adopt a much simpler approach by considering only section titles. Other works focused on the analysis of typical events in selected articles from Wikipedia biographies by looking for a particular list of predefined events (Bamman and Smith, 2014). Our approach may complement such works by introducing a preprocessing step that extracts all and only the sections describing the biographies, upon which event extraction experiments can be performed. This would increase both the precision and the recall of the extracted information. 3 Experimental Setup In this section we detail the data used f</context>
</contexts>
<marker>Filatova, Prager, 2005</marker>
<rawString>Elena Filatova and John M. Prager. 2005. Tell me what you do and i’ll tell you what you are: Learning occupation-related activities for biographies. In HLT/EMNLP 2005, Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, Proceedings of the Conference, 6-8 October 2005, Vancouver, British Columbia, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Relational features in fine-grained opinion analysis.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>3</issue>
<contexts>
<context position="13644" citStr="Johansson and Moschitti, 2013" startWordPosition="2120" endWordPosition="2124">e are extracted. This measure is useful to understand how often it is possible to extract the complete and exact biographical text concerning a person. P R F1 CRFsuite Exact 0.694 0.662 0.677 Intersection 0.933 0.863 0.897 Yamcha SVM Exact 0.605 0.630 0.617 Intersection 0.857 0.942 0.898 Baseline Exact 0.584 0.548 0.566 Intersection 0.882 0.809 0.844 Table 1: Classification results using the Exact and Intersection settings • The Intersection measure, instead, assigns a score between 0 and 1 for every predicted sequence of sections based on how much it overlaps with the gold standard sequence (Johansson and Moschitti, 2013). Evaluation results are reported in Table 1. The CRF-based approach outperforms the baseline in both configurations, with the highest improvement in the exact setting (+0.111 F1). Compared with the classification performance obtained with SVMs, CRFs yield better results only in the exact setting, while the intersection-based performance does not show substantial differences. In general, CRFs achieves a better precision but a lower recall than SVMs. If we look at the average length (in sections) of the false positive sequences, it is 3.72 for SVMs and 2.71 for CRFs. This difference confirms th</context>
</contexts>
<marker>Johansson, Moschitti, 2013</marker>
<rawString>Richard Johansson and Alessandro Moschitti. 2013. Relational features in fine-grained opinion analysis. Computational Linguistics, 39(3):473–509.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Chunking with support vector machines.</title>
<date>2001</date>
<booktitle>In Second Meeting of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="10173" citStr="Kudo and Matsumoto, 2001" startWordPosition="1555" endWordPosition="1558">uitable for sequence labelling (Lafferty et al., 2001). We use the implementation provided by CRFsuite7 (Okazaki, 2007) for both training and classification tasks. The algorithm parameters are tuned on the development set. In order to compare our approach with a nonsequential one, we perform the classification task also using Support Vector Machines (Vapnik, 1998). We use YAMCHA8, a tool developed for 7http://www.chokkan.org/software/ crfsuite/ 8http://chasen.org/˜taku/software/ yamcha/ chunking tasks, in which SVMs are easily combined with different context window sizes and dynamic features (Kudo and Matsumoto, 2001). Since this work is only a preliminary step towards the automatic identification and extraction of biographical information from Wikipedia, we first experiment with the simplest approach. Therefore, we consider a small set of shallow features extracted only from section titles, and we ignore the content of the sections. Our six features are: the whole title, the tokens (lowercased), the bigrams, the first token of the section title, the first bigram, the position of the section with respect to the other sections in the same page (first, last, inside). We also use a sliding window of size 1 (b</context>
</contexts>
<marker>Kudo, Matsumoto, 2001</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2001. Chunking with support vector machines. In Second Meeting of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John D Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando C N Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01,</booktitle>
<pages>282--289</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="9602" citStr="Lafferty et al., 2001" startWordPosition="1473" endWordPosition="1477">contain only non-biographical subsections, and the classification of the first level is enough to propagate the corresponding label to the lower levels. Overall, the training set includes 2,547 sequences of sections (22,499 sections in total: 6,861 positive, 15,638 negative). 3.2 Classification experiment We cast the problem as a supervised learning classification task, with the goal to label sequences of Wikipedia sections as describing a person’s biography or not. As discussed in the introduction, we use Conditional Random Fields, since they are particularly suitable for sequence labelling (Lafferty et al., 2001). We use the implementation provided by CRFsuite7 (Okazaki, 2007) for both training and classification tasks. The algorithm parameters are tuned on the development set. In order to compare our approach with a nonsequential one, we perform the classification task also using Support Vector Machines (Vapnik, 1998). We use YAMCHA8, a tool developed for 7http://www.chokkan.org/software/ crfsuite/ 8http://chasen.org/˜taku/software/ yamcha/ chunking tasks, in which SVMs are easily combined with different context window sizes and dynamic features (Kudo and Matsumoto, 2001). Since this work is only a p</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John D. Lafferty, Andrew McCallum, and Fernando C. N. Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, ICML ’01, pages 282–289, San Francisco, CA, USA. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoaki Okazaki</author>
</authors>
<title>CRFsuite: a fast implementation of Conditional Random Fields (CRFs).</title>
<date>2007</date>
<note>http://www.chokkan.org/software/ crfsuite/.</note>
<contexts>
<context position="9667" citStr="Okazaki, 2007" startWordPosition="1485" endWordPosition="1486">first level is enough to propagate the corresponding label to the lower levels. Overall, the training set includes 2,547 sequences of sections (22,499 sections in total: 6,861 positive, 15,638 negative). 3.2 Classification experiment We cast the problem as a supervised learning classification task, with the goal to label sequences of Wikipedia sections as describing a person’s biography or not. As discussed in the introduction, we use Conditional Random Fields, since they are particularly suitable for sequence labelling (Lafferty et al., 2001). We use the implementation provided by CRFsuite7 (Okazaki, 2007) for both training and classification tasks. The algorithm parameters are tuned on the development set. In order to compare our approach with a nonsequential one, we perform the classification task also using Support Vector Machines (Vapnik, 1998). We use YAMCHA8, a tool developed for 7http://www.chokkan.org/software/ crfsuite/ 8http://chasen.org/˜taku/software/ yamcha/ chunking tasks, in which SVMs are easily combined with different context window sizes and dynamic features (Kudo and Matsumoto, 2001). Since this work is only a preliminary step towards the automatic identification and extracti</context>
</contexts>
<marker>Okazaki, 2007</marker>
<rawString>Naoaki Okazaki. 2007. CRFsuite: a fast implementation of Conditional Random Fields (CRFs). http://www.chokkan.org/software/ crfsuite/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir N Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>Wiley-Interscience.</publisher>
<contexts>
<context position="9914" citStr="Vapnik, 1998" startWordPosition="1524" endWordPosition="1525">oblem as a supervised learning classification task, with the goal to label sequences of Wikipedia sections as describing a person’s biography or not. As discussed in the introduction, we use Conditional Random Fields, since they are particularly suitable for sequence labelling (Lafferty et al., 2001). We use the implementation provided by CRFsuite7 (Okazaki, 2007) for both training and classification tasks. The algorithm parameters are tuned on the development set. In order to compare our approach with a nonsequential one, we perform the classification task also using Support Vector Machines (Vapnik, 1998). We use YAMCHA8, a tool developed for 7http://www.chokkan.org/software/ crfsuite/ 8http://chasen.org/˜taku/software/ yamcha/ chunking tasks, in which SVMs are easily combined with different context window sizes and dynamic features (Kudo and Matsumoto, 2001). Since this work is only a preliminary step towards the automatic identification and extraction of biographical information from Wikipedia, we first experiment with the simplest approach. Therefore, we consider a small set of shallow features extracted only from section titles, and we ignore the content of the sections. Our six features a</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>Vladimir N. Vapnik. 1998. Statistical Learning Theory. Wiley-Interscience.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wikipedia Contributors</author>
</authors>
<title>Wikipedia: Systematicbias. https://en.wikipedia.org/ wiki/Wikipedia:Systemic_bias.</title>
<date>2014</date>
<journal>Accessed:</journal>
<pages>2015--06</pages>
<contexts>
<context position="1975" citStr="Contributors, 2014" startWordPosition="277" endWordPosition="278">ng biographical descriptions from large amounts of data and combining them in a more general picture, taking advantage of the availability of such descriptions on the web. Wikipedia has been 1http://www.biographynet.nl 2http://pantheon.media.mit.edu/ treemap/country_exports/IQ/all/-4000/ 2010/H15/pantheon 3http://www.oeaw.ac.at/acdh/de/node/ 188 Sara Tonelli Fondazione Bruno Kessler Via Sommarive, 18 38123 Trento, Italy satonelli@fbk.eu the main source of information for research in this direction despite its many biases, for instance its well-known English, Western and gender bias (Wikipedia Contributors, 2014). In fact, Wikipedia coverage both in terms of pages and in terms of languages, as well as the structured information that can be leveraged through DBpedia, has made it the primary resource for large-scale analyses on biographies. However, the lack of a consistent template for describing persons’ lives led to the creation of a plethora of page types, where biographical information is displayed in diverse ways. Based on a random sample of 100 persons’ pages, we noticed that only 20% of them includes a section called Biography or Life, typically containing a set of subsections describing the mai</context>
</contexts>
<marker>Contributors, 2014</marker>
<rawString>Wikipedia Contributors. 2014. Wikipedia: Systematicbias. https://en.wikipedia.org/ wiki/Wikipedia:Systemic_bias. Accessed: 2015-06-14.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Zhao Yu</author>
<author>Shahar Ronen</author>
<author>Kevin Zeng Hu</author>
<author>Tiffany Lu</author>
<author>C´esar A Hidalgo</author>
</authors>
<title>Pantheon: A Dataset for the Study of Global Cultural Production.</title>
<date>2015</date>
<location>CoRR, abs/1502.07310.</location>
<contexts>
<context position="6348" citStr="Yu et al., 2015" startWordPosition="958" endWordPosition="961">a preprocessing step that extracts all and only the sections describing the biographies, upon which event extraction experiments can be performed. This would increase both the precision and the recall of the extracted information. 3 Experimental Setup In this section we detail the data used for our experiments and the classification task. 4http://duc.nist.gov/duc2004/ 3.1 Data set Since our goal is to distinguish between biographical and non biographical sections, we focus only on Wikipedia pages describing persons. We derive our development, training and test data from the Pantheon data set (Yu et al., 2015), freely available for download.5 The data set includes a list of 11,340 notable individuals with the link to their Wikipedia page in multiple languages, plus a number of additional information such as date and place of birth, category and language editions, which we do not consider for our study. Only the persons whose Wikipedia page is translated in at least 25 languages are included in Pantheon, as a proxy of prominent world personalities. For each person in the list, we download the corresponding Wikipedia page in English and preprocess it using TheWikiMachine library6. Overall, we collect</context>
</contexts>
<marker>Yu, Ronen, Hu, Lu, Hidalgo, 2015</marker>
<rawString>Amy Zhao Yu, Shahar Ronen, Kevin Zeng Hu, Tiffany Lu, and C´esar A. Hidalgo. 2015. Pantheon: A Dataset for the Study of Global Cultural Production. CoRR, abs/1502.07310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Zhou</author>
<author>Miruna Ticrea</author>
<author>Eduard H Hovy</author>
</authors>
<title>Multi-document biography summarization.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, EMNLP 2004, A meeting of SIGDAT, a Special Interest Group of the ACL, held in conjunction with ACL</booktitle>
<pages>25--26</pages>
<location>Barcelona,</location>
<contexts>
<context position="4917" citStr="Zhou et al., 2004" startWordPosition="732" endWordPosition="735">to beat when the task is performed at section level (i.e. deciding whether a section is biographical or not), our method performs best when the evaluation is performed at page level, recognizing all sections that describe a person’s life. This is crucial if the task under investigation is meant as a preliminary step towards the automatic extraction of all events that compose a person’s biography. 2 Related Work To our knowledge, this is the first attempt to extract biographical sections from Wikipedia. Other past works focused on the recognition of biographical sentences (Biadsy et al., 2008; Zhou et al., 2004; Biryukov et al., 2005). However the two tasks have different goals: in our case, we aim at extracting all biographical sections, so that all events of a person’s life from birth to death are present. The other approach, instead, is used to generate biography summaries, which was a task of the DUC2004 evaluation exercise4. Besides, while approaches for sentence selection look for textual features such as typical unigrams or bigrams that characterize biographical descriptions (Filatova and Prager, 2005), we adopt a much simpler approach by considering only section titles. Other works focused o</context>
</contexts>
<marker>Zhou, Ticrea, Hovy, 2004</marker>
<rawString>Liang Zhou, Miruna Ticrea, and Eduard H. Hovy. 2004. Multi-document biography summarization. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing, EMNLP 2004, A meeting of SIGDAT, a Special Interest Group of the ACL, held in conjunction with ACL 2004, 25-26 July 2004, Barcelona, Spain, pages 434–441.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>