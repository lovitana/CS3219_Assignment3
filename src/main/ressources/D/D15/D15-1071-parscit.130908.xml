<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000018">
<title confidence="0.805214">
Detecting Risks in the Banking System by Sentiment Analysis
</title>
<note confidence="0.887175">
Clemens Nopp Allan Hanbury
TU Wien Institute of Software Technology
clemens.nopp@alumni.tuwien.ac.at and Interactive Systems
TU Wien
</note>
<email confidence="0.711684">
hanbury@ifs.tuwien.ac.at
</email>
<sectionHeader confidence="0.990204" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999914571428571">
In November 2014, the European Cen-
tral Bank (ECB) started to directly su-
pervise the largest banks in the Euro-
zone via the Single Supervisory Mecha-
nism (SSM). While supervisory risk as-
sessments are usually based on quantita-
tive data and surveys, this work explores
whether sentiment analysis is capable of
measuring a bank’s attitude and opinions
towards risk by analyzing text data. For
realizing this study, a collection consisting
of more than 500 CEO letters and outlook
sections extracted from bank annual re-
ports is built up. Based on these data, two
distinct experiments are conducted. The
evaluations find promising opportunities,
but also limitations for risk sentiment anal-
ysis in banking supervision. At the level of
individual banks, predictions are relatively
inaccurate. In contrast, the analysis of ag-
gregated figures revealed strong and sig-
nificant correlations between uncertainty
or negativity in textual disclosures and the
quantitative risk indicator’s future evolu-
tion. Risk sentiment analysis should there-
fore rather be used for macroprudential
analyses than for assessments of individ-
ual banks.
</bodyText>
<sectionHeader confidence="0.998103" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999677">
From 2007 on, a global crisis struck the financial
markets and led to a severe slow-down of the real
economy. It was triggered by the collapsing US
subprime mortgage sector, where loans had been
issued to borrowers with poor credit ratings. Due
to the tight interconnectedness of the financial sys-
tem, problems quickly propagated in the global
banking system. Governments had to bail out im-
portant institutions like Northern Rock, but such
solutions could not be provided for every troubled
bank. In September 2008, the large investment
bank Lehman Brothers had to file bankruptcy. In
the aftermath of this event, further banks had to be
rescued in order to stabilize the financial system.
This deep financial crisis highlighted the necessity
of better financial regulation as well as more ef-
fective financial supervision in the future (Hodson
and Quaglia, 2009).
As a reaction to the crisis and its severe eco-
nomic consequences, EU institutions decided to
build up an European Banking Union (EBU). The
EBU consists of three pillars, one of them being
a new system of financial supervision, the Sin-
gle Supervisory Mechanism (SSM). Its goal is to
“promote long-term safety and soundness of credit
institutions and the stability of the financial sys-
tem within the Union and each Member State
[...]” (Council of the EU, 2013, p. 72).
For supervising over 120 of the largest banks
in the Eurozone, the SSM utilizes a range of in-
formation sources in order to detect vulnerabilities
and risks. The sources include mainly backward-
looking quantitative Key Risk Indicators (KRIs),
which are complemented with surveys in order to
include forward-looking information as well (Eu-
ropean Banking Authority, 2014). However, an-
other source of information seems to be largely
untapped, namely textual data published by the
banks. Publications like periodic reports, press re-
leases, and news published for investors also con-
tain forward-looking information. Analyzing this
readily available data would be more cost-efficient
in comparison to traditional approaches like sur-
veys. It could provide answers to questions like:
what does official communication by banks re-
veal about their expectations and attitudes towards
risk?
In this paper, we present a novel applica-
tion of sentiment analysis for exploring attitudes
and opinions about risk in textual disclosures by
</bodyText>
<note confidence="0.802476">
591
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 591–600,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.9999151875">
banks. In particular, this work (1) finds suitable
data sources, (2) identifies appropriate techniques
for risk sentiment analysis, and (3) analyzes risk
sentiment within the last decade in order to cover
the financial crisis of 2007-08 adequately. The de-
rived sentiment scores quantify uncertainty, nega-
tivity, and positivity in the analyzed documents.
All of them are interesting with regards to risk
sentiment analysis: uncertainty relates to risk in
a direct way since the latter are “uncertainties re-
sulting in adverse variations of profitability or in
losses” (Bessis, 2002, p. 11). Highly negative sen-
timent refers to current or future problems, and
too positive sentiment could represent overconfi-
dence. We find that sentiment scores reflect not
only the financial crisis, but also other major eco-
nomic events within the last decade.
In addition, we test for correlations between the
sentiment scores and a popular quantitative risk in-
dicator. It turns out that aggregated risk sentiment
in forward-looking documents is a leading indica-
tor for the actual risk figures, so it can be used
within predictive models.
The remainder of this paper, which is based on
the Master’s thesis of one of the authors (Nopp,
2015), is organized as follows: first, we give an
overview on related work in the field of risk sen-
timent analysis. The following section introduces
the chosen sources for text data and quantitative
figures. Afterwards, we give an overview on the
chosen methodologies and evaluate the experi-
mental results. The last section concludes.
</bodyText>
<sectionHeader confidence="0.999786" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999564375">
Sentiment analysis in general and its application
in the financial domain in particular gained a lot
of interest within the last decade. There is a num-
ber of studies which aim to identify risks by means
of text mining. A common question tackled by
researchers is whether corporate disclosures drive
stock price volatilities or future earnings of the re-
spective firm (Groth and Muntermann, 2011; Ko-
gan et al., 2009; Tsai and Wang, 2013). Hence,
they focus on the risk an investor takes if he or
she buys stocks of a company. Generally spo-
ken, these studies find significant correlations be-
tween sentiment extracted from corporate disclo-
sures and future volatilities. Other papers deal
with financial distress prediction, for example Ha-
jek and Olej (2013). As a baseline, they classify
companies based on financial indicators. It turned
out that the inclusion of sentiment indicators im-
proved financial distress prediction.
Among the text data sources for these studies
are mainly annual reports, but also news stories
or earning calls transcripts1. Kogan et al. (2009)
exclude irrelevant information from the annual re-
ports by focusing on a section which contains im-
portant forward-looking content.
In the related studies, authors work with simi-
lar approaches for extracting sentiment from texts.
Linguistic preprocessing generally involves to-
kenization, lemmatization, and removing non-
essential items like tables, exhibits, or digit se-
quences. In almost every study, the authors also
make use of term weighting schemes. With the
selected features and additional quantitative data,
the studies either employ machine learning algo-
rithms, or use the data for regression analyses.
Although none of the mentioned papers focuses
on risk sentiment analysis in the banking industry,
parts of their processing pipelines and approaches
can be reused for this work. With regards to the se-
lection of appropriate data sources, it can be con-
cluded that analyzing annual reports is very pop-
ular in this field of research. Hence, these data
should also be considered for the experiments of
this study. In contrast to the majority of the related
papers, we only use specific sections of the annual
reports, namely CEO letters and outlook sections
(see Section 3).
Regarding the machine learning algorithms and
the incorporation of quantitative indicators, the ap-
proaches of Groth and Muntermann (2011), Ko-
gan et al. (2009), and Hajek and Olej (2013) are a
good basis for the experiments of this study. All of
them define the document labels based on suitable
quantitative indicators. For labeling, the related
studies consider the fact that text data are forward-
looking, but quantitative indicators reflect the past.
Hence, the indicators are taken from one period
after publication of the text data. The labeled data
are then used for training machine learning algo-
rithms. Since the focus of our work lies on banks,
we make use of a specific quantitative risk indica-
tor which is not employed by related studies. In
the following section, we introduce this indicator
and the selected text data sources.
</bodyText>
<footnote confidence="0.885562333333333">
1Earning calls are regular events where managers report
about the company’s current situation and answer questions
from business analysts.
</footnote>
<page confidence="0.892887">
592
</page>
<sectionHeader confidence="0.994376" genericHeader="method">
3 Data Sources
</sectionHeader>
<bodyText confidence="0.9933395">
Among this work’s aims is to test for relations be-
tween textual risk sentiment and quantitative risk
indicators. A careful selection of sources for both
types of data is crucial since irrelevant ones would
lead to biased conclusions.
Quantitative Risk Indicator. The selected
quantitative risk indicator has to represent fi-
nancial health and the general risk exposure of
a bank within a specific period or at a specific
point in time. Furthermore, the data have to be
(1) publicly accessible, (2) available for each
analyzed bank, (3) published at least annually,
and (4) comparable among the different banks.
A comparison of several quantitative risk in-
dicators based on expert interviews revealed that
only the Tier 1 Capital Ratio (T1) fulfills all cri-
teria. The T1 is one of the most important ratios
based on risk-weighted amount of the bank’s as-
sets. In particular, it refers to the bank’s Tier 1
capital as a percentage of its risk-weighted assets:
</bodyText>
<equation confidence="0.82968825">
Tier 1 Capital
Tier 1 Capital Ratio =
Risk-Weighted Assets
(1)
</equation>
<bodyText confidence="0.99989015942029">
Tier 1 capital is considered as the best form of
bank capital and has to fulfill several criteria mak-
ing it relatively secure. As Cannata et al. (2012,
p. 12) put it, this ratio “measures the ability of the
bank to absorb losses”. If the T1 is high, the bank
acts conservatively and with a high risk buffer. A
high ratio can be achieved by either increasing the
Tier 1 capital or by reducing the amount of risk-
weighted assets, i.e. reducing the amount of total
assets or replacing them with safer ones.
The T1 also played a major role during the 2014
EU-wide banking stress test, which was an impor-
tant part of the preparation phase for the Single
Supervisory Mechanism. The stress test had the
purpose to assess the resilience of large EU banks
in different macroeconomic scenarios, measured
by the impact on the T1.
Text Data Sources. In order to minimize noise
and to enhance the sentiment analysis validity, it is
crucial to work with the documents well adapted to
the task of risk sentiment analysis. Like the quan-
titative risk indicators, they need to be (1) publicly
accessible, (2) available for every analyzed bank,
and (3) published at least annually. In addition, for
this study, the documents need to be (4) written in
the English language, (5) directly published by the
bank, and (6) contain forward-looking and subjec-
tive information about the bank’s attitude and ex-
pectations towards risk.
These criteria are best fulfilled by two types of
document published in the banks’ annual reports,
namely CEO letters and outlook sections. The for-
mer are carefully crafted documents which con-
tain valuable information about the management’s
opinions about risk. Amernic et al. (2010) recog-
nize in their study from 2010 that the word choice
of managers strongly influences companies, and
CEO letters are a way for communicating their at-
titudes and values.
Outlook sections are usually a part of the man-
agement report, which is a textual summary of the
bank’s results, its business environment, and regu-
latory as well as internal developments. In their
outlook on the next year, banks write about the
expected macroeconomic environment, manage-
ment guidelines, and priorities for the next period.
These documents might be less subjective com-
pared to CEO letters, but they are usually more
comprehensive and contain interesting forward-
looking information.
Collection of Data. The annual reports for this
work were collected via a Bloomberg Terminal,
supplemented by direct downloads from bank
websites. In total, over 500 documents from 27
banks which published them between 2001 and
2013 were collected. The sample contains banks
from all 12 countries which have belonged to the
Eurozone at least since 2002. This promotes com-
parability of the data because the banks operated
in similar economic circumstances and with the
same currency.
Further data were retrieved from the online
database Bankscope: the bank’s country of resi-
dence, its full name, its size measured by total as-
sets, and its Tier 1 capital ratio at the end of each
year between 2001 and 2013. 31 % of the Tier 1
capital ratios could not be directly retrieved from
the database, so they had to be manually extracted
from the respective annual reports.
</bodyText>
<sectionHeader confidence="0.997183" genericHeader="method">
4 Methodologies
</sectionHeader>
<bodyText confidence="0.999958">
Two independent approaches are employed for the
risk sentiment analysis. First, a lexicon-based ap-
proach derives and analyzes negativity, positivity,
and uncertainty in publications by banks. The
second approach aims to predict the evolution of
</bodyText>
<page confidence="0.724389">
593
</page>
<bodyText confidence="0.999452481481482">
quantitative risk indicators by means of supervised
classification. The aim of both approaches is to
assess the potential of risk sentiment analysis in
banking supervision.
Creation of the Document Collection. The
original documents are provided as PDF files. For
building up the collection, they have to be parsed
in order to acquire plain text files containing the
required sections. One method for extracting the
relevant sections is to split the original PDF files
according to their bookmarks and to convert them
into plain text files afterwards. Another way is to
convert the PDF files already in the first step and
to extract the relevant sections by making use of
specific tokens. For example, a typical CEO let-
ter is delimited by the tokens Dear Shareholders
and Sincerely. If neither of these semi-automated
approaches is applicable, the extraction has to be
done manually2.
Table 4 gives an overview of the number of doc-
uments in the created collection. It shows that the
number of published outlook sections constantly
increased between 2002 and 2008. From 2009
on, the number was quite stable. The number of
CEO letters also increased over time, but only un-
til 2008, when some CEOs stopped writing letters
in the course of the financial crisis.
</bodyText>
<table confidence="0.981833666666667">
Year # of CEO letters # of outlooks
2002 15 14
2003 19 19
2004 17 20
2005 19 20
2006 19 21
2007 23 22
2008 25 23
2009 21 23
2010 20 23
2011 21 23
2012 20 23
2013 22 24
2014 22 23
Total 263 278
</table>
<tableCaption confidence="0.999783">
Table 1: An overview of the document collection.
</tableCaption>
<subsectionHeader confidence="0.980799">
4.1 Lexicon-based Approach
</subsectionHeader>
<bodyText confidence="0.992101586206896">
The first experiment is about analyzing sentiment
scores derived from the documents by incorpo-
2This was the case for around 20 % of the documents.
rating finance-specific word lists. The objective
of this experiment is to show how the language
of forward-looking disclosures by European banks
evolved within the last decade. The workflow con-
sists of the following steps: (1) pre-processing the
collected data, (2) the actual sentiment analysis
which derives the scores, (3) data consolidation,
and (4) data evaluation.
Sentiment Tagging. In the first step of the anal-
ysis, sentiment words in the textual data are
tagged. In particular, this study works with neg-
ative words (Fin-Neg), positive words (Fin-Pos),
and words related to uncertainty (Fin-Unc). All
of these word lists are provided by Loughran and
McDonald (2011). Such topic-specific word lists
are necessary because many words bear a different
sentiment if used in a financial context: according
to Loughran and McDonald (2011), almost three
quarters (73.8 %) of typically negative words can-
not be considered as negative when they appear in
financial texts. Kearney and Liu (2014) give the
examples tax and liability. These words appear in
the Harvard IV Negative Word List (H4N), but are
neutral when used in a financial context, e.g. in
an annual report. Table 2 lists some examples for
sentiment words in the financial context.
</bodyText>
<table confidence="0.999702666666667">
Positive efficient, stabilized, vibrant
Negative closure, postpone, threat
Uncertainty approximately, might, volatility
</table>
<tableCaption confidence="0.8363765">
Table 2: Examples for opinion words in the finan-
cial context (Loughran and McDonald, 2011).
Term Weighting. All terms in a document are
normalized by
</tableCaption>
<equation confidence="0.9827922">
1
Nj =
(2)
/
V Em0(GiLi,j)2.
</equation>
<bodyText confidence="0.986257428571428">
This equation is based on Salton and Buck-
ley (1988) and accounts for documents of differ-
ent lengths. Gi is the global weight of term i and
Li,j the local weight of term i in document j. An
established method for the latter is given by the
following formula (Manning and Sch¨utze, 1999,
p. 543):
</bodyText>
<equation confidence="0.8831915">
�
1 + log(tfi,j) if tfi,j ≥ 1
Li,j =(3)
0 otherwise
594
The term frequency is denoted as tfi,j. The most
popular global weight is the inverse document fre-
quency (IDF). In
rl
Gi = log l Ndfi I , (4 )
</equation>
<bodyText confidence="0.9993265">
the total number of documents is denoted by N,
and dfi is the number of documents where term i
occurs at least once (Salton and Buckley, 1988).
Valence Shifting. In order to account for
negated sentiment words, the simple negation han-
dling algorithm proposed by Polanyi and Zae-
nen (2006) is implemented. If one of the three di-
rect predecessors of a sentiment word is a negation
word3, its sentiment score will be negated. This is
done by assigning −1 to the valence shifter vari-
able vi of term i. If there is no negation word
among the predecessors, vi is set to 1.
Calculating Sentiment Scores. The document-
level sentiment scores are calculated for three sen-
timent classes, namely uncertainty, positivity, and
negativity. In
</bodyText>
<equation confidence="0.9215315">
�sc,j = Li,jGiNjvi, (5)
i∈c
</equation>
<bodyText confidence="0.999784166666667">
the term-level sentiment score is represented by
the product of the term weights Li,j and Gi, the
normalization factor Nj, and the valence shifter
vi. The document sentiment score sc,j is the sum
of the term sentiment scores which belong to the
document j and the sentiment class c.
Data Consolidation and Evaluation. After cal-
culating the sentiment scores, the data are filtered
and grouped in order to prepare them for the evalu-
ations. In particular, the data are filtered according
to specific countries and grouped by year respec-
tively by bank.
</bodyText>
<subsectionHeader confidence="0.972691">
4.2 Supervised Classification
</subsectionHeader>
<bodyText confidence="0.992309120689655">
For the second experiment, the documents are la-
beled based on a quantitative risk measure, namely
the T1 dating to the end of the period referred to
in the CEO letters and outlook sections. These
data are then used for training supervised classi-
fication algorithms which aim to predict the indi-
cator’s evolution.
3The considered negation words are no, not, don’t, never,
none, and neither.
The experiment consists of three steps: (1) read-
ing and parsing the collected data as well as as-
signing the class labels, (2) linguistic preprocess-
ing and feature selection, and (3) classifying the
data with Naive Bayes (NB) and Support Vector
Machine (SVM).
Assigning the Class Labels. The Tier 1 capital
ratio is published by banks at least once a year.
Since it is actually a continuous measure, it al-
ways strongly depends on the previous year’s ra-
tio. Banking supervisors like the ECB are inter-
ested in the future evolution of the ratio: if it in-
creases, the bank acts in a less risky way, and vice
versa. Hence, appropriate labels for the supervised
classification task are UP for an increasing T1, and
DOWN for a decreasing one. We assume that the
T1 did not change notably if the difference to the
previous year is less than 0.2 percent points4. In
this case, no class label is assigned.
Preprocessing and Feature Selection. Linguis-
tic preprocessing comprises the removal of punc-
tuation, numbers, single characters, and stop
words. The remaining words are converted to
lower case. Furthermore, the terms are weighted
according to the term weighting strategy presented
in Section 4.1.
For feature selection, two approaches are fol-
lowed. The first one assumes that the sentiment
words used in the lexicon-based analysis are the
relevant features for this experiment. Hence, all
words which do not appear in the first experi-
ment’s dictionaries are removed. The second ap-
proach utilizes a Snowball Stemmer to ensure that
different versions of the same word are treated as
equal. Its feature selection strategy is based on
the concepts of document frequency (DF) and in-
formation gain (IG). For DF, tests showed that a
lower bound of 20 documents yields the best re-
sults. The objective of the IG measure is to iden-
tify those features which have the highest discrim-
inatory power in a classification problem. It mea-
sures the impurity of a dataset, i.e. its entropy. If
a feature is able to reduce the entropy in a data
set by a large amount, its information gain is high.
Such features have a relatively high ability to pre-
dict the corresponding class. For calculating the
information gain, one has to compute the entropies
given the presence or absence of a feature in a
data set and subtract the results from the entropy
</bodyText>
<footnote confidence="0.458922">
4This affected 17 % of the data points in the sample.
</footnote>
<page confidence="0.852524">
595
</page>
<bodyText confidence="0.999124133333333">
of the original data set (Aggarwal and Zhai, 2012,
p. 169).
Classification. The outcome of the previous
steps is a set of document vectors with associated
class labels. With these data, the classification al-
gorithms Naive Bayes (NB) and Support Vector
Machine (SVM) are trained. The latter is used
in its basic version, i.e. with a linear kernel. The
performance measures are determined by employ-
ing 10-fold cross validation, which helps to avoid
problems like overfitting.
While Naive Bayes works without parameters,
the linear SVM depends on the parameter C. Its
optimal value of 111 was determined by conduct-
ing an automated grid search.
</bodyText>
<sectionHeader confidence="0.87725" genericHeader="evaluation">
5 Evaluation of the Experiments
</sectionHeader>
<bodyText confidence="0.9999346">
Both experiments aim to capture attitudes and
opinions about risk by analyzing CEO letters and
outlook sections of Eurozone banks. In this sec-
tion, conclusions are drawn from the results of the
experiments.
</bodyText>
<subsectionHeader confidence="0.652885">
5.1 Evaluation of the Lexicon-based
Approach
</subsectionHeader>
<bodyText confidence="0.994378291666667">
The outcome of the lexicon-based approach con-
sists of sentiment scores for each document repre-
senting the degrees of uncertainty, negativity, and
positivity.
Evolution of Sentiment Over Time. Figure 1
shows how sentiment in CEO letters has been
evolving since 2002. The evolution of sentiment in
outlook sections is not depicted, but is very similar
to that of CEO letters. The individual data points
represent the arithmetic mean of the document-
level sentiment scores for each year. In 2002 and
2003, CEO letters contained more negative sen-
timent than in the following years. Banks might
have emphasized that the recession following the
burst of the dot-com bubble was still not over
and that recovery had not yet arrived. Between
2003 and 2006, the letters became more positive
and less negative from year to year. The turn-
ing point was in 2006—from that time on, nega-
tivity in CEO letters rose and quadrupled within
three years. During the same period, positive sen-
timent scores decreased continuously. The summit
of these evolutions was in 2009, in the midst of
the financial crisis. The letters in 2010 had been
already much more optimistic, but negativity in-
creased in 2011 and 2012 again when CEOs rec-
ognized that the crisis was still not over.
The evolution of the uncertainty scores is simi-
lar to the negative sentiment scores. This observa-
tion is supported by a high correlation coefficient
of 0.93 between uncertainty and negativity scores.
Since 2012, uncertainty has been decreasing quite
sharply. This can potentially be attributed to an
important and often-cited speech by ECB presi-
dent Mario Draghi, who calmed the financial mar-
kets with the announcement to do “whatever it
takes to preserve the Euro. And believe me, it will
be enough”5.
Another observation is that the average uncer-
tainty scores are much lower than the average pos-
itivity and negativity scores. A plausible interpre-
tation thereof is that CEOs rather use clear state-
ments than uncertain language.
Do Sentiment Scores Predict Quantitative Risk
Measures? A comparison of the T1 average
evolution and the corresponding sentiment scores
reveals interesting relations, see Figure 2. The
correlation coefficients in Table 3 indicate that a
higher degree of uncertainty or negativity in the
documents is commonly followed by a higher in-
crease of the T1, and vice versa.
It is interesting to analyze the data by a regres-
sion model for predicting the T1 evolution. Table
4 shows such a model with negativity as the only
explaining variable. The coefficients can be inter-
preted as follows: if the average negativity score
rises by one unit, the T1 evolution increases by
0.9963 pp. If negativity is zero, the Tier 1 capital
ratio would decrease by the computed intercept,
which is -0.502 pp. Both coefficients are statisti-
cally significant if a 95 % confidence level is as-
sumed.
About 76 % of the average T1 evolution’s vari-
ation can be explained by the negativity score. A
model of similar quality could be constructed by
analyzing uncertainty in outlook sections. Hence,
sentiment scores can be considered as an addi-
tional leading indicator for the future evolution of
the Tier 1 capital ratio.
Limitations. A drawback of this regression
model is that it cannot model external shocks
which influence the T1 evolution, but are not ad-
</bodyText>
<footnote confidence="0.557282">
5A transcript of this speech is available at
https://www.ecb.europa.eu/press/key/
date/2012/html/sp120726.en.html, accessed
April 20th, 2015.
</footnote>
<page confidence="0.736984">
596
</page>
<figureCaption confidence="0.977848666666667">
Figure 1: Evolution of positivity, negativity, and uncertainty in CEO letters over time.
Figure 2: Evolution of the Tier 1 capital ratio compared to negativity in outlook sections. The error bars
represent the standard deviation of the negativity scores.
</figureCaption>
<table confidence="0.997355333333333">
Correlation coefficient Uncertainty Negativity Positivity
T1 evolution (CEO letters) 0.86 0.79 -0.69
T1 evolution (Outlooks) 0.85 0.89 0.12
</table>
<tableCaption confidence="0.993294">
Table 3: Correlation coefficients between T1 evolution and sentiment scores.
</tableCaption>
<table confidence="0.999538333333333">
Variable Coeff. Std. Err. t-value P&gt;t
Mean(Negativity score) 0.9963 0.1647 6.0478 0.0001
Intercept -0.5020 0.1883 -2.6651 0.0237
</table>
<tableCaption confidence="0.999934">
Table 4: Regression model based on negativity in outlook sections.
</tableCaption>
<figure confidence="0.999028222222222">
Sentiment score
-1.00
3.00
2.00
1.00
0.00
2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013
Year
Evolution of Tier 1 Capital Ratio
Mean(Negativity score)
3.00
0.00
2.00
1.00
-1.00
-2.00
Evolution of Tier 1 Capital Ratio (in pp)
597
</figure>
<figureCaption confidence="0.9334905">
Figure 3: Individual negativity scores in outlook
sections compared to the T1 evolution.
</figureCaption>
<bodyText confidence="0.9999575">
equately covered in the text data. Examples for
such shocks would be new regulations concern-
ing the minimum capital ratio or monetary pol-
icy actions by the ECB. A further limitation is in-
duced by the fact that our methodology makes use
of the bag of words (BoW) model, which ignores
the documents internal structure. Hence, it is not
possible to utilize information like word order and
grammar, although this definitely plays a role in
carefully crafted documents like CEO letters.
It should also be emphasized that the model is
based on figures aggregated by year. Applying it
on the data of individual banks could lead to in-
correct conclusions. This assumption is supported
by Figure 3, which compares negativity scores of
individual outlook sections with the associated T1
evolutions. Although it is still possible to identify
a positive relationship between the variables, the
variance is too big for satisfactory representation
by a regression model6. This observation is in line
with the relatively high standard deviations if the
figures are aggregated by year, see Figure 2.
</bodyText>
<subsectionHeader confidence="0.9995925">
5.2 Evaluation of the Supervised
Classification Approach
</subsectionHeader>
<bodyText confidence="0.986858101694916">
The supervised classification experiment aims to
assess whether this approach works better than the
lexicon-based approach in terms of predicting the
T1 evolution for individual banks based on their
CEO letters or outlook sections. The class la-
bels UP and DOWN have been assigned accord-
ing to the direction of the T1 evolution. Table
5 gives an overview of the experiments and lists
6If the regression model is built with non-aggregated data,
it explains only 6.6 % of the variation.
the respective performance measures. An analy-
sis of the data in the table reveals interesting re-
sults. First, feature selection based on document
frequency and information gain works better than
the approach based on word lists. Second, the clas-
sifiers trained with CEO letters yield better results
than the ones trained with outlook sections. Fi-
nally, three out of the four SVM results are not
meaningful due to the following reason: the pa-
rameter optimization of C suggests to choose a
very low value, which indeed maximizes the clas-
sifier accuracy—but these SVMs simply assign the
class UP to every instance. These classifiers can
be seen as a baseline for comparisons. However,
the remaining SVM clearly yields the best results
among the employed algorithms.
None of the classifiers based on the feature se-
lection method (1) is able to outperform the base-
line (assigning every instance to the UP class).
Both SVMs simply classify every instance as UP,
and the Naive Bayes classifiers also deliver unsat-
isfactory results. Feature selection based on docu-
ment frequency and information gain achieves bet-
ter results than the first one, but only when the
classifiers are trained with the CEO letter collec-
tion. Most likely, this can be explained with the
fact that outlook sections provide less terms with
discriminatory power than CEO letters. Naive
Bayes correctly classifies 75 % of the instances,
and the optimized SVM yields 79.2 %. The other
SVM performance measures can be interpreted as
follows: 81 % of the instances classified as UP
were indeed instances where the Tier 1 capital
ratio increased (= precision U). Furthermore, the
SVM correctly identified almost 92 % of the in-
stances which belong to the class UP (= recall U).
These results are better than the baseline and
demonstrate a noticeable potential for supervised
classification even at the level of individual bank
disclosures. Nevertheless, they are not good
enough for reliable predictions. However, the
aggregated classification data accurately predict
whether the majority of banks will increase or de-
crease their Tier 1 capital ratio in the following
year: for 12 out of 13 years, the algorithm cor-
rectly predicts the direction of the T1 evolution.
This finding is in line with the lexicon-based ap-
proach, where the aggregated data yielded much
better results than the individual ones.
</bodyText>
<page confidence="0.523348">
598
</page>
<table confidence="0.999758857142857">
Feature selection Document type Classifier Accuracy Precision U Recall U Precision D Recall D
(1) based on topic- CEO letters NB 0.703 0.741 0.889 0.500 0.263
specific sentiment
words
SVM 0.703 0.703 1.000 n.a. 0.000
Outlook sections NB 0.563 0.685 0.703 0.246 0.230
SVM 0.703 0.703 1.000 n.a. 0.000
(2) based on doc- CEO letters NB 0.750 0.774 0.911 0.636 0.368
ument frequency
and information
gain
SVM 0.792 0.810 0.919 0.718 0.491
Outlook sections NB 0.704 0.704 1.000 n.a. 0.000
SVM 0.704 0.704 1.000 n.a. 0.000
</table>
<tableCaption confidence="0.864001">
Table 5: Overview of the results of the supervised classification experiment. Bold numbers indicate the
best results, U class UP, and D class DOWN.
</tableCaption>
<sectionHeader confidence="0.997614" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999994901639345">
This study explored how banking supervisors
could utilize sentiment analysis for risk assess-
ments. The analysis of potential document types
revealed that two sections in a bank’s annual re-
port are particularly well suited for this work,
namely CEO letters and outlook sections. The for-
mer represent the tone from the top and provide
subjective information about the bank’s current
and future situation. Outlook sections are exclu-
sively forward-looking and reveal opinions about
the near future. Furthermore, the Tier 1 capital
ratio (T1) is the best suited quantitative risk indi-
cator. The T1 sets the most secure forms of bank
capital in relation to its risk-weighted assets and is
widely used in banking supervision, e.g. as a key
ratio for the ECB’s stress test in fall 2014.
The lexicon-based analysis showed that senti-
ment scores reflect major economic events be-
tween 2002 and 2014 very well. In addition, there
is a strong correlation between uncertainty, neg-
ativity, and the Tier 1 capital ratio evolution over
time. Hence, the sentiment scores could be used in
regression models for predicting the T1 evolution.
However, the results are only meaningful if the fig-
ures are aggregated by year. Applying the model
on data of individual banks leads to inaccurate re-
sults. It should also be noted that this method is
not meant to be used as a stand-alone estimator for
the T1 evolution. Instead, it should be combined
with other estimation methods.
The supervised risk classification approach cor-
rectly classifies 79.2 % of the CEO letters. This
is not good if one considers that it is possible to
yield an accuracy of 70 % simply by assigning the
class UP to every instance. However, if the results
of the best SVM classifier are aggregated by year,
the data correctly predict for 12 out of 13 years
whether the majority of banks will increase or de-
crease their Tier 1 capital ratio.
The described systems have the potential to pro-
vide valuable insights for banking supervisors, in
particular because of the strong correlation be-
tween sentiment scores derived from textual data
and the T1. Because of the mentioned limitations,
these techniques should only be used for macro-
prudential analyses, i.e. the promotion of stability
in the whole financial system. Examples are pre-
dictions for the average Tier 1 capital ratio’s evolu-
tion in the whole Eurozone or in groups of coun-
tries. Another option is to improve existing risk
prediction frameworks.
For future research, it would be interesting
to validate the results by conducting the study
on a larger scale. One could incorporate data
from all European banks, or from other regions.
The approach could also be used for other docu-
ment types, for example analyst reports or inter-
nal memos, or in other industries. Regarding the
methodology, it would be interesting to see how
alternative algorithms or word lists would affect
the results.
</bodyText>
<sectionHeader confidence="0.998458" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999303882352941">
Charu C. Aggarwal and Cheng Xiang Zhai. 2012.
A Survey of Text Classification Algorithms. In
Charu C. Aggarwal and Cheng Xiang Zhai, editors,
Mining Text Data, pages 163–222. Springer Sci-
ence+Business Media.
Joel Amernic, Russel Craig, and Dennis Tourish.
2010. Measuring and Assessing Tone at the
Top Using Annual Report CEO Letters. In-
stitute of Chartered Accountants of Scotland,
Edinburgh. Retrieved March 28th, 2014, from
http://eprints.port.ac.uk/12648/
1/CRAIG_2010_pub_Bk_Measuring_and_
assessing_tone_at_the_top_using_
annual_report_CEO_letters.pdf.
Jo¨el Bessis. 2002. Risk Management in Banking. John
Wiley &amp; Sons Ltd, Chichester, United Kingdom,
2nd edition.
</reference>
<page confidence="0.641205">
599
</page>
<reference confidence="0.999251383561644">
Francesco Cannata, Simone Casellina, and Gregorio
Guidi. 2012. Inside the labyrinth of Basel risk-
weighted assets: how not to get lost. Number 132
in Questioni di Economia e Finanza. Banca d’Italia.
Retrieved September 20th, 2014, from http://
www.bancaditalia.it/pubblicazioni/
qef/2012-0132/QEF_132.pdf.
Council of the EU. 2013. Council Regulation (EU)
1024/2013 of 15 October 2013 conferring specific
tasks on the European Central Bank concerning poli-
cies relating to the prudential supervision of credit
institutions. Official Journal of the European Union,
L287:63–89.
European Banking Authority. 2014. Risk As-
sessment of the European Banking System
- June 2014, 6. Retrieved July 27th, 2014,
from https://www.eba.europa.eu/
documents/10180/556730/EBA+Risk+
Assessment+Report+June+2014.pdf/.
Sven S. Groth and Jan Muntermann. 2011. An intra-
day market risk management approach based on tex-
tual analysis. Decision Support Systems, 50(4):680–
691.
Petr H´ajek and Vladimir Olej. 2013. Evaluating Sen-
timent in Annual Reports for Financial Distress Pre-
diction Using Neural Networks and Support Vector
Machines. In Lazaros Iliadis, Harris Papadopoulos,
and Chrisina Jayne, editors, Engineering Applica-
tions of Neural Networks, volume 384 of Communi-
cations in Computer and Information Science, pages
1–10. Springer Berlin Heidelberg.
Dermot Hodson and Lucia Quaglia. 2009. Euro-
pean Perspectives on the Global Financial Crisis:
Introduction. Journal of Common Market Studies,
47(5):939–953.
Colm Kearney and Sha Liu. 2014. Textual sen-
timent in finance: A survey of methods and
models. International Review of Financial Analysis,
33(2014):171–185. Retrieved May 26th, 2014,
from http://papers.ssrn.com/sol3/
papers.cfm?abstract_id=2213801.
Shimon Kogan, Dimitry Levin, Bryan R. Routledge,
Jacob S. Sagi, and Noah A. Smith. 2009. Predict-
ing Risk from Financial Reports with Regression.
In Proceedings of Human Language Technologies:
The 2009 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, pages 272–280. Association for Computa-
tional Linguistics.
Tim Loughran and Bill McDonald. 2011. When Is a
Liability Not a Liability? Textual Analysis, Dictio-
naries, and 10-Ks. Journal of Finance, 66(1):35–65,
02.
Christopher D. Manning and Hinrich Sch¨utze. 1999.
Foundations of Statistical Natural Language Pro-
cessing. MIT Press, Cambridge, MA, USA.
Clemens Nopp. 2015. Risk Sentiment Analysis in
Banking Supervision. Master’s thesis, Vienna Uni-
versity of Technology.
Livia Polanyi and Annie Zaenen. 2006. Contextual
valence shifters. In JamesG. Shanahan, Yan Qu, and
Janyce Wiebe, editors, Computing Attitude and Af-
fect in Text: Theory and Applications, volume 20
of The Information Retrieval Series, pages 1–10.
Springer Netherlands.
Gerard Salton and Christopher Buckley. 1988.
Term-weighting Approaches in Automatic Text Re-
trieval. Information Processing and Management,
24(5):513–523, August.
Ming-Feng Tsai and Chuan-Ju Wang. 2013. Risk
Ranking from Financial Reports. In Proceedings of
the 35th European Conference on Advances in Infor-
mation Retrieval, pages 804–807. Springer-Verlag.
</reference>
<page confidence="0.862763">
600
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.569420">
<title confidence="0.99994">Detecting Risks in the Banking System by Sentiment Analysis</title>
<author confidence="0.994961">Clemens Nopp Allan Hanbury</author>
<affiliation confidence="0.755129">TU Wien Institute of Software Technology</affiliation>
<title confidence="0.844316">Interactive Systems</title>
<author confidence="0.866063">TU Wien</author>
<email confidence="0.991241">hanbury@ifs.tuwien.ac.at</email>
<abstract confidence="0.997755">In November 2014, the European Central Bank (ECB) started to directly supervise the largest banks in the Eurozone via the Single Supervisory Mechanism (SSM). While supervisory risk assessments are usually based on quantitative data and surveys, this work explores analysis capable of measuring a bank’s attitude and opinions towards risk by analyzing text data. For realizing this study, a collection consisting of more than 500 CEO letters and outlook sections extracted from bank annual reports is built up. Based on these data, two distinct experiments are conducted. The evaluations find promising opportunities, but also limitations for risk sentiment analysis in banking supervision. At the level of individual banks, predictions are relatively inaccurate. In contrast, the analysis of aggregated figures revealed strong and significant correlations between uncertainty or negativity in textual disclosures and the quantitative risk indicator’s future evolution. Risk sentiment analysis should therefore rather be used for macroprudential analyses than for assessments of individual banks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Charu C Aggarwal</author>
<author>Cheng Xiang Zhai</author>
</authors>
<title>A Survey of Text Classification Algorithms. In</title>
<date>2012</date>
<booktitle>Mining Text Data,</booktitle>
<pages>163--222</pages>
<editor>Charu C. Aggarwal and Cheng Xiang Zhai, editors,</editor>
<publisher>Springer Science+Business Media.</publisher>
<contexts>
<context position="21085" citStr="Aggarwal and Zhai, 2012" startWordPosition="3447" endWordPosition="3450">s to identify those features which have the highest discriminatory power in a classification problem. It measures the impurity of a dataset, i.e. its entropy. If a feature is able to reduce the entropy in a data set by a large amount, its information gain is high. Such features have a relatively high ability to predict the corresponding class. For calculating the information gain, one has to compute the entropies given the presence or absence of a feature in a data set and subtract the results from the entropy 4This affected 17 % of the data points in the sample. 595 of the original data set (Aggarwal and Zhai, 2012, p. 169). Classification. The outcome of the previous steps is a set of document vectors with associated class labels. With these data, the classification algorithms Naive Bayes (NB) and Support Vector Machine (SVM) are trained. The latter is used in its basic version, i.e. with a linear kernel. The performance measures are determined by employing 10-fold cross validation, which helps to avoid problems like overfitting. While Naive Bayes works without parameters, the linear SVM depends on the parameter C. Its optimal value of 111 was determined by conducting an automated grid search. 5 Evalua</context>
</contexts>
<marker>Aggarwal, Zhai, 2012</marker>
<rawString>Charu C. Aggarwal and Cheng Xiang Zhai. 2012. A Survey of Text Classification Algorithms. In Charu C. Aggarwal and Cheng Xiang Zhai, editors, Mining Text Data, pages 163–222. Springer Science+Business Media.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joel Amernic</author>
<author>Russel Craig</author>
<author>Dennis Tourish</author>
</authors>
<title>Measuring and Assessing Tone at the Top Using Annual Report CEO Letters. Institute of Chartered Accountants of Scotland,</title>
<date>2010</date>
<location>Edinburgh. Retrieved</location>
<note>from http://eprints.port.ac.uk/12648/ 1/CRAIG_2010_pub_Bk_Measuring_and_ assessing_tone_at_the_top_using_ annual_report_CEO_letters.pdf.</note>
<contexts>
<context position="11423" citStr="Amernic et al. (2010)" startWordPosition="1816" endWordPosition="1819">blicly accessible, (2) available for every analyzed bank, and (3) published at least annually. In addition, for this study, the documents need to be (4) written in the English language, (5) directly published by the bank, and (6) contain forward-looking and subjective information about the bank’s attitude and expectations towards risk. These criteria are best fulfilled by two types of document published in the banks’ annual reports, namely CEO letters and outlook sections. The former are carefully crafted documents which contain valuable information about the management’s opinions about risk. Amernic et al. (2010) recognize in their study from 2010 that the word choice of managers strongly influences companies, and CEO letters are a way for communicating their attitudes and values. Outlook sections are usually a part of the management report, which is a textual summary of the bank’s results, its business environment, and regulatory as well as internal developments. In their outlook on the next year, banks write about the expected macroeconomic environment, management guidelines, and priorities for the next period. These documents might be less subjective compared to CEO letters, but they are usually mo</context>
</contexts>
<marker>Amernic, Craig, Tourish, 2010</marker>
<rawString>Joel Amernic, Russel Craig, and Dennis Tourish. 2010. Measuring and Assessing Tone at the Top Using Annual Report CEO Letters. Institute of Chartered Accountants of Scotland, Edinburgh. Retrieved March 28th, 2014, from http://eprints.port.ac.uk/12648/ 1/CRAIG_2010_pub_Bk_Measuring_and_ assessing_tone_at_the_top_using_ annual_report_CEO_letters.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo¨el Bessis</author>
</authors>
<title>Risk Management in Banking.</title>
<date>2002</date>
<publisher>John Wiley &amp; Sons Ltd,</publisher>
<location>Chichester, United</location>
<note>Kingdom, 2nd edition.</note>
<marker>Jo¨el Bessis, 2002</marker>
<rawString>Jo¨el Bessis. 2002. Risk Management in Banking. John Wiley &amp; Sons Ltd, Chichester, United Kingdom, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francesco Cannata</author>
<author>Simone Casellina</author>
<author>Gregorio Guidi</author>
</authors>
<title>Inside the labyrinth of Basel riskweighted assets: how not to get lost.</title>
<date>2012</date>
<journal>Number</journal>
<booktitle>in Questioni di Economia e Finanza. Banca d’Italia. Retrieved</booktitle>
<volume>132</volume>
<pages>2012--0132</pages>
<note>from http:// www.bancaditalia.it/pubblicazioni/</note>
<contexts>
<context position="9885" citStr="Cannata et al. (2012" startWordPosition="1557" endWordPosition="1560">east annually, and (4) comparable among the different banks. A comparison of several quantitative risk indicators based on expert interviews revealed that only the Tier 1 Capital Ratio (T1) fulfills all criteria. The T1 is one of the most important ratios based on risk-weighted amount of the bank’s assets. In particular, it refers to the bank’s Tier 1 capital as a percentage of its risk-weighted assets: Tier 1 Capital Tier 1 Capital Ratio = Risk-Weighted Assets (1) Tier 1 capital is considered as the best form of bank capital and has to fulfill several criteria making it relatively secure. As Cannata et al. (2012, p. 12) put it, this ratio “measures the ability of the bank to absorb losses”. If the T1 is high, the bank acts conservatively and with a high risk buffer. A high ratio can be achieved by either increasing the Tier 1 capital or by reducing the amount of riskweighted assets, i.e. reducing the amount of total assets or replacing them with safer ones. The T1 also played a major role during the 2014 EU-wide banking stress test, which was an important part of the preparation phase for the Single Supervisory Mechanism. The stress test had the purpose to assess the resilience of large EU banks in d</context>
</contexts>
<marker>Cannata, Casellina, Guidi, 2012</marker>
<rawString>Francesco Cannata, Simone Casellina, and Gregorio Guidi. 2012. Inside the labyrinth of Basel riskweighted assets: how not to get lost. Number 132 in Questioni di Economia e Finanza. Banca d’Italia. Retrieved September 20th, 2014, from http:// www.bancaditalia.it/pubblicazioni/ qef/2012-0132/QEF_132.pdf.</rawString>
</citation>
<citation valid="true">
<title>the EU.</title>
<date>2013</date>
<journal>Official Journal of the European</journal>
<institution>Council of</institution>
<location>Union, L287:63–89.</location>
<contexts>
<context position="6225" citStr="(2013)" startWordPosition="970" endWordPosition="970"> number of studies which aim to identify risks by means of text mining. A common question tackled by researchers is whether corporate disclosures drive stock price volatilities or future earnings of the respective firm (Groth and Muntermann, 2011; Kogan et al., 2009; Tsai and Wang, 2013). Hence, they focus on the risk an investor takes if he or she buys stocks of a company. Generally spoken, these studies find significant correlations between sentiment extracted from corporate disclosures and future volatilities. Other papers deal with financial distress prediction, for example Hajek and Olej (2013). As a baseline, they classify companies based on financial indicators. It turned out that the inclusion of sentiment indicators improved financial distress prediction. Among the text data sources for these studies are mainly annual reports, but also news stories or earning calls transcripts1. Kogan et al. (2009) exclude irrelevant information from the annual reports by focusing on a section which contains important forward-looking content. In the related studies, authors work with similar approaches for extracting sentiment from texts. Linguistic preprocessing generally involves tokenization,</context>
<context position="7904" citStr="(2013)" startWordPosition="1232" endWordPosition="1232">can be reused for this work. With regards to the selection of appropriate data sources, it can be concluded that analyzing annual reports is very popular in this field of research. Hence, these data should also be considered for the experiments of this study. In contrast to the majority of the related papers, we only use specific sections of the annual reports, namely CEO letters and outlook sections (see Section 3). Regarding the machine learning algorithms and the incorporation of quantitative indicators, the approaches of Groth and Muntermann (2011), Kogan et al. (2009), and Hajek and Olej (2013) are a good basis for the experiments of this study. All of them define the document labels based on suitable quantitative indicators. For labeling, the related studies consider the fact that text data are forwardlooking, but quantitative indicators reflect the past. Hence, the indicators are taken from one period after publication of the text data. The labeled data are then used for training machine learning algorithms. Since the focus of our work lies on banks, we make use of a specific quantitative risk indicator which is not employed by related studies. In the following section, we introdu</context>
</contexts>
<marker>2013</marker>
<rawString>Council of the EU. 2013. Council Regulation (EU) 1024/2013 of 15 October 2013 conferring specific tasks on the European Central Bank concerning policies relating to the prudential supervision of credit institutions. Official Journal of the European Union, L287:63–89.</rawString>
</citation>
<citation valid="true">
<authors>
<author>European Banking Authority</author>
</authors>
<title>Risk Assessment of the European Banking System -</title>
<date>2014</date>
<note>6. Retrieved</note>
<contexts>
<context position="3057" citStr="Authority, 2014" startWordPosition="473" endWordPosition="474">rvision, the Single Supervisory Mechanism (SSM). Its goal is to “promote long-term safety and soundness of credit institutions and the stability of the financial system within the Union and each Member State [...]” (Council of the EU, 2013, p. 72). For supervising over 120 of the largest banks in the Eurozone, the SSM utilizes a range of information sources in order to detect vulnerabilities and risks. The sources include mainly backwardlooking quantitative Key Risk Indicators (KRIs), which are complemented with surveys in order to include forward-looking information as well (European Banking Authority, 2014). However, another source of information seems to be largely untapped, namely textual data published by the banks. Publications like periodic reports, press releases, and news published for investors also contain forward-looking information. Analyzing this readily available data would be more cost-efficient in comparison to traditional approaches like surveys. It could provide answers to questions like: what does official communication by banks reveal about their expectations and attitudes towards risk? In this paper, we present a novel application of sentiment analysis for exploring attitudes</context>
</contexts>
<marker>Authority, 2014</marker>
<rawString>European Banking Authority. 2014. Risk Assessment of the European Banking System - June 2014, 6. Retrieved July 27th, 2014, from https://www.eba.europa.eu/ documents/10180/556730/EBA+Risk+ Assessment+Report+June+2014.pdf/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sven S Groth</author>
<author>Jan Muntermann</author>
</authors>
<title>An intraday market risk management approach based on textual analysis. Decision Support Systems,</title>
<date>2011</date>
<volume>50</volume>
<issue>4</issue>
<pages>691</pages>
<contexts>
<context position="5865" citStr="Groth and Muntermann, 2011" startWordPosition="907" endWordPosition="910">he following section introduces the chosen sources for text data and quantitative figures. Afterwards, we give an overview on the chosen methodologies and evaluate the experimental results. The last section concludes. 2 Related Work Sentiment analysis in general and its application in the financial domain in particular gained a lot of interest within the last decade. There is a number of studies which aim to identify risks by means of text mining. A common question tackled by researchers is whether corporate disclosures drive stock price volatilities or future earnings of the respective firm (Groth and Muntermann, 2011; Kogan et al., 2009; Tsai and Wang, 2013). Hence, they focus on the risk an investor takes if he or she buys stocks of a company. Generally spoken, these studies find significant correlations between sentiment extracted from corporate disclosures and future volatilities. Other papers deal with financial distress prediction, for example Hajek and Olej (2013). As a baseline, they classify companies based on financial indicators. It turned out that the inclusion of sentiment indicators improved financial distress prediction. Among the text data sources for these studies are mainly annual reports</context>
<context position="7856" citStr="Groth and Muntermann (2011)" startWordPosition="1219" endWordPosition="1222">banking industry, parts of their processing pipelines and approaches can be reused for this work. With regards to the selection of appropriate data sources, it can be concluded that analyzing annual reports is very popular in this field of research. Hence, these data should also be considered for the experiments of this study. In contrast to the majority of the related papers, we only use specific sections of the annual reports, namely CEO letters and outlook sections (see Section 3). Regarding the machine learning algorithms and the incorporation of quantitative indicators, the approaches of Groth and Muntermann (2011), Kogan et al. (2009), and Hajek and Olej (2013) are a good basis for the experiments of this study. All of them define the document labels based on suitable quantitative indicators. For labeling, the related studies consider the fact that text data are forwardlooking, but quantitative indicators reflect the past. Hence, the indicators are taken from one period after publication of the text data. The labeled data are then used for training machine learning algorithms. Since the focus of our work lies on banks, we make use of a specific quantitative risk indicator which is not employed by relat</context>
</contexts>
<marker>Groth, Muntermann, 2011</marker>
<rawString>Sven S. Groth and Jan Muntermann. 2011. An intraday market risk management approach based on textual analysis. Decision Support Systems, 50(4):680– 691.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Petr H´ajek</author>
<author>Vladimir Olej</author>
</authors>
<title>Evaluating Sentiment in Annual Reports for Financial Distress Prediction Using Neural Networks and Support Vector Machines.</title>
<date>2013</date>
<booktitle>Engineering Applications of Neural Networks, volume 384 of Communications in Computer and Information Science,</booktitle>
<pages>1--10</pages>
<editor>In Lazaros Iliadis, Harris Papadopoulos, and Chrisina Jayne, editors,</editor>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<marker>H´ajek, Olej, 2013</marker>
<rawString>Petr H´ajek and Vladimir Olej. 2013. Evaluating Sentiment in Annual Reports for Financial Distress Prediction Using Neural Networks and Support Vector Machines. In Lazaros Iliadis, Harris Papadopoulos, and Chrisina Jayne, editors, Engineering Applications of Neural Networks, volume 384 of Communications in Computer and Information Science, pages 1–10. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dermot Hodson</author>
<author>Lucia Quaglia</author>
</authors>
<title>European Perspectives on the Global Financial Crisis: Introduction.</title>
<date>2009</date>
<journal>Journal of Common Market Studies,</journal>
<volume>47</volume>
<issue>5</issue>
<contexts>
<context position="2221" citStr="Hodson and Quaglia, 2009" startWordPosition="335" endWordPosition="338">gs. Due to the tight interconnectedness of the financial system, problems quickly propagated in the global banking system. Governments had to bail out important institutions like Northern Rock, but such solutions could not be provided for every troubled bank. In September 2008, the large investment bank Lehman Brothers had to file bankruptcy. In the aftermath of this event, further banks had to be rescued in order to stabilize the financial system. This deep financial crisis highlighted the necessity of better financial regulation as well as more effective financial supervision in the future (Hodson and Quaglia, 2009). As a reaction to the crisis and its severe economic consequences, EU institutions decided to build up an European Banking Union (EBU). The EBU consists of three pillars, one of them being a new system of financial supervision, the Single Supervisory Mechanism (SSM). Its goal is to “promote long-term safety and soundness of credit institutions and the stability of the financial system within the Union and each Member State [...]” (Council of the EU, 2013, p. 72). For supervising over 120 of the largest banks in the Eurozone, the SSM utilizes a range of information sources in order to detect v</context>
</contexts>
<marker>Hodson, Quaglia, 2009</marker>
<rawString>Dermot Hodson and Lucia Quaglia. 2009. European Perspectives on the Global Financial Crisis: Introduction. Journal of Common Market Studies, 47(5):939–953.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colm Kearney</author>
<author>Sha Liu</author>
</authors>
<title>Textual sentiment in finance: A survey of methods and models.</title>
<date>2014</date>
<journal>International Review of Financial Analysis,</journal>
<volume>33</volume>
<issue>2014</issue>
<note>from http://papers.ssrn.com/sol3/ papers.cfm?abstract_id=2213801.</note>
<contexts>
<context position="15889" citStr="Kearney and Liu (2014)" startWordPosition="2553" endWordPosition="2556">Sentiment Tagging. In the first step of the analysis, sentiment words in the textual data are tagged. In particular, this study works with negative words (Fin-Neg), positive words (Fin-Pos), and words related to uncertainty (Fin-Unc). All of these word lists are provided by Loughran and McDonald (2011). Such topic-specific word lists are necessary because many words bear a different sentiment if used in a financial context: according to Loughran and McDonald (2011), almost three quarters (73.8 %) of typically negative words cannot be considered as negative when they appear in financial texts. Kearney and Liu (2014) give the examples tax and liability. These words appear in the Harvard IV Negative Word List (H4N), but are neutral when used in a financial context, e.g. in an annual report. Table 2 lists some examples for sentiment words in the financial context. Positive efficient, stabilized, vibrant Negative closure, postpone, threat Uncertainty approximately, might, volatility Table 2: Examples for opinion words in the financial context (Loughran and McDonald, 2011). Term Weighting. All terms in a document are normalized by 1 Nj = (2) / V Em0(GiLi,j)2. This equation is based on Salton and Buckley (1988</context>
</contexts>
<marker>Kearney, Liu, 2014</marker>
<rawString>Colm Kearney and Sha Liu. 2014. Textual sentiment in finance: A survey of methods and models. International Review of Financial Analysis, 33(2014):171–185. Retrieved May 26th, 2014, from http://papers.ssrn.com/sol3/ papers.cfm?abstract_id=2213801.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shimon Kogan</author>
<author>Dimitry Levin</author>
<author>Bryan R Routledge</author>
<author>Jacob S Sagi</author>
<author>Noah A Smith</author>
</authors>
<title>Predicting Risk from Financial Reports with Regression.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>272--280</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5885" citStr="Kogan et al., 2009" startWordPosition="911" endWordPosition="915">ces the chosen sources for text data and quantitative figures. Afterwards, we give an overview on the chosen methodologies and evaluate the experimental results. The last section concludes. 2 Related Work Sentiment analysis in general and its application in the financial domain in particular gained a lot of interest within the last decade. There is a number of studies which aim to identify risks by means of text mining. A common question tackled by researchers is whether corporate disclosures drive stock price volatilities or future earnings of the respective firm (Groth and Muntermann, 2011; Kogan et al., 2009; Tsai and Wang, 2013). Hence, they focus on the risk an investor takes if he or she buys stocks of a company. Generally spoken, these studies find significant correlations between sentiment extracted from corporate disclosures and future volatilities. Other papers deal with financial distress prediction, for example Hajek and Olej (2013). As a baseline, they classify companies based on financial indicators. It turned out that the inclusion of sentiment indicators improved financial distress prediction. Among the text data sources for these studies are mainly annual reports, but also news stor</context>
<context position="7877" citStr="Kogan et al. (2009)" startWordPosition="1223" endWordPosition="1227">eir processing pipelines and approaches can be reused for this work. With regards to the selection of appropriate data sources, it can be concluded that analyzing annual reports is very popular in this field of research. Hence, these data should also be considered for the experiments of this study. In contrast to the majority of the related papers, we only use specific sections of the annual reports, namely CEO letters and outlook sections (see Section 3). Regarding the machine learning algorithms and the incorporation of quantitative indicators, the approaches of Groth and Muntermann (2011), Kogan et al. (2009), and Hajek and Olej (2013) are a good basis for the experiments of this study. All of them define the document labels based on suitable quantitative indicators. For labeling, the related studies consider the fact that text data are forwardlooking, but quantitative indicators reflect the past. Hence, the indicators are taken from one period after publication of the text data. The labeled data are then used for training machine learning algorithms. Since the focus of our work lies on banks, we make use of a specific quantitative risk indicator which is not employed by related studies. In the fo</context>
</contexts>
<marker>Kogan, Levin, Routledge, Sagi, Smith, 2009</marker>
<rawString>Shimon Kogan, Dimitry Levin, Bryan R. Routledge, Jacob S. Sagi, and Noah A. Smith. 2009. Predicting Risk from Financial Reports with Regression. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 272–280. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Loughran</author>
<author>Bill McDonald</author>
</authors>
<title>When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks.</title>
<date>2011</date>
<journal>Journal of Finance,</journal>
<volume>66</volume>
<issue>1</issue>
<pages>02</pages>
<contexts>
<context position="15570" citStr="Loughran and McDonald (2011)" startWordPosition="2503" endWordPosition="2506">ve of this experiment is to show how the language of forward-looking disclosures by European banks evolved within the last decade. The workflow consists of the following steps: (1) pre-processing the collected data, (2) the actual sentiment analysis which derives the scores, (3) data consolidation, and (4) data evaluation. Sentiment Tagging. In the first step of the analysis, sentiment words in the textual data are tagged. In particular, this study works with negative words (Fin-Neg), positive words (Fin-Pos), and words related to uncertainty (Fin-Unc). All of these word lists are provided by Loughran and McDonald (2011). Such topic-specific word lists are necessary because many words bear a different sentiment if used in a financial context: according to Loughran and McDonald (2011), almost three quarters (73.8 %) of typically negative words cannot be considered as negative when they appear in financial texts. Kearney and Liu (2014) give the examples tax and liability. These words appear in the Harvard IV Negative Word List (H4N), but are neutral when used in a financial context, e.g. in an annual report. Table 2 lists some examples for sentiment words in the financial context. Positive efficient, stabilized</context>
</contexts>
<marker>Loughran, McDonald, 2011</marker>
<rawString>Tim Loughran and Bill McDonald. 2011. When Is a Liability Not a Liability? Textual Analysis, Dictionaries, and 10-Ks. Journal of Finance, 66(1):35–65, 02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clemens Nopp</author>
</authors>
<title>Risk Sentiment Analysis in Banking Supervision. Master’s thesis,</title>
<date>2015</date>
<institution>Vienna University of Technology.</institution>
<contexts>
<context position="5127" citStr="Nopp, 2015" startWordPosition="789" endWordPosition="790">ent refers to current or future problems, and too positive sentiment could represent overconfidence. We find that sentiment scores reflect not only the financial crisis, but also other major economic events within the last decade. In addition, we test for correlations between the sentiment scores and a popular quantitative risk indicator. It turns out that aggregated risk sentiment in forward-looking documents is a leading indicator for the actual risk figures, so it can be used within predictive models. The remainder of this paper, which is based on the Master’s thesis of one of the authors (Nopp, 2015), is organized as follows: first, we give an overview on related work in the field of risk sentiment analysis. The following section introduces the chosen sources for text data and quantitative figures. Afterwards, we give an overview on the chosen methodologies and evaluate the experimental results. The last section concludes. 2 Related Work Sentiment analysis in general and its application in the financial domain in particular gained a lot of interest within the last decade. There is a number of studies which aim to identify risks by means of text mining. A common question tackled by researc</context>
</contexts>
<marker>Nopp, 2015</marker>
<rawString>Clemens Nopp. 2015. Risk Sentiment Analysis in Banking Supervision. Master’s thesis, Vienna University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Livia Polanyi</author>
<author>Annie Zaenen</author>
</authors>
<title>Contextual valence shifters.</title>
<date>2006</date>
<booktitle>Computing Attitude and Affect in Text: Theory and Applications, volume 20 of The Information Retrieval Series,</booktitle>
<pages>1--10</pages>
<editor>In JamesG. Shanahan, Yan Qu, and Janyce Wiebe, editors,</editor>
<publisher>Springer Netherlands.</publisher>
<contexts>
<context position="17220" citStr="Polanyi and Zaenen (2006)" startWordPosition="2787" endWordPosition="2791">ight of term i in document j. An established method for the latter is given by the following formula (Manning and Sch¨utze, 1999, p. 543): � 1 + log(tfi,j) if tfi,j ≥ 1 Li,j =(3) 0 otherwise 594 The term frequency is denoted as tfi,j. The most popular global weight is the inverse document frequency (IDF). In rl Gi = log l Ndfi I , (4 ) the total number of documents is denoted by N, and dfi is the number of documents where term i occurs at least once (Salton and Buckley, 1988). Valence Shifting. In order to account for negated sentiment words, the simple negation handling algorithm proposed by Polanyi and Zaenen (2006) is implemented. If one of the three direct predecessors of a sentiment word is a negation word3, its sentiment score will be negated. This is done by assigning −1 to the valence shifter variable vi of term i. If there is no negation word among the predecessors, vi is set to 1. Calculating Sentiment Scores. The documentlevel sentiment scores are calculated for three sentiment classes, namely uncertainty, positivity, and negativity. In �sc,j = Li,jGiNjvi, (5) i∈c the term-level sentiment score is represented by the product of the term weights Li,j and Gi, the normalization factor Nj, and the va</context>
</contexts>
<marker>Polanyi, Zaenen, 2006</marker>
<rawString>Livia Polanyi and Annie Zaenen. 2006. Contextual valence shifters. In JamesG. Shanahan, Yan Qu, and Janyce Wiebe, editors, Computing Attitude and Affect in Text: Theory and Applications, volume 20 of The Information Retrieval Series, pages 1–10. Springer Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Christopher Buckley</author>
</authors>
<date>1988</date>
<booktitle>Term-weighting Approaches in Automatic Text Retrieval. Information Processing and Management,</booktitle>
<volume>24</volume>
<issue>5</issue>
<contexts>
<context position="16490" citStr="Salton and Buckley (1988)" startWordPosition="2649" endWordPosition="2653">. Kearney and Liu (2014) give the examples tax and liability. These words appear in the Harvard IV Negative Word List (H4N), but are neutral when used in a financial context, e.g. in an annual report. Table 2 lists some examples for sentiment words in the financial context. Positive efficient, stabilized, vibrant Negative closure, postpone, threat Uncertainty approximately, might, volatility Table 2: Examples for opinion words in the financial context (Loughran and McDonald, 2011). Term Weighting. All terms in a document are normalized by 1 Nj = (2) / V Em0(GiLi,j)2. This equation is based on Salton and Buckley (1988) and accounts for documents of different lengths. Gi is the global weight of term i and Li,j the local weight of term i in document j. An established method for the latter is given by the following formula (Manning and Sch¨utze, 1999, p. 543): � 1 + log(tfi,j) if tfi,j ≥ 1 Li,j =(3) 0 otherwise 594 The term frequency is denoted as tfi,j. The most popular global weight is the inverse document frequency (IDF). In rl Gi = log l Ndfi I , (4 ) the total number of documents is denoted by N, and dfi is the number of documents where term i occurs at least once (Salton and Buckley, 1988). Valence Shift</context>
</contexts>
<marker>Salton, Buckley, 1988</marker>
<rawString>Gerard Salton and Christopher Buckley. 1988. Term-weighting Approaches in Automatic Text Retrieval. Information Processing and Management, 24(5):513–523, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ming-Feng Tsai</author>
<author>Chuan-Ju Wang</author>
</authors>
<title>Risk Ranking from Financial Reports.</title>
<date>2013</date>
<booktitle>In Proceedings of the 35th European Conference on Advances in Information Retrieval,</booktitle>
<pages>804--807</pages>
<publisher>Springer-Verlag.</publisher>
<contexts>
<context position="5907" citStr="Tsai and Wang, 2013" startWordPosition="916" endWordPosition="919">es for text data and quantitative figures. Afterwards, we give an overview on the chosen methodologies and evaluate the experimental results. The last section concludes. 2 Related Work Sentiment analysis in general and its application in the financial domain in particular gained a lot of interest within the last decade. There is a number of studies which aim to identify risks by means of text mining. A common question tackled by researchers is whether corporate disclosures drive stock price volatilities or future earnings of the respective firm (Groth and Muntermann, 2011; Kogan et al., 2009; Tsai and Wang, 2013). Hence, they focus on the risk an investor takes if he or she buys stocks of a company. Generally spoken, these studies find significant correlations between sentiment extracted from corporate disclosures and future volatilities. Other papers deal with financial distress prediction, for example Hajek and Olej (2013). As a baseline, they classify companies based on financial indicators. It turned out that the inclusion of sentiment indicators improved financial distress prediction. Among the text data sources for these studies are mainly annual reports, but also news stories or earning calls t</context>
</contexts>
<marker>Tsai, Wang, 2013</marker>
<rawString>Ming-Feng Tsai and Chuan-Ju Wang. 2013. Risk Ranking from Financial Reports. In Proceedings of the 35th European Conference on Advances in Information Retrieval, pages 804–807. Springer-Verlag.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>