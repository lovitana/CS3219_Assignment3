<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000187">
<title confidence="0.992909">
Measuring Prerequisite Relations Among Concepts
</title>
<author confidence="0.996817">
Chen Liang † Zhaohui Wu$ Wenyi Huang† C. Lee Giles†
</author>
<affiliation confidence="0.981557333333333">
†Information Sciences and Technology
$Computer Science and Engineering
The Pennsylvania State University
</affiliation>
<address confidence="0.519292">
University Park, PA
</address>
<email confidence="0.99597">
cul226@ist.psu.edu zzw109@psu.edu {wzh112,giles}@ist.psu.edu
</email>
<sectionHeader confidence="0.982854" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999948733333333">
A prerequisite relation describes a basic
relation among concepts in cognition, ed-
ucation and other areas. However, as a se-
mantic relation, it has not been well stud-
ied in computational linguistics. We inves-
tigate the problem of measuring prereq-
uisite relations among concepts and pro-
pose a simple link-based metric, namely
reference distance (RefD), that effectively
models the relation by measuring how dif-
ferently two concepts refer to each other.
Evaluations on two datasets that include
seven domains show that our single metric
based method outperforms existing super-
vised learning based methods.
</bodyText>
<sectionHeader confidence="0.995138" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999128175438597">
What should one know/learn before starting to
learn a new area such as “deep learning”? A key
for answering this question is to understand what
a prerequisite is. A prerequisite is usually a con-
cept or requirement before one can proceed to a
following one. And the prerequisite relation exists
as a natural dependency among concepts in cog-
nitive processes when people learn, organize, ap-
ply, and generate knowledge (Laurence and Mar-
golis, 1999). While there has been serious effort
in understanding prerequisite relations in learning
and education (Bergan and Jeska, 1980; Ohland
et al., 2004; Vuong et al., 2011), it has not been
well studied as a semantic relation in computa-
tional linguistics, where researchers focus more
on lexical relations among lexical items (Miller,
1995) and fine-grained entity relations in knowl-
edge bases (Mintz et al., 2009).
Instead of treating it as a relation extraction or
link prediction problem using traditional machine
learning approaches (Talukdar and Cohen, 2012;
Yang et al., 2015), we seek to better understand
prerequisite relations from a perspective of cog-
nitive semantics (Croft and Cruse, 2004). Par-
tially motivated by the theory of frame seman-
tics (Fillmore, 2006), or, to understand a concept,
one needs to understand all the related concepts
in its “frame”, we propose a metric that measures
prerequisite relations based on a simple observa-
tion of human learning. When learning concept A,
if one needs to refer to concept B for a lot of A’s
related concepts but not vice versa, B would more
likely be a prerequisite of A than A of B. Specif-
ically, we model a concept in a vector space using
its related concepts and measure the prerequisite
relation between two concepts by computing how
differently the two’s related concepts refer to each
other, or reference distance (RefD).
Our simple metric RefD successfully reflects
some properties of the prerequisite relation such
as asymmetry and irreflexivity; and can be prop-
erly implemented for various applications using
different concept models. We present an imple-
mentation of the metric using Wikipedia by lever-
aging the links as reference relations among con-
cepts; and present a scalable prerequisite dataset
construction method by crawling public available
university course prerequisite websites and map-
ping them to Wikipedia concepts. Experimental
results on two datasets that include seven domains
demonstrate its effectiveness and robustness on
measuring prerequisites. Surprisingly, our single
metric based approach significantly outperforms
baselines which use more sophisticated supervised
learning. All the datasets are publicly available
upon request.
Our main contributions include:
</bodyText>
<listItem confidence="0.999598">
• A novel metric to measure the prerequisite re-
lation among concepts that outperforms ex-
isting supervised learning baselines.
• A new dataset containing 1336 concept pairs
in Computer Science and Math.
</listItem>
<page confidence="0.315287">
1668
</page>
<note confidence="0.828676">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 1668–1674,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.567234">
between a concept pair, RefD is expected to satisfy
the following constraints:
</bodyText>
<figure confidence="0.998352923076923">
Data
mining
B
A Statistics
Machine
learning
Cluster
analysis
Algorithm
Logic
Pseudocode
Programming
language
</figure>
<figureCaption confidence="0.698882666666667">
Figure 1: An example of the reference structure RefD(A,B)∈ ⎧ (0,1], if B is a prerequisite of A
for two concepts (“Data mining” and “Algorithm”) ⎨⎪⎪⎪ ⎪ [−0, 0], if no prerequisite relation
with a prerequisite relation. ⎪⎪⎪⎪⎩ [−1, −0), if A is a prerequisite of B
</figureCaption>
<sectionHeader confidence="0.848914" genericHeader="method">
2 Measuring Prerequisite Relations
</sectionHeader>
<bodyText confidence="0.99996964">
Our goal is to design a function f : C2 → R that
maps a concept pair (A, B) to a real value that
measures the extent to which A requires B as a
prerequisite, where C is the concept space. How
should a concept be represented in C? According
to the theory of frame semantics, one cannot un-
derstand a concept without access to all essential
knowledge related to it. Such knowledge can be
actually viewed as a set of related concepts. Thus,
a concept could be represented by its related con-
cepts in C. For example, the concept “deep learn-
ing” may be represented by concepts such as “ma-
chine learning”, “artificial neural network”, etc.
Compared to prerequisites, a more common and
observable relation among concepts is a reference,
which widely exists in various forms such as hy-
perlinks, citations, notes, etc. Although a single
evidence of reference does not indicate a prereq-
uisite relation, a large number of such evidences
might make a difference. For example, if most re-
lated concepts of A refer to B but few related con-
cepts of B refer to A, then B is more likely to be
a prerequisite of A, as shown in Figure 1. In or-
der to measure prerequisite relations, we propose
a reference distance (RefD), which is defined as
</bodyText>
<equation confidence="0.99952">
�k i=1 r(ci,B)·w(ci,A)
RefD(A, B) = −
Eki=1 w(ci,A)
Ek
i=1 r(ci,A)·w(ci,B)
Eki=1 w(ci,B)
</equation>
<bodyText confidence="0.995581111111111">
where C = {c1, ..., ck} is the concept space;
w(ci, A) weights the importance of ci to A; and
r(ci, A) is an indicator showing whether ci refers
to A, which could be links in Wikipedia, mentions
in books, citations in papers, etc.
RefD enables several useful properties
for the prerequisite relation: 1) normalized:
RefD(A, B) E [−1, 1]; 2) asymmetric:
RefD(A, B)+RefD(B, A)=0, which means if
A is a prerequisite of B then B is not a prereq-
uisite of A; and 3) irreflexive: RefD(A, A)=0,
which means A is not a prerequisite of itself. To
capture all three possible prerequisite relations
where 0 is a positive threshold.
Equation 1 provides a general framework to cal-
culate RefD. In practice, we need to specify the
concept space C, the weight w, and the reference
indicator function r.
</bodyText>
<sectionHeader confidence="0.970546" genericHeader="method">
3 Wikipedia-based RefD Implementation
</sectionHeader>
<bodyText confidence="0.991559166666667">
We now implement RefD using Wikipedia. As a
widely used open-access encyclopedia, Wikipedia
provides relatively up-to-date and high quality
knowledge and has been successfully utilized as
explicit concepts (Gabrilovich and Markovitch,
2007). Moreover, the rich hyperlinks created by
Wiki editors provide a natural way to calculate the
reference indicator function r.
Specifically, the concept space C consists of
all Wikipedia articles. r(c, A) represents whether
there is a link from Wiki article c to A. For
w(c, A), we experiment with two methods:
</bodyText>
<listItem confidence="0.9991445">
• EQUAL: A is represented by the concepts
linked from it (L(A)) with equal weights.
</listItem>
<equation confidence="0.983479">
�
1 if c E L(A)
w(c, A) =
0 if c E/ L(A)
</equation>
<listItem confidence="0.99964">
• TFIDF: A is represented by the concepts
linked from it with TFIDF weights.
</listItem>
<equation confidence="0.96720475">
�
tf(c, A) ∗ log N
df(c) if c E L(A)
w(c, A) = 0 if c E/ L(A)
</equation>
<bodyText confidence="0.99994725">
where tf(c, A) is the number of times c be-
ing linked from A; N is the total number of
Wikipedia articles; and df(c) is the number
of Wikipedia articles where c appears.
</bodyText>
<sectionHeader confidence="0.998714" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999970666666667">
In order to evaluate the proposed metric, we apply
it to predicting prerequisite relations in Wikipedia,
i.e., whether one article in Wikipedia is a prereq-
uisite of another article. Given a pair of concepts
(A,B), we predict whether B is a prerequisite of
A or not. Both pairs where A is a prerequisite of
</bodyText>
<equation confidence="0.77309">
(1)
</equation>
<table confidence="0.942769888888889">
1669
Dataset Domain # Pairs # Prerequisites
CrowdComp Meiosis 400 67
Public-key Cryp. 200 27
Parallel Postulate 200 25
Newton’s Laws 400 44
Global Warming 400 43
Course CS 678 108
MATH 658 75
</table>
<tableCaption confidence="0.869314">
Table 1: Statistics of CrowdComp and Course
Datasets
</tableCaption>
<table confidence="0.999922">
Domain MaxEnt† MaxEnt EQUAL TFIDF
Meiosis 51 60.2 53 55.7
Public-key Cryp. 67.1 60.3 55.1 57.7
Parallel Postulate 64.7 73.6 70.5 67.9
Newton’s Laws 53.9 57.7 63.7 64.6
Global Warming 56.8 50.0 57.4 60.1
Average 58.7 60.4 60.0* 61.2*
</table>
<tableCaption confidence="0.995527">
Table 2: Comparison of out-of-domain training
</tableCaption>
<bodyText confidence="0.98806195">
accuracies of a MaxEnt classifier and RefD using
EQUAL and TFIDF weighting. MaxEnt† is the
number reported by Talukdar et al. (2012). Max-
Ent shows the performance of our implementation.
* indicates the difference between RefD and Max-
Ent is statistically significant (p &lt; 0.01).
B and pairs where no prerequisite relation exists
will be viewed as negative examples.
RefD is tested on two datasets: CrowdComp
dataset (Talukdar and Cohen, 2012) and a Course
prerequisite dataset collected by us. We compare
RefD with a Maximum Entropy (MaxEnt) classi-
fier which exploits graph-based features such as
PageRank scores and content-based features such
as the category information, whether a title of con-
cept is mentioned in the first sentence of the other
concept, the number of times a concept is linked
from the other, etc. (Talukdar and Cohen, 2012).
All experiments use a Wikipedia dump of Dec 8,
2014.
</bodyText>
<subsectionHeader confidence="0.958332">
4.1 Results on the CrowdComp Dataset
</subsectionHeader>
<bodyText confidence="0.9653085">
The CrowdComp dataset was collected us-
ing Amazon Mechanical Turk by Talukdar et
al. (2012). It contains binary-labeled concept
pairs from five different domains, including meio-
sis, public-key cryptography, the parallel postu-
late, Newton’s laws of motion, and global warm-
ing. The label of the prerequisite relation for each
pair is assigned using majority vote. Details of the
dataset are shown in Table 1.
Following Talukdar et al. (2012), we evaluate
</bodyText>
<table confidence="0.9991426">
CS MATH
A P R F A P R F
MaxEnt 72.8 87.6 53.2 66.1 69.0 78.1 53 63.1
EQUAL 76.4* 80.4 69.9 74.7* 73.9* 78.4 67.3 71.9*
TFIDF 77.1* 82.3 69.1 75.1* 70.3* 76.3 60.1 66.7*
</table>
<tableCaption confidence="0.999038">
Table 3: Comparison of in-domain training accu-
</tableCaption>
<bodyText confidence="0.995782857142857">
racies, precision, recall, and F1 measure of Max-
Ent and RefD using EQUAL and TFIDF weight-
ing. * indicates the improvement over MaxEnt is
statistically significant (p &lt; 0.01).
different methods in a “leave one domain out”
manner, where data from one domain is used
for testing and data from other four for training.
Classes in the training and testing set are balanced
by oversampling the minority class. Table 2 lists
the accuracies of different methods. In terms of
average performance, RefD achieves comparable
average accuracy as MaxEnt. When TFIDF is
used to calculate w, RefD performs better than
MaxEnt. Also we notice that our implementation
of MaxEnt classifier achieves higher accuracy than
reported in the original paper, which may be due
to the difference between Wiki dumps used. In ad-
dition, we can see that there are large differences
in performance across different domains, which is
mainly due to two reasons. First, the coverage of
Wikipedia for different domains may vary a lot.
Some domains are more popular and thus edited
more frequently, leading to a better quality of ar-
ticles and a more complete link structure. Sec-
ond, since the ground-truth labels are collected by
crowdsourcing and there is no guarantee for work-
ers’ knowledge about a certain domain, the quality
of labels for different domains varies.
</bodyText>
<subsectionHeader confidence="0.851639">
4.2 Results on the Course Dataset
</subsectionHeader>
<bodyText confidence="0.991850666666667">
We also built a Course dataset with the help
of information available on a university’s course
website containing prerequisite relations between
courses. For example, “CS 331 Data Structures
and Algorithms” is a prerequisite for “CS 422
Data mining”. We get the prerequisite pairs by
crawling the website and linking the course to
Wikipedia using simple rules such as title match-
ing and content similarity. In order to get nega-
tive samples, we randomly sample 600 pairs using
concepts appearing in the prerequisite pairs. All
pairs are then checked by two domain experts by
removing pairs with incorrect labels. Table 1 lists
the information of the dataset.
Evaluation uses in-domain 5-fold cross-
</bodyText>
<figure confidence="0.998712444444444">
1670
Precision
0.8
0.6
0.4
0.2
1.0
0 00.2 0.4 0.6 0.8 1.0
MaxEnt (area = 0.777)
EQUAL (area = 0.810)
TFIDF (area = 0.831)
0 = 0.05
0.75
Accuracy (avg.)
0 = 0.02
0.62
0.70
0.60
0.58
0.56
0.60
0.54
0.52
0.50
−1.0 −0.5 0.0 0.5 1.0 −1.0 −0.5 0.0 0.5 1.0
0 0
(a) CrowdComp (b) Course
</figure>
<figureCaption confidence="0.9968805">
Figure 3: Average accuracy on two datasets with a
given threshold of RefD using TFIDF weighting.
</figureCaption>
<figure confidence="0.999684285714286">
Accuracy (avg.)
0.65
0.55
0.50
Recall
(a) CS
(b) MATH
</figure>
<figureCaption confidence="0.743709333333333">
Figure 2: Comparison of Precision-Recall curves
of MaxEnt and RefD (using EQUAL and TFIDF
weighting) on the Course dataset.
</figureCaption>
<bodyText confidence="0.999961535714286">
validation and classes are balanced by over-
sampling the minority class. Table 3 lists the
performance comparison of different methods on
accuracy, precision, recall and F1 score. We can
see that RefD outperforms MaxEnt in terms of
accuracy, recall, and F1 score on both CS and
MATH domain. Because MaxEnt relies on many
features but there are only limited distinct positive
samples in the dataset, it is more likely to overfit
the training data, which leads to high precision but
low recall on test set. In order to better compare
precision and recall, we plot the Precision-Recall
curves of different methods, as shown in Figure 2.
RefD shows a clear improvement in the area under
the Precision-Recall curve.
Comparing two weighting methods, we find that
TFIDF performs slightly better than EQUAL on
CS while EQUAL has higher scores than TFIDF
on MATH. Since how to compute w in RefD is
a crucial problem, our ongoing work is to ex-
plore more sophisticated semantic representations
to measure prerequisite relations. A natural exten-
sion to the two simple methods here is to represent
a concept using WordNet (Miller, 1995), Explicit
Semantic Analysis (Gabrilovich and Markovitch,
2007), or Word2vec embeddings (Mikolov et al.,
2013). Incorporating these representations may
improve the performance of RefD.
</bodyText>
<subsectionHeader confidence="0.999469">
4.3 Parameter Analysis and Case Study
</subsectionHeader>
<bodyText confidence="0.999958823529412">
Since using RefD to predict prerequisites requires
setting a threshold θ, we also investigate the rela-
tion between the threshold and the performance of
prediction, as shown in Figure 3. We can see that a
threshold of 0.05 for RefD using TFIDF achieves
the highest average accuracy on the CrowdComp
dataset while a threshold of 0.02 works the best for
Course dataset. Empirically we find that a thresh-
old between 0.02 and 0.1 yields a good perfor-
mance for prerequisite prediction task.
We further explore the performance of RefD
through a case study for the concept “deep learn-
ing” (denoted as c&apos;). Specifically, for any con-
cept c linked from c&apos; we calculate RefD(c&apos;, c).
Table 4 lists the RefD scores for different con-
cepts using EQUAL weighting. The concepts on
the left have negative RefD scores with high abso-
lute values, which means that “deep learning” is a
prerequisite of them. Meanwhile concepts on the
right have high positive RefD scores, which means
that “deep learning” requires knowing them first.
For example, people may first need to have some
knowledge of “machine learning”, “artificial intel-
ligence” and “algorithm” in order to learn “deep
learning”. Also we notice that concepts in the mid-
dle have RefD scores which are very close to 0,
showing that there is no prerequisite relations be-
tween these concepts and “deep learning”. How-
ever, since our RefD implementation is based on
Wikipedia, it might not give an accurate measure
for concepts if they have no Wikipedia articles or
their articles are too short to provide an encyclope-
dic coverage, such as “discriminative model” and
“feature engineering”.
</bodyText>
<figure confidence="0.99209425">
Recall
Precision
0.8
0.6
0.4
0.2
1.0
0 00.2 0.4 0.6 0.8 1.0
</figure>
<table confidence="0.9034072">
MaxEnt (area = 0.730)
EQUAL (area = 0.802)
TFIDF (area = 0.776)
1671
Concept RefD Concept RefD Concept RefD
Deep belief network -0.38 List of Nobel laureates 0.009 Machine learning 0.32
Neocognitron -0.28 Neural development 0.009 Artificial neural network 0.31
Word embedding -0.24 Watson (computer) 0.003 Artificial intelligence 0.15
Vanishing gradient problem -0.22 Self-organization 8e-5 Algorithm 0.14
Feature learning -0.17 Language model -0.004 Statistical classification 0.13
</table>
<tableCaption confidence="0.981233">
Table 4: RefD scores between “deep learning” and the concepts linked from it. All scores are calculated
by RefD(‘deep learning’, concept).
</tableCaption>
<bodyText confidence="0.9993752">
Please note that our Wikipedia-based imple-
mentation is computationally efficient especially
after precomputing weights and references and
can be easily incorporated as a feature into exist-
ing supervised learning based methods.
</bodyText>
<sectionHeader confidence="0.999618" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999746387755102">
In the area of education, researchers have tried
to find prerequisites based on the assessment data
of students’ performance (Scheines et al., 2014;
Vuong et al., 2011). However, prerequisite rela-
tions have not been well studied in computer sci-
ence, with only a few exceptions. Liu et al. (2011)
studied learning-dependency between knowledge
units using classification where a knowledge unit
is a special text fragment containing concepts.
We focus on more general prerequisite relations
among concepts. Talukdar and Cohen (2012) ap-
plied a Maximum Entropy classifier to predict
prerequisite structures in Wikipedia using various
features such as a random walk with restart score
and PageRank score. Instead of doing feature en-
gineering, we propose to measure prerequisite re-
lations using a single metric. Yang et al. (2015)
proposed Concept Graph Learning to induce rela-
tions among concepts from prerequisite relations
among courses, where the learned concept prereq-
uisite relations are implicit and thus can not be
evaluated. Our method is more interpretable for
measuring prerequisite relations.
Our work is closely related to the study of se-
mantic relations. One direction is automatic lex-
ical relation extraction. Different methods have
been proposed to discover hypernym-hyponym re-
lations based on lexical patterns (Hearst, 1992;
McNamee et al., 2008; Ritter et al., 2009), dis-
tributional similarity (Kotlerman et al., 2010), se-
mantic word embeddings (Fu et al., 2014), etc.
Another line is entity relation extraction, which
can be performed by distant supervision (Mintz
et al., 2009; Riedel et al., 2010), Open IE (Fader
et al., 2011), and neural networks (Bordes et al.,
2011; Lin et al., 2015).
In addition, semantic relatedness measures have
been widely studied, where the key is to model
the semantic representation based on a latent
space, such as LSA (Deerwester et al., 1990),
PLSA (Hofmann, 1999), LDA (Blei et al., 2003)
and distributed word embeddings (Huang et al.,
2012; Mikolov et al., 2013), or an explicit concept
space, such as ESA (Gabrilovich and Markovitch,
2007), SSA (Hassan and Mihalcea, 2011), and
SaSA (Wu and Giles, 2015). Our work can also
be served as a basis for building concept hierar-
chy (Wang et al., 2015) and teaching/learning as-
sistant tools (Liang et al., 2015).
</bodyText>
<sectionHeader confidence="0.981216" genericHeader="conclusions">
6 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.9999932">
We studied the problem of measuring prerequi-
site relations among concepts and proposed RefD,
a general, light-weight, and effective metric, to
capture the relation. We presented Wikipedia-
based implementations of RefD with two different
weighting strategies. Experiments on two datasets
including seven domains showed that our pro-
posed metric outperformed existing baselines us-
ing supervised learning.
Promising future directions would be applying
the framework of RefD to other contexts such as
measuring the prerequisite relations or reading or-
ders between papers and textbooks. In addition,
RefD can be incorporated into existing supervised
models for a more accurate measure. Also it
would be meaningful to explore ranking different
prerequisites of a concept. Besides the rich link
structure we could take advantage of more content
information from Wikipedia and other resources
such as textbooks and scientific papers.
</bodyText>
<sectionHeader confidence="0.995491" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99954125">
We gratefully acknowledge partial support from
the National Science Foundation, technical sup-
port from Jian Wu, and helpful comments from the
anonymous reviewers.
</bodyText>
<page confidence="0.681653">
1672
</page>
<sectionHeader confidence="0.981293" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.985942762237762">
John R Bergan and Patrick Jeska. 1980. An ex-
amination of prerequisite relations, positive trans-
fer among learning tasks, and variations in instruc-
tion for a seriation hierarchy. Contemporary Educa-
tional Psychology, 5(3):203–215.
David M Blei, Andrew Y Ng, and Michael I Jordan.
2003. Latent dirichlet allocation. the Journal of ma-
chine Learning research, 3:993–1022.
Antoine Bordes, Jason Weston, Ronan Collobert, and
Yoshua Bengio. 2011. Learning structured embed-
dings of knowledge bases. In Conference on Artifi-
cial Intelligence, number EPFL-CONF-192344.
William Croft and D Alan Cruse. 2004. Cognitive lin-
guistics. Cambridge University Press.
Scott C. Deerwester, Susan T Dumais, Thomas K. Lan-
dauer, George W. Furnas, and Richard A. Harshman.
1990. Indexing by latent semantic analysis. JAsIs,
41(6):391–407.
Anthony Fader, Stephen Soderland, and Oren Etzioni.
2011. Identifying relations for open information ex-
traction. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing,
pages 1535–1545. Association for Computational
Linguistics.
Charles J Fillmore. 2006. Frame semantics. Cognitive
linguistics: Basic readings, 34:373–400.
Ruiji Fu, Jiang Guo, Bing Qin, Wanxiang Che, Haifeng
Wang, and Ting Liu. 2014. Learning semantic hier-
archies via word embeddings. In Proceedings of the
52th Annual Meeting of the Association for Compu-
tational Linguistics: Long Papers, volume 1.
Evgeniy Gabrilovich and Shaul Markovitch. 2007.
Computing semantic relatedness using wikipedia-
based explicit semantic analysis. In IJCAI, vol-
ume 7, pages 1606–1611.
Samer Hassan and Rada Mihalcea. 2011. Semantic
relatedness using salient semantic analysis. In Pro-
ceedings of the Twenty-Fifth AAAI Conference on
Artificial Intelligence, AAAI 2011, San Francisco,
California, USA, August 7-11, 2011.
Marti A Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 14th conference on Computational linguistics-
Volume 2, pages 539–545. Association for Compu-
tational Linguistics.
Thomas Hofmann. 1999. Probabilistic latent semantic
indexing. In Proceedings of the 22nd annual inter-
national ACM SIGIR conference on Research and
development in information retrieval, pages 50–57.
ACM.
Eric H Huang, Richard Socher, Christopher D Man-
ning, and Andrew Y Ng. 2012. Improving word
representations via global context and multiple word
prototypes. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics: Long Papers-Volume 1, pages 873–882. Asso-
ciation for Computational Linguistics.
Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan
Zhitomirsky-Geffet. 2010. Directional distribu-
tional similarity for lexical inference. Natural Lan-
guage Engineering, 16(04):359–389.
Stephen Laurence and Eric Margolis. 1999. Concepts
and cognitive science. Concepts: core readings,
pages 3–81.
Chen Liang, Shuting Wang, Zhaohui Wu, Kyle
Williams, Bart Pursel, Benjamin Brautigam, Sher-
wyn Saul, Hannah Williams, Kyle Bowen, and
C. Lee Giles. 2015. Bbookx: An automatic book
creation framework. In Proceedings of the 2015
ACM Symposium on Document Engineering.
Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and
Xuan Zhu. 2015. Learning entity and relation em-
beddings for knowledge graph completion. In Pro-
ceedings of AAAI.
Jun Liu, Lu Jiang, Zhaohui Wu, Qinghua Zheng, and
Yanan Qian. 2011. Mining learning-dependency
between knowledge units from text. The VLDB
Journal, 20(3):335–345.
Paul McNamee, Rion Snow, Patrick Schone, and James
Mayfield. 2008. Learning named entity hyponyms
for question answering. In IJCNLP, pages 799–804.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems, pages 3111–3119.
George A Miller. 1995. Wordnet: a lexical
database for english. Communications of the ACM,
38(11):39–41.
Mike Mintz, Steven Bills, Rion Snow, and Dan Ju-
rafsky. 2009. Distant supervision for relation ex-
traction without labeled data. In Proceedings of the
Joint Conference of the 47th Annual Meeting of the
ACL and the 4th International Joint Conference on
Natural Language Processing of the AFNLP: Vol-
ume 2-Volume 2, pages 1003–1011. Association for
Computational Linguistics.
Matthew W Ohland, Amy G Yuhasz, and Benjamin L
Sill. 2004. Identifying and removing a calculus pre-
requisite as a bottleneck in clemson’s general engi-
neering curriculum. Journal of Engineering Educa-
tion, 93(3):253–257.
Sebastian Riedel, Limin Yao, and Andrew McCal-
lum. 2010. Modeling relations and their men-
tions without labeled text. In Machine Learning and
1673
Knowledge Discovery in Databases, pages 148–163.
Springer.
Alan Ritter, Stephen Soderland, and Oren Etzioni.
2009. What is this, anyway: Automatic hypernym
discovery. In AAAI Spring Symposium: Learning by
Reading and Learning to Read, pages 88–93.
Richard Scheines, Elizabeth Silver, and Ilya Goldin.
2014. Discovering prerequisite relationships among
knowledge components. In Proceedings of Educa-
tional Data Mining, pages 355–356.
Partha Pratim Talukdar and William W Cohen. 2012.
Crowdsourced comprehension: predicting prerequi-
site structure in wikipedia. In Proceedings of the
Seventh Workshop on Building Educational Appli-
cations Using NLP, pages 307–315. Association for
Computational Linguistics.
Annalies Vuong, Tristan Nixon, and Brendon Towle.
2011. A method for finding prerequisites within
a curriculum. In Proceedings of Educational Data
Mining, pages 211–216.
Shuting Wang, Chen Liang, Zhaohui Wu, Kyle
Williams, Bart Pursel, Benjamin Brautigam, Sher-
wyn Saul, Hannah Williams, Kyle Bowen, and
C. Lee Giles. 2015. Concept hierarchy extraction
from textbooks. In Proceedings of the 2015 ACM
Symposium on Document Engineering.
Zhaohui Wu and C. Lee Giles. 2015. Sense-aware se-
mantic analysis: A multi-prototypeword represen-
tation model usingwikipedia. In Proceedings of
the 29th AAAI Conference on Artificial Intelligence,
pages 2188–2194.
Yiming Yang, Hanxiao Liu, Jaime G. Carbonell, and
Wanli Ma. 2015. Concept graph learning from ed-
ucational data. In Proceedings of the Eighth ACM
International Conference on Web Search and Data
Mining, WSDM 2015, Shanghai, China, February
2-6, 2015, pages 159–168.
</reference>
<page confidence="0.829462">
1674
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.791506">
<title confidence="0.999927">Measuring Prerequisite Relations Among Concepts</title>
<author confidence="0.998506">Liang Wenyi C Lee</author>
<affiliation confidence="0.93326275">Sciences and Science and The Pennsylvania State University Park,</affiliation>
<email confidence="0.997589">zzw109@psu.edu</email>
<abstract confidence="0.9985774375">describes a basic relation among concepts in cognition, education and other areas. However, as a semantic relation, it has not been well studied in computational linguistics. We investigate the problem of measuring prerequisite relations among concepts and propose a simple link-based metric, namely distance that effectively models the relation by measuring how differently two concepts refer to each other. Evaluations on two datasets that include seven domains show that our single metric based method outperforms existing supervised learning based methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John R Bergan</author>
<author>Patrick Jeska</author>
</authors>
<title>An examination of prerequisite relations, positive transfer among learning tasks, and variations in instruction for a seriation hierarchy.</title>
<date>1980</date>
<journal>Contemporary Educational Psychology,</journal>
<volume>5</volume>
<issue>3</issue>
<contexts>
<context position="1484" citStr="Bergan and Jeska, 1980" startWordPosition="217" endWordPosition="220"> supervised learning based methods. 1 Introduction What should one know/learn before starting to learn a new area such as “deep learning”? A key for answering this question is to understand what a prerequisite is. A prerequisite is usually a concept or requirement before one can proceed to a following one. And the prerequisite relation exists as a natural dependency among concepts in cognitive processes when people learn, organize, apply, and generate knowledge (Laurence and Margolis, 1999). While there has been serious effort in understanding prerequisite relations in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the </context>
</contexts>
<marker>Bergan, Jeska, 1980</marker>
<rawString>John R Bergan and Patrick Jeska. 1980. An examination of prerequisite relations, positive transfer among learning tasks, and variations in instruction for a seriation hierarchy. Contemporary Educational Psychology, 5(3):203–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>the Journal of machine Learning research,</journal>
<pages>3--993</pages>
<contexts>
<context position="18507" citStr="Blei et al., 2003" startWordPosition="3009" endWordPosition="3012">s (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presented Wikipediabased implemen</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. the Journal of machine Learning research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Jason Weston</author>
<author>Ronan Collobert</author>
<author>Yoshua Bengio</author>
</authors>
<title>Learning structured embeddings of knowledge bases.</title>
<date>2011</date>
<booktitle>In Conference on Artificial Intelligence, number</booktitle>
<pages>192344</pages>
<contexts>
<context position="18254" citStr="Bordes et al., 2011" startWordPosition="2967" endWordPosition="2970">measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools </context>
</contexts>
<marker>Bordes, Weston, Collobert, Bengio, 2011</marker>
<rawString>Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. 2011. Learning structured embeddings of knowledge bases. In Conference on Artificial Intelligence, number EPFL-CONF-192344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Croft</author>
<author>D Alan Cruse</author>
</authors>
<title>Cognitive linguistics.</title>
<date>2004</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2055" citStr="Croft and Cruse, 2004" startWordPosition="306" endWordPosition="309">s in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the theory of frame semantics (Fillmore, 2006), or, to understand a concept, one needs to understand all the related concepts in its “frame”, we propose a metric that measures prerequisite relations based on a simple observation of human learning. When learning concept A, if one needs to refer to concept B for a lot of A’s related concepts but not vice versa, B would more likely be a prerequisite of A than A of B. Specifically, we model a concept in a vector space using its related concepts and measure the prerequisite relation between two concepts by computing how dif</context>
</contexts>
<marker>Croft, Cruse, 2004</marker>
<rawString>William Croft and D Alan Cruse. 2004. Cognitive linguistics. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott C Deerwester</author>
<author>Susan T Dumais</author>
<author>Thomas K Landauer</author>
<author>George W Furnas</author>
<author>Richard A Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>JAsIs,</journal>
<pages>41--6</pages>
<contexts>
<context position="18460" citStr="Deerwester et al., 1990" startWordPosition="3001" endWordPosition="3004">r hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the</context>
</contexts>
<marker>Deerwester, Dumais, Landauer, Furnas, Harshman, 1990</marker>
<rawString>Scott C. Deerwester, Susan T Dumais, Thomas K. Landauer, George W. Furnas, and Richard A. Harshman. 1990. Indexing by latent semantic analysis. JAsIs, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Fader</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1535--1545</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="18212" citStr="Fader et al., 2011" startWordPosition="2960" endWordPosition="2963">ted. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 20</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>Anthony Fader, Stephen Soderland, and Oren Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1535–1545. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>Frame semantics. Cognitive linguistics: Basic readings,</title>
<date>2006</date>
<pages>34--373</pages>
<contexts>
<context position="2126" citStr="Fillmore, 2006" startWordPosition="320" endWordPosition="321">g et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the theory of frame semantics (Fillmore, 2006), or, to understand a concept, one needs to understand all the related concepts in its “frame”, we propose a metric that measures prerequisite relations based on a simple observation of human learning. When learning concept A, if one needs to refer to concept B for a lot of A’s related concepts but not vice versa, B would more likely be a prerequisite of A than A of B. Specifically, we model a concept in a vector space using its related concepts and measure the prerequisite relation between two concepts by computing how differently the two’s related concepts refer to each other, or reference d</context>
</contexts>
<marker>Fillmore, 2006</marker>
<rawString>Charles J Fillmore. 2006. Frame semantics. Cognitive linguistics: Basic readings, 34:373–400.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruiji Fu</author>
<author>Jiang Guo</author>
<author>Bing Qin</author>
<author>Wanxiang Che</author>
<author>Haifeng Wang</author>
<author>Ting Liu</author>
</authors>
<title>Learning semantic hierarchies via word embeddings.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics: Long Papers,</booktitle>
<volume>1</volume>
<contexts>
<context position="18044" citStr="Fu et al., 2014" startWordPosition="2932" endWordPosition="2935">o induce relations among concepts from prerequisite relations among courses, where the learned concept prerequisite relations are implicit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and M</context>
</contexts>
<marker>Fu, Guo, Qin, Che, Wang, Liu, 2014</marker>
<rawString>Ruiji Fu, Jiang Guo, Bing Qin, Wanxiang Che, Haifeng Wang, and Ting Liu. 2014. Learning semantic hierarchies via word embeddings. In Proceedings of the 52th Annual Meeting of the Association for Computational Linguistics: Long Papers, volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipediabased explicit semantic analysis.</title>
<date>2007</date>
<booktitle>In IJCAI,</booktitle>
<volume>7</volume>
<pages>1606--1611</pages>
<contexts>
<context position="6870" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="1088" endWordPosition="1091"> a prerequisite of A; and 3) irreflexive: RefD(A, A)=0, which means A is not a prerequisite of itself. To capture all three possible prerequisite relations where 0 is a positive threshold. Equation 1 provides a general framework to calculate RefD. In practice, we need to specify the concept space C, the weight w, and the reference indicator function r. 3 Wikipedia-based RefD Implementation We now implement RefD using Wikipedia. As a widely used open-access encyclopedia, Wikipedia provides relatively up-to-date and high quality knowledge and has been successfully utilized as explicit concepts (Gabrilovich and Markovitch, 2007). Moreover, the rich hyperlinks created by Wiki editors provide a natural way to calculate the reference indicator function r. Specifically, the concept space C consists of all Wikipedia articles. r(c, A) represents whether there is a link from Wiki article c to A. For w(c, A), we experiment with two methods: • EQUAL: A is represented by the concepts linked from it (L(A)) with equal weights. � 1 if c E L(A) w(c, A) = 0 if c E/ L(A) • TFIDF: A is represented by the concepts linked from it with TFIDF weights. � tf(c, A) ∗ log N df(c) if c E L(A) w(c, A) = 0 if c E/ L(A) where tf(c, A) is the num</context>
<context position="13864" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="2280" endWordPosition="2283"> we plot the Precision-Recall curves of different methods, as shown in Figure 2. RefD shows a clear improvement in the area under the Precision-Recall curve. Comparing two weighting methods, we find that TFIDF performs slightly better than EQUAL on CS while EQUAL has higher scores than TFIDF on MATH. Since how to compute w in RefD is a crucial problem, our ongoing work is to explore more sophisticated semantic representations to measure prerequisite relations. A natural extension to the two simple methods here is to represent a concept using WordNet (Miller, 1995), Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007), or Word2vec embeddings (Mikolov et al., 2013). Incorporating these representations may improve the performance of RefD. 4.3 Parameter Analysis and Case Study Since using RefD to predict prerequisites requires setting a threshold θ, we also investigate the relation between the threshold and the performance of prediction, as shown in Figure 3. We can see that a threshold of 0.05 for RefD using TFIDF achieves the highest average accuracy on the CrowdComp dataset while a threshold of 0.02 works the best for Course dataset. Empirically we find that a threshold between 0.02 and 0.1 yields a good p</context>
<context position="18660" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="3033" endWordPosition="3036">(Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presented Wikipediabased implementations of RefD with two different weighting strategies. Experiments on two datasets including seven domains showed that our proposed metric outperformed</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Computing semantic relatedness using wikipediabased explicit semantic analysis. In IJCAI, volume 7, pages 1606–1611.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samer Hassan</author>
<author>Rada Mihalcea</author>
</authors>
<title>Semantic relatedness using salient semantic analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011,</booktitle>
<location>San Francisco, California, USA,</location>
<contexts>
<context position="18693" citStr="Hassan and Mihalcea, 2011" startWordPosition="3038" endWordPosition="3041">entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presented Wikipediabased implementations of RefD with two different weighting strategies. Experiments on two datasets including seven domains showed that our proposed metric outperformed existing baselines using supervi</context>
</contexts>
<marker>Hassan, Mihalcea, 2011</marker>
<rawString>Samer Hassan and Rada Mihalcea. 2011. Semantic relatedness using salient semantic analysis. In Proceedings of the Twenty-Fifth AAAI Conference on Artificial Intelligence, AAAI 2011, San Francisco, California, USA, August 7-11, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th conference on Computational linguisticsVolume 2,</booktitle>
<pages>539--545</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="17904" citStr="Hearst, 1992" startWordPosition="2911" endWordPosition="2912">re engineering, we propose to measure prerequisite relations using a single metric. Yang et al. (2015) proposed Concept Graph Learning to induce relations among concepts from prerequisite relations among courses, where the learned concept prerequisite relations are implicit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 20</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 14th conference on Computational linguisticsVolume 2, pages 539–545. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Hofmann</author>
</authors>
<title>Probabilistic latent semantic indexing.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>50--57</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="18482" citStr="Hofmann, 1999" startWordPosition="3006" endWordPosition="3007">ed on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presente</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>Thomas Hofmann. 1999. Probabilistic latent semantic indexing. In Proceedings of the 22nd annual international ACM SIGIR conference on Research and development in information retrieval, pages 50–57. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric H Huang</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Improving word representations via global context and multiple word prototypes.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>873--882</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="18559" citStr="Huang et al., 2012" startWordPosition="3017" endWordPosition="3020">, 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presented Wikipediabased implementations of RefD with two different weighting strateg</context>
</contexts>
<marker>Huang, Socher, Manning, Ng, 2012</marker>
<rawString>Eric H Huang, Richard Socher, Christopher D Manning, and Andrew Y Ng. 2012. Improving word representations via global context and multiple word prototypes. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 873–882. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lili Kotlerman</author>
<author>Ido Dagan</author>
<author>Idan Szpektor</author>
<author>Maayan Zhitomirsky-Geffet</author>
</authors>
<title>Directional distributional similarity for lexical inference.</title>
<date>2010</date>
<journal>Natural Language Engineering,</journal>
<volume>16</volume>
<issue>04</issue>
<contexts>
<context position="18000" citStr="Kotlerman et al., 2010" startWordPosition="2924" endWordPosition="2927">ang et al. (2015) proposed Concept Graph Learning to induce relations among concepts from prerequisite relations among courses, where the learned concept prerequisite relations are implicit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit c</context>
</contexts>
<marker>Kotlerman, Dagan, Szpektor, Zhitomirsky-Geffet, 2010</marker>
<rawString>Lili Kotlerman, Ido Dagan, Idan Szpektor, and Maayan Zhitomirsky-Geffet. 2010. Directional distributional similarity for lexical inference. Natural Language Engineering, 16(04):359–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Laurence</author>
<author>Eric Margolis</author>
</authors>
<title>Concepts and cognitive science. Concepts: core readings,</title>
<date>1999</date>
<pages>3--81</pages>
<contexts>
<context position="1357" citStr="Laurence and Margolis, 1999" startWordPosition="198" endWordPosition="202">r to each other. Evaluations on two datasets that include seven domains show that our single metric based method outperforms existing supervised learning based methods. 1 Introduction What should one know/learn before starting to learn a new area such as “deep learning”? A key for answering this question is to understand what a prerequisite is. A prerequisite is usually a concept or requirement before one can proceed to a following one. And the prerequisite relation exists as a natural dependency among concepts in cognitive processes when people learn, organize, apply, and generate knowledge (Laurence and Margolis, 1999). While there has been serious effort in understanding prerequisite relations in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better u</context>
</contexts>
<marker>Laurence, Margolis, 1999</marker>
<rawString>Stephen Laurence and Eric Margolis. 1999. Concepts and cognitive science. Concepts: core readings, pages 3–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Liang</author>
<author>Shuting Wang</author>
<author>Zhaohui Wu</author>
<author>Kyle Williams</author>
<author>Bart Pursel</author>
<author>Benjamin Brautigam</author>
<author>Sherwyn Saul</author>
<author>Hannah Williams</author>
<author>Kyle Bowen</author>
<author>C Lee Giles</author>
</authors>
<title>Bbookx: An automatic book creation framework.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 ACM Symposium on Document Engineering.</booktitle>
<contexts>
<context position="18874" citStr="Liang et al., 2015" startWordPosition="3071" endWordPosition="3074"> Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presented Wikipediabased implementations of RefD with two different weighting strategies. Experiments on two datasets including seven domains showed that our proposed metric outperformed existing baselines using supervised learning. Promising future directions would be applying the framework of RefD to other contexts such as measuring the prerequisite relations or reading orders between papers and</context>
</contexts>
<marker>Liang, Wang, Wu, Williams, Pursel, Brautigam, Saul, Williams, Bowen, Giles, 2015</marker>
<rawString>Chen Liang, Shuting Wang, Zhaohui Wu, Kyle Williams, Bart Pursel, Benjamin Brautigam, Sherwyn Saul, Hannah Williams, Kyle Bowen, and C. Lee Giles. 2015. Bbookx: An automatic book creation framework. In Proceedings of the 2015 ACM Symposium on Document Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yankai Lin</author>
<author>Zhiyuan Liu</author>
<author>Maosong Sun</author>
<author>Yang Liu</author>
<author>Xuan Zhu</author>
</authors>
<title>Learning entity and relation embeddings for knowledge graph completion.</title>
<date>2015</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="18273" citStr="Lin et al., 2015" startWordPosition="2971" endWordPosition="2974">e relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015</context>
</contexts>
<marker>Lin, Liu, Sun, Liu, Zhu, 2015</marker>
<rawString>Yankai Lin, Zhiyuan Liu, Maosong Sun, Yang Liu, and Xuan Zhu. 2015. Learning entity and relation embeddings for knowledge graph completion. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Liu</author>
<author>Lu Jiang</author>
<author>Zhaohui Wu</author>
<author>Qinghua Zheng</author>
<author>Yanan Qian</author>
</authors>
<title>Mining learning-dependency between knowledge units from text.</title>
<date>2011</date>
<journal>The VLDB Journal,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="16866" citStr="Liu et al. (2011)" startWordPosition="2756" endWordPosition="2759">ts linked from it. All scores are calculated by RefD(‘deep learning’, concept). Please note that our Wikipedia-based implementation is computationally efficient especially after precomputing weights and references and can be easily incorporated as a feature into existing supervised learning based methods. 5 Related Work In the area of education, researchers have tried to find prerequisites based on the assessment data of students’ performance (Scheines et al., 2014; Vuong et al., 2011). However, prerequisite relations have not been well studied in computer science, with only a few exceptions. Liu et al. (2011) studied learning-dependency between knowledge units using classification where a knowledge unit is a special text fragment containing concepts. We focus on more general prerequisite relations among concepts. Talukdar and Cohen (2012) applied a Maximum Entropy classifier to predict prerequisite structures in Wikipedia using various features such as a random walk with restart score and PageRank score. Instead of doing feature engineering, we propose to measure prerequisite relations using a single metric. Yang et al. (2015) proposed Concept Graph Learning to induce relations among concepts from</context>
</contexts>
<marker>Liu, Jiang, Wu, Zheng, Qian, 2011</marker>
<rawString>Jun Liu, Lu Jiang, Zhaohui Wu, Qinghua Zheng, and Yanan Qian. 2011. Mining learning-dependency between knowledge units from text. The VLDB Journal, 20(3):335–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul McNamee</author>
<author>Rion Snow</author>
<author>Patrick Schone</author>
<author>James Mayfield</author>
</authors>
<title>Learning named entity hyponyms for question answering. In</title>
<date>2008</date>
<booktitle>IJCNLP,</booktitle>
<pages>799--804</pages>
<contexts>
<context position="17926" citStr="McNamee et al., 2008" startWordPosition="2913" endWordPosition="2916">, we propose to measure prerequisite relations using a single metric. Yang et al. (2015) proposed Concept Graph Learning to induce relations among concepts from prerequisite relations among courses, where the learned concept prerequisite relations are implicit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed wo</context>
</contexts>
<marker>McNamee, Snow, Schone, Mayfield, 2008</marker>
<rawString>Paul McNamee, Rion Snow, Patrick Schone, and James Mayfield. 2008. Learning named entity hyponyms for question answering. In IJCNLP, pages 799–804.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="13911" citStr="Mikolov et al., 2013" startWordPosition="2287" endWordPosition="2290">as shown in Figure 2. RefD shows a clear improvement in the area under the Precision-Recall curve. Comparing two weighting methods, we find that TFIDF performs slightly better than EQUAL on CS while EQUAL has higher scores than TFIDF on MATH. Since how to compute w in RefD is a crucial problem, our ongoing work is to explore more sophisticated semantic representations to measure prerequisite relations. A natural extension to the two simple methods here is to represent a concept using WordNet (Miller, 1995), Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007), or Word2vec embeddings (Mikolov et al., 2013). Incorporating these representations may improve the performance of RefD. 4.3 Parameter Analysis and Case Study Since using RefD to predict prerequisites requires setting a threshold θ, we also investigate the relation between the threshold and the performance of prediction, as shown in Figure 3. We can see that a threshold of 0.05 for RefD using TFIDF achieves the highest average accuracy on the CrowdComp dataset while a threshold of 0.02 works the best for Course dataset. Empirically we find that a threshold between 0.02 and 0.1 yields a good performance for prerequisite prediction task. We</context>
<context position="18582" citStr="Mikolov et al., 2013" startWordPosition="3021" endWordPosition="3024">nal similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presented Wikipediabased implementations of RefD with two different weighting strategies. Experiments on two</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: a lexical database for english.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<contexts>
<context position="1694" citStr="Miller, 1995" startWordPosition="253" endWordPosition="254">requisite is usually a concept or requirement before one can proceed to a following one. And the prerequisite relation exists as a natural dependency among concepts in cognitive processes when people learn, organize, apply, and generate knowledge (Laurence and Margolis, 1999). While there has been serious effort in understanding prerequisite relations in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the theory of frame semantics (Fillmore, 2006), or, to understand a concept, one needs to understand all the related concepts in its “frame”, we propose a metric that measures prerequisite relations based on a simp</context>
<context position="13801" citStr="Miller, 1995" startWordPosition="2275" endWordPosition="2276">der to better compare precision and recall, we plot the Precision-Recall curves of different methods, as shown in Figure 2. RefD shows a clear improvement in the area under the Precision-Recall curve. Comparing two weighting methods, we find that TFIDF performs slightly better than EQUAL on CS while EQUAL has higher scores than TFIDF on MATH. Since how to compute w in RefD is a crucial problem, our ongoing work is to explore more sophisticated semantic representations to measure prerequisite relations. A natural extension to the two simple methods here is to represent a concept using WordNet (Miller, 1995), Explicit Semantic Analysis (Gabrilovich and Markovitch, 2007), or Word2vec embeddings (Mikolov et al., 2013). Incorporating these representations may improve the performance of RefD. 4.3 Parameter Analysis and Case Study Since using RefD to predict prerequisites requires setting a threshold θ, we also investigate the relation between the threshold and the performance of prediction, as shown in Figure 3. We can see that a threshold of 0.05 for RefD using TFIDF achieves the highest average accuracy on the CrowdComp dataset while a threshold of 0.02 works the best for Course dataset. Empiricall</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A Miller. 1995. Wordnet: a lexical database for english. Communications of the ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1768" citStr="Mintz et al., 2009" startWordPosition="263" endWordPosition="266"> to a following one. And the prerequisite relation exists as a natural dependency among concepts in cognitive processes when people learn, organize, apply, and generate knowledge (Laurence and Margolis, 1999). While there has been serious effort in understanding prerequisite relations in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the theory of frame semantics (Fillmore, 2006), or, to understand a concept, one needs to understand all the related concepts in its “frame”, we propose a metric that measures prerequisite relations based on a simple observation of human learning. When learning concept A, if one needs to</context>
<context position="18160" citStr="Mintz et al., 2009" startWordPosition="2950" endWordPosition="2953">e relations are implicit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a b</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003–1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew W Ohland</author>
<author>Amy G Yuhasz</author>
<author>Benjamin L Sill</author>
</authors>
<title>Identifying and removing a calculus prerequisite as a bottleneck in clemson’s general engineering curriculum.</title>
<date>2004</date>
<journal>Journal of Engineering Education,</journal>
<volume>93</volume>
<issue>3</issue>
<contexts>
<context position="1505" citStr="Ohland et al., 2004" startWordPosition="221" endWordPosition="224">ed methods. 1 Introduction What should one know/learn before starting to learn a new area such as “deep learning”? A key for answering this question is to understand what a prerequisite is. A prerequisite is usually a concept or requirement before one can proceed to a following one. And the prerequisite relation exists as a natural dependency among concepts in cognitive processes when people learn, organize, apply, and generate knowledge (Laurence and Margolis, 1999). While there has been serious effort in understanding prerequisite relations in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the theory of frame seman</context>
</contexts>
<marker>Ohland, Yuhasz, Sill, 2004</marker>
<rawString>Matthew W Ohland, Amy G Yuhasz, and Benjamin L Sill. 2004. Identifying and removing a calculus prerequisite as a bottleneck in clemson’s general engineering curriculum. Journal of Engineering Education, 93(3):253–257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Machine Learning and</booktitle>
<pages>1673</pages>
<contexts>
<context position="18182" citStr="Riedel et al., 2010" startWordPosition="2954" endWordPosition="2957">icit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building conc</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and 1673</rawString>
</citation>
<citation valid="false">
<title>Knowledge Discovery in Databases,</title>
<pages>148--163</pages>
<publisher>Springer.</publisher>
<marker></marker>
<rawString>Knowledge Discovery in Databases, pages 148–163. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Stephen Soderland</author>
<author>Oren Etzioni</author>
</authors>
<title>What is this, anyway: Automatic hypernym discovery. In AAAI Spring Symposium: Learning by Reading and Learning to Read,</title>
<date>2009</date>
<pages>88--93</pages>
<contexts>
<context position="17948" citStr="Ritter et al., 2009" startWordPosition="2917" endWordPosition="2920">e prerequisite relations using a single metric. Yang et al. (2015) proposed Concept Graph Learning to induce relations among concepts from prerequisite relations among courses, where the learned concept prerequisite relations are implicit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al., 2010), semantic word embeddings (Fu et al., 2014), etc. Another line is entity relation extraction, which can be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang e</context>
</contexts>
<marker>Ritter, Soderland, Etzioni, 2009</marker>
<rawString>Alan Ritter, Stephen Soderland, and Oren Etzioni. 2009. What is this, anyway: Automatic hypernym discovery. In AAAI Spring Symposium: Learning by Reading and Learning to Read, pages 88–93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Scheines</author>
<author>Elizabeth Silver</author>
<author>Ilya Goldin</author>
</authors>
<title>Discovering prerequisite relationships among knowledge components.</title>
<date>2014</date>
<booktitle>In Proceedings of Educational Data Mining,</booktitle>
<pages>355--356</pages>
<contexts>
<context position="16718" citStr="Scheines et al., 2014" startWordPosition="2730" endWordPosition="2733"> Algorithm 0.14 Feature learning -0.17 Language model -0.004 Statistical classification 0.13 Table 4: RefD scores between “deep learning” and the concepts linked from it. All scores are calculated by RefD(‘deep learning’, concept). Please note that our Wikipedia-based implementation is computationally efficient especially after precomputing weights and references and can be easily incorporated as a feature into existing supervised learning based methods. 5 Related Work In the area of education, researchers have tried to find prerequisites based on the assessment data of students’ performance (Scheines et al., 2014; Vuong et al., 2011). However, prerequisite relations have not been well studied in computer science, with only a few exceptions. Liu et al. (2011) studied learning-dependency between knowledge units using classification where a knowledge unit is a special text fragment containing concepts. We focus on more general prerequisite relations among concepts. Talukdar and Cohen (2012) applied a Maximum Entropy classifier to predict prerequisite structures in Wikipedia using various features such as a random walk with restart score and PageRank score. Instead of doing feature engineering, we propose</context>
</contexts>
<marker>Scheines, Silver, Goldin, 2014</marker>
<rawString>Richard Scheines, Elizabeth Silver, and Ilya Goldin. 2014. Discovering prerequisite relationships among knowledge components. In Proceedings of Educational Data Mining, pages 355–356.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Pratim Talukdar</author>
<author>William W Cohen</author>
</authors>
<title>Crowdsourced comprehension: predicting prerequisite structure in wikipedia.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Building Educational Applications Using NLP,</booktitle>
<pages>307--315</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1916" citStr="Talukdar and Cohen, 2012" startWordPosition="284" endWordPosition="287">nize, apply, and generate knowledge (Laurence and Margolis, 1999). While there has been serious effort in understanding prerequisite relations in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the theory of frame semantics (Fillmore, 2006), or, to understand a concept, one needs to understand all the related concepts in its “frame”, we propose a metric that measures prerequisite relations based on a simple observation of human learning. When learning concept A, if one needs to refer to concept B for a lot of A’s related concepts but not vice versa, B would more likely be a prerequisite of A than A of B. Specifically, we m</context>
<context position="8903" citStr="Talukdar and Cohen, 2012" startWordPosition="1449" endWordPosition="1452">Parallel Postulate 64.7 73.6 70.5 67.9 Newton’s Laws 53.9 57.7 63.7 64.6 Global Warming 56.8 50.0 57.4 60.1 Average 58.7 60.4 60.0* 61.2* Table 2: Comparison of out-of-domain training accuracies of a MaxEnt classifier and RefD using EQUAL and TFIDF weighting. MaxEnt† is the number reported by Talukdar et al. (2012). MaxEnt shows the performance of our implementation. * indicates the difference between RefD and MaxEnt is statistically significant (p &lt; 0.01). B and pairs where no prerequisite relation exists will be viewed as negative examples. RefD is tested on two datasets: CrowdComp dataset (Talukdar and Cohen, 2012) and a Course prerequisite dataset collected by us. We compare RefD with a Maximum Entropy (MaxEnt) classifier which exploits graph-based features such as PageRank scores and content-based features such as the category information, whether a title of concept is mentioned in the first sentence of the other concept, the number of times a concept is linked from the other, etc. (Talukdar and Cohen, 2012). All experiments use a Wikipedia dump of Dec 8, 2014. 4.1 Results on the CrowdComp Dataset The CrowdComp dataset was collected using Amazon Mechanical Turk by Talukdar et al. (2012). It contains b</context>
<context position="17100" citStr="Talukdar and Cohen (2012)" startWordPosition="2787" endWordPosition="2790">asily incorporated as a feature into existing supervised learning based methods. 5 Related Work In the area of education, researchers have tried to find prerequisites based on the assessment data of students’ performance (Scheines et al., 2014; Vuong et al., 2011). However, prerequisite relations have not been well studied in computer science, with only a few exceptions. Liu et al. (2011) studied learning-dependency between knowledge units using classification where a knowledge unit is a special text fragment containing concepts. We focus on more general prerequisite relations among concepts. Talukdar and Cohen (2012) applied a Maximum Entropy classifier to predict prerequisite structures in Wikipedia using various features such as a random walk with restart score and PageRank score. Instead of doing feature engineering, we propose to measure prerequisite relations using a single metric. Yang et al. (2015) proposed Concept Graph Learning to induce relations among concepts from prerequisite relations among courses, where the learned concept prerequisite relations are implicit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to </context>
</contexts>
<marker>Talukdar, Cohen, 2012</marker>
<rawString>Partha Pratim Talukdar and William W Cohen. 2012. Crowdsourced comprehension: predicting prerequisite structure in wikipedia. In Proceedings of the Seventh Workshop on Building Educational Applications Using NLP, pages 307–315. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annalies Vuong</author>
<author>Tristan Nixon</author>
<author>Brendon Towle</author>
</authors>
<title>A method for finding prerequisites within a curriculum.</title>
<date>2011</date>
<booktitle>In Proceedings of Educational Data Mining,</booktitle>
<pages>211--216</pages>
<contexts>
<context position="1526" citStr="Vuong et al., 2011" startWordPosition="225" endWordPosition="228">ction What should one know/learn before starting to learn a new area such as “deep learning”? A key for answering this question is to understand what a prerequisite is. A prerequisite is usually a concept or requirement before one can proceed to a following one. And the prerequisite relation exists as a natural dependency among concepts in cognitive processes when people learn, organize, apply, and generate knowledge (Laurence and Margolis, 1999). While there has been serious effort in understanding prerequisite relations in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the theory of frame semantics (Fillmore, 2006)</context>
<context position="16739" citStr="Vuong et al., 2011" startWordPosition="2734" endWordPosition="2737"> learning -0.17 Language model -0.004 Statistical classification 0.13 Table 4: RefD scores between “deep learning” and the concepts linked from it. All scores are calculated by RefD(‘deep learning’, concept). Please note that our Wikipedia-based implementation is computationally efficient especially after precomputing weights and references and can be easily incorporated as a feature into existing supervised learning based methods. 5 Related Work In the area of education, researchers have tried to find prerequisites based on the assessment data of students’ performance (Scheines et al., 2014; Vuong et al., 2011). However, prerequisite relations have not been well studied in computer science, with only a few exceptions. Liu et al. (2011) studied learning-dependency between knowledge units using classification where a knowledge unit is a special text fragment containing concepts. We focus on more general prerequisite relations among concepts. Talukdar and Cohen (2012) applied a Maximum Entropy classifier to predict prerequisite structures in Wikipedia using various features such as a random walk with restart score and PageRank score. Instead of doing feature engineering, we propose to measure prerequis</context>
</contexts>
<marker>Vuong, Nixon, Towle, 2011</marker>
<rawString>Annalies Vuong, Tristan Nixon, and Brendon Towle. 2011. A method for finding prerequisites within a curriculum. In Proceedings of Educational Data Mining, pages 211–216.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuting Wang</author>
<author>Chen Liang</author>
<author>Zhaohui Wu</author>
<author>Kyle Williams</author>
<author>Bart Pursel</author>
<author>Benjamin Brautigam</author>
<author>Sherwyn Saul</author>
<author>Hannah Williams</author>
<author>Kyle Bowen</author>
<author>C Lee Giles</author>
</authors>
<title>Concept hierarchy extraction from textbooks.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 ACM Symposium on Document Engineering.</booktitle>
<contexts>
<context position="18815" citStr="Wang et al., 2015" startWordPosition="3062" endWordPosition="3065">r et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presented Wikipediabased implementations of RefD with two different weighting strategies. Experiments on two datasets including seven domains showed that our proposed metric outperformed existing baselines using supervised learning. Promising future directions would be applying the framework of RefD to other contexts such as measuring the </context>
</contexts>
<marker>Wang, Liang, Wu, Williams, Pursel, Brautigam, Saul, Williams, Bowen, Giles, 2015</marker>
<rawString>Shuting Wang, Chen Liang, Zhaohui Wu, Kyle Williams, Bart Pursel, Benjamin Brautigam, Sherwyn Saul, Hannah Williams, Kyle Bowen, and C. Lee Giles. 2015. Concept hierarchy extraction from textbooks. In Proceedings of the 2015 ACM Symposium on Document Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhaohui Wu</author>
<author>C Lee Giles</author>
</authors>
<title>Sense-aware semantic analysis: A multi-prototypeword representation model usingwikipedia.</title>
<date>2015</date>
<booktitle>In Proceedings of the 29th AAAI Conference on Artificial Intelligence,</booktitle>
<pages>2188--2194</pages>
<contexts>
<context position="18724" citStr="Wu and Giles, 2015" startWordPosition="3044" endWordPosition="3047">be performed by distant supervision (Mintz et al., 2009; Riedel et al., 2010), Open IE (Fader et al., 2011), and neural networks (Bordes et al., 2011; Lin et al., 2015). In addition, semantic relatedness measures have been widely studied, where the key is to model the semantic representation based on a latent space, such as LSA (Deerwester et al., 1990), PLSA (Hofmann, 1999), LDA (Blei et al., 2003) and distributed word embeddings (Huang et al., 2012; Mikolov et al., 2013), or an explicit concept space, such as ESA (Gabrilovich and Markovitch, 2007), SSA (Hassan and Mihalcea, 2011), and SaSA (Wu and Giles, 2015). Our work can also be served as a basis for building concept hierarchy (Wang et al., 2015) and teaching/learning assistant tools (Liang et al., 2015). 6 Conclusions and Future Work We studied the problem of measuring prerequisite relations among concepts and proposed RefD, a general, light-weight, and effective metric, to capture the relation. We presented Wikipediabased implementations of RefD with two different weighting strategies. Experiments on two datasets including seven domains showed that our proposed metric outperformed existing baselines using supervised learning. Promising future </context>
</contexts>
<marker>Wu, Giles, 2015</marker>
<rawString>Zhaohui Wu and C. Lee Giles. 2015. Sense-aware semantic analysis: A multi-prototypeword representation model usingwikipedia. In Proceedings of the 29th AAAI Conference on Artificial Intelligence, pages 2188–2194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
<author>Hanxiao Liu</author>
<author>Jaime G Carbonell</author>
<author>Wanli Ma</author>
</authors>
<title>Concept graph learning from educational data.</title>
<date>2015</date>
<booktitle>In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, WSDM 2015,</booktitle>
<pages>159--168</pages>
<location>Shanghai, China,</location>
<contexts>
<context position="1936" citStr="Yang et al., 2015" startWordPosition="288" endWordPosition="291">knowledge (Laurence and Margolis, 1999). While there has been serious effort in understanding prerequisite relations in learning and education (Bergan and Jeska, 1980; Ohland et al., 2004; Vuong et al., 2011), it has not been well studied as a semantic relation in computational linguistics, where researchers focus more on lexical relations among lexical items (Miller, 1995) and fine-grained entity relations in knowledge bases (Mintz et al., 2009). Instead of treating it as a relation extraction or link prediction problem using traditional machine learning approaches (Talukdar and Cohen, 2012; Yang et al., 2015), we seek to better understand prerequisite relations from a perspective of cognitive semantics (Croft and Cruse, 2004). Partially motivated by the theory of frame semantics (Fillmore, 2006), or, to understand a concept, one needs to understand all the related concepts in its “frame”, we propose a metric that measures prerequisite relations based on a simple observation of human learning. When learning concept A, if one needs to refer to concept B for a lot of A’s related concepts but not vice versa, B would more likely be a prerequisite of A than A of B. Specifically, we model a concept in a </context>
<context position="17394" citStr="Yang et al. (2015)" startWordPosition="2834" endWordPosition="2837">e not been well studied in computer science, with only a few exceptions. Liu et al. (2011) studied learning-dependency between knowledge units using classification where a knowledge unit is a special text fragment containing concepts. We focus on more general prerequisite relations among concepts. Talukdar and Cohen (2012) applied a Maximum Entropy classifier to predict prerequisite structures in Wikipedia using various features such as a random walk with restart score and PageRank score. Instead of doing feature engineering, we propose to measure prerequisite relations using a single metric. Yang et al. (2015) proposed Concept Graph Learning to induce relations among concepts from prerequisite relations among courses, where the learned concept prerequisite relations are implicit and thus can not be evaluated. Our method is more interpretable for measuring prerequisite relations. Our work is closely related to the study of semantic relations. One direction is automatic lexical relation extraction. Different methods have been proposed to discover hypernym-hyponym relations based on lexical patterns (Hearst, 1992; McNamee et al., 2008; Ritter et al., 2009), distributional similarity (Kotlerman et al.,</context>
</contexts>
<marker>Yang, Liu, Carbonell, Ma, 2015</marker>
<rawString>Yiming Yang, Hanxiao Liu, Jaime G. Carbonell, and Wanli Ma. 2015. Concept graph learning from educational data. In Proceedings of the Eighth ACM International Conference on Web Search and Data Mining, WSDM 2015, Shanghai, China, February 2-6, 2015, pages 159–168.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>