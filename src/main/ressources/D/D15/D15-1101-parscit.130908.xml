<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.935918">
C3EL: A Joint Model for
Cross-Document Co-Reference Resolution and Entity Linking
</title>
<author confidence="0.953855">
Sourav Dutta
</author>
<affiliation confidence="0.87777">
Max-Planck Institute for Informatics
</affiliation>
<address confidence="0.404981">
Saarbr¨ucken, Germany
</address>
<email confidence="0.57062">
sdutta@mpi-inf.mpg.de
</email>
<author confidence="0.851702">
Gerhard Weikum
</author>
<affiliation confidence="0.781336">
Max-Planck Institute for Informatics
</affiliation>
<address confidence="0.394747">
Saarbr¨ucken, Germany
</address>
<email confidence="0.58843">
weikum@mpi-inf.mpg.de
</email>
<sectionHeader confidence="0.98411" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999574034482759">
Cross-document co-reference resolution
(CCR) computes equivalence classes over
textual mentions denoting the same entity
in a document corpus. Named-entity link-
ing (NEL) disambiguates mentions onto
entities present in a knowledge base (KB)
or maps them to null if not present in
the KB. Traditionally, CCR and NEL have
been addressed separately. However, such
approaches miss out on the mutual syn-
ergies if CCR and NEL were performed
jointly.
This paper proposes C3EL, an unsuper-
vised framework combining CCR and NEL
for jointly tackling both problems. C3EL
incorporates results from the CCR stage
into NEL, and vice versa: additional global
context obtained from CCR improves the
feature space and performance of NEL,
while NEL in turn provides distant KB fea-
tures for already disambiguated mentions
to improve CCR. The CCR and NEL steps
are interleaved in an iterative algorithm that
focuses on the highest-confidence still un-
resolved mentions in each iteration. Ex-
perimental results on two different corpora,
news-centric and web-centric, demonstrate
significant gains over state-of-the-art base-
lines for both CCR and NEL.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997929620689655">
With the advent of large knowledge bases (KB)
like DBpedia, YAGO, Freebase, and others, enti-
ties (people, places, organizations, etc.) along with
their attributes and relationships form the basis of
smart applications like search, analytics, recom-
mendations, question answering, and more. The
major task that arises in both the KB construc-
tion process and the entity-centric applications in-
volves precise recognition, resolution, and link-
ing of named entities distributed across web pages,
news articles, and social media.
Named Entity Recognition (NER) deals with the
identification of entity mentions in a text and their
classification into coarse-grained semantic types
(person, location, etc.) (Finkel et al., 2005; Nadeau
&amp; Sekine, 2007; Ratinov &amp; Roth, 2009). This in-
volves segmentation of token sequences to obtain
mention boundaries, and mapping relevant token
spans to pre-defined entity categories. For exam-
ple, NER on the text Einstein won the Nobel
Prize identifies the mentions “Einstein” and “No-
bel Prize” and marks them as person and misc type,
respectively.
Named Entity Linking (NEL)1 involves the dis-
ambiguation of textual mentions, based on context
and semantic information, and their mapping to
proper entities in a KB (Bunescu &amp; Pas¸ca, 2006;
Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart
et al., 2011; Ratinov et al., 2011; Cornolti et al.,
2013). For example, in the above text, the mention
“Einstein” is linked to the physicist Albert Einstein.
Entity Co-reference Resolution (CR) (Haghighi
&amp; Klein, 2010; Ng, 2010; Lee et al., 2013) is
essentially a clustering task to identify mentions
(and anaphoras) within a document referring to the
same entity, thus computing equivalence classes or
mention groups. For example, mentions Albert
Einstein and Nobel laureate Einstein both
refer to the same entity German physicist Albert
Einstein, but are different from the mention Hans
Albert Einstein.
When CR is extended to an entire text cor-
pus, in order to generate equivalence classes of
co-referring mentions across documents, the task
is known as Cross-document Co-reference Resolu-
tion (CCR) (Bagga &amp; Baldwin, 1998; Culotta et
al., 2007; Singh et al., 2011; Dutta &amp; Weikum,
2015). Note that CCR is not the same as merely
concatenating all documents in the corpus and uti-
lizing existing CR methods. The linguistic diver-
sity across documents and high computational cost
for huge numbers of mentions in the corpus would
typically make such a CR-based simulation per-
form poorly. Neither CR nor CCR links mention
groups to corresponding KB entities. Thus, they
represent both in-KB entities and out-of-KB enti-
ties (e.g., long-tail or emerging entities that do not
have a Wikipedia article) in the same way.
</bodyText>
<footnote confidence="0.9981008">
1Named Entity Disambiguation (NED) and “Wikification”
are often used to denote the same task. The latter may be more
broadly used, though, to include the disambiguation of com-
mon nouns and phrases onto concepts, whereas NED restricts
itself to noun phrases that denote individual entities.
</footnote>
<page confidence="0.942297">
846
</page>
<note confidence="0.9905095">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 846–856,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<bodyText confidence="0.981079972972973">
State-of-the-Art and its Limitations: Established
CR methods rely on rule-based methods or super-
vised learning techniques on syntactic paths be-
tween mentions, semantic compatibility, and other
linguistic features (Haghighi &amp; Klein, 2009), with
additional use of distant features from KBs (Lee
et al., 2013). Modern cluster-ranking (Rahman
&amp; Ng, 2011) and multi-sieve methods (Ratinov
&amp; Roth, 2012) involve incremental expansion of
mention groups by considering semantic types
and Wikipedia categories. CCR methods utilize
transitivity-aware clustering techniques (Singh et
al., 2011), by considering mention-mention sim-
ilarities (Bagga &amp; Baldwin, 1998) along with
features extracted from external KBs (Dutta &amp;
Weikum, 2015).
NEL methods often harness the semantic sim-
ilarity between mentions and entities and also
among candidate entities for different mentions (in
Wikipedia or other KBs) for contextualization and
coherence disambiguation (Hoffart et al., 2011;
Milne &amp; Witten, 2008; Kulkarni et al., 2009; Rati-
nov et al., 2011). However, in the absence of
CR mention groups, NEL has limited context and
is bound to miss out on certain kinds of difficult
cases.
Although NER, CR, CCR and NEL involve
closely related tasks and their tighter integration
has been shown to be promising (Chen &amp; Roth,
2013; Zheng et al., 2013), they have mostly been
explored in isolation. Recently, several joint mod-
els have been proposed for CR-NER (Haghighi &amp;
Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi
et al., 2013), and NER-CR-NEL (Durrett &amp; Klein,
2014). However, to the best of our knowledge, no
method exists for jointly handling CCR and NEL
on large text corpora.
</bodyText>
<subsectionHeader confidence="0.996457">
1.1 Approach and Contributions
</subsectionHeader>
<bodyText confidence="0.999624772727273">
This paper proposes the novel C3EL (Cross-
doCument Co-reference resolution and Entity
Linking) framework for jointly modeling cross-
document co-reference resolution (CCR) and link-
age of mention groups to entities in a knowledge
base (NEL).
Example: To illustrate the potential synergies
between CCR and NEL, consider the 3 docu-
ments in Figure 1 containing 9 mentions (on the
left) with candidate entities from a KB (on the
right). CCR alone would likely miss the co-
reference relation between Logan (Doc 1) and its
alias Wolverine (Doc 2), leaving NEL with the
difficult task of disambiguating “Logan” in a doc-
ument with sparse and highly ambiguous context
(Doc 1). On the other hand, NEL alone would
likely map Australia (Doc 3) to the country (not
the movie) and could easily choose the wrong link
for mention “Hugh”. Moreover, the presence of
Ava Eliot as an out-of-KB mention complicates
the task.
However, if we could more freely interleave
</bodyText>
<table confidence="0.962742125">
Input Corpus Knowledge Base
Hugh Jackman Hugh Hefner
Hugh Grant
Doc 1 When Hugh played Logan,
Ava Eliot was always with him.
Wolverine Mount Logan
(character) Logan Thomas
When Hugh played Wolverine,
Doc 2 his daughter Ava
Hurricane Nicole
accompanied him on the set. Nicole Kidman Nicolas Cage
Nicole Murphy
Doc 3 Hugh and Nicole
Australia (film) Australia
played together in Australia.
Ava Gardner Eva Green
</table>
<figureCaption confidence="0.97317625">
Figure 1: Joint CCR-NEL Example (Green KB en-
tries connected via arrows denote the correct entity linkage for
the mention co-reference groups; while the red ones represent
alternative incorrect candidates with similar surface forms)
</figureCaption>
<bodyText confidence="0.989326897435898">
CCR and NEL and could iterate them several
times, we would be in a much stronger position.
An initial NEL step for the easiest mention, namely
“Wolverine”, maps it to the character of X-Men
movies. This indicates that the three “Hugh” men-
tions could all be the same actor, and are thus eas-
ily merged into a co-reference group using CCR.
We now have enough cues for NEL to choose the
right entity for the “Hugh” mention group, which
in turn enables the proper mapping of “Australia”
to the movie. Finally, it becomes clear that men-
tions “Ava Eliot” and “his daughter Ava” should be
merged into the same group and represented as an
out-of-KB entity mapped to null.
The above example clearly demonstrates that
interleaving CCR and NEL is highly beneficial.
However, appropriate choices for the ordering of
CCR and NEL steps are usually not obvious at all.
The proposed C3EL algorithm solves this prob-
lem: automatically determining an efficient inter-
leaving of CCR and NEL.
Approach: C3EL iteratively aggregates interme-
diate information obtained from alternating steps
of CCR and NEL, thus forming a feedback loop
for propagating mention features and entity knowl-
edge. Intuitively, co-referring mentions obtained
via CCR generate global context for improved
NEL performance, while mentions linked to KB
entities (by NEL) provide distant semantic features
with additional cues for CCR. C3EL couples sev-
eral building blocks like unsupervised hierarchi-
cal clustering, context summaries for mentions and
distant KB features for entities, drawing inspiration
from the CCR-only method of (Dutta &amp; Weikum,
2015). Mention linking to the KB (NEL) is per-
formed using distant knowledge and co-occurring
mentions.
In a nutshell, the major contributions of this pa-
per are:
</bodyText>
<listItem confidence="0.996983857142857">
• the C3EL framework for joint computation of
cross-document co-reference resolution (CCR)
and entity linking to a KB (NEL), based on
propagating information across iterative CCR
and NEL steps;
• techniques for considering co-occurring men-
tions in context summaries and for harnessing
</listItem>
<page confidence="0.988439">
847
</page>
<bodyText confidence="0.722643333333333">
context-based keywords for link validation in
NEL, improving accuracy on out-of-KB enti-
ties;
</bodyText>
<listItem confidence="0.988514125">
• an experimental evaluation with two different
corpora, one based on news articles and one
based on web pages, demonstrating substantial
gains for both CCR and NEL over state-of-the-
art methods.
2 C3EL: Joint CCR-NEL Framework
Given an input corpus C of n documents, C =
{D1, D2, · · · , Dn} with entity mentions EM =
{m11, m12, ··· , m21, m22, ··· } (mij E Di),
C3EL aims to jointly compute:
• CCR: an equivalence relation over EM with
equivalence classes Ei, such that Ei ∩i=,4j Ej =
∅ and Ui Ei = EM, and
• NEL: linking each of the classes Ei to entities
present in a KB or map it to null if there is no
proper entity in the KB.
</listItem>
<bodyText confidence="0.889852666666667">
To this end, C3EL consists of 3 algorithmic
stages: (i) Pre-Processing, (ii) Interleaved NEL and
CCR, and (iii) Finalization.
</bodyText>
<subsectionHeader confidence="0.998302">
2.1 Pre-Processing Stage
</subsectionHeader>
<bodyText confidence="0.992701166666667">
HTML pages in the input corpus C are transformed
into plain text using standard tools like jsoup.
org. Recognition and markup of mentions are per-
formed using the Stanford CoreNLP toolkit (nlp.
stanford.edu), and a coarse-grained lexical
type for each mention (e.g., person, location, orga-
nization, etc.) is obtained from the Stanford NER
Tagger (Finkel et al., 2005). The multi-pass sieve
algorithm for single-document CR (Raghunathan
et al., 2010; Lee et al., 2011; Lee et al., 2013) then
computes mention co-reference chains per docu-
ment, and a head mention is chosen for each of the
mention groups (chains). The head mention is typ-
ically represented by the most explicit denotation
of the entity (e.g., person’s full name with title, lo-
cation name with country, etc.).
For each of the mention groups Mi, C3EL then
constructs a context summary using:
</bodyText>
<listItem confidence="0.980564333333333">
• Sentences – all sentences in the document that
contain mentions of group Mi; and
• Co-occurrence – all sentences for other men-
tion groups that contain mentions co-occurring
in any of the sentences of Mi (as obtained
above).
</listItem>
<bodyText confidence="0.850513285714286">
Formally, for each mention group Mi, let 5(Mi) =
{sentence(mj) |mj E Mi} represent the set
of extracted sentences, where sentence(mj) de-
notes the sentences in which mention mj occurs.
Also, let the co-occurring mention set of Mi be
Co(Mi) = {m&apos; |m&apos; E 5(Mi) ∧ m&apos; E/ Mi}. The
context summary of Mi is defined as:
</bodyText>
<equation confidence="0.992998">
CS(Mi) = 5(Mi) U U 5(m&apos;)
(m&apos;ECo(Mi)
</equation>
<bodyText confidence="0.973726340909091">
The context summaries intentionally do not in-
clude any distant KB features for mentions. The
intuition is to minimize potential noise from overly
speculative mappings to the KB at this initial stage.
2.2 Interleaved NEL &amp;CCR Approach
After the preliminary CR step on each document
and the construction of context summaries, C3EL
now performs an initial NEL step for each of the
mention groups Mi, using the extracted sentences
5(Mi) as inputs to NEL. It obtains the best match-
ing entity, the confidence of the match, and its
corresponding Wikipedia page. Off-the-shelf NEL
software (like WikipediaMiner or Illinois-Wikifier)
is used for mention-entity mapping based on prior
popularity of the named-entities (from the KB) and
textual similarity between 5(Mi) (context of the
mention group) and the entity descriptions in KB.
For each Mi, the entity link obtained (from
NEL) is then
using a similarity mea-
sure between features from the context summary,
CS(Mi) (including co-occurring mentions) and
distant KB labels
the link validation pro-
cedure of C3EL. This explicit use of co-occurring
(Co(Mi)) contexts helps to better iden-
tify out-of-KB entities compared to direct full-
fledged NEL using the entire input text (shown in
Section 3). Also the use of NEL on 5(Mi) alone,
makes
The mappings between the mention groups and
KB entries are then classified, on the basis of
the NEL confidence scores, into Strong Evidence
(SE), Weak Evidence (WE), and No Evidence (NE)
classes. For mention groups placed in SE, the
KB features (obtained previously) are appended to
their context summaries, while mentions strongly
linked to same KB entities are considered to be co-
referring and hence grouped together (performing
implicit CCR).
Considering our example (Figure 1), we now
outline the iterative steps of
interleaving
NEL &amp; CCR.
</bodyText>
<listItem confidence="0.9849905">
1. During Iteration 1,
performs:
• NEL: The initial NEL step maps the unam-
biguous mentions,
</listItem>
<bodyText confidence="0.991624545454545">
to the X-Men
movie character and Australia to the country,
with high confidence. However, link validation
fails for
as there is very low similar-
ity between the mention context features (e.g.,
Hugh, Wolverine, etc.) and the distant KB la-
bels extracted from its Wikipedia page (e.g.,
Commonwealth, population, etc.); thus the link
is dropped and the mention is added to NE. So
only the mention
</bodyText>
<equation confidence="0.91937825">
“validated”
– forming
mentions’
C3EL“light-weighted”.
C3EL
C3EL
Wolverine
“Australia”
</equation>
<bodyText confidence="0.452203">
“Wolverine” is added to the
</bodyText>
<page confidence="0.976008">
848
</page>
<bodyText confidence="0.929616625">
SE class and enriched with KB features (e.g.,
alias Logan).
On the other hand, the 3 “Hugh” mentions ex-
hibit low NEL confidence due to the high am-
biguity of this first name and are therefore clas-
sified into WE. The remaining mentions have
extremely low NEL confidence (due to sparse
contextual information) and are added to NE.
</bodyText>
<listItem confidence="0.948316">
• CCR: The WE and NE classes are fed sep-
arately to the CCR procedure. Based on
the context summary similarities between men-
tions, C3EL performs hierarchical clustering
to group together the “Hugh” mentions (in
</listItem>
<bodyText confidence="0.683701666666667">
the WE class) and creates a co-referring men-
tion group with the individual mentions’ con-
text summaries concatenated. This merging
of summaries grows and strengthens captured
contexts, which propagates across documents.
This concludes the first iteration of C3EL.
</bodyText>
<listItem confidence="0.967845166666667">
2. The above results are provided to the second
Iteration:
• NEL: The context summary of the “Hugh”
mention group in WE now provides definitive
cues to correctly map it to the actor Hugh Jack-
man with high confidence, thus placing it in the
SE class.
• CCR: The ensuing CCR step groups together
“Ava Eliot” and “Ava” (in NE) using co-
occurrence context of the co-referring Hugh
mentions.
3. Subsequent NEL iterations (on WE and NE)
</listItem>
<bodyText confidence="0.958953571428571">
identify “Ava” as an out-of-KB entity and cor-
rectly links “Australia” to the movie using CCR-
generated mention-group contexts and link valida-
tion. CCR finally groups together “Logan” with
“Wolverine” based on context similarity with dis-
tant KB features. This process of alternating CCR
and NEL is repeated until all mention groups are
strongly connected to KB entities (placed in SE),
or no changes are made anymore.
The NEL and CCR procedures are performed
separately on the different mention types (like
PER, LOC, etc.), since different mention types
rarely co-refer. We next present the internal work-
ing details of the NEL and CCR stages of C3EL.
</bodyText>
<subsectionHeader confidence="0.537804">
2.2.1 Named-Entity Linking (NEL) Stage
</subsectionHeader>
<bodyText confidence="0.981525771428572">
In its NEL procedure, C3EL disambiguates men-
tions to entities in the YAGO knowledge base
(yago-knowledge.org). We perform NEL on
the sentences (S(Mi)) of a mention group, us-
ing named-entity popularity statistics and context,
to obtain the best matching entity, its confidence
score, and the corresponding Wikipedia page (from
sameAs link in YAGO). Assume a mention group
Mi to be mapped to an entity ei with a confidence
score of O(Mi, ei).
A. Link Validation: For each mention group (e.g.,
Hugh), we extract distant KB labels such as se-
mantic types or categories (e.g., actor), title (e.g.,
Golden Globe winner), alias (e.g., Wolverine), lo-
cation, and gender (for person) from the Wikipedia
page infoboxes. The similarity of these features
to keywords obtained from the context summary
CS(Mi) is computed using IR-style term frequen-
cies within a document (tf) and inverse document
frequencies within the corpus (idf). We utilize the
bag-of-words model based tf x idf-weighted co-
sine similarity measure. If the similarity score is
above a threshold, T, the NEL result is accepted,
otherwise it is discarded – thus avoiding noisy link-
age of sparse mentions to prominent KB entries.
This subtle introduction of controlled distant su-
pervision within the C3EL framework enables ef-
ficient detection of out-of-KB mentions.
B. Classification: To sift out well-known and
long-tail entities from new ones, and prevent
“noisy” interactions among the contexts of in-
KB and out-of-KB mentions (with similar surface
forms), mention groups Mi (linked to ei with score
O(Mi, ei)) are classified into 3 classes by 2 thresh-
old parameters, 5s and 5w, as:
</bodyText>
<listItem confidence="0.996538045454546">
• Strong Evidence (SE): For O(Mi, ei) ≥ 5s,
mention group Mi exhibits high linkage con-
fidence with ei and is placed in SE. If two
or more mentions in SE are independently
mapped to the same KB entity, they co-refer
transitively and are hence grouped together
with their context summaries merged (implicit
CCR). Distant KB features for mentions in SE
are extracted and appended to CS(Mi), provid-
ing additional cues for later steps.
• Weak Evidence (WE): Mention groups with
5w ≤ O(Mi, ei) &lt; 5s are placed in this class.
They mostly represent long-tail in-KB entities
(sparsely represented in KB) with limited se-
mantic information (for detection) but might
also be new/emerging entities absent from KB.
• No Evidence (NE): O(Mi, ei) &lt; 5w represents
mentions groups that have been mapped to null
(or have near-zero match confidence) or have
failed link validation during the NEL proce-
dure. These entities are most likely to be out-
of-KB and are allocated to this class.
</listItem>
<subsectionHeader confidence="0.60768">
2.2.2 Cross-Document CR (CCR) Stage
</subsectionHeader>
<bodyText confidence="0.999861461538462">
The CCR stage of C3EL adopts the sampling-
based hierarchical clustering approach of (Dutta
&amp; Weikum, 2015), to obtain co-referring mention
clusters.
A. Similarity Measure: To infer whether two
mention groups represent the same entity, the simi-
larity between the context summaries are computed
based on (i) tf-idf-weighted bag-of-words cosine
distance, and (ii) partial-match scores of multi-
word keyphrases in bounded text windows (Taneva
et al., 2011). The context summaries (with stop-
words removed) are re-interpreted as, (i) bag of
words, and (ii) bag of keyphrases, to extract fea-
</bodyText>
<page confidence="0.992952">
849
</page>
<bodyText confidence="0.999334434782609">
ture vectors for similarity computation. Finally,
the mixture model of bag-of-words (BoW) and
keyphrases (KP) of (Dutta &amp; Weikum, 2015) is
used to assign feature weights using tf-idf measure.
B. Hierarchical Clustering: s mention groups
are uniformly randomly sampled and their sim-
ilarities to the other groups (using context sum-
mary) are computed. A similarity-weighted graph
with the mention groups as nodes and edge weights
representing mention-mention similarities is con-
structed. Bisection-based hierarchical balanced
min-edge-cut graph partitioning (Buluc et al.,
2013) is performed, using the METI5 soft-
ware (Karypis &amp; Kumar, 1999)2, to partition non-
coreferent mentions groups. The Bayesian Infor-
mation Criterion (BIC) (Schwarz, 1978; Hour-
dakis et al., 2010), a Bayesian variant of Minimum
Description Length (Gr¨unwald, 2007), is used as
the cluster split stopping criterion, and the context
summaries within each final cluster are merged.
CCR aims to process heterogeneous corpora that
go beyond a single domain and style, such as Web
collections.
</bodyText>
<subsectionHeader confidence="0.998467">
2.3 Finalization Stage
</subsectionHeader>
<bodyText confidence="0.999972857142857">
For the remaining mention groups in WE, we fi-
nally perform threshold based disambiguation of
mention clusters using the context summaries. For
each mention group MZ E WE, we compute (1) its
context summary similarities (as in Section 2.2.2)
to all other mention groups Mj in SE by also using
distance features from the weakly linked KB enti-
ties, and (2) textual overlap between the mention
group representatives. MZ is concatenated with the
best matching entity Mk (in SE) if the similarity
score is above a threshold θ; else MZ is marked as
an out-of-KB entity (mapped to null) and is placed
in the NE class. This helps in reducing propagated
CR errors like erroneous mention boundary detec-
tion (in NER), omissions in co-reference chain, etc.
(leading to “phantom” out-of-KB entities).
The obtained mention groups represent the final
equivalence classes of co-referring mentions across
documents – capturing both in-KB entities (with
links to the KB) in the 5E class and out-of-KB
entities (mapped to null) in the NE class.
</bodyText>
<sectionHeader confidence="0.998558" genericHeader="introduction">
3 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.913476833333333">
In this section, we empirically study the perfor-
mance of C3EL against various state-of-the-art
methods. We analyze the individual gains in CCR
and NEL due to the joint modeling.
Datasets: We use the following 2 publicly avail-
able corpora:
</bodyText>
<listItem confidence="0.925775">
• EventCorefBank (ECB) corpus3 (Bejan &amp;
Harabagiu, 2010): contains 482 news and Web
articles (classified into 43 topics) with a total
</listItem>
<page confidence="0.923228">
2
</page>
<bodyText confidence="0.9130676">
glaros.dtc.umn.edu/gkhome/metis/metis/overview
3faulty.washington.edu/bejan/data/ECB1.0.tar.gz
of 5447 mentions corresponding to 1068 dis-
tinct named-entities. Entity co-reference an-
notations (across documents within each topic
cluster) were provided by (Lee et al., 2012),
and we performed manual examination of the
annotations for KB linking of the entities to
Wikipedia entries, if present; thus providing
ground truth for both CCR and NEL.
</bodyText>
<listItem confidence="0.9969771">
• ClueWeb2009 FACC1 dataset4 (Gabrilovich
et al., 2013): provides machine automated
entity-linkage annotations of the ClueWeb09
corpus (ca. 1 Billion crawled Web pages) with
Freebase entries5. The corpus contains many
topical domains and highly diverse documents
from news, movie reviews, people home pages
to blogs and other social media posts. We ran-
domly select 500K documents containing 4.64
Million mentions associated with 1.29 Million
distinct entities to form our corpus. For NEL
ground-truth construction, we link the entities
to their Wikipedia pages (using Freebase’s “on
the web” property). Since no explicit anno-
tations of inter-document entity co-references
exists, we consider two mentions (in different
documents) to co-refer if they are linked with
the same Freebase entity.
Evaluation: To assess the output quality of C3EL
we use the following established metrics:
• B3 F1 score (Bagga &amp; Baldwin, 1998): mea-
sures the F1 score as the harmonic mean of av-
erage precision and recall computed over all
mention groups in the final equivalence classes.
Precision (for a mention group) represents the
ratio of the number of correctly reported co-
references (or linking) to the actual number;
while recall computes the fraction of the gold-
standard annotations correctly identified.
• φ3 − CEAF score (Luo, 2005): provides
</listItem>
<bodyText confidence="0.955064466666667">
an alternate F1 score computed as in the B3
measure; but calculates precision and recall of
mention groups using the best 1-to-1 mapping
(i.e., mapping with maximum mention overlap)
between the resultant equivalence classes and
those in the ground truth. Normalization with
the number of mentions for each of the resul-
tant classes yields the φ4-CEAF score.
We consider only the 3 most notable mention
types: person (PER), location (LOC), and orga-
nization (ORG) – accounting for 99.7% of enti-
ties present in the ECB corpus and 96.3% of our
ClueWeb09 corpus. All experiments were con-
ducted on a 4 core Intel i5 2.50 GHz processor with
8GB RAM running Ubuntu 12.04 LTS.
</bodyText>
<subsectionHeader confidence="0.993589">
3.1 Parameter Tuning &amp; Sensitivity Study
</subsectionHeader>
<bodyText confidence="0.9954955">
Validation of entity linkage to KB and their subse-
quent classification into confidence classes (as de-
</bodyText>
<page confidence="0.507726">
4lemurproject.org/clueweb09/FACC1
</page>
<bodyText confidence="0.3480455">
5Human analysis of a subset of the annotations generated revealed a preci-
sion of 80 − 85% (Gabrilovich et al., 2013)
</bodyText>
<page confidence="0.916785">
850
</page>
<table confidence="0.9999405">
Approach P R B3 03 04
EECR 74.9 55.5 63.7 - 33.7
CROCS 73.11 75.28 74.18 67.35 -
C3EL 79.52 82.91 81.18 73.89 53.3
</table>
<tableCaption confidence="0.999509">
Table 2: CCR performance (%) comparison on ECB
</tableCaption>
<bodyText confidence="0.997164692307692">
scribed in Section 2) during the NEL step of C3EL
are based on 3 parameters: confidence thresholds
(6s and 6w) and validation threshold (T); the values
of which can be tuned based on cross-validation
approach with train and test data subsets. Using
the “gold annotations” of the train-set (30% of to-
tal data), parameter values providing the best preci-
sion score are individually learnt using line search
with small step size.
In our experimental setup, we systematically
vary the parameter values and observe its effects
on C3EL for the training data. With increase in
6s, the number of mentions mapped to the Strong
Evidence (SE) class decreases. This in turn limits
the influx of external KB features, thus degrading
CCR performance as observed in Table 1(a). While
for low values of 6s, even weak mention links are
placed in SE, leading to a decrease in precision due
to noisy KB feature inclusion. On the other hand,
a high 6w value increases the number of mentions
in the NE class, while low values tends to accu-
mulate mentions in the WE class. This adversely
affects the detection of out-of-KB entities due to
noise from other co-occurring similar KB mentions
(refer Table 1(b)) during clustering in CCR step.
The effect of T on C3EL has be shown in Ta-
ble 1(c). Similar to the behavior induced by 6s,
we observe that a high T limits entity linking and
possible KB feature inclusion, while an extremely
low value (near to zero) allows for noisy feature
incorporation – both situations leading to lowered
CCR efficiency. However, since T prevents gross
mis-alignment of mentions to KB entities, a wide
range of small value (0.1− 0.35) is seen to provide
comparable performance.
Hence, for our remaining experimental study we
set 6s = 0.11 and 6w = 0.06 (as in (Hoffart et al.,
2014)), while T is set to 0.1, and threshold for the
finalization stage θ = 2 x 6s = 0.22.
</bodyText>
<subsectionHeader confidence="0.999332">
3.2 CCR Performance Results
</subsectionHeader>
<bodyText confidence="0.99779575">
We initially benchmark the performance improve-
ment in cross-document co-reference resolution
(CCR) procedure by C3EL against two compet-
ing approaches:
</bodyText>
<listItem confidence="0.9884306">
(1) state-of-the art sampling based hierarchical
clustering method, CROCS (Dutta &amp; Weikum,
2015); and
(2) iterative joint entity-event CCR, EECR (Lee
et al., 2012).
</listItem>
<bodyText confidence="0.714121333333333">
Table 2 tabulates the results obtained on the ECB
dataset. We observe C3EL to decisively outper-
form both the existing methods, providing a B3
F1 improvement of around 7% over CROCS and
17% over EECR. We further attain around 6%
03 −CEAF score enhancement over CROCS, and
</bodyText>
<table confidence="0.998269666666667">
Approach P (%) R (%) B3 (%) 03 (%)
CROCSG 79.9 83.33 81.58 74.11
C3ELG 84.74 89.9 87.24 80.5
</table>
<tableCaption confidence="0.970676">
Table 3: CCR results on ECB
</tableCaption>
<table confidence="0.999914142857143">
Type Approach P (%) R (%) B3 (%)
PER CROCSG 71.8 74.15 72.96
C3ELG 84.85 82.73 83.78
LOC CROCSG 78.23 85.41 81.66
C3ELG 81.41 94.31 87.29
ORG CROCSG 85.73 87.89 86.8
C3ELG 88.52 91.82 90.14
</table>
<tableCaption confidence="0.999569">
Table 4: CCR results on ECB for mention types
</tableCaption>
<bodyText confidence="0.688087666666667">
a significant 20% improved 04 − CEAF score
compared to EECR.
A. Gold Results: Errors introduced during the pre-
processing stage of C3EL (e.g., mention omission,
tag mis-classification, intra-document CR errors,
etc., by the Stanford CoreNLP toolkit) propagate
to subsequent computing stages and adversely im-
pacts the overall system performance. To provide
an unbiased viewpoint of the actual performance
of C3EL, we manually provided “exact” men-
tions, mention tags, and intra-document CR men-
tion chains for the ECB corpus; thereby obtaining
gold performance results. From Table 3 we ob-
serve a 6% F1 points improvement (for both B3 &amp;
CEAF-03) in C3EL compared to CROCS.
</bodyText>
<listItem confidence="0.87818545">
B. Mention Categorization: Person mention type
(PER) provides the greatest challenge for CCR sys-
tems (compared to other types like LOC, ORG,
etc.) due to associated nicknames, titles, and varied
surface forms (abbreviations, spellings, etc.). We
thus evaluate the CCR performance of C3EL (and
compare it with CROCS) on the ECB data, with
“exact” input mentions, for the different mention
categories. Table 4 validates that our joint mod-
eling provides better global information cues, re-
porting a B3 F1 score enhancement of around 11%
over CROCS for PER mentions; along with im-
proved results for the other mention types as well.
C. Large Data: To study the robustness of C3EL
and the effects of large datasets on CCR, we
performed evaluations on the ClueWeb09-FACC1
dataset. Similar to the ECB dataset, C3EL ex-
hibits a B3 F1 score improvement of nearly 10%
and a 03-CEAF F1 improvement of 12% over
CROCS (refer Table 5).
</listItem>
<bodyText confidence="0.9997416">
The above experimental results showcase that
a combined approach helps overcome challenges
faced in CCR by entity linkage and corresponding
distant KB feature extraction; improving the over-
all accuracy.
</bodyText>
<subsectionHeader confidence="0.998847">
3.3 Named-Entity Linking (NEL) Results
</subsectionHeader>
<bodyText confidence="0.999781857142857">
We now benchmark the performance of named-
entity linking (NEL) procedure for C3EL against
the state-of-the-art open-source AIDA software
(github.com/yago-naga/aida). We sepa-
rately inspect the precision of mention linking for
prominent entities (in-KB) as well as new/emerging
(out-of-KB) entities, and characterize the links as
</bodyText>
<page confidence="0.996589">
851
</page>
<table confidence="0.9653556">
Datasets bs (B3 F1) bw (P) r (B3 F1)
0.01 0.05 0.10 0.15 0.20 0.01 0.02 0.04 0.06 0.08 0.03 0.10 0.20 0.35 0.50
ECB 79.3 82.2 84.2 83.5 81.0 73.1 75.3 77.3 78.7 78.4 76.9 81.2 81.2 81.1 79.2
ClueWeb 70.1 77.2 81.5 81.0 78.7 78.2 81.1 83.6 85.1 85.1 70.3 79.1 78.2 78.8 76.4
(a) (b) (c)
</table>
<tableCaption confidence="0.998343">
Table 1: C3EL performance (a) in CCR with δ3, (b) in out-of-KB NEL with δ,,,, and (c) in CCR with T
</tableCaption>
<table confidence="0.999521">
Approach P (%) R (%) B3 (%) φ3 (%)
CROCS 68.66 70.96 69.79 62.85
C3EL 75.76 81.42 78.49 74.13
</table>
<tableCaption confidence="0.833383">
Table 5: CCR results on ClueWeb09-FACC1
</tableCaption>
<table confidence="0.999876">
Approach Within-KB Out-of-KB Overall
C I U C I P (%)
AIDA 86.5 13.5 0.0 63.9 36.1 83.4
C3EL 85.4 14.4 0.2 79.0 21.0 84.9
</table>
<tableCaption confidence="0.999745">
Table 6: NEL performance (%) comparison on ECB
</tableCaption>
<bodyText confidence="0.998154515151515">
Correct (C), Incorrect (I), or Unlinked (U). The
results on the ECB corpus are reported in Table 6.
C3EL attains comparable performance (∼ 85%
precision) to that of AIDA for well-known entity-
mentions present in KB; albeit with a few mentions
remaining unlinked due to our cautious link val-
idation (using 7-) approach. However, the use of
7- reduces aggressive KB linking to provide a sig-
nificant 15% improvement (over AIDA) in precise
detection of new/emerging entities absent in KB.
Overall, an 1.5% precision gain is observed by the
joint formulation.
A. Large Data: The diverse nature of the web-
scale ClueWeb09 dataset clearly portrays the per-
formance gains in NEL procedure due to CCR gen-
erated information integration. For entities present
in the KB, we observe an accuracy improvement of
0.5% over AIDA (refer Table 7). Similar to that of
the ECB data, C3EL attains a significant ∼ 14%
improvement in the detection of new/emerging en-
tities not represented in KB. For the 1 million men-
tions, C3EL provides around 4% overall perfor-
mance improvements.
Using a bootstrap re-sampling t-test (as in (Dur-
rett &amp; Klein, 2014)), we observed high statistical
significance (p &lt; 0.01) for Out-of-KB and Overall
NEL, whereas the difference for Within-KB NEL
is not statistically significant. Coping with Out-of-
KB entities is essential for joint CCR+NEL, and
an improved NEL performance using propagated
information from CCR using semantics along with
link validation enables highly efficient detection of
new or emerging entities.
</bodyText>
<subsectionHeader confidence="0.999054">
3.4 Comparison with Joint Models
</subsectionHeader>
<bodyText confidence="0.9987185">
Traditional CR methods fail to cope with the het-
erogeneity of mentions and contexts across mul-
tiple documents, and some form of clustering or
joint reasoning over all mentions is thus mandatory.
These methods have quadratic or cubic (some-
times even exponential) complexity, and hence run-
ning CR+NEL on a concatenated super-document
works only for small corpora, and would be pro-
hibitively expensive for large corpora, even in of-
fline processing mode (Singh et al., 2011).
However, to study the behavior of existing CR-
NEL joint models under “small” CCR environ-
</bodyText>
<table confidence="0.9994175">
Approach Within-KB Out-of-KB Overall
C I U C I P (%)
AIDA 88.5 10.6 1.0 69.6 30.4 84.6
C3EL 89.0 9.8 1.2 83.7 16.3 88.1
</table>
<tableCaption confidence="0.994307">
Table 7: NEL results (%) on ClueWeb09-FACC1 (statistical
significance p &lt; 0.01 for Out-of-KB entities)
</tableCaption>
<bodyText confidence="0.971673">
ments, we compare C3EL with:
</bodyText>
<listItem confidence="0.9897795">
(1) multi-sieve based NECo (Hajishirzi et al.,
2013)6; and
(2) conditional random field based BER (Durrett
&amp; Klein, 2014) 7.
</listItem>
<bodyText confidence="0.999882357142857">
Three topic clusters from the ECB corpus with
3, 4, and 5 articles respectively were selected, and
the documents within each cluster were merged to
form 3 “super-articles” (one per topic), forming a
simulated CR setting. NECo and BER were then
used to perform CR and NEL on these 3 articles,
and the results compared with that obtained by
C3EL on the original documents. We repeatedly
sample 12 articles across 3 topic clusters, and ex-
ecute the approaches to report the micro-averaged
results across 5 independent runs.
From Table 8(a) we observe that the algorithms
exhibit comparable co-reference resolution perfor-
mance; thus validating propagation of global se-
mantics in C3EL due to the joint formulation.
However, such CR methods using multi-sieves and
CRF do not scale beyond few documents (upon
concatenation), and require at least 4x more run-
time compared to C3EL. Hence, CCR cannot be
efficiently tackled by simply employing CR meth-
ods on a “super-document”.
However, harnessing of non-local mention fea-
tures (via CCR) and efficient detection of new
mentions using link validation enables C3EL to
achieve a gain of around 5% in NEL compared to
others (see Table 8(b)). For both procedures, we
observed statistically significant improvements of
C3EL over BER and NECo with p &lt; 0.05, using
the bootstrap re-sampling t-test.
To further study the effect of larger corpus, we
sampled 25 documents (with co-referring men-
tions) from the ClueWeb09 dataset and performed
analysis among the algorithms. As previously, we
observed significant computational complexity for
traditional CR methods when applied to CCR set-
ting making them far slower (6 − 7x) than C3EL.
Table 9 reports the CCR and NEL averaged results
obtained across 5 independent runs. We attained
comparable performance in CCR with around 3%
improvement in NEL. All the algorithms are seen
to achieve high NEL results due to the large pres-
ence of well-known (in-KB) entities.
</bodyText>
<footnote confidence="0.9317815">
6cs.washington.edu/research-projects/nlp/neco
7nlp.cs.berkeley.edu/projects/entity.shtml
</footnote>
<page confidence="0.987834">
852
</page>
<table confidence="0.987488333333333">
Approach P (%) R (%) B3 (%)
NECo 87.77 82.09 84.84
BER 88.30 86.53 87.41
C3EL 87.54 88.11 87.82
Approach C (%) H (%) U (%)
NECo 89.13 10.87 0.0
BER 89.89 10.11 0.0
C3EL 93.2 4.61 2.19
(a) (b)
</table>
<tableCaption confidence="0.970292">
Table 8: Joint “Simulated” results on ECB subset for (a) CCR, and (b) NEL (statistical significance P &lt; 0.05)
</tableCaption>
<table confidence="0.983644333333333">
Approach P (%) R (%) B3 (%)
NECo 81.14 79.65 80.39
BER 84.36 83.01 83.68
C3EL 83.52 85.56 84.53
Approach C (%) H (%) U (%)
NECo 94.71 5.29 0.0
BER 95.27 4.73 0.0
C3EL 98.23 1.5 0.27
(a) (b)
</table>
<tableCaption confidence="0.998623">
Table 9: Joint “Simulated” results on ClueWeb09 subset for (a) CCR, and (b) NEL
</tableCaption>
<subsectionHeader confidence="0.996277">
3.5 Algorithmic Baseline Study
</subsectionHeader>
<bodyText confidence="0.999613666666667">
We explore the performance of variants of C3EL
(on both corpora) ablating various system compo-
nents (see Table 10). Explicitly, we consider:
</bodyText>
<listItem confidence="0.899543692307692">
• Co-occurring Mentions: Removal of cooc-
currence mentions context from the context
summaries constructed, reduces semantic in-
formation and adversely affects both NEL and
CCR procedures. We thus observe a sharp de-
crease in CCR performance and also a degra-
dation in entity linking.
• Link Validation: Filtering of mention linking
to KB entities using link validation step (with
threshold T) in C3EL enables corroboration of
mention context keywords with the linked en-
tity features. This leads to enhanced detection
of new or emerging entities by reducing induc-
tion of noise during the CCR phase. Removal
of this process permits aggressive entity linking
and introduces noise, affecting new/emerging
entity detection. We observe (from Table 10)
nearly 20% reduction of precision (on both
datasets) in identification of out-of-KB entity-
mentions compared to C3EL.
• NEL Categorization: The differentiation of
mentions (into classes) confidently mapped to
KB entity reduces the collusion of “strong”
linked mentions with other “noisy” mention
contexts. This reduces incorrect grouping of
different mentions with similar surface forms,
contexts, etc., thereby improving precision of
the CCR process. Use of a single NEL classi-
fication approach is observed to degrade CCR
results, which in turn increases spurious entity
linkage, decreasing NEL efficiency (Table 10).
• Distant KB features: As observed in (Baker,
2012; Zheng et al., 2013), extracted external
KB features provide global and enhanced infor-
mation cues promoting CR. We similarly ob-
serve CCR to attain the lowest F1 scores (com-
pared to other baselines) when KB features
are ignored. This in turn affects the linking
of (some) well-known entities due to reduced
</listItem>
<bodyText confidence="0.95790575">
context, leading to incorrect or low confidence
NEL. Since no feature inclusion is performed
for out-of-KB mentions, no effect is observed.
We observe that a joint formulation encompass-
ing multiple information sources (along with noise
filtering) enables mutually enhanced CCR and
NEL within the proposed iterative feedback based
framework, C3EL.
</bodyText>
<sectionHeader confidence="0.999767" genericHeader="related work">
4 Related Work
</sectionHeader>
<bodyText confidence="0.959083585365854">
Co-reference Resolution (CR): Traditional intra-
document CR methods involve syntactic and se-
mantic feature combination for identifying the best
antecedent (preceding name or phrase) for a men-
tion. CR methods employ rules or supervised
learning techniques based on linguistic features
such as syntactic paths and mention distances to
assess semantic compatibility (Haghighi &amp; Klein,
2009; Raghunathan et al., 2010; Rahman &amp; Ng,
2011), while syntactic features are derived by deep
parsing of sentences and noun group parsing. Se-
mantic features from background knowledge re-
sources like encyclopedia were used in (Daum´e &amp;
Marcu, 2005; Ponzetto &amp; Strube, 2006; Ng, 2007).
The use of Wikipedia and structured knowledge
bases (such as YAGO) to obtain mention-type re-
lation and fine-grained mention attributes was ex-
plored by (Haghighi &amp; Klein, 2009; Rahman &amp;
Ng, 2011). An overview of CR methods is given
in (Ng, 2010).
Recent methods involve the use of multi-phase
sieve, applying a cascade of rules for narrow-
ing down the antecedent candidates for a men-
tion (Raghunathan et al., 2010). Cluster ranking
functions have also been proposed (Rahman &amp; Ng,
2011; Zheng et al., 2013) to extend this paradigm
for incrementally expanding and merging mention
groups with preceding candidate clusters using re-
latedness features (Ratinov &amp; Roth, 2012) and dis-
tant knowledge inclusion (Durrett &amp; Klein, 2013).
Person name disambiguation, a specific variation
of CR, dealing with only person names, titles, nick-
names, and other surface form variations was intro-
duced in (Chen &amp; Martin, 2007).
Distant Knowledge Labels: For obtaining seman-
tic features, additional knowledge resources such
as Wikipedia, YAGO, and FrameNet have been
considered (Rahman &amp; Ng, 2011; Baker, 2012).
CR methods with confidence-thresholds were pro-
posed in (Ratinov &amp; Roth, 2012; Lee et al., 2013),
and (Zheng et al., 2013) generalized these tech-
</bodyText>
<page confidence="0.997302">
853
</page>
<table confidence="0.999934857142857">
Baseline ECB Dataset ClueWeb09-FACC1 Dataset
CCR result NEL results CCR result NEL results
Within-KB Out-of-KB Within-KB Out-of-KB
P R B3 C ff III C ff P R B3 C ff III C ff
Ignored Mention 72.5 74.4 73.4 80.2 19.6 0.2 74.4 25.6 69.3 72.2 70.7 83.8 14.6 1.6 80.6 19.4
Co-occurrence
Link Validation 79.0 81.4 80.2 85.5 14.5 0.0 62.8 37.2 74.8 81.0 77.8 88.9 10.1 1.0 69.8 30.2
(τ) ignored
Removed NEL 73.2 80.7 76.8 83.9 15.9 0.2 76.1 23.9 70.1 77.6 73.6 86.1 12.3 1.6 79.5 20.5
Classification
Distant KB 68.9 73.1 70.9 82.8 17.0 0.2 79.0 21.0 66.4 72.9 69.5 85.4 13.0 1.6 83.7 16.3
feature dropped
C3EL 79.5 82.9 81.18 85.4 14.4 0.2 79.0 21.0 75.8 81.4 78.5 88.3 10.1 1.6 83.7 16.3
(Complete)
</table>
<tableCaption confidence="0.999154">
Table 10: CCR and NEL results (%) of C3EL for different baseline variations
</tableCaption>
<bodyText confidence="0.994098987654321">
niques by ranking the matching entities for dis-
tant labeling. However, such prior methods utilize
distance labels of the current mention and consid-
ers all matching mentions making the procedure
expensive. On the other hand, we extract distant
features for the strongly matching (best) candidate
only, reducing the performance overhead.
Cross-Document CR (CCR): Early approaches
towards CCR involved the use contextual infor-
mation from input documents for IR-style similar-
ity measures (e.g., tf×idf score, KL divergence,
etc.) over textual features (Bagga &amp; Baldwin,
1998; Gooi &amp; Allan, 2004). Probabilistic graph-
ical models jointly learning the mappings of men-
tions to equivalent classes (co-referring mentions)
using features similar to local CR techniques were
studied in (Culotta et al., 2007; Singh et al., 2010;
Singh et al., 2011), A clustering approach coupled
with statistical learning of parameters was stud-
ied in (Baron &amp; Freedman, 2008). However, such
methods fail to cope with large corpora, and hence
a “light-weight” streaming variant of CCR was in-
troduced by (Rao et al., 2010).
Co-occurring mentions context have been har-
nessed for disambiguating person names for CR
in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen
&amp; Martin, 2007; Baron &amp; Freedman, 2008). How-
ever, these methods do not use KB and depend
on information extraction (IE) methods, witness-
ing substantial noise due to IE quality variance. A
CCR framework combining co-occurring mention
context with distant KB features embedded in an
active hierarchical clustering procedure (Dutta &amp;
Weikum, 2015) was recently shown to perform ef-
ficiently, and provides inspiration for parts of our
proposed C3EL approach.
Named Entity Linking (NEL): Named entity res-
olution and linking stems from SemTag (Dill et
al., 2003), and similar frameworks like GLOW,
WikipediaMiner, AIDA, and others (Milne &amp; Wit-
ten, 2008; Ratinov et al., 2011). A collection
of entity disambiguation models was presented
in (Kulkarni et al., 2009). Other NEL approaches
utilize the notion of semantic similarity of enti-
ties to corresponding Wikipedia pages (Milne &amp;
Witten, 2008), while co-referent mention graph
construction modeling mention co-occurrences and
context similarity from outgoing hyperlinks in
Wikipedia was used by (Hoffart et al., 2011). An
integer linear programming (ILP) formulation also
based on Wikipedia page similarities was presented
in (Ratinov et al., 2011). However, none of these
methods involve the incorporation of CR results
for NEL. The first study on the benefits of CR for
NEL was by (Ratinov &amp; Roth, 2012); but a joint
model was not proposed, instead attributes from
Wikipedia categories were used as features. An
overview and evaluation of different NEL methods
has been given by (Hachey et al., 2013).
Joint Models: Jointly solving CR for entities and
events utilizing cluster construction based on fea-
ture semantic dependencies was devised in (Lee et
al., 2012). The use of CR as a pre-processing step
for subsequent NEL procedure using an ILP for-
mulation was proposed by (Chen &amp; Roth, 2013).
Recently, (Hajishirzi et al., 2013) proposed a joint
model for CR and NEL using the Stanford multi-
pass cluster update CR system with automatic link-
ing of mentions to Wikipedia. An integrated belief
propagation-based framework for CR, NER, and
relation extraction was developed in (Singh et al.,
2013). Subsequently, the model was enhanced by
the use of structured conditional random fields, to
solve CR, NER, and NEL in combination (Durrett
&amp; Klein, 2014). Other works involving joint for-
mulation of NER and NEL use uncertainty of men-
tion boundaries along with segmentation informa-
tion extracted from Wikipedia (Sil &amp; Yates, 2013).
However, to the best of our knowledge, this work
provides the first approach to jointly tackle CCR
and NEL across documents in an entire corpus.
</bodyText>
<sectionHeader confidence="0.999442" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999937466666667">
This paper presented the novel C3EL frame-
work for joint computation of cross-document co-
reference resolution (CCR) and named-entity link-
ing (NEL). Our approach utilizes: (1) context sum-
maries including co-occurring mention groups al-
lowing for global context and feature propagation,
and (2) link validation for NEL using distant KB
features. This is embedded in an interleaved CCR
and NEL model allowing for global semantics and
feature propagation. The iterative approach en-
ables information feedback between CCR (pro-
vides corpus-wide cues) and NEL (providing dis-
tant KB features). Experimental results on news
and web data demonstrate improved performance
of both CCR and NEL compared to prior methods.
</bodyText>
<page confidence="0.998402">
854
</page>
<sectionHeader confidence="0.990219" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999723971153846">
Amit Bagga and Breck Baldwin. Entity-Based Cross-
Document Coreferencing Using the Vector Space
Model. In COLING-ACL 1998, pages 79–85.
Collin F. Baker. FrameNet, Current Collaborations and
Future Goals. LREC 2012, 46(2):269–286.
Alex Baron and Marjorie Freedman. Who is Who and
What is What: Experiments in Cross-Document Co-
Reference. In EMNLP 2008, pages 274–283.
Cosmin A. Bejan and Sanda Harabagiu. Unsupervised
Event Coreference Resolution with Rich Linguistic
Features. In ACL 2010, pages 1412–1422.
Aydin Buluc, Henning Meyerhenke, Ilya Safro, Peter
Sanders, and Christian Schulz. Recent Advances in
Graph Partitioning. Karlsruhe Institute of Technol-
ogy, Technical Report 2013.
Razvan Bunescu and Marius Pas¸ca. Using Encyclope-
dic Knowledge for Named Entity Disambiguation. In
EACL 2006, pages 9–16.
Ying Chen and James Martin. Towards Robust Unsu-
pervised Personal Name Disambiguation. In EMNLP
2007, pages 190–198.
Xiao Cheng and Dan Roth. Relational Inference for
Wikification. In EMNLP 2013, pages 1787–1796.
Marco Cornolti, Paolo Ferragina, and Massimiliano
Ciaramita. A Framework for Benchmarking Entity-
Annotation Systems. In WWW 2013, pages 249–260.
Silviu Cucerzan. Large-Scale Named Entity Disam-
biguation Based on Wikipedia Data. In EMNLP-
CoNLL 2007, pages 708–716.
Aron Culotta, Michael L. Wick, and Andrew McCal-
lum. First-Order Probabilistic Models for Corefer-
ence Resolution. In HLT-NAACL 2007, pages 81–87.
Hal Daum´e III, Daniel Marcu. A large-scale exploration
of effective global features for a joint entity detection
and tracking model. In HLT-EMNLP 2005, pages 97–
104.
Stephan Dill, Nadav Eiron, David Gibson, Daniel
Gruhl, Ramanathan V. Guha, Aanat Jhingran, Tapas
Kanungo, Sridhar Rajagopalan, Andrew Tomkins,
John A. Tomlin, and Jason Y. Zien. SemTag and
Seeker: bootstrapping the semantic web via auto-
mated semantic annotation. In WWW 2003, pages
178–186.
Greg Durrett and Dan Klein. Easy victories and uphill
battles in coreference resolution. In EMNLP 2013,
pages 1971–1982.
Greg Durrett and Dan Klein. A Joint Model for Entity
Analysis: Coreference, Typing, and Linking. TACL
2014, 2:477–490.
Sourav Dutta and Gerhard Weikum. Cross-Document
Co-Reference Resolution using Sample-Based Clus-
tering with Knowledge Enrichment. TACL 2015,
3:15–28.
Jenny R. Finkel, Trond Grenager, and Christopher D.
Manning. Incorporating Non-local Information into
Information Extraction Systems by Gibbs Sampling.
In ACL 2005, pages 363–370.
Jenny R. Finkel and Christopher D. Manning. Joint
Parsing and Named Entity Recognition. In EMNLP-
CoNLL 2009, pages 326–334.
Evgeniy Gabrilovich, Michael Ringgaard, and Amar-
nag Subramanya. FACC1: Freebase annotation of
ClueWeb corpora, Version 1 (Format version 1, Cor-
rection level 0). 2013.
Chung H. Gooi and James Allan. Cross-Document
Coreference on a Large Scale Corpus. In HLT-
NAACL 2004, pages 9–16.
Peter D. Gr¨unwald. The Minimum Description Length
Principle. MIT University Press, 2007.
Ben Hachey, Will Radford, Joel Nothman, Matthew
Honnibal, and James R. Curran. Evaluating entity
linking with Wikipedia. Artificial Intelligence Jour-
nal 2013, 194:130–150.
Aria Haghighi and Dan Klein. Simple Coreference Res-
olution with Rich Syntactic and Semantic Features.
In EMNLP 2009, pages 1152–1161.
Aria Haghighi and Dan Klein. Coreference Resolu-
tion in a Modular, Entity-Centered Model. In HLT-
NAACL 2010, pages 385–393.
Hannaneh Hajishirzi, Leila Zilles, Daniel S. Weld, and
Luke Zettlemoyer. Joint Coreference Resolution and
Named-Entity Linking with Multi-pass Sieves. In
EMNLP 2013, pages 289–299.
Johannes Hoffart, Mohamed A. Yosef, Ilaria Bordino,
Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol,
Bilyana Taneva, Stefan Thater, and Gerhard Weikum.
Robust Disambiguation of Named Entities in Text. In
EMNLP 2011, pages 782–792.
Johannes Hoffart, Yasemin Altun, and Gerhard
Weikum. Discovering Emerging Entities with Am-
biguous Names. In WWW 2014, pages 385–396.
Nikos Hourdakis, Michalis Argyriou, Euripides G. M.
Petrakis, and Evangelos E. Milios. Hierarchical Clus-
tering in Medical Document Collections: the BIC-
Means Method. Journal of Digital Information Man-
agement 2010, 8(2):71–77.
George Karypis and Vipin Kumar. A Fast and Highly
Quality Multilevel Scheme for Partitioning Irregu-
lar Graphs. Journal on Scientific Computing 1999,
20(1):359–392.
Akshay Krishnamurty, Sivaraman Balakrishnan, Min
Xu, and Aarti Singh. Efficient Active Algorithms for
Hierarchical Clustering. In ICML 2012, pages 887–
894.
</reference>
<page confidence="0.987399">
855
</page>
<reference confidence="0.999927863157895">
Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan,
and Soumen Chakrabarti. Collective annotation of
Wikipedia entities in Web text. In KDD 2009, pages
457–466.
Heeyoung Lee, Yves Peirsman, Angel Chang,
Nathanael Chambers, Mihai Surdeanu, and Dan
Jurafsky. Stanford’s Multi-Pass Sieve Coreference
Resolution System at the CoNLL-2011 Shared Task.
In CoNLL 2011, pages 28–34.
Heeyoung Lee, Marta Recasens, Angel Chang, Mi-
hai Surdeanu, and Dan Jurafsky. Joint Entity and
Event Coreference Resolution across Documents. In
EMNLP 2012, pages 489–500.
Heeyoung Lee, Angel Chang, Yves Peirsman,
Nathanael Chambers, Mihai Surdeanu, and Dan
Jurafsky. Deterministic Coreference Resolution
based on Entity-centric, Precision-ranked Rules.
Computational Linguistics 2013, 39(4): 885–916.
Xiaoqiang Luo. On Coreference Resolution Perfor-
mance Metrics. In EMNLP 2005, pages 25–32.
Gideon S. Mann and David Yarowsky: Unsupervised
Personal Name Disambiguation. In CoNLL 2003,
pages 33–40.
David Milne and Ian H. Witten. Learning to Link with
Wikipedia. In CIKM 2008, pages 509–518.
David Nadeau and Satoshi Sekine. A survey of named
entity recognition and classification. Lingvisticae In-
vestigationes 2007, 30(1):3–26.
Vincent Ng. Shallow semantics for coreference resolu-
tion. In IJCAI 2007, pages 1689–1694.
Vincent Ng. Supervised Noun Phrase Coreference Re-
search: The First Fifteen Years. In ACL 2010, pages
1396–1411.
Cheng Niu, Wei Li, and Rohini K. Srihari. Weakly Su-
pervised Learning for Cross-document Person Name
Disambiguation Supported by Information Extrac-
tion. In ACL 2004, article 597.
Simone P. Ponzetto and Michael Strube. Exploiting se-
mantic role labeling, WordNet and Wikipedia for
coreference resolution. In HLT-NAACL 2006, pages
192–199.
Karthik Raghunathan, Heeyoung Lee, Sudarshan Ran-
garajan, Nathanael Chambers, Mihai Surdeanu, Dan
Jurafsky, and Christopher Manning. A Multi-Pass
Sieve for Coreference Resolution. In EMNLP 2010,
pages 492–501.
Altaf Rahman and Vincent Ng. Coreference Resolution
with World Knowledge. In ACL 2011, pages 814–
824.
Altaf Rahman and Vincent Ng. Ensemble-Based Coref-
erence Resolution. In IJCAI 2011, pages 1884–1889.
Delip Rao, Paul McNamee, and Mark Dredze. Stream-
ing Cross Document Entity Coreference Resolution.
In COLING 2010, pages 1050–1058.
Lev A. Ratinov and Dan Roth. Design Challenges and
Misconceptions in Named Entity Recognition. In
CoNLL 2009, pages 147–155.
Lev A. Ratinov, Dan Roth, Doug Downey, and Mike
Anderson. Local and Global Algorithms for Disam-
biguation to Wikipedia. In ACL 2011, pages 1375–
1384.
Lev A. Ratinov and Dan Roth. Learning-based Multi-
Sieve Co-reference Resolution with Knowledge. In
EMNLP-CoNLL 2012, pages 1234–1244.
Gideon E. Schwarz. Estimating the Dimension of a
Model. Annals of Statistics 1978, 6(2):461–464.
Avirup Sil and Alexander Yates. Re-ranking for Joint
Named-Entity Recognition and Linking. In CIKM
2013, pages 2369–2374.
Sameer Singh, Michael L. Wick, and Andrew McCal-
lum. Distantly Labeling Data for Large Scale Cross-
Document Coreference. CoRR abs/1005.4298, 2010.
Sameer Singh, Amarnag Subramanya, Fernando
Pereira, and Andrew McCallum. Large-Scale Cross-
Document Coreference Using Distributed Inference
and Hierarchical Models. In ACL 2011, pages 793–
803.
Sameer Singh, Sebastian Reidel, Brian Martin, Jiaping
Zheng, and Andrew McCallum. Joint Inference of
Entities, Relations, and Coreference. In Workshop of
AKBC 2013, pages 1–6.
Fabian M. Suchanek, Gjergji Kasneci, and Gerhard
Weikum. YAGO: a Core of Semantic Knowledge. In
WWW 2007, pages 697–706.
Bilyana Taneva, Mouna Kacimi, and Gerhard Weikum.
Finding Images of Difficult Entities in the Long Tail.
In CIKM 2011, pages 189–194.
Mohamed A. Yosef, Johannes Hoffart, Marc Spaniol,
and Gerhard Weikum. AIDA: An Online Tool for Ac-
curate Disambiguation of Named Entities in Text and
Tables. In VLDB 2011, 4(12):1450–1453.
Jiaping Zheng, Luke Vilnis, Sameer Singh, Jinho D.
Choi, and Andrew McCallum. Dynamic knowledge-
base alignment for coreference resolution. In CoNLL
2013, pages 153–162.
</reference>
<page confidence="0.999011">
856
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.122775">
<title confidence="0.9413945">A Joint Model for Cross-Document Co-Reference Resolution and Entity Linking Sourav Max-Planck Institute for</title>
<author confidence="0.484895">Saarbr¨ucken</author>
<email confidence="0.878692">sdutta@mpi-inf.mpg.de</email>
<author confidence="0.729003">Gerhard</author>
<affiliation confidence="0.886413">Max-Planck Institute for</affiliation>
<address confidence="0.505457">Saarbr¨ucken,</address>
<email confidence="0.996137">weikum@mpi-inf.mpg.de</email>
<abstract confidence="0.991866666666667">Cross-document co-reference resolution (CCR) computes equivalence classes over textual mentions denoting the same entity in a document corpus. Named-entity linking (NEL) disambiguates mentions onto entities present in a knowledge base (KB) maps them to not present in the KB. Traditionally, CCR and NEL have been addressed separately. However, such approaches miss out on the mutual synergies if CCR and NEL were performed jointly. paper proposes an unsupervised framework combining CCR and NEL jointly tackling both problems. incorporates results from the CCR stage into NEL, and vice versa: additional global context obtained from CCR improves the feature space and performance of NEL, while NEL in turn provides distant KB features for already disambiguated mentions to improve CCR. The CCR and NEL steps are interleaved in an iterative algorithm that focuses on the highest-confidence still unresolved mentions in each iteration. Experimental results on two different corpora, news-centric and web-centric, demonstrate significant gains over state-of-the-art baselines for both CCR and NEL.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amit Bagga</author>
<author>Breck Baldwin</author>
</authors>
<title>Entity-Based CrossDocument Coreferencing Using the Vector Space Model. In COLING-ACL</title>
<date>1998</date>
<pages>79--85</pages>
<contexts>
<context position="3557" citStr="Bagga &amp; Baldwin, 1998" startWordPosition="528" endWordPosition="531"> &amp; Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein. When CR is extended to an entire text corpus, in order to generate equivalence classes of co-referring mentions across documents, the task is known as Cross-document Co-reference Resolution (CCR) (Bagga &amp; Baldwin, 1998; Culotta et al., 2007; Singh et al., 2011; Dutta &amp; Weikum, 2015). Note that CCR is not the same as merely concatenating all documents in the corpus and utilizing existing CR methods. The linguistic diversity across documents and high computational cost for huge numbers of mentions in the corpus would typically make such a CR-based simulation perform poorly. Neither CR nor CCR links mention groups to corresponding KB entities. Thus, they represent both in-KB entities and out-of-KB entities (e.g., long-tail or emerging entities that do not have a Wikipedia article) in the same way. 1Named Entit</context>
<context position="5284" citStr="Bagga &amp; Baldwin, 1998" startWordPosition="785" endWordPosition="788">ations: Established CR methods rely on rule-based methods or supervised learning techniques on syntactic paths between mentions, semantic compatibility, and other linguistic features (Haghighi &amp; Klein, 2009), with additional use of distant features from KBs (Lee et al., 2013). Modern cluster-ranking (Rahman &amp; Ng, 2011) and multi-sieve methods (Ratinov &amp; Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases. Although NER, CR, CCR and NEL involve closely related tasks and their tighter integratio</context>
<context position="23694" citStr="Bagga &amp; Baldwin, 1998" startWordPosition="3753" endWordPosition="3756">me pages to blogs and other social media posts. We randomly select 500K documents containing 4.64 Million mentions associated with 1.29 Million distinct entities to form our corpus. For NEL ground-truth construction, we link the entities to their Wikipedia pages (using Freebase’s “on the web” property). Since no explicit annotations of inter-document entity co-references exists, we consider two mentions (in different documents) to co-refer if they are linked with the same Freebase entity. Evaluation: To assess the output quality of C3EL we use the following established metrics: • B3 F1 score (Bagga &amp; Baldwin, 1998): measures the F1 score as the harmonic mean of average precision and recall computed over all mention groups in the final equivalence classes. Precision (for a mention group) represents the ratio of the number of correctly reported coreferences (or linking) to the actual number; while recall computes the fraction of the goldstandard annotations correctly identified. • φ3 − CEAF score (Luo, 2005): provides an alternate F1 score computed as in the B3 measure; but calculates precision and recall of mention groups using the best 1-to-1 mapping (i.e., mapping with maximum mention overlap) between </context>
<context position="41511" citStr="Bagga &amp; Baldwin, 1998" startWordPosition="6677" endWordPosition="6680">ults (%) of C3EL for different baseline variations niques by ranking the matching entities for distant labeling. However, such prior methods utilize distance labels of the current mention and considers all matching mentions making the procedure expensive. On the other hand, we extract distant features for the strongly matching (best) candidate only, reducing the performance overhead. Cross-Document CR (CCR): Early approaches towards CCR involved the use contextual information from input documents for IR-style similarity measures (e.g., tf×idf score, KL divergence, etc.) over textual features (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004). Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person </context>
</contexts>
<marker>Bagga, Baldwin, 1998</marker>
<rawString>Amit Bagga and Breck Baldwin. Entity-Based CrossDocument Coreferencing Using the Vector Space Model. In COLING-ACL 1998, pages 79–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>FrameNet</author>
</authors>
<title>Current Collaborations and Future Goals. LREC</title>
<date>2012</date>
<pages>46--2</pages>
<marker>FrameNet, 2012</marker>
<rawString>Collin F. Baker. FrameNet, Current Collaborations and Future Goals. LREC 2012, 46(2):269–286.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Baron</author>
<author>Marjorie Freedman</author>
</authors>
<title>Who is Who and What is What: Experiments in Cross-Document CoReference. In EMNLP</title>
<date>2008</date>
<pages>274--283</pages>
<contexts>
<context position="41888" citStr="Baron &amp; Freedman, 2008" startWordPosition="6736" endWordPosition="6739">e overhead. Cross-Document CR (CCR): Early approaches towards CCR involved the use contextual information from input documents for IR-style similarity measures (e.g., tf×idf score, KL divergence, etc.) over textual features (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004). Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering pr</context>
</contexts>
<marker>Baron, Freedman, 2008</marker>
<rawString>Alex Baron and Marjorie Freedman. Who is Who and What is What: Experiments in Cross-Document CoReference. In EMNLP 2008, pages 274–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cosmin A Bejan</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Unsupervised Event Coreference Resolution with Rich Linguistic Features. In ACL</title>
<date>2010</date>
<pages>1412--1422</pages>
<contexts>
<context position="22251" citStr="Bejan &amp; Harabagiu, 2010" startWordPosition="3545" endWordPosition="3548">reference chain, etc. (leading to “phantom” out-of-KB entities). The obtained mention groups represent the final equivalence classes of co-referring mentions across documents – capturing both in-KB entities (with links to the KB) in the 5E class and out-of-KB entities (mapped to null) in the NE class. 3 Experimental Evaluation In this section, we empirically study the performance of C3EL against various state-of-the-art methods. We analyze the individual gains in CCR and NEL due to the joint modeling. Datasets: We use the following 2 publicly available corpora: • EventCorefBank (ECB) corpus3 (Bejan &amp; Harabagiu, 2010): contains 482 news and Web articles (classified into 43 topics) with a total 2 glaros.dtc.umn.edu/gkhome/metis/metis/overview 3faulty.washington.edu/bejan/data/ECB1.0.tar.gz of 5447 mentions corresponding to 1068 distinct named-entities. Entity co-reference annotations (across documents within each topic cluster) were provided by (Lee et al., 2012), and we performed manual examination of the annotations for KB linking of the entities to Wikipedia entries, if present; thus providing ground truth for both CCR and NEL. • ClueWeb2009 FACC1 dataset4 (Gabrilovich et al., 2013): provides machine aut</context>
</contexts>
<marker>Bejan, Harabagiu, 2010</marker>
<rawString>Cosmin A. Bejan and Sanda Harabagiu. Unsupervised Event Coreference Resolution with Rich Linguistic Features. In ACL 2010, pages 1412–1422.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aydin Buluc</author>
<author>Henning Meyerhenke</author>
<author>Ilya Safro</author>
<author>Peter Sanders</author>
<author>Christian Schulz</author>
</authors>
<title>Recent Advances in Graph Partitioning. Karlsruhe Institute of Technology,</title>
<date>2013</date>
<tech>Technical Report</tech>
<contexts>
<context position="20400" citStr="Buluc et al., 2013" startWordPosition="3248" endWordPosition="3251">d (ii) bag of keyphrases, to extract fea849 ture vectors for similarity computation. Finally, the mixture model of bag-of-words (BoW) and keyphrases (KP) of (Dutta &amp; Weikum, 2015) is used to assign feature weights using tf-idf measure. B. Hierarchical Clustering: s mention groups are uniformly randomly sampled and their similarities to the other groups (using context summary) are computed. A similarity-weighted graph with the mention groups as nodes and edge weights representing mention-mention similarities is constructed. Bisection-based hierarchical balanced min-edge-cut graph partitioning (Buluc et al., 2013) is performed, using the METI5 software (Karypis &amp; Kumar, 1999)2, to partition noncoreferent mentions groups. The Bayesian Information Criterion (BIC) (Schwarz, 1978; Hourdakis et al., 2010), a Bayesian variant of Minimum Description Length (Gr¨unwald, 2007), is used as the cluster split stopping criterion, and the context summaries within each final cluster are merged. CCR aims to process heterogeneous corpora that go beyond a single domain and style, such as Web collections. 2.3 Finalization Stage For the remaining mention groups in WE, we finally perform threshold based disambiguation of me</context>
</contexts>
<marker>Buluc, Meyerhenke, Safro, Sanders, Schulz, 2013</marker>
<rawString>Aydin Buluc, Henning Meyerhenke, Ilya Safro, Peter Sanders, and Christian Schulz. Recent Advances in Graph Partitioning. Karlsruhe Institute of Technology, Technical Report 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Razvan Bunescu</author>
<author>Marius Pas¸ca</author>
</authors>
<title>Using Encyclopedic Knowledge for Named Entity Disambiguation. In EACL</title>
<date>2006</date>
<pages>9--16</pages>
<marker>Bunescu, Pas¸ca, 2006</marker>
<rawString>Razvan Bunescu and Marius Pas¸ca. Using Encyclopedic Knowledge for Named Entity Disambiguation. In EACL 2006, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying Chen</author>
<author>James Martin</author>
</authors>
<title>Towards Robust Unsupervised Personal Name Disambiguation. In EMNLP</title>
<date>2007</date>
<pages>190--198</pages>
<contexts>
<context position="39840" citStr="Chen &amp; Martin, 2007" startWordPosition="6400" endWordPosition="6403">i-phase sieve, applying a cascade of rules for narrowing down the antecedent candidates for a mention (Raghunathan et al., 2010). Cluster ranking functions have also been proposed (Rahman &amp; Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with preceding candidate clusters using relatedness features (Ratinov &amp; Roth, 2012) and distant knowledge inclusion (Durrett &amp; Klein, 2013). Person name disambiguation, a specific variation of CR, dealing with only person names, titles, nicknames, and other surface form variations was introduced in (Chen &amp; Martin, 2007). Distant Knowledge Labels: For obtaining semantic features, additional knowledge resources such as Wikipedia, YAGO, and FrameNet have been considered (Rahman &amp; Ng, 2011; Baker, 2012). CR methods with confidence-thresholds were proposed in (Ratinov &amp; Roth, 2012; Lee et al., 2013), and (Zheng et al., 2013) generalized these tech853 Baseline ECB Dataset ClueWeb09-FACC1 Dataset CCR result NEL results CCR result NEL results Within-KB Out-of-KB Within-KB Out-of-KB P R B3 C ff III C ff P R B3 C ff III C ff Ignored Mention 72.5 74.4 73.4 80.2 19.6 0.2 74.4 25.6 69.3 72.2 70.7 83.8 14.6 1.6 80.6 19.4 </context>
<context position="42188" citStr="Chen &amp; Martin, 2007" startWordPosition="6787" endWordPosition="6790">tly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, WikipediaMiner, AIDA, a</context>
</contexts>
<marker>Chen, Martin, 2007</marker>
<rawString>Ying Chen and James Martin. Towards Robust Unsupervised Personal Name Disambiguation. In EMNLP 2007, pages 190–198.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiao Cheng</author>
<author>Dan Roth</author>
</authors>
<title>Relational Inference for Wikification. In EMNLP</title>
<date>2013</date>
<pages>1787--1796</pages>
<marker>Cheng, Roth, 2013</marker>
<rawString>Xiao Cheng and Dan Roth. Relational Inference for Wikification. In EMNLP 2013, pages 1787–1796.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Marco Cornolti</author>
<author>Paolo Ferragina</author>
<author>Massimiliano Ciaramita</author>
</authors>
<title>A Framework for Benchmarking EntityAnnotation Systems.</title>
<booktitle>In WWW 2013,</booktitle>
<pages>249--260</pages>
<marker>Cornolti, Ferragina, Ciaramita, </marker>
<rawString>Marco Cornolti, Paolo Ferragina, and Massimiliano Ciaramita. A Framework for Benchmarking EntityAnnotation Systems. In WWW 2013, pages 249–260.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Silviu Cucerzan</author>
</authors>
<title>Large-Scale Named Entity Disambiguation Based on Wikipedia Data. In EMNLPCoNLL</title>
<date>2007</date>
<pages>708--716</pages>
<contexts>
<context position="2700" citStr="Cucerzan, 2007" startWordPosition="396" endWordPosition="397">ic types (person, location, etc.) (Finkel et al., 2005; Nadeau &amp; Sekine, 2007; Ratinov &amp; Roth, 2009). This involves segmentation of token sequences to obtain mention boundaries, and mapping relevant token spans to pre-defined entity categories. For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2013). For example, in the above text, the mention “Einstein” is linked to the physicist Albert Einstein. Entity Co-reference Resolution (CR) (Haghighi &amp; Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different </context>
</contexts>
<marker>Cucerzan, 2007</marker>
<rawString>Silviu Cucerzan. Large-Scale Named Entity Disambiguation Based on Wikipedia Data. In EMNLPCoNLL 2007, pages 708–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Michael L Wick</author>
<author>Andrew McCallum</author>
</authors>
<title>First-Order Probabilistic Models for Coreference Resolution. In HLT-NAACL</title>
<date>2007</date>
<pages>81--87</pages>
<contexts>
<context position="3579" citStr="Culotta et al., 2007" startWordPosition="532" endWordPosition="535">0; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein. When CR is extended to an entire text corpus, in order to generate equivalence classes of co-referring mentions across documents, the task is known as Cross-document Co-reference Resolution (CCR) (Bagga &amp; Baldwin, 1998; Culotta et al., 2007; Singh et al., 2011; Dutta &amp; Weikum, 2015). Note that CCR is not the same as merely concatenating all documents in the corpus and utilizing existing CR methods. The linguistic diversity across documents and high computational cost for huge numbers of mentions in the corpus would typically make such a CR-based simulation perform poorly. Neither CR nor CCR links mention groups to corresponding KB entities. Thus, they represent both in-KB entities and out-of-KB entities (e.g., long-tail or emerging entities that do not have a Wikipedia article) in the same way. 1Named Entity Disambiguation (NED)</context>
<context position="41736" citStr="Culotta et al., 2007" startWordPosition="6711" endWordPosition="6714">king the procedure expensive. On the other hand, we extract distant features for the strongly matching (best) candidate only, reducing the performance overhead. Cross-Document CR (CCR): Early approaches towards CCR involved the use contextual information from input documents for IR-style similarity measures (e.g., tf×idf score, KL divergence, etc.) over textual features (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004). Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due </context>
</contexts>
<marker>Culotta, Wick, McCallum, 2007</marker>
<rawString>Aron Culotta, Michael L. Wick, and Andrew McCallum. First-Order Probabilistic Models for Coreference Resolution. In HLT-NAACL 2007, pages 81–87.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hal Daum´e Daniel Marcu</author>
</authors>
<title>A large-scale exploration of effective global features for a joint entity detection and tracking model.</title>
<booktitle>In HLT-EMNLP 2005,</booktitle>
<pages>97--104</pages>
<marker>Marcu, </marker>
<rawString>Hal Daum´e III, Daniel Marcu. A large-scale exploration of effective global features for a joint entity detection and tracking model. In HLT-EMNLP 2005, pages 97– 104.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Dill</author>
<author>Nadav Eiron</author>
<author>David Gibson</author>
<author>Daniel Gruhl</author>
<author>Ramanathan V Guha</author>
</authors>
<title>Aanat Jhingran, Tapas Kanungo, Sridhar Rajagopalan, Andrew Tomkins,</title>
<date>2003</date>
<pages>178--186</pages>
<location>John</location>
<contexts>
<context position="42729" citStr="Dill et al., 2003" startWordPosition="6871" endWordPosition="6874">names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, WikipediaMiner, AIDA, and others (Milne &amp; Witten, 2008; Ratinov et al., 2011). A collection of entity disambiguation models was presented in (Kulkarni et al., 2009). Other NEL approaches utilize the notion of semantic similarity of entities to corresponding Wikipedia pages (Milne &amp; Witten, 2008), while co-referent mention graph construction modeling mention co-occurrences and context similarity from outgoing hyperlinks in Wikipedia was used by (Hoffart et al., 2011). An integer linear programming (ILP) formulation also based on Wikipedia page similarities wa</context>
</contexts>
<marker>Dill, Eiron, Gibson, Gruhl, Guha, 2003</marker>
<rawString>Stephan Dill, Nadav Eiron, David Gibson, Daniel Gruhl, Ramanathan V. Guha, Aanat Jhingran, Tapas Kanungo, Sridhar Rajagopalan, Andrew Tomkins, John A. Tomlin, and Jason Y. Zien. SemTag and Seeker: bootstrapping the semantic web via automated semantic annotation. In WWW 2003, pages 178–186.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Greg Durrett</author>
<author>Dan Klein</author>
</authors>
<title>Easy victories and uphill battles in coreference resolution.</title>
<booktitle>In EMNLP 2013,</booktitle>
<pages>1971--1982</pages>
<marker>Durrett, Klein, </marker>
<rawString>Greg Durrett and Dan Klein. Easy victories and uphill battles in coreference resolution. In EMNLP 2013, pages 1971–1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Dan Klein</author>
</authors>
<title>A Joint Model for Entity Analysis: Coreference, Typing, and Linking. TACL</title>
<date>2014</date>
<pages>2--477</pages>
<contexts>
<context position="6182" citStr="Durrett &amp; Klein, 2014" startWordPosition="931" endWordPosition="934">sambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases. Although NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen &amp; Roth, 2013; Zheng et al., 2013), they have mostly been explored in isolation. Recently, several joint models have been proposed for CR-NER (Haghighi &amp; Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi et al., 2013), and NER-CR-NEL (Durrett &amp; Klein, 2014). However, to the best of our knowledge, no method exists for jointly handling CCR and NEL on large text corpora. 1.1 Approach and Contributions This paper proposes the novel C3EL (CrossdoCument Co-reference resolution and Entity Linking) framework for jointly modeling crossdocument co-reference resolution (CCR) and linkage of mention groups to entities in a knowledge base (NEL). Example: To illustrate the potential synergies between CCR and NEL, consider the 3 documents in Figure 1 containing 9 mentions (on the left) with candidate entities from a KB (on the right). CCR alone would likely mis</context>
<context position="32044" citStr="Durrett &amp; Klein, 2014" startWordPosition="5162" endWordPosition="5166"> precision gain is observed by the joint formulation. A. Large Data: The diverse nature of the webscale ClueWeb09 dataset clearly portrays the performance gains in NEL procedure due to CCR generated information integration. For entities present in the KB, we observe an accuracy improvement of 0.5% over AIDA (refer Table 7). Similar to that of the ECB data, C3EL attains a significant ∼ 14% improvement in the detection of new/emerging entities not represented in KB. For the 1 million mentions, C3EL provides around 4% overall performance improvements. Using a bootstrap re-sampling t-test (as in (Durrett &amp; Klein, 2014)), we observed high statistical significance (p &lt; 0.01) for Out-of-KB and Overall NEL, whereas the difference for Within-KB NEL is not statistically significant. Coping with Out-ofKB entities is essential for joint CCR+NEL, and an improved NEL performance using propagated information from CCR using semantics along with link validation enables highly efficient detection of new or emerging entities. 3.4 Comparison with Joint Models Traditional CR methods fail to cope with the heterogeneity of mentions and contexts across multiple documents, and some form of clustering or joint reasoning over all</context>
<context position="33410" citStr="Durrett &amp; Klein, 2014" startWordPosition="5381" endWordPosition="5384">enated super-document works only for small corpora, and would be prohibitively expensive for large corpora, even in offline processing mode (Singh et al., 2011). However, to study the behavior of existing CRNEL joint models under “small” CCR environApproach Within-KB Out-of-KB Overall C I U C I P (%) AIDA 88.5 10.6 1.0 69.6 30.4 84.6 C3EL 89.0 9.8 1.2 83.7 16.3 88.1 Table 7: NEL results (%) on ClueWeb09-FACC1 (statistical significance p &lt; 0.01 for Out-of-KB entities) ments, we compare C3EL with: (1) multi-sieve based NECo (Hajishirzi et al., 2013)6; and (2) conditional random field based BER (Durrett &amp; Klein, 2014) 7. Three topic clusters from the ECB corpus with 3, 4, and 5 articles respectively were selected, and the documents within each cluster were merged to form 3 “super-articles” (one per topic), forming a simulated CR setting. NECo and BER were then used to perform CR and NEL on these 3 articles, and the results compared with that obtained by C3EL on the original documents. We repeatedly sample 12 articles across 3 topic clusters, and execute the approaches to report the micro-averaged results across 5 independent runs. From Table 8(a) we observe that the algorithms exhibit comparable co-referen</context>
<context position="44469" citStr="Durrett &amp; Klein, 2014" startWordPosition="7147" endWordPosition="7150">s was devised in (Lee et al., 2012). The use of CR as a pre-processing step for subsequent NEL procedure using an ILP formulation was proposed by (Chen &amp; Roth, 2013). Recently, (Hajishirzi et al., 2013) proposed a joint model for CR and NEL using the Stanford multipass cluster update CR system with automatic linking of mentions to Wikipedia. An integrated belief propagation-based framework for CR, NER, and relation extraction was developed in (Singh et al., 2013). Subsequently, the model was enhanced by the use of structured conditional random fields, to solve CR, NER, and NEL in combination (Durrett &amp; Klein, 2014). Other works involving joint formulation of NER and NEL use uncertainty of mention boundaries along with segmentation information extracted from Wikipedia (Sil &amp; Yates, 2013). However, to the best of our knowledge, this work provides the first approach to jointly tackle CCR and NEL across documents in an entire corpus. 5 Conclusions This paper presented the novel C3EL framework for joint computation of cross-document coreference resolution (CCR) and named-entity linking (NEL). Our approach utilizes: (1) context summaries including co-occurring mention groups allowing for global context and fe</context>
</contexts>
<marker>Durrett, Klein, 2014</marker>
<rawString>Greg Durrett and Dan Klein. A Joint Model for Entity Analysis: Coreference, Typing, and Linking. TACL 2014, 2:477–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sourav Dutta</author>
<author>Gerhard Weikum</author>
</authors>
<title>Cross-Document Co-Reference Resolution using Sample-Based Clustering with Knowledge Enrichment. TACL</title>
<date>2015</date>
<pages>3--15</pages>
<contexts>
<context position="3622" citStr="Dutta &amp; Weikum, 2015" startWordPosition="540" endWordPosition="543">tering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein. When CR is extended to an entire text corpus, in order to generate equivalence classes of co-referring mentions across documents, the task is known as Cross-document Co-reference Resolution (CCR) (Bagga &amp; Baldwin, 1998; Culotta et al., 2007; Singh et al., 2011; Dutta &amp; Weikum, 2015). Note that CCR is not the same as merely concatenating all documents in the corpus and utilizing existing CR methods. The linguistic diversity across documents and high computational cost for huge numbers of mentions in the corpus would typically make such a CR-based simulation perform poorly. Neither CR nor CCR links mention groups to corresponding KB entities. Thus, they represent both in-KB entities and out-of-KB entities (e.g., long-tail or emerging entities that do not have a Wikipedia article) in the same way. 1Named Entity Disambiguation (NED) and “Wikification” are often used to denot</context>
<context position="5355" citStr="Dutta &amp; Weikum, 2015" startWordPosition="796" endWordPosition="799">learning techniques on syntactic paths between mentions, semantic compatibility, and other linguistic features (Haghighi &amp; Klein, 2009), with additional use of distant features from KBs (Lee et al., 2013). Modern cluster-ranking (Rahman &amp; Ng, 2011) and multi-sieve methods (Ratinov &amp; Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases. Although NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen &amp; Roth, 2013; Zheng et al., 2013</context>
<context position="9512" citStr="Dutta &amp; Weikum, 2015" startWordPosition="1468" endWordPosition="1471"> C3EL iteratively aggregates intermediate information obtained from alternating steps of CCR and NEL, thus forming a feedback loop for propagating mention features and entity knowledge. Intuitively, co-referring mentions obtained via CCR generate global context for improved NEL performance, while mentions linked to KB entities (by NEL) provide distant semantic features with additional cues for CCR. C3EL couples several building blocks like unsupervised hierarchical clustering, context summaries for mentions and distant KB features for entities, drawing inspiration from the CCR-only method of (Dutta &amp; Weikum, 2015). Mention linking to the KB (NEL) is performed using distant knowledge and co-occurring mentions. In a nutshell, the major contributions of this paper are: • the C3EL framework for joint computation of cross-document co-reference resolution (CCR) and entity linking to a KB (NEL), based on propagating information across iterative CCR and NEL steps; • techniques for considering co-occurring mentions in context summaries and for harnessing 847 context-based keywords for link validation in NEL, improving accuracy on out-of-KB entities; • an experimental evaluation with two different corpora, one b</context>
<context position="19344" citStr="Dutta &amp; Weikum, 2015" startWordPosition="3094" endWordPosition="3097">) &lt; 5s are placed in this class. They mostly represent long-tail in-KB entities (sparsely represented in KB) with limited semantic information (for detection) but might also be new/emerging entities absent from KB. • No Evidence (NE): O(Mi, ei) &lt; 5w represents mentions groups that have been mapped to null (or have near-zero match confidence) or have failed link validation during the NEL procedure. These entities are most likely to be outof-KB and are allocated to this class. 2.2.2 Cross-Document CR (CCR) Stage The CCR stage of C3EL adopts the samplingbased hierarchical clustering approach of (Dutta &amp; Weikum, 2015), to obtain co-referring mention clusters. A. Similarity Measure: To infer whether two mention groups represent the same entity, the similarity between the context summaries are computed based on (i) tf-idf-weighted bag-of-words cosine distance, and (ii) partial-match scores of multiword keyphrases in bounded text windows (Taneva et al., 2011). The context summaries (with stopwords removed) are re-interpreted as, (i) bag of words, and (ii) bag of keyphrases, to extract fea849 ture vectors for similarity computation. Finally, the mixture model of bag-of-words (BoW) and keyphrases (KP) of (Dutta</context>
<context position="27377" citStr="Dutta &amp; Weikum, 2015" startWordPosition="4373" endWordPosition="4376">owever, since T prevents gross mis-alignment of mentions to KB entities, a wide range of small value (0.1− 0.35) is seen to provide comparable performance. Hence, for our remaining experimental study we set 6s = 0.11 and 6w = 0.06 (as in (Hoffart et al., 2014)), while T is set to 0.1, and threshold for the finalization stage θ = 2 x 6s = 0.22. 3.2 CCR Performance Results We initially benchmark the performance improvement in cross-document co-reference resolution (CCR) procedure by C3EL against two competing approaches: (1) state-of-the art sampling based hierarchical clustering method, CROCS (Dutta &amp; Weikum, 2015); and (2) iterative joint entity-event CCR, EECR (Lee et al., 2012). Table 2 tabulates the results obtained on the ECB dataset. We observe C3EL to decisively outperform both the existing methods, providing a B3 F1 improvement of around 7% over CROCS and 17% over EECR. We further attain around 6% 03 −CEAF score enhancement over CROCS, and Approach P (%) R (%) B3 (%) 03 (%) CROCSG 79.9 83.33 81.58 74.11 C3ELG 84.74 89.9 87.24 80.5 Table 3: CCR results on ECB Type Approach P (%) R (%) B3 (%) PER CROCSG 71.8 74.15 72.96 C3ELG 84.85 82.73 83.78 LOC CROCSG 78.23 85.41 81.66 C3ELG 81.41 94.31 87.29 O</context>
<context position="42518" citStr="Dutta &amp; Weikum, 2015" startWordPosition="6837" endWordPosition="6840">, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, WikipediaMiner, AIDA, and others (Milne &amp; Witten, 2008; Ratinov et al., 2011). A collection of entity disambiguation models was presented in (Kulkarni et al., 2009). Other NEL approaches utilize the notion of semantic similarity of entities to corresponding Wikipedia pages (Milne &amp; Witten, 2008), while co-referent mention graph construction modeling m</context>
</contexts>
<marker>Dutta, Weikum, 2015</marker>
<rawString>Sourav Dutta and Gerhard Weikum. Cross-Document Co-Reference Resolution using Sample-Based Clustering with Knowledge Enrichment. TACL 2015, 3:15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Finkel</author>
<author>Trond Grenager</author>
<author>Christopher D Manning</author>
</authors>
<title>Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. In ACL</title>
<date>2005</date>
<pages>363--370</pages>
<contexts>
<context position="2140" citStr="Finkel et al., 2005" startWordPosition="305" endWordPosition="308">eople, places, organizations, etc.) along with their attributes and relationships form the basis of smart applications like search, analytics, recommendations, question answering, and more. The major task that arises in both the KB construction process and the entity-centric applications involves precise recognition, resolution, and linking of named entities distributed across web pages, news articles, and social media. Named Entity Recognition (NER) deals with the identification of entity mentions in a text and their classification into coarse-grained semantic types (person, location, etc.) (Finkel et al., 2005; Nadeau &amp; Sekine, 2007; Ratinov &amp; Roth, 2009). This involves segmentation of token sequences to obtain mention boundaries, and mapping relevant token spans to pre-defined entity categories. For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., </context>
<context position="11199" citStr="Finkel et al., 2005" startWordPosition="1756" endWordPosition="1759">f the classes Ei to entities present in a KB or map it to null if there is no proper entity in the KB. To this end, C3EL consists of 3 algorithmic stages: (i) Pre-Processing, (ii) Interleaved NEL and CCR, and (iii) Finalization. 2.1 Pre-Processing Stage HTML pages in the input corpus C are transformed into plain text using standard tools like jsoup. org. Recognition and markup of mentions are performed using the Stanford CoreNLP toolkit (nlp. stanford.edu), and a coarse-grained lexical type for each mention (e.g., person, location, organization, etc.) is obtained from the Stanford NER Tagger (Finkel et al., 2005). The multi-pass sieve algorithm for single-document CR (Raghunathan et al., 2010; Lee et al., 2011; Lee et al., 2013) then computes mention co-reference chains per document, and a head mention is chosen for each of the mention groups (chains). The head mention is typically represented by the most explicit denotation of the entity (e.g., person’s full name with title, location name with country, etc.). For each of the mention groups Mi, C3EL then constructs a context summary using: • Sentences – all sentences in the document that contain mentions of group Mi; and • Co-occurrence – all sentence</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny R. Finkel, Trond Grenager, and Christopher D. Manning. Incorporating Non-local Information into Information Extraction Systems by Gibbs Sampling. In ACL 2005, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny R Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint Parsing and Named Entity Recognition. In EMNLPCoNLL</title>
<date>2009</date>
<pages>326--334</pages>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny R. Finkel and Christopher D. Manning. Joint Parsing and Named Entity Recognition. In EMNLPCoNLL 2009, pages 326–334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
</authors>
<title>Michael Ringgaard, and Amarnag Subramanya. FACC1: Freebase annotation of ClueWeb corpora, Version 1 (Format version 1, Correction level 0).</title>
<date>2013</date>
<marker>Gabrilovich, 2013</marker>
<rawString>Evgeniy Gabrilovich, Michael Ringgaard, and Amarnag Subramanya. FACC1: Freebase annotation of ClueWeb corpora, Version 1 (Format version 1, Correction level 0). 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chung H Gooi</author>
<author>James Allan</author>
</authors>
<title>Cross-Document Coreference on a Large Scale Corpus. In HLTNAACL</title>
<date>2004</date>
<pages>9--16</pages>
<contexts>
<context position="41532" citStr="Gooi &amp; Allan, 2004" startWordPosition="6681" endWordPosition="6684">fferent baseline variations niques by ranking the matching entities for distant labeling. However, such prior methods utilize distance labels of the current mention and considers all matching mentions making the procedure expensive. On the other hand, we extract distant features for the strongly matching (best) candidate only, reducing the performance overhead. Cross-Document CR (CCR): Early approaches towards CCR involved the use contextual information from input documents for IR-style similarity measures (e.g., tf×idf score, KL divergence, etc.) over textual features (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004). Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann</context>
</contexts>
<marker>Gooi, Allan, 2004</marker>
<rawString>Chung H. Gooi and James Allan. Cross-Document Coreference on a Large Scale Corpus. In HLTNAACL 2004, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Gr¨unwald</author>
</authors>
<title>The Minimum Description Length Principle.</title>
<date>2007</date>
<publisher>MIT University Press,</publisher>
<marker>Gr¨unwald, 2007</marker>
<rawString>Peter D. Gr¨unwald. The Minimum Description Length Principle. MIT University Press, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hachey</author>
<author>Will Radford</author>
<author>Joel Nothman</author>
<author>Matthew Honnibal</author>
<author>James R Curran</author>
</authors>
<title>Evaluating entity linking with Wikipedia.</title>
<date>2013</date>
<journal>Artificial Intelligence Journal</journal>
<pages>194--130</pages>
<contexts>
<context position="43720" citStr="Hachey et al., 2013" startWordPosition="7025" endWordPosition="7028">ruction modeling mention co-occurrences and context similarity from outgoing hyperlinks in Wikipedia was used by (Hoffart et al., 2011). An integer linear programming (ILP) formulation also based on Wikipedia page similarities was presented in (Ratinov et al., 2011). However, none of these methods involve the incorporation of CR results for NEL. The first study on the benefits of CR for NEL was by (Ratinov &amp; Roth, 2012); but a joint model was not proposed, instead attributes from Wikipedia categories were used as features. An overview and evaluation of different NEL methods has been given by (Hachey et al., 2013). Joint Models: Jointly solving CR for entities and events utilizing cluster construction based on feature semantic dependencies was devised in (Lee et al., 2012). The use of CR as a pre-processing step for subsequent NEL procedure using an ILP formulation was proposed by (Chen &amp; Roth, 2013). Recently, (Hajishirzi et al., 2013) proposed a joint model for CR and NEL using the Stanford multipass cluster update CR system with automatic linking of mentions to Wikipedia. An integrated belief propagation-based framework for CR, NER, and relation extraction was developed in (Singh et al., 2013). Subs</context>
</contexts>
<marker>Hachey, Radford, Nothman, Honnibal, Curran, 2013</marker>
<rawString>Ben Hachey, Will Radford, Joel Nothman, Matthew Honnibal, and James R. Curran. Evaluating entity linking with Wikipedia. Artificial Intelligence Journal 2013, 194:130–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Simple Coreference Resolution with Rich Syntactic and Semantic Features. In EMNLP</title>
<date>2009</date>
<pages>1152--1161</pages>
<contexts>
<context position="4869" citStr="Haghighi &amp; Klein, 2009" startWordPosition="728" endWordPosition="731">ter may be more broadly used, though, to include the disambiguation of common nouns and phrases onto concepts, whereas NED restricts itself to noun phrases that denote individual entities. 846 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 846–856, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. State-of-the-Art and its Limitations: Established CR methods rely on rule-based methods or supervised learning techniques on syntactic paths between mentions, semantic compatibility, and other linguistic features (Haghighi &amp; Klein, 2009), with additional use of distant features from KBs (Lee et al., 2013). Modern cluster-ranking (Rahman &amp; Ng, 2011) and multi-sieve methods (Ratinov &amp; Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entitie</context>
<context position="38654" citStr="Haghighi &amp; Klein, 2009" startWordPosition="6209" endWordPosition="6212">t is observed. We observe that a joint formulation encompassing multiple information sources (along with noise filtering) enables mutually enhanced CCR and NEL within the proposed iterative feedback based framework, C3EL. 4 Related Work Co-reference Resolution (CR): Traditional intradocument CR methods involve syntactic and semantic feature combination for identifying the best antecedent (preceding name or phrase) for a mention. CR methods employ rules or supervised learning techniques based on linguistic features such as syntactic paths and mention distances to assess semantic compatibility (Haghighi &amp; Klein, 2009; Raghunathan et al., 2010; Rahman &amp; Ng, 2011), while syntactic features are derived by deep parsing of sentences and noun group parsing. Semantic features from background knowledge resources like encyclopedia were used in (Daum´e &amp; Marcu, 2005; Ponzetto &amp; Strube, 2006; Ng, 2007). The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi &amp; Klein, 2009; Rahman &amp; Ng, 2011). An overview of CR methods is given in (Ng, 2010). Recent methods involve the use of multi-phase sieve, applying a cascade </context>
</contexts>
<marker>Haghighi, Klein, 2009</marker>
<rawString>Aria Haghighi and Dan Klein. Simple Coreference Resolution with Rich Syntactic and Semantic Features. In EMNLP 2009, pages 1152–1161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Dan Klein</author>
</authors>
<title>Coreference Resolution in a Modular, Entity-Centered Model. In HLTNAACL</title>
<date>2010</date>
<pages>385--393</pages>
<contexts>
<context position="2950" citStr="Haghighi &amp; Klein, 2010" startWordPosition="434" endWordPosition="437">s. For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2013). For example, in the above text, the mention “Einstein” is linked to the physicist Albert Einstein. Entity Co-reference Resolution (CR) (Haghighi &amp; Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein. When CR is extended to an entire text corpus, in order to generate equivalence classes of co-referring mentions across documents, the task is known as Cross-document Co-reference Resolution (CCR) (Bagga &amp; Baldwi</context>
<context position="6087" citStr="Haghighi &amp; Klein, 2010" startWordPosition="916" endWordPosition="919">ities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases. Although NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen &amp; Roth, 2013; Zheng et al., 2013), they have mostly been explored in isolation. Recently, several joint models have been proposed for CR-NER (Haghighi &amp; Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi et al., 2013), and NER-CR-NEL (Durrett &amp; Klein, 2014). However, to the best of our knowledge, no method exists for jointly handling CCR and NEL on large text corpora. 1.1 Approach and Contributions This paper proposes the novel C3EL (CrossdoCument Co-reference resolution and Entity Linking) framework for jointly modeling crossdocument co-reference resolution (CCR) and linkage of mention groups to entities in a knowledge base (NEL). Example: To illustrate the potential synergies between CCR and NEL, consider the 3 documents in Figure 1 containing 9 ment</context>
</contexts>
<marker>Haghighi, Klein, 2010</marker>
<rawString>Aria Haghighi and Dan Klein. Coreference Resolution in a Modular, Entity-Centered Model. In HLTNAACL 2010, pages 385–393.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hannaneh Hajishirzi</author>
<author>Leila Zilles</author>
<author>Daniel S Weld</author>
<author>Luke Zettlemoyer</author>
</authors>
<title>Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves.</title>
<booktitle>In EMNLP 2013,</booktitle>
<pages>289--299</pages>
<marker>Hajishirzi, Zilles, Weld, Zettlemoyer, </marker>
<rawString>Hannaneh Hajishirzi, Leila Zilles, Daniel S. Weld, and Luke Zettlemoyer. Joint Coreference Resolution and Named-Entity Linking with Multi-pass Sieves. In EMNLP 2013, pages 289–299.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Johannes Hoffart</author>
<author>Mohamed A Yosef</author>
</authors>
<title>Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. Robust Disambiguation of Named Entities in Text.</title>
<booktitle>In EMNLP 2011,</booktitle>
<pages>782--792</pages>
<marker>Hoffart, Yosef, </marker>
<rawString>Johannes Hoffart, Mohamed A. Yosef, Ilaria Bordino, Hagen F¨urstenau, Manfred Pinkal, Marc Spaniol, Bilyana Taneva, Stefan Thater, and Gerhard Weikum. Robust Disambiguation of Named Entities in Text. In EMNLP 2011, pages 782–792.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Johannes Hoffart</author>
<author>Yasemin Altun</author>
<author>Gerhard Weikum</author>
</authors>
<title>Discovering Emerging Entities with Ambiguous Names.</title>
<booktitle>In WWW 2014,</booktitle>
<pages>385--396</pages>
<marker>Hoffart, Altun, Weikum, </marker>
<rawString>Johannes Hoffart, Yasemin Altun, and Gerhard Weikum. Discovering Emerging Entities with Ambiguous Names. In WWW 2014, pages 385–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikos Hourdakis</author>
<author>Michalis Argyriou</author>
<author>Euripides G M Petrakis</author>
<author>Evangelos E Milios</author>
</authors>
<title>Hierarchical Clustering in Medical Document Collections: the BICMeans Method.</title>
<date>2010</date>
<journal>Journal of Digital Information Management</journal>
<pages>8--2</pages>
<contexts>
<context position="20590" citStr="Hourdakis et al., 2010" startWordPosition="3277" endWordPosition="3281">d to assign feature weights using tf-idf measure. B. Hierarchical Clustering: s mention groups are uniformly randomly sampled and their similarities to the other groups (using context summary) are computed. A similarity-weighted graph with the mention groups as nodes and edge weights representing mention-mention similarities is constructed. Bisection-based hierarchical balanced min-edge-cut graph partitioning (Buluc et al., 2013) is performed, using the METI5 software (Karypis &amp; Kumar, 1999)2, to partition noncoreferent mentions groups. The Bayesian Information Criterion (BIC) (Schwarz, 1978; Hourdakis et al., 2010), a Bayesian variant of Minimum Description Length (Gr¨unwald, 2007), is used as the cluster split stopping criterion, and the context summaries within each final cluster are merged. CCR aims to process heterogeneous corpora that go beyond a single domain and style, such as Web collections. 2.3 Finalization Stage For the remaining mention groups in WE, we finally perform threshold based disambiguation of mention clusters using the context summaries. For each mention group MZ E WE, we compute (1) its context summary similarities (as in Section 2.2.2) to all other mention groups Mj in SE by also</context>
</contexts>
<marker>Hourdakis, Argyriou, Petrakis, Milios, 2010</marker>
<rawString>Nikos Hourdakis, Michalis Argyriou, Euripides G. M. Petrakis, and Evangelos E. Milios. Hierarchical Clustering in Medical Document Collections: the BICMeans Method. Journal of Digital Information Management 2010, 8(2):71–77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Karypis</author>
<author>Vipin Kumar</author>
</authors>
<title>A Fast and Highly Quality Multilevel Scheme for Partitioning Irregular Graphs.</title>
<date>1999</date>
<journal>Journal on Scientific Computing</journal>
<pages>20--1</pages>
<contexts>
<context position="20463" citStr="Karypis &amp; Kumar, 1999" startWordPosition="3259" endWordPosition="3262"> similarity computation. Finally, the mixture model of bag-of-words (BoW) and keyphrases (KP) of (Dutta &amp; Weikum, 2015) is used to assign feature weights using tf-idf measure. B. Hierarchical Clustering: s mention groups are uniformly randomly sampled and their similarities to the other groups (using context summary) are computed. A similarity-weighted graph with the mention groups as nodes and edge weights representing mention-mention similarities is constructed. Bisection-based hierarchical balanced min-edge-cut graph partitioning (Buluc et al., 2013) is performed, using the METI5 software (Karypis &amp; Kumar, 1999)2, to partition noncoreferent mentions groups. The Bayesian Information Criterion (BIC) (Schwarz, 1978; Hourdakis et al., 2010), a Bayesian variant of Minimum Description Length (Gr¨unwald, 2007), is used as the cluster split stopping criterion, and the context summaries within each final cluster are merged. CCR aims to process heterogeneous corpora that go beyond a single domain and style, such as Web collections. 2.3 Finalization Stage For the remaining mention groups in WE, we finally perform threshold based disambiguation of mention clusters using the context summaries. For each mention gr</context>
</contexts>
<marker>Karypis, Kumar, 1999</marker>
<rawString>George Karypis and Vipin Kumar. A Fast and Highly Quality Multilevel Scheme for Partitioning Irregular Graphs. Journal on Scientific Computing 1999, 20(1):359–392.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Akshay Krishnamurty</author>
<author>Sivaraman Balakrishnan</author>
<author>Min Xu</author>
<author>Aarti Singh</author>
</authors>
<title>Efficient Active Algorithms for Hierarchical Clustering.</title>
<booktitle>In ICML 2012,</booktitle>
<pages>887--894</pages>
<marker>Krishnamurty, Balakrishnan, Xu, Singh, </marker>
<rawString>Akshay Krishnamurty, Sivaraman Balakrishnan, Min Xu, and Aarti Singh. Efficient Active Algorithms for Hierarchical Clustering. In ICML 2012, pages 887– 894.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sayali Kulkarni</author>
<author>Amit Singh</author>
<author>Ganesh Ramakrishnan</author>
<author>Soumen Chakrabarti</author>
</authors>
<title>Collective annotation of Wikipedia entities in Web text.</title>
<date>2009</date>
<booktitle>In KDD</booktitle>
<pages>457--466</pages>
<contexts>
<context position="5639" citStr="Kulkarni et al., 2009" startWordPosition="838" endWordPosition="841">Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases. Although NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen &amp; Roth, 2013; Zheng et al., 2013), they have mostly been explored in isolation. Recently, several joint models have been proposed for CR-NER (Haghighi &amp; Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi et al., 2013), and NER-CR-NEL (Durrett &amp; Klein, 2014). However, to the best of our knowledge, no method exists</context>
<context position="42929" citStr="Kulkarni et al., 2009" startWordPosition="6902" endWordPosition="6905">essing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, WikipediaMiner, AIDA, and others (Milne &amp; Witten, 2008; Ratinov et al., 2011). A collection of entity disambiguation models was presented in (Kulkarni et al., 2009). Other NEL approaches utilize the notion of semantic similarity of entities to corresponding Wikipedia pages (Milne &amp; Witten, 2008), while co-referent mention graph construction modeling mention co-occurrences and context similarity from outgoing hyperlinks in Wikipedia was used by (Hoffart et al., 2011). An integer linear programming (ILP) formulation also based on Wikipedia page similarities was presented in (Ratinov et al., 2011). However, none of these methods involve the incorporation of CR results for NEL. The first study on the benefits of CR for NEL was by (Ratinov &amp; Roth, 2012); but </context>
</contexts>
<marker>Kulkarni, Singh, Ramakrishnan, Chakrabarti, 2009</marker>
<rawString>Sayali Kulkarni, Amit Singh, Ganesh Ramakrishnan, and Soumen Chakrabarti. Collective annotation of Wikipedia entities in Web text. In KDD 2009, pages 457–466.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Yves Peirsman</author>
<author>Angel Chang</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Stanford’s Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task. In CoNLL</title>
<date>2011</date>
<pages>28--34</pages>
<contexts>
<context position="11298" citStr="Lee et al., 2011" startWordPosition="1771" endWordPosition="1774">To this end, C3EL consists of 3 algorithmic stages: (i) Pre-Processing, (ii) Interleaved NEL and CCR, and (iii) Finalization. 2.1 Pre-Processing Stage HTML pages in the input corpus C are transformed into plain text using standard tools like jsoup. org. Recognition and markup of mentions are performed using the Stanford CoreNLP toolkit (nlp. stanford.edu), and a coarse-grained lexical type for each mention (e.g., person, location, organization, etc.) is obtained from the Stanford NER Tagger (Finkel et al., 2005). The multi-pass sieve algorithm for single-document CR (Raghunathan et al., 2010; Lee et al., 2011; Lee et al., 2013) then computes mention co-reference chains per document, and a head mention is chosen for each of the mention groups (chains). The head mention is typically represented by the most explicit denotation of the entity (e.g., person’s full name with title, location name with country, etc.). For each of the mention groups Mi, C3EL then constructs a context summary using: • Sentences – all sentences in the document that contain mentions of group Mi; and • Co-occurrence – all sentences for other mention groups that contain mentions co-occurring in any of the sentences of Mi (as obt</context>
</contexts>
<marker>Lee, Peirsman, Chang, Chambers, Surdeanu, Jurafsky, 2011</marker>
<rawString>Heeyoung Lee, Yves Peirsman, Angel Chang, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. Stanford’s Multi-Pass Sieve Coreference Resolution System at the CoNLL-2011 Shared Task. In CoNLL 2011, pages 28–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Marta Recasens</author>
<author>Angel Chang</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Joint Entity and Event Coreference Resolution across Documents. In EMNLP</title>
<date>2012</date>
<pages>489--500</pages>
<contexts>
<context position="22602" citStr="Lee et al., 2012" startWordPosition="3587" endWordPosition="3590">ly study the performance of C3EL against various state-of-the-art methods. We analyze the individual gains in CCR and NEL due to the joint modeling. Datasets: We use the following 2 publicly available corpora: • EventCorefBank (ECB) corpus3 (Bejan &amp; Harabagiu, 2010): contains 482 news and Web articles (classified into 43 topics) with a total 2 glaros.dtc.umn.edu/gkhome/metis/metis/overview 3faulty.washington.edu/bejan/data/ECB1.0.tar.gz of 5447 mentions corresponding to 1068 distinct named-entities. Entity co-reference annotations (across documents within each topic cluster) were provided by (Lee et al., 2012), and we performed manual examination of the annotations for KB linking of the entities to Wikipedia entries, if present; thus providing ground truth for both CCR and NEL. • ClueWeb2009 FACC1 dataset4 (Gabrilovich et al., 2013): provides machine automated entity-linkage annotations of the ClueWeb09 corpus (ca. 1 Billion crawled Web pages) with Freebase entries5. The corpus contains many topical domains and highly diverse documents from news, movie reviews, people home pages to blogs and other social media posts. We randomly select 500K documents containing 4.64 Million mentions associated with</context>
<context position="27444" citStr="Lee et al., 2012" startWordPosition="4384" endWordPosition="4387">, a wide range of small value (0.1− 0.35) is seen to provide comparable performance. Hence, for our remaining experimental study we set 6s = 0.11 and 6w = 0.06 (as in (Hoffart et al., 2014)), while T is set to 0.1, and threshold for the finalization stage θ = 2 x 6s = 0.22. 3.2 CCR Performance Results We initially benchmark the performance improvement in cross-document co-reference resolution (CCR) procedure by C3EL against two competing approaches: (1) state-of-the art sampling based hierarchical clustering method, CROCS (Dutta &amp; Weikum, 2015); and (2) iterative joint entity-event CCR, EECR (Lee et al., 2012). Table 2 tabulates the results obtained on the ECB dataset. We observe C3EL to decisively outperform both the existing methods, providing a B3 F1 improvement of around 7% over CROCS and 17% over EECR. We further attain around 6% 03 −CEAF score enhancement over CROCS, and Approach P (%) R (%) B3 (%) 03 (%) CROCSG 79.9 83.33 81.58 74.11 C3ELG 84.74 89.9 87.24 80.5 Table 3: CCR results on ECB Type Approach P (%) R (%) B3 (%) PER CROCSG 71.8 74.15 72.96 C3ELG 84.85 82.73 83.78 LOC CROCSG 78.23 85.41 81.66 C3ELG 81.41 94.31 87.29 ORG CROCSG 85.73 87.89 86.8 C3ELG 88.52 91.82 90.14 Table 4: CCR res</context>
<context position="43882" citStr="Lee et al., 2012" startWordPosition="7050" endWordPosition="7053">g (ILP) formulation also based on Wikipedia page similarities was presented in (Ratinov et al., 2011). However, none of these methods involve the incorporation of CR results for NEL. The first study on the benefits of CR for NEL was by (Ratinov &amp; Roth, 2012); but a joint model was not proposed, instead attributes from Wikipedia categories were used as features. An overview and evaluation of different NEL methods has been given by (Hachey et al., 2013). Joint Models: Jointly solving CR for entities and events utilizing cluster construction based on feature semantic dependencies was devised in (Lee et al., 2012). The use of CR as a pre-processing step for subsequent NEL procedure using an ILP formulation was proposed by (Chen &amp; Roth, 2013). Recently, (Hajishirzi et al., 2013) proposed a joint model for CR and NEL using the Stanford multipass cluster update CR system with automatic linking of mentions to Wikipedia. An integrated belief propagation-based framework for CR, NER, and relation extraction was developed in (Singh et al., 2013). Subsequently, the model was enhanced by the use of structured conditional random fields, to solve CR, NER, and NEL in combination (Durrett &amp; Klein, 2014). Other works</context>
</contexts>
<marker>Lee, Recasens, Chang, Surdeanu, Jurafsky, 2012</marker>
<rawString>Heeyoung Lee, Marta Recasens, Angel Chang, Mihai Surdeanu, and Dan Jurafsky. Joint Entity and Event Coreference Resolution across Documents. In EMNLP 2012, pages 489–500.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heeyoung Lee</author>
<author>Angel Chang</author>
<author>Yves Peirsman</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
</authors>
<title>Deterministic Coreference Resolution based on Entity-centric, Precision-ranked Rules. Computational Linguistics</title>
<date>2013</date>
<volume>39</volume>
<issue>4</issue>
<pages>885--916</pages>
<contexts>
<context position="2979" citStr="Lee et al., 2013" startWordPosition="440" endWordPosition="443">nstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2013). For example, in the above text, the mention “Einstein” is linked to the physicist Albert Einstein. Entity Co-reference Resolution (CR) (Haghighi &amp; Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein. When CR is extended to an entire text corpus, in order to generate equivalence classes of co-referring mentions across documents, the task is known as Cross-document Co-reference Resolution (CCR) (Bagga &amp; Baldwin, 1998; Culotta et al., 2007</context>
<context position="4938" citStr="Lee et al., 2013" startWordPosition="740" endWordPosition="743">on nouns and phrases onto concepts, whereas NED restricts itself to noun phrases that denote individual entities. 846 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 846–856, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. State-of-the-Art and its Limitations: Established CR methods rely on rule-based methods or supervised learning techniques on syntactic paths between mentions, semantic compatibility, and other linguistic features (Haghighi &amp; Klein, 2009), with additional use of distant features from KBs (Lee et al., 2013). Modern cluster-ranking (Rahman &amp; Ng, 2011) and multi-sieve methods (Ratinov &amp; Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualiz</context>
<context position="11317" citStr="Lee et al., 2013" startWordPosition="1775" endWordPosition="1778">consists of 3 algorithmic stages: (i) Pre-Processing, (ii) Interleaved NEL and CCR, and (iii) Finalization. 2.1 Pre-Processing Stage HTML pages in the input corpus C are transformed into plain text using standard tools like jsoup. org. Recognition and markup of mentions are performed using the Stanford CoreNLP toolkit (nlp. stanford.edu), and a coarse-grained lexical type for each mention (e.g., person, location, organization, etc.) is obtained from the Stanford NER Tagger (Finkel et al., 2005). The multi-pass sieve algorithm for single-document CR (Raghunathan et al., 2010; Lee et al., 2011; Lee et al., 2013) then computes mention co-reference chains per document, and a head mention is chosen for each of the mention groups (chains). The head mention is typically represented by the most explicit denotation of the entity (e.g., person’s full name with title, location name with country, etc.). For each of the mention groups Mi, C3EL then constructs a context summary using: • Sentences – all sentences in the document that contain mentions of group Mi; and • Co-occurrence – all sentences for other mention groups that contain mentions co-occurring in any of the sentences of Mi (as obtained above). Forma</context>
<context position="40120" citStr="Lee et al., 2013" startWordPosition="6442" endWordPosition="6445"> mention groups with preceding candidate clusters using relatedness features (Ratinov &amp; Roth, 2012) and distant knowledge inclusion (Durrett &amp; Klein, 2013). Person name disambiguation, a specific variation of CR, dealing with only person names, titles, nicknames, and other surface form variations was introduced in (Chen &amp; Martin, 2007). Distant Knowledge Labels: For obtaining semantic features, additional knowledge resources such as Wikipedia, YAGO, and FrameNet have been considered (Rahman &amp; Ng, 2011; Baker, 2012). CR methods with confidence-thresholds were proposed in (Ratinov &amp; Roth, 2012; Lee et al., 2013), and (Zheng et al., 2013) generalized these tech853 Baseline ECB Dataset ClueWeb09-FACC1 Dataset CCR result NEL results CCR result NEL results Within-KB Out-of-KB Within-KB Out-of-KB P R B3 C ff III C ff P R B3 C ff III C ff Ignored Mention 72.5 74.4 73.4 80.2 19.6 0.2 74.4 25.6 69.3 72.2 70.7 83.8 14.6 1.6 80.6 19.4 Co-occurrence Link Validation 79.0 81.4 80.2 85.5 14.5 0.0 62.8 37.2 74.8 81.0 77.8 88.9 10.1 1.0 69.8 30.2 (τ) ignored Removed NEL 73.2 80.7 76.8 83.9 15.9 0.2 76.1 23.9 70.1 77.6 73.6 86.1 12.3 1.6 79.5 20.5 Classification Distant KB 68.9 73.1 70.9 82.8 17.0 0.2 79.0 21.0 66.4 </context>
</contexts>
<marker>Lee, Chang, Peirsman, Chambers, Surdeanu, Jurafsky, 2013</marker>
<rawString>Heeyoung Lee, Angel Chang, Yves Peirsman, Nathanael Chambers, Mihai Surdeanu, and Dan Jurafsky. Deterministic Coreference Resolution based on Entity-centric, Precision-ranked Rules. Computational Linguistics 2013, 39(4): 885–916.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaoqiang Luo</author>
</authors>
<title>On Coreference Resolution Performance Metrics. In EMNLP</title>
<date>2005</date>
<pages>25--32</pages>
<contexts>
<context position="24093" citStr="Luo, 2005" startWordPosition="3821" endWordPosition="3822">different documents) to co-refer if they are linked with the same Freebase entity. Evaluation: To assess the output quality of C3EL we use the following established metrics: • B3 F1 score (Bagga &amp; Baldwin, 1998): measures the F1 score as the harmonic mean of average precision and recall computed over all mention groups in the final equivalence classes. Precision (for a mention group) represents the ratio of the number of correctly reported coreferences (or linking) to the actual number; while recall computes the fraction of the goldstandard annotations correctly identified. • φ3 − CEAF score (Luo, 2005): provides an alternate F1 score computed as in the B3 measure; but calculates precision and recall of mention groups using the best 1-to-1 mapping (i.e., mapping with maximum mention overlap) between the resultant equivalence classes and those in the ground truth. Normalization with the number of mentions for each of the resultant classes yields the φ4-CEAF score. We consider only the 3 most notable mention types: person (PER), location (LOC), and organization (ORG) – accounting for 99.7% of entities present in the ECB corpus and 96.3% of our ClueWeb09 corpus. All experiments were conducted o</context>
</contexts>
<marker>Luo, 2005</marker>
<rawString>Xiaoqiang Luo. On Coreference Resolution Performance Metrics. In EMNLP 2005, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon S Mann</author>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised Personal Name Disambiguation. In CoNLL</title>
<date>2003</date>
<pages>33--40</pages>
<contexts>
<context position="42149" citStr="Mann &amp; Yarowsky, 2003" startWordPosition="6779" endWordPosition="6782">004). Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar framew</context>
</contexts>
<marker>Mann, Yarowsky, 2003</marker>
<rawString>Gideon S. Mann and David Yarowsky: Unsupervised Personal Name Disambiguation. In CoNLL 2003, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milne</author>
<author>Ian H Witten</author>
</authors>
<title>Learning to Link with Wikipedia. In CIKM</title>
<date>2008</date>
<pages>509--518</pages>
<contexts>
<context position="2722" citStr="Milne &amp; Witten, 2008" startWordPosition="398" endWordPosition="401">, location, etc.) (Finkel et al., 2005; Nadeau &amp; Sekine, 2007; Ratinov &amp; Roth, 2009). This involves segmentation of token sequences to obtain mention boundaries, and mapping relevant token spans to pre-defined entity categories. For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2013). For example, in the above text, the mention “Einstein” is linked to the physicist Albert Einstein. Entity Co-reference Resolution (CR) (Haghighi &amp; Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans </context>
<context position="5616" citStr="Milne &amp; Witten, 2008" startWordPosition="834" endWordPosition="837">ve methods (Ratinov &amp; Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases. Although NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen &amp; Roth, 2013; Zheng et al., 2013), they have mostly been explored in isolation. Recently, several joint models have been proposed for CR-NER (Haghighi &amp; Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi et al., 2013), and NER-CR-NEL (Durrett &amp; Klein, 2014). However, to the best of our know</context>
<context position="42819" citStr="Milne &amp; Witten, 2008" startWordPosition="6884" endWordPosition="6888">reedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, WikipediaMiner, AIDA, and others (Milne &amp; Witten, 2008; Ratinov et al., 2011). A collection of entity disambiguation models was presented in (Kulkarni et al., 2009). Other NEL approaches utilize the notion of semantic similarity of entities to corresponding Wikipedia pages (Milne &amp; Witten, 2008), while co-referent mention graph construction modeling mention co-occurrences and context similarity from outgoing hyperlinks in Wikipedia was used by (Hoffart et al., 2011). An integer linear programming (ILP) formulation also based on Wikipedia page similarities was presented in (Ratinov et al., 2011). However, none of these methods involve the incorpor</context>
</contexts>
<marker>Milne, Witten, 2008</marker>
<rawString>David Milne and Ian H. Witten. Learning to Link with Wikipedia. In CIKM 2008, pages 509–518.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Nadeau</author>
<author>Satoshi Sekine</author>
</authors>
<title>A survey of named entity recognition and classification. Lingvisticae Investigationes</title>
<date>2007</date>
<pages>30--1</pages>
<contexts>
<context position="2163" citStr="Nadeau &amp; Sekine, 2007" startWordPosition="309" endWordPosition="312">zations, etc.) along with their attributes and relationships form the basis of smart applications like search, analytics, recommendations, question answering, and more. The major task that arises in both the KB construction process and the entity-centric applications involves precise recognition, resolution, and linking of named entities distributed across web pages, news articles, and social media. Named Entity Recognition (NER) deals with the identification of entity mentions in a text and their classification into coarse-grained semantic types (person, location, etc.) (Finkel et al., 2005; Nadeau &amp; Sekine, 2007; Ratinov &amp; Roth, 2009). This involves segmentation of token sequences to obtain mention boundaries, and mapping relevant token spans to pre-defined entity categories. For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2</context>
</contexts>
<marker>Nadeau, Sekine, 2007</marker>
<rawString>David Nadeau and Satoshi Sekine. A survey of named entity recognition and classification. Lingvisticae Investigationes 2007, 30(1):3–26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Shallow semantics for coreference resolution. In IJCAI</title>
<date>2007</date>
<pages>1689--1694</pages>
<contexts>
<context position="38934" citStr="Ng, 2007" startWordPosition="6256" endWordPosition="6257">CR methods involve syntactic and semantic feature combination for identifying the best antecedent (preceding name or phrase) for a mention. CR methods employ rules or supervised learning techniques based on linguistic features such as syntactic paths and mention distances to assess semantic compatibility (Haghighi &amp; Klein, 2009; Raghunathan et al., 2010; Rahman &amp; Ng, 2011), while syntactic features are derived by deep parsing of sentences and noun group parsing. Semantic features from background knowledge resources like encyclopedia were used in (Daum´e &amp; Marcu, 2005; Ponzetto &amp; Strube, 2006; Ng, 2007). The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi &amp; Klein, 2009; Rahman &amp; Ng, 2011). An overview of CR methods is given in (Ng, 2010). Recent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing down the antecedent candidates for a mention (Raghunathan et al., 2010). Cluster ranking functions have also been proposed (Rahman &amp; Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with preceding </context>
</contexts>
<marker>Ng, 2007</marker>
<rawString>Vincent Ng. Shallow semantics for coreference resolution. In IJCAI 2007, pages 1689–1694.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vincent Ng</author>
</authors>
<title>Supervised Noun Phrase Coreference Research: The First Fifteen Years. In ACL</title>
<date>2010</date>
<pages>1396--1411</pages>
<contexts>
<context position="2960" citStr="Ng, 2010" startWordPosition="438" endWordPosition="439">he text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2013). For example, in the above text, the mention “Einstein” is linked to the physicist Albert Einstein. Entity Co-reference Resolution (CR) (Haghighi &amp; Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein. When CR is extended to an entire text corpus, in order to generate equivalence classes of co-referring mentions across documents, the task is known as Cross-document Co-reference Resolution (CCR) (Bagga &amp; Baldwin, 1998; C</context>
<context position="39180" citStr="Ng, 2010" startWordPosition="6298" endWordPosition="6299">aths and mention distances to assess semantic compatibility (Haghighi &amp; Klein, 2009; Raghunathan et al., 2010; Rahman &amp; Ng, 2011), while syntactic features are derived by deep parsing of sentences and noun group parsing. Semantic features from background knowledge resources like encyclopedia were used in (Daum´e &amp; Marcu, 2005; Ponzetto &amp; Strube, 2006; Ng, 2007). The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi &amp; Klein, 2009; Rahman &amp; Ng, 2011). An overview of CR methods is given in (Ng, 2010). Recent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing down the antecedent candidates for a mention (Raghunathan et al., 2010). Cluster ranking functions have also been proposed (Rahman &amp; Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with preceding candidate clusters using relatedness features (Ratinov &amp; Roth, 2012) and distant knowledge inclusion (Durrett &amp; Klein, 2013). Person name disambiguation, a specific variation of CR, dealing with only person names, titles, nicknames, and other sur</context>
</contexts>
<marker>Ng, 2010</marker>
<rawString>Vincent Ng. Supervised Noun Phrase Coreference Research: The First Fifteen Years. In ACL 2010, pages 1396–1411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cheng Niu</author>
<author>Wei Li</author>
<author>Rohini K Srihari</author>
</authors>
<title>Weakly Supervised Learning for Cross-document Person Name Disambiguation Supported by Information Extraction.</title>
<date>2004</date>
<booktitle>In ACL</booktitle>
<pages>597</pages>
<contexts>
<context position="42167" citStr="Niu et al., 2004" startWordPosition="6783" endWordPosition="6786">phical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, Wi</context>
</contexts>
<marker>Niu, Li, Srihari, 2004</marker>
<rawString>Cheng Niu, Wei Li, and Rohini K. Srihari. Weakly Supervised Learning for Cross-document Person Name Disambiguation Supported by Information Extraction. In ACL 2004, article 597.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone P Ponzetto</author>
<author>Michael Strube</author>
</authors>
<title>Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In HLT-NAACL</title>
<date>2006</date>
<pages>192--199</pages>
<contexts>
<context position="38923" citStr="Ponzetto &amp; Strube, 2006" startWordPosition="6252" endWordPosition="6255">raditional intradocument CR methods involve syntactic and semantic feature combination for identifying the best antecedent (preceding name or phrase) for a mention. CR methods employ rules or supervised learning techniques based on linguistic features such as syntactic paths and mention distances to assess semantic compatibility (Haghighi &amp; Klein, 2009; Raghunathan et al., 2010; Rahman &amp; Ng, 2011), while syntactic features are derived by deep parsing of sentences and noun group parsing. Semantic features from background knowledge resources like encyclopedia were used in (Daum´e &amp; Marcu, 2005; Ponzetto &amp; Strube, 2006; Ng, 2007). The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi &amp; Klein, 2009; Rahman &amp; Ng, 2011). An overview of CR methods is given in (Ng, 2010). Recent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing down the antecedent candidates for a mention (Raghunathan et al., 2010). Cluster ranking functions have also been proposed (Rahman &amp; Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with</context>
</contexts>
<marker>Ponzetto, Strube, 2006</marker>
<rawString>Simone P. Ponzetto and Michael Strube. Exploiting semantic role labeling, WordNet and Wikipedia for coreference resolution. In HLT-NAACL 2006, pages 192–199.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karthik Raghunathan</author>
<author>Heeyoung Lee</author>
<author>Sudarshan Rangarajan</author>
<author>Nathanael Chambers</author>
<author>Mihai Surdeanu</author>
<author>Dan Jurafsky</author>
<author>Christopher Manning</author>
</authors>
<title>A Multi-Pass Sieve for Coreference Resolution. In EMNLP</title>
<date>2010</date>
<pages>492--501</pages>
<contexts>
<context position="11280" citStr="Raghunathan et al., 2010" startWordPosition="1767" endWordPosition="1770"> proper entity in the KB. To this end, C3EL consists of 3 algorithmic stages: (i) Pre-Processing, (ii) Interleaved NEL and CCR, and (iii) Finalization. 2.1 Pre-Processing Stage HTML pages in the input corpus C are transformed into plain text using standard tools like jsoup. org. Recognition and markup of mentions are performed using the Stanford CoreNLP toolkit (nlp. stanford.edu), and a coarse-grained lexical type for each mention (e.g., person, location, organization, etc.) is obtained from the Stanford NER Tagger (Finkel et al., 2005). The multi-pass sieve algorithm for single-document CR (Raghunathan et al., 2010; Lee et al., 2011; Lee et al., 2013) then computes mention co-reference chains per document, and a head mention is chosen for each of the mention groups (chains). The head mention is typically represented by the most explicit denotation of the entity (e.g., person’s full name with title, location name with country, etc.). For each of the mention groups Mi, C3EL then constructs a context summary using: • Sentences – all sentences in the document that contain mentions of group Mi; and • Co-occurrence – all sentences for other mention groups that contain mentions co-occurring in any of the sente</context>
<context position="38680" citStr="Raghunathan et al., 2010" startWordPosition="6213" endWordPosition="6216">e that a joint formulation encompassing multiple information sources (along with noise filtering) enables mutually enhanced CCR and NEL within the proposed iterative feedback based framework, C3EL. 4 Related Work Co-reference Resolution (CR): Traditional intradocument CR methods involve syntactic and semantic feature combination for identifying the best antecedent (preceding name or phrase) for a mention. CR methods employ rules or supervised learning techniques based on linguistic features such as syntactic paths and mention distances to assess semantic compatibility (Haghighi &amp; Klein, 2009; Raghunathan et al., 2010; Rahman &amp; Ng, 2011), while syntactic features are derived by deep parsing of sentences and noun group parsing. Semantic features from background knowledge resources like encyclopedia were used in (Daum´e &amp; Marcu, 2005; Ponzetto &amp; Strube, 2006; Ng, 2007). The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi &amp; Klein, 2009; Rahman &amp; Ng, 2011). An overview of CR methods is given in (Ng, 2010). Recent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing dow</context>
</contexts>
<marker>Raghunathan, Lee, Rangarajan, Chambers, Surdeanu, Jurafsky, Manning, 2010</marker>
<rawString>Karthik Raghunathan, Heeyoung Lee, Sudarshan Rangarajan, Nathanael Chambers, Mihai Surdeanu, Dan Jurafsky, and Christopher Manning. A Multi-Pass Sieve for Coreference Resolution. In EMNLP 2010, pages 492–501.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Coreference Resolution with World Knowledge.</title>
<booktitle>In ACL 2011,</booktitle>
<pages>814--824</pages>
<marker>Rahman, Ng, </marker>
<rawString>Altaf Rahman and Vincent Ng. Coreference Resolution with World Knowledge. In ACL 2011, pages 814– 824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altaf Rahman</author>
<author>Vincent Ng</author>
</authors>
<title>Ensemble-Based Coreference Resolution. In IJCAI</title>
<date>2011</date>
<pages>1884--1889</pages>
<contexts>
<context position="4982" citStr="Rahman &amp; Ng, 2011" startWordPosition="746" endWordPosition="749"> NED restricts itself to noun phrases that denote individual entities. 846 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 846–856, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. State-of-the-Art and its Limitations: Established CR methods rely on rule-based methods or supervised learning techniques on syntactic paths between mentions, semantic compatibility, and other linguistic features (Haghighi &amp; Klein, 2009), with additional use of distant features from KBs (Lee et al., 2013). Modern cluster-ranking (Rahman &amp; Ng, 2011) and multi-sieve methods (Ratinov &amp; Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart </context>
<context position="38700" citStr="Rahman &amp; Ng, 2011" startWordPosition="6217" endWordPosition="6220"> encompassing multiple information sources (along with noise filtering) enables mutually enhanced CCR and NEL within the proposed iterative feedback based framework, C3EL. 4 Related Work Co-reference Resolution (CR): Traditional intradocument CR methods involve syntactic and semantic feature combination for identifying the best antecedent (preceding name or phrase) for a mention. CR methods employ rules or supervised learning techniques based on linguistic features such as syntactic paths and mention distances to assess semantic compatibility (Haghighi &amp; Klein, 2009; Raghunathan et al., 2010; Rahman &amp; Ng, 2011), while syntactic features are derived by deep parsing of sentences and noun group parsing. Semantic features from background knowledge resources like encyclopedia were used in (Daum´e &amp; Marcu, 2005; Ponzetto &amp; Strube, 2006; Ng, 2007). The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi &amp; Klein, 2009; Rahman &amp; Ng, 2011). An overview of CR methods is given in (Ng, 2010). Recent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing down the antecedent can</context>
<context position="40009" citStr="Rahman &amp; Ng, 2011" startWordPosition="6424" endWordPosition="6427">roposed (Rahman &amp; Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with preceding candidate clusters using relatedness features (Ratinov &amp; Roth, 2012) and distant knowledge inclusion (Durrett &amp; Klein, 2013). Person name disambiguation, a specific variation of CR, dealing with only person names, titles, nicknames, and other surface form variations was introduced in (Chen &amp; Martin, 2007). Distant Knowledge Labels: For obtaining semantic features, additional knowledge resources such as Wikipedia, YAGO, and FrameNet have been considered (Rahman &amp; Ng, 2011; Baker, 2012). CR methods with confidence-thresholds were proposed in (Ratinov &amp; Roth, 2012; Lee et al., 2013), and (Zheng et al., 2013) generalized these tech853 Baseline ECB Dataset ClueWeb09-FACC1 Dataset CCR result NEL results CCR result NEL results Within-KB Out-of-KB Within-KB Out-of-KB P R B3 C ff III C ff P R B3 C ff III C ff Ignored Mention 72.5 74.4 73.4 80.2 19.6 0.2 74.4 25.6 69.3 72.2 70.7 83.8 14.6 1.6 80.6 19.4 Co-occurrence Link Validation 79.0 81.4 80.2 85.5 14.5 0.0 62.8 37.2 74.8 81.0 77.8 88.9 10.1 1.0 69.8 30.2 (τ) ignored Removed NEL 73.2 80.7 76.8 83.9 15.9 0.2 76.1 23.</context>
</contexts>
<marker>Rahman, Ng, 2011</marker>
<rawString>Altaf Rahman and Vincent Ng. Ensemble-Based Coreference Resolution. In IJCAI 2011, pages 1884–1889.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delip Rao</author>
<author>Paul McNamee</author>
<author>Mark Dredze</author>
</authors>
<title>Streaming Cross Document Entity Coreference Resolution. In COLING</title>
<date>2010</date>
<pages>1050--1058</pages>
<contexts>
<context position="42033" citStr="Rao et al., 2010" startWordPosition="6761" endWordPosition="6764">measures (e.g., tf×idf score, KL divergence, etc.) over textual features (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004). Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named</context>
</contexts>
<marker>Rao, McNamee, Dredze, 2010</marker>
<rawString>Delip Rao, Paul McNamee, and Mark Dredze. Streaming Cross Document Entity Coreference Resolution. In COLING 2010, pages 1050–1058.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev A Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Design Challenges and Misconceptions in Named Entity Recognition. In CoNLL</title>
<date>2009</date>
<pages>147--155</pages>
<contexts>
<context position="2186" citStr="Ratinov &amp; Roth, 2009" startWordPosition="313" endWordPosition="316">th their attributes and relationships form the basis of smart applications like search, analytics, recommendations, question answering, and more. The major task that arises in both the KB construction process and the entity-centric applications involves precise recognition, resolution, and linking of named entities distributed across web pages, news articles, and social media. Named Entity Recognition (NER) deals with the identification of entity mentions in a text and their classification into coarse-grained semantic types (person, location, etc.) (Finkel et al., 2005; Nadeau &amp; Sekine, 2007; Ratinov &amp; Roth, 2009). This involves segmentation of token sequences to obtain mention boundaries, and mapping relevant token spans to pre-defined entity categories. For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2</context>
</contexts>
<marker>Ratinov, Roth, 2009</marker>
<rawString>Lev A. Ratinov and Dan Roth. Design Challenges and Misconceptions in Named Entity Recognition. In CoNLL 2009, pages 147–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev A Ratinov</author>
<author>Dan Roth</author>
<author>Doug Downey</author>
<author>Mike Anderson</author>
</authors>
<title>Local and Global Algorithms for Disambiguation to Wikipedia. In ACL</title>
<date>2011</date>
<pages>1375--1384</pages>
<contexts>
<context position="2766" citStr="Ratinov et al., 2011" startWordPosition="406" endWordPosition="409">au &amp; Sekine, 2007; Ratinov &amp; Roth, 2009). This involves segmentation of token sequences to obtain mention boundaries, and mapping relevant token spans to pre-defined entity categories. For example, NER on the text Einstein won the Nobel Prize identifies the mentions “Einstein” and “Nobel Prize” and marks them as person and misc type, respectively. Named Entity Linking (NEL)1 involves the disambiguation of textual mentions, based on context and semantic information, and their mapping to proper entities in a KB (Bunescu &amp; Pas¸ca, 2006; Cucerzan, 2007; Milne &amp; Witten, 2008; Hoffart et al., 2011; Ratinov et al., 2011; Cornolti et al., 2013). For example, in the above text, the mention “Einstein” is linked to the physicist Albert Einstein. Entity Co-reference Resolution (CR) (Haghighi &amp; Klein, 2010; Ng, 2010; Lee et al., 2013) is essentially a clustering task to identify mentions (and anaphoras) within a document referring to the same entity, thus computing equivalence classes or mention groups. For example, mentions Albert Einstein and Nobel laureate Einstein both refer to the same entity German physicist Albert Einstein, but are different from the mention Hans Albert Einstein. When CR is extended to an e</context>
<context position="5662" citStr="Ratinov et al., 2011" startWordPosition="842" endWordPosition="846">remental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases. Although NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen &amp; Roth, 2013; Zheng et al., 2013), they have mostly been explored in isolation. Recently, several joint models have been proposed for CR-NER (Haghighi &amp; Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi et al., 2013), and NER-CR-NEL (Durrett &amp; Klein, 2014). However, to the best of our knowledge, no method exists for jointly handling C</context>
<context position="42842" citStr="Ratinov et al., 2011" startWordPosition="6889" endWordPosition="6892">r, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality variance. A CCR framework combining co-occurring mention context with distant KB features embedded in an active hierarchical clustering procedure (Dutta &amp; Weikum, 2015) was recently shown to perform efficiently, and provides inspiration for parts of our proposed C3EL approach. Named Entity Linking (NEL): Named entity resolution and linking stems from SemTag (Dill et al., 2003), and similar frameworks like GLOW, WikipediaMiner, AIDA, and others (Milne &amp; Witten, 2008; Ratinov et al., 2011). A collection of entity disambiguation models was presented in (Kulkarni et al., 2009). Other NEL approaches utilize the notion of semantic similarity of entities to corresponding Wikipedia pages (Milne &amp; Witten, 2008), while co-referent mention graph construction modeling mention co-occurrences and context similarity from outgoing hyperlinks in Wikipedia was used by (Hoffart et al., 2011). An integer linear programming (ILP) formulation also based on Wikipedia page similarities was presented in (Ratinov et al., 2011). However, none of these methods involve the incorporation of CR results for</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>Lev A. Ratinov, Dan Roth, Doug Downey, and Mike Anderson. Local and Global Algorithms for Disambiguation to Wikipedia. In ACL 2011, pages 1375– 1384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev A Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Learning-based MultiSieve Co-reference Resolution with Knowledge. In EMNLP-CoNLL</title>
<date>2012</date>
<pages>1234--1244</pages>
<contexts>
<context position="5029" citStr="Ratinov &amp; Roth, 2012" startWordPosition="753" endWordPosition="756">enote individual entities. 846 Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 846–856, Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics. State-of-the-Art and its Limitations: Established CR methods rely on rule-based methods or supervised learning techniques on syntactic paths between mentions, semantic compatibility, and other linguistic features (Haghighi &amp; Klein, 2009), with additional use of distant features from KBs (Lee et al., 2013). Modern cluster-ranking (Rahman &amp; Ng, 2011) and multi-sieve methods (Ratinov &amp; Roth, 2012) involve incremental expansion of mention groups by considering semantic types and Wikipedia categories. CCR methods utilize transitivity-aware clustering techniques (Singh et al., 2011), by considering mention-mention similarities (Bagga &amp; Baldwin, 1998) along with features extracted from external KBs (Dutta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et</context>
<context position="39602" citStr="Ratinov &amp; Roth, 2012" startWordPosition="6362" endWordPosition="6365"> bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi &amp; Klein, 2009; Rahman &amp; Ng, 2011). An overview of CR methods is given in (Ng, 2010). Recent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing down the antecedent candidates for a mention (Raghunathan et al., 2010). Cluster ranking functions have also been proposed (Rahman &amp; Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with preceding candidate clusters using relatedness features (Ratinov &amp; Roth, 2012) and distant knowledge inclusion (Durrett &amp; Klein, 2013). Person name disambiguation, a specific variation of CR, dealing with only person names, titles, nicknames, and other surface form variations was introduced in (Chen &amp; Martin, 2007). Distant Knowledge Labels: For obtaining semantic features, additional knowledge resources such as Wikipedia, YAGO, and FrameNet have been considered (Rahman &amp; Ng, 2011; Baker, 2012). CR methods with confidence-thresholds were proposed in (Ratinov &amp; Roth, 2012; Lee et al., 2013), and (Zheng et al., 2013) generalized these tech853 Baseline ECB Dataset ClueWeb0</context>
<context position="43523" citStr="Ratinov &amp; Roth, 2012" startWordPosition="6993" endWordPosition="6996"> in (Kulkarni et al., 2009). Other NEL approaches utilize the notion of semantic similarity of entities to corresponding Wikipedia pages (Milne &amp; Witten, 2008), while co-referent mention graph construction modeling mention co-occurrences and context similarity from outgoing hyperlinks in Wikipedia was used by (Hoffart et al., 2011). An integer linear programming (ILP) formulation also based on Wikipedia page similarities was presented in (Ratinov et al., 2011). However, none of these methods involve the incorporation of CR results for NEL. The first study on the benefits of CR for NEL was by (Ratinov &amp; Roth, 2012); but a joint model was not proposed, instead attributes from Wikipedia categories were used as features. An overview and evaluation of different NEL methods has been given by (Hachey et al., 2013). Joint Models: Jointly solving CR for entities and events utilizing cluster construction based on feature semantic dependencies was devised in (Lee et al., 2012). The use of CR as a pre-processing step for subsequent NEL procedure using an ILP formulation was proposed by (Chen &amp; Roth, 2013). Recently, (Hajishirzi et al., 2013) proposed a joint model for CR and NEL using the Stanford multipass cluste</context>
</contexts>
<marker>Ratinov, Roth, 2012</marker>
<rawString>Lev A. Ratinov and Dan Roth. Learning-based MultiSieve Co-reference Resolution with Knowledge. In EMNLP-CoNLL 2012, pages 1234–1244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon E Schwarz</author>
</authors>
<title>Estimating the Dimension of a Model. Annals of Statistics</title>
<date>1978</date>
<pages>6--2</pages>
<contexts>
<context position="20565" citStr="Schwarz, 1978" startWordPosition="3275" endWordPosition="3276">m, 2015) is used to assign feature weights using tf-idf measure. B. Hierarchical Clustering: s mention groups are uniformly randomly sampled and their similarities to the other groups (using context summary) are computed. A similarity-weighted graph with the mention groups as nodes and edge weights representing mention-mention similarities is constructed. Bisection-based hierarchical balanced min-edge-cut graph partitioning (Buluc et al., 2013) is performed, using the METI5 software (Karypis &amp; Kumar, 1999)2, to partition noncoreferent mentions groups. The Bayesian Information Criterion (BIC) (Schwarz, 1978; Hourdakis et al., 2010), a Bayesian variant of Minimum Description Length (Gr¨unwald, 2007), is used as the cluster split stopping criterion, and the context summaries within each final cluster are merged. CCR aims to process heterogeneous corpora that go beyond a single domain and style, such as Web collections. 2.3 Finalization Stage For the remaining mention groups in WE, we finally perform threshold based disambiguation of mention clusters using the context summaries. For each mention group MZ E WE, we compute (1) its context summary similarities (as in Section 2.2.2) to all other mentio</context>
</contexts>
<marker>Schwarz, 1978</marker>
<rawString>Gideon E. Schwarz. Estimating the Dimension of a Model. Annals of Statistics 1978, 6(2):461–464.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Avirup Sil</author>
<author>Alexander Yates</author>
</authors>
<title>Re-ranking for Joint Named-Entity Recognition and Linking.</title>
<booktitle>In CIKM 2013,</booktitle>
<pages>2369--2374</pages>
<marker>Sil, Yates, </marker>
<rawString>Avirup Sil and Alexander Yates. Re-ranking for Joint Named-Entity Recognition and Linking. In CIKM 2013, pages 2369–2374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Singh</author>
<author>Michael L Wick</author>
<author>Andrew McCallum</author>
</authors>
<title>Distantly Labeling Data for Large Scale CrossDocument Coreference. CoRR abs/1005.4298,</title>
<date>2010</date>
<contexts>
<context position="41756" citStr="Singh et al., 2010" startWordPosition="6715" endWordPosition="6718">ensive. On the other hand, we extract distant features for the strongly matching (best) candidate only, reducing the performance overhead. Cross-Document CR (CCR): Early approaches towards CCR involved the use contextual information from input documents for IR-style similarity measures (e.g., tf×idf score, KL divergence, etc.) over textual features (Bagga &amp; Baldwin, 1998; Gooi &amp; Allan, 2004). Probabilistic graphical models jointly learning the mappings of mentions to equivalent classes (co-referring mentions) using features similar to local CR techniques were studied in (Culotta et al., 2007; Singh et al., 2010; Singh et al., 2011), A clustering approach coupled with statistical learning of parameters was studied in (Baron &amp; Freedman, 2008). However, such methods fail to cope with large corpora, and hence a “light-weight” streaming variant of CCR was introduced by (Rao et al., 2010). Co-occurring mentions context have been harnessed for disambiguating person names for CR in (Mann &amp; Yarowsky, 2003; Niu et al., 2004; Chen &amp; Martin, 2007; Baron &amp; Freedman, 2008). However, these methods do not use KB and depend on information extraction (IE) methods, witnessing substantial noise due to IE quality varian</context>
</contexts>
<marker>Singh, Wick, McCallum, 2010</marker>
<rawString>Sameer Singh, Michael L. Wick, and Andrew McCallum. Distantly Labeling Data for Large Scale CrossDocument Coreference. CoRR abs/1005.4298, 2010.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sameer Singh</author>
<author>Amarnag Subramanya</author>
<author>Fernando Pereira</author>
<author>Andrew McCallum</author>
</authors>
<title>Large-Scale CrossDocument Coreference Using Distributed Inference and Hierarchical Models.</title>
<booktitle>In ACL 2011,</booktitle>
<pages>793--803</pages>
<marker>Singh, Subramanya, Pereira, McCallum, </marker>
<rawString>Sameer Singh, Amarnag Subramanya, Fernando Pereira, and Andrew McCallum. Large-Scale CrossDocument Coreference Using Distributed Inference and Hierarchical Models. In ACL 2011, pages 793– 803.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Sameer Singh</author>
<author>Sebastian Reidel</author>
<author>Brian Martin</author>
<author>Jiaping Zheng</author>
<author>Andrew McCallum</author>
</authors>
<title>Joint Inference of Entities, Relations, and Coreference.</title>
<booktitle>In Workshop of AKBC 2013,</booktitle>
<pages>1--6</pages>
<marker>Singh, Reidel, Martin, Zheng, McCallum, </marker>
<rawString>Sameer Singh, Sebastian Reidel, Brian Martin, Jiaping Zheng, and Andrew McCallum. Joint Inference of Entities, Relations, and Coreference. In Workshop of AKBC 2013, pages 1–6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabian M Suchanek</author>
<author>Gjergji Kasneci</author>
<author>Gerhard Weikum</author>
</authors>
<title>YAGO: a Core of Semantic Knowledge. In WWW</title>
<date>2007</date>
<pages>697--706</pages>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Fabian M. Suchanek, Gjergji Kasneci, and Gerhard Weikum. YAGO: a Core of Semantic Knowledge. In WWW 2007, pages 697–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bilyana Taneva</author>
<author>Mouna Kacimi</author>
<author>Gerhard Weikum</author>
</authors>
<title>Finding Images of Difficult Entities in the Long Tail. In CIKM</title>
<date>2011</date>
<pages>189--194</pages>
<contexts>
<context position="19689" citStr="Taneva et al., 2011" startWordPosition="3144" endWordPosition="3147"> have failed link validation during the NEL procedure. These entities are most likely to be outof-KB and are allocated to this class. 2.2.2 Cross-Document CR (CCR) Stage The CCR stage of C3EL adopts the samplingbased hierarchical clustering approach of (Dutta &amp; Weikum, 2015), to obtain co-referring mention clusters. A. Similarity Measure: To infer whether two mention groups represent the same entity, the similarity between the context summaries are computed based on (i) tf-idf-weighted bag-of-words cosine distance, and (ii) partial-match scores of multiword keyphrases in bounded text windows (Taneva et al., 2011). The context summaries (with stopwords removed) are re-interpreted as, (i) bag of words, and (ii) bag of keyphrases, to extract fea849 ture vectors for similarity computation. Finally, the mixture model of bag-of-words (BoW) and keyphrases (KP) of (Dutta &amp; Weikum, 2015) is used to assign feature weights using tf-idf measure. B. Hierarchical Clustering: s mention groups are uniformly randomly sampled and their similarities to the other groups (using context summary) are computed. A similarity-weighted graph with the mention groups as nodes and edge weights representing mention-mention similari</context>
</contexts>
<marker>Taneva, Kacimi, Weikum, 2011</marker>
<rawString>Bilyana Taneva, Mouna Kacimi, and Gerhard Weikum. Finding Images of Difficult Entities in the Long Tail. In CIKM 2011, pages 189–194.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mohamed A Yosef</author>
<author>Johannes Hoffart</author>
<author>Marc Spaniol</author>
<author>Gerhard Weikum</author>
</authors>
<title>AIDA: An Online Tool for Accurate Disambiguation of Named Entities in Text and Tables.</title>
<booktitle>In VLDB 2011,</booktitle>
<pages>4--12</pages>
<marker>Yosef, Hoffart, Spaniol, Weikum, </marker>
<rawString>Mohamed A. Yosef, Johannes Hoffart, Marc Spaniol, and Gerhard Weikum. AIDA: An Online Tool for Accurate Disambiguation of Named Entities in Text and Tables. In VLDB 2011, 4(12):1450–1453.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiaping Zheng</author>
<author>Luke Vilnis</author>
<author>Sameer Singh</author>
<author>Jinho D Choi</author>
<author>Andrew McCallum</author>
</authors>
<title>Dynamic knowledgebase alignment for coreference resolution. In CoNLL</title>
<date>2013</date>
<pages>153--162</pages>
<contexts>
<context position="5956" citStr="Zheng et al., 2013" startWordPosition="895" endWordPosition="898">ta &amp; Weikum, 2015). NEL methods often harness the semantic similarity between mentions and entities and also among candidate entities for different mentions (in Wikipedia or other KBs) for contextualization and coherence disambiguation (Hoffart et al., 2011; Milne &amp; Witten, 2008; Kulkarni et al., 2009; Ratinov et al., 2011). However, in the absence of CR mention groups, NEL has limited context and is bound to miss out on certain kinds of difficult cases. Although NER, CR, CCR and NEL involve closely related tasks and their tighter integration has been shown to be promising (Chen &amp; Roth, 2013; Zheng et al., 2013), they have mostly been explored in isolation. Recently, several joint models have been proposed for CR-NER (Haghighi &amp; Klein, 2010; Singh et al., 2013), CR-NEL (Hajishirzi et al., 2013), and NER-CR-NEL (Durrett &amp; Klein, 2014). However, to the best of our knowledge, no method exists for jointly handling CCR and NEL on large text corpora. 1.1 Approach and Contributions This paper proposes the novel C3EL (CrossdoCument Co-reference resolution and Entity Linking) framework for jointly modeling crossdocument co-reference resolution (CCR) and linkage of mention groups to entities in a knowledge bas</context>
<context position="37621" citStr="Zheng et al., 2013" startWordPosition="6054" endWordPosition="6057"> of out-of-KB entitymentions compared to C3EL. • NEL Categorization: The differentiation of mentions (into classes) confidently mapped to KB entity reduces the collusion of “strong” linked mentions with other “noisy” mention contexts. This reduces incorrect grouping of different mentions with similar surface forms, contexts, etc., thereby improving precision of the CCR process. Use of a single NEL classification approach is observed to degrade CCR results, which in turn increases spurious entity linkage, decreasing NEL efficiency (Table 10). • Distant KB features: As observed in (Baker, 2012; Zheng et al., 2013), extracted external KB features provide global and enhanced information cues promoting CR. We similarly observe CCR to attain the lowest F1 scores (compared to other baselines) when KB features are ignored. This in turn affects the linking of (some) well-known entities due to reduced context, leading to incorrect or low confidence NEL. Since no feature inclusion is performed for out-of-KB mentions, no effect is observed. We observe that a joint formulation encompassing multiple information sources (along with noise filtering) enables mutually enhanced CCR and NEL within the proposed iterative</context>
<context position="39439" citStr="Zheng et al., 2013" startWordPosition="6339" endWordPosition="6342">round knowledge resources like encyclopedia were used in (Daum´e &amp; Marcu, 2005; Ponzetto &amp; Strube, 2006; Ng, 2007). The use of Wikipedia and structured knowledge bases (such as YAGO) to obtain mention-type relation and fine-grained mention attributes was explored by (Haghighi &amp; Klein, 2009; Rahman &amp; Ng, 2011). An overview of CR methods is given in (Ng, 2010). Recent methods involve the use of multi-phase sieve, applying a cascade of rules for narrowing down the antecedent candidates for a mention (Raghunathan et al., 2010). Cluster ranking functions have also been proposed (Rahman &amp; Ng, 2011; Zheng et al., 2013) to extend this paradigm for incrementally expanding and merging mention groups with preceding candidate clusters using relatedness features (Ratinov &amp; Roth, 2012) and distant knowledge inclusion (Durrett &amp; Klein, 2013). Person name disambiguation, a specific variation of CR, dealing with only person names, titles, nicknames, and other surface form variations was introduced in (Chen &amp; Martin, 2007). Distant Knowledge Labels: For obtaining semantic features, additional knowledge resources such as Wikipedia, YAGO, and FrameNet have been considered (Rahman &amp; Ng, 2011; Baker, 2012). CR methods wit</context>
</contexts>
<marker>Zheng, Vilnis, Singh, Choi, McCallum, 2013</marker>
<rawString>Jiaping Zheng, Luke Vilnis, Sameer Singh, Jinho D. Choi, and Andrew McCallum. Dynamic knowledgebase alignment for coreference resolution. In CoNLL 2013, pages 153–162.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>