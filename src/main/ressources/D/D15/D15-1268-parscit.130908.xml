<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000571">
<title confidence="0.97952">
Fatal or not? Finding errors that lead to dialogue breakdowns in
chat-oriented dialogue systems
</title>
<author confidence="0.7586345">
Ryuichiro Higashinaka1, Masahiro Mizukami2, Kotaro Funakoshi3,
Masahiro Araki4, Hiroshi Tsukahara5, Yuka Kobayashi6
</author>
<affiliation confidence="0.965954666666667">
1NTT Corporation, 2Nara Institute of Science and Technology
3Honda Research Institute Japan, 4Kyoto Institute of Technology
5Denso IT Laboratory, Inc., 6Toshiba Corporation
</affiliation>
<sectionHeader confidence="0.977566" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999275">
This paper aims to find errors that lead to
dialogue breakdowns in chat-oriented dia-
logue systems. We collected chat dialogue
data, annotated them with dialogue break-
down labels, and collected comments de-
scribing the error that led to the break-
down. By mining the comments, we first
identified error types. Then, we calculated
the correlation between an error type and
the degree of dialogue breakdown it in-
curred, quantifying its impact on dialogue
breakdown. This is the first study to quan-
titatively analyze error types and their ef-
fect in chat-oriented dialogue systems.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998845">
Chat-oriented or open-domain dialogue systems
have recently been attracting attention from so-
cial and entertainment aspects (Bickmore and Cas-
sell, 2001; Banchs and Li, 2012; Wilcock and
Jokinen, 2013). However, since they need to
deal with open-domain utterances, which current
natural language processing techniques are not
mature enough to handle appropriately, the sys-
tem inevitably makes errors. This discourages
users from talking to the system, leading to di-
alogue breakdowns in conversation (Martinovsky
and Traum, 2003). Here, dialogue breakdowns de-
note points in dialogue where users are unable to
continue the conversation.
This paper aims to find errors that lead to dia-
logue breakdowns in chat-oriented dialogue sys-
tems. Our approach is two-fold: (1) identify error
types in chat-oriented dialogue systems, and (2)
calculate their impact on dialogue breakdown. For
(1), we first collect chat dialogues between an au-
tomated system and users, annotate the dialogues
with dialogue breakdown labels, and collect com-
ments that describe the error that led to the break-
downs. After that, we apply automatic cluster-
ing methods to the comments to obtain clusters of
comments, each of which corresponds to a partic-
ular error type. For (2), we calculate the correla-
tion between an error type and the degree of dia-
logue breakdown it incurs. This way, we can quan-
tify the impact of an error type on dialogue break-
down. By our approach, we hope to distinguish
fatal errors from non-fatal ones, providing useful
guidelines for dialogue system developers to avoid
breakdowns in chat-oriented dialogue systems.
</bodyText>
<sectionHeader confidence="0.989243" genericHeader="method">
2 Data Collection
</sectionHeader>
<bodyText confidence="0.960793518518519">
For data collection, we asked dialogue researchers
and their collaborators in Japan to use our chat-
oriented dialogue system. The system is text-
based and enables chatting in Japanese. It was
built by wrapping a chat API provided by NTT
DOCOMO (Onishi and Yoshimura, 2014). Since
the API works on the basis of (Higashinaka et al.,
2014), which uses a number of natural language
processing techniques to understand and generate
utterances, we expected to obtain a wide variety of
dialogues, and hence, a variety of errors.
A total of 116 users chatted with the system, re-
sulting in 1,146 dialogues. Here, each dialogue
was controlled to be 21 utterances long: one sys-
tem prompt with ten utterances each from the
user and system. Then, we randomly sampled
100 dialogues (called the init100 data set) for di-
alogue breakdown annotation. Twenty-four anno-
tators subjectively labeled each system utterance
in init100 with one of the following three dialogue
breakdown labels:
(NB) Not a breakdown: The conversation is
easy to continue after the system utterance in
question.
(PB) Possible breakdown: The conversation is
difficult to continue smoothly after the sys-
tem utterance in question.
</bodyText>
<page confidence="0.830176">
2243
</page>
<note confidence="0.8544365">
Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, pages 2243–2248,
Lisbon, Portugal, 17-21 September 2015. c�2015 Association for Computational Linguistics.
</note>
<table confidence="0.975039571428571">
Utterance NB PB B C
S0 Hello! Talk to me anytime. 24 0 0 0
U1 It’s hot today, isn’t it?
S1 Please tell me your favorite movie 20 2 2 2
genre.
U2 I like action movies.
S2 Action movies, I like them. 21 3 0 0
U3 What kind of movies do you like?
S3 I like Japanese ones. 23 1 0 0
U4 That’s great.
S4 Thank you. 24 0 0 0
U5 Do you know what movie will be
aired on Friday night?
S5 Yes, yes. 4 11 9 4
U6 I haven’t heard of that movie.
S6 That’s good. 3 10 11 4
U7 Oh, is it good? I will watch it then.
S7 That’s good! 18 3 3 1
U8 Recently, I have had lots of free
time.
S8 That’s great. 15 7 2 0
U9 Are you busy?
S9 Indeed so. 24 0 0 0
U10 Take care. Have some rest.
S10 I see. 10 9 5 2
Comments
User utterance is not considered. / The system ig-
nored user’s intended topic.
</table>
<bodyText confidence="0.950154555555555">
The system did not mention a movie name. / It
answered only “yes” but without saying a movie
name. / This is not an answer to the question. /
The conversation is not valid.
This is not a response to a question. / Strange an-
swer. / It is not clear what is good. / The conversa-
tion is not valid.
It is not clear what is good.
The system should thank the user. / Strange answer.
</bodyText>
<figureCaption confidence="0.972832833333333">
Figure 1: Example dialogue with the number of breakdown labels for each system utterance. S and U
stand for system and user utterances, respectively. C stands for the number of comments provided. The
dialogue was originally in Japanese and was translated by the authors.
(B) Breakdown: The conversation is difficult to
continue at all after the system utterance in
question.
</figureCaption>
<bodyText confidence="0.999970476190476">
The annotators were instructed to provide volun-
tary comments to describe the errors that led to the
breakdowns. Table 1 shows the statistics of the di-
alogue breakdown labels and comments. Figure
1 shows an example dialogue with the number of
breakdown labels and comments for each system
utterance. In this example, S5 and S6 were anno-
tated with nine and eleven breakdown labels, re-
spectively, both having four comments.
The inter-annotator agreement of dialogue
breakdown annotation in Fleiss’ kappa was 0.276,
which seems relatively low. One reason for this
is obviously the subjective nature of the task. An-
other possible reason is that we intentionally did
not set rigid guidelines for dialogue breakdown
annotation so as to explore possible error types in
chat-oriented dialogue systems. When we merge
PB and B and make it a two-class annotation, the
agreement becomes 0.396 (moderate agreement),
showing that the subjects share some common
conception about dialogue breakdown.
</bodyText>
<table confidence="0.25563">
Breakdown label # of labels # of comments
NB 14,212 57
PB 5,322 1,818
B 4,466 1,511
</table>
<tableCaption confidence="0.633421333333333">
Table 1: Statistics related to breakdown labels and
comments in init100 data set. Note that NB also
had some opinions as comments.
</tableCaption>
<sectionHeader confidence="0.996813" genericHeader="method">
3 Analysis
</sectionHeader>
<subsectionHeader confidence="0.999934">
3.1 Automatic clustering of comments
</subsectionHeader>
<bodyText confidence="0.999962692307692">
We first need to identify the error types in chat-
oriented dialogue systems. For this, we applied
an automatic clustering method to the comments
to obtain clusters of comments. Our idea is that,
since each comment describes a particular error
that led to a breakdown, a cluster of comments is
likely to represent an error type. Since the num-
ber of clusters is difficult to know in advance, we
turn to a non-parametric Bayesian method called
the Chinese restaurant process (CRP) as a cluster-
ing method. CRP can infer the number of clusters
automatically from data (Pitman, 1995).
We applied CRP to the 1,511 comments given
</bodyText>
<page confidence="0.985424">
2244
</page>
<figure confidence="0.997898342857143">
ID Size
2
0
6
7
1
8
16
4
5
3
14
11
12
13
10
15
9
259
194
148
134
113
107
100
95
77
54
53
39
38
36
35
25
4
</figure>
<table confidence="0.933918071428571">
Interpretation
General quality
Not understandable
Ignore user utterance
Ignore user question
Unclear intention
Contradiction
Analysis failure
Inappropriate answer
Repetition
Grammatical error
Expression error
Topic-change error
Violation of common sense
Word usage error
Diversion
Mismatch in conversation
Social error
Representative words in the cluster
dialogue, well-formed, consideration, conversation
understand, meaning, what
ignore, user, utterance
answer, question, partner, respond
unclear, intention, meaning, utterance
doubtful, change, negative (as opposed to positive), previous
analysis, recognition, related, understand
response, inappropriate, invalid, answer
say, add, mind, strange, tired
</table>
<tableCaption confidence="0.807394666666667">
(words specific to particular grammar usage)
(words specific to particular expressions)
change, topic, sudden, mismatch, response
match, flow, common sense, against, connection
(words specific to particular word usage)
story, different
match, story
(no words)
Table 2: Clusters by CRP of 1,511 comments given to breakdowns. The clusters are ordered by size.
</tableCaption>
<bodyText confidence="0.999982244444445">
to breakdown labels (B labels). For the clustering,
we used the same procedure as (Higashinaka et al.,
2011); each datum (comment) was represented by
a word frequency vector, and the probability that
it belonged to a particular cluster was calculated
by using the likelihood that the words are gener-
ated from the word distribution of that cluster. The
hyper-parameters α and β were both set to 0.1 and
the number of iterations for Gibbs sampling was
10,000. See (Higashinaka et al., 2011) for the de-
tails of the procedure.
Table 2 shows the clustering results. We ob-
tained 17 clusters. For each cluster, we mined
representative words by a log-likelihood ratio test,
which uses a two-by-two matrix to test the inde-
pendence of a word to a particular cluster. By
looking at the representative words and also the
raw comments, we came up with the interpreta-
tions of the clusters as indicated in the table. Al-
though we do not go into the details of the clus-
ters one by one, each cluster seems to success-
fully represent a certain error type in chat-oriented
dialogue systems. We also applied CRP to the
3,329 comments given to PB and B to obtain sim-
ilar clusters except that we additionally had clus-
ters whose interpretations are as follows: inability
to handle invalid user input, missing topic, miss-
ing information, mismatch in response, no reac-
tion, and no information. They account for about
13.3% of the comments and mostly concern miss-
ing elements (such as missing arguments) in dia-
logue. Since such missing elements can be com-
plemented by follow-on utterances in dialogue,
they only appear in the comments for PB; they do
not lead to an immediate dialogue breakdown.
To further categorize the clusters, we applied a
hierarchical clustering (an agglomerative cluster-
ing) to the clusters. Here, a cluster was represented
by the word frequency vector of all comments con-
tained in the cluster, and the similarity of the clus-
ters was calculated by cosine similarity of word
frequency vectors. For the linkage criterion, we
used Ward’s method. Figure 2 shows the cluster-
ing results. The figure indicates that there are the
following eight main error categories (E1–E8):
</bodyText>
<listItem confidence="0.980931">
(E1) Clusters 2 and 16 concern the general ability
of a system.
(E2) Clusters 7, 5, and 8 relate to context aware-
ness: the ability to recognize when it is asked
a question and to recognize what has been
said before.
(E3) Clusters 13, 3, and 14 concern the language
generation (surface realization) ability.
(E4) Clusters 4 and 6 concern the response abil-
ity: the ability to answer questions and to cre-
ate utterances relevant to the previous user ut-
terance.
(E5) Cluster 1 relates to the exhibition of an in-
tention or a plan: the ability to make clear the
</listItem>
<page confidence="0.981277">
2245
</page>
<figure confidence="0.887699833333333">
0.0 0.4 0.8 1.2
12:Violation of common sense (38)
0:Not understandable (194)
15:Mismatch in conversation (25)
10:Diversion (35)
11:Topic−change error (39)
</figure>
<figureCaption confidence="0.991803">
Figure 2: Hierarchical clustering applied to the ob-
tained clusters. The numbers in parentheses de-
note cluster size.
</figureCaption>
<bodyText confidence="0.898793">
purpose of an utterance.
</bodyText>
<listItem confidence="0.992048333333333">
(E6) Clusters 9 and 12 relate to the social ability:
the ability not to offend users or say things
that are not socially acceptable.
(E7) Clusters 0 and 15 concern the understand-
ability of an utterance: the ability to gener-
ate utterances that have clear meanings in the
context of the conversation.
(E8) Clusters 10 and 11 relate to the awareness of
current topics.
</listItem>
<subsectionHeader confidence="0.999969">
3.2 Analyzing the impact of error types
</subsectionHeader>
<bodyText confidence="0.9995247">
Having identified the error types and error cate-
gories, we investigated their impact on dialogue
breakdown. For this purpose, we examined the
correlation between an error type and its degree
of breakdown: the higher the correlation, the more
it is related to dialogue breakdown. Specifically,
we calculated the correlation ratio (η) between the
existence of a comment belonging to a particular
cluster (error type) and the number of breakdown
labels (B labels). Note that the correlation ratio
</bodyText>
<figure confidence="0.944844944444445">
ID Interpretation Cat η
0 Not understandable E7 0.38
7 Ignore user question E2 0.37
2 General quality E1 0.36
1 Unclear intention E5 0.36
6 Ignore user utterance E4 0.24
13 Word usage error E3 0.18
16 Analysis failure E1 0.17
4 Inappropriate answer E4 0.17
3 Grammatical error E3 0.15
12 Violation of common sense E6 0.15
8 Contradiction E2 0.14
5 Repetition E2 0.11
9 Social error E6 0.10
10 Diversion E8 0.09
11 Topic-change error E8 0.06
15 Mismatch in conversation E7 0.06
14 Expression error E3 0.02
</figure>
<tableCaption confidence="0.975299">
Table 3: Correlation ratio (η) between the exis-
</tableCaption>
<bodyText confidence="0.99119564516129">
tence of a comment of a cluster (error type) and
the number of breakdown labels. “Cat” denotes
the error category of an error type.
is equivalent to Pearson’s correlation coefficient
except that it can be applied to categorical data.
The η ranges from 0 to 1. For calculation, we first
extracted data that had one or more B labels and
one or more corresponding comments (we had 556
such samples in our data). Then, we calculated the
correlation ratios.
Table 3 shows the correlation ratios for the er-
ror types. Clearly, not all error types have the
same level of correlation. At the top of the ta-
ble, there are four salient error types with similar η
values: “Not understandable”, “Ignore user ques-
tion”, “General quality”, and “Unclear intention”.
Putting aside “General quality”, which seems to
concern the overall dialogue ability, the error types
that we need to consider as fatal would seem to be
the other three. Other errors seem to be less im-
portant with lower η values. “Expression error”,
which concerns the use of unnatural expressions,
was found the least important.
When we look at the error categories, we can
see an interesting result that it is NOT the error cat-
egory that determines the fatality of errors but the
specificity of error types. For example, “Not un-
derstandable” and “Mismatch in conversation” are
both under error category E7 but have totally dif-
ferent effects on perceived breakdown. The same
can be said for error types in E2.
</bodyText>
<footnote confidence="0.99416325">
2:General quality (259)
16:Analysis failure (100)
7:Ignore user question (134)
5:Repetition (77)
8:Contradiction (107)
13:Word usage error (36)
3:Grammatical error (54)
14:Expression error (53)
4:Inappropriate answer (95)
6:Ignore user utterance (148)
1:Unclear intention (113)
9:Social error (4)
</footnote>
<page confidence="0.992151">
2246
</page>
<bodyText confidence="0.9999653">
Note that, although the values of correlation ra-
tio seem rather low, the correlation often becomes
low when it comes to subjective judgments (Hi-
gashinaka et al., 2004). Considering that we deal
with chat-oriented dialogues, which are less re-
stricted than task-oriented ones, we consider the
current values of correlation ratio to be accept-
able. Here, the important finding is that several
error types are comparatively more important than
the others.
</bodyText>
<sectionHeader confidence="0.999969" genericHeader="method">
4 Related work
</sectionHeader>
<bodyText confidence="0.999966416666667">
Few studies have analyzed breakdowns in conver-
sation. One exception is the study by Martinovsky
and Traum (2003), who discussed possible causes
of breakdowns they observed. Our work is differ-
ent in that we systematically identify error types
and quantitatively evaluate their effect. Our work
can be seen as listing up errors in dialogue sys-
tems. A number of studies have aimed to create a
taxonomy of errors (Bernsen et al., 1996; M¨oller,
2002; Paek, 2003), but their taxonomies are cre-
ated manually and focus on task-oriented dialogue
systems.
</bodyText>
<sectionHeader confidence="0.96306" genericHeader="conclusions">
5 Summary and future work
</sectionHeader>
<bodyText confidence="0.999930538461538">
By processing dialogue data with dialogue break-
down annotations and comments, this paper iden-
tified 17 error types that can be further categorized
into eight error categories. By calculating corre-
lation ratios, we discovered three error types that
can be fatal: “Not understandable”, “Ignore user
question”, and “Unclear intention”. To avoid dia-
logue breakdowns, it is suggested that we need to
make clear the meanings of system utterances, not
ignore user questions, and show some intention
behind system utterances. The findings will be
useful for dialogue system developers who want
to realize smooth human-machine interaction in
chat-oriented dialogue systems and possibly in di-
alogue design as a whole.
For future work, we plan to consider ways to
improve systems on the basis of our findings and
also verify the generality of the results on data
using other systems. To accurately detect dia-
logue breakdowns, dialogue systems researchers
will need to collaborate. To this end, we are plan-
ning to organize an evaluation workshop on dia-
logue breakdown detection. For use in the eval-
uation workshop as well as in dialogue research
in general, we have released our data with all the
annotations and comments to the public.1
</bodyText>
<sectionHeader confidence="0.977969" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999248">
The “Project Next NLP” project in Japan is ad-
dressing the problems related to analyzing errors
in natural language processing systems. One sub-
group, comprising more than 32 researchers from
15 institutions, is collaborating in the performance
of a dialogue task. We thank the members of
this sub-group for the data collection, annotation,
and fruitful discussions. We also thank NTT DO-
COMO for letting us use their chat API for data
collection.
</bodyText>
<sectionHeader confidence="0.999402" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999657028571428">
Rafael E Banchs and Haizhou Li. 2012. IRIS: a chat-
oriented dialogue system based on the vector space
model. In Proc. the ACL 2012 System Demonstra-
tions, pages 37–42.
Niels Ole Bernsen, Hans Dybkjaer, and Laila Dybk-
jaer. 1996. Principles for the design of cooperative
spoken human-machine dialogue. In Proc. ICSLP,
volume 2, pages 729–732.
Timothy W. Bickmore and Justine Cassell. 2001.
Relational agents: a model and implementation of
building user trust. In Proc. CHI, pages 396–403.
Ryuichiro Higashinaka, Noboru Miyazaki, Mikio
Nakano, and Kiyoaki Aikawa. 2004. Evaluat-
ing discourse understanding in spoken dialogue sys-
tems. ACM Transactions on Speech and Language
Processing (TSLP), 1:1–20.
Ryuichiro Higashinaka, Noriaki Kawamae, Kugatsu
Sadamitsu, Yasuhiro Minami, Toyomi Meguro, Ko-
hji Dohsaka, and Hirohito Inagaki. 2011. Unsuper-
vised clustering of utterances using non-parametric
bayesian methods. In Proc. INTERSPEECH, pages
2081–2084.
Ryuichiro Higashinaka, Kenji Imamura, Toyomi Me-
guro, Chiaki Miyazaki, Nozomi Kobayashi, Hiroaki
Sugiyama, Toru Hirano, Toshiro Makino, and Yoshi-
hiro Matsuo. 2014. Towards an open-domain con-
versational system fully based on natural language
processing. In Proc. COLING, pages 928–939.
Bilyana Martinovsky and David Traum. 2003. The er-
ror is the clue: Breakdown in human-machine inter-
action. In Proc. ISCA Workshop on Error Handling
in Spoken Dialogue Systems, pages 11–16.
Sebastian M¨oller. 2002. A new taxonomy for the qual-
ity of telephone services based on spoken dialogue
systems. In Proc. SIGDIAL, pages 142–153.
</reference>
<footnote confidence="0.9505115">
1https://sites.google.com/site/
dialoguebreakdowndetection/
</footnote>
<page confidence="0.979474">
2247
</page>
<reference confidence="0.998660384615385">
Kanako Onishi and Takeshi Yoshimura. 2014. Ca-
sual conversation technology achieving natural di-
alog with computers. NTT DOCOMO Technical
Jouranl, 15(4):16–21.
Tim Paek. 2003. Toward a taxonomy of communica-
tion errors. In Proc. ISCA Workshop on Error Han-
dling in Spoken Dialogue Systems, pages 53–58.
Jim Pitman. 1995. Exchangeable and partially ex-
changeable random partitions. Probability theory
and related fields, 102(2):145–158.
Graham Wilcock and Kristiina Jokinen. 2013. Wik-
italk human-robot interactions. In Proc. ICMI,
pages 73–74.
</reference>
<page confidence="0.992122">
2248
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.935851">
<title confidence="0.9863115">Fatal or not? Finding errors that lead to dialogue breakdowns chat-oriented dialogue systems</title>
<author confidence="0.996623">Masahiro Kotaro</author>
<affiliation confidence="0.991085333333333">Corporation, Institute of Science and Research Institute Japan, Institute of IT Laboratory, Inc., Corporation</affiliation>
<abstract confidence="0.9984924">This paper aims to find errors that lead to dialogue breakdowns in chat-oriented dialogue systems. We collected chat dialogue data, annotated them with dialogue breakdown labels, and collected comments describing the error that led to the breakdown. By mining the comments, we first identified error types. Then, we calculated the correlation between an error type and the degree of dialogue breakdown it incurred, quantifying its impact on dialogue breakdown. This is the first study to quantitatively analyze error types and their effect in chat-oriented dialogue systems.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rafael E Banchs</author>
<author>Haizhou Li</author>
</authors>
<title>IRIS: a chatoriented dialogue system based on the vector space model.</title>
<date>2012</date>
<booktitle>In Proc. the ACL 2012 System Demonstrations,</booktitle>
<pages>37--42</pages>
<contexts>
<context position="1156" citStr="Banchs and Li, 2012" startWordPosition="165" endWordPosition="168">hem with dialogue breakdown labels, and collected comments describing the error that led to the breakdown. By mining the comments, we first identified error types. Then, we calculated the correlation between an error type and the degree of dialogue breakdown it incurred, quantifying its impact on dialogue breakdown. This is the first study to quantitatively analyze error types and their effect in chat-oriented dialogue systems. 1 Introduction Chat-oriented or open-domain dialogue systems have recently been attracting attention from social and entertainment aspects (Bickmore and Cassell, 2001; Banchs and Li, 2012; Wilcock and Jokinen, 2013). However, since they need to deal with open-domain utterances, which current natural language processing techniques are not mature enough to handle appropriately, the system inevitably makes errors. This discourages users from talking to the system, leading to dialogue breakdowns in conversation (Martinovsky and Traum, 2003). Here, dialogue breakdowns denote points in dialogue where users are unable to continue the conversation. This paper aims to find errors that lead to dialogue breakdowns in chat-oriented dialogue systems. Our approach is two-fold: (1) identify </context>
</contexts>
<marker>Banchs, Li, 2012</marker>
<rawString>Rafael E Banchs and Haizhou Li. 2012. IRIS: a chatoriented dialogue system based on the vector space model. In Proc. the ACL 2012 System Demonstrations, pages 37–42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niels Ole Bernsen</author>
<author>Hans Dybkjaer</author>
<author>Laila Dybkjaer</author>
</authors>
<title>Principles for the design of cooperative spoken human-machine dialogue.</title>
<date>1996</date>
<booktitle>In Proc. ICSLP,</booktitle>
<volume>2</volume>
<pages>729--732</pages>
<contexts>
<context position="15684" citStr="Bernsen et al., 1996" startWordPosition="2598" endWordPosition="2601">e consider the current values of correlation ratio to be acceptable. Here, the important finding is that several error types are comparatively more important than the others. 4 Related work Few studies have analyzed breakdowns in conversation. One exception is the study by Martinovsky and Traum (2003), who discussed possible causes of breakdowns they observed. Our work is different in that we systematically identify error types and quantitatively evaluate their effect. Our work can be seen as listing up errors in dialogue systems. A number of studies have aimed to create a taxonomy of errors (Bernsen et al., 1996; M¨oller, 2002; Paek, 2003), but their taxonomies are created manually and focus on task-oriented dialogue systems. 5 Summary and future work By processing dialogue data with dialogue breakdown annotations and comments, this paper identified 17 error types that can be further categorized into eight error categories. By calculating correlation ratios, we discovered three error types that can be fatal: “Not understandable”, “Ignore user question”, and “Unclear intention”. To avoid dialogue breakdowns, it is suggested that we need to make clear the meanings of system utterances, not ignore user </context>
</contexts>
<marker>Bernsen, Dybkjaer, Dybkjaer, 1996</marker>
<rawString>Niels Ole Bernsen, Hans Dybkjaer, and Laila Dybkjaer. 1996. Principles for the design of cooperative spoken human-machine dialogue. In Proc. ICSLP, volume 2, pages 729–732.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy W Bickmore</author>
<author>Justine Cassell</author>
</authors>
<title>Relational agents: a model and implementation of building user trust.</title>
<date>2001</date>
<booktitle>In Proc. CHI,</booktitle>
<pages>396--403</pages>
<contexts>
<context position="1135" citStr="Bickmore and Cassell, 2001" startWordPosition="160" endWordPosition="164">t dialogue data, annotated them with dialogue breakdown labels, and collected comments describing the error that led to the breakdown. By mining the comments, we first identified error types. Then, we calculated the correlation between an error type and the degree of dialogue breakdown it incurred, quantifying its impact on dialogue breakdown. This is the first study to quantitatively analyze error types and their effect in chat-oriented dialogue systems. 1 Introduction Chat-oriented or open-domain dialogue systems have recently been attracting attention from social and entertainment aspects (Bickmore and Cassell, 2001; Banchs and Li, 2012; Wilcock and Jokinen, 2013). However, since they need to deal with open-domain utterances, which current natural language processing techniques are not mature enough to handle appropriately, the system inevitably makes errors. This discourages users from talking to the system, leading to dialogue breakdowns in conversation (Martinovsky and Traum, 2003). Here, dialogue breakdowns denote points in dialogue where users are unable to continue the conversation. This paper aims to find errors that lead to dialogue breakdowns in chat-oriented dialogue systems. Our approach is tw</context>
</contexts>
<marker>Bickmore, Cassell, 2001</marker>
<rawString>Timothy W. Bickmore and Justine Cassell. 2001. Relational agents: a model and implementation of building user trust. In Proc. CHI, pages 396–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Noboru Miyazaki</author>
<author>Mikio Nakano</author>
<author>Kiyoaki Aikawa</author>
</authors>
<title>Evaluating discourse understanding in spoken dialogue systems.</title>
<date>2004</date>
<journal>ACM Transactions on Speech and Language Processing (TSLP),</journal>
<pages>1--1</pages>
<contexts>
<context position="14955" citStr="Higashinaka et al., 2004" startWordPosition="2479" endWordPosition="2483">ch in conversation” are both under error category E7 but have totally different effects on perceived breakdown. The same can be said for error types in E2. 2:General quality (259) 16:Analysis failure (100) 7:Ignore user question (134) 5:Repetition (77) 8:Contradiction (107) 13:Word usage error (36) 3:Grammatical error (54) 14:Expression error (53) 4:Inappropriate answer (95) 6:Ignore user utterance (148) 1:Unclear intention (113) 9:Social error (4) 2246 Note that, although the values of correlation ratio seem rather low, the correlation often becomes low when it comes to subjective judgments (Higashinaka et al., 2004). Considering that we deal with chat-oriented dialogues, which are less restricted than task-oriented ones, we consider the current values of correlation ratio to be acceptable. Here, the important finding is that several error types are comparatively more important than the others. 4 Related work Few studies have analyzed breakdowns in conversation. One exception is the study by Martinovsky and Traum (2003), who discussed possible causes of breakdowns they observed. Our work is different in that we systematically identify error types and quantitatively evaluate their effect. Our work can be s</context>
</contexts>
<marker>Higashinaka, Miyazaki, Nakano, Aikawa, 2004</marker>
<rawString>Ryuichiro Higashinaka, Noboru Miyazaki, Mikio Nakano, and Kiyoaki Aikawa. 2004. Evaluating discourse understanding in spoken dialogue systems. ACM Transactions on Speech and Language Processing (TSLP), 1:1–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
</authors>
<title>Noriaki Kawamae, Kugatsu Sadamitsu, Yasuhiro Minami, Toyomi Meguro, Kohji Dohsaka, and Hirohito Inagaki.</title>
<date>2011</date>
<booktitle>In Proc. INTERSPEECH,</booktitle>
<pages>2081--2084</pages>
<marker>Higashinaka, 2011</marker>
<rawString>Ryuichiro Higashinaka, Noriaki Kawamae, Kugatsu Sadamitsu, Yasuhiro Minami, Toyomi Meguro, Kohji Dohsaka, and Hirohito Inagaki. 2011. Unsupervised clustering of utterances using non-parametric bayesian methods. In Proc. INTERSPEECH, pages 2081–2084.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryuichiro Higashinaka</author>
<author>Kenji Imamura</author>
<author>Toyomi Meguro</author>
<author>Chiaki Miyazaki</author>
<author>Nozomi Kobayashi</author>
<author>Hiroaki Sugiyama</author>
<author>Toru Hirano</author>
<author>Toshiro Makino</author>
<author>Yoshihiro Matsuo</author>
</authors>
<title>Towards an open-domain conversational system fully based on natural language processing.</title>
<date>2014</date>
<booktitle>In Proc. COLING,</booktitle>
<pages>928--939</pages>
<contexts>
<context position="2942" citStr="Higashinaka et al., 2014" startWordPosition="452" endWordPosition="455">incurs. This way, we can quantify the impact of an error type on dialogue breakdown. By our approach, we hope to distinguish fatal errors from non-fatal ones, providing useful guidelines for dialogue system developers to avoid breakdowns in chat-oriented dialogue systems. 2 Data Collection For data collection, we asked dialogue researchers and their collaborators in Japan to use our chatoriented dialogue system. The system is textbased and enables chatting in Japanese. It was built by wrapping a chat API provided by NTT DOCOMO (Onishi and Yoshimura, 2014). Since the API works on the basis of (Higashinaka et al., 2014), which uses a number of natural language processing techniques to understand and generate utterances, we expected to obtain a wide variety of dialogues, and hence, a variety of errors. A total of 116 users chatted with the system, resulting in 1,146 dialogues. Here, each dialogue was controlled to be 21 utterances long: one system prompt with ten utterances each from the user and system. Then, we randomly sampled 100 dialogues (called the init100 data set) for dialogue breakdown annotation. Twenty-four annotators subjectively labeled each system utterance in init100 with one of the following </context>
</contexts>
<marker>Higashinaka, Imamura, Meguro, Miyazaki, Kobayashi, Sugiyama, Hirano, Makino, Matsuo, 2014</marker>
<rawString>Ryuichiro Higashinaka, Kenji Imamura, Toyomi Meguro, Chiaki Miyazaki, Nozomi Kobayashi, Hiroaki Sugiyama, Toru Hirano, Toshiro Makino, and Yoshihiro Matsuo. 2014. Towards an open-domain conversational system fully based on natural language processing. In Proc. COLING, pages 928–939.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bilyana Martinovsky</author>
<author>David Traum</author>
</authors>
<title>The error is the clue: Breakdown in human-machine interaction.</title>
<date>2003</date>
<booktitle>In Proc. ISCA Workshop on Error Handling in Spoken Dialogue Systems,</booktitle>
<pages>11--16</pages>
<contexts>
<context position="1511" citStr="Martinovsky and Traum, 2003" startWordPosition="216" endWordPosition="219">uantitatively analyze error types and their effect in chat-oriented dialogue systems. 1 Introduction Chat-oriented or open-domain dialogue systems have recently been attracting attention from social and entertainment aspects (Bickmore and Cassell, 2001; Banchs and Li, 2012; Wilcock and Jokinen, 2013). However, since they need to deal with open-domain utterances, which current natural language processing techniques are not mature enough to handle appropriately, the system inevitably makes errors. This discourages users from talking to the system, leading to dialogue breakdowns in conversation (Martinovsky and Traum, 2003). Here, dialogue breakdowns denote points in dialogue where users are unable to continue the conversation. This paper aims to find errors that lead to dialogue breakdowns in chat-oriented dialogue systems. Our approach is two-fold: (1) identify error types in chat-oriented dialogue systems, and (2) calculate their impact on dialogue breakdown. For (1), we first collect chat dialogues between an automated system and users, annotate the dialogues with dialogue breakdown labels, and collect comments that describe the error that led to the breakdowns. After that, we apply automatic clustering meth</context>
<context position="15366" citStr="Martinovsky and Traum (2003)" startWordPosition="2544" endWordPosition="2547">1:Unclear intention (113) 9:Social error (4) 2246 Note that, although the values of correlation ratio seem rather low, the correlation often becomes low when it comes to subjective judgments (Higashinaka et al., 2004). Considering that we deal with chat-oriented dialogues, which are less restricted than task-oriented ones, we consider the current values of correlation ratio to be acceptable. Here, the important finding is that several error types are comparatively more important than the others. 4 Related work Few studies have analyzed breakdowns in conversation. One exception is the study by Martinovsky and Traum (2003), who discussed possible causes of breakdowns they observed. Our work is different in that we systematically identify error types and quantitatively evaluate their effect. Our work can be seen as listing up errors in dialogue systems. A number of studies have aimed to create a taxonomy of errors (Bernsen et al., 1996; M¨oller, 2002; Paek, 2003), but their taxonomies are created manually and focus on task-oriented dialogue systems. 5 Summary and future work By processing dialogue data with dialogue breakdown annotations and comments, this paper identified 17 error types that can be further cate</context>
</contexts>
<marker>Martinovsky, Traum, 2003</marker>
<rawString>Bilyana Martinovsky and David Traum. 2003. The error is the clue: Breakdown in human-machine interaction. In Proc. ISCA Workshop on Error Handling in Spoken Dialogue Systems, pages 11–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian M¨oller</author>
</authors>
<title>A new taxonomy for the quality of telephone services based on spoken dialogue systems.</title>
<date>2002</date>
<booktitle>In Proc. SIGDIAL,</booktitle>
<pages>142--153</pages>
<marker>M¨oller, 2002</marker>
<rawString>Sebastian M¨oller. 2002. A new taxonomy for the quality of telephone services based on spoken dialogue systems. In Proc. SIGDIAL, pages 142–153.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kanako Onishi</author>
<author>Takeshi Yoshimura</author>
</authors>
<title>Casual conversation technology achieving natural dialog with computers.</title>
<date>2014</date>
<journal>NTT DOCOMO Technical Jouranl,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="2878" citStr="Onishi and Yoshimura, 2014" startWordPosition="440" endWordPosition="443">ion between an error type and the degree of dialogue breakdown it incurs. This way, we can quantify the impact of an error type on dialogue breakdown. By our approach, we hope to distinguish fatal errors from non-fatal ones, providing useful guidelines for dialogue system developers to avoid breakdowns in chat-oriented dialogue systems. 2 Data Collection For data collection, we asked dialogue researchers and their collaborators in Japan to use our chatoriented dialogue system. The system is textbased and enables chatting in Japanese. It was built by wrapping a chat API provided by NTT DOCOMO (Onishi and Yoshimura, 2014). Since the API works on the basis of (Higashinaka et al., 2014), which uses a number of natural language processing techniques to understand and generate utterances, we expected to obtain a wide variety of dialogues, and hence, a variety of errors. A total of 116 users chatted with the system, resulting in 1,146 dialogues. Here, each dialogue was controlled to be 21 utterances long: one system prompt with ten utterances each from the user and system. Then, we randomly sampled 100 dialogues (called the init100 data set) for dialogue breakdown annotation. Twenty-four annotators subjectively lab</context>
</contexts>
<marker>Onishi, Yoshimura, 2014</marker>
<rawString>Kanako Onishi and Takeshi Yoshimura. 2014. Casual conversation technology achieving natural dialog with computers. NTT DOCOMO Technical Jouranl, 15(4):16–21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Paek</author>
</authors>
<title>Toward a taxonomy of communication errors.</title>
<date>2003</date>
<booktitle>In Proc. ISCA Workshop on Error Handling in Spoken Dialogue Systems,</booktitle>
<pages>53--58</pages>
<contexts>
<context position="15712" citStr="Paek, 2003" startWordPosition="2604" endWordPosition="2605">elation ratio to be acceptable. Here, the important finding is that several error types are comparatively more important than the others. 4 Related work Few studies have analyzed breakdowns in conversation. One exception is the study by Martinovsky and Traum (2003), who discussed possible causes of breakdowns they observed. Our work is different in that we systematically identify error types and quantitatively evaluate their effect. Our work can be seen as listing up errors in dialogue systems. A number of studies have aimed to create a taxonomy of errors (Bernsen et al., 1996; M¨oller, 2002; Paek, 2003), but their taxonomies are created manually and focus on task-oriented dialogue systems. 5 Summary and future work By processing dialogue data with dialogue breakdown annotations and comments, this paper identified 17 error types that can be further categorized into eight error categories. By calculating correlation ratios, we discovered three error types that can be fatal: “Not understandable”, “Ignore user question”, and “Unclear intention”. To avoid dialogue breakdowns, it is suggested that we need to make clear the meanings of system utterances, not ignore user questions, and show some int</context>
</contexts>
<marker>Paek, 2003</marker>
<rawString>Tim Paek. 2003. Toward a taxonomy of communication errors. In Proc. ISCA Workshop on Error Handling in Spoken Dialogue Systems, pages 53–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jim Pitman</author>
</authors>
<title>Exchangeable and partially exchangeable random partitions. Probability theory and related fields,</title>
<date>1995</date>
<pages>102--2</pages>
<contexts>
<context position="7332" citStr="Pitman, 1995" startWordPosition="1228" endWordPosition="1229">3.1 Automatic clustering of comments We first need to identify the error types in chatoriented dialogue systems. For this, we applied an automatic clustering method to the comments to obtain clusters of comments. Our idea is that, since each comment describes a particular error that led to a breakdown, a cluster of comments is likely to represent an error type. Since the number of clusters is difficult to know in advance, we turn to a non-parametric Bayesian method called the Chinese restaurant process (CRP) as a clustering method. CRP can infer the number of clusters automatically from data (Pitman, 1995). We applied CRP to the 1,511 comments given 2244 ID Size 2 0 6 7 1 8 16 4 5 3 14 11 12 13 10 15 9 259 194 148 134 113 107 100 95 77 54 53 39 38 36 35 25 4 Interpretation General quality Not understandable Ignore user utterance Ignore user question Unclear intention Contradiction Analysis failure Inappropriate answer Repetition Grammatical error Expression error Topic-change error Violation of common sense Word usage error Diversion Mismatch in conversation Social error Representative words in the cluster dialogue, well-formed, consideration, conversation understand, meaning, what ignore, user</context>
</contexts>
<marker>Pitman, 1995</marker>
<rawString>Jim Pitman. 1995. Exchangeable and partially exchangeable random partitions. Probability theory and related fields, 102(2):145–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graham Wilcock</author>
<author>Kristiina Jokinen</author>
</authors>
<title>Wikitalk human-robot interactions.</title>
<date>2013</date>
<booktitle>In Proc. ICMI,</booktitle>
<pages>73--74</pages>
<contexts>
<context position="1184" citStr="Wilcock and Jokinen, 2013" startWordPosition="169" endWordPosition="172">akdown labels, and collected comments describing the error that led to the breakdown. By mining the comments, we first identified error types. Then, we calculated the correlation between an error type and the degree of dialogue breakdown it incurred, quantifying its impact on dialogue breakdown. This is the first study to quantitatively analyze error types and their effect in chat-oriented dialogue systems. 1 Introduction Chat-oriented or open-domain dialogue systems have recently been attracting attention from social and entertainment aspects (Bickmore and Cassell, 2001; Banchs and Li, 2012; Wilcock and Jokinen, 2013). However, since they need to deal with open-domain utterances, which current natural language processing techniques are not mature enough to handle appropriately, the system inevitably makes errors. This discourages users from talking to the system, leading to dialogue breakdowns in conversation (Martinovsky and Traum, 2003). Here, dialogue breakdowns denote points in dialogue where users are unable to continue the conversation. This paper aims to find errors that lead to dialogue breakdowns in chat-oriented dialogue systems. Our approach is two-fold: (1) identify error types in chat-oriented</context>
</contexts>
<marker>Wilcock, Jokinen, 2013</marker>
<rawString>Graham Wilcock and Kristiina Jokinen. 2013. Wikitalk human-robot interactions. In Proc. ICMI, pages 73–74.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>