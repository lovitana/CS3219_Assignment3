<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001241">
<title confidence="0.844375">
Two-stage Method for Large-scale Acquisition of
Contradiction Pattern Pairs using Entailment
Julien Kloetzer* Stijn De Saegert Kentaro Torisawat Chikara Hashimoto§
</title>
<author confidence="0.971447">
Jong-Hoon Oh¶ Motoki Sanoll Kiyonori Ohtake**
</author>
<affiliation confidence="0.9955405">
Information Analysis Laboratory,
National Institute of Information and Communications Technology (NICT), Kyoto, Japan
</affiliation>
<email confidence="0.912246">
{* julien, tstijn, ttorisawa, § ch, ¶rovellia, Imsano, **kiyonori.ohtake}@nict.go.jp
</email>
<sectionHeader confidence="0.996876" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.993883235294118">
In this paper we propose a two-stage method
to acquire contradiction relations between
typed lexico-syntactic patterns such as Xdrug
PreVents Ydisease and Ydisease caused by
Xdrug. In the first stage, we train an SVM
classifier to detect contradiction pattern pairs
in a large web archive by exploiting the exci-
tation polarity (Hashimoto et al., 2012) of the
patterns. In the second stage, we enlarge the
first stage classifier’s training data with new
contradiction pairs obtained by combining the
output of the first stage’s classifier and that of
an entailment classifier. We acquired this way
750,000 typed Japanese contradiction pattern
pairs with an estimated precision of 80%. We
plan to release this resource to the NLP com-
munity.
</bodyText>
<sectionHeader confidence="0.999519" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999112666666667">
The ability to detect contradictory information in
text has many practical applications. Among those,
Murakami et al. (2009) pointed out that a contra-
diction recognition system can detect conflicts and
anomalies in large bodies of texts and flag them to
help users identify unreliable information. For ex-
ample, many Japanese web pages claim that agari-
cus prevents cancer, where agaricus is a species of
mushroom found in a variety of commercial prod-
ucts. Although this has been accepted by many
Japanese people, by Googling keywords ”agaricus”,
”promotes” and ”cancer”, we can find pages claim-
ing that ”agaricus promotes cancer”, some of which
point to a study authorized by the Japanese Min-
istry of Health, Labour and Welfare&apos; reporting that
</bodyText>
<footnote confidence="0.944585">
1 http://www.mhlw.go.jp/topics/bukyoku/iyaku/syoku-
</footnote>
<page confidence="0.524722">
anzen/qa/060213-1.html
</page>
<bodyText confidence="0.999791388888889">
a commercial product containing agaricus promoted
cancer. Obviously, the existence of these pages casts
serious doubt on the ability of agaricus to prevent
cancer and encourages readers to dig more about this
subject.
The above example suggests that recognizing
contradictory information can guide users to a true
fact. Likewise, we believe that contradiction recog-
nition is also useful when dealing with non-factual
information that occupy most of our daily lives. For
instance, there is a big controversy recently whether
Japan should join an economic partnership agree-
ment called the Trans Paci�c Partnership (TPP), and
quite serious but contradictory claims are plentiful in
the mass media and on the web, e.g., TPP will wipe
out Japan’s agricultural businesses and TPP will
strengthen Japan’s agricultural businesses. Neither
of these are facts; they are predictions that can only
be realized or disputed after the underlying decision-
making is done: joining or refusing the TPP.
Furthermore, after reading documents including
contradictory predictions, one should notice that
each of them is supported by a convincing the-
ory that has no obvious defect, e.g., “Exports of
Japan’s agricultural products will increase thanks to
the TPP” or “A large amount of low-price agricul-
tural products will be imported to Japan due to the
TPP”. Even if one of these predictions may just hap-
pen to be true because of unexpected reasons such as
minor fluctuations in the Japanese yen, we must sur-
vey such theories that support contradictory predic-
tions, conduct balanced decision-making, and pre-
pare counter measures for the expected problems af-
ter examining multiple viewpoints. Contradiction
recognition should be useful to select documents to
be surveyed.
</bodyText>
<page confidence="0.98832">
693
</page>
<note confidence="0.880194">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 693–703,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999746">
Figure 1: Method workflow
</figureCaption>
<bodyText confidence="0.999580397590362">
We have developed a method for recog-
nizing pairs of contradictory binary patterns
such as h“X promotes Y”, “X prevents Y”i and
h“X will wipe out Y”, “X will strengthen Y”i. To
solve the problem described above, we can easily
develop a system that can find contradictory text
fragments from the web like “agaricus promotes
cancer” and “agaricus prevents cancer” from the
discovered contradictory pattern pairs.
Our method is a two-stage procedure with three
supervised classifiers (Fig. 1). In the first stage,
we build a classifier BASE to recognize contradic-
tions between binary patterns, and a classifier ENT
to recognize entailment. In the second stage, we
combine the contradiction pairs recognized by BASE
and the entailment pairs recognized by ENT to ex-
pand BASE’s training data and train a new contra-
diction classifier, EXP. This expansion using en-
tailment is one key idea of this work: we acquired
750,000 contradiction pairs with 80% precision us-
ing the expanded training data, more than doubling
the 285,000 pairs acquired at the same precision
level without expansion. We also demonstrate that
this result is not trivial by showing that our method
outperforms an alternative one based on Integer Lin-
ear Programming inspired by the successful entail-
ment recognition method of Berant et al. (2011).
As another technical contribution of this work, we
exploit the recently proposed semantic polarity of
excitation (Hashimoto et al., 2012) to recognize con-
tradictions between binary patterns. Hashimoto et
al. (2012) previously showed that excitation polari-
ties are useful to recognize contradictions between
phrases that consist of a noun and a predicate, such
as “promote cancer” and “prevent cancer”. While
it is trivial to extend this framework to contradic-
tions between unary patterns such as “promote X”
and “prevent X” by replacing the common nouns
in each pair with a variable, the information rep-
resented in unary patterns is often vague, and it is
unlikely that a contradiction between unary patterns
directly leads to the discovery of unreliable infor-
mation to be flagged or to a meaningful survey of
complex problems. As exemplified by the agaricus
and TPP examples, contradictions between binary
patterns that include two variables such as “X pro-
motes Y” or “X will wipe out Y” are more useful
than those between unary patterns. We also show
that it is not trivial to recognize contradictions be-
tween binary patterns using contradictions between
unary patterns.
Most works dealing with contradiction recogni-
tion up till now (Harabagiu et al., 2006; Bobrow
et al., 2007; Kawahara et al., 2008; Kawahara et
al., 2010; Ohki et al., 2011) focus on recognizing
contradictions between full sentences or documents,
not text fragments that match our relatively short
patterns (survey in Section 5). We expect that the
contradictory pattern pairs we acquired can be used
as building blocks in such full-fledged contradiction
recognition for full sentences or documents, simi-
larly to antonym pairs in Harabagiu et al. (2006).
Also, we should emphasize that our method
focuses on the most challenging part of contra-
diction recognition according to the classification
of De Marneffe et al. (2008). Since we discard
patterns with negations, an evident source of contra-
dictions like h“X causes Y”, “X does not cause Y”i,
most of our output are non-trivial contradic-
tions related to high-level semantic phenomena,
e.g., contradiction pairs related to antonyms
like h“X が Y を上げる”, “X が Y を下げる”i
(h“X increases Y”, “X decreases Y”i), lexical contra-
dictions like h“X が Y に勝つ”, “Y が X に勝つ”i
(h“X wins against Y”, “Y wins against X”i), or
contradictions due to common-sense knowledge
like h“X が Y を安心させる”, “X が Y を裏切る”i
(h“X reassures Y”, “X betrays Y”i). We believe
acquiring such contradictions in a large scale is a
valuable contribution.
The following is the outline of this paper. Sec-
tion 2 details our target and our proposed method.
Evaluation results are discussed in Section 3. Sec-
</bodyText>
<page confidence="0.99885">
694
</page>
<figureCaption confidence="0.999514">
Figure 2: Detailed data flow
</figureCaption>
<bodyText confidence="0.951883">
tion 4 details our features set, and Section 5 related
work. Section 6 provides a conclusion.
</bodyText>
<sectionHeader confidence="0.990715" genericHeader="introduction">
2 Proposed method
</sectionHeader>
<bodyText confidence="0.999939256410256">
As showed in Figure 1, our method consists of
three supervised classifiers. Classifiers BASE and
EXP recognize contradiction relations between bi-
nary patterns, and ENT recognizes entailment rela-
tions between binary patterns. The contradiction
pairs recognized by BASE and the entailment pairs
recognized by ENT are combined to generate new
contradiction pairs, part of which are then added to
BASE training data to train the EXP classifier. Our
final output is the set of all binary pattern pairs re-
garded as contradictions by EXP. Since the depen-
dencies between these three classifiers, their distinct
sets of training data, and the two data sets to be clas-
sified (we describe those in the two sections below)
is a bit complex, we show a complete description of
the whole process in Figure 2.
The key idea is in the scheme that expands the
training data. Logically speaking, patterns p and r
are contradictory if there exists a pattern q such that
p entails q and q contradicts r. For example, since
“X causes Y” entails “X promotes Y” and “X pro-
motes Y” contradicts “X prevents Y”, then “X causes
Y” contradicts “X prevents Y”. Hence, by combin-
ing entailment and contradiction pairs, we can ob-
tain more contradiction pairs.
Following this property of contradiction relations,
we collect a set of pattern pairs {(p, r)} for which
there exists a pattern q such that ENT recognizes that
p entails q and BASE recognizes that q contradicts r.
Then we rank these pairs based on a novel scoring
function called Contradiction Derivation Precision
(CDP) and expand BASE training data by adding to
it the top-ranked pairs according to CDP in order to
train EXP. This ranking scheme selects highly accu-
rate contradiction pairs and prevents errors caused
by BASE and ENT from being propagated to EXP.
In the following, after defining the patterns for
which we acquire contradiction relations, we de-
scribe BASE, EXP, ENT, and our expansion scheme.
</bodyText>
<subsectionHeader confidence="0.983793">
2.1 Patterns
</subsectionHeader>
<bodyText confidence="0.999979235294118">
In this work, a binary pattern is a word sequence
on the path of dependency relations connecting two
nouns in a syntactic dependency tree, like “X causes
Y”, and we say a noun pair co-occurs with a pattern
if the two nouns are connected by this pattern in the
dependency tree of a sentence in the corpus.
We focus on typed binary patterns, which place
semantic class restrictions on the noun pairs they
co-occur with, e.g., “Yorganization is in Xlo�ation”.
Subscripts organization and location indicate the se-
mantic classes of the X and Y slots. Since typed
patterns can distinguish between multiple senses
of ambiguous patterns, they greatly reduce errors
due to pattern ambiguity (De Saeger et al., 2009;
Schoenmackers et al., 2010; Berant et al., 2011).
We automatically induced semantic classes from our
corpus using the EM-based noun clustering algo-
</bodyText>
<page confidence="0.998482">
695
</page>
<bodyText confidence="0.999881722222222">
rithm presented in Kazama and Torisawa (2008),
and clustered one million nouns into 500 rela-
tively clean semantic classes, including for example
classes of diseases and of chemical substances.
The binary patterns and their co-occurring noun
pairs were extracted from our corpus of 600 mil-
lion Japanese web pages dependency parsed with
KNP (Kurohashi and Nagao, 1994). We restricted
our patterns to the most frequent 3.9 million pat-
terns of the form “X-[case particle] Y-[case parti-
cle] predicate” such as “X-ga Y-ni aru” (“X is in Y”)
which do not contain any negation, number, symbol
or punctuation character. Based on our observation
that patterns in meaningful contradiction and entail-
ment pairs tend to share many co-occurring noun
pairs, we used as input to our classifiers the set Pall
of 792 million pattern pairs for which both patterns
share three co-occurring noun pairs.
</bodyText>
<subsectionHeader confidence="0.87179">
2.2 BASE: First stage Classifier for
Contradiction
</subsectionHeader>
<bodyText confidence="0.999803675675676">
Below, we detail BASE: its training data and input
data to be classified, and some experimental results.
Our first stage classifier for contradictions, BASE,
is an SVM that uses commonsensical surface and
lexical resources based features, such as n-grams ex-
tracted from patterns, which will be detailed in Sec-
tion 4. An important point to be stressed here is
that we restricted the pattern pairs to be classified
by BASE by exploiting their excitation polarity, a
semantic orientation proposed by Hashimoto et al.
(2012). Excitation characterizes unary patterns as
excitatory, inhibitory, or neutral. Excitatory unary
patterns, such as “cause X” or “increase X”, entail
that the function, effect, purpose, or role of their ar-
gument’s referent is activated or enhanced, and in-
hibitory unary patterns, such as “prevent X” or “X
disappears”, entail that the function, effect, purpose,
or role of their argument’s referent is deactivated or
suppressed. Neutral unary patterns like “close to X”
are neither excitatory nor inhibitory.
We exploited excitation to restrict the input of
BASE. Based on the result of Hashimoto et al.
(2012) showing that two unary patterns with op-
posite polarity have a higher chance to be a con-
tradiction, we extracted from set Pall the set Popp
of binary pattern pairs that contain unary patterns
with opposite excitation polarities as sub-patterns.
(“Y cause X”, “Y prevent X”) is an example of such
a pair since the unary sub-patterns “cause X” and
“prevent X” are respectively excitatory and in-
hibitory. We used here 6,470 excitation unary pat-
terns hand-labeled as either excitatory (4,882 pat-
terns) or inhibitory (1,588 patterns). Set Popp con-
tains 8 million pattern pairs with roughly 38% true
contradiction pairs, and is the input to BASE. We
will show in experiments at the end of this section
that this restriction is necessary to obtain good per-
formance for BASE. We also tried to add the excita-
tion polarities in BASE’s feature set and classify Pall,
but the performance was worse.
Training Data Another key feature of BASE is
that it is distantly supervised. We did not use
training samples that are directly manually anno-
tated. Instead we automatically generated training
data from a smaller set of (non-)contradiction unary
pattern pairs. We first prepared a set of roughly
800 unary pattern pairs hand-labeled by three human
annotators as contradictions (238 pairs) and non-
contradictions (558 pairs) using majority vote. The
inter-annotator agreement was 0.78 (Fleiss’kappa).
Inspired by Hashimoto et al. (2012), we selected
these unary pattern pairs among pairs with high dis-
tributional similarity, with and without restricting
them to having opposite excitation polarity, such as
to get a fair distribution of contradictions and non-
contradictions.
We then extracted from set Pall all 256,000 pat-
tern pairs containing a contradictory unary pattern
pair, and all 5.2 million pattern pairs containing a
non-contradictory unary pattern pair, which we re-
spectively used as positive and negative training data
(estimated 79% and 73% accuracy from 200 hand-
labeled samples). Table 1 shows some examples.
The optimal composition of training data for
BASE was determined according to preliminary ex-
periments using our development set (1,000 manu-
ally labelled samples. See Section 3.1). We trained
20 different classifiers using from 6,250 to 50,000
positive samples (4 sets) and from 12,500 to 200,000
negative samples (5 sets), doubling the amounts in
each step, for a total of 20 configurations. We could
not try a larger training data due to long training time
but we do not expect it to be a problem because the
worst performance was observed with large train-
</bodyText>
<page confidence="0.99932">
696
</page>
<tableCaption confidence="0.99985">
Table 1: Examples of training samples for BASE obtained from unary pattern pairs
</tableCaption>
<table confidence="0.992411">
Binary pattern pair (the unary pattern pair that extracted it is underlined) Unary pattern pair label
Y も X が悪い (Xis bad in Y too) - Y でも X が良い (Xis good even in Y) contradiction
contradiction
Y も X に向かう (Y too heads toward X) - Y も X を出る (Y too comes out of X)
X にY を 加える (add Y to X) - X をY に 入れる (insert X into Y) non-contradiction
non-contradiction
Y も X に来る (Y too comes to X) - Y とは X に行く (go to X with Y)
</table>
<figureCaption confidence="0.998251">
Figure 3: Effect of the restriction using excitation
</figureCaption>
<bodyText confidence="0.999175777777778">
ing data (25,000 positives and 200,000 negatives;
the difference from the optimal setting was 2.3% in
average precision). The optimal training data set,
Trainbase, consists of 12,500 positives and 100,000
negatives samples as described above and is the one
we use in our experiments below and in Section 3.
Since BASE input for classification data is Popp
we also tried sampling Trainbase from Popp. We
obtained 56.27% average precision for our classi-
fier BASE, and 52.99% when restricting the source
of training data to pairs in Popp. We believe that the
difference lies in the size of the sets from which we
sampled our training data: while there are 5.46 mil-
lion binary pattern pairs in Pall with a hand-labeled
unary pattern pair in Pall, there are only 237,000
pairs in Popp. We believe this much smaller sam-
ple source lead to a lower performance because it
included much less variations of the patterns.
To train BASE and other classifiers mentioned in
this paper, we used the SVM tool TinySVM2 with
a polynomial kernel of degree 2, the setting which
showed the best performance during our preliminary
experiments.
Effect of Excitation Polarities We also empiri-
cally examined the effect of the restriction on the
patterns using excitation polarities. We used our test
set (2,000 manually annotated samples described in
</bodyText>
<footnote confidence="0.65859">
2 http://chasen.org/˜taku/software/TinySVM/
</footnote>
<bodyText confidence="0.999850307692308">
Section 3.1) and 250 manually annotated samples
(majority vote from 3 annotators) from top ranked
pairs of Pall to draw precision curves for BASE over
the top 2 million binary pairs from both Popp and
Pall. In each case we assumed that pairs were dis-
tributed uniformly (i.e., with a constant interval) in
the ranked list of pairs of Popp and Pall, and com-
puted precision accordingly. Since the pairs sets
are reasonably large and were sampled randomly we
thought this was a reasonable hypothesis. The pre-
cision over Popp is higher than that over Pall with
a large margin, suggesting that the restriction using
excitation polarities is beneficial.
</bodyText>
<subsectionHeader confidence="0.899819">
2.3 ENT: First stage Classifier for Entailment
</subsectionHeader>
<bodyText confidence="0.999980133333333">
ENT is an SVM classifier for entailment trained us-
ing 27,500 hand-annotated binary pattern pairs (set
Trainent, 45% of positive entailment pairs) created
for some previous work (Kloetzer et al., 2013). It es-
sentially uses the same feature set as that for BASE
with the addition of several distributional similar-
ity measures (see Section 4 below for more details).
This classifier is given all pairs of Pall as input and
scores each of them. For this study, we considered
the 44.5 million pattern pairs with a positive SVM
score as entailment pairs. Manual annotation of 200
random samples revealed that the precision of these
pairs was 63% and that the top 7.1 million pairs had
80% precision (result interpolated from the top 16%
of the annotated samples).
</bodyText>
<subsectionHeader confidence="0.918542">
2.4 Second stage: Training Data Expansion
and Classifier EXP
</subsectionHeader>
<bodyText confidence="0.99974025">
Below, we show how we combine BASE’s top output
(hereafter C) and ENT’s top output (hereafter E) in
the second stage of our method to expand Trainbase
and train a new classifier, EXP.
The training data expansion process is based on
the following logical constraint: if a pattern p entails
a pattern q and pattern q contradicts a third pattern r,
then p must contradict r. For example, because “X
</bodyText>
<page confidence="0.997916">
697
</page>
<tableCaption confidence="0.99786">
Table 2: Examples of triplets (p, q,r) where p entails q, q contradicts r, and hence p contradicts r
</tableCaption>
<table confidence="0.946847222222222">
Pattern p Pattern q Pattern r X/Y examples SVM Score(p, r) CDP(p, r)
Y b�G X b,ffiz.7a Y b�G X b, Y b, X Ic &apos;,7a 9D/R 0.3 0.98
X disappears from Y X vanishes from Y Y is full of X anger/eye
Y Ic X ;Le*ILI_7a Y Ic X ;Le�t_z.7a Y b�G X ;Lemdbj7a 4,q/1M -0.3 0.61
stop X in Y finish X in Y start X in Y April/activity
X U: Y ;LeTI_ X b, Y ;Len­� X U: Y ;Le�O 1-11/n 0.07 0.45
X shows Y X have Y X loses Y team/confidence
Algorithm 1 Training data expansion: C is the top 5%
output of BASE, E is the top output of ENT (score &gt; 0)
</table>
<listItem confidence="0.970726444444444">
1: procedure EXPAND(C, E)
2: Compute the set of expanded pairs C&apos; _ {(p, r) �
EIq : (p, q)E E,(q, r)E C}.
3: Rank the pairs in C&apos; using CDP.
4: Add the N top-ranked pairs in C&apos; \ C as new positive
samples to Trainba3,.
5: Remove incoherent negative training samples using
negative cleaning.
6: end procedure
</listItem>
<bodyText confidence="0.995645785714286">
causes Y” (pattern p) entails “X promotes Y” (pattern
q) and the latter contradicts “X prevents Y” (pattern
r), we conclude that “X causes Y” (p) contradicts
“X prevents Y” (r). We call the former contradic-
tion (q, r) a source contradiction pair, and the later
pair (p, r) an expanded contradiction pair. Based on
this idea, we combine C and E to aggressively ex-
pand Trainbase. This process is described in Al-
gorithm 1, and Table 2 shows examples of triples
(p, q,r) obtained in our experiments.
Expanding pairs from C and E compounds the er-
rors made by BASE and ENT, hence it is crucial to
select a highly precise subset of the expanded pairs.
Taking the top pairs according to their SVM score
would achieve this, but since BASE already handles
correctly such pairs, they should not help much as
new training data. We therefore propose a new scor-
ing function for selecting highly precise expanded
pairs: Contradiction Derivation Precision (CDP).
CDP was designed according to the following
assumption: a source contradiction pair that derives
correct expanded pairs with a high precision should
be reliable. Probably, all the expanded pairs derived
from such a reliable source pair will be correct and
should be included in the new training data.
In our formulation of CDP, correctness of an ex-
panded pair is judged according to the pair’s SVM
score using BASE. In other words, we regard an
expanded pair that has an SVM score above some
threshold a as a true contradiction. A source contra-
diction pair that derives true contradiction pairs with
a high precision is regarded as a reliable source con-
tradiction pair. CDP, which is defined over a ex-
panded pairs, is the maximum precision among that
of the source contradiction pairs that derive a given
expanded pair.
We first define CDPsub(q, r) over a source con-
tradiction pair (q, r) as the ratio of expanded pairs
obtained from (q, r) whose SVM score is above
threshold a. This ratio corresponds to the precision
of the expanded pairs derived from the source con-
tradiction pair (q, r).
</bodyText>
<equation confidence="0.9791995">
CDPsub(q, r) = I{(p, r) E Ex(q, r) I Sc(p, r) &gt; all
lEx(q, r)
</equation>
<bodyText confidence="0.971415238095238">
Here Ex(q, r) is the set of expanded pairs derived
from a source pair (q, r), and Sc is the SVM score
given by BASE. In our experiments, we set a = 0.46
such that pattern pairs for which BASE gives a score
over a corresponds to the top 5% of BASE’s output.
CDP(p, r) over an expanded pair is defined as fol-
lows, where Source(p, r) is the set of source con-
tradiction pairs that were derived into the expanded
pair (p, r).
CDP(p, r) = max(q,r)ESIIrII(p,r)CDPsub(q, r)
We then expand the top 5% contradictions of
BASE’s output (set C) and pattern pairs scored pos-
itively by ENT (set E), rank all expanded pairs not
already in C according to CDP, and add the top N
pairs with the highest CDP values as positives to
Trainbase to train EXP. The value of N shall be
determined empirically in later experiments using
a development set. Note that, since CDP(p, r) is
independent of (p, r)’s SVM score, even pairs that
were assigned a negative score by BASE can become
highly ranked by CDP (second triplet in Table 2)
</bodyText>
<page confidence="0.997535">
698
</page>
<bodyText confidence="0.9999695">
and be added to train EXP, hence we expect EXP to
learn something new from these pairs.
Finally, after the addition of expanded pairs, we
remove incoherent training samples. We propose to
remove from the negative training samples of EXP
any pattern pair that may conflict with the newly
added positives; we call this step negative cleaning.
Intuitively, since the content word pairs in a pattern
pair should present some of the strongest evidence
for determining the patterns (non-)contradiction sta-
tus, we remove any negative sample that shares a
content word pair with one of the added expanded
pairs. The final training data for EXP, set Trainee,,
consists of the following: (1) positive samples from
Trainbase, (2) (positive) expanded pairs, and (3)
negative training samples from Trainbase, cleaned
using negative cleaning. We confirmed in our exper-
iments that negative cleaning was necessary to train
a strong EXP classifier (details omitted for reason of
space).
After training EXP with Trainee„ we classify
Popp with EXP to produce the final output of the
whole method. Note that while this expansion pro-
cess can be re-iterated with EXP’s output, our exper-
iments failed to show any improvement with subse-
quent iterations.
</bodyText>
<sectionHeader confidence="0.999299" genericHeader="background">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.9904352">
This section presents our experimental results. We
describe first how we constructed test and develop-
ment data, and then report comparison results be-
tween our method and others including BASE and an
Integer Linear Programming-based (ILP) method.
</bodyText>
<subsectionHeader confidence="0.998005">
3.1 Development and Test Data
</subsectionHeader>
<bodyText confidence="0.99998075">
We asked three human annotators to label 3,000 bi-
nary pattern pairs randomly sampled from Popp as
contradiction or non-contradiction to be used as de-
velopment (1,000 pairs) and test (2,000 pairs) sets.
We considered a pattern pair as a true contradic-
tion relation if at least two out of the three annota-
tors marked it as positive. The inter-rater agreement
score (Fleiss Kappa) was 0.523, indicating moderate
agreement (Landis and Koch, 1977). As a definition
of contradiction, we used the notion of incompati-
bility (i.e., two statements are extremely unlikely to
be simultaneously true) proposed by De Marneffe et
</bodyText>
<figureCaption confidence="0.999698">
Figure 4: Precision of all the compared methods
</figureCaption>
<bodyText confidence="0.962683769230769">
al. (2008). We then say binary patterns such as “X
causes Y” and “X prevents Y” are contradictory if
the above definition holds for any noun pair that can
instantiate the patterns’ variables in the provided se-
mantic class pair.
Because our semantic classes are obtained by au-
tomatic clustering and have no meaningful labels,
we followed Szpektor et al. (2007) and provided the
annotators with three random noun pairs that co-
occur with the patterns as a proxy for the class pair.
The annotators marked a given pattern pair as posi-
tive if the contradiction relation between the patterns
held for all three noun pairs presented.
</bodyText>
<subsectionHeader confidence="0.997652">
3.2 Experimental Results
</subsectionHeader>
<bodyText confidence="0.986534583333333">
Here we show how our proposed method outper-
forms baseline methods. We compare the following
four methods:
• PROPOSED: our proposed method. N, the
number of newly added positive training sam-
ples during the training data expansion pro-
cess, was set to 6,000 according to preliminary
experiments using the development set. We
tried 50 different values of N from 1,000 up to
50,000, adding 1,000 each time, and chose the
N value giving the highest average precision
against our development set (1,000 samples).
</bodyText>
<listItem confidence="0.976547428571429">
• BASE: our first stage classifier.
• PROP-SCORE: same as PROPOSED except for
the use of BASE’s SVM score instead of CDP.
N was set to 30,000 in the same way we set N
for PROPOSED.
• HAS: an adaptation of the contradiction ex-
traction method presented in Hashimoto et al.
</listItem>
<page confidence="0.99848">
699
</page>
<bodyText confidence="0.999452583333333">
(2012). For a binary pattern pair we first
extracted its unary pattern pair with opposite
polarity (or one at random in case there are
two) and scored it based on our implementa-
tion of Hashimoto et al. (2012); the score is
based on the distributional similarity between
unary patterns and an excitation score obtained
using a minimally supervised method based on
the spin model. We then scored the binary pat-
tern pair by the score of this unary pattern pair.
We ranked the pattern pairs of our test set (2,000
random pairs from set Popp) based on the score pro-
duced by each method. For each tested method we
assumed that pairs in the test set were distributed
uniformly like explained in Section 2.2. The pre-
cision curves we obtained are shown in Figure 4.
PROPOSED clearly outperformed BASE and ac-
quired around 750,000 contradiction pattern pairs
with an estimated precision of 80%, out of which
some examples are shown in Table 3. These pairs
cover 26,941 content word pairs and reduce to
272,164 untyped pairs, showing that PROPOSED
does not just acquire a handful of contradictions in
many different class pairs. Also, when matching
these pairs against an antonyms database (extracted
from the dictionary of the morphical analyzer JU-
MAN) we found that only 100,886 of these pattern
pairs contain an antonym pair, which means that
most of the extracted pairs’ contradictions are due
to more complex phenomena than simple antonymy.
With the same precision, BASE and PROP-SCORE
acquired only 285,000 pairs (covering 11,794 con-
tent word pairs) and 636,000 pairs respectively. This
implies that our two-stage method can more than
double the number of highly precise contradiction
pairs we acquire as well as increasing their vari-
ety, and that ranking expanded pairs using our scor-
ing function CDP is better than with SVM score,
though even PROP-SCORE performs better than
BASE in our setting. Finally, the poor performance
of HAS suggests that extending the Hashimoto et
al.’s framework to recognition of binary patterns is
not a trivial task.
As to why adding only 6,000 top pairs ranked
by CDP performs better than adding 30,000 pairs
ranked by SVM score, the pattern pairs added in
PROP-SCORE had high SVM scores given by BASE
and as such are already handled nicely by BASE.
</bodyText>
<tableCaption confidence="0.77345">
Table 3: Examples of pairs acquired by PROPOSED: con-
tradiction (label +) and non-contradiction (label -)
</tableCaption>
<table confidence="0.999378464285715">
Lab. Pattern pairs (with rank) X/Y example
+ Y T X 7J#Ob,5 - Y ID X ;LeP3BMI,,5 JKPUIIq
X finished Y - X started from Y sale/yesterday
Rank 228,039
+ X b# Y ICE--) - Y b, X ICE-,) qV-`�&gt; tIA
X wins against Y - Y wins against X Japan/Vietnam
Rank: 258,068
- X N :Y ;Le9l-� - X ICN: Y N:Z,5 h/
X lose Y - Have Y in X people/interest
Rank 474,143
+ Y IC X ;Le くI, - Y IC16 X ;Leb� ��/��
Lose X in Y - Have X in Y too confidence/
Rank 522,534 oneself
- Y N: X VT4&amp;quot;,5 - X IC Y ;Le±if,5 9 &amp;L/1E&amp;L
Y falls down to X - raise Y to X 9th/ranking
Rank 538,901
+ X IC Y bIrFCI,,5 - X bYG Y ;Le1WC° rp/&apos;7_f11-71
Y exists in X - Keep Y out X inside/virus
Rank 620,430
- X bYG Y ;Le�I, - X N: Y Trrk,5 /H
Remove Y off X - X answer with Y I (or me)/eyes
Rank 652,530
+ Y ; LeX bYGAVIwiI, - X IC Y bla,5 4/911
Kick out Y from X - Y remains in X body/fatigue
Rank 697,177
+ Y b, X ;Le ibL FL4,5 - Y b, X bI;Le 4J,5 mak
X reassures Y - X betrays Y I/her
Rank: 749,916
</table>
<bodyText confidence="0.993027347826087">
Hence, we think the effect of adding a new sam-
ple from PROP-SCORE is smaller than that in PRO-
POSED, because in PROPOSED we add to the train-
ing data pattern pairs with both high and low (possi-
bly negative) SVM scores.
Finally, while the quality of the entailment pairs
plays a very important role in the assumption that
was the base of CDP, these results show that even
a simple rule such as “Use entailment pairs with
SVM score over 0 to expand contradictions before
ranking them with CDP” is sufficient to make the
method work. Though it may be possible to design
a more complex CDP formula which takes entail-
ment score into account, we did not explore this di-
rection in this work.
Comparison with an ILP-based method Finally,
we would like to compare our method with an ILP-
based method. The interaction between contradic-
tion and entailment that forms the basis for our ex-
pansion method has a natural interpretation as an op-
timization problem. We thus compared our method
to the following ILP formulation of this interaction
inspired by Berant et al. (2011), using our test set:
</bodyText>
<page confidence="0.994061">
700
</page>
<figureCaption confidence="0.992052">
Figure 5: Comparison between PROPOSED, BASE and
BASE+ILP on a restricted test set (1,306 samples)
</figureCaption>
<bodyText confidence="0.999975666666667">
and is worse than PROPOSED on all data points.
PROPOSED performs slightly worse in this setting
compared to when classifying the whole of Popp,
but this only means that its performance is good for
the 116 class pairs we ignored in this experiment.
While this comparison is only made in a restricted
setting, our expansion method still outperforms ILP
and is clearly more scalable. The ILP results could
be improved by adding more constraints (contradic-
tion is symmetric, entailment is transitive), but this
would also make the problem even more intractable
in terms of computational costs.
</bodyText>
<equation confidence="0.868901">
(1) G = argmax ∑ (e(p, q)−,Q)*Epq +(e(p, q)−,Q)*Cpq 4 Features
pi4q
</equation>
<listItem confidence="0.98474">
(2) s.t. ` p,q,r Epq + Cqr − Cpr &lt; 1
(3) ` p,q Epq + Cpq &lt; 1
(4) ` p,q Epq E {0, 11 (5) ` p,q Cpq E {0, 11
</listItem>
<bodyText confidence="0.999853612903226">
The objective in Equation (1) is a sum over the
weights of every pair of patterns (p, q), where Epq
indicates whether a pair (p, q) is an entailment pair
(Equation (4)), and Cpq indicates whether it is a con-
tradiction pair (Equation (5)). e(p, q) and c(p, q) are
the score given respectively by ENT and BASE, and
Q is a prior defining the weight of a pair as neither
entailment nor contradiction that shall be set before
any experimentation. Equation (2) states the tran-
sitivity relation which is the basis of our expansion
method. Finally, Equation (3) states that a given pat-
tern pair cannot be a contradiction pair and an entail-
ment pair at the same time. Since our patterns are
class-dependent, we solved separate ILP instances
for each semantic class pair.
We drew a precision curve for each of BASE,
PROPOSED and BASE+ILP. To draw the curve for
BASE+ILP, we incrementally raised the sample’s
non-contradiction non-entailment prior Q (more de-
tails in Berant et al. (2011)). Because of the com-
putational difficulty of ILP (NP-complete) and the
size of our data, the computation for the ILP-based
method ran out of memory on a 72GB machine for
116 class pairs out of the 1,031 that our test set cov-
ers. For this reason, we only used the 1,306 samples
of the test set covered by the remaining 915 class
pairs. We also measured the performance of BASE
and PROPOSED on the same restricted test set.
Figure 5 shows that under these conditions the
ILP-based method performance resembles BASE
In this section we present the features used in our
classifiers, which are mainly categorized into three:
surface features (i.e., those reflecting the patterns’
content itself), features based on external lexical re-
sources, and distributional similarity based features;
all features are listed in Table 4. ENT uses all the
features while BASE and EXP use all except for the
distributional similarity based ones. The optimality
of the feature sets was confirmed through ablation
tests using the development set (results omitted for
the sake of space).
Since patterns with a contradiction or entailment
relation are often superficially similar, for instance,
in case structure or inflection, we use a number of
surface features based on string similarity measures,
extending the feature sets used by Malakasiotis and
Androutsopoulos (2007) for entailment recognition.
They include bag-of-words features such as n-grams
and similarity scores concerning the bag-of-words
such as their Euclidian distance.
To complement the surface features with knowl-
edge about the content words, we used lexi-
cal databases including such as antonymy, syn-
onymy, entailment, or allography. The presence
of such word pairs is usually a good indicator of
(non-)contradiction or (non-)entailment at the pat-
tern level. More specifically, for any word pair
(wp, wq) taken from a pattern pair (p, q) we mark
the presence of (wp, wq) in each of the lexical re-
sources as a binary feature. We used the Japanese
lexical resources distributed by the ALAGIN Fo-
rum3: the verb entailment database (117,000 verb
</bodyText>
<footnote confidence="0.936579">
3 http://www.alagin.jp/
</footnote>
<page confidence="0.996222">
701
</page>
<tableCaption confidence="0.998449">
Table 4: Features summary, computed over a pair of patterns (p, q)
</tableCaption>
<bodyText confidence="0.888847428571429">
surface Similarity measures: common elements ratios, Dice coefficient, Jaccard and discounted Jaccard scores, Cosine, Euclidian, Manhattan, Levenshtein
and Jaro distances; computed over: the patterns’ 1-, 2- and 3-grams sets of: characters, morphemes, their stems &amp; POS; content words and stems
binary feature for each of the patterns’ subtrees, 1- and 2-grams ; patterns’ lengths and length ratios
lex.r. entries in databases of verb entailments and non-entailments, synonyms, antonyms, allographs ; checked over: pairs of content words,
pairs of content word stems, same for the reverse pattern pair (q, p)
dis.s. Distributional similarity measures: Common elements ratios, Jaccard and discounted Jaccard scores, sets and sets intersection cardinality,
DIRT (Lin and Pantel, 2001), Weeds (Weeds and Weir, 2003) and Hashimoto (Hashimoto et al., 2009) scores; computed over: patterns’
co-occurring noun pairs, POS tags of those, nouns co-occurring in each variable slot, nouns co-occurring with each unary sub-patterns
other binary feature for each semantic class pair and individual semantic classes
patterns frequency rank in the given semantic class pair
pairs; Alagin ID A-2), the databases of synonyms,
antonyms and meronyms (respectively 111,000,
5000 and 2500 pairs; Alagin ID A-9), and the al-
lographic word database (2.7 million pairs; Alagin
ID A-7). We also used the information concerning
allographic words in the dictionary of the morpho-
logical analyzer JUMAN4.
Distributional similarity values between patterns
are based on the idea that patterns that appear in
similar contexts tend to have similar meanings and
as such are useful to recognize entailment (Lin and
Pantel, 2001). We computed as features several dis-
tributional similarity measures on the sets of each
pattern’s co-occurring noun pairs and their POS
tags, of nouns co-occurring in each variable slot, and
with each of the pattern’s unary sub-patterns.
We also added a few more uncategorizable fea-
tures. See Table 4 for more details.
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="related work">
5 Related Work
</sectionHeader>
<bodyText confidence="0.9999569375">
A number of previous work dealt with the recogni-
tion of contradictions between sentences. Harabagiu
et al. (2006) proposed a contradiction detection
method that focuses on negation, antonymy and
some discourse information. Kawahara et al. (2010)
also used negations and antonyms to extract con-
trastive/contradictory statements from the web to
present users with a bird ’s-eye view of statements
about a given topic. Bobrow et al. (2007) showed
a method using logical forms with relatively precise
results. Ohki et al. (2011) proposed a method to rec-
ognize confinment, a novel semantic relation related
to both entailment and contradiction. While we do
not deal ourselves directly with sentences, we expect
that the binary pattern pairs we acquire can play a
role similar to that of basic linguistic resources such
</bodyText>
<footnote confidence="0.71656">
4 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN
</footnote>
<bodyText confidence="0.999954684210526">
as antonyms and negations in these works. Closer
to our work, Ritter et al. (2008) presented a method
for detecting contradictions between functional re-
lations like “X was born in Y”, but these constitute
only a part of the semantic relations expressed by the
binary patterns we deal with in this paper.
Other works analyzed contradictions from lin-
guistic/semantic viewpoints. Voorhees (2008) ana-
lyzed the contradiction recognition-task of the RTE3
contest. Magnini and Cabrio (2010) examined rela-
tions between contradictions and textual entailment
samples. De Marneffe et al. (2008) presented a
typology of contradictions, and showed that con-
tradictions can arise from a multitude of phenom-
ena. They showed contradictions based on lexical or
world knowledge are challenging and require a high-
level understanding of language and/or the world.
As stated in the introduction, these are the types of
contradictions our method focuses on.
</bodyText>
<sectionHeader confidence="0.999734" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999668">
This paper showed how to acquire a large number of
contradiction pairs between lexico-syntactic binary
patterns by exploiting (1) the interaction between
contradiction and entailment, and (2) excitation po-
larities. In the end, we could acquire 750,000 typed
contradiction pattern pairs with an estimated 80%
precision. The resulting contradiction pairs cov-
ered ones deeply related to world knowledge such
as the pair (“X reassures Y”, “X betrays Y”). We ex-
pect our work to lead to a high level analysis of
textual information, such as flagging unreliable in-
formation or identifying important documents to be
surveyed for understanding complex social prob-
lems. We plan to release the data we acquired to
the NLP community through the ALAGIN Forum5.
</bodyText>
<footnote confidence="0.903004">
5 http://www.alagin.jp/
</footnote>
<page confidence="0.996314">
702
</page>
<sectionHeader confidence="0.998325" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999912695652175">
J. Berant, I. Dagan, and J. Goldberger. 2011. Global
learning of typed entailment rules. In Proceedings of
ACL 2011, pages 610–619.
D. G. Bobrow, C. Condoravdi, R. Crouch, V. De Paiva,
L. Karttunen, T. H. King, R. Nairn, L. Price, and
A. Zaenen. 2007. Precision-focused textual inference.
In Proceedings of the ACL-PASCAL Workshop on Tex-
tual Entailment and Paraphrasing, page 16―21.
M.-C. De Marneffe, A. N. Rafferty, and C. D. Manning.
2008. Finding contradictions in text. Proceedings of
ACL 2008, page 1039―1047.
S. De Saeger, K. Torisawa, J. Kazama, K. Kuroda, and
M. Murata. 2009. Large scale relation acquisition us-
ing class dependent patterns. In Proceedings of ICDM
2009, page 764―769.
S.M. Harabagiu, A. Hickl, and V.F. Lacatusu. 2006.
Negation, contrast and contradiction in text process-
ing. In Proceedings of AAAI 2006, pages 755–762.
C. Hashimoto, K. Torisawa, K. Kuroda, S. De Saeger,
M. Murata, and J. Kazama. 2009. Large-scale verb
entailment acquisition from the web. In Proceedings
of EMNLP 2009, volume 3, page 1172―1181.
C. Hashimoto, K. Torisawa, S. De Saeger, J.-H. Oh, and
J. Kazama. 2012. Excitatory or inhibitory: A new se-
mantic orientation extracts contradiction and causality
from the web. In Proceedings of EMNLP 2012.
D. Kawahara, S. Kurohashi, and K. Inui. 2008. Grasp-
ing major statements and their contradictions toward
information credibility analysis of web contents. In
Proceedings of WI-IAT 2008, volume 1, page 393―
397.
D. Kawahara, K. Inui, and S. Kurohashi. 2010. Iden-
tifying contradictory and contrastive relations between
statements to outline web information on a given topic.
In Proceedings of COLING 2010, page 534―542.
J. Kazama and K. Torisawa. 2008. Inducing gazetteers
for named entity recognition by large-scale clustering
of dependency relations. Proceedings of ACL 2008,
page 407―415.
J. Kloetzer, S. De Saeger, K. Torisawa, M. Sano,
C. Hashimoto, and J. Gotoh. 2013. Large-scale acqui-
sition of entailment pattern pairs. In Information Pro-
cessing Society of Japan (IPSJ) Kansai-Branch Con-
vention.
S. Kurohashi and M. Nagao. 1994. KN parser: Japanese
dependency/case structure analyzer. In Proceedings
of the Workshop on Sharable Natural Language Re-
sources, page 48―55.
J. R. Landis and G. G. Koch. 1977. The measurement of
observer agreement for categorical data. Biometrics,
page 159―174.
D. Lin and P. Pantel. 2001. Dirt - discovery of inference
rules from text. In Proceedings of the ACM SIGKDD
Conference on Knowledge Discovery and Data Min-
ing, pages 323–328.
B. Magnini and E. Cabrio. 2010. Contradiction-focused
qualitative evaluation of textual entailment. In Pro-
ceedings of the Workshop on Negation and Speculation
in Natural Language Processing, page 86―94.
P. Malakasiotis and I. Androutsopoulos. 2007. Learning
textual entailment using SVMs and string similarity
measures. In Proceedings of the ACL- PASCAL Work-
shop on Textual Entailment and Paraphrasing, page 42
―47.
K. Murakami, E. Nichols, S. Matsuyoshi, A. Sumida,
S. Masuda, K. Inui, and Y. Matumoto. 2009. State-
ment map: assisting information crediblity analysis
by visualizing arguments. In Proceedings of the 3rd
workshop on Information credibility on the web, page
43―50. ACM.
M. Ohki, S. Matsuyoshi, J. Mizuno, K. Inui, E. Nichols,
K. Murakami, S. Masuda, and Y. Matsumoto. 2011.
Recognizing confinement in web texts. In the Pro-
ceedings of the Ninth International Conference on
Computational Semantics, page 215―224.
A. Ritter, D. Downey, S. Soderland, and O. Etzioni.
2008. It’s a contradiction—no, it’s not: a case study
using functional relations. In Proceedings of EMNLP
2008, pages 11–20.
S. Schoenmackers, O. Etzioni, D. S Weld, and J. Davis.
2010. Learning first-order horn clauses from web text.
In Proceedings of EMNLP 2010, page 1088―1098.
I. Szpektor, E. Shnarch, and I. Dagan. 2007. Instance-
based evaluation of entailment rule acquisition. In
Proceedings ofACL 2007, volume 45, page 456―463.
E. M. Voorhees. 2008. Contradictions and justifications:
Extensions to the textual entailment task. In Proceed-
ings of ACL 2008, page 63―71.
J. Weeds and D. Weir. 2003. A general framework for
distributional similarity. In Proceedings of EMNLP
2003, page 81―88. Association for Computational
Linguistics.
</reference>
<page confidence="0.998995">
703
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.554037">
<title confidence="0.990889">Two-stage Method for Large-scale Acquisition Contradiction Pattern Pairs using Entailment</title>
<author confidence="0.700098">De</author>
<affiliation confidence="0.97625">Information Analysis Laboratory, National Institute of Information and Communications Technology (NICT), Kyoto, Japan</affiliation>
<abstract confidence="0.989014222222222">In this paper we propose a two-stage method to acquire contradiction relations between lexico-syntactic patterns such as by In the first stage, we train an SVM classifier to detect contradiction pattern pairs a large web archive by exploiting the exci- (Hashimoto et al., 2012) of the patterns. In the second stage, we enlarge the first stage classifier’s training data with new contradiction pairs obtained by combining the output of the first stage’s classifier and that of We acquired this way 750,000 typed Japanese contradiction pattern pairs with an estimated precision of 80%. We plan to release this resource to the NLP community.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Berant</author>
<author>I Dagan</author>
<author>J Goldberger</author>
</authors>
<title>Global learning of typed entailment rules.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL 2011,</booktitle>
<pages>610--619</pages>
<contexts>
<context position="5274" citStr="Berant et al. (2011)" startWordPosition="798" endWordPosition="801">pairs recognized by BASE and the entailment pairs recognized by ENT to expand BASE’s training data and train a new contradiction classifier, EXP. This expansion using entailment is one key idea of this work: we acquired 750,000 contradiction pairs with 80% precision using the expanded training data, more than doubling the 285,000 pairs acquired at the same precision level without expansion. We also demonstrate that this result is not trivial by showing that our method outperforms an alternative one based on Integer Linear Programming inspired by the successful entailment recognition method of Berant et al. (2011). As another technical contribution of this work, we exploit the recently proposed semantic polarity of excitation (Hashimoto et al., 2012) to recognize contradictions between binary patterns. Hashimoto et al. (2012) previously showed that excitation polarities are useful to recognize contradictions between phrases that consist of a noun and a predicate, such as “promote cancer” and “prevent cancer”. While it is trivial to extend this framework to contradictions between unary patterns such as “promote X” and “prevent X” by replacing the common nouns in each pair with a variable, the informatio</context>
<context position="10807" citStr="Berant et al., 2011" startWordPosition="1714" endWordPosition="1717">ee, like “X causes Y”, and we say a noun pair co-occurs with a pattern if the two nouns are connected by this pattern in the dependency tree of a sentence in the corpus. We focus on typed binary patterns, which place semantic class restrictions on the noun pairs they co-occur with, e.g., “Yorganization is in Xlo�ation”. Subscripts organization and location indicate the semantic classes of the X and Y slots. Since typed patterns can distinguish between multiple senses of ambiguous patterns, they greatly reduce errors due to pattern ambiguity (De Saeger et al., 2009; Schoenmackers et al., 2010; Berant et al., 2011). We automatically induced semantic classes from our corpus using the EM-based noun clustering algo695 rithm presented in Kazama and Torisawa (2008), and clustered one million nouns into 500 relatively clean semantic classes, including for example classes of diseases and of chemical substances. The binary patterns and their co-occurring noun pairs were extracted from our corpus of 600 million Japanese web pages dependency parsed with KNP (Kurohashi and Nagao, 1994). We restricted our patterns to the most frequent 3.9 million patterns of the form “X-[case particle] Y-[case particle] predicate” </context>
<context position="31420" citStr="Berant et al. (2011)" startWordPosition="5289" endWordPosition="5292">expand contradictions before ranking them with CDP” is sufficient to make the method work. Though it may be possible to design a more complex CDP formula which takes entailment score into account, we did not explore this direction in this work. Comparison with an ILP-based method Finally, we would like to compare our method with an ILPbased method. The interaction between contradiction and entailment that forms the basis for our expansion method has a natural interpretation as an optimization problem. We thus compared our method to the following ILP formulation of this interaction inspired by Berant et al. (2011), using our test set: 700 Figure 5: Comparison between PROPOSED, BASE and BASE+ILP on a restricted test set (1,306 samples) and is worse than PROPOSED on all data points. PROPOSED performs slightly worse in this setting compared to when classifying the whole of Popp, but this only means that its performance is good for the 116 class pairs we ignored in this experiment. While this comparison is only made in a restricted setting, our expansion method still outperforms ILP and is clearly more scalable. The ILP results could be improved by adding more constraints (contradiction is symmetric, entai</context>
<context position="33285" citStr="Berant et al. (2011)" startWordPosition="5620" endWordPosition="5623">as neither entailment nor contradiction that shall be set before any experimentation. Equation (2) states the transitivity relation which is the basis of our expansion method. Finally, Equation (3) states that a given pattern pair cannot be a contradiction pair and an entailment pair at the same time. Since our patterns are class-dependent, we solved separate ILP instances for each semantic class pair. We drew a precision curve for each of BASE, PROPOSED and BASE+ILP. To draw the curve for BASE+ILP, we incrementally raised the sample’s non-contradiction non-entailment prior Q (more details in Berant et al. (2011)). Because of the computational difficulty of ILP (NP-complete) and the size of our data, the computation for the ILP-based method ran out of memory on a 72GB machine for 116 class pairs out of the 1,031 that our test set covers. For this reason, we only used the 1,306 samples of the test set covered by the remaining 915 class pairs. We also measured the performance of BASE and PROPOSED on the same restricted test set. Figure 5 shows that under these conditions the ILP-based method performance resembles BASE In this section we present the features used in our classifiers, which are mainly cate</context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2011</marker>
<rawString>J. Berant, I. Dagan, and J. Goldberger. 2011. Global learning of typed entailment rules. In Proceedings of ACL 2011, pages 610–619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D G Bobrow</author>
<author>C Condoravdi</author>
<author>R Crouch</author>
<author>V De Paiva</author>
<author>L Karttunen</author>
<author>T H King</author>
<author>R Nairn</author>
<author>L Price</author>
<author>A Zaenen</author>
</authors>
<title>Precision-focused textual inference.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>16--21</pages>
<marker>Bobrow, Condoravdi, Crouch, De Paiva, Karttunen, King, Nairn, Price, Zaenen, 2007</marker>
<rawString>D. G. Bobrow, C. Condoravdi, R. Crouch, V. De Paiva, L. Karttunen, T. H. King, R. Nairn, L. Price, and A. Zaenen. 2007. Precision-focused textual inference. In Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, page 16―21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-C De Marneffe</author>
<author>A N Rafferty</author>
<author>C D Manning</author>
</authors>
<title>Finding contradictions in text.</title>
<date>2008</date>
<booktitle>Proceedings of ACL 2008,</booktitle>
<pages>1039--1047</pages>
<marker>De Marneffe, Rafferty, Manning, 2008</marker>
<rawString>M.-C. De Marneffe, A. N. Rafferty, and C. D. Manning. 2008. Finding contradictions in text. Proceedings of ACL 2008, page 1039―1047.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S De Saeger</author>
<author>K Torisawa</author>
<author>J Kazama</author>
<author>K Kuroda</author>
<author>M Murata</author>
</authors>
<title>Large scale relation acquisition using class dependent patterns.</title>
<date>2009</date>
<booktitle>In Proceedings of ICDM 2009,</booktitle>
<pages>764--769</pages>
<marker>De Saeger, Torisawa, Kazama, Kuroda, Murata, 2009</marker>
<rawString>S. De Saeger, K. Torisawa, J. Kazama, K. Kuroda, and M. Murata. 2009. Large scale relation acquisition using class dependent patterns. In Proceedings of ICDM 2009, page 764―769.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Harabagiu</author>
<author>A Hickl</author>
<author>V F Lacatusu</author>
</authors>
<title>Negation, contrast and contradiction in text processing.</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI</booktitle>
<pages>755--762</pages>
<contexts>
<context position="6534" citStr="Harabagiu et al., 2006" startWordPosition="999" endWordPosition="1002">en vague, and it is unlikely that a contradiction between unary patterns directly leads to the discovery of unreliable information to be flagged or to a meaningful survey of complex problems. As exemplified by the agaricus and TPP examples, contradictions between binary patterns that include two variables such as “X promotes Y” or “X will wipe out Y” are more useful than those between unary patterns. We also show that it is not trivial to recognize contradictions between binary patterns using contradictions between unary patterns. Most works dealing with contradiction recognition up till now (Harabagiu et al., 2006; Bobrow et al., 2007; Kawahara et al., 2008; Kawahara et al., 2010; Ohki et al., 2011) focus on recognizing contradictions between full sentences or documents, not text fragments that match our relatively short patterns (survey in Section 5). We expect that the contradictory pattern pairs we acquired can be used as building blocks in such full-fledged contradiction recognition for full sentences or documents, similarly to antonym pairs in Harabagiu et al. (2006). Also, we should emphasize that our method focuses on the most challenging part of contradiction recognition according to the classi</context>
<context position="37607" citStr="Harabagiu et al. (2006)" startWordPosition="6292" endWordPosition="6295">atterns are based on the idea that patterns that appear in similar contexts tend to have similar meanings and as such are useful to recognize entailment (Lin and Pantel, 2001). We computed as features several distributional similarity measures on the sets of each pattern’s co-occurring noun pairs and their POS tags, of nouns co-occurring in each variable slot, and with each of the pattern’s unary sub-patterns. We also added a few more uncategorizable features. See Table 4 for more details. 5 Related Work A number of previous work dealt with the recognition of contradictions between sentences. Harabagiu et al. (2006) proposed a contradiction detection method that focuses on negation, antonymy and some discourse information. Kawahara et al. (2010) also used negations and antonyms to extract contrastive/contradictory statements from the web to present users with a bird ’s-eye view of statements about a given topic. Bobrow et al. (2007) showed a method using logical forms with relatively precise results. Ohki et al. (2011) proposed a method to recognize confinment, a novel semantic relation related to both entailment and contradiction. While we do not deal ourselves directly with sentences, we expect that th</context>
</contexts>
<marker>Harabagiu, Hickl, Lacatusu, 2006</marker>
<rawString>S.M. Harabagiu, A. Hickl, and V.F. Lacatusu. 2006. Negation, contrast and contradiction in text processing. In Proceedings of AAAI 2006, pages 755–762.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Hashimoto</author>
<author>K Torisawa</author>
<author>K Kuroda</author>
<author>S De Saeger</author>
<author>M Murata</author>
<author>J Kazama</author>
</authors>
<title>Large-scale verb entailment acquisition from the web.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP 2009,</booktitle>
<volume>3</volume>
<pages>1172--1181</pages>
<marker>Hashimoto, Torisawa, Kuroda, De Saeger, Murata, Kazama, 2009</marker>
<rawString>C. Hashimoto, K. Torisawa, K. Kuroda, S. De Saeger, M. Murata, and J. Kazama. 2009. Large-scale verb entailment acquisition from the web. In Proceedings of EMNLP 2009, volume 3, page 1172―1181.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Hashimoto</author>
<author>K Torisawa</author>
<author>S De Saeger</author>
<author>J-H Oh</author>
<author>J Kazama</author>
</authors>
<title>Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<marker>Hashimoto, Torisawa, De Saeger, Oh, Kazama, 2012</marker>
<rawString>C. Hashimoto, K. Torisawa, S. De Saeger, J.-H. Oh, and J. Kazama. 2012. Excitatory or inhibitory: A new semantic orientation extracts contradiction and causality from the web. In Proceedings of EMNLP 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kawahara</author>
<author>S Kurohashi</author>
<author>K Inui</author>
</authors>
<title>Grasping major statements and their contradictions toward information credibility analysis of web contents.</title>
<date>2008</date>
<booktitle>In Proceedings of WI-IAT 2008,</booktitle>
<volume>1</volume>
<pages>393--397</pages>
<contexts>
<context position="6578" citStr="Kawahara et al., 2008" startWordPosition="1007" endWordPosition="1010">tion between unary patterns directly leads to the discovery of unreliable information to be flagged or to a meaningful survey of complex problems. As exemplified by the agaricus and TPP examples, contradictions between binary patterns that include two variables such as “X promotes Y” or “X will wipe out Y” are more useful than those between unary patterns. We also show that it is not trivial to recognize contradictions between binary patterns using contradictions between unary patterns. Most works dealing with contradiction recognition up till now (Harabagiu et al., 2006; Bobrow et al., 2007; Kawahara et al., 2008; Kawahara et al., 2010; Ohki et al., 2011) focus on recognizing contradictions between full sentences or documents, not text fragments that match our relatively short patterns (survey in Section 5). We expect that the contradictory pattern pairs we acquired can be used as building blocks in such full-fledged contradiction recognition for full sentences or documents, similarly to antonym pairs in Harabagiu et al. (2006). Also, we should emphasize that our method focuses on the most challenging part of contradiction recognition according to the classification of De Marneffe et al. (2008). Since</context>
</contexts>
<marker>Kawahara, Kurohashi, Inui, 2008</marker>
<rawString>D. Kawahara, S. Kurohashi, and K. Inui. 2008. Grasping major statements and their contradictions toward information credibility analysis of web contents. In Proceedings of WI-IAT 2008, volume 1, page 393― 397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kawahara</author>
<author>K Inui</author>
<author>S Kurohashi</author>
</authors>
<title>Identifying contradictory and contrastive relations between statements to outline web information on a given topic.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING 2010,</booktitle>
<pages>534--542</pages>
<contexts>
<context position="6601" citStr="Kawahara et al., 2010" startWordPosition="1011" endWordPosition="1014">erns directly leads to the discovery of unreliable information to be flagged or to a meaningful survey of complex problems. As exemplified by the agaricus and TPP examples, contradictions between binary patterns that include two variables such as “X promotes Y” or “X will wipe out Y” are more useful than those between unary patterns. We also show that it is not trivial to recognize contradictions between binary patterns using contradictions between unary patterns. Most works dealing with contradiction recognition up till now (Harabagiu et al., 2006; Bobrow et al., 2007; Kawahara et al., 2008; Kawahara et al., 2010; Ohki et al., 2011) focus on recognizing contradictions between full sentences or documents, not text fragments that match our relatively short patterns (survey in Section 5). We expect that the contradictory pattern pairs we acquired can be used as building blocks in such full-fledged contradiction recognition for full sentences or documents, similarly to antonym pairs in Harabagiu et al. (2006). Also, we should emphasize that our method focuses on the most challenging part of contradiction recognition according to the classification of De Marneffe et al. (2008). Since we discard patterns wi</context>
<context position="37739" citStr="Kawahara et al. (2010)" startWordPosition="6310" endWordPosition="6313">ecognize entailment (Lin and Pantel, 2001). We computed as features several distributional similarity measures on the sets of each pattern’s co-occurring noun pairs and their POS tags, of nouns co-occurring in each variable slot, and with each of the pattern’s unary sub-patterns. We also added a few more uncategorizable features. See Table 4 for more details. 5 Related Work A number of previous work dealt with the recognition of contradictions between sentences. Harabagiu et al. (2006) proposed a contradiction detection method that focuses on negation, antonymy and some discourse information. Kawahara et al. (2010) also used negations and antonyms to extract contrastive/contradictory statements from the web to present users with a bird ’s-eye view of statements about a given topic. Bobrow et al. (2007) showed a method using logical forms with relatively precise results. Ohki et al. (2011) proposed a method to recognize confinment, a novel semantic relation related to both entailment and contradiction. While we do not deal ourselves directly with sentences, we expect that the binary pattern pairs we acquire can play a role similar to that of basic linguistic resources such 4 http://nlp.ist.i.kyoto-u.ac.j</context>
</contexts>
<marker>Kawahara, Inui, Kurohashi, 2010</marker>
<rawString>D. Kawahara, K. Inui, and S. Kurohashi. 2010. Identifying contradictory and contrastive relations between statements to outline web information on a given topic. In Proceedings of COLING 2010, page 534―542.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kazama</author>
<author>K Torisawa</author>
</authors>
<title>Inducing gazetteers for named entity recognition by large-scale clustering of dependency relations.</title>
<date>2008</date>
<booktitle>Proceedings of ACL 2008,</booktitle>
<pages>407--415</pages>
<contexts>
<context position="10955" citStr="Kazama and Torisawa (2008)" startWordPosition="1736" endWordPosition="1739">f a sentence in the corpus. We focus on typed binary patterns, which place semantic class restrictions on the noun pairs they co-occur with, e.g., “Yorganization is in Xlo�ation”. Subscripts organization and location indicate the semantic classes of the X and Y slots. Since typed patterns can distinguish between multiple senses of ambiguous patterns, they greatly reduce errors due to pattern ambiguity (De Saeger et al., 2009; Schoenmackers et al., 2010; Berant et al., 2011). We automatically induced semantic classes from our corpus using the EM-based noun clustering algo695 rithm presented in Kazama and Torisawa (2008), and clustered one million nouns into 500 relatively clean semantic classes, including for example classes of diseases and of chemical substances. The binary patterns and their co-occurring noun pairs were extracted from our corpus of 600 million Japanese web pages dependency parsed with KNP (Kurohashi and Nagao, 1994). We restricted our patterns to the most frequent 3.9 million patterns of the form “X-[case particle] Y-[case particle] predicate” such as “X-ga Y-ni aru” (“X is in Y”) which do not contain any negation, number, symbol or punctuation character. Based on our observation that patt</context>
</contexts>
<marker>Kazama, Torisawa, 2008</marker>
<rawString>J. Kazama and K. Torisawa. 2008. Inducing gazetteers for named entity recognition by large-scale clustering of dependency relations. Proceedings of ACL 2008, page 407―415.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Kloetzer</author>
<author>S De Saeger</author>
<author>K Torisawa</author>
<author>M Sano</author>
<author>C Hashimoto</author>
<author>J Gotoh</author>
</authors>
<title>Large-scale acquisition of entailment pattern pairs.</title>
<date>2013</date>
<booktitle>In Information Processing Society of Japan (IPSJ) Kansai-Branch Convention.</booktitle>
<marker>Kloetzer, De Saeger, Torisawa, Sano, Hashimoto, Gotoh, 2013</marker>
<rawString>J. Kloetzer, S. De Saeger, K. Torisawa, M. Sano, C. Hashimoto, and J. Gotoh. 2013. Large-scale acquisition of entailment pattern pairs. In Information Processing Society of Japan (IPSJ) Kansai-Branch Convention.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kurohashi</author>
<author>M Nagao</author>
</authors>
<title>KN parser: Japanese dependency/case structure analyzer.</title>
<date>1994</date>
<booktitle>In Proceedings of the Workshop on Sharable Natural Language Resources,</booktitle>
<pages>48--55</pages>
<contexts>
<context position="11276" citStr="Kurohashi and Nagao, 1994" startWordPosition="1786" endWordPosition="1789">e senses of ambiguous patterns, they greatly reduce errors due to pattern ambiguity (De Saeger et al., 2009; Schoenmackers et al., 2010; Berant et al., 2011). We automatically induced semantic classes from our corpus using the EM-based noun clustering algo695 rithm presented in Kazama and Torisawa (2008), and clustered one million nouns into 500 relatively clean semantic classes, including for example classes of diseases and of chemical substances. The binary patterns and their co-occurring noun pairs were extracted from our corpus of 600 million Japanese web pages dependency parsed with KNP (Kurohashi and Nagao, 1994). We restricted our patterns to the most frequent 3.9 million patterns of the form “X-[case particle] Y-[case particle] predicate” such as “X-ga Y-ni aru” (“X is in Y”) which do not contain any negation, number, symbol or punctuation character. Based on our observation that patterns in meaningful contradiction and entailment pairs tend to share many co-occurring noun pairs, we used as input to our classifiers the set Pall of 792 million pattern pairs for which both patterns share three co-occurring noun pairs. 2.2 BASE: First stage Classifier for Contradiction Below, we detail BASE: its traini</context>
</contexts>
<marker>Kurohashi, Nagao, 1994</marker>
<rawString>S. Kurohashi and M. Nagao. 1994. KN parser: Japanese dependency/case structure analyzer. In Proceedings of the Workshop on Sharable Natural Language Resources, page 48―55.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Landis</author>
<author>G G Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data. Biometrics,</title>
<date>1977</date>
<pages>159--174</pages>
<contexts>
<context position="25378" citStr="Landis and Koch, 1977" startWordPosition="4200" endWordPosition="4203">velopment data, and then report comparison results between our method and others including BASE and an Integer Linear Programming-based (ILP) method. 3.1 Development and Test Data We asked three human annotators to label 3,000 binary pattern pairs randomly sampled from Popp as contradiction or non-contradiction to be used as development (1,000 pairs) and test (2,000 pairs) sets. We considered a pattern pair as a true contradiction relation if at least two out of the three annotators marked it as positive. The inter-rater agreement score (Fleiss Kappa) was 0.523, indicating moderate agreement (Landis and Koch, 1977). As a definition of contradiction, we used the notion of incompatibility (i.e., two statements are extremely unlikely to be simultaneously true) proposed by De Marneffe et Figure 4: Precision of all the compared methods al. (2008). We then say binary patterns such as “X causes Y” and “X prevents Y” are contradictory if the above definition holds for any noun pair that can instantiate the patterns’ variables in the provided semantic class pair. Because our semantic classes are obtained by automatic clustering and have no meaningful labels, we followed Szpektor et al. (2007) and provided the an</context>
</contexts>
<marker>Landis, Koch, 1977</marker>
<rawString>J. R. Landis and G. G. Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, page 159―174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
<author>P Pantel</author>
</authors>
<title>Dirt - discovery of inference rules from text.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>323--328</pages>
<contexts>
<context position="36250" citStr="Lin and Pantel, 2001" startWordPosition="6081" endWordPosition="6084">distances; computed over: the patterns’ 1-, 2- and 3-grams sets of: characters, morphemes, their stems &amp; POS; content words and stems binary feature for each of the patterns’ subtrees, 1- and 2-grams ; patterns’ lengths and length ratios lex.r. entries in databases of verb entailments and non-entailments, synonyms, antonyms, allographs ; checked over: pairs of content words, pairs of content word stems, same for the reverse pattern pair (q, p) dis.s. Distributional similarity measures: Common elements ratios, Jaccard and discounted Jaccard scores, sets and sets intersection cardinality, DIRT (Lin and Pantel, 2001), Weeds (Weeds and Weir, 2003) and Hashimoto (Hashimoto et al., 2009) scores; computed over: patterns’ co-occurring noun pairs, POS tags of those, nouns co-occurring in each variable slot, nouns co-occurring with each unary sub-patterns other binary feature for each semantic class pair and individual semantic classes patterns frequency rank in the given semantic class pair pairs; Alagin ID A-2), the databases of synonyms, antonyms and meronyms (respectively 111,000, 5000 and 2500 pairs; Alagin ID A-9), and the allographic word database (2.7 million pairs; Alagin ID A-7). We also used the infor</context>
</contexts>
<marker>Lin, Pantel, 2001</marker>
<rawString>D. Lin and P. Pantel. 2001. Dirt - discovery of inference rules from text. In Proceedings of the ACM SIGKDD Conference on Knowledge Discovery and Data Mining, pages 323–328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>E Cabrio</author>
</authors>
<title>Contradiction-focused qualitative evaluation of textual entailment.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing,</booktitle>
<pages>86--94</pages>
<contexts>
<context position="38843" citStr="Magnini and Cabrio (2010)" startWordPosition="6479" endWordPosition="6482">ttern pairs we acquire can play a role similar to that of basic linguistic resources such 4 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN as antonyms and negations in these works. Closer to our work, Ritter et al. (2008) presented a method for detecting contradictions between functional relations like “X was born in Y”, but these constitute only a part of the semantic relations expressed by the binary patterns we deal with in this paper. Other works analyzed contradictions from linguistic/semantic viewpoints. Voorhees (2008) analyzed the contradiction recognition-task of the RTE3 contest. Magnini and Cabrio (2010) examined relations between contradictions and textual entailment samples. De Marneffe et al. (2008) presented a typology of contradictions, and showed that contradictions can arise from a multitude of phenomena. They showed contradictions based on lexical or world knowledge are challenging and require a highlevel understanding of language and/or the world. As stated in the introduction, these are the types of contradictions our method focuses on. 6 Conclusion This paper showed how to acquire a large number of contradiction pairs between lexico-syntactic binary patterns by exploiting (1) the i</context>
</contexts>
<marker>Magnini, Cabrio, 2010</marker>
<rawString>B. Magnini and E. Cabrio. 2010. Contradiction-focused qualitative evaluation of textual entailment. In Proceedings of the Workshop on Negation and Speculation in Natural Language Processing, page 86―94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Malakasiotis</author>
<author>I Androutsopoulos</author>
</authors>
<title>Learning textual entailment using SVMs and string similarity measures.</title>
<date>2007</date>
<booktitle>In Proceedings of the ACL- PASCAL Workshop on Textual Entailment and Paraphrasing,</booktitle>
<pages>42--47</pages>
<contexts>
<context position="34636" citStr="Malakasiotis and Androutsopoulos (2007)" startWordPosition="5837" endWordPosition="5840">ternal lexical resources, and distributional similarity based features; all features are listed in Table 4. ENT uses all the features while BASE and EXP use all except for the distributional similarity based ones. The optimality of the feature sets was confirmed through ablation tests using the development set (results omitted for the sake of space). Since patterns with a contradiction or entailment relation are often superficially similar, for instance, in case structure or inflection, we use a number of surface features based on string similarity measures, extending the feature sets used by Malakasiotis and Androutsopoulos (2007) for entailment recognition. They include bag-of-words features such as n-grams and similarity scores concerning the bag-of-words such as their Euclidian distance. To complement the surface features with knowledge about the content words, we used lexical databases including such as antonymy, synonymy, entailment, or allography. The presence of such word pairs is usually a good indicator of (non-)contradiction or (non-)entailment at the pattern level. More specifically, for any word pair (wp, wq) taken from a pattern pair (p, q) we mark the presence of (wp, wq) in each of the lexical resources </context>
</contexts>
<marker>Malakasiotis, Androutsopoulos, 2007</marker>
<rawString>P. Malakasiotis and I. Androutsopoulos. 2007. Learning textual entailment using SVMs and string similarity measures. In Proceedings of the ACL- PASCAL Workshop on Textual Entailment and Paraphrasing, page 42 ―47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Murakami</author>
<author>E Nichols</author>
<author>S Matsuyoshi</author>
<author>A Sumida</author>
<author>S Masuda</author>
<author>K Inui</author>
<author>Y Matumoto</author>
</authors>
<title>Statement map: assisting information crediblity analysis by visualizing arguments.</title>
<date>2009</date>
<booktitle>In Proceedings of the 3rd workshop on Information credibility on the web,</booktitle>
<pages>43--50</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="1300" citStr="Murakami et al. (2009)" startWordPosition="182" endWordPosition="185">ern pairs in a large web archive by exploiting the excitation polarity (Hashimoto et al., 2012) of the patterns. In the second stage, we enlarge the first stage classifier’s training data with new contradiction pairs obtained by combining the output of the first stage’s classifier and that of an entailment classifier. We acquired this way 750,000 typed Japanese contradiction pattern pairs with an estimated precision of 80%. We plan to release this resource to the NLP community. 1 Introduction The ability to detect contradictory information in text has many practical applications. Among those, Murakami et al. (2009) pointed out that a contradiction recognition system can detect conflicts and anomalies in large bodies of texts and flag them to help users identify unreliable information. For example, many Japanese web pages claim that agaricus prevents cancer, where agaricus is a species of mushroom found in a variety of commercial products. Although this has been accepted by many Japanese people, by Googling keywords ”agaricus”, ”promotes” and ”cancer”, we can find pages claiming that ”agaricus promotes cancer”, some of which point to a study authorized by the Japanese Ministry of Health, Labour and Welfa</context>
</contexts>
<marker>Murakami, Nichols, Matsuyoshi, Sumida, Masuda, Inui, Matumoto, 2009</marker>
<rawString>K. Murakami, E. Nichols, S. Matsuyoshi, A. Sumida, S. Masuda, K. Inui, and Y. Matumoto. 2009. Statement map: assisting information crediblity analysis by visualizing arguments. In Proceedings of the 3rd workshop on Information credibility on the web, page 43―50. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ohki</author>
<author>S Matsuyoshi</author>
<author>J Mizuno</author>
<author>K Inui</author>
<author>E Nichols</author>
<author>K Murakami</author>
<author>S Masuda</author>
<author>Y Matsumoto</author>
</authors>
<title>Recognizing confinement in web texts.</title>
<date>2011</date>
<booktitle>In the Proceedings of the Ninth International Conference on Computational Semantics,</booktitle>
<pages>215--224</pages>
<contexts>
<context position="6621" citStr="Ohki et al., 2011" startWordPosition="1015" endWordPosition="1018">the discovery of unreliable information to be flagged or to a meaningful survey of complex problems. As exemplified by the agaricus and TPP examples, contradictions between binary patterns that include two variables such as “X promotes Y” or “X will wipe out Y” are more useful than those between unary patterns. We also show that it is not trivial to recognize contradictions between binary patterns using contradictions between unary patterns. Most works dealing with contradiction recognition up till now (Harabagiu et al., 2006; Bobrow et al., 2007; Kawahara et al., 2008; Kawahara et al., 2010; Ohki et al., 2011) focus on recognizing contradictions between full sentences or documents, not text fragments that match our relatively short patterns (survey in Section 5). We expect that the contradictory pattern pairs we acquired can be used as building blocks in such full-fledged contradiction recognition for full sentences or documents, similarly to antonym pairs in Harabagiu et al. (2006). Also, we should emphasize that our method focuses on the most challenging part of contradiction recognition according to the classification of De Marneffe et al. (2008). Since we discard patterns with negations, an evi</context>
<context position="38018" citStr="Ohki et al. (2011)" startWordPosition="6355" endWordPosition="6358"> also added a few more uncategorizable features. See Table 4 for more details. 5 Related Work A number of previous work dealt with the recognition of contradictions between sentences. Harabagiu et al. (2006) proposed a contradiction detection method that focuses on negation, antonymy and some discourse information. Kawahara et al. (2010) also used negations and antonyms to extract contrastive/contradictory statements from the web to present users with a bird ’s-eye view of statements about a given topic. Bobrow et al. (2007) showed a method using logical forms with relatively precise results. Ohki et al. (2011) proposed a method to recognize confinment, a novel semantic relation related to both entailment and contradiction. While we do not deal ourselves directly with sentences, we expect that the binary pattern pairs we acquire can play a role similar to that of basic linguistic resources such 4 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN as antonyms and negations in these works. Closer to our work, Ritter et al. (2008) presented a method for detecting contradictions between functional relations like “X was born in Y”, but these constitute only a part of the semantic relations expressed by th</context>
</contexts>
<marker>Ohki, Matsuyoshi, Mizuno, Inui, Nichols, Murakami, Masuda, Matsumoto, 2011</marker>
<rawString>M. Ohki, S. Matsuyoshi, J. Mizuno, K. Inui, E. Nichols, K. Murakami, S. Masuda, and Y. Matsumoto. 2011. Recognizing confinement in web texts. In the Proceedings of the Ninth International Conference on Computational Semantics, page 215―224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ritter</author>
<author>D Downey</author>
<author>S Soderland</author>
<author>O Etzioni</author>
</authors>
<title>It’s a contradiction—no, it’s not: a case study using functional relations.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>11--20</pages>
<contexts>
<context position="38442" citStr="Ritter et al. (2008)" startWordPosition="6419" endWordPosition="6422">rom the web to present users with a bird ’s-eye view of statements about a given topic. Bobrow et al. (2007) showed a method using logical forms with relatively precise results. Ohki et al. (2011) proposed a method to recognize confinment, a novel semantic relation related to both entailment and contradiction. While we do not deal ourselves directly with sentences, we expect that the binary pattern pairs we acquire can play a role similar to that of basic linguistic resources such 4 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN as antonyms and negations in these works. Closer to our work, Ritter et al. (2008) presented a method for detecting contradictions between functional relations like “X was born in Y”, but these constitute only a part of the semantic relations expressed by the binary patterns we deal with in this paper. Other works analyzed contradictions from linguistic/semantic viewpoints. Voorhees (2008) analyzed the contradiction recognition-task of the RTE3 contest. Magnini and Cabrio (2010) examined relations between contradictions and textual entailment samples. De Marneffe et al. (2008) presented a typology of contradictions, and showed that contradictions can arise from a multitude </context>
</contexts>
<marker>Ritter, Downey, Soderland, Etzioni, 2008</marker>
<rawString>A. Ritter, D. Downey, S. Soderland, and O. Etzioni. 2008. It’s a contradiction—no, it’s not: a case study using functional relations. In Proceedings of EMNLP 2008, pages 11–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Schoenmackers</author>
<author>O Etzioni</author>
<author>D S Weld</author>
<author>J Davis</author>
</authors>
<title>Learning first-order horn clauses from web text.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP 2010,</booktitle>
<pages>1088--1098</pages>
<contexts>
<context position="10785" citStr="Schoenmackers et al., 2010" startWordPosition="1710" endWordPosition="1713">in a syntactic dependency tree, like “X causes Y”, and we say a noun pair co-occurs with a pattern if the two nouns are connected by this pattern in the dependency tree of a sentence in the corpus. We focus on typed binary patterns, which place semantic class restrictions on the noun pairs they co-occur with, e.g., “Yorganization is in Xlo�ation”. Subscripts organization and location indicate the semantic classes of the X and Y slots. Since typed patterns can distinguish between multiple senses of ambiguous patterns, they greatly reduce errors due to pattern ambiguity (De Saeger et al., 2009; Schoenmackers et al., 2010; Berant et al., 2011). We automatically induced semantic classes from our corpus using the EM-based noun clustering algo695 rithm presented in Kazama and Torisawa (2008), and clustered one million nouns into 500 relatively clean semantic classes, including for example classes of diseases and of chemical substances. The binary patterns and their co-occurring noun pairs were extracted from our corpus of 600 million Japanese web pages dependency parsed with KNP (Kurohashi and Nagao, 1994). We restricted our patterns to the most frequent 3.9 million patterns of the form “X-[case particle] Y-[case</context>
</contexts>
<marker>Schoenmackers, Etzioni, Weld, Davis, 2010</marker>
<rawString>S. Schoenmackers, O. Etzioni, D. S Weld, and J. Davis. 2010. Learning first-order horn clauses from web text. In Proceedings of EMNLP 2010, page 1088―1098.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Szpektor</author>
<author>E Shnarch</author>
<author>I Dagan</author>
</authors>
<title>Instancebased evaluation of entailment rule acquisition.</title>
<date>2007</date>
<booktitle>In Proceedings ofACL 2007,</booktitle>
<volume>45</volume>
<pages>456--463</pages>
<contexts>
<context position="25958" citStr="Szpektor et al. (2007)" startWordPosition="4296" endWordPosition="4299">moderate agreement (Landis and Koch, 1977). As a definition of contradiction, we used the notion of incompatibility (i.e., two statements are extremely unlikely to be simultaneously true) proposed by De Marneffe et Figure 4: Precision of all the compared methods al. (2008). We then say binary patterns such as “X causes Y” and “X prevents Y” are contradictory if the above definition holds for any noun pair that can instantiate the patterns’ variables in the provided semantic class pair. Because our semantic classes are obtained by automatic clustering and have no meaningful labels, we followed Szpektor et al. (2007) and provided the annotators with three random noun pairs that cooccur with the patterns as a proxy for the class pair. The annotators marked a given pattern pair as positive if the contradiction relation between the patterns held for all three noun pairs presented. 3.2 Experimental Results Here we show how our proposed method outperforms baseline methods. We compare the following four methods: • PROPOSED: our proposed method. N, the number of newly added positive training samples during the training data expansion process, was set to 6,000 according to preliminary experiments using the develo</context>
</contexts>
<marker>Szpektor, Shnarch, Dagan, 2007</marker>
<rawString>I. Szpektor, E. Shnarch, and I. Dagan. 2007. Instancebased evaluation of entailment rule acquisition. In Proceedings ofACL 2007, volume 45, page 456―463.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E M Voorhees</author>
</authors>
<title>Contradictions and justifications: Extensions to the textual entailment task.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL 2008,</booktitle>
<pages>63--71</pages>
<contexts>
<context position="38752" citStr="Voorhees (2008)" startWordPosition="6468" endWordPosition="6469">le we do not deal ourselves directly with sentences, we expect that the binary pattern pairs we acquire can play a role similar to that of basic linguistic resources such 4 http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?JUMAN as antonyms and negations in these works. Closer to our work, Ritter et al. (2008) presented a method for detecting contradictions between functional relations like “X was born in Y”, but these constitute only a part of the semantic relations expressed by the binary patterns we deal with in this paper. Other works analyzed contradictions from linguistic/semantic viewpoints. Voorhees (2008) analyzed the contradiction recognition-task of the RTE3 contest. Magnini and Cabrio (2010) examined relations between contradictions and textual entailment samples. De Marneffe et al. (2008) presented a typology of contradictions, and showed that contradictions can arise from a multitude of phenomena. They showed contradictions based on lexical or world knowledge are challenging and require a highlevel understanding of language and/or the world. As stated in the introduction, these are the types of contradictions our method focuses on. 6 Conclusion This paper showed how to acquire a large num</context>
</contexts>
<marker>Voorhees, 2008</marker>
<rawString>E. M. Voorhees. 2008. Contradictions and justifications: Extensions to the textual entailment task. In Proceedings of ACL 2008, page 63―71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Weeds</author>
<author>D Weir</author>
</authors>
<title>A general framework for distributional similarity.</title>
<date>2003</date>
<booktitle>In Proceedings of EMNLP 2003,</booktitle>
<pages>81--88</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="36280" citStr="Weeds and Weir, 2003" startWordPosition="6086" endWordPosition="6089">patterns’ 1-, 2- and 3-grams sets of: characters, morphemes, their stems &amp; POS; content words and stems binary feature for each of the patterns’ subtrees, 1- and 2-grams ; patterns’ lengths and length ratios lex.r. entries in databases of verb entailments and non-entailments, synonyms, antonyms, allographs ; checked over: pairs of content words, pairs of content word stems, same for the reverse pattern pair (q, p) dis.s. Distributional similarity measures: Common elements ratios, Jaccard and discounted Jaccard scores, sets and sets intersection cardinality, DIRT (Lin and Pantel, 2001), Weeds (Weeds and Weir, 2003) and Hashimoto (Hashimoto et al., 2009) scores; computed over: patterns’ co-occurring noun pairs, POS tags of those, nouns co-occurring in each variable slot, nouns co-occurring with each unary sub-patterns other binary feature for each semantic class pair and individual semantic classes patterns frequency rank in the given semantic class pair pairs; Alagin ID A-2), the databases of synonyms, antonyms and meronyms (respectively 111,000, 5000 and 2500 pairs; Alagin ID A-9), and the allographic word database (2.7 million pairs; Alagin ID A-7). We also used the information concerning allographic </context>
</contexts>
<marker>Weeds, Weir, 2003</marker>
<rawString>J. Weeds and D. Weir. 2003. A general framework for distributional similarity. In Proceedings of EMNLP 2003, page 81―88. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>