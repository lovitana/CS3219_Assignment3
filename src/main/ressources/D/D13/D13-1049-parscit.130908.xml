<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004414">
<title confidence="0.996748">
Source-Side Classifier Preordering for Machine Translation
</title>
<author confidence="0.979185">
Uri Lerner Slav Petrov
</author>
<affiliation confidence="0.966462">
Google Inc. Google Inc.
</affiliation>
<address confidence="0.595216">
Mountain View, CA, USA New York, NY, USA
</address>
<email confidence="0.998993">
uri@google.com slav@google.com
</email>
<sectionHeader confidence="0.995643" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999773157894737">
We present a simple and novel classifier-based
preordering approach. Unlike existing pre-
ordering models, we train feature-rich dis-
criminative classifiers that directly predict the
target-side word order. Our approach com-
bines the strengths of lexical reordering and
syntactic preordering models by performing
long-distance reorderings using the structure
of the parse tree, while utilizing a discrimina-
tive model with a rich set of features, includ-
ing lexical features. We present extensive ex-
periments on 22 language pairs, including pre-
ordering into English from 7 other languages.
We obtain improvements of up to 1.4 BLEU
on language pairs in the WMT 2010 shared
task. For languages from different families the
improvements often exceed 2 BLEU. Many of
these gains are also significant in human eval-
uations.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956191489362">
Generating the appropriate word order for the tar-
get language has been one of the fundamental prob-
lems in machine translation since the ground setting
work of Brown et al. (1990). Lexical reordering ap-
proaches (Tillmann, 2004; Zens and Ney, 2006) add
a reordering component to standard phrase-based
translation systems (Och and Ney, 2004). Because
the reordering model is trained discriminatively, it
can use a rich set of lexical features. However,
it only has access to the local context which often
times is insufficient to make the long-distance re-
ordering decisions that are necessary for language
pairs with significantly different word order.
Preordering (sometimes called pre-reordering or
simply reordering) approaches (Xia and McCord,
2004; Collins et al., 2005) preprocess the input in
such a way that the words on the source side appear
closer to their final positions on the target side. Be-
cause preordering is performed prior to word align-
ment, it can improve the alignment process and can
then be combined with any subsequent translation
model. Most preordering models use a source-side
syntactic parser and perform a series of tree trans-
formations. Approaches that do not use a parser ex-
ist as well and typically induce a hierarchical rep-
resentation that also allows them to perform long-
distance changes (Tromble and Eisner, 2009; DeN-
ero and Uszkoreit, 2011; Neubig et al., 2012).
Models that use a source-side parser differ on two
main dimensions: the way tree transformations are
expressed, and whether they are built manually or
learned from data. One common type of tree trans-
formation are rewrite rules. These typically involve
some condition under which the transformation can
be applied (e.g., a noun and an adjective found in
the same clause) and the transformation itself (e.g.,
move the adjective after the noun). These rules can
be designed manually (Collins et al., 2005; Wang
et al., 2007) or learned from data (Xia and McCord,
2004; Habash, 2007; Genzel, 2010; Wu et al., 2011).
Another type of tree transformations uses ranking
functions to implement precedence-based reorder-
ing. Here, a function assigns a numerical value
to every word in a clause, intended to express the
precedence of the word in the target language. The
reordering operation is then to sort the words accord-
ing to their assigned values. The ranking function
</bodyText>
<page confidence="0.980632">
513
</page>
<note confidence="0.7339135">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 513–523,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999842666666667">
can be designed manually (Xu et al., 2009) or trained
from data (Yang et al., 2012). This approach is
particularly effective for Subject-Object-Verb (SOV)
languages.
In this work we present a simple classifier-based
preordering model. Our model operates over de-
pendency parse trees and is therefore able to per-
form long-distance reordering decisions, as is typ-
ical for preordering models. But instead of deter-
ministic rules or ranking functions, we use discrim-
inative classifiers to directly predict the final word
order, using rich (bi-)lexical and syntactic features.
We present two models. The first model uses a
classifier to directly predict the permutation order in
which a family of words (a head word and all its
children) will appear on the target side. This ap-
proach is similar in spirit to the work of Li et al.
(2007), except that they use constituency parse trees
and consider only nodes with 2 or 3 children. We
instead work with dependency trees and consider
much larger head-children sets. Our second model is
designed to decompose the exponential search space
of all possible permutations. The prediction task is
broken into two separate steps. In the first step, for
each child word a binary classifier decides whether
it appears before or after its parent in the target lan-
guage. In the second step, we predict the best order
of the words on each side of the parent. We show
that the second approach is never worse than the first
one and sometimes significantly better.
We present experiments on 22 language pairs
from different language families using our preorder-
ing approach in a phrase-based system (Och and
Ney, 2004), as well as a forest-to-string system
(Zhang et al., 2011). In a first set of experiments,
we use the WMT 2010 shared task data (Callison-
Burch et al., 2010) and show significant improve-
ments of up to 1.4 BLEU (Papineni et al., 2002)
on three out of eight language pairs. In a second
set of experiments, we use automatically mined par-
allel data from the web and build translation sys-
tems for languages from various language families.
We obtain especially big improvements in transla-
tion quality (2-7 BLEU) when the language pairs
have divergent word order (for example English to
Indonesian, Japanese, Korean or Malay). In our ex-
periments on English to and from Hungarian, Dutch,
and Portuguese translation, we find that we can ob-
tain consistent improvements in both translation di-
rections. To additionally verify our improvements
we use human raters, who confirm the significance
of the BLEU score improvements.
Finally, we compare training the preordering clas-
sifiers on small amounts of manually aligned data to
training on large quantities of automatically aligned
data for English to Arabic, Hebrew, and Japanese.
When evaluated on a pure reordering task, the mod-
els trained on manually aligned data perform slightly
better, but similar BLEU scores are obtained in both
scenarios on an end-to-end translation task.
</bodyText>
<sectionHeader confidence="0.959148" genericHeader="method">
2 Classifier Reordering
</sectionHeader>
<bodyText confidence="0.992702">
Our goal is to learn a model that can transform the
word order of an input sentence to an order that is
natural in the target language. For example, when
translating the English sentence:
The black cat climbed to the tree top.
to Spanish, we would like to reorder it as:
The cat black climbed to the top tree.
When translating to Japanese, we would like to get:
The black cat the tree top to climbed.
Such a model can then be used in combination with
any translation model.
In our approach we first part-of-speech (POS) tag
and parse the input sentence, producing the POS
tags and head-modifier dependencies shown in Fig-
ure 1. Reordering is then done by traversing the
dependency tree starting at the root. For each head
word we determine the order of the head and its chil-
dren (independently of other decisions) and continue
the traversal recursively in that order. In the exam-
ple, we first need to decide on the order of the head
“climbed” and the children “cat”, “to”, and “.”.
</bodyText>
<subsectionHeader confidence="0.761581">
2.1 Classification Model &amp; Features
</subsectionHeader>
<bodyText confidence="0.999706">
The reordering decisions are made by multi-class
classifiers where class labels correspond to permu-
tation sequences. We train a separate classifier for
each number of possible children. Crucially, we do
not learn explicit tree transformations rules, but let
the classifiers learn to trade off between a rich set of
overlapping features.
</bodyText>
<page confidence="0.996147">
514
</page>
<bodyText confidence="0.999941166666667">
Obviously, it is possible to use any classification
model and learning algorithm. We use maximum
entropy classifiers with l1/l� regularization trained
with the GradBoost algorithm (Duchi and Singer,
2009). We chose this setup since it naturally sup-
ports multi-class prediction and can therefore be
used to select one out of many possible permuta-
tions. Additionally, the learning algorithm produces
a sparse set of features. In our experiments the final
models have typically only a few 100K non-zero fea-
ture weights per language pair. Given this relatively
small number of features, it is possible to manually
inspect the feature weights and gain insights into the
behavior of the model. We show an example analy-
sis in Section 5.
Our features encode information about the context
in which a word occurs in the sentence. We model
context as “informative” words:
</bodyText>
<listItem confidence="0.981280181818182">
• The head itself.
• The children. We indicate whether each child is
before, immediately before, immediately after,
or after the head.
• For every child, if there is a gap between it and
the head, then the first and last word of that gap.
• For every pair of consecutive children, if there
is a gap between them, then the first and last
word of that gap.
• The head’s immediate sibling to the left/right or
an indication that none exists.
</listItem>
<bodyText confidence="0.99965">
When extracting the features, every word can be rep-
resented by its word identity, its fine-grained POS
tag from the treebank, and a coarse-grained POS cat-
egory, similar to the universal categories described
in Petrov et al. (2012). We also include pairs of these
features, resulting in potentially bilexical features.
</bodyText>
<subsectionHeader confidence="0.999751">
2.2 Training Data
</subsectionHeader>
<bodyText confidence="0.998083375">
The training data for the classifiers is generated from
the word aligned parallel text. Since parallel data
is plentiful, we can afford to be selective. We first
construct the intersection of high-confidence source-
to-target and target-to-source alignments. For every
family in the source dependency tree we generate a
training instance if and only if the intersection de-
fines a full order on the source words:
</bodyText>
<listItem confidence="0.977034">
• Every source word must be aligned to at least
one target word.
</listItem>
<figure confidence="0.63636325">
ROOT
The black cat climbed to the tree top .
DT JJ NN VBD IN DT NN NN .
DET ADJ NOUN VERB ADP DET NOUN NOUN .
</figure>
<figureCaption confidence="0.9930195">
Figure 1: A sentence, its dependency parse and its fine-
grained and coarse-grained POS tags.
</figureCaption>
<listItem confidence="0.9959514">
• No two source words can be aligned to the
same target word.
• If a source word is aligned to multiple target
words, then no target word in this range can be
aligned to a different source word.
</listItem>
<bodyText confidence="0.98157303125">
While this might sound restrictive, we can usually
generate at least some training instances from every
sentence and discard the remaining families in the
tree. In particular, we do not need to extract train-
ing instances for all words in a given sentence since
the reordering decisions are made independently for
every head word.
A potential concern might be that our method for
selecting training data can exclude all instances of
certain words. Consider the English phrase “the
boy”. For languages without articles (e.g. Russian
or Japanese) the determiner “the” may either not be
aligned to any word or get aligned to the foreign
word for “boy”. In both cases the family will be
discarded according to either the first or the second
condition above. The concern is therefore that we
would have no training data with the English word
“the”. In practice, however, this does not seem to be
a problem. First, there are instances where the En-
glish word “the” gets aligned to something (perhaps
a preposition), and second, since the word “the” is
omitted in the target language its location in the re-
ordered sentence is not very important.
Naturally we learn better classifier models from
better alignments. The other direction is also true
– if we run preordering on the source side then the
alignment task becomes easier and tends to produce
better results. Therefore it can be useful to iter-
ate between generating the alignment and learning
a preordering model. Empirically, the gains from
this bootstrapping approach are not dramatic and are
realized after just one iteration, i.e., create the align-
</bodyText>
<page confidence="0.989714">
515
</page>
<bodyText confidence="0.999933">
ment, train a preordering model, use the preordering
model to learn a new alignment, and then train the
final preordering model.
</bodyText>
<subsectionHeader confidence="0.998776">
2.3 1-Step Classifier
</subsectionHeader>
<bodyText confidence="0.998753862068966">
As a first approach we use a single classifier to di-
rectly predict the correct permutation of a given fam-
ily. Consider the family headed by “climbed” in
Figure 1. There are three children and the original
order of the words is “cat”, “climbed”, “to”, and
“.”. A possible outcome of the classifier can be the
permutation 0-2-1-3, representing the order “cat”,
“to”, “climbed”, and “.”.
The number of permutations for the head and n
children is of course (n + 1)!, which becomes large
very quickly and causes some problems. In practice
we therefore limit ourselves to the K most common
permutations. Unfortunately, this means that when-
ever there are many children, the correct permuta-
tion order might not be available as an option. Even
when the correct permutation is available, classifica-
tion accuracy typically deteriorates as the number of
possible classes increases.
An additional subtle issue is that the 1-step classi-
fier cannot share useful information across different
numbers of children. For example, in Spanish adjec-
tives usually appear after the noun, but sometimes
they appear before the noun. The decision depends
on the adjective itself and sometimes the head noun,
but does not depend on other children. Ideally, if for
some adjective we have enough examples with 1 or
2 children we would like to make the same decision
for a larger number of children, but these classifiers
may not have enough relevant examples.
</bodyText>
<subsectionHeader confidence="0.995875">
2.4 2-Step Classifier
</subsectionHeader>
<bodyText confidence="0.999757">
Our 2-step approach addresses the exponential
blowup of the number of children by decomposing
the prediction into two steps:
</bodyText>
<listItem confidence="0.9319632">
1. For every child, decide whether it should ap-
pear before or after the head.
2. Determine the order of the children that appear
before the head and the order of the children
after the head.
</listItem>
<bodyText confidence="0.999994">
The two steps make the reordering of the modifiers
before and after the head independent of each other,
which is reminiscent of the lexicalized parse tree
generation approach of Collins (1997). In the run-
ning example, for the head “climbed” we might first
make the following three binary decisions: the word
“cat” should appear before the head and the words
“to” and “.” should appear after the head. In the
second step there is only one word before the head
so there is nothing to do. There are two words after
the head, so we use another classifier to determine
their order. The first step is implemented using a bi-
nary classifier, called the pivot classifier (since the
head functions like the pivot in quicksort). The sec-
ond step classifiers directly predict the correct per-
mutation of the children before / after the head.
To illustrate the effectiveness of the 2-step ap-
proach, consider a head word with 4 children. The 1-
step approach must predict 1 of 5! = 120 outcomes.
In the 2-step approach, in the worst case the second
step must predict 1 of 4! = 24 outcomes (if all the
children are on one side of the head); if we are lucky
and the children split evenly, then we only need two
binary decisions in the second step (for the two pairs
before and after the head). If we define hard cases as
cases involving 5 or more words, 5.54% of the non-
leaves are hard cases with the 1-step approach, but
only 1.07% are hard cases with the 2-step approach.
</bodyText>
<sectionHeader confidence="0.997693" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.99998085">
To provide a through evaluation of our approach, we
conduct experiments on two sets of data and with
two translation systems. The first translation system
is a phrase-based system (Och and Ney, 2004). In
addition to the regular distance distortion model, we
incorporate a maximum entropy based lexicalized
phrase reordering model (Zens and Ney, 2006). Our
second system is a forest-to-string system (Zhang et
al., 2011). The forest-to-string system uses a one-
best parse tree but factorizes it into a packed forest
of binary elementary trees – hence the name forest-
to-string rather than tree-to-string.
The systems are configured and tuned for each
language pair to produce the best results. We then
add our 1-step and 2-step preordering classifiers as
preprocessing steps at training and test time. We
train the reordering classifiers on up to 15M train-
ing instances. We train separate classifiers for every
number of involved words, and restrict each one to
the K = 20 most frequent outcomes.
</bodyText>
<page confidence="0.989422">
516
</page>
<bodyText confidence="0.999996321428571">
In our implementation, in the 1-step approach we
did not do any reordering for nodes with 7 or more
children. In the 2-step approach we did not reorder
the children on either side of the head if there were 7
or more of them. Even though there was no techni-
cal reason that prevented us from raising the thresh-
olds, there was no good reason to do so. There were
very few cases where children were not reordered
because of these thresholds, many of them corre-
sponded to bad parses, and they had very little im-
pact on the final scores. Thus, for the 1-step ap-
proach we had 6 classifiers: 1 binary classifier for a
head and a single child and 5 multi-class classifiers
for 3–7 words. For the 2-step approach we had 11
classifiers: 1 pivot classifier, 5 classifiers for words
before the head, and 5 for words after the head.
For a direct comparison to a strong preordering
system, we compare to the system of Genzel (2010),
which learns a set of unlexicalized reordering rules
from automatically aligned data by minimizing the
number of crossing alignments. We used a sliding
window of size 3 and tried all three of their vari-
ants. There were about 40-50 rules per language
pair. While conceptually possible, it is not practi-
cal to learn more rules (including lexicalized rules)
with this system, because of the computational com-
plexity of the learning algorithm and the incremental
nature in which the rules are learned and applied.
</bodyText>
<subsectionHeader confidence="0.992021">
3.1 WMT Setup
</subsectionHeader>
<bodyText confidence="0.999858857142857">
In our first set of experiments, we use the data pro-
vided for the WMT 2010 shared task (Callison-
Burch et al., 2010). We build systems for all lan-
guage pairs: English to and from Czech, French,
German, and Spanish. Since this is a publicly avail-
able dataset, it is easy to compare our results to other
submissions to the shared task.
During word alignment, we filter out sentences
exceeding 60 words in the parallel texts and per-
form 6 iterations of IBM Model-1 training (Brown
et al., 1993), followed by 6 iterations of HMM train-
ing (Vogel et al., 1996). We do not use Model-4
because it is slow and did not add much value to our
systems in a pilot study. Standard phrase extraction
heuristics (Koehn et al., 2003) are applied to extract
phrase pairs with a length limit of 6 from alignments
symmetrized with the “union” heuristic. Maximum
jump width is set to 8. Rule extraction for the forest-
to-string system is limited to 16 rules per tree node.
There are no length-based reordering constraints in
the forest-to-string system. We train two 5-gram lan-
guage models with Kneser-Ney smoothing for each
of the target languages. One is trained on the tar-
get side of the parallel text, the other on a news cor-
pus provided by the shared task. We tune the fea-
ture weights for every configuration with 10 rounds
of hypergraph-based Minimum Error Rate Training
(MERT) (Kumar et al., 2009).
</bodyText>
<subsectionHeader confidence="0.999138">
3.2 Additional Languages
</subsectionHeader>
<bodyText confidence="0.999937852941176">
In our second set of experiments, we explore the im-
pact of classifier preordering for a number of lan-
guages with different word orders. Some of the lan-
guages included in our study are verb-subject-object
(VSO) languages (Arabic, Irish, Welsh), subject-
object-verb (SOV) languages (Japanese, Korean),
and fairly free word order languages (Dutch, Hun-
garian). Where a parser is available, we also conduct
experiments on translating into English.
Since there are no standard training sets for many
of these language pairs, we use parallel data auto-
matically mined from the web. The amount of par-
allel text for each language pair is between 120M
and 160M words. For evaluation, we use a set of 9K
English sentences collected from the web and trans-
lated by humans into each of the target languages.
Each sentence has one reference translation. We use
5K sentences for evaluation and the rest for tuning.
The systems and training configurations are sim-
ilar to the WMT setup. The word alignment step
includes 3 iterations of IBM Model-1 training and
2 iterations of HMM training. Lexical reordering is
included where it helps, but typically makes only a
small difference. We again use a 5-gram language
model trained on a large amount of monolingual
text. Overall, we use between 20 and 30 features,
whose weights are optimized using hypergraph-
based MERT. All experiments for a given language
pair use the same set of MERT weights. This po-
tentially underestimates the improvements that can
be obtained, but also eliminates MERT as a pos-
sible source of improvement, allowing us to trace
back improvements in translation quality directly to
changes in preordering of the input data.
</bodyText>
<page confidence="0.977246">
517
</page>
<subsectionHeader confidence="0.966989">
3.3 Evaluation
</subsectionHeader>
<bodyText confidence="0.999993769230769">
We use case-sensitive BLEU (Papineni et al., 2002)
to assess translation quality. For Japanese and Ko-
rean we use character-level BLEU. We use bootstrap
resampling to compute confidence intervals.
Additionally, we also conduct a side-by-side hu-
man evaluation on 750 sentences for each language
pair (sampled from the same sentences used for
computing BLEU). For each sentence, we ask bilin-
gual annotators to compare the translations from two
different systems and say whether one is better, lead-
ing to three possible scores of -1, 0, and +1. We fo-
cus on this relative comparison since absolute scores
are difficult to calibrate across languages and raters.
</bodyText>
<subsectionHeader confidence="0.941312">
3.4 Syntactic Parsers
</subsectionHeader>
<bodyText confidence="0.999942269230769">
Table 1 shows our treebank sources and parsing ac-
curacies. For English, we use the updated WSJ with
OntoNotes-style annotations converted to Stanford
dependencies (de Marneffe et al., 2006). The re-
maining treebanks are all available in dependency
format. In all cases, we apply a set of heuristics to
the treebank data to make the tokenization as simi-
lar as possible to the one of the bitext. Our heuristics
can split treebank tokens but do not merge treebank
tokens. We found that adjusting the treebank tok-
enization is crucial for obtaining good results. How-
ever, this makes the reported parsing accuracies not
comparable to other numbers in the literature. When
necessary, we projectivize the treebanks by raising
arcs until the tree becomes projective, as described
in Nivre and Nilsson (2005); we do not reconstruct
non-projective arcs at parsing time, since our subse-
quent systems expect projective trees.
Our part-of-speech tagger is a conditional random
field model (Lafferty et al., 2001) with simple word-
identity and affix features. The parsing model is
a shift-reduce dependency parser, using the higher-
order features from Zhang and Nivre (2011). Addi-
tionally, we include 256 word-cluster features (Koo
et al., 2008) trained on a large amount of unlabeled
monolingual text (Uszkoreit and Brants, 2008).
</bodyText>
<sectionHeader confidence="0.999806" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999594">
Due to the large number of experiments and lan-
guage pairs we divide the experiments into groups
and discuss each in turn. We only include the results
</bodyText>
<table confidence="0.999468555555556">
UAS LAS POS
en: English1 92.28 90.28 97.05
cs: Czech2 84.66 72.01 98.97
de: German3 89.30 86.98 97.69
es: Spanish4 86.24 82.32 96.62
fr: French5 88.57 86.40 97.48
hu: Hungarian2 87.66 82.51 94.47
nl: Dutch3 86.09 82.31 97.38
pt: Portuguese4 90.22 87.26 98.10
</table>
<tableCaption confidence="0.991766">
Table 1: Parsing accuracies on the retokenized treebanks.
</tableCaption>
<figureCaption confidence="0.669785166666667">
UAS is unlabeled attachment score, LAS is labeled at-
tachment score, and POS is part-of-speech tagging accu-
racy. The treebank sources are (1): Marcus et al. (1993)
+ Judge et al. (2006) + Petrov and McDonald (2012), (2):
Nivre et al. (2007), (3): Buchholz and Marsi (2006), (4):
McDonald et al. (2013), (5): Abeill´e et al. (2003).
</figureCaption>
<bodyText confidence="0.998443333333333">
from the forest-to-string system when they are bet-
ter than the phrase-based results. We use * to denote
results from the forest-to-string system.
</bodyText>
<subsectionHeader confidence="0.987368">
4.1 WMT Experiments
</subsectionHeader>
<bodyText confidence="0.99990504">
Table 2 presents detailed results on the WMT setup.
Lexical reordering (Zens and Ney, 2006) never hurts
and is thus included in all systems. Overall, our re-
sults are a little better than the best results of the
WMT 2010 shared task for two language pairs and
within reach of the best results in most other cases.
The 2-step classifier preordering approach pro-
vides statistically significant improvements over the
lexical reordering baseline on three out of the eight
language pairs: English-Spanish (en-es: 1.4 BLEU),
German-English (de-en: 1.2 BLEU), and English-
French (en-fr: 1.0 BLEU). These improvements are
significant in our human side-by-side evaluation.
We also observe gains when combining our pre-
ordering approach with the forest-to-string system
for English-Spanish and German-English. While the
forest-to-string system is capable of performing long
distance reordering in the decoder, it appears that
an explicitly trained lexicalized preordering model
can provide complementary benefits. These bene-
fits are especially pronounced for German-English
where long distance verb movement is essential. For
the romance languages (Spanish and French), word
ordering depends highly on lexical choice which is
captured by the lexical features in our classifiers.
</bodyText>
<page confidence="0.994134">
518
</page>
<table confidence="0.999760454545454">
base lexical rule 1-step 2-step wmt best
en-cs 14.9 15.1 15.2 15.2 15.2 15.4
en-de 15.3 15.6 15.9 15.9 15.7 16.3
en-es 27.4 27.8° 28.4° 29.0 28.8&apos;&apos; 28.6
en-es* 28.9 - 28.7 29.0 29.2 28.6
en-fr 26.3 26.5° 26.8° 27.2 27.3&apos;° 27.6
cs-en 21.6 21.6 21.5 21.6 21.7 21.9
de-en 20.6 21.1° 21.9 21.9 21.8&apos; 22.8
de-en* 22.1 - 22.5 22.5 22.7 22.8
es-en 28.3 28.7 28.7 28.8 28.9 28.8
fr-en 26.8 27.0 26.9 26.9 27.0 28.3
</table>
<tableCaption confidence="0.991539857142857">
Table 2: BLEU scores on the WMT 2010 setup. Results from the forest-to-string system are marked with * and are
only included when better than the phrase-based results. The base system includes a distance distortion model; the
lexical system adds lexical reordering; rule is the rule preordering system of Genzel (2010) plus lexical reordering;
1-step and 2-step are our classifier-based systems plus lexical reordering. Bolded results are statistically significantly
better than non-bolded results as measured by a bootstrap sample test with a 99% confidence interval. Human evals
are conducted only where indicated; we use&apos; and&apos; to indicate a significantly better result than ° and ° in the human
eval at 95%. Also included are the best results from the WMT 2010 task.
</tableCaption>
<bodyText confidence="0.999864">
Compared to a state-of-the-art preordering sys-
tem, the automatic rule extraction system of Gen-
zel (2010), we observe significant gains in several
cases and no losses at all. The improvements on
English-Spanish are significant also in the human
evaluation, while the English-French improvements
are positive, but not statistically significant.
Comparing the different languages, Czech (cs) ap-
pears the most immune to improvements from pre-
ordering (and lexical reordering). One possible ex-
planation is that Czech has a relatively free word
order with a default SVO structure. It is therefore
difficult to learn reordering changes from English
to Czech. Additionally, the accuracy (LAS) of our
Czech parser is by far the lowest of all parsers that
we used, potentially limiting the benefits that can be
obtained when translating from Czech into English.
On this setup there is fairly little difference in per-
formance between the 1-step and 2-step approaches.
The main benefit of the 2-step approach is compact-
ness: the set of 2-step classifiers has about half the
number of non-zero features as the 1-step classifiers.
</bodyText>
<subsectionHeader confidence="0.987253">
4.2 Additional Languages Experiments
</subsectionHeader>
<bodyText confidence="0.9999635">
Table 3 shows our first set of results on the additional
languages, including some languages with a wide
disparity in word order relative to English. The SOV
languages Korean (ko) and Japanese (ja) benefit the
most from preordering and gain more than 7 BLEU
relative to the phrase-based baseline and still more
than 3 BLEU for the forest-to-string system. Simi-
lar improvements were reported by Xu et al. (2009)
with manual reordering rules. Indonesian (id) and
Malay (ms) are next with gains of 2.5 BLEU. Malay
does not have a grammatical subject in the sense
that English does, but instead uses a concept of an
agent and an object, whose order is determined by
the voice of the verb. It appears that our classifiers
have learned to model some of these highly lexical,
but systematic ordering preferences. Welsh (cy) and
Irish (ga) as VSO languages also exhibit large gains
of 2.1 BLEU. For Arabic (ar) and Hebrew (iw), the
gains are smaller, but still significant and exceed 1
BLEU relative to the baseline.
The benefits of our 2-step approach over the 1-
step approach become apparent on this set of lan-
guages where reordering is most important. By pre-
dicting the target word order in two steps, we reduce
sparsity and make two easier decisions in place of
a single difficult high entropy decision. Indeed, the
2-step approach produces improvements over the 1-
step approach on five out of nine language pairs. The
improvements are as large as 0.9 BLEU for Korean
and 0.5 BLEU for Japanese and Welsh. We per-
formed human evaluation for all language pairs with
a noticeable BLEU gain for the 2-step system over
</bodyText>
<page confidence="0.996513">
519
</page>
<table confidence="0.999832">
base rule 1-step 2-step
en-ar 11.4 12.3 12.5 12.6
en-cy 29.3 31.1 31.9p 32.4♣
en-ga 17.0 18.5 18.8p 19.1♣
en-iw 18.8 19.7 20.2 20.2
en-id 31.0 33.4 34.0p 34.3p
en-ja 10.4 16.4 17.5p 18.0♣
en-ja* 14.9 18.0 18.2p 18.6♣
en-ko 24.1 31.8 31.8p 32.7♣
en-ms 20.4 22.5 22.9 22.9
</table>
<tableCaption confidence="0.893907833333333">
Table 3: BLEU scores for language from various lan-
guage families: Arabic (ar), Welsh (cy), Irish (ga), In-
donesian (id), Hebrew (iw), Japanese (ja), Korean (ko),
and Malay (ms). Lexical reordering is not included in
any of the systems. Bolded results are significant at 99%.
♣ is significantly better than p in a human eval at 95%.
</tableCaption>
<bodyText confidence="0.9999674">
the 1-step system. The human judgments exactly
agree with the results of the BLEU significance tests.
The gains relative to the rule reordering system of
Genzel (2010) and the no-preordering baseline are
even larger and therefore clearly also significant.
In Table 4 we show results for Hungarian (hu),
Dutch (nl), and Portuguese (pt). In all cases but
English-Hungarian we observe significant improve-
ments over the no preordering baseline. It should be
noted that the gains are not symmetric – sometimes
there are larger gains for translating out of English,
while for Hungarian the gains are higher for trans-
lating into English. Hungarian has a free word order
which is difficult to predict which might partially ex-
plain why there are no improvements for translating
into Hungarian. For Dutch-English, the forest-to-
string system yields the best results, which was also
the case for German-English, further supporting the
observation that combining different types of syn-
tactic reordering approaches can be beneficial.
</bodyText>
<subsectionHeader confidence="0.999916">
4.3 Manually Aligned Data
</subsectionHeader>
<bodyText confidence="0.9998505">
For Arabic (ar), Hebrew (iw), and Japanese (ja) we
conducted some additional experiments with man-
ually aligned data. We asked bilingual speakers to
translate about 20K English sentences into the re-
spective target language and to mark the alignment
between the words. We reserved 20% of this data for
evaluation and used the rest for training. For evalu-
ation we used the fuzzy metric defined by Talbot et
</bodyText>
<table confidence="0.998809">
base rule 1-step 2-step
en-hu 12.7 12.6 12.8 12.7
en-nl 25.3 26.1 26.4 26.4
en-pt 30.2 31.9 32.6 32.8
hu-en 22.0 22.2 22.7 22.7
nl-en 34.9 35.7 35.2 35.1
nl-en* 36.3 36.5 36.6 36.7
pt-en 39.8 40.1 40.1 40.1
</table>
<tableCaption confidence="0.9984505">
Table 4: BLEU scores for translating to and from En-
glish for: Hungarian (hu), Dutch (nl), and Portuguese
(pt). Lexical reordering is not used for any language pair.
Bolded results are significant at 99%.
</tableCaption>
<bodyText confidence="0.999737769230769">
al. (2011), which counts the fraction of words that
are reordered into the correct position.
The BLEU scores in Table 5 show that training
from small amounts of manually aligned data or
large amounts of automatically aligned data results
in models of similar quality. In terms of the fuzzy
metric, the models trained from manually aligned
data were better. A possible explanation is that these
models were trained on data which was much more
similar to the evaluation data (both were subsets of
the manually aligned data), biasing the metric in
their favor. In absolute terms, the reordering ac-
curacy is around 80% for Arabic and Japanese and
close to 90% for Hebrew. Most impressively, more
than 60% of the Hebrew sentences are exactly in the
correct word order, implying that monotonic trans-
lation may suffice.
We also examined the accuracy of the individual
classifiers and found that the pivot classifier has an
accuracy around 95%. It is therefore unlikely that
a word is reordered to the wrong side of its head in
the 2-step reordering approach. The classifiers that
predict the final word order have an accuracy above
90% when there are only two words and drop to still
respectable 70%-80% when there are 4 or more chil-
dren or 20 possible options.
</bodyText>
<sectionHeader confidence="0.98064" genericHeader="evaluation">
5 Analysis
</sectionHeader>
<bodyText confidence="0.9973276">
In this section, we analyze an example whose trans-
lation is significantly improved by our preordering
approach, demonstrating the usefulness of our lexi-
calized features. Consider the English sentence:
It was a real whirlwind.
</bodyText>
<page confidence="0.987863">
520
</page>
<table confidence="0.999378">
no reordering manual automatic
fuzzy exact BLEU fuzzy exact BLEU fuzzy exact BLEU
en-ar 63.2 19.8 11.4 83.5 47.6 12.4 79.0 38.9 12.6
en-iw 67.9 22.2 18.8 89.8 62.4 20.3 89.2 61.2 20.2
en-ja* 44.1 0.0 14.9 80.9 41.5 18.4 78.5 36.8 18.6
</table>
<tableCaption confidence="0.987785">
Table 5: Preordering accuracy for the 2-step classifiers using manual alignments vs. automatic alignments. Fuzzy
refers to the metric defined in Talbot et al. (2011) and exact is the percentage of sentences with a perfect preordering.
</tableCaption>
<bodyText confidence="0.997528279069768">
taken from the WMT test set. The dependency parse
tree is shown in Figure 2. In our experiments the
rule-based approach of (Genzel, 2010) reordered the
source sentence into:
It was a whirlwind real.
and produced the translation:
Es un torbellino real.
In comparison, our 2-step system kept the English
sentence unchanged and produced the translation:
Fue un aut´entico torbellino.
The second translation is better than the first because
of the correct tense (which is not related directly to
the preordering) and because the noun phrase “real
whirlwind” is ordered correctly.
The main reason for the difference in the ordering
is that the rule-based system can only use the unlex-
icalized information from the parse tree. The head
“whirlwind” is a noun and the child “real” is an ad-
jective; since adjectives typically appear after nouns
in Spanish, their order is reversed.
To understand why the classifier-based system
keeps “real” before “whirlwind” we can examine
the features used by the classifier to make this deci-
sion. In Table 6 we consider the 3 strongest features
in favor of the child “real” appearing after the head
“whirlwind” and the three strongest features in favor
of the child appearing before the head. Recall that
the pivot is a binary classifier: positive features sup-
port one decision (in our case: the child should be
after the head) and the negative features support the
other decision (the child should be before the head).
The three features that have the highest positive
weight encode the fact that the child is an adjective,
since in general, adjectives in Spanish appear after
the noun. On the other hand, the three features with
the most negative weights all encode the fact that the
child is the word “real” which unlike most adjec-
tives tends to appear before the noun. It is interesting
to note that for this particular ordering decision the
child word is much more informative than the head
word and indeed, all the important features contain
information about the child and none of them con-
tains any information about the head.
</bodyText>
<sectionHeader confidence="0.999503" genericHeader="conclusions">
6 Conclusions &amp; Future Work
</sectionHeader>
<bodyText confidence="0.999962166666667">
We presented a simple and novel preordering ap-
proach that produces substantial improvements in
translation accuracy on a large number of languages.
We use a source-side syntactic parser and train dis-
criminative classifiers to predict the order of a parent
and its children in the target language, using features
from the dependency tree as well as (bi-)lexical fea-
tures. To decompose the exponential space of all
possible permutations, we introduce the 2-step ap-
proach. We show empirically that this approach is
significantly better than directly predicting the full
permutation for some languages, and never signifi-
cantly worse.
We obtain strong results on the WMT 2010 shared
task data, observing gains of up to 1.4 BLEU over a
state-of-the-art system. We also show gains of up
to 0.5 BLEU over a strong directly comparable pre-
ordering system that is based on learning unlexical-
ized reordering rules. We obtain improvements of
more than 2 BLEU in experiments on additional lan-
guages. The gains are especially large for languages
where the sentence structure is very different from
English. These positive results are confirmed in hu-
man side-by-side evaluations.
When comparing our approach to syntax-based
translation systems (Yamada and Knight, 2001; Gal-
ley et al., 2004; Huang et al., 2006; Dyer and Resnik,
2010) we note that both approaches use syntactic in-
formation for reordering decisions. Our preorder-
ing approach has several advantages. First, be-
</bodyText>
<page confidence="0.991718">
521
</page>
<note confidence="0.47690625">
ROOT
It was a real whirlwind .
NN VBD DT JJ NN .
NOUN VERB DET ADJ NOUN .
</note>
<figureCaption confidence="0.9786015">
Figure 2: An example where lexical information is nec-
essary for choosing the correct word order.
</figureCaption>
<bodyText confidence="0.999957594594595">
cause preordering is performed before learning word
alignments, it has the potential to improve the word
alignments. Second, by using discriminative clas-
sifiers we can take advantage of lexical features.
Finally, preordering can be combined with syntax-
based translation models and our results confirm the
complementary benefits that can be obtained.
Compared to other preordering models, our ap-
proach has the obvious problem of having to make
predictions over an exponential set of permutations.
We show that this is not an insurmountable diffi-
culty: our 2-step approach decomposes the exponen-
tial space, often leading to much easier prediction
tasks. Even when the number of possible permuta-
tions is large we can limit ourselves to the K most
popular permutations.
On the other hand, our approach provides im-
portant advantages. Compared to systems that use
rewrite rules, it is much easier to encode useful
knowledge that by itself is not enough to determine
a full rewrite rule, such as “a determiner is unlikely
to be the last word in a clause.” Perhaps more im-
portantly, our model provides an elegant answer to
the question of what to do when multiple rewrite
rules can be applied. Previous work has employed
different heuristics: use the most specific rule (Xia
and McCord, 2004), use all applicable rules (Gen-
zel, 2010), or use the most frequent rule (Wu et al.,
2011). In our model there is no need for such heuris-
tics – all the “rules” are treated as features to a dis-
criminative classifier, and the task of analyzing their
interactions is handled by the learning algorithm.
Compared to preordering systems that use rank-
ing functions, our model has the advantage that it
can encode information about the complete permu-
tation. For example, for three source words A, B,
and C, we can naturally express the useful prior that
</bodyText>
<table confidence="0.999220875">
Feature Weight
PrevChild:tag=JJ,PrevSibling:a 0.448
PrevChild:cat=ADJ,PrevSibling:a 0.292
PrevChild:cat=ADJ,NoNextSibling 0.212
...
PrevChild:real,NoNextHeadSibling -0.310
PrevChild:real,PrevSibling:cat=DET -0.516
PrevChild:real,PrevSibling:a -0.979
</table>
<tableCaption confidence="0.995126">
Table 6: The three features with the highest and low-
</tableCaption>
<bodyText confidence="0.940021363636364">
est weights for choosing the position of “real” relative
to “whirlwind.” PrevChild means that the child is the
immediate word before the head. PrevSibling refers to
the child’s sibling immediately to the left (the determiner
“a”). NoNextSibling and NoNextHeadSibling mean that
the child and head do not have a sibling to the right.
A-B-C and C-B-A are likely orders but C-A-B is not.
Promising directions for future work are joint
parsing and reordering models, and measuring the
influence of parsing accuracy on preordering and fi-
nal translation quality.
</bodyText>
<sectionHeader confidence="0.997994" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998254214285714">
A. Abeill´e, L. Cl´ement, and F. Toussenel. 2003. Build-
ing a Treebank for French. In A. Abeill´e, editor, Tree-
banks: Building and Using Parsed Corpora, chap-
ter 10. Kluwer.
P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della
Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and
P. S. Roossin. 1990. A statistical approach to machine
translation. Computational Linguistics, 16(2).
P. F. Brown, V. J. Della Pietra, S. A. Della Pietra, and
R. L. Mercer. 1993. The mathematics of statistical
machine translation: Parameter estimation. Computa-
tional Linguistics, 19.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proc. of
CoNLL ’06.
C. Callison-Burch, P. Koehn, C. Monz, K. Peterson,
M. Przybocki, and O. Zaidan. 2010. Findings of
the 2010 joint workshop on statistical machine trans-
lation and metrics for machine translation. In Proc. of
ACL’05 WMT.
M. Collins, P. Koehn, and I. Kuˇcerov´a. 2005. Clause re-
structuring for statistical machine translation. In Proc.
of ACL ’05.
M. Collins. 1997. Three generative, lexicalised models
for statistical parsing. In ACL ’97.
M.-C. de Marneffe, B. MacCartney, and C. Manning.
2006. Generating typed dependency parses from
phrase structure parses. In Proc. of LREC ’06.
</reference>
<page confidence="0.97146">
522
</page>
<reference confidence="0.999528252336449">
J. DeNero and J. Uszkoreit. 2011. Inducing sentence
structure from parallel corpora for reordering. In Proc.
of EMNLP ’11.
J. Duchi and Y. Singer. 2009. Boosting with structural
sparsity. In Proc. of ICML ’09.
C. Dyer and P. Resnik. 2010. Context-free reordering,
finite-state translation. In Proc. of NAACL-HLT ’10.
M. Galley, M. Hopkins, K. Knight, and D. Marcu. 2004.
What’s in a translation rule? In Proc. of NAACL-HLT
’04.
D. Genzel. 2010. Automatically learning source-side re-
ordering rules for large scale machine translation. In
Proc. of COLING ’10.
N. Habash. 2007. Syntactic preprocessing for statistical
machine translation. In Proc. of MTS ’07.
L. Huang, K. Knight, and A. Joshi. 2006. Statistical
syntax-directed translation with extended domain of
locality. In Proc. of AMTA ’06.
J. Judge, A. Cahill, and J. v. Genabith. 2006. Question-
Bank: creating a corpus of parse-annotated questions.
In Proc. of ACL ’06.
P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical
phrase based translation. In Proc. of NAACL-HLT ’03.
T. Koo, X. Carreras, and M. Collins. 2008. Simple semi-
supervised dependency parsing. In Proc. of ACL-HLT
’08.
S. Kumar, W. Macherey, C. Dyer, and F. Och. 2009. Effi-
cient minimum error rate training and minimum bayes-
risk decoding for translation hypergraphs and lattices.
In Proc. of ACL ’09.
J. Lafferty, A. McCallum, and F. Pereira. 2001. Con-
ditional Random Fields: Probabilistic models for seg-
menting and labeling sequence data. In Proc. of ICML
’01.
C. H. Li, M. Li, D. Zhang, M. Li, M. Zhou, and Y. Guan.
2007. A Probabilistic Approach to Syntax-based Re-
ordering for Statistical Machine Translation. In Proc.
of ACL ’07.
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993.
Building a large annotated corpus of English: The
Penn Treebank. In Computational Linguistics.
R. McDonald, J. Nivre, Y. Quirmbach-Brundagez,
Y. Goldberg, D. Das, K. Ganchev, K. Hall, S. Petrov,
H. Zhang, O. T¨ackstr¨om, C. Bedini, N. Bertomeu
Castell´o, and J. Lee. 2013. Universal dependency an-
notation for multilingual parsing. In Proc. ofACL ’13.
G. Neubig, T. Watanabe, and S. Mori. 2012. Inducing a
discriminative parser to optimize machine translation
reordering. In Proc. of EMNLP-CoNLL ’12.
J. Nivre and J. Nilsson. 2005. Pseudo-projective depen-
dency parsing. In Proc. of ACL ’05.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The CoNLL 2007
shared task on dependency parsing. In Proc. EMNLP-
CoNLL ’07.
F. J. Och and H. Ney. 2004. The alignment template
approach to statistical machine translation. Computa-
tional Linguistics, 30(4).
K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002.
BLEU: a method for automatic evaluation of machine
translation. In Proc. of ACL ’02.
S. Petrov and R. McDonald. 2012. Overview of the 2012
shared task on parsing the web. In Proc. of NAACL ’12
SANCL.
S. Petrov, D. Das, and R. McDonald. 2012. A universal
part-of-speech tagset. In Proc. of LREC ’12.
D. Talbot, H. Kazawa, H. Ichikawa, J. Katz-Brown,
M. Seno, and F. Och. 2011. A lightweight evalua-
tion framework for machine translation reordering. In
Proc. of EMNLP ’11 WMT.
C. Tillmann. 2004. A unigram orientation model for sta-
tistical machine translation. In Proc. of NAACL-HLT
’04.
R. Tromble and J. Eisner. 2009. Learning linear ordering
problems for better translation. In Proc. of EMNLP
’09.
J. Uszkoreit and T. Brants. 2008. Distributed word clus-
tering for large scale class-based language modeling in
machine translation. In Proc. of ACL-HLT ’08.
S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based
word alignment in statistical translation. In In Proc. of
COLING ’96.
C. Wang, M. Collins, and P. Koehn. 2007. Chinese syn-
tactic reordering for statistical machine translation. In
Proc. of EMNLP-CoNLL ’07.
X. Wu, K. Sudoh, K. Duh, H. Tsukada, and M. Nagata.
2011. Extracting pre-ordering rules from predicate-
argument structures. In Proc. of IJCNLP ’11.
F. Xia and M. McCord. 2004. Improving a statistical MT
system with automatically learned rewrite patterns. In
Proc. of COLING ’04.
P. Xu, J. Kang, M. Ringgaard, and F. Och. 2009. Using a
dependency parser to improve SMT for subject-object-
verb languages. In Proc. of NAACL-HLT ’09.
K. Yamada and K. Knight. 2001. A syntax-based statis-
tical translation model. In Proc. of ACL ’01.
N. Yang, M. Li, D. Zhang, and N. Yu. 2012. A ranking-
based approach to word reordering for statistical ma-
chine translation. In Proc. of ACL ’12.
R. Zens and H. Ney. 2006. Discriminative reordering
models for statistical machine translation. In Proc. of
NAACL ’06 WMT.
Y. Zhang and J. Nivre. 2011. Transition-based depen-
dency parsing with rich non-local features. In Proc. of
ACL-HLT ’11.
H. Zhang, L. Fang, P. Xu, and X. Wu. 2011. Binarized
forest to string translation. In Proc. of ACL-HLT ’11.
</reference>
<page confidence="0.99893">
523
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.877354">
<title confidence="0.999769">Source-Side Classifier Preordering for Machine Translation</title>
<author confidence="0.999243">Uri Lerner Slav Petrov</author>
<affiliation confidence="0.999897">Google Inc. Google Inc.</affiliation>
<address confidence="0.999669">Mountain View, CA, USA New York, NY, USA</address>
<email confidence="0.998871">uri@google.comslav@google.com</email>
<abstract confidence="0.9938981">We present a simple and novel classifier-based preordering approach. Unlike existing preordering models, we train feature-rich discriminative classifiers that directly predict the target-side word order. Our approach combines the strengths of lexical reordering and syntactic preordering models by performing long-distance reorderings using the structure of the parse tree, while utilizing a discriminative model with a rich set of features, including lexical features. We present extensive experiments on 22 language pairs, including preordering into English from 7 other languages. We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared For languages from families the improvements often exceed 2 BLEU. Many of these gains are also significant in human evaluations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeill´e</author>
<author>L Cl´ement</author>
<author>F Toussenel</author>
</authors>
<title>Building a Treebank for French. In</title>
<date>2003</date>
<booktitle>Treebanks: Building and Using Parsed Corpora, chapter 10.</booktitle>
<editor>A. Abeill´e, editor,</editor>
<publisher>Kluwer.</publisher>
<marker>Abeill´e, Cl´ement, Toussenel, 2003</marker>
<rawString>A. Abeill´e, L. Cl´ement, and F. Toussenel. 2003. Building a Treebank for French. In A. Abeill´e, editor, Treebanks: Building and Using Parsed Corpora, chapter 10. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J Cocke</author>
<author>S A Della Pietra</author>
<author>V J Della Pietra</author>
<author>F Jelinek</author>
<author>J D Lafferty</author>
<author>R L Mercer</author>
<author>P S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="1191" citStr="Brown et al. (1990)" startWordPosition="178" endWordPosition="181">zing a discriminative model with a rich set of features, including lexical features. We present extensive experiments on 22 language pairs, including preordering into English from 7 other languages. We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task. For languages from different families the improvements often exceed 2 BLEU. Many of these gains are also significant in human evaluations. 1 Introduction Generating the appropriate word order for the target language has been one of the fundamental problems in machine translation since the ground setting work of Brown et al. (1990). Lexical reordering approaches (Tillmann, 2004; Zens and Ney, 2006) add a reordering component to standard phrase-based translation systems (Och and Ney, 2004). Because the reordering model is trained discriminatively, it can use a rich set of lexical features. However, it only has access to the local context which often times is insufficient to make the long-distance reordering decisions that are necessary for language pairs with significantly different word order. Preordering (sometimes called pre-reordering or simply reordering) approaches (Xia and McCord, 2004; Collins et al., 2005) prepr</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>P. F. Brown, J. Cocke, S. A. Della Pietra, V. J. Della Pietra, F. Jelinek, J. D. Lafferty, R. L. Mercer, and P. S. Roossin. 1990. A statistical approach to machine translation. Computational Linguistics, 16(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>V J Della Pietra</author>
<author>S A Della Pietra</author>
<author>R L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<contexts>
<context position="18355" citStr="Brown et al., 1993" startWordPosition="3072" endWordPosition="3075">tional complexity of the learning algorithm and the incremental nature in which the rules are learned and applied. 3.1 WMT Setup In our first set of experiments, we use the data provided for the WMT 2010 shared task (CallisonBurch et al., 2010). We build systems for all language pairs: English to and from Czech, French, German, and Spanish. Since this is a publicly available dataset, it is easy to compare our results to other submissions to the shared task. During word alignment, we filter out sentences exceeding 60 words in the parallel texts and perform 6 iterations of IBM Model-1 training (Brown et al., 1993), followed by 6 iterations of HMM training (Vogel et al., 1996). We do not use Model-4 because it is slow and did not add much value to our systems in a pilot study. Standard phrase extraction heuristics (Koehn et al., 2003) are applied to extract phrase pairs with a length limit of 6 from alignments symmetrized with the “union” heuristic. Maximum jump width is set to 8. Rule extraction for the forestto-string system is limited to 16 rules per tree node. There are no length-based reordering constraints in the forest-to-string system. We train two 5-gram language models with Kneser-Ney smoothin</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>P. F. Brown, V. J. Della Pietra, S. A. Della Pietra, and R. L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computational Linguistics, 19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of CoNLL ’06.</booktitle>
<contexts>
<context position="23707" citStr="Buchholz and Marsi (2006)" startWordPosition="3954" endWordPosition="3957">in turn. We only include the results UAS LAS POS en: English1 92.28 90.28 97.05 cs: Czech2 84.66 72.01 98.97 de: German3 89.30 86.98 97.69 es: Spanish4 86.24 82.32 96.62 fr: French5 88.57 86.40 97.48 hu: Hungarian2 87.66 82.51 94.47 nl: Dutch3 86.09 82.31 97.38 pt: Portuguese4 90.22 87.26 98.10 Table 1: Parsing accuracies on the retokenized treebanks. UAS is unlabeled attachment score, LAS is labeled attachment score, and POS is part-of-speech tagging accuracy. The treebank sources are (1): Marcus et al. (1993) + Judge et al. (2006) + Petrov and McDonald (2012), (2): Nivre et al. (2007), (3): Buchholz and Marsi (2006), (4): McDonald et al. (2013), (5): Abeill´e et al. (2003). from the forest-to-string system when they are better than the phrase-based results. We use * to denote results from the forest-to-string system. 4.1 WMT Experiments Table 2 presents detailed results on the WMT setup. Lexical reordering (Zens and Ney, 2006) never hurts and is thus included in all systems. Overall, our results are a little better than the best results of the WMT 2010 shared task for two language pairs and within reach of the best results in most other cases. The 2-step classifier preordering approach provides statistic</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Callison-Burch</author>
<author>P Koehn</author>
<author>C Monz</author>
<author>K Peterson</author>
<author>M Przybocki</author>
<author>O Zaidan</author>
</authors>
<title>Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation.</title>
<date>2010</date>
<booktitle>In Proc. of ACL’05 WMT.</booktitle>
<marker>Callison-Burch, Koehn, Monz, Peterson, Przybocki, Zaidan, 2010</marker>
<rawString>C. Callison-Burch, P. Koehn, C. Monz, K. Peterson, M. Przybocki, and O. Zaidan. 2010. Findings of the 2010 joint workshop on statistical machine translation and metrics for machine translation. In Proc. of ACL’05 WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>P Koehn</author>
<author>I Kuˇcerov´a</author>
</authors>
<title>Clause restructuring for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proc. of ACL ’05.</booktitle>
<marker>Collins, Koehn, Kuˇcerov´a, 2005</marker>
<rawString>M. Collins, P. Koehn, and I. Kuˇcerov´a. 2005. Clause restructuring for statistical machine translation. In Proc. of ACL ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Three generative, lexicalised models for statistical parsing.</title>
<date>1997</date>
<booktitle>In ACL ’97.</booktitle>
<contexts>
<context position="14140" citStr="Collins (1997)" startWordPosition="2330" endWordPosition="2331">er number of children, but these classifiers may not have enough relevant examples. 2.4 2-Step Classifier Our 2-step approach addresses the exponential blowup of the number of children by decomposing the prediction into two steps: 1. For every child, decide whether it should appear before or after the head. 2. Determine the order of the children that appear before the head and the order of the children after the head. The two steps make the reordering of the modifiers before and after the head independent of each other, which is reminiscent of the lexicalized parse tree generation approach of Collins (1997). In the running example, for the head “climbed” we might first make the following three binary decisions: the word “cat” should appear before the head and the words “to” and “.” should appear after the head. In the second step there is only one word before the head so there is nothing to do. There are two words after the head, so we use another classifier to determine their order. The first step is implemented using a binary classifier, called the pivot classifier (since the head functions like the pivot in quicksort). The second step classifiers directly predict the correct permutation of th</context>
</contexts>
<marker>Collins, 1997</marker>
<rawString>M. Collins. 1997. Three generative, lexicalised models for statistical parsing. In ACL ’97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M-C de Marneffe</author>
<author>B MacCartney</author>
<author>C Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proc. of LREC ’06.</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>M.-C. de Marneffe, B. MacCartney, and C. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proc. of LREC ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J DeNero</author>
<author>J Uszkoreit</author>
</authors>
<title>Inducing sentence structure from parallel corpora for reordering.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP ’11.</booktitle>
<contexts>
<context position="2386" citStr="DeNero and Uszkoreit, 2011" startWordPosition="366" endWordPosition="370">04; Collins et al., 2005) preprocess the input in such a way that the words on the source side appear closer to their final positions on the target side. Because preordering is performed prior to word alignment, it can improve the alignment process and can then be combined with any subsequent translation model. Most preordering models use a source-side syntactic parser and perform a series of tree transformations. Approaches that do not use a parser exist as well and typically induce a hierarchical representation that also allows them to perform longdistance changes (Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Neubig et al., 2012). Models that use a source-side parser differ on two main dimensions: the way tree transformations are expressed, and whether they are built manually or learned from data. One common type of tree transformation are rewrite rules. These typically involve some condition under which the transformation can be applied (e.g., a noun and an adjective found in the same clause) and the transformation itself (e.g., move the adjective after the noun). These rules can be designed manually (Collins et al., 2005; Wang et al., 2007) or learned from data (Xia and McCord, 2004; Habash, 20</context>
</contexts>
<marker>DeNero, Uszkoreit, 2011</marker>
<rawString>J. DeNero and J. Uszkoreit. 2011. Inducing sentence structure from parallel corpora for reordering. In Proc. of EMNLP ’11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Duchi</author>
<author>Y Singer</author>
</authors>
<title>Boosting with structural sparsity.</title>
<date>2009</date>
<booktitle>In Proc. of ICML ’09.</booktitle>
<contexts>
<context position="8122" citStr="Duchi and Singer, 2009" startWordPosition="1307" endWordPosition="1310">d” and the children “cat”, “to”, and “.”. 2.1 Classification Model &amp; Features The reordering decisions are made by multi-class classifiers where class labels correspond to permutation sequences. We train a separate classifier for each number of possible children. Crucially, we do not learn explicit tree transformations rules, but let the classifiers learn to trade off between a rich set of overlapping features. 514 Obviously, it is possible to use any classification model and learning algorithm. We use maximum entropy classifiers with l1/l� regularization trained with the GradBoost algorithm (Duchi and Singer, 2009). We chose this setup since it naturally supports multi-class prediction and can therefore be used to select one out of many possible permutations. Additionally, the learning algorithm produces a sparse set of features. In our experiments the final models have typically only a few 100K non-zero feature weights per language pair. Given this relatively small number of features, it is possible to manually inspect the feature weights and gain insights into the behavior of the model. We show an example analysis in Section 5. Our features encode information about the context in which a word occurs i</context>
</contexts>
<marker>Duchi, Singer, 2009</marker>
<rawString>J. Duchi and Y. Singer. 2009. Boosting with structural sparsity. In Proc. of ICML ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Dyer</author>
<author>P Resnik</author>
</authors>
<title>Context-free reordering, finite-state translation.</title>
<date>2010</date>
<booktitle>In Proc. of NAACL-HLT ’10.</booktitle>
<contexts>
<context position="36984" citStr="Dyer and Resnik, 2010" startWordPosition="6135" endWordPosition="6138">ing gains of up to 1.4 BLEU over a state-of-the-art system. We also show gains of up to 0.5 BLEU over a strong directly comparable preordering system that is based on learning unlexicalized reordering rules. We obtain improvements of more than 2 BLEU in experiments on additional languages. The gains are especially large for languages where the sentence structure is very different from English. These positive results are confirmed in human side-by-side evaluations. When comparing our approach to syntax-based translation systems (Yamada and Knight, 2001; Galley et al., 2004; Huang et al., 2006; Dyer and Resnik, 2010) we note that both approaches use syntactic information for reordering decisions. Our preordering approach has several advantages. First, be521 ROOT It was a real whirlwind . NN VBD DT JJ NN . NOUN VERB DET ADJ NOUN . Figure 2: An example where lexical information is necessary for choosing the correct word order. cause preordering is performed before learning word alignments, it has the potential to improve the word alignments. Second, by using discriminative classifiers we can take advantage of lexical features. Finally, preordering can be combined with syntaxbased translation models and our </context>
</contexts>
<marker>Dyer, Resnik, 2010</marker>
<rawString>C. Dyer and P. Resnik. 2010. Context-free reordering, finite-state translation. In Proc. of NAACL-HLT ’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Galley</author>
<author>M Hopkins</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>What’s in a translation rule?</title>
<date>2004</date>
<booktitle>In Proc. of NAACL-HLT ’04.</booktitle>
<contexts>
<context position="36940" citStr="Galley et al., 2004" startWordPosition="6126" endWordPosition="6130"> on the WMT 2010 shared task data, observing gains of up to 1.4 BLEU over a state-of-the-art system. We also show gains of up to 0.5 BLEU over a strong directly comparable preordering system that is based on learning unlexicalized reordering rules. We obtain improvements of more than 2 BLEU in experiments on additional languages. The gains are especially large for languages where the sentence structure is very different from English. These positive results are confirmed in human side-by-side evaluations. When comparing our approach to syntax-based translation systems (Yamada and Knight, 2001; Galley et al., 2004; Huang et al., 2006; Dyer and Resnik, 2010) we note that both approaches use syntactic information for reordering decisions. Our preordering approach has several advantages. First, be521 ROOT It was a real whirlwind . NN VBD DT JJ NN . NOUN VERB DET ADJ NOUN . Figure 2: An example where lexical information is necessary for choosing the correct word order. cause preordering is performed before learning word alignments, it has the potential to improve the word alignments. Second, by using discriminative classifiers we can take advantage of lexical features. Finally, preordering can be combined </context>
</contexts>
<marker>Galley, Hopkins, Knight, Marcu, 2004</marker>
<rawString>M. Galley, M. Hopkins, K. Knight, and D. Marcu. 2004. What’s in a translation rule? In Proc. of NAACL-HLT ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Genzel</author>
</authors>
<title>Automatically learning source-side reordering rules for large scale machine translation.</title>
<date>2010</date>
<booktitle>In Proc. of COLING ’10.</booktitle>
<contexts>
<context position="3002" citStr="Genzel, 2010" startWordPosition="470" endWordPosition="471">ubig et al., 2012). Models that use a source-side parser differ on two main dimensions: the way tree transformations are expressed, and whether they are built manually or learned from data. One common type of tree transformation are rewrite rules. These typically involve some condition under which the transformation can be applied (e.g., a noun and an adjective found in the same clause) and the transformation itself (e.g., move the adjective after the noun). These rules can be designed manually (Collins et al., 2005; Wang et al., 2007) or learned from data (Xia and McCord, 2004; Habash, 2007; Genzel, 2010; Wu et al., 2011). Another type of tree transformations uses ranking functions to implement precedence-based reordering. Here, a function assigns a numerical value to every word in a clause, intended to express the precedence of the word in the target language. The reordering operation is then to sort the words according to their assigned values. The ranking function 513 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 513–523, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics can be designed manually (X</context>
<context position="17339" citStr="Genzel (2010)" startWordPosition="2899" endWordPosition="2900">hresholds, there was no good reason to do so. There were very few cases where children were not reordered because of these thresholds, many of them corresponded to bad parses, and they had very little impact on the final scores. Thus, for the 1-step approach we had 6 classifiers: 1 binary classifier for a head and a single child and 5 multi-class classifiers for 3–7 words. For the 2-step approach we had 11 classifiers: 1 pivot classifier, 5 classifiers for words before the head, and 5 for words after the head. For a direct comparison to a strong preordering system, we compare to the system of Genzel (2010), which learns a set of unlexicalized reordering rules from automatically aligned data by minimizing the number of crossing alignments. We used a sliding window of size 3 and tried all three of their variants. There were about 40-50 rules per language pair. While conceptually possible, it is not practical to learn more rules (including lexicalized rules) with this system, because of the computational complexity of the learning algorithm and the incremental nature in which the rules are learned and applied. 3.1 WMT Setup In our first set of experiments, we use the data provided for the WMT 2010</context>
<context position="25928" citStr="Genzel (2010)" startWordPosition="4308" endWordPosition="4309"> en-es 27.4 27.8° 28.4° 29.0 28.8&apos;&apos; 28.6 en-es* 28.9 - 28.7 29.0 29.2 28.6 en-fr 26.3 26.5° 26.8° 27.2 27.3&apos;° 27.6 cs-en 21.6 21.6 21.5 21.6 21.7 21.9 de-en 20.6 21.1° 21.9 21.9 21.8&apos; 22.8 de-en* 22.1 - 22.5 22.5 22.7 22.8 es-en 28.3 28.7 28.7 28.8 28.9 28.8 fr-en 26.8 27.0 26.9 26.9 27.0 28.3 Table 2: BLEU scores on the WMT 2010 setup. Results from the forest-to-string system are marked with * and are only included when better than the phrase-based results. The base system includes a distance distortion model; the lexical system adds lexical reordering; rule is the rule preordering system of Genzel (2010) plus lexical reordering; 1-step and 2-step are our classifier-based systems plus lexical reordering. Bolded results are statistically significantly better than non-bolded results as measured by a bootstrap sample test with a 99% confidence interval. Human evals are conducted only where indicated; we use&apos; and&apos; to indicate a significantly better result than ° and ° in the human eval at 95%. Also included are the best results from the WMT 2010 task. Compared to a state-of-the-art preordering system, the automatic rule extraction system of Genzel (2010), we observe significant gains in several ca</context>
<context position="29917" citStr="Genzel (2010)" startWordPosition="4970" endWordPosition="4971">.3p en-ja 10.4 16.4 17.5p 18.0♣ en-ja* 14.9 18.0 18.2p 18.6♣ en-ko 24.1 31.8 31.8p 32.7♣ en-ms 20.4 22.5 22.9 22.9 Table 3: BLEU scores for language from various language families: Arabic (ar), Welsh (cy), Irish (ga), Indonesian (id), Hebrew (iw), Japanese (ja), Korean (ko), and Malay (ms). Lexical reordering is not included in any of the systems. Bolded results are significant at 99%. ♣ is significantly better than p in a human eval at 95%. the 1-step system. The human judgments exactly agree with the results of the BLEU significance tests. The gains relative to the rule reordering system of Genzel (2010) and the no-preordering baseline are even larger and therefore clearly also significant. In Table 4 we show results for Hungarian (hu), Dutch (nl), and Portuguese (pt). In all cases but English-Hungarian we observe significant improvements over the no preordering baseline. It should be noted that the gains are not symmetric – sometimes there are larger gains for translating out of English, while for Hungarian the gains are higher for translating into English. Hungarian has a free word order which is difficult to predict which might partially explain why there are no improvements for translatin</context>
<context position="33714" citStr="Genzel, 2010" startWordPosition="5601" endWordPosition="5602">. 520 no reordering manual automatic fuzzy exact BLEU fuzzy exact BLEU fuzzy exact BLEU en-ar 63.2 19.8 11.4 83.5 47.6 12.4 79.0 38.9 12.6 en-iw 67.9 22.2 18.8 89.8 62.4 20.3 89.2 61.2 20.2 en-ja* 44.1 0.0 14.9 80.9 41.5 18.4 78.5 36.8 18.6 Table 5: Preordering accuracy for the 2-step classifiers using manual alignments vs. automatic alignments. Fuzzy refers to the metric defined in Talbot et al. (2011) and exact is the percentage of sentences with a perfect preordering. taken from the WMT test set. The dependency parse tree is shown in Figure 2. In our experiments the rule-based approach of (Genzel, 2010) reordered the source sentence into: It was a whirlwind real. and produced the translation: Es un torbellino real. In comparison, our 2-step system kept the English sentence unchanged and produced the translation: Fue un aut´entico torbellino. The second translation is better than the first because of the correct tense (which is not related directly to the preordering) and because the noun phrase “real whirlwind” is ordered correctly. The main reason for the difference in the ordering is that the rule-based system can only use the unlexicalized information from the parse tree. The head “whirlw</context>
<context position="38624" citStr="Genzel, 2010" startWordPosition="6409" endWordPosition="6411">n limit ourselves to the K most popular permutations. On the other hand, our approach provides important advantages. Compared to systems that use rewrite rules, it is much easier to encode useful knowledge that by itself is not enough to determine a full rewrite rule, such as “a determiner is unlikely to be the last word in a clause.” Perhaps more importantly, our model provides an elegant answer to the question of what to do when multiple rewrite rules can be applied. Previous work has employed different heuristics: use the most specific rule (Xia and McCord, 2004), use all applicable rules (Genzel, 2010), or use the most frequent rule (Wu et al., 2011). In our model there is no need for such heuristics – all the “rules” are treated as features to a discriminative classifier, and the task of analyzing their interactions is handled by the learning algorithm. Compared to preordering systems that use ranking functions, our model has the advantage that it can encode information about the complete permutation. For example, for three source words A, B, and C, we can naturally express the useful prior that Feature Weight PrevChild:tag=JJ,PrevSibling:a 0.448 PrevChild:cat=ADJ,PrevSibling:a 0.292 PrevC</context>
</contexts>
<marker>Genzel, 2010</marker>
<rawString>D. Genzel. 2010. Automatically learning source-side reordering rules for large scale machine translation. In Proc. of COLING ’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Habash</author>
</authors>
<title>Syntactic preprocessing for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of MTS ’07.</booktitle>
<contexts>
<context position="2988" citStr="Habash, 2007" startWordPosition="468" endWordPosition="469">reit, 2011; Neubig et al., 2012). Models that use a source-side parser differ on two main dimensions: the way tree transformations are expressed, and whether they are built manually or learned from data. One common type of tree transformation are rewrite rules. These typically involve some condition under which the transformation can be applied (e.g., a noun and an adjective found in the same clause) and the transformation itself (e.g., move the adjective after the noun). These rules can be designed manually (Collins et al., 2005; Wang et al., 2007) or learned from data (Xia and McCord, 2004; Habash, 2007; Genzel, 2010; Wu et al., 2011). Another type of tree transformations uses ranking functions to implement precedence-based reordering. Here, a function assigns a numerical value to every word in a clause, intended to express the precedence of the word in the target language. The reordering operation is then to sort the words according to their assigned values. The ranking function 513 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 513–523, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics can be design</context>
</contexts>
<marker>Habash, 2007</marker>
<rawString>N. Habash. 2007. Syntactic preprocessing for statistical machine translation. In Proc. of MTS ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Huang</author>
<author>K Knight</author>
<author>A Joshi</author>
</authors>
<title>Statistical syntax-directed translation with extended domain of locality.</title>
<date>2006</date>
<booktitle>In Proc. of AMTA ’06.</booktitle>
<contexts>
<context position="36960" citStr="Huang et al., 2006" startWordPosition="6131" endWordPosition="6134">ed task data, observing gains of up to 1.4 BLEU over a state-of-the-art system. We also show gains of up to 0.5 BLEU over a strong directly comparable preordering system that is based on learning unlexicalized reordering rules. We obtain improvements of more than 2 BLEU in experiments on additional languages. The gains are especially large for languages where the sentence structure is very different from English. These positive results are confirmed in human side-by-side evaluations. When comparing our approach to syntax-based translation systems (Yamada and Knight, 2001; Galley et al., 2004; Huang et al., 2006; Dyer and Resnik, 2010) we note that both approaches use syntactic information for reordering decisions. Our preordering approach has several advantages. First, be521 ROOT It was a real whirlwind . NN VBD DT JJ NN . NOUN VERB DET ADJ NOUN . Figure 2: An example where lexical information is necessary for choosing the correct word order. cause preordering is performed before learning word alignments, it has the potential to improve the word alignments. Second, by using discriminative classifiers we can take advantage of lexical features. Finally, preordering can be combined with syntaxbased tra</context>
</contexts>
<marker>Huang, Knight, Joshi, 2006</marker>
<rawString>L. Huang, K. Knight, and A. Joshi. 2006. Statistical syntax-directed translation with extended domain of locality. In Proc. of AMTA ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Judge</author>
<author>A Cahill</author>
<author>J v Genabith</author>
</authors>
<title>QuestionBank: creating a corpus of parse-annotated questions.</title>
<date>2006</date>
<booktitle>In Proc. of ACL ’06.</booktitle>
<contexts>
<context position="23620" citStr="Judge et al. (2006)" startWordPosition="3939" endWordPosition="3942">iments and language pairs we divide the experiments into groups and discuss each in turn. We only include the results UAS LAS POS en: English1 92.28 90.28 97.05 cs: Czech2 84.66 72.01 98.97 de: German3 89.30 86.98 97.69 es: Spanish4 86.24 82.32 96.62 fr: French5 88.57 86.40 97.48 hu: Hungarian2 87.66 82.51 94.47 nl: Dutch3 86.09 82.31 97.38 pt: Portuguese4 90.22 87.26 98.10 Table 1: Parsing accuracies on the retokenized treebanks. UAS is unlabeled attachment score, LAS is labeled attachment score, and POS is part-of-speech tagging accuracy. The treebank sources are (1): Marcus et al. (1993) + Judge et al. (2006) + Petrov and McDonald (2012), (2): Nivre et al. (2007), (3): Buchholz and Marsi (2006), (4): McDonald et al. (2013), (5): Abeill´e et al. (2003). from the forest-to-string system when they are better than the phrase-based results. We use * to denote results from the forest-to-string system. 4.1 WMT Experiments Table 2 presents detailed results on the WMT setup. Lexical reordering (Zens and Ney, 2006) never hurts and is thus included in all systems. Overall, our results are a little better than the best results of the WMT 2010 shared task for two language pairs and within reach of the best res</context>
</contexts>
<marker>Judge, Cahill, Genabith, 2006</marker>
<rawString>J. Judge, A. Cahill, and J. v. Genabith. 2006. QuestionBank: creating a corpus of parse-annotated questions. In Proc. of ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>F J Och</author>
<author>D Marcu</author>
</authors>
<title>Statistical phrase based translation.</title>
<date>2003</date>
<booktitle>In Proc. of NAACL-HLT ’03.</booktitle>
<contexts>
<context position="18579" citStr="Koehn et al., 2003" startWordPosition="3114" endWordPosition="3117">nBurch et al., 2010). We build systems for all language pairs: English to and from Czech, French, German, and Spanish. Since this is a publicly available dataset, it is easy to compare our results to other submissions to the shared task. During word alignment, we filter out sentences exceeding 60 words in the parallel texts and perform 6 iterations of IBM Model-1 training (Brown et al., 1993), followed by 6 iterations of HMM training (Vogel et al., 1996). We do not use Model-4 because it is slow and did not add much value to our systems in a pilot study. Standard phrase extraction heuristics (Koehn et al., 2003) are applied to extract phrase pairs with a length limit of 6 from alignments symmetrized with the “union” heuristic. Maximum jump width is set to 8. Rule extraction for the forestto-string system is limited to 16 rules per tree node. There are no length-based reordering constraints in the forest-to-string system. We train two 5-gram language models with Kneser-Ney smoothing for each of the target languages. One is trained on the target side of the parallel text, the other on a news corpus provided by the shared task. We tune the feature weights for every configuration with 10 rounds of hyperg</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>P. Koehn, F. J. Och, and D. Marcu. 2003. Statistical phrase based translation. In Proc. of NAACL-HLT ’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Koo</author>
<author>X Carreras</author>
<author>M Collins</author>
</authors>
<title>Simple semisupervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proc. of ACL-HLT ’08.</booktitle>
<contexts>
<context position="22868" citStr="Koo et al., 2008" startWordPosition="3814" endWordPosition="3817">ot comparable to other numbers in the literature. When necessary, we projectivize the treebanks by raising arcs until the tree becomes projective, as described in Nivre and Nilsson (2005); we do not reconstruct non-projective arcs at parsing time, since our subsequent systems expect projective trees. Our part-of-speech tagger is a conditional random field model (Lafferty et al., 2001) with simple wordidentity and affix features. The parsing model is a shift-reduce dependency parser, using the higherorder features from Zhang and Nivre (2011). Additionally, we include 256 word-cluster features (Koo et al., 2008) trained on a large amount of unlabeled monolingual text (Uszkoreit and Brants, 2008). 4 Experiments Due to the large number of experiments and language pairs we divide the experiments into groups and discuss each in turn. We only include the results UAS LAS POS en: English1 92.28 90.28 97.05 cs: Czech2 84.66 72.01 98.97 de: German3 89.30 86.98 97.69 es: Spanish4 86.24 82.32 96.62 fr: French5 88.57 86.40 97.48 hu: Hungarian2 87.66 82.51 94.47 nl: Dutch3 86.09 82.31 97.38 pt: Portuguese4 90.22 87.26 98.10 Table 1: Parsing accuracies on the retokenized treebanks. UAS is unlabeled attachment scor</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>T. Koo, X. Carreras, and M. Collins. 2008. Simple semisupervised dependency parsing. In Proc. of ACL-HLT ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kumar</author>
<author>W Macherey</author>
<author>C Dyer</author>
<author>F Och</author>
</authors>
<title>Efficient minimum error rate training and minimum bayesrisk decoding for translation hypergraphs and lattices.</title>
<date>2009</date>
<booktitle>In Proc. of ACL ’09.</booktitle>
<contexts>
<context position="19245" citStr="Kumar et al., 2009" startWordPosition="3228" endWordPosition="3231">gth limit of 6 from alignments symmetrized with the “union” heuristic. Maximum jump width is set to 8. Rule extraction for the forestto-string system is limited to 16 rules per tree node. There are no length-based reordering constraints in the forest-to-string system. We train two 5-gram language models with Kneser-Ney smoothing for each of the target languages. One is trained on the target side of the parallel text, the other on a news corpus provided by the shared task. We tune the feature weights for every configuration with 10 rounds of hypergraph-based Minimum Error Rate Training (MERT) (Kumar et al., 2009). 3.2 Additional Languages In our second set of experiments, we explore the impact of classifier preordering for a number of languages with different word orders. Some of the languages included in our study are verb-subject-object (VSO) languages (Arabic, Irish, Welsh), subjectobject-verb (SOV) languages (Japanese, Korean), and fairly free word order languages (Dutch, Hungarian). Where a parser is available, we also conduct experiments on translating into English. Since there are no standard training sets for many of these language pairs, we use parallel data automatically mined from the web. </context>
</contexts>
<marker>Kumar, Macherey, Dyer, Och, 2009</marker>
<rawString>S. Kumar, W. Macherey, C. Dyer, and F. Och. 2009. Efficient minimum error rate training and minimum bayesrisk decoding for translation hypergraphs and lattices. In Proc. of ACL ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proc. of ICML ’01.</booktitle>
<contexts>
<context position="22638" citStr="Lafferty et al., 2001" startWordPosition="3778" endWordPosition="3781">ne of the bitext. Our heuristics can split treebank tokens but do not merge treebank tokens. We found that adjusting the treebank tokenization is crucial for obtaining good results. However, this makes the reported parsing accuracies not comparable to other numbers in the literature. When necessary, we projectivize the treebanks by raising arcs until the tree becomes projective, as described in Nivre and Nilsson (2005); we do not reconstruct non-projective arcs at parsing time, since our subsequent systems expect projective trees. Our part-of-speech tagger is a conditional random field model (Lafferty et al., 2001) with simple wordidentity and affix features. The parsing model is a shift-reduce dependency parser, using the higherorder features from Zhang and Nivre (2011). Additionally, we include 256 word-cluster features (Koo et al., 2008) trained on a large amount of unlabeled monolingual text (Uszkoreit and Brants, 2008). 4 Experiments Due to the large number of experiments and language pairs we divide the experiments into groups and discuss each in turn. We only include the results UAS LAS POS en: English1 92.28 90.28 97.05 cs: Czech2 84.66 72.01 98.97 de: German3 89.30 86.98 97.69 es: Spanish4 86.2</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional Random Fields: Probabilistic models for segmenting and labeling sequence data. In Proc. of ICML ’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Li</author>
<author>M Li</author>
<author>D Zhang</author>
<author>M Li</author>
<author>M Zhou</author>
<author>Y Guan</author>
</authors>
<title>A Probabilistic Approach to Syntax-based Reordering for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>In Proc. of ACL ’07.</booktitle>
<contexts>
<context position="4404" citStr="Li et al. (2007)" startWordPosition="691" endWordPosition="694">ed preordering model. Our model operates over dependency parse trees and is therefore able to perform long-distance reordering decisions, as is typical for preordering models. But instead of deterministic rules or ranking functions, we use discriminative classifiers to directly predict the final word order, using rich (bi-)lexical and syntactic features. We present two models. The first model uses a classifier to directly predict the permutation order in which a family of words (a head word and all its children) will appear on the target side. This approach is similar in spirit to the work of Li et al. (2007), except that they use constituency parse trees and consider only nodes with 2 or 3 children. We instead work with dependency trees and consider much larger head-children sets. Our second model is designed to decompose the exponential search space of all possible permutations. The prediction task is broken into two separate steps. In the first step, for each child word a binary classifier decides whether it appears before or after its parent in the target language. In the second step, we predict the best order of the words on each side of the parent. We show that the second approach is never w</context>
</contexts>
<marker>Li, Li, Zhang, Li, Zhou, Guan, 2007</marker>
<rawString>C. H. Li, M. Li, D. Zhang, M. Li, M. Zhou, and Y. Guan. 2007. A Probabilistic Approach to Syntax-based Reordering for Statistical Machine Translation. In Proc. of ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. In Computational Linguistics.</title>
<date>1993</date>
<contexts>
<context position="23598" citStr="Marcus et al. (1993)" startWordPosition="3934" endWordPosition="3937">e large number of experiments and language pairs we divide the experiments into groups and discuss each in turn. We only include the results UAS LAS POS en: English1 92.28 90.28 97.05 cs: Czech2 84.66 72.01 98.97 de: German3 89.30 86.98 97.69 es: Spanish4 86.24 82.32 96.62 fr: French5 88.57 86.40 97.48 hu: Hungarian2 87.66 82.51 94.47 nl: Dutch3 86.09 82.31 97.38 pt: Portuguese4 90.22 87.26 98.10 Table 1: Parsing accuracies on the retokenized treebanks. UAS is unlabeled attachment score, LAS is labeled attachment score, and POS is part-of-speech tagging accuracy. The treebank sources are (1): Marcus et al. (1993) + Judge et al. (2006) + Petrov and McDonald (2012), (2): Nivre et al. (2007), (3): Buchholz and Marsi (2006), (4): McDonald et al. (2013), (5): Abeill´e et al. (2003). from the forest-to-string system when they are better than the phrase-based results. We use * to denote results from the forest-to-string system. 4.1 WMT Experiments Table 2 presents detailed results on the WMT setup. Lexical reordering (Zens and Ney, 2006) never hurts and is thus included in all systems. Overall, our results are a little better than the best results of the WMT 2010 shared task for two language pairs and within</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. In Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>J Nivre</author>
<author>Y Quirmbach-Brundagez</author>
<author>Y Goldberg</author>
<author>D Das</author>
<author>K Ganchev</author>
<author>K Hall</author>
<author>S Petrov</author>
<author>H Zhang</author>
<author>O T¨ackstr¨om</author>
<author>C Bedini</author>
<author>N Bertomeu Castell´o</author>
<author>J Lee</author>
</authors>
<title>Universal dependency annotation for multilingual parsing.</title>
<date>2013</date>
<booktitle>In Proc. ofACL ’13.</booktitle>
<marker>McDonald, Nivre, Quirmbach-Brundagez, Goldberg, Das, Ganchev, Hall, Petrov, Zhang, T¨ackstr¨om, Bedini, Castell´o, Lee, 2013</marker>
<rawString>R. McDonald, J. Nivre, Y. Quirmbach-Brundagez, Y. Goldberg, D. Das, K. Ganchev, K. Hall, S. Petrov, H. Zhang, O. T¨ackstr¨om, C. Bedini, N. Bertomeu Castell´o, and J. Lee. 2013. Universal dependency annotation for multilingual parsing. In Proc. ofACL ’13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Neubig</author>
<author>T Watanabe</author>
<author>S Mori</author>
</authors>
<title>Inducing a discriminative parser to optimize machine translation reordering.</title>
<date>2012</date>
<booktitle>In Proc. of EMNLP-CoNLL</booktitle>
<pages>12</pages>
<contexts>
<context position="2408" citStr="Neubig et al., 2012" startWordPosition="371" endWordPosition="374">eprocess the input in such a way that the words on the source side appear closer to their final positions on the target side. Because preordering is performed prior to word alignment, it can improve the alignment process and can then be combined with any subsequent translation model. Most preordering models use a source-side syntactic parser and perform a series of tree transformations. Approaches that do not use a parser exist as well and typically induce a hierarchical representation that also allows them to perform longdistance changes (Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Neubig et al., 2012). Models that use a source-side parser differ on two main dimensions: the way tree transformations are expressed, and whether they are built manually or learned from data. One common type of tree transformation are rewrite rules. These typically involve some condition under which the transformation can be applied (e.g., a noun and an adjective found in the same clause) and the transformation itself (e.g., move the adjective after the noun). These rules can be designed manually (Collins et al., 2005; Wang et al., 2007) or learned from data (Xia and McCord, 2004; Habash, 2007; Genzel, 2010; Wu e</context>
</contexts>
<marker>Neubig, Watanabe, Mori, 2012</marker>
<rawString>G. Neubig, T. Watanabe, and S. Mori. 2012. Inducing a discriminative parser to optimize machine translation reordering. In Proc. of EMNLP-CoNLL ’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Nilsson</author>
</authors>
<title>Pseudo-projective dependency parsing.</title>
<date>2005</date>
<booktitle>In Proc. of ACL ’05.</booktitle>
<contexts>
<context position="22438" citStr="Nivre and Nilsson (2005)" startWordPosition="3748" endWordPosition="3751">fe et al., 2006). The remaining treebanks are all available in dependency format. In all cases, we apply a set of heuristics to the treebank data to make the tokenization as similar as possible to the one of the bitext. Our heuristics can split treebank tokens but do not merge treebank tokens. We found that adjusting the treebank tokenization is crucial for obtaining good results. However, this makes the reported parsing accuracies not comparable to other numbers in the literature. When necessary, we projectivize the treebanks by raising arcs until the tree becomes projective, as described in Nivre and Nilsson (2005); we do not reconstruct non-projective arcs at parsing time, since our subsequent systems expect projective trees. Our part-of-speech tagger is a conditional random field model (Lafferty et al., 2001) with simple wordidentity and affix features. The parsing model is a shift-reduce dependency parser, using the higherorder features from Zhang and Nivre (2011). Additionally, we include 256 word-cluster features (Koo et al., 2008) trained on a large amount of unlabeled monolingual text (Uszkoreit and Brants, 2008). 4 Experiments Due to the large number of experiments and language pairs we divide t</context>
</contexts>
<marker>Nivre, Nilsson, 2005</marker>
<rawString>J. Nivre and J. Nilsson. 2005. Pseudo-projective dependency parsing. In Proc. of ACL ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proc. EMNLPCoNLL ’07.</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proc. EMNLPCoNLL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>The alignment template approach to statistical machine translation.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>4</issue>
<contexts>
<context position="1351" citStr="Och and Ney, 2004" startWordPosition="201" endWordPosition="204"> into English from 7 other languages. We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task. For languages from different families the improvements often exceed 2 BLEU. Many of these gains are also significant in human evaluations. 1 Introduction Generating the appropriate word order for the target language has been one of the fundamental problems in machine translation since the ground setting work of Brown et al. (1990). Lexical reordering approaches (Tillmann, 2004; Zens and Ney, 2006) add a reordering component to standard phrase-based translation systems (Och and Ney, 2004). Because the reordering model is trained discriminatively, it can use a rich set of lexical features. However, it only has access to the local context which often times is insufficient to make the long-distance reordering decisions that are necessary for language pairs with significantly different word order. Preordering (sometimes called pre-reordering or simply reordering) approaches (Xia and McCord, 2004; Collins et al., 2005) preprocess the input in such a way that the words on the source side appear closer to their final positions on the target side. Because preordering is performed prio</context>
<context position="5216" citStr="Och and Ney, 2004" startWordPosition="827" endWordPosition="830">is designed to decompose the exponential search space of all possible permutations. The prediction task is broken into two separate steps. In the first step, for each child word a binary classifier decides whether it appears before or after its parent in the target language. In the second step, we predict the best order of the words on each side of the parent. We show that the second approach is never worse than the first one and sometimes significantly better. We present experiments on 22 language pairs from different language families using our preordering approach in a phrase-based system (Och and Ney, 2004), as well as a forest-to-string system (Zhang et al., 2011). In a first set of experiments, we use the WMT 2010 shared task data (CallisonBurch et al., 2010) and show significant improvements of up to 1.4 BLEU (Papineni et al., 2002) on three out of eight language pairs. In a second set of experiments, we use automatically mined parallel data from the web and build translation systems for languages from various language families. We obtain especially big improvements in translation quality (2-7 BLEU) when the language pairs have divergent word order (for example English to Indonesian, Japanese</context>
<context position="15624" citStr="Och and Ney, 2004" startWordPosition="2598" endWordPosition="2601"> = 24 outcomes (if all the children are on one side of the head); if we are lucky and the children split evenly, then we only need two binary decisions in the second step (for the two pairs before and after the head). If we define hard cases as cases involving 5 or more words, 5.54% of the nonleaves are hard cases with the 1-step approach, but only 1.07% are hard cases with the 2-step approach. 3 Experimental Setup To provide a through evaluation of our approach, we conduct experiments on two sets of data and with two translation systems. The first translation system is a phrase-based system (Och and Ney, 2004). In addition to the regular distance distortion model, we incorporate a maximum entropy based lexicalized phrase reordering model (Zens and Ney, 2006). Our second system is a forest-to-string system (Zhang et al., 2011). The forest-to-string system uses a onebest parse tree but factorizes it into a packed forest of binary elementary trees – hence the name forestto-string rather than tree-to-string. The systems are configured and tuned for each language pair to produce the best results. We then add our 1-step and 2-step preordering classifiers as preprocessing steps at training and test time. </context>
</contexts>
<marker>Och, Ney, 2004</marker>
<rawString>F. J. Och and H. Ney. 2004. The alignment template approach to statistical machine translation. Computational Linguistics, 30(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Papineni</author>
<author>S Roukos</author>
<author>T Ward</author>
<author>W Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of ACL ’02.</booktitle>
<contexts>
<context position="5449" citStr="Papineni et al., 2002" startWordPosition="870" endWordPosition="873">re or after its parent in the target language. In the second step, we predict the best order of the words on each side of the parent. We show that the second approach is never worse than the first one and sometimes significantly better. We present experiments on 22 language pairs from different language families using our preordering approach in a phrase-based system (Och and Ney, 2004), as well as a forest-to-string system (Zhang et al., 2011). In a first set of experiments, we use the WMT 2010 shared task data (CallisonBurch et al., 2010) and show significant improvements of up to 1.4 BLEU (Papineni et al., 2002) on three out of eight language pairs. In a second set of experiments, we use automatically mined parallel data from the web and build translation systems for languages from various language families. We obtain especially big improvements in translation quality (2-7 BLEU) when the language pairs have divergent word order (for example English to Indonesian, Japanese, Korean or Malay). In our experiments on English to and from Hungarian, Dutch, and Portuguese translation, we find that we can obtain consistent improvements in both translation directions. To additionally verify our improvements we</context>
<context position="21013" citStr="Papineni et al., 2002" startWordPosition="3518" endWordPosition="3521">ut typically makes only a small difference. We again use a 5-gram language model trained on a large amount of monolingual text. Overall, we use between 20 and 30 features, whose weights are optimized using hypergraphbased MERT. All experiments for a given language pair use the same set of MERT weights. This potentially underestimates the improvements that can be obtained, but also eliminates MERT as a possible source of improvement, allowing us to trace back improvements in translation quality directly to changes in preordering of the input data. 517 3.3 Evaluation We use case-sensitive BLEU (Papineni et al., 2002) to assess translation quality. For Japanese and Korean we use character-level BLEU. We use bootstrap resampling to compute confidence intervals. Additionally, we also conduct a side-by-side human evaluation on 750 sentences for each language pair (sampled from the same sentences used for computing BLEU). For each sentence, we ask bilingual annotators to compare the translations from two different systems and say whether one is better, leading to three possible scores of -1, 0, and +1. We focus on this relative comparison since absolute scores are difficult to calibrate across languages and ra</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>K. Papineni, S. Roukos, T. Ward, and W. Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proc. of ACL ’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>R McDonald</author>
</authors>
<title>Overview of the 2012 shared task on parsing the web. In</title>
<date>2012</date>
<booktitle>Proc. of NAACL ’12 SANCL.</booktitle>
<contexts>
<context position="23649" citStr="Petrov and McDonald (2012)" startWordPosition="3944" endWordPosition="3947">irs we divide the experiments into groups and discuss each in turn. We only include the results UAS LAS POS en: English1 92.28 90.28 97.05 cs: Czech2 84.66 72.01 98.97 de: German3 89.30 86.98 97.69 es: Spanish4 86.24 82.32 96.62 fr: French5 88.57 86.40 97.48 hu: Hungarian2 87.66 82.51 94.47 nl: Dutch3 86.09 82.31 97.38 pt: Portuguese4 90.22 87.26 98.10 Table 1: Parsing accuracies on the retokenized treebanks. UAS is unlabeled attachment score, LAS is labeled attachment score, and POS is part-of-speech tagging accuracy. The treebank sources are (1): Marcus et al. (1993) + Judge et al. (2006) + Petrov and McDonald (2012), (2): Nivre et al. (2007), (3): Buchholz and Marsi (2006), (4): McDonald et al. (2013), (5): Abeill´e et al. (2003). from the forest-to-string system when they are better than the phrase-based results. We use * to denote results from the forest-to-string system. 4.1 WMT Experiments Table 2 presents detailed results on the WMT setup. Lexical reordering (Zens and Ney, 2006) never hurts and is thus included in all systems. Overall, our results are a little better than the best results of the WMT 2010 shared task for two language pairs and within reach of the best results in most other cases. The</context>
</contexts>
<marker>Petrov, McDonald, 2012</marker>
<rawString>S. Petrov and R. McDonald. 2012. Overview of the 2012 shared task on parsing the web. In Proc. of NAACL ’12 SANCL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Petrov</author>
<author>D Das</author>
<author>R McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>In Proc. of LREC ’12.</booktitle>
<contexts>
<context position="9448" citStr="Petrov et al. (2012)" startWordPosition="1536" endWordPosition="1539">ether each child is before, immediately before, immediately after, or after the head. • For every child, if there is a gap between it and the head, then the first and last word of that gap. • For every pair of consecutive children, if there is a gap between them, then the first and last word of that gap. • The head’s immediate sibling to the left/right or an indication that none exists. When extracting the features, every word can be represented by its word identity, its fine-grained POS tag from the treebank, and a coarse-grained POS category, similar to the universal categories described in Petrov et al. (2012). We also include pairs of these features, resulting in potentially bilexical features. 2.2 Training Data The training data for the classifiers is generated from the word aligned parallel text. Since parallel data is plentiful, we can afford to be selective. We first construct the intersection of high-confidence sourceto-target and target-to-source alignments. For every family in the source dependency tree we generate a training instance if and only if the intersection defines a full order on the source words: • Every source word must be aligned to at least one target word. ROOT The black cat </context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>S. Petrov, D. Das, and R. McDonald. 2012. A universal part-of-speech tagset. In Proc. of LREC ’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Talbot</author>
<author>H Kazawa</author>
<author>H Ichikawa</author>
<author>J Katz-Brown</author>
<author>M Seno</author>
<author>F Och</author>
</authors>
<title>A lightweight evaluation framework for machine translation reordering.</title>
<date>2011</date>
<booktitle>In Proc. of EMNLP ’11 WMT.</booktitle>
<contexts>
<context position="33507" citStr="Talbot et al. (2011)" startWordPosition="5564" endWordPosition="5567">ction, we analyze an example whose translation is significantly improved by our preordering approach, demonstrating the usefulness of our lexicalized features. Consider the English sentence: It was a real whirlwind. 520 no reordering manual automatic fuzzy exact BLEU fuzzy exact BLEU fuzzy exact BLEU en-ar 63.2 19.8 11.4 83.5 47.6 12.4 79.0 38.9 12.6 en-iw 67.9 22.2 18.8 89.8 62.4 20.3 89.2 61.2 20.2 en-ja* 44.1 0.0 14.9 80.9 41.5 18.4 78.5 36.8 18.6 Table 5: Preordering accuracy for the 2-step classifiers using manual alignments vs. automatic alignments. Fuzzy refers to the metric defined in Talbot et al. (2011) and exact is the percentage of sentences with a perfect preordering. taken from the WMT test set. The dependency parse tree is shown in Figure 2. In our experiments the rule-based approach of (Genzel, 2010) reordered the source sentence into: It was a whirlwind real. and produced the translation: Es un torbellino real. In comparison, our 2-step system kept the English sentence unchanged and produced the translation: Fue un aut´entico torbellino. The second translation is better than the first because of the correct tense (which is not related directly to the preordering) and because the noun </context>
</contexts>
<marker>Talbot, Kazawa, Ichikawa, Katz-Brown, Seno, Och, 2011</marker>
<rawString>D. Talbot, H. Kazawa, H. Ichikawa, J. Katz-Brown, M. Seno, and F. Och. 2011. A lightweight evaluation framework for machine translation reordering. In Proc. of EMNLP ’11 WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Tillmann</author>
</authors>
<title>A unigram orientation model for statistical machine translation.</title>
<date>2004</date>
<booktitle>In Proc. of NAACL-HLT ’04.</booktitle>
<contexts>
<context position="1238" citStr="Tillmann, 2004" startWordPosition="186" endWordPosition="187">res, including lexical features. We present extensive experiments on 22 language pairs, including preordering into English from 7 other languages. We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task. For languages from different families the improvements often exceed 2 BLEU. Many of these gains are also significant in human evaluations. 1 Introduction Generating the appropriate word order for the target language has been one of the fundamental problems in machine translation since the ground setting work of Brown et al. (1990). Lexical reordering approaches (Tillmann, 2004; Zens and Ney, 2006) add a reordering component to standard phrase-based translation systems (Och and Ney, 2004). Because the reordering model is trained discriminatively, it can use a rich set of lexical features. However, it only has access to the local context which often times is insufficient to make the long-distance reordering decisions that are necessary for language pairs with significantly different word order. Preordering (sometimes called pre-reordering or simply reordering) approaches (Xia and McCord, 2004; Collins et al., 2005) preprocess the input in such a way that the words on</context>
</contexts>
<marker>Tillmann, 2004</marker>
<rawString>C. Tillmann. 2004. A unigram orientation model for statistical machine translation. In Proc. of NAACL-HLT ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Tromble</author>
<author>J Eisner</author>
</authors>
<title>Learning linear ordering problems for better translation.</title>
<date>2009</date>
<booktitle>In Proc. of EMNLP ’09.</booktitle>
<contexts>
<context position="2358" citStr="Tromble and Eisner, 2009" startWordPosition="362" endWordPosition="365">oaches (Xia and McCord, 2004; Collins et al., 2005) preprocess the input in such a way that the words on the source side appear closer to their final positions on the target side. Because preordering is performed prior to word alignment, it can improve the alignment process and can then be combined with any subsequent translation model. Most preordering models use a source-side syntactic parser and perform a series of tree transformations. Approaches that do not use a parser exist as well and typically induce a hierarchical representation that also allows them to perform longdistance changes (Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Neubig et al., 2012). Models that use a source-side parser differ on two main dimensions: the way tree transformations are expressed, and whether they are built manually or learned from data. One common type of tree transformation are rewrite rules. These typically involve some condition under which the transformation can be applied (e.g., a noun and an adjective found in the same clause) and the transformation itself (e.g., move the adjective after the noun). These rules can be designed manually (Collins et al., 2005; Wang et al., 2007) or learned from data (Xia </context>
</contexts>
<marker>Tromble, Eisner, 2009</marker>
<rawString>R. Tromble and J. Eisner. 2009. Learning linear ordering problems for better translation. In Proc. of EMNLP ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Uszkoreit</author>
<author>T Brants</author>
</authors>
<title>Distributed word clustering for large scale class-based language modeling in machine translation.</title>
<date>2008</date>
<booktitle>In Proc. of ACL-HLT ’08.</booktitle>
<contexts>
<context position="22953" citStr="Uszkoreit and Brants, 2008" startWordPosition="3827" endWordPosition="3830">tivize the treebanks by raising arcs until the tree becomes projective, as described in Nivre and Nilsson (2005); we do not reconstruct non-projective arcs at parsing time, since our subsequent systems expect projective trees. Our part-of-speech tagger is a conditional random field model (Lafferty et al., 2001) with simple wordidentity and affix features. The parsing model is a shift-reduce dependency parser, using the higherorder features from Zhang and Nivre (2011). Additionally, we include 256 word-cluster features (Koo et al., 2008) trained on a large amount of unlabeled monolingual text (Uszkoreit and Brants, 2008). 4 Experiments Due to the large number of experiments and language pairs we divide the experiments into groups and discuss each in turn. We only include the results UAS LAS POS en: English1 92.28 90.28 97.05 cs: Czech2 84.66 72.01 98.97 de: German3 89.30 86.98 97.69 es: Spanish4 86.24 82.32 96.62 fr: French5 88.57 86.40 97.48 hu: Hungarian2 87.66 82.51 94.47 nl: Dutch3 86.09 82.31 97.38 pt: Portuguese4 90.22 87.26 98.10 Table 1: Parsing accuracies on the retokenized treebanks. UAS is unlabeled attachment score, LAS is labeled attachment score, and POS is part-of-speech tagging accuracy. The t</context>
</contexts>
<marker>Uszkoreit, Brants, 2008</marker>
<rawString>J. Uszkoreit and T. Brants. 2008. Distributed word clustering for large scale class-based language modeling in machine translation. In Proc. of ACL-HLT ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Vogel</author>
<author>H Ney</author>
<author>C Tillmann</author>
</authors>
<title>HMM-based word alignment in statistical translation. In</title>
<date>1996</date>
<booktitle>In Proc. of COLING ’96.</booktitle>
<contexts>
<context position="18418" citStr="Vogel et al., 1996" startWordPosition="3084" endWordPosition="3087"> nature in which the rules are learned and applied. 3.1 WMT Setup In our first set of experiments, we use the data provided for the WMT 2010 shared task (CallisonBurch et al., 2010). We build systems for all language pairs: English to and from Czech, French, German, and Spanish. Since this is a publicly available dataset, it is easy to compare our results to other submissions to the shared task. During word alignment, we filter out sentences exceeding 60 words in the parallel texts and perform 6 iterations of IBM Model-1 training (Brown et al., 1993), followed by 6 iterations of HMM training (Vogel et al., 1996). We do not use Model-4 because it is slow and did not add much value to our systems in a pilot study. Standard phrase extraction heuristics (Koehn et al., 2003) are applied to extract phrase pairs with a length limit of 6 from alignments symmetrized with the “union” heuristic. Maximum jump width is set to 8. Rule extraction for the forestto-string system is limited to 16 rules per tree node. There are no length-based reordering constraints in the forest-to-string system. We train two 5-gram language models with Kneser-Ney smoothing for each of the target languages. One is trained on the targe</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>S. Vogel, H. Ney, and C. Tillmann. 1996. HMM-based word alignment in statistical translation. In In Proc. of COLING ’96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wang</author>
<author>M Collins</author>
<author>P Koehn</author>
</authors>
<title>Chinese syntactic reordering for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. of EMNLP-CoNLL</booktitle>
<pages>07</pages>
<contexts>
<context position="2931" citStr="Wang et al., 2007" startWordPosition="456" endWordPosition="459">ongdistance changes (Tromble and Eisner, 2009; DeNero and Uszkoreit, 2011; Neubig et al., 2012). Models that use a source-side parser differ on two main dimensions: the way tree transformations are expressed, and whether they are built manually or learned from data. One common type of tree transformation are rewrite rules. These typically involve some condition under which the transformation can be applied (e.g., a noun and an adjective found in the same clause) and the transformation itself (e.g., move the adjective after the noun). These rules can be designed manually (Collins et al., 2005; Wang et al., 2007) or learned from data (Xia and McCord, 2004; Habash, 2007; Genzel, 2010; Wu et al., 2011). Another type of tree transformations uses ranking functions to implement precedence-based reordering. Here, a function assigns a numerical value to every word in a clause, intended to express the precedence of the word in the target language. The reordering operation is then to sort the words according to their assigned values. The ranking function 513 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 513–523, Seattle, Washington, USA, 18-21 October 2013. c�201</context>
</contexts>
<marker>Wang, Collins, Koehn, 2007</marker>
<rawString>C. Wang, M. Collins, and P. Koehn. 2007. Chinese syntactic reordering for statistical machine translation. In Proc. of EMNLP-CoNLL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Wu</author>
<author>K Sudoh</author>
<author>K Duh</author>
<author>H Tsukada</author>
<author>M Nagata</author>
</authors>
<title>Extracting pre-ordering rules from predicateargument structures.</title>
<date>2011</date>
<booktitle>In Proc. of IJCNLP ’11.</booktitle>
<contexts>
<context position="3020" citStr="Wu et al., 2011" startWordPosition="472" endWordPosition="475">012). Models that use a source-side parser differ on two main dimensions: the way tree transformations are expressed, and whether they are built manually or learned from data. One common type of tree transformation are rewrite rules. These typically involve some condition under which the transformation can be applied (e.g., a noun and an adjective found in the same clause) and the transformation itself (e.g., move the adjective after the noun). These rules can be designed manually (Collins et al., 2005; Wang et al., 2007) or learned from data (Xia and McCord, 2004; Habash, 2007; Genzel, 2010; Wu et al., 2011). Another type of tree transformations uses ranking functions to implement precedence-based reordering. Here, a function assigns a numerical value to every word in a clause, intended to express the precedence of the word in the target language. The reordering operation is then to sort the words according to their assigned values. The ranking function 513 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 513–523, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics can be designed manually (Xu et al., 2009) or</context>
<context position="38673" citStr="Wu et al., 2011" startWordPosition="6418" endWordPosition="6421">ations. On the other hand, our approach provides important advantages. Compared to systems that use rewrite rules, it is much easier to encode useful knowledge that by itself is not enough to determine a full rewrite rule, such as “a determiner is unlikely to be the last word in a clause.” Perhaps more importantly, our model provides an elegant answer to the question of what to do when multiple rewrite rules can be applied. Previous work has employed different heuristics: use the most specific rule (Xia and McCord, 2004), use all applicable rules (Genzel, 2010), or use the most frequent rule (Wu et al., 2011). In our model there is no need for such heuristics – all the “rules” are treated as features to a discriminative classifier, and the task of analyzing their interactions is handled by the learning algorithm. Compared to preordering systems that use ranking functions, our model has the advantage that it can encode information about the complete permutation. For example, for three source words A, B, and C, we can naturally express the useful prior that Feature Weight PrevChild:tag=JJ,PrevSibling:a 0.448 PrevChild:cat=ADJ,PrevSibling:a 0.292 PrevChild:cat=ADJ,NoNextSibling 0.212 ... PrevChild:re</context>
</contexts>
<marker>Wu, Sudoh, Duh, Tsukada, Nagata, 2011</marker>
<rawString>X. Wu, K. Sudoh, K. Duh, H. Tsukada, and M. Nagata. 2011. Extracting pre-ordering rules from predicateargument structures. In Proc. of IJCNLP ’11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Xia</author>
<author>M McCord</author>
</authors>
<title>Improving a statistical MT system with automatically learned rewrite patterns.</title>
<date>2004</date>
<booktitle>In Proc. of COLING ’04.</booktitle>
<contexts>
<context position="1762" citStr="Xia and McCord, 2004" startWordPosition="261" endWordPosition="264">ce the ground setting work of Brown et al. (1990). Lexical reordering approaches (Tillmann, 2004; Zens and Ney, 2006) add a reordering component to standard phrase-based translation systems (Och and Ney, 2004). Because the reordering model is trained discriminatively, it can use a rich set of lexical features. However, it only has access to the local context which often times is insufficient to make the long-distance reordering decisions that are necessary for language pairs with significantly different word order. Preordering (sometimes called pre-reordering or simply reordering) approaches (Xia and McCord, 2004; Collins et al., 2005) preprocess the input in such a way that the words on the source side appear closer to their final positions on the target side. Because preordering is performed prior to word alignment, it can improve the alignment process and can then be combined with any subsequent translation model. Most preordering models use a source-side syntactic parser and perform a series of tree transformations. Approaches that do not use a parser exist as well and typically induce a hierarchical representation that also allows them to perform longdistance changes (Tromble and Eisner, 2009; De</context>
<context position="38583" citStr="Xia and McCord, 2004" startWordPosition="6401" endWordPosition="6404">he number of possible permutations is large we can limit ourselves to the K most popular permutations. On the other hand, our approach provides important advantages. Compared to systems that use rewrite rules, it is much easier to encode useful knowledge that by itself is not enough to determine a full rewrite rule, such as “a determiner is unlikely to be the last word in a clause.” Perhaps more importantly, our model provides an elegant answer to the question of what to do when multiple rewrite rules can be applied. Previous work has employed different heuristics: use the most specific rule (Xia and McCord, 2004), use all applicable rules (Genzel, 2010), or use the most frequent rule (Wu et al., 2011). In our model there is no need for such heuristics – all the “rules” are treated as features to a discriminative classifier, and the task of analyzing their interactions is handled by the learning algorithm. Compared to preordering systems that use ranking functions, our model has the advantage that it can encode information about the complete permutation. For example, for three source words A, B, and C, we can naturally express the useful prior that Feature Weight PrevChild:tag=JJ,PrevSibling:a 0.448 Pr</context>
</contexts>
<marker>Xia, McCord, 2004</marker>
<rawString>F. Xia and M. McCord. 2004. Improving a statistical MT system with automatically learned rewrite patterns. In Proc. of COLING ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Xu</author>
<author>J Kang</author>
<author>M Ringgaard</author>
<author>F Och</author>
</authors>
<title>Using a dependency parser to improve SMT for subject-objectverb languages. In</title>
<date>2009</date>
<booktitle>Proc. of NAACL-HLT ’09.</booktitle>
<contexts>
<context position="3617" citStr="Xu et al., 2009" startWordPosition="562" endWordPosition="565">0; Wu et al., 2011). Another type of tree transformations uses ranking functions to implement precedence-based reordering. Here, a function assigns a numerical value to every word in a clause, intended to express the precedence of the word in the target language. The reordering operation is then to sort the words according to their assigned values. The ranking function 513 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 513–523, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics can be designed manually (Xu et al., 2009) or trained from data (Yang et al., 2012). This approach is particularly effective for Subject-Object-Verb (SOV) languages. In this work we present a simple classifier-based preordering model. Our model operates over dependency parse trees and is therefore able to perform long-distance reordering decisions, as is typical for preordering models. But instead of deterministic rules or ranking functions, we use discriminative classifiers to directly predict the final word order, using rich (bi-)lexical and syntactic features. We present two models. The first model uses a classifier to directly pre</context>
<context position="27943" citStr="Xu et al. (2009)" startWordPosition="4625" endWordPosition="4628">roaches. The main benefit of the 2-step approach is compactness: the set of 2-step classifiers has about half the number of non-zero features as the 1-step classifiers. 4.2 Additional Languages Experiments Table 3 shows our first set of results on the additional languages, including some languages with a wide disparity in word order relative to English. The SOV languages Korean (ko) and Japanese (ja) benefit the most from preordering and gain more than 7 BLEU relative to the phrase-based baseline and still more than 3 BLEU for the forest-to-string system. Similar improvements were reported by Xu et al. (2009) with manual reordering rules. Indonesian (id) and Malay (ms) are next with gains of 2.5 BLEU. Malay does not have a grammatical subject in the sense that English does, but instead uses a concept of an agent and an object, whose order is determined by the voice of the verb. It appears that our classifiers have learned to model some of these highly lexical, but systematic ordering preferences. Welsh (cy) and Irish (ga) as VSO languages also exhibit large gains of 2.1 BLEU. For Arabic (ar) and Hebrew (iw), the gains are smaller, but still significant and exceed 1 BLEU relative to the baseline. T</context>
</contexts>
<marker>Xu, Kang, Ringgaard, Och, 2009</marker>
<rawString>P. Xu, J. Kang, M. Ringgaard, and F. Och. 2009. Using a dependency parser to improve SMT for subject-objectverb languages. In Proc. of NAACL-HLT ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proc. of ACL ’01.</booktitle>
<contexts>
<context position="36919" citStr="Yamada and Knight, 2001" startWordPosition="6122" endWordPosition="6125"> We obtain strong results on the WMT 2010 shared task data, observing gains of up to 1.4 BLEU over a state-of-the-art system. We also show gains of up to 0.5 BLEU over a strong directly comparable preordering system that is based on learning unlexicalized reordering rules. We obtain improvements of more than 2 BLEU in experiments on additional languages. The gains are especially large for languages where the sentence structure is very different from English. These positive results are confirmed in human side-by-side evaluations. When comparing our approach to syntax-based translation systems (Yamada and Knight, 2001; Galley et al., 2004; Huang et al., 2006; Dyer and Resnik, 2010) we note that both approaches use syntactic information for reordering decisions. Our preordering approach has several advantages. First, be521 ROOT It was a real whirlwind . NN VBD DT JJ NN . NOUN VERB DET ADJ NOUN . Figure 2: An example where lexical information is necessary for choosing the correct word order. cause preordering is performed before learning word alignments, it has the potential to improve the word alignments. Second, by using discriminative classifiers we can take advantage of lexical features. Finally, preorde</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>K. Yamada and K. Knight. 2001. A syntax-based statistical translation model. In Proc. of ACL ’01.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Yang</author>
<author>M Li</author>
<author>D Zhang</author>
<author>N Yu</author>
</authors>
<title>A rankingbased approach to word reordering for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proc. of ACL ’12.</booktitle>
<contexts>
<context position="3658" citStr="Yang et al., 2012" startWordPosition="570" endWordPosition="573">ee transformations uses ranking functions to implement precedence-based reordering. Here, a function assigns a numerical value to every word in a clause, intended to express the precedence of the word in the target language. The reordering operation is then to sort the words according to their assigned values. The ranking function 513 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 513–523, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics can be designed manually (Xu et al., 2009) or trained from data (Yang et al., 2012). This approach is particularly effective for Subject-Object-Verb (SOV) languages. In this work we present a simple classifier-based preordering model. Our model operates over dependency parse trees and is therefore able to perform long-distance reordering decisions, as is typical for preordering models. But instead of deterministic rules or ranking functions, we use discriminative classifiers to directly predict the final word order, using rich (bi-)lexical and syntactic features. We present two models. The first model uses a classifier to directly predict the permutation order in which a fam</context>
</contexts>
<marker>Yang, Li, Zhang, Yu, 2012</marker>
<rawString>N. Yang, M. Li, D. Zhang, and N. Yu. 2012. A rankingbased approach to word reordering for statistical machine translation. In Proc. of ACL ’12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Zens</author>
<author>H Ney</author>
</authors>
<title>Discriminative reordering models for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proc. of NAACL ’06 WMT.</booktitle>
<contexts>
<context position="1259" citStr="Zens and Ney, 2006" startWordPosition="188" endWordPosition="191">exical features. We present extensive experiments on 22 language pairs, including preordering into English from 7 other languages. We obtain improvements of up to 1.4 BLEU on language pairs in the WMT 2010 shared task. For languages from different families the improvements often exceed 2 BLEU. Many of these gains are also significant in human evaluations. 1 Introduction Generating the appropriate word order for the target language has been one of the fundamental problems in machine translation since the ground setting work of Brown et al. (1990). Lexical reordering approaches (Tillmann, 2004; Zens and Ney, 2006) add a reordering component to standard phrase-based translation systems (Och and Ney, 2004). Because the reordering model is trained discriminatively, it can use a rich set of lexical features. However, it only has access to the local context which often times is insufficient to make the long-distance reordering decisions that are necessary for language pairs with significantly different word order. Preordering (sometimes called pre-reordering or simply reordering) approaches (Xia and McCord, 2004; Collins et al., 2005) preprocess the input in such a way that the words on the source side appe</context>
<context position="15775" citStr="Zens and Ney, 2006" startWordPosition="2620" endWordPosition="2623">s in the second step (for the two pairs before and after the head). If we define hard cases as cases involving 5 or more words, 5.54% of the nonleaves are hard cases with the 1-step approach, but only 1.07% are hard cases with the 2-step approach. 3 Experimental Setup To provide a through evaluation of our approach, we conduct experiments on two sets of data and with two translation systems. The first translation system is a phrase-based system (Och and Ney, 2004). In addition to the regular distance distortion model, we incorporate a maximum entropy based lexicalized phrase reordering model (Zens and Ney, 2006). Our second system is a forest-to-string system (Zhang et al., 2011). The forest-to-string system uses a onebest parse tree but factorizes it into a packed forest of binary elementary trees – hence the name forestto-string rather than tree-to-string. The systems are configured and tuned for each language pair to produce the best results. We then add our 1-step and 2-step preordering classifiers as preprocessing steps at training and test time. We train the reordering classifiers on up to 15M training instances. We train separate classifiers for every number of involved words, and restrict eac</context>
<context position="24024" citStr="Zens and Ney, 2006" startWordPosition="4005" endWordPosition="4008"> on the retokenized treebanks. UAS is unlabeled attachment score, LAS is labeled attachment score, and POS is part-of-speech tagging accuracy. The treebank sources are (1): Marcus et al. (1993) + Judge et al. (2006) + Petrov and McDonald (2012), (2): Nivre et al. (2007), (3): Buchholz and Marsi (2006), (4): McDonald et al. (2013), (5): Abeill´e et al. (2003). from the forest-to-string system when they are better than the phrase-based results. We use * to denote results from the forest-to-string system. 4.1 WMT Experiments Table 2 presents detailed results on the WMT setup. Lexical reordering (Zens and Ney, 2006) never hurts and is thus included in all systems. Overall, our results are a little better than the best results of the WMT 2010 shared task for two language pairs and within reach of the best results in most other cases. The 2-step classifier preordering approach provides statistically significant improvements over the lexical reordering baseline on three out of the eight language pairs: English-Spanish (en-es: 1.4 BLEU), German-English (de-en: 1.2 BLEU), and EnglishFrench (en-fr: 1.0 BLEU). These improvements are significant in our human side-by-side evaluation. We also observe gains when co</context>
</contexts>
<marker>Zens, Ney, 2006</marker>
<rawString>R. Zens and H. Ney. 2006. Discriminative reordering models for statistical machine translation. In Proc. of NAACL ’06 WMT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>J Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-HLT ’11.</booktitle>
<contexts>
<context position="22797" citStr="Zhang and Nivre (2011)" startWordPosition="3803" endWordPosition="3806">btaining good results. However, this makes the reported parsing accuracies not comparable to other numbers in the literature. When necessary, we projectivize the treebanks by raising arcs until the tree becomes projective, as described in Nivre and Nilsson (2005); we do not reconstruct non-projective arcs at parsing time, since our subsequent systems expect projective trees. Our part-of-speech tagger is a conditional random field model (Lafferty et al., 2001) with simple wordidentity and affix features. The parsing model is a shift-reduce dependency parser, using the higherorder features from Zhang and Nivre (2011). Additionally, we include 256 word-cluster features (Koo et al., 2008) trained on a large amount of unlabeled monolingual text (Uszkoreit and Brants, 2008). 4 Experiments Due to the large number of experiments and language pairs we divide the experiments into groups and discuss each in turn. We only include the results UAS LAS POS en: English1 92.28 90.28 97.05 cs: Czech2 84.66 72.01 98.97 de: German3 89.30 86.98 97.69 es: Spanish4 86.24 82.32 96.62 fr: French5 88.57 86.40 97.48 hu: Hungarian2 87.66 82.51 94.47 nl: Dutch3 86.09 82.31 97.38 pt: Portuguese4 90.22 87.26 98.10 Table 1: Parsing ac</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Y. Zhang and J. Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proc. of ACL-HLT ’11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang</author>
<author>L Fang</author>
<author>P Xu</author>
<author>X Wu</author>
</authors>
<title>Binarized forest to string translation.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-HLT ’11.</booktitle>
<contexts>
<context position="5275" citStr="Zhang et al., 2011" startWordPosition="837" endWordPosition="840">ll possible permutations. The prediction task is broken into two separate steps. In the first step, for each child word a binary classifier decides whether it appears before or after its parent in the target language. In the second step, we predict the best order of the words on each side of the parent. We show that the second approach is never worse than the first one and sometimes significantly better. We present experiments on 22 language pairs from different language families using our preordering approach in a phrase-based system (Och and Ney, 2004), as well as a forest-to-string system (Zhang et al., 2011). In a first set of experiments, we use the WMT 2010 shared task data (CallisonBurch et al., 2010) and show significant improvements of up to 1.4 BLEU (Papineni et al., 2002) on three out of eight language pairs. In a second set of experiments, we use automatically mined parallel data from the web and build translation systems for languages from various language families. We obtain especially big improvements in translation quality (2-7 BLEU) when the language pairs have divergent word order (for example English to Indonesian, Japanese, Korean or Malay). In our experiments on English to and fr</context>
<context position="15844" citStr="Zhang et al., 2011" startWordPosition="2631" endWordPosition="2634">f we define hard cases as cases involving 5 or more words, 5.54% of the nonleaves are hard cases with the 1-step approach, but only 1.07% are hard cases with the 2-step approach. 3 Experimental Setup To provide a through evaluation of our approach, we conduct experiments on two sets of data and with two translation systems. The first translation system is a phrase-based system (Och and Ney, 2004). In addition to the regular distance distortion model, we incorporate a maximum entropy based lexicalized phrase reordering model (Zens and Ney, 2006). Our second system is a forest-to-string system (Zhang et al., 2011). The forest-to-string system uses a onebest parse tree but factorizes it into a packed forest of binary elementary trees – hence the name forestto-string rather than tree-to-string. The systems are configured and tuned for each language pair to produce the best results. We then add our 1-step and 2-step preordering classifiers as preprocessing steps at training and test time. We train the reordering classifiers on up to 15M training instances. We train separate classifiers for every number of involved words, and restrict each one to the K = 20 most frequent outcomes. 516 In our implementation</context>
</contexts>
<marker>Zhang, Fang, Xu, Wu, 2011</marker>
<rawString>H. Zhang, L. Fang, P. Xu, and X. Wu. 2011. Binarized forest to string translation. In Proc. of ACL-HLT ’11.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>