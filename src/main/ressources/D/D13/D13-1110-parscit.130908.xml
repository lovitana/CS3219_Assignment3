<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.9963725">
Efficient Left-to-Right Hierarchical Phrase-based Translation with
Improved Reordering
</title>
<author confidence="0.959439">
Maryam Siahbani, Baskaran Sankaran, Anoop Sarkar
</author>
<affiliation confidence="0.7153625">
Simon Fraser University
Burnaby BC. CANADA
</affiliation>
<email confidence="0.981673">
{msiahban,baskaran,anoop}@cs.sfu.ca
</email>
<sectionHeader confidence="0.974951" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999647347826087">
Left-to-right (LR) decoding (Watanabe et al.,
2006b) is a promising decoding algorithm for
hierarchical phrase-based translation (Hiero).
It generates the target sentence by extending
the hypotheses only on the right edge. LR de-
coding has complexity O(n2b) for input of n
words and beam size b, compared to O(n3) for
the CKY algorithm. It requires a single lan-
guage model (LM) history for each target hy-
pothesis rather than two LM histories per hy-
pothesis as in CKY. In this paper we present an
augmented LR decoding algorithm that builds
on the original algorithm in (Watanabe et al.,
2006b). Unlike that algorithm, using experi-
ments over multiple language pairs we show
two new results: our LR decoding algorithm
provides demonstrably more efficient decod-
ing than CKY Hiero, four times faster; and by
introducing new distortion and reordering fea-
tures for LR decoding, it maintains the same
translation quality (as in BLEU scores) ob-
tained phrase-based and CKY Hiero with the
same translation model.
</bodyText>
<sectionHeader confidence="0.998785" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999935236363637">
Hiero (Chiang, 2007) models translation using a lex-
icalized synchronous context-free grammar (SCFG)
extracted from word aligned bitexts. Typically,
CKY-style decoding is used for Hiero with time
complexity O(n3) for source input with n words.
Scoring the target language output using a lan-
guage model within CKY-style decoding requires
two histories per hypothesis, one on the left edge
of each span and one on the right, due to the fact
that the target side is not generated in left to right
order, but rather built bottom-up from sub-spans.
This leads to complex problems in efficient lan-
guage model integration and requires state reduc-
tion techniques (Heafield et al., 2011; Heafield et
al., 2013). The size of a Hiero SCFG grammar is
typically larger than phrase-based models extracted
from the same data creating challenges in rule ex-
traction and decoding time especially for larger
datasets (Sankaran et al., 2012).
In contrast, the LR-decoding algorithm could
avoid these shortcomings such as faster time com-
plexity, reduction in the grammar size and the sim-
plified left-to-right language model scoring. It
means LR decoding has the potential to replace
CKY decoding for Hiero. Despite these attractive
properties, we show that the original LR-Hiero de-
coding proposed by (Watanabe et al., 2006b) does
not perform to the same level of the standard CKY
Hiero with cube pruning (see Table 3). In addition,
the current LR decoding algorithm does not obtain
BLEU scores comparable to phrase-based or CKY-
based Hiero models for different language pairs (see
Table 4). In this paper we propose modifications to
the LR decoding algorithm that addresses these limi-
tations and provides, for the first time, a true alterna-
tive to the standard CKY Hiero algorithm that uses
left-to-right decoding.
We introduce a new extended version of the LR
decoding algorithm presented in (Watanabe et al.,
2006b) which is demonstrably more efficient than
the CKY Hiero algorithm. We measure the effi-
ciency of the LR Hiero decoder in a way that is
independent of the choice of system and program-
ming language by measuring the number of lan-
guage model queries. Although more efficient, the
new LR decoding algorithm suffered from lower
BLEU scores compared to CKY Hiero. Our anal-
ysis of left to right decoding showed that it has more
potential for search errors due to early pruning of
good hypotheses. This is unlike bottom-up decoding
(CKY) which keeps best hypotheses for each span.
To address this issue, we introduce two novel fea-
tures into the Hiero SMT model that deal with re-
ordering and distortion. Our experiments show that
LR decoding with these features using prefix lexi-
</bodyText>
<page confidence="0.977742">
1089
</page>
<note confidence="0.7327255">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1089–1099,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999615181818182">
calized target side rules equals the scores obtained
by CKY decoding with prefix lexicalized target side
rules and phrase-based translation system. It per-
forms four times fewer language model queries on
average, compare to CKY Hiero decoding with un-
restricted Hiero rules: 6466.7 LM queries for CKY
Hiero (with cube pruning) compared to 1500.45 LM
queries in LR Hiero (with cube pruning). While
translation quality suffers by only about 0.67 in
BLEU score on average, across two different lan-
guage pairs.
</bodyText>
<sectionHeader confidence="0.895483" genericHeader="method">
2 Left-to-Right Decoding for Hiero
</sectionHeader>
<bodyText confidence="0.99986952631579">
Hierarchical phrase-based SMT (Chiang, 2005; Chi-
ang, 2007) uses a synchronous context free gram-
mar (SCFG), where the rules are of the form X —*
(-y, α), where X is a non-terminal, -y and α are
strings of terminals and non-terminals.
Chiang (2007) places certain constraints on the
extracted rules in order to simplify decoding. This
includes limiting the maximum number of non-
terminals (rule arity) to two and disallowing any rule
with consecutive non-terminals on the foreign lan-
guage side. It further limits the length of the initial
phrase-pair as well as the number of terminals and
non-terminals in the rule. For translating sentences
longer than the maximum phrase-pair length, the de-
coder relies on additional glue rules 5 —* (X, X)
and 5 —* (5X, 5X) that allows monotone combi-
nation of phrases. The glue rules are used when no
rules could match or the span length is larger than
the maximum phrase-pair length.
</bodyText>
<subsectionHeader confidence="0.988603">
2.1 Rule Extraction for LR Decoding
</subsectionHeader>
<bodyText confidence="0.999915">
Left-to-right Hiero (Watanabe et al., 2006b) gener-
ates the target hypotheses left to right, but for syn-
chronous context-free grammar (SCFG) as used in
Hiero. The target-side rules are constrained to be
prefix lexicalized. These constrained SCFG rules
are defined as:
</bodyText>
<equation confidence="0.999408">
X —* (-y,bQ) (1)
</equation>
<bodyText confidence="0.8991028">
where -y is a mixed string of terminals and non-
terminals. b is a terminal sequence prefixed to the
possibly empty non-terminal sequence Q. For the
sake of simplicity, We refer to these type of rules as
schuler ihre arbeit noch nicht gemacht haben .
</bodyText>
<figureCaption confidence="0.999459">
Figure 1: (a): A word-aligned German-English sentence
pair. The bars above the source words indicate phrase-
pairs having at least two words. (b): its corresponding
left-to-right target derivation tree. Superscripts on the
source non-terminals show the indices of the rules (see
Fig 2) used in derivation.
</figureCaption>
<bodyText confidence="0.9827705">
GNF rules1 in this paper.
Rule extraction is similar to Hiero, except any
rules violating GNF form on the target side are
excluded. Rule extraction considers each smaller
source-target phrase pair within a larger phrase pair
and replaces the spans with non-terminal X, yield-
ing hierarchical rules. Figure 1(a) shows a word-
aligned German-English sentence with a phrase
pair (ihre arbeit noch nicht gemacht haben,
have not yet done their work) that will lead to a
SCFG rule. Given other smaller phrases (marked by
bars above the source side), we extract a GNF rule2:
</bodyText>
<equation confidence="0.9980315">
X —*
(X1 noch nicht X2 haben, have not yet X2 X1) (2)
</equation>
<bodyText confidence="0.9997846">
In order to avoid data sparsity and for better gen-
eralization, Watanabe et al. (2006b) adds four glue
rules for each lexical rule (f, e) which are analo-
gous to the glue rules defined in (Chiang, 2007) (see
above) except that these glue rules for LR decoding
</bodyText>
<footnote confidence="0.9376552">
1Griebach Normal Form (GNF), although the synchronous
grammar is not in this normal form, rather only the target side
is prefix lexicalized as if it were in GNF form.
2 LR-Hiero rule extraction excludes non-GNF rules such as
X --+ (X1 noch nicht gemacht X2, X2 not yet done X1).
</footnote>
<figure confidence="0.94568575">
students have not yet done their work .
(a)
X1
students
have
X2
X6
X3
not yet
.
X4 X5
ihre arbeit gemacht done their work
(b)
1
X1
schuler
3 6
X6
5 4
X5 noch nicht X4
2
X2
X3 haben
.
</figure>
<page confidence="0.769779">
1090
</page>
<bodyText confidence="0.42637">
allow reordering as well.
</bodyText>
<equation confidence="0.999789857142857">
X ( fX1, eX1) X (X1 fX2, eX1X2)
fX2, eX2X1) (3)
X � (X1
�
1
f,
eX1) X � (X
</equation>
<bodyText confidence="0.999820821428571">
It might appear that the restriction that target-side
rules be GNF is a severe restriction on the cover-
age of possible hypotheses compared to the full set
of rules permitted by the Hiero extraction heuris-
tic. However there is some evidence in the liter-
ature that discontinuous spans on the source side
in translation rules is a lot more useful than dis-
continuous spans in the target side (which is disal-
lowed in the GNF). For instance, (Galley and Man-
ning, 2010) do an extensive study of discontinuous
spans on source and target side and show that source
side discontinuous spans are very useful but remov-
ing discontinuous spans on the target side only low-
ers the BLEU score by 0.2 points (using the Joshua
SMT system on Chinese-English). Removing dis-
continuous spans means that the target side rules
have the form: uX, Xu, XuX, XXu, or uXX of
which we disallow Xu, XuX, XXu. Zhang and
Zong (2012) also conduct a study on discontinuous
spans on source and target side of Hiero rules and
conclude that source discontinuous spans are always
more useful than discontinuities on the target side
with experiments on four language pairs (zh-en, fr-
en, de-en and es-en). As we shall also see in our
experimental results (see Table 4) we can get close
to the BLEU scores obtained using the full set of Hi-
ero rules by using only target lexicalized rules in our
LR decoder.
</bodyText>
<subsectionHeader confidence="0.996923">
2.2 LR-Hiero Decoding
</subsectionHeader>
<bodyText confidence="0.999892384615385">
LR-Hiero decoding uses a top-down depth-first
search, which strictly grows the hypotheses in target
surface ordering. Search on the source side follows
an Earley-style search (Earley, 1970), the dot jumps
around on the source side of the rules based on the
order of nonterminals on the target side. This search
is integrated with beam search or cube pruning to
efficiently find the k-best translations.
Several important details about the algorithm of
LR-Hiero decoding are implicit and unexplained
in (Watanabe et al., 2006b). In this section we de-
scribe the LR-Hiero decoding algorithm in more de-
tail than the original description in (Watanabe et al.,
</bodyText>
<listItem confidence="0.961837727272728">
Algorithm 1: LR-Hiero Decoding
1: Input sentence: f = f0f1 ... fn
2: J7 = FutureCost(f) (Precompute future cost for
spans)
3: for i = 0,...,n do
4: Si = {} (Create empty stacks)
5: h0 = ((s), [[0, n]], 0, J7[0,n]) (Initial hypothesis
4-tuple)
6: Add h0 to S0 (Push initial hyp into first Stack)
7: for i = 0,...,n − 1 do
8: for each h in Si do
9: [u, v] = pop(hs) (Pop first uncovered span
from list)
10: R = GetSpanRules([u, v]) (Extract rules
matching the entire span [u, v])
11: for r E R do
12: h&apos; = GrowHypothesis(h, r, [u, v], J7) (New
hypothesis)
13: Add h&apos; to Sl, where l = h&apos; (Add new
co
hyp to stack)
14: return argmax(Sn)
15: GrowHypothesis(h, r, [u, v], J7)
16: h&apos; = (h&apos;t = 0, h&apos; s = hs, h&apos;cov = 0, h&apos; c = 0)
17: rX = {Xj, Xk, ... Ij a k a ...} (Get NTs in
surface order)
18: for each X in reverse(rX) do
19: push(h&apos; s, span(X)) (Push uncovered spans to
LIFO list)
20: h&apos;t = Concatenate(ht, rt)
21: h&apos; cov = UpdateCoverage(hcov, rs)
22: h&apos; c = ComputeCost(g(h&apos;),J77hl_)
23: return h&apos;
</listItem>
<bodyText confidence="0.999518411764706">
2006b). We explain our own modified algorithm for
LR decoding with cube pruning in Section 2.3.
Algorithm 1 shows the pseudocode for LR de-
coding. Decoding the example in Figure 1(b)
is explained using a walk-through shown in Fig-
ure 2. Each partial hypothesis h is a 4-tuple
(ht, hs, hcov, hc): consisting of a translation prefix
ht, a (LIFO-ordered) list hs of uncovered spans,
source words coverage set hcov and the hypothesis
cost hc. The initial hypothesis is a null string with
just a sentence-initial marker (s) and the list hs con-
taining a span of the whole sentence, [0, n]. The hy-
potheses are stored in stacks S0,... , Sn, where each
stack corresponds to a coverage vector of same size,
covering same number of source words (Koehn et
al., 2003).
At the beginning of beam search the initial hy-
</bodyText>
<page confidence="0.970101">
1091
</page>
<figure confidence="0.935009058823529">
rules source side coverage hypothesis
 X ⟦schulerihre arbeit nochnicht gemacht haben.⟧
schuler  X1 1⟦ihrearbeit nochnicht gemacht haben.⟧
&lt;s&gt;
schuler  X1 2⟦ihre arbeit nochnicht gemacht⟧ haben X2 2⟦.⟧
schuler X1 3⟦ihrearbeit⟧ nochnicht X2 3⟦gemacht⟧ haben X2 2⟦.⟧
schuler  X1 3 ⟦ihre arbeit⟧ nochnicht gemacht haben X2 2⟦.⟧
schuler ihre arbeitnochnicht gemacht haben X2 2⟦.⟧
schuler ihre arbeit nochnicht gemacht haben.
&lt;s&gt;
&lt;s&gt;
&lt;s&gt;
&lt;s&gt; &lt;s&gt;
&lt;s&gt;
[0,8]
students[1,8]
students have[1,6][7,8]
</figure>
<construct confidence="0.380398">
students have notyet[5,6][1,3][7,8]
students have notyetdone[1,3][7,8]
students have not yet done their work[7,8]
students have not yet done their work. &lt;/s&gt;
</construct>
<figure confidence="0.985722166666667">
G 1)X →〈schuler X1/ students X1〉
G 2)X→〈X1heban X2/have X1X2〉
3) X→〈X1nochnicht X2/not yet X 2X1〉
4 ) X →〈gemacht /done〉
5) X→〈ihre arbeit /their work〉
6)X→〈./.〉
</figure>
<figureCaption confidence="0.960324">
Figure 2: Illustration of the LR-Hiero decoding process in Figure 1. (a) Rules pane show the rules used in the derivation
(glue rules are marked by G) (b) Decoder state using Earley dot notation (superscripts show rule#) (c) Hypotheses pane
showing translation prefix and ordered list of yet-to-be-covered spans.
</figureCaption>
<bodyText confidence="0.999967431034483">
pothesis h0 is added to the decoder stack S0 (line 6
in Algoorithm 1). Hypotheses in each decoder stack
are expanded iteratively, generating new hypotheses,
which are added to the latter stacks corresponding to
the number of source words covered. In each step it
pops from the LIFO list hs, the span [u, v] of the
next hypothesis h to be processed.
All rules that match the entire span [u, v] are then
obtained efficiently via pattern matching (Lopez,
2007). GetSpanRules addresses possible ambigui-
ties in matched rules to the given span [u, v]. For
example, given a rule r, with source side rs :
(X1 the X2) and source phrase p : (ok, the more
the better). There is ambiguity in matching r to
p. GetSpanRules returns a distinct matched rule for
each possible matching.
The GrowHypothesis routine creates a new can-
didate by expanding given hypothesis h using rule
r and computes the complete hypothesis score in-
cluding language model score. Since the target-side
rules are in GNF, the translation prefix of the new
hypothesis is obtained by simply concatenating the
terminal prefixes of h and r in same order (line 20).
UpdateCoverage updates source word coverage set
using the source side of r. The hs list is built by
pushing the non-terminal spans of rule r in a reverse
order (lines 17 and 18). The reverse ordering main-
tains the left-to-right generation of the target side.
In the walk-through in Figure 2, the derivation
process starts by expanding the initial hypothesis h0
(first item in the right pane of Fig 2) with the rule
(rule #1 in left pane) to generate a new partial candi-
date having a terminal prefix of (s) students (second
item in right pane). The second item in the middle
pane shows the current position of the parser em-
ploying Earley’s dot notation, indicating that the first
word has already been translated. Now the decoder
considers the second hypothesis and pops the span
[1, 8]. It then matches the rule (#2) and pushes the
spans [1, 6] and [7,8] into the list hs in the reverse
order of their appearance in the target-side rule. At
each step the new hypothesis is added to the decoder
stack Sl depending on the number of covered words
in the new hypothesis (line 13 in Algorithm 1).
For pruning we use an estimate of the future cost3
of the spans uncovered by current hypothesis to-
gether with the hypothesis cost. The future cost is
precomputed (line 2 Algorithm 1) in a way simi-
lar to the phrase-based models (Koehn et al., 2007)
using only the terminal rules of the grammar. The
ComputeCost method (line 22 in Algorithm 1) uses
the usual log-linear model and scores a hypothesis
based on its different feature scores g(h&apos;) and the
future cost of the yet to be covered spans (.Fhyo„).
Time complexity of left to right Hiero decoding with
beam search is O(n2b) in practice where n is the
length of source sentence and b is the size of beam
(Huang and Mi, 2010).
</bodyText>
<subsectionHeader confidence="0.969339">
2.3 LR-Hiero Decoding with Cube Pruning
</subsectionHeader>
<bodyText confidence="0.999904833333333">
The Algorithm 1 presented earlier does an ex-
haustive search as it generates all possible partial
translations for a given stack that are reachable from
the hypotheses in previous stacks. However only a
few of these hypotheses are retained, while majority
of them are pruned away. The cube pruning tech-
nique (Chiang, 2007) avoids the wasteful generation
of poor hypotheses that are likely to be pruned away
by efficiently restricting the generation to only high
scoring partial translations.
We modify the cube pruning for LR-decoding
that takes into account the next uncovered span to
</bodyText>
<footnote confidence="0.9360345">
3 Watanabe et al. (2006b) also use a similar future cost, even
though it is not discussed in the paper (p.c.).
</footnote>
<page confidence="0.96202">
1092
</page>
<construct confidence="0.411233">
Algorithm 2: LR-Hiero Decoding with Cube Pruning
</construct>
<listItem confidence="0.983442882352941">
1: Input sentence: f = f0f1 ... fn
2: F = FutureCost(f) (Precompute future cost for
spans)
3: S0 = {} (Create empty initial stack)
4: h0 = ((s), [[0, n]], 0, F[0,n]) (Initial hypothesis
4-tuple)
5: Add h0 to S0 (Push initial hyp into first Stack)
6: for i = 1,...,n do
7: cubeList = {} (MRL is max rule length)
8: for p = max(i − MRL, 0), ... , i − 1 do
9: {G} = Grouped(Sp) (Group based on the first
uncovered span)
10: for g E {G} do
11: [u, v] = gspan
12: R = GetSpanRules([u, v])
13: for Rs E R do
14: cube = [ghyps, Rs]
15: Add cube to cubeList
16: Si = Merge(cubeList, F) (Create stack Si and
add new hypotheses to it, see Figure 3)
17: return argmax(Sn)
18: Merge(CubeList, F)
19: heapQ = {}
20: for each (H, R) in cubeList do
21: [u, v] = span of rule R
22: h0 = GrowHypothesis(h1, r1, [u, v], F) (from
Algorithm 1)
23: push(heapQ, (h0�, h0, [H, R])
24: hypList = {}
25: while |heapQ |&gt; 0 and |hypList |&lt; K do
26: (h0�, h0, [H, R]) = pop(heapQ)
27: push(heapQ, GetNeighbours([H, R])
28: Add h0 to hypList
29: return hypList
</listItem>
<bodyText confidence="0.9996319">
be translated indicated by the Earley’s dot nota-
tion. The Algorithm 2 shows the pseudocode for
LR-decoding using cube pruning. The structure of
stacks and hypotheses and computing the future cost
is similar to Algorithm 1 (lines 1-5). To fill stack
Si, it iterates over previous stacks (line 8 in Algo-
rithm 2) 4. All hypotheses in each stack Sp (cov-
ering p words on the source-side) are first parti-
tioned into a set of groups, {G}, based on their
first uncovered span (line 9) 5. Each group g is a
</bodyText>
<footnote confidence="0.9974845">
4As the length of rules are limited (at most MRL), we can
ignore stacks with index less than i − MRL
5The beam search decoder in Phrase-based system (Huang
and Chiang, 2007; Koehn et al., 2007; Sankaran et al., 2010)
</footnote>
<bodyText confidence="0.995788613636364">
2-tuple (gspan, ghyps), where ghyps is a list of hy-
potheses which share the same first uncovered span
gspan. Rules matching the span gspan are obtained
from routine GetSpanRules, which are then grouped
based on unique source side rules (i.e. each Rs con-
tains rules that share the same source side s but have
different target sides). Each ghyps and possible Rs6
create a cube which is added to cubeList.
In LR-Hiero, each hypothesis is developed with
only one uncovered span, therefore each cube al-
ways has just two dimensions: (1) hypotheses with
the same number of covered words and similar first
uncovered span, (2) rules sharing the same source
side. In Figure 3(a), each group of hypotheses,
ghyps, is shown in a green box (in stacks), and each
rectangle on the top is a cube. Figure 3 is using the
example in Figure 2.
The Merge routine is the core function of cube
pruning which generates the best hypotheses from
all cubes (Chiang, 2007). For each possible cube,
(H, R), the best hypothesis is generated by calling
GrowHypothesis(hi, ri, span, F) where hi and
ri are the best hypothesis and rule in H and R re-
spectively (line 22). Figure 3 (b) shows a more de-
tailed view of a cube (shaded cube in Figure 3(a)).
Rows are hypotheses and columns are rules which
are sorted based on their scores.
The first best hypotheses, h&apos;, along with their
score, h&apos; � and corresponding cube, (H, R) are
placed in a priority queue, heapQ (triangle in Fig-
ure 3). Iteratively the best hypothesis is popped
from the queue (line 26) and its neighbours in
the cube are added to the priority queue (using
GetNeighbours([H, Q])). It continues to generate
all K best hypotheses. Using cube pruning tech-
nique, each stack is filled with K best hypotheses
without generating all possible hypotheses in each
cube.
groups the hypotheses in a given stack based on their coverage
vector. But this idea does not work in LRHiero decoding in
which the expansion of each hypothesis is restricted to its first
uncovered span. We have also tried another way of grouping
hypotheses: group by all uncovered spans, h3. Our experiments
did not show any significant difference between the final results
</bodyText>
<footnote confidence="0.777915">
(BLEU score), therefore we decided to stick to the simpler idea:
using first uncovered span for grouping.
6Note that, just rules whose number of terminals in their
source side is equal to i − p can be used.
</footnote>
<page confidence="0.959732">
1093
</page>
<figure confidence="0.9997347">
made
do
done
0.9 1.1 3.2
students have not yet [5,6] 10.2 12.5 12.4 14.3 12.5 12.4 14.3
pupils have not yet [5,6] 11.5 12.6 12.8 14.7 12.6 12.8 14.7
student has not already [5,6] 12.7 13.3 13.5 15.4 13.3 13.5 15.4
1 2 3 4 5
[1,6]
[1,6]
[1,6]
[0,3]
[0,3]
[5,6]
[5,6]
[1,4]
[6,8]
[6,8]
[5,6]
[5,6]
[5,6]
[1,3]
[7,8]
[5,8]
[1,8]
[1,8]
[0,3]
[0,3]
[1,3]
(a) (b)
</figure>
<figureCaption confidence="0.71622075">
Figure 3: Example of generating hypotheses in cube pruning using Figure 2: (a) Hypotheses in previous stacks are
grouped based on their first uncovered span, and build cubes (grids on top). Cubes are in different sizes because
of different number of rules and group sizes. Cubes are fed to a priority queue (triangle) and new hypotheses are
iteratively popped from the queue and added to the current stack, S5. (b) Generating hypotheses from a cube. The top
side of the grid denotes the target side of rules sharing the same source side (R3) along with their scores. Left side of
the grid shows the hypotheses in a same group, their first uncovered span and their scores. Hypothesis generated from
row 1 and column 1 is added to the queue at first. Once it is popped from the queue, its neighbours (in the grid) are
subsequently added to the queue.
</figureCaption>
<bodyText confidence="0.98696">
Figure 3 (b) shows the derivation of the two best
hypotheses from the cube. The best hypothesis of
this cube which is likely created from the best hy-
pothesis and rule (left top most entry) is popped
at first step. Then, GetNeighbours calls GrowHy-
pothesis to generate next potential best hypotheses
of this cube (neighbours of the popped entry which
are shaded in Figure 3(b)). These hypotheses are
added to the priority queue. In the next iteration, the
best hypothesis is popped from all candidates in the
queue and algorithm continues.
</bodyText>
<sectionHeader confidence="0.999667" genericHeader="method">
3 Features
</sectionHeader>
<bodyText confidence="0.999845405405405">
We use the following standard SMT features for the
log-linear model of LR-Hiero: relative-frequency
translation probabilities p(f|e) and p(e|f), lexical
translation probabilities pl(f|e) and pl(e|f), a lan-
guage model probability, word count and phrase
count. In addition we also use the glue rule count
and the two reordering penalty features employed
by Watanabe et al. (2006b; 2006a). These features
compute the height and width (span size of the en-
tire subtree) of all subtrees which are backtraced in
the derivation of a hypothesis. A non-terminal XZ
is pushed into the LIFO list of a partial hypothesis;
it’s backtrace refers to the set of NTs that must be
popped before XZ.
In Figure 1(b), X2 has two subtrees X3 and X6,
where X3 should be processed before X6. The sub-
tree rooted at X3 in Figure 1(b) has a height of 2 and
span [1, 6] having a width of 5. Similarly, X4 should
be backtraced before X5 and has height and width of
1. Backtracing applies only for rules having at least
two non-terminals. Thus the total height and width
penalty for this derivation are 3 and 6 respectively.
However, the height and width features do not
distinguish between a rule that reorders the non-
terminals in source and target from one that pre-
serves the ordering. Rules #2 and #3 in Figure 2
are treated equally although they have different or-
derings. The decoder is thus agnostic to this dif-
ference and would not be able to exploit this ef-
fectively to control reordering and instead would
rely on the partial LM score. This issue is exac-
erbated for glue rules, where the decoder has to
choose from different possibilities without any way
to favour one over the others. Instead of the rule
#2, the decoder could use its reordered version
(X1 haben X2, have X2 X1) leading to a poor
translation.
</bodyText>
<page confidence="0.99174">
1094
</page>
<bodyText confidence="0.99998075">
The features we introduce can be used to learn
if the model should favour monotone translations at
the cost of re-orderings or vice versa and hence can
easily adapt to different language pairs. Further, our
experiments (see Section 4) suggest that the features
h and w are not sufficient by themselves to model re-
ordering for language pairs exhibiting very different
syntactic structure.
</bodyText>
<subsectionHeader confidence="0.999243">
3.1 Distortion Features
</subsectionHeader>
<bodyText confidence="0.999527">
Our distortion features are inspired by their name-
sake in phrase-based system, with some modifica-
tions to adapt the idea for the discontiguous phrases
in LR-Hiero grammar.
</bodyText>
<equation confidence="0.7667384">
T : (f1X1f2X2f0X2X1) I = [`,�1,�2,�3,X2,X1,a1
r :〈X1noch nicht X2/not yet X2 X1〉
(b)
1ihre2arbeit3noch4nicht5gemacht6
I=[(1,1),(3,5),(5,6),(1,3),(6,6)]
</equation>
<figureCaption confidence="0.9981538">
Figure 4: (a) Distortion feature computation using a rule
r. (b) Example of distortion computation for applying r3
on phrase (ihre arbeit noch nicht gemacht haben). sub-
scripts between words show the indices which are used to
build I. Distortion would be: d = 2 + 0 + 5 + 3.
</figureCaption>
<bodyText confidence="0.998535352941177">
Consider a rule r = (-y, b Q), with the source
term -y being a mixed string of terminals and non-
terminals. Representing the non-terminal spans and
each sequence of terminals in -y as distinct items, our
distortion feature counts the total length ofjumps be-
tween the items during Earley parsing.
Figure 4 (a) explains the computation of our dis-
tortion feature for an example rule r. Let I =
[I0, ... , Ik] be the items denoting the terminal se-
quences and non-terminal spans with I0 and Ik be-
ing dummy items (�- and -1 in Fig) marking the left
and right indices of the rule r in input sentence f.
Other items are arranged by their realization order
on the target-side with the terminal sequences pre-
ceding non-terminal spans. The items for the exam-
ple rule are shown in Figure 4 (a). The distortion
feature is computed as follows:
</bodyText>
<equation confidence="0.996579">
k
d(r) = |IS − I�j�1 |(4)
j=1
</equation>
<bodyText confidence="0.999971952380952">
where superscripts refer to position of left (Z) and
right (92,) edge of each item in the source sentence
f. These are then aggregated across the rules of a
derivation D as: d = E,CD d(r). For each item
Ij, we count the jump from the end of previous item
to the beginning of the current. In Figure 4 (a) the
jumps are indicated by the arrows above the rule.
Figure 4 (b) shows an example of distortion com-
putation for r3 and phrase (ihre arbeit noch nicht
gemacht haben) from Figure 2.
Since the glue rules are likely to be used in the top
levels (possibly with large distortion) of the deriva-
tion, we would want the decoder to learn the distor-
tion for regular and glue rules separately. We thus
use two distortion features for the two rule types and
we call them dp and dg.
These features do not directly model the source-
target reordering, but only capture the source-side
jumps. Furthermore they apply for both monotone
and reordering rules. We now introduce a new fea-
ture for exclusively modelling the reordering.
</bodyText>
<subsectionHeader confidence="0.999964">
3.2 Reordering Feature
</subsectionHeader>
<bodyText confidence="0.999983428571429">
This feature simply counts the number of reordering
rules, where the non-terminals in source and target
sides are reordered. Thus rod = rule(D, ()), where
rule(D, ()) is the number of reordering rules in D.
Similar to width and height, this feature is applied
for rule having at least two non-terminals. This fea-
ture is applied to regular and glue rules.
</bodyText>
<sectionHeader confidence="0.998656" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999910166666667">
We conduct different types of experiments to evalu-
ate LR-Hiero decoding developed by cube pruning
and integrating new features into LR-Hiero system
for two language pairs: German-English (de-en) and
Czech-English (cs-en).Table 1 shows the dataset de-
tails.
</bodyText>
<subsectionHeader confidence="0.998762">
4.1 System Setup
</subsectionHeader>
<bodyText confidence="0.993544666666667">
In our experiments we use four baselines as well
as our implementation of LR-Hiero (written in
Python):
</bodyText>
<figure confidence="0.981646833333333">
J3
X2
X,
J2
J,
(a)
</figure>
<page confidence="0.956213">
1095
</page>
<table confidence="0.998456">
Corpus Train/Dev/Test
cs-en Europarl(v7), CzEng(v0.9); 7.95M/3000/3003
News commentary
de-en Europarl(v7); News 1.5M/2000/2000
commentary
</table>
<tableCaption confidence="0.996201">
Table 1: Corpus statistics in number of sentences
</tableCaption>
<table confidence="0.99936725">
Model cs-en de-en
Phrase-based 233.0 77.2
Hiero 1,961.6 858.5
LR-Hiero 230.5 101.3
</table>
<tableCaption confidence="0.968285666666667">
Table 2: Model sizes (millions of rules). We do not count
glue rules for LR-Hiero which are created at runtime as
needed.
</tableCaption>
<listItem confidence="0.996877733333333">
• Hiero: we used Kriya, our open-source im-
plementation of Hiero in Python, which per-
forms comparably to other open-source Hiero
systems (Sankaran et al., 2012). Kriya can
obtain statistically significantly equal BLEU
scores when compared with Moses (Koehn et
al., 2007) for several language pairs (Razmara
et al., 2012; Callison-Burch et al., 2012).
• Hiero-GNF: where we use Hiero decoder with
the restricted LR-Hiero grammar (GNF rules).
• LR-Hiero: our implementation of LR-Hiero
(Watanabe et al., 2006b) in Python.
• phrase-based: Moses (Koehn et al., 2007)
• LR-Hiero+CP: LR-Hiero decoding with cube
pruning.
</listItem>
<bodyText confidence="0.947035769230769">
We use a 5-gram LM trained on the Gigaword cor-
pus and use KenLM (Heafield, 2011) for LM scor-
ing during decoding. We tune weights by minimiz-
ing BLEU loss on the dev set through MERT (Och,
2003) and report BLEU scores on the test set. We
use comparable pop limits in each of the decoders:
1000 for Moses and LR-Hiero and 500 with cube
pruning for CKY Hiero and LR-Hiero+CP. Other
extraction and decoder settings such as maximum
phrase length, etc. were identical across settings so
that the results are comparable.
Table 2 shows how the LR-Hiero grammar is
much smaller than CKY-based Hiero.
</bodyText>
<table confidence="0.998874428571428">
Model cs-en de-en
#queries / time(ms) #queries / time(ms)
Hiero 5,679.7 / 16.12 7,231.62 / 20.33
Hiero-GNF 4,952.5 / 14.71 5,858.74 / 18.23
LR-Hiero (1000) 46,333.21 / 163.6 83,518.63 / 328.11
LR-Hiero (500) 24,141.03 / 97.61 42,783.12 / 192.23
LR-Hiero+CP 1,303.2 / 4.2 1,697.7 / 5.67
</table>
<tableCaption confidence="0.994694">
Table 3: Comparing average number and time of lan-
guage model queries.
</tableCaption>
<subsectionHeader confidence="0.997141">
4.2 Time Efficiency Comparison
</subsectionHeader>
<bodyText confidence="0.999954178571429">
To evaluate the performance of LR-Hiero decod-
ing with cube pruning (LR-Hiero+CP), we compare
it with three baselines: (i) CKY Hiero, (ii) CKY
Hiero-GNF, and (iii) LR-Hiero (without cube prun-
ing) with two different beam size 500 and 1000.
When it comes to instrument timing results, there are
lots of system level details that we wish to abstract
away from, and focus only on the number of “edges”
processed by the decoder. In comparison of parsing
algorithms, the common practice is to measure the
number of edges processed by different algorithms
for the same reason (Moore and Dowding, 1991).
By analogy to parsing algorithm comparisons, we
compare the different decoding algorithms with re-
spect to the number of calls made to the language
model (LM) since that directly corresponds to the
number of hypotheses considered by the decoder.
A decoder is more time efficient if it can consider
fewer translation hypotheses while maintaining the
same BLEU score. All of the baselines use the same
wrapper to query the language model, and we have
instrumented the wrapper to count the statistics we
need and thus we can say this is a fair comparison.
For this experiment we use a sample set of 50 sen-
tences taken from the test sets.
Table 3 shows the results in terms of average num-
ber of language model queries and times in millisec-
onds.
</bodyText>
<subsectionHeader confidence="0.998392">
4.3 Reordering Features
</subsectionHeader>
<bodyText confidence="0.999796333333333">
To evaluate the new reordering features proposed
to LR-Hiero (Section 3.2), LR-Hiero+CP with new
features is compared to all baselines. Table 4 shows
the BLEU scores of different models in two lan-
guage pairs. The baseline (Watanabe et al., 2006b)
model uses all the features mentioned therein but is
</bodyText>
<page confidence="0.954498">
1096
</page>
<table confidence="0.998662666666667">
Model cs-en de-en
Phrase-based 20.32 24.71
CKY Hiero 20.64 25.52
CKY Hiero-GNF 20.04 24.84
LR-Hiero 18.30 23.47
LR-Hiero + reordering feats 20.20 24.90
LR-Hiero + CP + reordering feats 20.15 24.83
CKY Hiero-GNF + reordering feats 20.52 25.09
CKY Hiero + reordering feats 20.77 25.72
</table>
<tableCaption confidence="0.887697">
Table 4: BLEU scores. The rows are grouped such that
each group use the same model. The last row in part 2 of
table shows LR-Hiero+CP using our new features in ad-
</tableCaption>
<bodyText confidence="0.99258565625">
dition to the baseline Watanabe features (line LR-Hiero
baseline). The last part shows CKY Hiero using new re-
ordering features. The reordering features used are dp, d9
and ro. LR-Hiero+CP has a beam size of 500 while LR-
Hiero has a beam size of 1000, c.f. with the LM calls
shown in Table 3.
worse than both phrase-based and CKY-Hiero base-
lines by up to 2.3 BLEU points.
All the reported results are obtained from a single
optimizer run. However we observed insignificant
changes in different tuning runs in our experiments.
We find a gain of about 1 BLEU point when we add
a single distortion feature d and a further gain of
0.3 BLEU (not shown due to lack of space) when
we split the distortion feature for the two rule types
(dp and dg). The last line in part two of Table 4
shows a consistent gain of 1.6 BLEU over the LR-
Hiero baseline for both language pairs. It shows that
LR-Hiero maintains the BLEU scores obtained by
“phrase-based” and “CKY Hiero-GNF”.
We performed statistical significance tests us-
ing two different tools: Moses bootstrap resam-
pling and MultEval (Clark et al., 2011). The dif-
ference between “LR-Hiero+CP+reordering feat”
and three baselines: “phrase-based”, “CKY Hiero-
GNF”, “LR-Hiero+reordering feat” are not statis-
tically significant even for p-value of 0.1 for both
tools.
To investigate the impact of proposed reordering
features with other decoder or models. We add these
features to both Hiero and Hiero-GNF7. The last
part of Table 4 shows the performance CKY decoder
</bodyText>
<footnote confidence="0.98022675">
7Feature rod is defined for SCFG rules and cannot be
adopted to phrase-based translation systems; and Moses uses
distortion feature therefore we omit Moses from this experi-
ment.
</footnote>
<bodyText confidence="0.999972086956522">
with different models (full Hiero and GNF) with the
new reordering features in terms of BLEU score.
The results show that these features are helpful in
both models. Although, they do not make a big dif-
ference in Hiero with full model, they can alleviate
the lack of non-GNF rules in Hiero-GNF.
Nguyen and Vogel (2013) integrate traditional
phrase-based features: distortion and lexicalized re-
ordering into Hiero as well. They show that such
features can be useful to boost the translation quality
of CKY Hiero with the full rule set. Nguyen and Vo-
gel (2013) compute the distortion feature in a differ-
ent way, only applicable to CKY. The distortion for
each cell is computed after the translation for non-
terminal sub-spans is complete. In LR-decoding,
we compute distortion for rules even though we are
yet to translate some of the sub-spans. Thus our ap-
proach computes the distortion incrementally for the
untranslated sub-spans which are later added. Un-
like (Nguyen and Vogel, 2013), our distortion fea-
ture can be applied to both LR and CKY-decoding
(Table 4). We have also introduced another reorder-
ing feature (Section 3.2) not proposed previously.
</bodyText>
<sectionHeader confidence="0.992794" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999010521739131">
We provided a detailed description of left-to-right
Hiero decoding, many details of which were only
implicit in (Watanabe et al., 2006b). We presented
an augmented LR decoding algorithm that builds on
the original algorithm in (Watanabe et al., 2006b)
but unlike that algorithm, using experiments over
multiple language pairs we showed two new results:
(i) Our LR decoding algorithm provides demonstra-
bly more efficient decoding than CKY Hiero and the
original LR decoding algorithm in (Watanabe et al.,
2006b). And, (ii) by introducing new distortion and
reordering features for LR decoding we show that
it maintains the BLEU scores obtained by phrase-
based and CKY Hiero-GNF.
CKY Hiero uses standard Hiero-style translation
rules capturing better reordering model than prefix
lexicalized target-side translation rules used in LR-
Hiero. Our LR-decoding algorithm is 4 times faster
in terms of LM calls while translation quality suffers
by about 0.67 in BLEU score on average.
Unlike Watanabe et al. (2006b), our new features
can easily adapt to the reordering requirements of
different language pairs. We also introduce the use
</bodyText>
<page confidence="0.985038">
1097
</page>
<bodyText confidence="0.999943647058824">
of future cost in decoding algorithm which is an es-
sential part in decoding. We have shown in this pa-
per that left-to-right (LR) decoding can be consid-
ered as a potential faster alternative to CKY decod-
ing for Hiero-style machine translation systems.
In future work, we plan to apply lexicalized re-
ordering models to LR-Hiero. It has been shown to
be useful for Hiero in some languages therefore it
is promising to improve translation quality in LR-
Hiero which suffers from lack of modeling power
of non-GNF target side rules. We also plan to ex-
tend the glue rules in LR-Hiero to provide a bet-
ter reordering model. We believe such an exten-
sion would be very effective in reducing search er-
rors and capturing better reordering models in lan-
guage pairs involving complex reordering require-
ments like Chinese-English.
</bodyText>
<sectionHeader confidence="0.999022" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999925333333333">
This research was partially supported by an NSERC,
Canada (RGPIN: 264905) grant and a Google Fac-
ulty Award to the third author. The authors wish
to thank Taro Watanabe and Marzieh Razavi for
their valuable discussions and suggestions, and the
anonymous reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.998984" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997394213333333">
Chris Callison-Burch, Philipp Koehn, Christof Monz,
Matt Post, Radu Soricut, and Lucia Specia. 2012.
Findings of the 2012 workshop on statistical machine
translation. In Proceedings of the Seventh Work-
shop on Statistical Machine Translation, pages 10–
51, Montr´eal, Canada, June. Association for Compu-
tational Linguistics.
David Chiang. 2005. A hierarchical phrase-based model
for statistical machine translation. In In ACL, pages
263–270.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A.
Smith. 2011. Better hypothesis testing for statisti-
cal machine translation: controlling for optimizer in-
stability. In Proceedings of the 49th Annual Meeting
of the Association for Computational Linguistics: Hu-
man Language Technologies: short papers - Volume
2, HLT ’11, pages 176–181, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Jay Earley. 1970. An efficient context-free parsing algo-
rithm. Commun. ACM, 13(2):94–102, February.
Michel Galley and Christopher D. Manning. 2010. Ac-
curate non-hierarchical phrase-based translation. In
Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 966–
974, Los Angeles, California, June. Association for
Computational Linguistics.
Kenneth Heafield, Hieu Hoang, Philipp Koehn, Tetsuo
Kiso, and Marcello Federico. 2011. Left language
model state for syntactic machine translation. In Pro-
ceedings of the International Workshop on Spoken
Language Translation, pages 183–190, San Francisco,
California, USA, 12.
Kenneth Heafield, Philipp Koehn, and Alon Lavie. 2013.
Grouping language model boundary words to speed K-
Best extraction from hypergraphs. In Proceedings of
the 2013 Conference of the North American Chapter
of the Association for Computational Linguistics: Hu-
man Language Technologies, Atlanta, Georgia, USA,
6.
Kenneth Heafield. 2011. KenLM: Faster and smaller
language model queries. In In Proc. of the Sixth Work-
shop on Statistical Machine Translation.
Liang Huang and David Chiang. 2007. Forest rescoring:
Faster decoding with integrated language models. In
In ACL 07.
Liang Huang and Haitao Mi. 2010. Efficient incremental
decoding for tree-to-string translation. In Proceedings
of the 2010 Conference on Empirical Methods in Natu-
ral Language Processing, pages 273–283, Cambridge,
MA, October. Association for Computational Linguis-
tics.
Philipp Koehn, Franz Josef Och, and Daniel Marcu.
2003. Statistical phrase-based translation. In Proc.
of NAACL.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Con-
stantin, and Evan Herbst. 2007. Moses: open source
toolkit for statistical machine translation. In Proceed-
ings of the 45th Annual Meeting of the ACL on Inter-
active Poster and Demonstration Sessions, ACL ’07,
pages 177–180, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Adam Lopez. 2007. Hierarchical phrase-based trans-
lation with suffix arrays. In EMNLP-CoNLL, pages
976–985.
Robert C. Moore and John Dowding. 1991. Efficient
bottom-up parsing. In HLT. Morgan Kaufmann.
Thuylinh Nguyen and Stephan Vogel. 2013. Integrat-
ing phrase-based reordering features into chart-based
decoder for machine translation. In Proc. of ACL.
</reference>
<page confidence="0.806837">
1098
</page>
<reference confidence="0.999858272727273">
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Annual Meeting on Association for Compu-
tational Linguistics - Volume 1, ACL ’03, pages 160–
167, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Majid Razmara, Baskaran Sankaran, Ann Clifton, and
Anoop Sarkar. 2012. Kriya - the sfu system for trans-
lation task at wmt-12. In Proceedings of the Seventh
Workshop on Statistical Machine Translation, WMT
’12, pages 356–361, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Baskaran Sankaran, Ajeet Grewal, and Anoop Sarkar.
2010. Incremental decoding for phrase-based statis-
tical machine translation. In Proceedings of the Joint
Fifth Workshop on Statistical Machine Translation and
MetricsMATR, WMT ’10, pages 216–223, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Baskaran Sankaran, Majid Razmara, and Anoop Sarkar.
2012. Kriya - an end-to-end hierarchical phrase-based
mt system. The Prague Bulletin of Mathematical Lin-
guistics (PBML), (97):83–98, apr.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki
Isozaki. 2006a. NTT statistical machine translation
for iwslt 2006. In Proceedings of IWSLT 2006, pages
95–102.
Taro Watanabe, Hajime Tsukada, and Hideki Isozaki.
2006b. Left-to-right target generation for hierarchical
phrase-based translation. In Proc. of ACL.
Jiajun Zhang and Chenqqing Zong. 2012. A Compar-
ative Study on Discontinuous Phrase Translation. In
NLPCC 2012, pages 164–175.
</reference>
<page confidence="0.997299">
1099
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.529540">
<title confidence="0.9980105">Efficient Left-to-Right Hierarchical Phrase-based Translation Improved Reordering</title>
<author confidence="0.839164">Maryam Siahbani</author>
<author confidence="0.839164">Baskaran Sankaran</author>
<author confidence="0.839164">Anoop Simon Fraser Burnaby BC</author>
<abstract confidence="0.999735416666667">Left-to-right (LR) decoding (Watanabe et al., 2006b) is a promising decoding algorithm for hierarchical phrase-based translation (Hiero). It generates the target sentence by extending the hypotheses only on the right edge. LR dehas complexity input of and beam size compared to the CKY algorithm. It requires a single language model (LM) history for each target hypothesis rather than two LM histories per hypothesis as in CKY. In this paper we present an augmented LR decoding algorithm that builds on the original algorithm in (Watanabe et al., 2006b). Unlike that algorithm, using experiments over multiple language pairs we show two new results: our LR decoding algorithm provides demonstrably more efficient decoding than CKY Hiero, four times faster; and by introducing new distortion and reordering features for LR decoding, it maintains the same translation quality (as in BLEU scores) obtained phrase-based and CKY Hiero with the same translation model.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>Philipp Koehn</author>
<author>Christof Monz</author>
<author>Matt Post</author>
<author>Radu Soricut</author>
<author>Lucia Specia</author>
</authors>
<title>Findings of the 2012 workshop on statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<pages>10--51</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="28630" citStr="Callison-Burch et al., 2012" startWordPosition="4938" endWordPosition="4941">.5M/2000/2000 commentary Table 1: Corpus statistics in number of sentences Model cs-en de-en Phrase-based 233.0 77.2 Hiero 1,961.6 858.5 LR-Hiero 230.5 101.3 Table 2: Model sizes (millions of rules). We do not count glue rules for LR-Hiero which are created at runtime as needed. • Hiero: we used Kriya, our open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems (Sankaran et al., 2012). Kriya can obtain statistically significantly equal BLEU scores when compared with Moses (Koehn et al., 2007) for several language pairs (Razmara et al., 2012; Callison-Burch et al., 2012). • Hiero-GNF: where we use Hiero decoder with the restricted LR-Hiero grammar (GNF rules). • LR-Hiero: our implementation of LR-Hiero (Watanabe et al., 2006b) in Python. • phrase-based: Moses (Koehn et al., 2007) • LR-Hiero+CP: LR-Hiero decoding with cube pruning. We use a 5-gram LM trained on the Gigaword corpus and use KenLM (Heafield, 2011) for LM scoring during decoding. We tune weights by minimizing BLEU loss on the dev set through MERT (Och, 2003) and report BLEU scores on the test set. We use comparable pop limits in each of the decoders: 1000 for Moses and LR-Hiero and 500 with cube p</context>
</contexts>
<marker>Callison-Burch, Koehn, Monz, Post, Soricut, Specia, 2012</marker>
<rawString>Chris Callison-Burch, Philipp Koehn, Christof Monz, Matt Post, Radu Soricut, and Lucia Specia. 2012. Findings of the 2012 workshop on statistical machine translation. In Proceedings of the Seventh Workshop on Statistical Machine Translation, pages 10– 51, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation. In</title>
<date>2005</date>
<booktitle>In ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="4692" citStr="Chiang, 2005" startWordPosition="739" endWordPosition="740">or Computational Linguistics calized target side rules equals the scores obtained by CKY decoding with prefix lexicalized target side rules and phrase-based translation system. It performs four times fewer language model queries on average, compare to CKY Hiero decoding with unrestricted Hiero rules: 6466.7 LM queries for CKY Hiero (with cube pruning) compared to 1500.45 LM queries in LR Hiero (with cube pruning). While translation quality suffers by only about 0.67 in BLEU score on average, across two different language pairs. 2 Left-to-Right Decoding for Hiero Hierarchical phrase-based SMT (Chiang, 2005; Chiang, 2007) uses a synchronous context free grammar (SCFG), where the rules are of the form X —* (-y, α), where X is a non-terminal, -y and α are strings of terminals and non-terminals. Chiang (2007) places certain constraints on the extracted rules in order to simplify decoding. This includes limiting the maximum number of nonterminals (rule arity) to two and disallowing any rule with consecutive non-terminals on the foreign language side. It further limits the length of the initial phrase-pair as well as the number of terminals and non-terminals in the rule. For translating sentences lon</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In In ACL, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<contexts>
<context position="1261" citStr="Chiang, 2007" startWordPosition="188" endWordPosition="189">two LM histories per hypothesis as in CKY. In this paper we present an augmented LR decoding algorithm that builds on the original algorithm in (Watanabe et al., 2006b). Unlike that algorithm, using experiments over multiple language pairs we show two new results: our LR decoding algorithm provides demonstrably more efficient decoding than CKY Hiero, four times faster; and by introducing new distortion and reordering features for LR decoding, it maintains the same translation quality (as in BLEU scores) obtained phrase-based and CKY Hiero with the same translation model. 1 Introduction Hiero (Chiang, 2007) models translation using a lexicalized synchronous context-free grammar (SCFG) extracted from word aligned bitexts. Typically, CKY-style decoding is used for Hiero with time complexity O(n3) for source input with n words. Scoring the target language output using a language model within CKY-style decoding requires two histories per hypothesis, one on the left edge of each span and one on the right, due to the fact that the target side is not generated in left to right order, but rather built bottom-up from sub-spans. This leads to complex problems in efficient language model integration and re</context>
<context position="4707" citStr="Chiang, 2007" startWordPosition="741" endWordPosition="743">al Linguistics calized target side rules equals the scores obtained by CKY decoding with prefix lexicalized target side rules and phrase-based translation system. It performs four times fewer language model queries on average, compare to CKY Hiero decoding with unrestricted Hiero rules: 6466.7 LM queries for CKY Hiero (with cube pruning) compared to 1500.45 LM queries in LR Hiero (with cube pruning). While translation quality suffers by only about 0.67 in BLEU score on average, across two different language pairs. 2 Left-to-Right Decoding for Hiero Hierarchical phrase-based SMT (Chiang, 2005; Chiang, 2007) uses a synchronous context free grammar (SCFG), where the rules are of the form X —* (-y, α), where X is a non-terminal, -y and α are strings of terminals and non-terminals. Chiang (2007) places certain constraints on the extracted rules in order to simplify decoding. This includes limiting the maximum number of nonterminals (rule arity) to two and disallowing any rule with consecutive non-terminals on the foreign language side. It further limits the length of the initial phrase-pair as well as the number of terminals and non-terminals in the rule. For translating sentences longer than the ma</context>
<context position="7260" citStr="Chiang, 2007" startWordPosition="1176" endWordPosition="1177">larger phrase pair and replaces the spans with non-terminal X, yielding hierarchical rules. Figure 1(a) shows a wordaligned German-English sentence with a phrase pair (ihre arbeit noch nicht gemacht haben, have not yet done their work) that will lead to a SCFG rule. Given other smaller phrases (marked by bars above the source side), we extract a GNF rule2: X —* (X1 noch nicht X2 haben, have not yet X2 X1) (2) In order to avoid data sparsity and for better generalization, Watanabe et al. (2006b) adds four glue rules for each lexical rule (f, e) which are analogous to the glue rules defined in (Chiang, 2007) (see above) except that these glue rules for LR decoding 1Griebach Normal Form (GNF), although the synchronous grammar is not in this normal form, rather only the target side is prefix lexicalized as if it were in GNF form. 2 LR-Hiero rule extraction excludes non-GNF rules such as X --+ (X1 noch nicht gemacht X2, X2 not yet done X1). students have not yet done their work . (a) X1 students have X2 X6 X3 not yet . X4 X5 ihre arbeit gemacht done their work (b) 1 X1 schuler 3 6 X6 5 4 X5 noch nicht X4 2 X2 X3 haben . 1090 allow reordering as well. X ( fX1, eX1) X (X1 fX2, eX1X2) fX2, eX2X1) (3) X</context>
<context position="16105" citStr="Chiang, 2007" startWordPosition="2743" endWordPosition="2744">e scores g(h&apos;) and the future cost of the yet to be covered spans (.Fhyo„). Time complexity of left to right Hiero decoding with beam search is O(n2b) in practice where n is the length of source sentence and b is the size of beam (Huang and Mi, 2010). 2.3 LR-Hiero Decoding with Cube Pruning The Algorithm 1 presented earlier does an exhaustive search as it generates all possible partial translations for a given stack that are reachable from the hypotheses in previous stacks. However only a few of these hypotheses are retained, while majority of them are pruned away. The cube pruning technique (Chiang, 2007) avoids the wasteful generation of poor hypotheses that are likely to be pruned away by efficiently restricting the generation to only high scoring partial translations. We modify the cube pruning for LR-decoding that takes into account the next uncovered span to 3 Watanabe et al. (2006b) also use a similar future cost, even though it is not discussed in the paper (p.c.). 1092 Algorithm 2: LR-Hiero Decoding with Cube Pruning 1: Input sentence: f = f0f1 ... fn 2: F = FutureCost(f) (Precompute future cost for spans) 3: S0 = {} (Create empty initial stack) 4: h0 = ((s), [[0, n]], 0, F[0,n]) (Init</context>
<context position="18236" citStr="Chiang, 2007" startWordPosition="3148" endWordPosition="3149">Algorithm 2 shows the pseudocode for LR-decoding using cube pruning. The structure of stacks and hypotheses and computing the future cost is similar to Algorithm 1 (lines 1-5). To fill stack Si, it iterates over previous stacks (line 8 in Algorithm 2) 4. All hypotheses in each stack Sp (covering p words on the source-side) are first partitioned into a set of groups, {G}, based on their first uncovered span (line 9) 5. Each group g is a 4As the length of rules are limited (at most MRL), we can ignore stacks with index less than i − MRL 5The beam search decoder in Phrase-based system (Huang and Chiang, 2007; Koehn et al., 2007; Sankaran et al., 2010) 2-tuple (gspan, ghyps), where ghyps is a list of hypotheses which share the same first uncovered span gspan. Rules matching the span gspan are obtained from routine GetSpanRules, which are then grouped based on unique source side rules (i.e. each Rs contains rules that share the same source side s but have different target sides). Each ghyps and possible Rs6 create a cube which is added to cubeList. In LR-Hiero, each hypothesis is developed with only one uncovered span, therefore each cube always has just two dimensions: (1) hypotheses with the same</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jonathan H Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<pages>176--181</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="33074" citStr="Clark et al., 2011" startWordPosition="5699" endWordPosition="5702">anges in different tuning runs in our experiments. We find a gain of about 1 BLEU point when we add a single distortion feature d and a further gain of 0.3 BLEU (not shown due to lack of space) when we split the distortion feature for the two rule types (dp and dg). The last line in part two of Table 4 shows a consistent gain of 1.6 BLEU over the LRHiero baseline for both language pairs. It shows that LR-Hiero maintains the BLEU scores obtained by “phrase-based” and “CKY Hiero-GNF”. We performed statistical significance tests using two different tools: Moses bootstrap resampling and MultEval (Clark et al., 2011). The difference between “LR-Hiero+CP+reordering feat” and three baselines: “phrase-based”, “CKY HieroGNF”, “LR-Hiero+reordering feat” are not statistically significant even for p-value of 0.1 for both tools. To investigate the impact of proposed reordering features with other decoder or models. We add these features to both Hiero and Hiero-GNF7. The last part of Table 4 shows the performance CKY decoder 7Feature rod is defined for SCFG rules and cannot be adopted to phrase-based translation systems; and Moses uses distortion feature therefore we omit Moses from this experiment. with different</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A. Smith. 2011. Better hypothesis testing for statistical machine translation: controlling for optimizer instability. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, pages 176–181, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay Earley</author>
</authors>
<title>An efficient context-free parsing algorithm.</title>
<date>1970</date>
<journal>Commun. ACM,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="9460" citStr="Earley, 1970" startWordPosition="1577" endWordPosition="1578">t side of Hiero rules and conclude that source discontinuous spans are always more useful than discontinuities on the target side with experiments on four language pairs (zh-en, fren, de-en and es-en). As we shall also see in our experimental results (see Table 4) we can get close to the BLEU scores obtained using the full set of Hiero rules by using only target lexicalized rules in our LR decoder. 2.2 LR-Hiero Decoding LR-Hiero decoding uses a top-down depth-first search, which strictly grows the hypotheses in target surface ordering. Search on the source side follows an Earley-style search (Earley, 1970), the dot jumps around on the source side of the rules based on the order of nonterminals on the target side. This search is integrated with beam search or cube pruning to efficiently find the k-best translations. Several important details about the algorithm of LR-Hiero decoding are implicit and unexplained in (Watanabe et al., 2006b). In this section we describe the LR-Hiero decoding algorithm in more detail than the original description in (Watanabe et al., Algorithm 1: LR-Hiero Decoding 1: Input sentence: f = f0f1 ... fn 2: J7 = FutureCost(f) (Precompute future cost for spans) 3: for i = 0</context>
</contexts>
<marker>Earley, 1970</marker>
<rawString>Jay Earley. 1970. An efficient context-free parsing algorithm. Commun. ACM, 13(2):94–102, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate non-hierarchical phrase-based translation.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>966--974</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Los Angeles, California,</location>
<contexts>
<context position="8348" citStr="Galley and Manning, 2010" startWordPosition="1385" endWordPosition="1389">1 X1 schuler 3 6 X6 5 4 X5 noch nicht X4 2 X2 X3 haben . 1090 allow reordering as well. X ( fX1, eX1) X (X1 fX2, eX1X2) fX2, eX2X1) (3) X � (X1 � 1 f, eX1) X � (X It might appear that the restriction that target-side rules be GNF is a severe restriction on the coverage of possible hypotheses compared to the full set of rules permitted by the Hiero extraction heuristic. However there is some evidence in the literature that discontinuous spans on the source side in translation rules is a lot more useful than discontinuous spans in the target side (which is disallowed in the GNF). For instance, (Galley and Manning, 2010) do an extensive study of discontinuous spans on source and target side and show that source side discontinuous spans are very useful but removing discontinuous spans on the target side only lowers the BLEU score by 0.2 points (using the Joshua SMT system on Chinese-English). Removing discontinuous spans means that the target side rules have the form: uX, Xu, XuX, XXu, or uXX of which we disallow Xu, XuX, XXu. Zhang and Zong (2012) also conduct a study on discontinuous spans on source and target side of Hiero rules and conclude that source discontinuous spans are always more useful than discon</context>
</contexts>
<marker>Galley, Manning, 2010</marker>
<rawString>Michel Galley and Christopher D. Manning. 2010. Accurate non-hierarchical phrase-based translation. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 966– 974, Los Angeles, California, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Hieu Hoang</author>
<author>Philipp Koehn</author>
<author>Tetsuo Kiso</author>
<author>Marcello Federico</author>
</authors>
<title>Left language model state for syntactic machine translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Workshop on Spoken Language Translation,</booktitle>
<pages>183--190</pages>
<location>San Francisco, California, USA,</location>
<contexts>
<context position="1917" citStr="Heafield et al., 2011" startWordPosition="292" endWordPosition="295">ized synchronous context-free grammar (SCFG) extracted from word aligned bitexts. Typically, CKY-style decoding is used for Hiero with time complexity O(n3) for source input with n words. Scoring the target language output using a language model within CKY-style decoding requires two histories per hypothesis, one on the left edge of each span and one on the right, due to the fact that the target side is not generated in left to right order, but rather built bottom-up from sub-spans. This leads to complex problems in efficient language model integration and requires state reduction techniques (Heafield et al., 2011; Heafield et al., 2013). The size of a Hiero SCFG grammar is typically larger than phrase-based models extracted from the same data creating challenges in rule extraction and decoding time especially for larger datasets (Sankaran et al., 2012). In contrast, the LR-decoding algorithm could avoid these shortcomings such as faster time complexity, reduction in the grammar size and the simplified left-to-right language model scoring. It means LR decoding has the potential to replace CKY decoding for Hiero. Despite these attractive properties, we show that the original LR-Hiero decoding proposed b</context>
</contexts>
<marker>Heafield, Hoang, Koehn, Kiso, Federico, 2011</marker>
<rawString>Kenneth Heafield, Hieu Hoang, Philipp Koehn, Tetsuo Kiso, and Marcello Federico. 2011. Left language model state for syntactic machine translation. In Proceedings of the International Workshop on Spoken Language Translation, pages 183–190, San Francisco, California, USA, 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
<author>Philipp Koehn</author>
<author>Alon Lavie</author>
</authors>
<title>Grouping language model boundary words to speed KBest extraction from hypergraphs.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<location>Atlanta, Georgia, USA, 6.</location>
<contexts>
<context position="1941" citStr="Heafield et al., 2013" startWordPosition="296" endWordPosition="299">t-free grammar (SCFG) extracted from word aligned bitexts. Typically, CKY-style decoding is used for Hiero with time complexity O(n3) for source input with n words. Scoring the target language output using a language model within CKY-style decoding requires two histories per hypothesis, one on the left edge of each span and one on the right, due to the fact that the target side is not generated in left to right order, but rather built bottom-up from sub-spans. This leads to complex problems in efficient language model integration and requires state reduction techniques (Heafield et al., 2011; Heafield et al., 2013). The size of a Hiero SCFG grammar is typically larger than phrase-based models extracted from the same data creating challenges in rule extraction and decoding time especially for larger datasets (Sankaran et al., 2012). In contrast, the LR-decoding algorithm could avoid these shortcomings such as faster time complexity, reduction in the grammar size and the simplified left-to-right language model scoring. It means LR decoding has the potential to replace CKY decoding for Hiero. Despite these attractive properties, we show that the original LR-Hiero decoding proposed by (Watanabe et al., 2006</context>
</contexts>
<marker>Heafield, Koehn, Lavie, 2013</marker>
<rawString>Kenneth Heafield, Philipp Koehn, and Alon Lavie. 2013. Grouping language model boundary words to speed KBest extraction from hypergraphs. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Atlanta, Georgia, USA, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: Faster and smaller language model queries. In</title>
<date>2011</date>
<booktitle>In Proc. of the Sixth Workshop on Statistical Machine Translation.</booktitle>
<contexts>
<context position="28976" citStr="Heafield, 2011" startWordPosition="4996" endWordPosition="4997">h performs comparably to other open-source Hiero systems (Sankaran et al., 2012). Kriya can obtain statistically significantly equal BLEU scores when compared with Moses (Koehn et al., 2007) for several language pairs (Razmara et al., 2012; Callison-Burch et al., 2012). • Hiero-GNF: where we use Hiero decoder with the restricted LR-Hiero grammar (GNF rules). • LR-Hiero: our implementation of LR-Hiero (Watanabe et al., 2006b) in Python. • phrase-based: Moses (Koehn et al., 2007) • LR-Hiero+CP: LR-Hiero decoding with cube pruning. We use a 5-gram LM trained on the Gigaword corpus and use KenLM (Heafield, 2011) for LM scoring during decoding. We tune weights by minimizing BLEU loss on the dev set through MERT (Och, 2003) and report BLEU scores on the test set. We use comparable pop limits in each of the decoders: 1000 for Moses and LR-Hiero and 500 with cube pruning for CKY Hiero and LR-Hiero+CP. Other extraction and decoder settings such as maximum phrase length, etc. were identical across settings so that the results are comparable. Table 2 shows how the LR-Hiero grammar is much smaller than CKY-based Hiero. Model cs-en de-en #queries / time(ms) #queries / time(ms) Hiero 5,679.7 / 16.12 7,231.62 /</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: Faster and smaller language model queries. In In Proc. of the Sixth Workshop on Statistical Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Forest rescoring: Faster decoding with integrated language models.</title>
<date>2007</date>
<booktitle>In In ACL 07.</booktitle>
<contexts>
<context position="18236" citStr="Huang and Chiang, 2007" startWordPosition="3146" endWordPosition="3149">tion. The Algorithm 2 shows the pseudocode for LR-decoding using cube pruning. The structure of stacks and hypotheses and computing the future cost is similar to Algorithm 1 (lines 1-5). To fill stack Si, it iterates over previous stacks (line 8 in Algorithm 2) 4. All hypotheses in each stack Sp (covering p words on the source-side) are first partitioned into a set of groups, {G}, based on their first uncovered span (line 9) 5. Each group g is a 4As the length of rules are limited (at most MRL), we can ignore stacks with index less than i − MRL 5The beam search decoder in Phrase-based system (Huang and Chiang, 2007; Koehn et al., 2007; Sankaran et al., 2010) 2-tuple (gspan, ghyps), where ghyps is a list of hypotheses which share the same first uncovered span gspan. Rules matching the span gspan are obtained from routine GetSpanRules, which are then grouped based on unique source side rules (i.e. each Rs contains rules that share the same source side s but have different target sides). Each ghyps and possible Rs6 create a cube which is added to cubeList. In LR-Hiero, each hypothesis is developed with only one uncovered span, therefore each cube always has just two dimensions: (1) hypotheses with the same</context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Liang Huang and David Chiang. 2007. Forest rescoring: Faster decoding with integrated language models. In In ACL 07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Haitao Mi</author>
</authors>
<title>Efficient incremental decoding for tree-to-string translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>273--283</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Cambridge, MA,</location>
<contexts>
<context position="15742" citStr="Huang and Mi, 2010" startWordPosition="2682" endWordPosition="2685">spans uncovered by current hypothesis together with the hypothesis cost. The future cost is precomputed (line 2 Algorithm 1) in a way similar to the phrase-based models (Koehn et al., 2007) using only the terminal rules of the grammar. The ComputeCost method (line 22 in Algorithm 1) uses the usual log-linear model and scores a hypothesis based on its different feature scores g(h&apos;) and the future cost of the yet to be covered spans (.Fhyo„). Time complexity of left to right Hiero decoding with beam search is O(n2b) in practice where n is the length of source sentence and b is the size of beam (Huang and Mi, 2010). 2.3 LR-Hiero Decoding with Cube Pruning The Algorithm 1 presented earlier does an exhaustive search as it generates all possible partial translations for a given stack that are reachable from the hypotheses in previous stacks. However only a few of these hypotheses are retained, while majority of them are pruned away. The cube pruning technique (Chiang, 2007) avoids the wasteful generation of poor hypotheses that are likely to be pruned away by efficiently restricting the generation to only high scoring partial translations. We modify the cube pruning for LR-decoding that takes into account </context>
</contexts>
<marker>Huang, Mi, 2010</marker>
<rawString>Liang Huang and Haitao Mi. 2010. Efficient incremental decoding for tree-to-string translation. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 273–283, Cambridge, MA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Franz Josef Och</author>
<author>Daniel Marcu</author>
</authors>
<title>Statistical phrase-based translation.</title>
<date>2003</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="11673" citStr="Koehn et al., 2003" startWordPosition="1989" endWordPosition="1992">LR decoding. Decoding the example in Figure 1(b) is explained using a walk-through shown in Figure 2. Each partial hypothesis h is a 4-tuple (ht, hs, hcov, hc): consisting of a translation prefix ht, a (LIFO-ordered) list hs of uncovered spans, source words coverage set hcov and the hypothesis cost hc. The initial hypothesis is a null string with just a sentence-initial marker (s) and the list hs containing a span of the whole sentence, [0, n]. The hypotheses are stored in stacks S0,... , Sn, where each stack corresponds to a coverage vector of same size, covering same number of source words (Koehn et al., 2003). At the beginning of beam search the initial hy1091 rules source side coverage hypothesis  X ⟦schulerihre arbeit nochnicht gemacht haben.⟧ schuler  X1 1⟦ihrearbeit nochnicht gemacht haben.⟧ &lt;s&gt; schuler  X1 2⟦ihre arbeit nochnicht gemacht⟧ haben X2 2⟦.⟧ schuler X1 3⟦ihrearbeit⟧ nochnicht X2 3⟦gemacht⟧ haben X2 2⟦.⟧ schuler  X1 3 ⟦ihre arbeit⟧ nochnicht gemacht haben X2 2⟦.⟧ schuler ihre arbeitnochnicht gemacht haben X2 2⟦.⟧ schuler ihre arbeit nochnicht gemacht haben. &lt;s&gt; &lt;s&gt; &lt;s&gt; &lt;s&gt; &lt;s&gt; &lt;s&gt; [0,8] students[1,8] students have[1,6][7,8] students have notyet[5,6][1,3][7,8] students have not</context>
</contexts>
<marker>Koehn, Och, Marcu, 2003</marker>
<rawString>Philipp Koehn, Franz Josef Och, and Daniel Marcu. 2003. Statistical phrase-based translation. In Proc. of NAACL.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Chris Dyer</author>
<author>Ondˇrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07,</booktitle>
<pages>177--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="15312" citStr="Koehn et al., 2007" startWordPosition="2604" endWordPosition="2607"> decoder considers the second hypothesis and pops the span [1, 8]. It then matches the rule (#2) and pushes the spans [1, 6] and [7,8] into the list hs in the reverse order of their appearance in the target-side rule. At each step the new hypothesis is added to the decoder stack Sl depending on the number of covered words in the new hypothesis (line 13 in Algorithm 1). For pruning we use an estimate of the future cost3 of the spans uncovered by current hypothesis together with the hypothesis cost. The future cost is precomputed (line 2 Algorithm 1) in a way similar to the phrase-based models (Koehn et al., 2007) using only the terminal rules of the grammar. The ComputeCost method (line 22 in Algorithm 1) uses the usual log-linear model and scores a hypothesis based on its different feature scores g(h&apos;) and the future cost of the yet to be covered spans (.Fhyo„). Time complexity of left to right Hiero decoding with beam search is O(n2b) in practice where n is the length of source sentence and b is the size of beam (Huang and Mi, 2010). 2.3 LR-Hiero Decoding with Cube Pruning The Algorithm 1 presented earlier does an exhaustive search as it generates all possible partial translations for a given stack </context>
<context position="18256" citStr="Koehn et al., 2007" startWordPosition="3150" endWordPosition="3153">ows the pseudocode for LR-decoding using cube pruning. The structure of stacks and hypotheses and computing the future cost is similar to Algorithm 1 (lines 1-5). To fill stack Si, it iterates over previous stacks (line 8 in Algorithm 2) 4. All hypotheses in each stack Sp (covering p words on the source-side) are first partitioned into a set of groups, {G}, based on their first uncovered span (line 9) 5. Each group g is a 4As the length of rules are limited (at most MRL), we can ignore stacks with index less than i − MRL 5The beam search decoder in Phrase-based system (Huang and Chiang, 2007; Koehn et al., 2007; Sankaran et al., 2010) 2-tuple (gspan, ghyps), where ghyps is a list of hypotheses which share the same first uncovered span gspan. Rules matching the span gspan are obtained from routine GetSpanRules, which are then grouped based on unique source side rules (i.e. each Rs contains rules that share the same source side s but have different target sides). Each ghyps and possible Rs6 create a cube which is added to cubeList. In LR-Hiero, each hypothesis is developed with only one uncovered span, therefore each cube always has just two dimensions: (1) hypotheses with the same number of covered w</context>
<context position="28551" citStr="Koehn et al., 2007" startWordPosition="4926" endWordPosition="4929">zEng(v0.9); 7.95M/3000/3003 News commentary de-en Europarl(v7); News 1.5M/2000/2000 commentary Table 1: Corpus statistics in number of sentences Model cs-en de-en Phrase-based 233.0 77.2 Hiero 1,961.6 858.5 LR-Hiero 230.5 101.3 Table 2: Model sizes (millions of rules). We do not count glue rules for LR-Hiero which are created at runtime as needed. • Hiero: we used Kriya, our open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems (Sankaran et al., 2012). Kriya can obtain statistically significantly equal BLEU scores when compared with Moses (Koehn et al., 2007) for several language pairs (Razmara et al., 2012; Callison-Burch et al., 2012). • Hiero-GNF: where we use Hiero decoder with the restricted LR-Hiero grammar (GNF rules). • LR-Hiero: our implementation of LR-Hiero (Watanabe et al., 2006b) in Python. • phrase-based: Moses (Koehn et al., 2007) • LR-Hiero+CP: LR-Hiero decoding with cube pruning. We use a 5-gram LM trained on the Gigaword corpus and use KenLM (Heafield, 2011) for LM scoring during decoding. We tune weights by minimizing BLEU loss on the dev set through MERT (Och, 2003) and report BLEU scores on the test set. We use comparable pop </context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondˇrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, ACL ’07, pages 177–180, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
</authors>
<title>Hierarchical phrase-based translation with suffix arrays.</title>
<date>2007</date>
<booktitle>In EMNLP-CoNLL,</booktitle>
<pages>976--985</pages>
<contexts>
<context position="13310" citStr="Lopez, 2007" startWordPosition="2251" endWordPosition="2252">oder state using Earley dot notation (superscripts show rule#) (c) Hypotheses pane showing translation prefix and ordered list of yet-to-be-covered spans. pothesis h0 is added to the decoder stack S0 (line 6 in Algoorithm 1). Hypotheses in each decoder stack are expanded iteratively, generating new hypotheses, which are added to the latter stacks corresponding to the number of source words covered. In each step it pops from the LIFO list hs, the span [u, v] of the next hypothesis h to be processed. All rules that match the entire span [u, v] are then obtained efficiently via pattern matching (Lopez, 2007). GetSpanRules addresses possible ambiguities in matched rules to the given span [u, v]. For example, given a rule r, with source side rs : (X1 the X2) and source phrase p : (ok, the more the better). There is ambiguity in matching r to p. GetSpanRules returns a distinct matched rule for each possible matching. The GrowHypothesis routine creates a new candidate by expanding given hypothesis h using rule r and computes the complete hypothesis score including language model score. Since the target-side rules are in GNF, the translation prefix of the new hypothesis is obtained by simply concatena</context>
</contexts>
<marker>Lopez, 2007</marker>
<rawString>Adam Lopez. 2007. Hierarchical phrase-based translation with suffix arrays. In EMNLP-CoNLL, pages 976–985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
<author>John Dowding</author>
</authors>
<title>Efficient bottom-up parsing.</title>
<date>1991</date>
<booktitle>In HLT.</booktitle>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="30466" citStr="Moore and Dowding, 1991" startWordPosition="5244" endWordPosition="5247">4.2 Time Efficiency Comparison To evaluate the performance of LR-Hiero decoding with cube pruning (LR-Hiero+CP), we compare it with three baselines: (i) CKY Hiero, (ii) CKY Hiero-GNF, and (iii) LR-Hiero (without cube pruning) with two different beam size 500 and 1000. When it comes to instrument timing results, there are lots of system level details that we wish to abstract away from, and focus only on the number of “edges” processed by the decoder. In comparison of parsing algorithms, the common practice is to measure the number of edges processed by different algorithms for the same reason (Moore and Dowding, 1991). By analogy to parsing algorithm comparisons, we compare the different decoding algorithms with respect to the number of calls made to the language model (LM) since that directly corresponds to the number of hypotheses considered by the decoder. A decoder is more time efficient if it can consider fewer translation hypotheses while maintaining the same BLEU score. All of the baselines use the same wrapper to query the language model, and we have instrumented the wrapper to count the statistics we need and thus we can say this is a fair comparison. For this experiment we use a sample set of 50 </context>
</contexts>
<marker>Moore, Dowding, 1991</marker>
<rawString>Robert C. Moore and John Dowding. 1991. Efficient bottom-up parsing. In HLT. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thuylinh Nguyen</author>
<author>Stephan Vogel</author>
</authors>
<title>Integrating phrase-based reordering features into chart-based decoder for machine translation.</title>
<date>2013</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="33977" citStr="Nguyen and Vogel (2013)" startWordPosition="5844" endWordPosition="5847">coder or models. We add these features to both Hiero and Hiero-GNF7. The last part of Table 4 shows the performance CKY decoder 7Feature rod is defined for SCFG rules and cannot be adopted to phrase-based translation systems; and Moses uses distortion feature therefore we omit Moses from this experiment. with different models (full Hiero and GNF) with the new reordering features in terms of BLEU score. The results show that these features are helpful in both models. Although, they do not make a big difference in Hiero with full model, they can alleviate the lack of non-GNF rules in Hiero-GNF. Nguyen and Vogel (2013) integrate traditional phrase-based features: distortion and lexicalized reordering into Hiero as well. They show that such features can be useful to boost the translation quality of CKY Hiero with the full rule set. Nguyen and Vogel (2013) compute the distortion feature in a different way, only applicable to CKY. The distortion for each cell is computed after the translation for nonterminal sub-spans is complete. In LR-decoding, we compute distortion for rules even though we are yet to translate some of the sub-spans. Thus our approach computes the distortion incrementally for the untranslate</context>
</contexts>
<marker>Nguyen, Vogel, 2013</marker>
<rawString>Thuylinh Nguyen and Stephan Vogel. 2013. Integrating phrase-based reordering features into chart-based decoder for machine translation. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>160--167</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="29088" citStr="Och, 2003" startWordPosition="5018" endWordPosition="5019">ificantly equal BLEU scores when compared with Moses (Koehn et al., 2007) for several language pairs (Razmara et al., 2012; Callison-Burch et al., 2012). • Hiero-GNF: where we use Hiero decoder with the restricted LR-Hiero grammar (GNF rules). • LR-Hiero: our implementation of LR-Hiero (Watanabe et al., 2006b) in Python. • phrase-based: Moses (Koehn et al., 2007) • LR-Hiero+CP: LR-Hiero decoding with cube pruning. We use a 5-gram LM trained on the Gigaword corpus and use KenLM (Heafield, 2011) for LM scoring during decoding. We tune weights by minimizing BLEU loss on the dev set through MERT (Och, 2003) and report BLEU scores on the test set. We use comparable pop limits in each of the decoders: 1000 for Moses and LR-Hiero and 500 with cube pruning for CKY Hiero and LR-Hiero+CP. Other extraction and decoder settings such as maximum phrase length, etc. were identical across settings so that the results are comparable. Table 2 shows how the LR-Hiero grammar is much smaller than CKY-based Hiero. Model cs-en de-en #queries / time(ms) #queries / time(ms) Hiero 5,679.7 / 16.12 7,231.62 / 20.33 Hiero-GNF 4,952.5 / 14.71 5,858.74 / 18.23 LR-Hiero (1000) 46,333.21 / 163.6 83,518.63 / 328.11 LR-Hiero </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 160– 167, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Majid Razmara</author>
<author>Baskaran Sankaran</author>
<author>Ann Clifton</author>
<author>Anoop Sarkar</author>
</authors>
<title>Kriya - the sfu system for translation task at wmt-12.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation, WMT ’12,</booktitle>
<pages>356--361</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="28600" citStr="Razmara et al., 2012" startWordPosition="4934" endWordPosition="4937">n Europarl(v7); News 1.5M/2000/2000 commentary Table 1: Corpus statistics in number of sentences Model cs-en de-en Phrase-based 233.0 77.2 Hiero 1,961.6 858.5 LR-Hiero 230.5 101.3 Table 2: Model sizes (millions of rules). We do not count glue rules for LR-Hiero which are created at runtime as needed. • Hiero: we used Kriya, our open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems (Sankaran et al., 2012). Kriya can obtain statistically significantly equal BLEU scores when compared with Moses (Koehn et al., 2007) for several language pairs (Razmara et al., 2012; Callison-Burch et al., 2012). • Hiero-GNF: where we use Hiero decoder with the restricted LR-Hiero grammar (GNF rules). • LR-Hiero: our implementation of LR-Hiero (Watanabe et al., 2006b) in Python. • phrase-based: Moses (Koehn et al., 2007) • LR-Hiero+CP: LR-Hiero decoding with cube pruning. We use a 5-gram LM trained on the Gigaword corpus and use KenLM (Heafield, 2011) for LM scoring during decoding. We tune weights by minimizing BLEU loss on the dev set through MERT (Och, 2003) and report BLEU scores on the test set. We use comparable pop limits in each of the decoders: 1000 for Moses an</context>
</contexts>
<marker>Razmara, Sankaran, Clifton, Sarkar, 2012</marker>
<rawString>Majid Razmara, Baskaran Sankaran, Ann Clifton, and Anoop Sarkar. 2012. Kriya - the sfu system for translation task at wmt-12. In Proceedings of the Seventh Workshop on Statistical Machine Translation, WMT ’12, pages 356–361, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baskaran Sankaran</author>
<author>Ajeet Grewal</author>
<author>Anoop Sarkar</author>
</authors>
<title>Incremental decoding for phrase-based statistical machine translation.</title>
<date>2010</date>
<booktitle>In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, WMT ’10,</booktitle>
<pages>216--223</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="18280" citStr="Sankaran et al., 2010" startWordPosition="3154" endWordPosition="3157">or LR-decoding using cube pruning. The structure of stacks and hypotheses and computing the future cost is similar to Algorithm 1 (lines 1-5). To fill stack Si, it iterates over previous stacks (line 8 in Algorithm 2) 4. All hypotheses in each stack Sp (covering p words on the source-side) are first partitioned into a set of groups, {G}, based on their first uncovered span (line 9) 5. Each group g is a 4As the length of rules are limited (at most MRL), we can ignore stacks with index less than i − MRL 5The beam search decoder in Phrase-based system (Huang and Chiang, 2007; Koehn et al., 2007; Sankaran et al., 2010) 2-tuple (gspan, ghyps), where ghyps is a list of hypotheses which share the same first uncovered span gspan. Rules matching the span gspan are obtained from routine GetSpanRules, which are then grouped based on unique source side rules (i.e. each Rs contains rules that share the same source side s but have different target sides). Each ghyps and possible Rs6 create a cube which is added to cubeList. In LR-Hiero, each hypothesis is developed with only one uncovered span, therefore each cube always has just two dimensions: (1) hypotheses with the same number of covered words and similar first u</context>
</contexts>
<marker>Sankaran, Grewal, Sarkar, 2010</marker>
<rawString>Baskaran Sankaran, Ajeet Grewal, and Anoop Sarkar. 2010. Incremental decoding for phrase-based statistical machine translation. In Proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, WMT ’10, pages 216–223, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Baskaran Sankaran</author>
<author>Majid Razmara</author>
<author>Anoop Sarkar</author>
</authors>
<title>Kriya - an end-to-end hierarchical phrase-based mt system.</title>
<date>2012</date>
<booktitle>The Prague Bulletin of Mathematical Linguistics (PBML),</booktitle>
<location>(97):83–98,</location>
<contexts>
<context position="2161" citStr="Sankaran et al., 2012" startWordPosition="331" endWordPosition="334">el within CKY-style decoding requires two histories per hypothesis, one on the left edge of each span and one on the right, due to the fact that the target side is not generated in left to right order, but rather built bottom-up from sub-spans. This leads to complex problems in efficient language model integration and requires state reduction techniques (Heafield et al., 2011; Heafield et al., 2013). The size of a Hiero SCFG grammar is typically larger than phrase-based models extracted from the same data creating challenges in rule extraction and decoding time especially for larger datasets (Sankaran et al., 2012). In contrast, the LR-decoding algorithm could avoid these shortcomings such as faster time complexity, reduction in the grammar size and the simplified left-to-right language model scoring. It means LR decoding has the potential to replace CKY decoding for Hiero. Despite these attractive properties, we show that the original LR-Hiero decoding proposed by (Watanabe et al., 2006b) does not perform to the same level of the standard CKY Hiero with cube pruning (see Table 3). In addition, the current LR decoding algorithm does not obtain BLEU scores comparable to phrase-based or CKYbased Hiero mod</context>
<context position="28441" citStr="Sankaran et al., 2012" startWordPosition="4910" endWordPosition="4913">plementation of LR-Hiero (written in Python): J3 X2 X, J2 J, (a) 1095 Corpus Train/Dev/Test cs-en Europarl(v7), CzEng(v0.9); 7.95M/3000/3003 News commentary de-en Europarl(v7); News 1.5M/2000/2000 commentary Table 1: Corpus statistics in number of sentences Model cs-en de-en Phrase-based 233.0 77.2 Hiero 1,961.6 858.5 LR-Hiero 230.5 101.3 Table 2: Model sizes (millions of rules). We do not count glue rules for LR-Hiero which are created at runtime as needed. • Hiero: we used Kriya, our open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems (Sankaran et al., 2012). Kriya can obtain statistically significantly equal BLEU scores when compared with Moses (Koehn et al., 2007) for several language pairs (Razmara et al., 2012; Callison-Burch et al., 2012). • Hiero-GNF: where we use Hiero decoder with the restricted LR-Hiero grammar (GNF rules). • LR-Hiero: our implementation of LR-Hiero (Watanabe et al., 2006b) in Python. • phrase-based: Moses (Koehn et al., 2007) • LR-Hiero+CP: LR-Hiero decoding with cube pruning. We use a 5-gram LM trained on the Gigaword corpus and use KenLM (Heafield, 2011) for LM scoring during decoding. We tune weights by minimizing BL</context>
</contexts>
<marker>Sankaran, Razmara, Sarkar, 2012</marker>
<rawString>Baskaran Sankaran, Majid Razmara, and Anoop Sarkar. 2012. Kriya - an end-to-end hierarchical phrase-based mt system. The Prague Bulletin of Mathematical Linguistics (PBML), (97):83–98, apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Jun Suzuki</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
</authors>
<title>NTT statistical machine translation for iwslt</title>
<date>2006</date>
<booktitle>In Proceedings of IWSLT</booktitle>
<pages>95--102</pages>
<contexts>
<context position="814" citStr="Watanabe et al., 2006" startWordPosition="117" endWordPosition="120">aran,anoop}@cs.sfu.ca Abstract Left-to-right (LR) decoding (Watanabe et al., 2006b) is a promising decoding algorithm for hierarchical phrase-based translation (Hiero). It generates the target sentence by extending the hypotheses only on the right edge. LR decoding has complexity O(n2b) for input of n words and beam size b, compared to O(n3) for the CKY algorithm. It requires a single language model (LM) history for each target hypothesis rather than two LM histories per hypothesis as in CKY. In this paper we present an augmented LR decoding algorithm that builds on the original algorithm in (Watanabe et al., 2006b). Unlike that algorithm, using experiments over multiple language pairs we show two new results: our LR decoding algorithm provides demonstrably more efficient decoding than CKY Hiero, four times faster; and by introducing new distortion and reordering features for LR decoding, it maintains the same translation quality (as in BLEU scores) obtained phrase-based and CKY Hiero with the same translation model. 1 Introduction Hiero (Chiang, 2007) models translation using a lexicalized synchronous context-free grammar (SCFG) extracted from word aligned bitexts. Typically, CKY-style decoding is use</context>
<context position="2541" citStr="Watanabe et al., 2006" startWordPosition="390" endWordPosition="393">eafield et al., 2013). The size of a Hiero SCFG grammar is typically larger than phrase-based models extracted from the same data creating challenges in rule extraction and decoding time especially for larger datasets (Sankaran et al., 2012). In contrast, the LR-decoding algorithm could avoid these shortcomings such as faster time complexity, reduction in the grammar size and the simplified left-to-right language model scoring. It means LR decoding has the potential to replace CKY decoding for Hiero. Despite these attractive properties, we show that the original LR-Hiero decoding proposed by (Watanabe et al., 2006b) does not perform to the same level of the standard CKY Hiero with cube pruning (see Table 3). In addition, the current LR decoding algorithm does not obtain BLEU scores comparable to phrase-based or CKYbased Hiero models for different language pairs (see Table 4). In this paper we propose modifications to the LR decoding algorithm that addresses these limitations and provides, for the first time, a true alternative to the standard CKY Hiero algorithm that uses left-to-right decoding. We introduce a new extended version of the LR decoding algorithm presented in (Watanabe et al., 2006b) which</context>
<context position="5646" citStr="Watanabe et al., 2006" startWordPosition="900" endWordPosition="903">terminals (rule arity) to two and disallowing any rule with consecutive non-terminals on the foreign language side. It further limits the length of the initial phrase-pair as well as the number of terminals and non-terminals in the rule. For translating sentences longer than the maximum phrase-pair length, the decoder relies on additional glue rules 5 —* (X, X) and 5 —* (5X, 5X) that allows monotone combination of phrases. The glue rules are used when no rules could match or the span length is larger than the maximum phrase-pair length. 2.1 Rule Extraction for LR Decoding Left-to-right Hiero (Watanabe et al., 2006b) generates the target hypotheses left to right, but for synchronous context-free grammar (SCFG) as used in Hiero. The target-side rules are constrained to be prefix lexicalized. These constrained SCFG rules are defined as: X —* (-y,bQ) (1) where -y is a mixed string of terminals and nonterminals. b is a terminal sequence prefixed to the possibly empty non-terminal sequence Q. For the sake of simplicity, We refer to these type of rules as schuler ihre arbeit noch nicht gemacht haben . Figure 1: (a): A word-aligned German-English sentence pair. The bars above the source words indicate phrasepa</context>
<context position="7144" citStr="Watanabe et al. (2006" startWordPosition="1152" endWordPosition="1155">olating GNF form on the target side are excluded. Rule extraction considers each smaller source-target phrase pair within a larger phrase pair and replaces the spans with non-terminal X, yielding hierarchical rules. Figure 1(a) shows a wordaligned German-English sentence with a phrase pair (ihre arbeit noch nicht gemacht haben, have not yet done their work) that will lead to a SCFG rule. Given other smaller phrases (marked by bars above the source side), we extract a GNF rule2: X —* (X1 noch nicht X2 haben, have not yet X2 X1) (2) In order to avoid data sparsity and for better generalization, Watanabe et al. (2006b) adds four glue rules for each lexical rule (f, e) which are analogous to the glue rules defined in (Chiang, 2007) (see above) except that these glue rules for LR decoding 1Griebach Normal Form (GNF), although the synchronous grammar is not in this normal form, rather only the target side is prefix lexicalized as if it were in GNF form. 2 LR-Hiero rule extraction excludes non-GNF rules such as X --+ (X1 noch nicht gemacht X2, X2 not yet done X1). students have not yet done their work . (a) X1 students have X2 X6 X3 not yet . X4 X5 ihre arbeit gemacht done their work (b) 1 X1 schuler 3 6 X6 5</context>
<context position="9795" citStr="Watanabe et al., 2006" startWordPosition="1630" endWordPosition="1633">t of Hiero rules by using only target lexicalized rules in our LR decoder. 2.2 LR-Hiero Decoding LR-Hiero decoding uses a top-down depth-first search, which strictly grows the hypotheses in target surface ordering. Search on the source side follows an Earley-style search (Earley, 1970), the dot jumps around on the source side of the rules based on the order of nonterminals on the target side. This search is integrated with beam search or cube pruning to efficiently find the k-best translations. Several important details about the algorithm of LR-Hiero decoding are implicit and unexplained in (Watanabe et al., 2006b). In this section we describe the LR-Hiero decoding algorithm in more detail than the original description in (Watanabe et al., Algorithm 1: LR-Hiero Decoding 1: Input sentence: f = f0f1 ... fn 2: J7 = FutureCost(f) (Precompute future cost for spans) 3: for i = 0,...,n do 4: Si = {} (Create empty stacks) 5: h0 = ((s), [[0, n]], 0, J7[0,n]) (Initial hypothesis 4-tuple) 6: Add h0 to S0 (Push initial hyp into first Stack) 7: for i = 0,...,n − 1 do 8: for each h in Si do 9: [u, v] = pop(hs) (Pop first uncovered span from list) 10: R = GetSpanRules([u, v]) (Extract rules matching the entire span </context>
<context position="16392" citStr="Watanabe et al. (2006" startWordPosition="2787" endWordPosition="2790">Cube Pruning The Algorithm 1 presented earlier does an exhaustive search as it generates all possible partial translations for a given stack that are reachable from the hypotheses in previous stacks. However only a few of these hypotheses are retained, while majority of them are pruned away. The cube pruning technique (Chiang, 2007) avoids the wasteful generation of poor hypotheses that are likely to be pruned away by efficiently restricting the generation to only high scoring partial translations. We modify the cube pruning for LR-decoding that takes into account the next uncovered span to 3 Watanabe et al. (2006b) also use a similar future cost, even though it is not discussed in the paper (p.c.). 1092 Algorithm 2: LR-Hiero Decoding with Cube Pruning 1: Input sentence: f = f0f1 ... fn 2: F = FutureCost(f) (Precompute future cost for spans) 3: S0 = {} (Create empty initial stack) 4: h0 = ((s), [[0, n]], 0, F[0,n]) (Initial hypothesis 4-tuple) 5: Add h0 to S0 (Push initial hyp into first Stack) 6: for i = 1,...,n do 7: cubeList = {} (MRL is max rule length) 8: for p = max(i − MRL, 0), ... , i − 1 do 9: {G} = Grouped(Sp) (Group based on the first uncovered span) 10: for g E {G} do 11: [u, v] = gspan 12:</context>
<context position="22793" citStr="Watanabe et al. (2006" startWordPosition="3937" endWordPosition="3940">s cube (neighbours of the popped entry which are shaded in Figure 3(b)). These hypotheses are added to the priority queue. In the next iteration, the best hypothesis is popped from all candidates in the queue and algorithm continues. 3 Features We use the following standard SMT features for the log-linear model of LR-Hiero: relative-frequency translation probabilities p(f|e) and p(e|f), lexical translation probabilities pl(f|e) and pl(e|f), a language model probability, word count and phrase count. In addition we also use the glue rule count and the two reordering penalty features employed by Watanabe et al. (2006b; 2006a). These features compute the height and width (span size of the entire subtree) of all subtrees which are backtraced in the derivation of a hypothesis. A non-terminal XZ is pushed into the LIFO list of a partial hypothesis; it’s backtrace refers to the set of NTs that must be popped before XZ. In Figure 1(b), X2 has two subtrees X3 and X6, where X3 should be processed before X6. The subtree rooted at X3 in Figure 1(b) has a height of 2 and span [1, 6] having a width of 5. Similarly, X4 should be backtraced before X5 and has height and width of 1. Backtracing applies only for rules hav</context>
<context position="28787" citStr="Watanabe et al., 2006" startWordPosition="4962" endWordPosition="4965">2: Model sizes (millions of rules). We do not count glue rules for LR-Hiero which are created at runtime as needed. • Hiero: we used Kriya, our open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems (Sankaran et al., 2012). Kriya can obtain statistically significantly equal BLEU scores when compared with Moses (Koehn et al., 2007) for several language pairs (Razmara et al., 2012; Callison-Burch et al., 2012). • Hiero-GNF: where we use Hiero decoder with the restricted LR-Hiero grammar (GNF rules). • LR-Hiero: our implementation of LR-Hiero (Watanabe et al., 2006b) in Python. • phrase-based: Moses (Koehn et al., 2007) • LR-Hiero+CP: LR-Hiero decoding with cube pruning. We use a 5-gram LM trained on the Gigaword corpus and use KenLM (Heafield, 2011) for LM scoring during decoding. We tune weights by minimizing BLEU loss on the dev set through MERT (Och, 2003) and report BLEU scores on the test set. We use comparable pop limits in each of the decoders: 1000 for Moses and LR-Hiero and 500 with cube pruning for CKY Hiero and LR-Hiero+CP. Other extraction and decoder settings such as maximum phrase length, etc. were identical across settings so that the re</context>
<context position="31476" citStr="Watanabe et al., 2006" startWordPosition="5417" endWordPosition="5420">se the same wrapper to query the language model, and we have instrumented the wrapper to count the statistics we need and thus we can say this is a fair comparison. For this experiment we use a sample set of 50 sentences taken from the test sets. Table 3 shows the results in terms of average number of language model queries and times in milliseconds. 4.3 Reordering Features To evaluate the new reordering features proposed to LR-Hiero (Section 3.2), LR-Hiero+CP with new features is compared to all baselines. Table 4 shows the BLEU scores of different models in two language pairs. The baseline (Watanabe et al., 2006b) model uses all the features mentioned therein but is 1096 Model cs-en de-en Phrase-based 20.32 24.71 CKY Hiero 20.64 25.52 CKY Hiero-GNF 20.04 24.84 LR-Hiero 18.30 23.47 LR-Hiero + reordering feats 20.20 24.90 LR-Hiero + CP + reordering feats 20.15 24.83 CKY Hiero-GNF + reordering feats 20.52 25.09 CKY Hiero + reordering feats 20.77 25.72 Table 4: BLEU scores. The rows are grouped such that each group use the same model. The last row in part 2 of table shows LR-Hiero+CP using our new features in addition to the baseline Watanabe features (line LR-Hiero baseline). The last part shows CKY Hie</context>
<context position="34975" citStr="Watanabe et al., 2006" startWordPosition="6005" endWordPosition="6008">n for nonterminal sub-spans is complete. In LR-decoding, we compute distortion for rules even though we are yet to translate some of the sub-spans. Thus our approach computes the distortion incrementally for the untranslated sub-spans which are later added. Unlike (Nguyen and Vogel, 2013), our distortion feature can be applied to both LR and CKY-decoding (Table 4). We have also introduced another reordering feature (Section 3.2) not proposed previously. 5 Conclusion and Future Work We provided a detailed description of left-to-right Hiero decoding, many details of which were only implicit in (Watanabe et al., 2006b). We presented an augmented LR decoding algorithm that builds on the original algorithm in (Watanabe et al., 2006b) but unlike that algorithm, using experiments over multiple language pairs we showed two new results: (i) Our LR decoding algorithm provides demonstrably more efficient decoding than CKY Hiero and the original LR decoding algorithm in (Watanabe et al., 2006b). And, (ii) by introducing new distortion and reordering features for LR decoding we show that it maintains the BLEU scores obtained by phrasebased and CKY Hiero-GNF. CKY Hiero uses standard Hiero-style translation rules cap</context>
</contexts>
<marker>Watanabe, Suzuki, Tsukada, Isozaki, 2006</marker>
<rawString>Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki Isozaki. 2006a. NTT statistical machine translation for iwslt 2006. In Proceedings of IWSLT 2006, pages 95–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
</authors>
<title>Left-to-right target generation for hierarchical phrase-based translation.</title>
<date>2006</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="814" citStr="Watanabe et al., 2006" startWordPosition="117" endWordPosition="120">aran,anoop}@cs.sfu.ca Abstract Left-to-right (LR) decoding (Watanabe et al., 2006b) is a promising decoding algorithm for hierarchical phrase-based translation (Hiero). It generates the target sentence by extending the hypotheses only on the right edge. LR decoding has complexity O(n2b) for input of n words and beam size b, compared to O(n3) for the CKY algorithm. It requires a single language model (LM) history for each target hypothesis rather than two LM histories per hypothesis as in CKY. In this paper we present an augmented LR decoding algorithm that builds on the original algorithm in (Watanabe et al., 2006b). Unlike that algorithm, using experiments over multiple language pairs we show two new results: our LR decoding algorithm provides demonstrably more efficient decoding than CKY Hiero, four times faster; and by introducing new distortion and reordering features for LR decoding, it maintains the same translation quality (as in BLEU scores) obtained phrase-based and CKY Hiero with the same translation model. 1 Introduction Hiero (Chiang, 2007) models translation using a lexicalized synchronous context-free grammar (SCFG) extracted from word aligned bitexts. Typically, CKY-style decoding is use</context>
<context position="2541" citStr="Watanabe et al., 2006" startWordPosition="390" endWordPosition="393">eafield et al., 2013). The size of a Hiero SCFG grammar is typically larger than phrase-based models extracted from the same data creating challenges in rule extraction and decoding time especially for larger datasets (Sankaran et al., 2012). In contrast, the LR-decoding algorithm could avoid these shortcomings such as faster time complexity, reduction in the grammar size and the simplified left-to-right language model scoring. It means LR decoding has the potential to replace CKY decoding for Hiero. Despite these attractive properties, we show that the original LR-Hiero decoding proposed by (Watanabe et al., 2006b) does not perform to the same level of the standard CKY Hiero with cube pruning (see Table 3). In addition, the current LR decoding algorithm does not obtain BLEU scores comparable to phrase-based or CKYbased Hiero models for different language pairs (see Table 4). In this paper we propose modifications to the LR decoding algorithm that addresses these limitations and provides, for the first time, a true alternative to the standard CKY Hiero algorithm that uses left-to-right decoding. We introduce a new extended version of the LR decoding algorithm presented in (Watanabe et al., 2006b) which</context>
<context position="5646" citStr="Watanabe et al., 2006" startWordPosition="900" endWordPosition="903">terminals (rule arity) to two and disallowing any rule with consecutive non-terminals on the foreign language side. It further limits the length of the initial phrase-pair as well as the number of terminals and non-terminals in the rule. For translating sentences longer than the maximum phrase-pair length, the decoder relies on additional glue rules 5 —* (X, X) and 5 —* (5X, 5X) that allows monotone combination of phrases. The glue rules are used when no rules could match or the span length is larger than the maximum phrase-pair length. 2.1 Rule Extraction for LR Decoding Left-to-right Hiero (Watanabe et al., 2006b) generates the target hypotheses left to right, but for synchronous context-free grammar (SCFG) as used in Hiero. The target-side rules are constrained to be prefix lexicalized. These constrained SCFG rules are defined as: X —* (-y,bQ) (1) where -y is a mixed string of terminals and nonterminals. b is a terminal sequence prefixed to the possibly empty non-terminal sequence Q. For the sake of simplicity, We refer to these type of rules as schuler ihre arbeit noch nicht gemacht haben . Figure 1: (a): A word-aligned German-English sentence pair. The bars above the source words indicate phrasepa</context>
<context position="7144" citStr="Watanabe et al. (2006" startWordPosition="1152" endWordPosition="1155">olating GNF form on the target side are excluded. Rule extraction considers each smaller source-target phrase pair within a larger phrase pair and replaces the spans with non-terminal X, yielding hierarchical rules. Figure 1(a) shows a wordaligned German-English sentence with a phrase pair (ihre arbeit noch nicht gemacht haben, have not yet done their work) that will lead to a SCFG rule. Given other smaller phrases (marked by bars above the source side), we extract a GNF rule2: X —* (X1 noch nicht X2 haben, have not yet X2 X1) (2) In order to avoid data sparsity and for better generalization, Watanabe et al. (2006b) adds four glue rules for each lexical rule (f, e) which are analogous to the glue rules defined in (Chiang, 2007) (see above) except that these glue rules for LR decoding 1Griebach Normal Form (GNF), although the synchronous grammar is not in this normal form, rather only the target side is prefix lexicalized as if it were in GNF form. 2 LR-Hiero rule extraction excludes non-GNF rules such as X --+ (X1 noch nicht gemacht X2, X2 not yet done X1). students have not yet done their work . (a) X1 students have X2 X6 X3 not yet . X4 X5 ihre arbeit gemacht done their work (b) 1 X1 schuler 3 6 X6 5</context>
<context position="9795" citStr="Watanabe et al., 2006" startWordPosition="1630" endWordPosition="1633">t of Hiero rules by using only target lexicalized rules in our LR decoder. 2.2 LR-Hiero Decoding LR-Hiero decoding uses a top-down depth-first search, which strictly grows the hypotheses in target surface ordering. Search on the source side follows an Earley-style search (Earley, 1970), the dot jumps around on the source side of the rules based on the order of nonterminals on the target side. This search is integrated with beam search or cube pruning to efficiently find the k-best translations. Several important details about the algorithm of LR-Hiero decoding are implicit and unexplained in (Watanabe et al., 2006b). In this section we describe the LR-Hiero decoding algorithm in more detail than the original description in (Watanabe et al., Algorithm 1: LR-Hiero Decoding 1: Input sentence: f = f0f1 ... fn 2: J7 = FutureCost(f) (Precompute future cost for spans) 3: for i = 0,...,n do 4: Si = {} (Create empty stacks) 5: h0 = ((s), [[0, n]], 0, J7[0,n]) (Initial hypothesis 4-tuple) 6: Add h0 to S0 (Push initial hyp into first Stack) 7: for i = 0,...,n − 1 do 8: for each h in Si do 9: [u, v] = pop(hs) (Pop first uncovered span from list) 10: R = GetSpanRules([u, v]) (Extract rules matching the entire span </context>
<context position="16392" citStr="Watanabe et al. (2006" startWordPosition="2787" endWordPosition="2790">Cube Pruning The Algorithm 1 presented earlier does an exhaustive search as it generates all possible partial translations for a given stack that are reachable from the hypotheses in previous stacks. However only a few of these hypotheses are retained, while majority of them are pruned away. The cube pruning technique (Chiang, 2007) avoids the wasteful generation of poor hypotheses that are likely to be pruned away by efficiently restricting the generation to only high scoring partial translations. We modify the cube pruning for LR-decoding that takes into account the next uncovered span to 3 Watanabe et al. (2006b) also use a similar future cost, even though it is not discussed in the paper (p.c.). 1092 Algorithm 2: LR-Hiero Decoding with Cube Pruning 1: Input sentence: f = f0f1 ... fn 2: F = FutureCost(f) (Precompute future cost for spans) 3: S0 = {} (Create empty initial stack) 4: h0 = ((s), [[0, n]], 0, F[0,n]) (Initial hypothesis 4-tuple) 5: Add h0 to S0 (Push initial hyp into first Stack) 6: for i = 1,...,n do 7: cubeList = {} (MRL is max rule length) 8: for p = max(i − MRL, 0), ... , i − 1 do 9: {G} = Grouped(Sp) (Group based on the first uncovered span) 10: for g E {G} do 11: [u, v] = gspan 12:</context>
<context position="22793" citStr="Watanabe et al. (2006" startWordPosition="3937" endWordPosition="3940">s cube (neighbours of the popped entry which are shaded in Figure 3(b)). These hypotheses are added to the priority queue. In the next iteration, the best hypothesis is popped from all candidates in the queue and algorithm continues. 3 Features We use the following standard SMT features for the log-linear model of LR-Hiero: relative-frequency translation probabilities p(f|e) and p(e|f), lexical translation probabilities pl(f|e) and pl(e|f), a language model probability, word count and phrase count. In addition we also use the glue rule count and the two reordering penalty features employed by Watanabe et al. (2006b; 2006a). These features compute the height and width (span size of the entire subtree) of all subtrees which are backtraced in the derivation of a hypothesis. A non-terminal XZ is pushed into the LIFO list of a partial hypothesis; it’s backtrace refers to the set of NTs that must be popped before XZ. In Figure 1(b), X2 has two subtrees X3 and X6, where X3 should be processed before X6. The subtree rooted at X3 in Figure 1(b) has a height of 2 and span [1, 6] having a width of 5. Similarly, X4 should be backtraced before X5 and has height and width of 1. Backtracing applies only for rules hav</context>
<context position="28787" citStr="Watanabe et al., 2006" startWordPosition="4962" endWordPosition="4965">2: Model sizes (millions of rules). We do not count glue rules for LR-Hiero which are created at runtime as needed. • Hiero: we used Kriya, our open-source implementation of Hiero in Python, which performs comparably to other open-source Hiero systems (Sankaran et al., 2012). Kriya can obtain statistically significantly equal BLEU scores when compared with Moses (Koehn et al., 2007) for several language pairs (Razmara et al., 2012; Callison-Burch et al., 2012). • Hiero-GNF: where we use Hiero decoder with the restricted LR-Hiero grammar (GNF rules). • LR-Hiero: our implementation of LR-Hiero (Watanabe et al., 2006b) in Python. • phrase-based: Moses (Koehn et al., 2007) • LR-Hiero+CP: LR-Hiero decoding with cube pruning. We use a 5-gram LM trained on the Gigaword corpus and use KenLM (Heafield, 2011) for LM scoring during decoding. We tune weights by minimizing BLEU loss on the dev set through MERT (Och, 2003) and report BLEU scores on the test set. We use comparable pop limits in each of the decoders: 1000 for Moses and LR-Hiero and 500 with cube pruning for CKY Hiero and LR-Hiero+CP. Other extraction and decoder settings such as maximum phrase length, etc. were identical across settings so that the re</context>
<context position="31476" citStr="Watanabe et al., 2006" startWordPosition="5417" endWordPosition="5420">se the same wrapper to query the language model, and we have instrumented the wrapper to count the statistics we need and thus we can say this is a fair comparison. For this experiment we use a sample set of 50 sentences taken from the test sets. Table 3 shows the results in terms of average number of language model queries and times in milliseconds. 4.3 Reordering Features To evaluate the new reordering features proposed to LR-Hiero (Section 3.2), LR-Hiero+CP with new features is compared to all baselines. Table 4 shows the BLEU scores of different models in two language pairs. The baseline (Watanabe et al., 2006b) model uses all the features mentioned therein but is 1096 Model cs-en de-en Phrase-based 20.32 24.71 CKY Hiero 20.64 25.52 CKY Hiero-GNF 20.04 24.84 LR-Hiero 18.30 23.47 LR-Hiero + reordering feats 20.20 24.90 LR-Hiero + CP + reordering feats 20.15 24.83 CKY Hiero-GNF + reordering feats 20.52 25.09 CKY Hiero + reordering feats 20.77 25.72 Table 4: BLEU scores. The rows are grouped such that each group use the same model. The last row in part 2 of table shows LR-Hiero+CP using our new features in addition to the baseline Watanabe features (line LR-Hiero baseline). The last part shows CKY Hie</context>
<context position="34975" citStr="Watanabe et al., 2006" startWordPosition="6005" endWordPosition="6008">n for nonterminal sub-spans is complete. In LR-decoding, we compute distortion for rules even though we are yet to translate some of the sub-spans. Thus our approach computes the distortion incrementally for the untranslated sub-spans which are later added. Unlike (Nguyen and Vogel, 2013), our distortion feature can be applied to both LR and CKY-decoding (Table 4). We have also introduced another reordering feature (Section 3.2) not proposed previously. 5 Conclusion and Future Work We provided a detailed description of left-to-right Hiero decoding, many details of which were only implicit in (Watanabe et al., 2006b). We presented an augmented LR decoding algorithm that builds on the original algorithm in (Watanabe et al., 2006b) but unlike that algorithm, using experiments over multiple language pairs we showed two new results: (i) Our LR decoding algorithm provides demonstrably more efficient decoding than CKY Hiero and the original LR decoding algorithm in (Watanabe et al., 2006b). And, (ii) by introducing new distortion and reordering features for LR decoding we show that it maintains the BLEU scores obtained by phrasebased and CKY Hiero-GNF. CKY Hiero uses standard Hiero-style translation rules cap</context>
</contexts>
<marker>Watanabe, Tsukada, Isozaki, 2006</marker>
<rawString>Taro Watanabe, Hajime Tsukada, and Hideki Isozaki. 2006b. Left-to-right target generation for hierarchical phrase-based translation. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jiajun Zhang</author>
<author>Chenqqing Zong</author>
</authors>
<title>A Comparative Study on Discontinuous Phrase Translation.</title>
<date>2012</date>
<booktitle>In NLPCC 2012,</booktitle>
<pages>164--175</pages>
<marker>Zhang, Zong, 2012</marker>
<rawString>Jiajun Zhang and Chenqqing Zong. 2012. A Comparative Study on Discontinuous Phrase Translation. In NLPCC 2012, pages 164–175.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>