<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019303">
<title confidence="0.9951675">
Classifying Message Board Posts with an Extracted Lexicon of Patient
Attributes
</title>
<author confidence="0.998809">
Ruihong Huang and Ellen Riloff
</author>
<affiliation confidence="0.921285333333333">
School of Computing
University of Utah
Salt Lake City, UT 84112
</affiliation>
<email confidence="0.997471">
{huangrh, riloff}@cs.utah.edu
</email>
<sectionHeader confidence="0.998578" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998001875">
The goal of our research is to distinguish vet-
erinary message board posts that describe a
case involving a specific patient from posts
that ask a general question. We create a text
classifier that incorporates automatically gen-
erated attribute lists for veterinary patients to
tackle this problem. Using a small amount of
annotated data, we train an information extrac-
tion (IE) system to identify veterinary patient
attributes. We then apply the IE system to a
large collection of unannotated texts to pro-
duce a lexicon of veterinary patient attribute
terms. Our experimental results show that us-
ing the learned attribute lists to encode pa-
tient information in the text classifier yields
improved performance on this task.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999359857142857">
Our research focuses on the problem of classify-
ing message board posts in the domain of veterinary
medicine. Most of the posts in our corpus discuss a
case involving a specific patient, which we will call
patient-specific posts. But there are also posts that
ask a general question, for example to seek advice
about different medications, information about new
procedures, or how to perform a test. Our goal is
to distinguish the patient-specific posts from general
posts so that they can be automatically routed to dif-
ferent message board folders.
Distinguishing patient-specific posts from general
posts is a challenging problem for two reasons. First,
virtually any medical topic can appear in either type
of post, so the vocabulary is very similar. Second,
a highly skewed distribution exists between patient-
specific posts and general posts. Almost 90% of the
posts in our data are about specific patients.
With such a highly skewed distribution, it would
seem logical to focus on recognizing instances of the
minority class. But the distinguishing characteristic
of a general post is the absence of a patient. Two
nearly identical posts belong in different categories
if one mentions a patient and the other does not.
Consequently, our aim is to create features that iden-
tify references to a specific patient and use these to
more accurately distinguish the two types of posts.
Our research explores the use of information ex-
traction (IE) techniques to automatically identify
common attributes of veterinary patients, which we
use to encode patient information in a text classifier.
Our approach involves three phases. First, we train
a conditional random fields (CRF) tagger to iden-
tify seven common types of attributes that are of-
ten ascribed to veterinary patients: SPECIES/BREED,
NAME, AGE, GENDER, WEIGHT, POSSESSOR, and
DISEASE/SYMPTOM. Second, we apply the CRF
tagger to a large set of unannotated message board
posts, collect its extractions, and harvest the most
frequently extracted terms to create a Veterinary Pa-
tient Attribute (VPA) Lexicon.
Finally, we define three types of features that ex-
ploit the harvested VPA lexicon. These features rep-
resent the patient attribute terms, types, and com-
binations of them to help the classifier determine
whether a post is discussing a specific patient. We
conduct experiments which show that the extracted
patient attribute information improves text classifi-
cation performance on this task.
</bodyText>
<page confidence="0.964596">
1557
</page>
<bodyText confidence="0.292872">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1557–1562,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.999687" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999788066666667">
Our work demonstrates the use of information ex-
traction techniques to benefit a text classification ap-
plication. There has been a great deal of research on
text classification (e.g., (Borko and Bernick, 1963;
Hoyle, 1973; Joachims, 1998; Nigam et al., 2000;
Sebastiani, 2002)), which most commonly has used
bag-of-word features. Researchers have also inves-
tigated clustering (Baker and McCallum, 1998), La-
tent Semantic Indexing (LSI) (Zelikovitz and Hirsh,
2001), Latent Dirichlet Allocation (LDA) (Br et al.,
2008) and string kernels (Lodhi et al., 2001). Infor-
mation extraction techniques have been used previ-
ously to create richer features for event-based text
classification (Riloff and Lehnert, 1994) and web
page classification (Furnkranz et al., 1998). Se-
mantic information has also been incorporated for
text classification. However, most previous work re-
lies on existing semantic resources, such as Wordnet
(Scott and Stan, 1998; Bloehdorn and Hotho, 2006)
or Wikipedia (Wang et al., 2009).
There is also a rich history of automatic lexicon
induction from text corpora (e.g., (Roark and Char-
niak, 1998; Riloff and Jones, 1999; McIntosh and
Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel,
2009)), and the Web (e.g., (Etzioni et al., 2005;
Kozareva et al., 2008; Carlson et al., 2010)). The
novel aspects of our work are in using an IE tagger
to harvest a domain-specific lexicon from unanno-
tated texts, and using the induced lexicon to encode
domain-specific features for text classification.
</bodyText>
<sectionHeader confidence="0.990713" genericHeader="method">
3 Text Classification with Extracted
</sectionHeader>
<subsectionHeader confidence="0.899515">
Patient Attributes
</subsectionHeader>
<bodyText confidence="0.993490952380953">
This resesarch studies message board posts from the
Veterinary Information Network (VIN), which is a
web site (www.vin.com) for professionals in veteri-
nary medicine. VIN hosts forums where veterinar-
ians discuss medical issues, challenging cases, etc.
We observed that patient-specific veterinary posts
almost always include some basic facts about the
patient, such as the animal’s breed, age, or gender.
It is also common to mention the patient’s owner
(e.g., “a new client’s cat”) or a disease or symptom
that the patient has (e.g., “a diabetic cat”). General
posts almost never contain this information.
Although some of these terms can be found in
existing resources such as Wordnet (Miller, 1990),
our veterinary message board posts are filled with
informal and unconventional vocabulary. For ex-
ample, one might naively assume that “male” and
“female” are sufficient to identify gender. But the
gender of animals is often revealed by describing
their spayed/neutered status, often indicated with
shorthand notations. For example, “m/n” means
male and neutered, “fs” means female spayed, “cas-
trated” means neutered and implies male. Short-
hand terms and informal jargon are also frequently
used for breeds (e.g., “doxy” for dachsund, “labx”
for labrador cross, “gshep” for German Shepherd)
and ages (e.g., “3-yr-old”, “3yo”, “3mo”). A par-
ticularly creative age expression describes an animal
as (say) “a 1999 model” (i.e., born in 1999). To rec-
ognize the idiosyncratic vocabulary in these texts,
we use information extraction techniques to identify
terms corresponding to seven attributes of veterinary
patients: SPECIES/BREED, NAME, AGE, WEIGHT,
GENDER, POSSESSOR, and DISEASE/SYMPTOM.
Figure 1 illustrates our overall approach, which
consists of three steps. First, we train a sequential
IE tagger to label veterinary patient attributes using
supervised learning. Second, we apply the tagger
to 10,000 unannotated message board posts to auto-
matically create a Veterinary Patient Attribute (VPA)
Lexicon. Third, we use the VPA Lexicon to encode
patient attribute features in a document classifier.
</bodyText>
<figureCaption confidence="0.80896">
Figure 1: Flowchart for Creating a Patient-Specific vs.
General Document Classifier
</figureCaption>
<subsectionHeader confidence="0.999337">
3.1 Patient Attribute Tagger
</subsectionHeader>
<bodyText confidence="0.999944">
The first component of our system is a tagger that
labels veterinary patient attributes. To train the tag-
ger, we need texts labeled with patient attributes.
</bodyText>
<figure confidence="0.999337318181818">
VPA Tagger
(CRF)
PI Sentence
Classifier
Step 3
Annotated
Texts
VPA
Lexicon
Step 1
Annotated
Texts
Document
Classifier
Step 2 Unannotated
Texts
PI Sentence
Classifier
VPA Tagger
(CRF)
VPA
Lexicon
</figure>
<page confidence="0.978075">
1558
</page>
<bodyText confidence="0.999848125000001">
The message board posts can be long and tedious
to read (i.e., they are often filled with medical his-
tory and test results), so manually annotating every
word would be arduous. However, the patient is usu-
ally described at the beginning of a post, most com-
monly in 1-2 “introductory” sentences. Therefore
we adopted a two stage process, both for manual and
automatic tagging of patient attributes.
First, we created annotation guidelines to iden-
tify “patient introductory” (PI) sentences, which we
defined as sentences that introduce a patient to the
reader by providing a general (non-medical) descrip-
tion of the animal (e.g., “I was presented with a m/n
Siamese cat that is lethargic.”) We randomly se-
lected 300 posts from our text collection and asked
two human annotators to manually identify the PI
sentences. We measured their inter-annotator agree-
ment using Cohen’s kappa (r.) and their agreement
was r.=.93. The two annotators then adjudicated
their differences to create our gold standard set of PI
sentence annotations. 269 of the 300 posts contained
at least one PI sentence , indicating that 89.7% of the
posts mention a specific patient. The remaining 31
posts (10.3%) are general in nature.
Second, the annotators manually labeled the
words in these PI sentences with respect to the 7 vet-
erinary patient attributes. On 50 randomly selected
texts, the annotators achieved an inter-annotator
agreement of r. = .89. The remaining 250 posts were
then annotated with patient attributes (in the PI sen-
tences), providing us with gold standard attribute an-
notations for all 300 posts. To illustrate, the sentence
below would have the following labels:
Daisyname is a 10yrage oldage labspedes
We used these 300 annotated posts to train both
a PI sentence classifier and a patient attribute tag-
ger. The PI sentence classifier is a support vector
machine (SVM) with a linear kernel (Keerthi and
DeCoste, 2005), unigram and bigram features, and
binary feature values. The PI sentences are the posi-
tive training instances, and the sentences in the gen-
eral posts are negative training instances.
For the tagger, we trained a single conditional ran-
dom fields (CRF) model to label all 7 types of pa-
tient attributes using the CRF++ package (Lafferty
et al., 2001). We defined features for the word string
and the part-of-speech tags of the targeted word, two
words on its left, and two words on its right.
Given new texts to process, we first apply the PI
sentence classifier to identify sentences that intro-
duce a patient. These sentences are given to the pa-
tient attribute tagger, which labels the words in those
sentences for the 7 patient attribute categories.
To evaluate the performance of the patient at-
tribute tagger, we randomly sampled 200 of the 300
annotated documents to use as training data and used
the remaining 100 documents for testing. For this
experiment, we only applied the CRF tagger to the
gold standard PI sentences, to eliminate any con-
founding factors from the PI sentence classifier. Ta-
ble 1 shows the performance of the CRF tagger in
terms of Recall (%), Precision (%), and F Score (%).
Its precision is consistently high, averaging 91%
across all seven attributes. But the average recall is
only 47%, with only one attribute (AGE) achieving
recall &gt; 80%. Nevertheless, the CRF’s high preci-
sion justifies our plan to use the CRF tagger to har-
vest additional attribute terms from a large collection
of unannotated texts. As we will see in Section 4,
the additional terms harvested from the unannotated
texts provide substantially more attribute informa-
tion for the document classifier to use.
</bodyText>
<table confidence="0.999621555555556">
Attribute Rec Prec F
SPECIES/BREED 59 93 72
NAME 62 100 76
POSSESSOR 12 100 21
AGE 80 91 85
GENDER 59 81 68
WEIGHT 19 100 32
DISEASE/SYMPTOM 35 73 47
Average 47 91 62
</table>
<tableCaption confidence="0.999684">
Table 1: Patient Attribute Tagger Evaluation
</tableCaption>
<subsectionHeader confidence="0.9220845">
3.2 Creating a Veterinary Patient Attribute
(VPA) Lexicon
</subsectionHeader>
<bodyText confidence="0.999920666666667">
The patient attribute tagger was trained with super-
vised learning, so its ability to recognize important
words is limited by the scope of its training set.
Since we had an additional 10,000 unannotated vet-
erinary message board posts, we used the tagger to
acquire a large lexicon of patient attribute terms.
We applied the PI sentence classifier to all 10,000
texts and then applied the patient attribute tagger to
each PI sentence. The patient attribute tagger is not
</bodyText>
<page confidence="0.992749">
1559
</page>
<bodyText confidence="0.999094857142857">
perfect, so we assumed that words tagged with the
same attribute value at least five times1 are most
likely to be correct and harvested them to create a
veterinary patient attribute (VPA) lexicon. This pro-
duced a VPA lexicon of 592 words. Table 2 shows
examples of learned terms for each attribute, with
the total number of learned words in parentheses.
</bodyText>
<table confidence="0.99767575">
Species/Breed (177): DSH, Schnauzer, kitty, Bengal,
pug, Labrador, siamese, Shep, miniature, golden, lab,
Spaniel, Westie, springer, Chow, cat, Beagle, Mix, ...
Name (53): Lucky, Shadow, Toby, Ginger, Boo, Max,
Baby, Buddy, Tucker, Gracie, Maggie, Willie, Tiger,
Sasha, Rusty, Beau, Kiki, Oscar, Harley, Scooter, ...
Age (59): #-year, adult, young, YO, y/o, model, wk,
y.o., yr-old, yrs, y, #-yr, #-month, #m, mo, mth, ...
Gender (39): F/s, speyed, neutered, spayed, N/M,
FN, CM, F, mc, mn, SF, male, fs, M/N, Female,
S, S/F, m/n, m/c, intact, M, NM, castrated,...
Weight (5): lb, lbs, pound, pounds, kg
Possessor (7): my, owner, client, technician,...
Disease/Symptom (252): abscess, fever, edema,
hepatic, inappetance, sneezing, blindness, pain,
persistent, mass, insufficiency, acute, poor,...
</table>
<tableCaption confidence="0.999204">
Table 2: Examples from the Induced VPA Lexicon
</tableCaption>
<subsectionHeader confidence="0.766285">
3.3 Text Classification with Patient Attributes
</subsectionHeader>
<bodyText confidence="0.991760791666667">
Our ultimate goal is to incorporate patient attribute
information into a text classifier to help it distinguish
between patient-specific posts and general posts. We
designed three sets of features:
Attribute Types: We create one feature for each
attribute type, indicating whether a word of that at-
tribute type appeared or not.
Attribute Types with Neighbor: For each word la-
beled as a patient attribute, we create two features
by pairing its Attribute Type with a preceding or fol-
lowing word. For example, given the sentence: “The
tiny Siamese kitten was lethargic.”, if “Siamese” has
attribute type SPECIES then we create two features:
&lt;tiny, SPECIES&gt; and &lt;SPECIES, kitten&gt;.
Attribute Pairs: We create features for all pairs of
patient attribute words that occur in the same sen-
tence. For each pair, we create one feature repre-
1After our text classification experiments were done, we re-
ran the experiments with the unigrams+lexicon classifier using
thresholds ranging from 1 to 10 for lexicon creation, just to see
how much difference this threshold made. We found that values
&gt; 5 produced nearly identical classification results.
senting the words themselves and one feature repre-
senting the attribute types of the words.
</bodyText>
<sectionHeader confidence="0.998804" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999994341463415">
To create a blind test set for evaluation, our anno-
tators labeled an additional 500 posts as patient-
specific or general. Specifically, they labeled those
500 posts with PI sentences. The absence of a PI
sentence meant that the post was general. Of the 500
texts, 48 (9.6%) were labeled as general posts. We
evaluated the performance of the PI sentence classi-
fier on this test set and found that it achieved 88% ac-
curacy at identifying patient introductory sentences.
We then conducted a series of experiments for the
document classification task: distinguishing patient-
specific message board posts from general posts.
All of our experiments used support vector machine
(SVM) classifiers with a linear kernel, and ran 10-
fold cross validation on our blind test set of 500
posts. We report Recall (%), Precision (%), and F
score (%) results for the patient-specific posts and
general posts separately, and for the macro-averaged
score across both classes. For the sake of complete-
ness, we also show overall Accuracy (%) results.
However, we will focus attention on the results for
the general posts, since our main goal is to improve
performance at recognizing this minority class.
As a baseline, we created SVM classifiers using
unigram features.2 We tried binary, frequency, and
tf-idf feature values. The first three rows of Table 3
show that binary feature values performed the best,
yielding a macro-averaged F score of 81% but iden-
tifying only 54% of the general posts.
The middle section of Table 3 shows the perfor-
mance of SVM classifiers using our patient attribute
features. We conducted three experiments: apply-
ing the CRF tagger to PI sentences (per its design),
and labeling words with the VPA lexicon either on
all sentences or only on PI sentences (as identi-
fied by the PI sentence classifier). The CRF fea-
tures produced extremely low recall and precision
on the general posts. The VPA lexicon performed
best when applied only to PI sentences and pro-
duced much higher recall than all of the other clas-
sifiers, although with lower precision than the two
</bodyText>
<footnote confidence="0.9949755">
2We also tried unigrams +bigrams, but they did not perform
better.
</footnote>
<page confidence="0.923271">
1560
</page>
<table confidence="0.999726307692308">
Method Patient-Specific Posts General Posts Macro Avg F Acc
Rec Prec F Rec Prec F Rec Prec
Unigram Features
Unigrams (freq) 96 96 96 58 60 59 77 76 77 92
Unigrams (tf-idf) 99 93 96 33 84 48 66 89 76 93
Unigrams (binary) 98 95 97 54 79 64 76 87 81 94
Patient Attribute Features
CRF Features (PI Sents) 99 91 95 02 25 04 51 58 54 90
VPA Lexicon Features (All Sents) 96 96 96 60 63 62 78 79 79 93
VPA Lexicon Features (PI Sents) 96 98 97 81 66 73 88 82 85 94
Unigram &amp; Patient Attribute Features
CRF Features (PI Sents) 97 96 97 60 71 65 79 83 81 94
VPA Lexicon Features (PI Sents) 98 98 98 79 78 78 88 88 88 96
</table>
<tableCaption confidence="0.999457">
Table 3: Experimental Results
</tableCaption>
<bodyText confidence="0.974326409090909">
best unigram-based SVMs.
The bottom section of Table 3 shows results for
classifiers with both unigrams (binary) and patient
attribute features. Using the CRF features increases
recall on the general posts from 54 —* 60, but de-
creases precision from 79 —* 71. Using the patient
attribute features from the VPA lexicon yields a sub-
stantial improvement. Recall improves from 54 —*
79 and precision is just one point lower. Overall, the
macro-averaged F score across the two categories
jumps from 81% to 88%.
We performed paired bootstrap testing (Berg-
Kirkpatrick et al., 2012)) to determine whether the
SVM with unigrams and VPA lexicon features is
statistically significantly better than the best SVM
with only unigram features (binary). The SVM with
unigrams and VPA lexicon features produces sig-
nificantly better F scores at the p &lt; 0.05 level for
general post classification as well as the macro av-
erage. The F score for patient-specific classification
and overall accuracy are statistically significant at
the p &lt; 0.10 level.
</bodyText>
<table confidence="0.998253">
Attribute CRF VPA
Tagger Lexicon
SPECIES/BREED 270 1045
NAME 36 43
POSSESSOR 12 233
AGE 545 1773
GENDER 153 338
WEIGHT 27 83
DISEASE/SYMPTOM 220 2673
</table>
<tableCaption confidence="0.99976">
Table 4: Number of Attributes Labeled in Test Set
</tableCaption>
<bodyText confidence="0.999973555555556">
Finally, we did an analysis to understand why the
VPA lexicon was so much more effective than the
CRF tagger when used to create features for text
classification. Table 4 shows the number of words
in PI sentences (identified by the classifier) of the
test set that were labeled as patient attributes by the
CRF tagger or the VPA lexicon. The VPA lexicon
clearly labeled many more terms, and the additional
coverage made a big difference for the text classifier.
</bodyText>
<sectionHeader confidence="0.999575" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999994076923077">
This work demonstrated how annotated data can be
leveraged to automatically harvest a domain-specific
lexicon from a large collection of unannotated texts.
Our induced VPA lexicon was then used to create
patient attribute features that improved the ability of
a document classifier to distinguish between patient-
specific message board posts and general posts. We
believe that this approach could also be used to cre-
ate specialized lexicons for many other domains and
applications. A key benefit of inducing lexicons
from unannotated texts is that they provide addi-
tional vocabulary coverage beyond the terms found
in annotated data sets, which are usually small.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.9978412">
This material is based upon work supported by
the National Science Foundation under grant IIS-
1018314. We are very grateful to the Veterinary In-
formation Network for providing us with samples of
their data.
</bodyText>
<page confidence="0.990039">
1561
</page>
<sectionHeader confidence="0.995743" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99587103125">
D. Baker and A. McCallum. 1998. Distributional cluster-
ing of words for text classification. In Proceedings of
the 21st annual international ACM SIGIR conference
on Research and development in information retrieval.
T. Berg-Kirkpatrick, D. Burkett, and D. Klein. 2012. An
Empirical Investigation of Statistical Significance in
NLP. In Proceedings of the 2012 Conference on Em-
pirical Methods in Natural Language Processing.
S. Bloehdorn and A. Hotho. 2006. Boosting for text
classification with semantic features. In Advances in
Web mining and Web usage Analysis.
H. Borko and M. Bernick. 1963. Automatic Document
Classification. J. ACM, 10(2):151–162.
I. Br, J. Szab, and A. Benczr. 2008. Latent dirichlet allo-
cation in web spam filtering. In Proceedings of the 4th
international workshop on Adversarial information re-
trieval on the web.
A. Carlson, J. Betteridge, B. Kisiel, B. Settles, R. Es-
tevam, J. Hruschka, and T. Mitchell. 2010. Toward
an Architecture for Never-Ending Language Learning.
In Proceedings of the Twenty-Fourth National Confer-
ence on Artificial Intelligence.
O. Etzioni, M. Cafarella, A. Popescu, T. Shaked,
S. Soderland, D. Weld, and A. Yates. 2005. Unsuper-
vised Named-Entity Extraction from the Web: An Ex-
perimental Study. Artificial Intelligence, 165(1):91–
134.
J. Furnkranz, T. Mitchell, and E. Riloff. 1998. A Case
Study in Using Linguistic Phrases for Text Catego-
rization from the WWW. In Working Notes of the
AAAI/ICML Workshop on Learning for Text Catego-
rization.
W. Hoyle. 1973. Automatic Indexing and Generation
of Classification Systems by Algorithm. Information
Storage and Retrieval, 9(4):233–242.
T. Joachims. 1998. Text categorization with support vec-
tor machines: Learning with many relevant features.
In Proceedings of the European Conference on Ma-
chine Learning (ECML).
S. Keerthi and D. DeCoste. 2005. A Modified Finite
Newton Method for Fast Solution of Large Scale Lin-
ear SVMs. Journal ofMachine Learning Research.
Z. Kozareva, E. Riloff, and E. Hovy. 2008. Semantic
Class Learning from the Web with Hyponym Pattern
Linkage Graphs. In Proceedings of the 46th Annual
Meeting ofthe Association for Computational Linguis-
tics: Human Language Technologies (ACL-08).
J. Lafferty, A. McCallum, and F. Pereira. 2001. Condi-
tional Random Fields: Probabilistic Models for Seg-
menting and Labeling Sequence Data. In Proceedings
of the Eighteenth International Conference on Ma-
chine Learning.
H. Lodhi, J. Shawe-Taylor, N. Christianini, and
C. Watkins. 2001. Text classification using string ker-
nels. In Advances in Neural Information Processing
Systems (NIPS).
T. McIntosh and J. Curran. 2009. Reducing Semantic
Drift with Bagging and Distributional Similarity. In
Proceedings of the 47th Annual Meeting of the Associ-
ation for Computational Linguistics.
G. Miller. 1990. Wordnet: An On-line Lexical Database.
International Journal ofLexicography, 3(4).
K. Nigam, A. McCallum, S. Thrun, and T. Mitchell.
2000. Text Classification from Labeled and Unla-
beled Documents using EM. Machine Learning, 39(2-
3):103–134, May.
E. Riloff and R. Jones. 1999. Learning Dictionaries for
Information Extraction by Multi-Level Bootstrapping.
In Proceedings of the Sixteenth National Conference
on Artificial Intelligence.
E. Riloff and W. Lehnert. 1994. Information Ex-
traction as a Basis for High-Precision Text Classifi-
cation. ACM Transactions on Information Systems,
12(3):296–333, July.
B. Roark and E. Charniak. 1998. Noun-phrase Co-
occurrence Statistics for Semi-automatic Semantic
Lexicon Construction. In Proceedings of the 36th
Annual Meeting of the Association for Computational
Linguistics, pages 1110–1116.
S. Scott and M. Stan. 1998. Text classification using
WordNet hypernyms. In In Use of WordNet in Natu-
ral Language Processing Systems: Proceedings of the
Conference.
F. Sebastiani. 2002. Machine learning in automated text
categorization. In ACM computing surveys (CSUR).
V. Vyas and P. Pantel. 2009. Semi-automatic entity set
refinement. In Proceedings of North American Asso-
ciation for Computational Linguistics / Human Lan-
guage Technology (NAACL/HLT-09).
P. Wang, J. Hu, H. Zeng, and Z. Chen. 2009. Using
Wikipedia knowledge to improve text classification.
In Knowledge and Information Systems.
S. Zelikovitz and H. Hirsh. 2001. Using LSI for text
classication in the presence of background text. In
Proceedings of the 10th International Conference on
Information and Knowledge Management (CIKM).
</reference>
<page confidence="0.994241">
1562
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.790596">
<title confidence="0.998794">Classifying Message Board Posts with an Extracted Lexicon of Patient Attributes</title>
<author confidence="0.999319">Ruihong Huang</author>
<author confidence="0.999319">Ellen</author>
<affiliation confidence="0.9982735">School of University of</affiliation>
<address confidence="0.806514">Salt Lake City, UT</address>
<abstract confidence="0.999117176470588">The goal of our research is to distinguish veterinary message board posts that describe a case involving a specific patient from posts that ask a general question. We create a text classifier that incorporates automatically generated attribute lists for veterinary patients to tackle this problem. Using a small amount of annotated data, we train an information extraction (IE) system to identify veterinary patient attributes. We then apply the IE system to a large collection of unannotated texts to produce a lexicon of veterinary patient attribute terms. Our experimental results show that using the learned attribute lists to encode patient information in the text classifier yields improved performance on this task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Baker</author>
<author>A McCallum</author>
</authors>
<title>Distributional clustering of words for text classification.</title>
<date>1998</date>
<booktitle>In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval.</booktitle>
<contexts>
<context position="4022" citStr="Baker and McCallum, 1998" startWordPosition="619" endWordPosition="622">sk. 1557 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1557–1562, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). T</context>
</contexts>
<marker>Baker, McCallum, 1998</marker>
<rawString>D. Baker and A. McCallum. 1998. Distributional clustering of words for text classification. In Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Berg-Kirkpatrick</author>
<author>D Burkett</author>
<author>D Klein</author>
</authors>
<title>An Empirical Investigation of Statistical Significance in NLP.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<marker>Berg-Kirkpatrick, Burkett, Klein, 2012</marker>
<rawString>T. Berg-Kirkpatrick, D. Burkett, and D. Klein. 2012. An Empirical Investigation of Statistical Significance in NLP. In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bloehdorn</author>
<author>A Hotho</author>
</authors>
<title>Boosting for text classification with semantic features.</title>
<date>2006</date>
<booktitle>In Advances in Web</booktitle>
<contexts>
<context position="4586" citStr="Bloehdorn and Hotho, 2006" startWordPosition="703" endWordPosition="706">s have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This </context>
</contexts>
<marker>Bloehdorn, Hotho, 2006</marker>
<rawString>S. Bloehdorn and A. Hotho. 2006. Boosting for text classification with semantic features. In Advances in Web mining and Web usage Analysis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Borko</author>
<author>M Bernick</author>
</authors>
<title>Automatic Document Classification.</title>
<date>1963</date>
<journal>J. ACM,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="3828" citStr="Borko and Bernick, 1963" startWordPosition="592" endWordPosition="595">etermine whether a post is discussing a specific patient. We conduct experiments which show that the extracted patient attribute information improves text classification performance on this task. 1557 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1557–1562, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated</context>
</contexts>
<marker>Borko, Bernick, 1963</marker>
<rawString>H. Borko and M. Bernick. 1963. Automatic Document Classification. J. ACM, 10(2):151–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Br</author>
<author>J Szab</author>
<author>A Benczr</author>
</authors>
<title>Latent dirichlet allocation in web spam filtering.</title>
<date>2008</date>
<booktitle>In Proceedings of the 4th international workshop on Adversarial information retrieval on the web.</booktitle>
<contexts>
<context position="4136" citStr="Br et al., 2008" startWordPosition="636" endWordPosition="639">Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Ril</context>
</contexts>
<marker>Br, Szab, Benczr, 2008</marker>
<rawString>I. Br, J. Szab, and A. Benczr. 2008. Latent dirichlet allocation in web spam filtering. In Proceedings of the 4th international workshop on Adversarial information retrieval on the web.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Carlson</author>
<author>J Betteridge</author>
<author>B Kisiel</author>
<author>B Settles</author>
<author>R Estevam</author>
<author>J Hruschka</author>
<author>T Mitchell</author>
</authors>
<title>Toward an Architecture for Never-Ending Language Learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the Twenty-Fourth National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="4915" citStr="Carlson et al., 2010" startWordPosition="758" endWordPosition="761">ation (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This resesarch studies message board posts from the Veterinary Information Network (VIN), which is a web site (www.vin.com) for professionals in veterinary medicine. VIN hosts forums where veterinarians discuss medical issues, challenging cases, etc. We observed that patient-specific veterinary posts almost always include some basic</context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Estevam, Hruschka, Mitchell, 2010</marker>
<rawString>A. Carlson, J. Betteridge, B. Kisiel, B. Settles, R. Estevam, J. Hruschka, and T. Mitchell. 2010. Toward an Architecture for Never-Ending Language Learning. In Proceedings of the Twenty-Fourth National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Etzioni</author>
<author>M Cafarella</author>
<author>A Popescu</author>
<author>T Shaked</author>
<author>S Soderland</author>
<author>D Weld</author>
<author>A Yates</author>
</authors>
<title>Unsupervised Named-Entity Extraction from the Web: An Experimental Study.</title>
<date>2005</date>
<journal>Artificial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<pages>134</pages>
<contexts>
<context position="4869" citStr="Etzioni et al., 2005" startWordPosition="750" endWordPosition="753">icher features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This resesarch studies message board posts from the Veterinary Information Network (VIN), which is a web site (www.vin.com) for professionals in veterinary medicine. VIN hosts forums where veterinarians discuss medical issues, challenging cases, etc. We observed that patient-specific vet</context>
</contexts>
<marker>Etzioni, Cafarella, Popescu, Shaked, Soderland, Weld, Yates, 2005</marker>
<rawString>O. Etzioni, M. Cafarella, A. Popescu, T. Shaked, S. Soderland, D. Weld, and A. Yates. 2005. Unsupervised Named-Entity Extraction from the Web: An Experimental Study. Artificial Intelligence, 165(1):91– 134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Furnkranz</author>
<author>T Mitchell</author>
<author>E Riloff</author>
</authors>
<title>A Case Study in Using Linguistic Phrases for Text Categorization from the WWW.</title>
<date>1998</date>
<booktitle>In Working Notes of the AAAI/ICML Workshop on Learning for Text Categorization.</booktitle>
<contexts>
<context position="4379" citStr="Furnkranz et al., 1998" startWordPosition="672" endWordPosition="675"> deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to ha</context>
</contexts>
<marker>Furnkranz, Mitchell, Riloff, 1998</marker>
<rawString>J. Furnkranz, T. Mitchell, and E. Riloff. 1998. A Case Study in Using Linguistic Phrases for Text Categorization from the WWW. In Working Notes of the AAAI/ICML Workshop on Learning for Text Categorization.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Hoyle</author>
</authors>
<title>Automatic Indexing and Generation of Classification Systems by Algorithm.</title>
<date>1973</date>
<journal>Information Storage and Retrieval,</journal>
<volume>9</volume>
<issue>4</issue>
<contexts>
<context position="3841" citStr="Hoyle, 1973" startWordPosition="596" endWordPosition="597">s discussing a specific patient. We conduct experiments which show that the extracted patient attribute information improves text classification performance on this task. 1557 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1557–1562, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text cla</context>
</contexts>
<marker>Hoyle, 1973</marker>
<rawString>W. Hoyle. 1973. Automatic Indexing and Generation of Classification Systems by Algorithm. Information Storage and Retrieval, 9(4):233–242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text categorization with support vector machines: Learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of the European Conference on Machine Learning (ECML).</booktitle>
<contexts>
<context position="3857" citStr="Joachims, 1998" startWordPosition="598" endWordPosition="599">a specific patient. We conduct experiments which show that the extracted patient attribute information improves text classification performance on this task. 1557 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1557–1562, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. How</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>T. Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of the European Conference on Machine Learning (ECML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Keerthi</author>
<author>D DeCoste</author>
</authors>
<title>A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs.</title>
<date>2005</date>
<journal>Journal ofMachine Learning Research.</journal>
<contexts>
<context position="9663" citStr="Keerthi and DeCoste, 2005" startWordPosition="1497" endWordPosition="1500">ect to the 7 veterinary patient attributes. On 50 randomly selected texts, the annotators achieved an inter-annotator agreement of r. = .89. The remaining 250 posts were then annotated with patient attributes (in the PI sentences), providing us with gold standard attribute annotations for all 300 posts. To illustrate, the sentence below would have the following labels: Daisyname is a 10yrage oldage labspedes We used these 300 annotated posts to train both a PI sentence classifier and a patient attribute tagger. The PI sentence classifier is a support vector machine (SVM) with a linear kernel (Keerthi and DeCoste, 2005), unigram and bigram features, and binary feature values. The PI sentences are the positive training instances, and the sentences in the general posts are negative training instances. For the tagger, we trained a single conditional random fields (CRF) model to label all 7 types of patient attributes using the CRF++ package (Lafferty et al., 2001). We defined features for the word string and the part-of-speech tags of the targeted word, two words on its left, and two words on its right. Given new texts to process, we first apply the PI sentence classifier to identify sentences that introduce a </context>
</contexts>
<marker>Keerthi, DeCoste, 2005</marker>
<rawString>S. Keerthi and D. DeCoste. 2005. A Modified Finite Newton Method for Fast Solution of Large Scale Linear SVMs. Journal ofMachine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Kozareva</author>
<author>E Riloff</author>
<author>E Hovy</author>
</authors>
<title>Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting ofthe Association for Computational Linguistics: Human Language Technologies (ACL-08).</booktitle>
<contexts>
<context position="4892" citStr="Kozareva et al., 2008" startWordPosition="754" endWordPosition="757">nt-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This resesarch studies message board posts from the Veterinary Information Network (VIN), which is a web site (www.vin.com) for professionals in veterinary medicine. VIN hosts forums where veterinarians discuss medical issues, challenging cases, etc. We observed that patient-specific veterinary posts almost al</context>
</contexts>
<marker>Kozareva, Riloff, Hovy, 2008</marker>
<rawString>Z. Kozareva, E. Riloff, and E. Hovy. 2008. Semantic Class Learning from the Web with Hyponym Pattern Linkage Graphs. In Proceedings of the 46th Annual Meeting ofthe Association for Computational Linguistics: Human Language Technologies (ACL-08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lafferty</author>
<author>A McCallum</author>
<author>F Pereira</author>
</authors>
<title>Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning.</booktitle>
<contexts>
<context position="10011" citStr="Lafferty et al., 2001" startWordPosition="1556" endWordPosition="1559">e following labels: Daisyname is a 10yrage oldage labspedes We used these 300 annotated posts to train both a PI sentence classifier and a patient attribute tagger. The PI sentence classifier is a support vector machine (SVM) with a linear kernel (Keerthi and DeCoste, 2005), unigram and bigram features, and binary feature values. The PI sentences are the positive training instances, and the sentences in the general posts are negative training instances. For the tagger, we trained a single conditional random fields (CRF) model to label all 7 types of patient attributes using the CRF++ package (Lafferty et al., 2001). We defined features for the word string and the part-of-speech tags of the targeted word, two words on its left, and two words on its right. Given new texts to process, we first apply the PI sentence classifier to identify sentences that introduce a patient. These sentences are given to the patient attribute tagger, which labels the words in those sentences for the 7 patient attribute categories. To evaluate the performance of the patient attribute tagger, we randomly sampled 200 of the 300 annotated documents to use as training data and used the remaining 100 documents for testing. For this</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>J. Lafferty, A. McCallum, and F. Pereira. 2001. Conditional Random Fields: Probabilistic Models for Segmenting and Labeling Sequence Data. In Proceedings of the Eighteenth International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Lodhi</author>
<author>J Shawe-Taylor</author>
<author>N Christianini</author>
<author>C Watkins</author>
</authors>
<title>Text classification using string kernels.</title>
<date>2001</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS).</booktitle>
<contexts>
<context position="4176" citStr="Lodhi et al., 2001" startWordPosition="643" endWordPosition="646">c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran</context>
</contexts>
<marker>Lodhi, Shawe-Taylor, Christianini, Watkins, 2001</marker>
<rawString>H. Lodhi, J. Shawe-Taylor, N. Christianini, and C. Watkins. 2001. Text classification using string kernels. In Advances in Neural Information Processing Systems (NIPS).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T McIntosh</author>
<author>J Curran</author>
</authors>
<title>Reducing Semantic Drift with Bagging and Distributional Similarity.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="4783" citStr="McIntosh and Curran, 2009" startWordPosition="736" endWordPosition="739">Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This resesarch studies message board posts from the Veterinary Information Network (VIN), which is a web site (www.vin.com) for professionals in veterinary medicine. VIN hosts forums where veterinarians</context>
</contexts>
<marker>McIntosh, Curran, 2009</marker>
<rawString>T. McIntosh and J. Curran. 2009. Reducing Semantic Drift with Bagging and Distributional Similarity. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
</authors>
<title>Wordnet: An On-line Lexical Database.</title>
<date>1990</date>
<journal>International Journal ofLexicography,</journal>
<volume>3</volume>
<issue>4</issue>
<contexts>
<context position="5881" citStr="Miller, 1990" startWordPosition="909" endWordPosition="910">), which is a web site (www.vin.com) for professionals in veterinary medicine. VIN hosts forums where veterinarians discuss medical issues, challenging cases, etc. We observed that patient-specific veterinary posts almost always include some basic facts about the patient, such as the animal’s breed, age, or gender. It is also common to mention the patient’s owner (e.g., “a new client’s cat”) or a disease or symptom that the patient has (e.g., “a diabetic cat”). General posts almost never contain this information. Although some of these terms can be found in existing resources such as Wordnet (Miller, 1990), our veterinary message board posts are filled with informal and unconventional vocabulary. For example, one might naively assume that “male” and “female” are sufficient to identify gender. But the gender of animals is often revealed by describing their spayed/neutered status, often indicated with shorthand notations. For example, “m/n” means male and neutered, “fs” means female spayed, “castrated” means neutered and implies male. Shorthand terms and informal jargon are also frequently used for breeds (e.g., “doxy” for dachsund, “labx” for labrador cross, “gshep” for German Shepherd) and ages</context>
</contexts>
<marker>Miller, 1990</marker>
<rawString>G. Miller. 1990. Wordnet: An On-line Lexical Database. International Journal ofLexicography, 3(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Nigam</author>
<author>A McCallum</author>
<author>S Thrun</author>
<author>T Mitchell</author>
</authors>
<title>Text Classification from Labeled and Unlabeled Documents using EM.</title>
<date>2000</date>
<booktitle>Machine Learning,</booktitle>
<pages>39--2</pages>
<contexts>
<context position="3877" citStr="Nigam et al., 2000" startWordPosition="600" endWordPosition="603">nt. We conduct experiments which show that the extracted patient attribute information improves text classification performance on this task. 1557 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1557–1562, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous </context>
</contexts>
<marker>Nigam, McCallum, Thrun, Mitchell, 2000</marker>
<rawString>K. Nigam, A. McCallum, S. Thrun, and T. Mitchell. 2000. Text Classification from Labeled and Unlabeled Documents using EM. Machine Learning, 39(2-3):103–134, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>R Jones</author>
</authors>
<title>Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="4755" citStr="Riloff and Jones, 1999" startWordPosition="732" endWordPosition="735">08) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This resesarch studies message board posts from the Veterinary Information Network (VIN), which is a web site (www.vin.com) for professionals in veterinary medicine. VIN host</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>E. Riloff and R. Jones. 1999. Learning Dictionaries for Information Extraction by Multi-Level Bootstrapping. In Proceedings of the Sixteenth National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>W Lehnert</author>
</authors>
<title>Information Extraction as a Basis for High-Precision Text Classification.</title>
<date>1994</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="4326" citStr="Riloff and Lehnert, 1994" startWordPosition="664" endWordPosition="667">text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The nove</context>
</contexts>
<marker>Riloff, Lehnert, 1994</marker>
<rawString>E. Riloff and W. Lehnert. 1994. Information Extraction as a Basis for High-Precision Text Classification. ACM Transactions on Information Systems, 12(3):296–333, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Roark</author>
<author>E Charniak</author>
</authors>
<title>Noun-phrase Cooccurrence Statistics for Semi-automatic Semantic Lexicon Construction.</title>
<date>1998</date>
<booktitle>In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1110--1116</pages>
<contexts>
<context position="4731" citStr="Roark and Charniak, 1998" startWordPosition="727" endWordPosition="731">ation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This resesarch studies message board posts from the Veterinary Information Network (VIN), which is a web site (www.vin.com) for professionals in veter</context>
</contexts>
<marker>Roark, Charniak, 1998</marker>
<rawString>B. Roark and E. Charniak. 1998. Noun-phrase Cooccurrence Statistics for Semi-automatic Semantic Lexicon Construction. In Proceedings of the 36th Annual Meeting of the Association for Computational Linguistics, pages 1110–1116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Scott</author>
<author>M Stan</author>
</authors>
<title>Text classification using WordNet hypernyms. In</title>
<date>1998</date>
<booktitle>In Use of WordNet in Natural Language Processing Systems: Proceedings of the Conference.</booktitle>
<contexts>
<context position="4558" citStr="Scott and Stan, 1998" startWordPosition="699" endWordPosition="702">d features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extrac</context>
</contexts>
<marker>Scott, Stan, 1998</marker>
<rawString>S. Scott and M. Stan. 1998. Text classification using WordNet hypernyms. In In Use of WordNet in Natural Language Processing Systems: Proceedings of the Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Sebastiani</author>
</authors>
<title>Machine learning in automated text categorization.</title>
<date>2002</date>
<booktitle>In ACM computing surveys (CSUR).</booktitle>
<contexts>
<context position="3896" citStr="Sebastiani, 2002" startWordPosition="604" endWordPosition="605">iments which show that the extracted patient attribute information improves text classification performance on this task. 1557 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1557–1562, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on exis</context>
</contexts>
<marker>Sebastiani, 2002</marker>
<rawString>F. Sebastiani. 2002. Machine learning in automated text categorization. In ACM computing surveys (CSUR).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vyas</author>
<author>P Pantel</author>
</authors>
<title>Semi-automatic entity set refinement.</title>
<date>2009</date>
<booktitle>In Proceedings of North American Association for Computational Linguistics / Human Language Technology (NAACL/HLT-09).</booktitle>
<contexts>
<context position="4826" citStr="Vyas and Pantel, 2009" startWordPosition="742" endWordPosition="745">hniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This resesarch studies message board posts from the Veterinary Information Network (VIN), which is a web site (www.vin.com) for professionals in veterinary medicine. VIN hosts forums where veterinarians discuss medical issues, challenging cases,</context>
</contexts>
<marker>Vyas, Pantel, 2009</marker>
<rawString>V. Vyas and P. Pantel. 2009. Semi-automatic entity set refinement. In Proceedings of North American Association for Computational Linguistics / Human Language Technology (NAACL/HLT-09).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Wang</author>
<author>J Hu</author>
<author>H Zeng</author>
<author>Z Chen</author>
</authors>
<title>Using Wikipedia knowledge to improve text classification. In Knowledge and Information Systems.</title>
<date>2009</date>
<contexts>
<context position="4619" citStr="Wang et al., 2009" startWordPosition="709" endWordPosition="712">r and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction from text corpora (e.g., (Roark and Charniak, 1998; Riloff and Jones, 1999; McIntosh and Curran, 2009)), Wikipedia (e.g., (Vyas and Pantel, 2009)), and the Web (e.g., (Etzioni et al., 2005; Kozareva et al., 2008; Carlson et al., 2010)). The novel aspects of our work are in using an IE tagger to harvest a domain-specific lexicon from unannotated texts, and using the induced lexicon to encode domain-specific features for text classification. 3 Text Classification with Extracted Patient Attributes This resesarch studies message board p</context>
</contexts>
<marker>Wang, Hu, Zeng, Chen, 2009</marker>
<rawString>P. Wang, J. Hu, H. Zeng, and Z. Chen. 2009. Using Wikipedia knowledge to improve text classification. In Knowledge and Information Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Zelikovitz</author>
<author>H Hirsh</author>
</authors>
<title>Using LSI for text classication in the presence of background text.</title>
<date>2001</date>
<booktitle>In Proceedings of the 10th International Conference on Information and Knowledge Management (CIKM).</booktitle>
<contexts>
<context position="4083" citStr="Zelikovitz and Hirsh, 2001" startWordPosition="628" endWordPosition="631">thods in Natural Language Processing, pages 1557–1562, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics 2 Related Work Our work demonstrates the use of information extraction techniques to benefit a text classification application. There has been a great deal of research on text classification (e.g., (Borko and Bernick, 1963; Hoyle, 1973; Joachims, 1998; Nigam et al., 2000; Sebastiani, 2002)), which most commonly has used bag-of-word features. Researchers have also investigated clustering (Baker and McCallum, 1998), Latent Semantic Indexing (LSI) (Zelikovitz and Hirsh, 2001), Latent Dirichlet Allocation (LDA) (Br et al., 2008) and string kernels (Lodhi et al., 2001). Information extraction techniques have been used previously to create richer features for event-based text classification (Riloff and Lehnert, 1994) and web page classification (Furnkranz et al., 1998). Semantic information has also been incorporated for text classification. However, most previous work relies on existing semantic resources, such as Wordnet (Scott and Stan, 1998; Bloehdorn and Hotho, 2006) or Wikipedia (Wang et al., 2009). There is also a rich history of automatic lexicon induction fr</context>
</contexts>
<marker>Zelikovitz, Hirsh, 2001</marker>
<rawString>S. Zelikovitz and H. Hirsh. 2001. Using LSI for text classication in the presence of background text. In Proceedings of the 10th International Conference on Information and Knowledge Management (CIKM).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>