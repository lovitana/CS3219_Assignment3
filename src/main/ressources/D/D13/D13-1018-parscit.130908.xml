<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.998814">
Growing Multi-Domain Glossaries from a Few Seeds
using Probabilistic Topic Models
</title>
<author confidence="0.899725">
Stefano Faralli and Roberto Navigli
</author>
<affiliation confidence="0.716491">
Dipartimento di Informatica
</affiliation>
<address confidence="0.553716">
Sapienza Universit`a di Roma
</address>
<email confidence="0.988386">
{faralli,navigli}@di.uniroma1.it
</email>
<sectionHeader confidence="0.998605" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9930681">
In this paper we present a minimally-
supervised approach to the multi-domain ac-
quisition of wide-coverage glossaries. We start
from a small number of hypernymy rela-
tion seeds and bootstrap glossaries from the
Web for dozens of domains using Probabilis-
tic Topic Models. Our experiments show that
we are able to extract high-precision glos-
saries comprising thousands of terms and def-
initions.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999955245283019">
Dictionaries, thesauri and glossaries are useful
sources of information for students, scholars and ev-
eryday readers, who use them to look up words of
which they either do not know, or have forgotten,
the meaning. With the advent of the Web an increas-
ing number of dictionaries and technical glossaries
has been made available online, thereby speeding
up the definition search process. However, finding
definitions is not always immediate, especially if the
target term pertains to a specialized domain. Indeed,
not even well-known services such as Google Define
are able to provide definitions for scientific or tech-
nical terms such as taxonomy learning or distant su-
pervision in AI or figure-four leglock and suspended
surfboard in wrestling.
Domain-specific knowledge of a definitional na-
ture is not only useful for humans, it is also use-
ful for machines (Hovy et al., 2013). Examples
include Natural Language Processing tasks such as
Question Answering (Cui et al., 2007), Word Sense
Disambiguation (Duan and Yates, 2010; Faralli and
Navigli, 2012) and ontology learning (Velardi et al.,
2013). Unfortunately, most of the Web dictionar-
ies and glossaries available online comprise just a
few hundred definitions, and they therefore provide
only a partial view of a domain. This is also the
case with manually compiled glossaries created by
means of collaborative efforts, such as Wikipedia.1
The coverage issue is addressed by online aggrega-
tion services such as Google Define, which bring to-
gether definitions from several online dictionaries.
However, these services do not classify textual def-
initions by domain: they just present the collected
definitions for all the possible meanings of a given
term.
In order to automatically obtain large domain
glossaries, in recent years computational approaches
have been developed which extract textual defi-
nitions from corpora (Navigli and Velardi, 2010;
Reiplinger et al., 2012) or the Web (Velardi et al.,
2008; Fujii and Ishikawa, 2000). The methods in-
volving corpora start from a given set of terms (pos-
sibly automatically extracted from a domain cor-
pus) and then harvest textual definitions for these
terms from the input corpus using a supervised sys-
tem. Web-based methods, instead, extract text snip-
pets from Web pages which match pre-defined lex-
ical patterns, such as “X is a Y”, along the lines
of Hearst (1992). These approaches typically per-
form with high precision and low recall, because
they fall short of detecting the high variability of the
syntactic structure of textual definitions. To address
the low-recall issue, recurring cue terms occurring
</bodyText>
<footnote confidence="0.977404">
1See http://en.wikipedia.org/wiki/Portal:
Contents/Glossaries
</footnote>
<page confidence="0.895319">
170
</page>
<note confidence="0.738689">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 170–181,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.99377665625">
within dictionary and encyclopedic resources can be
automatically extracted and incorporated into lexical
patterns (Saggion, 2004). However, this approach is
term-specific and does not scale to arbitrary termi-
nologies and domains.
The goal of the new approach outlined in this pa-
per is to enable the automatic harvesting of large-
scale, full-fledged domain glossaries for dozens of
domains, an outcome which should be very use-
ful for both human activities and automatic tasks.
We present ProToDoG (Probabilistic Topics for
multi-Domain Glossaries), a framework for growing
multi-domain glossaries which has three main nov-
elties:
i) minimal human supervision: a small set of
hypernymy relation seeds for each domain is
used to bootstrap the multi-domain acquisition
process;
ii) jointness: our approach harvests terms and
glosses at the same time;
iii) probabilistic topic models are leveraged for
a simultaneous, high-precision multi-domain
classification of the extracted definitions, with
substantial performance improvements over
our previous work on glossary bootstrapping,
i.e., GlossBoot (De Benedictis et al., 2013).
ProToDog is able to harvest definitions from the
Web and thus drop the requirement of large corpora
for each domain. Moreover, apart from the need to
select a few seeds, it avoids the use of training data
or manually defined sets of lexical patterns. It is thus
applicable to virtually any language of interest.
</bodyText>
<sectionHeader confidence="0.998657" genericHeader="introduction">
2 ProToDoG
</sectionHeader>
<bodyText confidence="0.9867084">
Given a set of domains D = {di, ..., d�}, for each
domain d E D ProToDoG harvests a domain glos-
sary Gd containing pairs of the kind (t, g) where t
is a domain term and g is its textual definition, i.e.,
gloss. We show the pseudocode of ProToDoG in Al-
gorithm 1.
Step 1. Initial seed selection: Algorithm 1 takes
as input a set of domains D and, for each domain
d E D, a small set of hypernymy relation seeds
Sd = {(ti, hi), ... , (t|Sd|, h|Sd|)}, where the seed
</bodyText>
<figure confidence="0.911219833333333">
Algorithm 1 ProToDoG
Input: the set of domains D,
a set Sd of hypernymy seeds for each domain
dED
Output: a multi-domain glossary G
1: k +— 1
</figure>
<listItem confidence="0.746963833333333">
2: repeat
3: for each domain d E D do
4: Gkd 0
5: for each seed (tj, hj) E Sd do
6: pages +— webSearch(tj, hj, “glossary”)
7: Gkd +— Gkd U extractGlossary(pages)
8: end for
9: end for
10: create a topic model using glossaries from previ-
ous iterations
11: infer topic assignments for iteration-k glosses
12: filter out non-domain glosses for each domain
13: for each d E D do
14: Sd +— seedSelectionForNextIteration(Gkd)
15: end for
16: k +— k + 1
17: until k &gt; max
18: for each domain d E D do
19: recover filtered glosses into Gmax+1
d
Gd +_II 7
20: G j=1,...,max+1 Cd
21: end for
22: return G = {(Gd, d) : d E D}
</listItem>
<bodyText confidence="0.999033476190476">
pair (tj, hj) contains a term tj and its generalization
hj (e.g., (linux, operating system)). This is the only
human input to the entire glossary acquisition pro-
cess. The selection of the input seeds plays a key
role in the bootstrapping process, in that the pattern
and gloss extraction process will be driven by them.
The chosen hypernymy relations thus have to be as
topical and representative as possible for the domain
of interest (e.g., (compiler, computer program) is an
appropriate pair for computer science, while (byte,
unit of measurement) is not, as it might cause the
extraction of out-of-domain glossaries of units and
measures).
The algorithm first sets the iteration counter k to
1 (line 1) and starts the first iteration of the glos-
sary bootstrapping process (lines 2-17), each involv-
ing steps 2-4, described below. After each iteration
k, for each domain d we keep track of the set of
glosses Gd acquired during that iteration. After the
last iteration, we perform step (5) of gloss recovery
(lines 18-21).
</bodyText>
<page confidence="0.997077">
171
</page>
<bodyText confidence="0.9902532">
Step 2. Web search and glossary extraction (lines
3-9): For each domain d, we first initialize the do-
main glossary for iteration k: Gkd := 0 (line 4).
Then, for each seed pair (tj, hj) E 5d, we submit
the following query to a Web search engine: “tj”
“hj” glossary and collect the top-ranking results
for each query (line 6).2 Each resulting page is a
candidate glossary for the domain d.
We then call the extractGlossary function (line
7) which extracts terms and glosses from the re-
trieved pages as follows. From each candidate page,
we harvest all the text snippets s starting with tj and
ending with hj (e.g., “linux&lt;/b&gt; – an &lt;i&gt;operating
system”), i.e., s = tj ... hj. For each such text snip-
pet s, we extract the following pattern instance:
</bodyText>
<equation confidence="0.901187">
pL tj pM glosss(tj) pR,
</equation>
<bodyText confidence="0.566019">
where:
</bodyText>
<listItem confidence="0.923523076923077">
• pM is the longest sequence of HTML tags and
non-alphanumeric characters between tj and
the glossary definition (e.g., “&lt;/b&gt; –” between
“linux” and “an” in the above example);
• glosss(tj) is the gloss of tj obtained by mov-
ing to the right of pM until we reach a non-
formatting tag element (e.g., &lt;span&gt;, &lt;p&gt;,
&lt;div&gt;), while ignoring formatting elements
such as &lt;b&gt;, &lt;i&gt; and &lt;a&gt; which are typi-
cally included within a definition sentence;
• pL and pR are the longest sequences of HTML
tags on the left of tj and the right of glosss(tj),
respectively.
</listItem>
<bodyText confidence="0.989971444444445">
For instance, given the HTML snippet
“... &lt;p&gt;&lt;b&gt;linux&lt;/b&gt; – an &lt;i&gt;operating
system&lt;/i&gt; developed by Linus Torvalds&lt;/p&gt;...”
we extract the following pattern instance: pL =
“&lt;p&gt;&lt;b&gt;”, tj = “linux”, pM = “&lt;/b&gt; –”,
glosss(tj) = “an &lt;i&gt;operating system&lt;/i&gt;
developed by Linus Torvalds”, pR =“&lt;/p&gt;”.
Then we generalize the above pattern instance by
replacing tj and glosss(tj) with *, obtaining:
</bodyText>
<equation confidence="0.983162">
pL * pM * pR,
</equation>
<bodyText confidence="0.992785">
For the above example, we obtain the following
pattern:
</bodyText>
<footnote confidence="0.9039985">
2We use the Google Ajax API, which returns the 64 top-
ranking search results.
</footnote>
<equation confidence="0.574318">
&lt;p&gt;&lt;b&gt; * &lt;/b&gt; – * &lt;/p&gt;.
</equation>
<bodyText confidence="0.9980815">
We add the first sentence of the retrieved gloss
glosss(tj) to our glossary Gkd, i.e., Gkd := Gkd U
{(tj, first(glosss(tj)))}, where first(g) returns
the first sentence of gloss g. Finally, we look for ad-
ditional pairs of terms/glosses in the Web page con-
taining the snippet s by matching the page against
the generalized pattern pL * pM * pR, and adding
them to Gkd.
As a result of step (2), for each domain d E D
we obtain a glossary Gkd for the terms discovered at
iteration k.
Step 3. Topic modeling and gloss filtering (lines
10-12): Unfortunately, not all (term, gloss) pairs
in a glossary Gkd will pertain to the domain d. For in-
stance, we might end up retrieving interdisciplinary
or even unrelated glossaries. In order to address this
fuzziness, we model domains with a Probabilistic
Topic Model (PTM) (Blei et al., 2003; Steyvers and
Griffiths, 2007). PTMs model a given text document
as a mixture of topics. In our case topics are do-
mains and we, first, create a topic model from the
domain glossaries acquired before the current iter-
ation k, then, second, use the topic model to esti-
mate the domain assignment of each new pair (term,
gloss) in our glossaries Gkd, i.e., obtained at iteration
k, third, filter out non-domain glosses.
Creating the topic model (line 10): For a given
iteration k and domain d, we first define the ter-
minology accumulated up until iteration k − 1 for
that domain as the set Td,k−1 := U� −1 Td, where
Tdj is the set of terms acquired at iteration j, i.e.,
Tdj := {t : 1(t, g) E Gjd}.3 Then we define:
</bodyText>
<listItem confidence="0.928621555555555">
• W := Ud∈D T 1,k−1 as the entire terminology
d
acquired up until iteration k−1 for all domains,
i.e., the full set of terms independently of their
domain;
• M:= Ud∈D Uj=1 d k−1 G&apos; as the multi-domain
glossary acquired up until iteration k − 1, i.e.,
the full set of pairs (term, gloss) independently
of their domain;4
</listItem>
<equation confidence="0.4708642">
3For the first iteration, i.e., when k = 1, we define T 1,0
d :=
{t : 3(t, g) E Gd}, i.e., we use the terminology resulting from
step (2) of the first iteration.
4For k = 1, M := UdED Gd.
</equation>
<page confidence="0.980925">
172
</page>
<listItem confidence="0.668060666666667">
• Two count matrices, i.e., the word-domain ma-
trix CWD and the gloss-domain matrix CMD,
such that: CW D
</listItem>
<bodyText confidence="0.990082">
w,d counts the number of times
w E W is assigned to domain d E D, i.e., it oc-
curs in the glosses of domain d; CMD
(t,g),d counts
the number of words in g assigned to domain d.
At this point, as shown by Steyvers and Grif-
fiths (2007), we can estimate the probability φ(d)
w for
word w, and the probability θ(t,g) dfor a term/gloss
pair (t, g), of belonging to domain d:
</bodyText>
<equation confidence="0.9982986">
φ(d) = CWD
w,d + β
w
d E|d&apos; l 1 CMD
(t,g),d&apos; + |D|α
</equation>
<bodyText confidence="0.986770941176471">
where α and β are smoothing factors.5 The two
above probabilities represent the core of our topic
model of the domain knowledge acquired up until
iteration k − 1.
Probabilistic modeling of iteration-k glosses (line
11): We now utilize the above topic model to es-
timate the probabilities in Formulas 1 and 2 for the
newly acquired glosses at iteration k. To this end we
define M0 := Ud∈D Gkd as the union of the (term,
gloss) pairs at iteration k and W0 := Ud∈D Tk n W
d
as the union of terms acquired at iteration k, but also
occurring in W (i.e., the entire terminology up un-
til iteration k − 1). Then we apply Gibbs sampling
(Blei et al., 2003; Phan et al., 2008) to estimate the
probability of each pair (t, g) E M0 of pertaining to
a domain d by computing:
</bodyText>
<equation confidence="0.994596">
(3)
E|d0= |1 RM0D
(t,g),d0 + |D|α
</equation>
<bodyText confidence="0.948045222222222">
where the gloss-domain matrix RM0D is initially de-
fined by counting random domain assignments for
each word w0 in the bag of words of each (term,
gloss) pair E M0. Next, the domain assignment
counts in RM0D are iteratively updated using Gibbs
sampling.6
5As experienced by Steyvers and Griffiths (2007), the values
of α = 50/1D1 and ,Q = 0.01 work well with many different
text collections.
</bodyText>
<footnote confidence="0.590343">
6For the PTM part of ProToDoG we used the JGibbLDA
</footnote>
<bodyText confidence="0.982610666666667">
Filtering out non-domain glosses (line 12): Now,
for each domain d E D, for each pair (t, g) E Gkd we
have a probability θd of belonging to d. We mark
</bodyText>
<equation confidence="0.996409">
0(t,g)
(t, g) as a non-domain item if θd &lt; δ, where δ is
0(t,g)
</equation>
<bodyText confidence="0.988484675">
a confidence threshold, or if θ0(t,g) dis not maximum
among all domains in D. Non-domain pairs are re-
moved from Gkd and stored into a set Ad for possible
recovery after the last iteration (see step (5)).
Step 4. Seed selection for next iteration (lines
13-15): For each domain d E D, we now select
the new set of hypernymy relation seeds to be used
to start the next iteration. First, for each newly-
acquired term/gloss pair (t, g) E Gkd, we automat-
ically extract a candidate hypernym h from the tex-
tual gloss g. To do this we use a simple heuristic
which just selects the first content term in the gloss.7
Then we sort all the glosses in Gkd by the number of
seed terms found in each gloss. In the case of ties
(i.e., glosses with the same number of seed terms),
we further sort the glosses by θ0(t,g)
d . Finally we se-
lect the (term, hypernym) pairs corresponding to the
|Sd |top-ranking glosses as the new set of seeds for
the next iteration.
Next, we increment k (line 16 of Algorithm 1)
and if the maximum number of iterations is reached
we jump to step (5). Otherwise, we go back to step
(2) of our glossary bootstrapping algorithm with the
new set of seeds Sd.
Step 5. Gloss recovery (line 19): After all iter-
ations, the entire multi-domain terminology W (cf.
step (3)) may contain several new terms which were
not present when a given gloss g was filtered out.
So, thanks to the last-iteration topic model, the gloss
g might come back into play because its words are
now important cues for a domain. To reassess the
domain pertinence of (term, gloss) pairs in Ad for
each d, we just reapply the entire step (3) by setting
Gmax+1 := Ad for each d E D. As a result, we
d
library, a Java Implementation of Latent Dirichlet Allocation
(LDA) using Gibbs Sampling for Parameter Estimation and In-
ference, available at: http://jgibblda.sourceforge.
net/
</bodyText>
<footnote confidence="0.7441896">
7While more complex strategies could be devised, e.g.,
lattice-based hypernym extraction (Navigli and Velardi, 2010),
we found that this heuristic works well because, even when it is
not a hypernym, the first term acts as a cue word for the defined
term.
</footnote>
<equation confidence="0.998689666666667">
E|W �w&apos;= 1 Cw D + |W|β (1)
MD
θ(t,g) = C(t,g),d + α 2
θ0(t,g) d=
M0D
R(t,g),d + α
</equation>
<page confidence="0.988906">
173
</page>
<bodyText confidence="0.9787645">
obtain an updated glossary Gmax+1 which contains
d
all the recovered glosses.
Final output: For each domain d E D the final
output of ProToDoG is a domain glossary Gd :=
Uj_1,...,max+1 Gjd. Finally the algorithm aggregates
all glossaries Gd into a multi-domain glossary G
(line 22).
</bodyText>
<sectionHeader confidence="0.998321" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.986337">
3.1 Domains
</subsectionHeader>
<bodyText confidence="0.9998374">
For our experiments we selected 30 different do-
mains ranging from Arts to Warfare, mostly follow-
ing the domain classification of Wikipedia featured
articles (full list at http://lcl.uniroma1.
it/protodog). The set includes several techni-
cal domains, such as Chemistry, Geology, Meteorol-
ogy, Mathematics, some of which are highly inter-
disciplinary. For instance, the Environment domain
covers terms from fields such as Chemistry, Biology,
Law, Politics, etc.
</bodyText>
<subsectionHeader confidence="0.999602">
3.2 Gold Standard
</subsectionHeader>
<bodyText confidence="0.999869333333333">
Since our evaluations required considerable human
effort, in what follows we calculated all perfor-
mances on a random set of 10 domains, shown in the
top row of Table 1. For each of these 10 domains we
selected well-reputed glossaries on the Web as gold
standards, including the Reuters glossary of finance,
the Utah computing glossary and many others (full
list at the above URL). We show the size of our 10
gold-standard datasets in Table 1.
</bodyText>
<subsectionHeader confidence="0.9976">
3.3 Evaluation measures
</subsectionHeader>
<bodyText confidence="0.999997">
We evaluated the quality of both terms and glosses,
as jointly extracted by ProToDoG.
</bodyText>
<sectionHeader confidence="0.648132" genericHeader="method">
3.3.1 Terms
</sectionHeader>
<bodyText confidence="0.999908888888889">
For each domain we calculated coverage, extra-
coverage and precision of the acquired terms T.
Coverage is the ratio of extracted terms in T also
contained in the gold standard Tˆ over the size of Tˆ.
Extra-coverage is calculated as the ratio of the ad-
ditional extracted terms in T \ Tˆ over the number of
gold standard terms Tˆ. Finally, precision is the ra-
tio of extracted terms in T deemed to be within the
domain. To calculate precision we randomly sam-
pled 5% of the retrieved terms and asked two human
annotators to manually tag their domain pertinence
(with adjudication in case of disagreement; κ = .62,
indicating substantial agreement). Note that by ran-
domly sampling on the entire set T we calculate the
precision of both terms in T n Tˆ, i.e., in the gold
standard, and terms in T \ Tˆ, i.e., not in the gold
standard, but which are not necessarily outside the
domain.
</bodyText>
<subsectionHeader confidence="0.707711">
3.3.2 Glosses
</subsectionHeader>
<bodyText confidence="0.9999419">
We calculated the precision of the extracted
glosses as the ratio of glosses which were both well-
formed textual definitions and specific to the tar-
get domain. Precision was determined on a random
sample of 5% of the acquired glosses for each do-
main. The annotation was made by two annotators,
with κ = .675, indicating substantial agreement.
The annotators were provided with specific guide-
lines available on the ProToDoG Web site (see URL
above).
</bodyText>
<subsectionHeader confidence="0.95417">
3.4 Comparison
</subsectionHeader>
<bodyText confidence="0.996829">
We compared ProToDog against:
</bodyText>
<listItem confidence="0.9620285">
• BoW: a bag-of-words variant in which step
(3) is replaced by a simple bag-of-words scor-
ing approach which assigns a score to each
term/gloss pair (t, g) E Gkd as follows:
</listItem>
<equation confidence="0.9898755">
Bag(n T , −1
score(g) =   ||B) g(g) I I .(4)
</equation>
<bodyText confidence="0.997354142857143">
where Bag(g) contains all content words in
g. At iteration k, we filter out those glosses
whose score(g) &lt; σ, where σ is a thresh-
old tuned in the same manner as δ (see Sec-
tion 3.5). This approach essentially implements
GlossBoot, our previous work on domain glos-
sary bootstrapping (De Benedictis et al., 2013).
</bodyText>
<listItem confidence="0.975025428571429">
• Wikipedia: since Wikipedia is the largest
collaborative resource, covering hundreds
of fields of knowledge, we devised a simple
heuristic for producing multi-domain glos-
saries from Wikipedia, so as to compare their
performance against our gold standards. For
each target domain we manually selected one
</listItem>
<page confidence="0.976828">
174
</page>
<figure confidence="0.8953585">
2 4 6 8 10 12 14 16 18 20
iteration
</figure>
<figureCaption confidence="0.956207">
Figure 1: Harmonic mean of precision and coverage for
Botany and Fashion (tuning domains) over 20 iterations
(|Sd|=5, 6=0.03).
</figureCaption>
<bodyText confidence="0.999755588235294">
or more Wikipedia categories representing
the domain (for instance, Category:Arts
for Arts, Category:Business for Fi-
nance, etc.). Then, for each domain d,
we picked out all the Wikipedia pages
tagged either with the categories selected
for d or their direct subcategories (e.g.,
Category:Creative works) or sub-
subcategories (e.g., Category:Genres).
From each page we extracted a (page title,
gloss) pair, where the gloss was obtained by
extracting the first sentence of the Wikipedia
page, as done, e.g., in BabelNet (Navigli and
Ponzetto, 2012). Since subcategories might
have more parents and might thus belong to
multiple domains, we discarded pages assigned
to more than 2 domains.
</bodyText>
<subsectionHeader confidence="0.932411">
3.5 Parameter tuning
</subsectionHeader>
<bodyText confidence="0.999195325">
In order to choose the optimal values of the parame-
ters of ProToDoG (number |Sd |of seeds per domain,
number max of iterations, and filtering threshold 6)
and BoW (Q threshold) we selected two extra do-
mains, i.e., Botany and Fashion, not used in our
tests, together with the corresponding gold standard
Web glossaries.
As regards the number of seeds, we defined an
initial pool of 10 seeds for each of the two tun-
ing domains and studied the average performance
of 5 random sets of x seeds (from the initial pool),
when x = 1, 3, 5, 7, 9. As regards the number of
iterations, we explored all values between 1 and
20. Finally, for the filtering thresholds 6 and Q
for ProToDoG PTM and its BoW variant, we tried
values of 6 E 10, 0.03, 0.06, ... , 0.6} and Q E
10, 0.05, 0.1, ... ,1.0}, respectively.
Given the high number of possible parameter
value configurations, we first explored the entire
search space automatically by calculating the cov-
erage of ProToDoG PTM (and BoW) with each con-
figuration against our tuning gold standards. Then
we identified as optimal candidates those “fron-
tier” configurations for which, when moving from
a lower-coverage configuration, coverage reached a
maximum. We then calculated the precision of each
optimal candidate configuration by manually vali-
dating a 3% random sample of the resulting glos-
saries for the two tuning domains. The optimal con-
figuration for ProToDoG was |Sd |= 5, max = 5,
6 = 0.03, while for BoW was Q = 0.1.
In Figure 1 we show the performance trend over
iterations for our two tuning domains when |Sd |= 5
and 6 = 0.03. Performance is calculated as the
harmonic mean of precision and coverage of the ac-
quired glossary after each iteration, from 1 to 20. We
can see that after 5 iterations performance decreases
for Botany (a highly interdisciplinary domain) due
to lower precision, while it remains stable for Fash-
ion due to the lack of newly-acquired glosses.
</bodyText>
<subsectionHeader confidence="0.992774">
3.6 Seed Selection
</subsectionHeader>
<bodyText confidence="0.999874428571428">
For each domain d we manually selected five seed
hypernymy relations as the seed sets Sd input to Al-
gorithm 1 (see Section 3.5). The seeds were selected
by the authors on the basis of just two conditions: i)
the seeds should cover different aspects of the do-
main and, indeed, should identify the domain im-
plicitly; ii) at least 10,000 results should be returned
by the search engine when querying it with the seeds
plus the glossary keyword (see line 6 of Algo-
rithm 1). The seed selection was not fine-tuned (i.e.,
it was not adjusted to improve performance), so it
might well be that better seeds would provide better
results (see (Kozareva and Hovy, 2010a)). However,
such a study is beyond the scope of this paper.
</bodyText>
<figure confidence="0.996811181818182">
Botany
Fashion
85%
80%
75%
70%
65%
60%
55%
50%
45%
</figure>
<page confidence="0.992099">
175
</page>
<table confidence="0.999090142857143">
Art Business Chemistry Computing Environment Food Law Music Physics Sport
Gold t/g 394 1777 164 421 713 946 180 218 315 146
PTM t 4253 7370 2493 3412 3009 1526 1836 1647 3847 1696
g 7386 9795 3841 4186 3552 2175 4141 2729 5197 2938
BoW t 4012 7639 1174 3127 3644 1827 1773 1166 4471 1990
g 5923 8999 1414 3662 4334 2601 4024 1249 6956 3425
Wiki t,g 107.1k 48.4k 8137 32.0k 23.6k 5698 13.5k 84.1k 33.8k 267.5k
</table>
<tableCaption confidence="0.984573">
Table 1: Size of the gold standard and the automatically-acquired glossaries for 10 of the 30 selected domains (t:
number of terms, g: number of glosses).
</tableCaption>
<sectionHeader confidence="0.999623" genericHeader="method">
4 Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.653869">
4.1 Terms
</subsectionHeader>
<bodyText confidence="0.99997312244898">
The size of the extracted terminologies for the 10 do-
mains after five iterations is reported in Table 1 (the
output for all 30 domains is available at the above
URL, cf. Section 3.1). ProToDoG PTM and its BoW
variant extract thousands of terms and glosses for
each domain, whereas the number of glosses ob-
tained from Wikipedia (cf. Section 3.4) varies de-
pending upon the domain, from thousands to hun-
dreds of thousands. Note that there is no overlap
between the glossaries extracted by ProToDoG and
the set of Wikipedia articles, since the latter are not
organized as glossaries.
In Table 2 we show the percentage results in
terms of precision (P), coverage (C), and extra-
coverage (X, see Section 3.3 for definitions) for
ProToDoG PTM and its BoW variant and for the
Wikipedia glossary. With the exception of the
Food domain, ProToDoG achieves the best pre-
cision. The Wikipedia glossary has fluctuating
precision values, ranging between 25% and 90%,
due to the heterogeneous nature of subcategories.
ProToDog achieves the best coverage of gold stan-
dard terms on 6 of the 10 domains, with the BoW
variant obtaining slightly higher coverage on 3 do-
mains and +10% on the Food domain. The cov-
erage of Wikipedia glossaries, instead, with the
sole exception of Sport, is much lower, despite the
use of (sub)subcategories (cf. Section 3.4). Both
ProToDoG PTM and BoW achieve very high extra-
coverage percentages, meaning that they are able to
go substantially beyond our domain gold standards,
but it is the Wikipedia glossary which achieves the
highest extra-coverage values. To get a better in-
sight into the quality of extra-coverage we calcu-
lated the percentage of named entities (i.e., encyclo-
pedic) among the terms extracted by each of the dif-
ferent approaches. Comparing results across the (E)
columns of Table 2 it can be seen that high percent-
ages of the terms extracted by Wikipedia are named
entities, which is in marked contrast to the 0%-1%
extracted by ProToDog. This is as should be ex-
pected for an encyclopedia, whose coverage focuses
on people, places, brands, etc. rather than concepts.
To summarize, ProToDoG PTM outperforms both
BoW and Wikipedia in terms of precision, while
at the same time achieving both competitive cov-
erage and extra-coverage. The Wikipedia glossary
suffers from fluctuating precision values across do-
mains and overly encyclopedic coverage of terms.
</bodyText>
<subsectionHeader confidence="0.960162">
4.2 Glosses
</subsectionHeader>
<bodyText confidence="0.999951583333333">
We show the results of gloss evaluation in Table 2
(last two columns) for ProToDoG PTM and BoW
(we do not report the precision values for Wikipedia,
as they are slightly lower than those obtained for
terms). Precision ranges between 89% and 99%
for ProToDoG PTM and between 82% and 97%
for BoW. We observe that these results are strongly
correlated with the precision of the extracted terms
(cf. Table 2), because the retrieved glosses of do-
main terms are usually in-domain too, and follow a
definitional style since they come from glossaries.
Note, however, that the gloss precision could also be
</bodyText>
<page confidence="0.9952">
176
</page>
<table confidence="0.999438153846154">
terms glosses
PTM BoW Wiki PTM BoW
P C X E P C X E P C X E P P
Art 92 26 1053 1 86 25 992 0 81 19 23.4k 67 93 87
Business 95 41 374 0 90 43 387 0 37 15 2692 31 96 91
Chemistry 99 77 1410 0 95 73 643 0 49 18 12.9k 3 98 96
Computing 95 43 767 0 93 40 702 0 81 30 7506 36 96 94
Environment 91 29 393 0 84 28 482 0 25 9 3302 12 89 82
Food 91 21 1404 0 97 31 1621 0 81 9 3997 25 92 95
Law 98 89 931 0 95 87 897 0 35 34 7406 16 99 97
Music 94 98 660 0 93 84 453 0 90 50 37.1k 84 96 95
Physics 97 43 1178 0 91 46 1373 0 68 25 10.6k 10 95 89
Sport 98 22 1139 1 96 23 1339 1 87 44 178.2k 83 97 96
</table>
<tableCaption confidence="0.993747">
Table 2: Precision (P), coverage (C), extra-coverage (X), encyclopedic (E) percentages after 5 iterations.
</tableCaption>
<table confidence="0.999650666666667">
Art Business Chemistry Computing Environment Food Law Music Physics Sport
Google Define 76 80 93 86 88 91 96 96 98 84
ProToDoG 27 41 81 40 37 19 85 98 47 27
</table>
<tableCaption confidence="0.850818">
Table 3: Number of domain glosses (from a random sam-
ple of 100 gold standard terms per domain) retrieved us-
ing Google Define and ProToDoG.
</tableCaption>
<bodyText confidence="0.9985435">
higher than term precision, thanks to many pertinent
glosses being extracted for the same term (cf. Table
1).
In Table 4 we show an excerpt of the multi-
domain glossary extracted by ProToDoG for the Art,
Business and Sport domains.
</bodyText>
<sectionHeader confidence="0.997892" genericHeader="method">
5 Comparative Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999939">
5.1 Comparison with Google Define
</subsectionHeader>
<bodyText confidence="0.999977875">
We performed a comparison with Google Define,8
a state-of-the-art definition search service. This
service inputs a term query and outputs a list of
glosses. First, we randomly sampled 100 terms
from our gold standard for each domain. Next, for
each domain, we manually calculated the fraction
of terms for which at least one in-domain defini-
tion was provided by Google Define and ProToDoG.
</bodyText>
<footnote confidence="0.8729355">
8Accessible from Google search with the define: key-
word.
</footnote>
<bodyText confidence="0.999645">
Table 3 shows the coverage results. In this exper-
iment, Google Define outperforms our system on
9 of the 10 analyzed domains. However, we note
that when searching for domain-specific knowledge
only, Google Define: i) needs to know the domain
term to be defined in advance, while ProToDoG
jointly acquires domain terms and glosses starting
from just a few seeds; ii) does not discriminate be-
tween glosses pertaining to the target domain and
glosses pertaining to other fields or senses, whereas
ProToDog extracts terms and glosses specific to each
domain of interest.
</bodyText>
<subsectionHeader confidence="0.999893">
5.2 Comparison with TaxoLearn
</subsectionHeader>
<bodyText confidence="0.999975933333333">
We also compared ProToDoG with the output of
a state-of-the-art taxonomy learning framework,
called TaxoLearn (Navigli et al., 2011). We did
this because i) TaxoLearn extracts terms and glosses
from domain corpora in order to create a domain tax-
onomy; ii) it is one of the few systems which extracts
both terms and glosses from specialized corpora; iii)
the extracted glossaries are available online.9 There-
fore we compared the performance of ProToDoG on
two domains for which glossaries were extracted by
TaxoLearn, i.e. AI and Finance. The glossaries were
harvested from large collections of scholarly arti-
cles. For ProToDoG we selected 10 seeds to cover
all the fields of AI, while for the financial domain
we selected the same 5 seeds used in the Business
</bodyText>
<footnote confidence="0.998834">
9http://ontolearn.org and http://lcl.
uniroma1.it/taxolearn
</footnote>
<page confidence="0.982173">
177
</page>
<table confidence="0.982020789473684">
Art
rock art includes pictographs (designs painted on stone surfaces) and petroglyphs (designs
pecked or incised on stone surfaces).
impressionism Late 19th-century French school dedicated to defining transitory visual impressions
painted directly from nature, with light and color of primary importance.
point Regarding paper, a unit of thickness equating 1/1000 inch.
Business
hyperinflation Extremely rapid or out of control inflation.
interbank rate The rate of interest charged by a bank on a loan to another bank.
points Amount of discount on a mortgage loan stated as a percentage; one point equals one
percent of the face amount of the loan; a discount of one point raises the net yield on
the loan by one-eighth of one percent.
Sport
gross score The actual number of strokes taken by a player for hole or round before the player’s
handicap is deducted.
obstructing preventing the opponent from going around a player by standing in the path of move-
ment.
points a team statistic indicating its degree of success, calculated as follows: 2 points for a
win (3 in the 1994 World Cup), 1 point for a tie, 0 points for a loss.
</table>
<tableCaption confidence="0.999799">
Table 4: An excerpt of the resulting multi-domain glossary obtained with ProToDoG.
</tableCaption>
<bodyText confidence="0.9997732">
domain of our experiments above (cf. Section 3).
We show the number of extracted terms and
glosses for ProToDoG and TaxoLearn in Table 5.
We also show the precision values calculated on a
random sample of 5% of terms and glosses. As can
be clearly seen, on both domains ProToDoG extracts
a number of terms and glosses which is an order
of magnitude greater than those obtained by Tax-
oLearn, while at the same time obtaining consider-
ably higher precision.
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999940342105263">
Current approaches to automatic glossary acquisi-
tion suffer from two main issues: i) the poor avail-
ability of large domain-specific corpora from which
terms and glosses are extracted at different times;
ii) the focus on individual domains. ProToDog ad-
dresses both issues by providing a joint multi-
domain approach to term and glossary extraction.
Among the approaches which extract unre-
stricted textual definitions from open text, Fujii and
Ishikawa (2000) determine the definitional nature of
text fragments by using an n-gram model, whereas
Klavans and Muresan (2001) apply pattern match-
ing techniques at the lexical level guided by cue
phrases such as “is called” and “is defined as”.
More recently, a domain-independent supervised ap-
proach, named Word-Class Lattices (WCLs), was
presented which learns lattice-based definition clas-
sifiers applied to candidate sentences containing the
input terms (Navigli and Velardi, 2010). To avoid
the burden of manually creating a training dataset,
definitional patterns can be extracted automatically.
Faralli and Navigli (2013) utilized Wikipedia as
a huge source of definitions and simple, yet ef-
fective heuristics to automatically annotate them.
Reiplinger et al. (2012) experimented with two dif-
ferent approaches for the acquisition of lexical-
syntactic patterns. The first approach bootstraps pat-
terns from a domain corpus and then manually re-
fines the acquired patterns. The second approach, in-
stead, automatically acquires definitional sentences
by using a more sophisticated syntactic and seman-
tic processing. The results show high precision
in both cases. However, all the above approaches
need large domain corpora, the poor availability of
which hampers the creation of wide-coverage glos-
saries for several domains. To avoid the need to
use a large corpus, domain terminologies can be ob-
tained by using Doubly-Anchored Patterns (DAPs)
</bodyText>
<page confidence="0.991482">
178
</page>
<table confidence="0.99841925">
AI Finance
# terms P # glosses P # terms P # glosses P
ProToDoG 4983 83% 5326 84% 7370 95% 9795 96%
TaxoLearn 427 77% 834 79% 2348 86% 1064 88%
</table>
<tableCaption confidence="0.9346535">
Table 5: Number and precision of terms and glosses extracted by ProToDoG and TaxoLearn in the Artificial Intelli-
gence (AI) and Finance domains.
</tableCaption>
<bodyText confidence="0.999975533333334">
which, given a (term, hypernym) pair, extract from
the Web sentences matching manually-defined pat-
terns like “&lt;hypernym&gt; such as &lt;term&gt;, and *”
(Kozareva and Hovy, 2010b). This term extrac-
tion process is further extended by harvesting new
hypernyms using the corresponding inverse pat-
terns (called DAP−1) like “* such as &lt;term1&gt;, and
&lt;term2&gt;”. Similarly to ProToDoG, this approach
drops the requirement of a domain corpus and starts
from a small number of (term, hypernym) seeds.
However, while DAPs have proven useful in the in-
duction of domain taxonomies (Kozareva and Hovy,
2010b), they cannot be applied to the glossary learn-
ing task because the extracted sentences are not for-
mal definitions. In contrast, ProToDoG performs
the novel task of multi-domain glossary acquisition
from the Web by bootstrapping the extraction pro-
cess with a few (term, hypernym) seeds. Bootstrap-
ping techniques (Brin, 1998; Agichtein and Gra-
vano, 2000; Pas¸ca et al., 2006) have been success-
fully applied to several tasks, including learning se-
mantic relations (Pantel and Pennacchiotti, 2006),
extracting surface text patterns for open-domain
question answering (Ravichandran and Hovy, 2002),
semantic tagging (Huang and Riloff, 2010) and un-
supervised Word Sense Disambiguation (Yarowsky,
1995). ProToDoG synergistically integrates boot-
strapping with probabilistic topic models so as to
keep the glossary acquisition process within the tar-
get domains as much as possible.
</bodyText>
<sectionHeader confidence="0.99951" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999660875">
In this paper we have presented ProToDoG, a new,
minimally-supervised approach to multi-domain
glossary acquisition. Starting from a small set of hy-
pernymy seeds which identify each domain of inter-
est, we apply a bootstrapping approach which itera-
tively obtains generalized patterns from Web glos-
saries and then applies them to the extraction of
term/gloss pairs. To our knowledge, ProToDoG is
the first approach to large-scale probabilistic glos-
sary learning which jointly acquires thousands of
terms and glosses for dozens of domains with mini-
mal supervision.
At the core of ProToDoG lies our glossary boot-
strapping approach, thanks to which we can drop
the requirements of existing techniques such as the
ready availability of domain corpora, which often do
not contain enough definitions (cf. Table 5), and the
manual definition of lexical patterns, which typically
extract sentence snippets instead of formal glosses.
ProToDoG will be made available to the re-
search community. Beyond the immediate usabil-
ity of the output glossaries (we show an excerpt
in Table 4), we also wish to show the benefit
of ProToDoG in gloss-driven approaches to taxon-
omy learning (Navigli et al., 2011; Velardi et al.,
2013) and Word Sense Disambiguation (Duan and
Yates, 2010; Faralli and Navigli, 2012). The 30-
domain glossaries and gold standards created for
our experiments are available from http://lcl.
uniroma1.it/protodog.
We remark that the terminologies covered with
ProToDoG are not only precise, but are also one
order of magnitude greater than those covered in
individual online glossaries. As future work, we
plan to study the ability of ProToDoG to acquire
domain glossaries at different levels of specificity
(i.e., domains vs. subdomains). Finally, we will
adapt ProToDoG to other languages, by translating
the glossary keyword used in step (2), along the
lines of (De Benedictis et al., 2013).
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999403666666667">
The authors gratefully acknowledge
the support of the “MultiJEDI” ERC
Starting Grant No. 259234.
</bodyText>
<page confidence="0.998345">
179
</page>
<sectionHeader confidence="0.995746" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998024580952381">
Eugene Agichtein and Luis Gravano. 2000. Snowball:
extracting relations from large plain-text collections.
In Proceedings of the 5th ACM conference on Digital
Libraries, pages 85–94, San Antonio, Texas, USA.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet Allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
Sergey Brin. 1998. Extracting patterns and relations
from the World Wide Web. In Proceedings of the
International Workshop on The World Wide Web and
Databases, pages 172–183, London, UK.
Hang Cui, Min-Yen Kan, and Tat-Seng Chua. 2007. Soft
pattern matching models for definitional question an-
swering. ACM Transactions on Information Systems,
25(2):8.
Flavio De Benedictis, Stefano Faralli, and Roberto Nav-
igli. 2013. GlossBoot: Bootstrapping Multilingual
Domain Glossaries from the Web. In Proceedings of
the 51st Annual Meeting of the Association for Compu-
tational Linguistics, pages 528–538, Sofia, Bulgaria.
Weisi Duan and Alexander Yates. 2010. Extracting
glosses to disambiguate word senses. In Proceedings
of Human Language Technologies: The 11th Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics, pages 627–
635, Los Angeles, CA, USA.
Stefano Faralli and Roberto Navigli. 2012. A New
Minimally-supervised Framework for Domain Word
Sense Disambiguation. In Proceedings of the 2012
Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Natural
Language Learning, pages 1411–1422, Jeju, Korea.
Stefano Faralli and Roberto Navigli. 2013. A Java
Framework for Multilingual Definition and Hypernym
Extraction. In Proceedings of the 51st Annual Meeting
of the Association for Computational Linguistics, Sys-
tem Demonstrations, pages 103–108, Sofia, Bulgaria.
Atsushi Fujii and Tetsuya Ishikawa. 2000. Utilizing
the World Wide Web as an encyclopedia: extracting
term descriptions from semi-structured texts. In Pro-
ceedings of the 38th Annual Meeting on Association
for Computational Linguistics, pages 488–495, Hong
Kong.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proceedings of
the 15th International Conference on Computational
Linguistics, pages 539–545, Nantes, France.
Eduard H. Hovy, Roberto Navigli, and Simone Paolo
Ponzetto. 2013. Collaboratively built semi-structured
content and Artificial Intelligence: The story so far.
Artificial Intelligence, 194:2–27.
Ruihong Huang and Ellen Riloff. 2010. Inducing
domain-specific semantic class taggers from (almost)
nothing. In Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, pages
275–285, Uppsala, Sweden.
Judith Klavans and Smaranda Muresan. 2001. Evalu-
ation of the DEFINDER system for fully automatic
glossary construction. In Proceedings of the American
Medical Informatics Association (AMIA) Symposium,
pages 324–328, Washington, D.C., USA.
Zornitsa Kozareva and Eduard H. Hovy. 2010a. Not all
seeds are equal: Measuring the quality of text min-
ing seeds. In Proceedings of Human Language Tech-
nologies: The 11th Annual Conference of the North
American Chapter of the Association for Computa-
tional Linguistics, pages 618–626, Los Angeles, Cali-
fornia, USA.
Zornitsa Kozareva and Eduard H. Hovy. 2010b. A semi-
supervised method to learn and construct taxonomies
using the web. In Proceedings of Empirical Methods
in Natural Language Processing, pages 1110–1118,
Cambridge, MA, USA.
Roberto Navigli and Simone Paolo Ponzetto. 2012. Ba-
belNet: The automatic construction, evaluation and
application of a wide-coverage multilingual semantic
network. Artificial Intelligence, 193:217–250.
Roberto Navigli and Paola Velardi. 2010. Learning
Word-Class Lattices for definition and hypernym ex-
traction. In Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, pages
1318–1327, Uppsala, Sweden.
Roberto Navigli, Paola Velardi, and Stefano Faralli.
2011. A graph-based algorithm for inducing lexi-
cal taxonomies from scratch. In Proceedings of the
22th International Joint Conference on Artificial Intel-
ligence, pages 1872–1877, Barcelona, Spain.
Marius Pas¸ca, Dekang Lin, Jeffrey Bigham, Andrei Lif-
chits, and Alpa Jain. 2006. Names and similarities on
the Web: Fact extraction in the fast lane. In Proceed-
ings of the 21st International Conference on Computa-
tional Linguistics and 44th Annual Meeting of the As-
sociation for Computational Linguistics, pages 809–
816, Sydney, Australia.
Patrick Pantel and Marco Pennacchiotti. 2006. Espresso:
Leveraging Generic Patterns for Automatically Har-
vesting Semantic Relations. In Proceedings of the
21st International Conference on Computational Lin-
guistics and 44th Annual Meeting of the Association
for Computational Linguistics (COLING-ACL), Syd-
ney, Australia, pages 113–120, Sydney, Australia.
Xuan-Hieu Phan, Le-Minh Nguyen, and Susumu
Horiguchi. 2008. Learning to classify short and sparse
text &amp; web with hidden topics from large-scale data
collections. In Proceedings of the 17th international
</reference>
<page confidence="0.973307">
180
</page>
<reference confidence="0.99955546875">
conference on World Wide Web, WWW ’08, pages 91–
100, New York, NY, USA.
Deepak Ravichandran and Eduard Hovy. 2002. Learn-
ing surface text patterns for a question answering sys-
tem. In Proceedings of the 40th Annual Meeting on
Association for Computational Linguistics, pages 41–
47, Philadelphia, PA, USA.
Melanie Reiplinger, Ulrich Sch¨afer, and Magdalena Wol-
ska. 2012. Extracting glossary sentences from schol-
arly articles: A comparative evaluation of pattern
bootstrapping and deep analysis. In Proceedings of
the ACL-2012 Special Workshop on Rediscovering 50
Years of Discoveries, pages 55–65, Jeju Island, Korea.
Horacio Saggion. 2004. Identifying definitions in text
collections for question answering. In Proceedings
of the Fourth International Conference on Language
Resources and Evaluation, pages 1927–1930, Lisbon,
Portugal.
Mark Steyvers and Tom Griffiths, 2007. Probabilistic
Topic Models. Lawrence Erlbaum Associates.
Paola Velardi, Roberto Navigli, and Pierluigi D’Amadio.
2008. Mining the web to create specialized glossaries.
IEEE Intelligent Systems, 23(5):18–25.
Paola Velardi, Stefano Faralli, and Roberto Navigli.
2013. OntoLearn Reloaded: A graph-based algorithm
for taxonomy induction. Computational Linguistics,
39(3):665–707.
David Yarowsky. 1995. Unsupervised Word Sense Dis-
ambiguation rivaling supervised methods. In Proceed-
ings of the 33Td Annual Meeting of the Association
for Computational Linguistics, pages 189–196, Cam-
bridge, MA, USA.
</reference>
<page confidence="0.998383">
181
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.443970">
<title confidence="0.897868666666667">Growing Multi-Domain Glossaries from a Few using Probabilistic Topic Models Faralli</title>
<author confidence="0.800043">Dipartimento di_Sapienza Universit`a di</author>
<abstract confidence="0.984771090909091">In this paper we present a minimallysupervised approach to the multi-domain acquisition of wide-coverage glossaries. We start from a small number of hypernymy relation seeds and bootstrap glossaries from the Web for dozens of domains using Probabilistic Topic Models. Our experiments show that we are able to extract high-precision glossaries comprising thousands of terms and definitions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Agichtein</author>
<author>Luis Gravano</author>
</authors>
<title>Snowball: extracting relations from large plain-text collections.</title>
<date>2000</date>
<booktitle>In Proceedings of the 5th ACM conference on Digital Libraries,</booktitle>
<pages>85--94</pages>
<location>San Antonio, Texas, USA.</location>
<contexts>
<context position="33999" citStr="Agichtein and Gravano, 2000" startWordPosition="5853" endWordPosition="5857">ke “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to ProToDoG, this approach drops the requirement of a domain corpus and starts from a small number of (term, hypernym) seeds. However, while DAPs have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010b), they cannot be applied to the glossary learning task because the extracted sentences are not formal definitions. In contrast, ProToDoG performs the novel task of multi-domain glossary acquisition from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). ProToDoG synergistically integrates bootstrapping with probabilistic topic models so as to keep the glossary acquisition process within the target domains as much as possible. 7 Conclusions In this paper we have presented ProToDoG, a new, minimally-super</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>Eugene Agichtein and Luis Gravano. 2000. Snowball: extracting relations from large plain-text collections. In Proceedings of the 5th ACM conference on Digital Libraries, pages 85–94, San Antonio, Texas, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="9907" citStr="Blei et al., 2003" startWordPosition="1640" endWordPosition="1643"> pairs of terms/glosses in the Web page containing the snippet s by matching the page against the generalized pattern pL * pM * pR, and adding them to Gkd. As a result of step (2), for each domain d E D we obtain a glossary Gkd for the terms discovered at iteration k. Step 3. Topic modeling and gloss filtering (lines 10-12): Unfortunately, not all (term, gloss) pairs in a glossary Gkd will pertain to the domain d. For instance, we might end up retrieving interdisciplinary or even unrelated glossaries. In order to address this fuzziness, we model domains with a Probabilistic Topic Model (PTM) (Blei et al., 2003; Steyvers and Griffiths, 2007). PTMs model a given text document as a mixture of topics. In our case topics are domains and we, first, create a topic model from the domain glossaries acquired before the current iteration k, then, second, use the topic model to estimate the domain assignment of each new pair (term, gloss) in our glossaries Gkd, i.e., obtained at iteration k, third, filter out non-domain glosses. Creating the topic model (line 10): For a given iteration k and domain d, we first define the terminology accumulated up until iteration k − 1 for that domain as the set Td,k−1 := U� −</context>
<context position="12300" citStr="Blei et al., 2003" startWordPosition="2107" endWordPosition="2110">factors.5 The two above probabilities represent the core of our topic model of the domain knowledge acquired up until iteration k − 1. Probabilistic modeling of iteration-k glosses (line 11): We now utilize the above topic model to estimate the probabilities in Formulas 1 and 2 for the newly acquired glosses at iteration k. To this end we define M0 := Ud∈D Gkd as the union of the (term, gloss) pairs at iteration k and W0 := Ud∈D Tk n W d as the union of terms acquired at iteration k, but also occurring in W (i.e., the entire terminology up until iteration k − 1). Then we apply Gibbs sampling (Blei et al., 2003; Phan et al., 2008) to estimate the probability of each pair (t, g) E M0 of pertaining to a domain d by computing: (3) E|d0= |1 RM0D (t,g),d0 + |D|α where the gloss-domain matrix RM0D is initially defined by counting random domain assignments for each word w0 in the bag of words of each (term, gloss) pair E M0. Next, the domain assignment counts in RM0D are iteratively updated using Gibbs sampling.6 5As experienced by Steyvers and Griffiths (2007), the values of α = 50/1D1 and ,Q = 0.01 work well with many different text collections. 6For the PTM part of ProToDoG we used the JGibbLDA Filterin</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
</authors>
<title>Extracting patterns and relations from the World Wide Web.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Workshop on The World Wide Web and Databases,</booktitle>
<pages>172--183</pages>
<location>London, UK.</location>
<contexts>
<context position="33970" citStr="Brin, 1998" startWordPosition="5851" endWordPosition="5852">ed DAP−1) like “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to ProToDoG, this approach drops the requirement of a domain corpus and starts from a small number of (term, hypernym) seeds. However, while DAPs have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010b), they cannot be applied to the glossary learning task because the extracted sentences are not formal definitions. In contrast, ProToDoG performs the novel task of multi-domain glossary acquisition from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). ProToDoG synergistically integrates bootstrapping with probabilistic topic models so as to keep the glossary acquisition process within the target domains as much as possible. 7 Conclusions In this paper we have presented Pro</context>
</contexts>
<marker>Brin, 1998</marker>
<rawString>Sergey Brin. 1998. Extracting patterns and relations from the World Wide Web. In Proceedings of the International Workshop on The World Wide Web and Databases, pages 172–183, London, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Cui</author>
<author>Min-Yen Kan</author>
<author>Tat-Seng Chua</author>
</authors>
<title>Soft pattern matching models for definitional question answering.</title>
<date>2007</date>
<journal>ACM Transactions on Information Systems,</journal>
<volume>25</volume>
<issue>2</issue>
<contexts>
<context position="1596" citStr="Cui et al., 2007" startWordPosition="240" endWordPosition="243"> definition search process. However, finding definitions is not always immediate, especially if the target term pertains to a specialized domain. Indeed, not even well-known services such as Google Define are able to provide definitions for scientific or technical terms such as taxonomy learning or distant supervision in AI or figure-four leglock and suspended surfboard in wrestling. Domain-specific knowledge of a definitional nature is not only useful for humans, it is also useful for machines (Hovy et al., 2013). Examples include Natural Language Processing tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Velardi et al., 2013). Unfortunately, most of the Web dictionaries and glossaries available online comprise just a few hundred definitions, and they therefore provide only a partial view of a domain. This is also the case with manually compiled glossaries created by means of collaborative efforts, such as Wikipedia.1 The coverage issue is addressed by online aggregation services such as Google Define, which bring together definitions from several online dictionaries. However, these services do </context>
</contexts>
<marker>Cui, Kan, Chua, 2007</marker>
<rawString>Hang Cui, Min-Yen Kan, and Tat-Seng Chua. 2007. Soft pattern matching models for definitional question answering. ACM Transactions on Information Systems, 25(2):8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Flavio De Benedictis</author>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>GlossBoot: Bootstrapping Multilingual Domain Glossaries from the Web.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>528--538</pages>
<location>Sofia, Bulgaria.</location>
<marker>De Benedictis, Faralli, Navigli, 2013</marker>
<rawString>Flavio De Benedictis, Stefano Faralli, and Roberto Navigli. 2013. GlossBoot: Bootstrapping Multilingual Domain Glossaries from the Web. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 528–538, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Weisi Duan</author>
<author>Alexander Yates</author>
</authors>
<title>Extracting glosses to disambiguate word senses.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>627--635</pages>
<location>Los Angeles, CA, USA.</location>
<contexts>
<context position="1645" citStr="Duan and Yates, 2010" startWordPosition="247" endWordPosition="250">efinitions is not always immediate, especially if the target term pertains to a specialized domain. Indeed, not even well-known services such as Google Define are able to provide definitions for scientific or technical terms such as taxonomy learning or distant supervision in AI or figure-four leglock and suspended surfboard in wrestling. Domain-specific knowledge of a definitional nature is not only useful for humans, it is also useful for machines (Hovy et al., 2013). Examples include Natural Language Processing tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Velardi et al., 2013). Unfortunately, most of the Web dictionaries and glossaries available online comprise just a few hundred definitions, and they therefore provide only a partial view of a domain. This is also the case with manually compiled glossaries created by means of collaborative efforts, such as Wikipedia.1 The coverage issue is addressed by online aggregation services such as Google Define, which bring together definitions from several online dictionaries. However, these services do not classify textual definitions by domain: they </context>
<context position="35795" citStr="Duan and Yates, 2010" startWordPosition="6129" endWordPosition="6132">ich we can drop the requirements of existing techniques such as the ready availability of domain corpora, which often do not contain enough definitions (cf. Table 5), and the manual definition of lexical patterns, which typically extract sentence snippets instead of formal glosses. ProToDoG will be made available to the research community. Beyond the immediate usability of the output glossaries (we show an excerpt in Table 4), we also wish to show the benefit of ProToDoG in gloss-driven approaches to taxonomy learning (Navigli et al., 2011; Velardi et al., 2013) and Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012). The 30- domain glossaries and gold standards created for our experiments are available from http://lcl. uniroma1.it/protodog. We remark that the terminologies covered with ProToDoG are not only precise, but are also one order of magnitude greater than those covered in individual online glossaries. As future work, we plan to study the ability of ProToDoG to acquire domain glossaries at different levels of specificity (i.e., domains vs. subdomains). Finally, we will adapt ProToDoG to other languages, by translating the glossary keyword used in step (2), along the li</context>
</contexts>
<marker>Duan, Yates, 2010</marker>
<rawString>Weisi Duan and Alexander Yates. 2010. Extracting glosses to disambiguate word senses. In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 627– 635, Los Angeles, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>A New Minimally-supervised Framework for Domain Word Sense Disambiguation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1411--1422</pages>
<location>Jeju,</location>
<contexts>
<context position="1673" citStr="Faralli and Navigli, 2012" startWordPosition="251" endWordPosition="254">ys immediate, especially if the target term pertains to a specialized domain. Indeed, not even well-known services such as Google Define are able to provide definitions for scientific or technical terms such as taxonomy learning or distant supervision in AI or figure-four leglock and suspended surfboard in wrestling. Domain-specific knowledge of a definitional nature is not only useful for humans, it is also useful for machines (Hovy et al., 2013). Examples include Natural Language Processing tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Velardi et al., 2013). Unfortunately, most of the Web dictionaries and glossaries available online comprise just a few hundred definitions, and they therefore provide only a partial view of a domain. This is also the case with manually compiled glossaries created by means of collaborative efforts, such as Wikipedia.1 The coverage issue is addressed by online aggregation services such as Google Define, which bring together definitions from several online dictionaries. However, these services do not classify textual definitions by domain: they just present the collected d</context>
<context position="35823" citStr="Faralli and Navigli, 2012" startWordPosition="6133" endWordPosition="6136">quirements of existing techniques such as the ready availability of domain corpora, which often do not contain enough definitions (cf. Table 5), and the manual definition of lexical patterns, which typically extract sentence snippets instead of formal glosses. ProToDoG will be made available to the research community. Beyond the immediate usability of the output glossaries (we show an excerpt in Table 4), we also wish to show the benefit of ProToDoG in gloss-driven approaches to taxonomy learning (Navigli et al., 2011; Velardi et al., 2013) and Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012). The 30- domain glossaries and gold standards created for our experiments are available from http://lcl. uniroma1.it/protodog. We remark that the terminologies covered with ProToDoG are not only precise, but are also one order of magnitude greater than those covered in individual online glossaries. As future work, we plan to study the ability of ProToDoG to acquire domain glossaries at different levels of specificity (i.e., domains vs. subdomains). Finally, we will adapt ProToDoG to other languages, by translating the glossary keyword used in step (2), along the lines of (De Benedictis et al.</context>
</contexts>
<marker>Faralli, Navigli, 2012</marker>
<rawString>Stefano Faralli and Roberto Navigli. 2012. A New Minimally-supervised Framework for Domain Word Sense Disambiguation. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1411–1422, Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>A Java Framework for Multilingual Definition and Hypernym Extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, System Demonstrations,</booktitle>
<pages>103--108</pages>
<location>Sofia, Bulgaria.</location>
<contexts>
<context position="31956" citStr="Faralli and Navigli (2013)" startWordPosition="5527" endWordPosition="5530">kawa (2000) determine the definitional nature of text fragments by using an n-gram model, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. More recently, a domain-independent supervised approach, named Word-Class Lattices (WCLs), was presented which learns lattice-based definition classifiers applied to candidate sentences containing the input terms (Navigli and Velardi, 2010). To avoid the burden of manually creating a training dataset, definitional patterns can be extracted automatically. Faralli and Navigli (2013) utilized Wikipedia as a huge source of definitions and simple, yet effective heuristics to automatically annotate them. Reiplinger et al. (2012) experimented with two different approaches for the acquisition of lexicalsyntactic patterns. The first approach bootstraps patterns from a domain corpus and then manually refines the acquired patterns. The second approach, instead, automatically acquires definitional sentences by using a more sophisticated syntactic and semantic processing. The results show high precision in both cases. However, all the above approaches need large domain corpora, the</context>
</contexts>
<marker>Faralli, Navigli, 2013</marker>
<rawString>Stefano Faralli and Roberto Navigli. 2013. A Java Framework for Multilingual Definition and Hypernym Extraction. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, System Demonstrations, pages 103–108, Sofia, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
<author>Tetsuya Ishikawa</author>
</authors>
<title>Utilizing the World Wide Web as an encyclopedia: extracting term descriptions from semi-structured texts.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>488--495</pages>
<location>Hong Kong.</location>
<contexts>
<context position="2609" citStr="Fujii and Ishikawa, 2000" startWordPosition="395" endWordPosition="398">ve efforts, such as Wikipedia.1 The coverage issue is addressed by online aggregation services such as Google Define, which bring together definitions from several online dictionaries. However, these services do not classify textual definitions by domain: they just present the collected definitions for all the possible meanings of a given term. In order to automatically obtain large domain glossaries, in recent years computational approaches have been developed which extract textual definitions from corpora (Navigli and Velardi, 2010; Reiplinger et al., 2012) or the Web (Velardi et al., 2008; Fujii and Ishikawa, 2000). The methods involving corpora start from a given set of terms (possibly automatically extracted from a domain corpus) and then harvest textual definitions for these terms from the input corpus using a supervised system. Web-based methods, instead, extract text snippets from Web pages which match pre-defined lexical patterns, such as “X is a Y”, along the lines of Hearst (1992). These approaches typically perform with high precision and low recall, because they fall short of detecting the high variability of the syntactic structure of textual definitions. To address the low-recall issue, recu</context>
<context position="31341" citStr="Fujii and Ishikawa (2000)" startWordPosition="5438" endWordPosition="5441">terms and glosses which is an order of magnitude greater than those obtained by TaxoLearn, while at the same time obtaining considerably higher precision. 6 Related Work Current approaches to automatic glossary acquisition suffer from two main issues: i) the poor availability of large domain-specific corpora from which terms and glosses are extracted at different times; ii) the focus on individual domains. ProToDog addresses both issues by providing a joint multidomain approach to term and glossary extraction. Among the approaches which extract unrestricted textual definitions from open text, Fujii and Ishikawa (2000) determine the definitional nature of text fragments by using an n-gram model, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. More recently, a domain-independent supervised approach, named Word-Class Lattices (WCLs), was presented which learns lattice-based definition classifiers applied to candidate sentences containing the input terms (Navigli and Velardi, 2010). To avoid the burden of manually creating a training dataset, definitional patterns can be extracted automatically. Faralli and</context>
</contexts>
<marker>Fujii, Ishikawa, 2000</marker>
<rawString>Atsushi Fujii and Tetsuya Ishikawa. 2000. Utilizing the World Wide Web as an encyclopedia: extracting term descriptions from semi-structured texts. In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, pages 488–495, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the 15th International Conference on Computational Linguistics,</booktitle>
<pages>539--545</pages>
<location>Nantes, France.</location>
<contexts>
<context position="2990" citStr="Hearst (1992)" startWordPosition="463" endWordPosition="464">glossaries, in recent years computational approaches have been developed which extract textual definitions from corpora (Navigli and Velardi, 2010; Reiplinger et al., 2012) or the Web (Velardi et al., 2008; Fujii and Ishikawa, 2000). The methods involving corpora start from a given set of terms (possibly automatically extracted from a domain corpus) and then harvest textual definitions for these terms from the input corpus using a supervised system. Web-based methods, instead, extract text snippets from Web pages which match pre-defined lexical patterns, such as “X is a Y”, along the lines of Hearst (1992). These approaches typically perform with high precision and low recall, because they fall short of detecting the high variability of the syntactic structure of textual definitions. To address the low-recall issue, recurring cue terms occurring 1See http://en.wikipedia.org/wiki/Portal: Contents/Glossaries 170 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 170–181, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics within dictionary and encyclopedic resources can be automatically extracted and incorporate</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proceedings of the 15th International Conference on Computational Linguistics, pages 539–545, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>Collaboratively built semi-structured content and Artificial Intelligence: The story so far.</title>
<date>2013</date>
<journal>Artificial Intelligence,</journal>
<pages>194--2</pages>
<contexts>
<context position="1498" citStr="Hovy et al., 2013" startWordPosition="226" endWordPosition="229">er of dictionaries and technical glossaries has been made available online, thereby speeding up the definition search process. However, finding definitions is not always immediate, especially if the target term pertains to a specialized domain. Indeed, not even well-known services such as Google Define are able to provide definitions for scientific or technical terms such as taxonomy learning or distant supervision in AI or figure-four leglock and suspended surfboard in wrestling. Domain-specific knowledge of a definitional nature is not only useful for humans, it is also useful for machines (Hovy et al., 2013). Examples include Natural Language Processing tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Velardi et al., 2013). Unfortunately, most of the Web dictionaries and glossaries available online comprise just a few hundred definitions, and they therefore provide only a partial view of a domain. This is also the case with manually compiled glossaries created by means of collaborative efforts, such as Wikipedia.1 The coverage issue is addressed by online aggregation services such as Google Defi</context>
</contexts>
<marker>Hovy, Navigli, Ponzetto, 2013</marker>
<rawString>Eduard H. Hovy, Roberto Navigli, and Simone Paolo Ponzetto. 2013. Collaboratively built semi-structured content and Artificial Intelligence: The story so far. Artificial Intelligence, 194:2–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruihong Huang</author>
<author>Ellen Riloff</author>
</authors>
<title>Inducing domain-specific semantic class taggers from (almost) nothing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>275--285</pages>
<location>Uppsala,</location>
<contexts>
<context position="34283" citStr="Huang and Riloff, 2010" startWordPosition="5893" endWordPosition="5896">t be applied to the glossary learning task because the extracted sentences are not formal definitions. In contrast, ProToDoG performs the novel task of multi-domain glossary acquisition from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). ProToDoG synergistically integrates bootstrapping with probabilistic topic models so as to keep the glossary acquisition process within the target domains as much as possible. 7 Conclusions In this paper we have presented ProToDoG, a new, minimally-supervised approach to multi-domain glossary acquisition. Starting from a small set of hypernymy seeds which identify each domain of interest, we apply a bootstrapping approach which iteratively obtains generalized patterns from Web glossaries and then applies them to the extraction of te</context>
</contexts>
<marker>Huang, Riloff, 2010</marker>
<rawString>Ruihong Huang and Ellen Riloff. 2010. Inducing domain-specific semantic class taggers from (almost) nothing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 275–285, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judith Klavans</author>
<author>Smaranda Muresan</author>
</authors>
<title>Evaluation of the DEFINDER system for fully automatic glossary construction.</title>
<date>2001</date>
<booktitle>In Proceedings of the American Medical Informatics Association (AMIA) Symposium,</booktitle>
<pages>324--328</pages>
<location>Washington, D.C., USA.</location>
<contexts>
<context position="31454" citStr="Klavans and Muresan (2001)" startWordPosition="5455" endWordPosition="5458">e obtaining considerably higher precision. 6 Related Work Current approaches to automatic glossary acquisition suffer from two main issues: i) the poor availability of large domain-specific corpora from which terms and glosses are extracted at different times; ii) the focus on individual domains. ProToDog addresses both issues by providing a joint multidomain approach to term and glossary extraction. Among the approaches which extract unrestricted textual definitions from open text, Fujii and Ishikawa (2000) determine the definitional nature of text fragments by using an n-gram model, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. More recently, a domain-independent supervised approach, named Word-Class Lattices (WCLs), was presented which learns lattice-based definition classifiers applied to candidate sentences containing the input terms (Navigli and Velardi, 2010). To avoid the burden of manually creating a training dataset, definitional patterns can be extracted automatically. Faralli and Navigli (2013) utilized Wikipedia as a huge source of definitions and simple, yet effective heuristics to automa</context>
</contexts>
<marker>Klavans, Muresan, 2001</marker>
<rawString>Judith Klavans and Smaranda Muresan. 2001. Evaluation of the DEFINDER system for fully automatic glossary construction. In Proceedings of the American Medical Informatics Association (AMIA) Symposium, pages 324–328, Washington, D.C., USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard H Hovy</author>
</authors>
<title>Not all seeds are equal: Measuring the quality of text mining seeds.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>618--626</pages>
<location>Los Angeles, California, USA.</location>
<contexts>
<context position="22342" citStr="Kozareva and Hovy, 2010" startWordPosition="3860" endWordPosition="3863">ected five seed hypernymy relations as the seed sets Sd input to Algorithm 1 (see Section 3.5). The seeds were selected by the authors on the basis of just two conditions: i) the seeds should cover different aspects of the domain and, indeed, should identify the domain implicitly; ii) at least 10,000 results should be returned by the search engine when querying it with the seeds plus the glossary keyword (see line 6 of Algorithm 1). The seed selection was not fine-tuned (i.e., it was not adjusted to improve performance), so it might well be that better seeds would provide better results (see (Kozareva and Hovy, 2010a)). However, such a study is beyond the scope of this paper. Botany Fashion 85% 80% 75% 70% 65% 60% 55% 50% 45% 175 Art Business Chemistry Computing Environment Food Law Music Physics Sport Gold t/g 394 1777 164 421 713 946 180 218 315 146 PTM t 4253 7370 2493 3412 3009 1526 1836 1647 3847 1696 g 7386 9795 3841 4186 3552 2175 4141 2729 5197 2938 BoW t 4012 7639 1174 3127 3644 1827 1773 1166 4471 1990 g 5923 8999 1414 3662 4334 2601 4024 1249 6956 3425 Wiki t,g 107.1k 48.4k 8137 32.0k 23.6k 5698 13.5k 84.1k 33.8k 267.5k Table 1: Size of the gold standard and the automatically-acquired glossari</context>
<context position="33233" citStr="Kozareva and Hovy, 2010" startWordPosition="5733" endWordPosition="5736">de-coverage glossaries for several domains. To avoid the need to use a large corpus, domain terminologies can be obtained by using Doubly-Anchored Patterns (DAPs) 178 AI Finance # terms P # glosses P # terms P # glosses P ProToDoG 4983 83% 5326 84% 7370 95% 9795 96% TaxoLearn 427 77% 834 79% 2348 86% 1064 88% Table 5: Number and precision of terms and glosses extracted by ProToDoG and TaxoLearn in the Artificial Intelligence (AI) and Finance domains. which, given a (term, hypernym) pair, extract from the Web sentences matching manually-defined patterns like “&lt;hypernym&gt; such as &lt;term&gt;, and *” (Kozareva and Hovy, 2010b). This term extraction process is further extended by harvesting new hypernyms using the corresponding inverse patterns (called DAP−1) like “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to ProToDoG, this approach drops the requirement of a domain corpus and starts from a small number of (term, hypernym) seeds. However, while DAPs have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010b), they cannot be applied to the glossary learning task because the extracted sentences are not formal definitions. In contrast, ProToDoG performs the novel task of multi-domain glossary</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard H. Hovy. 2010a. Not all seeds are equal: Measuring the quality of text mining seeds. In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 618–626, Los Angeles, California, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard H Hovy</author>
</authors>
<title>A semisupervised method to learn and construct taxonomies using the web.</title>
<date>2010</date>
<booktitle>In Proceedings of Empirical Methods in Natural Language Processing,</booktitle>
<pages>1110--1118</pages>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="22342" citStr="Kozareva and Hovy, 2010" startWordPosition="3860" endWordPosition="3863">ected five seed hypernymy relations as the seed sets Sd input to Algorithm 1 (see Section 3.5). The seeds were selected by the authors on the basis of just two conditions: i) the seeds should cover different aspects of the domain and, indeed, should identify the domain implicitly; ii) at least 10,000 results should be returned by the search engine when querying it with the seeds plus the glossary keyword (see line 6 of Algorithm 1). The seed selection was not fine-tuned (i.e., it was not adjusted to improve performance), so it might well be that better seeds would provide better results (see (Kozareva and Hovy, 2010a)). However, such a study is beyond the scope of this paper. Botany Fashion 85% 80% 75% 70% 65% 60% 55% 50% 45% 175 Art Business Chemistry Computing Environment Food Law Music Physics Sport Gold t/g 394 1777 164 421 713 946 180 218 315 146 PTM t 4253 7370 2493 3412 3009 1526 1836 1647 3847 1696 g 7386 9795 3841 4186 3552 2175 4141 2729 5197 2938 BoW t 4012 7639 1174 3127 3644 1827 1773 1166 4471 1990 g 5923 8999 1414 3662 4334 2601 4024 1249 6956 3425 Wiki t,g 107.1k 48.4k 8137 32.0k 23.6k 5698 13.5k 84.1k 33.8k 267.5k Table 1: Size of the gold standard and the automatically-acquired glossari</context>
<context position="33233" citStr="Kozareva and Hovy, 2010" startWordPosition="5733" endWordPosition="5736">de-coverage glossaries for several domains. To avoid the need to use a large corpus, domain terminologies can be obtained by using Doubly-Anchored Patterns (DAPs) 178 AI Finance # terms P # glosses P # terms P # glosses P ProToDoG 4983 83% 5326 84% 7370 95% 9795 96% TaxoLearn 427 77% 834 79% 2348 86% 1064 88% Table 5: Number and precision of terms and glosses extracted by ProToDoG and TaxoLearn in the Artificial Intelligence (AI) and Finance domains. which, given a (term, hypernym) pair, extract from the Web sentences matching manually-defined patterns like “&lt;hypernym&gt; such as &lt;term&gt;, and *” (Kozareva and Hovy, 2010b). This term extraction process is further extended by harvesting new hypernyms using the corresponding inverse patterns (called DAP−1) like “* such as &lt;term1&gt;, and &lt;term2&gt;”. Similarly to ProToDoG, this approach drops the requirement of a domain corpus and starts from a small number of (term, hypernym) seeds. However, while DAPs have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010b), they cannot be applied to the glossary learning task because the extracted sentences are not formal definitions. In contrast, ProToDoG performs the novel task of multi-domain glossary</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard H. Hovy. 2010b. A semisupervised method to learn and construct taxonomies using the web. In Proceedings of Empirical Methods in Natural Language Processing, pages 1110–1118, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<pages>193--217</pages>
<contexts>
<context position="19587" citStr="Navigli and Ponzetto, 2012" startWordPosition="3377" endWordPosition="3380">rage for Botany and Fashion (tuning domains) over 20 iterations (|Sd|=5, 6=0.03). or more Wikipedia categories representing the domain (for instance, Category:Arts for Arts, Category:Business for Finance, etc.). Then, for each domain d, we picked out all the Wikipedia pages tagged either with the categories selected for d or their direct subcategories (e.g., Category:Creative works) or subsubcategories (e.g., Category:Genres). From each page we extracted a (page title, gloss) pair, where the gloss was obtained by extracting the first sentence of the Wikipedia page, as done, e.g., in BabelNet (Navigli and Ponzetto, 2012). Since subcategories might have more parents and might thus belong to multiple domains, we discarded pages assigned to more than 2 domains. 3.5 Parameter tuning In order to choose the optimal values of the parameters of ProToDoG (number |Sd |of seeds per domain, number max of iterations, and filtering threshold 6) and BoW (Q threshold) we selected two extra domains, i.e., Botany and Fashion, not used in our tests, together with the corresponding gold standard Web glossaries. As regards the number of seeds, we defined an initial pool of 10 seeds for each of the two tuning domains and studied t</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artificial Intelligence, 193:217–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
</authors>
<title>Learning Word-Class Lattices for definition and hypernym extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1318--1327</pages>
<location>Uppsala,</location>
<contexts>
<context position="2523" citStr="Navigli and Velardi, 2010" startWordPosition="380" endWordPosition="383">his is also the case with manually compiled glossaries created by means of collaborative efforts, such as Wikipedia.1 The coverage issue is addressed by online aggregation services such as Google Define, which bring together definitions from several online dictionaries. However, these services do not classify textual definitions by domain: they just present the collected definitions for all the possible meanings of a given term. In order to automatically obtain large domain glossaries, in recent years computational approaches have been developed which extract textual definitions from corpora (Navigli and Velardi, 2010; Reiplinger et al., 2012) or the Web (Velardi et al., 2008; Fujii and Ishikawa, 2000). The methods involving corpora start from a given set of terms (possibly automatically extracted from a domain corpus) and then harvest textual definitions for these terms from the input corpus using a supervised system. Web-based methods, instead, extract text snippets from Web pages which match pre-defined lexical patterns, such as “X is a Y”, along the lines of Hearst (1992). These approaches typically perform with high precision and low recall, because they fall short of detecting the high variability of</context>
<context position="15076" citStr="Navigli and Velardi, 2010" startWordPosition="2613" endWordPosition="2616">loss g was filtered out. So, thanks to the last-iteration topic model, the gloss g might come back into play because its words are now important cues for a domain. To reassess the domain pertinence of (term, gloss) pairs in Ad for each d, we just reapply the entire step (3) by setting Gmax+1 := Ad for each d E D. As a result, we d library, a Java Implementation of Latent Dirichlet Allocation (LDA) using Gibbs Sampling for Parameter Estimation and Inference, available at: http://jgibblda.sourceforge. net/ 7While more complex strategies could be devised, e.g., lattice-based hypernym extraction (Navigli and Velardi, 2010), we found that this heuristic works well because, even when it is not a hypernym, the first term acts as a cue word for the defined term. E|W �w&apos;= 1 Cw D + |W|β (1) MD θ(t,g) = C(t,g),d + α 2 θ0(t,g) d= M0D R(t,g),d + α 173 obtain an updated glossary Gmax+1 which contains d all the recovered glosses. Final output: For each domain d E D the final output of ProToDoG is a domain glossary Gd := Uj_1,...,max+1 Gjd. Finally the algorithm aggregates all glossaries Gd into a multi-domain glossary G (line 22). 3 Experimental Setup 3.1 Domains For our experiments we selected 30 different domains rangin</context>
<context position="31813" citStr="Navigli and Velardi, 2010" startWordPosition="5507" endWordPosition="5510">in approach to term and glossary extraction. Among the approaches which extract unrestricted textual definitions from open text, Fujii and Ishikawa (2000) determine the definitional nature of text fragments by using an n-gram model, whereas Klavans and Muresan (2001) apply pattern matching techniques at the lexical level guided by cue phrases such as “is called” and “is defined as”. More recently, a domain-independent supervised approach, named Word-Class Lattices (WCLs), was presented which learns lattice-based definition classifiers applied to candidate sentences containing the input terms (Navigli and Velardi, 2010). To avoid the burden of manually creating a training dataset, definitional patterns can be extracted automatically. Faralli and Navigli (2013) utilized Wikipedia as a huge source of definitions and simple, yet effective heuristics to automatically annotate them. Reiplinger et al. (2012) experimented with two different approaches for the acquisition of lexicalsyntactic patterns. The first approach bootstraps patterns from a domain corpus and then manually refines the acquired patterns. The second approach, instead, automatically acquires definitional sentences by using a more sophisticated syn</context>
</contexts>
<marker>Navigli, Velardi, 2010</marker>
<rawString>Roberto Navigli and Paola Velardi. 2010. Learning Word-Class Lattices for definition and hypernym extraction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1318–1327, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Paola Velardi</author>
<author>Stefano Faralli</author>
</authors>
<title>A graph-based algorithm for inducing lexical taxonomies from scratch.</title>
<date>2011</date>
<booktitle>In Proceedings of the 22th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1872--1877</pages>
<location>Barcelona,</location>
<contexts>
<context position="28512" citStr="Navigli et al., 2011" startWordPosition="4973" endWordPosition="4976">analyzed domains. However, we note that when searching for domain-specific knowledge only, Google Define: i) needs to know the domain term to be defined in advance, while ProToDoG jointly acquires domain terms and glosses starting from just a few seeds; ii) does not discriminate between glosses pertaining to the target domain and glosses pertaining to other fields or senses, whereas ProToDog extracts terms and glosses specific to each domain of interest. 5.2 Comparison with TaxoLearn We also compared ProToDoG with the output of a state-of-the-art taxonomy learning framework, called TaxoLearn (Navigli et al., 2011). We did this because i) TaxoLearn extracts terms and glosses from domain corpora in order to create a domain taxonomy; ii) it is one of the few systems which extracts both terms and glosses from specialized corpora; iii) the extracted glossaries are available online.9 Therefore we compared the performance of ProToDoG on two domains for which glossaries were extracted by TaxoLearn, i.e. AI and Finance. The glossaries were harvested from large collections of scholarly articles. For ProToDoG we selected 10 seeds to cover all the fields of AI, while for the financial domain we selected the same 5</context>
<context position="35720" citStr="Navigli et al., 2011" startWordPosition="6117" endWordPosition="6120">the core of ProToDoG lies our glossary bootstrapping approach, thanks to which we can drop the requirements of existing techniques such as the ready availability of domain corpora, which often do not contain enough definitions (cf. Table 5), and the manual definition of lexical patterns, which typically extract sentence snippets instead of formal glosses. ProToDoG will be made available to the research community. Beyond the immediate usability of the output glossaries (we show an excerpt in Table 4), we also wish to show the benefit of ProToDoG in gloss-driven approaches to taxonomy learning (Navigli et al., 2011; Velardi et al., 2013) and Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012). The 30- domain glossaries and gold standards created for our experiments are available from http://lcl. uniroma1.it/protodog. We remark that the terminologies covered with ProToDoG are not only precise, but are also one order of magnitude greater than those covered in individual online glossaries. As future work, we plan to study the ability of ProToDoG to acquire domain glossaries at different levels of specificity (i.e., domains vs. subdomains). Finally, we will adapt ProToDoG to other la</context>
</contexts>
<marker>Navigli, Velardi, Faralli, 2011</marker>
<rawString>Roberto Navigli, Paola Velardi, and Stefano Faralli. 2011. A graph-based algorithm for inducing lexical taxonomies from scratch. In Proceedings of the 22th International Joint Conference on Artificial Intelligence, pages 1872–1877, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pas¸ca</author>
<author>Dekang Lin</author>
<author>Jeffrey Bigham</author>
<author>Andrei Lifchits</author>
<author>Alpa Jain</author>
</authors>
<title>Names and similarities on the Web: Fact extraction in the fast lane.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>809--816</pages>
<location>Sydney, Australia.</location>
<marker>Pas¸ca, Lin, Bigham, Lifchits, Jain, 2006</marker>
<rawString>Marius Pas¸ca, Dekang Lin, Jeffrey Bigham, Andrei Lifchits, and Alpa Jain. 2006. Names and similarities on the Web: Fact extraction in the fast lane. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 809– 816, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL),</booktitle>
<pages>113--120</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="34141" citStr="Pantel and Pennacchiotti, 2006" startWordPosition="5875" endWordPosition="5878"> number of (term, hypernym) seeds. However, while DAPs have proven useful in the induction of domain taxonomies (Kozareva and Hovy, 2010b), they cannot be applied to the glossary learning task because the extracted sentences are not formal definitions. In contrast, ProToDoG performs the novel task of multi-domain glossary acquisition from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). ProToDoG synergistically integrates bootstrapping with probabilistic topic models so as to keep the glossary acquisition process within the target domains as much as possible. 7 Conclusions In this paper we have presented ProToDoG, a new, minimally-supervised approach to multi-domain glossary acquisition. Starting from a small set of hypernymy seeds which identify each domain of interest, we a</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Patrick Pantel and Marco Pennacchiotti. 2006. Espresso: Leveraging Generic Patterns for Automatically Harvesting Semantic Relations. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics (COLING-ACL), Sydney, Australia, pages 113–120, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xuan-Hieu Phan</author>
<author>Le-Minh Nguyen</author>
<author>Susumu Horiguchi</author>
</authors>
<title>Learning to classify short and sparse text &amp; web with hidden topics from large-scale data collections.</title>
<date>2008</date>
<booktitle>In Proceedings of the 17th international conference on World Wide Web, WWW ’08,</booktitle>
<pages>91--100</pages>
<location>New York, NY, USA.</location>
<contexts>
<context position="12320" citStr="Phan et al., 2008" startWordPosition="2111" endWordPosition="2114">bove probabilities represent the core of our topic model of the domain knowledge acquired up until iteration k − 1. Probabilistic modeling of iteration-k glosses (line 11): We now utilize the above topic model to estimate the probabilities in Formulas 1 and 2 for the newly acquired glosses at iteration k. To this end we define M0 := Ud∈D Gkd as the union of the (term, gloss) pairs at iteration k and W0 := Ud∈D Tk n W d as the union of terms acquired at iteration k, but also occurring in W (i.e., the entire terminology up until iteration k − 1). Then we apply Gibbs sampling (Blei et al., 2003; Phan et al., 2008) to estimate the probability of each pair (t, g) E M0 of pertaining to a domain d by computing: (3) E|d0= |1 RM0D (t,g),d0 + |D|α where the gloss-domain matrix RM0D is initially defined by counting random domain assignments for each word w0 in the bag of words of each (term, gloss) pair E M0. Next, the domain assignment counts in RM0D are iteratively updated using Gibbs sampling.6 5As experienced by Steyvers and Griffiths (2007), the values of α = 50/1D1 and ,Q = 0.01 work well with many different text collections. 6For the PTM part of ProToDoG we used the JGibbLDA Filtering out non-domain glo</context>
</contexts>
<marker>Phan, Nguyen, Horiguchi, 2008</marker>
<rawString>Xuan-Hieu Phan, Le-Minh Nguyen, and Susumu Horiguchi. 2008. Learning to classify short and sparse text &amp; web with hidden topics from large-scale data collections. In Proceedings of the 17th international conference on World Wide Web, WWW ’08, pages 91– 100, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deepak Ravichandran</author>
<author>Eduard Hovy</author>
</authors>
<title>Learning surface text patterns for a question answering system.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>41--47</pages>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="34240" citStr="Ravichandran and Hovy, 2002" startWordPosition="5887" endWordPosition="5890">axonomies (Kozareva and Hovy, 2010b), they cannot be applied to the glossary learning task because the extracted sentences are not formal definitions. In contrast, ProToDoG performs the novel task of multi-domain glossary acquisition from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). ProToDoG synergistically integrates bootstrapping with probabilistic topic models so as to keep the glossary acquisition process within the target domains as much as possible. 7 Conclusions In this paper we have presented ProToDoG, a new, minimally-supervised approach to multi-domain glossary acquisition. Starting from a small set of hypernymy seeds which identify each domain of interest, we apply a bootstrapping approach which iteratively obtains generalized patterns from Web glossaries an</context>
</contexts>
<marker>Ravichandran, Hovy, 2002</marker>
<rawString>Deepak Ravichandran and Eduard Hovy. 2002. Learning surface text patterns for a question answering system. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 41– 47, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Melanie Reiplinger</author>
<author>Ulrich Sch¨afer</author>
<author>Magdalena Wolska</author>
</authors>
<title>Extracting glossary sentences from scholarly articles: A comparative evaluation of pattern bootstrapping and deep analysis.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries,</booktitle>
<pages>55--65</pages>
<location>Jeju Island,</location>
<marker>Reiplinger, Sch¨afer, Wolska, 2012</marker>
<rawString>Melanie Reiplinger, Ulrich Sch¨afer, and Magdalena Wolska. 2012. Extracting glossary sentences from scholarly articles: A comparative evaluation of pattern bootstrapping and deep analysis. In Proceedings of the ACL-2012 Special Workshop on Rediscovering 50 Years of Discoveries, pages 55–65, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horacio Saggion</author>
</authors>
<title>Identifying definitions in text collections for question answering.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation,</booktitle>
<pages>1927--1930</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="3629" citStr="Saggion, 2004" startWordPosition="544" endWordPosition="545">lly perform with high precision and low recall, because they fall short of detecting the high variability of the syntactic structure of textual definitions. To address the low-recall issue, recurring cue terms occurring 1See http://en.wikipedia.org/wiki/Portal: Contents/Glossaries 170 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 170–181, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics within dictionary and encyclopedic resources can be automatically extracted and incorporated into lexical patterns (Saggion, 2004). However, this approach is term-specific and does not scale to arbitrary terminologies and domains. The goal of the new approach outlined in this paper is to enable the automatic harvesting of largescale, full-fledged domain glossaries for dozens of domains, an outcome which should be very useful for both human activities and automatic tasks. We present ProToDoG (Probabilistic Topics for multi-Domain Glossaries), a framework for growing multi-domain glossaries which has three main novelties: i) minimal human supervision: a small set of hypernymy relation seeds for each domain is used to boots</context>
</contexts>
<marker>Saggion, 2004</marker>
<rawString>Horacio Saggion. 2004. Identifying definitions in text collections for question answering. In Proceedings of the Fourth International Conference on Language Resources and Evaluation, pages 1927–1930, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Tom Griffiths</author>
</authors>
<title>Probabilistic Topic Models. Lawrence Erlbaum Associates.</title>
<date>2007</date>
<contexts>
<context position="9938" citStr="Steyvers and Griffiths, 2007" startWordPosition="1644" endWordPosition="1647">sses in the Web page containing the snippet s by matching the page against the generalized pattern pL * pM * pR, and adding them to Gkd. As a result of step (2), for each domain d E D we obtain a glossary Gkd for the terms discovered at iteration k. Step 3. Topic modeling and gloss filtering (lines 10-12): Unfortunately, not all (term, gloss) pairs in a glossary Gkd will pertain to the domain d. For instance, we might end up retrieving interdisciplinary or even unrelated glossaries. In order to address this fuzziness, we model domains with a Probabilistic Topic Model (PTM) (Blei et al., 2003; Steyvers and Griffiths, 2007). PTMs model a given text document as a mixture of topics. In our case topics are domains and we, first, create a topic model from the domain glossaries acquired before the current iteration k, then, second, use the topic model to estimate the domain assignment of each new pair (term, gloss) in our glossaries Gkd, i.e., obtained at iteration k, third, filter out non-domain glosses. Creating the topic model (line 10): For a given iteration k and domain d, we first define the terminology accumulated up until iteration k − 1 for that domain as the set Td,k−1 := U� −1 Td, where Tdj is the set of t</context>
<context position="11466" citStr="Steyvers and Griffiths (2007)" startWordPosition="1943" endWordPosition="1947"> up until iteration k − 1, i.e., the full set of pairs (term, gloss) independently of their domain;4 3For the first iteration, i.e., when k = 1, we define T 1,0 d := {t : 3(t, g) E Gd}, i.e., we use the terminology resulting from step (2) of the first iteration. 4For k = 1, M := UdED Gd. 172 • Two count matrices, i.e., the word-domain matrix CWD and the gloss-domain matrix CMD, such that: CW D w,d counts the number of times w E W is assigned to domain d E D, i.e., it occurs in the glosses of domain d; CMD (t,g),d counts the number of words in g assigned to domain d. At this point, as shown by Steyvers and Griffiths (2007), we can estimate the probability φ(d) w for word w, and the probability θ(t,g) dfor a term/gloss pair (t, g), of belonging to domain d: φ(d) = CWD w,d + β w d E|d&apos; l 1 CMD (t,g),d&apos; + |D|α where α and β are smoothing factors.5 The two above probabilities represent the core of our topic model of the domain knowledge acquired up until iteration k − 1. Probabilistic modeling of iteration-k glosses (line 11): We now utilize the above topic model to estimate the probabilities in Formulas 1 and 2 for the newly acquired glosses at iteration k. To this end we define M0 := Ud∈D Gkd as the union of the </context>
<context position="12752" citStr="Steyvers and Griffiths (2007)" startWordPosition="2187" endWordPosition="2190">d as the union of terms acquired at iteration k, but also occurring in W (i.e., the entire terminology up until iteration k − 1). Then we apply Gibbs sampling (Blei et al., 2003; Phan et al., 2008) to estimate the probability of each pair (t, g) E M0 of pertaining to a domain d by computing: (3) E|d0= |1 RM0D (t,g),d0 + |D|α where the gloss-domain matrix RM0D is initially defined by counting random domain assignments for each word w0 in the bag of words of each (term, gloss) pair E M0. Next, the domain assignment counts in RM0D are iteratively updated using Gibbs sampling.6 5As experienced by Steyvers and Griffiths (2007), the values of α = 50/1D1 and ,Q = 0.01 work well with many different text collections. 6For the PTM part of ProToDoG we used the JGibbLDA Filtering out non-domain glosses (line 12): Now, for each domain d E D, for each pair (t, g) E Gkd we have a probability θd of belonging to d. We mark 0(t,g) (t, g) as a non-domain item if θd &lt; δ, where δ is 0(t,g) a confidence threshold, or if θ0(t,g) dis not maximum among all domains in D. Non-domain pairs are removed from Gkd and stored into a set Ad for possible recovery after the last iteration (see step (5)). Step 4. Seed selection for next iteration</context>
</contexts>
<marker>Steyvers, Griffiths, 2007</marker>
<rawString>Mark Steyvers and Tom Griffiths, 2007. Probabilistic Topic Models. Lawrence Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Velardi</author>
<author>Roberto Navigli</author>
<author>Pierluigi D’Amadio</author>
</authors>
<title>Mining the web to create specialized glossaries.</title>
<date>2008</date>
<journal>IEEE Intelligent Systems,</journal>
<volume>23</volume>
<issue>5</issue>
<marker>Velardi, Navigli, D’Amadio, 2008</marker>
<rawString>Paola Velardi, Roberto Navigli, and Pierluigi D’Amadio. 2008. Mining the web to create specialized glossaries. IEEE Intelligent Systems, 23(5):18–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Velardi</author>
<author>Stefano Faralli</author>
<author>Roberto Navigli</author>
</authors>
<title>OntoLearn Reloaded: A graph-based algorithm for taxonomy induction.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>3</issue>
<contexts>
<context position="1718" citStr="Velardi et al., 2013" startWordPosition="258" endWordPosition="261">ns to a specialized domain. Indeed, not even well-known services such as Google Define are able to provide definitions for scientific or technical terms such as taxonomy learning or distant supervision in AI or figure-four leglock and suspended surfboard in wrestling. Domain-specific knowledge of a definitional nature is not only useful for humans, it is also useful for machines (Hovy et al., 2013). Examples include Natural Language Processing tasks such as Question Answering (Cui et al., 2007), Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012) and ontology learning (Velardi et al., 2013). Unfortunately, most of the Web dictionaries and glossaries available online comprise just a few hundred definitions, and they therefore provide only a partial view of a domain. This is also the case with manually compiled glossaries created by means of collaborative efforts, such as Wikipedia.1 The coverage issue is addressed by online aggregation services such as Google Define, which bring together definitions from several online dictionaries. However, these services do not classify textual definitions by domain: they just present the collected definitions for all the possible meanings of a</context>
<context position="35743" citStr="Velardi et al., 2013" startWordPosition="6121" endWordPosition="6124">ies our glossary bootstrapping approach, thanks to which we can drop the requirements of existing techniques such as the ready availability of domain corpora, which often do not contain enough definitions (cf. Table 5), and the manual definition of lexical patterns, which typically extract sentence snippets instead of formal glosses. ProToDoG will be made available to the research community. Beyond the immediate usability of the output glossaries (we show an excerpt in Table 4), we also wish to show the benefit of ProToDoG in gloss-driven approaches to taxonomy learning (Navigli et al., 2011; Velardi et al., 2013) and Word Sense Disambiguation (Duan and Yates, 2010; Faralli and Navigli, 2012). The 30- domain glossaries and gold standards created for our experiments are available from http://lcl. uniroma1.it/protodog. We remark that the terminologies covered with ProToDoG are not only precise, but are also one order of magnitude greater than those covered in individual online glossaries. As future work, we plan to study the ability of ProToDoG to acquire domain glossaries at different levels of specificity (i.e., domains vs. subdomains). Finally, we will adapt ProToDoG to other languages, by translating</context>
</contexts>
<marker>Velardi, Faralli, Navigli, 2013</marker>
<rawString>Paola Velardi, Stefano Faralli, and Roberto Navigli. 2013. OntoLearn Reloaded: A graph-based algorithm for taxonomy induction. Computational Linguistics, 39(3):665–707.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised Word Sense Disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33Td Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="34343" citStr="Yarowsky, 1995" startWordPosition="5903" endWordPosition="5904">tences are not formal definitions. In contrast, ProToDoG performs the novel task of multi-domain glossary acquisition from the Web by bootstrapping the extraction process with a few (term, hypernym) seeds. Bootstrapping techniques (Brin, 1998; Agichtein and Gravano, 2000; Pas¸ca et al., 2006) have been successfully applied to several tasks, including learning semantic relations (Pantel and Pennacchiotti, 2006), extracting surface text patterns for open-domain question answering (Ravichandran and Hovy, 2002), semantic tagging (Huang and Riloff, 2010) and unsupervised Word Sense Disambiguation (Yarowsky, 1995). ProToDoG synergistically integrates bootstrapping with probabilistic topic models so as to keep the glossary acquisition process within the target domains as much as possible. 7 Conclusions In this paper we have presented ProToDoG, a new, minimally-supervised approach to multi-domain glossary acquisition. Starting from a small set of hypernymy seeds which identify each domain of interest, we apply a bootstrapping approach which iteratively obtains generalized patterns from Web glossaries and then applies them to the extraction of term/gloss pairs. To our knowledge, ProToDoG is the first appr</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995. Unsupervised Word Sense Disambiguation rivaling supervised methods. In Proceedings of the 33Td Annual Meeting of the Association for Computational Linguistics, pages 189–196, Cambridge, MA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>