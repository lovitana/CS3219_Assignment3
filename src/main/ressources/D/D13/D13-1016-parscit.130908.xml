<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<title confidence="0.9981735">
Learning Latent Word Representations for Domain Adaptation
using Supervised Word Clustering
</title>
<author confidence="0.996387">
Min Xiao and Feipeng Zhao and Yuhong Guo
</author>
<affiliation confidence="0.869236">
Department of Computer and Information Sciences
Temple University
Philadelphia, PA 19122, USA
</affiliation>
<email confidence="0.998256">
{minxiao,feipeng.zhao,yuhong}@temple.edu
</email>
<sectionHeader confidence="0.998595" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999846076923077">
Domain adaptation has been popularly stud-
ied on exploiting labeled information from a
source domain to learn a prediction model in
a target domain. In this paper, we develop a
novel representation learning approach to ad-
dress domain adaptation for text classification
with automatically induced discriminative la-
tent features, which are generalizable across
domains while informative to the prediction
task. Specifically, we propose a hierarchical
multinomial Naive Bayes model with latent
variables to conduct supervised word cluster-
ing on labeled documents from both source
and target domains, and then use the produced
cluster distribution of each word as its la-
tent feature representation for domain adapta-
tion. We train this latent graphical model us-
ing a simple expectation-maximization (EM)
algorithm. We empirically evaluate the pro-
posed method with both cross-domain doc-
ument categorization tasks on Reuters-21578
dataset and cross-domain sentiment classifica-
tion tasks on Amazon product review dataset.
The experimental results demonstrate that our
proposed approach achieves superior perfor-
mance compared with alternative methods.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999883512195122">
Supervised prediction models typically require a
large amount of labeled data for training. However,
manually collecting data annotations is expensive in
many real-world applications such as document cat-
egorization or sentiment classification. Recently, do-
main adaptation has been proposed to exploit exist-
ing labeled data in a related source domain to assist
the prediction model training in the target domain
(Ben-David et al., 2006; Blitzer et al., 2006; Daum´e
III, 2007; Blitzer et al., 2011; Chen et al., 2012). As
an effective tool to reduce annotation effort, domain
adaptation has achieved success in various cross-
domain natural language processing (NLP) systems
such as document categorization (Dai et al., 2007),
sentiment classification (Blitzer et al., 2007; Chen
et al., 2012; Mejova and Srinivasan, 2012; Chen
et al., 2011), email spam detection (Jiang and Zhai,
2007), and a number of other NLP tasks (Blitzer
et al., 2011; Daum´e III, 2007).
One primary challenge of domain adaptation lies
in the distribution divergence of the two domains
in the original feature representation space. For ex-
ample, documents about books may contain very
different high-frequency words and discriminative
words from documents about kitchen. A good cross-
domain feature representation thus has been viewed
as critical for bridging the domain divergence gap
and facilitating domain adaptation in the NLP area
(Ben-David et al., 2006, 2010). Many domain adap-
tation works have been proposed to learn new
cross-domain feature representations (Blitzer et al.,
2006, 2011). Though demonstrated good perfor-
mance on certain problems, these works mostly in-
duce new feature representations in an unsupervised
way, without taking the valuable label information
into account.
In this work, we present a novel supervised rep-
resentation learning approach to discover a latent
representation of words which is not only general-
izable across domains but also informative to the
classification task. Specifically, we propose a hier-
</bodyText>
<page confidence="0.968793">
152
</page>
<note confidence="0.7352945">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 152–162,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999445666666667">
archical multinomial Naive Bayes model with la-
tent word cluster variables to perform supervised
word clustering on labeled documents from both do-
mains. Our model directly models the relationships
between the observed document label variables and
the latent word cluster variables. The induced clus-
ter representation of each word thus will be infor-
mative for the classification labels, and hence dis-
criminative for the target classification task. We train
this directed graphical model using an expectation-
maximization (EM) algorithm, which maximizes the
log-likelihood of the observations of labeled docu-
ments. The induced cluster distribution of each word
can then be used as its generalizable representa-
tion to construct new cluster-based representation of
each document. For domain adaptation, we train a
supervised learning system with labeled data from
both domains in the new representation space and
apply it to categorize test documents in the target do-
main. In order to evaluate the proposed technique,
we conduct extensive experiments on the Reuters-
21578 dataset for cross-domain document catego-
rization and on Amazon product review dataset for
cross-domain sentiment classification. The experi-
mental results show the proposed approach can pro-
duce more effective representations than the com-
parison domain adaptation methods.
</bodyText>
<sectionHeader confidence="0.999931" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999963576923077">
Domain adaptation has recently been popularly
studied in natural language processing and a variety
of domain adaptation approaches have been devel-
oped, including instance weighting adaptation meth-
ods and feature representation learning methods.
Instance weighting adaptation methods improve
the transferability of a prediction model by training
an instance weighted learning system. Much work in
this category has been developed to address differ-
ent weighting schemas (Sugiyama et al., 2007; Wan
et al., 2011). Jiang and Zhai (2007) applied instance
weighting algorithms to tackle cross-domain NLP
tasks and proposed to remove misleading source
training data and assign less weights to labeled data
from the source domain than labeled data from the
target domain. Dai et al. (2007) proposed to increase
the weights of mistakenly predicted instances from
the target domain and decrease the weights of incor-
rectly predicted instances from the source domain
during an iterative training process.
Representation learning methods bridge do-
main divergence either by differentiating domain-
invariant features from domain-specific features
(Daum´e III, 2007; Daum´e III et al., 2010; Blitzer
et al., 2011; Finkel and Manning, 2009) or seeking
generalizable latent features across domains (Blitzer
et al., 2006, 2007; Prettenhofer and Stein, 2010).
Daum´e III (2007); Daum´e III et al. (2010) proposed
a simple heuristic feature replication method to rep-
resent common, source specific and target specific
features. Finkel and Manning (2009) proposed a for-
mer version of it based on the use of a hierarchi-
cal Bayesian prior. Blitzer et al. (2011) proposed
a coupled subspace learning method, which learns
two projectors, one for each domain, to project the
original features into domain-sharing and domain-
specific features. Blitzer et al. (2006) proposed a
structural correspondence learning (SCL) method to
model the correlation between pivot features and
non-pivot features. It uses the correlation to in-
duce latent domain-invariant features as augment-
ing features for supervised learning. Extensions of
this work include improving pivot feature selection
(Blitzer et al., 2007; Prettenhofer and Stein, 2010),
and improving the correlation modeling between
pivot and non-pivot features (Tan, 2009).
The proposed approach in this paper belongs to
representation learning methods. However, unlike
the unsupervised representation learning methods
reviewed above, our proposed approach learns gen-
eralizable feature representations of words by ex-
ploiting data labels from the two domains.
</bodyText>
<sectionHeader confidence="0.780215" genericHeader="method">
3 Learning Latent Word Representations
using Supervised Word Clustering
</sectionHeader>
<bodyText confidence="0.9999169">
In this paper, we address domain adaptation for
text classification. Given a source domain DS with
plenty of labeled documents, and a target domain
DT with a very few labeled documents, the task is
to learn a classifier from the labeled documents in
both domains, and use it to classify the unlabeled
documents in the target domain. The documents in
the two domains share the same universal vocabu-
lary V = {w1, w2, · · · , wn}, but the word distri-
butions in the two domains are typically different.
</bodyText>
<page confidence="0.998639">
153
</page>
<bodyText confidence="0.999968047619048">
Therefore, training the classification model directly
from the original word feature space V may not gen-
eralize well in the target domain.
We propose to address this problem by first learn-
ing a supervised mapping function 0 : V ) Z
from the labeled documents in both domains, which
maps the input word features in the large vocabu-
lary set V into a low dimensional latent feature space
Z. By filtering out unimportant details and noises,
we expect the low dimensional mapping can cap-
ture the intrinsic structure of the input data that is
discriminative for the classification task and gener-
alizable across domains. In particular, we learn such
a mapping function by conducting supervised word
clustering on the labeled documents using a hierar-
chical multinomial Naive Bayes model. Below, we
will first introduce this supervised word clustering
model and then use the mapping function produced
to transform documents in different domains into the
same low-dimensional space for training cross do-
main text classification systems.
</bodyText>
<subsectionHeader confidence="0.998858">
3.1 Supervised Word Clustering
</subsectionHeader>
<bodyText confidence="0.971819538461538">
Given all labeled documents from the source and
target domains, D = {(wt, yt)}Tt=1, where the t-th
labeled document is expressed as a bag of words,
wt = {wt1, wt2, · · · , wtNt}, and its label value is
yt E Y for Y = {1, · · · , K}, we propose to per-
form supervised word clustering by modeling the
document-label pair distribution using a hierarchical
multinomial Naive Bayes model given in Figure 1,
which has a middle layer of latent cluster variables.
In this plate model, the variable Yt denotes the
observed class label for the t-th document, and all
the label variables, {Yt}Tt=1, share the same multi-
nomial distribution OY across documents. The la-
tent variable Ct,i denotes the cluster membership
of the word Wt,i, and all the cluster variables,
{Ct,i}T,Nt
t=1,i=1, share the same set of conditional dis-
tributions {OC|y}Ky=1 across documents and words.
The variable Wt,i denotes the i-th observed word
in the t-th document, and all the word variables,
{Wt,i}T,Nt
t=1,i=1, share the same set of conditional dis-
tributions {OW|c}mc=1. Here we assume the number
of word clusters is m. For simplicity, we do not show
the distribution parameter variables in the Figure.
Following the Markov property of directed graph-
</bodyText>
<figureCaption confidence="0.998636">
Figure 1: Supervised word clustering model.
</figureCaption>
<bodyText confidence="0.999950588235294">
ical models, we can see that given the cluster vari-
able values, the document label variables will be
completely independent of the word variables. By
learning this latent directed graphical model, we
thus expect the important classification information
expressed in the input observation words can be
effectively summarized into the latent cluster vari-
ables. This latent model is much simpler than the
supervised topic models (Blei and McAuliffe, 2007),
but we will show later that it can suitably produce a
generalizable feature mapping function for domain
adaptation.
To train the latent graphical model in Fig-
ure 1 on labeled documents D, we use a standard
expectation-maximization (EM) algorithm (Demp-
ster et al., 1977) to maximize the marginal log-
likelihood of the observations:
</bodyText>
<equation confidence="0.98239">
LL(D; 0) = � log P(yt,wt10) (1)
t
</equation>
<bodyText confidence="0.9997835">
The EM algorithm is an iterative procedure. In each
iteration, it takes an alternative E-step and M-step
to maximize the lower bound of the marginal log-
likelihood function. In our experiments, we start
from a random initialization of the model parame-
ters and the latent variable values, and then perform
iterative EM updates until converge to a local opti-
mal solution.
</bodyText>
<subsectionHeader confidence="0.996364">
3.2 Induced Word Representation
</subsectionHeader>
<bodyText confidence="0.999697833333333">
After training the supervised clustering model using
EM algorithm, a set of local optimal model parame-
ters 0* will be returned, which define a joint distri-
bution over the three groups of variables in the di-
rected graphical model. Next we define a supervised
latent feature mapping function 0 from this trained
</bodyText>
<page confidence="0.999627">
154
</page>
<bodyText confidence="0.998063">
model to map each word w in the vocabulary V into
a conditional distribution vector over the word clus-
ter variable, such as
</bodyText>
<subsectionHeader confidence="0.966314">
4.1 Approaches
</subsectionHeader>
<bodyText confidence="0.9371265">
We compared our proposed supervised word cluster-
ing approach (SWC) with the following five compar-
ison methods for domain adaptation:
φ(w)=[P(c=1|w, θ∗), ··· , P(c=m|w, θ∗)]. (2)
The conditional distributions involved in this map-
ping function can be computed as
</bodyText>
<equation confidence="0.655581">
(3)
</equation>
<bodyText confidence="0.964232">
where P(w|c, θ∗) = θ∗ w|c P(c|y, θ∗) = θ∗c|y and
P(y|θ∗) = θ∗ y can be determined from the model
parameters directly, and p(w) can be computed as
the empirical frequency of word w among all the
other words in all the training documents.
We then define a transformation matrix H E
Rn×m based on the mapping function φ defined in
Eq. (2), such that Hi: = φ(wi) where wi is the i-th
word in the vocabulary V. That is, each row of H
is the induced representation vector for one word. H
can be viewed as a soft word clustering matrix, and
Hi,j denotes the probability of word wi belongs to
the j-th cluster. Given the original document-word
frequency matrix Xtr E RT×n for the labeled train-
ing documents from the two domains, we can con-
struct its representations Ztr E RT×m in the pre-
dictive latent clustering space by performing the fol-
lowing transformation:
</bodyText>
<equation confidence="0.945131">
Ztr = XtrH. (4)
</equation>
<bodyText confidence="0.999814">
Similarly, we can construct the new representation
matrix Zts for the test data Xts in the target domain.
We then train a classification model on the labeled
data Ztr and apply it to classify the test data Zts.
</bodyText>
<sectionHeader confidence="0.999649" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.998512">
We evaluate the proposed approach with experi-
ments on cross domain document categorization of
Reuters data and cross domain sentiment classifi-
cation of Amazon product reviews, comparing to a
number of baseline and existing domain adaptation
methods. In this section, we report the experimental
setting and results on these two data sets.
</bodyText>
<listItem confidence="0.963232516129032">
(1) BOW: This is a bag-of-word baseline method,
which trains a SVM classifier with labeled data
from both domains using the original bag-of-
word features.
(2) PLSA: This is an unsupervised word clustering
method, which first applies the probabilistic la-
tent semantic analysis (PLSA) (Hofmann, 1999)
to obtain word clusterings with both labeled and
unlabeled data from the two domains and then
uses the soft word clusterings as augmenting
features to train SVM classifiers.
(3) FDLDA: This is an alternative supervised word
clustering method we built by training the
Fast-Discriminative Latent Dirichlet Allocation
model (Shan et al., 2009) with all labeled data
from the two domains. After training the model,
we used the learned topic distribution p(z) and
the conditional word distributions p(w|z) to
compute the conditional distribution over topics
p(z|w) for each word as the soft clustering of the
word. We then used the soft word clusterings as
augmenting features to train SVM classifiers.
(4) SCL: This is the structural correspondence
learning based domain adaptation method
(Blitzer et al., 2006). It first induces generaliz-
able features with all data from both domains
by modeling the correlations between pivot fea-
tures and non-pivot features, and then uses the
produced generalizable features as augmenting
features to train SVM classifiers.
(5) CPSP: This is coupled subspace learning based
</listItem>
<bodyText confidence="0.8156455">
domain adaptation method (Blitzer et al., 2011).
It first learns two domain projectors using all
data from the two domains by approximating
multi-view dimensionality reduction, and then
projects the labeled data to low dimensional la-
tent feature space to train SVM Classifiers.
We used the LIBSVM package (Chang and Lin,
2011) with its default parameter setting to train lin-
ear SVM classifiers as the base classification model
for all comparison methods.
</bodyText>
<equation confidence="0.984823666666667">
�y∈YP(w|c, θ∗)P(c|y, θ∗)P(y|θ∗)
P(c|w,θ∗)=
P( w)
</equation>
<page confidence="0.998965">
155
</page>
<tableCaption confidence="0.9531205">
Table 1: Average results (accuracy±standard deviation) for three cross-domain document categorization tasks on
Reuters-21578 dataset.
</tableCaption>
<table confidence="0.99494525">
Task BOW PLSA FDLDA SCL CPSP SWC
Orgs vs People 76.07±0.39 76.50±0.10 76.95±0.23 78.71±0.20 77.58±0.21 81.27±0.23
Orgs vs Places 73.88±0.58 74.68±0.20 74.87±0.29 76.71±0.23 75.76±0.28 78.33±0.64
People vs Places 61.80±0.44 63.36±0.40 63.46±0.40 64.65±0.40 62.73±0.53 67.48±0.20
</table>
<subsectionHeader confidence="0.992391">
4.2 Experiments on Reuters Data Set
</subsectionHeader>
<bodyText confidence="0.9999567">
We used the popularly studied Reuters-21578
dataset (Dai et al., 2007), which contains three cross-
domain document categorization tasks, Orgs vs Peo-
ple, Orgs vs Places, People vs Places. The source
and target domains of each task contain documents
sampled from different non-overlapping subcate-
gories. From example, the task of Orgs vs People
assigns a document into one of the two top cate-
gories (Orgs, People), and the source domain doc-
uments and the target domain documents are sam-
pled from different subcategories of Orgs and Peo-
ple. There are 1237 source documents and 1208 tar-
get documents for the task of Orgs vs People, 1016
source documents and 1043 target documents for the
task of Orgs vs Places, and 1077 source documents
and 1077 target documents for the task ofPeople vs
Places. For each task, we built a unigram vocabulary
based on all the documents from the two domains
and represented each document as a feature vector
containing term frequency values.
</bodyText>
<subsectionHeader confidence="0.959435">
4.2.1 Experimental Results for Cross-Domain
Document Categorization
</subsectionHeader>
<bodyText confidence="0.999462230769231">
For each of the three cross-domain document cat-
egorization tasks on Reuters-21578 dataset, we used
all the source documents as labeled training data
while randomly selecting 100 target documents as
labeled training data and setting the rest as unla-
beled test data. For the BOW baseline method, we
used the term-frequency features. The other five ap-
proaches are based on representation learning, and
we selected the dimension size of the representation
learning, i.e., the cluster number in our proposed ap-
proach, from 15, 10, 20, 50,100} according to the
average classification results over 3 runs on the task
of Orgs vs People. The dimension sizes of the in-
duced representations for the five approaches, PLSA,
FDLDA, SCL, CPSP and SWC are 20, 20, 100, 100
and 20 respectively.
We then repeated each experiment 10 times on
each task with different random selections of the 100
labeled target documents to compare the six compar-
ison approaches. The average classification results
in terms of accuracy and standard deviations are re-
ported in Table 1. We can see that by simply combin-
ing labeled documents from the two domains with-
out adaptation, the BOW method performs poorly
across the three tasks. The PLSA method outper-
forms the BOW method over all the three tasks with
small improvements. The supervised word cluster-
ing method FDLDA, though performing slightly bet-
ter than the unsupervised clustering method PLSA,
produces poor performance comparing to the pro-
posed SWC method. One possible reason is that
the FDLDA model is not specialized for supervised
word clustering, and it uses a logistic regression
model to predict the labels from the word topics,
while the final soft word clustering is computed from
the learned distribution p(z) and p(wjz). That is,
in the FDLDA model the labels only influence the
word clusterings indirectly and hence its influence
can be much smaller than the influence of labels as
direct parent variables of the word cluster variables
in the SWC model. The two domain adaptation ap-
proaches, SCL and CPSP, both produce significant
improvements over BOW, PLSA and FDLDA on the
two tasks of Orgs vs People and Orgs vs Places,
while the CPSP method produces slightly inferior
performance than PLSA and FDLDA on the task of
People vs Places. The proposed method SWC on
the other hand consistently and significantly outper-
forms all the other comparison methods across all
the three tasks.
We also studied the sensitivity of the proposed
approach with respect to the number of clusters,
</bodyText>
<page confidence="0.983518">
156
</page>
<figure confidence="0.9772955">
Reuters−21578
Number of Cluster
</figure>
<figureCaption confidence="0.999471">
Figure 2: Sensitivity analysis of the proposed approach
w.r.t. the number of clusters for the three cross-domain
document categorization tasks on Reuters-21578 dataset.
</figureCaption>
<bodyText confidence="0.999906166666667">
i.e., the dimension size of the learned representa-
tion. We experimented with a set of different val-
ues m E 15, 10, 20, 50,100} as the number of clus-
ters. For each m value, we used the same experimen-
tal setting as above and repeated the experiments 10
times to obtain the average comparison results. The
classification accuracy results on the three tasks are
reported in Figure 2. We can see that the proposed
method is not very sensitive to the number of clus-
ters, across the set of increasing values we consid-
ered, and its performance becomes very stable after
the cluster number reaches 20.
</bodyText>
<subsubsectionHeader confidence="0.717591">
4.2.2 Document Categorization Accuracy vs
</subsubsectionHeader>
<subsectionHeader confidence="0.67647">
Label Complexity in Target Domain
</subsectionHeader>
<bodyText confidence="0.999973043478261">
We next conducted experiments to compare the
six approaches by varying the amount of the labeled
data from the target domain. We tested a set of dif-
ferent values, s E 1100, 200, 300, 400, 500}, as the
number of labeled documents from the target do-
main. For each different s value, we repeated the ex-
periments 10 times by randomly selecting s labeled
documents from the target domain using the same
experimental setting as before. The comparison re-
sults across the set of s values are plotted in Fig-
ure 3. We can see that in general the performance of
each method improves with the increase of the num-
ber of labeled documents from the target domain.
The proposed method SWC and the domain adapta-
tion method SCL clearly outperform the other four
methods. Moreover, the proposed method SWC not
only maintains consistent and significant advantages
over all other methods across the range of differ-
ent s values, its performance with 300 labeled tar-
get instances is even superior to the other methods
with 500 labeled target instances. All these results
suggest the proposed approach is very effective for
adapting data across domains.
</bodyText>
<subsectionHeader confidence="0.997855">
4.3 Experiments on Amazon Product Reviews
</subsectionHeader>
<bodyText confidence="0.999932529411765">
We conducted cross-domain sentiment classification
on the widely used Amazon product reviews (Blitzer
et al., 2007), which contains review documents dis-
tributed in four categories: Books(B), DVD(D), Elec-
tronics(E) and Kitchen(K). Each category contains
1000 positive and 1000 negative reviews. We con-
structed 12 cross-domain sentiment classification
tasks, one for each source-target domain pair, B2D,
B2E, B2K, D2B, D2E, D2K, E2B, E2D, E2K, K2B,
K2D, K2E. For example, the task B2D means that
we use the Books reviews as the source domain and
the DVD reviews as the target domain. For each pair
of domains, we built a vocabulary with both uni-
gram and bigram features extracted from all the doc-
uments of the two domains, and then represented
each review document as a feature vector with term
frequency values.
</bodyText>
<subsectionHeader confidence="0.903499">
4.3.1 Experimental Results for Cross-Domain
Sentiment Classification
</subsectionHeader>
<bodyText confidence="0.993571277777778">
For each of the twelve cross-domain sentiment
classification tasks on Amazon product reviews, we
used all the source reviews as labeled data and ran-
domly selected 100 target reviews as labeled data
while treating the rest as unlabeled test data. For the
baseline method BOW, we used binary indicator val-
ues as features, which has been shown to work better
than the term-frequency features for sentiment clas-
sification tasks (Pang et al., 2002; Na et al., 2004).
For all the other representation learning based meth-
ods, we selected the dimension size of learned repre-
sentation according to the average results over 3 runs
on the B2D task. The dimension sizes selected for
the methods PLSA, FDLDA, SCL, CPSP, and SWC
are 10, 50, 50, 100 and 10, respectively.1
150 and 100 are also the suggested values for SCL (Blitzer
et al., 2007) and CPSP (Blitzer et al., 2011) respectively on this
cross-domain sentiment classification dataset.
</bodyText>
<figure confidence="0.975849272727273">
85
80
Accuracy
20 40 60 80 100
Orgs vs People
Orgs vs Places
People vs Places
75
70
65
60
</figure>
<page confidence="0.615594">
157
</page>
<figureCaption confidence="0.842124">
Figure 3: Average classification results for three cross-domain document categorization tasks on Reuters-21578 dataset
by varying the amount of labeled training data from the target domain.
</figureCaption>
<tableCaption confidence="0.933594">
Table 2: Average results (accuracy±standard deviation) for twelve cross-domain sentiment classification tasks on
Amazon product reviews.
</tableCaption>
<table confidence="0.962323857142857">
Task BOW PLSA FDLDA SCL CPSP SWC
B2D 76.58±0.14 76.01±0.10 75.95±0.16 80.17±0.16 77.53±0.14 81.66±0.23
B2K 75.48 ±0.34 74.68 ±0.20 74.87 ±0.15 78.13 ±0.21 76.38 ±0.15 82.26 ±0.20
B2E 72.92 ±0.37 73.36 ±0.19 73.46 ±0.21 74.79 ±0.19 73.31 ±0.17 77.04 ±0.64
D2B 74.10 ±0.29 74.04 ±0.20 74.08 ±0.18 78.73 ±0.23 77.07 ±0.15 79.95 ±0.25
D2K 75.19 ±0.33 75.37 ±0.31 75.44 ±0.31 76.98 ±0.19 76.77 ±0.10 82.13 ±0.20
D2E 73.01 ±0.34 74.21 ±0.30 74.09 ±0.31 75.69 ±0.25 73.83 ±0.21 76.98 ±0.54
E2B 67.58 ±0.24 68.48 ±0.15 68.44 ±0.17 70.21 ±0.16 70.47 ±0.16 72.11 ±0.46
E2D 70.15 ±0.27 70.16 ±0.23 70.06 ±0.22 72.83 ±0.25 71.76 ±0.20 73.81 ±0.59
E2K 82.23 ±0.12 82.24 ±0.18 82.26 ±0.19 84.69 ±0.11 81.31 ±0.14 85.33 ±0.16
K2B 70.67 ±0.18 72.18 ±0.21 72.18 ±0.16 73.91 ±0.21 72.18 ±0.19 75.78 ±0.55
K2D 71.51 ±0.26 72.00 ±0.18 72.05 ±0.19 74.82 ±0.26 72.59 ±0.18 76.88 ±0.49
K2E 80.81 ±0.12 80.39 ±0.18 80.46 ±0.18 82.96 ±0.11 80.81 ±0.14 84.78 ±0.19
Orgs vs People
</table>
<figure confidence="0.9894603">
Orgs vs Places
People vs Places
86
74
82
84
72
80
70
82
Accuracy
Accuracy
Accuracy
68
78
80
BOW
PLSA
FDLDA
SCL
CPSP
SWC
BOW
PLSA
FDLDA
SCL
CPSP
SWC
BOW
PLSA
FDLDA
SCL
CPSP
SWC
66
76
78
64
74
76
62
72
60
74
100 200 300 400 500
#Labeled instances
100 200 300 400 500
#Labeled instances
100 200 300 400 500
#Labeled instances
</figure>
<bodyText confidence="0.999887464285714">
We then repeated each experiment 10 times based
on different random selections of 100 labeled re-
views from the target domain to compare the six
methods on the twelve tasks. The average classifica-
tion results are reported in Table 2. We can see that
the PLSA and FDLDA methods do not show much
advantage over the baseline method BOW. CPSP
performs better than PLSA and BOW on many of
the twelve tasks, but with small advantages, while
SCL outperforms CPSP on most tasks. The proposed
method SWC however demonstrates a clear advan-
tage over all the other methods and produces the best
results on all the twelve tasks.
We also conducted sensitivity analysis over the
proposed approach regarding the number of clus-
ters on the twelve cross-domain sentiment classifi-
cation tasks, by testing a set of cluster number val-
ues m = 15, 10, 20, 50, 1001. The average results
are plotted in Figure 5. Similar as before, we can
see the proposed approach has stable performance
across the set of different cluster numbers. More-
over, these results also clearly show that domain
adaptation is not a symmetric process, as we can see
it is easier to conduct domain adaptation from the
source domain Books to the target domain Kitchen
(with an accuracy around 82%), but it is more diffi-
cult to make domain adaptation from the source do-
main Kitchen to the target domain Books (with an ac-
</bodyText>
<page confidence="0.982236">
158
</page>
<figure confidence="0.991447171779141">
B2D B2E B2K
80
82
82
78
Accuracy
Accuracy
78
76
74
76
74
72
78
76
74
80
BOW
PLSA
FDLDA
SCL
CPSP
SWC
100 200 300 400 500
#Labeled instances
BOW
PLSA
FDLDA
SCL
CPSP
SWC
70
100 200 300 400 500
#Labeled instances
80
BOW
PLSA
FDLDA
SCL
CPSP
SWC
100 200 300 400 500
#Labeled instances
D2B D2E D2K
80
78
76
76
74
74
72
72
100 200 300 400 500 100 200 300 400 500 100 200 300 400 500
100 200 300 400 500
100 200 300 400 500
100 200 300 400 500
#Labeled instances
#Labeled instances
#Labeled instances
#Labeled instances #Labeled instances #Labeled instances
E2B
E2D
E2K
E2B E2D E2K
74
80
82
BOW
PLSA
FDLDA
SCL
CPSP
SWC
Accuracy
78
BOW
PLSA
FDLDA
SCL
CPSP
SWC
Accuracy
80
78
76
74
BOW
PLSA
FDLDA
SCL
CPSP
SWC
78
88
76
86
72
74
70
72
68
70
66
68
100 200 300 400 500 100 200 300 400 500 100 200 300 400 500
100 200 300 400 500
100 200 300 400 500
100 200 300 400 500
#Labeled instances
#Labeled instances
#Labeled instances
#Labeled instances #Labeled instances #Labeled instances
K2B
K2D
K2E
K2B K2D K2E
BOW
PLSA
FDLDA
SCL
CPSP
SWC
Accuracy
BOW
PLSA
FDLDA
SCL
CPSP
SWC
Accuracy
84
82
80
78
76
BOW
PLSA
FDLDA
SCL
CPSP
SWC
78
86
76
84
76
Accuracy
Accuracy
74
74
72
72
70
70
68
100 200 300 400 500 100 200 300 400 500 100 200 300 400 500
100 200 300 400 500
100 200 300 400 500
100 200 300 400 500
#Labeled instances
#Labeled instances
#Labeled instances
#Labeled instances #Labeled instances #Labeled instances
</figure>
<figureCaption confidence="0.9369885">
Figure 4: Average results (accuracyfstandard deviation) for the 12 cross-domain sentiment classification tasks on
Amazon product reviews with different numbers of labeled training data from the target domain.
</figureCaption>
<figure confidence="0.997992576923077">
82
BOW
PLSA
FDLDA
SCL
CPSP
SWC
BOW
PLSA
FDLDA
SCL
CPSP
SWC
80
78
76
BOW
PLSA
FDLDA
SCL
CPSP
SWC
Accuracy
Accuracy
Accuracy
Accuracy
</figure>
<page confidence="0.788034">
159
</page>
<figureCaption confidence="0.991239">
Figure 5: Sensitivity analysis of the proposed approach wrt the number of clusters for the twelve cross-domain senti-
ment classification tasks. Each figure shows experimental results for three tasks with the same source domain.
</figureCaption>
<figure confidence="0.992595240740741">
84
84
86
74
74
72
Books
DVD
Kitchen
70
72
Books
Electronics
Kitchen
DVD
20 40 60 80 100
Number of cluster
20 40 60 80 100
Number of cluster
20 40 60 80 100
Number of cluster
20 40 60 80 100
Number of cluster
DVD
Kitchen
Electronics
85
82
82
84
Accuracy
80
78
76
Accuracy
80
78
76
Accuracy
80
75
Accuracy
82
80
78
76
Books
DVD
Electronics
Books
Kitchen
Electronics
74
72
</figure>
<bodyText confidence="0.999829">
curacy around 75%). It also shows that the degree of
relatedness of the two domains is an important factor
for the effectiveness of knowledge adaptation. For
example, one can see that it is much easier to con-
duct domain adaptation from Kitchen to Electronics
(with an accuracy around 84%) than from Kitchen to
Books (with an accuracy around 75%), as Kitchen is
more closely related to Electronics than Books.
</bodyText>
<subsectionHeader confidence="0.6408245">
4.3.2 Sentiment Classification Accuracy vs
Label Complexity in Target Domain
</subsectionHeader>
<bodyText confidence="0.999954">
Similar as before, we tested the proposed ap-
proach using a set of different values s E
1100, 200, 300, 400, 500} as the number of labeled
reviews from the target domain. For each given s
value, we conducted the comparison experiments us-
ing the same setting above. The average results are
reported in Figure 4. We can see that the perfor-
mance of each approach in general improves with
the increase of the number of labeled reviews from
the target domain. The proposed approach maintains
a clear advantage over all the other methods on all
the twelve tasks across different label complexities.
All those empirical results demonstrate the effec-
tiveness of the proposed approach for cross-domain
sentiment classification.
</bodyText>
<subsectionHeader confidence="0.652286">
4.3.3 Illustration of the Word Clusters
</subsectionHeader>
<bodyText confidence="0.999994473684211">
Finally, we would also like to demonstrate the
hard word clusters produced by the proposed su-
pervised word clustering method. We assign a word
into the cluster it most likely belongs to according
to its soft clustering representation, such as c* _
arg max, P(c|w, 0*). Table 3 presents the top repre-
sentative words (i.e., the most frequent words) of the
10 word clusters produced on the task of B2K. We
can see that the first three clusters (C1, C2, and C3)
contain words with positive sentiment polarity in
different degrees. The two clusters (C4 and C5) con-
tain words used to express the degree of opinions.
The next four clusters (C6, C7, C8, and C9) contain
content words related to Books or Kitchen. The last
cluster (C10) contains words of negative sentiment
polarity. These results demonstrate that the proposed
supervised word clustering can produce task mean-
ingful word clusters and hence label-informative la-
tent features, which justifies its effectiveness.
</bodyText>
<sectionHeader confidence="0.999656" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999987076923077">
In this paper, we proposed a novel supervised rep-
resentation learning method to tackle domain adap-
tation by inducing predictive latent features based
on supervised word clustering. With the soft word
clustering produced, we can transform all docu-
ments from the two domains into a unified low-
dimensional feature space for effective training of
cross-domain NLP prediction system. We conducted
extensive experiments on cross-domain document
categorization tasks on Reuters-21578 dataset and
cross-domain sentiment classification tasks on Ama-
zon product reviews. Our empirical results demon-
strated the efficacy of the proposed approach.
</bodyText>
<sectionHeader confidence="0.999152" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.945737">
S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira.
Analysis of representations for domain adapta-
</reference>
<page confidence="0.999335">
160
</page>
<tableCaption confidence="0.999805">
Table 3: Clustering illustration for the task of B2K on Amazon product reviews.
</tableCaption>
<footnote confidence="0.6600774">
C1 recommend excellent wonderful beautiful love powerful happy satisfied outstanding
C2 enjoyed fantastic glad i liked nicely was great benefits pleasure amazingly
C3 good and made me most people ordered this standards accurately check out
C4 was a kind of basically is only half of first of as if and still anything about have some
C5 ever may still going maybe either at least of all totally sort of are very
C6 life work machine size design bottom business picture hand hook gas sink turner shelves
C7 way coffee pan keep cooking maker heat job working children handle meet core wine
C8 people us world come fact man place stars during example went short bathroom apple price
C9 pot friends daily light fire tells knew holds keep the continued meal hooked silver wind
C10 disappointed waste unfortunately worse poorly sorry weak not worth stupid fails awful useless
</footnote>
<reference confidence="0.999614721311475">
tion. In Advances in Neural Information Process-
ing Systems (NIPS), 2006.
S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza,
F. Pereira, and J. Vaughan. A theory of learning
from different domains. Machine Learng, 79(1-
2):151–175, 2010.
D. Blei and J. McAuliffe. Supervised topic mod-
els. In Advances in Neural Information Process-
ing Systems (NIPS), 2007.
J. Blitzer, R. McDonald, and F. Pereira. Domain
adaptation with structural correspondence learn-
ing. In Proc. of the Conference on Empir-
ical Methods in Natural Language Processing
(EMNLP), 2006.
J. Blitzer, M. Dredze, and F. Pereira. Biographies,
bollywood, boom-boxes and blenders: Domain
adaptation for sentiment classification. In Proc.
of the Annual Meeting ofthe Association for Com-
putational Linguistics (ACL), 2007.
J. Blitzer, D. Foster, and S. Kakade. Domain adapta-
tion with coupled subspaces. In Proc. of the Inter-
national Conference on Artificial Intelligence and
Statistics (AISTATS), 2011.
C. Chang and C. Lin. LIBSVM: A library for sup-
port vector machines. ACM Transactions on In-
telligent Systems and Technology, 2:27:1–27:27,
2011.
M. Chen, K. Weinberger, and J. Blitzer. Co-training
for domain adaptation. In Advances in Neural In-
form. Process. Systems (NIPS), 2011.
M. Chen, Z. Xu, K. Weinberger, and F. Sha.
Marginalized denoising autoencoders for domain
adaptation. In Proc. of the International Conf. on
Machine Learning (ICML), 2012.
W. Dai, Q. Yang, G. Xue, and Y. Yu. Boosting for
transfer learning. In Proc. of the International
Conf. on Machine Learning (ICML), 2007.
H. Daum´e III. Frustratingly easy domain adaptation.
In Proc. of the Annual Meeting of the Association
for Comput. Linguistics (ACL), 2007.
H. Daum´e III, A. Kumar, and A. Saha. Co-
regularization based semi-supervised domain
adaptation. In Advances in Neural Information
Processing Systems (NIPS), 2010.
A. Dempster, N. Laird, and D. Rubin. Maximum
likelihood from incomplete data via the em algo-
rithm. Journal of the royal statistical society, 39
(1):1–38, 1977.
J. Finkel and C. Manning. Hierarchical bayesian
domain adaptation. In Proc. of the Conference
of the North American Chapter of the Association
for Computational Linguistics (NAACL), 2009.
T. Hofmann. Probabilistic latent semantic analysis.
In Proc. of the Conference on Uncertainty in Ar-
tificial Intelligence (UAI), 1999.
J. Jiang and C. Zhai. Instance weighting for domain
adaptation in nlp. In Proc. of the Annual Meeting
of the Association for Computational Linguistics
(ACL), 2007.
Y. Mejova and P. Srinivasan. Crossing media
streams with sentiment: Domain adaptation in
</reference>
<page confidence="0.976923">
161
</page>
<reference confidence="0.998733606060606">
blogs, reviews and twitter. In Proc. of the Inter-
national AAAI Conference on Weblogs and Social
Media (ICWSM), 2012.
J. Na, H. Sui, C. Khoo, S. Chan, and Y. Zhou. Effec-
tiveness of simple linguistic processing in auto-
matic sentiment classification of product reviews.
In Proc. of the Conf. of the Inter. Society for
Knowledge Organization, 2004.
B. Pang, L. Lee, and S. Vaithyanathan. Thumbs
up?: sentiment classification using machine learn-
ing techniques. In Proc. of the Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP), 2002.
P. Prettenhofer and B. Stein. Cross-language
text classification using structural correspondence
learning. In Proc. of the Annual Meeting of the
Association for Comput. Linguistics (ACL), 2010.
H. Shan, A. Banerjee, and N. Oza. Discriminative
mixed-membership models. In Proc. of the IEEE
Inter. Conference on Data Mining (ICDM), 2009.
M. Sugiyama, S. Nakajima, H. Kashima, P. von
B¨unau, and M. Kawanabe. Direct importance es-
timation with model selection and its application
to covariate shift adaptation. In Advances in Neu-
ral Information Processing Systems (NIPS), 2007.
S. Tan. Improving scl model for sentiment-transfer
learning. In Proc. of the Conference of the North
American Chapter of the Association for Compu-
tational Linguistics (NAACL), 2009.
C. Wan, R. Pan, and J. Li. Bi-weighting domain
adaptation for cross-language text classification.
In Proc. of the International Joint Conference on
Artificial Intelligence (IJCAI), 2011.
</reference>
<page confidence="0.997783">
162
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.599494">
<title confidence="0.998526">Learning Latent Word Representations for Domain using Supervised Word Clustering</title>
<author confidence="0.999829">Xiao Zhao</author>
<affiliation confidence="0.999514">Department of Computer and Information</affiliation>
<address confidence="0.8030305">Temple Philadelphia, PA 19122,</address>
<abstract confidence="0.999231148148148">Domain adaptation has been popularly studied on exploiting labeled information from a source domain to learn a prediction model in a target domain. In this paper, we develop a novel representation learning approach to address domain adaptation for text classification with automatically induced discriminative latent features, which are generalizable across domains while informative to the prediction task. Specifically, we propose a hierarchical multinomial Naive Bayes model with latent variables to conduct supervised word clustering on labeled documents from both source and target domains, and then use the produced cluster distribution of each word as its latent feature representation for domain adaptation. We train this latent graphical model using a simple expectation-maximization (EM) algorithm. We empirically evaluate the proposed method with both cross-domain document categorization tasks on Reuters-21578 dataset and cross-domain sentiment classification tasks on Amazon product review dataset. The experimental results demonstrate that our proposed approach achieves superior performance compared with alternative methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Ben-David</author>
<author>J Blitzer</author>
<author>K Crammer</author>
<author>F Pereira</author>
</authors>
<title>Analysis of representations for domain adaptation.</title>
<date>2006</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS),</booktitle>
<contexts>
<context position="1868" citStr="Ben-David et al., 2006" startWordPosition="259" endWordPosition="262">ion tasks on Amazon product review dataset. The experimental results demonstrate that our proposed approach achieves superior performance compared with alternative methods. 1 Introduction Supervised prediction models typically require a large amount of labeled data for training. However, manually collecting data annotations is expensive in many real-world applications such as document categorization or sentiment classification. Recently, domain adaptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution diverge</context>
</contexts>
<marker>Ben-David, Blitzer, Crammer, Pereira, 2006</marker>
<rawString>S. Ben-David, J. Blitzer, K. Crammer, and F. Pereira. Analysis of representations for domain adaptation. In Advances in Neural Information Processing Systems (NIPS), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Ben-David</author>
<author>J Blitzer</author>
<author>K Crammer</author>
<author>A Kulesza</author>
<author>F Pereira</author>
<author>J Vaughan</author>
</authors>
<title>A theory of learning from different domains. Machine Learng,</title>
<date>2010</date>
<pages>79--1</pages>
<marker>Ben-David, Blitzer, Crammer, Kulesza, Pereira, Vaughan, 2010</marker>
<rawString>S. Ben-David, J. Blitzer, K. Crammer, A. Kulesza, F. Pereira, and J. Vaughan. A theory of learning from different domains. Machine Learng, 79(1-2):151–175, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
<author>J McAuliffe</author>
</authors>
<title>Supervised topic models.</title>
<date>2007</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS),</booktitle>
<contexts>
<context position="10920" citStr="Blei and McAuliffe, 2007" startWordPosition="1655" endWordPosition="1658">or simplicity, we do not show the distribution parameter variables in the Figure. Following the Markov property of directed graphFigure 1: Supervised word clustering model. ical models, we can see that given the cluster variable values, the document label variables will be completely independent of the word variables. By learning this latent directed graphical model, we thus expect the important classification information expressed in the input observation words can be effectively summarized into the latent cluster variables. This latent model is much simpler than the supervised topic models (Blei and McAuliffe, 2007), but we will show later that it can suitably produce a generalizable feature mapping function for domain adaptation. To train the latent graphical model in Figure 1 on labeled documents D, we use a standard expectation-maximization (EM) algorithm (Dempster et al., 1977) to maximize the marginal loglikelihood of the observations: LL(D; 0) = � log P(yt,wt10) (1) t The EM algorithm is an iterative procedure. In each iteration, it takes an alternative E-step and M-step to maximize the lower bound of the marginal loglikelihood function. In our experiments, we start from a random initialization of </context>
</contexts>
<marker>Blei, McAuliffe, 2007</marker>
<rawString>D. Blei and J. McAuliffe. Supervised topic models. In Advances in Neural Information Processing Systems (NIPS), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Domain adaptation with structural correspondence learning.</title>
<date>2006</date>
<booktitle>In Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<contexts>
<context position="1890" citStr="Blitzer et al., 2006" startWordPosition="263" endWordPosition="266">uct review dataset. The experimental results demonstrate that our proposed approach achieves superior performance compared with alternative methods. 1 Introduction Supervised prediction models typically require a large amount of labeled data for training. However, manually collecting data annotations is expensive in many real-world applications such as document categorization or sentiment classification. Recently, domain adaptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution divergence of the two domains</context>
<context position="6298" citStr="Blitzer et al., 2006" startWordPosition="917" endWordPosition="920">ts to labeled data from the source domain than labeled data from the target domain. Dai et al. (2007) proposed to increase the weights of mistakenly predicted instances from the target domain and decrease the weights of incorrectly predicted instances from the source domain during an iterative training process. Representation learning methods bridge domain divergence either by differentiating domaininvariant features from domain-specific features (Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011; Finkel and Manning, 2009) or seeking generalizable latent features across domains (Blitzer et al., 2006, 2007; Prettenhofer and Stein, 2010). Daum´e III (2007); Daum´e III et al. (2010) proposed a simple heuristic feature replication method to represent common, source specific and target specific features. Finkel and Manning (2009) proposed a former version of it based on the use of a hierarchical Bayesian prior. Blitzer et al. (2011) proposed a coupled subspace learning method, which learns two projectors, one for each domain, to project the original features into domain-sharing and domainspecific features. Blitzer et al. (2006) proposed a structural correspondence learning (SCL) method to mod</context>
<context position="14944" citStr="Blitzer et al., 2006" startWordPosition="2324" endWordPosition="2327">his is an alternative supervised word clustering method we built by training the Fast-Discriminative Latent Dirichlet Allocation model (Shan et al., 2009) with all labeled data from the two domains. After training the model, we used the learned topic distribution p(z) and the conditional word distributions p(w|z) to compute the conditional distribution over topics p(z|w) for each word as the soft clustering of the word. We then used the soft word clusterings as augmenting features to train SVM classifiers. (4) SCL: This is the structural correspondence learning based domain adaptation method (Blitzer et al., 2006). It first induces generalizable features with all data from both domains by modeling the correlations between pivot features and non-pivot features, and then uses the produced generalizable features as augmenting features to train SVM classifiers. (5) CPSP: This is coupled subspace learning based domain adaptation method (Blitzer et al., 2011). It first learns two domain projectors using all data from the two domains by approximating multi-view dimensionality reduction, and then projects the labeled data to low dimensional latent feature space to train SVM Classifiers. We used the LIBSVM pack</context>
</contexts>
<marker>Blitzer, McDonald, Pereira, 2006</marker>
<rawString>J. Blitzer, R. McDonald, and F. Pereira. Domain adaptation with structural correspondence learning. In Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>M Dredze</author>
<author>F Pereira</author>
</authors>
<title>Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification.</title>
<date>2007</date>
<booktitle>In Proc. of the Annual Meeting ofthe Association for Computational Linguistics (ACL),</booktitle>
<contexts>
<context position="2204" citStr="Blitzer et al., 2007" startWordPosition="310" endWordPosition="313"> in many real-world applications such as document categorization or sentiment classification. Recently, domain adaptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution divergence of the two domains in the original feature representation space. For example, documents about books may contain very different high-frequency words and discriminative words from documents about kitchen. A good crossdomain feature representation thus has been viewed as critical for bridging the domain divergence gap and facilitatin</context>
<context position="7166" citStr="Blitzer et al., 2007" startWordPosition="1048" endWordPosition="1051"> version of it based on the use of a hierarchical Bayesian prior. Blitzer et al. (2011) proposed a coupled subspace learning method, which learns two projectors, one for each domain, to project the original features into domain-sharing and domainspecific features. Blitzer et al. (2006) proposed a structural correspondence learning (SCL) method to model the correlation between pivot features and non-pivot features. It uses the correlation to induce latent domain-invariant features as augmenting features for supervised learning. Extensions of this work include improving pivot feature selection (Blitzer et al., 2007; Prettenhofer and Stein, 2010), and improving the correlation modeling between pivot and non-pivot features (Tan, 2009). The proposed approach in this paper belongs to representation learning methods. However, unlike the unsupervised representation learning methods reviewed above, our proposed approach learns generalizable feature representations of words by exploiting data labels from the two domains. 3 Learning Latent Word Representations using Supervised Word Clustering In this paper, we address domain adaptation for text classification. Given a source domain DS with plenty of labeled docu</context>
<context position="21914" citStr="Blitzer et al., 2007" startWordPosition="3446" endWordPosition="3449">od SWC and the domain adaptation method SCL clearly outperform the other four methods. Moreover, the proposed method SWC not only maintains consistent and significant advantages over all other methods across the range of different s values, its performance with 300 labeled target instances is even superior to the other methods with 500 labeled target instances. All these results suggest the proposed approach is very effective for adapting data across domains. 4.3 Experiments on Amazon Product Reviews We conducted cross-domain sentiment classification on the widely used Amazon product reviews (Blitzer et al., 2007), which contains review documents distributed in four categories: Books(B), DVD(D), Electronics(E) and Kitchen(K). Each category contains 1000 positive and 1000 negative reviews. We constructed 12 cross-domain sentiment classification tasks, one for each source-target domain pair, B2D, B2E, B2K, D2B, D2E, D2K, E2B, E2D, E2K, K2B, K2D, K2E. For example, the task B2D means that we use the Books reviews as the source domain and the DVD reviews as the target domain. For each pair of domains, we built a vocabulary with both unigram and bigram features extracted from all the documents of the two dom</context>
<context position="23509" citStr="Blitzer et al., 2007" startWordPosition="3709" endWordPosition="3712">ing the rest as unlabeled test data. For the baseline method BOW, we used binary indicator values as features, which has been shown to work better than the term-frequency features for sentiment classification tasks (Pang et al., 2002; Na et al., 2004). For all the other representation learning based methods, we selected the dimension size of learned representation according to the average results over 3 runs on the B2D task. The dimension sizes selected for the methods PLSA, FDLDA, SCL, CPSP, and SWC are 10, 50, 50, 100 and 10, respectively.1 150 and 100 are also the suggested values for SCL (Blitzer et al., 2007) and CPSP (Blitzer et al., 2011) respectively on this cross-domain sentiment classification dataset. 85 80 Accuracy 20 40 60 80 100 Orgs vs People Orgs vs Places People vs Places 75 70 65 60 157 Figure 3: Average classification results for three cross-domain document categorization tasks on Reuters-21578 dataset by varying the amount of labeled training data from the target domain. Table 2: Average results (accuracy±standard deviation) for twelve cross-domain sentiment classification tasks on Amazon product reviews. Task BOW PLSA FDLDA SCL CPSP SWC B2D 76.58±0.14 76.01±0.10 75.95±0.16 80.17±0.</context>
</contexts>
<marker>Blitzer, Dredze, Pereira, 2007</marker>
<rawString>J. Blitzer, M. Dredze, and F. Pereira. Biographies, bollywood, boom-boxes and blenders: Domain adaptation for sentiment classification. In Proc. of the Annual Meeting ofthe Association for Computational Linguistics (ACL), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Blitzer</author>
<author>D Foster</author>
<author>S Kakade</author>
</authors>
<title>Domain adaptation with coupled subspaces.</title>
<date>2011</date>
<booktitle>In Proc. of the International Conference on Artificial Intelligence and Statistics (AISTATS),</booktitle>
<contexts>
<context position="1930" citStr="Blitzer et al., 2011" startWordPosition="270" endWordPosition="273">ults demonstrate that our proposed approach achieves superior performance compared with alternative methods. 1 Introduction Supervised prediction models typically require a large amount of labeled data for training. However, manually collecting data annotations is expensive in many real-world applications such as document categorization or sentiment classification. Recently, domain adaptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution divergence of the two domains in the original feature representation </context>
<context position="6193" citStr="Blitzer et al., 2011" startWordPosition="902" endWordPosition="905">ackle cross-domain NLP tasks and proposed to remove misleading source training data and assign less weights to labeled data from the source domain than labeled data from the target domain. Dai et al. (2007) proposed to increase the weights of mistakenly predicted instances from the target domain and decrease the weights of incorrectly predicted instances from the source domain during an iterative training process. Representation learning methods bridge domain divergence either by differentiating domaininvariant features from domain-specific features (Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011; Finkel and Manning, 2009) or seeking generalizable latent features across domains (Blitzer et al., 2006, 2007; Prettenhofer and Stein, 2010). Daum´e III (2007); Daum´e III et al. (2010) proposed a simple heuristic feature replication method to represent common, source specific and target specific features. Finkel and Manning (2009) proposed a former version of it based on the use of a hierarchical Bayesian prior. Blitzer et al. (2011) proposed a coupled subspace learning method, which learns two projectors, one for each domain, to project the original features into domain-sharing and domains</context>
<context position="15290" citStr="Blitzer et al., 2011" startWordPosition="2376" endWordPosition="2379">ribution over topics p(z|w) for each word as the soft clustering of the word. We then used the soft word clusterings as augmenting features to train SVM classifiers. (4) SCL: This is the structural correspondence learning based domain adaptation method (Blitzer et al., 2006). It first induces generalizable features with all data from both domains by modeling the correlations between pivot features and non-pivot features, and then uses the produced generalizable features as augmenting features to train SVM classifiers. (5) CPSP: This is coupled subspace learning based domain adaptation method (Blitzer et al., 2011). It first learns two domain projectors using all data from the two domains by approximating multi-view dimensionality reduction, and then projects the labeled data to low dimensional latent feature space to train SVM Classifiers. We used the LIBSVM package (Chang and Lin, 2011) with its default parameter setting to train linear SVM classifiers as the base classification model for all comparison methods. �y∈YP(w|c, θ∗)P(c|y, θ∗)P(y|θ∗) P(c|w,θ∗)= P( w) 155 Table 1: Average results (accuracy±standard deviation) for three cross-domain document categorization tasks on Reuters-21578 dataset. Task </context>
<context position="23541" citStr="Blitzer et al., 2011" startWordPosition="3715" endWordPosition="3718">ata. For the baseline method BOW, we used binary indicator values as features, which has been shown to work better than the term-frequency features for sentiment classification tasks (Pang et al., 2002; Na et al., 2004). For all the other representation learning based methods, we selected the dimension size of learned representation according to the average results over 3 runs on the B2D task. The dimension sizes selected for the methods PLSA, FDLDA, SCL, CPSP, and SWC are 10, 50, 50, 100 and 10, respectively.1 150 and 100 are also the suggested values for SCL (Blitzer et al., 2007) and CPSP (Blitzer et al., 2011) respectively on this cross-domain sentiment classification dataset. 85 80 Accuracy 20 40 60 80 100 Orgs vs People Orgs vs Places People vs Places 75 70 65 60 157 Figure 3: Average classification results for three cross-domain document categorization tasks on Reuters-21578 dataset by varying the amount of labeled training data from the target domain. Table 2: Average results (accuracy±standard deviation) for twelve cross-domain sentiment classification tasks on Amazon product reviews. Task BOW PLSA FDLDA SCL CPSP SWC B2D 76.58±0.14 76.01±0.10 75.95±0.16 80.17±0.16 77.53±0.14 81.66±0.23 B2K 75.</context>
</contexts>
<marker>Blitzer, Foster, Kakade, 2011</marker>
<rawString>J. Blitzer, D. Foster, and S. Kakade. Domain adaptation with coupled subspaces. In Proc. of the International Conference on Artificial Intelligence and Statistics (AISTATS), 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Chang</author>
<author>C Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>2</volume>
<contexts>
<context position="15569" citStr="Chang and Lin, 2011" startWordPosition="2420" endWordPosition="2423">first induces generalizable features with all data from both domains by modeling the correlations between pivot features and non-pivot features, and then uses the produced generalizable features as augmenting features to train SVM classifiers. (5) CPSP: This is coupled subspace learning based domain adaptation method (Blitzer et al., 2011). It first learns two domain projectors using all data from the two domains by approximating multi-view dimensionality reduction, and then projects the labeled data to low dimensional latent feature space to train SVM Classifiers. We used the LIBSVM package (Chang and Lin, 2011) with its default parameter setting to train linear SVM classifiers as the base classification model for all comparison methods. �y∈YP(w|c, θ∗)P(c|y, θ∗)P(y|θ∗) P(c|w,θ∗)= P( w) 155 Table 1: Average results (accuracy±standard deviation) for three cross-domain document categorization tasks on Reuters-21578 dataset. Task BOW PLSA FDLDA SCL CPSP SWC Orgs vs People 76.07±0.39 76.50±0.10 76.95±0.23 78.71±0.20 77.58±0.21 81.27±0.23 Orgs vs Places 73.88±0.58 74.68±0.20 74.87±0.29 76.71±0.23 75.76±0.28 78.33±0.64 People vs Places 61.80±0.44 63.36±0.40 63.46±0.40 64.65±0.40 62.73±0.53 67.48±0.20 4.2 Ex</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>C. Chang and C. Lin. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chen</author>
<author>K Weinberger</author>
<author>J Blitzer</author>
</authors>
<title>Co-training for domain adaptation.</title>
<date>2011</date>
<booktitle>In Advances in Neural Inform. Process. Systems (NIPS),</booktitle>
<contexts>
<context position="2272" citStr="Chen et al., 2011" startWordPosition="322" endWordPosition="325">ntiment classification. Recently, domain adaptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution divergence of the two domains in the original feature representation space. For example, documents about books may contain very different high-frequency words and discriminative words from documents about kitchen. A good crossdomain feature representation thus has been viewed as critical for bridging the domain divergence gap and facilitating domain adaptation in the NLP area (Ben-David et al., 2006, 2010). </context>
</contexts>
<marker>Chen, Weinberger, Blitzer, 2011</marker>
<rawString>M. Chen, K. Weinberger, and J. Blitzer. Co-training for domain adaptation. In Advances in Neural Inform. Process. Systems (NIPS), 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Chen</author>
<author>Z Xu</author>
<author>K Weinberger</author>
<author>F Sha</author>
</authors>
<title>Marginalized denoising autoencoders for domain adaptation.</title>
<date>2012</date>
<booktitle>In Proc. of the International Conf. on Machine Learning (ICML),</booktitle>
<contexts>
<context position="1950" citStr="Chen et al., 2012" startWordPosition="274" endWordPosition="277">our proposed approach achieves superior performance compared with alternative methods. 1 Introduction Supervised prediction models typically require a large amount of labeled data for training. However, manually collecting data annotations is expensive in many real-world applications such as document categorization or sentiment classification. Recently, domain adaptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution divergence of the two domains in the original feature representation space. For example, </context>
</contexts>
<marker>Chen, Xu, Weinberger, Sha, 2012</marker>
<rawString>M. Chen, Z. Xu, K. Weinberger, and F. Sha. Marginalized denoising autoencoders for domain adaptation. In Proc. of the International Conf. on Machine Learning (ICML), 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Dai</author>
<author>Q Yang</author>
<author>G Xue</author>
<author>Y Yu</author>
</authors>
<title>Boosting for transfer learning.</title>
<date>2007</date>
<booktitle>In Proc. of the International Conf. on Machine Learning (ICML),</booktitle>
<contexts>
<context position="2156" citStr="Dai et al., 2007" startWordPosition="304" endWordPosition="307">ally collecting data annotations is expensive in many real-world applications such as document categorization or sentiment classification. Recently, domain adaptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution divergence of the two domains in the original feature representation space. For example, documents about books may contain very different high-frequency words and discriminative words from documents about kitchen. A good crossdomain feature representation thus has been viewed as critical for br</context>
<context position="5779" citStr="Dai et al. (2007)" startWordPosition="843" endWordPosition="846">stance weighting adaptation methods and feature representation learning methods. Instance weighting adaptation methods improve the transferability of a prediction model by training an instance weighted learning system. Much work in this category has been developed to address different weighting schemas (Sugiyama et al., 2007; Wan et al., 2011). Jiang and Zhai (2007) applied instance weighting algorithms to tackle cross-domain NLP tasks and proposed to remove misleading source training data and assign less weights to labeled data from the source domain than labeled data from the target domain. Dai et al. (2007) proposed to increase the weights of mistakenly predicted instances from the target domain and decrease the weights of incorrectly predicted instances from the source domain during an iterative training process. Representation learning methods bridge domain divergence either by differentiating domaininvariant features from domain-specific features (Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011; Finkel and Manning, 2009) or seeking generalizable latent features across domains (Blitzer et al., 2006, 2007; Prettenhofer and Stein, 2010). Daum´e III (2007); Daum´e III et al. (2010</context>
<context position="16269" citStr="Dai et al., 2007" startWordPosition="2513" endWordPosition="2516">ssification model for all comparison methods. �y∈YP(w|c, θ∗)P(c|y, θ∗)P(y|θ∗) P(c|w,θ∗)= P( w) 155 Table 1: Average results (accuracy±standard deviation) for three cross-domain document categorization tasks on Reuters-21578 dataset. Task BOW PLSA FDLDA SCL CPSP SWC Orgs vs People 76.07±0.39 76.50±0.10 76.95±0.23 78.71±0.20 77.58±0.21 81.27±0.23 Orgs vs Places 73.88±0.58 74.68±0.20 74.87±0.29 76.71±0.23 75.76±0.28 78.33±0.64 People vs Places 61.80±0.44 63.36±0.40 63.46±0.40 64.65±0.40 62.73±0.53 67.48±0.20 4.2 Experiments on Reuters Data Set We used the popularly studied Reuters-21578 dataset (Dai et al., 2007), which contains three crossdomain document categorization tasks, Orgs vs People, Orgs vs Places, People vs Places. The source and target domains of each task contain documents sampled from different non-overlapping subcategories. From example, the task of Orgs vs People assigns a document into one of the two top categories (Orgs, People), and the source domain documents and the target domain documents are sampled from different subcategories of Orgs and People. There are 1237 source documents and 1208 target documents for the task of Orgs vs People, 1016 source documents and 1043 target docum</context>
</contexts>
<marker>Dai, Yang, Xue, Yu, 2007</marker>
<rawString>W. Dai, Q. Yang, G. Xue, and Y. Yu. Boosting for transfer learning. In Proc. of the International Conf. on Machine Learning (ICML), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Daum´e</author>
</authors>
<title>Frustratingly easy domain adaptation.</title>
<date>2007</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Comput. Linguistics (ACL),</booktitle>
<marker>Daum´e, 2007</marker>
<rawString>H. Daum´e III. Frustratingly easy domain adaptation. In Proc. of the Annual Meeting of the Association for Comput. Linguistics (ACL), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Daum´e A Kumar</author>
<author>A Saha</author>
</authors>
<title>Coregularization based semi-supervised domain adaptation.</title>
<date>2010</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS),</booktitle>
<marker>Kumar, Saha, 2010</marker>
<rawString>H. Daum´e III, A. Kumar, and A. Saha. Coregularization based semi-supervised domain adaptation. In Advances in Neural Information Processing Systems (NIPS), 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dempster</author>
<author>N Laird</author>
<author>D Rubin</author>
</authors>
<title>Maximum likelihood from incomplete data via the em algorithm.</title>
<date>1977</date>
<journal>Journal of the royal statistical society,</journal>
<volume>39</volume>
<contexts>
<context position="11191" citStr="Dempster et al., 1977" startWordPosition="1698" endWordPosition="1702">completely independent of the word variables. By learning this latent directed graphical model, we thus expect the important classification information expressed in the input observation words can be effectively summarized into the latent cluster variables. This latent model is much simpler than the supervised topic models (Blei and McAuliffe, 2007), but we will show later that it can suitably produce a generalizable feature mapping function for domain adaptation. To train the latent graphical model in Figure 1 on labeled documents D, we use a standard expectation-maximization (EM) algorithm (Dempster et al., 1977) to maximize the marginal loglikelihood of the observations: LL(D; 0) = � log P(yt,wt10) (1) t The EM algorithm is an iterative procedure. In each iteration, it takes an alternative E-step and M-step to maximize the lower bound of the marginal loglikelihood function. In our experiments, we start from a random initialization of the model parameters and the latent variable values, and then perform iterative EM updates until converge to a local optimal solution. 3.2 Induced Word Representation After training the supervised clustering model using EM algorithm, a set of local optimal model paramete</context>
</contexts>
<marker>Dempster, Laird, Rubin, 1977</marker>
<rawString>A. Dempster, N. Laird, and D. Rubin. Maximum likelihood from incomplete data via the em algorithm. Journal of the royal statistical society, 39 (1):1–38, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Finkel</author>
<author>C Manning</author>
</authors>
<title>Hierarchical bayesian domain adaptation.</title>
<date>2009</date>
<booktitle>In Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<contexts>
<context position="6220" citStr="Finkel and Manning, 2009" startWordPosition="906" endWordPosition="909"> tasks and proposed to remove misleading source training data and assign less weights to labeled data from the source domain than labeled data from the target domain. Dai et al. (2007) proposed to increase the weights of mistakenly predicted instances from the target domain and decrease the weights of incorrectly predicted instances from the source domain during an iterative training process. Representation learning methods bridge domain divergence either by differentiating domaininvariant features from domain-specific features (Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011; Finkel and Manning, 2009) or seeking generalizable latent features across domains (Blitzer et al., 2006, 2007; Prettenhofer and Stein, 2010). Daum´e III (2007); Daum´e III et al. (2010) proposed a simple heuristic feature replication method to represent common, source specific and target specific features. Finkel and Manning (2009) proposed a former version of it based on the use of a hierarchical Bayesian prior. Blitzer et al. (2011) proposed a coupled subspace learning method, which learns two projectors, one for each domain, to project the original features into domain-sharing and domainspecific features. Blitzer e</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>J. Finkel and C. Manning. Hierarchical bayesian domain adaptation. In Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Hofmann</author>
</authors>
<title>Probabilistic latent semantic analysis.</title>
<date>1999</date>
<booktitle>In Proc. of the Conference on Uncertainty in Artificial Intelligence (UAI),</booktitle>
<contexts>
<context position="14136" citStr="Hofmann, 1999" startWordPosition="2201" endWordPosition="2202">sed approach with experiments on cross domain document categorization of Reuters data and cross domain sentiment classification of Amazon product reviews, comparing to a number of baseline and existing domain adaptation methods. In this section, we report the experimental setting and results on these two data sets. (1) BOW: This is a bag-of-word baseline method, which trains a SVM classifier with labeled data from both domains using the original bag-ofword features. (2) PLSA: This is an unsupervised word clustering method, which first applies the probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) to obtain word clusterings with both labeled and unlabeled data from the two domains and then uses the soft word clusterings as augmenting features to train SVM classifiers. (3) FDLDA: This is an alternative supervised word clustering method we built by training the Fast-Discriminative Latent Dirichlet Allocation model (Shan et al., 2009) with all labeled data from the two domains. After training the model, we used the learned topic distribution p(z) and the conditional word distributions p(w|z) to compute the conditional distribution over topics p(z|w) for each word as the soft clustering of</context>
</contexts>
<marker>Hofmann, 1999</marker>
<rawString>T. Hofmann. Probabilistic latent semantic analysis. In Proc. of the Conference on Uncertainty in Artificial Intelligence (UAI), 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Jiang</author>
<author>C Zhai</author>
</authors>
<title>Instance weighting for domain adaptation in nlp.</title>
<date>2007</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<contexts>
<context position="2317" citStr="Jiang and Zhai, 2007" startWordPosition="329" endWordPosition="332">daptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution divergence of the two domains in the original feature representation space. For example, documents about books may contain very different high-frequency words and discriminative words from documents about kitchen. A good crossdomain feature representation thus has been viewed as critical for bridging the domain divergence gap and facilitating domain adaptation in the NLP area (Ben-David et al., 2006, 2010). Many domain adaptation works have been propos</context>
<context position="5530" citStr="Jiang and Zhai (2007)" startWordPosition="804" endWordPosition="807"> effective representations than the comparison domain adaptation methods. 2 Related Work Domain adaptation has recently been popularly studied in natural language processing and a variety of domain adaptation approaches have been developed, including instance weighting adaptation methods and feature representation learning methods. Instance weighting adaptation methods improve the transferability of a prediction model by training an instance weighted learning system. Much work in this category has been developed to address different weighting schemas (Sugiyama et al., 2007; Wan et al., 2011). Jiang and Zhai (2007) applied instance weighting algorithms to tackle cross-domain NLP tasks and proposed to remove misleading source training data and assign less weights to labeled data from the source domain than labeled data from the target domain. Dai et al. (2007) proposed to increase the weights of mistakenly predicted instances from the target domain and decrease the weights of incorrectly predicted instances from the source domain during an iterative training process. Representation learning methods bridge domain divergence either by differentiating domaininvariant features from domain-specific features (</context>
</contexts>
<marker>Jiang, Zhai, 2007</marker>
<rawString>J. Jiang and C. Zhai. Instance weighting for domain adaptation in nlp. In Proc. of the Annual Meeting of the Association for Computational Linguistics (ACL), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Mejova</author>
<author>P Srinivasan</author>
</authors>
<title>Crossing media streams with sentiment: Domain adaptation in blogs, reviews and twitter.</title>
<date>2012</date>
<booktitle>In Proc. of the International AAAI Conference on Weblogs and Social Media (ICWSM),</booktitle>
<contexts>
<context position="2252" citStr="Mejova and Srinivasan, 2012" startWordPosition="318" endWordPosition="321">document categorization or sentiment classification. Recently, domain adaptation has been proposed to exploit existing labeled data in a related source domain to assist the prediction model training in the target domain (Ben-David et al., 2006; Blitzer et al., 2006; Daum´e III, 2007; Blitzer et al., 2011; Chen et al., 2012). As an effective tool to reduce annotation effort, domain adaptation has achieved success in various crossdomain natural language processing (NLP) systems such as document categorization (Dai et al., 2007), sentiment classification (Blitzer et al., 2007; Chen et al., 2012; Mejova and Srinivasan, 2012; Chen et al., 2011), email spam detection (Jiang and Zhai, 2007), and a number of other NLP tasks (Blitzer et al., 2011; Daum´e III, 2007). One primary challenge of domain adaptation lies in the distribution divergence of the two domains in the original feature representation space. For example, documents about books may contain very different high-frequency words and discriminative words from documents about kitchen. A good crossdomain feature representation thus has been viewed as critical for bridging the domain divergence gap and facilitating domain adaptation in the NLP area (Ben-David e</context>
</contexts>
<marker>Mejova, Srinivasan, 2012</marker>
<rawString>Y. Mejova and P. Srinivasan. Crossing media streams with sentiment: Domain adaptation in blogs, reviews and twitter. In Proc. of the International AAAI Conference on Weblogs and Social Media (ICWSM), 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Na</author>
<author>H Sui</author>
<author>C Khoo</author>
<author>S Chan</author>
<author>Y Zhou</author>
</authors>
<title>Effectiveness of simple linguistic processing in automatic sentiment classification of product reviews.</title>
<date>2004</date>
<booktitle>In Proc. of the Conf. of the Inter. Society for Knowledge Organization,</booktitle>
<contexts>
<context position="23139" citStr="Na et al., 2004" startWordPosition="3644" endWordPosition="3647"> then represented each review document as a feature vector with term frequency values. 4.3.1 Experimental Results for Cross-Domain Sentiment Classification For each of the twelve cross-domain sentiment classification tasks on Amazon product reviews, we used all the source reviews as labeled data and randomly selected 100 target reviews as labeled data while treating the rest as unlabeled test data. For the baseline method BOW, we used binary indicator values as features, which has been shown to work better than the term-frequency features for sentiment classification tasks (Pang et al., 2002; Na et al., 2004). For all the other representation learning based methods, we selected the dimension size of learned representation according to the average results over 3 runs on the B2D task. The dimension sizes selected for the methods PLSA, FDLDA, SCL, CPSP, and SWC are 10, 50, 50, 100 and 10, respectively.1 150 and 100 are also the suggested values for SCL (Blitzer et al., 2007) and CPSP (Blitzer et al., 2011) respectively on this cross-domain sentiment classification dataset. 85 80 Accuracy 20 40 60 80 100 Orgs vs People Orgs vs Places People vs Places 75 70 65 60 157 Figure 3: Average classification re</context>
</contexts>
<marker>Na, Sui, Khoo, Chan, Zhou, 2004</marker>
<rawString>J. Na, H. Sui, C. Khoo, S. Chan, and Y. Zhou. Effectiveness of simple linguistic processing in automatic sentiment classification of product reviews. In Proc. of the Conf. of the Inter. Society for Knowledge Organization, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
<author>S Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<contexts>
<context position="23121" citStr="Pang et al., 2002" startWordPosition="3640" endWordPosition="3643">he two domains, and then represented each review document as a feature vector with term frequency values. 4.3.1 Experimental Results for Cross-Domain Sentiment Classification For each of the twelve cross-domain sentiment classification tasks on Amazon product reviews, we used all the source reviews as labeled data and randomly selected 100 target reviews as labeled data while treating the rest as unlabeled test data. For the baseline method BOW, we used binary indicator values as features, which has been shown to work better than the term-frequency features for sentiment classification tasks (Pang et al., 2002; Na et al., 2004). For all the other representation learning based methods, we selected the dimension size of learned representation according to the average results over 3 runs on the B2D task. The dimension sizes selected for the methods PLSA, FDLDA, SCL, CPSP, and SWC are 10, 50, 50, 100 and 10, respectively.1 150 and 100 are also the suggested values for SCL (Blitzer et al., 2007) and CPSP (Blitzer et al., 2011) respectively on this cross-domain sentiment classification dataset. 85 80 Accuracy 20 40 60 80 100 Orgs vs People Orgs vs Places People vs Places 75 70 65 60 157 Figure 3: Average</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>B. Pang, L. Lee, and S. Vaithyanathan. Thumbs up?: sentiment classification using machine learning techniques. In Proc. of the Conference on Empirical Methods in Natural Language Processing (EMNLP), 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Prettenhofer</author>
<author>B Stein</author>
</authors>
<title>Cross-language text classification using structural correspondence learning.</title>
<date>2010</date>
<booktitle>In Proc. of the Annual Meeting of the Association for Comput. Linguistics (ACL),</booktitle>
<contexts>
<context position="6335" citStr="Prettenhofer and Stein, 2010" startWordPosition="922" endWordPosition="925">source domain than labeled data from the target domain. Dai et al. (2007) proposed to increase the weights of mistakenly predicted instances from the target domain and decrease the weights of incorrectly predicted instances from the source domain during an iterative training process. Representation learning methods bridge domain divergence either by differentiating domaininvariant features from domain-specific features (Daum´e III, 2007; Daum´e III et al., 2010; Blitzer et al., 2011; Finkel and Manning, 2009) or seeking generalizable latent features across domains (Blitzer et al., 2006, 2007; Prettenhofer and Stein, 2010). Daum´e III (2007); Daum´e III et al. (2010) proposed a simple heuristic feature replication method to represent common, source specific and target specific features. Finkel and Manning (2009) proposed a former version of it based on the use of a hierarchical Bayesian prior. Blitzer et al. (2011) proposed a coupled subspace learning method, which learns two projectors, one for each domain, to project the original features into domain-sharing and domainspecific features. Blitzer et al. (2006) proposed a structural correspondence learning (SCL) method to model the correlation between pivot feat</context>
</contexts>
<marker>Prettenhofer, Stein, 2010</marker>
<rawString>P. Prettenhofer and B. Stein. Cross-language text classification using structural correspondence learning. In Proc. of the Annual Meeting of the Association for Comput. Linguistics (ACL), 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Shan</author>
<author>A Banerjee</author>
<author>N Oza</author>
</authors>
<title>Discriminative mixed-membership models.</title>
<date>2009</date>
<booktitle>In Proc. of the IEEE Inter. Conference on Data Mining (ICDM),</booktitle>
<contexts>
<context position="14477" citStr="Shan et al., 2009" startWordPosition="2251" endWordPosition="2254">ag-of-word baseline method, which trains a SVM classifier with labeled data from both domains using the original bag-ofword features. (2) PLSA: This is an unsupervised word clustering method, which first applies the probabilistic latent semantic analysis (PLSA) (Hofmann, 1999) to obtain word clusterings with both labeled and unlabeled data from the two domains and then uses the soft word clusterings as augmenting features to train SVM classifiers. (3) FDLDA: This is an alternative supervised word clustering method we built by training the Fast-Discriminative Latent Dirichlet Allocation model (Shan et al., 2009) with all labeled data from the two domains. After training the model, we used the learned topic distribution p(z) and the conditional word distributions p(w|z) to compute the conditional distribution over topics p(z|w) for each word as the soft clustering of the word. We then used the soft word clusterings as augmenting features to train SVM classifiers. (4) SCL: This is the structural correspondence learning based domain adaptation method (Blitzer et al., 2006). It first induces generalizable features with all data from both domains by modeling the correlations between pivot features and non</context>
</contexts>
<marker>Shan, Banerjee, Oza, 2009</marker>
<rawString>H. Shan, A. Banerjee, and N. Oza. Discriminative mixed-membership models. In Proc. of the IEEE Inter. Conference on Data Mining (ICDM), 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Sugiyama</author>
<author>S Nakajima</author>
<author>H Kashima</author>
<author>P von B¨unau</author>
<author>M Kawanabe</author>
</authors>
<title>Direct importance estimation with model selection and its application to covariate shift adaptation.</title>
<date>2007</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS),</booktitle>
<marker>Sugiyama, Nakajima, Kashima, von B¨unau, Kawanabe, 2007</marker>
<rawString>M. Sugiyama, S. Nakajima, H. Kashima, P. von B¨unau, and M. Kawanabe. Direct importance estimation with model selection and its application to covariate shift adaptation. In Advances in Neural Information Processing Systems (NIPS), 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Tan</author>
</authors>
<title>Improving scl model for sentiment-transfer learning.</title>
<date>2009</date>
<booktitle>In Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL),</booktitle>
<contexts>
<context position="7286" citStr="Tan, 2009" startWordPosition="1066" endWordPosition="1067">d, which learns two projectors, one for each domain, to project the original features into domain-sharing and domainspecific features. Blitzer et al. (2006) proposed a structural correspondence learning (SCL) method to model the correlation between pivot features and non-pivot features. It uses the correlation to induce latent domain-invariant features as augmenting features for supervised learning. Extensions of this work include improving pivot feature selection (Blitzer et al., 2007; Prettenhofer and Stein, 2010), and improving the correlation modeling between pivot and non-pivot features (Tan, 2009). The proposed approach in this paper belongs to representation learning methods. However, unlike the unsupervised representation learning methods reviewed above, our proposed approach learns generalizable feature representations of words by exploiting data labels from the two domains. 3 Learning Latent Word Representations using Supervised Word Clustering In this paper, we address domain adaptation for text classification. Given a source domain DS with plenty of labeled documents, and a target domain DT with a very few labeled documents, the task is to learn a classifier from the labeled docu</context>
</contexts>
<marker>Tan, 2009</marker>
<rawString>S. Tan. Improving scl model for sentiment-transfer learning. In Proc. of the Conference of the North American Chapter of the Association for Computational Linguistics (NAACL), 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wan</author>
<author>R Pan</author>
<author>J Li</author>
</authors>
<title>Bi-weighting domain adaptation for cross-language text classification.</title>
<date>2011</date>
<booktitle>In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<contexts>
<context position="5507" citStr="Wan et al., 2011" startWordPosition="800" endWordPosition="803">ch can produce more effective representations than the comparison domain adaptation methods. 2 Related Work Domain adaptation has recently been popularly studied in natural language processing and a variety of domain adaptation approaches have been developed, including instance weighting adaptation methods and feature representation learning methods. Instance weighting adaptation methods improve the transferability of a prediction model by training an instance weighted learning system. Much work in this category has been developed to address different weighting schemas (Sugiyama et al., 2007; Wan et al., 2011). Jiang and Zhai (2007) applied instance weighting algorithms to tackle cross-domain NLP tasks and proposed to remove misleading source training data and assign less weights to labeled data from the source domain than labeled data from the target domain. Dai et al. (2007) proposed to increase the weights of mistakenly predicted instances from the target domain and decrease the weights of incorrectly predicted instances from the source domain during an iterative training process. Representation learning methods bridge domain divergence either by differentiating domaininvariant features from dom</context>
</contexts>
<marker>Wan, Pan, Li, 2011</marker>
<rawString>C. Wan, R. Pan, and J. Li. Bi-weighting domain adaptation for cross-language text classification. In Proc. of the International Joint Conference on Artificial Intelligence (IJCAI), 2011.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>