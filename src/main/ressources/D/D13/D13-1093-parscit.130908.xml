<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.996671">
Online Learning for Inexact Hypergraph Search
</title>
<author confidence="0.999396">
Hao Zhang Liang Huang Kai Zhao Ryan McDonald
</author>
<affiliation confidence="0.998995">
Google City University of New York Google
</affiliation>
<email confidence="0.988319">
haozhang@google.com {lhuang@cs.qc,kzhao@gc}.cuny.edu ryanmcd@google.com
</email>
<sectionHeader confidence="0.996814" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.913585111111111">
Online learning algorithms like the percep-
tron are widely used for structured predic-
tion tasks. For sequential search problems,
like left-to-right tagging and parsing, beam
search has been successfully combined with
perceptron variants that accommodate search
errors (Collins and Roark, 2004; Huang et
al., 2012). However, perceptron training with
inexact search is less studied for bottom-up
parsing and, more generally, inference over
hypergraphs. In this paper, we generalize
the violation-fixing perceptron of Huang et
al. (2012) to hypergraphs and apply it to the
cube-pruning parser of Zhang and McDonald
(2012). This results in the highest reported
scores on WSJ evaluation set (UAS 93.50%
and LAS 92.41% respectively) without the aid
of additional resources.
</bodyText>
<sectionHeader confidence="0.999454" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932194444444">
Structured prediction problems generally deal with
exponentially many outputs, often making exact
search infeasible. For sequential search problems,
such as tagging and incremental parsing, beam
search coupled with perceptron algorithms that ac-
count for potential search errors have been shown
to be a powerful combination (Collins and Roark,
2004; Daum´e and Marcu, 2005; Zhang and Clark,
2008; Huang et al., 2012). However, sequen-
tial search algorithms, and in particular left-to-right
beam search (Collins and Roark, 2004; Zhang and
Clark, 2008), squeeze inference into a very narrow
space. To address this, Huang (2008) formulated
constituency parsing as approximate bottom-up in-
ference in order to compactly represent an exponen-
tial number of outputs while scoring features of ar-
bitrary scope. This idea was adapted to graph-based
dependency parsers by Zhang and McDonald (2012)
and shown to outperform left-to-right beam search.
Both these examples, bottom-up approximate de-
pendency and constituency parsing, can be viewed
as specific instances of inexact hypergraph search.
Typically, the approximation is accomplished by
cube-pruning throughout the hypergraph (Chiang,
2007). Unfortunately, as the scope of features at
each node increases, the inexactness of search and
its negative impact on learning can potentially be ex-
acerbated. Unlike sequential search, the impact on
learning of approximate hypergraph search – as well
as methods to mitigate any ill effects – has not been
studied. Motivated by this, we develop online learn-
ing algorithms for inexact hypergraph search by gen-
eralizing the violation-fixing percepron of Huang et
al. (2012). We empirically validate the benefit of
this approach within the cube-pruning dependency
parser of Zhang and McDonald (2012).
</bodyText>
<sectionHeader confidence="0.768305" genericHeader="method">
2 Structured Perceptron for Inexact
Hypergraph Search
</sectionHeader>
<bodyText confidence="0.971066125">
The structured perceptron algorithm (Collins, 2002)
is a general learning algorithm. Given training in-
stances (x, y), the algorithm first solves the decod-
ing problem y′ = argmaxyEY(x) w · f(x, y) given
the weight vector w for the high-dimensional fea-
ture representation f of the mapping (x, y), where
y′ is the prediction under the current model, y� is the
gold output and Y(x) is the space of all valid outputs
for input x. The perceptron update rule is simply:
w′ = w + f(x, y) − f(x, y′).
The convergence of original perceptron algorithm
relies on the argmax function being exact so that
the condition w·f(x, y′) &gt; w·f(x, y) (modulo ties)
always holds. This condition is called a violation
because the prediction y′ scores higher than the cor-
rect label y. Each perceptron update moves weights
</bodyText>
<page confidence="0.959765">
908
</page>
<note confidence="0.880261">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 908–913,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.992828666666667">
Figure 1: A hypergraph showing the union of the gold
and Viterbi subtrees. The hyperedges in bold and dashed
are from the gold and Viterbi trees, respectively.
</figureCaption>
<bodyText confidence="0.997044434782609">
away from y′ and towards y� to fix such violations.
But when search is inexact, y′ could be suboptimal
so that sometimes w · f(x, y′) &lt; w · f(x, y). Huang
et al. (2012) named such instances non-violations
and showed that perceptron model updates for non-
violations nullify guarantees of convergence. To ac-
count for this, they generalized the original update
rule to select an output y′ within the pruned search
space that scores higher than y, but is not necessar-
ily the highest among all possibilities, which repre-
sents a true violation of the model on that training
instance. This violation fixing perceptron thus re-
laxes the argmax function to accommodate inexact
search and becomes provably convergent as a result.
In the sequential cases where y� has a linear struc-
ture such as tagging and incremental parsing, the
violation fixing perceptron boils down to finding
and updating along a certain prefix of P. Collins
and Roark (2004) locate the earliest position in a
chain structure where ypref is worse than y′pref by
a margin large enough to cause y� to be dropped
from the beam. Huang et al. (2012) locate the po-
sition where the violation is largest among all pre-
fixes of y, where size of a violation is defined as
w · f(x, y′pref) − w · f(x, ypref).
For hypergraphs, the notion of prefix must be gen-
eralized to subtrees. Figure 1 shows the packed-
forest representation of the union of gold subtrees
and highest-scoring (Viterbi) subtrees at every gold
node for an input. At each gold node, there are
two incoming hyperedges: one for the gold subtree
and the other for the Viterbi subtree. After bottom-
up parsing, we can compute the scores for the gold
subtrees as well as extract the corresponding Viterbi
subtrees by following backpointers. These Viterbi
subtrees need not necessarily to belong to the full
Viterbi path (i.e., the Viterbi tree rooted at node N ).
An update strategy must choose a subtree or a set of
subtrees at gold nodes. This is to ensure that the
model is updating its weights relative to the inter-
section of the search space and the gold path.
Our first update strategy is called single-node
max-violation (s-max). Given a gold tree y, it tra-
verses the gold tree and finds the node n on which
the violation between the Viterbi subtree and the
gold subtree is the largest over all gold nodes. The
violation is guaranteed to be greater than or equal to
zero because the lower bound for the max-violation
on any hypergraph is 0 which happens at the leaf
nodes. Then we choose the subtree pair (yn, y′n) and
do the update similar to the prefix update for the se-
quential case. For example, in Figure 1, suppose the
max-violation happens at node K , which covers the
left half of the input x, then the perceptron update
would move parameters to the subtree represented
by nodes B , C , H and K and away from A ,
B , G and K .
Our second update strategy is called parallel max-
violation (p-max). It is based on the observation that
violations on non-overlapping nodes can be fixed
in parallel. We define a set of frontiers as a set
of nodes that are non-overlapping and the union of
which covers the entire input string x. The frontier
set can include up to |x |nodes, in the case where the
frontier is equivalent to the set of leaves. We traverse
y� bottom-up to compute the set of frontiers such
that each has the max-violation in the span it cov-
ers. Concretely, for each node n, the max-violation
frontier set can be defined recursively,
</bodyText>
<equation confidence="0.9692358">
�
n, if n = maxv(n)
U
niEchildren(n)
ft(nz), otherwise
</equation>
<bodyText confidence="0.8646026">
where maxv(n) is the function that returns the node
with the absolute maximum violation in the subtree
rooted at n and can easily be computed recursively
over the hypergraph. To make a perceptron update,
we generate the max-violation frontier set for the en-
tire hypergraph and use it to choose subtree pairs
root(x)
the root
the hypergraph for input x. For example, in Figure 1,
if the union of K an
</bodyText>
<equation confidence="0.642548">
U
n∈ft(root(x))(�yn,y′n),where
is
</equation>
<bodyText confidence="0.979639666666667">
of
d L satisfies the definition of
ft, then the perceptron update would move feature
</bodyText>
<equation confidence="0.938017166666667">
A B C D E F
G H I J
K L
N
M
ft(n) =
</equation>
<page confidence="0.985809">
909
</page>
<bodyText confidence="0.999878">
weights away from the union of the two Viterbi sub-
trees and towards their gold counterparts.
In our experiments, we compare the performance
of the two violation-fixing update strategies against
two baselines. The first baseline is the standard up-
date, where updates always happen at the root node
of a gold tree, even if the Viterbi tree at the root node
leads to a non-violation update. The second baseline
is the skip update, which also always updates at the
root nodes but skips any non-violations. This is the
strategy used by Zhang and McDonald (2012).
</bodyText>
<sectionHeader confidence="0.999359" genericHeader="evaluation">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999241971428572">
We ran a number of experiments on the cube-
pruning dependency parser of Zhang and McDonald
(2012), whose search space can be represented as a
hypergraph in which the nodes are the complete and
incomplete states and the hyperedges are the instan-
tiations of the two parsing rules in the Eisner algo-
rithm (Eisner, 1996).
The feature templates we used are a superset of
Zhang and McDonald (2012). These features in-
clude first-, second-, and third-order features and
their labeled counterparts, as well as valency fea-
tures. In addition, we also included a feature tem-
plate from Bohnet and Kuhn (2012). This tem-
plate examines the leftmost child and the rightmost
child of a modifier simultaneously. All other high-
order features of Zhang and McDonald (2012) only
look at arcs on the same side of their head. We
trained the parser with hamming-loss-augmented
MIRA (Crammer et al., 2006), following Martins et
al. (2010). Based on results on the English valida-
tion data, in all the experiments, we trained MIRA
with 8 epochs and used a beam of size 6 per node.
To speed up the parser, we used an unlabeled
first-order model to prune unlikely dependency arcs
at both training and testing time (Koo and Collins,
2010; Martins et al., 2013). We followed Rush and
Petrov (2012) to train the first-order model to min-
imize filter loss with respect to max-marginal filter-
ing. On the English validation corpus, the filtering
model pruned 80% of arcs while keeping the oracle
unlabeled attachment score above 99.50%. During
training only, we insert the gold tree into the hy-
pergraph if it was mistakenly pruned. This ensures
that the gold nodes are always available, which is
required for model updates.
</bodyText>
<subsectionHeader confidence="0.994598">
3.1 English and Chinese Results
</subsectionHeader>
<bodyText confidence="0.999962285714286">
We report dependency parsing results on the Penn
WSJ Treebank and the Chinese CTB-5 Treebank.
Both treebanks are constituency treebanks. We gen-
erated two versions of dependency treebanks by ap-
plying commonly-used conversion procedures. For
the first English version (PTB-YM), we used the
Penn2Malt1 software to apply the head rules of Ya-
mada and Matsumoto and the Malt label set. For
the second English version (PTB-S), we used the
Stanford dependency framework (De Marneffe et
al., 2006) by applying version 2.0.5 of the Stan-
ford parser. We split the data in the standard way:
sections 2-21 for training; section 22 for validation;
and section 23 for evaluation. We utilized a linear
chain CRF tagger which has an accuracy of 96.9%
on the validation data and 97.3% on the evaluation
data2. For Chinese, we use the Chinese Penn Tree-
bank converted to dependencies and split into train/-
validation/evaluation according to Zhang and Nivre
(2011). We report both unlabeled attachment scores
(UAS) and labeled attachment scores (LAS), ignor-
ing punctuations (Buchholz and Marsi, 2006).
Table 1 displays the results. Our improved
cube-pruned parser represents a significant improve-
ment over the feature-rich transition-based parser of
Zhang and Nivre (2011) with a large beam size. It
also improves over the baseline cube-pruning parser
without max-violation update strategies (Zhang and
McDonald, 2012), showing the importance of up-
date strategies in inexact hypergraph search. The
UAS score on Penn-YM is slightly higher than the
best result known in the literature which was re-
ported by the fourth-order unlabeled dependency
parser of Ma and Zhao (2012), although we did
not utilize fourth-order features. The LAS score on
Penn-YM is on par with the best reported by Bohnet
and Kuhn (2012). On Penn-S, there are not many
existing results to compare with, due to the tradition
of reporting results on Penn-YM in the past. Never-
theless, our result is higher than the second best by
a large margin. Our Chinese parsing scores are the
highest reported results.
</bodyText>
<footnote confidence="0.995834666666667">
1http://stp.lingfil.uu.se//—nivre/research/Penn2Malt.html
2The data was prepared by Andr´e F. T. Martins as was done
in Martins et al. (2013).
</footnote>
<page confidence="0.942934">
910
</page>
<table confidence="0.996154266666667">
Parser UAS Penn-YM Toks/Sec
LAS
Zhang and Nivre (2011) 92.9- 91.8- †680
Zhang and Nivre (reimpl.) (beam=64) 93.00 91.98 800
Zhang and Nivre (reimpl.) (beam=128) 92.94 91.91 400
Koo and Collins (2010) 93.04 - -
Zhang and McDonald (2012) 93.06 91.86 220
Rush and Petrov (2012) - - -
Martins et al. (2013) 93.07 - 740
Qian and Liu (2013) 93.17 - 180
Bohnet and Kuhn (2012) 93.39 92.38 †120
Ma and Zhao (2012) 93.4- - -
cube-pruning w/ skip 93.21 92.07 300
w/ s-max 93.50 92.41 300
w/ p-max 93.44 92.33 300
</table>
<figure confidence="0.985793530120482">
Penn-S CTB-5
-
500
250
-
-
4460
600
-
-
-
200
200
200
86.0-
85.93
86.05
-
86.87
-
-
87.25
87.5-
87.4-
86.95
87.78
87.87
Toks/Sec
84.4-
84.42
84.50
-
85.19
-
-
-
85.9-
-
85.23
86.13
86.24
-
700
360
-
-
-
-
100
-
-
200
200
200
UAS
LAS
Toks/Sec UAS LAS
-
92.96
93.11
-
-
92.7-
92.82
-
-
-
92.92
90.35
93.59
91.17
93.64
91.28
-
90.74
90.84
-
-
-
-
-
-
-
</figure>
<tableCaption confidence="0.98081775">
Table 1: Parsing results on test sets of the Penn Treebank and CTB-5. UAS and LAS are measured on all tokens except
punctuations. We also include the tokens per second numbers for different parsers whenever available, although the
numbers from other papers were obtained on different machines. Speed numbers marked with † were converted from
sentences per second.
</tableCaption>
<bodyText confidence="0.999857733333333">
The speed of our parser is around 200-300 tokens
per second for English. This is faster than the parser
of Bohnet and Kuhn (2012) which has roughly the
same level of accuracy, but is slower than the parser
of Martins et al. (2013) and Rush and Petrov (2012),
both of which only do unlabeled dependency pars-
ing and are less accurate. Given that predicting la-
bels on arcs can slow down a parser by a constant
factor proportional to the size of the label set, the
speed of our parser is competitive. We also tried to
prune away arc labels based on observed labels for
each POS tag pair in the training data. By doing so,
we could speed up our parser to 500-600 tokens per
second with less than a 0.2% drop in both UAS and
LAS.
</bodyText>
<subsectionHeader confidence="0.999796">
3.2 Importance of Update Strategies
</subsectionHeader>
<bodyText confidence="0.999935866666667">
The lower portion of Table 1 compares cube-pruning
parsing with different online update strategies in or-
der to show the importance of choosing an update
strategy that accommodates search errors. The max-
violation update strategies (s-max and p-max) im-
proved results on both versions of the Penn Treebank
as well as the CTB-5 Chinese treebank. It made
a larger difference on Penn-S relative to Penn-YM,
improving as much as 0.93% in LAS against the skip
update strategy. Additionally, we measured the per-
centage of non-violation updates at root nodes. In
the last epoch of training, on Penn-YM, there was
24% non-violations if we used the skip update strat-
egy; on Penn-S, there was 36% non-violations. The
portion of non-violations indicates the inexactness
</bodyText>
<figure confidence="0.842205">
UAS on Penn-YM dev
1 2 3 4 5 6 7 8
epochs
</figure>
<figureCaption confidence="0.9927726">
Figure 2: Constrast of different update strategies on the
validation data set of Penn-YM. The x-axis is the number
of training epochs. The y-axis is the UAS score. s-max
stands for single-node max-violation. p-max stands for
parallel max-violation.
</figureCaption>
<bodyText confidence="0.996128272727273">
of the underlying search. Search is harder on Penn-S
due to the larger label set. Thus, as expected, max-
violation update strategies improve most where the
search is the hardest and least exact.
Figure 2 shows accuracy per training epoch on the
validation data. It can be seen that bad update strate-
gies are not simply slow learners. More iterations
of training cannot close the gap between strategies.
Forcing invalid updates on non-violations (standard
update) or simply ignoring them (skip update) pro-
duces less accurate models overall.
</bodyText>
<figure confidence="0.976626666666667">
94
UAS 93.8
93.6
93.4
93.2
93
92.8
92.6
92.4
92.2
92
s-max
p-max
skip
standard
</figure>
<page confidence="0.98341">
911
</page>
<table confidence="0.978943">
ZN 2011 (reimpl.)
Language UAS LAS
SPANISH 86.76 83.81
CATALAN 94.00 88.65
JAPANESE 93.10 91.57
BULGARIAN 93.08 89.23
ITALIAN 87.31 82.88
SWEDISH 90.98 85.66
ARABIC 78.26 67.09
TURKISH 76.62 66.00
DANISH 90.84 86.65
PORTUGUESE 91.18 87.66
GREEK 85.63 78.41
SLOVENE 84.63 76.06
CZECH 87.78 82.38
BASQUE 79.65 71.03
HUNGARIAN 84.71 80.16
GERMAN 91.57 89.48
DUTCH 82.49 79.71
AVG 86.98 81.55
skip s-max p-max Best Published†
UAS LAS UAS LAS UAS LAS UAS LAS
87.48 84.05
94.07 89.09
93.72 91.7-
93.50 88.23
87.47 83.50
91.44 85.42
81.12 66.9-
77.55 65.7-
91.86 84.8-
93.03 87.70
86.05 77.87
86.95 73.4-
90.32 80.2-
80.23 73.18
86.81 81.86
92.41 88.42
86.19 79.2-
81.56 87.76 82.08 87.80 82.14
87.33
87.34
94.54
93.40
93.52
87.75
</table>
<page confidence="0.783040931034483">
90.64
80.42
76.18
91.40
91.69
86.37
85.01
86.92
79.57
85.67
91.23
83.01
84.15
89.14
91.65
89.25
83.41
83.89
69.46
65.90
86.59
88.04
78.29
75.92
80.36
71.43
80.84
88.34
79.79
</page>
<figure confidence="0.853509308823529">
87.96
94.58
93.26
94.02
87.57
91.62
80.48
76.94
91.88
92.07
86.14
86.01
88.36
79.59
85.85
92.03
83.57
84.95
89.05
91.67
89.87
83.22
85.08
69.68
66.80
86.95
88.30
78.20
77.14
82.16
71.52
81.02
89.44
80.29
87.68
94.98
93.20
93.80
87.79
91.62
80.60
76.86
92.00
92.19
86.46
85.77
88.48
79.61
86.49
91.79
83.35
84.75
89.56
91.49
89.65
83.59
85.00
70.12
66.56
87.07
88.40
78.55
76.62
82.38
71.65
81.67
89.28
80.09
</figure>
<tableCaption confidence="0.713638833333333">
Table 2: Parsing Results for languages from CoNLL 2006/2007 shared tasks. When a language is in both years,
we use the 2006 data set. The best results with † are the maximum in the following papers: Buchholz and Marsi
(2006), Nivre et al. (2007), Zhang and McDonald (2012), Bohnet and Kuhn (2012), and Martins et al. (2013), For
consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is
our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011
reimplementation and different update strategies from this paper.
</tableCaption>
<subsectionHeader confidence="0.99957">
3.3 CoNLL Results
</subsectionHeader>
<bodyText confidence="0.999985379310345">
We also report parsing results for 17 languages from
the CoNLL 2006/2007 shared-task (Buchholz and
Marsi, 2006; Nivre et al., 2007). The parser in
our experiments can only produce projective depen-
dency trees as it uses an Eisner algorithm backbone
to generate the hypergraph (Eisner, 1996). So, at
training time, we convert non-projective trees – of
which there are many in the CoNLL data – to projec-
tive ones through flattening, i.e., attaching words to
the lowest ancestor that results in projective trees. At
testing time, our parser can only predict projective
trees, though we evaluate on the true non-projective
trees.
Table 2 shows the full results. We sort the
languages according to the percentage of non-
projective trees in increasing order. The Spanish
treebank is 98% projective, while the Dutch tree-
bank is only 64% projective. With respect to the
Zhang and Nivre (2011) baseline, we improved UAS
in 16 languages and LAS in 15 languages. The im-
provements are stronger for the projective languages
in the top rows. We achieved the best published
UAS results for 7 languages: Spanish, Catalan, Bul-
garain, Italian, Swedish, Danish, and Greek. As
these languages are typically from the more projec-
tive data sets, we speculate that extending the parser
used in this study to handle non-projectivity will
lead to state-of-the-art models for the majority of
languages.
</bodyText>
<sectionHeader confidence="0.998688" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999831789473684">
We proposed perceptron update strategies for in-
exact hypergraph search and experimented with
a cube-pruning dependency parser. Both single-
node max-violation and parallel max-violation up-
date strategies signficantly improved parsing results
over the strategy that ignores any invalid udpates
caused by inexactness of search. The update strate-
gies are applicable to any bottom-up parsing prob-
lems such as constituent parsing (Huang, 2008) and
syntax-based machine translation with online learn-
ing (Chiang et al., 2008).
Acknowledgments: We thank Andr´e F. T. Martins
for the dependency converted Penn Treebank with
automatic POS tags from his experiments; the re-
viewers for their useful suggestions; the NLP team
at Google for numerous discussions and comments;
Liang Huang and Kai Zhao are supported in part by
DARPA FA8750-13-2-0041 (DEFT), PSC-CUNY,
and a Google Faculty Research Award.
</bodyText>
<sectionHeader confidence="0.998424" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999049145161291">
B. Bohnet and J. Kuhn. 2012. The best of bothworlds
- a graph-based completion model for transition-based
parsers. In Proc. of EACL.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proc. of
CoNLL.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proc. of EMNLP.
D. Chiang. 2007. Hierarchical phrase-based translation.
Computational Linguistics, 33(2).
M. Collins and B. Roark. 2004. Incremental parsing with
the perceptron algorithm. In Proc. of ACL.
M. Collins. 2002. Discriminative training methods for
hidden markov models: Theory and experiments with
perceptron algorithms. In Proc. ofACL.
K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz,
and Y. Singer. 2006. Online passive-aggressive al-
gorithms. Journal of Machine Learning Research.
H. Daum´e and D. Marcu. 2005. Learning as search
optimization: Approximate large margin methods for
structured prediction. In Proc. of ICML.
M. De Marneffe, B. MacCartney, and C.D. Manning.
2006. Generating typed dependency parses from
phrase structure parses. In Proc. of LREC.
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: an exploration. In Proc. of COL-
ING.
L. Huang, S. Fayong, and G. Yang. 2012. Structured
perceptron with inexact search. In Proc. of NAACL.
L. Huang. 2008. Forest reranking: Discriminative pars-
ing with non-local features. In Proc. of ACL.
T. Koo and M. Collins. 2010. Efficient third-order de-
pendency parsers. In Proc. of ACL.
X. Ma and H. Zhao. 2012. Fourth-order dependency
parsing. In Proc. of COLING.
A. F. T. Martins, N. Smith, E. P. Xing, P. M. Q. Aguiar,
and M. A. T. Figueiredo. 2010. Turbo parsers: Depen-
dency parsing by approximate variational inference.
In Proc. of EMNLP.
A. F. T. Martins, M. B. Almeida, and N. A. Smith. 2013.
Turning on the turbo: Fast third-order non-projective
turbo parsers. In Proc. of ACL.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nils-
son, S. Riedel, and D. Yuret. 2007. The CoNLL
2007 shared task on dependency parsing. In Proc. of
EMNLP-CoNLL.
X. Qian and Y. Liu. 2013. Branch and bound algo-
rithm for dependency parsing with non-local features.
TACL, Vol 1.
A. Rush and S. Petrov. 2012. Efficient multi-pass depen-
dency pruning with vine parsing. In Proc. of NAACL.
Y. Zhang and S. Clark. 2008. A Tale of Two
Parsers: Investigating and Combining Graph-based
and Transition-based Dependency Parsing. In Proc.
of EMNLP.
H. Zhang and R. McDonald. 2012. Generalized higher-
order dependency parsing with cube pruning. In Proc.
of EMNLP.
Y. Zhang and J. Nivre. 2011. Transition-based depen-
dency parsing with rich non-local features. In Proc. of
ACL-HLT, volume 2.
</reference>
<page confidence="0.999074">
913
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.804767">
<title confidence="0.999229">Online Learning for Inexact Hypergraph Search</title>
<author confidence="0.917806">Hao Zhang Liang Huang Kai Zhao Ryan McDonald Google City University of New York Google</author>
<email confidence="0.999704">ryanmcd@google.com</email>
<abstract confidence="0.997170473684211">Online learning algorithms like the perceptron are widely used for structured prediction tasks. For sequential search problems, like left-to-right tagging and parsing, beam search has been successfully combined with perceptron variants that accommodate search errors (Collins and Roark, 2004; Huang et al., 2012). However, perceptron training with inexact search is less studied for bottom-up parsing and, more generally, inference over hypergraphs. In this paper, we generalize the violation-fixing perceptron of Huang et al. (2012) to hypergraphs and apply it to the cube-pruning parser of Zhang and McDonald (2012). This results in the highest reported scores on WSJ evaluation set (UAS 93.50% and LAS 92.41% respectively) without the aid of additional resources.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Bohnet</author>
<author>J Kuhn</author>
</authors>
<title>The best of bothworlds - a graph-based completion model for transition-based parsers.</title>
<date>2012</date>
<booktitle>In Proc. of EACL.</booktitle>
<contexts>
<context position="9230" citStr="Bohnet and Kuhn (2012)" startWordPosition="1534" endWordPosition="1537">onald (2012). 3 Experiments We ran a number of experiments on the cubepruning dependency parser of Zhang and McDonald (2012), whose search space can be represented as a hypergraph in which the nodes are the complete and incomplete states and the hyperedges are the instantiations of the two parsing rules in the Eisner algorithm (Eisner, 1996). The feature templates we used are a superset of Zhang and McDonald (2012). These features include first-, second-, and third-order features and their labeled counterparts, as well as valency features. In addition, we also included a feature template from Bohnet and Kuhn (2012). This template examines the leftmost child and the rightmost child of a modifier simultaneously. All other highorder features of Zhang and McDonald (2012) only look at arcs on the same side of their head. We trained the parser with hamming-loss-augmented MIRA (Crammer et al., 2006), following Martins et al. (2010). Based on results on the English validation data, in all the experiments, we trained MIRA with 8 epochs and used a beam of size 6 per node. To speed up the parser, we used an unlabeled first-order model to prune unlikely dependency arcs at both training and testing time (Koo and Col</context>
<context position="12139" citStr="Bohnet and Kuhn (2012)" startWordPosition="2007" endWordPosition="2010">ant improvement over the feature-rich transition-based parser of Zhang and Nivre (2011) with a large beam size. It also improves over the baseline cube-pruning parser without max-violation update strategies (Zhang and McDonald, 2012), showing the importance of update strategies in inexact hypergraph search. The UAS score on Penn-YM is slightly higher than the best result known in the literature which was reported by the fourth-order unlabeled dependency parser of Ma and Zhao (2012), although we did not utilize fourth-order features. The LAS score on Penn-YM is on par with the best reported by Bohnet and Kuhn (2012). On Penn-S, there are not many existing results to compare with, due to the tradition of reporting results on Penn-YM in the past. Nevertheless, our result is higher than the second best by a large margin. Our Chinese parsing scores are the highest reported results. 1http://stp.lingfil.uu.se//—nivre/research/Penn2Malt.html 2The data was prepared by Andr´e F. T. Martins as was done in Martins et al. (2013). 910 Parser UAS Penn-YM Toks/Sec LAS Zhang and Nivre (2011) 92.9- 91.8- †680 Zhang and Nivre (reimpl.) (beam=64) 93.00 91.98 800 Zhang and Nivre (reimpl.) (beam=128) 92.94 91.91 400 Koo and </context>
<context position="13900" citStr="Bohnet and Kuhn (2012)" startWordPosition="2333" endWordPosition="2336">200 UAS LAS Toks/Sec UAS LAS - 92.96 93.11 - - 92.7- 92.82 - - - 92.92 90.35 93.59 91.17 93.64 91.28 - 90.74 90.84 - - - - - - - Table 1: Parsing results on test sets of the Penn Treebank and CTB-5. UAS and LAS are measured on all tokens except punctuations. We also include the tokens per second numbers for different parsers whenever available, although the numbers from other papers were obtained on different machines. Speed numbers marked with † were converted from sentences per second. The speed of our parser is around 200-300 tokens per second for English. This is faster than the parser of Bohnet and Kuhn (2012) which has roughly the same level of accuracy, but is slower than the parser of Martins et al. (2013) and Rush and Petrov (2012), both of which only do unlabeled dependency parsing and are less accurate. Given that predicting labels on arcs can slow down a parser by a constant factor proportional to the size of the label set, the speed of our parser is competitive. We also tried to prune away arc labels based on observed labels for each POS tag pair in the training data. By doing so, we could speed up our parser to 500-600 tokens per second with less than a 0.2% drop in both UAS and LAS. 3.2 I</context>
<context position="17802" citStr="Bohnet and Kuhn (2012)" startWordPosition="2996" endWordPosition="2999">9 85.85 92.03 83.57 84.95 89.05 91.67 89.87 83.22 85.08 69.68 66.80 86.95 88.30 78.20 77.14 82.16 71.52 81.02 89.44 80.29 87.68 94.98 93.20 93.80 87.79 91.62 80.60 76.86 92.00 92.19 86.46 85.77 88.48 79.61 86.49 91.79 83.35 84.75 89.56 91.49 89.65 83.59 85.00 70.12 66.56 87.07 88.40 78.55 76.62 82.38 71.65 81.67 89.28 80.09 Table 2: Parsing Results for languages from CoNLL 2006/2007 shared tasks. When a language is in both years, we use the 2006 data set. The best results with † are the maximum in the following papers: Buchholz and Marsi (2006), Nivre et al. (2007), Zhang and McDonald (2012), Bohnet and Kuhn (2012), and Martins et al. (2013), For consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011 reimplementation and different update strategies from this paper. 3.3 CoNLL Results We also report parsing results for 17 languages from the CoNLL 2006/2007 shared-task (Buchholz and Marsi, 2006; Nivre et al., 2007). The parser in our experiments can only produce projective dependency trees as it uses an Eisner algorithm backbone to generate th</context>
</contexts>
<marker>Bohnet, Kuhn, 2012</marker>
<rawString>B. Bohnet and J. Kuhn. 2012. The best of bothworlds - a graph-based completion model for transition-based parsers. In Proc. of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of CoNLL.</booktitle>
<contexts>
<context position="11432" citStr="Buchholz and Marsi, 2006" startWordPosition="1896" endWordPosition="1899">amework (De Marneffe et al., 2006) by applying version 2.0.5 of the Stanford parser. We split the data in the standard way: sections 2-21 for training; section 22 for validation; and section 23 for evaluation. We utilized a linear chain CRF tagger which has an accuracy of 96.9% on the validation data and 97.3% on the evaluation data2. For Chinese, we use the Chinese Penn Treebank converted to dependencies and split into train/- validation/evaluation according to Zhang and Nivre (2011). We report both unlabeled attachment scores (UAS) and labeled attachment scores (LAS), ignoring punctuations (Buchholz and Marsi, 2006). Table 1 displays the results. Our improved cube-pruned parser represents a significant improvement over the feature-rich transition-based parser of Zhang and Nivre (2011) with a large beam size. It also improves over the baseline cube-pruning parser without max-violation update strategies (Zhang and McDonald, 2012), showing the importance of update strategies in inexact hypergraph search. The UAS score on Penn-YM is slightly higher than the best result known in the literature which was reported by the fourth-order unlabeled dependency parser of Ma and Zhao (2012), although we did not utilize</context>
<context position="17730" citStr="Buchholz and Marsi (2006)" startWordPosition="2984" endWordPosition="2987">4.58 93.26 94.02 87.57 91.62 80.48 76.94 91.88 92.07 86.14 86.01 88.36 79.59 85.85 92.03 83.57 84.95 89.05 91.67 89.87 83.22 85.08 69.68 66.80 86.95 88.30 78.20 77.14 82.16 71.52 81.02 89.44 80.29 87.68 94.98 93.20 93.80 87.79 91.62 80.60 76.86 92.00 92.19 86.46 85.77 88.48 79.61 86.49 91.79 83.35 84.75 89.56 91.49 89.65 83.59 85.00 70.12 66.56 87.07 88.40 78.55 76.62 82.38 71.65 81.67 89.28 80.09 Table 2: Parsing Results for languages from CoNLL 2006/2007 shared tasks. When a language is in both years, we use the 2006 data set. The best results with † are the maximum in the following papers: Buchholz and Marsi (2006), Nivre et al. (2007), Zhang and McDonald (2012), Bohnet and Kuhn (2012), and Martins et al. (2013), For consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011 reimplementation and different update strategies from this paper. 3.3 CoNLL Results We also report parsing results for 17 languages from the CoNLL 2006/2007 shared-task (Buchholz and Marsi, 2006; Nivre et al., 2007). The parser in our experiments can only produce projective</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="2178" citStr="Chiang, 2007" startWordPosition="308" endWordPosition="309">nto a very narrow space. To address this, Huang (2008) formulated constituency parsing as approximate bottom-up inference in order to compactly represent an exponential number of outputs while scoring features of arbitrary scope. This idea was adapted to graph-based dependency parsers by Zhang and McDonald (2012) and shown to outperform left-to-right beam search. Both these examples, bottom-up approximate dependency and constituency parsing, can be viewed as specific instances of inexact hypergraph search. Typically, the approximation is accomplished by cube-pruning throughout the hypergraph (Chiang, 2007). Unfortunately, as the scope of features at each node increases, the inexactness of search and its negative impact on learning can potentially be exacerbated. Unlike sequential search, the impact on learning of approximate hypergraph search – as well as methods to mitigate any ill effects – has not been studied. Motivated by this, we develop online learning algorithms for inexact hypergraph search by generalizing the violation-fixing percepron of Huang et al. (2012). We empirically validate the benefit of this approach within the cube-pruning dependency parser of Zhang and McDonald (2012). 2 </context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>D. Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>B Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1343" citStr="Collins and Roark, 2004" startWordPosition="185" endWordPosition="188">tron of Huang et al. (2012) to hypergraphs and apply it to the cube-pruning parser of Zhang and McDonald (2012). This results in the highest reported scores on WSJ evaluation set (UAS 93.50% and LAS 92.41% respectively) without the aid of additional resources. 1 Introduction Structured prediction problems generally deal with exponentially many outputs, often making exact search infeasible. For sequential search problems, such as tagging and incremental parsing, beam search coupled with perceptron algorithms that account for potential search errors have been shown to be a powerful combination (Collins and Roark, 2004; Daum´e and Marcu, 2005; Zhang and Clark, 2008; Huang et al., 2012). However, sequential search algorithms, and in particular left-to-right beam search (Collins and Roark, 2004; Zhang and Clark, 2008), squeeze inference into a very narrow space. To address this, Huang (2008) formulated constituency parsing as approximate bottom-up inference in order to compactly represent an exponential number of outputs while scoring features of arbitrary scope. This idea was adapted to graph-based dependency parsers by Zhang and McDonald (2012) and shown to outperform left-to-right beam search. Both these e</context>
<context position="4923" citStr="Collins and Roark (2004)" startWordPosition="757" endWordPosition="760">or this, they generalized the original update rule to select an output y′ within the pruned search space that scores higher than y, but is not necessarily the highest among all possibilities, which represents a true violation of the model on that training instance. This violation fixing perceptron thus relaxes the argmax function to accommodate inexact search and becomes provably convergent as a result. In the sequential cases where y� has a linear structure such as tagging and incremental parsing, the violation fixing perceptron boils down to finding and updating along a certain prefix of P. Collins and Roark (2004) locate the earliest position in a chain structure where ypref is worse than y′pref by a margin large enough to cause y� to be dropped from the beam. Huang et al. (2012) locate the position where the violation is largest among all prefixes of y, where size of a violation is defined as w · f(x, y′pref) − w · f(x, ypref). For hypergraphs, the notion of prefix must be generalized to subtrees. Figure 1 shows the packedforest representation of the union of gold subtrees and highest-scoring (Viterbi) subtrees at every gold node for an input. At each gold node, there are two incoming hyperedges: one </context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>M. Collins and B. Roark. 2004. Incremental parsing with the perceptron algorithm. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms.</title>
<date>2002</date>
<booktitle>In Proc. ofACL.</booktitle>
<contexts>
<context position="2881" citStr="Collins, 2002" startWordPosition="414" endWordPosition="415">ch and its negative impact on learning can potentially be exacerbated. Unlike sequential search, the impact on learning of approximate hypergraph search – as well as methods to mitigate any ill effects – has not been studied. Motivated by this, we develop online learning algorithms for inexact hypergraph search by generalizing the violation-fixing percepron of Huang et al. (2012). We empirically validate the benefit of this approach within the cube-pruning dependency parser of Zhang and McDonald (2012). 2 Structured Perceptron for Inexact Hypergraph Search The structured perceptron algorithm (Collins, 2002) is a general learning algorithm. Given training instances (x, y), the algorithm first solves the decoding problem y′ = argmaxyEY(x) w · f(x, y) given the weight vector w for the high-dimensional feature representation f of the mapping (x, y), where y′ is the prediction under the current model, y� is the gold output and Y(x) is the space of all valid outputs for input x. The perceptron update rule is simply: w′ = w + f(x, y) − f(x, y′). The convergence of original perceptron algorithm relies on the argmax function being exact so that the condition w·f(x, y′) &gt; w·f(x, y) (modulo ties) always ho</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>M. Collins. 2002. Discriminative training methods for hidden markov models: Theory and experiments with perceptron algorithms. In Proc. ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Crammer</author>
<author>O Dekel</author>
<author>J Keshet</author>
<author>S Shalev-Shwartz</author>
<author>Y Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="9513" citStr="Crammer et al., 2006" startWordPosition="1581" endWordPosition="1584">he two parsing rules in the Eisner algorithm (Eisner, 1996). The feature templates we used are a superset of Zhang and McDonald (2012). These features include first-, second-, and third-order features and their labeled counterparts, as well as valency features. In addition, we also included a feature template from Bohnet and Kuhn (2012). This template examines the leftmost child and the rightmost child of a modifier simultaneously. All other highorder features of Zhang and McDonald (2012) only look at arcs on the same side of their head. We trained the parser with hamming-loss-augmented MIRA (Crammer et al., 2006), following Martins et al. (2010). Based on results on the English validation data, in all the experiments, we trained MIRA with 8 epochs and used a beam of size 6 per node. To speed up the parser, we used an unlabeled first-order model to prune unlikely dependency arcs at both training and testing time (Koo and Collins, 2010; Martins et al., 2013). We followed Rush and Petrov (2012) to train the first-order model to minimize filter loss with respect to max-marginal filtering. On the English validation corpus, the filtering model pruned 80% of arcs while keeping the oracle unlabeled attachment</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>K. Crammer, O. Dekel, J. Keshet, S. Shalev-Shwartz, and Y. Singer. 2006. Online passive-aggressive algorithms. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Daum´e</author>
<author>D Marcu</author>
</authors>
<title>Learning as search optimization: Approximate large margin methods for structured prediction.</title>
<date>2005</date>
<booktitle>In Proc. of ICML.</booktitle>
<marker>Daum´e, Marcu, 2005</marker>
<rawString>H. Daum´e and D. Marcu. 2005. Learning as search optimization: Approximate large margin methods for structured prediction. In Proc. of ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M De Marneffe</author>
<author>B MacCartney</author>
<author>C D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proc. of LREC.</booktitle>
<marker>De Marneffe, MacCartney, Manning, 2006</marker>
<rawString>M. De Marneffe, B. MacCartney, and C.D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proc. of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: an exploration.</title>
<date>1996</date>
<booktitle>In Proc. of COLING.</booktitle>
<contexts>
<context position="8951" citStr="Eisner, 1996" startWordPosition="1490" endWordPosition="1491">appen at the root node of a gold tree, even if the Viterbi tree at the root node leads to a non-violation update. The second baseline is the skip update, which also always updates at the root nodes but skips any non-violations. This is the strategy used by Zhang and McDonald (2012). 3 Experiments We ran a number of experiments on the cubepruning dependency parser of Zhang and McDonald (2012), whose search space can be represented as a hypergraph in which the nodes are the complete and incomplete states and the hyperedges are the instantiations of the two parsing rules in the Eisner algorithm (Eisner, 1996). The feature templates we used are a superset of Zhang and McDonald (2012). These features include first-, second-, and third-order features and their labeled counterparts, as well as valency features. In addition, we also included a feature template from Bohnet and Kuhn (2012). This template examines the leftmost child and the rightmost child of a modifier simultaneously. All other highorder features of Zhang and McDonald (2012) only look at arcs on the same side of their head. We trained the parser with hamming-loss-augmented MIRA (Crammer et al., 2006), following Martins et al. (2010). Bas</context>
<context position="18429" citStr="Eisner, 1996" startWordPosition="3100" endWordPosition="3101">et al. (2013), For consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011 reimplementation and different update strategies from this paper. 3.3 CoNLL Results We also report parsing results for 17 languages from the CoNLL 2006/2007 shared-task (Buchholz and Marsi, 2006; Nivre et al., 2007). The parser in our experiments can only produce projective dependency trees as it uses an Eisner algorithm backbone to generate the hypergraph (Eisner, 1996). So, at training time, we convert non-projective trees – of which there are many in the CoNLL data – to projective ones through flattening, i.e., attaching words to the lowest ancestor that results in projective trees. At testing time, our parser can only predict projective trees, though we evaluate on the true non-projective trees. Table 2 shows the full results. We sort the languages according to the percentage of nonprojective trees in increasing order. The Spanish treebank is 98% projective, while the Dutch treebank is only 64% projective. With respect to the Zhang and Nivre (2011) baseli</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. Eisner. 1996. Three new probabilistic models for dependency parsing: an exploration. In Proc. of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Huang</author>
<author>S Fayong</author>
<author>G Yang</author>
</authors>
<title>Structured perceptron with inexact search.</title>
<date>2012</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="747" citStr="Huang et al. (2012)" startWordPosition="97" endWordPosition="100">ogle haozhang@google.com {lhuang@cs.qc,kzhao@gc}.cuny.edu ryanmcd@google.com Abstract Online learning algorithms like the perceptron are widely used for structured prediction tasks. For sequential search problems, like left-to-right tagging and parsing, beam search has been successfully combined with perceptron variants that accommodate search errors (Collins and Roark, 2004; Huang et al., 2012). However, perceptron training with inexact search is less studied for bottom-up parsing and, more generally, inference over hypergraphs. In this paper, we generalize the violation-fixing perceptron of Huang et al. (2012) to hypergraphs and apply it to the cube-pruning parser of Zhang and McDonald (2012). This results in the highest reported scores on WSJ evaluation set (UAS 93.50% and LAS 92.41% respectively) without the aid of additional resources. 1 Introduction Structured prediction problems generally deal with exponentially many outputs, often making exact search infeasible. For sequential search problems, such as tagging and incremental parsing, beam search coupled with perceptron algorithms that account for potential search errors have been shown to be a powerful combination (Collins and Roark, 2004; Da</context>
<context position="2649" citStr="Huang et al. (2012)" startWordPosition="381" endWordPosition="384">ecific instances of inexact hypergraph search. Typically, the approximation is accomplished by cube-pruning throughout the hypergraph (Chiang, 2007). Unfortunately, as the scope of features at each node increases, the inexactness of search and its negative impact on learning can potentially be exacerbated. Unlike sequential search, the impact on learning of approximate hypergraph search – as well as methods to mitigate any ill effects – has not been studied. Motivated by this, we develop online learning algorithms for inexact hypergraph search by generalizing the violation-fixing percepron of Huang et al. (2012). We empirically validate the benefit of this approach within the cube-pruning dependency parser of Zhang and McDonald (2012). 2 Structured Perceptron for Inexact Hypergraph Search The structured perceptron algorithm (Collins, 2002) is a general learning algorithm. Given training instances (x, y), the algorithm first solves the decoding problem y′ = argmaxyEY(x) w · f(x, y) given the weight vector w for the high-dimensional feature representation f of the mapping (x, y), where y′ is the prediction under the current model, y� is the gold output and Y(x) is the space of all valid outputs for inp</context>
<context position="4156" citStr="Huang et al. (2012)" startWordPosition="633" endWordPosition="636">ediction y′ scores higher than the correct label y. Each perceptron update moves weights 908 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 908–913, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics Figure 1: A hypergraph showing the union of the gold and Viterbi subtrees. The hyperedges in bold and dashed are from the gold and Viterbi trees, respectively. away from y′ and towards y� to fix such violations. But when search is inexact, y′ could be suboptimal so that sometimes w · f(x, y′) &lt; w · f(x, y). Huang et al. (2012) named such instances non-violations and showed that perceptron model updates for nonviolations nullify guarantees of convergence. To account for this, they generalized the original update rule to select an output y′ within the pruned search space that scores higher than y, but is not necessarily the highest among all possibilities, which represents a true violation of the model on that training instance. This violation fixing perceptron thus relaxes the argmax function to accommodate inexact search and becomes provably convergent as a result. In the sequential cases where y� has a linear stru</context>
</contexts>
<marker>Huang, Fayong, Yang, 2012</marker>
<rawString>L. Huang, S. Fayong, and G. Yang. 2012. Structured perceptron with inexact search. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Huang</author>
</authors>
<title>Forest reranking: Discriminative parsing with non-local features.</title>
<date>2008</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="1619" citStr="Huang (2008)" startWordPosition="230" endWordPosition="231">prediction problems generally deal with exponentially many outputs, often making exact search infeasible. For sequential search problems, such as tagging and incremental parsing, beam search coupled with perceptron algorithms that account for potential search errors have been shown to be a powerful combination (Collins and Roark, 2004; Daum´e and Marcu, 2005; Zhang and Clark, 2008; Huang et al., 2012). However, sequential search algorithms, and in particular left-to-right beam search (Collins and Roark, 2004; Zhang and Clark, 2008), squeeze inference into a very narrow space. To address this, Huang (2008) formulated constituency parsing as approximate bottom-up inference in order to compactly represent an exponential number of outputs while scoring features of arbitrary scope. This idea was adapted to graph-based dependency parsers by Zhang and McDonald (2012) and shown to outperform left-to-right beam search. Both these examples, bottom-up approximate dependency and constituency parsing, can be viewed as specific instances of inexact hypergraph search. Typically, the approximation is accomplished by cube-pruning throughout the hypergraph (Chiang, 2007). Unfortunately, as the scope of features</context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>L. Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Koo</author>
<author>M Collins</author>
</authors>
<title>Efficient third-order dependency parsers.</title>
<date>2010</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="9840" citStr="Koo and Collins, 2010" startWordPosition="1640" endWordPosition="1643">Kuhn (2012). This template examines the leftmost child and the rightmost child of a modifier simultaneously. All other highorder features of Zhang and McDonald (2012) only look at arcs on the same side of their head. We trained the parser with hamming-loss-augmented MIRA (Crammer et al., 2006), following Martins et al. (2010). Based on results on the English validation data, in all the experiments, we trained MIRA with 8 epochs and used a beam of size 6 per node. To speed up the parser, we used an unlabeled first-order model to prune unlikely dependency arcs at both training and testing time (Koo and Collins, 2010; Martins et al., 2013). We followed Rush and Petrov (2012) to train the first-order model to minimize filter loss with respect to max-marginal filtering. On the English validation corpus, the filtering model pruned 80% of arcs while keeping the oracle unlabeled attachment score above 99.50%. During training only, we insert the gold tree into the hypergraph if it was mistakenly pruned. This ensures that the gold nodes are always available, which is required for model updates. 3.1 English and Chinese Results We report dependency parsing results on the Penn WSJ Treebank and the Chinese CTB-5 Tre</context>
<context position="12753" citStr="Koo and Collins (2010)" startWordPosition="2104" endWordPosition="2107">n (2012). On Penn-S, there are not many existing results to compare with, due to the tradition of reporting results on Penn-YM in the past. Nevertheless, our result is higher than the second best by a large margin. Our Chinese parsing scores are the highest reported results. 1http://stp.lingfil.uu.se//—nivre/research/Penn2Malt.html 2The data was prepared by Andr´e F. T. Martins as was done in Martins et al. (2013). 910 Parser UAS Penn-YM Toks/Sec LAS Zhang and Nivre (2011) 92.9- 91.8- †680 Zhang and Nivre (reimpl.) (beam=64) 93.00 91.98 800 Zhang and Nivre (reimpl.) (beam=128) 92.94 91.91 400 Koo and Collins (2010) 93.04 - - Zhang and McDonald (2012) 93.06 91.86 220 Rush and Petrov (2012) - - - Martins et al. (2013) 93.07 - 740 Qian and Liu (2013) 93.17 - 180 Bohnet and Kuhn (2012) 93.39 92.38 †120 Ma and Zhao (2012) 93.4- - - cube-pruning w/ skip 93.21 92.07 300 w/ s-max 93.50 92.41 300 w/ p-max 93.44 92.33 300 Penn-S CTB-5 - 500 250 - - 4460 600 - - - 200 200 200 86.0- 85.93 86.05 - 86.87 - - 87.25 87.5- 87.4- 86.95 87.78 87.87 Toks/Sec 84.4- 84.42 84.50 - 85.19 - - - 85.9- - 85.23 86.13 86.24 - 700 360 - - - - 100 - - 200 200 200 UAS LAS Toks/Sec UAS LAS - 92.96 93.11 - - 92.7- 92.82 - - - 92.92 90.3</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>T. Koo and M. Collins. 2010. Efficient third-order dependency parsers. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Ma</author>
<author>H Zhao</author>
</authors>
<title>Fourth-order dependency parsing.</title>
<date>2012</date>
<booktitle>In Proc. of COLING.</booktitle>
<contexts>
<context position="12003" citStr="Ma and Zhao (2012)" startWordPosition="1983" endWordPosition="1986">gnoring punctuations (Buchholz and Marsi, 2006). Table 1 displays the results. Our improved cube-pruned parser represents a significant improvement over the feature-rich transition-based parser of Zhang and Nivre (2011) with a large beam size. It also improves over the baseline cube-pruning parser without max-violation update strategies (Zhang and McDonald, 2012), showing the importance of update strategies in inexact hypergraph search. The UAS score on Penn-YM is slightly higher than the best result known in the literature which was reported by the fourth-order unlabeled dependency parser of Ma and Zhao (2012), although we did not utilize fourth-order features. The LAS score on Penn-YM is on par with the best reported by Bohnet and Kuhn (2012). On Penn-S, there are not many existing results to compare with, due to the tradition of reporting results on Penn-YM in the past. Nevertheless, our result is higher than the second best by a large margin. Our Chinese parsing scores are the highest reported results. 1http://stp.lingfil.uu.se//—nivre/research/Penn2Malt.html 2The data was prepared by Andr´e F. T. Martins as was done in Martins et al. (2013). 910 Parser UAS Penn-YM Toks/Sec LAS Zhang and Nivre (</context>
</contexts>
<marker>Ma, Zhao, 2012</marker>
<rawString>X. Ma and H. Zhao. 2012. Fourth-order dependency parsing. In Proc. of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F T Martins</author>
<author>N Smith</author>
<author>E P Xing</author>
<author>P M Q Aguiar</author>
<author>M A T Figueiredo</author>
</authors>
<title>Turbo parsers: Dependency parsing by approximate variational inference.</title>
<date>2010</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="9546" citStr="Martins et al. (2010)" startWordPosition="1586" endWordPosition="1589">r algorithm (Eisner, 1996). The feature templates we used are a superset of Zhang and McDonald (2012). These features include first-, second-, and third-order features and their labeled counterparts, as well as valency features. In addition, we also included a feature template from Bohnet and Kuhn (2012). This template examines the leftmost child and the rightmost child of a modifier simultaneously. All other highorder features of Zhang and McDonald (2012) only look at arcs on the same side of their head. We trained the parser with hamming-loss-augmented MIRA (Crammer et al., 2006), following Martins et al. (2010). Based on results on the English validation data, in all the experiments, we trained MIRA with 8 epochs and used a beam of size 6 per node. To speed up the parser, we used an unlabeled first-order model to prune unlikely dependency arcs at both training and testing time (Koo and Collins, 2010; Martins et al., 2013). We followed Rush and Petrov (2012) to train the first-order model to minimize filter loss with respect to max-marginal filtering. On the English validation corpus, the filtering model pruned 80% of arcs while keeping the oracle unlabeled attachment score above 99.50%. During train</context>
</contexts>
<marker>Martins, Smith, Xing, Aguiar, Figueiredo, 2010</marker>
<rawString>A. F. T. Martins, N. Smith, E. P. Xing, P. M. Q. Aguiar, and M. A. T. Figueiredo. 2010. Turbo parsers: Dependency parsing by approximate variational inference. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A F T Martins</author>
<author>M B Almeida</author>
<author>N A Smith</author>
</authors>
<title>Turning on the turbo: Fast third-order non-projective turbo parsers.</title>
<date>2013</date>
<booktitle>In Proc. of ACL.</booktitle>
<contexts>
<context position="9863" citStr="Martins et al., 2013" startWordPosition="1644" endWordPosition="1647">ate examines the leftmost child and the rightmost child of a modifier simultaneously. All other highorder features of Zhang and McDonald (2012) only look at arcs on the same side of their head. We trained the parser with hamming-loss-augmented MIRA (Crammer et al., 2006), following Martins et al. (2010). Based on results on the English validation data, in all the experiments, we trained MIRA with 8 epochs and used a beam of size 6 per node. To speed up the parser, we used an unlabeled first-order model to prune unlikely dependency arcs at both training and testing time (Koo and Collins, 2010; Martins et al., 2013). We followed Rush and Petrov (2012) to train the first-order model to minimize filter loss with respect to max-marginal filtering. On the English validation corpus, the filtering model pruned 80% of arcs while keeping the oracle unlabeled attachment score above 99.50%. During training only, we insert the gold tree into the hypergraph if it was mistakenly pruned. This ensures that the gold nodes are always available, which is required for model updates. 3.1 English and Chinese Results We report dependency parsing results on the Penn WSJ Treebank and the Chinese CTB-5 Treebank. Both treebanks a</context>
<context position="12548" citStr="Martins et al. (2013)" startWordPosition="2071" endWordPosition="2074">ported by the fourth-order unlabeled dependency parser of Ma and Zhao (2012), although we did not utilize fourth-order features. The LAS score on Penn-YM is on par with the best reported by Bohnet and Kuhn (2012). On Penn-S, there are not many existing results to compare with, due to the tradition of reporting results on Penn-YM in the past. Nevertheless, our result is higher than the second best by a large margin. Our Chinese parsing scores are the highest reported results. 1http://stp.lingfil.uu.se//—nivre/research/Penn2Malt.html 2The data was prepared by Andr´e F. T. Martins as was done in Martins et al. (2013). 910 Parser UAS Penn-YM Toks/Sec LAS Zhang and Nivre (2011) 92.9- 91.8- †680 Zhang and Nivre (reimpl.) (beam=64) 93.00 91.98 800 Zhang and Nivre (reimpl.) (beam=128) 92.94 91.91 400 Koo and Collins (2010) 93.04 - - Zhang and McDonald (2012) 93.06 91.86 220 Rush and Petrov (2012) - - - Martins et al. (2013) 93.07 - 740 Qian and Liu (2013) 93.17 - 180 Bohnet and Kuhn (2012) 93.39 92.38 †120 Ma and Zhao (2012) 93.4- - - cube-pruning w/ skip 93.21 92.07 300 w/ s-max 93.50 92.41 300 w/ p-max 93.44 92.33 300 Penn-S CTB-5 - 500 250 - - 4460 600 - - - 200 200 200 86.0- 85.93 86.05 - 86.87 - - 87.25 8</context>
<context position="14001" citStr="Martins et al. (2013)" startWordPosition="2352" endWordPosition="2355"> 90.74 90.84 - - - - - - - Table 1: Parsing results on test sets of the Penn Treebank and CTB-5. UAS and LAS are measured on all tokens except punctuations. We also include the tokens per second numbers for different parsers whenever available, although the numbers from other papers were obtained on different machines. Speed numbers marked with † were converted from sentences per second. The speed of our parser is around 200-300 tokens per second for English. This is faster than the parser of Bohnet and Kuhn (2012) which has roughly the same level of accuracy, but is slower than the parser of Martins et al. (2013) and Rush and Petrov (2012), both of which only do unlabeled dependency parsing and are less accurate. Given that predicting labels on arcs can slow down a parser by a constant factor proportional to the size of the label set, the speed of our parser is competitive. We also tried to prune away arc labels based on observed labels for each POS tag pair in the training data. By doing so, we could speed up our parser to 500-600 tokens per second with less than a 0.2% drop in both UAS and LAS. 3.2 Importance of Update Strategies The lower portion of Table 1 compares cube-pruning parsing with differ</context>
<context position="17829" citStr="Martins et al. (2013)" startWordPosition="3001" endWordPosition="3004">.05 91.67 89.87 83.22 85.08 69.68 66.80 86.95 88.30 78.20 77.14 82.16 71.52 81.02 89.44 80.29 87.68 94.98 93.20 93.80 87.79 91.62 80.60 76.86 92.00 92.19 86.46 85.77 88.48 79.61 86.49 91.79 83.35 84.75 89.56 91.49 89.65 83.59 85.00 70.12 66.56 87.07 88.40 78.55 76.62 82.38 71.65 81.67 89.28 80.09 Table 2: Parsing Results for languages from CoNLL 2006/2007 shared tasks. When a language is in both years, we use the 2006 data set. The best results with † are the maximum in the following papers: Buchholz and Marsi (2006), Nivre et al. (2007), Zhang and McDonald (2012), Bohnet and Kuhn (2012), and Martins et al. (2013), For consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011 reimplementation and different update strategies from this paper. 3.3 CoNLL Results We also report parsing results for 17 languages from the CoNLL 2006/2007 shared-task (Buchholz and Marsi, 2006; Nivre et al., 2007). The parser in our experiments can only produce projective dependency trees as it uses an Eisner algorithm backbone to generate the hypergraph (Eisner, 1996)</context>
</contexts>
<marker>Martins, Almeida, Smith, 2013</marker>
<rawString>A. F. T. Martins, M. B. Almeida, and N. A. Smith. 2013. Turning on the turbo: Fast third-order non-projective turbo parsers. In Proc. of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proc. of EMNLP-CoNLL.</booktitle>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proc. of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Qian</author>
<author>Y Liu</author>
</authors>
<title>Branch and bound algorithm for dependency parsing with non-local features.</title>
<date>2013</date>
<journal>TACL, Vol</journal>
<volume>1</volume>
<contexts>
<context position="12888" citStr="Qian and Liu (2013)" startWordPosition="2132" endWordPosition="2135">. Nevertheless, our result is higher than the second best by a large margin. Our Chinese parsing scores are the highest reported results. 1http://stp.lingfil.uu.se//—nivre/research/Penn2Malt.html 2The data was prepared by Andr´e F. T. Martins as was done in Martins et al. (2013). 910 Parser UAS Penn-YM Toks/Sec LAS Zhang and Nivre (2011) 92.9- 91.8- †680 Zhang and Nivre (reimpl.) (beam=64) 93.00 91.98 800 Zhang and Nivre (reimpl.) (beam=128) 92.94 91.91 400 Koo and Collins (2010) 93.04 - - Zhang and McDonald (2012) 93.06 91.86 220 Rush and Petrov (2012) - - - Martins et al. (2013) 93.07 - 740 Qian and Liu (2013) 93.17 - 180 Bohnet and Kuhn (2012) 93.39 92.38 †120 Ma and Zhao (2012) 93.4- - - cube-pruning w/ skip 93.21 92.07 300 w/ s-max 93.50 92.41 300 w/ p-max 93.44 92.33 300 Penn-S CTB-5 - 500 250 - - 4460 600 - - - 200 200 200 86.0- 85.93 86.05 - 86.87 - - 87.25 87.5- 87.4- 86.95 87.78 87.87 Toks/Sec 84.4- 84.42 84.50 - 85.19 - - - 85.9- - 85.23 86.13 86.24 - 700 360 - - - - 100 - - 200 200 200 UAS LAS Toks/Sec UAS LAS - 92.96 93.11 - - 92.7- 92.82 - - - 92.92 90.35 93.59 91.17 93.64 91.28 - 90.74 90.84 - - - - - - - Table 1: Parsing results on test sets of the Penn Treebank and CTB-5. UAS and LAS</context>
</contexts>
<marker>Qian, Liu, 2013</marker>
<rawString>X. Qian and Y. Liu. 2013. Branch and bound algorithm for dependency parsing with non-local features. TACL, Vol 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rush</author>
<author>S Petrov</author>
</authors>
<title>Efficient multi-pass dependency pruning with vine parsing.</title>
<date>2012</date>
<booktitle>In Proc. of NAACL.</booktitle>
<contexts>
<context position="9899" citStr="Rush and Petrov (2012)" startWordPosition="1650" endWordPosition="1653"> the rightmost child of a modifier simultaneously. All other highorder features of Zhang and McDonald (2012) only look at arcs on the same side of their head. We trained the parser with hamming-loss-augmented MIRA (Crammer et al., 2006), following Martins et al. (2010). Based on results on the English validation data, in all the experiments, we trained MIRA with 8 epochs and used a beam of size 6 per node. To speed up the parser, we used an unlabeled first-order model to prune unlikely dependency arcs at both training and testing time (Koo and Collins, 2010; Martins et al., 2013). We followed Rush and Petrov (2012) to train the first-order model to minimize filter loss with respect to max-marginal filtering. On the English validation corpus, the filtering model pruned 80% of arcs while keeping the oracle unlabeled attachment score above 99.50%. During training only, we insert the gold tree into the hypergraph if it was mistakenly pruned. This ensures that the gold nodes are always available, which is required for model updates. 3.1 English and Chinese Results We report dependency parsing results on the Penn WSJ Treebank and the Chinese CTB-5 Treebank. Both treebanks are constituency treebanks. We genera</context>
<context position="12828" citStr="Rush and Petrov (2012)" startWordPosition="2118" endWordPosition="2121">ue to the tradition of reporting results on Penn-YM in the past. Nevertheless, our result is higher than the second best by a large margin. Our Chinese parsing scores are the highest reported results. 1http://stp.lingfil.uu.se//—nivre/research/Penn2Malt.html 2The data was prepared by Andr´e F. T. Martins as was done in Martins et al. (2013). 910 Parser UAS Penn-YM Toks/Sec LAS Zhang and Nivre (2011) 92.9- 91.8- †680 Zhang and Nivre (reimpl.) (beam=64) 93.00 91.98 800 Zhang and Nivre (reimpl.) (beam=128) 92.94 91.91 400 Koo and Collins (2010) 93.04 - - Zhang and McDonald (2012) 93.06 91.86 220 Rush and Petrov (2012) - - - Martins et al. (2013) 93.07 - 740 Qian and Liu (2013) 93.17 - 180 Bohnet and Kuhn (2012) 93.39 92.38 †120 Ma and Zhao (2012) 93.4- - - cube-pruning w/ skip 93.21 92.07 300 w/ s-max 93.50 92.41 300 w/ p-max 93.44 92.33 300 Penn-S CTB-5 - 500 250 - - 4460 600 - - - 200 200 200 86.0- 85.93 86.05 - 86.87 - - 87.25 87.5- 87.4- 86.95 87.78 87.87 Toks/Sec 84.4- 84.42 84.50 - 85.19 - - - 85.9- - 85.23 86.13 86.24 - 700 360 - - - - 100 - - 200 200 200 UAS LAS Toks/Sec UAS LAS - 92.96 93.11 - - 92.7- 92.82 - - - 92.92 90.35 93.59 91.17 93.64 91.28 - 90.74 90.84 - - - - - - - Table 1: Parsing resu</context>
</contexts>
<marker>Rush, Petrov, 2012</marker>
<rawString>A. Rush and S. Petrov. 2012. Efficient multi-pass dependency pruning with vine parsing. In Proc. of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Clark</author>
</authors>
<title>A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing.</title>
<date>2008</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="1390" citStr="Zhang and Clark, 2008" startWordPosition="193" endWordPosition="196">ply it to the cube-pruning parser of Zhang and McDonald (2012). This results in the highest reported scores on WSJ evaluation set (UAS 93.50% and LAS 92.41% respectively) without the aid of additional resources. 1 Introduction Structured prediction problems generally deal with exponentially many outputs, often making exact search infeasible. For sequential search problems, such as tagging and incremental parsing, beam search coupled with perceptron algorithms that account for potential search errors have been shown to be a powerful combination (Collins and Roark, 2004; Daum´e and Marcu, 2005; Zhang and Clark, 2008; Huang et al., 2012). However, sequential search algorithms, and in particular left-to-right beam search (Collins and Roark, 2004; Zhang and Clark, 2008), squeeze inference into a very narrow space. To address this, Huang (2008) formulated constituency parsing as approximate bottom-up inference in order to compactly represent an exponential number of outputs while scoring features of arbitrary scope. This idea was adapted to graph-based dependency parsers by Zhang and McDonald (2012) and shown to outperform left-to-right beam search. Both these examples, bottom-up approximate dependency and c</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Y. Zhang and S. Clark. 2008. A Tale of Two Parsers: Investigating and Combining Graph-based and Transition-based Dependency Parsing. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Zhang</author>
<author>R McDonald</author>
</authors>
<title>Generalized higherorder dependency parsing with cube pruning.</title>
<date>2012</date>
<booktitle>In Proc. of EMNLP.</booktitle>
<contexts>
<context position="831" citStr="Zhang and McDonald (2012)" startWordPosition="111" endWordPosition="114">bstract Online learning algorithms like the perceptron are widely used for structured prediction tasks. For sequential search problems, like left-to-right tagging and parsing, beam search has been successfully combined with perceptron variants that accommodate search errors (Collins and Roark, 2004; Huang et al., 2012). However, perceptron training with inexact search is less studied for bottom-up parsing and, more generally, inference over hypergraphs. In this paper, we generalize the violation-fixing perceptron of Huang et al. (2012) to hypergraphs and apply it to the cube-pruning parser of Zhang and McDonald (2012). This results in the highest reported scores on WSJ evaluation set (UAS 93.50% and LAS 92.41% respectively) without the aid of additional resources. 1 Introduction Structured prediction problems generally deal with exponentially many outputs, often making exact search infeasible. For sequential search problems, such as tagging and incremental parsing, beam search coupled with perceptron algorithms that account for potential search errors have been shown to be a powerful combination (Collins and Roark, 2004; Daum´e and Marcu, 2005; Zhang and Clark, 2008; Huang et al., 2012). However, sequentia</context>
<context position="2774" citStr="Zhang and McDonald (2012)" startWordPosition="399" endWordPosition="402">the hypergraph (Chiang, 2007). Unfortunately, as the scope of features at each node increases, the inexactness of search and its negative impact on learning can potentially be exacerbated. Unlike sequential search, the impact on learning of approximate hypergraph search – as well as methods to mitigate any ill effects – has not been studied. Motivated by this, we develop online learning algorithms for inexact hypergraph search by generalizing the violation-fixing percepron of Huang et al. (2012). We empirically validate the benefit of this approach within the cube-pruning dependency parser of Zhang and McDonald (2012). 2 Structured Perceptron for Inexact Hypergraph Search The structured perceptron algorithm (Collins, 2002) is a general learning algorithm. Given training instances (x, y), the algorithm first solves the decoding problem y′ = argmaxyEY(x) w · f(x, y) given the weight vector w for the high-dimensional feature representation f of the mapping (x, y), where y′ is the prediction under the current model, y� is the gold output and Y(x) is the space of all valid outputs for input x. The perceptron update rule is simply: w′ = w + f(x, y) − f(x, y′). The convergence of original perceptron algorithm rel</context>
<context position="8620" citStr="Zhang and McDonald (2012)" startWordPosition="1431" endWordPosition="1434">on update would move feature A B C D E F G H I J K L N M ft(n) = 909 weights away from the union of the two Viterbi subtrees and towards their gold counterparts. In our experiments, we compare the performance of the two violation-fixing update strategies against two baselines. The first baseline is the standard update, where updates always happen at the root node of a gold tree, even if the Viterbi tree at the root node leads to a non-violation update. The second baseline is the skip update, which also always updates at the root nodes but skips any non-violations. This is the strategy used by Zhang and McDonald (2012). 3 Experiments We ran a number of experiments on the cubepruning dependency parser of Zhang and McDonald (2012), whose search space can be represented as a hypergraph in which the nodes are the complete and incomplete states and the hyperedges are the instantiations of the two parsing rules in the Eisner algorithm (Eisner, 1996). The feature templates we used are a superset of Zhang and McDonald (2012). These features include first-, second-, and third-order features and their labeled counterparts, as well as valency features. In addition, we also included a feature template from Bohnet and K</context>
<context position="11750" citStr="Zhang and McDonald, 2012" startWordPosition="1941" endWordPosition="1944"> evaluation data2. For Chinese, we use the Chinese Penn Treebank converted to dependencies and split into train/- validation/evaluation according to Zhang and Nivre (2011). We report both unlabeled attachment scores (UAS) and labeled attachment scores (LAS), ignoring punctuations (Buchholz and Marsi, 2006). Table 1 displays the results. Our improved cube-pruned parser represents a significant improvement over the feature-rich transition-based parser of Zhang and Nivre (2011) with a large beam size. It also improves over the baseline cube-pruning parser without max-violation update strategies (Zhang and McDonald, 2012), showing the importance of update strategies in inexact hypergraph search. The UAS score on Penn-YM is slightly higher than the best result known in the literature which was reported by the fourth-order unlabeled dependency parser of Ma and Zhao (2012), although we did not utilize fourth-order features. The LAS score on Penn-YM is on par with the best reported by Bohnet and Kuhn (2012). On Penn-S, there are not many existing results to compare with, due to the tradition of reporting results on Penn-YM in the past. Nevertheless, our result is higher than the second best by a large margin. Our </context>
<context position="17778" citStr="Zhang and McDonald (2012)" startWordPosition="2992" endWordPosition="2995">2.07 86.14 86.01 88.36 79.59 85.85 92.03 83.57 84.95 89.05 91.67 89.87 83.22 85.08 69.68 66.80 86.95 88.30 78.20 77.14 82.16 71.52 81.02 89.44 80.29 87.68 94.98 93.20 93.80 87.79 91.62 80.60 76.86 92.00 92.19 86.46 85.77 88.48 79.61 86.49 91.79 83.35 84.75 89.56 91.49 89.65 83.59 85.00 70.12 66.56 87.07 88.40 78.55 76.62 82.38 71.65 81.67 89.28 80.09 Table 2: Parsing Results for languages from CoNLL 2006/2007 shared tasks. When a language is in both years, we use the 2006 data set. The best results with † are the maximum in the following papers: Buchholz and Marsi (2006), Nivre et al. (2007), Zhang and McDonald (2012), Bohnet and Kuhn (2012), and Martins et al. (2013), For consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011 reimplementation and different update strategies from this paper. 3.3 CoNLL Results We also report parsing results for 17 languages from the CoNLL 2006/2007 shared-task (Buchholz and Marsi, 2006; Nivre et al., 2007). The parser in our experiments can only produce projective dependency trees as it uses an Eisner algorithm</context>
</contexts>
<marker>Zhang, McDonald, 2012</marker>
<rawString>H. Zhang and R. McDonald. 2012. Generalized higherorder dependency parsing with cube pruning. In Proc. of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>J Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proc. of ACL-HLT,</booktitle>
<volume>2</volume>
<contexts>
<context position="11296" citStr="Zhang and Nivre (2011)" startWordPosition="1877" endWordPosition="1880">head rules of Yamada and Matsumoto and the Malt label set. For the second English version (PTB-S), we used the Stanford dependency framework (De Marneffe et al., 2006) by applying version 2.0.5 of the Stanford parser. We split the data in the standard way: sections 2-21 for training; section 22 for validation; and section 23 for evaluation. We utilized a linear chain CRF tagger which has an accuracy of 96.9% on the validation data and 97.3% on the evaluation data2. For Chinese, we use the Chinese Penn Treebank converted to dependencies and split into train/- validation/evaluation according to Zhang and Nivre (2011). We report both unlabeled attachment scores (UAS) and labeled attachment scores (LAS), ignoring punctuations (Buchholz and Marsi, 2006). Table 1 displays the results. Our improved cube-pruned parser represents a significant improvement over the feature-rich transition-based parser of Zhang and Nivre (2011) with a large beam size. It also improves over the baseline cube-pruning parser without max-violation update strategies (Zhang and McDonald, 2012), showing the importance of update strategies in inexact hypergraph search. The UAS score on Penn-YM is slightly higher than the best result known</context>
<context position="12608" citStr="Zhang and Nivre (2011)" startWordPosition="2081" endWordPosition="2084">a and Zhao (2012), although we did not utilize fourth-order features. The LAS score on Penn-YM is on par with the best reported by Bohnet and Kuhn (2012). On Penn-S, there are not many existing results to compare with, due to the tradition of reporting results on Penn-YM in the past. Nevertheless, our result is higher than the second best by a large margin. Our Chinese parsing scores are the highest reported results. 1http://stp.lingfil.uu.se//—nivre/research/Penn2Malt.html 2The data was prepared by Andr´e F. T. Martins as was done in Martins et al. (2013). 910 Parser UAS Penn-YM Toks/Sec LAS Zhang and Nivre (2011) 92.9- 91.8- †680 Zhang and Nivre (reimpl.) (beam=64) 93.00 91.98 800 Zhang and Nivre (reimpl.) (beam=128) 92.94 91.91 400 Koo and Collins (2010) 93.04 - - Zhang and McDonald (2012) 93.06 91.86 220 Rush and Petrov (2012) - - - Martins et al. (2013) 93.07 - 740 Qian and Liu (2013) 93.17 - 180 Bohnet and Kuhn (2012) 93.39 92.38 †120 Ma and Zhao (2012) 93.4- - - cube-pruning w/ skip 93.21 92.07 300 w/ s-max 93.50 92.41 300 w/ p-max 93.44 92.33 300 Penn-S CTB-5 - 500 250 - - 4460 600 - - - 200 200 200 86.0- 85.93 86.05 - 86.87 - - 87.25 87.5- 87.4- 86.95 87.78 87.87 Toks/Sec 84.4- 84.42 84.50 - 85</context>
<context position="17992" citStr="Zhang and Nivre (2011)" startWordPosition="3027" endWordPosition="3030">.77 88.48 79.61 86.49 91.79 83.35 84.75 89.56 91.49 89.65 83.59 85.00 70.12 66.56 87.07 88.40 78.55 76.62 82.38 71.65 81.67 89.28 80.09 Table 2: Parsing Results for languages from CoNLL 2006/2007 shared tasks. When a language is in both years, we use the 2006 data set. The best results with † are the maximum in the following papers: Buchholz and Marsi (2006), Nivre et al. (2007), Zhang and McDonald (2012), Bohnet and Kuhn (2012), and Martins et al. (2013), For consistency, we scored the CoNLL 2007 best systems with the CoNLL 2006 evaluation script. ZN 2011 (reimpl.) is our reimplementation of Zhang and Nivre (2011), with a beam of 64. Results in bold are the best among ZN 2011 reimplementation and different update strategies from this paper. 3.3 CoNLL Results We also report parsing results for 17 languages from the CoNLL 2006/2007 shared-task (Buchholz and Marsi, 2006; Nivre et al., 2007). The parser in our experiments can only produce projective dependency trees as it uses an Eisner algorithm backbone to generate the hypergraph (Eisner, 1996). So, at training time, we convert non-projective trees – of which there are many in the CoNLL data – to projective ones through flattening, i.e., attaching words </context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Y. Zhang and J. Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proc. of ACL-HLT, volume 2.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>