<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.996212">
Semi-supervised Feature Transformation for Dependency Parsing
</title>
<author confidence="0.99896">
Wenliang Chen†, Min Zhang†; and Yue Zhang$
</author>
<affiliation confidence="0.9998325">
†School of Computer Science and Technology, Soochow University, China
$Singapore University of Technology and Design, Singapore
</affiliation>
<email confidence="0.973778">
{wlchen, mzhang}@suda.edu.cn
yue zhang@sutd.edu.sg
</email>
<sectionHeader confidence="0.995083" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999845428571429">
In current dependency parsing models, con-
ventional features (i.e. base features) defined
over surface words and part-of-speech tags
in a relatively high-dimensional feature space
may suffer from the data sparseness problem
and thus exhibit less discriminative power on
unseen data. In this paper, we propose a
novel semi-supervised approach to address-
ing the problem by transforming the base fea-
tures into high-level features (i.e. meta fea-
tures) with the help of a large amount of au-
tomatically parsed data. The meta features are
used together with base features in our final
parser. Our studies indicate that our proposed
approach is very effective in processing un-
seen data and features. Experiments on Chi-
nese and English data sets show that the fi-
nal parser achieves the best-reported accuracy
on the Chinese data and comparable accuracy
with the best known parsers on the English
data.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.987182659090909">
In recent years, supervised learning models have
achieved lots of progress in the dependency pars-
ing task, as can be found in the CoNLL shared
tasks (Buchholz and Marsi, 2006; Nivre et al.,
2007). The supervised models take annotated data
as training data, utilize features defined over surface
words, part-of-speech tags, and dependency trees,
and learn the preference of features via adjusting
feature weights.
*Corresponding author
In the supervised learning scenarios, many previ-
ous studies explore rich feature representation that
leads to significant improvements. McDonald and
Pereira (2006) and Carreras (2007) define second-
order features over two adjacent arcs in second-
order graph-based models. Koo and Collins (2010)
use third-order features in a third-order graph-based
model. Bohnet (2010) considers information of
more surrounding words for the graph-based mod-
els, while Zhang and Nivre (2011) define a set
of rich features including the word valency and
the third-order context features for transition-based
models. All these models utilize richer and more
complex feature representations and achieve better
performance than the earlier models that utilize the
simpler features (McDonald et al., 2005; Yamada
and Matsumoto, 2003; Nivre and Scholz, 2004).
However, the richer feature representations result in
a high-dimensional feature space. Features in such a
space may suffer from the data sparseness problem
and thus have less discriminative power on unseen
data. If input sentences contain unknown features
that are not included in training data, the parsers can
usually give lower accuracy.
Several methods have been proposed to alleviate
this problem by using large amounts of unannotated
data, ranging from self-training and co-training (Mc-
Closky et al., 2006; Sagae and Tsujii, 2007) to more
complex methods that collect statistical information
from unannotated sentences and use them as addi-
tional features (Koo et al., 2008; Chen et al., 2009).
In this paper, we propose an alternative approach
to semi-supervised dependency parsing via feature
transformation (Ando and Zhang, 2005). More
</bodyText>
<page confidence="0.85363">
1303
</page>
<note confidence="0.7304085">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1303–1313,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.956219128205128">
specifically, we transform base features to a higher-
level space. The base features defined over surface
words, part-of-speech tags, and dependency trees
are high dimensional and have been explored in the
above previous studies. The higher-level features,
which we call meta features, are low dimensional,
and newly defined in this paper. The key idea be-
hind is that we build connections between known
and unknown base features via the meta features.
From another viewpoint, we can also interpret the
meta features as a way of doing feature smoothing.
Our feature transfer method is simpler than that of
Ando and Zhang (2005), which is based on splitting
the original problem into multiple auxiliary prob-
lems. In our approach, the base features are grouped
and each group relates to a meta feature. In the first
step, we use a baseline parser to parse a large amount
of unannotated sentences. Then we collect the base
features from the parse trees. The collected features
are transformed into predefined discrete values via a
transformation function. Based on the transformed
values, we define a set of meta features. Finally, the
meta features are incorporated directly into parsing
models.
To demonstrate the effectiveness of the proposed
approach, we apply it to the graph-based parsing
models (McDonald and Nivre, 2007). We conduct
experiments on the standard data split of the Penn
English Treebank (Marcus et al., 1993) and the Chi-
nese Treebank Version 5.1 (Xue et al., 2005). The
results indicate that the approach significantly im-
proves the accuracy. In summary, we make the fol-
lowing contributions:
• We define a simple yet useful transformation
function to transform base features to meta fea-
tures automatically. The meta features build
connections between known and unknown base
features, and relieve the data sparseness prob-
lem.
</bodyText>
<listItem confidence="0.9667205">
• Compared to the base features, the number of
meta features is remarkably small.
• We build semi-supervised dependency parsers
that achieve the best accuracy on the Chinese
data and comparable accuracy with the best
known systems on the English data.
</listItem>
<bodyText confidence="0.999809625">
The rest of this paper is organized as follows. Sec-
tion 2 introduces the graph-based parsing model.
Section 3 describes the meta features and meta
parser. Section 4 describes the experiment settings
and reports the experimental results on English and
Chinese data sets. Section 5 discusses related work.
Finally, in Section 6 we summarize the proposed ap-
proach.
</bodyText>
<sectionHeader confidence="0.875631" genericHeader="method">
2 Baseline parser
</sectionHeader>
<bodyText confidence="0.997031666666667">
In this section, we introduce a graph-based pars-
ing model proposed by McDonald et al. (2005) and
build a baseline parser.
</bodyText>
<subsectionHeader confidence="0.9959">
2.1 Graph-based parsing model
</subsectionHeader>
<bodyText confidence="0.997203863636363">
Given an input sentence, dependency parsing is
to build a dependency tree. We define X as
the set of possible input sentences, Y as the
set of possible dependency trees, and D =
(x1, y1), ..., (xi, yi), ..., (xn, yn) as a training set of
n pairs of xi E X and yi E Y . A sentence is de-
noted by x = (w0, w1, ..., wi,..., wm), where w0 is
ROOT and does not depend on any other word and
wi refers to a word.
In the graph-based model, we define ordered pair
(wi, wj) E y as a dependency relation in tree y from
word wi to word wj (wi is the head and wj is the
dependent), Gx as a graph that consists of a set of
nodes Vx = {w0, w1, ..., wi, ..., wm} and a set of
arcs (edges) Ex = {(wi, wj)|i ≠ j, wi E Vx, wj E
(Vx−{w0})}. The parsing model of McDonald et al.
(2005) is to search for the maximum spanning tree
(MST) in graph Gx. We denote Y (Gx) as the set
of all the subgraphs of Gx that are valid dependency
trees (McDonald and Nivre, 2007) for sentence x.
We define the score of a dependency tree y E
Y (Gx) to be the sum of the subgraph scores,
</bodyText>
<equation confidence="0.976049">
∑score(x,y) = score(x,g) (1)
gEy
</equation>
<bodyText confidence="0.9999498">
where g is a spanning subgraph of y, which can be a
single arc or adjacent arcs. In this paper we assume
the dependency tree to be a spanning projective tree.
The model scores each subgraph using a linear rep-
resentation. Then scoring function score(x, g) is,
</bodyText>
<equation confidence="0.730983">
score(x, g) = f(x, g) · w (2)
</equation>
<bodyText confidence="0.999859666666667">
where f(x, g) is a high-dimensional feature vector
based on features defined over g and x and w refers
to the weights for the features.
</bodyText>
<page confidence="0.994131">
1304
</page>
<bodyText confidence="0.9997905">
The maximum spanning tree is the highest scoring
tree in Y(G„). The task of decoding algorithms in
the parsing model for an input sentence x is to find
y*, where
</bodyText>
<equation confidence="0.999700166666667">
y* = arg max score(x, y)
YEY(G�)
∑= arg max score(x, g)
YEY(G�) yEY
∑= arg max f(x, g) • w (3)
YEY(G�) yEY
</equation>
<bodyText confidence="0.999433666666667">
In our system, we use the decoding algorithm
proposed by Carreras (2007), which is a second-
order CKY-style algorithm (Eisner, 1996) and fea-
ture weights w are learned during training using the
Margin Infused Relaxed Algorithm (MIRA) (Cram-
mer and Singer, 2003; McDonald et al., 2005).
</bodyText>
<subsectionHeader confidence="0.999665">
2.2 Base features
</subsectionHeader>
<bodyText confidence="0.999995761904762">
Previous studies have defined different sets of fea-
tures for the graph-based parsing models, such as
the first-order features defined in McDonald et al.
(2005), the second-order parent-siblings features de-
fined in McDonald and Pereira (2006), and the
second-order parent-child-grandchild features de-
fined in Carreras (2007). Bohnet (2010) explorers
a richer set of features than the above sets. We fur-
ther extend the features defined by Bohnet (2010)
by introducing more lexical features as the base fea-
tures. The base feature templates are listed in Table
1, where h, d refer to the head, the dependent re-
spectively, c refers to d’s sibling or child, b refers
to the word between h and d, +1 (−1) refers to the
next (previous) word, w and p refer to the surface
word and part-of-speech tag respectively, [wp] refers
to the surface word or part-of-speech tag, d(h, d) is
the direction of the dependency relation between h
and d, and d(h, d, c) is the directions of the relation
among h, d, and c. We generate the base features
based on the above templates.
</bodyText>
<subsectionHeader confidence="0.999617">
2.3 Baseline parser
</subsectionHeader>
<bodyText confidence="0.999261">
We train a parser with the base features as the Base-
line parser. We define fb(x, g) as the base features
and wb as the corresponding weights. The scoring
function becomes,
</bodyText>
<equation confidence="0.538368">
score(x, g) = fb(x, g) • wb (4)
</equation>
<sectionHeader confidence="0.981207" genericHeader="method">
3 Meta features
</sectionHeader>
<bodyText confidence="0.999945">
In this section, we propose a semi-supervised ap-
proach to transform the features in the base feature
space (FB) to features in a higher-level space (FM)
with the following properties:
</bodyText>
<listItem confidence="0.983398142857143">
• The features in FM are able to build connec-
tions between known and unknown features in
FB and therefore should be highly informative.
• The transformation should be learnable based
on a labeled training set and an automatically
parsed data set, and automatically computable
for the test sentences.
</listItem>
<bodyText confidence="0.999829">
The features in FM are referred to as meta fea-
tures. In order to perform the feature transformation,
we choose to define a simple yet effective mapping
function. Based on the mapped values, we define
feature templates for generating the meta features.
Finally, we build a new parser with the base and
meta features.
</bodyText>
<subsectionHeader confidence="0.999441">
3.1 Template-based mapping function
</subsectionHeader>
<bodyText confidence="0.9999925">
We define a template-based function for mapping
the base features to predefined discrete values. We
first put the base features into several groups and
then perform mapping.
We have a set of base feature templates TB. For
each template Ti E TB, we can generate a set of
base features Fi from dependency trees in the parsed
data, which is automatically parsed by the Baseline
parser. We collect the features and count their fre-
quencies. The collected features are sorted in de-
creasing order of frequencies. The mapping function
for a base feature fb of Fi is defined as follows,
</bodyText>
<equation confidence="0.9584435">
Hi if R(fb) &lt; TOP10
Mi if TOP10 &lt; R(fb) &lt; TOP30
Li if TOP30 &lt; R(fb)
Oi Others
</equation>
<bodyText confidence="0.999967375">
where R(fb) is the position number of fb in the
sorted list, “Others” is defined for the base features
that are not included in the list, and TOP10 and TOP
30 refer to the position numbers of top 10% and top
30% respectively. The numbers, 10% and 30%, are
tuned on the development sets in the experiments.
For a base feature generated from template Ti, we
have four possible values: Hi, Mi, Li, and Oi. In
</bodyText>
<equation confidence="0.7234885">



`b(fb) =
</equation>
<page confidence="0.822053">
1305
</page>
<figure confidence="0.5842375">
(d) Second-order Linear
(b) First-order Linear h[wp], h+1[wp], c[wp], d(h,d,c)
</figure>
<table confidence="0.999183971428571">
h−1[wp], h[wp], c[wp], d(h,d,c)
h[wp], c−1[wp], c[wp], d(h,d,c)
h[wp], c[wp], c+1[wp], d(h,d,c)
h−1[wp], h[wp], c−1[wp], c[wp], d(h,d,c)
h[wp], h+1[wp], c−1[wp], c[wp], d(h,d,c)
h−1[wp], h[wp], c[wp], c+1[wp], d(h,d,c)
h[wp], h+1[wp], c[wp], c+1[wp], d(h,d,c)
d[wp], d+1[wp], c[wp], d(h,d,c)
d−1[wp], d[wp], c[wp], d(h,d,c)
d[wp], c−1[wp], c[wp], d(h,d,c)
d[wp], c[wp], c+1[wp], d(h,d,c)
d[wp], d+1[wp], c−1[wp], c[wp], d(h,d,c)
d[wp], d+1[wp], c[wp], c+1[wp], d(h,d,c)
d−1[wp], d[wp], c−1[wp], c[wp], d(h,d,c)
d−1[wp], d[wp], c[wp], c+1[wp], d(h,d,c)
(a) First-order standard hp, bp, dp, d(h,d)
hp, h+1p, d−1p, dp, d(h,d)
h−1p, hp, d−1p, dp, d(h,d)
hp, h+1p, dp, d+1p, d(h,d)
h−1p, hp, dp, d+1p, d(h,d)
h[wp], d[wp], d(h,d)
h[wp], d(h,d)
dw, dp, d(h,d)
d[wp], d(h,d)
hw, hp, dw, dp, d(h,d)
hp, hw, dp, d(h,d)
hw, dw, dp, d(h,d)
hw, hp, d[wp], d(h,d)
(c) Second-order standard
hp, dp, cp, d(h,d,c)
hw, dw, cw, d(h,d,c)
hp, c[wp], d(h,d,c)
dp, c[wp], d(h,d,c)
hw, c[wp], d(h,d,c)
dw, c[wp], d(h,d,c)
</table>
<tableCaption confidence="0.999875">
Table 1: Base feature templates
</tableCaption>
<bodyText confidence="0.999976">
total, we have 4 x N(TB) possible values for all the
base features, where N(TB) refers to the number of
the base feature templates, which is usually small.
We can obtain the mapped values of all the collected
features via the mapping function.
</bodyText>
<subsectionHeader confidence="0.999906">
3.2 Meta feature templates
</subsectionHeader>
<bodyText confidence="0.998830428571429">
Based on the mapped values, we define meta fea-
ture templates in FM for dependency parsing. The
meta feature templates are listed in Table 2, where
fb is a base feature of FB, hp refers to the part-
of-speech tag of the head and hw refers to the sur-
face word of the head. Of the table, the first tem-
plate uses the mapped value only, the second and
third templates combine the value with the head in-
formation. The number of the meta features is rel-
atively small. It has 4 x N(TB) for the first type,
4 x N(TB) x N(PO5) for the second type, and
4 x N(TB) x N(WORD) for the third one, where
N(PO5) refers to the number of part-of-speech
tags, N(WORD) refers to the number of words.
We remove any feature related to the surface form
if the word is not one of the Top-N most frequent
words in the training data. We used N=1000 for the
experiments for this paper. This method can reduce
the size of the feature sets. The empirical statistics
of the feature sizes at Section 4.2.2 shows that the
size of meta features is only 1.2% of base features.
</bodyText>
<equation confidence="0.512827">
[Φ(fb)]
[Φ(fb)],hp
[Φ(fb)], hw
</equation>
<tableCaption confidence="0.96116">
Table 2: Meta feature templates
</tableCaption>
<subsectionHeader confidence="0.998927">
3.3 Generating meta features
</subsectionHeader>
<bodyText confidence="0.999991444444445">
We use an example to demonstrate how to gener-
ate the meta features based on the meta feature tem-
plates in practice. Suppose that we have sentence “I
ate the meat with a fork.” and want to generate the
meta features for the relation among “ate”, “meat”,
and “with”, where “ate” is the head, “meat” is the
dependent, and “with” is the closest left sibling of
“meat”. Figure 1 shows the example.
We demonstrate the generating procedure using
template Tk = “hw, dw, cw, d(h, d, c)” (the second
template of Table 1-(c) ), which contains the sur-
face forms of the head, the dependent, its sibling,
and the directions of the dependencies among h,
d, and c. We can have a base feature “ate, meat,
with, RIGHTSIB”, where “RIGHTSIB” refers to the
parent-siblings structure with the right direction. In
the auto-parsed data, this feature occurs 200 times
and ranks between TOP10 and TOP30. Accord-
</bodyText>
<page confidence="0.929761">
1306
</page>
<figure confidence="0.23998175">
Tk: hw, dw, cw, d(h,d,c)
Fb: ate, meat, with, RIGHTSIB
(D (fb)=Mk
[Mkl; [Mkl, VV; [Mkl, ate
</figure>
<figureCaption confidence="0.99861">
Figure 1: An example of generating meta features
</figureCaption>
<bodyText confidence="0.9990865">
ing to the mapping function, we obtain the mapped
value Mk. Finally, we have the three meta features
“[Mk]”, “[Mk], V V ”, and “[Mk], ate”, where V V is
the part-of-speech tag of word “ate”. In this way,
we can generate all the meta features for the graph-
based model.
</bodyText>
<subsectionHeader confidence="0.996732">
3.4 Meta parser
</subsectionHeader>
<bodyText confidence="0.961456916666667">
We combine the base features with the meta features
by a new scoring function,
score(x, g) = fb(x, g) &apos; wb + fm(x, g) &apos; wm (5)
where fb(x, g) refers to the base features, fm(x, g)
refers to the meta features, and wb and wm are
their corresponding weights respectively. The fea-
ture weights are learned during training using MIRA
(Crammer and Singer, 2003; McDonald et al.,
2005). Note that wb is also retrained here.
We use the same decoding algorithm in the new
parser as in the Baseline parser. The new parser is
referred to as the meta parser.
</bodyText>
<sectionHeader confidence="0.999742" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.9997895">
We evaluated the effect of the meta features for the
graph-based parsers on English and Chinese data.
</bodyText>
<subsectionHeader confidence="0.975461">
4.1 Experimental settings
</subsectionHeader>
<bodyText confidence="0.9957715">
In our experiments, we used the Penn Treebank
(PTB) (Marcus et al., 1993) for English and the
Chinese Treebank version 5.1 (CTB5) (Xue et al.,
2005) for Chinese. The tool “Penn2Malt”1 was used
</bodyText>
<footnote confidence="0.898046">
1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html
</footnote>
<bodyText confidence="0.9995012">
to convert the data into dependency structures with
the English head rules of Yamada and Matsumoto
(2003) and the Chinese head rules of Zhang and
Clark (2008). We followed the standard data splits
as shown in Table 3. Following the work of Koo et
al. (2008), we used a tagger trained on training data
to provide part-of-speech (POS) tags for the devel-
opment and test sets, and used 10-way jackknifing to
generate part-of-speech tags for the training set. We
used the MXPOST (Ratnaparkhi, 1996) tagger for
English and the CRF-based tagger for Chinese. We
used gold standard segmentation in the CTB5. The
data partition of Chinese were chosen to match pre-
vious work (Duan et al., 2007; Li et al., 2011; Hatori
et al., 2011).
</bodyText>
<table confidence="0.9988952">
train dev test
PTB 2-21 22 23
(sections)
CTB5 001-815 886-931 816-885
(files) 1001-1136 1148-1151 1137-1147
</table>
<tableCaption confidence="0.999375">
Table 3: Standard data splits
</tableCaption>
<bodyText confidence="0.999826333333333">
For the unannotated data in English, we used the
BLLIP WSJ corpus (Charniak et al., 2000) contain-
ing about 43 million words.2 We used the MXPOST
tagger trained on the training data to assign part-of-
speech tags and used the Baseline parser to process
the sentences of the Brown corpus. For the unanno-
tated data in Chinese, we used the Xinhua portion
of Chinese Gigaword3 Version 2.0 (LDC2009T14)
(Huang, 2009), which has approximately 311 mil-
lion words. We used the MMA system (Kruengkrai
et al., 2009) trained on the training data to perform
word segmentation and POS tagging and used the
Baseline parser to parse the sentences in the Giga-
word data.
In collecting the base features, we removed the
features which occur only once in the English data
and less than four times in the Chinese data. The
feature occurrences of one time and four times are
based on the development data performance.
We measured the parser quality by the unlabeled
attachment score (UAS), i.e., the percentage of to-
</bodyText>
<footnote confidence="0.99947525">
2We ensured that the text used for building the meta features
did not include the sentences of the Penn Treebank.
3We excluded the sentences of the CTB data from the Giga-
word data.
</footnote>
<note confidence="0.815462">
I ate the meat with a fork .
</note>
<page confidence="0.989816">
1307
</page>
<bodyText confidence="0.896436">
kens (excluding all punctuation tokens) with the cor-
rect HEAD. We also reported the scores on complete
dependency trees evaluation (COMP).
</bodyText>
<subsectionHeader confidence="0.911294">
4.2 Feature selection on development sets
</subsectionHeader>
<bodyText confidence="0.99998">
We evaluated the parsers with different settings on
the development sets to select the meta features.
</bodyText>
<subsubsectionHeader confidence="0.762338">
4.2.1 Different models vs meta features
</subsubsectionHeader>
<bodyText confidence="0.999687466666667">
In this section, we investigated the effect of dif-
ferent types of meta features for the models trained
on different sizes of training data on English.
There are too many base feature templates to test
one by one. We divided the templates into several
categories. Of Table 1, some templates are only re-
lated to part-of-speech tags (P), some are only re-
lated to surface words (W), and the others contain
both part-of-speech tags and surfaces (M). Table 4
shows the categories, where numbers [1− 4] refer to
the numbers of words involved in templates. For ex-
ample, the templates of N3WM are related to three
words and contain the templates of W and M. Based
on different categories of base templates, we have
different sets of meta features.4
</bodyText>
<table confidence="0.999336333333333">
Category Example
N1P hp, d(h, d)
N1WM hw, d(h, d); hw, hp, d(h, d)
N2P hp, dp, d(h, d)
N2WM hw, dw, d(h, d);
hw, dp, d(h, d)
N3P hp, dp, cp, d(h, d, c)
N3WM hw, dw, cw, d(h, d, c);
dw, d+1p, cp, d(h, d, c)
N4P hp, h+1p, cp, c+1p, d(h, d, c)
N4WM hw,h+1w,cw,c+1w,d(h,d,c);
hw, h+1p, cp, c+1p, d(h, d, c)
</table>
<tableCaption confidence="0.999748">
Table 4: Categories of base feature templates
</tableCaption>
<bodyText confidence="0.9998515">
We randomly selected 1% and 10% of the sen-
tences respectively from the training data. We
trained the POS taggers and Baseline parsers on
these small training data and used them to process
the unannotated data. Then, we generated the meta
features based on the newly auto-parsed data. The
</bodyText>
<footnote confidence="0.88033525">
4We also tested the settings of dividing WM into two sub-
types: W and M. The results showed that both two sub-types
provided positive results. To simplify, we merged W and M
into one category WM.
</footnote>
<bodyText confidence="0.9994148">
meta parsers were trained on the different subsets
of the training data with different sets of meta fea-
tures. Finally, we have three meta parsers: MP1,
MP10, MPFULL, which were trained on 1%, 10%
and 100% of the training data.
</bodyText>
<table confidence="0.997778545454545">
MP1 MP10 MPFULL
Baseline 82.22 89.50 93.01
+N1P 82.42 89.48 93.08
+N1WM 82.80 89.42 93.19
+N2P 81.29 89.01 93.02
+N2WM 82.69 90.10 93.23
+N3P 83.32 89.73 93.05
+N3WM 84.47 90.75 93.80
+N4P 82.73 89.48 93.01
+N4WM 84.07 90.42 93.67
OURS 85.11 91.14 93.91
</table>
<tableCaption confidence="0.999828">
Table 5: Effect of different categories of meta features
</tableCaption>
<bodyText confidence="0.999295071428572">
Table 5 shows the results, where we add each cat-
egory of Table 4 individually. From the table, we
found that the meta features that are only related to
part-of-speech tags did not always help, while the
ones related to the surface words were very helpful.
We also found that MP1 provided the largest relative
improvement among the three settings. These sug-
gested that the more sparse the base features were,
the more effective the corresponding meta features
were. Thus, we built the final parsers by adding
the meta features of N1WM, N2WM, N3WM, and
N4WM. The results showed that OURS achieved
better performance than the systems with individual
sets of meta features.
</bodyText>
<subsubsectionHeader confidence="0.71733">
4.2.2 Different meta feature types
</subsubsectionHeader>
<bodyText confidence="0.999856818181818">
In Table 2, there are three types of meta feature
templates. Here, the results of the parsers with dif-
ferent settings are shown in Table 6, where CORE
refers to the first type, WithPOS refers to the sec-
ond one, and WithWORD refers to the third one.
The results showed that with all the types the parser
(OURS) achieved the best. We also counted the
numbers of the meta features. Only 327,864 (or
1.2%) features were added into OURS. Thus, we
used all the three types of meta features in our final
meta parsers.
</bodyText>
<page confidence="0.977449">
1308
</page>
<table confidence="0.999181">
System NumOfFeat UAS
Baseline 27,119,354 93.01
+CORE +498 93.84
+WithPOS +14,993 93.82
+WithWORD +312,373 93.27
OURS +327,864 93.91
</table>
<tableCaption confidence="0.970488">
Table 6: Numbers of meta features
</tableCaption>
<table confidence="0.998568">
English Chinese
Baseline 92.76 81.01
TrainData 91.93 80.40
P0.1 92.82 81.58
P1 93.14 82.23
P10 93.48 82.81
FULL 93.77 83.08
</table>
<tableCaption confidence="0.99971">
Table 9: Effect of different sizes of auto-parsed data
</tableCaption>
<subsectionHeader confidence="0.998352">
4.3 Main results on test sets
</subsectionHeader>
<bodyText confidence="0.998089">
We then evaluated the meta parsers on the English
and Chinese test sets.
</bodyText>
<subsectionHeader confidence="0.476234">
4.3.1 English
</subsectionHeader>
<bodyText confidence="0.999198125">
The results are shown in Table 7, where Meta-
Parser refers to the meta parser. We found that the
meta parser outperformed the baseline with an ab-
solute improvement of 1.01 points (UAS). The im-
provement was significant in McNemar’s Test (p
&lt; 10−7 ).
9 shows the results, where P0.1, P1, and P10 corre-
spond to 0.1%, 1%, and 10% respectively. From the
table, we found that the parsers obtained more ben-
efits as we used more raw sentences. We also tried
generating the meta features from the training data
only, shown as TrainData in Table 9. However, the
results shows that the parsers performed worse than
the baselines. This is not surprising because only
the known base features are included in the training
data.
</bodyText>
<figure confidence="0.703493125">
UAS COMP
Baseline 92.76 48.05
MetaParser 93.77 51.36
Table 7: Main results on English
4.3.2 Chinese
UAS
Baseline 81.01
MetaParser 83.08
</figure>
<tableCaption confidence="0.990593">
Table 8: Main results on Chinese
</tableCaption>
<bodyText confidence="0.999978714285714">
The results are shown in Table 8. As in the ex-
periment on English, the meta parser outperformed
the baseline. We obtained an absolute improvement
of 2.07 points (UAS). The improvement was signif-
icant in McNemar’s Test (p &lt; 10−8 ).
In summary, Tables 7 and 8 convincingly show
the effectiveness of our proposed approach.
</bodyText>
<subsectionHeader confidence="0.998029">
4.4 Different sizes of unannotated data
</subsectionHeader>
<bodyText confidence="0.99995775">
Here, we considered the improvement relative to the
sizes of the unannotated data used to generate the
meta features. We randomly selected the 0.1%, 1%,
and 10% of the sentences from the full data. Table
</bodyText>
<subsectionHeader confidence="0.9932945">
4.5 Comparison with previous work
4.5.1 English
</subsectionHeader>
<bodyText confidence="0.999811043478261">
Table 10 shows the performance of the previ-
ous systems that were compared, where McDon-
ald06 refers to the second-order parser of McDon-
ald and Pereira (2006), Koo10 refers to the third-
order parser with model1 of Koo and Collins (2010),
Zhang11 refers to the parser of Zhang and Nivre
(2011), Li12 refers to the unlabeled parser of Li et
al. (2012), Koo08 refers to the parser of Koo et al.
(2008), Suzuki09 refers to the parser of Suzuki et al.
(2009), Chen09 refers to the parser of Chen et al.
(2009), Zhou11 refers to the parser of Zhou et al.
(2011), Suzuki11 refers to the parser of Suzuki et al.
(2011), and Chen12 refers to the parser of Chen et
al. (2012).
The results showed that our meta parser out-
performed most of the previous systems and ob-
tained the comparable accuracy with the best result
of Suzuki11 (Suzuki et al., 2011) which combined
the clustering-based word representations of Koo et
al. (2008) and a condensed feature representation.
However, our approach is much simpler than theirs
and we believe that our meta parser can be further
improved by combining their methods.
</bodyText>
<table confidence="0.919359882352941">
COMP
29.71
32.21
1309
Type System UAS COMP
McDonald06 91.5
Sup Koo10 93.04 -
Zhang11 92.9 48.0
Li12 93.12 -
Our Baseline 92.76 48.05
Koo08 93.16
Semi Suzuki09 93.79 47.15
Chen09 93.16
Zhou11 92.64 46.61
Suzuki11 94.22 -
Chen12 92.76 -
MetaParser 93.77 51.36
</table>
<tableCaption confidence="0.999195333333333">
Table 10: Relevant results for English. Sup denotes the
supervised parsers, Semi denotes the parsers with semi-
supervised methods.
</tableCaption>
<subsectionHeader confidence="0.702044">
4.5.2 Chinese
</subsectionHeader>
<bodyText confidence="0.998793916666667">
Table 11 shows the comparative results, where
Li11 refers to the parser of Li et al. (2011), Hatori11
refers to the parser of Hatori et al. (2011), and Li12
refers to the unlabeled parser of Li et al. (2012). The
reported scores on this data were produced by the
supervised learning methods and our Baseline (su-
pervised) parser provided the comparable accuracy.
We found that the score of our meta parser for this
data was the best reported so far and significantly
higher than the previous scores. Note that we used
the auto-assigned POS tags in the test set to match
the above previous studies.
</bodyText>
<table confidence="0.998819666666667">
System UAS COMP
Li11 80.79 29.11
Hatori11 81.33 29.90
Li12 81.21 -
Our Baseline 81.01 29.71
MetaParser 83.08 32.21
</table>
<tableCaption confidence="0.997027">
Table 11: Relevant results for Chinese
</tableCaption>
<subsectionHeader confidence="0.992785">
4.6 Analysis
</subsectionHeader>
<bodyText confidence="0.999574588235294">
Here, we analyzed the effect of the meta features on
the data sparseness problem.
We first checked the effect of unknown features
on the parsing accuracy. We calculated the number
of unknown features in each sentence and computed
the average number per word. The average num-
bers were used to eliminate the influence of varied
sentence sizes. We sorted the test sentences in in-
creasing orders of these average numbers, and di-
vided equally into five bins. BIN 1 is assigned the
sentences with the smallest numbers and BIN 5 is
with the largest ones. Figure 2 shows the average
accuracy scores of the Baseline parsers against to
the bins. From the figure, we found that for both
two languages the Baseline parsers performed worse
while the sentences contained more unknown fea-
tures.
</bodyText>
<figure confidence="0.859832">
1 2 3 4 5
BIN
</figure>
<figureCaption confidence="0.9982165">
Figure 2: Accuracies relative to numbers of unknown fea-
tures (average per word) by Baseline parsers
</figureCaption>
<bodyText confidence="0.999976722222222">
Then, we investigated the effect of the meta fea-
tures. We calculated the average number of ac-
tive meta features per word that were transformed
from the unknown features for each sentence. We
sorted the sentences in increasing order of the av-
erage numbers of active meta features and divided
them into five bins. BIN 1 is assigned the sen-
tences with the smallest numbers and BIN 5 is with
the largest ones. Figures 3 and 4 show the results,
where “Better” is for the sentences where the meta
parsers provided better results than the baselines and
“Worse” is for those where the meta parsers pro-
vided worse results. We found that the gap between
“Better” and “Worse” became larger while the sen-
tences contain more active meta features for the un-
known features. The gap means performance im-
provement. This indicates that the meta features are
very effective in processing the unknown features.
</bodyText>
<sectionHeader confidence="0.999756" genericHeader="method">
5 Related work
</sectionHeader>
<bodyText confidence="0.9661965">
Our approach is to use unannotated data to generate
the meta features to improve dependency parsing.
</bodyText>
<figure confidence="0.9971966">
Accuracy
100
95
90
85
80
75
70
English
Chinese
</figure>
<page confidence="0.51064">
1310
</page>
<figureCaption confidence="0.999333">
Figure 3: Improvement relative to numbers of active meta
features on English (average per word)
Figure 4: Improvement relative to numbers of active meta
features on Chinese (average per word)
</figureCaption>
<bodyText confidence="0.999966897959184">
Several previous studies relevant to our approach
have been conducted.
Koo et al. (2008) used a word clusters trained on a
large amount of unannotated data and designed a set
of new features based on the clusters for dependency
parsing models. Chen et al. (2009) extracted sub-
tree structures from a large amount of data and rep-
resented them as the additional features to improve
dependency parsing. Suzuki et al. (2009) extended a
Semi-supervised Structured Conditional Model (SS-
SCM) of Suzuki and Isozaki (2008) to the depen-
dency parsing problem and combined their method
with the word clustering feature representation of
Koo et al. (2008). Chen et al. (2012) proposed an ap-
proach to representing high-order features for graph-
based dependency parsing models using a depen-
dency language model and beam search. In future
work, we may consider to combine their methods
with ours to improve performance.
Several previous studies used co-training/self-
training methods. McClosky et al. (2006) presented
a self-training method combined with a reranking al-
gorithm for constituency parsing. Sagae and Tsujii
(2007) applied the standard co-training method for
dependency parsing. In their approaches, some au-
tomatically parsed sentences were selected as new
training data, which was used together with the orig-
inal labeled data to retrain a new parser. We are able
to use their approaches on top of the output of our
parsers.
With regard to feature transformation, the work
of Ando and Zhang (2005) is similar in spirit to our
work. They studied semi-supervised text chunking
by using a large projection matrix to map sparse base
features into a small number of high level features.
Their project matrix was trained by transforming the
original problem into a large number of auxiliary
problems, obtaining training data for the auxiliary
problems by automatically labeling raw data and us-
ing alternating structure optimization to estimate the
matrix across all auxiliary tasks. In comparison with
their approach, our method is simpler in the sense
that we do not request any intermediate step of split-
ting the prediction problem, and obtain meta fea-
tures directly from self-annotated data. The training
of our meta feature values is highly efficient, requir-
ing the collection of simple statistics over base fea-
tures from huge amount of data. Hence our method
can potentially be useful to other tasks also.
</bodyText>
<sectionHeader confidence="0.999358" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999626">
In this paper, we have presented a simple but effec-
tive semi-supervised approach to learning the meta
features from the auto-parsed data for dependency
parsing. We build a meta parser by combining the
meta features with the base features in a graph-based
model. The experimental results show that the pro-
posed approach significantly improves the accuracy.
Our meta parser achieves comparable accuracy with
the best known parsers on the English data (Penn
English Treebank) and the best accuracy on the Chi-
nese data (Chinese Treebank Version 5.1) so far.
Further analysis indicate that the meta features are
very effective in processing the unknown features.
The idea described in this paper is general and can
be applied to other NLP applications, such as part-
</bodyText>
<figure confidence="0.994438090909091">
50
Better
Worse
40
30
20
10
0
1 2 3 4 5
BIN
Percentage
50
Better
Worse
40
30
20
10
0
1 2 3 4 5
BIN
Percentage
</figure>
<page confidence="0.984904">
1311
</page>
<bodyText confidence="0.999165">
of-speech tagging and Chinese word segmentation,
in future work.
</bodyText>
<sectionHeader confidence="0.99549" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999128">
This study was started when Wenliang Chen and
Min Zhang were members of the Department of
Human Language Technology, Institute for Info-
comm Research, Singapore. Wenliang Chen was
funded partially by the National Science Founda-
tion of China (61203314) and Yue Zhang was sup-
ported by MOE grant 2012-T2-2-163. We would
also thank the anonymous reviewers for their de-
tailed comments, which have helped us to improve
the quality of this work.
</bodyText>
<sectionHeader confidence="0.99882" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999304670588236">
R.K. Ando and T. Zhang. 2005. A high-performance
semi-supervised learning method for text chunking.
ACL.
Bernd Bohnet. 2010. Top accuracy and fast dependency
parsing is not a contradiction. In Proceedings of the
23rd International Conference on Computational Lin-
guistics (Coling 2010), pages 89–97, Beijing, China,
August. Coling 2010 Organizing Committee.
S. Buchholz and E. Marsi. 2006. CoNLL-X shared
task on multilingual dependency parsing. In Proc. of
CoNLL-X. SIGNLL.
Xavier Carreras. 2007. Experiments with a higher-order
projective dependency parser. In Proceedings of the
CoNLL Shared Task Session of EMNLP-CoNLL 2007,
pages 957–961, Prague, Czech Republic, June. Asso-
ciation for Computational Linguistics.
Eugene Charniak, Don Blaheta, Niyu Ge, Keith Hall,
John Hale, and Mark Johnson. 2000. BLLIP 1987-
89 WSJ Corpus Release 1, LDC2000T43. Linguistic
Data Consortium.
Wenliang Chen, Jun’ichi Kazama, Kiyotaka Uchimoto,
and Kentaro Torisawa. 2009. Improving dependency
parsing with subtrees from auto-parsed data. In Pro-
ceedings of EMNLP 2009, pages 570–579, Singapore,
August.
Wenliang Chen, Min Zhang, and Haizhou Li. 2012. Uti-
lizing dependency language models for graph-based
dependency parsing models. In Proceedings of ACL
2012, Korea, July.
Koby Crammer and Yoram Singer. 2003. Ultraconser-
vative online algorithms for multiclass problems. J.
Mach. Learn. Res., 3:951–991.
Xiangyu Duan, Jun Zhao, and Bo Xu. 2007. Probabilis-
tic models for action-based chinese dependency pars-
ing. In Proceedings of ECML/ECPPKDD, Warsaw,
Poland.
J. Eisner. 1996. Three new probabilistic models for de-
pendency parsing: An exploration. In Proceedings of
COLING1996, pages 340–345.
Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and
Jun’ichi Tsujii. 2011. Incremental joint pos tag-
ging and dependency parsing in chinese. In Proceed-
ings of 5th International Joint Conference on Natu-
ral Language Processing, pages 1216–1224, Chiang
Mai, Thailand, November. Asian Federation of Natu-
ral Language Processing.
Chu-Ren Huang. 2009. Tagged Chinese Gigaword Ver-
sion 2.0, LDC2009T14. Linguistic Data Consortium.
Terry Koo and Michael Collins. 2010. Efficient third-
order dependency parsers. In Proceedings of ACL
2010, pages 1–11, Uppsala, Sweden, July. Association
for Computational Linguistics.
T. Koo, X. Carreras, and M. Collins. 2008. Simple
semi-supervised dependency parsing. In Proceedings
of ACL-08: HLT, Columbus, Ohio, June.
Canasai Kruengkrai, Kiyotaka Uchimoto, Jun’ichi
Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi
Isahara. 2009. An error-driven word-character hybrid
model for joint Chinese word segmentation and POS
tagging. In Proceedings of ACL-IJCNLP2009, pages
513–521, Suntec, Singapore, August. Association for
Computational Linguistics.
Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wen-
liang Chen, and Haizhou Li. 2011. Joint models for
chinese pos tagging and dependency parsing. In Pro-
ceedings of EMNLP 2011, UK, July.
Zhenghua Li, Min Zhang, Wanxiang Che, and Ting Liu.
2012. A separately passive-aggressive training algo-
rithm for joint pos tagging and dependency parsing.
In Proceedings of the 24rd International Conference
on Computational Linguistics (Coling 2012), Mumbai,
India. Coling 2012 Organizing Committee.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a large annotated cor-
pus of English: the Penn Treebank. Computational
Linguisticss, 19(2):313–330.
D. McClosky, E. Charniak, and M. Johnson. 2006.
Reranking and self-training for parser adaptation. In
Proceedings of Coling-ACL, pages 337–344.
R. McDonald and J. Nivre. 2007. Characterizing the
errors of data-driven dependency parsing models. In
Proceedings of EMNLP-CoNLL, pages 122–131.
Ryan McDonald and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing algo-
rithms. In Proceedings of EACL 2006, pages 81–88.
</reference>
<page confidence="0.861896">
1312
</page>
<reference confidence="0.999207816666667">
Ryan McDonald, Koby Crammer, and Fernando Pereira.
2005. Online large-margin training of dependency
parsers. In Proceedings of ACL 2005, pages 91–98.
Association for Computational Linguistics.
Joakim Nivre and Mario Scholz. 2004. Determinis-
tic dependency parsing of English text. In Proc. of
the 20th Intern. Conf. on Computational Linguistics
(COLING), pages 64–70.
J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson,
S. Riedel, and D. Yuret. 2007. The CoNLL 2007
shared task on dependency parsing. In Proceedings
of the CoNLL Shared Task Session of EMNLP-CoNLL
2007, pages 915–932.
Adwait Ratnaparkhi. 1996. A maximum entropy model
for part-of-speech tagging. In Proceedings of EMNLP
1996, pages 133–142.
K. Sagae and J. Tsujii. 2007. Dependency parsing and
domain adaptation with LR models and parser ensem-
bles. In Proceedings of the CoNLL Shared Task Ses-
sion of EMNLP-CoNLL 2007, pages 1044–1050.
Jun Suzuki and Hideki Isozaki. 2008. Semi-supervised
sequential labeling and segmentation using Giga-word
scale unlabeled data. In Proceedings ofACL-08: HLT,
pages 665–673, Columbus, Ohio, June. Association
for Computational Linguistics.
Jun Suzuki, Hideki Isozaki, Xavier Carreras, and Michael
Collins. 2009. An empirical study of semi-supervised
structured conditional models for dependency parsing.
In Proceedings of EMNLP2009, pages 551–560, Sin-
gapore, August. Association for Computational Lin-
guistics.
Jun Suzuki, Hideki Isozaki, and Masaaki Nagata. 2011.
Learning condensed feature representations from large
unsupervised data sets for supervised learning. In Pro-
ceedings of the 49th Annual Meeting of the Associa-
tion for Computational Linguistics: Human Language
Technologies, pages 636–641, Portland, Oregon, USA,
June. Association for Computational Linguistics.
Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha
Palmer. 2005. Building a Large Annotated Chinese
Corpus: the Penn Chinese Treebank. Journal of Natu-
ral Language Engineering, 11(2):207–238.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical
dependency analysis with support vector machines. In
Proceedings of IWPT 2003, pages 195–206.
Y. Zhang and S. Clark. 2008. A tale of two parsers: In-
vestigating and combining graph-based and transition-
based dependency parsing. In Proceedings of EMNLP
2008, pages 562–571, Honolulu, Hawaii, October.
Yue Zhang and Joakim Nivre. 2011. Transition-based
dependency parsing with rich non-local features. In
Proceedings of ACL-HLT2011, pages 188–193, Port-
land, Oregon, USA, June. Association for Computa-
tional Linguistics.
Guangyou Zhou, Jun Zhao, Kang Liu, and Li Cai. 2011.
Exploiting web-derived selectional preference to im-
prove statistical dependency parsing. In Proceedings
of ACL-HLT2011, pages 1556–1565, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
</reference>
<page confidence="0.97849">
1313
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.644428">
<title confidence="0.99986">Semi-supervised Feature Transformation for Dependency Parsing</title>
<author confidence="0.999961">Min Yue</author>
<affiliation confidence="0.9997965">of Computer Science and Technology, Soochow University, University of Technology and Design,</affiliation>
<email confidence="0.705967">yuezhang@sutd.edu.sg</email>
<abstract confidence="0.996010409090909">In current dependency parsing models, conventional features (i.e. base features) defined over surface words and part-of-speech tags in a relatively high-dimensional feature space may suffer from the data sparseness problem and thus exhibit less discriminative power on unseen data. In this paper, we propose a novel semi-supervised approach to addressing the problem by transforming the base features into high-level features (i.e. meta features) with the help of a large amount of automatically parsed data. The meta features are used together with base features in our final parser. Our studies indicate that our proposed approach is very effective in processing unseen data and features. Experiments on Chinese and English data sets show that the final parser achieves the best-reported accuracy on the Chinese data and comparable accuracy with the best known parsers on the English data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R K Ando</author>
<author>T Zhang</author>
</authors>
<title>A high-performance semi-supervised learning method for text chunking.</title>
<date>2005</date>
<publisher>ACL.</publisher>
<contexts>
<context position="3308" citStr="Ando and Zhang, 2005" startWordPosition="489" endWordPosition="492">nput sentences contain unknown features that are not included in training data, the parsers can usually give lower accuracy. Several methods have been proposed to alleviate this problem by using large amounts of unannotated data, ranging from self-training and co-training (McClosky et al., 2006; Sagae and Tsujii, 2007) to more complex methods that collect statistical information from unannotated sentences and use them as additional features (Koo et al., 2008; Chen et al., 2009). In this paper, we propose an alternative approach to semi-supervised dependency parsing via feature transformation (Ando and Zhang, 2005). More 1303 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1303–1313, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics specifically, we transform base features to a higherlevel space. The base features defined over surface words, part-of-speech tags, and dependency trees are high dimensional and have been explored in the above previous studies. The higher-level features, which we call meta features, are low dimensional, and newly defined in this paper. The key idea behind is that we build connections b</context>
<context position="29775" citStr="Ando and Zhang (2005)" startWordPosition="5052" endWordPosition="5055">ith ours to improve performance. Several previous studies used co-training/selftraining methods. McClosky et al. (2006) presented a self-training method combined with a reranking algorithm for constituency parsing. Sagae and Tsujii (2007) applied the standard co-training method for dependency parsing. In their approaches, some automatically parsed sentences were selected as new training data, which was used together with the original labeled data to retrain a new parser. We are able to use their approaches on top of the output of our parsers. With regard to feature transformation, the work of Ando and Zhang (2005) is similar in spirit to our work. They studied semi-supervised text chunking by using a large projection matrix to map sparse base features into a small number of high level features. Their project matrix was trained by transforming the original problem into a large number of auxiliary problems, obtaining training data for the auxiliary problems by automatically labeling raw data and using alternating structure optimization to estimate the matrix across all auxiliary tasks. In comparison with their approach, our method is simpler in the sense that we do not request any intermediate step of sp</context>
</contexts>
<marker>Ando, Zhang, 2005</marker>
<rawString>R.K. Ando and T. Zhang. 2005. A high-performance semi-supervised learning method for text chunking. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Top accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>89--97</pages>
<location>Beijing, China,</location>
<contexts>
<context position="2002" citStr="Bohnet (2010)" startWordPosition="295" endWordPosition="296"> 2007). The supervised models take annotated data as training data, utilize features defined over surface words, part-of-speech tags, and dependency trees, and learn the preference of features via adjusting feature weights. *Corresponding author In the supervised learning scenarios, many previous studies explore rich feature representation that leads to significant improvements. McDonald and Pereira (2006) and Carreras (2007) define secondorder features over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order graph-based model. Bohnet (2010) considers information of more surrounding words for the graph-based models, while Zhang and Nivre (2011) define a set of rich features including the word valency and the third-order context features for transition-based models. All these models utilize richer and more complex feature representations and achieve better performance than the earlier models that utilize the simpler features (McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). However, the richer feature representations result in a high-dimensional feature space. Features in such a space may suffer from the</context>
<context position="8562" citStr="Bohnet (2010)" startWordPosition="1401" endWordPosition="1402">decoding algorithm proposed by Carreras (2007), which is a secondorder CKY-style algorithm (Eisner, 1996) and feature weights w are learned during training using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; McDonald et al., 2005). 2.2 Base features Previous studies have defined different sets of features for the graph-based parsing models, such as the first-order features defined in McDonald et al. (2005), the second-order parent-siblings features defined in McDonald and Pereira (2006), and the second-order parent-child-grandchild features defined in Carreras (2007). Bohnet (2010) explorers a richer set of features than the above sets. We further extend the features defined by Bohnet (2010) by introducing more lexical features as the base features. The base feature templates are listed in Table 1, where h, d refer to the head, the dependent respectively, c refers to d’s sibling or child, b refers to the word between h and d, +1 (−1) refers to the next (previous) word, w and p refer to the surface word and part-of-speech tag respectively, [wp] refers to the surface word or part-of-speech tag, d(h, d) is the direction of the dependency relation between h and d, and d(h, </context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Top accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 89–97, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Buchholz</author>
<author>E Marsi</author>
</authors>
<title>CoNLL-X shared task on multilingual dependency parsing.</title>
<date>2006</date>
<booktitle>In Proc. of CoNLL-X. SIGNLL.</booktitle>
<contexts>
<context position="1374" citStr="Buchholz and Marsi, 2006" startWordPosition="205" endWordPosition="208">elp of a large amount of automatically parsed data. The meta features are used together with base features in our final parser. Our studies indicate that our proposed approach is very effective in processing unseen data and features. Experiments on Chinese and English data sets show that the final parser achieves the best-reported accuracy on the Chinese data and comparable accuracy with the best known parsers on the English data. 1 Introduction In recent years, supervised learning models have achieved lots of progress in the dependency parsing task, as can be found in the CoNLL shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). The supervised models take annotated data as training data, utilize features defined over surface words, part-of-speech tags, and dependency trees, and learn the preference of features via adjusting feature weights. *Corresponding author In the supervised learning scenarios, many previous studies explore rich feature representation that leads to significant improvements. McDonald and Pereira (2006) and Carreras (2007) define secondorder features over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order grap</context>
</contexts>
<marker>Buchholz, Marsi, 2006</marker>
<rawString>S. Buchholz and E. Marsi. 2006. CoNLL-X shared task on multilingual dependency parsing. In Proc. of CoNLL-X. SIGNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xavier Carreras</author>
</authors>
<title>Experiments with a higher-order projective dependency parser.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>957--961</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1818" citStr="Carreras (2007)" startWordPosition="268" endWordPosition="269">recent years, supervised learning models have achieved lots of progress in the dependency parsing task, as can be found in the CoNLL shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). The supervised models take annotated data as training data, utilize features defined over surface words, part-of-speech tags, and dependency trees, and learn the preference of features via adjusting feature weights. *Corresponding author In the supervised learning scenarios, many previous studies explore rich feature representation that leads to significant improvements. McDonald and Pereira (2006) and Carreras (2007) define secondorder features over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order graph-based model. Bohnet (2010) considers information of more surrounding words for the graph-based models, while Zhang and Nivre (2011) define a set of rich features including the word valency and the third-order context features for transition-based models. All these models utilize richer and more complex feature representations and achieve better performance than the earlier models that utilize the simpler features (McDonald et al., 2005; Y</context>
<context position="7995" citStr="Carreras (2007)" startWordPosition="1316" endWordPosition="1317">e. The model scores each subgraph using a linear representation. Then scoring function score(x, g) is, score(x, g) = f(x, g) · w (2) where f(x, g) is a high-dimensional feature vector based on features defined over g and x and w refers to the weights for the features. 1304 The maximum spanning tree is the highest scoring tree in Y(G„). The task of decoding algorithms in the parsing model for an input sentence x is to find y*, where y* = arg max score(x, y) YEY(G�) ∑= arg max score(x, g) YEY(G�) yEY ∑= arg max f(x, g) • w (3) YEY(G�) yEY In our system, we use the decoding algorithm proposed by Carreras (2007), which is a secondorder CKY-style algorithm (Eisner, 1996) and feature weights w are learned during training using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; McDonald et al., 2005). 2.2 Base features Previous studies have defined different sets of features for the graph-based parsing models, such as the first-order features defined in McDonald et al. (2005), the second-order parent-siblings features defined in McDonald and Pereira (2006), and the second-order parent-child-grandchild features defined in Carreras (2007). Bohnet (2010) explorers a richer set of featur</context>
</contexts>
<marker>Carreras, 2007</marker>
<rawString>Xavier Carreras. 2007. Experiments with a higher-order projective dependency parser. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 957–961, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Don Blaheta</author>
<author>Niyu Ge</author>
<author>Keith Hall</author>
<author>John Hale</author>
<author>Mark Johnson</author>
</authors>
<date>2000</date>
<booktitle>BLLIP 1987-89 WSJ Corpus Release 1, LDC2000T43. Linguistic Data Consortium.</booktitle>
<contexts>
<context position="17153" citStr="Charniak et al., 2000" startWordPosition="2889" endWordPosition="2892">POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger for English and the CRF-based tagger for Chinese. We used gold standard segmentation in the CTB5. The data partition of Chinese were chosen to match previous work (Duan et al., 2007; Li et al., 2011; Hatori et al., 2011). train dev test PTB 2-21 22 23 (sections) CTB5 001-815 886-931 816-885 (files) 1001-1136 1148-1151 1137-1147 Table 3: Standard data splits For the unannotated data in English, we used the BLLIP WSJ corpus (Charniak et al., 2000) containing about 43 million words.2 We used the MXPOST tagger trained on the training data to assign part-ofspeech tags and used the Baseline parser to process the sentences of the Brown corpus. For the unannotated data in Chinese, we used the Xinhua portion of Chinese Gigaword3 Version 2.0 (LDC2009T14) (Huang, 2009), which has approximately 311 million words. We used the MMA system (Kruengkrai et al., 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline parser to parse the sentences in the Gigaword data. In collecting the base features, we rem</context>
</contexts>
<marker>Charniak, Blaheta, Ge, Hall, Hale, Johnson, 2000</marker>
<rawString>Eugene Charniak, Don Blaheta, Niyu Ge, Keith Hall, John Hale, and Mark Johnson. 2000. BLLIP 1987-89 WSJ Corpus Release 1, LDC2000T43. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenliang Chen</author>
<author>Jun’ichi Kazama</author>
<author>Kiyotaka Uchimoto</author>
<author>Kentaro Torisawa</author>
</authors>
<title>Improving dependency parsing with subtrees from auto-parsed data.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP 2009,</booktitle>
<pages>570--579</pages>
<location>Singapore,</location>
<contexts>
<context position="3169" citStr="Chen et al., 2009" startWordPosition="470" endWordPosition="473">space. Features in such a space may suffer from the data sparseness problem and thus have less discriminative power on unseen data. If input sentences contain unknown features that are not included in training data, the parsers can usually give lower accuracy. Several methods have been proposed to alleviate this problem by using large amounts of unannotated data, ranging from self-training and co-training (McClosky et al., 2006; Sagae and Tsujii, 2007) to more complex methods that collect statistical information from unannotated sentences and use them as additional features (Koo et al., 2008; Chen et al., 2009). In this paper, we propose an alternative approach to semi-supervised dependency parsing via feature transformation (Ando and Zhang, 2005). More 1303 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1303–1313, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics specifically, we transform base features to a higherlevel space. The base features defined over surface words, part-of-speech tags, and dependency trees are high dimensional and have been explored in the above previous studies. The higher-level feat</context>
<context position="24381" citStr="Chen et al. (2009)" startWordPosition="4147" endWordPosition="4150">ted the 0.1%, 1%, and 10% of the sentences from the full data. Table 4.5 Comparison with previous work 4.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2011) which combined the clustering-based word representations of Koo et al. (2008) and a condensed feature representation. However, our approach is much simpler than theirs and we believe that our meta parser can be further improved by combining their methods. COMP 29</context>
<context position="28547" citStr="Chen et al. (2009)" startWordPosition="4858" endWordPosition="4861">lated work Our approach is to use unannotated data to generate the meta features to improve dependency parsing. Accuracy 100 95 90 85 80 75 70 English Chinese 1310 Figure 3: Improvement relative to numbers of active meta features on English (average per word) Figure 4: Improvement relative to numbers of active meta features on Chinese (average per word) Several previous studies relevant to our approach have been conducted. Koo et al. (2008) used a word clusters trained on a large amount of unannotated data and designed a set of new features based on the clusters for dependency parsing models. Chen et al. (2009) extracted subtree structures from a large amount of data and represented them as the additional features to improve dependency parsing. Suzuki et al. (2009) extended a Semi-supervised Structured Conditional Model (SSSCM) of Suzuki and Isozaki (2008) to the dependency parsing problem and combined their method with the word clustering feature representation of Koo et al. (2008). Chen et al. (2012) proposed an approach to representing high-order features for graphbased dependency parsing models using a dependency language model and beam search. In future work, we may consider to combine their me</context>
</contexts>
<marker>Chen, Kazama, Uchimoto, Torisawa, 2009</marker>
<rawString>Wenliang Chen, Jun’ichi Kazama, Kiyotaka Uchimoto, and Kentaro Torisawa. 2009. Improving dependency parsing with subtrees from auto-parsed data. In Proceedings of EMNLP 2009, pages 570–579, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenliang Chen</author>
<author>Min Zhang</author>
<author>Haizhou Li</author>
</authors>
<title>Utilizing dependency language models for graph-based dependency parsing models.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL 2012, Korea,</booktitle>
<contexts>
<context position="24542" citStr="Chen et al. (2012)" startWordPosition="4178" endWordPosition="4181">us systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2011) which combined the clustering-based word representations of Koo et al. (2008) and a condensed feature representation. However, our approach is much simpler than theirs and we believe that our meta parser can be further improved by combining their methods. COMP 29.71 32.21 1309 Type System UAS COMP McDonald06 91.5 Sup Koo10 93.04 - Zhang11 92.9 48.0 Li12 93.12 - Our Baseline 92.76 48.05 Koo08 93.16 Semi Suzuki09 93.79 47.</context>
<context position="28946" citStr="Chen et al. (2012)" startWordPosition="4922" endWordPosition="4925">proach have been conducted. Koo et al. (2008) used a word clusters trained on a large amount of unannotated data and designed a set of new features based on the clusters for dependency parsing models. Chen et al. (2009) extracted subtree structures from a large amount of data and represented them as the additional features to improve dependency parsing. Suzuki et al. (2009) extended a Semi-supervised Structured Conditional Model (SSSCM) of Suzuki and Isozaki (2008) to the dependency parsing problem and combined their method with the word clustering feature representation of Koo et al. (2008). Chen et al. (2012) proposed an approach to representing high-order features for graphbased dependency parsing models using a dependency language model and beam search. In future work, we may consider to combine their methods with ours to improve performance. Several previous studies used co-training/selftraining methods. McClosky et al. (2006) presented a self-training method combined with a reranking algorithm for constituency parsing. Sagae and Tsujii (2007) applied the standard co-training method for dependency parsing. In their approaches, some automatically parsed sentences were selected as new training da</context>
</contexts>
<marker>Chen, Zhang, Li, 2012</marker>
<rawString>Wenliang Chen, Min Zhang, and Haizhou Li. 2012. Utilizing dependency language models for graph-based dependency parsing models. In Proceedings of ACL 2012, Korea, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Yoram Singer</author>
</authors>
<title>Ultraconservative online algorithms for multiclass problems.</title>
<date>2003</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>3--951</pages>
<contexts>
<context position="8180" citStr="Crammer and Singer, 2003" startWordPosition="1343" endWordPosition="1347"> vector based on features defined over g and x and w refers to the weights for the features. 1304 The maximum spanning tree is the highest scoring tree in Y(G„). The task of decoding algorithms in the parsing model for an input sentence x is to find y*, where y* = arg max score(x, y) YEY(G�) ∑= arg max score(x, g) YEY(G�) yEY ∑= arg max f(x, g) • w (3) YEY(G�) yEY In our system, we use the decoding algorithm proposed by Carreras (2007), which is a secondorder CKY-style algorithm (Eisner, 1996) and feature weights w are learned during training using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; McDonald et al., 2005). 2.2 Base features Previous studies have defined different sets of features for the graph-based parsing models, such as the first-order features defined in McDonald et al. (2005), the second-order parent-siblings features defined in McDonald and Pereira (2006), and the second-order parent-child-grandchild features defined in Carreras (2007). Bohnet (2010) explorers a richer set of features than the above sets. We further extend the features defined by Bohnet (2010) by introducing more lexical features as the base features. The base feature templates are listed in Table</context>
<context position="15622" citStr="Crammer and Singer, 2003" startWordPosition="2635" endWordPosition="2638">pping function, we obtain the mapped value Mk. Finally, we have the three meta features “[Mk]”, “[Mk], V V ”, and “[Mk], ate”, where V V is the part-of-speech tag of word “ate”. In this way, we can generate all the meta features for the graphbased model. 3.4 Meta parser We combine the base features with the meta features by a new scoring function, score(x, g) = fb(x, g) &apos; wb + fm(x, g) &apos; wm (5) where fb(x, g) refers to the base features, fm(x, g) refers to the meta features, and wb and wm are their corresponding weights respectively. The feature weights are learned during training using MIRA (Crammer and Singer, 2003; McDonald et al., 2005). Note that wb is also retrained here. We use the same decoding algorithm in the new parser as in the Baseline parser. The new parser is referred to as the meta parser. 4 Experiments We evaluated the effect of the meta features for the graph-based parsers on English and Chinese data. 4.1 Experimental settings In our experiments, we used the Penn Treebank (PTB) (Marcus et al., 1993) for English and the Chinese Treebank version 5.1 (CTB5) (Xue et al., 2005) for Chinese. The tool “Penn2Malt”1 was used 1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html to convert the data</context>
</contexts>
<marker>Crammer, Singer, 2003</marker>
<rawString>Koby Crammer and Yoram Singer. 2003. Ultraconservative online algorithms for multiclass problems. J. Mach. Learn. Res., 3:951–991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiangyu Duan</author>
<author>Jun Zhao</author>
<author>Bo Xu</author>
</authors>
<title>Probabilistic models for action-based chinese dependency parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of ECML/ECPPKDD,</booktitle>
<location>Warsaw, Poland.</location>
<contexts>
<context position="16885" citStr="Duan et al., 2007" startWordPosition="2844" endWordPosition="2847">ead rules of Yamada and Matsumoto (2003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger for English and the CRF-based tagger for Chinese. We used gold standard segmentation in the CTB5. The data partition of Chinese were chosen to match previous work (Duan et al., 2007; Li et al., 2011; Hatori et al., 2011). train dev test PTB 2-21 22 23 (sections) CTB5 001-815 886-931 816-885 (files) 1001-1136 1148-1151 1137-1147 Table 3: Standard data splits For the unannotated data in English, we used the BLLIP WSJ corpus (Charniak et al., 2000) containing about 43 million words.2 We used the MXPOST tagger trained on the training data to assign part-ofspeech tags and used the Baseline parser to process the sentences of the Brown corpus. For the unannotated data in Chinese, we used the Xinhua portion of Chinese Gigaword3 Version 2.0 (LDC2009T14) (Huang, 2009), which has a</context>
</contexts>
<marker>Duan, Zhao, Xu, 2007</marker>
<rawString>Xiangyu Duan, Jun Zhao, and Bo Xu. 2007. Probabilistic models for action-based chinese dependency parsing. In Proceedings of ECML/ECPPKDD, Warsaw, Poland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Eisner</author>
</authors>
<title>Three new probabilistic models for dependency parsing: An exploration.</title>
<date>1996</date>
<booktitle>In Proceedings of COLING1996,</booktitle>
<pages>340--345</pages>
<contexts>
<context position="8054" citStr="Eisner, 1996" startWordPosition="1325" endWordPosition="1326">on. Then scoring function score(x, g) is, score(x, g) = f(x, g) · w (2) where f(x, g) is a high-dimensional feature vector based on features defined over g and x and w refers to the weights for the features. 1304 The maximum spanning tree is the highest scoring tree in Y(G„). The task of decoding algorithms in the parsing model for an input sentence x is to find y*, where y* = arg max score(x, y) YEY(G�) ∑= arg max score(x, g) YEY(G�) yEY ∑= arg max f(x, g) • w (3) YEY(G�) yEY In our system, we use the decoding algorithm proposed by Carreras (2007), which is a secondorder CKY-style algorithm (Eisner, 1996) and feature weights w are learned during training using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; McDonald et al., 2005). 2.2 Base features Previous studies have defined different sets of features for the graph-based parsing models, such as the first-order features defined in McDonald et al. (2005), the second-order parent-siblings features defined in McDonald and Pereira (2006), and the second-order parent-child-grandchild features defined in Carreras (2007). Bohnet (2010) explorers a richer set of features than the above sets. We further extend the features defi</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>J. Eisner. 1996. Three new probabilistic models for dependency parsing: An exploration. In Proceedings of COLING1996, pages 340–345.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Hatori</author>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Incremental joint pos tagging and dependency parsing in chinese.</title>
<date>2011</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of 5th International Joint Conference on Natural Language Processing,</booktitle>
<pages>1216--1224</pages>
<location>Chiang Mai, Thailand,</location>
<contexts>
<context position="16924" citStr="Hatori et al., 2011" startWordPosition="2852" endWordPosition="2855">003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger for English and the CRF-based tagger for Chinese. We used gold standard segmentation in the CTB5. The data partition of Chinese were chosen to match previous work (Duan et al., 2007; Li et al., 2011; Hatori et al., 2011). train dev test PTB 2-21 22 23 (sections) CTB5 001-815 886-931 816-885 (files) 1001-1136 1148-1151 1137-1147 Table 3: Standard data splits For the unannotated data in English, we used the BLLIP WSJ corpus (Charniak et al., 2000) containing about 43 million words.2 We used the MXPOST tagger trained on the training data to assign part-ofspeech tags and used the Baseline parser to process the sentences of the Brown corpus. For the unannotated data in Chinese, we used the Xinhua portion of Chinese Gigaword3 Version 2.0 (LDC2009T14) (Huang, 2009), which has approximately 311 million words. We used</context>
<context position="25522" citStr="Hatori et al. (2011)" startWordPosition="4339" endWordPosition="4342">hat our meta parser can be further improved by combining their methods. COMP 29.71 32.21 1309 Type System UAS COMP McDonald06 91.5 Sup Koo10 93.04 - Zhang11 92.9 48.0 Li12 93.12 - Our Baseline 92.76 48.05 Koo08 93.16 Semi Suzuki09 93.79 47.15 Chen09 93.16 Zhou11 92.64 46.61 Suzuki11 94.22 - Chen12 92.76 - MetaParser 93.77 51.36 Table 10: Relevant results for English. Sup denotes the supervised parsers, Semi denotes the parsers with semisupervised methods. 4.5.2 Chinese Table 11 shows the comparative results, where Li11 refers to the parser of Li et al. (2011), Hatori11 refers to the parser of Hatori et al. (2011), and Li12 refers to the unlabeled parser of Li et al. (2012). The reported scores on this data were produced by the supervised learning methods and our Baseline (supervised) parser provided the comparable accuracy. We found that the score of our meta parser for this data was the best reported so far and significantly higher than the previous scores. Note that we used the auto-assigned POS tags in the test set to match the above previous studies. System UAS COMP Li11 80.79 29.11 Hatori11 81.33 29.90 Li12 81.21 - Our Baseline 81.01 29.71 MetaParser 83.08 32.21 Table 11: Relevant results for Chi</context>
</contexts>
<marker>Hatori, Matsuzaki, Miyao, Tsujii, 2011</marker>
<rawString>Jun Hatori, Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2011. Incremental joint pos tagging and dependency parsing in chinese. In Proceedings of 5th International Joint Conference on Natural Language Processing, pages 1216–1224, Chiang Mai, Thailand, November. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chu-Ren Huang</author>
</authors>
<title>Tagged Chinese Gigaword Version 2.0, LDC2009T14. Linguistic Data Consortium.</title>
<date>2009</date>
<contexts>
<context position="17472" citStr="Huang, 2009" startWordPosition="2945" endWordPosition="2946">s work (Duan et al., 2007; Li et al., 2011; Hatori et al., 2011). train dev test PTB 2-21 22 23 (sections) CTB5 001-815 886-931 816-885 (files) 1001-1136 1148-1151 1137-1147 Table 3: Standard data splits For the unannotated data in English, we used the BLLIP WSJ corpus (Charniak et al., 2000) containing about 43 million words.2 We used the MXPOST tagger trained on the training data to assign part-ofspeech tags and used the Baseline parser to process the sentences of the Brown corpus. For the unannotated data in Chinese, we used the Xinhua portion of Chinese Gigaword3 Version 2.0 (LDC2009T14) (Huang, 2009), which has approximately 311 million words. We used the MMA system (Kruengkrai et al., 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline parser to parse the sentences in the Gigaword data. In collecting the base features, we removed the features which occur only once in the English data and less than four times in the Chinese data. The feature occurrences of one time and four times are based on the development data performance. We measured the parser quality by the unlabeled attachment score (UAS), i.e., the percentage of to2We ensured that </context>
</contexts>
<marker>Huang, 2009</marker>
<rawString>Chu-Ren Huang. 2009. Tagged Chinese Gigaword Version 2.0, LDC2009T14. Linguistic Data Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Michael Collins</author>
</authors>
<title>Efficient thirdorder dependency parsers.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL 2010,</booktitle>
<pages>1--11</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="1927" citStr="Koo and Collins (2010)" startWordPosition="283" endWordPosition="286">, as can be found in the CoNLL shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). The supervised models take annotated data as training data, utilize features defined over surface words, part-of-speech tags, and dependency trees, and learn the preference of features via adjusting feature weights. *Corresponding author In the supervised learning scenarios, many previous studies explore rich feature representation that leads to significant improvements. McDonald and Pereira (2006) and Carreras (2007) define secondorder features over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order graph-based model. Bohnet (2010) considers information of more surrounding words for the graph-based models, while Zhang and Nivre (2011) define a set of rich features including the word valency and the third-order context features for transition-based models. All these models utilize richer and more complex feature representations and achieve better performance than the earlier models that utilize the simpler features (McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). However, the richer feature representations result in a h</context>
<context position="24113" citStr="Koo and Collins (2010)" startWordPosition="4096" endWordPosition="4099">10−8 ). In summary, Tables 7 and 8 convincingly show the effectiveness of our proposed approach. 4.4 Different sizes of unannotated data Here, we considered the improvement relative to the sizes of the unannotated data used to generate the meta features. We randomly selected the 0.1%, 1%, and 10% of the sentences from the full data. Table 4.5 Comparison with previous work 4.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2</context>
</contexts>
<marker>Koo, Collins, 2010</marker>
<rawString>Terry Koo and Michael Collins. 2010. Efficient thirdorder dependency parsers. In Proceedings of ACL 2010, pages 1–11, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Koo</author>
<author>X Carreras</author>
<author>M Collins</author>
</authors>
<title>Simple semi-supervised dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<location>Columbus, Ohio,</location>
<contexts>
<context position="3149" citStr="Koo et al., 2008" startWordPosition="466" endWordPosition="469">mensional feature space. Features in such a space may suffer from the data sparseness problem and thus have less discriminative power on unseen data. If input sentences contain unknown features that are not included in training data, the parsers can usually give lower accuracy. Several methods have been proposed to alleviate this problem by using large amounts of unannotated data, ranging from self-training and co-training (McClosky et al., 2006; Sagae and Tsujii, 2007) to more complex methods that collect statistical information from unannotated sentences and use them as additional features (Koo et al., 2008; Chen et al., 2009). In this paper, we propose an alternative approach to semi-supervised dependency parsing via feature transformation (Ando and Zhang, 2005). More 1303 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1303–1313, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics specifically, we transform base features to a higherlevel space. The base features defined over surface words, part-of-speech tags, and dependency trees are high dimensional and have been explored in the above previous studies. T</context>
<context position="16460" citStr="Koo et al. (2008)" startWordPosition="2773" endWordPosition="2776">he effect of the meta features for the graph-based parsers on English and Chinese data. 4.1 Experimental settings In our experiments, we used the Penn Treebank (PTB) (Marcus et al., 1993) for English and the Chinese Treebank version 5.1 (CTB5) (Xue et al., 2005) for Chinese. The tool “Penn2Malt”1 was used 1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html to convert the data into dependency structures with the English head rules of Yamada and Matsumoto (2003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger for English and the CRF-based tagger for Chinese. We used gold standard segmentation in the CTB5. The data partition of Chinese were chosen to match previous work (Duan et al., 2007; Li et al., 2011; Hatori et al., 2011). train dev test PTB 2-21 22 23 (sections) CTB5 001-815 886-931 816-885 (files) 1001-1136 1148-1151 1137-1147 Table 3: Standard data spl</context>
<context position="24275" citStr="Koo et al. (2008)" startWordPosition="4127" endWordPosition="4130">ement relative to the sizes of the unannotated data used to generate the meta features. We randomly selected the 0.1%, 1%, and 10% of the sentences from the full data. Table 4.5 Comparison with previous work 4.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2011) which combined the clustering-based word representations of Koo et al. (2008) and a condensed feature representation. However, our approach is much simpler t</context>
<context position="28373" citStr="Koo et al. (2008)" startWordPosition="4827" endWordPosition="4830">a features for the unknown features. The gap means performance improvement. This indicates that the meta features are very effective in processing the unknown features. 5 Related work Our approach is to use unannotated data to generate the meta features to improve dependency parsing. Accuracy 100 95 90 85 80 75 70 English Chinese 1310 Figure 3: Improvement relative to numbers of active meta features on English (average per word) Figure 4: Improvement relative to numbers of active meta features on Chinese (average per word) Several previous studies relevant to our approach have been conducted. Koo et al. (2008) used a word clusters trained on a large amount of unannotated data and designed a set of new features based on the clusters for dependency parsing models. Chen et al. (2009) extracted subtree structures from a large amount of data and represented them as the additional features to improve dependency parsing. Suzuki et al. (2009) extended a Semi-supervised Structured Conditional Model (SSSCM) of Suzuki and Isozaki (2008) to the dependency parsing problem and combined their method with the word clustering feature representation of Koo et al. (2008). Chen et al. (2012) proposed an approach to re</context>
</contexts>
<marker>Koo, Carreras, Collins, 2008</marker>
<rawString>T. Koo, X. Carreras, and M. Collins. 2008. Simple semi-supervised dependency parsing. In Proceedings of ACL-08: HLT, Columbus, Ohio, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Canasai Kruengkrai</author>
<author>Kiyotaka Uchimoto</author>
<author>Jun’ichi Kazama</author>
<author>Yiou Wang</author>
<author>Kentaro Torisawa</author>
<author>Hitoshi Isahara</author>
</authors>
<title>An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP2009,</booktitle>
<pages>513--521</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="17565" citStr="Kruengkrai et al., 2009" startWordPosition="2959" endWordPosition="2962">PTB 2-21 22 23 (sections) CTB5 001-815 886-931 816-885 (files) 1001-1136 1148-1151 1137-1147 Table 3: Standard data splits For the unannotated data in English, we used the BLLIP WSJ corpus (Charniak et al., 2000) containing about 43 million words.2 We used the MXPOST tagger trained on the training data to assign part-ofspeech tags and used the Baseline parser to process the sentences of the Brown corpus. For the unannotated data in Chinese, we used the Xinhua portion of Chinese Gigaword3 Version 2.0 (LDC2009T14) (Huang, 2009), which has approximately 311 million words. We used the MMA system (Kruengkrai et al., 2009) trained on the training data to perform word segmentation and POS tagging and used the Baseline parser to parse the sentences in the Gigaword data. In collecting the base features, we removed the features which occur only once in the English data and less than four times in the Chinese data. The feature occurrences of one time and four times are based on the development data performance. We measured the parser quality by the unlabeled attachment score (UAS), i.e., the percentage of to2We ensured that the text used for building the meta features did not include the sentences of the Penn Treeba</context>
</contexts>
<marker>Kruengkrai, Uchimoto, Kazama, Wang, Torisawa, Isahara, 2009</marker>
<rawString>Canasai Kruengkrai, Kiyotaka Uchimoto, Jun’ichi Kazama, Yiou Wang, Kentaro Torisawa, and Hitoshi Isahara. 2009. An error-driven word-character hybrid model for joint Chinese word segmentation and POS tagging. In Proceedings of ACL-IJCNLP2009, pages 513–521, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhenghua Li</author>
<author>Min Zhang</author>
<author>Wanxiang Che</author>
<author>Ting Liu</author>
<author>Wenliang Chen</author>
<author>Haizhou Li</author>
</authors>
<title>Joint models for chinese pos tagging and dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP 2011,</booktitle>
<location>UK,</location>
<contexts>
<context position="16902" citStr="Li et al., 2011" startWordPosition="2848" endWordPosition="2851"> and Matsumoto (2003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger for English and the CRF-based tagger for Chinese. We used gold standard segmentation in the CTB5. The data partition of Chinese were chosen to match previous work (Duan et al., 2007; Li et al., 2011; Hatori et al., 2011). train dev test PTB 2-21 22 23 (sections) CTB5 001-815 886-931 816-885 (files) 1001-1136 1148-1151 1137-1147 Table 3: Standard data splits For the unannotated data in English, we used the BLLIP WSJ corpus (Charniak et al., 2000) containing about 43 million words.2 We used the MXPOST tagger trained on the training data to assign part-ofspeech tags and used the Baseline parser to process the sentences of the Brown corpus. For the unannotated data in Chinese, we used the Xinhua portion of Chinese Gigaword3 Version 2.0 (LDC2009T14) (Huang, 2009), which has approximately 311 </context>
<context position="25467" citStr="Li et al. (2011)" startWordPosition="4329" endWordPosition="4332">proach is much simpler than theirs and we believe that our meta parser can be further improved by combining their methods. COMP 29.71 32.21 1309 Type System UAS COMP McDonald06 91.5 Sup Koo10 93.04 - Zhang11 92.9 48.0 Li12 93.12 - Our Baseline 92.76 48.05 Koo08 93.16 Semi Suzuki09 93.79 47.15 Chen09 93.16 Zhou11 92.64 46.61 Suzuki11 94.22 - Chen12 92.76 - MetaParser 93.77 51.36 Table 10: Relevant results for English. Sup denotes the supervised parsers, Semi denotes the parsers with semisupervised methods. 4.5.2 Chinese Table 11 shows the comparative results, where Li11 refers to the parser of Li et al. (2011), Hatori11 refers to the parser of Hatori et al. (2011), and Li12 refers to the unlabeled parser of Li et al. (2012). The reported scores on this data were produced by the supervised learning methods and our Baseline (supervised) parser provided the comparable accuracy. We found that the score of our meta parser for this data was the best reported so far and significantly higher than the previous scores. Note that we used the auto-assigned POS tags in the test set to match the above previous studies. System UAS COMP Li11 80.79 29.11 Hatori11 81.33 29.90 Li12 81.21 - Our Baseline 81.01 29.71 Me</context>
</contexts>
<marker>Li, Zhang, Che, Liu, Chen, Li, 2011</marker>
<rawString>Zhenghua Li, Min Zhang, Wanxiang Che, Ting Liu, Wenliang Chen, and Haizhou Li. 2011. Joint models for chinese pos tagging and dependency parsing. In Proceedings of EMNLP 2011, UK, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhenghua Li</author>
<author>Min Zhang</author>
<author>Wanxiang Che</author>
<author>Ting Liu</author>
</authors>
<title>A separately passive-aggressive training algorithm for joint pos tagging and dependency parsing.</title>
<date>2012</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 24rd International Conference on Computational Linguistics (Coling 2012), Mumbai, India. Coling</booktitle>
<contexts>
<context position="24226" citStr="Li et al. (2012)" startWordPosition="4117" endWordPosition="4120"> unannotated data Here, we considered the improvement relative to the sizes of the unannotated data used to generate the meta features. We randomly selected the 0.1%, 1%, and 10% of the sentences from the full data. Table 4.5 Comparison with previous work 4.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2011) which combined the clustering-based word representations of Koo et al. (2008) and a condensed feature repres</context>
<context position="25583" citStr="Li et al. (2012)" startWordPosition="4351" endWordPosition="4354">thods. COMP 29.71 32.21 1309 Type System UAS COMP McDonald06 91.5 Sup Koo10 93.04 - Zhang11 92.9 48.0 Li12 93.12 - Our Baseline 92.76 48.05 Koo08 93.16 Semi Suzuki09 93.79 47.15 Chen09 93.16 Zhou11 92.64 46.61 Suzuki11 94.22 - Chen12 92.76 - MetaParser 93.77 51.36 Table 10: Relevant results for English. Sup denotes the supervised parsers, Semi denotes the parsers with semisupervised methods. 4.5.2 Chinese Table 11 shows the comparative results, where Li11 refers to the parser of Li et al. (2011), Hatori11 refers to the parser of Hatori et al. (2011), and Li12 refers to the unlabeled parser of Li et al. (2012). The reported scores on this data were produced by the supervised learning methods and our Baseline (supervised) parser provided the comparable accuracy. We found that the score of our meta parser for this data was the best reported so far and significantly higher than the previous scores. Note that we used the auto-assigned POS tags in the test set to match the above previous studies. System UAS COMP Li11 80.79 29.11 Hatori11 81.33 29.90 Li12 81.21 - Our Baseline 81.01 29.71 MetaParser 83.08 32.21 Table 11: Relevant results for Chinese 4.6 Analysis Here, we analyzed the effect of the meta fe</context>
</contexts>
<marker>Li, Zhang, Che, Liu, 2012</marker>
<rawString>Zhenghua Li, Min Zhang, Wanxiang Che, and Ting Liu. 2012. A separately passive-aggressive training algorithm for joint pos tagging and dependency parsing. In Proceedings of the 24rd International Conference on Computational Linguistics (Coling 2012), Mumbai, India. Coling 2012 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank. Computational Linguisticss,</title>
<date>1993</date>
<contexts>
<context position="4944" citStr="Marcus et al., 1993" startWordPosition="745" endWordPosition="748"> first step, we use a baseline parser to parse a large amount of unannotated sentences. Then we collect the base features from the parse trees. The collected features are transformed into predefined discrete values via a transformation function. Based on the transformed values, we define a set of meta features. Finally, the meta features are incorporated directly into parsing models. To demonstrate the effectiveness of the proposed approach, we apply it to the graph-based parsing models (McDonald and Nivre, 2007). We conduct experiments on the standard data split of the Penn English Treebank (Marcus et al., 1993) and the Chinese Treebank Version 5.1 (Xue et al., 2005). The results indicate that the approach significantly improves the accuracy. In summary, we make the following contributions: • We define a simple yet useful transformation function to transform base features to meta features automatically. The meta features build connections between known and unknown base features, and relieve the data sparseness problem. • Compared to the base features, the number of meta features is remarkably small. • We build semi-supervised dependency parsers that achieve the best accuracy on the Chinese data and c</context>
<context position="16030" citStr="Marcus et al., 1993" startWordPosition="2706" endWordPosition="2709"> refers to the base features, fm(x, g) refers to the meta features, and wb and wm are their corresponding weights respectively. The feature weights are learned during training using MIRA (Crammer and Singer, 2003; McDonald et al., 2005). Note that wb is also retrained here. We use the same decoding algorithm in the new parser as in the Baseline parser. The new parser is referred to as the meta parser. 4 Experiments We evaluated the effect of the meta features for the graph-based parsers on English and Chinese data. 4.1 Experimental settings In our experiments, we used the Penn Treebank (PTB) (Marcus et al., 1993) for English and the Chinese Treebank version 5.1 (CTB5) (Xue et al., 2005) for Chinese. The tool “Penn2Malt”1 was used 1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html to convert the data into dependency structures with the English head rules of Yamada and Matsumoto (2003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. Computational Linguisticss, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McClosky</author>
<author>E Charniak</author>
<author>M Johnson</author>
</authors>
<title>Reranking and self-training for parser adaptation.</title>
<date>2006</date>
<booktitle>In Proceedings of Coling-ACL,</booktitle>
<pages>337--344</pages>
<contexts>
<context position="2982" citStr="McClosky et al., 2006" startWordPosition="439" endWordPosition="443">at utilize the simpler features (McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). However, the richer feature representations result in a high-dimensional feature space. Features in such a space may suffer from the data sparseness problem and thus have less discriminative power on unseen data. If input sentences contain unknown features that are not included in training data, the parsers can usually give lower accuracy. Several methods have been proposed to alleviate this problem by using large amounts of unannotated data, ranging from self-training and co-training (McClosky et al., 2006; Sagae and Tsujii, 2007) to more complex methods that collect statistical information from unannotated sentences and use them as additional features (Koo et al., 2008; Chen et al., 2009). In this paper, we propose an alternative approach to semi-supervised dependency parsing via feature transformation (Ando and Zhang, 2005). More 1303 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1303–1313, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics specifically, we transform base features to a higherlevel spac</context>
<context position="29273" citStr="McClosky et al. (2006)" startWordPosition="4971" endWordPosition="4974">s to improve dependency parsing. Suzuki et al. (2009) extended a Semi-supervised Structured Conditional Model (SSSCM) of Suzuki and Isozaki (2008) to the dependency parsing problem and combined their method with the word clustering feature representation of Koo et al. (2008). Chen et al. (2012) proposed an approach to representing high-order features for graphbased dependency parsing models using a dependency language model and beam search. In future work, we may consider to combine their methods with ours to improve performance. Several previous studies used co-training/selftraining methods. McClosky et al. (2006) presented a self-training method combined with a reranking algorithm for constituency parsing. Sagae and Tsujii (2007) applied the standard co-training method for dependency parsing. In their approaches, some automatically parsed sentences were selected as new training data, which was used together with the original labeled data to retrain a new parser. We are able to use their approaches on top of the output of our parsers. With regard to feature transformation, the work of Ando and Zhang (2005) is similar in spirit to our work. They studied semi-supervised text chunking by using a large pro</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>D. McClosky, E. Charniak, and M. Johnson. 2006. Reranking and self-training for parser adaptation. In Proceedings of Coling-ACL, pages 337–344.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>J Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>122--131</pages>
<contexts>
<context position="4842" citStr="McDonald and Nivre, 2007" startWordPosition="728" endWordPosition="731">y problems. In our approach, the base features are grouped and each group relates to a meta feature. In the first step, we use a baseline parser to parse a large amount of unannotated sentences. Then we collect the base features from the parse trees. The collected features are transformed into predefined discrete values via a transformation function. Based on the transformed values, we define a set of meta features. Finally, the meta features are incorporated directly into parsing models. To demonstrate the effectiveness of the proposed approach, we apply it to the graph-based parsing models (McDonald and Nivre, 2007). We conduct experiments on the standard data split of the Penn English Treebank (Marcus et al., 1993) and the Chinese Treebank Version 5.1 (Xue et al., 2005). The results indicate that the approach significantly improves the accuracy. In summary, we make the following contributions: • We define a simple yet useful transformation function to transform base features to meta features automatically. The meta features build connections between known and unknown base features, and relieve the data sparseness problem. • Compared to the base features, the number of meta features is remarkably small. </context>
<context position="7084" citStr="McDonald and Nivre, 2007" startWordPosition="1139" endWordPosition="1142">..., wm), where w0 is ROOT and does not depend on any other word and wi refers to a word. In the graph-based model, we define ordered pair (wi, wj) E y as a dependency relation in tree y from word wi to word wj (wi is the head and wj is the dependent), Gx as a graph that consists of a set of nodes Vx = {w0, w1, ..., wi, ..., wm} and a set of arcs (edges) Ex = {(wi, wj)|i ≠ j, wi E Vx, wj E (Vx−{w0})}. The parsing model of McDonald et al. (2005) is to search for the maximum spanning tree (MST) in graph Gx. We denote Y (Gx) as the set of all the subgraphs of Gx that are valid dependency trees (McDonald and Nivre, 2007) for sentence x. We define the score of a dependency tree y E Y (Gx) to be the sum of the subgraph scores, ∑score(x,y) = score(x,g) (1) gEy where g is a spanning subgraph of y, which can be a single arc or adjacent arcs. In this paper we assume the dependency tree to be a spanning projective tree. The model scores each subgraph using a linear representation. Then scoring function score(x, g) is, score(x, g) = f(x, g) · w (2) where f(x, g) is a high-dimensional feature vector based on features defined over g and x and w refers to the weights for the features. 1304 The maximum spanning tree is t</context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>R. McDonald and J. Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proceedings of EMNLP-CoNLL, pages 122–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL</booktitle>
<pages>81--88</pages>
<contexts>
<context position="1798" citStr="McDonald and Pereira (2006)" startWordPosition="263" endWordPosition="266">English data. 1 Introduction In recent years, supervised learning models have achieved lots of progress in the dependency parsing task, as can be found in the CoNLL shared tasks (Buchholz and Marsi, 2006; Nivre et al., 2007). The supervised models take annotated data as training data, utilize features defined over surface words, part-of-speech tags, and dependency trees, and learn the preference of features via adjusting feature weights. *Corresponding author In the supervised learning scenarios, many previous studies explore rich feature representation that leads to significant improvements. McDonald and Pereira (2006) and Carreras (2007) define secondorder features over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order graph-based model. Bohnet (2010) considers information of more surrounding words for the graph-based models, while Zhang and Nivre (2011) define a set of rich features including the word valency and the third-order context features for transition-based models. All these models utilize richer and more complex feature representations and achieve better performance than the earlier models that utilize the simpler features (McDo</context>
<context position="8465" citStr="McDonald and Pereira (2006)" startWordPosition="1387" endWordPosition="1390">y) YEY(G�) ∑= arg max score(x, g) YEY(G�) yEY ∑= arg max f(x, g) • w (3) YEY(G�) yEY In our system, we use the decoding algorithm proposed by Carreras (2007), which is a secondorder CKY-style algorithm (Eisner, 1996) and feature weights w are learned during training using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; McDonald et al., 2005). 2.2 Base features Previous studies have defined different sets of features for the graph-based parsing models, such as the first-order features defined in McDonald et al. (2005), the second-order parent-siblings features defined in McDonald and Pereira (2006), and the second-order parent-child-grandchild features defined in Carreras (2007). Bohnet (2010) explorers a richer set of features than the above sets. We further extend the features defined by Bohnet (2010) by introducing more lexical features as the base features. The base feature templates are listed in Table 1, where h, d refer to the head, the dependent respectively, c refers to d’s sibling or child, b refers to the word between h and d, +1 (−1) refers to the next (previous) word, w and p refer to the surface word and part-of-speech tag respectively, [wp] refers to the surface word or p</context>
<context position="24036" citStr="McDonald and Pereira (2006)" startWordPosition="4081" endWordPosition="4085">ment of 2.07 points (UAS). The improvement was significant in McNemar’s Test (p &lt; 10−8 ). In summary, Tables 7 and 8 convincingly show the effectiveness of our proposed approach. 4.4 Different sizes of unannotated data Here, we considered the improvement relative to the sizes of the unannotated data used to generate the meta features. We randomly selected the 0.1%, 1%, and 10% of the sentences from the full data. Table 4.5 Comparison with previous work 4.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtain</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of EACL 2006, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of ACL 2005,</booktitle>
<pages>91--98</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2415" citStr="McDonald et al., 2005" startWordPosition="354" endWordPosition="357">006) and Carreras (2007) define secondorder features over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order graph-based model. Bohnet (2010) considers information of more surrounding words for the graph-based models, while Zhang and Nivre (2011) define a set of rich features including the word valency and the third-order context features for transition-based models. All these models utilize richer and more complex feature representations and achieve better performance than the earlier models that utilize the simpler features (McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). However, the richer feature representations result in a high-dimensional feature space. Features in such a space may suffer from the data sparseness problem and thus have less discriminative power on unseen data. If input sentences contain unknown features that are not included in training data, the parsers can usually give lower accuracy. Several methods have been proposed to alleviate this problem by using large amounts of unannotated data, ranging from self-training and co-training (McClosky et al., 2006; Sagae and Tsujii, 2007) to more</context>
<context position="6084" citStr="McDonald et al. (2005)" startWordPosition="929" endWordPosition="932">rvised dependency parsers that achieve the best accuracy on the Chinese data and comparable accuracy with the best known systems on the English data. The rest of this paper is organized as follows. Section 2 introduces the graph-based parsing model. Section 3 describes the meta features and meta parser. Section 4 describes the experiment settings and reports the experimental results on English and Chinese data sets. Section 5 discusses related work. Finally, in Section 6 we summarize the proposed approach. 2 Baseline parser In this section, we introduce a graph-based parsing model proposed by McDonald et al. (2005) and build a baseline parser. 2.1 Graph-based parsing model Given an input sentence, dependency parsing is to build a dependency tree. We define X as the set of possible input sentences, Y as the set of possible dependency trees, and D = (x1, y1), ..., (xi, yi), ..., (xn, yn) as a training set of n pairs of xi E X and yi E Y . A sentence is denoted by x = (w0, w1, ..., wi,..., wm), where w0 is ROOT and does not depend on any other word and wi refers to a word. In the graph-based model, we define ordered pair (wi, wj) E y as a dependency relation in tree y from word wi to word wj (wi is the hea</context>
<context position="8204" citStr="McDonald et al., 2005" startWordPosition="1348" endWordPosition="1351">defined over g and x and w refers to the weights for the features. 1304 The maximum spanning tree is the highest scoring tree in Y(G„). The task of decoding algorithms in the parsing model for an input sentence x is to find y*, where y* = arg max score(x, y) YEY(G�) ∑= arg max score(x, g) YEY(G�) yEY ∑= arg max f(x, g) • w (3) YEY(G�) yEY In our system, we use the decoding algorithm proposed by Carreras (2007), which is a secondorder CKY-style algorithm (Eisner, 1996) and feature weights w are learned during training using the Margin Infused Relaxed Algorithm (MIRA) (Crammer and Singer, 2003; McDonald et al., 2005). 2.2 Base features Previous studies have defined different sets of features for the graph-based parsing models, such as the first-order features defined in McDonald et al. (2005), the second-order parent-siblings features defined in McDonald and Pereira (2006), and the second-order parent-child-grandchild features defined in Carreras (2007). Bohnet (2010) explorers a richer set of features than the above sets. We further extend the features defined by Bohnet (2010) by introducing more lexical features as the base features. The base feature templates are listed in Table 1, where h, d refer to </context>
<context position="15646" citStr="McDonald et al., 2005" startWordPosition="2639" endWordPosition="2642">the mapped value Mk. Finally, we have the three meta features “[Mk]”, “[Mk], V V ”, and “[Mk], ate”, where V V is the part-of-speech tag of word “ate”. In this way, we can generate all the meta features for the graphbased model. 3.4 Meta parser We combine the base features with the meta features by a new scoring function, score(x, g) = fb(x, g) &apos; wb + fm(x, g) &apos; wm (5) where fb(x, g) refers to the base features, fm(x, g) refers to the meta features, and wb and wm are their corresponding weights respectively. The feature weights are learned during training using MIRA (Crammer and Singer, 2003; McDonald et al., 2005). Note that wb is also retrained here. We use the same decoding algorithm in the new parser as in the Baseline parser. The new parser is referred to as the meta parser. 4 Experiments We evaluated the effect of the meta features for the graph-based parsers on English and Chinese data. 4.1 Experimental settings In our experiments, we used the Penn Treebank (PTB) (Marcus et al., 1993) for English and the Chinese Treebank version 5.1 (CTB5) (Xue et al., 2005) for Chinese. The tool “Penn2Malt”1 was used 1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html to convert the data into dependency structu</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005. Online large-margin training of dependency parsers. In Proceedings of ACL 2005, pages 91–98. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Mario Scholz</author>
</authors>
<title>Deterministic dependency parsing of English text.</title>
<date>2004</date>
<booktitle>In Proc. of the 20th Intern. Conf. on Computational Linguistics (COLING),</booktitle>
<pages>64--70</pages>
<contexts>
<context position="2468" citStr="Nivre and Scholz, 2004" startWordPosition="362" endWordPosition="365">s over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order graph-based model. Bohnet (2010) considers information of more surrounding words for the graph-based models, while Zhang and Nivre (2011) define a set of rich features including the word valency and the third-order context features for transition-based models. All these models utilize richer and more complex feature representations and achieve better performance than the earlier models that utilize the simpler features (McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). However, the richer feature representations result in a high-dimensional feature space. Features in such a space may suffer from the data sparseness problem and thus have less discriminative power on unseen data. If input sentences contain unknown features that are not included in training data, the parsers can usually give lower accuracy. Several methods have been proposed to alleviate this problem by using large amounts of unannotated data, ranging from self-training and co-training (McClosky et al., 2006; Sagae and Tsujii, 2007) to more complex methods that collect statistical information</context>
</contexts>
<marker>Nivre, Scholz, 2004</marker>
<rawString>Joakim Nivre and Mario Scholz. 2004. Deterministic dependency parsing of English text. In Proc. of the 20th Intern. Conf. on Computational Linguistics (COLING), pages 64–70.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>S K¨ubler</author>
<author>R McDonald</author>
<author>J Nilsson</author>
<author>S Riedel</author>
<author>D Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>915--932</pages>
<marker>Nivre, Hall, K¨ubler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>J. Nivre, J. Hall, S. K¨ubler, R. McDonald, J. Nilsson, S. Riedel, and D. Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>133--142</pages>
<contexts>
<context position="16696" citStr="Ratnaparkhi, 1996" startWordPosition="2813" endWordPosition="2814">1 (CTB5) (Xue et al., 2005) for Chinese. The tool “Penn2Malt”1 was used 1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html to convert the data into dependency structures with the English head rules of Yamada and Matsumoto (2003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger for English and the CRF-based tagger for Chinese. We used gold standard segmentation in the CTB5. The data partition of Chinese were chosen to match previous work (Duan et al., 2007; Li et al., 2011; Hatori et al., 2011). train dev test PTB 2-21 22 23 (sections) CTB5 001-815 886-931 816-885 (files) 1001-1136 1148-1151 1137-1147 Table 3: Standard data splits For the unannotated data in English, we used the BLLIP WSJ corpus (Charniak et al., 2000) containing about 43 million words.2 We used the MXPOST tagger trained on the training data to assign part-ofspeech tags and used the Baseline </context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings of EMNLP 1996, pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Sagae</author>
<author>J Tsujii</author>
</authors>
<title>Dependency parsing and domain adaptation with LR models and parser ensembles.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<pages>1044--1050</pages>
<contexts>
<context position="3007" citStr="Sagae and Tsujii, 2007" startWordPosition="444" endWordPosition="447">features (McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). However, the richer feature representations result in a high-dimensional feature space. Features in such a space may suffer from the data sparseness problem and thus have less discriminative power on unseen data. If input sentences contain unknown features that are not included in training data, the parsers can usually give lower accuracy. Several methods have been proposed to alleviate this problem by using large amounts of unannotated data, ranging from self-training and co-training (McClosky et al., 2006; Sagae and Tsujii, 2007) to more complex methods that collect statistical information from unannotated sentences and use them as additional features (Koo et al., 2008; Chen et al., 2009). In this paper, we propose an alternative approach to semi-supervised dependency parsing via feature transformation (Ando and Zhang, 2005). More 1303 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1303–1313, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics specifically, we transform base features to a higherlevel space. The base features defi</context>
<context position="29392" citStr="Sagae and Tsujii (2007)" startWordPosition="4988" endWordPosition="4991">of Suzuki and Isozaki (2008) to the dependency parsing problem and combined their method with the word clustering feature representation of Koo et al. (2008). Chen et al. (2012) proposed an approach to representing high-order features for graphbased dependency parsing models using a dependency language model and beam search. In future work, we may consider to combine their methods with ours to improve performance. Several previous studies used co-training/selftraining methods. McClosky et al. (2006) presented a self-training method combined with a reranking algorithm for constituency parsing. Sagae and Tsujii (2007) applied the standard co-training method for dependency parsing. In their approaches, some automatically parsed sentences were selected as new training data, which was used together with the original labeled data to retrain a new parser. We are able to use their approaches on top of the output of our parsers. With regard to feature transformation, the work of Ando and Zhang (2005) is similar in spirit to our work. They studied semi-supervised text chunking by using a large projection matrix to map sparse base features into a small number of high level features. Their project matrix was trained</context>
</contexts>
<marker>Sagae, Tsujii, 2007</marker>
<rawString>K. Sagae and J. Tsujii. 2007. Dependency parsing and domain adaptation with LR models and parser ensembles. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 1044–1050.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
</authors>
<title>Semi-supervised sequential labeling and segmentation using Giga-word scale unlabeled data.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-08: HLT,</booktitle>
<pages>665--673</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="28797" citStr="Suzuki and Isozaki (2008)" startWordPosition="4897" endWordPosition="4900">verage per word) Figure 4: Improvement relative to numbers of active meta features on Chinese (average per word) Several previous studies relevant to our approach have been conducted. Koo et al. (2008) used a word clusters trained on a large amount of unannotated data and designed a set of new features based on the clusters for dependency parsing models. Chen et al. (2009) extracted subtree structures from a large amount of data and represented them as the additional features to improve dependency parsing. Suzuki et al. (2009) extended a Semi-supervised Structured Conditional Model (SSSCM) of Suzuki and Isozaki (2008) to the dependency parsing problem and combined their method with the word clustering feature representation of Koo et al. (2008). Chen et al. (2012) proposed an approach to representing high-order features for graphbased dependency parsing models using a dependency language model and beam search. In future work, we may consider to combine their methods with ours to improve performance. Several previous studies used co-training/selftraining methods. McClosky et al. (2006) presented a self-training method combined with a reranking algorithm for constituency parsing. Sagae and Tsujii (2007) appl</context>
</contexts>
<marker>Suzuki, Isozaki, 2008</marker>
<rawString>Jun Suzuki and Hideki Isozaki. 2008. Semi-supervised sequential labeling and segmentation using Giga-word scale unlabeled data. In Proceedings ofACL-08: HLT, pages 665–673, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
<author>Xavier Carreras</author>
<author>Michael Collins</author>
</authors>
<title>An empirical study of semi-supervised structured conditional models for dependency parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP2009,</booktitle>
<pages>551--560</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="24330" citStr="Suzuki et al. (2009)" startWordPosition="4137" endWordPosition="4140">used to generate the meta features. We randomly selected the 0.1%, 1%, and 10% of the sentences from the full data. Table 4.5 Comparison with previous work 4.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2011) which combined the clustering-based word representations of Koo et al. (2008) and a condensed feature representation. However, our approach is much simpler than theirs and we believe that our meta parser can be f</context>
<context position="28704" citStr="Suzuki et al. (2009)" startWordPosition="4884" endWordPosition="4887">ese 1310 Figure 3: Improvement relative to numbers of active meta features on English (average per word) Figure 4: Improvement relative to numbers of active meta features on Chinese (average per word) Several previous studies relevant to our approach have been conducted. Koo et al. (2008) used a word clusters trained on a large amount of unannotated data and designed a set of new features based on the clusters for dependency parsing models. Chen et al. (2009) extracted subtree structures from a large amount of data and represented them as the additional features to improve dependency parsing. Suzuki et al. (2009) extended a Semi-supervised Structured Conditional Model (SSSCM) of Suzuki and Isozaki (2008) to the dependency parsing problem and combined their method with the word clustering feature representation of Koo et al. (2008). Chen et al. (2012) proposed an approach to representing high-order features for graphbased dependency parsing models using a dependency language model and beam search. In future work, we may consider to combine their methods with ours to improve performance. Several previous studies used co-training/selftraining methods. McClosky et al. (2006) presented a self-training meth</context>
</contexts>
<marker>Suzuki, Isozaki, Carreras, Collins, 2009</marker>
<rawString>Jun Suzuki, Hideki Isozaki, Xavier Carreras, and Michael Collins. 2009. An empirical study of semi-supervised structured conditional models for dependency parsing. In Proceedings of EMNLP2009, pages 551–560, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun Suzuki</author>
<author>Hideki Isozaki</author>
<author>Masaaki Nagata</author>
</authors>
<title>Learning condensed feature representations from large unsupervised data sets for supervised learning.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>636--641</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="24487" citStr="Suzuki et al. (2011)" startWordPosition="4167" endWordPosition="4170">.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2011) which combined the clustering-based word representations of Koo et al. (2008) and a condensed feature representation. However, our approach is much simpler than theirs and we believe that our meta parser can be further improved by combining their methods. COMP 29.71 32.21 1309 Type System UAS COMP McDonald06 91.5 Sup Koo10 93.04 - Zhang11 92.9 48.0 Li12 93.12 - Our B</context>
</contexts>
<marker>Suzuki, Isozaki, Nagata, 2011</marker>
<rawString>Jun Suzuki, Hideki Isozaki, and Masaaki Nagata. 2011. Learning condensed feature representations from large unsupervised data sets for supervised learning. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 636–641, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Fei Xia</author>
<author>Fu dong Chiou</author>
<author>Martha Palmer</author>
</authors>
<title>Building a Large Annotated Chinese Corpus: the Penn Chinese Treebank.</title>
<date>2005</date>
<journal>Journal of Natural Language Engineering,</journal>
<volume>11</volume>
<issue>2</issue>
<contexts>
<context position="5000" citStr="Xue et al., 2005" startWordPosition="756" endWordPosition="759">nt of unannotated sentences. Then we collect the base features from the parse trees. The collected features are transformed into predefined discrete values via a transformation function. Based on the transformed values, we define a set of meta features. Finally, the meta features are incorporated directly into parsing models. To demonstrate the effectiveness of the proposed approach, we apply it to the graph-based parsing models (McDonald and Nivre, 2007). We conduct experiments on the standard data split of the Penn English Treebank (Marcus et al., 1993) and the Chinese Treebank Version 5.1 (Xue et al., 2005). The results indicate that the approach significantly improves the accuracy. In summary, we make the following contributions: • We define a simple yet useful transformation function to transform base features to meta features automatically. The meta features build connections between known and unknown base features, and relieve the data sparseness problem. • Compared to the base features, the number of meta features is remarkably small. • We build semi-supervised dependency parsers that achieve the best accuracy on the Chinese data and comparable accuracy with the best known systems on the En</context>
<context position="16105" citStr="Xue et al., 2005" startWordPosition="2719" endWordPosition="2722"> wm are their corresponding weights respectively. The feature weights are learned during training using MIRA (Crammer and Singer, 2003; McDonald et al., 2005). Note that wb is also retrained here. We use the same decoding algorithm in the new parser as in the Baseline parser. The new parser is referred to as the meta parser. 4 Experiments We evaluated the effect of the meta features for the graph-based parsers on English and Chinese data. 4.1 Experimental settings In our experiments, we used the Penn Treebank (PTB) (Marcus et al., 1993) for English and the Chinese Treebank version 5.1 (CTB5) (Xue et al., 2005) for Chinese. The tool “Penn2Malt”1 was used 1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html to convert the data into dependency structures with the English head rules of Yamada and Matsumoto (2003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger f</context>
</contexts>
<marker>Xue, Xia, Chiou, Palmer, 2005</marker>
<rawString>Nianwen Xue, Fei Xia, Fu dong Chiou, and Martha Palmer. 2005. Building a Large Annotated Chinese Corpus: the Penn Chinese Treebank. Journal of Natural Language Engineering, 11(2):207–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of IWPT</booktitle>
<pages>195--206</pages>
<contexts>
<context position="2443" citStr="Yamada and Matsumoto, 2003" startWordPosition="358" endWordPosition="361">) define secondorder features over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order graph-based model. Bohnet (2010) considers information of more surrounding words for the graph-based models, while Zhang and Nivre (2011) define a set of rich features including the word valency and the third-order context features for transition-based models. All these models utilize richer and more complex feature representations and achieve better performance than the earlier models that utilize the simpler features (McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). However, the richer feature representations result in a high-dimensional feature space. Features in such a space may suffer from the data sparseness problem and thus have less discriminative power on unseen data. If input sentences contain unknown features that are not included in training data, the parsers can usually give lower accuracy. Several methods have been proposed to alleviate this problem by using large amounts of unannotated data, ranging from self-training and co-training (McClosky et al., 2006; Sagae and Tsujii, 2007) to more complex methods that collec</context>
<context position="16308" citStr="Yamada and Matsumoto (2003)" startWordPosition="2744" endWordPosition="2747">re. We use the same decoding algorithm in the new parser as in the Baseline parser. The new parser is referred to as the meta parser. 4 Experiments We evaluated the effect of the meta features for the graph-based parsers on English and Chinese data. 4.1 Experimental settings In our experiments, we used the Penn Treebank (PTB) (Marcus et al., 1993) for English and the Chinese Treebank version 5.1 (CTB5) (Xue et al., 2005) for Chinese. The tool “Penn2Malt”1 was used 1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html to convert the data into dependency structures with the English head rules of Yamada and Matsumoto (2003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger for English and the CRF-based tagger for Chinese. We used gold standard segmentation in the CTB5. The data partition of Chinese were chosen to match previous work (Duan et al., 2007; Li et al., 2011; Hato</context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of IWPT 2003, pages 195–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Zhang</author>
<author>S Clark</author>
</authors>
<title>A tale of two parsers: Investigating and combining graph-based and transitionbased dependency parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>562--571</pages>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="16361" citStr="Zhang and Clark (2008)" startWordPosition="2754" endWordPosition="2757">s in the Baseline parser. The new parser is referred to as the meta parser. 4 Experiments We evaluated the effect of the meta features for the graph-based parsers on English and Chinese data. 4.1 Experimental settings In our experiments, we used the Penn Treebank (PTB) (Marcus et al., 1993) for English and the Chinese Treebank version 5.1 (CTB5) (Xue et al., 2005) for Chinese. The tool “Penn2Malt”1 was used 1http://w3.msi.vxu.se/˜nivre/research/Penn2Malt.html to convert the data into dependency structures with the English head rules of Yamada and Matsumoto (2003) and the Chinese head rules of Zhang and Clark (2008). We followed the standard data splits as shown in Table 3. Following the work of Koo et al. (2008), we used a tagger trained on training data to provide part-of-speech (POS) tags for the development and test sets, and used 10-way jackknifing to generate part-of-speech tags for the training set. We used the MXPOST (Ratnaparkhi, 1996) tagger for English and the CRF-based tagger for Chinese. We used gold standard segmentation in the CTB5. The data partition of Chinese were chosen to match previous work (Duan et al., 2007; Li et al., 2011; Hatori et al., 2011). train dev test PTB 2-21 22 23 (sect</context>
</contexts>
<marker>Zhang, Clark, 2008</marker>
<rawString>Y. Zhang and S. Clark. 2008. A tale of two parsers: Investigating and combining graph-based and transitionbased dependency parsing. In Proceedings of EMNLP 2008, pages 562–571, Honolulu, Hawaii, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Joakim Nivre</author>
</authors>
<title>Transition-based dependency parsing with rich non-local features.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT2011,</booktitle>
<pages>188--193</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="2107" citStr="Zhang and Nivre (2011)" startWordPosition="309" endWordPosition="312">r surface words, part-of-speech tags, and dependency trees, and learn the preference of features via adjusting feature weights. *Corresponding author In the supervised learning scenarios, many previous studies explore rich feature representation that leads to significant improvements. McDonald and Pereira (2006) and Carreras (2007) define secondorder features over two adjacent arcs in secondorder graph-based models. Koo and Collins (2010) use third-order features in a third-order graph-based model. Bohnet (2010) considers information of more surrounding words for the graph-based models, while Zhang and Nivre (2011) define a set of rich features including the word valency and the third-order context features for transition-based models. All these models utilize richer and more complex feature representations and achieve better performance than the earlier models that utilize the simpler features (McDonald et al., 2005; Yamada and Matsumoto, 2003; Nivre and Scholz, 2004). However, the richer feature representations result in a high-dimensional feature space. Features in such a space may suffer from the data sparseness problem and thus have less discriminative power on unseen data. If input sentences conta</context>
<context position="24169" citStr="Zhang and Nivre (2011)" startWordPosition="4106" endWordPosition="4109"> effectiveness of our proposed approach. 4.4 Different sizes of unannotated data Here, we considered the improvement relative to the sizes of the unannotated data used to generate the meta features. We randomly selected the 0.1%, 1%, and 10% of the sentences from the full data. Table 4.5 Comparison with previous work 4.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2011) which combined the clustering-based word representa</context>
</contexts>
<marker>Zhang, Nivre, 2011</marker>
<rawString>Yue Zhang and Joakim Nivre. 2011. Transition-based dependency parsing with rich non-local features. In Proceedings of ACL-HLT2011, pages 188–193, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guangyou Zhou</author>
<author>Jun Zhao</author>
<author>Kang Liu</author>
<author>Li Cai</author>
</authors>
<title>Exploiting web-derived selectional preference to improve statistical dependency parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT2011,</booktitle>
<pages>1556--1565</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="24432" citStr="Zhou et al. (2011)" startWordPosition="4157" endWordPosition="4160"> full data. Table 4.5 Comparison with previous work 4.5.1 English Table 10 shows the performance of the previous systems that were compared, where McDonald06 refers to the second-order parser of McDonald and Pereira (2006), Koo10 refers to the thirdorder parser with model1 of Koo and Collins (2010), Zhang11 refers to the parser of Zhang and Nivre (2011), Li12 refers to the unlabeled parser of Li et al. (2012), Koo08 refers to the parser of Koo et al. (2008), Suzuki09 refers to the parser of Suzuki et al. (2009), Chen09 refers to the parser of Chen et al. (2009), Zhou11 refers to the parser of Zhou et al. (2011), Suzuki11 refers to the parser of Suzuki et al. (2011), and Chen12 refers to the parser of Chen et al. (2012). The results showed that our meta parser outperformed most of the previous systems and obtained the comparable accuracy with the best result of Suzuki11 (Suzuki et al., 2011) which combined the clustering-based word representations of Koo et al. (2008) and a condensed feature representation. However, our approach is much simpler than theirs and we believe that our meta parser can be further improved by combining their methods. COMP 29.71 32.21 1309 Type System UAS COMP McDonald06 91.5</context>
</contexts>
<marker>Zhou, Zhao, Liu, Cai, 2011</marker>
<rawString>Guangyou Zhou, Jun Zhao, Kang Liu, and Li Cai. 2011. Exploiting web-derived selectional preference to improve statistical dependency parsing. In Proceedings of ACL-HLT2011, pages 1556–1565, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>