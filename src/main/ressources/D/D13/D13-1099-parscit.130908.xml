<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000077">
<title confidence="0.998683">
Tree Kernel-based Negation and Speculation Scope Detection with
Structured Syntactic Parse Features
</title>
<author confidence="0.90213">
Bowei Zou Guodong Zhou Qiaoming Zhu*
</author>
<affiliation confidence="0.864833">
Natural Language Processing Lab, School of Computer Science and Technology
</affiliation>
<address confidence="0.901003">
Soochow University, Suzhou, 215006, China
</address>
<email confidence="0.999176">
zoubowei@gmail.com, {gdzhou,qmzhu}@suda.edu.cn
</email>
<sectionHeader confidence="0.995633" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.995186538461539">
Scope detection is a key task in information ex-
traction. This paper proposes a new approach for
tree kernel-based scope detection by using the
structured syntactic parse information. In addi-
tion, we have explored the way of selecting
compatible features for different part-of-speech
cues. Experiments on the BioScope corpus show
that both constituent and dependency structured
syntactic parse features have the advantage in
capturing the potential relationships between
cues and their scopes. Compared with the state
of the art scope detection systems, our system
achieves substantial improvement.
</bodyText>
<sectionHeader confidence="0.998983" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999953571428572">
The task of scope detection is to detect the linguis-
tic scope dominated by a specific cue. Current re-
searches in this field focus on two semantic as-
pects: negation and speculation. The negative
scope detection is to detect the linguistic scope
which is repudiated by a negative word (viz., nega-
tive cue, e.g., “not”). In other side, the speculative
scope detection is to detect the uncertain part in a
sentence corresponding to the speculative word
(viz., speculative cue, e.g., “seems”). See the sen-
tence 1) below, the negative cue “not” dominates
the scope of “not expensive”. Similarly, the specu-
lative cue “possible” in sentence 2) dominates the
uncertain scope “the possible future scenarios”.
</bodyText>
<footnote confidence="0.450814666666667">
1) The chair is [not expensive] but comfortable.
2) Considering all that we have seen, what are now
[the possible future scenarios]?
</footnote>
<note confidence="0.57914">
* Corresponding author
</note>
<bodyText confidence="0.99993372972973">
The negative and speculative scope detection
task consists of two basic stages. The first one is to
identify the sentences involving negative or specu-
lative meaning. The second stage is to detect the
linguistic scope of the cue in sentences (Velldal et
al, 2012). In this paper, we focus on the second
stage. That is, by given golden cues, we detect
their linguistic scopes.
We propose a tree kernel-based negation and
speculation scope detection with structured syntac-
tic parse features. In detail, we regard the scope
detection task as a binary classification issue,
which is to classify the tokens in a sentence as be-
ing inside or outside the scope. In the basic
framework, we focus on the analysis and applica-
tion of structured syntactic parse features as fol-
lows:
Both constituent and dependency syntactic fea-
tures have been proved to be effective in scope
detection (Özgür et al, 2009; Øvrelid et al, 2010).
However, these flat features are hardly to reflect
the information implicit in syntactic parse tree
structures. Our intuition is that the segments of the
syntactic parse tree around a negative or specula-
tive cue is effective for scope detection. The relat-
ed structures normally underlay the indirect clues
to identify the relations between cues and their
scopes, e.g., in sentence 1), “but something”, as a
frequently co-occurred syntactic structure with
“not something”, is an effective clue to determine
the linguistic scope of “not”.
The tree kernel classifier (Moschitti, 2006)
based on support vector machines uses a kernel
function between two trees, affording a compari-
son between their substructures. Therefore, a tree
kernel-based scope detection approach with struc-
tured syntactic parse tree is employed. The tree
</bodyText>
<page confidence="0.962857">
968
</page>
<note confidence="0.7340375">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 968–976,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999944730769231">
kernel has been already proved to be effective in
semantic role labeling (Che et al, 2006) and rela-
tion extraction (Zhou et al, 2007).
In addition, the empirical observation shows
that features have imbalanced efficiency for scope
classification, which is normally affected by the
part-of-speech (abbr., POS) of cues. Hence, we
build the discriminative classifiers for each kind of
POS of cues, then explore and select the most
compatible features for them.
We construct a scope detection system by using
the structured syntactic parse features based tree
kernel classification. Compared with the state of
the art scope detection systems, our system
achieves the performance of accuracy 76.90% on
negation and 84.21% on speculation (on Abstracts
sub-corpus). Additionally, we test our system on
different sub-corpus (Clinical Reports and Full
Papers). The results show that our approach has
better cross-domain performance.
The rest of this paper is organized as follows:
Section 2 reviews related work. Section 3 intro-
duces the corpus and corresponding usage in our
experiments. Section 4 describes our approach and
the experiments are presented in Section 5. Finally,
there is a conclusion in Section 6.
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9998988">
Most of the previous studies on negation and spec-
ulation scope detection task can be divided into
two main aspects: the heuristic rule based methods
and the machine learning based methods. We re-
spectively introduce the aspects in below.
</bodyText>
<subsectionHeader confidence="0.998836">
2.1 Heuristic Rule based Methods
</subsectionHeader>
<bodyText confidence="0.999930085106383">
The initial studies for scope detection are to com-
pile effective heuristic rules (Chapman et al, 2001;
Goldin et al, 2003). Recently, the heuristic rule
based methods have further involved the syntactic
features.
Huang et al (2007) implemented a hybrid ap-
proach to automated negation scope detection.
They combined the regular expression matching
with grammatical parsing: negations are classified
on the basis of syntactic categories and located in
parse trees. Their hybrid approach is able to identi-
fy negated concepts in radiology reports even
when they are located at some distance from the
negative term.
Özgür et al (2009) hypothesized that the scope
of a speculation cue can be characterized by its
part-of-speech and the syntactic structure of the
sentence and developed rules to map the scope of a
cue to the nodes in the syntactic parse tree. By
given golden speculation cues, their rule-based
method achieves the accuracies of 79.89% and
61.13% on the Abstracts and the Full-Papers sub-
corpus, respectively.
Øvrelid et al (2010) constructed a small set of
heuristic rules which define the scope for each cue.
In developing these rules, they made use of the
information provided by the guidelines for scope
annotation in the BioScope corpus, combined with
manual inspection of the training data in order to
further generalize over the phenomena discussed
by Vincze et al (2008) and work out interactions of
constructions for various types of cues.
Apostolova et al (2011) presented a linguistical-
ly motivated rule-based system for the detection of
negation and speculation scopes that performs on
par with state-of-the-art machine learning systems.
The rules are automatically extracted from the Bi-
oScope corpus and encode lexico-syntactic pat-
terns in a user-friendly format. While their system
was developed and tested using a biomedical cor-
pus, the rule extraction mechanism is not domain-
specific.
The heuristic rule based methods have bad ro-
bustness in detecting scopes crossing different
meaning aspects (e.g., negative vs. speculative)
and crossing different linguistic resources (e.g.,
Technical Papers vs. Clinical Reports).
</bodyText>
<subsectionHeader confidence="0.999755">
2.2 Machine Learning based Methods
</subsectionHeader>
<bodyText confidence="0.99898425">
The machine learning based methods have been
ignored until the release of the BioScope corpus
(Szarvas et al, 2008), where the large-scale data of
manually annotated cues and corresponding scopes
can support machine learning well.
Morante et al (2008) formulated scope detection
as a chunk classification problem. It is worth not-
ing that they also proposed an effective proper
post-processing approach to ensure the consecu-
tiveness of scope. Then, for further improving the
scope detection, Morante et al (2009a) applied a
meta-learner that uses the predictions of the three
classifiers (TiMBL/SVM/CRF) to predict the
scope.
For the competitive task in CoNLL’2010 (Far-
kas et al, 2010), Morante et al (2010) used a
</bodyText>
<page confidence="0.997706">
969
</page>
<bodyText confidence="0.996873421052631">
memory-based classifier based on the k-nearest
neighbor rule to determine if a token is the first
token in a scope sequence, the last, or neither.
Therefore, in order to guarantee that all scopes are
continuous sequences of tokens they apply a first
post-processing step that builds the sequence of
scope.
The existing machine learning based approaches
substantially improve the robustness of scope de-
tection, and have nearly 80% accuracy. However,
the approaches ignore the availability of the struc-
tured syntactic parse information. This information
involves more clues which can well reflect the re-
lations between cues and scopes. Sánchez et al
(2010) employed a tree kernel based classifier with
CCG structures to identify speculative sentences
on Wikipedia dataset. However, in Sánchez’s ap-
proach, not all sentences are covered by the classi-
fier.
</bodyText>
<sectionHeader confidence="0.997002" genericHeader="method">
3 Corpus
</sectionHeader>
<bodyText confidence="0.999849714285714">
We have employed the BioScope corpus (Szarvas
et al, 2008; Vincze et al, 2008)1, an open resource
from the biomedical domain, as the benchmark
corpus. The corpus contains annotations at the to-
ken level for negative and speculative cues and at
the sentence level for their linguistic scope (as
shown in Figure 1).
</bodyText>
<figureCaption confidence="0.799111090909091">
&lt;sentence id=”S26.8”&gt; These findings &lt;xcope id=”X26.8.2”&gt;
&lt;cue type=”speculation” ref=”X26.8.2”&gt; indicate that &lt;/cue&gt;
&lt;xcope id=”X26.8.1”&gt; corticosteroid resistance in bronchial
asthma &lt;cue type=”negation” ref=”X26.8.1”&gt; can not &lt;/cue&gt;
be explained by abnormalities in corticosteroid receptor char-
acteristics &lt;/xcope&gt;&lt;/xcope&gt; . &lt;/sentence&gt;
(Note: &lt;Sentence&gt; denotes one sentence and the tag “id” denotes its
serial number; &lt;xcope&gt; denotes the scope of a cue; &lt;cue&gt; denotes the
cue, the tag “type” denotes the specific kind of cues and the tag “ref”
is the cue’s serial number.)
Figure 1. An annotated sentence in BioScope.
</figureCaption>
<bodyText confidence="0.962159">
The BioScope corpus consists of three sub-
corpora: biological Full Papers from FlyBase and
BMC Bioinformatics, biological paper Abstracts
from the GENIA corpus (Collier et al, 1999), and
Clinical Reports. Among them, the Full Papers
sub-corpus and the Abstracts sub-corpus come
from the same genre. In comparison, the Clinical
Reports sub-corpus consists of clinical radiology
reports with short sentences.
</bodyText>
<footnote confidence="0.833406">
1 http://www.inf.u-szeged.hu/rgai/bioscope
</footnote>
<bodyText confidence="0.9989556875">
In our experiments, if there is more than one cue
in a sentence, we treat them as different cue and
scope (two independent instances). The statistical
data for our corpus is presented in Table 1 in be-
low.
The average length of sentences in the negation
portion is almost as long as that in speculation,
while the average length of scope in negation is
shorter than that in speculation. In addition, the
length of sentence and scope in both Abstracts and
Full Papers sub-corpora is comparative. But in
Clinical Reports sub-corpus, it is shorter than that
in Abstracts and Full Papers. Thus, looking for the
effective features in short sentences is especially
important for improving the robustness for scope
detection.
</bodyText>
<table confidence="0.99487575">
Abstract Paper Clinical
Iega- Sentences 1594 336 441
tion Words 46849 10246 3613
Scopes 1667 359 442
Av. Len Sentence 29.39 30.49 8.19
Av. Len Scope 9.62 9.36 5.28
Specu- Sentences 2084 519 854
lation Words 62449 16248 10241
Scopes 2693 682 1137
Av. Len Sentence 29.97 31.31 11.99
Av. Len Scope 17.24 15.58 6.99
(Note: “Av. Len” stands for average length.)
</table>
<tableCaption confidence="0.998302">
Table 1. Statistics for our corpus in BioScope.
</tableCaption>
<sectionHeader confidence="0.989654" genericHeader="method">
4 Methodology
</sectionHeader>
<bodyText confidence="0.999857181818182">
We regard the scope detection task as a binary
classification problem, which is to classify each
token in sentence as being the element of the scope
or not. Under this framework, we describe the flat
syntactic features and employ them in our bench-
mark system. Then, we propose a tree kernel-
based scope detection approach using the struc-
tured syntactic parse features. Finally, we con-
struct the discriminative classifier for each kind of
POS of cues, and select the most compatible fea-
tures for each classifier.
</bodyText>
<subsectionHeader confidence="0.999719">
4.1 Flat Syntactic Features
</subsectionHeader>
<bodyText confidence="0.999825428571429">
In our benchmark classification system, the fea-
tures relevant to the cues or tokens are selected.
Then, we have explored the constituent and de-
pendency syntactic features for scope detection.
These features are all flat ones which reflect the
characteristic of tokens, cues, scopes, and the rela-
tion between them.
</bodyText>
<page confidence="0.981032">
970
</page>
<bodyText confidence="0.998723">
Basic Features: Table 2 shows the basic fea-
tures which directly relate to the characteristic of
cues or tokens in our basic classification.
</bodyText>
<subsectionHeader confidence="0.482254">
Feature Remark
</subsectionHeader>
<table confidence="0.674925">
B1 Cue.
B2 Candidate token.
B3 Part-of-speech of candidate token.
B4 Left token of candidate token.
B5 Right token of candidate token.
B6 Positional relation between cue and token.
</table>
<tableCaption confidence="0.997263">
Table 2. Basic features.
</tableCaption>
<bodyText confidence="0.99985888">
ship between cues and tokens by dependency arcs
as shown in Table 4.
The features in Table 2, 3, and 4 have imbal-
anced classification for the scope classification.
Therefore, we adopt the greedy feature selection
algorithm as described in Jiang et al (2006) to pick
up positive features incrementally according to
their contributions. The algorithm repeatedly se-
lects one feature each time, which contributes most,
and stops when adding any of the remaining fea-
tures fails to improve the performance.
Constituent Syntactic Features: For improv-
ing the basic classification, we employ 10 constit-
uent features belonging to two aspects. On the one
hand, we regard the linguistic information of the
neighbor locating around the candidate tokens as
the coherent features (CS1—CS6 in Table 3). These
features are used for detecting the close coopera-
tion of a candidate token co-occurring with its
neighbors in a scope. On the other hand, we regard
the linguistic characteristics of the candidate to-
kens themselves in a syntactic tree as the inherent
features (CS7—CS10 in Table 3). These features
are used for determining whether the token has the
direct relationship with the cue or not.
</bodyText>
<subsectionHeader confidence="0.931984">
Features Remarks
</subsectionHeader>
<tableCaption confidence="0.642987384615385">
CS1 POS of left token.
CS2 POS of right token.
CS3 Syntactic category of left token.
CS4 Syntactic category of right token.
CS5 Syntactic path from left token to the cue.
CS6 Syntactic path from right token to the cue.
CS7 Syntactic category of the token.
CS8 Syntactic path from the token to the cue.
CS9 Whether the syntactic category of the token is
the ancestor of the cue.
CS10 Whether the syntactic category of the cue is the
ancestor of the token.
Table 3. Constituent syntactic features.
</tableCaption>
<subsectionHeader confidence="0.720557">
Features Remarks
</subsectionHeader>
<footnote confidence="0.842750666666667">
DS1 Dependency direction (“head”or “dependent”).
DS2 Dependency syntactic path from the token to cue.
DS3 The kind of dependency relation between the token
and cue.
DS4 Whether the token is the ancestor of the cue.
DS5 Whether the cue is the ancestor of the token.
</footnote>
<tableCaption confidence="0.988701">
Table 4. Dependency syntactic features.
</tableCaption>
<bodyText confidence="0.97722375">
Dependency Syntactic Features: For the effec-
tiveness to obtain the syntactic information far
apart from cues, we use 5 dependency syntactic
features which emphasize the dominant relation-
</bodyText>
<subsectionHeader confidence="0.99924">
4.2 Structured Syntactic Features
</subsectionHeader>
<bodyText confidence="0.999713708333333">
Syntactic trees involve not only the direct bridge
(e.g., syntactic path) between cue and its scope but
also the related structures to support the bridge
(e.g., sub-tree). The related structures normally
involve implicit clues which underlay the relation
between cue and its scope. Therefore, we use the
constituent and dependency syntactic structures as
the supplementary features to further improve the
benchmark system.
Furthermore, we employ the tree kernel-based
classifier to capture the structured information
both in constituent and dependency parsing trees.
The results of the constituent syntactic parser are
typical trees which always consist of the syntactic
category nodes and the terminal nodes. Thus, the
constituent syntactic tree structures could be used
in tree kernel-based classifier directly, but not for
the dependency syntactic tree structures. As Figure
2 shows, in sentence “The chair is not expensive
but comfortable.” the tree kernels cannot represent
the relations on the arcs (e.g., “COIJ” between
“expensive” and “comfortable”). It is hard to use
the relations between tokens and cues in tree ker-
nels.
</bodyText>
<figureCaption confidence="0.906351">
Figure 2: The dependency tree of sentence “The
chair is not expensive but comfortable.”
</figureCaption>
<page confidence="0.97373">
971
</page>
<figureCaption confidence="0.998881">
Figure 3. Two transformational rules.
</figureCaption>
<bodyText confidence="0.9706264">
To solve the problem, we transform the depend-
ency tree into other two forms capable of being
used directly as the compatible features in tree-
kernel based classification. The transformational
rules are described as below:
(1) Extracting the dependency relations to gen-
erate a tree of pure relations (named dependency
relational frame), where the tokens on the nodes of
original dependency tree are ignored and only the
relation labels are used. E.g., the tokens “chair”,
“is”, etc in Figure 2 are all deleted and replaced by
the corresponding relation labels. E.g., “NSUBJ”,
“COP”, etc are used as nodes in the dependency
relational frame, see (1a) &amp; (1b) in Figure 3.
(2) Inserting the tokens which have been deleted
in step (1) into the dependency relational frame
and making them follow and link with their origi-
nal dependency relations. E.g., the tokens “chair”,
“is”, etc are added below the nodes “NSUBJ”,
“COP”, etc, see (2a) &amp; (2b) in Figure 3.
</bodyText>
<figureCaption confidence="0.889185">
Figure 4. Two transformations for tree-kernel.
</figureCaption>
<bodyText confidence="0.999925222222222">
Within the constituent and dependency syntactic
trees, we have employed both the Completed Sub-
Tree and the Critical Path as the syntactic structure
features for our classification. The former is a min-
imum sub-tree that involves the cues and the to-
kens, while the latter is the path from the cues to
the tokens in the completed tree containing the
primary structural information. Figure 4 shows
them.
</bodyText>
<subsectionHeader confidence="0.9911125">
4.3 Part-of-Speech Based Classification Op-
timization
</subsectionHeader>
<bodyText confidence="0.9986285">
Motivating in part by the rule-based approach of
Özgür et al (2009), we infer that features have im-
balanced efficiency for scope classification, nor-
mally affected by the part-of-speech (POS) of cues.
</bodyText>
<table confidence="0.999818714285714">
POS of Cues Number POS of Cues Number
CC 157 VB 31
IN 115 VBD 131
JJ 238 VBG 225
MD 733 VBN 112
NN 43 VBP 561
RB 137 VBZ 207
</table>
<tableCaption confidence="0.939288">
Table 5. Distribution of different POSs of specula-
tive cues in Abstracts sub-corpus.
</tableCaption>
<bodyText confidence="0.913532714285714">
Table 5 shows the distribution for different
POSs of cues in the Abstracts sub-corpus of Bio-
Scope for speculation detection task. The cues of
different POS usually undertake different syntactic
roles. Thus, there are different characteristics in
triggering linguistic scopes. See the two examples
below:
</bodyText>
<construct confidence="0.615785">
3) TCF-1 contained a single DNA box in the [putative
mammalian sex-determining gene SRY].
4) The circadian rhythm of plasma cortisol [either
disappeared or was inverted].
</construct>
<bodyText confidence="0.999976">
The speculative cue “putative” in sentence 3) is
an adjective. The corresponding scope is its modi-
ficatory structure (“putative mammalian sex-
determining gene SRY”). In sentence 4), “ei-
ther...or...” is a conjunction speculation cue. Its
scope is the two connected components (“either
disappeared or was inverted”). Thus, the effective
features for the adjectival cue are normally the de-
pendency features, e.g., the features of DS1 and
DS5 in Table 4, while the features for the conjunc-
tion cue are normally the constituent information,
e.g., the features of CS9 in Table 3.
In Table 5, considering the different function of
verb voice, we cannot combine the “VB(*)” POS.
For instance, the POS of “suggest” in sentence 5)
is “VBP” (the verb present tense). The correspond-
ing scope does not involve the sentence subject.
</bodyText>
<page confidence="0.995705">
972
</page>
<bodyText confidence="0.981813333333333">
The POS of “suggested” in sentence 6) is “VBN”
(the past participle). The scope involves the sub-
ject “An age-related decrease”.
</bodyText>
<listItem confidence="0.88002975">
5) These results [suggest that the genes might be in-
volved in terminal granulocyte differentiation].
6) [An age-related decrease was suggested between
subjects younger than 20 years].
</listItem>
<bodyText confidence="0.99970925">
As a result, we have built a discriminative clas-
sifier for each kind of POS of cues, and then ex-
plored and selected the most compatible features
for each classifier.
</bodyText>
<sectionHeader confidence="0.996387" genericHeader="evaluation">
5 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.99244">
5.1 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.998810578947368">
Considering the effectiveness of different features,
we have split the Abstracts sub-corpus into 5 equal
parts, within which 2 parts are used for feature
selection (Feature Selection Data) and the rest for
the scope detection experiments (Scope Detection
Data). The Feature Selection Data are divided into
5 equal parts, within which 4 parts for training and
the rest for developing. In our scope detection ex-
periments, we divide the Scope Detection Data
into 10 folds randomly, so as to perform 10-fold
cross validation. As the experiment data is easily
confusable, Figure 5 illustrates the allocation.
Checking the validity of our method, we use the
Abstracts sub-corpus in Section 5.2, 5.3 and 5.4,
while in Section 5.5 we use all of the three sub-
corpora (Abstracts, Full Papers, and Clinical Re-
ports) to test the robustness of our system when
applied to different text types within the same do-
main.
</bodyText>
<figureCaption confidence="0.986017">
Figure 5. The allocation for experiment data.
</figureCaption>
<bodyText confidence="0.992224363636364">
The evaluation is made using the precision, re-
call and their harmonic mean, F1-score. Addition-
ally, we report the accuracy in PCS (Percentage of
Correct Scopes) applied in CoNLL’2010, within
which a scope is fully correct if all tokens in a sen-
tence have been assigned to the correct scope class
for a given cue. The evaluation in terms of preci-
sion and recall measures takes a token as a unit,
whereas the evaluation in terms of PCS takes a
scope as a unit. The key toolkits for scope classifi-
cation include:
Constituent and Dependency Parser: All the
sentences in BioScope corpus are tokenized and
parsed using the Berkeley Parser (Petrov et al,
2007) 2 which have been trained on the GENIA
TreeBank 1.0 (Tateisi et al, 2005)3, a bracketed
corpus in PTB style. 10-fold cross-validation on
GTB1.0 shows that the parser achieves 87.12% in
F1-score. On the other hand, we obtain the de-
pendency relations by the Stanford Dependencies
Parser4.
Support Vector Machine Classifier: SVMLight5
is selected as our classifier, which provides a way
to combine the tree kernels with the default and
custom SVMLight kernels. We use the default pa-
rameter computed by SVMLight.
Besides, according to the guideline of the Bio-
Scope corpus, scope must be a continuous chunk.
The scope classifier may result in discontinuous
blocks, as each token may be classified inside or
outside the scope. Therefore, we perform the rule
based post-processing algorithm proposed by Mo-
rante et al (2008) to obtain continuous scopes.
</bodyText>
<subsectionHeader confidence="0.997261">
5.2 Results on Flat Syntactic Features
</subsectionHeader>
<bodyText confidence="0.999938642857143">
Relying on the results of the greedy feature selec-
tion algorithm (described in Section 4.1), we ob-
tain 9 effective features {B1, B3, B6, CS3, CS4,
CS9, DS1, DS3, DS5} (see Table 2, 3 and 4) for
negation scope detection and 13 effective features
{B3, B4, B5, B6, CS1, CS5, CS6, CS8, CS9, CS10,
DS1, DS4, DS5} for speculation. Table 6 lists the
performances on the Scope Detection Data by per-
forming 10-fold cross validation. It shows that flat
constituent and dependency syntactic features sig-
nificantly improve the basic scope detection by
13.48% PCS for negation and 30.46% for specula-
tion (χ2; p &lt; 0.01). It demonstrates that the selected
syntactic features are effective for scope detection.
</bodyText>
<footnote confidence="0.99960275">
2 http://code.google.com/p/berkeleyparser
3 http://www-tsujii.is.s.u-tokyo.ac.jp/GENIA
4 http://nlp.stanford.edu/software/lex-parser.shtml
5 http://svmlight.joachims.org
</footnote>
<page confidence="0.993927">
973
</page>
<table confidence="0.996406235294118">
Negation Features P R F PCS
Basic 89.89 68.72 77.86 39.50
Con. 85.72 67.80 75.66 41.81
Dep. 90.31 69.01 78.19 40.08
Bas.&amp;Con. 88.86 79.07 83.61 51.64
Bas.&amp;Dep. 90.44 73.62 81.17 49.36
All 91.21 76.57 83.25 52.98
Speculation Features P R F PCS
Basic 89.67 86.86 88.24 40.09
Con. 96.43 87.46 91.72 66.57
Dep. 90.84 87.04 88.89 44.45
Bas.&amp;Con. 95.66 92.08 93.83 69.59
Bas.&amp;Dep. 92.39 88.27 90.28 67.49
All 95.71 92.09 93.86 70.55
(Note: “Bas.” denotes basic features; “Con.” denotes Constituent
features; “Dep.” denotes Dependency features; “All” contains Basic,
Constituent, and Dependency features being selected.)
</table>
<tableCaption confidence="0.99475">
Table 6. Performance of flat syntactic features.
</tableCaption>
<bodyText confidence="0.998260190476191">
The results also show that the speculative scope
detection achieves higher performance (16.98%
higher in PCS) (χ2; p &lt; 0.01) than the negation
scope detection. The main reason is that although
the average sentence length of negation and specu-
lation are comparable (29.97 vs. 29.39 words, in
Table 1), the average length of speculation scopes
is much longer than the negation (17.24 vs. 9.62
words, in Table 1) in Abstracts sub-corpus. With
the shorter scopes in training data, the classifier
inevitably have more negative samples. Thus, by
using a token as the basic unit in our classification,
the imbalanced samples will seriously mislead the
classifier and result in bias on the negative samples.
In addition, both constituent and dependency
flat features can improve the scope classification,
for the reason that the constituent features usually
provide the nearer syntactic information of the
cues, and that the further syntactic information
between cues and scopes have been obtained by
the dependency features.
</bodyText>
<subsectionHeader confidence="0.9996535">
5.3 Results on Structured Syntactic Parse
Features
</subsectionHeader>
<bodyText confidence="0.99768145">
Table 7 and Table 8 give the scope detection per-
formance using the different structured syntactic
parse features on negation and speculation respec-
tively. Compared to the optimal system (using all
of the selected flat features in Table 6) in Section
5.2, the structured syntactic parse features at best
improve the scope classification nearly 17.29% on
negation (PCS=70.27%) and 12.32% on specula-
tion (PCS=82.87%) (χ2; p &lt; 0.01). It indicates that
the structured syntactic parse features can provide
more implicit linguistic information, as supple-
mentary clues, to support scope classification.
The improvements also show that both the com-
pleted syntactic sub-trees and critical paths in con-
stituent and dependency parsing trees are effective.
The reason is that the completed syntactic sub-
trees contain the surrounding information related
to cues and tokens, while there are more direct
syntactic information in the critical paths between
cue and its scope.
</bodyText>
<table confidence="0.99983475">
Features P R F PCS
Con. CT 91.12 83.25 86.89 54.57
Con. CT&amp;CP 93.31 89.32 91.20 66.58
Dep. T1 CT 87.29 84.37 85.81 53.07
Dep. T1 CT&amp;CP 90.03 86.77 88.37 59.53
Dep. T2 CT 88.17 84.58 86.34 53.76
Dep. T2 CT&amp;CP 91.09 87.31 89.16 60.11
All 93.84 91.94 92.88 70.27
</table>
<tableCaption confidence="0.887536625">
(Note: “Con.” denotes Constituent features; “Dep.” denotes Depend-
ency features; “T1” use the transformational rule (1) in Section 4.2 to
get the dependency tree; “T2” use the transformational rule (2) in
Section 4.2 to get the dependency tree; CT-“Completed syntactic sub-
Tree”; CP-“Critical Path”; “All” contains Con CT&amp;CP, Dep T1
CT&amp;CP and Dep T2 CT&amp;CP)
Table 7. Performance of structured syntactic parse
features on negation.
</tableCaption>
<table confidence="0.999949875">
Features P R F PCS
Con. CT 95.89 93.37 94.61 75.17
Con. CT&amp;CP 96.05 94.36 95.20 76.73
Dep. T1 CT 93.24 90.77 91.99 72.31
Dep. T1 CT&amp;CP 94.28 92.30 93.28 73.75
Dep. T2 CT 93.76 89.68 91.67 73.06
Dep. T2 CT&amp;CP 95.29 94.55 94.92 75.69
All 96.93 96.86 96.89 82.87
</table>
<tableCaption confidence="0.9993215">
Table 8. Performance of structured syntactic parse
features on speculation.
</tableCaption>
<subsectionHeader confidence="0.9731475">
5.4 Results on Part-of-Speech Based Classifi-
cation
</subsectionHeader>
<bodyText confidence="0.985282571428572">
To confirm the assumption in Section 4.3, we have
built a discriminative classifier for each kind of
POS of cues. Considering that the features involv-
ing the global structured syntactic parse infor-
mation in Section 4.2 are almost effective to all
instances, we only use the flat syntactic features in
Section 4.1.
</bodyText>
<table confidence="0.999322625">
Negation System P R F PCS
All Features 91.21 76.57 83.25 52.98
POS Classifier 91.79 78.29 84.50 56.77
Specula- System P R F PCS
tion
All Features 95.71 92.09 93.86 70.55
POS Classifier 95.79 93.13 94.44 71.68
(Note: “All Features” System is the optimal system in Section 5.2)
</table>
<tableCaption confidence="0.9208295">
Table 9. Performances of POS based classification.
Table 9 shows the performance of POS based
classification. Compared with the system which
only uses one classifier for all cues in Section 5.2,
</tableCaption>
<page confidence="0.997061">
974
</page>
<bodyText confidence="0.999615588235294">
the POS based classification improves 1.13% on
PCS (χ2; p &lt; 0.01), as different POS kinds of cues
involve respectively effective features with more
related clues between cue and its scope.
Table 10 lists the performance of each POS kind
of cues in speculation scope classification. There
are still some low performances in some kinds of
POS of cues. We consider it caused by two reasons.
Firstly, some kinds of POS of cues (e.g. NN etc.)
have fewer samples (just 43 samples shown in Ta-
ble 5). For this reason, the training for classifier is
limited. Then, for these low performance kinds of
POS of cues, we may have not found the effective
features for them. Although there are some kinds
of cues with low performance, the whole perfor-
mance of part-of-speech based classification is
improved.
</bodyText>
<table confidence="0.999822642857143">
Cue’s B1~B6 CS1~CS10 DS1~DS5 PCS
POS 1 2 3 4 5 6 1 2 3 4 5 6 7 8 9 10 1 2 3 4 5
CC √ √ √ √ √ √ √ √ √ √ 38.45
IN √ √ √ √ √ √ √ √ √ √ √ 87.99
JJ √ √ √ √ √ √ 31.83
MD √ √ √ √ √ √ √ √ √ √ √ √ 79.84
NN √ √ √ √ √ √ √ √ 65.83
RB √ √ √ √ √ √ √ 37.03
VB √ √ √ √ 44.29
VBD √ √ √ √ √ √ √ √ √ √ √ 63.57
VBG √ √ √ √ √ √ √ √ √ √ √ 82.89
VBN √ √ √ √ √ √ √ √ √ 66.38
VBP √ √ √ √ √ √ √ √ √ √ √ √ 81.91
VBZ √ √ √ √ √ √ √ √ √ √ √ √ 77.16
</table>
<tableCaption confidence="0.9809965">
Table 10. Performance of each POS kind of cues
in speculation scope classification.
</tableCaption>
<subsectionHeader confidence="0.972717">
5.5 Results of Comparison Experiments
</subsectionHeader>
<bodyText confidence="0.991193166666667">
To get the final performance of our approach, we
train the classifiers respectively by different effec-
tive features in Section 4.1 for POS kinds of cues,
and use the structured syntactic parse features in
Section 4.2 on Abstracts sub-corpus by performing
10-fold cross validation.
</bodyText>
<table confidence="0.999700444444444">
Negation System Abstract Paper Clinical
Morante (2008) 57.33 N/A N/A
Morante (2009a) 73.36 50.26 87.27
Ours 76.90 61.19 85.31
Specula- System Abstract Paper Clinical
tion
Morante (2009b) 77.13 47.94 60.59
Özgür (2009) 79.89 61.13 N/A
Ours 84.21 67.24 72.92
</table>
<tableCaption confidence="0.946738">
Table 11. Performance comparison of our system
with the state-of-the-art ones in PCS.
</tableCaption>
<bodyText confidence="0.999490611111111">
The results in Table 11 show that our system
outperforms the state of the art ones both on nega-
tion and speculation scope detection. Results also
show that the system is portable to different types
of documents, although performance varies de-
pending on the characteristics of the corpus.
In addition, on both negation and speculation,
the results on Clinical Reports sub-corpus are bet-
ter than those on Full Papers sub-corpus. It is
mainly due to that the clinical reports are easier to
process than full papers and abstracts. The average
length of sentence for negative clinical reports is
8.19 tokens, whereas for abstracts it is 29.39 and
for full papers 30.49. Shorter sentences imply
shorter scopes. The more unambiguous sentence
structure of short sentence can make the structured
constituent and dependency syntactic features eas-
ier to be processed.
</bodyText>
<sectionHeader confidence="0.999561" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999981">
This paper proposes a new approach for tree ker-
nel-based scope detection by using the structured
syntactic parse information. In particular, we have
explored the way of selecting compatible features
for different part-of-speech cues. Experiments
show substantial improvements of our scope clas-
sification and better robustness.
However, the results on the Full Papers and the
Clinical Reports sub-corpora are lower than those
on the Abstracts sub-corpus for both negation and
speculation. That is because the structured syntac-
tic parse features contain some complicated and
lengthy components, and the flat features cross
corpus are sparse. Our future work will focus on
the pruning algorithm for the syntactic structures
and analyzing errors in depth in order to get more
effective features for the scope detection on differ-
ent corpora.
</bodyText>
<sectionHeader confidence="0.997492" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9988042">
This research is supported by the National Natural
Science Foundation of China, No.61272260,
No.61373097, No.61003152, the Natural Science
Foundation of Jiangsu Province, No.BK2011282,
the Major Project of College Natural Science
Foundation of Jiangsu Province, No.11KJA520003
and the Graduates Project of Science and Innova-
tion, No.CXZZ12_0818. Besides, thanks to Yu
Hong and the three anonymous reviewers for their
valuable comments on an earlier draft.
</bodyText>
<page confidence="0.998353">
975
</page>
<sectionHeader confidence="0.99588" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999941706521739">
Emilia Apostolova, Noriko Tomuro and Dina Demner-
Fushman. 2011. Automatic Extraction of Lexico-
Syntactic Patterns for Detection of Negation and
Speculation Scopes. In Proceedings of ACL-HLT
short papers, pages 283-287.
Wendy W. Chapman, Will Bridewell, Paul Hanbury,
Gregory F. Cooper, and Bruce G. Buchanan. 2001. A
Simple Algorithm for Identifying Negated Findings
and Diseases in Discharge Summaries. Journal of
Biomedical Informatics, 34 (5): 301-310.
Wanxiang Che, Min Zhang, Ting Liu and Sheng Li.
2006. A Hybrid Convolution Tree Kernel for Seman-
tic Role Labeling. In Proceedings of ACL, pages 73-
80.
Nigel Collier, Hyun S. Park, Norihiro Ogata, et al. 1999.
The GENIA Project: Corpus-Based Knowledge Ac-
quisition and Information Extraction from Genome
Research Papers. In Proceedings of EACL.
Richárd Farkas, Veronika Vincze, György Móra, János
Csirik, and György Szarvas. 2010. The CoNLL-2010
Shared Task: Learning to Detect Hedges and their
Scope in Natural Language Text. In Proceedings of
CoILL: Shared Task, pages 1-12.
Ilya M. Goldin and Wendy W. Chapman. 2003. Learn-
ing to Detect Negation with ‘Not’ in Medical Texts.
In SIGIR Workshop: Text Analysis and Search for
Bioinformatics.
Yang Huang and Henry Lowe. 2007. A Novel Hybrid
Approach to Automated Negation Detection in Clin-
ical Radiology Reports. Journal of the American
Medical Informatics Association, 14(3):304-311.
Zhengping Jiang and Hwee T. Ng. 2006. Semantic Role
Labeling of NomBank: A Maximum Entropy Ap-
proach. In Proceedings of EMILP, pages 138-145.
Roser Morante, Anthony Liekens, and Walter Daele-
mans. 2008. Learning the Scope of Negation in Bio-
medical Texts. In Proceedings of EMILP, pages
715-724.
Roser Morante and Walter Daelemans. 2009a. A Met-
alearning Approach to Processing the Scope of Ne-
gation. In Proceedings of CoILL, pages 21-29.
Roser Morante and Walter Daelemans. 2009b. Learning
the Scope of Hedge Cues in Biomedical Texts. In
Proceedings of the BioILP Workshop, pages 28-36.
Roser Morante, Vincent Van Asch and Walter Daele-
mans. 2010. Memory-Based Resolution of In-
Sentence Scopes of Hedge Cues. In Proceedings of
CoILL Shared Task, pages 40-47.
Alessandro Moschitti. 2006. Making tree kernels practi-
cal for natural language learning. In Proceedings of
the 11th Conference of the European Chapter of the
Association for Computational Linguistics, pages
113-120.
Lilja Øvrelid, Erik Velldal, and Stephan Oepen. 2010.
Syntactic Scope Resolution in Uncertainty Analysis.
In Proceedings of COLIIG, pages 1379-1387.
Arzucan Özgür and Dragomir R. Radev. 2009. Detect-
ing Speculations and their Scopes in Scientific Text.
In Proceedings of EMILP, pages 1398-1407.
Slav Petrov and Dan Klein. 2007. Improved Inference
for Unlexicalized Parsing. In Proceedings of IAACL,
pages 404-411.
Liliana M. Sánchez, Baoli Li, Carl Vogel. 2007. Ex-
ploiting CCG Structures with Tree Kernels for Spec-
ulation Detection. In Proceedings of the Fourteenth
Conference on Computational Iatural Language
Learning: Shared Task, pages 126-131.
György Szarvas, Veronika Vincze, Richárd Farkas, and
János Csirik. 2008. The BioScope corpus: Annota-
tion for Negation, Uncertainty and their Scope in Bi-
omedical Texts. In Proceedings of BioILP, pages
38-45.
Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and
Jun’ichi Tsujii. 2005. Syntax Annotation for the
GENIA Corpus. In Proceedings of IJCILP, Com-
panion volume, pages 222-227.
Erik Velldal, Lilja Øvrelid, Jonathon Read and Stephan
Oepen. 2012. Speculation and Negation: Rules,
Rankers, and the Role of Syntax. Computational
Linguistics, 38(2):369-410.
Veronika Vincze, György Szarvas, Richárd Farkas,
György Móra and János Csirik. 2008. The BioScope
corpus: biomedical texts annotated for uncertainty,
negation and their scopes. BMC Bioinformatics,
9(Suppl 11):S9.
Guodong Zhou, Min Zhang, Donghong Ji, and Qi-
aoming Zhu. 2007. Tree Kernel-based Relation Ex-
traction with Context-Sensitive Structured Parse
Tree Information. In Proceedings of the 2007 Joint
Conference on Empirical Methods in Iatural Lan-
guage Processing and Computational Iatural Lan-
guage Learning, pages, 728-736.
</reference>
<page confidence="0.998821">
976
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.735150">
<title confidence="0.9989325">Tree Kernel-based Negation and Speculation Scope Detection Structured Syntactic Parse Features</title>
<author confidence="0.996188">Zou Guodong Zhou Qiaoming</author>
<affiliation confidence="0.987202">Natural Language Processing Lab, School of Computer Science and</affiliation>
<address confidence="0.762161">Soochow University, Suzhou, 215006, China</address>
<email confidence="0.9738">zoubowei@gmail.com,{gdzhou,qmzhu}@suda.edu.cn</email>
<abstract confidence="0.998859285714286">Scope detection is a key task in information extraction. This paper proposes a new approach for tree kernel-based scope detection by using the structured syntactic parse information. In addition, we have explored the way of selecting compatible features for different part-of-speech cues. Experiments on the BioScope corpus show that both constituent and dependency structured syntactic parse features have the advantage in capturing the potential relationships between cues and their scopes. Compared with the state of the art scope detection systems, our system achieves substantial improvement.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Emilia Apostolova</author>
<author>Noriko Tomuro</author>
<author>Dina DemnerFushman</author>
</authors>
<title>Automatic Extraction of LexicoSyntactic Patterns for Detection of Negation and Speculation Scopes.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT short papers,</booktitle>
<pages>283--287</pages>
<contexts>
<context position="6690" citStr="Apostolova et al (2011)" startWordPosition="1036" endWordPosition="1039">iven golden speculation cues, their rule-based method achieves the accuracies of 79.89% and 61.13% on the Abstracts and the Full-Papers subcorpus, respectively. Øvrelid et al (2010) constructed a small set of heuristic rules which define the scope for each cue. In developing these rules, they made use of the information provided by the guidelines for scope annotation in the BioScope corpus, combined with manual inspection of the training data in order to further generalize over the phenomena discussed by Vincze et al (2008) and work out interactions of constructions for various types of cues. Apostolova et al (2011) presented a linguistically motivated rule-based system for the detection of negation and speculation scopes that performs on par with state-of-the-art machine learning systems. The rules are automatically extracted from the BioScope corpus and encode lexico-syntactic patterns in a user-friendly format. While their system was developed and tested using a biomedical corpus, the rule extraction mechanism is not domainspecific. The heuristic rule based methods have bad robustness in detecting scopes crossing different meaning aspects (e.g., negative vs. speculative) and crossing different linguis</context>
</contexts>
<marker>Apostolova, Tomuro, DemnerFushman, 2011</marker>
<rawString>Emilia Apostolova, Noriko Tomuro and Dina DemnerFushman. 2011. Automatic Extraction of LexicoSyntactic Patterns for Detection of Negation and Speculation Scopes. In Proceedings of ACL-HLT short papers, pages 283-287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wendy W Chapman</author>
<author>Will Bridewell</author>
<author>Paul Hanbury</author>
<author>Gregory F Cooper</author>
<author>Bruce G Buchanan</author>
</authors>
<title>A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries.</title>
<date>2001</date>
<journal>Journal of Biomedical Informatics,</journal>
<volume>34</volume>
<issue>5</issue>
<pages>301--310</pages>
<contexts>
<context position="5310" citStr="Chapman et al, 2001" startWordPosition="815" endWordPosition="818">ection 2 reviews related work. Section 3 introduces the corpus and corresponding usage in our experiments. Section 4 describes our approach and the experiments are presented in Section 5. Finally, there is a conclusion in Section 6. 2 Related Work Most of the previous studies on negation and speculation scope detection task can be divided into two main aspects: the heuristic rule based methods and the machine learning based methods. We respectively introduce the aspects in below. 2.1 Heuristic Rule based Methods The initial studies for scope detection are to compile effective heuristic rules (Chapman et al, 2001; Goldin et al, 2003). Recently, the heuristic rule based methods have further involved the syntactic features. Huang et al (2007) implemented a hybrid approach to automated negation scope detection. They combined the regular expression matching with grammatical parsing: negations are classified on the basis of syntactic categories and located in parse trees. Their hybrid approach is able to identify negated concepts in radiology reports even when they are located at some distance from the negative term. Özgür et al (2009) hypothesized that the scope of a speculation cue can be characterized b</context>
</contexts>
<marker>Chapman, Bridewell, Hanbury, Cooper, Buchanan, 2001</marker>
<rawString>Wendy W. Chapman, Will Bridewell, Paul Hanbury, Gregory F. Cooper, and Bruce G. Buchanan. 2001. A Simple Algorithm for Identifying Negated Findings and Diseases in Discharge Summaries. Journal of Biomedical Informatics, 34 (5): 301-310.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wanxiang Che</author>
<author>Min Zhang</author>
<author>Ting Liu</author>
<author>Sheng Li</author>
</authors>
<title>A Hybrid Convolution Tree Kernel for Semantic Role Labeling.</title>
<date>2006</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>73--80</pages>
<contexts>
<context position="3808" citStr="Che et al, 2006" startWordPosition="581" endWordPosition="584">rmine the linguistic scope of “not”. The tree kernel classifier (Moschitti, 2006) based on support vector machines uses a kernel function between two trees, affording a comparison between their substructures. Therefore, a tree kernel-based scope detection approach with structured syntactic parse tree is employed. The tree 968 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 968–976, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics kernel has been already proved to be effective in semantic role labeling (Che et al, 2006) and relation extraction (Zhou et al, 2007). In addition, the empirical observation shows that features have imbalanced efficiency for scope classification, which is normally affected by the part-of-speech (abbr., POS) of cues. Hence, we build the discriminative classifiers for each kind of POS of cues, then explore and select the most compatible features for them. We construct a scope detection system by using the structured syntactic parse features based tree kernel classification. Compared with the state of the art scope detection systems, our system achieves the performance of accuracy 76.</context>
</contexts>
<marker>Che, Zhang, Liu, Li, 2006</marker>
<rawString>Wanxiang Che, Min Zhang, Ting Liu and Sheng Li. 2006. A Hybrid Convolution Tree Kernel for Semantic Role Labeling. In Proceedings of ACL, pages 73-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nigel Collier</author>
<author>Hyun S Park</author>
<author>Norihiro Ogata</author>
</authors>
<title>The GENIA Project: Corpus-Based Knowledge Acquisition and Information Extraction from Genome Research Papers.</title>
<date>1999</date>
<booktitle>In Proceedings of EACL.</booktitle>
<contexts>
<context position="10081" citStr="Collier et al, 1999" startWordPosition="1548" endWordPosition="1551">a &lt;cue type=”negation” ref=”X26.8.1”&gt; can not &lt;/cue&gt; be explained by abnormalities in corticosteroid receptor characteristics &lt;/xcope&gt;&lt;/xcope&gt; . &lt;/sentence&gt; (Note: &lt;Sentence&gt; denotes one sentence and the tag “id” denotes its serial number; &lt;xcope&gt; denotes the scope of a cue; &lt;cue&gt; denotes the cue, the tag “type” denotes the specific kind of cues and the tag “ref” is the cue’s serial number.) Figure 1. An annotated sentence in BioScope. The BioScope corpus consists of three subcorpora: biological Full Papers from FlyBase and BMC Bioinformatics, biological paper Abstracts from the GENIA corpus (Collier et al, 1999), and Clinical Reports. Among them, the Full Papers sub-corpus and the Abstracts sub-corpus come from the same genre. In comparison, the Clinical Reports sub-corpus consists of clinical radiology reports with short sentences. 1 http://www.inf.u-szeged.hu/rgai/bioscope In our experiments, if there is more than one cue in a sentence, we treat them as different cue and scope (two independent instances). The statistical data for our corpus is presented in Table 1 in below. The average length of sentences in the negation portion is almost as long as that in speculation, while the average length of </context>
</contexts>
<marker>Collier, Park, Ogata, 1999</marker>
<rawString>Nigel Collier, Hyun S. Park, Norihiro Ogata, et al. 1999. The GENIA Project: Corpus-Based Knowledge Acquisition and Information Extraction from Genome Research Papers. In Proceedings of EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richárd Farkas</author>
<author>Veronika Vincze</author>
<author>György Móra</author>
<author>János Csirik</author>
<author>György Szarvas</author>
</authors>
<title>The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of CoILL: Shared Task,</booktitle>
<pages>1--12</pages>
<contexts>
<context position="8070" citStr="Farkas et al, 2010" startWordPosition="1240" endWordPosition="1244">lease of the BioScope corpus (Szarvas et al, 2008), where the large-scale data of manually annotated cues and corresponding scopes can support machine learning well. Morante et al (2008) formulated scope detection as a chunk classification problem. It is worth noting that they also proposed an effective proper post-processing approach to ensure the consecutiveness of scope. Then, for further improving the scope detection, Morante et al (2009a) applied a meta-learner that uses the predictions of the three classifiers (TiMBL/SVM/CRF) to predict the scope. For the competitive task in CoNLL’2010 (Farkas et al, 2010), Morante et al (2010) used a 969 memory-based classifier based on the k-nearest neighbor rule to determine if a token is the first token in a scope sequence, the last, or neither. Therefore, in order to guarantee that all scopes are continuous sequences of tokens they apply a first post-processing step that builds the sequence of scope. The existing machine learning based approaches substantially improve the robustness of scope detection, and have nearly 80% accuracy. However, the approaches ignore the availability of the structured syntactic parse information. This information involves more </context>
</contexts>
<marker>Farkas, Vincze, Móra, Csirik, Szarvas, 2010</marker>
<rawString>Richárd Farkas, Veronika Vincze, György Móra, János Csirik, and György Szarvas. 2010. The CoNLL-2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of CoILL: Shared Task, pages 1-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilya M Goldin</author>
<author>Wendy W Chapman</author>
</authors>
<title>Learning to Detect Negation with ‘Not’ in Medical Texts. In SIGIR Workshop: Text Analysis and Search for Bioinformatics.</title>
<date>2003</date>
<marker>Goldin, Chapman, 2003</marker>
<rawString>Ilya M. Goldin and Wendy W. Chapman. 2003. Learning to Detect Negation with ‘Not’ in Medical Texts. In SIGIR Workshop: Text Analysis and Search for Bioinformatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yang Huang</author>
<author>Henry Lowe</author>
</authors>
<title>A Novel Hybrid Approach to Automated Negation Detection in Clinical Radiology Reports.</title>
<date>2007</date>
<journal>Journal of the American Medical Informatics Association,</journal>
<pages>14--3</pages>
<marker>Huang, Lowe, 2007</marker>
<rawString>Yang Huang and Henry Lowe. 2007. A Novel Hybrid Approach to Automated Negation Detection in Clinical Radiology Reports. Journal of the American Medical Informatics Association, 14(3):304-311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhengping Jiang</author>
<author>Hwee T Ng</author>
</authors>
<title>Semantic Role Labeling of NomBank: A Maximum Entropy Approach.</title>
<date>2006</date>
<booktitle>In Proceedings of EMILP,</booktitle>
<pages>138--145</pages>
<marker>Jiang, Ng, 2006</marker>
<rawString>Zhengping Jiang and Hwee T. Ng. 2006. Semantic Role Labeling of NomBank: A Maximum Entropy Approach. In Proceedings of EMILP, pages 138-145.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Anthony Liekens</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the Scope of Negation in Biomedical Texts.</title>
<date>2008</date>
<booktitle>In Proceedings of EMILP,</booktitle>
<pages>715--724</pages>
<contexts>
<context position="7637" citStr="Morante et al (2008)" startWordPosition="1174" endWordPosition="1177"> developed and tested using a biomedical corpus, the rule extraction mechanism is not domainspecific. The heuristic rule based methods have bad robustness in detecting scopes crossing different meaning aspects (e.g., negative vs. speculative) and crossing different linguistic resources (e.g., Technical Papers vs. Clinical Reports). 2.2 Machine Learning based Methods The machine learning based methods have been ignored until the release of the BioScope corpus (Szarvas et al, 2008), where the large-scale data of manually annotated cues and corresponding scopes can support machine learning well. Morante et al (2008) formulated scope detection as a chunk classification problem. It is worth noting that they also proposed an effective proper post-processing approach to ensure the consecutiveness of scope. Then, for further improving the scope detection, Morante et al (2009a) applied a meta-learner that uses the predictions of the three classifiers (TiMBL/SVM/CRF) to predict the scope. For the competitive task in CoNLL’2010 (Farkas et al, 2010), Morante et al (2010) used a 969 memory-based classifier based on the k-nearest neighbor rule to determine if a token is the first token in a scope sequence, the last</context>
<context position="22311" citStr="Morante et al (2008)" startWordPosition="3531" endWordPosition="3535">n the other hand, we obtain the dependency relations by the Stanford Dependencies Parser4. Support Vector Machine Classifier: SVMLight5 is selected as our classifier, which provides a way to combine the tree kernels with the default and custom SVMLight kernels. We use the default parameter computed by SVMLight. Besides, according to the guideline of the BioScope corpus, scope must be a continuous chunk. The scope classifier may result in discontinuous blocks, as each token may be classified inside or outside the scope. Therefore, we perform the rule based post-processing algorithm proposed by Morante et al (2008) to obtain continuous scopes. 5.2 Results on Flat Syntactic Features Relying on the results of the greedy feature selection algorithm (described in Section 4.1), we obtain 9 effective features {B1, B3, B6, CS3, CS4, CS9, DS1, DS3, DS5} (see Table 2, 3 and 4) for negation scope detection and 13 effective features {B3, B4, B5, B6, CS1, CS5, CS6, CS8, CS9, CS10, DS1, DS4, DS5} for speculation. Table 6 lists the performances on the Scope Detection Data by performing 10-fold cross validation. It shows that flat constituent and dependency syntactic features significantly improve the basic scope dete</context>
</contexts>
<marker>Morante, Liekens, Daelemans, 2008</marker>
<rawString>Roser Morante, Anthony Liekens, and Walter Daelemans. 2008. Learning the Scope of Negation in Biomedical Texts. In Proceedings of EMILP, pages 715-724.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>A Metalearning Approach to Processing the Scope of Negation.</title>
<date>2009</date>
<booktitle>In Proceedings of CoILL,</booktitle>
<pages>21--29</pages>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009a. A Metalearning Approach to Processing the Scope of Negation. In Proceedings of CoILL, pages 21-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Walter Daelemans</author>
</authors>
<title>Learning the Scope of Hedge Cues in Biomedical Texts.</title>
<date>2009</date>
<booktitle>In Proceedings of the BioILP Workshop,</booktitle>
<pages>28--36</pages>
<marker>Morante, Daelemans, 2009</marker>
<rawString>Roser Morante and Walter Daelemans. 2009b. Learning the Scope of Hedge Cues in Biomedical Texts. In Proceedings of the BioILP Workshop, pages 28-36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Morante</author>
<author>Vincent Van Asch</author>
<author>Walter Daelemans</author>
</authors>
<title>Memory-Based Resolution of InSentence Scopes of Hedge Cues.</title>
<date>2010</date>
<booktitle>In Proceedings of CoILL Shared Task,</booktitle>
<pages>40--47</pages>
<marker>Morante, Van Asch, Daelemans, 2010</marker>
<rawString>Roser Morante, Vincent Van Asch and Walter Daelemans. 2010. Memory-Based Resolution of InSentence Scopes of Hedge Cues. In Proceedings of CoILL Shared Task, pages 40-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="3273" citStr="Moschitti, 2006" startWordPosition="505" endWordPosition="506">et al, 2009; Øvrelid et al, 2010). However, these flat features are hardly to reflect the information implicit in syntactic parse tree structures. Our intuition is that the segments of the syntactic parse tree around a negative or speculative cue is effective for scope detection. The related structures normally underlay the indirect clues to identify the relations between cues and their scopes, e.g., in sentence 1), “but something”, as a frequently co-occurred syntactic structure with “not something”, is an effective clue to determine the linguistic scope of “not”. The tree kernel classifier (Moschitti, 2006) based on support vector machines uses a kernel function between two trees, affording a comparison between their substructures. Therefore, a tree kernel-based scope detection approach with structured syntactic parse tree is employed. The tree 968 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 968–976, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics kernel has been already proved to be effective in semantic role labeling (Che et al, 2006) and relation extraction (Zhou et al, 2007). In addition, the emp</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Making tree kernels practical for natural language learning. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, pages 113-120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lilja Øvrelid</author>
<author>Erik Velldal</author>
<author>Stephan Oepen</author>
</authors>
<title>Syntactic Scope Resolution in Uncertainty Analysis.</title>
<date>2010</date>
<booktitle>In Proceedings of COLIIG,</booktitle>
<pages>1379--1387</pages>
<contexts>
<context position="2690" citStr="Øvrelid et al, 2010" startWordPosition="414" endWordPosition="417">he second stage. That is, by given golden cues, we detect their linguistic scopes. We propose a tree kernel-based negation and speculation scope detection with structured syntactic parse features. In detail, we regard the scope detection task as a binary classification issue, which is to classify the tokens in a sentence as being inside or outside the scope. In the basic framework, we focus on the analysis and application of structured syntactic parse features as follows: Both constituent and dependency syntactic features have been proved to be effective in scope detection (Özgür et al, 2009; Øvrelid et al, 2010). However, these flat features are hardly to reflect the information implicit in syntactic parse tree structures. Our intuition is that the segments of the syntactic parse tree around a negative or speculative cue is effective for scope detection. The related structures normally underlay the indirect clues to identify the relations between cues and their scopes, e.g., in sentence 1), “but something”, as a frequently co-occurred syntactic structure with “not something”, is an effective clue to determine the linguistic scope of “not”. The tree kernel classifier (Moschitti, 2006) based on support</context>
<context position="6248" citStr="Øvrelid et al (2010)" startWordPosition="964" endWordPosition="967">ctic categories and located in parse trees. Their hybrid approach is able to identify negated concepts in radiology reports even when they are located at some distance from the negative term. Özgür et al (2009) hypothesized that the scope of a speculation cue can be characterized by its part-of-speech and the syntactic structure of the sentence and developed rules to map the scope of a cue to the nodes in the syntactic parse tree. By given golden speculation cues, their rule-based method achieves the accuracies of 79.89% and 61.13% on the Abstracts and the Full-Papers subcorpus, respectively. Øvrelid et al (2010) constructed a small set of heuristic rules which define the scope for each cue. In developing these rules, they made use of the information provided by the guidelines for scope annotation in the BioScope corpus, combined with manual inspection of the training data in order to further generalize over the phenomena discussed by Vincze et al (2008) and work out interactions of constructions for various types of cues. Apostolova et al (2011) presented a linguistically motivated rule-based system for the detection of negation and speculation scopes that performs on par with state-of-the-art machin</context>
</contexts>
<marker>Øvrelid, Velldal, Oepen, 2010</marker>
<rawString>Lilja Øvrelid, Erik Velldal, and Stephan Oepen. 2010. Syntactic Scope Resolution in Uncertainty Analysis. In Proceedings of COLIIG, pages 1379-1387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arzucan Özgür</author>
<author>Dragomir R Radev</author>
</authors>
<title>Detecting Speculations and their Scopes in Scientific Text.</title>
<date>2009</date>
<booktitle>In Proceedings of EMILP,</booktitle>
<pages>1398--1407</pages>
<marker>Özgür, Radev, 2009</marker>
<rawString>Arzucan Özgür and Dragomir R. Radev. 2009. Detecting Speculations and their Scopes in Scientific Text. In Proceedings of EMILP, pages 1398-1407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved Inference for Unlexicalized Parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of IAACL,</booktitle>
<pages>404--411</pages>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved Inference for Unlexicalized Parsing. In Proceedings of IAACL, pages 404-411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liliana M Sánchez</author>
<author>Baoli Li</author>
<author>Carl Vogel</author>
</authors>
<title>Exploiting CCG Structures with Tree Kernels for Speculation Detection.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Iatural Language Learning: Shared Task,</booktitle>
<pages>126--131</pages>
<marker>Sánchez, Li, Vogel, 2007</marker>
<rawString>Liliana M. Sánchez, Baoli Li, Carl Vogel. 2007. Exploiting CCG Structures with Tree Kernels for Speculation Detection. In Proceedings of the Fourteenth Conference on Computational Iatural Language Learning: Shared Task, pages 126-131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>György Szarvas</author>
<author>Veronika Vincze</author>
<author>Richárd Farkas</author>
<author>János Csirik</author>
</authors>
<title>The BioScope corpus: Annotation for Negation, Uncertainty and their Scope in Biomedical Texts.</title>
<date>2008</date>
<booktitle>In Proceedings of BioILP,</booktitle>
<pages>38--45</pages>
<contexts>
<context position="7501" citStr="Szarvas et al, 2008" startWordPosition="1154" endWordPosition="1157"> automatically extracted from the BioScope corpus and encode lexico-syntactic patterns in a user-friendly format. While their system was developed and tested using a biomedical corpus, the rule extraction mechanism is not domainspecific. The heuristic rule based methods have bad robustness in detecting scopes crossing different meaning aspects (e.g., negative vs. speculative) and crossing different linguistic resources (e.g., Technical Papers vs. Clinical Reports). 2.2 Machine Learning based Methods The machine learning based methods have been ignored until the release of the BioScope corpus (Szarvas et al, 2008), where the large-scale data of manually annotated cues and corresponding scopes can support machine learning well. Morante et al (2008) formulated scope detection as a chunk classification problem. It is worth noting that they also proposed an effective proper post-processing approach to ensure the consecutiveness of scope. Then, for further improving the scope detection, Morante et al (2009a) applied a meta-learner that uses the predictions of the three classifiers (TiMBL/SVM/CRF) to predict the scope. For the competitive task in CoNLL’2010 (Farkas et al, 2010), Morante et al (2010) used a 9</context>
<context position="9022" citStr="Szarvas et al, 2008" startWordPosition="1392" endWordPosition="1395">scope. The existing machine learning based approaches substantially improve the robustness of scope detection, and have nearly 80% accuracy. However, the approaches ignore the availability of the structured syntactic parse information. This information involves more clues which can well reflect the relations between cues and scopes. Sánchez et al (2010) employed a tree kernel based classifier with CCG structures to identify speculative sentences on Wikipedia dataset. However, in Sánchez’s approach, not all sentences are covered by the classifier. 3 Corpus We have employed the BioScope corpus (Szarvas et al, 2008; Vincze et al, 2008)1, an open resource from the biomedical domain, as the benchmark corpus. The corpus contains annotations at the token level for negative and speculative cues and at the sentence level for their linguistic scope (as shown in Figure 1). &lt;sentence id=”S26.8”&gt; These findings &lt;xcope id=”X26.8.2”&gt; &lt;cue type=”speculation” ref=”X26.8.2”&gt; indicate that &lt;/cue&gt; &lt;xcope id=”X26.8.1”&gt; corticosteroid resistance in bronchial asthma &lt;cue type=”negation” ref=”X26.8.1”&gt; can not &lt;/cue&gt; be explained by abnormalities in corticosteroid receptor characteristics &lt;/xcope&gt;&lt;/xcope&gt; . &lt;/sentence&gt; (Not</context>
</contexts>
<marker>Szarvas, Vincze, Farkas, Csirik, 2008</marker>
<rawString>György Szarvas, Veronika Vincze, Richárd Farkas, and János Csirik. 2008. The BioScope corpus: Annotation for Negation, Uncertainty and their Scope in Biomedical Texts. In Proceedings of BioILP, pages 38-45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuka Tateisi</author>
<author>Akane Yakushiji</author>
<author>Tomoko Ohta</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Syntax Annotation for the GENIA Corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of IJCILP, Companion volume,</booktitle>
<pages>222--227</pages>
<contexts>
<context position="21568" citStr="Tateisi et al, 2005" startWordPosition="3414" endWordPosition="3417">rt the accuracy in PCS (Percentage of Correct Scopes) applied in CoNLL’2010, within which a scope is fully correct if all tokens in a sentence have been assigned to the correct scope class for a given cue. The evaluation in terms of precision and recall measures takes a token as a unit, whereas the evaluation in terms of PCS takes a scope as a unit. The key toolkits for scope classification include: Constituent and Dependency Parser: All the sentences in BioScope corpus are tokenized and parsed using the Berkeley Parser (Petrov et al, 2007) 2 which have been trained on the GENIA TreeBank 1.0 (Tateisi et al, 2005)3, a bracketed corpus in PTB style. 10-fold cross-validation on GTB1.0 shows that the parser achieves 87.12% in F1-score. On the other hand, we obtain the dependency relations by the Stanford Dependencies Parser4. Support Vector Machine Classifier: SVMLight5 is selected as our classifier, which provides a way to combine the tree kernels with the default and custom SVMLight kernels. We use the default parameter computed by SVMLight. Besides, according to the guideline of the BioScope corpus, scope must be a continuous chunk. The scope classifier may result in discontinuous blocks, as each token</context>
</contexts>
<marker>Tateisi, Yakushiji, Ohta, Tsujii, 2005</marker>
<rawString>Yuka Tateisi, Akane Yakushiji, Tomoko Ohta, and Jun’ichi Tsujii. 2005. Syntax Annotation for the GENIA Corpus. In Proceedings of IJCILP, Companion volume, pages 222-227.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik Velldal</author>
<author>Lilja Øvrelid</author>
<author>Jonathon Read</author>
<author>Stephan Oepen</author>
</authors>
<date>2012</date>
<booktitle>Speculation and Negation: Rules, Rankers, and the Role of Syntax. Computational Linguistics,</booktitle>
<pages>38--2</pages>
<contexts>
<context position="2040" citStr="Velldal et al, 2012" startWordPosition="304" endWordPosition="307">sentence 1) below, the negative cue “not” dominates the scope of “not expensive”. Similarly, the speculative cue “possible” in sentence 2) dominates the uncertain scope “the possible future scenarios”. 1) The chair is [not expensive] but comfortable. 2) Considering all that we have seen, what are now [the possible future scenarios]? * Corresponding author The negative and speculative scope detection task consists of two basic stages. The first one is to identify the sentences involving negative or speculative meaning. The second stage is to detect the linguistic scope of the cue in sentences (Velldal et al, 2012). In this paper, we focus on the second stage. That is, by given golden cues, we detect their linguistic scopes. We propose a tree kernel-based negation and speculation scope detection with structured syntactic parse features. In detail, we regard the scope detection task as a binary classification issue, which is to classify the tokens in a sentence as being inside or outside the scope. In the basic framework, we focus on the analysis and application of structured syntactic parse features as follows: Both constituent and dependency syntactic features have been proved to be effective in scope </context>
</contexts>
<marker>Velldal, Øvrelid, Read, Oepen, 2012</marker>
<rawString>Erik Velldal, Lilja Øvrelid, Jonathon Read and Stephan Oepen. 2012. Speculation and Negation: Rules, Rankers, and the Role of Syntax. Computational Linguistics, 38(2):369-410.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronika Vincze</author>
</authors>
<title>György Szarvas, Richárd Farkas, György Móra and János Csirik.</title>
<date>2008</date>
<journal>BMC Bioinformatics,</journal>
<volume>9</volume>
<pages>11--9</pages>
<marker>Vincze, 2008</marker>
<rawString>Veronika Vincze, György Szarvas, Richárd Farkas, György Móra and János Csirik. 2008. The BioScope corpus: biomedical texts annotated for uncertainty, negation and their scopes. BMC Bioinformatics, 9(Suppl 11):S9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guodong Zhou</author>
<author>Min Zhang</author>
<author>Donghong Ji</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Tree Kernel-based Relation Extraction with Context-Sensitive Structured Parse Tree Information.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Iatural Language Processing and Computational Iatural Language Learning,</booktitle>
<pages>728--736</pages>
<contexts>
<context position="3851" citStr="Zhou et al, 2007" startWordPosition="589" endWordPosition="592">ree kernel classifier (Moschitti, 2006) based on support vector machines uses a kernel function between two trees, affording a comparison between their substructures. Therefore, a tree kernel-based scope detection approach with structured syntactic parse tree is employed. The tree 968 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 968–976, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics kernel has been already proved to be effective in semantic role labeling (Che et al, 2006) and relation extraction (Zhou et al, 2007). In addition, the empirical observation shows that features have imbalanced efficiency for scope classification, which is normally affected by the part-of-speech (abbr., POS) of cues. Hence, we build the discriminative classifiers for each kind of POS of cues, then explore and select the most compatible features for them. We construct a scope detection system by using the structured syntactic parse features based tree kernel classification. Compared with the state of the art scope detection systems, our system achieves the performance of accuracy 76.90% on negation and 84.21% on speculation (</context>
</contexts>
<marker>Zhou, Zhang, Ji, Zhu, 2007</marker>
<rawString>Guodong Zhou, Min Zhang, Donghong Ji, and Qiaoming Zhu. 2007. Tree Kernel-based Relation Extraction with Context-Sensitive Structured Parse Tree Information. In Proceedings of the 2007 Joint Conference on Empirical Methods in Iatural Language Processing and Computational Iatural Language Learning, pages, 728-736.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>