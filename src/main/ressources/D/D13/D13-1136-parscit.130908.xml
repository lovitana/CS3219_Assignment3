<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000270">
<title confidence="0.9983045">
Connecting Language and Knowledge Bases with Embedding Models
for Relation Extraction
</title>
<author confidence="0.945019">
Jason Weston Antoine Bordes Oksana Yakhnenko Nicolas Usunier
</author>
<affiliation confidence="0.508746">
Google Heudiasyc Google Heudiasyc
</affiliation>
<address confidence="0.916728">
111 8th avenue UT de Compiègne 111 8th avenue UT de Compiègne
New York, NY, USA &amp; CNRS New York, NY, USA &amp; CNRS
jweston@google.com Compiègne, France oksana@google.com Compiègne, France
</address>
<email confidence="0.992246">
bordesan@utc.fr nusunier@utc.fr
</email>
<sectionHeader confidence="0.99549" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999484285714286">
This paper proposes a novel approach for rela-
tion extraction from free text which is trained
to jointly use information from the text and
from existing knowledge. Our model is based
on scoring functions that operate by learning
low-dimensional embeddings of words, enti-
ties and relationships from a knowledge base.
We empirically show on New York Times ar-
ticles aligned with Freebase relations that our
approach is able to efficiently use the extra in-
formation provided by a large subset of Free-
base data (4M entities, 23k relationships) to
improve over methods that rely on text fea-
tures alone.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9997265625">
Information extraction (IE) aims at generating struc-
tured data from free text in order to populate Knowl-
edge Bases (KBs). Hence, one is given an incom-
plete KB composed of a set of triples of the form
(h, r, t); h is the left-hand side entity (or head), t
the right-hand side entity (or tail) and r the relation-
ship linking them. An example from the Freebase
KB1 is (/m/2d3rf ,&lt;director-of&gt;, /m/3/324), where
/m/2d3rf refers to the director “Alfred Hitchcock&amp;quot;
and /m/3/324 to the movie “The Birds&amp;quot;.
This paper focuses on the problem of learning to
perform relation extraction (RE) under weak super-
vision from a KB. RE is sub-task of IE that consid-
ers that entities have already been detected by a dif-
ferent process, such as a named-entity recognizer.
RE then aims at assigning to a relation mention m
</bodyText>
<footnote confidence="0.944717">
1www.freebase.com
</footnote>
<bodyText confidence="0.999861482758621">
(i.e. a sequence of text which states that some rela-
tion is true) the corresponding relationship from the
KB, given a pair of extracted entities (h, t) as con-
text. For example, given the triple (/m/2d3rf ,“wrote
and directed&amp;quot;, /m/3/324), a system should predict
&lt;director-of&gt;. The task is said to be weakly super-
vised because for each pair of entities (h, t) detected
in the text, all relation mentions m associated with
them are labeled with all the relationships connect-
ing h and t in the KB, whether they are actually ex-
pressed by m or not.
Our key contribution is a novel model that em-
ploys not only weakly labeled text mention data, as
most approaches do, but also leverages triples from
the known KB. The model thus learns the plausi-
bility of new (h, r, t) triples by generalizing from
the KB, even though this triple is not present. A
ranking-based embedding framework is used to train
our model. Thereby, relation mentions, entities and
relationships are all embedded into a common low-
dimensional vector space, where scores are com-
puted. We show that our method can successfully
take into account information from a large-scale KB
(Freebase: 4M entities, 23k relationships) to im-
prove over systems that are only using text features.
This paper is organized as follows: Section 2
presents related work, Section 3 introduces our
model and its main influences, and experimental re-
sults are displayed in Section 4.
</bodyText>
<sectionHeader confidence="0.995193" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.989476666666667">
Learning under weak supervision is common in nat-
ural language processing, especially for tasks where
the annotation costs are significant such as in se-
</bodyText>
<page confidence="0.901029">
1366
</page>
<bodyText confidence="0.9789635">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1366–1371,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
mantic parsing (Kate and Mooney, 2007; Liang et
al., 2009; Bordes et al., 2010; Matuszek et al.,
2012). This is also naturally used in IE, since it
allows to train large-scale systems without requir-
ing to label numerous texts. The idea was intro-
duced by (Craven et al., 1999), which matched the
Yeast Protein Database with PubMed abstracts. It
was also used to train open extractors based on
Wikipedia infoboxes and corresponding sentences
(Wu and Weld, 2007; Wu and Weld, 2010). Large-
scale open IE projects (e.g. (Banko et al., 2007))
also rely on weak supervision, since they learn mod-
els from a seed KB in order to extend it.
Weak supervision is also a popular option for RE:
Mintz et al. (2009) used Freebase to train weakly su-
pervised relational extractors on Wikipedia, an ap-
proach generalized by the multi-instance learning
frameworks (Riedel et al., 2010; Hoffmann et al.,
2011; Surdeanu et al., 2012). All these works only
use textual information to perform extraction.
Lao et al. (2012) proposed the first work aiming to
perform RE employing both KB data and text, using
a rule-based random walk method. Recently, Riedel
et al. (2013) proposed another joint approach based
on collaborative filtering for learning entity embed-
dings. This approach connects text with Freebase
by learning shared embeddings of entities through
weak supervision, in contrast to our method where
no joint learning is performed. We do not compare
to these two approaches since they use two different
evaluation protocols that greatly differ from those
used in all aforementioned previous works. Never-
theless, our method is easier to integrate into exist-
ing systems than those, since KB data is used via
the addition of a scoring term, which is trained sepa-
rately beforehand (with no shared embeddings). Be-
sides, we demonstrate in our experimental section
that our system can handle a large number of rela-
tionships, significantly larger than that presented in
(Lao et al., 2012; Riedel et al., 2013).
</bodyText>
<sectionHeader confidence="0.99973" genericHeader="method">
3 Embedding-based Framework
</sectionHeader>
<bodyText confidence="0.999690304347826">
Our work concerns energy-based methods, which
learn low-dimensional vector representations (em-
beddings) of atomic symbols (words, entities, re-
lationships, etc.). In this framework, we learn two
models: one for predicting relationships given re-
lation mentions and another one to encode the in-
teractions among entities and relationships from the
KB. The joint action of both models in prediction
allows us to use the connection between the KB and
text to perform relation extraction. One could also
share parameters between models (via shared em-
beddings), but this is not implemented in this work.
This approach is inspired by previous work designed
to connect words and Wordnet (Bordes et al., 2012).
Both submodels end up learning vector embed-
dings of symbols, either for entities or relationships
in the KB, or for each word/feature of the vocabulary
(denoted V). The set of entities and relationships in
the KB are denoted by £ and R, and nv, ne and nr
denote the size of V, £ and R respectively. Given
a triple (h, r, t) the embeddings of the entities and
the relationship (vectors in Rk) are denoted with the
same letter, in boldface characters (i.e. h, r, t).
</bodyText>
<subsectionHeader confidence="0.999962">
3.1 Connecting Text and Relationships
</subsectionHeader>
<bodyText confidence="0.999985307692308">
The first part of the framework concerns the learn-
ing of a function Sm2r(m, r), based on embeddings,
that is designed to score the similarity of a relation
mention m and a relationship r.
Our scoring approach is inspired by previous
work for connecting word labels and images (We-
ston et al., 2010), which we adapted, replacing im-
ages by mentions and word labels by relationships.
Intuitively, it consists of first projecting words and
features into the embedding space and then comput-
ing a similarity measure (the dot product in this pa-
per) between this projection and a relationship em-
bedding. The scoring function is then:
</bodyText>
<equation confidence="0.763673">
Sm2r(m, r) = f(m)Tr
</equation>
<bodyText confidence="0.7951255">
with f a function mapping words and features into
Rk, f(m) = WT(V(m). W is the matrix of n
</bodyText>
<equation confidence="0.927853">
R x k
</equation>
<bodyText confidence="0.999527272727273">
containing all word embeddings w, 0(m) is the
(sparse) binary representation of m (E Rnv) indi-
cating absence or presence of words/features, and
r E Rk is the embedding of the relationship r.
This approach can be easily applied at test time to
score (mention, relationship) pairs. Since this type
of learning problem is weakly supervised, Bordes et
al. (2010) showed that a convenient way to train it
is by using a ranking loss. Hence, given a data set
D = {(mi, ri), i = 1, ... , |D|} consisting of (men-
tion, relationship) training pairs, one could learn the
</bodyText>
<page confidence="0.78682">
1367
</page>
<bodyText confidence="0.869730777777778">
embeddings using constraints of the form:
2. Select at random a secondary training pair
(mj, rj), used to calibrate the scores.
∀i, ∀r0 =6 ri, f(mi)&gt;ri &gt; 1 + f(mi)&gt;r0 , (1)
where 1 is the margin. That is, we want the re-
lation that (weakly) labels a given mention to be
scored higher than other relation by a margin of 1.
Then, given any mention m one can predict the cor-
responding relationship ?(m) with:
</bodyText>
<listItem confidence="0.918242">
3. Select at random a negative relation r0 such that
r0 =6ri and r0 =6rj.
4. Make a stochastic gradient step to minimize
max(0, 1 − f(mi)&gt;ri + f(mj)&gt;r0).
</listItem>
<bodyText confidence="0.946050727272727">
?(m) = arg max Sm2r(m, r0) = arg max (f(m)&gt;r0). 5. Enforce the constraint that each embedding
r&apos;∈R r&apos;∈R vector is normalized, i.e. if ||Wi||2 &gt; 1 then
Wi ← Wi/||Wi||2.
Learning Sm2r(·) under constraints (1) is well
suited when one is interested in building a per-
mention prediction system. However, performance
metrics of relation extraction are sometimes mea-
sured using precision recall curves aggregated for
all mentions concerning the same pair of entities,
as in (Riedel et al., 2010). In that case the scores
across predictions for different mentions need to be
calibrated so that the most confident ones have the
higher scores. This can be better encoded with con-
straints of the following form:
∀i, j, ∀r0 =6 ri, rj, f(mi)&gt;ri &gt; 1 + f(mj)&gt;r0 .
In this setup, scores of pairs observed in the training
set should be larger than that of any other prediction
across all mentions. In practice, we use “soft” rank-
ing constraints (optimizing the hinge loss), i.e. we
minimize:
∀i, j, ∀r0 =6 ri, rj, max(0, 1−f(mi)&gt;ri +f(mj)&gt;r0).
Finally, we also enforce a (hard) constraint on the
norms of the columns of W and r, i.e. ∀i, ||Wi||2 ≤
1 and ∀j, ||rj||2 ≤ 1. Training is carried out by
Stochastic Gradient Descent (SGD), updating W
and r at each step, following (Weston et al., 2010;
Bordes et al., 2013). That is, at the start of training
the parameters to be learnt (the n„ × k word/feature
embeddings in W and the nr × k relation embed-
dings r) are initialized to random weights. We ini-
tialize each k-dimensional embedding vector ran-
domly with mean 0, standard deviation 1k. Then, we
iterate the following steps to train them:
</bodyText>
<listItem confidence="0.9305925">
1. Select at random a positive training pair
(mi, ri).
</listItem>
<subsectionHeader confidence="0.999872">
3.2 Encoding Structured Data of KBs
</subsectionHeader>
<bodyText confidence="0.999759206896552">
Using only weakly labeled text mentions for train-
ing ignores much of the prior knowledge we can
leverage from a large KB such as Freebase. In or-
der to connect this relational data with our model,
we propose to encode its information into entity and
relationship embeddings. This allows us to build a
model which can score the plausibility of new en-
tity relationship triples which are missing from Free-
base. Several models have been recently developed
for that purpose (e.g. in (Nickel et al., 2011; Bor-
des et al., 2011; Bordes et al., 2012)): we chose in
this work to follow the approach of (Bordes et al.,
2013), which is simple, flexible and has shown very
promising results on Freebase data.
Given a training set S = {(hi, ri, ti), i =
1, ... , |S|} of relations extracted from the KB, this
model learns vector embeddings of the entities and
of the relationships using the idea that the func-
tional relation induced by the r-labeled arcs of the
KB should correspond to a translation of the em-
beddings. That is, given a k-dimensional embed-
ding of the left-hand side (head) entity, adding the
k-dimensional embedding of a given relation should
yield the point (or close to the point) of the k-
dimensional embedding of the right-hand side (tail)
entity. Hence, this method enforces that h + r ≈ t
when (h, r, t) holds, while h + r should be far away
from t otherwise. The model thus gives the follow-
ing score for the plausibility of a relation:
</bodyText>
<equation confidence="0.549575">
Skb(h, r, t) = −||h + r − t||22 .
</equation>
<bodyText confidence="0.993293">
A ranking loss is also used for training Skb. The
ranking objective is designed to assign higher scores
</bodyText>
<page confidence="0.912747">
1368
</page>
<bodyText confidence="0.809975">
to existing relations versus any other possibility:
</bodyText>
<equation confidence="0.962072">
Vi,Vh0 =� hi, Skb(hi, ri, ti) &gt; 1 + Skb(h0, ri, ti),
Vi,Vr0 =� ri, Skb(hi, ri, ti) &gt; 1 + Skb(hi, r0, ti),
Vi, Vt0 =� ti, Skb(hi, ri, ti) &gt; 1 + Skb(hi, ri, t0).
</equation>
<bodyText confidence="0.999826714285714">
That is, for each known triple (h, r, t), if we re-
placed the (i) head, (ii) relation or (iii) tail with some
other possibility, the modified triple should have a
lower score (i.e. be less plausible) than the original
triple. The three sets of constraints defined above
encode the three types of modification. As in Sec-
tion 3.1 we use soft constraints via the hinge loss,
enforce constraints on the norm of embeddings, i.e.
Vh,r,t, ||h||2 &lt; 1,||r||2 &lt; 1,||t||2 &lt; 1, and training
is performed using SGD, as in (Bordes et al., 2013).
At test time, one may again need to calibrate the
scores Skb across entity pairs. We propose a sim-
ple approach: we convert the scores by ranking all
relationships R by Skb and instead output:
</bodyText>
<equation confidence="0.692945">
˜Skb(h, r, t)=Φ( S(Skb(h, r, t)&gt;Skb(h, r�, t))),
r&apos;#r
</equation>
<bodyText confidence="0.998668">
i.e. a function of the rank of r. We chose the simpli-
fied model Φ(x) = 1 if x &lt; T and 0 otherwise; S(·)
is the Kronecker function.
</bodyText>
<subsectionHeader confidence="0.965382">
3.3 Implementation for Relation Extraction
</subsectionHeader>
<bodyText confidence="0.9997498">
Our framework can be used for relation extraction
in the following way. First, for each pair of entities
(h, t) that appear in the test set, all the correspond-
ing mentions Mh,t in the test set are collected and a
prediction is performed with:
</bodyText>
<equation confidence="0.905410333333333">
J: ˆrh,t = argmax
rER
mEMh,t
</equation>
<bodyText confidence="0.9991558">
The predicted relationship can either be a valid re-
lationship or NA – a marker that means that there is
no relation between h and t (NA is added to R dur-
ing training and is treated like other relationships).
If ˆrh,t is a relationship, a composite score is defined:
</bodyText>
<equation confidence="0.5938855">
J: Sm2r+kb(h, ˆrh,t, t)= Sm2r(m, ˆrh,t)+˜Skb(h, ˆrh,t, t)
mEMh,t
</equation>
<bodyText confidence="0.9814255">
That is, only the top scoring non-NA predictions are
re-scored. Hence, our final composite model favors
predictions that agree with both the mentions and the
KB. If ˆrh,t is NA, the score is unchanged.
</bodyText>
<sectionHeader confidence="0.999206" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999976422222222">
We use the training and test data, evaluation frame-
work and baselines from (Riedel et al., 2010; Hoff-
mann et al., 2011; Surdeanu et al., 2012).
NYT+FB This dataset, developed by (Riedel et
al., 2010), aligns Freebase relations with the New
York Times corpus. Entities were found using the
Stanford named entity tagger (Finkel et al., 2005),
and were matched to their name in Freebase. For
each mention, sentence level features are extracted
which include part of speech, named entity and de-
pendency tree path properties. Unlike some of the
previous methods, we do not use features that aggre-
gate properties across multiple mentions. We kept
the 100,000 most frequent features.There are 52 pos-
sible relationships and 121,034 training mentions of
which most are labeled as no relation (labeled “NA”)
– there are 4700 Freebase relations mentioned in the
training set, and 1950 in the test set.
Freebase Freebase is a large-scale KB that has
around 80M entities, 23k relationships and 1.2B re-
lations. We used a subset restricted to the top 4M
entities for scalability reasons – where top is defined
as the ones with the largest number of relations to
other entities. We used all the 23k possible relation-
ships in Freebase. To make a realistic setting, we
did not choose the entity set using the NYT+FB data
set, so it may not overlap completely. For that rea-
son, we needed to keep the set rather large. Keeping
the top 4M entities gives an overlap of 80% with the
entities in the NYT+FB test set. Most importantly,
we then removed all the entity pairs present in the
NYT+FB test set from Freebase, i.e. all relations
they are involved in independent of the relationship.
This ensures that we cannot just memorize the true
relations for an entity pair – we have to learn to gen-
eralize from other entities and relations.
As the NYT+FB dataset was built on an earlier
version of Freebase we also had to translate the dep-
recated relationships into their new variants (e.g.
“/p/business/company/place_founded ” —* “/orga-
nization/organization/place_founded”) to make the
two datasets link (then, the 52 relationships in
NYT+FB are now a subset of the 23k from Free-
base). We then trained the Skb model on the remain-
ing triples.
</bodyText>
<equation confidence="0.784444">
Sm2r(m, r) .
</equation>
<page confidence="0.984693">
1369
</page>
<figureCaption confidence="0.994666">
Figure 1: Top: Aggregate extraction precision/recall
</figureCaption>
<bodyText confidence="0.979704688888889">
curves for a variety of methods. Bottom: the
same plot zoomed to the recall [0-0.1] region.
WsabieM2R is our method trained only on mentions,
WsabieM2R+FB uses Freebase annotations as well.
Modeling Following (Bordes et al., 2013) we set
the embedding dimension k to 50. The learning rate
for SGD was selected using a validation set: we ob-
tained 0.001 for S,,,2,,, and 0.1 for Skb. For the cal-
ibration of Skb, T = 10 (note, here we are ranking
all 23k Freebase relationships). Training S,,,2,, took
5 minutes, whilst training Skb took 2 days due to the
large scale of the data set.
Results Figure 1 displays the aggregate precision
/ recall curves of our approach WSABIEM2R+FB
which uses the combination of S,,,2,, + Skb, as well
as WSABIEM2R , which only uses S,,,2,,, and existing
state-of-the-art approaches: HOFFMANN (Hoffmann
et al., 2011)2, MIMLRE (Surdeanu et al., 2012).
RIEDEL (Riedel et al., 2010) and MINTZ (Mintz et
al., 2009).
WSABIEM2R is comparable to, but slightly worse
than, the MIMLRE and HOFFMANN methods, possi-
bly due to its simplified assumptions (e.g. predict-
ing a single relationship per entity pair). However,
the addition of extra knowledge from other Freebase
entities in WSABIEM2R+FB provides superior per-
formance to all other methods, by a wide margin, at
least between 0 and 0.1 recall (see bottom plot).
Performance of WSABIEM2R and
WSABIEM2R+FB for recall &gt; 0.1 degrades rapidly,
faster than that of other methods. This is also
caused by the simplifications of WSABIEM2R that
prevent it from reaching high precision when the
recall is greater than 0.1. We recall that Freebase
data is not used to detect relationships i.e. to
discriminate between NA and the rest, but only to
select the best relationship in case of detection.
That is WSABIEM2R+FB only improves precision,
not recall, so both versions of Wsabie are similar
w.r.t. recall. This could be improved by borrowing
ideas from HOFFMANN (Hoffmann et al., 2011) or
MIMLRE (Surdeanu et al., 2012) for dealing with
the multi-label case. Our approach, which uses
Freebase to increase precision, is general and could
improve any other method.
</bodyText>
<sectionHeader confidence="0.994581" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.998498">
In this paper we described a framework for leverag-
ing large scale knowledge bases to improve relation
extraction by training not only on (mention, relation-
ship) pairs but using all other KB triples as well. We
empirically showed that it allows to significantly im-
prove precision on extracted relations. Our model-
ing approach is general and should apply to other
settings, e.g. for the task of entity linking.
</bodyText>
<sectionHeader confidence="0.991433" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99984775">
This work was carried out in the framework of
the Labex MS2T (ANR-11-IDEX-0004-02), and
funded by the French National Agency for Research
(EVEREST-12-JS02-005-01).
</bodyText>
<footnote confidence="0.982608">
2There is an error in the plot from (Hoffmann et al., 2011),
which we have corrected. The authors acknowledged this issue.
</footnote>
<figure confidence="0.99735334375">
recall
recall
precision
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
00 0.1 0.2
Wsabie M2R+FB
MIMLRE
Hoffmann
Wsabie M2R
Riedel
Mintz
precision
0.9
0.8
0.7
0.6
0.5
0.40 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.1
Wsabie M2R+FB
MIMLRE
Hoffmann
Wsabie M2R
Riedel
Mintz
</figure>
<page confidence="0.954427">
1370
</page>
<sectionHeader confidence="0.985676" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999843970873786">
Michele Banko, Michael J Cafarella, Stephen Soderland,
Matthew Broadhead, and Oren Etzioni. 2007. Open
information extraction from the web. In IJCAI, vol-
ume 7, pages 2670–2676.
Antoine Bordes, Nicolas Usunier, and Jason Weston.
2010. Label ranking under ambiguous supervision for
learning semantic correspondences. In Proceedings of
the 27th International Conference on Machine Learn-
ing (ICML-10), pages 103–110.
Antoine Bordes, Jason Weston, Ronan Collobert, and
Yoshua Bengio. 2011. Learning structured embed-
dings of knowledge bases. In Proc. of the 25th Conf.
on Artif. Intel. (AAAI).
Antoine Bordes, Xavier Glorot, Jason Weston, and
Yoshua Bengio. 2012. Joint learning of words and
meaning representations for open-text semantic pars-
ing. In Proc. of the 15th Intern. Conf. on Artif. Intel.
and Stat., volume 22, pages 127–135. JMLR.
Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran,
Jason Weston, and Oksana Yakhnenko. 2013. Trans-
lating embeddings for modeling multi-relational data.
In Advances in Neural Information Processing Sys-
tems (NIPS 26).
Mark Craven, Johan Kumlien, et al. 1999. Constructing
biological knowledge bases by extracting information
from text sources. In ISMB, volume 1999, pages 77–
86.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local information
into information extraction systems by gibbs sampling.
In Proceedings of the 43rd Annual Meeting on Associ-
ation for Computational Linguistics, pages 363–370.
Association for Computational Linguistics.
Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction of
overlapping relations. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, vol-
ume 1, pages 541–550.
Rohit J Kate and Raymond J Mooney. 2007. Learning
language semantics from ambiguous supervision. In
AAAI, volume 7, pages 895–900.
Ni Lao, Amarnag Subramanya, Fernando Pereira, and
William W Cohen. 2012. Reading the web with
learned syntactic-semantic inference rules. In Pro-
ceedings of the 2012 Joint Conference on Empirical
Methods in Natural Language Processing and Com-
putational Natural Language Learning, pages 1017–
1026. Association for Computational Linguistics.
Percy Liang, Michael I Jordan, and Dan Klein. 2009.
Learning semantic correspondences with less supervi-
sion. In Proceedings of the Joint Conference of the
47th Annual Meeting of the ACL and the 4th Interna-
tional Joint Conference on Natural Language Process-
ing of the AFNLP: Volume 1-Volume 1, pages 91–99.
Association for Computational Linguistics.
Cynthia Matuszek, Nicholas FitzGerald, Luke Zettle-
moyer, Liefeng Bo, and Dieter Fox. 2012. A joint
model of language and perception for grounded at-
tribute learning. In Proceedings of the International
Conference on Machine Learning.
Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.
2009. Distant supervision for relation extraction with-
out labeled data. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP: Volume 2-Volume 2,
pages 1003–1011. Association for Computational Lin-
guistics.
Maximilian Nickel, Volker Tresp, and Hans-Peter
Kriegel. 2011. A three-way model for collective
learning on multi-relational data. In Proceedings of
the 28th International Conference on Machine Learn-
ing (ICML-11), pages 809–816.
Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Machine Learning and Knowledge
Discovery in Databases, pages 148–163. Springer.
Sebastian Riedel, Limin Yao, Andrew McCallum, and
Benjamin M Marlin. 2013. Relation extraction with
matrix factorization and universal schemas. In Pro-
ceedings of NAACL-HLT, pages 74–84.
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and
Christopher D Manning. 2012. Multi-instance multi-
label learning for relation extraction. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 455–465. Associa-
tion for Computational Linguistics.
Jason Weston, Samy Bengio, and Nicolas Usunier. 2010.
Large scale image annotation: learning to rank with
joint word-image embeddings. Machine learning,
81(1):21–35.
Fei Wu and Daniel S Weld. 2007. Autonomously se-
mantifying wikipedia. In Proceedings of the sixteenth
ACM conference on Conference on information and
knowledge management, pages 41–50. ACM.
Fei Wu and Daniel S Weld. 2010. Open information ex-
traction using wikipedia. In Proceedings of the 48th
Annual Meeting of the Association for Computational
Linguistics, pages 118–127. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.992935">
1371
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.415075">
<title confidence="0.999922">Connecting Language and Knowledge Bases with Embedding for Relation Extraction</title>
<author confidence="0.999114">Jason Weston Antoine Bordes Oksana Yakhnenko Nicolas Usunier</author>
<affiliation confidence="0.753888">Google Heudiasyc Google Heudiasyc</affiliation>
<address confidence="0.837259333333333">111 8th avenue UT de Compiègne 111 8th avenue UT de Compiègne New York, NY, USA &amp; CNRS New York, NY, USA &amp; CNRS jweston@google.com Compiègne, France oksana@google.com Compiègne, France</address>
<email confidence="0.932464">bordesan@utc.frnusunier@utc.fr</email>
<abstract confidence="0.9879032">This paper proposes a novel approach for relation extraction from free text which is trained to jointly use information from the text and from existing knowledge. Our model is based on scoring functions that operate by learning low-dimensional embeddings of words, entities and relationships from a knowledge base. We empirically show on New York Times articles aligned with Freebase relations that our approach is able to efficiently use the extra information provided by a large subset of Freebase data (4M entities, 23k relationships) to improve over methods that rely on text features alone.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matthew Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<title>Open information extraction from the web. In</title>
<date>2007</date>
<booktitle>IJCAI,</booktitle>
<volume>7</volume>
<pages>2670--2676</pages>
<contexts>
<context position="4161" citStr="Banko et al., 2007" startWordPosition="681" endWordPosition="684">ashington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics mantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012). This is also naturally used in IE, since it allows to train large-scale systems without requiring to label numerous texts. The idea was introduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both KB data and text, using a rule-based random walk method. Recently, Riedel et </context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J Cafarella, Stephen Soderland, Matthew Broadhead, and Oren Etzioni. 2007. Open information extraction from the web. In IJCAI, volume 7, pages 2670–2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Nicolas Usunier</author>
<author>Jason Weston</author>
</authors>
<title>Label ranking under ambiguous supervision for learning semantic correspondences.</title>
<date>2010</date>
<booktitle>In Proceedings of the 27th International Conference on Machine Learning (ICML-10),</booktitle>
<pages>103--110</pages>
<contexts>
<context position="3705" citStr="Bordes et al., 2010" startWordPosition="604" endWordPosition="607">r is organized as follows: Section 2 presents related work, Section 3 introduces our model and its main influences, and experimental results are displayed in Section 4. 2 Previous Work Learning under weak supervision is common in natural language processing, especially for tasks where the annotation costs are significant such as in se1366 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1366–1371, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics mantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012). This is also naturally used in IE, since it allows to train large-scale systems without requiring to label numerous texts. The idea was introduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE:</context>
<context position="7945" citStr="Bordes et al. (2010)" startWordPosition="1313" endWordPosition="1316">mputing a similarity measure (the dot product in this paper) between this projection and a relationship embedding. The scoring function is then: Sm2r(m, r) = f(m)Tr with f a function mapping words and features into Rk, f(m) = WT(V(m). W is the matrix of n R x k containing all word embeddings w, 0(m) is the (sparse) binary representation of m (E Rnv) indicating absence or presence of words/features, and r E Rk is the embedding of the relationship r. This approach can be easily applied at test time to score (mention, relationship) pairs. Since this type of learning problem is weakly supervised, Bordes et al. (2010) showed that a convenient way to train it is by using a ranking loss. Hence, given a data set D = {(mi, ri), i = 1, ... , |D|} consisting of (mention, relationship) training pairs, one could learn the 1367 embeddings using constraints of the form: 2. Select at random a secondary training pair (mj, rj), used to calibrate the scores. ∀i, ∀r0 =6 ri, f(mi)&gt;ri &gt; 1 + f(mi)&gt;r0 , (1) where 1 is the margin. That is, we want the relation that (weakly) labels a given mention to be scored higher than other relation by a margin of 1. Then, given any mention m one can predict the corresponding relationship </context>
</contexts>
<marker>Bordes, Usunier, Weston, 2010</marker>
<rawString>Antoine Bordes, Nicolas Usunier, and Jason Weston. 2010. Label ranking under ambiguous supervision for learning semantic correspondences. In Proceedings of the 27th International Conference on Machine Learning (ICML-10), pages 103–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Jason Weston</author>
<author>Ronan Collobert</author>
<author>Yoshua Bengio</author>
</authors>
<title>Learning structured embeddings of knowledge bases.</title>
<date>2011</date>
<booktitle>In Proc. of the 25th Conf. on Artif. Intel. (AAAI).</booktitle>
<contexts>
<context position="10942" citStr="Bordes et al., 2011" startWordPosition="1850" endWordPosition="1854">ain them: 1. Select at random a positive training pair (mi, ri). 3.2 Encoding Structured Data of KBs Using only weakly labeled text mentions for training ignores much of the prior knowledge we can leverage from a large KB such as Freebase. In order to connect this relational data with our model, we propose to encode its information into entity and relationship embeddings. This allows us to build a model which can score the plausibility of new entity relationship triples which are missing from Freebase. Several models have been recently developed for that purpose (e.g. in (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012)): we chose in this work to follow the approach of (Bordes et al., 2013), which is simple, flexible and has shown very promising results on Freebase data. Given a training set S = {(hi, ri, ti), i = 1, ... , |S|} of relations extracted from the KB, this model learns vector embeddings of the entities and of the relationships using the idea that the functional relation induced by the r-labeled arcs of the KB should correspond to a translation of the embeddings. That is, given a k-dimensional embedding of the left-hand side (head) entity, adding the k-dimensional embedding o</context>
</contexts>
<marker>Bordes, Weston, Collobert, Bengio, 2011</marker>
<rawString>Antoine Bordes, Jason Weston, Ronan Collobert, and Yoshua Bengio. 2011. Learning structured embeddings of knowledge bases. In Proc. of the 25th Conf. on Artif. Intel. (AAAI).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Xavier Glorot</author>
<author>Jason Weston</author>
<author>Yoshua Bengio</author>
</authors>
<title>Joint learning of words and meaning representations for open-text semantic parsing.</title>
<date>2012</date>
<booktitle>In Proc. of the 15th Intern. Conf. on Artif. Intel. and Stat.,</booktitle>
<volume>22</volume>
<pages>127--135</pages>
<publisher>JMLR.</publisher>
<contexts>
<context position="6340" citStr="Bordes et al., 2012" startWordPosition="1030" endWordPosition="1033">resentations (embeddings) of atomic symbols (words, entities, relationships, etc.). In this framework, we learn two models: one for predicting relationships given relation mentions and another one to encode the interactions among entities and relationships from the KB. The joint action of both models in prediction allows us to use the connection between the KB and text to perform relation extraction. One could also share parameters between models (via shared embeddings), but this is not implemented in this work. This approach is inspired by previous work designed to connect words and Wordnet (Bordes et al., 2012). Both submodels end up learning vector embeddings of symbols, either for entities or relationships in the KB, or for each word/feature of the vocabulary (denoted V). The set of entities and relationships in the KB are denoted by £ and R, and nv, ne and nr denote the size of V, £ and R respectively. Given a triple (h, r, t) the embeddings of the entities and the relationship (vectors in Rk) are denoted with the same letter, in boldface characters (i.e. h, r, t). 3.1 Connecting Text and Relationships The first part of the framework concerns the learning of a function Sm2r(m, r), based on embedd</context>
<context position="10964" citStr="Bordes et al., 2012" startWordPosition="1855" endWordPosition="1858">t random a positive training pair (mi, ri). 3.2 Encoding Structured Data of KBs Using only weakly labeled text mentions for training ignores much of the prior knowledge we can leverage from a large KB such as Freebase. In order to connect this relational data with our model, we propose to encode its information into entity and relationship embeddings. This allows us to build a model which can score the plausibility of new entity relationship triples which are missing from Freebase. Several models have been recently developed for that purpose (e.g. in (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012)): we chose in this work to follow the approach of (Bordes et al., 2013), which is simple, flexible and has shown very promising results on Freebase data. Given a training set S = {(hi, ri, ti), i = 1, ... , |S|} of relations extracted from the KB, this model learns vector embeddings of the entities and of the relationships using the idea that the functional relation induced by the r-labeled arcs of the KB should correspond to a translation of the embeddings. That is, given a k-dimensional embedding of the left-hand side (head) entity, adding the k-dimensional embedding of a given relation sho</context>
</contexts>
<marker>Bordes, Glorot, Weston, Bengio, 2012</marker>
<rawString>Antoine Bordes, Xavier Glorot, Jason Weston, and Yoshua Bengio. 2012. Joint learning of words and meaning representations for open-text semantic parsing. In Proc. of the 15th Intern. Conf. on Artif. Intel. and Stat., volume 22, pages 127–135. JMLR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Nicolas Usunier</author>
<author>Alberto Garcia-Duran</author>
<author>Jason Weston</author>
<author>Oksana Yakhnenko</author>
</authors>
<title>Translating embeddings for modeling multi-relational data.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems (NIPS 26).</booktitle>
<contexts>
<context position="10008" citStr="Bordes et al., 2013" startWordPosition="1686" endWordPosition="1689">f the following form: ∀i, j, ∀r0 =6 ri, rj, f(mi)&gt;ri &gt; 1 + f(mj)&gt;r0 . In this setup, scores of pairs observed in the training set should be larger than that of any other prediction across all mentions. In practice, we use “soft” ranking constraints (optimizing the hinge loss), i.e. we minimize: ∀i, j, ∀r0 =6 ri, rj, max(0, 1−f(mi)&gt;ri +f(mj)&gt;r0). Finally, we also enforce a (hard) constraint on the norms of the columns of W and r, i.e. ∀i, ||Wi||2 ≤ 1 and ∀j, ||rj||2 ≤ 1. Training is carried out by Stochastic Gradient Descent (SGD), updating W and r at each step, following (Weston et al., 2010; Bordes et al., 2013). That is, at the start of training the parameters to be learnt (the n„ × k word/feature embeddings in W and the nr × k relation embeddings r) are initialized to random weights. We initialize each k-dimensional embedding vector randomly with mean 0, standard deviation 1k. Then, we iterate the following steps to train them: 1. Select at random a positive training pair (mi, ri). 3.2 Encoding Structured Data of KBs Using only weakly labeled text mentions for training ignores much of the prior knowledge we can leverage from a large KB such as Freebase. In order to connect this relational data with</context>
<context position="12751" citStr="Bordes et al., 2013" startWordPosition="2189" endWordPosition="2192">b(hi, ri, ti) &gt; 1 + Skb(hi, r0, ti), Vi, Vt0 =� ti, Skb(hi, ri, ti) &gt; 1 + Skb(hi, ri, t0). That is, for each known triple (h, r, t), if we replaced the (i) head, (ii) relation or (iii) tail with some other possibility, the modified triple should have a lower score (i.e. be less plausible) than the original triple. The three sets of constraints defined above encode the three types of modification. As in Section 3.1 we use soft constraints via the hinge loss, enforce constraints on the norm of embeddings, i.e. Vh,r,t, ||h||2 &lt; 1,||r||2 &lt; 1,||t||2 &lt; 1, and training is performed using SGD, as in (Bordes et al., 2013). At test time, one may again need to calibrate the scores Skb across entity pairs. We propose a simple approach: we convert the scores by ranking all relationships R by Skb and instead output: ˜Skb(h, r, t)=Φ( S(Skb(h, r, t)&gt;Skb(h, r�, t))), r&apos;#r i.e. a function of the rank of r. We chose the simplified model Φ(x) = 1 if x &lt; T and 0 otherwise; S(·) is the Kronecker function. 3.3 Implementation for Relation Extraction Our framework can be used for relation extraction in the following way. First, for each pair of entities (h, t) that appear in the test set, all the corresponding mentions Mh,t i</context>
<context position="16510" citStr="Bordes et al., 2013" startWordPosition="2834" endWordPosition="2837">anslate the deprecated relationships into their new variants (e.g. “/p/business/company/place_founded ” —* “/organization/organization/place_founded”) to make the two datasets link (then, the 52 relationships in NYT+FB are now a subset of the 23k from Freebase). We then trained the Skb model on the remaining triples. Sm2r(m, r) . 1369 Figure 1: Top: Aggregate extraction precision/recall curves for a variety of methods. Bottom: the same plot zoomed to the recall [0-0.1] region. WsabieM2R is our method trained only on mentions, WsabieM2R+FB uses Freebase annotations as well. Modeling Following (Bordes et al., 2013) we set the embedding dimension k to 50. The learning rate for SGD was selected using a validation set: we obtained 0.001 for S,,,2,,, and 0.1 for Skb. For the calibration of Skb, T = 10 (note, here we are ranking all 23k Freebase relationships). Training S,,,2,, took 5 minutes, whilst training Skb took 2 days due to the large scale of the data set. Results Figure 1 displays the aggregate precision / recall curves of our approach WSABIEM2R+FB which uses the combination of S,,,2,, + Skb, as well as WSABIEM2R , which only uses S,,,2,,, and existing state-of-the-art approaches: HOFFMANN (Hoffmann</context>
</contexts>
<marker>Bordes, Usunier, Garcia-Duran, Weston, Yakhnenko, 2013</marker>
<rawString>Antoine Bordes, Nicolas Usunier, Alberto Garcia-Duran, Jason Weston, and Oksana Yakhnenko. 2013. Translating embeddings for modeling multi-relational data. In Advances in Neural Information Processing Systems (NIPS 26).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Craven</author>
<author>Johan Kumlien</author>
</authors>
<title>Constructing biological knowledge bases by extracting information from text sources.</title>
<date>1999</date>
<booktitle>In ISMB,</booktitle>
<volume>volume</volume>
<pages>77--86</pages>
<marker>Craven, Kumlien, 1999</marker>
<rawString>Mark Craven, Johan Kumlien, et al. 1999. Constructing biological knowledge bases by extracting information from text sources. In ISMB, volume 1999, pages 77– 86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>363--370</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="14331" citStr="Finkel et al., 2005" startWordPosition="2469" endWordPosition="2472">J: Sm2r+kb(h, ˆrh,t, t)= Sm2r(m, ˆrh,t)+˜Skb(h, ˆrh,t, t) mEMh,t That is, only the top scoring non-NA predictions are re-scored. Hence, our final composite model favors predictions that agree with both the mentions and the KB. If ˆrh,t is NA, the score is unchanged. 4 Experiments We use the training and test data, evaluation framework and baselines from (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). NYT+FB This dataset, developed by (Riedel et al., 2010), aligns Freebase relations with the New York Times corpus. Entities were found using the Stanford named entity tagger (Finkel et al., 2005), and were matched to their name in Freebase. For each mention, sentence level features are extracted which include part of speech, named entity and dependency tree path properties. Unlike some of the previous methods, we do not use features that aggregate properties across multiple mentions. We kept the 100,000 most frequent features.There are 52 possible relationships and 121,034 training mentions of which most are labeled as no relation (labeled “NA”) – there are 4700 Freebase relations mentioned in the training set, and 1950 in the test set. Freebase Freebase is a large-scale KB that has a</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 363–370. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledgebased weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<volume>1</volume>
<pages>541--550</pages>
<contexts>
<context position="4512" citStr="Hoffmann et al., 2011" startWordPosition="741" endWordPosition="744"> al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both KB data and text, using a rule-based random walk method. Recently, Riedel et al. (2013) proposed another joint approach based on collaborative filtering for learning entity embeddings. This approach connects text with Freebase by learning shared embeddings of entities through weak supervision, in contrast to our method where no joint learning is performed. We do not compare to these two approaches since they use two differen</context>
<context position="14110" citStr="Hoffmann et al., 2011" startWordPosition="2433" endWordPosition="2437">alid relationship or NA – a marker that means that there is no relation between h and t (NA is added to R during training and is treated like other relationships). If ˆrh,t is a relationship, a composite score is defined: J: Sm2r+kb(h, ˆrh,t, t)= Sm2r(m, ˆrh,t)+˜Skb(h, ˆrh,t, t) mEMh,t That is, only the top scoring non-NA predictions are re-scored. Hence, our final composite model favors predictions that agree with both the mentions and the KB. If ˆrh,t is NA, the score is unchanged. 4 Experiments We use the training and test data, evaluation framework and baselines from (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). NYT+FB This dataset, developed by (Riedel et al., 2010), aligns Freebase relations with the New York Times corpus. Entities were found using the Stanford named entity tagger (Finkel et al., 2005), and were matched to their name in Freebase. For each mention, sentence level features are extracted which include part of speech, named entity and dependency tree path properties. Unlike some of the previous methods, we do not use features that aggregate properties across multiple mentions. We kept the 100,000 most frequent features.There are 52 possible relationships and 12</context>
<context position="17124" citStr="Hoffmann et al., 2011" startWordPosition="2941" endWordPosition="2944">., 2013) we set the embedding dimension k to 50. The learning rate for SGD was selected using a validation set: we obtained 0.001 for S,,,2,,, and 0.1 for Skb. For the calibration of Skb, T = 10 (note, here we are ranking all 23k Freebase relationships). Training S,,,2,, took 5 minutes, whilst training Skb took 2 days due to the large scale of the data set. Results Figure 1 displays the aggregate precision / recall curves of our approach WSABIEM2R+FB which uses the combination of S,,,2,, + Skb, as well as WSABIEM2R , which only uses S,,,2,,, and existing state-of-the-art approaches: HOFFMANN (Hoffmann et al., 2011)2, MIMLRE (Surdeanu et al., 2012). RIEDEL (Riedel et al., 2010) and MINTZ (Mintz et al., 2009). WSABIEM2R is comparable to, but slightly worse than, the MIMLRE and HOFFMANN methods, possibly due to its simplified assumptions (e.g. predicting a single relationship per entity pair). However, the addition of extra knowledge from other Freebase entities in WSABIEM2R+FB provides superior performance to all other methods, by a wide margin, at least between 0 and 0.1 recall (see bottom plot). Performance of WSABIEM2R and WSABIEM2R+FB for recall &gt; 0.1 degrades rapidly, faster than that of other method</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, volume 1, pages 541–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rohit J Kate</author>
<author>Raymond J Mooney</author>
</authors>
<title>Learning language semantics from ambiguous supervision.</title>
<date>2007</date>
<booktitle>In AAAI,</booktitle>
<volume>7</volume>
<pages>895--900</pages>
<contexts>
<context position="3664" citStr="Kate and Mooney, 2007" startWordPosition="596" endWordPosition="599">hat are only using text features. This paper is organized as follows: Section 2 presents related work, Section 3 introduces our model and its main influences, and experimental results are displayed in Section 4. 2 Previous Work Learning under weak supervision is common in natural language processing, especially for tasks where the annotation costs are significant such as in se1366 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1366–1371, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics mantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012). This is also naturally used in IE, since it allows to train large-scale systems without requiring to label numerous texts. The idea was introduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak sup</context>
</contexts>
<marker>Kate, Mooney, 2007</marker>
<rawString>Rohit J Kate and Raymond J Mooney. 2007. Learning language semantics from ambiguous supervision. In AAAI, volume 7, pages 895–900.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ni Lao</author>
<author>Amarnag Subramanya</author>
<author>Fernando Pereira</author>
<author>William W Cohen</author>
</authors>
<title>Reading the web with learned syntactic-semantic inference rules.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1017--1026</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="4623" citStr="Lao et al. (2012)" startWordPosition="759" endWordPosition="762">ors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both KB data and text, using a rule-based random walk method. Recently, Riedel et al. (2013) proposed another joint approach based on collaborative filtering for learning entity embeddings. This approach connects text with Freebase by learning shared embeddings of entities through weak supervision, in contrast to our method where no joint learning is performed. We do not compare to these two approaches since they use two different evaluation protocols that greatly differ from those used in all aforementioned previous works. Nevertheless, </context>
</contexts>
<marker>Lao, Subramanya, Pereira, Cohen, 2012</marker>
<rawString>Ni Lao, Amarnag Subramanya, Fernando Pereira, and William W Cohen. 2012. Reading the web with learned syntactic-semantic inference rules. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1017– 1026. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Percy Liang</author>
<author>Michael I Jordan</author>
<author>Dan Klein</author>
</authors>
<title>Learning semantic correspondences with less supervision.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>1</volume>
<pages>91--99</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="3684" citStr="Liang et al., 2009" startWordPosition="600" endWordPosition="603"> features. This paper is organized as follows: Section 2 presents related work, Section 3 introduces our model and its main influences, and experimental results are displayed in Section 4. 2 Previous Work Learning under weak supervision is common in natural language processing, especially for tasks where the annotation costs are significant such as in se1366 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1366–1371, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics mantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012). This is also naturally used in IE, since it allows to train large-scale systems without requiring to label numerous texts. The idea was introduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a p</context>
</contexts>
<marker>Liang, Jordan, Klein, 2009</marker>
<rawString>Percy Liang, Michael I Jordan, and Dan Klein. 2009. Learning semantic correspondences with less supervision. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1-Volume 1, pages 91–99. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Matuszek</author>
<author>Nicholas FitzGerald</author>
<author>Luke Zettlemoyer</author>
<author>Liefeng Bo</author>
<author>Dieter Fox</author>
</authors>
<title>A joint model of language and perception for grounded attribute learning.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Machine Learning.</booktitle>
<contexts>
<context position="3729" citStr="Matuszek et al., 2012" startWordPosition="608" endWordPosition="611">lows: Section 2 presents related work, Section 3 introduces our model and its main influences, and experimental results are displayed in Section 4. 2 Previous Work Learning under weak supervision is common in natural language processing, especially for tasks where the annotation costs are significant such as in se1366 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1366–1371, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics mantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012). This is also naturally used in IE, since it allows to train large-scale systems without requiring to label numerous texts. The idea was introduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) use</context>
</contexts>
<marker>Matuszek, FitzGerald, Zettlemoyer, Bo, Fox, 2012</marker>
<rawString>Cynthia Matuszek, Nicholas FitzGerald, Luke Zettlemoyer, Liefeng Bo, and Dieter Fox. 2012. A joint model of language and perception for grounded attribute learning. In Proceedings of the International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4325" citStr="Mintz et al. (2009)" startWordPosition="713" endWordPosition="716"> Matuszek et al., 2012). This is also naturally used in IE, since it allows to train large-scale systems without requiring to label numerous texts. The idea was introduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both KB data and text, using a rule-based random walk method. Recently, Riedel et al. (2013) proposed another joint approach based on collaborative filtering for learning entity embeddings. This approach connects text with Freebase by learning sh</context>
<context position="17218" citStr="Mintz et al., 2009" startWordPosition="2957" endWordPosition="2960">alidation set: we obtained 0.001 for S,,,2,,, and 0.1 for Skb. For the calibration of Skb, T = 10 (note, here we are ranking all 23k Freebase relationships). Training S,,,2,, took 5 minutes, whilst training Skb took 2 days due to the large scale of the data set. Results Figure 1 displays the aggregate precision / recall curves of our approach WSABIEM2R+FB which uses the combination of S,,,2,, + Skb, as well as WSABIEM2R , which only uses S,,,2,,, and existing state-of-the-art approaches: HOFFMANN (Hoffmann et al., 2011)2, MIMLRE (Surdeanu et al., 2012). RIEDEL (Riedel et al., 2010) and MINTZ (Mintz et al., 2009). WSABIEM2R is comparable to, but slightly worse than, the MIMLRE and HOFFMANN methods, possibly due to its simplified assumptions (e.g. predicting a single relationship per entity pair). However, the addition of extra knowledge from other Freebase entities in WSABIEM2R+FB provides superior performance to all other methods, by a wide margin, at least between 0 and 0.1 recall (see bottom plot). Performance of WSABIEM2R and WSABIEM2R+FB for recall &gt; 0.1 degrades rapidly, faster than that of other methods. This is also caused by the simplifications of WSABIEM2R that prevent it from reaching high </context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003–1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Nickel</author>
<author>Volker Tresp</author>
<author>Hans-Peter Kriegel</author>
</authors>
<title>A three-way model for collective learning on multi-relational data.</title>
<date>2011</date>
<booktitle>In Proceedings of the 28th International Conference on Machine Learning (ICML-11),</booktitle>
<pages>809--816</pages>
<contexts>
<context position="10921" citStr="Nickel et al., 2011" startWordPosition="1846" endWordPosition="1849">following steps to train them: 1. Select at random a positive training pair (mi, ri). 3.2 Encoding Structured Data of KBs Using only weakly labeled text mentions for training ignores much of the prior knowledge we can leverage from a large KB such as Freebase. In order to connect this relational data with our model, we propose to encode its information into entity and relationship embeddings. This allows us to build a model which can score the plausibility of new entity relationship triples which are missing from Freebase. Several models have been recently developed for that purpose (e.g. in (Nickel et al., 2011; Bordes et al., 2011; Bordes et al., 2012)): we chose in this work to follow the approach of (Bordes et al., 2013), which is simple, flexible and has shown very promising results on Freebase data. Given a training set S = {(hi, ri, ti), i = 1, ... , |S|} of relations extracted from the KB, this model learns vector embeddings of the entities and of the relationships using the idea that the functional relation induced by the r-labeled arcs of the KB should correspond to a translation of the embeddings. That is, given a k-dimensional embedding of the left-hand side (head) entity, adding the k-di</context>
</contexts>
<marker>Nickel, Tresp, Kriegel, 2011</marker>
<rawString>Maximilian Nickel, Volker Tresp, and Hans-Peter Kriegel. 2011. A three-way model for collective learning on multi-relational data. In Proceedings of the 28th International Conference on Machine Learning (ICML-11), pages 809–816.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Machine Learning and Knowledge Discovery in Databases,</booktitle>
<pages>148--163</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="4489" citStr="Riedel et al., 2010" startWordPosition="737" endWordPosition="740">roduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both KB data and text, using a rule-based random walk method. Recently, Riedel et al. (2013) proposed another joint approach based on collaborative filtering for learning entity embeddings. This approach connects text with Freebase by learning shared embeddings of entities through weak supervision, in contrast to our method where no joint learning is performed. We do not compare to these two approaches sinc</context>
<context position="9197" citStr="Riedel et al., 2010" startWordPosition="1539" endWordPosition="1542"> negative relation r0 such that r0 =6ri and r0 =6rj. 4. Make a stochastic gradient step to minimize max(0, 1 − f(mi)&gt;ri + f(mj)&gt;r0). ?(m) = arg max Sm2r(m, r0) = arg max (f(m)&gt;r0). 5. Enforce the constraint that each embedding r&apos;∈R r&apos;∈R vector is normalized, i.e. if ||Wi||2 &gt; 1 then Wi ← Wi/||Wi||2. Learning Sm2r(·) under constraints (1) is well suited when one is interested in building a permention prediction system. However, performance metrics of relation extraction are sometimes measured using precision recall curves aggregated for all mentions concerning the same pair of entities, as in (Riedel et al., 2010). In that case the scores across predictions for different mentions need to be calibrated so that the most confident ones have the higher scores. This can be better encoded with constraints of the following form: ∀i, j, ∀r0 =6 ri, rj, f(mi)&gt;ri &gt; 1 + f(mj)&gt;r0 . In this setup, scores of pairs observed in the training set should be larger than that of any other prediction across all mentions. In practice, we use “soft” ranking constraints (optimizing the hinge loss), i.e. we minimize: ∀i, j, ∀r0 =6 ri, rj, max(0, 1−f(mi)&gt;ri +f(mj)&gt;r0). Finally, we also enforce a (hard) constraint on the norms of </context>
<context position="14087" citStr="Riedel et al., 2010" startWordPosition="2429" endWordPosition="2432">hip can either be a valid relationship or NA – a marker that means that there is no relation between h and t (NA is added to R during training and is treated like other relationships). If ˆrh,t is a relationship, a composite score is defined: J: Sm2r+kb(h, ˆrh,t, t)= Sm2r(m, ˆrh,t)+˜Skb(h, ˆrh,t, t) mEMh,t That is, only the top scoring non-NA predictions are re-scored. Hence, our final composite model favors predictions that agree with both the mentions and the KB. If ˆrh,t is NA, the score is unchanged. 4 Experiments We use the training and test data, evaluation framework and baselines from (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). NYT+FB This dataset, developed by (Riedel et al., 2010), aligns Freebase relations with the New York Times corpus. Entities were found using the Stanford named entity tagger (Finkel et al., 2005), and were matched to their name in Freebase. For each mention, sentence level features are extracted which include part of speech, named entity and dependency tree path properties. Unlike some of the previous methods, we do not use features that aggregate properties across multiple mentions. We kept the 100,000 most frequent features.There are 52 possib</context>
<context position="17187" citStr="Riedel et al., 2010" startWordPosition="2951" endWordPosition="2954">e for SGD was selected using a validation set: we obtained 0.001 for S,,,2,,, and 0.1 for Skb. For the calibration of Skb, T = 10 (note, here we are ranking all 23k Freebase relationships). Training S,,,2,, took 5 minutes, whilst training Skb took 2 days due to the large scale of the data set. Results Figure 1 displays the aggregate precision / recall curves of our approach WSABIEM2R+FB which uses the combination of S,,,2,, + Skb, as well as WSABIEM2R , which only uses S,,,2,,, and existing state-of-the-art approaches: HOFFMANN (Hoffmann et al., 2011)2, MIMLRE (Surdeanu et al., 2012). RIEDEL (Riedel et al., 2010) and MINTZ (Mintz et al., 2009). WSABIEM2R is comparable to, but slightly worse than, the MIMLRE and HOFFMANN methods, possibly due to its simplified assumptions (e.g. predicting a single relationship per entity pair). However, the addition of extra knowledge from other Freebase entities in WSABIEM2R+FB provides superior performance to all other methods, by a wide margin, at least between 0 and 0.1 recall (see bottom plot). Performance of WSABIEM2R and WSABIEM2R+FB for recall &gt; 0.1 degrades rapidly, faster than that of other methods. This is also caused by the simplifications of WSABIEM2R that</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and Knowledge Discovery in Databases, pages 148–163. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
<author>Benjamin M Marlin</author>
</authors>
<title>Relation extraction with matrix factorization and universal schemas.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>74--84</pages>
<contexts>
<context position="4771" citStr="Riedel et al. (2013)" startWordPosition="784" endWordPosition="787">al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both KB data and text, using a rule-based random walk method. Recently, Riedel et al. (2013) proposed another joint approach based on collaborative filtering for learning entity embeddings. This approach connects text with Freebase by learning shared embeddings of entities through weak supervision, in contrast to our method where no joint learning is performed. We do not compare to these two approaches since they use two different evaluation protocols that greatly differ from those used in all aforementioned previous works. Nevertheless, our method is easier to integrate into existing systems than those, since KB data is used via the addition of a scoring term, which is trained separ</context>
</contexts>
<marker>Riedel, Yao, McCallum, Marlin, 2013</marker>
<rawString>Sebastian Riedel, Limin Yao, Andrew McCallum, and Benjamin M Marlin. 2013. Relation extraction with matrix factorization and universal schemas. In Proceedings of NAACL-HLT, pages 74–84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multi-instance multilabel learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>455--465</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4536" citStr="Surdeanu et al., 2012" startWordPosition="745" endWordPosition="748">hed the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both KB data and text, using a rule-based random walk method. Recently, Riedel et al. (2013) proposed another joint approach based on collaborative filtering for learning entity embeddings. This approach connects text with Freebase by learning shared embeddings of entities through weak supervision, in contrast to our method where no joint learning is performed. We do not compare to these two approaches since they use two different evaluation protocols t</context>
<context position="14134" citStr="Surdeanu et al., 2012" startWordPosition="2438" endWordPosition="2441"> – a marker that means that there is no relation between h and t (NA is added to R during training and is treated like other relationships). If ˆrh,t is a relationship, a composite score is defined: J: Sm2r+kb(h, ˆrh,t, t)= Sm2r(m, ˆrh,t)+˜Skb(h, ˆrh,t, t) mEMh,t That is, only the top scoring non-NA predictions are re-scored. Hence, our final composite model favors predictions that agree with both the mentions and the KB. If ˆrh,t is NA, the score is unchanged. 4 Experiments We use the training and test data, evaluation framework and baselines from (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). NYT+FB This dataset, developed by (Riedel et al., 2010), aligns Freebase relations with the New York Times corpus. Entities were found using the Stanford named entity tagger (Finkel et al., 2005), and were matched to their name in Freebase. For each mention, sentence level features are extracted which include part of speech, named entity and dependency tree path properties. Unlike some of the previous methods, we do not use features that aggregate properties across multiple mentions. We kept the 100,000 most frequent features.There are 52 possible relationships and 121,034 training mentions </context>
<context position="17157" citStr="Surdeanu et al., 2012" startWordPosition="2946" endWordPosition="2949">ension k to 50. The learning rate for SGD was selected using a validation set: we obtained 0.001 for S,,,2,,, and 0.1 for Skb. For the calibration of Skb, T = 10 (note, here we are ranking all 23k Freebase relationships). Training S,,,2,, took 5 minutes, whilst training Skb took 2 days due to the large scale of the data set. Results Figure 1 displays the aggregate precision / recall curves of our approach WSABIEM2R+FB which uses the combination of S,,,2,, + Skb, as well as WSABIEM2R , which only uses S,,,2,,, and existing state-of-the-art approaches: HOFFMANN (Hoffmann et al., 2011)2, MIMLRE (Surdeanu et al., 2012). RIEDEL (Riedel et al., 2010) and MINTZ (Mintz et al., 2009). WSABIEM2R is comparable to, but slightly worse than, the MIMLRE and HOFFMANN methods, possibly due to its simplified assumptions (e.g. predicting a single relationship per entity pair). However, the addition of extra knowledge from other Freebase entities in WSABIEM2R+FB provides superior performance to all other methods, by a wide margin, at least between 0 and 0.1 recall (see bottom plot). Performance of WSABIEM2R and WSABIEM2R+FB for recall &gt; 0.1 degrades rapidly, faster than that of other methods. This is also caused by the sim</context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multilabel learning for relation extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 455–465. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Weston</author>
<author>Samy Bengio</author>
<author>Nicolas Usunier</author>
</authors>
<title>Large scale image annotation: learning to rank with joint word-image embeddings.</title>
<date>2010</date>
<booktitle>Machine learning,</booktitle>
<pages>81--1</pages>
<contexts>
<context position="7142" citStr="Weston et al., 2010" startWordPosition="1173" endWordPosition="1177">ties and relationships in the KB are denoted by £ and R, and nv, ne and nr denote the size of V, £ and R respectively. Given a triple (h, r, t) the embeddings of the entities and the relationship (vectors in Rk) are denoted with the same letter, in boldface characters (i.e. h, r, t). 3.1 Connecting Text and Relationships The first part of the framework concerns the learning of a function Sm2r(m, r), based on embeddings, that is designed to score the similarity of a relation mention m and a relationship r. Our scoring approach is inspired by previous work for connecting word labels and images (Weston et al., 2010), which we adapted, replacing images by mentions and word labels by relationships. Intuitively, it consists of first projecting words and features into the embedding space and then computing a similarity measure (the dot product in this paper) between this projection and a relationship embedding. The scoring function is then: Sm2r(m, r) = f(m)Tr with f a function mapping words and features into Rk, f(m) = WT(V(m). W is the matrix of n R x k containing all word embeddings w, 0(m) is the (sparse) binary representation of m (E Rnv) indicating absence or presence of words/features, and r E Rk is t</context>
<context position="9986" citStr="Weston et al., 2010" startWordPosition="1682" endWordPosition="1685">ed with constraints of the following form: ∀i, j, ∀r0 =6 ri, rj, f(mi)&gt;ri &gt; 1 + f(mj)&gt;r0 . In this setup, scores of pairs observed in the training set should be larger than that of any other prediction across all mentions. In practice, we use “soft” ranking constraints (optimizing the hinge loss), i.e. we minimize: ∀i, j, ∀r0 =6 ri, rj, max(0, 1−f(mi)&gt;ri +f(mj)&gt;r0). Finally, we also enforce a (hard) constraint on the norms of the columns of W and r, i.e. ∀i, ||Wi||2 ≤ 1 and ∀j, ||rj||2 ≤ 1. Training is carried out by Stochastic Gradient Descent (SGD), updating W and r at each step, following (Weston et al., 2010; Bordes et al., 2013). That is, at the start of training the parameters to be learnt (the n„ × k word/feature embeddings in W and the nr × k relation embeddings r) are initialized to random weights. We initialize each k-dimensional embedding vector randomly with mean 0, standard deviation 1k. Then, we iterate the following steps to train them: 1. Select at random a positive training pair (mi, ri). 3.2 Encoding Structured Data of KBs Using only weakly labeled text mentions for training ignores much of the prior knowledge we can leverage from a large KB such as Freebase. In order to connect thi</context>
</contexts>
<marker>Weston, Bengio, Usunier, 2010</marker>
<rawString>Jason Weston, Samy Bengio, and Nicolas Usunier. 2010. Large scale image annotation: learning to rank with joint word-image embeddings. Machine learning, 81(1):21–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Autonomously semantifying wikipedia.</title>
<date>2007</date>
<booktitle>In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management,</booktitle>
<pages>41--50</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="4085" citStr="Wu and Weld, 2007" startWordPosition="667" endWordPosition="670">irical Methods in Natural Language Processing, pages 1366–1371, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics mantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012). This is also naturally used in IE, since it allows to train large-scale systems without requiring to label numerous texts. The idea was introduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both K</context>
</contexts>
<marker>Wu, Weld, 2007</marker>
<rawString>Fei Wu and Daniel S Weld. 2007. Autonomously semantifying wikipedia. In Proceedings of the sixteenth ACM conference on Conference on information and knowledge management, pages 41–50. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Wu</author>
<author>Daniel S Weld</author>
</authors>
<title>Open information extraction using wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>118--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4105" citStr="Wu and Weld, 2010" startWordPosition="671" endWordPosition="674">atural Language Processing, pages 1366–1371, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics mantic parsing (Kate and Mooney, 2007; Liang et al., 2009; Bordes et al., 2010; Matuszek et al., 2012). This is also naturally used in IE, since it allows to train large-scale systems without requiring to label numerous texts. The idea was introduced by (Craven et al., 1999), which matched the Yeast Protein Database with PubMed abstracts. It was also used to train open extractors based on Wikipedia infoboxes and corresponding sentences (Wu and Weld, 2007; Wu and Weld, 2010). Largescale open IE projects (e.g. (Banko et al., 2007)) also rely on weak supervision, since they learn models from a seed KB in order to extend it. Weak supervision is also a popular option for RE: Mintz et al. (2009) used Freebase to train weakly supervised relational extractors on Wikipedia, an approach generalized by the multi-instance learning frameworks (Riedel et al., 2010; Hoffmann et al., 2011; Surdeanu et al., 2012). All these works only use textual information to perform extraction. Lao et al. (2012) proposed the first work aiming to perform RE employing both KB data and text, usi</context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>Fei Wu and Daniel S Weld. 2010. Open information extraction using wikipedia. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 118–127. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>