<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000050">
<title confidence="0.993466">
Collective Opinion Target Extraction in Chinese Microblogs
</title>
<author confidence="0.998749">
Xinjie Zhou, Xiaojun Wan* and Jianguo Xiao
</author>
<affiliation confidence="0.972231333333333">
Institute of Computer Science and Technology
The MOE Key Laboratory of Computational Linguistics
Peking University
</affiliation>
<address confidence="0.949606">
No. 5, Yiheyuan Road, Beijing, China
</address>
<email confidence="0.991139">
{zhouxinjie,wanxiaojun,xiaojianguo}@pku.edu.cn
</email>
<sectionHeader confidence="0.993624" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999275055555556">
Microblog messages pose severe challenges
for current sentiment analysis techniques due
to some inherent characteristics such as the
length limit and informal writing style. In this
paper, we study the problem of extracting
opinion targets of Chinese microblog messag-
es. Such fine-grained word-level task has not
been well investigated in microblogs yet. We
propose an unsupervised label propagation al-
gorithm to address the problem. The opinion
targets of all messages in a topic are collec-
tively extracted based on the assumption that
similar messages may focus on similar opinion
targets. Topics in microblogs are identified by
hashtags or using clustering algorithms. Ex-
perimental results on Chinese microblogs
show the effectiveness of our framework and
algorithms.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999534384615385">
Microblogging services such as Twitter 1 , Sina
Weibo2 and Tencent Weibo3 have swept across the
globe in recent years. Users of microblogs range
from celebrities to ordinary people, who usually
express their emotions or attitudes towards a broad
range of topics. It is reported that there are more
than 340 million tweets per day on Twitter and
more than 200 million on Sina Weibo. A tweet
means a post on Twitter. Since we mainly focus
on Chinese microblogs instead of Twitter in this
paper, we will refer to a post as a message. Each
message is limited to 140 Chinese characters and
usually contains several sentences.
</bodyText>
<footnote confidence="0.89924575">
* Xiaojun Wan is the corresponding author.
1 https://twitter.com
2 http://weibo.com/
3 http://t.qq.com/
</footnote>
<bodyText confidence="0.999906923076923">
Currently, researches on microblog sentiment
analysis have been conducted on polarity classifi-
cation (Barbosa and Feng, 2010; Jiang el al., 2011;
Speriosu et al., 2011) and have been proved to be
useful in many applications, such as opinion poll-
ing (Tang et al., 2012), election prediction
(Tumasjan et al., 2010) and even stock market
prediction (Bollen et al., 2011). However, classify-
ing microblog texts at the sentence level is often
insufficient for applications because it does not
identify the opinion targets. In this paper, we will
study the task of opinion target extraction for Chi-
nese microblog messages.
Opinion target extraction aims to find the object
to which the opinion is expressed. For example, in
the sentence “The sound quality is good!”, “sound
quality” is the opinion target. This task is mostly
studied in customer review texts in which opinion
targets are often referred as features or aspects
(Liu, 2012). Most of the opinion target extraction
approaches rely on dependency parsing (Zhuang et
al., 2006; Jakob and Gurevych, 2010; Qiu et al.,
2011) and are regarded as a domain-dependent
task (Li et al., 2012a). However, such approaches
are not suitable for microblogs because the natural
language processing tools perform poorly on mi-
croblog texts due to their inherent characteristics.
Studies show that one of the state-of-the-art part-
of-speech taggers - OpenNLP only achieves the
accuracy of 74% on tweets (Liu et al. 2011). The
syntactic analysis tool that generates dependency
relation may perform even worse. Besides, mi-
croblog messages may express opinion in different
ways and do not always contain opinion words,
which lowers the performance of methods utiliz-
ing opinion words to find opinion targets.
In this study, we propose an unsupervised
method to collectively extract the opinion targets
from opinionated sentences in the same topic.
</bodyText>
<page confidence="0.919079">
1840
</page>
<note confidence="0.7305915">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1840–1850,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999932380952381">
Topics are directly identified by hashtags. We first
present a dynamic programming based segmenta-
tion algorithm for Chinese hashtag segmentation.
By leveraging the contents in a topic, our segmen-
tation algorithm can successfully identify out-of-
vocabulary words and achieve promising results.
Afterwards, all the noun phrases in each sentence
and the hashtag segments are extracted as opinion
target candidates. We propose an unsupervised
label propagation algorithm to collectively rank
the candidates of all sentences based on the as-
sumption that similar sentences in a topic may
share the same opinion targets. Finally, for each
sentence, the candidate which gets the highest
score after unsupervised label propagation is se-
lected as the opinion target.
Our contributions in this study are summarized
as follows: 1) our method considers not only the
explicit opinion targets within the sentence but
also the implicit opinion targets in the hashtag or
mentioned in the previous sentence. 2) We devel-
op an efficient algorithm to segment Chinese
hashtags. It can successfully identify out-of-
vocabulary words by leveraging contextual infor-
mation and help to improve the segmentation per-
formance of the messages in the topic. 3) We
develop an unsupervised label propagation algo-
rithm for collective opinion target extraction. La-
bel propagation (Zhu and Ghahramani, 2002) aims
to spread label distributions from a small training
set throughout the graph. However, our unsuper-
vised algorithm leverages the connection between
two adjacent unlabeled nodes to find the correct
labels for both of them. The proposed unsuper-
vised method does not need any training corpus
which will cost much human labor especially for
fine-grained annotation. 4) To the best of our
knowledge, the task of opinion target extraction in
microblogs has not been well studied yet. It is
more challenging than microblog sentiment classi-
fication and opinion target extraction in review
texts.
</bodyText>
<sectionHeader confidence="0.682527" genericHeader="method">
2 Characteristics of Chinese Microblogs
</sectionHeader>
<bodyText confidence="0.9999504375">
Most of previous microblog sentiment analysis
researches focus on Twitter and especially in Eng-
lish. However, the analysis of Chinese microblogs
has some differences with that of Twitter: 1) Chi-
nese word segmentation is a necessary step for
Chinese sentiment analysis, but the existing seg-
mentation tool performs poorly on microblogs
because the microblog texts are much different
from regular texts. 2) Wang et al. (2011) find that
hashtags in English tweets are used to highlight
the sentiment information such as “ #love”,
“#sucks” or serve as user-annotated coarse topics
such as “#news”, “#sports”. But in Chinese mi-
croblogs, most of the hashtags are used to indicate
fine-grained topics such as #NBA ,O�k %-LJ*#
(#NBAFinalG7#). Besides, hashtags in Twitter
always appear within a sentence such as “I love
#BarackObama!” while hashtags in Chinese mi-
croblogs are always isolated and are surrounded
by two # symbols such as “#ETAAAET�# VII
*!” (“#BarackObama# I love him!”).
It is noteworthy that topics aggregated by the
same hashtag play an important role in Chinese
microblog websites. These websites often provide
an individual webpage4 to list hot topics and invite
people to participate in the discussion, where each
topic consists of tens of thousands of messages
with the same hashtag. The hot topics have a wide
coverage of timely events and entities. Analyzing
the opinion targets of these topics can help to get a
deeper overview of the public attitudes towards
the entities involved in the hot topics.
</bodyText>
<sectionHeader confidence="0.992956" genericHeader="method">
3 Motivation
</sectionHeader>
<bodyText confidence="0.999984125">
As described above, #hashtags# in Chinese mi-
croblogs often indicate fine-grained topics. In this
study, we aim to collectively extract the opinion
targets of messages with the same hashtag, i.e. in
the same topic. Opinion target of a sentence can be
divided into two types, one of which called explic-
it target appears in the sentence such as “I love
Obama”, and the other one called implicit target
</bodyText>
<table confidence="0.933033571428571">
Topic Sentence
#&apos; _6dX�C `%r•# 1. q1 4/P_*!
#Property publicity (Just for show! )
of government offic
-ials#
(Property publicity is just a show
in China.)
#V_TfUrffJ* # 1. ���������
#Philippine navy (The government is not tough
vessel hits Chinese enough.)
fishing boat#
2. fAff L?
(Why cannot the government take
a tougher line?)
</table>
<tableCaption confidence="0.998023">
Table 1. Motivation Examples
</tableCaption>
<footnote confidence="0.971634">
4 http://huati.weibo.com/
</footnote>
<page confidence="0.995661">
1841
</page>
<bodyText confidence="0.999964413043479">
may appear out of the sentence, for example, the
sentence “Just for show!” in Table 1 directly
comments on the target in the hashtag “#Property
publicity of government officials#” . Such implicit
opinion targets are not considered in previous
works and are more difficult to extract than explic-
it targets. However, we believe that the contextual
information will help to locate both of the two
kinds of opinion targets because similar sentences
in a topic may share the same opinion target,
which provides the possibility for collective ex-
traction.
Table 1 shows the motivation examples of two
topics and four sentences. The two sentences in
each topic are considered to be similar because
they share several Chinese words. In the topic #j
�ISI GST# (#Property publicity of government
officials#), the first sentence omits the opinion
target. However, the second one contains an ex-
plicit target “ISI GST” (“property publicity”) in
the sentence. If we find the correct opinion target
for sentence 2, we can infer that sentence 1 may
have an implicit opinion target similar to the opin-
ion target in sentence 2. In the second topic, both
sentences contain a noun word “�C�” (“govern-
ment”). The similarity between these two sentenc-
es may indicate that both of the two sentences are
expressing opinion on “�C�”.
Based on the above observation, we can assume
that similar sentences in a topic may have the
same opinion targets. Such assumption can help to
locate both explicit and implicit opinion targets.
Following this idea, we firstly extract all the noun
phrases in each sentence as opinion target candi-
dates after applying Chinese word segmentation
and part-of-speech tagging. Afterwards, an unsu-
pervised label propagation algorithm is proposed
to rank these candidates for all sentences in the
topic.
In our methods, hashtags are used to find gold-
standard topics. For messages without hashtags, an
alternative way is to generate pseudo topics by
clustering microblogs messages and then apply the
proposed algorithm to each pseudo topic. The de-
tailed discussion of such general circumstance is
shown in Section 5.7.
</bodyText>
<sectionHeader confidence="0.999802" genericHeader="method">
4 Methodology
</sectionHeader>
<subsectionHeader confidence="0.999667">
4.1 Context-Aware Hashtag Segmentation
</subsectionHeader>
<bodyText confidence="0.999947958333333">
In our approach, the Chinese word segmentations
of hashtags and topic contents are treated separate-
ly. Existing Chinese word segmentation tools
work poorly on microblog texts. The segmentation
errors especially on opinion target words will di-
rectly influence the results of part-of-speech tag-
ging and candidate extraction. However, some of
the opinion target words in a topic are often in-
cluded in the hashtag. By finding the correct seg-
ments of a hashtag and adding them to the user
dictionary of the Chinese word segmentation tool,
we can remarkably improve the overall segmenta-
tion performance.
The following example can help to understand
the idea better. In the topic #90 , Fri TT�KA# (means
“A young man hits an old man”), “90 , Fri ” (literally
“90 later” and means a young man born in the 90s)
is an important word because it is the opinion tar-
get of many sentences. However, existing Chinese
word segmentation tools will regard it as two sep-
arate words “90” and “, Fri ” (“later”). Then in the
part-of-speech tagging stage, “90” will be tagged
as number and “, Fri ” will be tagged as localizer. As
we only extract noun phrases as opinion target
candidates, the wrong segmentation on “90 , Fri ”
makes it impossible to find the right opinion target.
Such error may occur many times in sentences that
mention the word “90 , Fri ” and express opinion on
it. In our method, the message texts of the topic
are utilized to identify such out-of-vocabulary
words based on its frequency in the topic. For ex-
ample, the high frequency of “90 , Fri ” is a strong
indication that it should be regard as a single word.
After segmenting the hashtag correctly into “90 , Fri
/TT/�KA”, we can add the hashtag segments to the
user dictionary of the segmentation tool to further
segment the message texts of the topic.
The basic idea for our hashtag segmentation al-
gorithm is to regard strings that appear frequently
in a topic as words. Formally, given a hashtag h
that contains n Chinese characters c1c2...cn. We
want to segment into several words w1w2...wm,
where each word is formed by one of more charac-
ters.
Firstly, we define the stickiness score for a Chi-
nese string c1c2...cn based on the Symmetrical
Conditional Probability (SCP) (Silva and Lopes,
1999):
</bodyText>
<page confidence="0.600912">
1842
</page>
<equation confidence="0.968045">
]MC,C2 ... C.) (1)
</equation>
<bodyText confidence="0.998289714285714">
and SCP(c1) = Pr(c1)2 for string with only one
character. Pr(c1c2...cn) is the occurrence frequency
of the string in the topic.
Following (Li et al., 2012b), we smooth the
SCP value by taking logarithm calculation. Be-
sides, the length of the string is taken into consid-
eration,
</bodyText>
<equation confidence="0.939235">
SCP (c,c2...cn) = n x log SCP(c,c2...cn) (2)
</equation>
<bodyText confidence="0.999967714285714">
where n is the number of characters in the string.
Then the stickiness score is defined by the sig-
moid function as follows:
For the hashtag h = c1c2...cn, we want to seg-
ment it into m words w1w2...wm which maximize
the following equation,
The optimization of Equation (4) can be solved
efficiently by dynamic programming which itera-
tively segments a string into two substrings. Dif-
ferent from (Li et al., 2012b) which calculates the
SCP value of each string based on Microsoft Web
N-Gram, our hashtag segmentation algorithm only
uses the topic content and do not need any addi-
tional corpus.
</bodyText>
<subsectionHeader confidence="0.99592">
4.2 Candidate Extraction
</subsectionHeader>
<bodyText confidence="0.98714075">
After segmenting the hashtag, all the hashtag seg-
ments with length greater than one are added to
the user dictionary of the Chinese word segmenta-
tion tool ICTCLAS5 to further segment the mes-
sage texts of the topic. It also assigns the part-of-
speech tag for each word after segmentation. The
noun phrases in each sentence is extracted by the
following regular expression:
(noun  |adj)(noun adj 的) noun. That means a
noun phrase can only include nouns, adjectives
and the Chinese word “的” (“of”). It should begin
with a noun or adjective and end with a noun. For
</bodyText>
<footnote confidence="0.427407">
5 http://www.ictclas.org/
</footnote>
<bodyText confidence="0.999985458333333">
example, in the following sentence, “中国/n 的/u
教育/n 制度/n 有/v 问题/n 。/w” (“Chinese edu-
cation system has problems.”), “中国的教育制度”
(“Chinese education system”) and “问题” (“prob-
lem”) are extracted as noun phrases.
The character number of a noun phrase is lim-
ited between two and seven Chinese characters.
For each sentence, all phrases that match the regu-
lar expression and meet the length restriction are
extracted as explicit opinion target candidates. The
hashtag segments are regarded as implicit candi-
dates for all sentences. Besides, some opinionated
sentences in microblogs do not contain any noun
phase, such as “无聊 至极 ! ” (“So boring!”).
These sentences may express opinion on object
that has been mentioned before. Therefore, the
explicit candidates of the previous sentence in the
same message are also taken as the implicit candi-
dates for such sentences.
We do not use any syntactic parsing tool to ex-
tract noun phrases because the parsing results on
microblogs are not reliable. A performance com-
parison of our rule based method and the state-of-
the-art syntactic parser will be shown in Section 5.
</bodyText>
<subsectionHeader confidence="0.999632">
4.3 Unsupervised Label Propagation for
Candidate Ranking
</subsectionHeader>
<bodyText confidence="0.999309">
We simply assume that each opinionated sentence
has one opinion target, which is consistent with
</bodyText>
<figure confidence="0.607948222222222">
Algorithm 1 Unsupervised Label Propagation
Input:
Graph: G =&lt; V, E, W &gt;
Candidate Similarity: Se R xm
Prior labeling: for veV
Filtering Matrix: for veV
Probability: pinj and pcont
Output:
Label vector: Y e R+&amp;quot;M
</figure>
<listItem confidence="0.9822787">
1: for all ve V do
2: Y &lt;— Y
3: end for
4: repeat
5: for all ve V do
6: D E Wuv (Y X S)X 1
ue V,umv
7: ˆYv  pinyYv  pcontDv
8: end for
9: until convergence
</listItem>
<page confidence="0.960163">
1843
</page>
<bodyText confidence="0.999973292682927">
the statistical result of our dataset that over 93%
sentences have only one opinion target and each
sentence has an average of 1.09 targets. Therefore,
the most confident candidate of each sentence will
be selected as the opinion target. In this section,
we introduce an unsupervised graph-based label
propagation algorithm to collectively rank the
candidates of all sentences in a topic.
Label propagation (Zhu and Ghahramani, 2002;
Talukdar and Crammer, 2009) is a semi-
supervised algorithm which spreads label distribu-
tions from a small set of nodes seeded with some
initial label information throughout the graph. The
basic idea is to use information from the labeled
nodes to label the adjacent nodes in the graph.
However, our idea is to use the connection be-
tween different nodes to find the correct labels for
all of them. Our unsupervised label propagation
algorithm is summarized in Algorithm 1. Sentenc-
es are regarded as nodes and candidates of each
sentence are regarded as labels. The label vector
for each node is initialized based on the results of
the candidate extraction step, which means no
manually-labeled instances are needed in our
model. In each iteration, the label vector of one
node is propagated to the adjacent nodes. Both the
sentence (node) similarity and the candidate (label)
similarity are considered during propagation. Fi-
nally, we select the candidate with the highest
score in the label vector as the opinion target for
each sentence. The details of Algorithm 1 are pre-
sented as follows.
Formally, an undirected graphG=&lt;V,E,W&gt;
is built for each topic. A node vV represents a
sentence in the topic and an edge e = (a, b) E
indicates that the labels of the two vertices should
be similar. is the normalized weight matrix to
reflect the strength of this similarity. The similari-
ty between two nodes Wab is simply calculated by
using the cosine measure (Salton et al., 1975) of
the two sentences.
</bodyText>
<equation confidence="0.855845">
T T
</equation>
<bodyText confidence="0.955394">
where Ta and Tb are the term vectors of sentences a
and b represented by the standard vector space
model and weighted by term frequency. After cal-
culating the similarity matrix W, we get the weight
matrix by normalizing each row of W such that
</bodyText>
<equation confidence="0.987191">
(Y)k 1&lt;_k&lt;_M � (8)
.
</equation>
<bodyText confidence="0.988997333333333">
For each sentence (node) v, a candidate set Cv is
extracted in the previous step. The candidate set
CT for the whole topic is the union of all Cv,
</bodyText>
<equation confidence="0.854890833333333">
(6)
The total number of candidates in the topic is
denoted by M = |CT|. We calculate the candidate
similarity matrix based on Jaccard In-
dex:
(7)
</equation>
<bodyText confidence="0.99980575">
where A(CTi) and A(CTj) are the Chinese character
sets of the i-th and j-th candidates in CT respec-
tively.
Candidates are regarded as labels in our model
and without loss of generality we assume that the
possible labels for the whole topic are L = {1...M}
and each label in L corresponds to a unique can-
didate in CT. For each node vV, a label vector
</bodyText>
<equation confidence="0.994381">
Y. E R&apos;XM is initialized as
r w Lk E Cv
0 Lk � Cv
</equation>
<bodyText confidence="0.999871076923077">
where w is the initial weight of the candidate. We
set w = we if Lk is an explicit candidate (extracted
noun phrase) of v and w = wi if Lk is an implicit
candidate (hashtag segment or inherited from pre-
vious sentence) of v. If Lk is not a candidate of the
current sentence, then the corresponding value in
the label vector is 0. These values which are ini-
tialized as zero should always remain zero during
the propagation algorithm because the correspond-
ing label does not belong to the candidate set Cv of
node v. To reset the values on these positions, a
diagonal matrix F E RMXM is created for all nodes
v,
</bodyText>
<equation confidence="0.99486">
1
(F)kk=( (Y)k&gt;0 1&lt;k&lt;M (9)
10 ( v )k=0
</equation>
<bodyText confidence="0.998848666666667">
where the subscript kk denotes the k-th position in
the diagonal of matrix Fv. We can right-multiply
Yv by Fv to clear the values of the invalid candi-
</bodyText>
<figure confidence="0.9670745">
Wab =cos(Ta,Tb)= a b

Ta  Tb
(5)
</figure>
<page confidence="0.98668">
1844
</page>
<bodyText confidence="0.9992105">
dates. Figure 1 shows an example of creating the
filtering matrix for a label vector.
</bodyText>
<equation confidence="0.7350465">
 1
0 
</equation>
<table confidence="0.8487518">
Yv   1 1 0.5 0   Fv   0 0 0 
 1 0 0 
0 0 1 
 0 0 0 
0
</table>
<figureCaption confidence="0.998545">
Figure 1. Example of filtering matrix
</figureCaption>
<equation confidence="0.619961">
0 
</equation>
<bodyText confidence="0.999009">
The propagation process is formalized via two
possible actions: inject and continue, with pre-
defined probabilities pinj and pcont. Their sum is
unit: pinj + pcont = 1. In each iteration, every node is
influenced by its adjacent nodes. The propagation
influence for each node v is
</bodyText>
<equation confidence="0.930118">
(10)
</equation>
<bodyText confidence="0.999909272727273">
where is the label vector of node u at the previ-
ous iteration. By multiplying the candidate simi-
larity matrix S, we aim to propagate the score of
the i-th candidate of node u not only to the i-th
candidate of node v, but also to all the other can-
didates. Wuv measures the strength of such propa-
gation. The filtering matrix Fv is used to clear the
values of the invalid candidates as described
above.
Then the label vector of node v is updated as
follow,
</bodyText>
<equation confidence="0.999513">
Y = p&apos;YY + pc°&amp;quot;D (11)
</equation>
<bodyText confidence="0.999925">
When the positions of the largest values in all
label vectors keep unchanged in ten iterations, it is
regarded that the algorithm has already converged.
</bodyText>
<sectionHeader confidence="0.999594" genericHeader="method">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.789043">
5.1 Dataset
</subsectionHeader>
<bodyText confidence="0.999856">
We use the dataset from the 2012 Chinese Mi-
croblog Sentiment Analysis Evaluation (CMSAE)6
held by China Computer Federation (CCF). There
are three tasks in the evaluation: subjectivity clas-
sification, polarity classification and opinion target
extraction. The dataset contains 20 topics collect-
ed from Tencent Weibo, a popular Chinese mi-
croblogging website. All the messages in a topic
contain the same hashtag. The dataset has a total
</bodyText>
<footnote confidence="0.7688145">
6 http://tcci.ccf.org.cn/conference/2012/pages/page04_eva.
html. The dataset can also be publicly accessed on the website.
</footnote>
<bodyText confidence="0.9858208">
of 17518 messages and 31675 sentences. In each
topic, 100 messages are manually annotated with
subjectivity, polarity and opinion targets. A total
of 2361opinion targets are annotated for 2152
opinionated sentences.
</bodyText>
<subsectionHeader confidence="0.996156">
5.2 Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.977778">
Precision, recall and F-measure are used in the
evaluation. Since expression boundaries are hard
to define exactly in annotation guidelines (Wiebe
et al., 2005), both the strict evaluation metric and
the soft evaluation metric are used in CMSAE.
Strict Evaluation: For a proposed opinion tar-
get, it is regarded as correct only if it covers the
same span with the annotation result. Note that, in
CMSAE, an opinion target should be proposed
along with its polarity. The correctness of the po-
larity is also necessary.
</bodyText>
<listItem confidence="0.5297842">
Soft Evaluation: The soft evaluation metric
presented in (Johansson and Moschitti, 2010) is
adopted by CMSAE. The span coverage c be-
tween each pair of the proposed target span s and
the gold standard span s’ is calculated as follows,
</listItem>
<equation confidence="0.969196333333333">
s S s S
   
(12)
</equation>
<bodyText confidence="0.9990902">
In Equation 12, the operator |· |counts Chinese
characters, and the intersection ∩ gives the set of
characters that two spans have in common.
Using the span coverage, the span set coverage
C of a set of spans S with respect to another set S’
</bodyText>
<equation confidence="0.882236">
is C(S,S&apos;)=EEc(s,$) (13)
</equation>
<bodyText confidence="0.691902666666667">
The soft precision P and recall R of a proposed
set of spans with respect to a gold standard set
S is defined as follows:
</bodyText>
<equation confidence="0.998797">
Precision  C(S, S) Recall  C(S, S) (14)
|Sˆ ||S|
</equation>
<bodyText confidence="0.999916666666667">
Note that the operator |· |counts spans in Equation
14. The soft F-measure is the harmonic mean of
soft precision and recall.
</bodyText>
<subsectionHeader confidence="0.845033">
5.3 Comparison Methods
</subsectionHeader>
<bodyText confidence="0.9844658">
Our proposed approach is first compared with the
CMSAE teams.
CMSAE Teams: Sixteen teams participated in
the opinion target extraction task of CMSAE. The
methods of the top 3 teams are used as baselines
</bodyText>
<page confidence="0.982777">
1845
</page>
<bodyText confidence="0.999939">
here. They are denoted as Team-1, Team-2 and
Team-3 respectively. The average result of all the
sixteen teams is also included and is denoted as
Team-Avg. We will briefly introduce the best
team’s method. The most important component of
their model is a topic-dependent opinion target
lexicon which is called object sheet. If a word or
phrase in the object sheet appears in a sentence or
a hashtag, it is extracted as opinion target. The
object sheet is manually built for each topic,
which means their method cannot be applied to
new topics.
The following models are also used for compar-
ison.
AssocMi: We implement the unsupervised
method for opinion target extraction based on (Hu
and Liu, 2004), which relies on association mining
and a sentiment lexicon to extract frequent and
infrequent product features.
CRF: The CRF-based method used in (Jakob
and Gurevych, 2010) is also used for comparison.
We implement both the single-domain and cross-
domain models. Both models are evaluated using
5-fold cross-validation. More specifically, the sin-
gle-domain model, denoted as CRF-S, trains dif-
ferent models for different topics. In each cross-
validation round, 80 percent of each topic is used
for training and the other 20 percent is used for
test. The cross-domain model, denoted as CRF-C,
uses 16 topics for training and the rest 4 topics for
test in each round.
</bodyText>
<subsectionHeader confidence="0.994469">
5.4 Comparison Results
</subsectionHeader>
<bodyText confidence="0.999581243243243">
CMSAE requires all the teams to perform the sub-
jectivity and polarity classification task in advance.
The opinion targets are extracted only for opinion-
ated sentences and should be proposed along with
their polarity. To make a fair comparison, we di-
rectly use the subjectivity and polarity classifica-
tion results of Team-1. Then our unsupervised
label propagation (ULP) method is used to extract
the opinion targets for the proposed opinionated
sentences. The parameters of our method are
simply set as pinj = pcont = 0.5, we = 1 and wi = 0.5.
Table 2 lists the comparison results with
CMSAE teams. The average F-measure of all
teams is 0.12 and 0.20 in strict and soft evaluation,
respectively. It shows that opinion target extrac-
tion is a quite hard problem in Chinese microblogs.
Our method performs better than all the teams. It
increases by 10% and 13% in the two kinds of F-
measure compared to the best team. Besides, we
do not need any prior information of the topics
while Team-1 has to manually build an opinion
target lexicon for each topic.
To compare with the other opinion target ex-
traction methods, we only use gold-standard opin-
ionated sentences for evaluation and do not
classify the polarity of the opinion targets. Table 3
shows the experimental results of the four models.
Our approach achieves the best result among them.
AssocMi performs worst in strict evaluation but
gets better results than the two CRF-based models
in soft evaluation. The two CRF-based models
achieve high precision but low recall. We can also
observe that CRF-S is much more effective than
CRF-C. It achieves high results because it has al-
ready seen the opinion targets in the training set.
However, it is impossible to build such single-
domain model in practical applications because
</bodyText>
<table confidence="0.998970714285714">
Method. Strict Soft
Precision Recall F-measure Precision Recall F-measure
Team-Avg 0.17 0.09 0.12 0.29 0.15 0.20
Team-3 0.26 0.16 0.20 0.40 0.25 0.31
Team-2 0.31 0.18 0.23 0.40 0.22 0.29
Team-1 0.30 0.27 0.29 0.39 0.36 0.37
ULP 0.37 0.27 0.32 0.48 0.37 0.42
</table>
<tableCaption confidence="0.999398">
Table 2. Comparison results with CMSAE teams (with subjectivity and polarity classification in advance)
</tableCaption>
<table confidence="0.999848833333333">
Method Strict Soft
Precision Recall F-Measure Precision Recall F-Measure
AssocMi 0.22 0.20 0.21 0.47 0.43 0.45
CRF-C 0.59 0.15 0.24 0.70 0.18 0.28
CRF-S 0.61 0.27 0.35 0.73 0.31 0.41
ULP 0.43 0.39 0.41 0.61 0.55 0.58
</table>
<tableCaption confidence="0.999876">
Table 3. Comparison results with baseline methods (only gold-standard opinionated sentences are used)
</tableCaption>
<page confidence="0.970172">
1846
</page>
<figure confidence="0.983083">
(a) Initial Candidate Weight (b) Injection Probability
</figure>
<figureCaption confidence="0.999989">
Figure 2. Influence of the parameters
</figureCaption>
<bodyText confidence="0.992736666666667">
labeled instances are not available for new topics.
Our proposed method does not require any train-
ing data and gets an increase of 17% over CRF-S
and 70% over CRF-C in strict evaluation. In terms
of soft evaluation, we achieve an increase of 41%
and 107% over the two CRF models.
</bodyText>
<subsectionHeader confidence="0.987877">
5.5 Parameter Sensitivity Study
</subsectionHeader>
<bodyText confidence="0.99996896875">
In this section, we study the parameter sensitivity.
There are two major parameters in our algorithm:
the initial weight w for both explicit and implicit
candidates in Equation 8 and the injection proba-
bility pinj in Equation 11.
The initial weights of explicit and implicit can-
didates are set differently because the explicit can-
didates are more likely to be the opinion targets.
These two kinds of initial weights are denoted as
we and wi for explicit and implicit candidate, re-
spectively. To study the impact of the initial
weights, we fix we at 1 and tune wi because we
only care about the relative contribution of them.
The injection probability is fixed at 0.5. Figure 2(a)
displays the opinion target extraction performance
when wi varies from 0 to 1.5. Due to limited space,
we only list the strict F-measure of opinion target
extraction evaluated on opinioned sentences (same
experimental setup as Table 3).
In particular, when wi is equal to 0, only explicit
candidates are considered. When wi becomes larg-
er than 1, the implicit candidates become more
important than explicit candidates. From the curve
in Figure 2(a), we can observe that the implicit
candidates help to improve the performance sig-
nificantly when wi varies from 0 to 0.1. The per-
formance reaches the peak when wi = 0.7 and
declines rapidly when wi gets larger than 1.
To study the impact of injection probability pinj,
we fix the initial weights for explicit and implicit
candidates as 1 and 0.5, respectively. Figure 2(b)
shows the results of opinion target extraction with
</bodyText>
<table confidence="0.998839857142857">
F-Measure of Opinion
Method Total Correct Target Extraction
Strict Soft
Berkley 4554 877 0.36 0.56
Parser
Rule 4105 918 0.37 0.56
HS + Rule 4094 1042 0.41 0.58
</table>
<tableCaption confidence="0.99477">
Table 4. Performance of candidate extraction and
opinion target extraction
</tableCaption>
<bodyText confidence="0.999758666666667">
respect to different values of the injection proba-
bility. We can observe that the performance keeps
steady except for the two extreme values 0 and 1.
From the above two figures, we can conclude that
our proposed method performs well and robustly
with a wide range of parameter values.
</bodyText>
<subsectionHeader confidence="0.999611">
5.6 Analysis of Candidate Extraction
</subsectionHeader>
<bodyText confidence="0.99997006060606">
Candidate extraction is an important step in our
proposed method. If the correct opinion target is
not extracted as a candidate, the ranking step will
be in vain. As described in Section 3, we develop
a hashtag segmentation algorithm and use a rule
based method to extract noun phrases from each
sentence. We do not use any parsing tool because
we believe the performance of these tools is not
good enough when applied on microblogs. A
quantitative comparison is shown in this section.
We use one of the state-of-the-art syntactic
analysis tools - Berkeley Parser (Petrov et al.,
2006) for comparison here. Noun phrases are di-
rectly extracted from the parsing results. Our
method HS+Rule leverages the hashtag segments
to enhance the segmentation result and extracts
explicit candidate using a regular expression. To
demonstrate the effectiveness of our hashtag seg-
mentation algorithm, the second comparison base-
line Rule directly uses ICTCLAS to segment the
whole topic content and labels each word with its
part-of-speech tag. The explicit candidates are ex-
tracted by using the same regular expression.
The performance on candidate extraction is
compared in Table 4. The second column shows
the number of all extracted candidates for all the
opinionated sentences by different methods. The
third column shows the number of correct opinion
targets among them. We can find that the two rule-
based models both outperform Berkeley Parser
and our HS+Rule method finds 14% more correct
opinion targets than Rule. It proves the effective-
ness of our hashtag segmentation algorithm. The
</bodyText>
<figure confidence="0.997286538461539">
0.3
0.3
0 0.2 0.4 0.6 0.8 1 1.2 1.4
wi
0.2 0.4 0.6 0.8 1
pinj
0.44
0.42
0.4
0.38
0.36
0.4
0.38
Precision
0.36
Precision
Recall
F-Measure
0.34
0.32
0.44
0.42
0.34
0.32
Recall
F-Measure
</figure>
<page confidence="0.990957">
1847
</page>
<bodyText confidence="0.999676545454545">
total number of candidates extracted by HS+Rule
is also less than the other two methods. Therefore,
the performance of label propagation will be im-
proved when there are fewer candidates to rank. It
can be demonstrated by the F-measure of opinion
target extraction in the fourth and fifth columns.
The experiments are conducted on opinionated
sentence only as above. By using HS+Rule to ex-
tract candidates, our label propagation algorithm
gets the highest F-measure in both evaluation met-
rics.
</bodyText>
<subsectionHeader confidence="0.989503">
5.7 Performance on Pseudo Topics by Mes-
sage Clustering
</subsectionHeader>
<bodyText confidence="0.999941027777778">
In our collective extraction algorithm, topics are
directly identified by hashtags. For messages
without hashtags, we can first employ clustering
algorithms to obtain pseudo topics (clusters) and
then exploiting the topic-oriented algorithm for
collective opinion target extraction. To test the
performance of the proposed method in such cir-
cumstance, we use the popular clustering algo-
rithm - Affinity Propagation (Frey and Dueck,
2007) to generate topics. The experimental results
are shown in Table 5. APCluster means that the
messages are clustered after removing all the
hashtags. APCluster+HS means that all the
hashtags are retained as normal texts for calculat-
ing message similarity. Therefore, the clustering
performance can be largely improved. The stand-
ard cosine similarity is used to measure the dis-
tance between microblog messages for Affinity
Propagation in the above two methods. The last
method denoted as GoldCluster directly uses
hashtags to identify the gold-standard topics which
shows the upper bound of the performance. After
clustering microblogs, the opinion targets of mes-
sages in each cluster are collectively extracted by
the proposed unsupervised label propagation algo-
rithm. The experiments are conducted on opinion-
ated sentences only.
From the results, we can see that clustering mi-
croblogs without hashtags is a quite difficult job
which only gets an F-Measure of 0.27. However,
the corresponding opinion target extraction per-
formance is still promising, which outperforms the
AssocMi and CRF-C methods in Table 3. With the
help of hashtags, the clustering performance of
APCluster+HS is largely improved and the opin-
ion target extraction performance is also increased.
</bodyText>
<table confidence="0.998522333333333">
F-Measure of Opinion
Clustering Method F-Measure Target Extraction
of Clustering Strict Soft
APCluster 0.27 0.35 0.50
APCluster+HS 0.71 0.37 0.55
GoldCluster 1.00 0.41 0.58
</table>
<tableCaption confidence="0.9788645">
Table 5. Performance of clustering and opinion
target extraction
</tableCaption>
<bodyText confidence="0.999877">
It outperforms all the baseline methods in Table 3.
The above results reveal that our proposed unsu-
pervised label propagation algorithm works well
in pseudo topics and the performance can be in-
creased with better clustering results. Therefore,
we can try to incorporate other social network in-
formation to improve the message clustering per-
formance, which will be studied in our future
work.
</bodyText>
<sectionHeader confidence="0.999978" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999938903225807">
Sentiment analysis, a.k.a. opinion mining, is the
field of studying and analyzing people’s opinions,
sentiments, evaluations, appraisals, attitudes, and
emotions (Liu, 2012). Most of the previous senti-
ment analysis researches focus on customer re-
views (Pang et al., 2002; Hu and Liu, 2004) and
some of them focus on news (Kim and Hovy,
2006) and blogs (Draya et al., 2009). However,
sentiment analysis on microblogs has recently at-
tracted much attention and has been proved to be
very useful in many applications.
Classification of opinion polarity is the most
common task studied in microblogs. Go et.al
(2009) follow the supervised machine learning
approach of Pang et al. (2002) to classify the po-
larity of each tweet by distant supervision. The
training dataset of their method is not manually
labeled but automatically collected using the
emoticons. Barbosa and Feng (2010) use the simi-
lar pseudo training data collected from three
online websites which provide Twitter sentiment
analysis services. Speriosu et al. (2009) explore
the possibility of exploiting the Twitter follower
graph to improve polarity classification.
Opinion target extraction is a fine-grained
word-level task of sentiment analysis. Currently,
this task has not been well studied in microblogs
yet. It is mostly performed on product reviews
where opinion targets are always described as
product features or aspects. The pioneering re-
search on this task is conducted by Hu and Liu
</bodyText>
<page confidence="0.9755">
1848
</page>
<bodyText confidence="0.999877636363636">
(2004) who propose a method which extracts fre-
quent nouns and noun phrases as the opinion tar-
gets. Jakob and Gurevych (2010) model the
problem as a sequence labeling task based on
Conditional Random Fields (CRF). Qiu et al.
(2011) propose a double propagation method to
extract opinion word and opinion target simulta-
neously. Liu et al. (2012) use the word translation
model in a monolingual scenario to mine the asso-
ciations between opinion targets and opinion
words.
</bodyText>
<sectionHeader confidence="0.990331" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999954571428571">
In this paper, we study the problem of opinion
target extraction in Chinese microblogs which has
not been well investigated yet. We propose an un-
supervised label propagation algorithm to collec-
tively rank the opinion target candidates of all
sentences in a topic. We also propose a dynamic
programming based algorithm for segmenting
Chinese hashtags. Experimental results show the
effectiveness of our method.
In future work, we will try to collect and anno-
tate data for microblogs in other languages to test
the robustness of our method. The repost and reply
messages can also be integrated into our graph
model to help improve the results.
</bodyText>
<sectionHeader confidence="0.997653" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.990570666666667">
The work was supported by NSFC (61170166),
Beijing Nova Program (2008B03) and National
High-Tech R&amp;D Program (2012AA011101).
</bodyText>
<sectionHeader confidence="0.998473" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999608317460318">
Barbosa Luciano and Junlan Feng. 2010. Robust senti-
ment detection on twitter from biased and noisy data.
In Proceedings of the 23rd International Conference
on Computational Linguistics: Posters. Association
for Computational Linguistics, 2010.
Johan Bollen, Huina Mao and Xiaojun Zeng. 2011.
Twitter mood predicts the stock market. Journal of
Computational Science 2.1 (2011): 1-8.
Gérard Dray, Michel Plantié, Ali Harb, Pascal Poncelet,
Mathieu Roche and François Trousset. 2009. Opin-
ion Mining from Blogs. In International Journal of
Computer Informa-tion Systems and Industrial Man-
agement Applications.
Brendan J. Frey and Delbert Dueck. 2007. &amp;quot;Clustering
by passing messages between data points.&amp;quot; Science
315.5814 (2007): 972-976.
Alec Go, Richa Bhayani and Lei Huang. 2009. Twitter
sentiment classification using distant supervision.
CS224N Project Report, Stanford (2009): 1-12.
Minqing Hu and Bing Liu. Mining and summarizing
customer reviews. 2004. In Proceedings of the tenth
ACM SIGKDD international conference on
Knowledge discovery and data mining, pp. 168-177.
ACM.
Long Jiang , Mo Yu, Ming Zhou, Xiaohua Liu and
Tiejun Zhao. 2011. Target-dependent twitter senti-
ment classification. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, vol. 1,
pp. 151-160.
Niklas Jakob and Iryna Gurevych. Extracting opinion
targets in a single-and cross-domain setting with
conditional random fields. 2010. In Proceedings of
the 2010 Conference on Empirical Methods in Natu-
ral Language Processing. Association for Computa-
tional Linguistics.
Richard Johansson and Alessandro Moschitti. 2010.
Syntactic and semantic structure for opinion expres-
sion detection. Proceedings of the Fourteenth Con-
ference on Computational Natural Language
Learning. Association for Computational Linguistics.
Soo-Min Kim and Eduard Hovy. 2006. Extracting
Opinions, Opinion Holders and Topics Expressed in
Online News Media Text. In Proceedings of the
ACL Workshop on Sentiment and Subjectivity in
Text, 2006, pp. 1–8.
Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang and
Xiaoyan Zhu. 2012a. Cross-Domain Co-Extraction
of Sentiment and Topic Lexicons. In Proceedings of
the 50th Annual Meeting of the Association for
Computational Linguistics, pages 410–419, Jeju,
Republic of Korea, 8-14 July 2012.
Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao,
Anwitaman Datta, Aixin Sun and Bu-Sung Lee.
2012b. Twiner: Named entity recognition in targeted
twitter stream. In Proceedings of the 35th interna-
tional ACM SIGIR conference on Research and de-
velopment in information retrieval, pp. 721-730.
ACM.
Xiaohua Liu, Kuan Li, Ming Zhou and Zhongyang
Xiong. 2011. Collective semantic role labeling for
tweets with clustering. In Proceedings of the Twen-
ty-Second international joint conference on Artificial
</reference>
<page confidence="0.896286">
1849
</page>
<reference confidence="0.999849031746032">
Intelligence-Volume Volume Three, pp. 1832-1837.
AAAI Press.
Bing Liu. 2012. Sentiment analysis and opinion mining.
Synthesis Lectures on Human Language Technolo-
gies 5.1 (2012): 1-167.
Kang Liu, Liheng Xu and Jun Zhao. 2012. Opinion
Target Extraction Using Word-Based Translation
Model. In Proceedings of the 2012 Joint Conference
on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing.
Bo Pang, Lillian Lee and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natural
language processing-Volume 10, pp. 79-86. Associa-
tion for Computational Linguistics.
Slav Petrov, Leon Barrett, Romain Thibaux and Dan
Klein. Learning accurate, compact, and interpretable
tree annotation. 2006. In Proceedings of the 21st In-
ternational Conference on Computational Linguistics
and the 44th annual meeting of the Association for
Computational Linguistics, pp. 433-440.
Guang Qiu, Bing Liu, Jiajun Bu and Chun Chen. 2011.
Opinion word expansion and target extraction
through double propagation. Computational linguis-
tics 37, no. 1 (2011): 9-27.
G. Salton, A. Wong and C. S. Yang. 1975. A Vector
Space Model for Automatic Indexing, Communica-
tions of the ACM, vol. 18, nr. 11, pages 613–620.
J. F. da Silva and G. P. Lopes. 1999. A local maxima
method and a fair dispersion normalization for ex-
tracting multi-word units from corpora. In Proc. of
the 6th Meeting on Mathematics of Language .
Michael Speriosu, Nikita Sudan, Sid Upadhyay and
Jason Baldridge. 2011. Twitter polarity classification
with label propagation over lexical links and the fol-
lower graph. In Proceedings of the First Workshop
on Unsupervised Learning in NLP, pp. 53-63. Asso-
ciation for Computational Linguistics, 2011.
Partha Talukdar and Koby Crammer. New regularized
algorithms for transductive learning. 2009. Machine
Learning and Knowledge Discovery in Databases
(2009): 442-457.
Jie Tang, Yuan Zhang, Jimeng Sun, Jinhai Rao, Wen-
jing Yu, Yiran Chen and A. C. M. Fong. 2012.
Quantitative study of individual emotional states in
social networks. Affective Computing, IEEE Trans-
actions on 3, no. 2 (2012): 132-144.
Andranik Tumasjan, Timm O. Sprenger, Philipp G.
Sandner and Isabell M. Welpe. 2010. Predicting
elections with twitter: What 140 characters reveal
about political sentiment. In Proceedings of the
fourth international aaai conference on weblogs and
social media, pp. 178-185.
X. Zhu and Z. Ghahramani. 2002. Learning from la-
beled and unlabeled data with label propagation.
Technical report, CMU CALD tech report.
Li Zhuang, Feng Jing and Xiaoyan Zhu. 2006. Movie
review mining and summarization. In Proceedings of
the ACM 15th Conference on Information and
Knowledge Management, pages 43–50, Arlington,
Virginia, USA, November.
</reference>
<page confidence="0.990553">
1850
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.423091">
<title confidence="0.998919">Collective Opinion Target Extraction in Chinese Microblogs</title>
<author confidence="0.930967">Xinjie Zhou</author>
<author confidence="0.930967">Xiaojun Wan</author>
<author confidence="0.930967">Jianguo</author>
<affiliation confidence="0.973634">Institute of Computer Science and The MOE Key Laboratory of Computational</affiliation>
<address confidence="0.748458">Peking No. 5, Yiheyuan Road, Beijing,</address>
<email confidence="0.990325">zhouxinjie@pku.edu.cn</email>
<email confidence="0.990325">wanxiaojun@pku.edu.cn</email>
<email confidence="0.990325">xiaojianguo@pku.edu.cn</email>
<abstract confidence="0.996131894736842">Microblog messages pose severe challenges for current sentiment analysis techniques due to some inherent characteristics such as the length limit and informal writing style. In this paper, we study the problem of extracting opinion targets of Chinese microblog messages. Such fine-grained word-level task has not been well investigated in microblogs yet. We propose an unsupervised label propagation algorithm to address the problem. The opinion targets of all messages in a topic are collectively extracted based on the assumption that similar messages may focus on similar opinion targets. Topics in microblogs are identified by hashtags or using clustering algorithms. Experimental results on Chinese microblogs show the effectiveness of our framework and algorithms.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Barbosa Luciano</author>
<author>Junlan Feng</author>
</authors>
<title>Robust sentiment detection on twitter from biased and noisy data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters. Association for Computational Linguistics,</booktitle>
<marker>Luciano, Feng, 2010</marker>
<rawString>Barbosa Luciano and Junlan Feng. 2010. Robust sentiment detection on twitter from biased and noisy data. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters. Association for Computational Linguistics, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bollen</author>
</authors>
<title>Huina Mao and Xiaojun Zeng.</title>
<date>2011</date>
<journal>Journal of Computational Science</journal>
<volume>2</volume>
<pages>1--8</pages>
<marker>Bollen, 2011</marker>
<rawString>Johan Bollen, Huina Mao and Xiaojun Zeng. 2011. Twitter mood predicts the stock market. Journal of Computational Science 2.1 (2011): 1-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gérard Dray</author>
<author>Michel Plantié</author>
<author>Ali Harb</author>
<author>Pascal Poncelet</author>
</authors>
<title>Mathieu Roche and François Trousset.</title>
<date>2009</date>
<booktitle>In International Journal of Computer Informa-tion Systems and Industrial Management Applications.</booktitle>
<marker>Dray, Plantié, Harb, Poncelet, 2009</marker>
<rawString>Gérard Dray, Michel Plantié, Ali Harb, Pascal Poncelet, Mathieu Roche and François Trousset. 2009. Opinion Mining from Blogs. In International Journal of Computer Informa-tion Systems and Industrial Management Applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brendan J Frey</author>
<author>Delbert Dueck</author>
</authors>
<title>Clustering by passing messages between data points.&amp;quot;</title>
<date>2007</date>
<journal>Science</journal>
<volume>315</volume>
<pages>972--976</pages>
<contexts>
<context position="32184" citStr="Frey and Dueck, 2007" startWordPosition="5355" endWordPosition="5358">. By using HS+Rule to extract candidates, our label propagation algorithm gets the highest F-measure in both evaluation metrics. 5.7 Performance on Pseudo Topics by Message Clustering In our collective extraction algorithm, topics are directly identified by hashtags. For messages without hashtags, we can first employ clustering algorithms to obtain pseudo topics (clusters) and then exploiting the topic-oriented algorithm for collective opinion target extraction. To test the performance of the proposed method in such circumstance, we use the popular clustering algorithm - Affinity Propagation (Frey and Dueck, 2007) to generate topics. The experimental results are shown in Table 5. APCluster means that the messages are clustered after removing all the hashtags. APCluster+HS means that all the hashtags are retained as normal texts for calculating message similarity. Therefore, the clustering performance can be largely improved. The standard cosine similarity is used to measure the distance between microblog messages for Affinity Propagation in the above two methods. The last method denoted as GoldCluster directly uses hashtags to identify the gold-standard topics which shows the upper bound of the perform</context>
</contexts>
<marker>Frey, Dueck, 2007</marker>
<rawString>Brendan J. Frey and Delbert Dueck. 2007. &amp;quot;Clustering by passing messages between data points.&amp;quot; Science 315.5814 (2007): 972-976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision. CS224N Project Report,</title>
<date>2009</date>
<pages>1--12</pages>
<location>Stanford</location>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani and Lei Huang. 2009. Twitter sentiment classification using distant supervision. CS224N Project Report, Stanford (2009): 1-12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>168--177</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="23766" citStr="Hu and Liu, 2004" startWordPosition="3972" endWordPosition="3975">sult of all the sixteen teams is also included and is denoted as Team-Avg. We will briefly introduce the best team’s method. The most important component of their model is a topic-dependent opinion target lexicon which is called object sheet. If a word or phrase in the object sheet appears in a sentence or a hashtag, it is extracted as opinion target. The object sheet is manually built for each topic, which means their method cannot be applied to new topics. The following models are also used for comparison. AssocMi: We implement the unsupervised method for opinion target extraction based on (Hu and Liu, 2004), which relies on association mining and a sentiment lexicon to extract frequent and infrequent product features. CRF: The CRF-based method used in (Jakob and Gurevych, 2010) is also used for comparison. We implement both the single-domain and crossdomain models. Both models are evaluated using 5-fold cross-validation. More specifically, the single-domain model, denoted as CRF-S, trains different models for different topics. In each crossvalidation round, 80 percent of each topic is used for training and the other 20 percent is used for test. The cross-domain model, denoted as CRF-C, uses 16 t</context>
<context position="34383" citStr="Hu and Liu, 2004" startWordPosition="5689" endWordPosition="5692">at our proposed unsupervised label propagation algorithm works well in pseudo topics and the performance can be increased with better clustering results. Therefore, we can try to incorporate other social network information to improve the message clustering performance, which will be studied in our future work. 6 Related Work Sentiment analysis, a.k.a. opinion mining, is the field of studying and analyzing people’s opinions, sentiments, evaluations, appraisals, attitudes, and emotions (Liu, 2012). Most of the previous sentiment analysis researches focus on customer reviews (Pang et al., 2002; Hu and Liu, 2004) and some of them focus on news (Kim and Hovy, 2006) and blogs (Draya et al., 2009). However, sentiment analysis on microblogs has recently attracted much attention and has been proved to be very useful in many applications. Classification of opinion polarity is the most common task studied in microblogs. Go et.al (2009) follow the supervised machine learning approach of Pang et al. (2002) to classify the polarity of each tweet by distant supervision. The training dataset of their method is not manually labeled but automatically collected using the emoticons. Barbosa and Feng (2010) use the si</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. Mining and summarizing customer reviews. 2004. In Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining, pp. 168-177. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
<author>Tiejun Zhao</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<volume>1</volume>
<pages>151--160</pages>
<marker>Yu, Zhou, Liu, Zhao, 2011</marker>
<rawString>Long Jiang , Mo Yu, Ming Zhou, Xiaohua Liu and Tiejun Zhao. 2011. Target-dependent twitter sentiment classification. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, vol. 1, pp. 151-160.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting opinion targets in a single-and cross-domain setting with conditional random fields.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2876" citStr="Jakob and Gurevych, 2010" startWordPosition="439" endWordPosition="442"> often insufficient for applications because it does not identify the opinion targets. In this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound quality” is the opinion target. This task is mostly studied in customer review texts in which opinion targets are often referred as features or aspects (Liu, 2012). Most of the opinion target extraction approaches rely on dependency parsing (Zhuang et al., 2006; Jakob and Gurevych, 2010; Qiu et al., 2011) and are regarded as a domain-dependent task (Li et al., 2012a). However, such approaches are not suitable for microblogs because the natural language processing tools perform poorly on microblog texts due to their inherent characteristics. Studies show that one of the state-of-the-art partof-speech taggers - OpenNLP only achieves the accuracy of 74% on tweets (Liu et al. 2011). The syntactic analysis tool that generates dependency relation may perform even worse. Besides, microblog messages may express opinion in different ways and do not always contain opinion words, which</context>
<context position="23940" citStr="Jakob and Gurevych, 2010" startWordPosition="3998" endWordPosition="4001">el is a topic-dependent opinion target lexicon which is called object sheet. If a word or phrase in the object sheet appears in a sentence or a hashtag, it is extracted as opinion target. The object sheet is manually built for each topic, which means their method cannot be applied to new topics. The following models are also used for comparison. AssocMi: We implement the unsupervised method for opinion target extraction based on (Hu and Liu, 2004), which relies on association mining and a sentiment lexicon to extract frequent and infrequent product features. CRF: The CRF-based method used in (Jakob and Gurevych, 2010) is also used for comparison. We implement both the single-domain and crossdomain models. Both models are evaluated using 5-fold cross-validation. More specifically, the single-domain model, denoted as CRF-S, trains different models for different topics. In each crossvalidation round, 80 percent of each topic is used for training and the other 20 percent is used for test. The cross-domain model, denoted as CRF-C, uses 16 topics for training and the rest 4 topics for test in each round. 5.4 Comparison Results CMSAE requires all the teams to perform the subjectivity and polarity classification t</context>
<context position="35681" citStr="Jakob and Gurevych (2010)" startWordPosition="5896" endWordPosition="5899">vide Twitter sentiment analysis services. Speriosu et al. (2009) explore the possibility of exploiting the Twitter follower graph to improve polarity classification. Opinion target extraction is a fine-grained word-level task of sentiment analysis. Currently, this task has not been well studied in microblogs yet. It is mostly performed on product reviews where opinion targets are always described as product features or aspects. The pioneering research on this task is conducted by Hu and Liu 1848 (2004) who propose a method which extracts frequent nouns and noun phrases as the opinion targets. Jakob and Gurevych (2010) model the problem as a sequence labeling task based on Conditional Random Fields (CRF). Qiu et al. (2011) propose a double propagation method to extract opinion word and opinion target simultaneously. Liu et al. (2012) use the word translation model in a monolingual scenario to mine the associations between opinion targets and opinion words. 7 Conclusion and Future Work In this paper, we study the problem of opinion target extraction in Chinese microblogs which has not been well investigated yet. We propose an unsupervised label propagation algorithm to collectively rank the opinion target ca</context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. Extracting opinion targets in a single-and cross-domain setting with conditional random fields. 2010. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Syntactic and semantic structure for opinion expression detection.</title>
<date>2010</date>
<booktitle>Proceedings of the Fourteenth Conference on Computational Natural Language Learning. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="22105" citStr="Johansson and Moschitti, 2010" startWordPosition="3673" endWordPosition="3676">es. 5.2 Evaluation Metric Precision, recall and F-measure are used in the evaluation. Since expression boundaries are hard to define exactly in annotation guidelines (Wiebe et al., 2005), both the strict evaluation metric and the soft evaluation metric are used in CMSAE. Strict Evaluation: For a proposed opinion target, it is regarded as correct only if it covers the same span with the annotation result. Note that, in CMSAE, an opinion target should be proposed along with its polarity. The correctness of the polarity is also necessary. Soft Evaluation: The soft evaluation metric presented in (Johansson and Moschitti, 2010) is adopted by CMSAE. The span coverage c between each pair of the proposed target span s and the gold standard span s’ is calculated as follows, s S s S     (12) In Equation 12, the operator |· |counts Chinese characters, and the intersection ∩ gives the set of characters that two spans have in common. Using the span coverage, the span set coverage C of a set of spans S with respect to another set S’ is C(S,S&apos;)=EEc(s,$) (13) The soft precision P and recall R of a proposed set of spans with respect to a gold standard set S is defined as follows: Precision  C(S, S) Recall  C(S, S) (14) |S</context>
</contexts>
<marker>Johansson, Moschitti, 2010</marker>
<rawString>Richard Johansson and Alessandro Moschitti. 2010. Syntactic and semantic structure for opinion expression detection. Proceedings of the Fourteenth Conference on Computational Natural Language Learning. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Extracting Opinions, Opinion Holders and Topics Expressed in Online News Media Text.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACL Workshop on Sentiment and Subjectivity in Text,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="34435" citStr="Kim and Hovy, 2006" startWordPosition="5700" endWordPosition="5703">orithm works well in pseudo topics and the performance can be increased with better clustering results. Therefore, we can try to incorporate other social network information to improve the message clustering performance, which will be studied in our future work. 6 Related Work Sentiment analysis, a.k.a. opinion mining, is the field of studying and analyzing people’s opinions, sentiments, evaluations, appraisals, attitudes, and emotions (Liu, 2012). Most of the previous sentiment analysis researches focus on customer reviews (Pang et al., 2002; Hu and Liu, 2004) and some of them focus on news (Kim and Hovy, 2006) and blogs (Draya et al., 2009). However, sentiment analysis on microblogs has recently attracted much attention and has been proved to be very useful in many applications. Classification of opinion polarity is the most common task studied in microblogs. Go et.al (2009) follow the supervised machine learning approach of Pang et al. (2002) to classify the polarity of each tweet by distant supervision. The training dataset of their method is not manually labeled but automatically collected using the emoticons. Barbosa and Feng (2010) use the similar pseudo training data collected from three onli</context>
</contexts>
<marker>Kim, Hovy, 2006</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2006. Extracting Opinions, Opinion Holders and Topics Expressed in Online News Media Text. In Proceedings of the ACL Workshop on Sentiment and Subjectivity in Text, 2006, pp. 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Sinno Jialin Pan</author>
<author>Ou Jin</author>
</authors>
<title>Qiang Yang and Xiaoyan Zhu. 2012a. Cross-Domain Co-Extraction of Sentiment and Topic Lexicons.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>410--419</pages>
<location>Jeju, Republic of</location>
<contexts>
<context position="2956" citStr="Li et al., 2012" startWordPosition="454" endWordPosition="457"> this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound quality” is the opinion target. This task is mostly studied in customer review texts in which opinion targets are often referred as features or aspects (Liu, 2012). Most of the opinion target extraction approaches rely on dependency parsing (Zhuang et al., 2006; Jakob and Gurevych, 2010; Qiu et al., 2011) and are regarded as a domain-dependent task (Li et al., 2012a). However, such approaches are not suitable for microblogs because the natural language processing tools perform poorly on microblog texts due to their inherent characteristics. Studies show that one of the state-of-the-art partof-speech taggers - OpenNLP only achieves the accuracy of 74% on tweets (Liu et al. 2011). The syntactic analysis tool that generates dependency relation may perform even worse. Besides, microblog messages may express opinion in different ways and do not always contain opinion words, which lowers the performance of methods utilizing opinion words to find opinion targe</context>
<context position="12827" citStr="Li et al., 2012" startWordPosition="2046" endWordPosition="2049"> idea for our hashtag segmentation algorithm is to regard strings that appear frequently in a topic as words. Formally, given a hashtag h that contains n Chinese characters c1c2...cn. We want to segment into several words w1w2...wm, where each word is formed by one of more characters. Firstly, we define the stickiness score for a Chinese string c1c2...cn based on the Symmetrical Conditional Probability (SCP) (Silva and Lopes, 1999): 1842 ]MC,C2 ... C.) (1) and SCP(c1) = Pr(c1)2 for string with only one character. Pr(c1c2...cn) is the occurrence frequency of the string in the topic. Following (Li et al., 2012b), we smooth the SCP value by taking logarithm calculation. Besides, the length of the string is taken into consideration, SCP (c,c2...cn) = n x log SCP(c,c2...cn) (2) where n is the number of characters in the string. Then the stickiness score is defined by the sigmoid function as follows: For the hashtag h = c1c2...cn, we want to segment it into m words w1w2...wm which maximize the following equation, The optimization of Equation (4) can be solved efficiently by dynamic programming which iteratively segments a string into two substrings. Different from (Li et al., 2012b) which calculates th</context>
</contexts>
<marker>Li, Pan, Jin, 2012</marker>
<rawString>Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang and Xiaoyan Zhu. 2012a. Cross-Domain Co-Extraction of Sentiment and Topic Lexicons. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 410–419, Jeju, Republic of Korea, 8-14 July 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenliang Li</author>
<author>Jianshu Weng</author>
<author>Qi He</author>
<author>Yuxia Yao</author>
<author>Anwitaman Datta</author>
<author>Aixin Sun</author>
<author>Bu-Sung Lee</author>
</authors>
<title>Twiner: Named entity recognition in targeted twitter stream.</title>
<date>2012</date>
<booktitle>In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval,</booktitle>
<pages>721--730</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2956" citStr="Li et al., 2012" startWordPosition="454" endWordPosition="457"> this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound quality” is the opinion target. This task is mostly studied in customer review texts in which opinion targets are often referred as features or aspects (Liu, 2012). Most of the opinion target extraction approaches rely on dependency parsing (Zhuang et al., 2006; Jakob and Gurevych, 2010; Qiu et al., 2011) and are regarded as a domain-dependent task (Li et al., 2012a). However, such approaches are not suitable for microblogs because the natural language processing tools perform poorly on microblog texts due to their inherent characteristics. Studies show that one of the state-of-the-art partof-speech taggers - OpenNLP only achieves the accuracy of 74% on tweets (Liu et al. 2011). The syntactic analysis tool that generates dependency relation may perform even worse. Besides, microblog messages may express opinion in different ways and do not always contain opinion words, which lowers the performance of methods utilizing opinion words to find opinion targe</context>
<context position="12827" citStr="Li et al., 2012" startWordPosition="2046" endWordPosition="2049"> idea for our hashtag segmentation algorithm is to regard strings that appear frequently in a topic as words. Formally, given a hashtag h that contains n Chinese characters c1c2...cn. We want to segment into several words w1w2...wm, where each word is formed by one of more characters. Firstly, we define the stickiness score for a Chinese string c1c2...cn based on the Symmetrical Conditional Probability (SCP) (Silva and Lopes, 1999): 1842 ]MC,C2 ... C.) (1) and SCP(c1) = Pr(c1)2 for string with only one character. Pr(c1c2...cn) is the occurrence frequency of the string in the topic. Following (Li et al., 2012b), we smooth the SCP value by taking logarithm calculation. Besides, the length of the string is taken into consideration, SCP (c,c2...cn) = n x log SCP(c,c2...cn) (2) where n is the number of characters in the string. Then the stickiness score is defined by the sigmoid function as follows: For the hashtag h = c1c2...cn, we want to segment it into m words w1w2...wm which maximize the following equation, The optimization of Equation (4) can be solved efficiently by dynamic programming which iteratively segments a string into two substrings. Different from (Li et al., 2012b) which calculates th</context>
</contexts>
<marker>Li, Weng, He, Yao, Datta, Sun, Lee, 2012</marker>
<rawString>Chenliang Li, Jianshu Weng, Qi He, Yuxia Yao, Anwitaman Datta, Aixin Sun and Bu-Sung Lee. 2012b. Twiner: Named entity recognition in targeted twitter stream. In Proceedings of the 35th international ACM SIGIR conference on Research and development in information retrieval, pp. 721-730. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Kuan Li</author>
<author>Ming Zhou</author>
<author>Zhongyang Xiong</author>
</authors>
<title>Collective semantic role labeling for tweets with clustering.</title>
<date>2011</date>
<booktitle>In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three,</booktitle>
<pages>1832--1837</pages>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="3275" citStr="Liu et al. 2011" startWordPosition="503" endWordPosition="506">r review texts in which opinion targets are often referred as features or aspects (Liu, 2012). Most of the opinion target extraction approaches rely on dependency parsing (Zhuang et al., 2006; Jakob and Gurevych, 2010; Qiu et al., 2011) and are regarded as a domain-dependent task (Li et al., 2012a). However, such approaches are not suitable for microblogs because the natural language processing tools perform poorly on microblog texts due to their inherent characteristics. Studies show that one of the state-of-the-art partof-speech taggers - OpenNLP only achieves the accuracy of 74% on tweets (Liu et al. 2011). The syntactic analysis tool that generates dependency relation may perform even worse. Besides, microblog messages may express opinion in different ways and do not always contain opinion words, which lowers the performance of methods utilizing opinion words to find opinion targets. In this study, we propose an unsupervised method to collectively extract the opinion targets from opinionated sentences in the same topic. 1840 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1840–1850, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association f</context>
</contexts>
<marker>Liu, Li, Zhou, Xiong, 2011</marker>
<rawString>Xiaohua Liu, Kuan Li, Ming Zhou and Zhongyang Xiong. 2011. Collective semantic role labeling for tweets with clustering. In Proceedings of the Twenty-Second international joint conference on Artificial Intelligence-Volume Volume Three, pp. 1832-1837. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies</journal>
<volume>5</volume>
<pages>1--167</pages>
<contexts>
<context position="2752" citStr="Liu, 2012" startWordPosition="422" endWordPosition="423">n stock market prediction (Bollen et al., 2011). However, classifying microblog texts at the sentence level is often insufficient for applications because it does not identify the opinion targets. In this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound quality” is the opinion target. This task is mostly studied in customer review texts in which opinion targets are often referred as features or aspects (Liu, 2012). Most of the opinion target extraction approaches rely on dependency parsing (Zhuang et al., 2006; Jakob and Gurevych, 2010; Qiu et al., 2011) and are regarded as a domain-dependent task (Li et al., 2012a). However, such approaches are not suitable for microblogs because the natural language processing tools perform poorly on microblog texts due to their inherent characteristics. Studies show that one of the state-of-the-art partof-speech taggers - OpenNLP only achieves the accuracy of 74% on tweets (Liu et al. 2011). The syntactic analysis tool that generates dependency relation may perform </context>
<context position="34267" citStr="Liu, 2012" startWordPosition="5670" endWordPosition="5671">and opinion target extraction It outperforms all the baseline methods in Table 3. The above results reveal that our proposed unsupervised label propagation algorithm works well in pseudo topics and the performance can be increased with better clustering results. Therefore, we can try to incorporate other social network information to improve the message clustering performance, which will be studied in our future work. 6 Related Work Sentiment analysis, a.k.a. opinion mining, is the field of studying and analyzing people’s opinions, sentiments, evaluations, appraisals, attitudes, and emotions (Liu, 2012). Most of the previous sentiment analysis researches focus on customer reviews (Pang et al., 2002; Hu and Liu, 2004) and some of them focus on news (Kim and Hovy, 2006) and blogs (Draya et al., 2009). However, sentiment analysis on microblogs has recently attracted much attention and has been proved to be very useful in many applications. Classification of opinion polarity is the most common task studied in microblogs. Go et.al (2009) follow the supervised machine learning approach of Pang et al. (2002) to classify the polarity of each tweet by distant supervision. The training dataset of thei</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies 5.1 (2012): 1-167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kang Liu</author>
<author>Liheng Xu</author>
<author>Jun Zhao</author>
</authors>
<title>Opinion Target Extraction Using Word-Based Translation Model.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="35900" citStr="Liu et al. (2012)" startWordPosition="5932" endWordPosition="5935">f sentiment analysis. Currently, this task has not been well studied in microblogs yet. It is mostly performed on product reviews where opinion targets are always described as product features or aspects. The pioneering research on this task is conducted by Hu and Liu 1848 (2004) who propose a method which extracts frequent nouns and noun phrases as the opinion targets. Jakob and Gurevych (2010) model the problem as a sequence labeling task based on Conditional Random Fields (CRF). Qiu et al. (2011) propose a double propagation method to extract opinion word and opinion target simultaneously. Liu et al. (2012) use the word translation model in a monolingual scenario to mine the associations between opinion targets and opinion words. 7 Conclusion and Future Work In this paper, we study the problem of opinion target extraction in Chinese microblogs which has not been well investigated yet. We propose an unsupervised label propagation algorithm to collectively rank the opinion target candidates of all sentences in a topic. We also propose a dynamic programming based algorithm for segmenting Chinese hashtags. Experimental results show the effectiveness of our method. In future work, we will try to coll</context>
</contexts>
<marker>Liu, Xu, Zhao, 2012</marker>
<rawString>Kang Liu, Liheng Xu and Jun Zhao. 2012. Opinion Target Extraction Using Word-Based Translation Model. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10,</booktitle>
<pages>79--86</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="34364" citStr="Pang et al., 2002" startWordPosition="5685" endWordPosition="5688">e results reveal that our proposed unsupervised label propagation algorithm works well in pseudo topics and the performance can be increased with better clustering results. Therefore, we can try to incorporate other social network information to improve the message clustering performance, which will be studied in our future work. 6 Related Work Sentiment analysis, a.k.a. opinion mining, is the field of studying and analyzing people’s opinions, sentiments, evaluations, appraisals, attitudes, and emotions (Liu, 2012). Most of the previous sentiment analysis researches focus on customer reviews (Pang et al., 2002; Hu and Liu, 2004) and some of them focus on news (Kim and Hovy, 2006) and blogs (Draya et al., 2009). However, sentiment analysis on microblogs has recently attracted much attention and has been proved to be very useful in many applications. Classification of opinion polarity is the most common task studied in microblogs. Go et.al (2009) follow the supervised machine learning approach of Pang et al. (2002) to classify the polarity of each tweet by distant supervision. The training dataset of their method is not manually labeled but automatically collected using the emoticons. Barbosa and Fen</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing-Volume 10, pp. 79-86. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>433--440</pages>
<contexts>
<context position="30016" citStr="Petrov et al., 2006" startWordPosition="5012" endWordPosition="5015">6 Analysis of Candidate Extraction Candidate extraction is an important step in our proposed method. If the correct opinion target is not extracted as a candidate, the ranking step will be in vain. As described in Section 3, we develop a hashtag segmentation algorithm and use a rule based method to extract noun phrases from each sentence. We do not use any parsing tool because we believe the performance of these tools is not good enough when applied on microblogs. A quantitative comparison is shown in this section. We use one of the state-of-the-art syntactic analysis tools - Berkeley Parser (Petrov et al., 2006) for comparison here. Noun phrases are directly extracted from the parsing results. Our method HS+Rule leverages the hashtag segments to enhance the segmentation result and extracts explicit candidate using a regular expression. To demonstrate the effectiveness of our hashtag segmentation algorithm, the second comparison baseline Rule directly uses ICTCLAS to segment the whole topic content and labels each word with its part-of-speech tag. The explicit candidates are extracted by using the same regular expression. The performance on candidate extraction is compared in Table 4. The second colum</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux and Dan Klein. Learning accurate, compact, and interpretable tree annotation. 2006. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pp. 433-440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion word expansion and target extraction through double propagation.</title>
<date>2011</date>
<journal>Computational linguistics</journal>
<volume>37</volume>
<pages>9--27</pages>
<contexts>
<context position="2895" citStr="Qiu et al., 2011" startWordPosition="443" endWordPosition="446">plications because it does not identify the opinion targets. In this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound quality” is the opinion target. This task is mostly studied in customer review texts in which opinion targets are often referred as features or aspects (Liu, 2012). Most of the opinion target extraction approaches rely on dependency parsing (Zhuang et al., 2006; Jakob and Gurevych, 2010; Qiu et al., 2011) and are regarded as a domain-dependent task (Li et al., 2012a). However, such approaches are not suitable for microblogs because the natural language processing tools perform poorly on microblog texts due to their inherent characteristics. Studies show that one of the state-of-the-art partof-speech taggers - OpenNLP only achieves the accuracy of 74% on tweets (Liu et al. 2011). The syntactic analysis tool that generates dependency relation may perform even worse. Besides, microblog messages may express opinion in different ways and do not always contain opinion words, which lowers the perform</context>
<context position="35787" citStr="Qiu et al. (2011)" startWordPosition="5914" endWordPosition="5917"> follower graph to improve polarity classification. Opinion target extraction is a fine-grained word-level task of sentiment analysis. Currently, this task has not been well studied in microblogs yet. It is mostly performed on product reviews where opinion targets are always described as product features or aspects. The pioneering research on this task is conducted by Hu and Liu 1848 (2004) who propose a method which extracts frequent nouns and noun phrases as the opinion targets. Jakob and Gurevych (2010) model the problem as a sequence labeling task based on Conditional Random Fields (CRF). Qiu et al. (2011) propose a double propagation method to extract opinion word and opinion target simultaneously. Liu et al. (2012) use the word translation model in a monolingual scenario to mine the associations between opinion targets and opinion words. 7 Conclusion and Future Work In this paper, we study the problem of opinion target extraction in Chinese microblogs which has not been well investigated yet. We propose an unsupervised label propagation algorithm to collectively rank the opinion target candidates of all sentences in a topic. We also propose a dynamic programming based algorithm for segmenting</context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu and Chun Chen. 2011. Opinion word expansion and target extraction through double propagation. Computational linguistics 37, no. 1 (2011): 9-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>A Wong</author>
<author>C S Yang</author>
</authors>
<title>A Vector Space Model for Automatic Indexing,</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<pages>613--620</pages>
<contexts>
<context position="17737" citStr="Salton et al., 1975" startWordPosition="2878" endWordPosition="2881">e candidate (label) similarity are considered during propagation. Finally, we select the candidate with the highest score in the label vector as the opinion target for each sentence. The details of Algorithm 1 are presented as follows. Formally, an undirected graphG=&lt;V,E,W&gt; is built for each topic. A node vV represents a sentence in the topic and an edge e = (a, b) E indicates that the labels of the two vertices should be similar. is the normalized weight matrix to reflect the strength of this similarity. The similarity between two nodes Wab is simply calculated by using the cosine measure (Salton et al., 1975) of the two sentences. T T where Ta and Tb are the term vectors of sentences a and b represented by the standard vector space model and weighted by term frequency. After calculating the similarity matrix W, we get the weight matrix by normalizing each row of W such that (Y)k 1&lt;_k&lt;_M � (8) . For each sentence (node) v, a candidate set Cv is extracted in the previous step. The candidate set CT for the whole topic is the union of all Cv, (6) The total number of candidates in the topic is denoted by M = |CT|. We calculate the candidate similarity matrix based on Jaccard Index: (7) where A(CTi) and</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>G. Salton, A. Wong and C. S. Yang. 1975. A Vector Space Model for Automatic Indexing, Communications of the ACM, vol. 18, nr. 11, pages 613–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F da Silva</author>
<author>G P Lopes</author>
</authors>
<title>A local maxima method and a fair dispersion normalization for extracting multi-word units from corpora.</title>
<date>1999</date>
<booktitle>In Proc. of the 6th Meeting on Mathematics of Language .</booktitle>
<contexts>
<context position="12647" citStr="Silva and Lopes, 1999" startWordPosition="2015" endWordPosition="2018">the hashtag correctly into “90 , Fri /TT/�KA”, we can add the hashtag segments to the user dictionary of the segmentation tool to further segment the message texts of the topic. The basic idea for our hashtag segmentation algorithm is to regard strings that appear frequently in a topic as words. Formally, given a hashtag h that contains n Chinese characters c1c2...cn. We want to segment into several words w1w2...wm, where each word is formed by one of more characters. Firstly, we define the stickiness score for a Chinese string c1c2...cn based on the Symmetrical Conditional Probability (SCP) (Silva and Lopes, 1999): 1842 ]MC,C2 ... C.) (1) and SCP(c1) = Pr(c1)2 for string with only one character. Pr(c1c2...cn) is the occurrence frequency of the string in the topic. Following (Li et al., 2012b), we smooth the SCP value by taking logarithm calculation. Besides, the length of the string is taken into consideration, SCP (c,c2...cn) = n x log SCP(c,c2...cn) (2) where n is the number of characters in the string. Then the stickiness score is defined by the sigmoid function as follows: For the hashtag h = c1c2...cn, we want to segment it into m words w1w2...wm which maximize the following equation, The optimiza</context>
</contexts>
<marker>Silva, Lopes, 1999</marker>
<rawString>J. F. da Silva and G. P. Lopes. 1999. A local maxima method and a fair dispersion normalization for extracting multi-word units from corpora. In Proc. of the 6th Meeting on Mathematics of Language .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Speriosu</author>
<author>Nikita Sudan</author>
<author>Sid Upadhyay</author>
<author>Jason Baldridge</author>
</authors>
<title>Twitter polarity classification with label propagation over lexical links and the follower graph.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Unsupervised Learning in NLP,</booktitle>
<pages>53--63</pages>
<contexts>
<context position="1989" citStr="Speriosu et al., 2011" startWordPosition="295" endWordPosition="298">ported that there are more than 340 million tweets per day on Twitter and more than 200 million on Sina Weibo. A tweet means a post on Twitter. Since we mainly focus on Chinese microblogs instead of Twitter in this paper, we will refer to a post as a message. Each message is limited to 140 Chinese characters and usually contains several sentences. * Xiaojun Wan is the corresponding author. 1 https://twitter.com 2 http://weibo.com/ 3 http://t.qq.com/ Currently, researches on microblog sentiment analysis have been conducted on polarity classification (Barbosa and Feng, 2010; Jiang el al., 2011; Speriosu et al., 2011) and have been proved to be useful in many applications, such as opinion polling (Tang et al., 2012), election prediction (Tumasjan et al., 2010) and even stock market prediction (Bollen et al., 2011). However, classifying microblog texts at the sentence level is often insufficient for applications because it does not identify the opinion targets. In this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound </context>
</contexts>
<marker>Speriosu, Sudan, Upadhyay, Baldridge, 2011</marker>
<rawString>Michael Speriosu, Nikita Sudan, Sid Upadhyay and Jason Baldridge. 2011. Twitter polarity classification with label propagation over lexical links and the follower graph. In Proceedings of the First Workshop on Unsupervised Learning in NLP, pp. 53-63. Association for Computational Linguistics, 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Partha Talukdar</author>
<author>Koby Crammer</author>
</authors>
<title>New regularized algorithms for transductive learning.</title>
<date>2009</date>
<booktitle>Machine Learning and Knowledge Discovery in Databases</booktitle>
<pages>442--457</pages>
<contexts>
<context position="16290" citStr="Talukdar and Crammer, 2009" startWordPosition="2633" endWordPosition="2636">&amp;quot;M 1: for all ve V do 2: Y &lt;— Y 3: end for 4: repeat 5: for all ve V do 6: D E Wuv (Y X S)X 1 ue V,umv 7: ˆYv  pinyYv  pcontDv 8: end for 9: until convergence 1843 the statistical result of our dataset that over 93% sentences have only one opinion target and each sentence has an average of 1.09 targets. Therefore, the most confident candidate of each sentence will be selected as the opinion target. In this section, we introduce an unsupervised graph-based label propagation algorithm to collectively rank the candidates of all sentences in a topic. Label propagation (Zhu and Ghahramani, 2002; Talukdar and Crammer, 2009) is a semisupervised algorithm which spreads label distributions from a small set of nodes seeded with some initial label information throughout the graph. The basic idea is to use information from the labeled nodes to label the adjacent nodes in the graph. However, our idea is to use the connection between different nodes to find the correct labels for all of them. Our unsupervised label propagation algorithm is summarized in Algorithm 1. Sentences are regarded as nodes and candidates of each sentence are regarded as labels. The label vector for each node is initialized based on the results o</context>
</contexts>
<marker>Talukdar, Crammer, 2009</marker>
<rawString>Partha Talukdar and Koby Crammer. New regularized algorithms for transductive learning. 2009. Machine Learning and Knowledge Discovery in Databases (2009): 442-457.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jie Tang</author>
<author>Yuan Zhang</author>
<author>Jimeng Sun</author>
<author>Jinhai Rao</author>
<author>Wenjing Yu</author>
<author>Yiran Chen</author>
<author>A C M Fong</author>
</authors>
<title>Quantitative study of individual emotional states in social networks.</title>
<date>2012</date>
<journal>Affective Computing, IEEE Transactions on</journal>
<volume>3</volume>
<pages>132--144</pages>
<contexts>
<context position="2089" citStr="Tang et al., 2012" startWordPosition="314" endWordPosition="317">Weibo. A tweet means a post on Twitter. Since we mainly focus on Chinese microblogs instead of Twitter in this paper, we will refer to a post as a message. Each message is limited to 140 Chinese characters and usually contains several sentences. * Xiaojun Wan is the corresponding author. 1 https://twitter.com 2 http://weibo.com/ 3 http://t.qq.com/ Currently, researches on microblog sentiment analysis have been conducted on polarity classification (Barbosa and Feng, 2010; Jiang el al., 2011; Speriosu et al., 2011) and have been proved to be useful in many applications, such as opinion polling (Tang et al., 2012), election prediction (Tumasjan et al., 2010) and even stock market prediction (Bollen et al., 2011). However, classifying microblog texts at the sentence level is often insufficient for applications because it does not identify the opinion targets. In this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound quality” is the opinion target. This task is mostly studied in customer review texts in which opinio</context>
</contexts>
<marker>Tang, Zhang, Sun, Rao, Yu, Chen, Fong, 2012</marker>
<rawString>Jie Tang, Yuan Zhang, Jimeng Sun, Jinhai Rao, Wenjing Yu, Yiran Chen and A. C. M. Fong. 2012. Quantitative study of individual emotional states in social networks. Affective Computing, IEEE Transactions on 3, no. 2 (2012): 132-144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andranik Tumasjan</author>
<author>Timm O Sprenger</author>
<author>Philipp G Sandner</author>
<author>Isabell M Welpe</author>
</authors>
<title>Predicting elections with twitter: What 140 characters reveal about political sentiment.</title>
<date>2010</date>
<booktitle>In Proceedings of the fourth international aaai conference on weblogs and social media,</booktitle>
<pages>178--185</pages>
<contexts>
<context position="2134" citStr="Tumasjan et al., 2010" startWordPosition="320" endWordPosition="323">ince we mainly focus on Chinese microblogs instead of Twitter in this paper, we will refer to a post as a message. Each message is limited to 140 Chinese characters and usually contains several sentences. * Xiaojun Wan is the corresponding author. 1 https://twitter.com 2 http://weibo.com/ 3 http://t.qq.com/ Currently, researches on microblog sentiment analysis have been conducted on polarity classification (Barbosa and Feng, 2010; Jiang el al., 2011; Speriosu et al., 2011) and have been proved to be useful in many applications, such as opinion polling (Tang et al., 2012), election prediction (Tumasjan et al., 2010) and even stock market prediction (Bollen et al., 2011). However, classifying microblog texts at the sentence level is often insufficient for applications because it does not identify the opinion targets. In this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound quality” is the opinion target. This task is mostly studied in customer review texts in which opinion targets are often referred as features or a</context>
</contexts>
<marker>Tumasjan, Sprenger, Sandner, Welpe, 2010</marker>
<rawString>Andranik Tumasjan, Timm O. Sprenger, Philipp G. Sandner and Isabell M. Welpe. 2010. Predicting elections with twitter: What 140 characters reveal about political sentiment. In Proceedings of the fourth international aaai conference on weblogs and social media, pp. 178-185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
</authors>
<title>Learning from labeled and unlabeled data with label propagation.</title>
<date>2002</date>
<tech>Technical report, CMU CALD tech report.</tech>
<contexts>
<context position="5271" citStr="Zhu and Ghahramani, 2002" startWordPosition="801" endWordPosition="804">inion target. Our contributions in this study are summarized as follows: 1) our method considers not only the explicit opinion targets within the sentence but also the implicit opinion targets in the hashtag or mentioned in the previous sentence. 2) We develop an efficient algorithm to segment Chinese hashtags. It can successfully identify out-ofvocabulary words by leveraging contextual information and help to improve the segmentation performance of the messages in the topic. 3) We develop an unsupervised label propagation algorithm for collective opinion target extraction. Label propagation (Zhu and Ghahramani, 2002) aims to spread label distributions from a small training set throughout the graph. However, our unsupervised algorithm leverages the connection between two adjacent unlabeled nodes to find the correct labels for both of them. The proposed unsupervised method does not need any training corpus which will cost much human labor especially for fine-grained annotation. 4) To the best of our knowledge, the task of opinion target extraction in microblogs has not been well studied yet. It is more challenging than microblog sentiment classification and opinion target extraction in review texts. 2 Chara</context>
<context position="16261" citStr="Zhu and Ghahramani, 2002" startWordPosition="2629" endWordPosition="2632">tput: Label vector: Y e R+&amp;quot;M 1: for all ve V do 2: Y &lt;— Y 3: end for 4: repeat 5: for all ve V do 6: D E Wuv (Y X S)X 1 ue V,umv 7: ˆYv  pinyYv  pcontDv 8: end for 9: until convergence 1843 the statistical result of our dataset that over 93% sentences have only one opinion target and each sentence has an average of 1.09 targets. Therefore, the most confident candidate of each sentence will be selected as the opinion target. In this section, we introduce an unsupervised graph-based label propagation algorithm to collectively rank the candidates of all sentences in a topic. Label propagation (Zhu and Ghahramani, 2002; Talukdar and Crammer, 2009) is a semisupervised algorithm which spreads label distributions from a small set of nodes seeded with some initial label information throughout the graph. The basic idea is to use information from the labeled nodes to label the adjacent nodes in the graph. However, our idea is to use the connection between different nodes to find the correct labels for all of them. Our unsupervised label propagation algorithm is summarized in Algorithm 1. Sentences are regarded as nodes and candidates of each sentence are regarded as labels. The label vector for each node is initi</context>
</contexts>
<marker>Zhu, Ghahramani, 2002</marker>
<rawString>X. Zhu and Z. Ghahramani. 2002. Learning from labeled and unlabeled data with label propagation. Technical report, CMU CALD tech report.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhuang</author>
<author>Feng Jing</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the ACM 15th Conference on Information and Knowledge Management,</booktitle>
<pages>43--50</pages>
<location>Arlington, Virginia, USA,</location>
<contexts>
<context position="2850" citStr="Zhuang et al., 2006" startWordPosition="435" endWordPosition="438">the sentence level is often insufficient for applications because it does not identify the opinion targets. In this paper, we will study the task of opinion target extraction for Chinese microblog messages. Opinion target extraction aims to find the object to which the opinion is expressed. For example, in the sentence “The sound quality is good!”, “sound quality” is the opinion target. This task is mostly studied in customer review texts in which opinion targets are often referred as features or aspects (Liu, 2012). Most of the opinion target extraction approaches rely on dependency parsing (Zhuang et al., 2006; Jakob and Gurevych, 2010; Qiu et al., 2011) and are regarded as a domain-dependent task (Li et al., 2012a). However, such approaches are not suitable for microblogs because the natural language processing tools perform poorly on microblog texts due to their inherent characteristics. Studies show that one of the state-of-the-art partof-speech taggers - OpenNLP only achieves the accuracy of 74% on tweets (Liu et al. 2011). The syntactic analysis tool that generates dependency relation may perform even worse. Besides, microblog messages may express opinion in different ways and do not always co</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>Li Zhuang, Feng Jing and Xiaoyan Zhu. 2006. Movie review mining and summarization. In Proceedings of the ACM 15th Conference on Information and Knowledge Management, pages 43–50, Arlington, Virginia, USA, November.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>