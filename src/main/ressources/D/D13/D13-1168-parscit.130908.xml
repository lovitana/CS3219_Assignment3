<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000024">
<title confidence="0.998752">
A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data
(and Nothing Else)
</title>
<author confidence="0.996223">
Ivan Vuli´c and Marie-Francine Moens
</author>
<affiliation confidence="0.999254">
Department of Computer Science
</affiliation>
<address confidence="0.717722">
KU Leuven
Celestijnenlaan 200A
Leuven, Belgium
</address>
<email confidence="0.996609">
{ivan.vulic,marie-francine.moens}@cs.kuleuven.be
</email>
<sectionHeader confidence="0.995588" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99941505">
We present a new language pair agnostic ap-
proach to inducing bilingual vector spaces
from non-parallel data without any other re-
source in a bootstrapping fashion. The pa-
per systematically introduces and describes all
key elements of the bootstrapping procedure:
(1) starting point or seed lexicon, (2) the confi-
dence estimation and selection of new dimen-
sions of the space, and (3) convergence. We
test the quality of the induced bilingual vec-
tor spaces, and analyze the influence of the
different components of the bootstrapping ap-
proach in the task of bilingual lexicon extrac-
tion (BLE) for two language pairs. Results re-
veal that, contrary to conclusions from prior
work, the seeding of the bootstrapping pro-
cess has a heavy impact on the quality of the
learned lexicons. We also show that our ap-
proach outperforms the best performing fully
corpus-based BLE methods on these test sets.
</bodyText>
<sectionHeader confidence="0.999132" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999827069767442">
Bilingual lexicons serve as an indispensable source
of knowledge for various cross-lingual tasks such
as cross-lingual information retrieval (Lavrenko et
al., 2002; Levow et al., 2005) or statistical machine
translation (Och and Ney, 2003). Additionally, they
are a crucial component in cross-lingual knowledge
transfer, where the knowledge about utterances in
one language may be transferred to another. The
utility of the transfer or annotation projection by
means of bilingual lexicons has already been proven
in various tasks such as semantic role labeling (Pad´o
and Lapata, 2009; van der Plas et al., 2011), parsing
(Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et
al., 2013b), POS tagging (Yarowsky and Ngai, 2001;
Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc.
Techniques for automatic bilingual lexicon ex-
traction (BLE) from parallel corpora on the basis
of word alignment models are well established (Och
and Ney, 2003). However, due to a relative scarce-
ness of parallel data for many language pairs and
domains, alternative approaches that rely on compa-
rable corpora have also gained much interest (e.g.,
Fung and Yee (1998); Rapp (1999)).
The models that rely on non-parallel data typ-
ically represent each word by a high-dimensional
vector in a feature vector space, where the dimen-
sions of the vector are its context features. The con-
text features are typically words co-occurring with
the word in a predefined context.1 The similar-
ity of two words, wS1 given in the source language
LS with vocabulary V S and wT2 in the target lan-
guage LT with vocabulary VT is then computed as
sim(wS1 , wT2 ) = 5F(cv(wS1 ), cv(wT2 )). cv(wS1 ) =
[scS1 (c1), ... , scS1 (cN)] is a context vector for wS1
with N context features ck, where scS1 (ck) denotes
the score for wS1 associated with context feature ck
(similar for wT2 ). 5F is a similarity function (e.g.,
cosine, the Kullback-Leibler divergence, the Jaccard
index) operating on the context vectors (Lee, 1999).
When operating with 2 languages, the context fea-
tures cannot be compared directly. Therefore, in
order to compare the feature vectors cv(wS1 ) and
cv(wT2 ), the context features need to span a shared
</bodyText>
<footnote confidence="0.859180666666667">
1The context may be a document, a paragraph, a window of
predefined size around each occurrence of wS� in CS, etc. For
an overview, see, e.g., (Tamura et al., 2012).
</footnote>
<page confidence="0.691007">
1613
</page>
<note confidence="0.7475105">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1613–1624,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999678638888889">
bilingual vector space. The standard way of build-
ing a bilingual vector space is to use bilingual lex-
icon entries (Rapp, 1999; Fung and Cheung, 2004;
Gaussier et al., 2004) as dimensions of the space.
However, there seems to be an apparent flaw in
logic, since the methods assume that there exist
readily available bilingual lexicons that are then
used to induce bilingual lexicons! Therefore, the fo-
cus of the researchers has turned to designing BLE
methods that do not rely on any external translation
resources such as machine-readable bilingual lex-
icons and parallel corpora (Haghighi et al., 2008;
Vuli´c et al., 2011).
In order to circumvent this issue, one line of re-
cent work aims to bootstrap high-quality bilingual
vector spaces from a small initial seed lexicon. The
seed lexicon is constructed by harvesting identical
or similarly spelled words across languages (Koehn
and Knight, 2002; Peirsman and Pad´o, 2010), and it
spans the initial bilingual vector space. The space is
then gradually enriched with new dimensions/axes
during the bootstrapping procedure. The bootstrap-
ping process has already proven its validity in induc-
ing bilingual lexicons for closely similar languages
such as Spanish-Portuguese or Croatian-Slovene
(Fiˇser and Ljubeˇsi´c, 2011), but it still lacks further
generalization to more distant language pairs.
The main goal of this paper is to shed new light
on the bootstrapping approaches to bilingual lexicon
extraction, and to construct a language pair agnos-
tic bootstrapping method that is able to build high-
quality bilingual vector spaces that consequently
lead to high-quality bilingual lexicons for more dis-
tant language pairs where orthographic similarity is
not sufficient to seed bilingual vector spaces. We
aim to answer the following key questions:
</bodyText>
<listItem confidence="0.989959333333333">
• How to seed bilingual vector spaces besides us-
ing only orthographically similar words?
• Is it better to seed bilingual spaces with trans-
lation pairs/dimensions that are frequent in the
corpus, and does the frequency matter at all?
Does the size of the initial seed lexicon matter?
• How to enrich bilingual vector spaces with only
highly reliable dimensions in order to prevent
semantic drift?
</listItem>
<bodyText confidence="0.5863265">
With respect to these questions, the main contribu-
tions of this article are:
</bodyText>
<listItem confidence="0.921068125">
• We present a complete overview of the frame-
work of bootstrapping bilingual vector spaces
from non-parallel data without any additional
resources. We dissect the bootstrapping pro-
cess and describe all its key components.
• We introduce a new way of seeding the boot-
strapping procedure that does not rely on any
orthographic clues and that yields bilingual
vector spaces of higher quality. We analyze the
impact of different seed lexicons on the quality
of induced bilingual vector spaces.
• We show that in the setting without any ex-
ternal translation resources, our bootstrapping
approach yields lexicons that outperform the
best performing corpus-based BLE methods on
standard test datasets for 2 language pairs.
</listItem>
<sectionHeader confidence="0.860199" genericHeader="method">
2 Boostrapping Bilingual Vector Spaces: A
General Overview
</sectionHeader>
<bodyText confidence="0.999945333333333">
This section presents the complete bootstrapping
procedure that starts with an initial seed lexicon
which spans the initial bilingual vector space, while
as the output in each iteration of the procedure it pro-
duces an updated bilingual vector space that can be
used to extract a bilingual lexicon.
</bodyText>
<subsectionHeader confidence="0.924035">
2.1 General Framework
</subsectionHeader>
<bodyText confidence="0.99789935">
We assume that we are solely in possession of a
(non-parallel) bilingual corpus C that is composed
of a sub-corpus CS given in the source language LS,
and a sub-corpus CT in the target language LT. All
word types that occur in CS constitute a set V S. All
word types in CT constitute a set VT. The goal is to
build a bilingual vector space using only corpus C.
Assumption 1. Dimensions of the bilingual vector
space are one-to-one word translation pairs. For in-
stance, dimensions of a Spanish-English space are
pairs like (perro, dog), (ciencia, science), etc. The
one-to-one constraint (Melamed, 2000), although
not valid in general, simplifies the construction of
the bootstrapping procedure. i denotes the set of
translation pairs that are the dimensions of the space.
Computing cross-lingual word similarity in a
bilingual vector space. Now, assume that our bilin-
gual vector space consists of N one-to-one word
translation pairs ck = (cSk, cTk ), k = 1, ... , N. For
each word wSi E V S, we compute the similarity of
</bodyText>
<page confidence="0.989779">
1614
</page>
<bodyText confidence="0.9995885">
that word with each word wTj E V T by computing
the similarity between their context vectors cv(wSi )
and cv(wTj ), which are actually their representations
in the N-dimensional bilingual vector space.
The cross-lingual similarity is computed follow-
ing the standard procedure (Gaussier et al., 2004):
</bodyText>
<listItem confidence="0.998368">
(1) For each source word wSi E V S, build its N-
dimensional context vector cv(wSi ) that consists of
association scores scSk (cSk), that is, we compute the
strength of association with the “source” part of each
dimension ck that constitutes the N-dimensional
bilingual space. The association is dependent on the
co-occurrence of wSi and cSk in a predefined context.
Various functions such as the log-likelihood ratio
(LLR) (Rapp, 1999; Ismail and Manandhar, 2010),
TF-IDF (Fung and Yee, 1998), or pointwise mu-
tual information (PMI) (Bullinaria and Levy, 2007;
Shezaf and Rappoport, 2010) are typically used as
weighting functions to quantify the strength of the
association.
(2) Repeat step (1) for each target word wTj E VT
and build context vectors cv(wTj ) that consist of
scores scTk (cTk ).
(3) Since cSk and cTkaddress the same dimension
ck in the bilingual vector space for each k =
1, ... , N, we are able to compute the similarity be-
tween cv(wSi ) and cv(wTj ) using any similarity mea-
</listItem>
<bodyText confidence="0.954227925925926">
sure such as the Jaccard index, the Kullback-Leibler
or the Jensen-Shannon divergence, the cosine mea-
sure, or others (Lee, 1999; Cha, 2007).
The similarity score for two words wSi and wTj
is sim(wSi , wTj ). For each source word wSi , we can
build a ranked list RL(wSi ) that consists of all words
wTj E V T ranked according to their respective sim-
ilarity scores sim(wSi , wTj ). In the similar fashion,
we can build a ranked list RL(wTj ), for each target
word wT j . We call the top scoring target word wTj
for some source word wSi its translation candidate,
and write TC(wSi ) = wTj . Additionally, we label
the ranked list RL(wSi ) that is pruned at position M
as RLM(wSi ).
Bootstrapping. The key idea of the bootstrapping
approach relies on an insight that highly reliable
translation pairs (wS1 , wT2 ) that are encountered us-
ing the N-dimensional bilingual vector space might
be added as new dimensions of the space. By adding
these new dimensions, it might be possible to extract
more highly reliable translation pairs that were pre-
viously not used as dimensions of the space, and the
iterative procedure repeats until no new dimensions
are found. The induced bilingual vector space may
then be observed as a bilingual lexicon per se, but it
may also be used to find translation equivalents for
other words which are not used to span the space.
</bodyText>
<figure confidence="0.262722285714286">
Algorithm 1: Bootstrapping a bilingual vector space
Input : Bilingual corpus C = CS U CT
Initialize: (1) Obtain a one-to-one seed lexicon. The
entries from the lexicon are initial dimensions of the
space: Z0; (2) s = 0;
Bootstrap:
repeat
</figure>
<listItem confidence="0.946744333333333">
1: For each wSi E V S: compute RL(wSi ) using Zs ;
2: For each wTj E V T: compute RL(wj T) using Zs ;
3: For each wSi E V S and wT E V T: score each
translation pair (wSi ,�C(w�)) and (� C(wT j ), wT j )
and add them to a pool of candidate dimensions ;
4: Choose the best candidates from the pool and add
them as new dimensions: Zs+1 +-- Zs U {best} ;
5: Resolve collisions in Zs+1;
6:s+--s+1;
until no new dimensions are found (convergence) ;
Output: One-to-one translation pairs --+ Dimensions of a
bilingual vector space Zfinal
</listItem>
<bodyText confidence="0.999767">
The overview of the procedure as given by alg. 1
reveals these crucial points in the procedure: (Q1)
how to provide initial dimensions of the space? (the
initialization step), (Q2) how to score each trans-
lation pair, estimate their confidence, and how to
choose the best candidates from the pool of candi-
dates? (steps 3 and 4), and (Q3) how to resolve
potential collisions that violate the one-to-one con-
straint? (step 5). We will discuss (Q1) and (Q2) in
more detail later, while we resolve (Q3) following a
simple heuristic as follows:
Assumption 2. In case of collision, dimen-
sions/pairs that are found at later stages of the boot-
strapping process overwrite previous dimensions.
The intuition here is that we expect for the quality of
the space to increase at each stage of the bootstrap-
ping process, and newer translation pairs should be
more confident than the older ones. For instance, if 2
out of N dimensions of a Spanish-English bilingual
space are pairs (piedra,wall) and (tapia,stone), but
then if during the bootstrapping process we extract a
new candidate pair (piedra,stone), we will delete the
former two dimensions and add the latter.
</bodyText>
<page confidence="0.981916">
1615
</page>
<subsectionHeader confidence="0.99844">
2.2 Initializing Bilingual Vector Spaces
</subsectionHeader>
<bodyText confidence="0.999533393939394">
Seeding or initializing a bootstrapping procedure is
often a critical step regardless of the actual task
(McIntosh and Curran, 2009; Kozareva and Hovy,
2010), and it decides whether the complete process
will end as a success or a failure. However, Peirsman
and Pad´o (2011) argue that the initialization step is
not crucial when dealing with bootstrapping bilin-
gual vector spaces. Here, we present two different
strategies of initializing the bilingual vector space.
Identical words and cognates. Previous work re-
lies exclusively on identical and similarly spelled
words to build the initial set of dimensions io
(Koehn and Knight, 2002; Peirsman and Pad´o, 2010;
Fiˇser and Ljubeˇsi´c, 2011). This strategy yields
promising results for closely similar language pairs,
but is of limited use for other language pairs.
High-frequency seeds. Another problem with us-
ing only identical words and cognates as seeds lies in
the fact that many of them might be infrequent in the
corpus, and as a consequence the expressiveness of a
bilingual vector space might be limited. On the other
hand, high-frequency words offer a lot of evidence
in the corpus that could be exploited in the boot-
strapping approach. In order to induce initial trans-
lation pairs, we rely on the framework of multilin-
gual probabilistic topic modeling (MuPTM) (Boyd-
Graber and Blei, 2009; De Smet and Moens, 2009;
Mimno et al., 2009; Zhang et al., 2010), that does
not require a bilingual lexicon, it operates with non-
parallel data, and is able to produce highly confident
translation pairs for high-frequency words (Mimno
et al., 2009; Vuli´c and Moens, 2013).2 Therefore,
we can construct the initial seed lexicon as follows:
</bodyText>
<listItem confidence="0.99906">
(1) Train a multilingual topic model on the corpus.
(2) Obtain one-to-one translation pairs using any of
the MuPTM-based models of cross-lingual similar-
ity, e.g., (Vuli´c et al., 2011; Vuli´c and Moens, 2013).
(3) Retain only symmetric translation pairs. This
step ensures that only highly confident pairs are used
as seed translation pairs.
(4) Rank translation pairs according to their fre-
quency in the corpus and use a subset of the most
</listItem>
<footnote confidence="0.861208">
2One can also use other models that are similar to MuPTM
such as (Haghighi et al., 2008; Daum´e III and Jagarlamudi,
2011) to produce the initial seed lexicon, but that analysis is
beyond the scope of this work.
</footnote>
<bodyText confidence="0.930091">
frequent symmetric pairs as seeds.
</bodyText>
<subsectionHeader confidence="0.997649">
2.3 Estimating Confidence of New Dimensions
</subsectionHeader>
<bodyText confidence="0.999907636363636">
Another crucial step in the bootstrapping proce-
dure is the estimation of confidence in a translation
pair/candidate dimension. Errors in the early stages
of the procedure may negatively affect the learning
process and even cause semantic drift (Riloff and
Shepherd, 1999; McIntosh and Curran, 2009). We
therefore impose the constraint which requires trans-
lation pairs to be symmetric in order to qualify as po-
tential new dimensions of the space. In other words,
given the current set of dimensions is, a transla-
tion pair (ws, w�) has a possibility to be chosen as
a new dimension from the pool of candidate dimen-
sions if and only if it holds: TC(ws) =w� and
TC(w�� ) = ws. This symmetry constraint should
ensure a relative reliability of translation pairs.
In each iteration of the bootstrapping process, we
may add all symmetric pairs from the pool of candi-
dates as new dimensions, or we could impose addi-
tional selection criteria that quantify the degree of
confidence in translation pairs. We are then able
to rank the symmetric candidate translation pairs in
the pool of candidates according to their confidence
scores (step 3 of alg. 1), and choose only the best
B candidates from the pool in each iteration (step 4)
as done in (Thelen and Riloff, 2002; McIntosh and
Curran, 2009; Huang and Riloff, 2012). By picking
only a subset of the B most confident candidates in
each iteration, we hope to further prevent a possibil-
ity of semantic drift, i.e., “poisoning” the bootstrap-
ping process that might happen if we include incor-
rect translation pairs as dimensions of the space.
In this paper, we investigate 3 different confidence
estimation functions:3
</bodyText>
<listItem confidence="0.9641698">
(1) Absolute similarity score. Confidence of a
translation pair CF(ws, TC(ws)) is simply the ab-
solute similarity value sim(ws3 ,TC(ws))
(2) M-Best confidence function. It contrasts the
score of the translation candidate with the average
</listItem>
<bodyText confidence="0.67633825">
score over the first M most similar words in the
ranked list. The larger the difference, the more con-
fidence we have in the translation candidate. Given
a word ws E Vs and a ranked list RLM(ws), the
</bodyText>
<footnote confidence="0.841597">
3A symmetrized version of the confidence functions is com-
puted as the geometric mean of source-to-target and target-to-
source confidence scores.
</footnote>
<page confidence="0.985089">
1616
</page>
<bodyText confidence="0.991493">
average score of the best M words is computed as:
The final confidence score is then:
</bodyText>
<equation confidence="0.680129">
CF(wSi ,TC(wSi )) = sim(wSi ,TC(wSi )) − simM(wSi )
</equation>
<bodyText confidence="0.971863166666667">
(3) Entropy-based confidence function. We adapt
the well-known entropy-based confidence (Smith
and Eisner, 2007; Tu and Honavar, 2012) to this par-
ticular task. First, we need to define a distribution:
The confidence function is then minus the entropy
of the probability distribution p:
</bodyText>
<equation confidence="0.9304435">
CF(wSi ,TC(wSi )) = � p(wTl |wSi ) log p(wT l |wS i )
wi EVT
</equation>
<sectionHeader confidence="0.997677" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<bodyText confidence="0.986295555555556">
Data collections. We investigate our bootstrapping
approach on the BLE task for 2 language pairs:
Spanish-English (ES-EN) and Italian-English (IT-
EN), and work with the following corpora previ-
ously used by Vuli´c and Moens (2013): (i) a col-
lection of 13,696 Spanish-English Wikipedia arti-
cle pairs (Wiki-ES-EN), (ii) 18,898 Italian-English
Wikipedia article pairs (Wiki-IT-EN).4
Following (Koehn and Knight, 2002; Haghighi et
al., 2008; Prochasson and Fung, 2011; Vuli´c and
Moens, 2013), we use TreeTagger (Schmid, 1994)
for POS-tagging and lemmatization of the corpora,
and then retain only nouns that occur at least 5 times
in the corpus. We record the lemmatized form when
available, and the original form otherwise. Our fi-
nal vocabularies consist of 9,439 Spanish nouns and
4Vuli´c and Moens (2013) also worked with Dutch-English
(NL-EN), but we have decided to leave out the results obtained
for that language pair due to space constraints, high similarity
between the two languages, and the fact that the results obtained
for that language pair are qualitatively similar to the results we
report for ES-EN and IT-EN. Hence including the results for
NL-EN would not contribute to the paper with any new impor-
tant insight and conclusion.
12,945 nouns for ES-EN, and 7,160 Italian nouns
and 9,116 English nouns for IT-EN.
Ground truth. The goal of the BLE task is to ex-
tract a bilingual lexicon of one-to-one translations.
In order to test the quality of bilingual vector spaces
induced by our bootstrapping approach, we evaluate
it on standard 1000 ground truth one-to-one trans-
lation pairs built for the Wiki-ES-EN and Wiki-IT-
EN datasets (Vuli´c and Moens, 2013). Note that
we do not explicitly test the bilingual vector space
as a bilingual lexicon, but rather its ability to find
semantically similar words and translations also for
words that are not used as dimensions of the space
(see sect. 2.1).
Evaluation metrics. We measure the performance
on the BLE task using a standard Top M accuracy
(AccM) metric. It denotes the number of source
words ws from ground truth translation pairs whose
list RLM(ws ) contains the correct translation ac-
cording to our ground truth over the total number
of ground truth translation pairs (=1000) (Gaussier
et al., 2004; Tamura et al., 2012).5 Additionally,
we report the mean reciprocal rank (MRR) scores
(Voorhees, 1999) for some experimental runs.
Multilingual topic model. We utilize a straightfor-
ward multilingual extension of the standard Blei et
al.’s LDA model (Blei et al., 2003) called bilingual
LDA (Mimno et al., 2009; Ni et al., 2009; De Smet
and Moens, 2009). BiLDA training follows the pro-
cedure from (Vuli´c and Moens, 2013), that is, the
training method is Gibbs sampling with the number
of topics set to K = 2000. Hyperparameters of the
model are set to standard values (Steyvers and Grif-
fiths, 2007): α = 50/K and Q = 0.01.
Building initial seed lexicons. To produce the lists
of one-to-one translation pairs that are used as seeds
for the bootstrapping approach (see sect. 2.2), we
experiment with the TopicBC and the ResponseBC
methods from (Vuli´c and Moens, 2013), which are
the MuPTM-based models of cross-lingual seman-
tic similarity that obtain the best results in the BLE
task on these datasets. In short, the TopicBC method
computes the similarity of two words according to
the similarity of their conditional topic distributions
(Griffiths et al., 2007; Vuli´c et al., 2011) using
5We can build a one-to-one bilingual lexicon by harvesting
one-to-one translation pairs (ws, TC(ws)), and the quality of
that lexicon is best reflected in the Accl score.
</bodyText>
<equation confidence="0.989428444444445">
simM(wi ) = 1
E
wTj ERLM(ws)
sim(ws , w� )
M
esim(ws ,wTj )
p(w�j |w�i ) =
EwT EV T esim(ws,wT )
l
</equation>
<page confidence="0.908633">
1617
</page>
<bodyText confidence="0.999976119047619">
the Bhattacharyya coefficient (BC) (Kazama et al.,
2010) as the similarity function. ResponseBC is a
second-order similarity method. It first computes
initial similarity scores between all words cross-
lingually and monolingually using the cross-lingual
topical space and, in the second step, it computes the
similarity between 2 words as the similarity between
their word vectors that now contain the initial word-
to-word similarity scores with all source and target
words. The similarity function is again BC.
We use these models of similarity as a black box
to acquire seeds for the bootstrapping approach, but
we encourage the interested reader to find more de-
tails about the methods in the relevant literature.
These two models also serve as our baseline models,
and our goal is to test whether we are able to obtain
bilingual lexicons of higher quality using bootstrap-
ping that starts from the output of these models.
Weighting and similarity functions. We have
experimented with different families of weighting
(e.g., PMI, LLR, TF-IDF, chi-square) and similar-
ity functions (e.g., cosine, Dice, Kullback-Leibler,
Jensen-Shannon) (Lee, 1999; Turney and Pantel,
2010). In this paper, we present results obtained
by positive pointwise mutual information (PPMI)
(Niwa and Nitta, 1994) as a weighting function,
which is a standard choice in vector space seman-
tics (Turney and Pantel, 2010), and (combined with
cosine) yields the best results over a group of seman-
tic tasks according to (Bullinaria and Levy, 2007).
We use a smoothed version of PPMI as presented
in (Pantel and Lin, 2002; Turney and Pantel, 2010).
Again, based on the results reported in the relevant
literature (Bullinaria and Levy, 2007; Laroche and
Langlais, 2010; Turney and Pantel, 2010), we opt
for the cosine similarity as a standard choice for 5F.
We have also experimented with different window
sizes ranging from 3 to 15 in both directions around
the pivot word, but we have not detected any major
qualitative difference in the results and their inter-
pretation. Therefore, all results reported in the paper
are obtained by setting the window size to 6.
</bodyText>
<sectionHeader confidence="0.999801" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<subsectionHeader confidence="0.963877">
4.1 Are Seeds Important?
</subsectionHeader>
<bodyText confidence="0.99847066">
In recent work, Peirsman and Pad´o (2010; 2011)
report that “the size and quality of the (seed) lex-
icon are not of primary importance given that the
bootstrapping procedure effectively helped filter out
incorrect translation pairs and added more newly
identified mutual nearest neighbors.” According to
their findings, (1) noisy translation pairs are cor-
rected in later stages of the bootstrapping process,
since the quality of bilingual vector spaces gradu-
ally increases, (2) the size of the seed lexicon does
not matter since the bootstrapping approach is able
to learn translation pairs that were previously not
present in the seed lexicon. Additionally, they do not
provide any insight whether the frequency of seeds
in the corpus influences the quality of induced bilin-
gual vector spaces. In this paper, we question these
claims with a series of BLE experiments.
All experiments conducted in this section do not
rely on any extra confidence estimation except for
the symmetry constraint, that is, in each step we en-
rich the bilingual vector space with all new symmet-
ric translation pairs (see alg. 1 and sect. 2.3).
Exp. I: Same size, different seedings? The goal
of this experiment is to test whether the quality of
seeds plays an important role in the bootstrapping
approach. We experiment with 3 different seed lex-
icons: (1) Following (Peirsman and Pad´o, 2010;
Fiˇser and Ljubeˇsi´c, 2011), we harvest identically
spelled words across 2 languages and treat them
as one-to-one translations. This procedure results
in 459 seed translation pairs for ES-EN, and 431
pairs for IT-EN (SEED-ID), (2) We obtain symmet-
ric translation pairs using the TopicBC method (see
sect. 3) and use 459 pairs that have the highest fre-
quency in the Wiki-ES-EN corpus as seeds for ES-
EN (similarly 431 pairs for IT-EN) (SEED-TB), (3)
As in (2), but we now use the ResponseBC method to
acquire seeds (SEED-RB). The frequency of a one-
to-one translation pair is simply computed as the ge-
ometric mean of the frequencies of words that con-
stitute the translation pair.
Fig. 1(a) and 1(b) display the progress of the same
bootstrapping procedure using the 3 different seed
lexicons. We derive several interesting conclusions:
(i) Regardless of the actual choice of the seeding
method, the bootstrapping process proves its valid-
ity and utility since we observe that the quality of
induced bilingual vector spaces increases over time
for all 3 seeding methods. The bootstrapping proce-
dure converges quickly. The increase is especially
</bodyText>
<page confidence="0.948903">
1618
</page>
<figure confidence="0.999488204545454">
Ate„
0.8
0.
0.
0.2
Acc1 ( )
Acc1 ( )
Acc1 ( )
Acc10 ( )
Acc10 ( )
Acc10 ( )
Ate„
0.8
0.
0.
0.2
Acc1 ( )
Acc1 ( )
Acc1 ( )
Acc10 ( )
Acc10 ( )
Acc10 ( )
�
1 50
1500
1250
1000
500
50
� �
� �
� �
� �
� �
� �
0 1 2 5 8 9 10 11 12 1 1 15
�
(a) Spanish to English
0 1 2 5 8 9 10 11 12 1 1 15
�
(b) Italian to English
0 1 2 5 8 9 10 11 12 1 1 15
�
(c) # Dimensions over iterations
</figure>
<figureCaption confidence="0.997587">
Figure 1: Results with 3 different seeding methods as starting points of the bootstrapping process: (i) identical words
only (SEED-ID), (ii) the TopicBC method (SEED-TB), (iii) the ResponseBC method (SEED-RB). (a) Accts scores for
ES-EN; (b) Accts scores for IT-EN; (c) the number of dimensions in the space with the 3 different seeding methods
in each iteration for ES-EN and IT-EN. The bootstrapping procedure typically converges after a few iterations.
</figureCaption>
<figure confidence="0.999838172413793">
Acc
0.8
0.
0.
0.2
0
1
Acc1 ( )
Acc1 ( )
Acc1 ( )
Acc10 ( )
Acc10 ( )
Acc10 ( )
Accm
0.8
0.
0.
0.2
0
1
Acc1 ( )
Acc1 ( )
Acc1 ( )
Acc10 ( )
Acc10 ( )
Acc10 ( )
0 1 2 5 8 9 0 1 2 5 8 9 10
o o
(a) Spanish to English (b) Italian to English
</figure>
<figureCaption confidence="0.999105">
Figure 2: Results on the BLE task with SEED-RB when using seed translation pairs of different frequency: (i) high-
frequency (HF-SEED), (ii) medium-frequency (MF-SEED), (iii) low-frequency (LF-SEED).
</figureCaption>
<bodyText confidence="0.999772333333333">
prominent in the first few iterations, when the ap-
proach learns more new dimensions (see fig. 1(c)).
(ii) The seeding method is important. A bootstrap-
ping approach that starts with a better seed lexicon
is able to extract bilingual lexicons of higher quality
as reflected in Acci scores. Although the bootstrap-
ping approach seems more beneficial when dealing
with noisier seed lexicons (226% increase in terms
of Acci for ES-EN and 177% increase for IT-EN
when starting with SEED-ID, compared to 35% in-
crease for ES-EN, and 15% for IT-EN with SEED-
RB), when starting from a noisy seed lexicon such
as SEED-ID the method is unable to reach the same
level of performance. Starting with SEED-ID, the
approach is able to recover noisy dimensions from
an initial bilingual vector space, but it is still unable
to match the results that are obtained when starting
from a better initial space (e.g., SEED-RB).
(iii) SEED-RB produces slightly better results than
SEED-TB (e.g., the final Acci of 0.649 for SEED-
RB compared to 0.626 for SEED-TB for IT-EN, and
0.572 compared to 0.553 for ES-EN). This finding is
in line with the results reported in (Vuli´c and Moens,
2013) where ResponseBC proved to be a more ro-
bust and a more effective method when applied to
the BLE task directly. In all further experiments we
use ResponseBC to acquire seed pairs, i.e., the seed-
ing method is SEED-RB.
Exp. II: Does the frequency of seeds matter? In
the next experiment, we test whether the frequency
of seeds in the corpus plays an important role in
the bootstrapping process. The intuition is that by
using highly frequent and highly confident transla-
tion pairs the bootstrapping method has more reli-
able clues that help extract new dimensions in sub-
sequent iterations. On the other hand, low-frequency
</bodyText>
<page confidence="0.990319">
1619
</page>
<bodyText confidence="0.9983043125">
pairs (although potentially correct one-to-one trans-
lations) do not occur in the corpus and in the con-
texts of other words frequently enough, and are
therefore not sufficient to extract reliable new di-
mensions of the space.
To test the hypothesis, we again obtain all sym-
metric translation pairs using ResponseBC and then
sort them in descending order based on their fre-
quency in the corpus. In total, we retrieve a sorted
list of 2031 symmetric translation pairs for ES-EN,
and 1689 pairs for IT-EN. Following that, we split
the list in 3 parts of equal size: (i) the top third com-
prises translation pairs with the highest frequency in
the corpus (HF-SEED), (ii) the middle third com-
prises pairs of “medium” frequency (MF-SEED),
(iii) the bottom third are low-frequency pairs (LF-
SEED). We then use these 3 different seed lexicons
of equal size to seed the bootstrapping approach.
Fig. 2(a) and 2(b) show the progress of the boot-
strapping process using these 3 seed lexicons. We
again observe several interesting phenomena:
(i) High-frequency seed translation pairs are better
seeds, and that finding is in line with our hypothesis.
Although the bootstrapping approach again displays
a positive trend regardless of the actual choice of
seeds (we observe an increase even when using LF-
SEED), high-frequency seeds lead to better overall
results in the BLE task. Besides its high presence in
contexts of other words, another advantage of high-
frequency seed pairs is the fact that an initial sim-
ilarity method will typically acquire more reliable
translation candidates for such words (Pekar et al.,
2006). For instance, 89.5% of ES-EN pairs in HF-
SEED are correct one-to-one translations, compared
to 65.1% in MF-SEED, and 44.3% in LF-SEED.
(ii) The difference in results between HF-SEED and
MF-SEED is more visible in Acci scores. Although
both seed lexicons for all test words provide ranked
lists which contain words that exhibit some semantic
relation to the given word, the reliability and the fre-
quency of translation pairs are especially important
for detecting the relation of cross-lingual word syn-
onymy, that is, the translational equivalence that is
exploited in building one-to-one bilingual lexicons.
Exp. III: Does size matter? The following exper-
iment investigates whether bilingual vector spaces
may be effectively bootstrapped from small high-
quality seed lexicons, and if larger seed lexicons
necessarily lead to bilingual vector spaces of higher
quality as reflected in BLE results. We again retrieve
a sorted list of symmetric translation pairs as in Exp.
II. Following that, we build seed lexicons of vari-
ous sizes by retaining only the first N pairs from
the list, where we vary N from 200 to 1400 in steps
of 200. We also use the entire sorted list as a seed
lexicon (All), and compare the results on the BLE
task with the results obtained by applying the Re-
sponseBC and TopicBC methods directly (Vuli´c and
Moens, 2013). The results are summarized in tables
1 and 2. We observe the following:
(i) If we provide a seed lexicon with sufficient en-
tries, the bootstrapping procedure provides compa-
rable results regardless of the seed lexicon size, al-
though results tend to be higher for larger seed lex-
icons (e.g., compare results when starting with 600
and 1200 lexicon entries). When starting with the
size of 600, the bootstrapping approach is able to
find dimensions that were already in the seed lexi-
con of size 1200. The consequence is that, although
bootstrapping with a smaller seed lexicon displays a
slower start (see the difference in results at iteration
0), the performances level after convergence.
(ii) Regardless of the seed lexicon size, the boot-
strapping approach is valuable. It consistently im-
proves the quality of the induced bilingual vector
space, and consequently, the quality of bilingual lex-
icons extracted using that vector space. The positive
impact is more prominent for smaller seed lexicons,
i.e., we observe an increase of 78% for ES-EN when
starting with only 200 seed pairs, compared to an
increase of 15% when starting with 800 seed pairs,
and 10% when starting with 1400 seed pairs.
(iii) The bootstrapping approach outperforms Re-
sponseBC and TopicBC in terms of Acci and MRR
scores for both language pairs when the seed lexi-
con provides a sufficient number of entries. How-
ever, in terms of Accio, TopicBC and ResponseBC
still exhibit comparable (for IT-EN) or even better
(ES-EN) results. Both TopicBC and ResponseBC
are MuPTM-based methods that, due to MuPTM
properties, model the similarity of two words at the
level of documents as contexts, while the bootstrap-
ping approach is a window-based approach that nar-
rows down the context to a local neighborhood of a
word. The MuPTM-based models are better suited
to detect a general topical similarity of words, and
</bodyText>
<page confidence="0.957326">
1620
</page>
<table confidence="0.999628076923077">
Iteration: 0 2 5 10
Seed lexicon
Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10
200(-*1617) 0.274 0.352 0.525 0.446 0.534 0.713 0.481 0.569 0.753 0.488 0.576 0.752
400(-*1563) 0.416 0.499 0.663 0.518 0.602 0.774 0.542 0.620 0.787 0.545 0.625 0.788
600(-*1554) 0.459 0.539 0.707 0.550 0.630 0.787 0.573 0.650 0.803 0.578 0.654 0.802
800(-*1582) 0.494 0.572 0.728 0.548 0.631 0.799 0.563 0.644 0.802 0.567 0.646 0.806
1000(-*1636) 0.516 0.591 0.744 0.563 0.644 0.805 0.578 0.656 0.813 0.581 0.658 0.817
1200(-*1740) 0.536 0.613 0.764 0.586 0.661 0.804 0.588 0.664 0.812 0.591 0.667 0.814
1400(-*1888) 0.536 0.620 0.776 0.583 0.659 0.808 0.589 0.666 0.815 0.588 0.666 0.818
All-2031(-*2437) 0.543 0.625 0.785 0.589 0.667 0.813 0.597 0.675 0.818 0.599 0.677 0.820
TopicBC 0.433 0.576 0.843 − − − − − − − − −
ResponseBC 0.517 0.635 0.891 − − − − − − − − −
</table>
<tableCaption confidence="0.862783">
Table 1: ES-EN: Results with different sizes of the seed lexicon. The number in the parentheses denotes the number
of dimensions in the bilingual space after the bootstrapping procedure converges. The seeding method is SEED-RB.
</tableCaption>
<table confidence="0.999875307692308">
Iteration: 0 2 5 10
Seed lexicon
Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10 Acc1 MRR Acc10
200(-*1255) 0.394 0.469 0.703 0.515 0.595 0.757 0.548 0.621 0.782 0.555 0.628 0.787
400(-*1265) 0.546 0.618 0.757 0.623 0.690 0.831 0.639 0.704 0.840 0.644 0.709 0.844
600(-*1309) 0.585 0.657 0.798 0.653 0.718 0.856 0.664 0.726 0.859 0.672 0.734 0.862
800(-*1365) 0.602 0.672 0.813 0.657 0.723 0.857 0.663 0.726 0.865 0.665 0.730 0.867
1000(-*1416) 0.616 0.688 0.828 0.629 0.706 0.853 0.636 0.709 0.857 0.642 0.714 0.861
1200(-*1581) 0.628 0.700 0.840 0.655 0.724 0.869 0.664 0.733 0.877 0.668 0.736 0.883
1400(-*1749) 0.626 0.701 0.851 0.654 0.727 0.867 0.656 0.728 0.867 0.661 0.733 0.874
All-1689(-*2008) 0.616 0.695 0.850 0.643 0.716 0.860 0.653 0.724 0.862 0.654 0.726 0.866
TopicBC 0.578 0.667 0.834 − − − − − − − − −
ResponseBC 0.622 0.729 0.882 − − − − − − − − −
</table>
<tableCaption confidence="0.989811">
Table 2: IT-EN: Results with different sizes of the seed lexicon. The number in the parentheses denotes the number of
dimensions in the bilingual space after the bootstrapping procedure converges. The seeding method is SEED-RB.
</tableCaption>
<bodyText confidence="0.9998802">
are therefore not always able to push the real cross-
lingual synonyms higher in the ranked list of seman-
tically similar words, while the window-based boot-
strapping approach is better tailored to model the
relation of cross-lingual synonymy, i.e., to extract
one-to-one translation pairs (as reflected in Accl
scores). A similar conclusion for monolingual set-
tings is drawn by Baroni and Lenci (2010).
(iv) Since our bootstrapping approach utilizes Re-
sponseBC or TopicBC as a preprocessing step, it is
obvious that the approach leads to an increased com-
plexity. On top of the initial complexity of Respon-
seBC and TopicBC, the bootstrapping method re-
quires |V S||V &apos; |comparisons at each iteration, but
given the fact that each wS� E V S may be processed
independently of any other wS� E V S in each itera-
tion, the bootstrapping method is trivially paralleliz-
able. That makes the method computationally fea-
sible even for vocabularies larger than the ones re-
ported in the paper.
</bodyText>
<subsectionHeader confidence="0.992654">
4.2 Is Confidence Estimation Important?
</subsectionHeader>
<bodyText confidence="0.999942526315789">
According to the results from tables 1 and 2, re-
gardless of the seed lexicon size, the bootstrapping
approach does not suffer from semantic drift, i.e.,
if we seed the process with high-quality symmetric
translation pairs, it is able to recover more pairs and
add them as new dimensions of the bilingual vector
space. However, we also study the influence of ap-
plying different confidence estimation functions on
top of the symmetry constraint (see sect 2.3), but we
do not observe any improvement in the BLE results,
regardless of the actual choice of a confidence esti-
mation function. The only observed phenomenon,
as illustrated by fig. 3, is the slower convergence
rate when setting the parameter B to lower values.
The symmetry constraint alone seems to be sufficient
to prevent semantic drift, but it might also be a too
strong and a too conservative assumption, since only
a small portion of all possible translation pairs is
used to span the bilingual vector space (for instance,
</bodyText>
<page confidence="0.966711">
1621
</page>
<figure confidence="0.993282333333333">
Accl
0 1 2 5 8 9 10 11 12 1 1 15
o
</figure>
<figureCaption confidence="0.996651">
Figure 3: The effect of learning rate B on bootstrapping.
Language pair: ES-EN, seed lexicon: SEED-RB with
600 pairs, confidence function: symmetrized M-Best.
</figureCaption>
<bodyText confidence="0.999967">
when starting with 600 entries for ES-EN, the final
bilingual vector space consists of only 1554 pairs,
while the total number of ES nouns is 9439). One
line of future work will address the construction of
bootstrapping algorithms that also enable the usage
of highly reliable asymmetric pairs as dimensions,
and the confidence estimation functions might have
a more important role in that setting.
</bodyText>
<sectionHeader confidence="0.998833" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999991466666667">
We have presented a new bootstrapping approach to
inducing bilingual vector spaces from non-parallel
data, and have shown the utility of the induced space
in the BLE task. The approach is fully corpus-based
and, unlike previous work, it does not rely on the
availability of machine-readable translation dictio-
naries or predefined concept categories. We have
systematically described, analyzed and evaluated all
key components of the bootstrapping approach. Re-
sults reveal that, contrary to conclusions from prior
work, the initialization of the bilingual vector space
is especially important. We have presented a novel
approach to initializing the bootstrapping procedure,
and have shown that better results in the BLE task
are obtained by starting from seed lexicons that com-
prise highly reliable high-frequent translation pairs.
The bootstrapping framework presented in the pa-
per is completely language pair independent, which
makes it effectively applicable to any language pair.
In future work, we will investigate other models
of similarity besides TopicBC and ResponseBC (e.g,
the method from (Haghighi et al., 2008)) that could
be used as preliminary models for constructing an
initial bilingual vector space. Furthermore, we plan
to study other confidence functions and explore if
asymmetric translation candidates could also con-
tribute to the bootstrapping method. Finally, we also
plan to test the robustness of our fully corpus-based
bootstrapping approach by porting it to more lan-
guage pairs.
</bodyText>
<sectionHeader confidence="0.997385" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9982102">
We would like to thank the anonymous reviewers for
their useful suggestions. This research has been car-
ried out in the framework of the TermWise Knowl-
edge Platform (IOF-KP/09/001) funded by the In-
dustrial Research Fund, KU Leuven, Belgium.
</bodyText>
<sectionHeader confidence="0.998926" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.981279764705882">
Marco Baroni and Alessandro Lenci. 2010. Distribu-
tional memory: A general framework for corpus-based
semantics. Computational Linguistics, 36(4):673–
721.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet Allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
Jordan Boyd-Graber and David M. Blei. 2009. Multilin-
gual topic models for unaligned text. In Proceedings
of UAI, pages 75–82.
John A. Bullinaria and Joseph P. Levy. 2007. Extract-
ing semantic representations from word co-occurrence
statistics: A computational study. Behavior Research
Methods, 39(3):510–526.
Sung-Hyuk Cha. 2007. Comprehensive survey on
distance/similarity measures between probability den-
sity functions. International Journal of Mathematical
Models and Methods in Applied Sciences, 1(4):300–
307.
Dipanjan Das and Slav Petrov. 2011. Unsupervised part-
of-speech tagging with bilingual graph-based projec-
tions. In Proceedings of ACL-HLT, pages 600–609.
Hal Daum´e III and Jagadeesh Jagarlamudi. 2011. Do-
main adaptation for machine translation by mining un-
seen words. In Proceedings of ACL-HLT, pages 407–
412.
Wim De Smet and Marie-Francine Moens. 2009. Cross-
language linking of news stories on the Web using in-
terlingual topic modeling. In Proceedings of the CIKM
2009 Workshop on Social Web Search and Mining,
pages 57–64.
Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syntac-
tic transfer using a bilingual lexicon. In Proceedings
of EMNLP-CoNLL, pages 1–11.
</reference>
<figure confidence="0.999925909090909">
0.
0.55
0.5
0. 5
0.
B = 0
B = 50
B = 100
B = 150
B = 200
B = A
</figure>
<page confidence="0.967921">
1622
</page>
<reference confidence="0.99669362345679">
Darja Fi&amp;quot;ser and Nikola Ljube&amp;quot;si´c. 2011. Bilingual lexicon
extraction from comparable corpora for closely related
languages. In Proceedings of RANLP, pages 125–131.
Pascale Fung and Percy Cheung. 2004. Mining very-
non-parallel corpora: Parallel sentence and lexicon ex-
traction via bootstrapping and EM. In Proceedings of
EMNLP, pages 57–63.
Pascale Fung and Lo Yuen Yee. 1998. An IR approach
for translating new words from nonparallel, compara-
ble texts. In Proceedings of COLING, pages 414–420.
´Eric Gaussier, Jean-Michel Renders, Irina Matveeva,
Cyril Goutte, and Herv´e D´ejean. 2004. A geometric
view on bilingual lexicon extraction from comparable
corpora. In Proceedings of ACL, pages 526–533.
Thomas L. Griffiths, Mark Steyvers, and Joshua B.
Tenenbaum. 2007. Topics in semantic representation.
Psychological Review, 114(2):211–244.
Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick,
and Dan Klein. 2008. Learning bilingual lexicons
from monolingual corpora. In Proceedings of ACL,
pages 771–779.
Ruihong Huang and Ellen Riloff. 2012. Bootstrapped
training of event extraction classifiers. In Proceedings
of EACL, pages 286–295.
Azniah Ismail and Suresh Manandhar. 2010. Bilin-
gual lexicon extraction from comparable corpora using
in-domain terms. In Proceedings of COLING, pages
481–489.
Jun’ichi Kazama, Stijn De Saeger, Kow Kuroda, Masaki
Murata, and Kentaro Torisawa. 2010. A Bayesian
method for robust estimation of distributional similar-
ities. In Proceedings of ACL, pages 247–256.
Philipp Koehn and Kevin Knight. 2002. Learning a
translation lexicon from monolingual corpora. In Pro-
ceedings of the ACL Workshop on Unsupervised Lexi-
cal Acquisition, pages 9–16.
Zornitsa Kozareva and Eduard H. Hovy. 2010. Not all
seeds are equal: Measuring the quality of text min-
ing seeds. In Proceedings of NAACL-HLT, pages 618–
626.
Audrey Laroche and Philippe Langlais. 2010. Revisiting
context-based projection methods for term-translation
spotting in comparable corpora. In Proceedings of
COLING, pages 617–625.
Victor Lavrenko, Martin Choquette, and W. Bruce Croft.
2002. Cross-lingual relevance models. In Proceedings
of SIGIR, pages 175–182.
Lillian Lee. 1999. Measures of distributional similarity.
In Proceedings of ACL, pages 25–32.
Gina-Anne Levow, Douglas W. Oard, and Philip Resnik.
2005. Dictionary-based techniques for cross-language
information retrieval. Information Processing and
Management, 41(3):523–547.
Tara McIntosh and James R. Curran. 2009. Reducing se-
mantic drift with bagging and distributional similarity.
In Proceedings of ACL, pages 396–404.
I. Dan Melamed. 2000. Models of translational equiv-
alence among words. Computational Linguistics,
26(2):221–249.
David Mimno, Hanna M. Wallach, Jason Naradowsky,
David A. Smith, and Andrew McCallum. 2009.
Polylingual topic models. In Proceedings of EMNLP,
pages 880–889.
Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen.
2009. Mining multilingual topics from Wikipedia. In
Proceedings of WWW, pages 1155–1156.
Yoshiki Niwa and Yoshihiko Nitta. 1994. Co-occurrence
vectors from corpora vs. distance vectors from dictio-
naries. In Proceedings of COLING, pages 304–309.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, 29(1):19–51.
Sebastian Pad´o and Mirella Lapata. 2009. Cross-lingual
annotation projection for semantic roles. Journal of
Artificial Intelligence Research, 36:307–340.
Patrick Pantel and Dekang Lin. 2002. Discovering word
senses from text. In Proceedings of KDD, pages 613–
619.
Yves Peirsman and Sebastian Pad´o. 2010. Cross-
lingual induction of selectional preferences with bilin-
gual vector spaces. In Proceedings of NAACL-HLT,
pages 921–929.
Yves Peirsman and Sebastian Pad´o. 2011. Semantic re-
lations in bilingual lexicons. ACM Transactions on
Speech and Language Processing, 8(2):article 3.
Viktor Pekar, Ruslan Mitkov, Dimitar Blagoev, and An-
drea Mulloni. 2006. Finding translations for low-
frequency words in comparable corpora. Machine
Translation, 20(4):247–266.
Emmanuel Prochasson and Pascale Fung. 2011. Rare
word translation extraction from aligned comparable
documents. In Proceedings ofACL, pages 1327–1335.
Reinhard Rapp. 1999. Automatic identification of word
translations from unrelated English and German cor-
pora. In Proceedings of ACL, pages 519–526.
Ellen Riloff and Jessica Shepherd. 1999. A corpus-based
bootstrapping algorithm for semi-automated semantic
lexicon construction. Natural Language Engineering,
5(2):147–156.
Helmut Schmid. 1994. Probabilistic part-of-speech tag-
ging using decision trees. In International Conference
on New Methods in Language Processing.
Daphna Shezaf and Ari Rappoport. 2010. Bilingual lex-
icon generation using non-aligned signatures. In Pro-
ceedings of ACL, pages 98–107.
1623
David A. Smith and Jason Eisner. 2007. Bootstrapping
feature-rich dependency parsers with entropic priors.
In Proceedings of EMNLP-CoNLL, pages 667–677.
Mark Steyvers and Tom Griffiths. 2007. Probabilistic
topic models. Handbook of Latent Semantic Analysis,
427(7):424–440.
Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan Mc-
Donald, and Joakim Nivre. 2013a. Token and type
constraints for cross-lingual part-of-speech tagging.
Transactions of ACL, 1:1–12.
Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre.
2013b. Target language adaptation of discrimina-
tive transfer parsers. In Proceedings of NAACL-HLT,
pages 1061–1071.
Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita.
2012. Bilingual lexicon extraction from comparable
corpora using label propagation. In Proceedings of
EMNLP-CoNLL, pages 24–36.
Michael Thelen and Ellen Riloff. 2002. A bootstrap-
ping method for learning semantic lexicons using ex-
traction pattern contexts. In Proceedings of EMNLP,
pages 214–221.
Kewei Tu and Vasant Honavar. 2012. Unambiguity reg-
ularization for unsupervised learning of probabilistic
grammars. In Proceedings of EMNLP-CoNLL, pages
1324–1334.
Peter D. Turney and Patrick Pantel. 2010. From fre-
quency to meaning: vector space models of semantics.
Journal of Artifical Intelligence Research, 37(1):141–
188.
Lonneke van der Plas, Paola Merlo, and James Hender-
son. 2011. Scaling up automatic cross-lingual seman-
tic role annotation. In Proceedings ofACL-HLT, pages
299–304.
Ellen M. Voorhees. 1999. The TREC-8 question answer-
ing track report. In Proceedings of TREC, pages 77–
82.
Ivan Vuli´c and Marie-Francine Moens. 2013. Cross-
lingual semantic similarity of words as the similarity
of their semantic word responses. In Proceedings of
NAACL-HLT, pages 106–116.
Ivan Vuli´c, Wim De Smet, and Marie-Francine Moens.
2011. Identifying word translations from comparable
corpora using latent topic models. In Proceedings of
ACL-HLT, pages 479–484.
David Yarowsky and Grace Ngai. 2001. Inducing mul-
tilingual POS taggers and NP bracketers via robust
projection across aligned corpora. In Proceedings of
NAACL, pages 200–207.
Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai. 2010.
Cross-lingual latent topic extraction. In Proceedings
of ACL, pages 1128–1137.
Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou.
2009. Cross language dependency parsing using a
bilingual lexicon. In Proceedings of ACL, pages 55–
63.
</reference>
<page confidence="0.994753">
1624
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.513954">
<title confidence="0.984855">A Study on Bootstrapping Bilingual Vector Spaces from Non-Parallel Data (and Nothing Else)</title>
<author confidence="0.992963">Ivan Vuli´c</author>
<author confidence="0.992963">Marie-Francine</author>
<affiliation confidence="0.96181">Department of Computer KU Celestijnenlaan</affiliation>
<address confidence="0.605736">Leuven,</address>
<abstract confidence="0.998051428571429">We present a new language pair agnostic approach to inducing bilingual vector spaces from non-parallel data without any other resource in a bootstrapping fashion. The paper systematically introduces and describes all key elements of the bootstrapping procedure: (1) starting point or seed lexicon, (2) the confidence estimation and selection of new dimensions of the space, and (3) convergence. We test the quality of the induced bilingual vector spaces, and analyze the influence of the different components of the bootstrapping approach in the task of bilingual lexicon extraction (BLE) for two language pairs. Results reveal that, contrary to conclusions from prior work, the seeding of the bootstrapping process has a heavy impact on the quality of the learned lexicons. We also show that our approach outperforms the best performing fully corpus-based BLE methods on these test sets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Alessandro Lenci</author>
</authors>
<title>Distributional memory: A general framework for corpus-based semantics.</title>
<date>2010</date>
<journal>Computational Linguistics,</journal>
<volume>36</volume>
<issue>4</issue>
<pages>721</pages>
<contexts>
<context position="36774" citStr="Baroni and Lenci (2010)" startWordPosition="6153" endWordPosition="6156">le 2: IT-EN: Results with different sizes of the seed lexicon. The number in the parentheses denotes the number of dimensions in the bilingual space after the bootstrapping procedure converges. The seeding method is SEED-RB. are therefore not always able to push the real crosslingual synonyms higher in the ranked list of semantically similar words, while the window-based bootstrapping approach is better tailored to model the relation of cross-lingual synonymy, i.e., to extract one-to-one translation pairs (as reflected in Accl scores). A similar conclusion for monolingual settings is drawn by Baroni and Lenci (2010). (iv) Since our bootstrapping approach utilizes ResponseBC or TopicBC as a preprocessing step, it is obvious that the approach leads to an increased complexity. On top of the initial complexity of ResponseBC and TopicBC, the bootstrapping method requires |V S||V &apos; |comparisons at each iteration, but given the fact that each wS� E V S may be processed independently of any other wS� E V S in each iteration, the bootstrapping method is trivially parallelizable. That makes the method computationally feasible even for vocabularies larger than the ones reported in the paper. 4.2 Is Confidence Estim</context>
</contexts>
<marker>Baroni, Lenci, 2010</marker>
<rawString>Marco Baroni and Alessandro Lenci. 2010. Distributional memory: A general framework for corpus-based semantics. Computational Linguistics, 36(4):673– 721.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="20431" citStr="Blei et al., 2003" startWordPosition="3370" endWordPosition="3373">ion metrics. We measure the performance on the BLE task using a standard Top M accuracy (AccM) metric. It denotes the number of source words ws from ground truth translation pairs whose list RLM(ws ) contains the correct translation according to our ground truth over the total number of ground truth translation pairs (=1000) (Gaussier et al., 2004; Tamura et al., 2012).5 Additionally, we report the mean reciprocal rank (MRR) scores (Voorhees, 1999) for some experimental runs. Multilingual topic model. We utilize a straightforward multilingual extension of the standard Blei et al.’s LDA model (Blei et al., 2003) called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). BiLDA training follows the procedure from (Vuli´c and Moens, 2013), that is, the training method is Gibbs sampling with the number of topics set to K = 2000. Hyperparameters of the model are set to standard values (Steyvers and Griffiths, 2007): α = 50/K and Q = 0.01. Building initial seed lexicons. To produce the lists of one-to-one translation pairs that are used as seeds for the bootstrapping approach (see sect. 2.2), we experiment with the TopicBC and the ResponseBC methods from (Vuli´c and Moens, 2013), </context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jordan Boyd-Graber</author>
<author>David M Blei</author>
</authors>
<title>Multilingual topic models for unaligned text.</title>
<date>2009</date>
<booktitle>In Proceedings of UAI,</booktitle>
<pages>75--82</pages>
<marker>Boyd-Graber, Blei, 2009</marker>
<rawString>Jordan Boyd-Graber and David M. Blei. 2009. Multilingual topic models for unaligned text. In Proceedings of UAI, pages 75–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bullinaria</author>
<author>Joseph P Levy</author>
</authors>
<title>Extracting semantic representations from word co-occurrence statistics: A computational study.</title>
<date>2007</date>
<journal>Behavior Research Methods,</journal>
<volume>39</volume>
<issue>3</issue>
<contexts>
<context position="8972" citStr="Bullinaria and Levy, 2007" startWordPosition="1437" endWordPosition="1440"> computed following the standard procedure (Gaussier et al., 2004): (1) For each source word wSi E V S, build its Ndimensional context vector cv(wSi ) that consists of association scores scSk (cSk), that is, we compute the strength of association with the “source” part of each dimension ck that constitutes the N-dimensional bilingual space. The association is dependent on the co-occurrence of wSi and cSk in a predefined context. Various functions such as the log-likelihood ratio (LLR) (Rapp, 1999; Ismail and Manandhar, 2010), TF-IDF (Fung and Yee, 1998), or pointwise mutual information (PMI) (Bullinaria and Levy, 2007; Shezaf and Rappoport, 2010) are typically used as weighting functions to quantify the strength of the association. (2) Repeat step (1) for each target word wTj E VT and build context vectors cv(wTj ) that consist of scores scTk (cTk ). (3) Since cSk and cTkaddress the same dimension ck in the bilingual vector space for each k = 1, ... , N, we are able to compute the similarity between cv(wSi ) and cv(wTj ) using any similarity measure such as the Jaccard index, the Kullback-Leibler or the Jensen-Shannon divergence, the cosine measure, or others (Lee, 1999; Cha, 2007). The similarity score fo</context>
<context position="23138" citStr="Bullinaria and Levy, 2007" startWordPosition="3814" endWordPosition="3817">ts from the output of these models. Weighting and similarity functions. We have experimented with different families of weighting (e.g., PMI, LLR, TF-IDF, chi-square) and similarity functions (e.g., cosine, Dice, Kullback-Leibler, Jensen-Shannon) (Lee, 1999; Turney and Pantel, 2010). In this paper, we present results obtained by positive pointwise mutual information (PPMI) (Niwa and Nitta, 1994) as a weighting function, which is a standard choice in vector space semantics (Turney and Pantel, 2010), and (combined with cosine) yields the best results over a group of semantic tasks according to (Bullinaria and Levy, 2007). We use a smoothed version of PPMI as presented in (Pantel and Lin, 2002; Turney and Pantel, 2010). Again, based on the results reported in the relevant literature (Bullinaria and Levy, 2007; Laroche and Langlais, 2010; Turney and Pantel, 2010), we opt for the cosine similarity as a standard choice for 5F. We have also experimented with different window sizes ranging from 3 to 15 in both directions around the pivot word, but we have not detected any major qualitative difference in the results and their interpretation. Therefore, all results reported in the paper are obtained by setting the wi</context>
</contexts>
<marker>Bullinaria, Levy, 2007</marker>
<rawString>John A. Bullinaria and Joseph P. Levy. 2007. Extracting semantic representations from word co-occurrence statistics: A computational study. Behavior Research Methods, 39(3):510–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sung-Hyuk Cha</author>
</authors>
<title>Comprehensive survey on distance/similarity measures between probability density functions.</title>
<date>2007</date>
<journal>International Journal of Mathematical Models and Methods in Applied Sciences,</journal>
<volume>1</volume>
<issue>4</issue>
<pages>307</pages>
<contexts>
<context position="9547" citStr="Cha, 2007" startWordPosition="1542" endWordPosition="1543">on (PMI) (Bullinaria and Levy, 2007; Shezaf and Rappoport, 2010) are typically used as weighting functions to quantify the strength of the association. (2) Repeat step (1) for each target word wTj E VT and build context vectors cv(wTj ) that consist of scores scTk (cTk ). (3) Since cSk and cTkaddress the same dimension ck in the bilingual vector space for each k = 1, ... , N, we are able to compute the similarity between cv(wSi ) and cv(wTj ) using any similarity measure such as the Jaccard index, the Kullback-Leibler or the Jensen-Shannon divergence, the cosine measure, or others (Lee, 1999; Cha, 2007). The similarity score for two words wSi and wTj is sim(wSi , wTj ). For each source word wSi , we can build a ranked list RL(wSi ) that consists of all words wTj E V T ranked according to their respective similarity scores sim(wSi , wTj ). In the similar fashion, we can build a ranked list RL(wTj ), for each target word wT j . We call the top scoring target word wTj for some source word wSi its translation candidate, and write TC(wSi ) = wTj . Additionally, we label the ranked list RL(wSi ) that is pruned at position M as RLM(wSi ). Bootstrapping. The key idea of the bootstrapping approach re</context>
</contexts>
<marker>Cha, 2007</marker>
<rawString>Sung-Hyuk Cha. 2007. Comprehensive survey on distance/similarity measures between probability density functions. International Journal of Mathematical Models and Methods in Applied Sciences, 1(4):300– 307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised partof-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<pages>600--609</pages>
<contexts>
<context position="1918" citStr="Das and Petrov, 2011" startWordPosition="290" endWordPosition="293"> retrieval (Lavrenko et al., 2002; Levow et al., 2005) or statistical machine translation (Och and Ney, 2003). Additionally, they are a crucial component in cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc. Techniques for automatic bilingual lexicon extraction (BLE) from parallel corpora on the basis of word alignment models are well established (Och and Ney, 2003). However, due to a relative scarceness of parallel data for many language pairs and domains, alternative approaches that rely on comparable corpora have also gained much interest (e.g., Fung and Yee (1998); Rapp (1999)). The models that rely on non-parallel data typically represent each word by a high-dimensional vector in a feature vector space, where the dimensions of the vector are its context feat</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised partof-speech tagging with bilingual graph-based projections. In Proceedings of ACL-HLT, pages 600–609.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Jagadeesh Jagarlamudi</author>
</authors>
<title>Domain adaptation for machine translation by mining unseen words.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<pages>407--412</pages>
<marker>Daum´e, Jagarlamudi, 2011</marker>
<rawString>Hal Daum´e III and Jagadeesh Jagarlamudi. 2011. Domain adaptation for machine translation by mining unseen words. In Proceedings of ACL-HLT, pages 407– 412.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wim De Smet</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Crosslanguage linking of news stories on the Web using interlingual topic modeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the CIKM 2009 Workshop on Social Web Search and Mining,</booktitle>
<pages>57--64</pages>
<marker>De Smet, Moens, 2009</marker>
<rawString>Wim De Smet and Marie-Francine Moens. 2009. Crosslanguage linking of news stories on the Web using interlingual topic modeling. In Proceedings of the CIKM 2009 Workshop on Social Web Search and Mining, pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Greg Durrett</author>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Syntactic transfer using a bilingual lexicon.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>1--11</pages>
<contexts>
<context position="1830" citStr="Durrett et al., 2012" startWordPosition="276" endWordPosition="279">le source of knowledge for various cross-lingual tasks such as cross-lingual information retrieval (Lavrenko et al., 2002; Levow et al., 2005) or statistical machine translation (Och and Ney, 2003). Additionally, they are a crucial component in cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc. Techniques for automatic bilingual lexicon extraction (BLE) from parallel corpora on the basis of word alignment models are well established (Och and Ney, 2003). However, due to a relative scarceness of parallel data for many language pairs and domains, alternative approaches that rely on comparable corpora have also gained much interest (e.g., Fung and Yee (1998); Rapp (1999)). The models that rely on non-parallel data typically represent each word by a high-dimensional v</context>
</contexts>
<marker>Durrett, Pauls, Klein, 2012</marker>
<rawString>Greg Durrett, Adam Pauls, and Dan Klein. 2012. Syntactic transfer using a bilingual lexicon. In Proceedings of EMNLP-CoNLL, pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Darja Fiser</author>
<author>Nikola Ljubesi´c</author>
</authors>
<title>Bilingual lexicon extraction from comparable corpora for closely related languages.</title>
<date>2011</date>
<booktitle>In Proceedings of RANLP,</booktitle>
<pages>125--131</pages>
<marker>Fiser, Ljubesi´c, 2011</marker>
<rawString>Darja Fi&amp;quot;ser and Nikola Ljube&amp;quot;si´c. 2011. Bilingual lexicon extraction from comparable corpora for closely related languages. In Proceedings of RANLP, pages 125–131.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Percy Cheung</author>
</authors>
<title>Mining verynon-parallel corpora: Parallel sentence and lexicon extraction via bootstrapping and EM.</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>57--63</pages>
<contexts>
<context position="3871" citStr="Fung and Cheung, 2004" startWordPosition="617" endWordPosition="620">rder to compare the feature vectors cv(wS1 ) and cv(wT2 ), the context features need to span a shared 1The context may be a document, a paragraph, a window of predefined size around each occurrence of wS� in CS, etc. For an overview, see, e.g., (Tamura et al., 2012). 1613 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1613–1624, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics bilingual vector space. The standard way of building a bilingual vector space is to use bilingual lexicon entries (Rapp, 1999; Fung and Cheung, 2004; Gaussier et al., 2004) as dimensions of the space. However, there seems to be an apparent flaw in logic, since the methods assume that there exist readily available bilingual lexicons that are then used to induce bilingual lexicons! Therefore, the focus of the researchers has turned to designing BLE methods that do not rely on any external translation resources such as machine-readable bilingual lexicons and parallel corpora (Haghighi et al., 2008; Vuli´c et al., 2011). In order to circumvent this issue, one line of recent work aims to bootstrap high-quality bilingual vector spaces from a sm</context>
</contexts>
<marker>Fung, Cheung, 2004</marker>
<rawString>Pascale Fung and Percy Cheung. 2004. Mining verynon-parallel corpora: Parallel sentence and lexicon extraction via bootstrapping and EM. In Proceedings of EMNLP, pages 57–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
<author>Lo Yuen Yee</author>
</authors>
<title>An IR approach for translating new words from nonparallel, comparable texts.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>414--420</pages>
<contexts>
<context position="2319" citStr="Fung and Yee (1998)" startWordPosition="354" endWordPosition="357">ch as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc. Techniques for automatic bilingual lexicon extraction (BLE) from parallel corpora on the basis of word alignment models are well established (Och and Ney, 2003). However, due to a relative scarceness of parallel data for many language pairs and domains, alternative approaches that rely on comparable corpora have also gained much interest (e.g., Fung and Yee (1998); Rapp (1999)). The models that rely on non-parallel data typically represent each word by a high-dimensional vector in a feature vector space, where the dimensions of the vector are its context features. The context features are typically words co-occurring with the word in a predefined context.1 The similarity of two words, wS1 given in the source language LS with vocabulary V S and wT2 in the target language LT with vocabulary VT is then computed as sim(wS1 , wT2 ) = 5F(cv(wS1 ), cv(wT2 )). cv(wS1 ) = [scS1 (c1), ... , scS1 (cN)] is a context vector for wS1 with N context features ck, where</context>
<context position="8906" citStr="Fung and Yee, 1998" startWordPosition="1427" endWordPosition="1430">onal bilingual vector space. The cross-lingual similarity is computed following the standard procedure (Gaussier et al., 2004): (1) For each source word wSi E V S, build its Ndimensional context vector cv(wSi ) that consists of association scores scSk (cSk), that is, we compute the strength of association with the “source” part of each dimension ck that constitutes the N-dimensional bilingual space. The association is dependent on the co-occurrence of wSi and cSk in a predefined context. Various functions such as the log-likelihood ratio (LLR) (Rapp, 1999; Ismail and Manandhar, 2010), TF-IDF (Fung and Yee, 1998), or pointwise mutual information (PMI) (Bullinaria and Levy, 2007; Shezaf and Rappoport, 2010) are typically used as weighting functions to quantify the strength of the association. (2) Repeat step (1) for each target word wTj E VT and build context vectors cv(wTj ) that consist of scores scTk (cTk ). (3) Since cSk and cTkaddress the same dimension ck in the bilingual vector space for each k = 1, ... , N, we are able to compute the similarity between cv(wSi ) and cv(wTj ) using any similarity measure such as the Jaccard index, the Kullback-Leibler or the Jensen-Shannon divergence, the cosine </context>
</contexts>
<marker>Fung, Yee, 1998</marker>
<rawString>Pascale Fung and Lo Yuen Yee. 1998. An IR approach for translating new words from nonparallel, comparable texts. In Proceedings of COLING, pages 414–420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>´Eric Gaussier</author>
<author>Jean-Michel Renders</author>
<author>Irina Matveeva</author>
<author>Cyril Goutte</author>
<author>Herv´e D´ejean</author>
</authors>
<title>A geometric view on bilingual lexicon extraction from comparable corpora.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>526--533</pages>
<marker>Gaussier, Renders, Matveeva, Goutte, D´ejean, 2004</marker>
<rawString>´Eric Gaussier, Jean-Michel Renders, Irina Matveeva, Cyril Goutte, and Herv´e D´ejean. 2004. A geometric view on bilingual lexicon extraction from comparable corpora. In Proceedings of ACL, pages 526–533.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
<author>Joshua B Tenenbaum</author>
</authors>
<title>Topics in semantic representation.</title>
<date>2007</date>
<journal>Psychological Review,</journal>
<volume>114</volume>
<issue>2</issue>
<contexts>
<context position="21323" citStr="Griffiths et al., 2007" startWordPosition="3520" endWordPosition="3523">el are set to standard values (Steyvers and Griffiths, 2007): α = 50/K and Q = 0.01. Building initial seed lexicons. To produce the lists of one-to-one translation pairs that are used as seeds for the bootstrapping approach (see sect. 2.2), we experiment with the TopicBC and the ResponseBC methods from (Vuli´c and Moens, 2013), which are the MuPTM-based models of cross-lingual semantic similarity that obtain the best results in the BLE task on these datasets. In short, the TopicBC method computes the similarity of two words according to the similarity of their conditional topic distributions (Griffiths et al., 2007; Vuli´c et al., 2011) using 5We can build a one-to-one bilingual lexicon by harvesting one-to-one translation pairs (ws, TC(ws)), and the quality of that lexicon is best reflected in the Accl score. simM(wi ) = 1 E wTj ERLM(ws) sim(ws , w� ) M esim(ws ,wTj ) p(w�j |w�i ) = EwT EV T esim(ws,wT ) l 1617 the Bhattacharyya coefficient (BC) (Kazama et al., 2010) as the similarity function. ResponseBC is a second-order similarity method. It first computes initial similarity scores between all words crosslingually and monolingually using the cross-lingual topical space and, in the second step, it co</context>
</contexts>
<marker>Griffiths, Steyvers, Tenenbaum, 2007</marker>
<rawString>Thomas L. Griffiths, Mark Steyvers, and Joshua B. Tenenbaum. 2007. Topics in semantic representation. Psychological Review, 114(2):211–244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aria Haghighi</author>
<author>Percy Liang</author>
<author>Taylor Berg-Kirkpatrick</author>
<author>Dan Klein</author>
</authors>
<title>Learning bilingual lexicons from monolingual corpora.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>771--779</pages>
<contexts>
<context position="4324" citStr="Haghighi et al., 2008" startWordPosition="690" endWordPosition="693">ational Linguistics bilingual vector space. The standard way of building a bilingual vector space is to use bilingual lexicon entries (Rapp, 1999; Fung and Cheung, 2004; Gaussier et al., 2004) as dimensions of the space. However, there seems to be an apparent flaw in logic, since the methods assume that there exist readily available bilingual lexicons that are then used to induce bilingual lexicons! Therefore, the focus of the researchers has turned to designing BLE methods that do not rely on any external translation resources such as machine-readable bilingual lexicons and parallel corpora (Haghighi et al., 2008; Vuli´c et al., 2011). In order to circumvent this issue, one line of recent work aims to bootstrap high-quality bilingual vector spaces from a small initial seed lexicon. The seed lexicon is constructed by harvesting identical or similarly spelled words across languages (Koehn and Knight, 2002; Peirsman and Pad´o, 2010), and it spans the initial bilingual vector space. The space is then gradually enriched with new dimensions/axes during the bootstrapping procedure. The bootstrapping process has already proven its validity in inducing bilingual lexicons for closely similar languages such as S</context>
<context position="14945" citStr="Haghighi et al., 2008" startWordPosition="2470" endWordPosition="2473">; Vuli´c and Moens, 2013).2 Therefore, we can construct the initial seed lexicon as follows: (1) Train a multilingual topic model on the corpus. (2) Obtain one-to-one translation pairs using any of the MuPTM-based models of cross-lingual similarity, e.g., (Vuli´c et al., 2011; Vuli´c and Moens, 2013). (3) Retain only symmetric translation pairs. This step ensures that only highly confident pairs are used as seed translation pairs. (4) Rank translation pairs according to their frequency in the corpus and use a subset of the most 2One can also use other models that are similar to MuPTM such as (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) to produce the initial seed lexicon, but that analysis is beyond the scope of this work. frequent symmetric pairs as seeds. 2.3 Estimating Confidence of New Dimensions Another crucial step in the bootstrapping procedure is the estimation of confidence in a translation pair/candidate dimension. Errors in the early stages of the procedure may negatively affect the learning process and even cause semantic drift (Riloff and Shepherd, 1999; McIntosh and Curran, 2009). We therefore impose the constraint which requires translation pairs to be symmetric in order to </context>
<context position="18332" citStr="Haghighi et al., 2008" startWordPosition="3026" endWordPosition="3029">ine a distribution: The confidence function is then minus the entropy of the probability distribution p: CF(wSi ,TC(wSi )) = � p(wTl |wSi ) log p(wT l |wS i ) wi EVT 3 Experimental Setup Data collections. We investigate our bootstrapping approach on the BLE task for 2 language pairs: Spanish-English (ES-EN) and Italian-English (ITEN), and work with the following corpora previously used by Vuli´c and Moens (2013): (i) a collection of 13,696 Spanish-English Wikipedia article pairs (Wiki-ES-EN), (ii) 18,898 Italian-English Wikipedia article pairs (Wiki-IT-EN).4 Following (Koehn and Knight, 2002; Haghighi et al., 2008; Prochasson and Fung, 2011; Vuli´c and Moens, 2013), we use TreeTagger (Schmid, 1994) for POS-tagging and lemmatization of the corpora, and then retain only nouns that occur at least 5 times in the corpus. We record the lemmatized form when available, and the original form otherwise. Our final vocabularies consist of 9,439 Spanish nouns and 4Vuli´c and Moens (2013) also worked with Dutch-English (NL-EN), but we have decided to leave out the results obtained for that language pair due to space constraints, high similarity between the two languages, and the fact that the results obtained for th</context>
<context position="40111" citStr="Haghighi et al., 2008" startWordPosition="6694" endWordPosition="6697">s from prior work, the initialization of the bilingual vector space is especially important. We have presented a novel approach to initializing the bootstrapping procedure, and have shown that better results in the BLE task are obtained by starting from seed lexicons that comprise highly reliable high-frequent translation pairs. The bootstrapping framework presented in the paper is completely language pair independent, which makes it effectively applicable to any language pair. In future work, we will investigate other models of similarity besides TopicBC and ResponseBC (e.g, the method from (Haghighi et al., 2008)) that could be used as preliminary models for constructing an initial bilingual vector space. Furthermore, we plan to study other confidence functions and explore if asymmetric translation candidates could also contribute to the bootstrapping method. Finally, we also plan to test the robustness of our fully corpus-based bootstrapping approach by porting it to more language pairs. Acknowledgments We would like to thank the anonymous reviewers for their useful suggestions. This research has been carried out in the framework of the TermWise Knowledge Platform (IOF-KP/09/001) funded by the Indust</context>
</contexts>
<marker>Haghighi, Liang, Berg-Kirkpatrick, Klein, 2008</marker>
<rawString>Aria Haghighi, Percy Liang, Taylor Berg-Kirkpatrick, and Dan Klein. 2008. Learning bilingual lexicons from monolingual corpora. In Proceedings of ACL, pages 771–779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruihong Huang</author>
<author>Ellen Riloff</author>
</authors>
<title>Bootstrapped training of event extraction classifiers.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>286--295</pages>
<contexts>
<context position="16458" citStr="Huang and Riloff, 2012" startWordPosition="2724" endWordPosition="2727"> constraint should ensure a relative reliability of translation pairs. In each iteration of the bootstrapping process, we may add all symmetric pairs from the pool of candidates as new dimensions, or we could impose additional selection criteria that quantify the degree of confidence in translation pairs. We are then able to rank the symmetric candidate translation pairs in the pool of candidates according to their confidence scores (step 3 of alg. 1), and choose only the best B candidates from the pool in each iteration (step 4) as done in (Thelen and Riloff, 2002; McIntosh and Curran, 2009; Huang and Riloff, 2012). By picking only a subset of the B most confident candidates in each iteration, we hope to further prevent a possibility of semantic drift, i.e., “poisoning” the bootstrapping process that might happen if we include incorrect translation pairs as dimensions of the space. In this paper, we investigate 3 different confidence estimation functions:3 (1) Absolute similarity score. Confidence of a translation pair CF(ws, TC(ws)) is simply the absolute similarity value sim(ws3 ,TC(ws)) (2) M-Best confidence function. It contrasts the score of the translation candidate with the average score over the</context>
</contexts>
<marker>Huang, Riloff, 2012</marker>
<rawString>Ruihong Huang and Ellen Riloff. 2012. Bootstrapped training of event extraction classifiers. In Proceedings of EACL, pages 286–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Azniah Ismail</author>
<author>Suresh Manandhar</author>
</authors>
<title>Bilingual lexicon extraction from comparable corpora using in-domain terms.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>481--489</pages>
<contexts>
<context position="8877" citStr="Ismail and Manandhar, 2010" startWordPosition="1422" endWordPosition="1425">heir representations in the N-dimensional bilingual vector space. The cross-lingual similarity is computed following the standard procedure (Gaussier et al., 2004): (1) For each source word wSi E V S, build its Ndimensional context vector cv(wSi ) that consists of association scores scSk (cSk), that is, we compute the strength of association with the “source” part of each dimension ck that constitutes the N-dimensional bilingual space. The association is dependent on the co-occurrence of wSi and cSk in a predefined context. Various functions such as the log-likelihood ratio (LLR) (Rapp, 1999; Ismail and Manandhar, 2010), TF-IDF (Fung and Yee, 1998), or pointwise mutual information (PMI) (Bullinaria and Levy, 2007; Shezaf and Rappoport, 2010) are typically used as weighting functions to quantify the strength of the association. (2) Repeat step (1) for each target word wTj E VT and build context vectors cv(wTj ) that consist of scores scTk (cTk ). (3) Since cSk and cTkaddress the same dimension ck in the bilingual vector space for each k = 1, ... , N, we are able to compute the similarity between cv(wSi ) and cv(wTj ) using any similarity measure such as the Jaccard index, the Kullback-Leibler or the Jensen-Sh</context>
</contexts>
<marker>Ismail, Manandhar, 2010</marker>
<rawString>Azniah Ismail and Suresh Manandhar. 2010. Bilingual lexicon extraction from comparable corpora using in-domain terms. In Proceedings of COLING, pages 481–489.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jun’ichi Kazama</author>
<author>Stijn De Saeger</author>
<author>Kow Kuroda</author>
<author>Masaki Murata</author>
<author>Kentaro Torisawa</author>
</authors>
<title>A Bayesian method for robust estimation of distributional similarities.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>247--256</pages>
<marker>Kazama, De Saeger, Kuroda, Murata, Torisawa, 2010</marker>
<rawString>Jun’ichi Kazama, Stijn De Saeger, Kow Kuroda, Masaki Murata, and Kentaro Torisawa. 2010. A Bayesian method for robust estimation of distributional similarities. In Proceedings of ACL, pages 247–256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL Workshop on Unsupervised Lexical Acquisition,</booktitle>
<pages>9--16</pages>
<contexts>
<context position="4620" citStr="Koehn and Knight, 2002" startWordPosition="737" endWordPosition="740">sume that there exist readily available bilingual lexicons that are then used to induce bilingual lexicons! Therefore, the focus of the researchers has turned to designing BLE methods that do not rely on any external translation resources such as machine-readable bilingual lexicons and parallel corpora (Haghighi et al., 2008; Vuli´c et al., 2011). In order to circumvent this issue, one line of recent work aims to bootstrap high-quality bilingual vector spaces from a small initial seed lexicon. The seed lexicon is constructed by harvesting identical or similarly spelled words across languages (Koehn and Knight, 2002; Peirsman and Pad´o, 2010), and it spans the initial bilingual vector space. The space is then gradually enriched with new dimensions/axes during the bootstrapping procedure. The bootstrapping process has already proven its validity in inducing bilingual lexicons for closely similar languages such as Spanish-Portuguese or Croatian-Slovene (Fiˇser and Ljubeˇsi´c, 2011), but it still lacks further generalization to more distant language pairs. The main goal of this paper is to shed new light on the bootstrapping approaches to bilingual lexicon extraction, and to construct a language pair agnost</context>
<context position="13364" citStr="Koehn and Knight, 2002" startWordPosition="2208" endWordPosition="2211">tializing a bootstrapping procedure is often a critical step regardless of the actual task (McIntosh and Curran, 2009; Kozareva and Hovy, 2010), and it decides whether the complete process will end as a success or a failure. However, Peirsman and Pad´o (2011) argue that the initialization step is not crucial when dealing with bootstrapping bilingual vector spaces. Here, we present two different strategies of initializing the bilingual vector space. Identical words and cognates. Previous work relies exclusively on identical and similarly spelled words to build the initial set of dimensions io (Koehn and Knight, 2002; Peirsman and Pad´o, 2010; Fiˇser and Ljubeˇsi´c, 2011). This strategy yields promising results for closely similar language pairs, but is of limited use for other language pairs. High-frequency seeds. Another problem with using only identical words and cognates as seeds lies in the fact that many of them might be infrequent in the corpus, and as a consequence the expressiveness of a bilingual vector space might be limited. On the other hand, high-frequency words offer a lot of evidence in the corpus that could be exploited in the bootstrapping approach. In order to induce initial translation</context>
<context position="18309" citStr="Koehn and Knight, 2002" startWordPosition="3022" endWordPosition="3025">k. First, we need to define a distribution: The confidence function is then minus the entropy of the probability distribution p: CF(wSi ,TC(wSi )) = � p(wTl |wSi ) log p(wT l |wS i ) wi EVT 3 Experimental Setup Data collections. We investigate our bootstrapping approach on the BLE task for 2 language pairs: Spanish-English (ES-EN) and Italian-English (ITEN), and work with the following corpora previously used by Vuli´c and Moens (2013): (i) a collection of 13,696 Spanish-English Wikipedia article pairs (Wiki-ES-EN), (ii) 18,898 Italian-English Wikipedia article pairs (Wiki-IT-EN).4 Following (Koehn and Knight, 2002; Haghighi et al., 2008; Prochasson and Fung, 2011; Vuli´c and Moens, 2013), we use TreeTagger (Schmid, 1994) for POS-tagging and lemmatization of the corpora, and then retain only nouns that occur at least 5 times in the corpus. We record the lemmatized form when available, and the original form otherwise. Our final vocabularies consist of 9,439 Spanish nouns and 4Vuli´c and Moens (2013) also worked with Dutch-English (NL-EN), but we have decided to leave out the results obtained for that language pair due to space constraints, high similarity between the two languages, and the fact that the </context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of the ACL Workshop on Unsupervised Lexical Acquisition, pages 9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zornitsa Kozareva</author>
<author>Eduard H Hovy</author>
</authors>
<title>Not all seeds are equal: Measuring the quality of text mining seeds.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>618--626</pages>
<contexts>
<context position="12885" citStr="Kozareva and Hovy, 2010" startWordPosition="2133" endWordPosition="2136">lity of the space to increase at each stage of the bootstrapping process, and newer translation pairs should be more confident than the older ones. For instance, if 2 out of N dimensions of a Spanish-English bilingual space are pairs (piedra,wall) and (tapia,stone), but then if during the bootstrapping process we extract a new candidate pair (piedra,stone), we will delete the former two dimensions and add the latter. 1615 2.2 Initializing Bilingual Vector Spaces Seeding or initializing a bootstrapping procedure is often a critical step regardless of the actual task (McIntosh and Curran, 2009; Kozareva and Hovy, 2010), and it decides whether the complete process will end as a success or a failure. However, Peirsman and Pad´o (2011) argue that the initialization step is not crucial when dealing with bootstrapping bilingual vector spaces. Here, we present two different strategies of initializing the bilingual vector space. Identical words and cognates. Previous work relies exclusively on identical and similarly spelled words to build the initial set of dimensions io (Koehn and Knight, 2002; Peirsman and Pad´o, 2010; Fiˇser and Ljubeˇsi´c, 2011). This strategy yields promising results for closely similar lang</context>
</contexts>
<marker>Kozareva, Hovy, 2010</marker>
<rawString>Zornitsa Kozareva and Eduard H. Hovy. 2010. Not all seeds are equal: Measuring the quality of text mining seeds. In Proceedings of NAACL-HLT, pages 618– 626.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Audrey Laroche</author>
<author>Philippe Langlais</author>
</authors>
<title>Revisiting context-based projection methods for term-translation spotting in comparable corpora.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>617--625</pages>
<contexts>
<context position="23357" citStr="Laroche and Langlais, 2010" startWordPosition="3850" endWordPosition="3853">ck-Leibler, Jensen-Shannon) (Lee, 1999; Turney and Pantel, 2010). In this paper, we present results obtained by positive pointwise mutual information (PPMI) (Niwa and Nitta, 1994) as a weighting function, which is a standard choice in vector space semantics (Turney and Pantel, 2010), and (combined with cosine) yields the best results over a group of semantic tasks according to (Bullinaria and Levy, 2007). We use a smoothed version of PPMI as presented in (Pantel and Lin, 2002; Turney and Pantel, 2010). Again, based on the results reported in the relevant literature (Bullinaria and Levy, 2007; Laroche and Langlais, 2010; Turney and Pantel, 2010), we opt for the cosine similarity as a standard choice for 5F. We have also experimented with different window sizes ranging from 3 to 15 in both directions around the pivot word, but we have not detected any major qualitative difference in the results and their interpretation. Therefore, all results reported in the paper are obtained by setting the window size to 6. 4 Results and Discussion 4.1 Are Seeds Important? In recent work, Peirsman and Pad´o (2010; 2011) report that “the size and quality of the (seed) lexicon are not of primary importance given that the boot</context>
</contexts>
<marker>Laroche, Langlais, 2010</marker>
<rawString>Audrey Laroche and Philippe Langlais. 2010. Revisiting context-based projection methods for term-translation spotting in comparable corpora. In Proceedings of COLING, pages 617–625.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victor Lavrenko</author>
<author>Martin Choquette</author>
<author>W Bruce Croft</author>
</authors>
<title>Cross-lingual relevance models.</title>
<date>2002</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>175--182</pages>
<contexts>
<context position="1331" citStr="Lavrenko et al., 2002" startWordPosition="197" endWordPosition="200"> spaces, and analyze the influence of the different components of the bootstrapping approach in the task of bilingual lexicon extraction (BLE) for two language pairs. Results reveal that, contrary to conclusions from prior work, the seeding of the bootstrapping process has a heavy impact on the quality of the learned lexicons. We also show that our approach outperforms the best performing fully corpus-based BLE methods on these test sets. 1 Introduction Bilingual lexicons serve as an indispensable source of knowledge for various cross-lingual tasks such as cross-lingual information retrieval (Lavrenko et al., 2002; Levow et al., 2005) or statistical machine translation (Och and Ney, 2003). Additionally, they are a crucial component in cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om</context>
</contexts>
<marker>Lavrenko, Choquette, Croft, 2002</marker>
<rawString>Victor Lavrenko, Martin Choquette, and W. Bruce Croft. 2002. Cross-lingual relevance models. In Proceedings of SIGIR, pages 175–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="3150" citStr="Lee, 1999" startWordPosition="503" endWordPosition="504">ures are typically words co-occurring with the word in a predefined context.1 The similarity of two words, wS1 given in the source language LS with vocabulary V S and wT2 in the target language LT with vocabulary VT is then computed as sim(wS1 , wT2 ) = 5F(cv(wS1 ), cv(wT2 )). cv(wS1 ) = [scS1 (c1), ... , scS1 (cN)] is a context vector for wS1 with N context features ck, where scS1 (ck) denotes the score for wS1 associated with context feature ck (similar for wT2 ). 5F is a similarity function (e.g., cosine, the Kullback-Leibler divergence, the Jaccard index) operating on the context vectors (Lee, 1999). When operating with 2 languages, the context features cannot be compared directly. Therefore, in order to compare the feature vectors cv(wS1 ) and cv(wT2 ), the context features need to span a shared 1The context may be a document, a paragraph, a window of predefined size around each occurrence of wS� in CS, etc. For an overview, see, e.g., (Tamura et al., 2012). 1613 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1613–1624, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics bilingual vector space. The</context>
<context position="9535" citStr="Lee, 1999" startWordPosition="1540" endWordPosition="1541">l information (PMI) (Bullinaria and Levy, 2007; Shezaf and Rappoport, 2010) are typically used as weighting functions to quantify the strength of the association. (2) Repeat step (1) for each target word wTj E VT and build context vectors cv(wTj ) that consist of scores scTk (cTk ). (3) Since cSk and cTkaddress the same dimension ck in the bilingual vector space for each k = 1, ... , N, we are able to compute the similarity between cv(wSi ) and cv(wTj ) using any similarity measure such as the Jaccard index, the Kullback-Leibler or the Jensen-Shannon divergence, the cosine measure, or others (Lee, 1999; Cha, 2007). The similarity score for two words wSi and wTj is sim(wSi , wTj ). For each source word wSi , we can build a ranked list RL(wSi ) that consists of all words wTj E V T ranked according to their respective similarity scores sim(wSi , wTj ). In the similar fashion, we can build a ranked list RL(wTj ), for each target word wT j . We call the top scoring target word wTj for some source word wSi its translation candidate, and write TC(wSi ) = wTj . Additionally, we label the ranked list RL(wSi ) that is pruned at position M as RLM(wSi ). Bootstrapping. The key idea of the bootstrapping</context>
<context position="22769" citStr="Lee, 1999" startWordPosition="3756" endWordPosition="3757">imilarity as a black box to acquire seeds for the bootstrapping approach, but we encourage the interested reader to find more details about the methods in the relevant literature. These two models also serve as our baseline models, and our goal is to test whether we are able to obtain bilingual lexicons of higher quality using bootstrapping that starts from the output of these models. Weighting and similarity functions. We have experimented with different families of weighting (e.g., PMI, LLR, TF-IDF, chi-square) and similarity functions (e.g., cosine, Dice, Kullback-Leibler, Jensen-Shannon) (Lee, 1999; Turney and Pantel, 2010). In this paper, we present results obtained by positive pointwise mutual information (PPMI) (Niwa and Nitta, 1994) as a weighting function, which is a standard choice in vector space semantics (Turney and Pantel, 2010), and (combined with cosine) yields the best results over a group of semantic tasks according to (Bullinaria and Levy, 2007). We use a smoothed version of PPMI as presented in (Pantel and Lin, 2002; Turney and Pantel, 2010). Again, based on the results reported in the relevant literature (Bullinaria and Levy, 2007; Laroche and Langlais, 2010; Turney and</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>Lillian Lee. 1999. Measures of distributional similarity. In Proceedings of ACL, pages 25–32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gina-Anne Levow</author>
<author>Douglas W Oard</author>
<author>Philip Resnik</author>
</authors>
<title>Dictionary-based techniques for cross-language information retrieval.</title>
<date>2005</date>
<booktitle>Information Processing and Management,</booktitle>
<pages>41--3</pages>
<contexts>
<context position="1352" citStr="Levow et al., 2005" startWordPosition="201" endWordPosition="204">e influence of the different components of the bootstrapping approach in the task of bilingual lexicon extraction (BLE) for two language pairs. Results reveal that, contrary to conclusions from prior work, the seeding of the bootstrapping process has a heavy impact on the quality of the learned lexicons. We also show that our approach outperforms the best performing fully corpus-based BLE methods on these test sets. 1 Introduction Bilingual lexicons serve as an indispensable source of knowledge for various cross-lingual tasks such as cross-lingual information retrieval (Lavrenko et al., 2002; Levow et al., 2005) or statistical machine translation (Och and Ney, 2003). Additionally, they are a crucial component in cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc.</context>
</contexts>
<marker>Levow, Oard, Resnik, 2005</marker>
<rawString>Gina-Anne Levow, Douglas W. Oard, and Philip Resnik. 2005. Dictionary-based techniques for cross-language information retrieval. Information Processing and Management, 41(3):523–547.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tara McIntosh</author>
<author>James R Curran</author>
</authors>
<title>Reducing semantic drift with bagging and distributional similarity.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>396--404</pages>
<contexts>
<context position="12859" citStr="McIntosh and Curran, 2009" startWordPosition="2129" endWordPosition="2132"> that we expect for the quality of the space to increase at each stage of the bootstrapping process, and newer translation pairs should be more confident than the older ones. For instance, if 2 out of N dimensions of a Spanish-English bilingual space are pairs (piedra,wall) and (tapia,stone), but then if during the bootstrapping process we extract a new candidate pair (piedra,stone), we will delete the former two dimensions and add the latter. 1615 2.2 Initializing Bilingual Vector Spaces Seeding or initializing a bootstrapping procedure is often a critical step regardless of the actual task (McIntosh and Curran, 2009; Kozareva and Hovy, 2010), and it decides whether the complete process will end as a success or a failure. However, Peirsman and Pad´o (2011) argue that the initialization step is not crucial when dealing with bootstrapping bilingual vector spaces. Here, we present two different strategies of initializing the bilingual vector space. Identical words and cognates. Previous work relies exclusively on identical and similarly spelled words to build the initial set of dimensions io (Koehn and Knight, 2002; Peirsman and Pad´o, 2010; Fiˇser and Ljubeˇsi´c, 2011). This strategy yields promising result</context>
<context position="15447" citStr="McIntosh and Curran, 2009" startWordPosition="2547" endWordPosition="2550"> corpus and use a subset of the most 2One can also use other models that are similar to MuPTM such as (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) to produce the initial seed lexicon, but that analysis is beyond the scope of this work. frequent symmetric pairs as seeds. 2.3 Estimating Confidence of New Dimensions Another crucial step in the bootstrapping procedure is the estimation of confidence in a translation pair/candidate dimension. Errors in the early stages of the procedure may negatively affect the learning process and even cause semantic drift (Riloff and Shepherd, 1999; McIntosh and Curran, 2009). We therefore impose the constraint which requires translation pairs to be symmetric in order to qualify as potential new dimensions of the space. In other words, given the current set of dimensions is, a translation pair (ws, w�) has a possibility to be chosen as a new dimension from the pool of candidate dimensions if and only if it holds: TC(ws) =w� and TC(w�� ) = ws. This symmetry constraint should ensure a relative reliability of translation pairs. In each iteration of the bootstrapping process, we may add all symmetric pairs from the pool of candidates as new dimensions, or we could imp</context>
</contexts>
<marker>McIntosh, Curran, 2009</marker>
<rawString>Tara McIntosh and James R. Curran. 2009. Reducing semantic drift with bagging and distributional similarity. In Proceedings of ACL, pages 396–404.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Dan Melamed</author>
</authors>
<title>Models of translational equivalence among words.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>2</issue>
<contexts>
<context position="7690" citStr="Melamed, 2000" startWordPosition="1228" endWordPosition="1229">l Framework We assume that we are solely in possession of a (non-parallel) bilingual corpus C that is composed of a sub-corpus CS given in the source language LS, and a sub-corpus CT in the target language LT. All word types that occur in CS constitute a set V S. All word types in CT constitute a set VT. The goal is to build a bilingual vector space using only corpus C. Assumption 1. Dimensions of the bilingual vector space are one-to-one word translation pairs. For instance, dimensions of a Spanish-English space are pairs like (perro, dog), (ciencia, science), etc. The one-to-one constraint (Melamed, 2000), although not valid in general, simplifies the construction of the bootstrapping procedure. i denotes the set of translation pairs that are the dimensions of the space. Computing cross-lingual word similarity in a bilingual vector space. Now, assume that our bilingual vector space consists of N one-to-one word translation pairs ck = (cSk, cTk ), k = 1, ... , N. For each word wSi E V S, we compute the similarity of 1614 that word with each word wTj E V T by computing the similarity between their context vectors cv(wSi ) and cv(wTj ), which are actually their representations in the N-dimensiona</context>
</contexts>
<marker>Melamed, 2000</marker>
<rawString>I. Dan Melamed. 2000. Models of translational equivalence among words. Computational Linguistics, 26(2):221–249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna M Wallach</author>
<author>Jason Naradowsky</author>
<author>David A Smith</author>
<author>Andrew McCallum</author>
</authors>
<title>Polylingual topic models.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>880--889</pages>
<contexts>
<context position="14121" citStr="Mimno et al., 2009" startWordPosition="2334" endWordPosition="2337"> of limited use for other language pairs. High-frequency seeds. Another problem with using only identical words and cognates as seeds lies in the fact that many of them might be infrequent in the corpus, and as a consequence the expressiveness of a bilingual vector space might be limited. On the other hand, high-frequency words offer a lot of evidence in the corpus that could be exploited in the bootstrapping approach. In order to induce initial translation pairs, we rely on the framework of multilingual probabilistic topic modeling (MuPTM) (BoydGraber and Blei, 2009; De Smet and Moens, 2009; Mimno et al., 2009; Zhang et al., 2010), that does not require a bilingual lexicon, it operates with nonparallel data, and is able to produce highly confident translation pairs for high-frequency words (Mimno et al., 2009; Vuli´c and Moens, 2013).2 Therefore, we can construct the initial seed lexicon as follows: (1) Train a multilingual topic model on the corpus. (2) Obtain one-to-one translation pairs using any of the MuPTM-based models of cross-lingual similarity, e.g., (Vuli´c et al., 2011; Vuli´c and Moens, 2013). (3) Retain only symmetric translation pairs. This step ensures that only highly confident pair</context>
<context position="20472" citStr="Mimno et al., 2009" startWordPosition="3377" endWordPosition="3380">n the BLE task using a standard Top M accuracy (AccM) metric. It denotes the number of source words ws from ground truth translation pairs whose list RLM(ws ) contains the correct translation according to our ground truth over the total number of ground truth translation pairs (=1000) (Gaussier et al., 2004; Tamura et al., 2012).5 Additionally, we report the mean reciprocal rank (MRR) scores (Voorhees, 1999) for some experimental runs. Multilingual topic model. We utilize a straightforward multilingual extension of the standard Blei et al.’s LDA model (Blei et al., 2003) called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). BiLDA training follows the procedure from (Vuli´c and Moens, 2013), that is, the training method is Gibbs sampling with the number of topics set to K = 2000. Hyperparameters of the model are set to standard values (Steyvers and Griffiths, 2007): α = 50/K and Q = 0.01. Building initial seed lexicons. To produce the lists of one-to-one translation pairs that are used as seeds for the bootstrapping approach (see sect. 2.2), we experiment with the TopicBC and the ResponseBC methods from (Vuli´c and Moens, 2013), which are the MuPTM-based models of cross</context>
</contexts>
<marker>Mimno, Wallach, Naradowsky, Smith, McCallum, 2009</marker>
<rawString>David Mimno, Hanna M. Wallach, Jason Naradowsky, David A. Smith, and Andrew McCallum. 2009. Polylingual topic models. In Proceedings of EMNLP, pages 880–889.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaochuan Ni</author>
<author>Jian-Tao Sun</author>
<author>Jian Hu</author>
<author>Zheng Chen</author>
</authors>
<title>Mining multilingual topics from Wikipedia.</title>
<date>2009</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>1155--1156</pages>
<contexts>
<context position="20489" citStr="Ni et al., 2009" startWordPosition="3381" endWordPosition="3384"> a standard Top M accuracy (AccM) metric. It denotes the number of source words ws from ground truth translation pairs whose list RLM(ws ) contains the correct translation according to our ground truth over the total number of ground truth translation pairs (=1000) (Gaussier et al., 2004; Tamura et al., 2012).5 Additionally, we report the mean reciprocal rank (MRR) scores (Voorhees, 1999) for some experimental runs. Multilingual topic model. We utilize a straightforward multilingual extension of the standard Blei et al.’s LDA model (Blei et al., 2003) called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). BiLDA training follows the procedure from (Vuli´c and Moens, 2013), that is, the training method is Gibbs sampling with the number of topics set to K = 2000. Hyperparameters of the model are set to standard values (Steyvers and Griffiths, 2007): α = 50/K and Q = 0.01. Building initial seed lexicons. To produce the lists of one-to-one translation pairs that are used as seeds for the bootstrapping approach (see sect. 2.2), we experiment with the TopicBC and the ResponseBC methods from (Vuli´c and Moens, 2013), which are the MuPTM-based models of cross-lingual semantic</context>
</contexts>
<marker>Ni, Sun, Hu, Chen, 2009</marker>
<rawString>Xiaochuan Ni, Jian-Tao Sun, Jian Hu, and Zheng Chen. 2009. Mining multilingual topics from Wikipedia. In Proceedings of WWW, pages 1155–1156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshiki Niwa</author>
<author>Yoshihiko Nitta</author>
</authors>
<title>Co-occurrence vectors from corpora vs. distance vectors from dictionaries.</title>
<date>1994</date>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>304--309</pages>
<contexts>
<context position="22910" citStr="Niwa and Nitta, 1994" startWordPosition="3775" endWordPosition="3778">ails about the methods in the relevant literature. These two models also serve as our baseline models, and our goal is to test whether we are able to obtain bilingual lexicons of higher quality using bootstrapping that starts from the output of these models. Weighting and similarity functions. We have experimented with different families of weighting (e.g., PMI, LLR, TF-IDF, chi-square) and similarity functions (e.g., cosine, Dice, Kullback-Leibler, Jensen-Shannon) (Lee, 1999; Turney and Pantel, 2010). In this paper, we present results obtained by positive pointwise mutual information (PPMI) (Niwa and Nitta, 1994) as a weighting function, which is a standard choice in vector space semantics (Turney and Pantel, 2010), and (combined with cosine) yields the best results over a group of semantic tasks according to (Bullinaria and Levy, 2007). We use a smoothed version of PPMI as presented in (Pantel and Lin, 2002; Turney and Pantel, 2010). Again, based on the results reported in the relevant literature (Bullinaria and Levy, 2007; Laroche and Langlais, 2010; Turney and Pantel, 2010), we opt for the cosine similarity as a standard choice for 5F. We have also experimented with different window sizes ranging f</context>
</contexts>
<marker>Niwa, Nitta, 1994</marker>
<rawString>Yoshiki Niwa and Yoshihiko Nitta. 1994. Co-occurrence vectors from corpora vs. distance vectors from dictionaries. In Proceedings of COLING, pages 304–309.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="1407" citStr="Och and Ney, 2003" startWordPosition="209" endWordPosition="212">ping approach in the task of bilingual lexicon extraction (BLE) for two language pairs. Results reveal that, contrary to conclusions from prior work, the seeding of the bootstrapping process has a heavy impact on the quality of the learned lexicons. We also show that our approach outperforms the best performing fully corpus-based BLE methods on these test sets. 1 Introduction Bilingual lexicons serve as an indispensable source of knowledge for various cross-lingual tasks such as cross-lingual information retrieval (Lavrenko et al., 2002; Levow et al., 2005) or statistical machine translation (Och and Ney, 2003). Additionally, they are a crucial component in cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc. Techniques for automatic bilingual lexicon extraction </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Pad´o</author>
<author>Mirella Lapata</author>
</authors>
<title>Cross-lingual annotation projection for semantic roles.</title>
<date>2009</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>36--307</pages>
<marker>Pad´o, Lapata, 2009</marker>
<rawString>Sebastian Pad´o and Mirella Lapata. 2009. Cross-lingual annotation projection for semantic roles. Journal of Artificial Intelligence Research, 36:307–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering word senses from text.</title>
<date>2002</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>613--619</pages>
<contexts>
<context position="23211" citStr="Pantel and Lin, 2002" startWordPosition="3828" endWordPosition="3831"> experimented with different families of weighting (e.g., PMI, LLR, TF-IDF, chi-square) and similarity functions (e.g., cosine, Dice, Kullback-Leibler, Jensen-Shannon) (Lee, 1999; Turney and Pantel, 2010). In this paper, we present results obtained by positive pointwise mutual information (PPMI) (Niwa and Nitta, 1994) as a weighting function, which is a standard choice in vector space semantics (Turney and Pantel, 2010), and (combined with cosine) yields the best results over a group of semantic tasks according to (Bullinaria and Levy, 2007). We use a smoothed version of PPMI as presented in (Pantel and Lin, 2002; Turney and Pantel, 2010). Again, based on the results reported in the relevant literature (Bullinaria and Levy, 2007; Laroche and Langlais, 2010; Turney and Pantel, 2010), we opt for the cosine similarity as a standard choice for 5F. We have also experimented with different window sizes ranging from 3 to 15 in both directions around the pivot word, but we have not detected any major qualitative difference in the results and their interpretation. Therefore, all results reported in the paper are obtained by setting the window size to 6. 4 Results and Discussion 4.1 Are Seeds Important? In rece</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel and Dekang Lin. 2002. Discovering word senses from text. In Proceedings of KDD, pages 613– 619.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Peirsman</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Crosslingual induction of selectional preferences with bilingual vector spaces.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>921--929</pages>
<marker>Peirsman, Pad´o, 2010</marker>
<rawString>Yves Peirsman and Sebastian Pad´o. 2010. Crosslingual induction of selectional preferences with bilingual vector spaces. In Proceedings of NAACL-HLT, pages 921–929.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Peirsman</author>
<author>Sebastian Pad´o</author>
</authors>
<title>Semantic relations in bilingual lexicons.</title>
<date>2011</date>
<journal>ACM Transactions on Speech and Language Processing,</journal>
<volume>8</volume>
<issue>2</issue>
<pages>3</pages>
<marker>Peirsman, Pad´o, 2011</marker>
<rawString>Yves Peirsman and Sebastian Pad´o. 2011. Semantic relations in bilingual lexicons. ACM Transactions on Speech and Language Processing, 8(2):article 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viktor Pekar</author>
<author>Ruslan Mitkov</author>
<author>Dimitar Blagoev</author>
<author>Andrea Mulloni</author>
</authors>
<title>Finding translations for lowfrequency words in comparable corpora.</title>
<date>2006</date>
<journal>Machine Translation,</journal>
<volume>20</volume>
<issue>4</issue>
<contexts>
<context position="30972" citStr="Pekar et al., 2006" startWordPosition="5191" endWordPosition="5194">in observe several interesting phenomena: (i) High-frequency seed translation pairs are better seeds, and that finding is in line with our hypothesis. Although the bootstrapping approach again displays a positive trend regardless of the actual choice of seeds (we observe an increase even when using LFSEED), high-frequency seeds lead to better overall results in the BLE task. Besides its high presence in contexts of other words, another advantage of highfrequency seed pairs is the fact that an initial similarity method will typically acquire more reliable translation candidates for such words (Pekar et al., 2006). For instance, 89.5% of ES-EN pairs in HFSEED are correct one-to-one translations, compared to 65.1% in MF-SEED, and 44.3% in LF-SEED. (ii) The difference in results between HF-SEED and MF-SEED is more visible in Acci scores. Although both seed lexicons for all test words provide ranked lists which contain words that exhibit some semantic relation to the given word, the reliability and the frequency of translation pairs are especially important for detecting the relation of cross-lingual word synonymy, that is, the translational equivalence that is exploited in building one-to-one bilingual l</context>
</contexts>
<marker>Pekar, Mitkov, Blagoev, Mulloni, 2006</marker>
<rawString>Viktor Pekar, Ruslan Mitkov, Dimitar Blagoev, and Andrea Mulloni. 2006. Finding translations for lowfrequency words in comparable corpora. Machine Translation, 20(4):247–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emmanuel Prochasson</author>
<author>Pascale Fung</author>
</authors>
<title>Rare word translation extraction from aligned comparable documents.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>1327--1335</pages>
<contexts>
<context position="18359" citStr="Prochasson and Fung, 2011" startWordPosition="3030" endWordPosition="3033"> confidence function is then minus the entropy of the probability distribution p: CF(wSi ,TC(wSi )) = � p(wTl |wSi ) log p(wT l |wS i ) wi EVT 3 Experimental Setup Data collections. We investigate our bootstrapping approach on the BLE task for 2 language pairs: Spanish-English (ES-EN) and Italian-English (ITEN), and work with the following corpora previously used by Vuli´c and Moens (2013): (i) a collection of 13,696 Spanish-English Wikipedia article pairs (Wiki-ES-EN), (ii) 18,898 Italian-English Wikipedia article pairs (Wiki-IT-EN).4 Following (Koehn and Knight, 2002; Haghighi et al., 2008; Prochasson and Fung, 2011; Vuli´c and Moens, 2013), we use TreeTagger (Schmid, 1994) for POS-tagging and lemmatization of the corpora, and then retain only nouns that occur at least 5 times in the corpus. We record the lemmatized form when available, and the original form otherwise. Our final vocabularies consist of 9,439 Spanish nouns and 4Vuli´c and Moens (2013) also worked with Dutch-English (NL-EN), but we have decided to leave out the results obtained for that language pair due to space constraints, high similarity between the two languages, and the fact that the results obtained for that language pair are qualit</context>
</contexts>
<marker>Prochasson, Fung, 2011</marker>
<rawString>Emmanuel Prochasson and Pascale Fung. 2011. Rare word translation extraction from aligned comparable documents. In Proceedings ofACL, pages 1327–1335.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated English and German corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>519--526</pages>
<contexts>
<context position="2332" citStr="Rapp (1999)" startWordPosition="358" endWordPosition="359">abeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc. Techniques for automatic bilingual lexicon extraction (BLE) from parallel corpora on the basis of word alignment models are well established (Och and Ney, 2003). However, due to a relative scarceness of parallel data for many language pairs and domains, alternative approaches that rely on comparable corpora have also gained much interest (e.g., Fung and Yee (1998); Rapp (1999)). The models that rely on non-parallel data typically represent each word by a high-dimensional vector in a feature vector space, where the dimensions of the vector are its context features. The context features are typically words co-occurring with the word in a predefined context.1 The similarity of two words, wS1 given in the source language LS with vocabulary V S and wT2 in the target language LT with vocabulary VT is then computed as sim(wS1 , wT2 ) = 5F(cv(wS1 ), cv(wT2 )). cv(wS1 ) = [scS1 (c1), ... , scS1 (cN)] is a context vector for wS1 with N context features ck, where scS1 (ck) de</context>
<context position="3848" citStr="Rapp, 1999" startWordPosition="615" endWordPosition="616">refore, in order to compare the feature vectors cv(wS1 ) and cv(wT2 ), the context features need to span a shared 1The context may be a document, a paragraph, a window of predefined size around each occurrence of wS� in CS, etc. For an overview, see, e.g., (Tamura et al., 2012). 1613 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1613–1624, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics bilingual vector space. The standard way of building a bilingual vector space is to use bilingual lexicon entries (Rapp, 1999; Fung and Cheung, 2004; Gaussier et al., 2004) as dimensions of the space. However, there seems to be an apparent flaw in logic, since the methods assume that there exist readily available bilingual lexicons that are then used to induce bilingual lexicons! Therefore, the focus of the researchers has turned to designing BLE methods that do not rely on any external translation resources such as machine-readable bilingual lexicons and parallel corpora (Haghighi et al., 2008; Vuli´c et al., 2011). In order to circumvent this issue, one line of recent work aims to bootstrap high-quality bilingual </context>
<context position="8848" citStr="Rapp, 1999" startWordPosition="1420" endWordPosition="1421">e actually their representations in the N-dimensional bilingual vector space. The cross-lingual similarity is computed following the standard procedure (Gaussier et al., 2004): (1) For each source word wSi E V S, build its Ndimensional context vector cv(wSi ) that consists of association scores scSk (cSk), that is, we compute the strength of association with the “source” part of each dimension ck that constitutes the N-dimensional bilingual space. The association is dependent on the co-occurrence of wSi and cSk in a predefined context. Various functions such as the log-likelihood ratio (LLR) (Rapp, 1999; Ismail and Manandhar, 2010), TF-IDF (Fung and Yee, 1998), or pointwise mutual information (PMI) (Bullinaria and Levy, 2007; Shezaf and Rappoport, 2010) are typically used as weighting functions to quantify the strength of the association. (2) Repeat step (1) for each target word wTj E VT and build context vectors cv(wTj ) that consist of scores scTk (cTk ). (3) Since cSk and cTkaddress the same dimension ck in the bilingual vector space for each k = 1, ... , N, we are able to compute the similarity between cv(wSi ) and cv(wTj ) using any similarity measure such as the Jaccard index, the Kull</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated English and German corpora. In Proceedings of ACL, pages 519–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Jessica Shepherd</author>
</authors>
<title>A corpus-based bootstrapping algorithm for semi-automated semantic lexicon construction.</title>
<date>1999</date>
<journal>Natural Language Engineering,</journal>
<volume>5</volume>
<issue>2</issue>
<contexts>
<context position="15419" citStr="Riloff and Shepherd, 1999" startWordPosition="2543" endWordPosition="2546">g to their frequency in the corpus and use a subset of the most 2One can also use other models that are similar to MuPTM such as (Haghighi et al., 2008; Daum´e III and Jagarlamudi, 2011) to produce the initial seed lexicon, but that analysis is beyond the scope of this work. frequent symmetric pairs as seeds. 2.3 Estimating Confidence of New Dimensions Another crucial step in the bootstrapping procedure is the estimation of confidence in a translation pair/candidate dimension. Errors in the early stages of the procedure may negatively affect the learning process and even cause semantic drift (Riloff and Shepherd, 1999; McIntosh and Curran, 2009). We therefore impose the constraint which requires translation pairs to be symmetric in order to qualify as potential new dimensions of the space. In other words, given the current set of dimensions is, a translation pair (ws, w�) has a possibility to be chosen as a new dimension from the pool of candidate dimensions if and only if it holds: TC(ws) =w� and TC(w�� ) = ws. This symmetry constraint should ensure a relative reliability of translation pairs. In each iteration of the bootstrapping process, we may add all symmetric pairs from the pool of candidates as new</context>
</contexts>
<marker>Riloff, Shepherd, 1999</marker>
<rawString>Ellen Riloff and Jessica Shepherd. 1999. A corpus-based bootstrapping algorithm for semi-automated semantic lexicon construction. Natural Language Engineering, 5(2):147–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Helmut Schmid</author>
</authors>
<title>Probabilistic part-of-speech tagging using decision trees.</title>
<date>1994</date>
<booktitle>In International Conference on New Methods in Language Processing.</booktitle>
<contexts>
<context position="18418" citStr="Schmid, 1994" startWordPosition="3041" endWordPosition="3042">ibution p: CF(wSi ,TC(wSi )) = � p(wTl |wSi ) log p(wT l |wS i ) wi EVT 3 Experimental Setup Data collections. We investigate our bootstrapping approach on the BLE task for 2 language pairs: Spanish-English (ES-EN) and Italian-English (ITEN), and work with the following corpora previously used by Vuli´c and Moens (2013): (i) a collection of 13,696 Spanish-English Wikipedia article pairs (Wiki-ES-EN), (ii) 18,898 Italian-English Wikipedia article pairs (Wiki-IT-EN).4 Following (Koehn and Knight, 2002; Haghighi et al., 2008; Prochasson and Fung, 2011; Vuli´c and Moens, 2013), we use TreeTagger (Schmid, 1994) for POS-tagging and lemmatization of the corpora, and then retain only nouns that occur at least 5 times in the corpus. We record the lemmatized form when available, and the original form otherwise. Our final vocabularies consist of 9,439 Spanish nouns and 4Vuli´c and Moens (2013) also worked with Dutch-English (NL-EN), but we have decided to leave out the results obtained for that language pair due to space constraints, high similarity between the two languages, and the fact that the results obtained for that language pair are qualitatively similar to the results we report for ES-EN and IT-E</context>
</contexts>
<marker>Schmid, 1994</marker>
<rawString>Helmut Schmid. 1994. Probabilistic part-of-speech tagging using decision trees. In International Conference on New Methods in Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daphna Shezaf</author>
<author>Ari Rappoport</author>
</authors>
<title>Bilingual lexicon generation using non-aligned signatures.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>98--107</pages>
<contexts>
<context position="9001" citStr="Shezaf and Rappoport, 2010" startWordPosition="1441" endWordPosition="1444">ndard procedure (Gaussier et al., 2004): (1) For each source word wSi E V S, build its Ndimensional context vector cv(wSi ) that consists of association scores scSk (cSk), that is, we compute the strength of association with the “source” part of each dimension ck that constitutes the N-dimensional bilingual space. The association is dependent on the co-occurrence of wSi and cSk in a predefined context. Various functions such as the log-likelihood ratio (LLR) (Rapp, 1999; Ismail and Manandhar, 2010), TF-IDF (Fung and Yee, 1998), or pointwise mutual information (PMI) (Bullinaria and Levy, 2007; Shezaf and Rappoport, 2010) are typically used as weighting functions to quantify the strength of the association. (2) Repeat step (1) for each target word wTj E VT and build context vectors cv(wTj ) that consist of scores scTk (cTk ). (3) Since cSk and cTkaddress the same dimension ck in the bilingual vector space for each k = 1, ... , N, we are able to compute the similarity between cv(wSi ) and cv(wTj ) using any similarity measure such as the Jaccard index, the Kullback-Leibler or the Jensen-Shannon divergence, the cosine measure, or others (Lee, 1999; Cha, 2007). The similarity score for two words wSi and wTj is si</context>
</contexts>
<marker>Shezaf, Rappoport, 2010</marker>
<rawString>Daphna Shezaf and Ari Rappoport. 2010. Bilingual lexicon generation using non-aligned signatures. In Proceedings of ACL, pages 98–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Bootstrapping feature-rich dependency parsers with entropic priors.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>667--677</pages>
<contexts>
<context position="17641" citStr="Smith and Eisner, 2007" startWordPosition="2915" endWordPosition="2918">ndidate with the average score over the first M most similar words in the ranked list. The larger the difference, the more confidence we have in the translation candidate. Given a word ws E Vs and a ranked list RLM(ws), the 3A symmetrized version of the confidence functions is computed as the geometric mean of source-to-target and target-tosource confidence scores. 1616 average score of the best M words is computed as: The final confidence score is then: CF(wSi ,TC(wSi )) = sim(wSi ,TC(wSi )) − simM(wSi ) (3) Entropy-based confidence function. We adapt the well-known entropy-based confidence (Smith and Eisner, 2007; Tu and Honavar, 2012) to this particular task. First, we need to define a distribution: The confidence function is then minus the entropy of the probability distribution p: CF(wSi ,TC(wSi )) = � p(wTl |wSi ) log p(wT l |wS i ) wi EVT 3 Experimental Setup Data collections. We investigate our bootstrapping approach on the BLE task for 2 language pairs: Spanish-English (ES-EN) and Italian-English (ITEN), and work with the following corpora previously used by Vuli´c and Moens (2013): (i) a collection of 13,696 Spanish-English Wikipedia article pairs (Wiki-ES-EN), (ii) 18,898 Italian-English Wiki</context>
</contexts>
<marker>Smith, Eisner, 2007</marker>
<rawString>David A. Smith and Jason Eisner. 2007. Bootstrapping feature-rich dependency parsers with entropic priors. In Proceedings of EMNLP-CoNLL, pages 667–677.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steyvers</author>
<author>Tom Griffiths</author>
</authors>
<date>2007</date>
<booktitle>Probabilistic topic models. Handbook of Latent Semantic Analysis,</booktitle>
<pages>427--7</pages>
<contexts>
<context position="20761" citStr="Steyvers and Griffiths, 2007" startWordPosition="3428" endWordPosition="3432">(=1000) (Gaussier et al., 2004; Tamura et al., 2012).5 Additionally, we report the mean reciprocal rank (MRR) scores (Voorhees, 1999) for some experimental runs. Multilingual topic model. We utilize a straightforward multilingual extension of the standard Blei et al.’s LDA model (Blei et al., 2003) called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). BiLDA training follows the procedure from (Vuli´c and Moens, 2013), that is, the training method is Gibbs sampling with the number of topics set to K = 2000. Hyperparameters of the model are set to standard values (Steyvers and Griffiths, 2007): α = 50/K and Q = 0.01. Building initial seed lexicons. To produce the lists of one-to-one translation pairs that are used as seeds for the bootstrapping approach (see sect. 2.2), we experiment with the TopicBC and the ResponseBC methods from (Vuli´c and Moens, 2013), which are the MuPTM-based models of cross-lingual semantic similarity that obtain the best results in the BLE task on these datasets. In short, the TopicBC method computes the similarity of two words according to the similarity of their conditional topic distributions (Griffiths et al., 2007; Vuli´c et al., 2011) using 5We can b</context>
</contexts>
<marker>Steyvers, Griffiths, 2007</marker>
<rawString>Mark Steyvers and Tom Griffiths. 2007. Probabilistic topic models. Handbook of Latent Semantic Analysis, 427(7):424–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<journal>Transactions of ACL,</journal>
<pages>1--1</pages>
<marker>T¨ackstr¨om, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013a. Token and type constraints for cross-lingual part-of-speech tagging. Transactions of ACL, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar T¨ackstr¨om</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Target language adaptation of discriminative transfer parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>1061--1071</pages>
<marker>T¨ackstr¨om, McDonald, Nivre, 2013</marker>
<rawString>Oscar T¨ackstr¨om, Ryan McDonald, and Joakim Nivre. 2013b. Target language adaptation of discriminative transfer parsers. In Proceedings of NAACL-HLT, pages 1061–1071.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akihiro Tamura</author>
<author>Taro Watanabe</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Bilingual lexicon extraction from comparable corpora using label propagation.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>24--36</pages>
<contexts>
<context position="3516" citStr="Tamura et al., 2012" startWordPosition="565" endWordPosition="568">text features ck, where scS1 (ck) denotes the score for wS1 associated with context feature ck (similar for wT2 ). 5F is a similarity function (e.g., cosine, the Kullback-Leibler divergence, the Jaccard index) operating on the context vectors (Lee, 1999). When operating with 2 languages, the context features cannot be compared directly. Therefore, in order to compare the feature vectors cv(wS1 ) and cv(wT2 ), the context features need to span a shared 1The context may be a document, a paragraph, a window of predefined size around each occurrence of wS� in CS, etc. For an overview, see, e.g., (Tamura et al., 2012). 1613 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1613–1624, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics bilingual vector space. The standard way of building a bilingual vector space is to use bilingual lexicon entries (Rapp, 1999; Fung and Cheung, 2004; Gaussier et al., 2004) as dimensions of the space. However, there seems to be an apparent flaw in logic, since the methods assume that there exist readily available bilingual lexicons that are then used to induce bilingual lexicons! Therefore,</context>
<context position="20184" citStr="Tamura et al., 2012" startWordPosition="3333" endWordPosition="3336">). Note that we do not explicitly test the bilingual vector space as a bilingual lexicon, but rather its ability to find semantically similar words and translations also for words that are not used as dimensions of the space (see sect. 2.1). Evaluation metrics. We measure the performance on the BLE task using a standard Top M accuracy (AccM) metric. It denotes the number of source words ws from ground truth translation pairs whose list RLM(ws ) contains the correct translation according to our ground truth over the total number of ground truth translation pairs (=1000) (Gaussier et al., 2004; Tamura et al., 2012).5 Additionally, we report the mean reciprocal rank (MRR) scores (Voorhees, 1999) for some experimental runs. Multilingual topic model. We utilize a straightforward multilingual extension of the standard Blei et al.’s LDA model (Blei et al., 2003) called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). BiLDA training follows the procedure from (Vuli´c and Moens, 2013), that is, the training method is Gibbs sampling with the number of topics set to K = 2000. Hyperparameters of the model are set to standard values (Steyvers and Griffiths, 2007): α = 50/K and Q = 0.01</context>
</contexts>
<marker>Tamura, Watanabe, Sumita, 2012</marker>
<rawString>Akihiro Tamura, Taro Watanabe, and Eiichiro Sumita. 2012. Bilingual lexicon extraction from comparable corpora using label propagation. In Proceedings of EMNLP-CoNLL, pages 24–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Thelen</author>
<author>Ellen Riloff</author>
</authors>
<title>A bootstrapping method for learning semantic lexicons using extraction pattern contexts.</title>
<date>2002</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>214--221</pages>
<contexts>
<context position="16406" citStr="Thelen and Riloff, 2002" startWordPosition="2716" endWordPosition="2719">t holds: TC(ws) =w� and TC(w�� ) = ws. This symmetry constraint should ensure a relative reliability of translation pairs. In each iteration of the bootstrapping process, we may add all symmetric pairs from the pool of candidates as new dimensions, or we could impose additional selection criteria that quantify the degree of confidence in translation pairs. We are then able to rank the symmetric candidate translation pairs in the pool of candidates according to their confidence scores (step 3 of alg. 1), and choose only the best B candidates from the pool in each iteration (step 4) as done in (Thelen and Riloff, 2002; McIntosh and Curran, 2009; Huang and Riloff, 2012). By picking only a subset of the B most confident candidates in each iteration, we hope to further prevent a possibility of semantic drift, i.e., “poisoning” the bootstrapping process that might happen if we include incorrect translation pairs as dimensions of the space. In this paper, we investigate 3 different confidence estimation functions:3 (1) Absolute similarity score. Confidence of a translation pair CF(ws, TC(ws)) is simply the absolute similarity value sim(ws3 ,TC(ws)) (2) M-Best confidence function. It contrasts the score of the t</context>
</contexts>
<marker>Thelen, Riloff, 2002</marker>
<rawString>Michael Thelen and Ellen Riloff. 2002. A bootstrapping method for learning semantic lexicons using extraction pattern contexts. In Proceedings of EMNLP, pages 214–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kewei Tu</author>
<author>Vasant Honavar</author>
</authors>
<title>Unambiguity regularization for unsupervised learning of probabilistic grammars.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>1324--1334</pages>
<contexts>
<context position="17664" citStr="Tu and Honavar, 2012" startWordPosition="2919" endWordPosition="2922"> score over the first M most similar words in the ranked list. The larger the difference, the more confidence we have in the translation candidate. Given a word ws E Vs and a ranked list RLM(ws), the 3A symmetrized version of the confidence functions is computed as the geometric mean of source-to-target and target-tosource confidence scores. 1616 average score of the best M words is computed as: The final confidence score is then: CF(wSi ,TC(wSi )) = sim(wSi ,TC(wSi )) − simM(wSi ) (3) Entropy-based confidence function. We adapt the well-known entropy-based confidence (Smith and Eisner, 2007; Tu and Honavar, 2012) to this particular task. First, we need to define a distribution: The confidence function is then minus the entropy of the probability distribution p: CF(wSi ,TC(wSi )) = � p(wTl |wSi ) log p(wT l |wS i ) wi EVT 3 Experimental Setup Data collections. We investigate our bootstrapping approach on the BLE task for 2 language pairs: Spanish-English (ES-EN) and Italian-English (ITEN), and work with the following corpora previously used by Vuli´c and Moens (2013): (i) a collection of 13,696 Spanish-English Wikipedia article pairs (Wiki-ES-EN), (ii) 18,898 Italian-English Wikipedia article pairs (Wi</context>
</contexts>
<marker>Tu, Honavar, 2012</marker>
<rawString>Kewei Tu and Vasant Honavar. 2012. Unambiguity regularization for unsupervised learning of probabilistic grammars. In Proceedings of EMNLP-CoNLL, pages 1324–1334.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artifical Intelligence Research,</journal>
<volume>37</volume>
<issue>1</issue>
<pages>188</pages>
<contexts>
<context position="22795" citStr="Turney and Pantel, 2010" startWordPosition="3758" endWordPosition="3761">s a black box to acquire seeds for the bootstrapping approach, but we encourage the interested reader to find more details about the methods in the relevant literature. These two models also serve as our baseline models, and our goal is to test whether we are able to obtain bilingual lexicons of higher quality using bootstrapping that starts from the output of these models. Weighting and similarity functions. We have experimented with different families of weighting (e.g., PMI, LLR, TF-IDF, chi-square) and similarity functions (e.g., cosine, Dice, Kullback-Leibler, Jensen-Shannon) (Lee, 1999; Turney and Pantel, 2010). In this paper, we present results obtained by positive pointwise mutual information (PPMI) (Niwa and Nitta, 1994) as a weighting function, which is a standard choice in vector space semantics (Turney and Pantel, 2010), and (combined with cosine) yields the best results over a group of semantic tasks according to (Bullinaria and Levy, 2007). We use a smoothed version of PPMI as presented in (Pantel and Lin, 2002; Turney and Pantel, 2010). Again, based on the results reported in the relevant literature (Bullinaria and Levy, 2007; Laroche and Langlais, 2010; Turney and Pantel, 2010), we opt for</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: vector space models of semantics. Journal of Artifical Intelligence Research, 37(1):141– 188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lonneke van der Plas</author>
<author>Paola Merlo</author>
<author>James Henderson</author>
</authors>
<title>Scaling up automatic cross-lingual semantic role annotation.</title>
<date>2011</date>
<booktitle>In Proceedings ofACL-HLT,</booktitle>
<pages>299--304</pages>
<marker>van der Plas, Merlo, Henderson, 2011</marker>
<rawString>Lonneke van der Plas, Paola Merlo, and James Henderson. 2011. Scaling up automatic cross-lingual semantic role annotation. In Proceedings ofACL-HLT, pages 299–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen M Voorhees</author>
</authors>
<title>The TREC-8 question answering track report.</title>
<date>1999</date>
<booktitle>In Proceedings of TREC,</booktitle>
<pages>77--82</pages>
<contexts>
<context position="20265" citStr="Voorhees, 1999" startWordPosition="3346" endWordPosition="3347">on, but rather its ability to find semantically similar words and translations also for words that are not used as dimensions of the space (see sect. 2.1). Evaluation metrics. We measure the performance on the BLE task using a standard Top M accuracy (AccM) metric. It denotes the number of source words ws from ground truth translation pairs whose list RLM(ws ) contains the correct translation according to our ground truth over the total number of ground truth translation pairs (=1000) (Gaussier et al., 2004; Tamura et al., 2012).5 Additionally, we report the mean reciprocal rank (MRR) scores (Voorhees, 1999) for some experimental runs. Multilingual topic model. We utilize a straightforward multilingual extension of the standard Blei et al.’s LDA model (Blei et al., 2003) called bilingual LDA (Mimno et al., 2009; Ni et al., 2009; De Smet and Moens, 2009). BiLDA training follows the procedure from (Vuli´c and Moens, 2013), that is, the training method is Gibbs sampling with the number of topics set to K = 2000. Hyperparameters of the model are set to standard values (Steyvers and Griffiths, 2007): α = 50/K and Q = 0.01. Building initial seed lexicons. To produce the lists of one-to-one translation </context>
</contexts>
<marker>Voorhees, 1999</marker>
<rawString>Ellen M. Voorhees. 1999. The TREC-8 question answering track report. In Proceedings of TREC, pages 77– 82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Vuli´c</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Crosslingual semantic similarity of words as the similarity of their semantic word responses.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>106--116</pages>
<marker>Vuli´c, Moens, 2013</marker>
<rawString>Ivan Vuli´c and Marie-Francine Moens. 2013. Crosslingual semantic similarity of words as the similarity of their semantic word responses. In Proceedings of NAACL-HLT, pages 106–116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Vuli´c</author>
<author>Wim De Smet</author>
<author>Marie-Francine Moens</author>
</authors>
<title>Identifying word translations from comparable corpora using latent topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL-HLT,</booktitle>
<pages>479--484</pages>
<marker>Vuli´c, De Smet, Moens, 2011</marker>
<rawString>Ivan Vuli´c, Wim De Smet, and Marie-Francine Moens. 2011. Identifying word translations from comparable corpora using latent topic models. In Proceedings of ACL-HLT, pages 479–484.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>200--207</pages>
<contexts>
<context position="1896" citStr="Yarowsky and Ngai, 2001" startWordPosition="286" endWordPosition="289">cross-lingual information retrieval (Lavrenko et al., 2002; Levow et al., 2005) or statistical machine translation (Och and Ney, 2003). Additionally, they are a crucial component in cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc. Techniques for automatic bilingual lexicon extraction (BLE) from parallel corpora on the basis of word alignment models are well established (Och and Ney, 2003). However, due to a relative scarceness of parallel data for many language pairs and domains, alternative approaches that rely on comparable corpora have also gained much interest (e.g., Fung and Yee (1998); Rapp (1999)). The models that rely on non-parallel data typically represent each word by a high-dimensional vector in a feature vector space, where the dimensions of the vecto</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>David Yarowsky and Grace Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of NAACL, pages 200–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Duo Zhang</author>
<author>Qiaozhu Mei</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Cross-lingual latent topic extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1128--1137</pages>
<contexts>
<context position="14142" citStr="Zhang et al., 2010" startWordPosition="2338" endWordPosition="2341">other language pairs. High-frequency seeds. Another problem with using only identical words and cognates as seeds lies in the fact that many of them might be infrequent in the corpus, and as a consequence the expressiveness of a bilingual vector space might be limited. On the other hand, high-frequency words offer a lot of evidence in the corpus that could be exploited in the bootstrapping approach. In order to induce initial translation pairs, we rely on the framework of multilingual probabilistic topic modeling (MuPTM) (BoydGraber and Blei, 2009; De Smet and Moens, 2009; Mimno et al., 2009; Zhang et al., 2010), that does not require a bilingual lexicon, it operates with nonparallel data, and is able to produce highly confident translation pairs for high-frequency words (Mimno et al., 2009; Vuli´c and Moens, 2013).2 Therefore, we can construct the initial seed lexicon as follows: (1) Train a multilingual topic model on the corpus. (2) Obtain one-to-one translation pairs using any of the MuPTM-based models of cross-lingual similarity, e.g., (Vuli´c et al., 2011; Vuli´c and Moens, 2013). (3) Retain only symmetric translation pairs. This step ensures that only highly confident pairs are used as seed tr</context>
</contexts>
<marker>Zhang, Mei, Zhai, 2010</marker>
<rawString>Duo Zhang, Qiaozhu Mei, and ChengXiang Zhai. 2010. Cross-lingual latent topic extraction. In Proceedings of ACL, pages 1128–1137.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Yan Song</author>
<author>Chunyu Kit</author>
<author>Guodong Zhou</author>
</authors>
<title>Cross language dependency parsing using a bilingual lexicon.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>55--63</pages>
<contexts>
<context position="1808" citStr="Zhao et al., 2009" startWordPosition="272" endWordPosition="275">e as an indispensable source of knowledge for various cross-lingual tasks such as cross-lingual information retrieval (Lavrenko et al., 2002; Levow et al., 2005) or statistical machine translation (Och and Ney, 2003). Additionally, they are a crucial component in cross-lingual knowledge transfer, where the knowledge about utterances in one language may be transferred to another. The utility of the transfer or annotation projection by means of bilingual lexicons has already been proven in various tasks such as semantic role labeling (Pad´o and Lapata, 2009; van der Plas et al., 2011), parsing (Zhao et al., 2009; Durrett et al., 2012; T¨ackstr¨om et al., 2013b), POS tagging (Yarowsky and Ngai, 2001; Das and Petrov, 2011; T¨ackstr¨om et al., 2013a), etc. Techniques for automatic bilingual lexicon extraction (BLE) from parallel corpora on the basis of word alignment models are well established (Och and Ney, 2003). However, due to a relative scarceness of parallel data for many language pairs and domains, alternative approaches that rely on comparable corpora have also gained much interest (e.g., Fung and Yee (1998); Rapp (1999)). The models that rely on non-parallel data typically represent each word b</context>
</contexts>
<marker>Zhao, Song, Kit, Zhou, 2009</marker>
<rawString>Hai Zhao, Yan Song, Chunyu Kit, and Guodong Zhou. 2009. Cross language dependency parsing using a bilingual lexicon. In Proceedings of ACL, pages 55– 63.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>