<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.9950925">
Combining Generative and Discriminative Model Scores for Distant
Supervision
</title>
<author confidence="0.999315">
Benjamin Roth, Dietrich Klakow
</author>
<affiliation confidence="0.9457635">
Saarland University
Spoken Language Systems
</affiliation>
<address confidence="0.702681">
Saarbr¨ucken, Germany
</address>
<email confidence="0.996904">
{benjamin.roth|dietrich.klakow}@lsv.uni-saarland.de
</email>
<sectionHeader confidence="0.995587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996073285714286">
Distant supervision is a scheme to generate
noisy training data for relation extraction by
aligning entities of a knowledge base with
text. In this work we combine the output of
a discriminative at-least-one learner with that
of a generative hierarchical topic model to re-
duce the noise in distant supervision data. The
combination significantly increases the rank-
ing quality of extracted facts and achieves
state-of-the-art extraction performance in an
end-to-end setting. A simple linear interpo-
lation of the model scores performs better
than a parameter-free scheme based on non-
dominated sorting.
</bodyText>
<sectionHeader confidence="0.998975" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999838529411765">
Relation extraction is the task of finding relational
facts in unstructured text and putting them into a
structured (tabularized) knowledge base. Training
machine learning algorithms for relation extraction
requires training data. If the set of relations is pre-
specified, the training data needs to be labeled with
those relations.
Manual annotation of training data is laborious
and costly, however, the knowledge base may al-
ready partially be filled with instances from the rela-
tions. This is utilized by a scheme known as distant
supervision (DS) (Mintz et al., 2009): text is au-
tomatically labeled by aligning (matching) pairs of
entities that are contained in a knowledge base with
their textual occurrences. Whenever such a match is
encountered, the surrounding context (sentence) is
assumed to express the relation.
</bodyText>
<page confidence="0.97982">
24
</page>
<bodyText confidence="0.88031925">
This assumption, however, can fail.
Consider the example given in (Taka-
matsu et al., 2012): If the tuple
place_of_birth(Michael Jackson, Gary)
is contained in the knowledge base, one matching
context could be:
Michael Jackson was born in Gary ...
And another possible context:
</bodyText>
<subsectionHeader confidence="0.330492">
Michael Jackson moved from Gary ...
</subsectionHeader>
<bodyText confidence="0.99997156">
Clearly, only the first context indeed expresses the
relation and should be labeled accordingly.
Three basic approaches have been proposed to
deal with noisy distant supervision instances: The
discriminative at-least-one approach (Riedel et al.,
2010), that requires that at least one of the matches
for a relation-entity tuple indeed expresses the
relation; The generative approach (Alfonseca et
al., 2012) that separates relation-specific distribu-
tions from noise distributions by using hierarchical
topic models; And the pattern correlation approach
(Takamatsu et al., 2012) that assumes that contexts
which match argument pairs have a high overlap in
argument pairs with other patterns expressing the re-
lation.
In this work we combine 1) a discriminative at-
least-one learner, that requires high scores for both
a dedicated noise label and the matched relation, and
2) a generative topic model that uses a feature-based
representation to separate relation-specific patterns
from background or pair-specific noise. We score
surface patterns and show that combining the two
approaches results in a better ranking quality of re-
lational facts. In an end-to-end evaluation we set a
threshold on the pattern scores and apply the pat-
</bodyText>
<note confidence="0.3092335">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 24–29,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9947585">
Figure 1: Hierarchical topic models. Intertext model
(left) and feature model (right).
</figureCaption>
<bodyText confidence="0.984539">
terns in a TAC KBP-style evaluation. Although
the surface patterns are very simple (only strings of
tokens), they achieve state-of-the-art extraction re-
sults.
</bodyText>
<sectionHeader confidence="0.999914" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.962753">
2.1 At-Least-One Models
</subsectionHeader>
<bodyText confidence="0.999978666666667">
The original form of distant supervision (Mintz et
al., 2009) assumes all sentences containing an entity
pair to be potential patterns for the relation holding
between the entities. A variety of models relax this
assumption and only presume that at least one of the
entity pair occurrences is a textual manifestation of
the relation. The first proposed model with an at-
least-one learner is that of Riedel et al. (2010) and
Yao et al. (2010). It consists of a factor graph that
includes binary variables for contexts, and groups
contexts together for each entity pair. MultiR (Hoff-
mann et al., 2011) can be viewed as a multi-label
extension of (Riedel et al., 2010). A further exten-
sion is MIMLRE (Surdeanu et al., 2012), a jointly
trained two-stage classification model.
</bodyText>
<subsectionHeader confidence="0.998283">
2.2 Hierarchical Topic Model
</subsectionHeader>
<bodyText confidence="0.99976675">
The hierarchical topic model (HierTopics) by Alfon-
seca et al. (2012) models the distant supervision data
by a generative model. For each corpus match of an
entity pair in the knowledge base, the corresponding
surface pattern is assumed to be typical for either the
entity pair, the relation, or neither. This principle is
then used to infer distributions over patterns of one
of the following types:
</bodyText>
<listItem confidence="0.9988292">
1. For every entity pair, a pair-specific distribu-
tion.
2. For every relation, a relation-specific distribu-
tion.
3. A general background distribution.
</listItem>
<bodyText confidence="0.9973235">
The generative process assumes that for each ar-
gument pair in the knowledge base, all patterns
are generated by first choosing a hidden variable z
which can take on three values, B for background, R
for relation and P for pair. Corresponding vocabu-
lary distributions (Obg, Orel, Opair) for generating the
context patterns are chosen according to the value of
z. The Dirichlet-smoothed vocabulary distributions
are shared on the respective levels. Figure 1 shows
the plate diagram of the HierTopics model.
</bodyText>
<sectionHeader confidence="0.74879" genericHeader="method">
3 Model Extensions and Combination
</sectionHeader>
<subsectionHeader confidence="0.687369">
3.1 Generative Model
</subsectionHeader>
<bodyText confidence="0.999977736842105">
We use a feature-based extension (Roth and Klakow,
2013) of Alfonseca et al. (2012) to include bigrams
for a more fine-grained representation of the pat-
terns. For including features in the model, the model
is extended with a second layer of hidden variables.
A variable x represents a choice of B, R or P for
every pattern, i.e. there is one variable x for every
pattern. Each feature is generated conditioned on
a second variable z E {B, R, P}, i.e. there are as
many variables z for a pattern as there are features
for it. First, the hidden variable x is generated, then
all z variables are generated for the corresponding
features (see Figure 1). The values B, R or P of z
depend on the corresponding x by a transition distri-
bution:
where features at indices i are mapped to the corre-
sponding pattern indices by a function j(i); psame
is set to .99 to enforce the correspondence between
pattern and feature topics. 1
</bodyText>
<subsectionHeader confidence="0.965035">
3.2 Discriminative Model
</subsectionHeader>
<bodyText confidence="0.9999445">
As a second feature-based model, we employ a per-
ceptron model that enforces constraints on the labels
for patterns (Roth and Klakow, 2013). The model
consists of log-linear factors for the set of relations
</bodyText>
<footnote confidence="0.757758">
1The hyper-parameters used for the feature-based topic
</footnote>
<equation confidence="0.894972285714286">
model are α = (1, 1, 1) and ,(3 = (.1, .001, .001).
�
psame, if z = x
P(Zi = z|Xj(i) = x) =
1−Na—e,
otherwise
2
</equation>
<page confidence="0.848615">
25
</page>
<bodyText confidence="0.233752">
Algorithm 1 At-Least-One Perceptron Training
</bodyText>
<equation confidence="0.827892692307692">
θ +— 0
for r E R do
for pair E kb pairs(r) do
for s E sentences(pair) do
for r0 E R \ r do
if P(r|s, θ) &lt; P(r0|s, θ) then
θ +— θ + φ(s, r) − φ(s, r0)
if P(NIL|s, θ) &lt; P(r0|s, θ) then
θ +— θ + φ(s, NIL) − φ(s, r0)
if ds∈sentences(pair) : P(r|s, θ) &lt; P(NIL|s, θ) then
P (r|s,θ)
s∗ = arg maxs P(NIL|s,θ)
θ +— θ + φ(s∗, r) − φ(s∗, NIL)
</equation>
<bodyText confidence="0.999603055555556">
R as well as a factor for the NIL label (no relation).
Probabilities for a relation r given a sentence pat-
tern s are calculated by normalizing over log-linear
factors defined as fr(s) = exp (Ei 0i(s, r)Bi), with
0(s, r) the feature vector for sentence s and label
assignment r, and Or the feature weight vector.
The learner is directed by the following se-
mantics: First, for a sentence s that has a distant
supervision match for relation r, relation r should
have a higher probability than any other relation
r&apos; E R \ r. As extractions are expected to be
noisy, high probabilities for NIL are enforced
by a second constraint: NIL must have a higher
probability than any relation r&apos; E R \ r. Third, at
least one DS sentence for an argument pair is ex-
pected to express the corresponding relation r. For
sentences s for an entity pair belonging to relation
r, this can be written as the following constraints:
</bodyText>
<equation confidence="0.9986685">
Vs,r0 : P(r|s) &gt; P(r&apos;|s) ∧ P(NIL|s) &gt; P(r&apos;|s)
1s : P(r|s) &gt; P(NIL|s)
</equation>
<bodyText confidence="0.999690333333333">
The violation of any of the above constraints
triggers a perceptron update. The basic algorithm is
sketched in Algorithm 1.2
</bodyText>
<subsectionHeader confidence="0.998719">
3.3 Model Combination
</subsectionHeader>
<bodyText confidence="0.999521777777778">
The per-pattern probabilities P(r|pat) are calcu-
lated as in Alfonseca et al. (2012) and aggregated
over all pattern occurrences: For the topic model,
the number of times the relation-specific topic has
been sampled for a pattern is divided by n(pat), the
number of times the same pattern has been observed.
Analogously for the perceptron, the number of times
a pattern co-occurs with entity pairs for r is multi-
plied by the perceptron score and divided by n(pat).
</bodyText>
<footnote confidence="0.927394">
2The weight vectors are averaged over 20 iterations.
</footnote>
<figureCaption confidence="0.9976236">
Figure 2: Score combination by non-dominated sorting:
Circles indicate patterns on the Pareto-frontier, which are
ranked highest. They are followed by the triangles, the
square indicates the lowest ranked pattern in this exam-
ple.
</figureCaption>
<bodyText confidence="0.990799">
For the patterns of the form [ARG1] context
[ARG2], we compute the following scores:
</bodyText>
<listItem confidence="0.698854428571429">
• Maximum Likelihood (MLE):
n(pat,r)
n(pat)
• Topic Model:
n(pat,topic(r))
n(pat)
• Perceptron:
</listItem>
<equation confidence="0.653074">
n(pat,r)
n(pat) �
</equation>
<listItem confidence="0.868895">
• Interpolation:
</listItem>
<equation confidence="0.997080333333333">
0.5·n(pat,topic(r)) 0.5·n(pat,r)·P(rjs,0)
+
n(pat) n(pat)·(P(rjs,0)+P(NILjs,0))
</equation>
<bodyText confidence="0.971381421052631">
The topic model and perceptron approaches are
based on plausible yet fundamentally different prin-
ciples of modeling noise without direct supervision.
It is therefore an interesting question how comple-
mentary the models are and how much can be gained
from a combination. As the two models do not use
direct supervision, we also avoid tuning parameters
for their combination.
We use two schemes to obtain a combined rank-
ing from the two model scores: The first is a rank-
ing based on non-dominated sorting by successively
computing the Pareto-frontier of the 2-dimensional
score vectors (Borzsony et al., 2001; Godfrey et
al., 2007). The underlying principle is that all data
points (patterns in our case) that are not dominated
by another point3 build the frontier and are ranked
highest (see Figure 2), with ties broken by linear
3A data point h1 dominates a data point h2 if h1 &gt; h2 in all
metrics and h1 &gt; h2 in at least one metric.
</bodyText>
<equation confidence="0.978405">
P(rjs,B)
P(rjs,0)+P(NILjs,0)
</equation>
<page confidence="0.977795">
26
</page>
<bodyText confidence="0.999983818181818">
combination. Sorting by computing the Pareto-
frontier has been applied to training machine transla-
tion systems (Duh et al., 2012) to combine the trans-
lation quality metrics BLEU, RIBES and LATER,
each of which is based on different principles. In the
context of machine translation it has been found to
outperform a linear interpolation of the metrics and
to be more stable to non-smooth metrics and non-
comparable scalings. We compare non-dominated
sorting with a simple linear interpolation with uni-
form weights.
</bodyText>
<sectionHeader confidence="0.999714" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<subsectionHeader confidence="0.990486">
4.1 Ranking-Based Evaluation
</subsectionHeader>
<bodyText confidence="0.999968787878788">
Evaluation is done on the ranking quality according
to TAC KBP gold annotations (Ji et al., 2010) of ex-
tracted facts from all TAC KBP queries from 2009-
2011 and the TAC KBP 2009-2011 corpora. First,
candidate sentences are retrieved in which the query
entity and a second entity with the appropriate type
are contained. Candidate sentences are then used
to provide answer candidates if one of the extracted
patterns matches. The answer candidates are ranked
according to the score of the matching pattern.
The basis for pattern extraction is the noisy DS
training data of a top-3 ranked system in TAC KBP
2012 (Roth et al., 2012). The retrieval component
of this system is used to obtain sentence and an-
swer candidates (ranked according to their respec-
tive pattern scores). Evaluation results are reported
as averages over per-relation results of the standard
ranking metrics mean average precision (map), geo-
metric map (gmap), precision at 5 and at 10 (p@S,
p@10).
The maximum-likelihood estimator (MLE) base-
line scores patterns by the relative frequency they
occur with a certain relation. The hierarchical topic
(hier orig) as described in Alfonseca et al. (2012)
increases the scores under most metrics, however
the increase is only significant for p@5 and p@10.
The feature-based extension of the topic model
(hier feat) has significantly better ranking quality.
Slightly better scores are obtained by the at-least-
one perceptron learner. It is interesting to see that the
model combinations both by non-dominated sorting
perc+hier (pareto) as well as uniform interpolation
perc+hier (itpl) give a further increase in ranking
</bodyText>
<table confidence="0.997804714285714">
map gmap p@5 p@10
.253 .142 .263 .232
.270 .158 .353* .297*
.318†* .205†* .363* .321*
.330†* .210†* .379* .337*
.340†* .220†* .400* .340*
.344†* .220†* .426†* .353†*
</table>
<tableCaption confidence="0.994931">
Table 1: Ranking quality of extracted facts. Significance
(paired t-test, p &lt; 0.05) w.r.t. MLE(*) and hier orig(†).
</tableCaption>
<figure confidence="0.990483666666667">
Interpolated Precision/Recall
0 0.2 0.4 0.6 0.8 1
Recall
</figure>
<figureCaption confidence="0.999973">
Figure 3: Precision at recall levels.
</figureCaption>
<bodyText confidence="0.999923">
quality. The simpler interpolation scheme gener-
ally works best. Figure 3 shows the Precision/Recall
curves of the basic models and the linear interpola-
tion. On the P/R curve, the linear interpolation is
equal or better than the single methods on all recall
levels.
</bodyText>
<subsectionHeader confidence="0.90128">
4.2 End-To-End Evaluation
</subsectionHeader>
<bodyText confidence="0.9999495625">
We evaluate the extraction quality of the induced
perc+hier (itpl) patterns in an end-to-end setting.
We use the evaluation setting of (Surdeanu et al.,
2012) and the results obtained with their pipeline for
MIMLRE and their re-implementation of MultiR as
a point of reference.
In Surdeanu et al. (2012) evaluation is done us-
ing a subset of queries from the TAC KBP 2010 and
2011 evaluation. The source corpus is the TAC KBP
source corpus and a 2010 Wikipedia dump. Only
those answers are considered in scoring that are con-
tained in a list of possible answers from their can-
didates (reducing the number of gold answers from
1601 to 576 and thereby considerably increasing the
value of reported recall).
For evaluating our patterns, we take the same
</bodyText>
<figure confidence="0.99858945">
Precision
0.7
0.6
0.5
0.4
0.3
0.2
0.1
MLE
hier orig
hier feat
perceptron
perc+hier (itpl)
method
MLE
hier orig
hier feature
perceptron
perc+hier (pareto)
perc+hier (itpl)
</figure>
<page confidence="0.995253">
27
</page>
<bodyText confidence="0.998832375">
queries for testing as Surdeanu et al. (2012). As the
document collection, we use the TAC KBP source
collection and a Wikipedia dump from 07/2009 that
was available to us. From this document collec-
tion, we use our retrieval pipeline of Roth et al.
(2012) and take those sentences that contain query
entities and slot filler candidates according to NE-
tags. We filter out all candidates that are not con-
tained in the list of candidates considered in (Sur-
deanu et al., 2012), and use the same reduced set
of 576 gold answers as the key. We tune a single
threshold parameter t = .3 on held-out development
data and take all patterns with higher scores. Ta-
ble 2 shows that results obtained with the induced
patterns compare well with state-of-the-art relation
extraction systems.
</bodyText>
<table confidence="0.99894125">
method Recall Precision F1
MultiR .200 .306 .242
MIMLRE .314 .247 .277
perc+hier (itpl) .248 .401 .307
</table>
<tableCaption confidence="0.992263">
Table 2: TAC Scores on (Surdeanu et al., 2012) queries.
</tableCaption>
<subsectionHeader confidence="0.988559">
4.3 Illustration: Top-Ranked Patterns
</subsectionHeader>
<bodyText confidence="0.999822736842105">
Figure 4 shows top-ranked patterns for per:title
and org:top members employees, the two rela-
tions with most answers in the gold annotations. For
maximum likelihood estimation the score is 1.0 if
the patterns occurs only with the relation in question
– this includes all cases where the pattern is only
found once in the corpus. While this could be cir-
cumvented by frequency thresholding, we leave the
long tail of the data as it is and let the algorithm deal
with both frequent and infrequent patterns.
One can see that while the maximum likelihood
patterns contain some reasonable relational con-
texts, they are less prototypical and more prone to
distant supervision errors. The patterns scored high
by the proposed combination generalize better, vari-
ation at the top is achieved by re-combining ele-
ments that carry relational meaning (“is an”, “vice
president”, “president director”) or are closely cor-
related to the particular relation.
</bodyText>
<sectionHeader confidence="0.999255" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9974635">
We have combined two models based on distinct
principles for noise reduction in distant supervision:
</bodyText>
<figure confidence="0.713157107142857">
per:title, MLE
[ARG11 , a singing [ARG21
*[ARG11 Best film : Capote ( as [ARG21
[ARG11 Nunn ( born October 7 , 1957 in Little Rock, Arkansas
) is an American jazz [ARG21
*[ARG21 Kevin Weekes , subbing for a rarely rested [ARG11
[ARG11 Butterfill FRICS ( born February 14 , 1941 , Surrey) is
a British [ARG21
per:title, perc+hier (itpl)
[ARG11 , is a Canadian [ARG21
[ARG11 Hilligoss is an American [ARG21
[ARG11 , is an American film [ARG21
[ARG11 , is an American film and television [ARG21
*[ARG11 for Best [ARG21
org:top members employees, MLE
[ARG21 remained chairman of [ARG11
*[ARG21 asks the ball whether he and [ARG11
[ARG21 was chairman of the [ARG11
*[ARG11 , Joe Lieberman and [ARG21
*[ARG11 ’s responsibility to pin down just how the government
decided to front $ 30 billion in taxpayer dollars for the Bear
Stearns deal, “ Chairman [ARG21
org:top members employees, perc+hier (itpl)
[ARG21 , Vice President of the [ARG11
[ARG11 Vice president [ARG21
[ARG11 president director [ARG21
[ARG11 vice president director [ARG21
[ARG11 Board member [ARG21
</figure>
<figureCaption confidence="0.977215333333333">
Figure 4: Top-scored patterns for maximum likelihood
(MLE) and the interpolation (perc+hier itpl) method. In-
exact patterns are marked by *.
</figureCaption>
<bodyText confidence="0.9999067">
a feature-based extension of a hierarchical topic
model, and an at-least-one perceptron. Interpola-
tion increases the quality of extractions and achieves
state-of-the-art extraction performance. A combina-
tion scheme based on non-dominated sorting, that
was inspired by work on combining machine trans-
lation metrics, was not as good as a simple linear
combination of scores. We think that the good re-
sults motivate research into more integrated combi-
nations of noise reduction approaches.
</bodyText>
<sectionHeader confidence="0.959371" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.99732775">
Benjamin Roth is a recipient of the Google Europe
Fellowship in Natural Language Processing, and this
research is supported in part by this Google Fellow-
ship.
</bodyText>
<page confidence="0.997666">
28
</page>
<sectionHeader confidence="0.990112" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999768472972973">
Enrique Alfonseca, Katja Filippova, Jean-Yves Delort,
and Guillermo Garrido. 2012. Pattern learning for
relation extraction with a hierarchical topic model. In
Proceedings of the 50th Annual Meeting of the Asso-
ciation for Computational Linguistics: Short Papers-
Volume 2, pages 54–59. Association for Computa-
tional Linguistics.
S Borzsony, Donald Kossmann, and Konrad Stocker.
2001. The skyline operator. In Data Engineering,
2001. Proceedings. 17th International Conference on,
pages 421–430. IEEE.
Kevin Duh, Katsuhito Sudoh, Xianchao Wu, Hajime
Tsukada, and Masaaki Nagata. 2012. Learning to
translate with multiple objectives. In Proceedings of
the 50th Annual Meeting of the Association for Com-
putational Linguistics: Long Papers-Volume 1, pages
1–10. Association for Computational Linguistics.
Parke Godfrey, Ryan Shipley, and Jarek Gryz. 2007. Al-
gorithms and analyses for maximal vector computa-
tion. The VLDB JournalThe International Journal on
Very Large Data Bases, 16(1):5–28.
Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke
Zettlemoyer, and Daniel S Weld. 2011. Knowledge-
based weak supervision for information extraction of
overlapping relations. In Proceedings of the 49th An-
nual Meeting of the Association for Computational
Linguistics: Human Language Technologies, vol-
ume 1, pages 541–550.
Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Grif-
fitt, and Joe Ellis. 2010. Overview of the tac 2010
knowledge base population track. In Third Text Anal-
ysis Conference (TAC 2010).
Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky.
2009. Distant supervision for relation extraction with-
out labeled data. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP: Volume 2-Volume 2,
pages 1003–1011. Association for Computational Lin-
guistics.
Sebastian Riedel, Limin Yao, and Andrew McCallum.
2010. Modeling relations and their mentions with-
out labeled text. In Machine Learning and Knowledge
Discovery in Databases, pages 148–163. Springer.
Benjamin Roth and Dietrich Klakow. 2013. Feature-
based models for improving the quality of noisy train-
ing data for relation extraction. In Proceedings of the
22nd ACM International Conference on Information
and Knowledge Management (CIKM). ACM.
Benjamin Roth, Grzegorz Chrupala, Michael Wiegand,
Mittul Singh, and Dietrich Klakow. 2012. General-
izing from freebase and patterns using distant supervi-
sion for slot filling. In Proceedings of the TextAnalysis
Conference (TAC).
Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and
Christopher D Manning. 2012. Multi-instance multi-
label learning for relation extraction. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, pages 455–465. Associa-
tion for Computational Linguistics.
Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa.
2012. Reducing wrong labels in distant supervi-
sion for relation extraction. In Proceedings of the
50th Annual Meeting of the Association for Compu-
tational Linguistics: Long Papers - Volume 1, ACL
’12, pages 721–729, Stroudsburg, PA, USA. Associ-
ation for Computational Linguistics.
Limin Yao, Sebastian Riedel, and Andrew McCallum.
2010. Collective cross-document relation extraction
without labelled data. In Proceedings of the 2010 Con-
ference on Empirical Methods in Natural Language
Processing, pages 1013–1023. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.999116">
29
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.214505">
<title confidence="0.9996975">Combining Generative and Discriminative Model Scores for Distant Supervision</title>
<author confidence="0.998873">Benjamin Roth</author>
<author confidence="0.998873">Dietrich</author>
<affiliation confidence="0.858981">Saarland Spoken Language</affiliation>
<email confidence="0.340882">Saarbr¨ucken,</email>
<abstract confidence="0.990501133333333">Distant supervision is a scheme to generate noisy training data for relation extraction by aligning entities of a knowledge base with text. In this work we combine the output of a discriminative at-least-one learner with that of a generative hierarchical topic model to reduce the noise in distant supervision data. The combination significantly increases the ranking quality of extracted facts and achieves state-of-the-art extraction performance in an end-to-end setting. A simple linear interpolation of the model scores performs better than a parameter-free scheme based on nondominated sorting.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Enrique Alfonseca</author>
<author>Katja Filippova</author>
<author>Jean-Yves Delort</author>
<author>Guillermo Garrido</author>
</authors>
<title>Pattern learning for relation extraction with a hierarchical topic model.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short PapersVolume 2,</booktitle>
<pages>54--59</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2396" citStr="Alfonseca et al., 2012" startWordPosition="347" endWordPosition="350">e tuple place_of_birth(Michael Jackson, Gary) is contained in the knowledge base, one matching context could be: Michael Jackson was born in Gary ... And another possible context: Michael Jackson moved from Gary ... Clearly, only the first context indeed expresses the relation and should be labeled accordingly. Three basic approaches have been proposed to deal with noisy distant supervision instances: The discriminative at-least-one approach (Riedel et al., 2010), that requires that at least one of the matches for a relation-entity tuple indeed expresses the relation; The generative approach (Alfonseca et al., 2012) that separates relation-specific distributions from noise distributions by using hierarchical topic models; And the pattern correlation approach (Takamatsu et al., 2012) that assumes that contexts which match argument pairs have a high overlap in argument pairs with other patterns expressing the relation. In this work we combine 1) a discriminative atleast-one learner, that requires high scores for both a dedicated noise label and the matched relation, and 2) a generative topic model that uses a feature-based representation to separate relation-specific patterns from background or pair-specif</context>
<context position="4567" citStr="Alfonseca et al. (2012)" startWordPosition="682" endWordPosition="686"> at least one of the entity pair occurrences is a textual manifestation of the relation. The first proposed model with an atleast-one learner is that of Riedel et al. (2010) and Yao et al. (2010). It consists of a factor graph that includes binary variables for contexts, and groups contexts together for each entity pair. MultiR (Hoffmann et al., 2011) can be viewed as a multi-label extension of (Riedel et al., 2010). A further extension is MIMLRE (Surdeanu et al., 2012), a jointly trained two-stage classification model. 2.2 Hierarchical Topic Model The hierarchical topic model (HierTopics) by Alfonseca et al. (2012) models the distant supervision data by a generative model. For each corpus match of an entity pair in the knowledge base, the corresponding surface pattern is assumed to be typical for either the entity pair, the relation, or neither. This principle is then used to infer distributions over patterns of one of the following types: 1. For every entity pair, a pair-specific distribution. 2. For every relation, a relation-specific distribution. 3. A general background distribution. The generative process assumes that for each argument pair in the knowledge base, all patterns are generated by first</context>
<context position="8515" citStr="Alfonseca et al. (2012)" startWordPosition="1391" endWordPosition="1394">r NIL are enforced by a second constraint: NIL must have a higher probability than any relation r&apos; E R \ r. Third, at least one DS sentence for an argument pair is expected to express the corresponding relation r. For sentences s for an entity pair belonging to relation r, this can be written as the following constraints: Vs,r0 : P(r|s) &gt; P(r&apos;|s) ∧ P(NIL|s) &gt; P(r&apos;|s) 1s : P(r|s) &gt; P(NIL|s) The violation of any of the above constraints triggers a perceptron update. The basic algorithm is sketched in Algorithm 1.2 3.3 Model Combination The per-pattern probabilities P(r|pat) are calculated as in Alfonseca et al. (2012) and aggregated over all pattern occurrences: For the topic model, the number of times the relation-specific topic has been sampled for a pattern is divided by n(pat), the number of times the same pattern has been observed. Analogously for the perceptron, the number of times a pattern co-occurs with entity pairs for r is multiplied by the perceptron score and divided by n(pat). 2The weight vectors are averaged over 20 iterations. Figure 2: Score combination by non-dominated sorting: Circles indicate patterns on the Pareto-frontier, which are ranked highest. They are followed by the triangles, </context>
<context position="12163" citStr="Alfonseca et al. (2012)" startWordPosition="1976" endWordPosition="1979">he noisy DS training data of a top-3 ranked system in TAC KBP 2012 (Roth et al., 2012). The retrieval component of this system is used to obtain sentence and answer candidates (ranked according to their respective pattern scores). Evaluation results are reported as averages over per-relation results of the standard ranking metrics mean average precision (map), geometric map (gmap), precision at 5 and at 10 (p@S, p@10). The maximum-likelihood estimator (MLE) baseline scores patterns by the relative frequency they occur with a certain relation. The hierarchical topic (hier orig) as described in Alfonseca et al. (2012) increases the scores under most metrics, however the increase is only significant for p@5 and p@10. The feature-based extension of the topic model (hier feat) has significantly better ranking quality. Slightly better scores are obtained by the at-leastone perceptron learner. It is interesting to see that the model combinations both by non-dominated sorting perc+hier (pareto) as well as uniform interpolation perc+hier (itpl) give a further increase in ranking map gmap p@5 p@10 .253 .142 .263 .232 .270 .158 .353* .297* .318†* .205†* .363* .321* .330†* .210†* .379* .337* .340†* .220†* .400* .340</context>
</contexts>
<marker>Alfonseca, Filippova, Delort, Garrido, 2012</marker>
<rawString>Enrique Alfonseca, Katja Filippova, Jean-Yves Delort, and Guillermo Garrido. 2012. Pattern learning for relation extraction with a hierarchical topic model. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Short PapersVolume 2, pages 54–59. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Borzsony</author>
<author>Donald Kossmann</author>
<author>Konrad Stocker</author>
</authors>
<title>The skyline operator.</title>
<date>2001</date>
<booktitle>In Data Engineering,</booktitle>
<pages>421--430</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="10081" citStr="Borzsony et al., 2001" startWordPosition="1632" endWordPosition="1635">0)+P(NILjs,0)) The topic model and perceptron approaches are based on plausible yet fundamentally different principles of modeling noise without direct supervision. It is therefore an interesting question how complementary the models are and how much can be gained from a combination. As the two models do not use direct supervision, we also avoid tuning parameters for their combination. We use two schemes to obtain a combined ranking from the two model scores: The first is a ranking based on non-dominated sorting by successively computing the Pareto-frontier of the 2-dimensional score vectors (Borzsony et al., 2001; Godfrey et al., 2007). The underlying principle is that all data points (patterns in our case) that are not dominated by another point3 build the frontier and are ranked highest (see Figure 2), with ties broken by linear 3A data point h1 dominates a data point h2 if h1 &gt; h2 in all metrics and h1 &gt; h2 in at least one metric. P(rjs,B) P(rjs,0)+P(NILjs,0) 26 combination. Sorting by computing the Paretofrontier has been applied to training machine translation systems (Duh et al., 2012) to combine the translation quality metrics BLEU, RIBES and LATER, each of which is based on different principle</context>
</contexts>
<marker>Borzsony, Kossmann, Stocker, 2001</marker>
<rawString>S Borzsony, Donald Kossmann, and Konrad Stocker. 2001. The skyline operator. In Data Engineering, 2001. Proceedings. 17th International Conference on, pages 421–430. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Katsuhito Sudoh</author>
<author>Xianchao Wu</author>
<author>Hajime Tsukada</author>
<author>Masaaki Nagata</author>
</authors>
<title>Learning to translate with multiple objectives.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>1--10</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10569" citStr="Duh et al., 2012" startWordPosition="1718" endWordPosition="1721"> on non-dominated sorting by successively computing the Pareto-frontier of the 2-dimensional score vectors (Borzsony et al., 2001; Godfrey et al., 2007). The underlying principle is that all data points (patterns in our case) that are not dominated by another point3 build the frontier and are ranked highest (see Figure 2), with ties broken by linear 3A data point h1 dominates a data point h2 if h1 &gt; h2 in all metrics and h1 &gt; h2 in at least one metric. P(rjs,B) P(rjs,0)+P(NILjs,0) 26 combination. Sorting by computing the Paretofrontier has been applied to training machine translation systems (Duh et al., 2012) to combine the translation quality metrics BLEU, RIBES and LATER, each of which is based on different principles. In the context of machine translation it has been found to outperform a linear interpolation of the metrics and to be more stable to non-smooth metrics and noncomparable scalings. We compare non-dominated sorting with a simple linear interpolation with uniform weights. 4 Evaluation 4.1 Ranking-Based Evaluation Evaluation is done on the ranking quality according to TAC KBP gold annotations (Ji et al., 2010) of extracted facts from all TAC KBP queries from 2009- 2011 and the TAC KBP</context>
</contexts>
<marker>Duh, Sudoh, Wu, Tsukada, Nagata, 2012</marker>
<rawString>Kevin Duh, Katsuhito Sudoh, Xianchao Wu, Hajime Tsukada, and Masaaki Nagata. 2012. Learning to translate with multiple objectives. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 1–10. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Parke Godfrey</author>
<author>Ryan Shipley</author>
<author>Jarek Gryz</author>
</authors>
<title>Algorithms and analyses for maximal vector computation.</title>
<date>2007</date>
<journal>The VLDB JournalThe International Journal on Very Large Data Bases,</journal>
<volume>16</volume>
<issue>1</issue>
<contexts>
<context position="10104" citStr="Godfrey et al., 2007" startWordPosition="1636" endWordPosition="1639">c model and perceptron approaches are based on plausible yet fundamentally different principles of modeling noise without direct supervision. It is therefore an interesting question how complementary the models are and how much can be gained from a combination. As the two models do not use direct supervision, we also avoid tuning parameters for their combination. We use two schemes to obtain a combined ranking from the two model scores: The first is a ranking based on non-dominated sorting by successively computing the Pareto-frontier of the 2-dimensional score vectors (Borzsony et al., 2001; Godfrey et al., 2007). The underlying principle is that all data points (patterns in our case) that are not dominated by another point3 build the frontier and are ranked highest (see Figure 2), with ties broken by linear 3A data point h1 dominates a data point h2 if h1 &gt; h2 in all metrics and h1 &gt; h2 in at least one metric. P(rjs,B) P(rjs,0)+P(NILjs,0) 26 combination. Sorting by computing the Paretofrontier has been applied to training machine translation systems (Duh et al., 2012) to combine the translation quality metrics BLEU, RIBES and LATER, each of which is based on different principles. In the context of ma</context>
</contexts>
<marker>Godfrey, Shipley, Gryz, 2007</marker>
<rawString>Parke Godfrey, Ryan Shipley, and Jarek Gryz. 2007. Algorithms and analyses for maximal vector computation. The VLDB JournalThe International Journal on Very Large Data Bases, 16(1):5–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raphael Hoffmann</author>
<author>Congle Zhang</author>
<author>Xiao Ling</author>
<author>Luke Zettlemoyer</author>
<author>Daniel S Weld</author>
</authors>
<title>Knowledgebased weak supervision for information extraction of overlapping relations.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<volume>1</volume>
<pages>541--550</pages>
<contexts>
<context position="4297" citStr="Hoffmann et al., 2011" startWordPosition="639" endWordPosition="643">2.1 At-Least-One Models The original form of distant supervision (Mintz et al., 2009) assumes all sentences containing an entity pair to be potential patterns for the relation holding between the entities. A variety of models relax this assumption and only presume that at least one of the entity pair occurrences is a textual manifestation of the relation. The first proposed model with an atleast-one learner is that of Riedel et al. (2010) and Yao et al. (2010). It consists of a factor graph that includes binary variables for contexts, and groups contexts together for each entity pair. MultiR (Hoffmann et al., 2011) can be viewed as a multi-label extension of (Riedel et al., 2010). A further extension is MIMLRE (Surdeanu et al., 2012), a jointly trained two-stage classification model. 2.2 Hierarchical Topic Model The hierarchical topic model (HierTopics) by Alfonseca et al. (2012) models the distant supervision data by a generative model. For each corpus match of an entity pair in the knowledge base, the corresponding surface pattern is assumed to be typical for either the entity pair, the relation, or neither. This principle is then used to infer distributions over patterns of one of the following types</context>
</contexts>
<marker>Hoffmann, Zhang, Ling, Zettlemoyer, Weld, 2011</marker>
<rawString>Raphael Hoffmann, Congle Zhang, Xiao Ling, Luke Zettlemoyer, and Daniel S Weld. 2011. Knowledgebased weak supervision for information extraction of overlapping relations. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, volume 1, pages 541–550.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
<author>Hoa Trang Dang</author>
<author>Kira Griffitt</author>
<author>Joe Ellis</author>
</authors>
<title>Overview of the tac 2010 knowledge base population track.</title>
<date>2010</date>
<booktitle>In Third Text Analysis Conference (TAC</booktitle>
<contexts>
<context position="11093" citStr="Ji et al., 2010" startWordPosition="1802" endWordPosition="1805">e Paretofrontier has been applied to training machine translation systems (Duh et al., 2012) to combine the translation quality metrics BLEU, RIBES and LATER, each of which is based on different principles. In the context of machine translation it has been found to outperform a linear interpolation of the metrics and to be more stable to non-smooth metrics and noncomparable scalings. We compare non-dominated sorting with a simple linear interpolation with uniform weights. 4 Evaluation 4.1 Ranking-Based Evaluation Evaluation is done on the ranking quality according to TAC KBP gold annotations (Ji et al., 2010) of extracted facts from all TAC KBP queries from 2009- 2011 and the TAC KBP 2009-2011 corpora. First, candidate sentences are retrieved in which the query entity and a second entity with the appropriate type are contained. Candidate sentences are then used to provide answer candidates if one of the extracted patterns matches. The answer candidates are ranked according to the score of the matching pattern. The basis for pattern extraction is the noisy DS training data of a top-3 ranked system in TAC KBP 2012 (Roth et al., 2012). The retrieval component of this system is used to obtain sentence</context>
</contexts>
<marker>Ji, Grishman, Dang, Griffitt, Ellis, 2010</marker>
<rawString>Heng Ji, Ralph Grishman, Hoa Trang Dang, Kira Griffitt, and Joe Ellis. 2010. Overview of the tac 2010 knowledge base population track. In Third Text Analysis Conference (TAC 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mike Mintz</author>
<author>Steven Bills</author>
<author>Rion Snow</author>
<author>Dan Jurafsky</author>
</authors>
<title>Distant supervision for relation extraction without labeled data.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>1003--1011</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="1420" citStr="Mintz et al., 2009" startWordPosition="200" endWordPosition="203">me based on nondominated sorting. 1 Introduction Relation extraction is the task of finding relational facts in unstructured text and putting them into a structured (tabularized) knowledge base. Training machine learning algorithms for relation extraction requires training data. If the set of relations is prespecified, the training data needs to be labeled with those relations. Manual annotation of training data is laborious and costly, however, the knowledge base may already partially be filled with instances from the relations. This is utilized by a scheme known as distant supervision (DS) (Mintz et al., 2009): text is automatically labeled by aligning (matching) pairs of entities that are contained in a knowledge base with their textual occurrences. Whenever such a match is encountered, the surrounding context (sentence) is assumed to express the relation. 24 This assumption, however, can fail. Consider the example given in (Takamatsu et al., 2012): If the tuple place_of_birth(Michael Jackson, Gary) is contained in the knowledge base, one matching context could be: Michael Jackson was born in Gary ... And another possible context: Michael Jackson moved from Gary ... Clearly, only the first context</context>
<context position="3760" citStr="Mintz et al., 2009" startWordPosition="549" endWordPosition="552">-to-end evaluation we set a threshold on the pattern scores and apply the patProceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 24–29, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics Figure 1: Hierarchical topic models. Intertext model (left) and feature model (right). terns in a TAC KBP-style evaluation. Although the surface patterns are very simple (only strings of tokens), they achieve state-of-the-art extraction results. 2 Related Work 2.1 At-Least-One Models The original form of distant supervision (Mintz et al., 2009) assumes all sentences containing an entity pair to be potential patterns for the relation holding between the entities. A variety of models relax this assumption and only presume that at least one of the entity pair occurrences is a textual manifestation of the relation. The first proposed model with an atleast-one learner is that of Riedel et al. (2010) and Yao et al. (2010). It consists of a factor graph that includes binary variables for contexts, and groups contexts together for each entity pair. MultiR (Hoffmann et al., 2011) can be viewed as a multi-label extension of (Riedel et al., 20</context>
</contexts>
<marker>Mintz, Bills, Snow, Jurafsky, 2009</marker>
<rawString>Mike Mintz, Steven Bills, Rion Snow, and Dan Jurafsky. 2009. Distant supervision for relation extraction without labeled data. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 1003–1011. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Riedel</author>
<author>Limin Yao</author>
<author>Andrew McCallum</author>
</authors>
<title>Modeling relations and their mentions without labeled text.</title>
<date>2010</date>
<booktitle>In Machine Learning and Knowledge Discovery in Databases,</booktitle>
<pages>148--163</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2240" citStr="Riedel et al., 2010" startWordPosition="323" endWordPosition="326">ntext (sentence) is assumed to express the relation. 24 This assumption, however, can fail. Consider the example given in (Takamatsu et al., 2012): If the tuple place_of_birth(Michael Jackson, Gary) is contained in the knowledge base, one matching context could be: Michael Jackson was born in Gary ... And another possible context: Michael Jackson moved from Gary ... Clearly, only the first context indeed expresses the relation and should be labeled accordingly. Three basic approaches have been proposed to deal with noisy distant supervision instances: The discriminative at-least-one approach (Riedel et al., 2010), that requires that at least one of the matches for a relation-entity tuple indeed expresses the relation; The generative approach (Alfonseca et al., 2012) that separates relation-specific distributions from noise distributions by using hierarchical topic models; And the pattern correlation approach (Takamatsu et al., 2012) that assumes that contexts which match argument pairs have a high overlap in argument pairs with other patterns expressing the relation. In this work we combine 1) a discriminative atleast-one learner, that requires high scores for both a dedicated noise label and the matc</context>
<context position="4117" citStr="Riedel et al. (2010)" startWordPosition="609" endWordPosition="612">t). terns in a TAC KBP-style evaluation. Although the surface patterns are very simple (only strings of tokens), they achieve state-of-the-art extraction results. 2 Related Work 2.1 At-Least-One Models The original form of distant supervision (Mintz et al., 2009) assumes all sentences containing an entity pair to be potential patterns for the relation holding between the entities. A variety of models relax this assumption and only presume that at least one of the entity pair occurrences is a textual manifestation of the relation. The first proposed model with an atleast-one learner is that of Riedel et al. (2010) and Yao et al. (2010). It consists of a factor graph that includes binary variables for contexts, and groups contexts together for each entity pair. MultiR (Hoffmann et al., 2011) can be viewed as a multi-label extension of (Riedel et al., 2010). A further extension is MIMLRE (Surdeanu et al., 2012), a jointly trained two-stage classification model. 2.2 Hierarchical Topic Model The hierarchical topic model (HierTopics) by Alfonseca et al. (2012) models the distant supervision data by a generative model. For each corpus match of an entity pair in the knowledge base, the corresponding surface p</context>
</contexts>
<marker>Riedel, Yao, McCallum, 2010</marker>
<rawString>Sebastian Riedel, Limin Yao, and Andrew McCallum. 2010. Modeling relations and their mentions without labeled text. In Machine Learning and Knowledge Discovery in Databases, pages 148–163. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Roth</author>
<author>Dietrich Klakow</author>
</authors>
<title>Featurebased models for improving the quality of noisy training data for relation extraction.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22nd ACM International Conference on Information and Knowledge Management (CIKM).</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="5667" citStr="Roth and Klakow, 2013" startWordPosition="858" endWordPosition="861">ion. The generative process assumes that for each argument pair in the knowledge base, all patterns are generated by first choosing a hidden variable z which can take on three values, B for background, R for relation and P for pair. Corresponding vocabulary distributions (Obg, Orel, Opair) for generating the context patterns are chosen according to the value of z. The Dirichlet-smoothed vocabulary distributions are shared on the respective levels. Figure 1 shows the plate diagram of the HierTopics model. 3 Model Extensions and Combination 3.1 Generative Model We use a feature-based extension (Roth and Klakow, 2013) of Alfonseca et al. (2012) to include bigrams for a more fine-grained representation of the patterns. For including features in the model, the model is extended with a second layer of hidden variables. A variable x represents a choice of B, R or P for every pattern, i.e. there is one variable x for every pattern. Each feature is generated conditioned on a second variable z E {B, R, P}, i.e. there are as many variables z for a pattern as there are features for it. First, the hidden variable x is generated, then all z variables are generated for the corresponding features (see Figure 1). The va</context>
</contexts>
<marker>Roth, Klakow, 2013</marker>
<rawString>Benjamin Roth and Dietrich Klakow. 2013. Featurebased models for improving the quality of noisy training data for relation extraction. In Proceedings of the 22nd ACM International Conference on Information and Knowledge Management (CIKM). ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Roth</author>
<author>Grzegorz Chrupala</author>
<author>Michael Wiegand</author>
<author>Mittul Singh</author>
<author>Dietrich Klakow</author>
</authors>
<title>Generalizing from freebase and patterns using distant supervision for slot filling.</title>
<date>2012</date>
<booktitle>In Proceedings of the TextAnalysis Conference (TAC).</booktitle>
<contexts>
<context position="11626" citStr="Roth et al., 2012" startWordPosition="1893" endWordPosition="1896">s done on the ranking quality according to TAC KBP gold annotations (Ji et al., 2010) of extracted facts from all TAC KBP queries from 2009- 2011 and the TAC KBP 2009-2011 corpora. First, candidate sentences are retrieved in which the query entity and a second entity with the appropriate type are contained. Candidate sentences are then used to provide answer candidates if one of the extracted patterns matches. The answer candidates are ranked according to the score of the matching pattern. The basis for pattern extraction is the noisy DS training data of a top-3 ranked system in TAC KBP 2012 (Roth et al., 2012). The retrieval component of this system is used to obtain sentence and answer candidates (ranked according to their respective pattern scores). Evaluation results are reported as averages over per-relation results of the standard ranking metrics mean average precision (map), geometric map (gmap), precision at 5 and at 10 (p@S, p@10). The maximum-likelihood estimator (MLE) baseline scores patterns by the relative frequency they occur with a certain relation. The hierarchical topic (hier orig) as described in Alfonseca et al. (2012) increases the scores under most metrics, however the increase </context>
<context position="14472" citStr="Roth et al. (2012)" startWordPosition="2353" endWordPosition="2356"> from their candidates (reducing the number of gold answers from 1601 to 576 and thereby considerably increasing the value of reported recall). For evaluating our patterns, we take the same Precision 0.7 0.6 0.5 0.4 0.3 0.2 0.1 MLE hier orig hier feat perceptron perc+hier (itpl) method MLE hier orig hier feature perceptron perc+hier (pareto) perc+hier (itpl) 27 queries for testing as Surdeanu et al. (2012). As the document collection, we use the TAC KBP source collection and a Wikipedia dump from 07/2009 that was available to us. From this document collection, we use our retrieval pipeline of Roth et al. (2012) and take those sentences that contain query entities and slot filler candidates according to NEtags. We filter out all candidates that are not contained in the list of candidates considered in (Surdeanu et al., 2012), and use the same reduced set of 576 gold answers as the key. We tune a single threshold parameter t = .3 on held-out development data and take all patterns with higher scores. Table 2 shows that results obtained with the induced patterns compare well with state-of-the-art relation extraction systems. method Recall Precision F1 MultiR .200 .306 .242 MIMLRE .314 .247 .277 perc+hie</context>
</contexts>
<marker>Roth, Chrupala, Wiegand, Singh, Klakow, 2012</marker>
<rawString>Benjamin Roth, Grzegorz Chrupala, Michael Wiegand, Mittul Singh, and Dietrich Klakow. 2012. Generalizing from freebase and patterns using distant supervision for slot filling. In Proceedings of the TextAnalysis Conference (TAC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Julie Tibshirani</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Multi-instance multilabel learning for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>455--465</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4418" citStr="Surdeanu et al., 2012" startWordPosition="662" endWordPosition="665"> entity pair to be potential patterns for the relation holding between the entities. A variety of models relax this assumption and only presume that at least one of the entity pair occurrences is a textual manifestation of the relation. The first proposed model with an atleast-one learner is that of Riedel et al. (2010) and Yao et al. (2010). It consists of a factor graph that includes binary variables for contexts, and groups contexts together for each entity pair. MultiR (Hoffmann et al., 2011) can be viewed as a multi-label extension of (Riedel et al., 2010). A further extension is MIMLRE (Surdeanu et al., 2012), a jointly trained two-stage classification model. 2.2 Hierarchical Topic Model The hierarchical topic model (HierTopics) by Alfonseca et al. (2012) models the distant supervision data by a generative model. For each corpus match of an entity pair in the knowledge base, the corresponding surface pattern is assumed to be typical for either the entity pair, the relation, or neither. This principle is then used to infer distributions over patterns of one of the following types: 1. For every entity pair, a pair-specific distribution. 2. For every relation, a relation-specific distribution. 3. A g</context>
<context position="13453" citStr="Surdeanu et al., 2012" startWordPosition="2177" endWordPosition="2180">facts. Significance (paired t-test, p &lt; 0.05) w.r.t. MLE(*) and hier orig(†). Interpolated Precision/Recall 0 0.2 0.4 0.6 0.8 1 Recall Figure 3: Precision at recall levels. quality. The simpler interpolation scheme generally works best. Figure 3 shows the Precision/Recall curves of the basic models and the linear interpolation. On the P/R curve, the linear interpolation is equal or better than the single methods on all recall levels. 4.2 End-To-End Evaluation We evaluate the extraction quality of the induced perc+hier (itpl) patterns in an end-to-end setting. We use the evaluation setting of (Surdeanu et al., 2012) and the results obtained with their pipeline for MIMLRE and their re-implementation of MultiR as a point of reference. In Surdeanu et al. (2012) evaluation is done using a subset of queries from the TAC KBP 2010 and 2011 evaluation. The source corpus is the TAC KBP source corpus and a 2010 Wikipedia dump. Only those answers are considered in scoring that are contained in a list of possible answers from their candidates (reducing the number of gold answers from 1601 to 576 and thereby considerably increasing the value of reported recall). For evaluating our patterns, we take the same Precision</context>
<context position="14689" citStr="Surdeanu et al., 2012" startWordPosition="2390" endWordPosition="2394">.4 0.3 0.2 0.1 MLE hier orig hier feat perceptron perc+hier (itpl) method MLE hier orig hier feature perceptron perc+hier (pareto) perc+hier (itpl) 27 queries for testing as Surdeanu et al. (2012). As the document collection, we use the TAC KBP source collection and a Wikipedia dump from 07/2009 that was available to us. From this document collection, we use our retrieval pipeline of Roth et al. (2012) and take those sentences that contain query entities and slot filler candidates according to NEtags. We filter out all candidates that are not contained in the list of candidates considered in (Surdeanu et al., 2012), and use the same reduced set of 576 gold answers as the key. We tune a single threshold parameter t = .3 on held-out development data and take all patterns with higher scores. Table 2 shows that results obtained with the induced patterns compare well with state-of-the-art relation extraction systems. method Recall Precision F1 MultiR .200 .306 .242 MIMLRE .314 .247 .277 perc+hier (itpl) .248 .401 .307 Table 2: TAC Scores on (Surdeanu et al., 2012) queries. 4.3 Illustration: Top-Ranked Patterns Figure 4 shows top-ranked patterns for per:title and org:top members employees, the two relations w</context>
</contexts>
<marker>Surdeanu, Tibshirani, Nallapati, Manning, 2012</marker>
<rawString>Mihai Surdeanu, Julie Tibshirani, Ramesh Nallapati, and Christopher D Manning. 2012. Multi-instance multilabel learning for relation extraction. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 455–465. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shingo Takamatsu</author>
<author>Issei Sato</author>
<author>Hiroshi Nakagawa</author>
</authors>
<title>Reducing wrong labels in distant supervision for relation extraction.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12,</booktitle>
<pages>721--729</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1766" citStr="Takamatsu et al., 2012" startWordPosition="253" endWordPosition="257">ds to be labeled with those relations. Manual annotation of training data is laborious and costly, however, the knowledge base may already partially be filled with instances from the relations. This is utilized by a scheme known as distant supervision (DS) (Mintz et al., 2009): text is automatically labeled by aligning (matching) pairs of entities that are contained in a knowledge base with their textual occurrences. Whenever such a match is encountered, the surrounding context (sentence) is assumed to express the relation. 24 This assumption, however, can fail. Consider the example given in (Takamatsu et al., 2012): If the tuple place_of_birth(Michael Jackson, Gary) is contained in the knowledge base, one matching context could be: Michael Jackson was born in Gary ... And another possible context: Michael Jackson moved from Gary ... Clearly, only the first context indeed expresses the relation and should be labeled accordingly. Three basic approaches have been proposed to deal with noisy distant supervision instances: The discriminative at-least-one approach (Riedel et al., 2010), that requires that at least one of the matches for a relation-entity tuple indeed expresses the relation; The generative app</context>
</contexts>
<marker>Takamatsu, Sato, Nakagawa, 2012</marker>
<rawString>Shingo Takamatsu, Issei Sato, and Hiroshi Nakagawa. 2012. Reducing wrong labels in distant supervision for relation extraction. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12, pages 721–729, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Limin Yao</author>
<author>Sebastian Riedel</author>
<author>Andrew McCallum</author>
</authors>
<title>Collective cross-document relation extraction without labelled data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1013--1023</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4139" citStr="Yao et al. (2010)" startWordPosition="614" endWordPosition="617">yle evaluation. Although the surface patterns are very simple (only strings of tokens), they achieve state-of-the-art extraction results. 2 Related Work 2.1 At-Least-One Models The original form of distant supervision (Mintz et al., 2009) assumes all sentences containing an entity pair to be potential patterns for the relation holding between the entities. A variety of models relax this assumption and only presume that at least one of the entity pair occurrences is a textual manifestation of the relation. The first proposed model with an atleast-one learner is that of Riedel et al. (2010) and Yao et al. (2010). It consists of a factor graph that includes binary variables for contexts, and groups contexts together for each entity pair. MultiR (Hoffmann et al., 2011) can be viewed as a multi-label extension of (Riedel et al., 2010). A further extension is MIMLRE (Surdeanu et al., 2012), a jointly trained two-stage classification model. 2.2 Hierarchical Topic Model The hierarchical topic model (HierTopics) by Alfonseca et al. (2012) models the distant supervision data by a generative model. For each corpus match of an entity pair in the knowledge base, the corresponding surface pattern is assumed to b</context>
</contexts>
<marker>Yao, Riedel, McCallum, 2010</marker>
<rawString>Limin Yao, Sebastian Riedel, and Andrew McCallum. 2010. Collective cross-document relation extraction without labelled data. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1013–1023. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>