<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000516">
<title confidence="0.985411">
Automatically Identifying Pseudepigraphic Texts
</title>
<author confidence="0.993047">
Moshe Koppel
</author>
<affiliation confidence="0.99188">
Bar Ilan University
</affiliation>
<address confidence="0.719731">
Ramat-Gan, 52900, Israel
</address>
<email confidence="0.983216">
moishk@gmail.com
</email>
<author confidence="0.969997">
Shachar Seidman
</author>
<affiliation confidence="0.978081">
Bar Ilan University
</affiliation>
<address confidence="0.711738">
Ramat-Gan, 52900, Israel
</address>
<email confidence="0.975811">
shachar9@gmail.com
</email>
<sectionHeader confidence="0.997125" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999878">
The identification of pseudepigraphic texts –
texts not written by the authors to which they
are attributed – has important historical, fo-
rensic and commercial applications. We in-
troduce an unsupervised technique for identi-
fying pseudepigrapha. The idea is to identify
textual outliers in a corpus based on the pair-
wise similarities of all documents in the cor-
pus. The crucial point is that document simi-
larity not be measured in any of the standard
ways but rather be based on the output of a re-
cently introduced algorithm for authorship ve-
rification. The proposed method strongly
outperforms existing techniques in systematic
experiments on a blog corpus.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999962782608696">
The Shakespeare attribution problem is centuries
old and shows no signs of abating. Some scholars
argue that some, or even all, of Shakespeare’s
works were not actually written by him. The most
mainstream theory – and the one that interests us
here – is that most of the works were written by
Shakespeare, but that several of them were not.
Could modern methods of computational author-
ship attribution be used to detect which, if any, of
the works attributed to Shakespeare were not writ-
ten by him?
More generally, this paper deals with the unsu-
pervised problem of detecting pseudepigrapha:
documents in a supposedly single-author corpus
that were not actually written by the corpus’s pre-
sumed author. Studies as early as Mendenhall
(1887), have observed that texts by a single author
tend to be somewhat homogeneous in style. If this
is indeed the case, we would expect that pseudepi-
grapha would be detectable as outliers.
Identifying such outlier texts is, of course, a
special case of general outlier identification, one of
the central tasks of statistics. We will thus consider
the pseudepigrapha problem in the context of the
more general outlier detection problem.
Typically, research on textual outliers assumes
that we have a corpus of known authentic docu-
ments and are asked to decide if a specified other
document is authentic or not (Juola and Stamata-
tos, 2013). One crucial aspect of our problem is
that we do not assume that any specific text in a
corpus is known a priori to be authentic or pseude-
pigraphic; we can assume only that most of the
documents in the corpus are authentic.
The method we introduce in this paper builds on
the approach of Koppel and Winter (2013) for de-
termining if two documents are by the same au-
thor. We apply that method to every pair of
documents in a corpus and use properties of the
resulting adjacency graph to identify outliers. In
the following section, we briefly outline previous
work. In Section 3 we provide a framework for
outlier detection and in Section 4 we describe our
method. In Section 5 we describe the experimental
setting and give results and in Section 6 we present
results for the plays of Shakespeare.
</bodyText>
<sectionHeader confidence="0.999889" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.997649125">
Identifying outlier texts consists of two main stag-
es: first, representing each text as a numerical vec-
tor representing relevant linguistic features of the
text and second, using generic methods to identify
outlier vectors.
There is a vast literature on generic methods for
outlier detection, summarized in Hodge &amp; Austin
(2004) and Chandola et al. (2009). Since our prob-
</bodyText>
<page confidence="0.944306">
1449
</page>
<bodyText confidence="0.970472866666667">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1449–1454,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
lem setup does not entail obtaining any labeled
examples of authentic or outlier documents, super-
vised and semi-supervised methods are inapplica-
ble. The available methods are unsupervised,
principally probabilistic or proximity-based me-
thods. A classical variant of such methods for un-
ivariate normally distributed data uses the the z-
score (Grubbs, 1969). Such simple univariate out-
lier detectors are, however, inappropriate for iden-
tifying outliers in a high-dimensional textual
corpus. Subsequent work, such as the Stahel-
Donoho Estimator (Stahel, 1981; Donoho, 1982),
PCout (Filzmoser et al., 2008), LOF (Breunig and
Kriegel, 2000) and ABOD (Kriegel et al., 2008)
have generalized univariate methods to high-
dimensional data points.
In his comprehensive review of outlier detection
methods in textual data, Guthrie (2008) compares a
variety of vectorization methods along with a va-
riety of generic outlier methods. The vectorization
methods employ a variety of lexical and syntactic
stylistic features, while the outlier detection me-
thods use a variety of similarity/distance measures
such as cosine and Euclidean distance. Similar me-
thods have also been used in the field of intrinsic
plagiarism detection, which involves segmenting a
text and then identifying outlier segments (Stama-
tatos, 2009; Stein et al., 2010).
</bodyText>
<sectionHeader confidence="0.999704" genericHeader="method">
3 Proximity Methods
</sectionHeader>
<bodyText confidence="0.999451692307692">
Formally, the problem we wish to solve is defined
as follows: Given a set of documents D =
{d1,...,dn}, all or most of which were written by
author A, which, if any, documents in D were not
written by A?
We begin by considering the kinds of proximity
methods for textual outlier detection considered by
Guthrie (2008) and in the work on intrinsic plagiar-
ism detection; these will serve as baseline methods
for our approach. The idea is simple: mark as an
outlier any document that is too far from the rest of
the documents in the corpus.
We briefly sketch the key steps:
</bodyText>
<listItem confidence="0.804252">
1. Represent a document as a numerical vector.
</listItem>
<bodyText confidence="0.999589666666667">
The kinds of measurable features that can be
used to represent a document include frequen-
cies of word unigrams, function words, parts-
of-speech and character n-grams, as well as
complexity measures such as type/token ratio,
sentence and word length and so on.
</bodyText>
<listItem confidence="0.963926">
2. Measure the similarity of two document vec-
tors.
</listItem>
<bodyText confidence="0.99908325">
We can use either inverses of distance meas-
ures such as Euclidean distance or Manhattan
distance, or else direct similarity measures
such as cosine or min-max.
</bodyText>
<listItem confidence="0.9270435">
3. Use an aggregation method to measure the
similarity of a document to a set of documents.
</listItem>
<bodyText confidence="0.9649974">
One approach is to simply measure the dis-
tance from a document to the centroid of all
the other documents (centroid method).
Another approach is to first measure the simi-
larity of a document to each other document
and then to aggregate the results by averaging
all the obtained values (mean method):
Alternatively, we can average the values only
for the k nearest neighbors (k-NN method):
(where Dk = k nearest neighbors of di).
Yet another method is to use median distance
(median method).
We note that the centroid method and mean
method suffer from the masking effect (Bendre
and Kale, 1987; Rousseeuw and Leroy, 2003):
the presence of some outliers in the data can
greatly distort the estimator&apos;s results regarding
the presence of other outliers. The k-NN me-
thod and the median method are both much
more robust.
</bodyText>
<listItem confidence="0.971625">
4. Choose some threshold beyond which a docu-
ment is marked as an outlier.
</listItem>
<bodyText confidence="0.99928">
Choosing the threshold is one of the central is-
sues in statistical approaches. For our purpos-
es, however, the choice of threshold is simply
a parameter trading off recall and precision.
</bodyText>
<sectionHeader confidence="0.995252" genericHeader="method">
4 Second-Order Similarity
</sectionHeader>
<bodyText confidence="0.9891576">
Our approach is to use an entirely different kind of
similarity measure in Step 2. Rather than use a
first-order similarity measure, as is customary, we
employ a second-order similarity measure that is
the output of an algorithm used for the authorship
verification problem (Koppel et al. 2011), in which
we need to determine if two, possibly short, docu-
ments were written by the same author.
That algorithm, known as the “impostors me-
thod” (IM), works as follows. Given two docu-
</bodyText>
<page confidence="0.95853">
1450
</page>
<bodyText confidence="0.999538272727273">
ments, d1 and d2, generate an appropriate set of
impostor documents, p1,...,pm and represent each
of the documents in terms of some large feature set
(for example, the frequencies of various words or
character n-grams in the document). For some ran-
dom subset of the feature set, measure the similari-
ty of d1 to d2 as well as to each of the documents
p1,...,pm and note if d1 is closer to d2 than to any of
the impostors. Repeat this k times, choosing a dif-
ferent random subset of the features in each itera-
tion. If d1 is closer to d2 than to any of the
impostors (and likewise switching the roles of d1
and d2) for at least 0% of iterations, then output
that d2 and d1 are the same author. (The parameter
0 is used to trade-off recall and precision.)
Adapting that method for our purposes, we use
the proportion of iterations for which d1 is closer to
d2 than to any of the impostors as our similarity
measure (adding a small twist to make the measure
symmetric over d1 and d2, as can be seen in line
2.2.2 of the algorithm). More precisely, we do the
following:
</bodyText>
<listItem confidence="0.714599">
Given: Corpus D={d1,...,dn}
1. Choose a feature set FS for representing documents, a
first-order similarity measure sim, and an impostor set
{p1,...,pm}.
2. For each pair of documents &lt;di, dj&gt; in set D:
</listItem>
<table confidence="0.739052875">
2.1. Let sim2(di, dj) := 0
2.2. Iterate K times:
2.2.1. Randomly choose 40% of features in FS
2.2.2. If sim(di, dj) 2 &gt;
maxuE{1,..,m}sim(di, pu)*maxuE{1,..,m}sim(dj, pu),
then sim2(di, dj) ≔ sim2(di, dj) + 1/K
3. For each document di in set D:
3.1. Compute sim2(di, D) = agg wE{1,..,n}[sim2(di, dw)]
</table>
<bodyText confidence="0.916834857142857">
where agg is some aggregation function
3.2. If sim2(di, D) &lt; 0 (where 0 is a parameter),
then mark di as outlier.
The method for choosing the impostor set is
corpus-dependent, but quite straightforward: we
simply choose random impostors from the same
genre and language as the documents in question.
The choice of feature set FS, first-order similarity
measure sim, and aggregation function agg can be
varied. For FS, we simply use bag-of-words
(BOW). As for sim and agg, we show below re-
sults of experiments comparing the effectiveness of
various choices for these parameters.
Using second-order similarity has several sur-
face advantages over standard first-order measures.
First, it is decisive: for most pairs, second-order
similarity will be close to 0 or close to 1. Second, it
is self-normalizing: scaling doesn’t depend on the
size of the underlying feature sets or the lengths of
the documents. As we will see, it is also simply
much more effective for identifying outliers.
</bodyText>
<sectionHeader confidence="0.999408" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.998375444444444">
We begin by assembling a corpus consisting of
3540 blog posts written by 156 different bloggers.
The blogs are taken from the blog corpus assem-
bled by Schler et al. (2006) for use in authorship
attribution tasks. Each of the blogs was written in
English by a single author in 2004 and each post
consists of 1000 words (excess is truncated).
For our initial experiments, each trial consists of
10 blog posts, all but p of which are by a single
blogger. The number of pseudepigraphic docu-
ments, p, is chosen from a uniform distribution
over the set {0,1,2,3}. Our task is to identify
which, if any, documents in the set are not by the
main author of the set. The pseudepigraphic docu-
ments might be written by a single author or by
multiple authors.
To measure the performance of a given similari-
ty measure sim, we do the following in each trial:
</bodyText>
<listItem confidence="0.964913777777778">
1. Represent each document in the trial set D
in terms of BOW.
2. Measure the similarity of each pair of doc-
uments in the trial set using the similarity
measure sim.
3. Using some aggregation function agg,
compute for each document di:
sim(di, D) = agg wE{1,..,n}[sim(di, dw)].
4. If sim (di, D) &lt; 0, mark di as an outlier
</listItem>
<bodyText confidence="0.996325625">
(where 0 is a parameter ).
Our objective is to show that results using
second-order similarity are stronger than those us-
ing first-order similarity. Before we do this, we
need to determine the best aggregation function to
use in our experiments. In Figure 1, we show re-
call-precision breakeven values (for the outlier
class) over 250 independent trials, for each of our
four first-order similarity measures (inverse Eucli-
dean, inverse Manhattan, cosine, min-max) used in
conjunction with each of four aggregation func-
tions (centroid, mean, k-NN mean, median). As is
evident, k-NN is the best aggregation function in
each case. We will give these baseline methods an
advantage by using k-NN as our aggregation func-
tion in all our subsequent experiments.
</bodyText>
<page confidence="0.99579">
1451
</page>
<figureCaption confidence="0.99959">
Figure 1. Breakeven values on first-order similarity
measures with various aggregation functions.
</figureCaption>
<bodyText confidence="0.9993695625">
We are now ready to perform our main expe-
riment. We use BOW as our feature set and k-NN
as our aggregation function. We use 500 random
blog posts as our impostor set. In Figure 2, we
show recall-precision curves for outlier documents
over 250 independent trials, as just described, us-
ing four first-order similarity measures as well our
second-order similarity measure using each of the
four as a base measure. As can be seen, even the
worst second-order similarity measure significantly
outperforms all the standard first-order measures.
In Figure 3, we show the breakeven values for each
measure, pairing each first-order measure with the
second-order measure that uses it as a base. Clear-
ly, the mere use of a second-order method im-
proves results, regardless of the base measure.
</bodyText>
<figureCaption confidence="0.9992468">
Figure 2. Recall-precision curves for four first-order
similarity measures and four second-order similarity
measures, based on 250 trials of 10 documents each.
Figure 3. Breakeven values for first-order measures and
corresponding second-order measures.
</figureCaption>
<bodyText confidence="0.999279444444444">
Thus far we have considered authorial corpora
consisting of only ten documents. In Figures 4 and
5, we repeat the experiment described in Figures 2
and 3 above, but with each trial consisting of 50
documents including any number of pseudepi-
graphic documents in the range 0 to 15. The same
phenomenon is apparent: second-order similarity
strongly improves results over the corresponding
first-order base similarity measure.
</bodyText>
<figureCaption confidence="0.973969333333333">
Figure 4. Recall-precision curves for four first-order
similarity measures and four second-order similarity
measures, based on 250 trials of 50 documents each.
</figureCaption>
<page confidence="0.986827">
1452
</page>
<figureCaption confidence="0.9940995">
Figure 5. Breakeven values for first-order measures and
corresponding second-order measures
</figureCaption>
<sectionHeader confidence="0.998225" genericHeader="evaluation">
6 Results on Shakespeare
</sectionHeader>
<bodyText confidence="0.999958814814815">
We applied our methods to the texts of 42 plays by
Shakespeare (taken from Project Gutenberg). We
included two plays by Thomas Kyd as sanity
checks. In addition, we included three plays occa-
sionally attributed to Shakespeare, but generally
regarded by authorities as pseudepigrapha (A York-
shire Tragedy, The Life of Sir John Oldcastle and
Pericles Prince of Tyre). We also included King
Edward III and King Henry VI (Part 1), both of
which are subjects of dispute among Shakespeare
scholars. As impostors we used 39 works by con-
temporaries of Shakespeare, including Christopher
Marlowe, Ben Jonson and John Fletcher.
We found that the two plays by Thomas Kyd
and the three pseudepigraphic plays were all
among the seven furthest outliers, as one would
expect. In addition, King Edward III was 9th fur-
thest. King Henry VI (Part 1) was not found to be
an outlier at all. Curiously, however, three undis-
puted plays by Shakespeare were found to be
greater outliers than King Edward III. These are
The Merry Wives of Windsor, The Comedy of Er-
rors and The Tragedy of Julius Caesar. The Merry
Wives of Windsor is a particularly distant outlier,
even further out than Oldcastle and Pericles. We
leave it to Shakespeare scholars to explain the rea-
sons for these anomalies.
</bodyText>
<sectionHeader confidence="0.999292" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999492714285714">
In this paper we defined the problem of unsuper-
vised outlier detection in the authorship verifica-
tion domain. Our method combines standard
outlier detection methods with a novel inter-
document similarity measure. This similarity
measure is the output of the impostors method re-
cently developed for solving the authorship verifi-
cation problem. We have found that use of the
kNN method for outlier detection in conjunction
with this second-order similarity measure strongly
outperforms methods based on any outlier detec-
tion method used in conjunction with any standard
first-order similarity measures. This improvement
proves to be robust, holding for various corpus siz-
es and various underlying base similarity measures
used in the second-order similarity measure.
The method can be used to resolve historical
conundrums regarding the authenticity of works in
questioned corpora, such as the Shakespeare cor-
pus briefly considered here. This is currently the
subject of our ongoing research.
</bodyText>
<sectionHeader confidence="0.991839" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.934246153846154">
S. M. Bendre and B. K. Kale. 1987. Masking effect
on tests for outliers in normal samples, Biome-
trika, 74(4):891-896.
Markus M. Breunig, Hans-Peter Kriegel,
Raymond T. Ng and Jörg Sander. 2000. LOF:
Identifying Density-Based Local Outliers, ACM
SIGMOD Conference Proceedings.
Varun Chandola, Arindam Banerjee and Vipin
Kumar. 2009. Anomaly detection: a survey.
ACM Computing Surveys 41, 3, Article 15.
David L. Donoho. 1982. Breakdown properties of
multivariate location estimators. Ph.D.
qualifying paper, Harvard University.
Peter Filzmoser, Ricardo Maronna and Mark
Werner. 2008. Outlier identification in high
dimensions. Computational Statistics and Data
Analysis, 52:1694-1711.
David Guthrie. 2008. Unsupervised Detection of
Anomalous Text. PhD Thesis, University of
Sheffield.
Frank E. Grubbs. 1969. Procedures for detecting
outlying observations in samples,
Technometrics.
V.J. Hodge and J. Austin. 2004. A survey of outlier
detection methodologies. Artificial. Intelligence
Review, 22 (2). pp. 85-126.
</reference>
<page confidence="0.800289">
1453
</page>
<reference confidence="0.998797894736842">
Patrick Juola and Efstathios Stamatatos. 2013.
Overview of the Author Identification Task at
PAN 2013. P. Forner, R. Navigli, and D. Tufis
(eds) CLEF 2013 Evaluation Labs and
Workshop –Working Notes Papers.
Moshe Koppel and Jonathan Schler 2004.
Authorship verification as a one-class
classification problem. In ICML ’04: Twenty-
first International Conference on Machine
Learning, New York, NY, USA.
Moshe Koppel, Jonathan Schler, and Shlomo
Argamon. 2011. Authorship attribution in the
wild. Language Resources and Evaluation,
45(1): 83–94.
Moshe Koppel M. and Yaron Winter. 2013.
Determining If Two Documents Are by the Same
Author. J. Am. Soc. Inf. Sci. Technol.
Frederick Mosteller and David L. Wallace. 1964.
Inference and Disputed Authorship: The
Federalist. Reading, Mass. Addison Wesley.
Hans-Peter Kriegel, Matthias S. Schubert and
Arthur Zimek. 2008. Angle-based outlier
detection in high dimensional data. Proc. KDD.
Thomas C. Mendenhall. 1887. The characteristic
curves of composition, Science 9, 237-259.
Sridhar Ramaswamy, Rajeev Rastogi and Kyuseok
Shim. 2000. Efficient Algorithms for Mining
Outliers from Large Data Sets. Proc. ACM
SIDMOD Int. Conf. on Management of Data.
Peter J. Rousseeuw. 1984. Least median of squares
regression. Journal of the American Statistical
Association, 79(388):87-880.
Peter J. Rousseeuw and Annick M. Leroy. 2003.
Robust Regression and Outlier Detection. John
Wiley &amp; Sons.
J. Schler, M. Koppel, S. Argamon and J.
Pennebaker. 2006. Effects of Age and Gender on
Blogging. in Proceedings of 2006 AAAI Spring
Symposium on Computational Approaches for
Analyzing Weblogs.
Werner A. Stahel. 1981. Breakdown of covariance
estimators. Research Report 31, Fachgruppe f¨ur
Statistik, Swiss Federal Institute of Technology
(ETH), Zurich.
Efstathios Stamatatos. 2009. Intrinsic plagiarism
detection using character n-gram profiles.
Proceedings of the SEPLN’09 Workshop on
Uncovering Plagiarism, Authorship and Social
Software Misuse. pp. 38–46.
Benno Stein B, Nedim Lipka and Peter
Prettenhofer. 2010. Intrinsic Plagiarism
Analysis. Language Resources and Evaluation,
1–20. 2010.
Benno Stein B, Nedim Lipka and Peter
Prettenhofer. 2010. Intrinsic Plagiarism
Analysis. Language Resources and Evaluation,
1–20. 2010.
</reference>
<page confidence="0.995017">
1454
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.177556">
<title confidence="0.8634505">Automatically Identifying Pseudepigraphic Texts Moshe</title>
<author confidence="0.797778">Bar Ilan</author>
<address confidence="0.956865">Ramat-Gan, 52900, Israel</address>
<email confidence="0.999826">moishk@gmail.com</email>
<author confidence="0.489462">Shachar</author>
<affiliation confidence="0.3575">Bar Ilan</affiliation>
<address confidence="0.956143">Ramat-Gan, 52900, Israel</address>
<email confidence="0.998994">shachar9@gmail.com</email>
<abstract confidence="0.999461625">identification of pseudepigraphic texts texts not written by the authors to which they attributed important historical, forensic and commercial applications. We introduce an unsupervised technique for identifying pseudepigrapha. The idea is to identify textual outliers in a corpus based on the pairwise similarities of all documents in the corpus. The crucial point is that document similarity not be measured in any of the standard ways but rather be based on the output of a recently introduced algorithm for authorship verification. The proposed method strongly outperforms existing techniques in systematic experiments on a blog corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S M Bendre</author>
<author>B K Kale</author>
</authors>
<title>Masking effect on tests for outliers in normal samples,</title>
<date>1987</date>
<journal>Biometrika,</journal>
<pages>74--4</pages>
<contexts>
<context position="6758" citStr="Bendre and Kale, 1987" startWordPosition="1095" endWordPosition="1098">ment to a set of documents. One approach is to simply measure the distance from a document to the centroid of all the other documents (centroid method). Another approach is to first measure the similarity of a document to each other document and then to aggregate the results by averaging all the obtained values (mean method): Alternatively, we can average the values only for the k nearest neighbors (k-NN method): (where Dk = k nearest neighbors of di). Yet another method is to use median distance (median method). We note that the centroid method and mean method suffer from the masking effect (Bendre and Kale, 1987; Rousseeuw and Leroy, 2003): the presence of some outliers in the data can greatly distort the estimator&apos;s results regarding the presence of other outliers. The k-NN method and the median method are both much more robust. 4. Choose some threshold beyond which a document is marked as an outlier. Choosing the threshold is one of the central issues in statistical approaches. For our purposes, however, the choice of threshold is simply a parameter trading off recall and precision. 4 Second-Order Similarity Our approach is to use an entirely different kind of similarity measure in Step 2. Rather t</context>
</contexts>
<marker>Bendre, Kale, 1987</marker>
<rawString>S. M. Bendre and B. K. Kale. 1987. Masking effect on tests for outliers in normal samples, Biometrika, 74(4):891-896.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus M Breunig</author>
<author>Hans-Peter Kriegel</author>
<author>Raymond T Ng</author>
<author>Jörg Sander</author>
</authors>
<title>LOF: Identifying Density-Based Local Outliers,</title>
<date>2000</date>
<journal>ACM SIGMOD Conference Proceedings.</journal>
<marker>Breunig, Kriegel, Ng, Sander, 2000</marker>
<rawString>Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng and Jörg Sander. 2000. LOF: Identifying Density-Based Local Outliers, ACM SIGMOD Conference Proceedings.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Varun Chandola</author>
<author>Arindam Banerjee</author>
<author>Vipin Kumar</author>
</authors>
<title>Anomaly detection: a survey.</title>
<date>2009</date>
<journal>ACM Computing Surveys</journal>
<volume>41</volume>
<contexts>
<context position="3424" citStr="Chandola et al. (2009)" startWordPosition="559" endWordPosition="562">line previous work. In Section 3 we provide a framework for outlier detection and in Section 4 we describe our method. In Section 5 we describe the experimental setting and give results and in Section 6 we present results for the plays of Shakespeare. 2 Related Work Identifying outlier texts consists of two main stages: first, representing each text as a numerical vector representing relevant linguistic features of the text and second, using generic methods to identify outlier vectors. There is a vast literature on generic methods for outlier detection, summarized in Hodge &amp; Austin (2004) and Chandola et al. (2009). Since our prob1449 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1449–1454, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics lem setup does not entail obtaining any labeled examples of authentic or outlier documents, supervised and semi-supervised methods are inapplicable. The available methods are unsupervised, principally probabilistic or proximity-based methods. A classical variant of such methods for univariate normally distributed data uses the the zscore (Grubbs, 1969). Such simple univariate </context>
</contexts>
<marker>Chandola, Banerjee, Kumar, 2009</marker>
<rawString>Varun Chandola, Arindam Banerjee and Vipin Kumar. 2009. Anomaly detection: a survey. ACM Computing Surveys 41, 3, Article 15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Donoho</author>
</authors>
<title>Breakdown properties of multivariate location estimators. Ph.D. qualifying paper,</title>
<date>1982</date>
<institution>Harvard University.</institution>
<contexts>
<context position="4213" citStr="Donoho, 1982" startWordPosition="672" endWordPosition="673">13 Association for Computational Linguistics lem setup does not entail obtaining any labeled examples of authentic or outlier documents, supervised and semi-supervised methods are inapplicable. The available methods are unsupervised, principally probabilistic or proximity-based methods. A classical variant of such methods for univariate normally distributed data uses the the zscore (Grubbs, 1969). Such simple univariate outlier detectors are, however, inappropriate for identifying outliers in a high-dimensional textual corpus. Subsequent work, such as the StahelDonoho Estimator (Stahel, 1981; Donoho, 1982), PCout (Filzmoser et al., 2008), LOF (Breunig and Kriegel, 2000) and ABOD (Kriegel et al., 2008) have generalized univariate methods to highdimensional data points. In his comprehensive review of outlier detection methods in textual data, Guthrie (2008) compares a variety of vectorization methods along with a variety of generic outlier methods. The vectorization methods employ a variety of lexical and syntactic stylistic features, while the outlier detection methods use a variety of similarity/distance measures such as cosine and Euclidean distance. Similar methods have also been used in the </context>
</contexts>
<marker>Donoho, 1982</marker>
<rawString>David L. Donoho. 1982. Breakdown properties of multivariate location estimators. Ph.D. qualifying paper, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Filzmoser</author>
<author>Ricardo Maronna</author>
<author>Mark Werner</author>
</authors>
<title>Outlier identification in high dimensions. Computational Statistics and Data Analysis,</title>
<date>2008</date>
<pages>52--1694</pages>
<contexts>
<context position="4245" citStr="Filzmoser et al., 2008" startWordPosition="675" endWordPosition="678">putational Linguistics lem setup does not entail obtaining any labeled examples of authentic or outlier documents, supervised and semi-supervised methods are inapplicable. The available methods are unsupervised, principally probabilistic or proximity-based methods. A classical variant of such methods for univariate normally distributed data uses the the zscore (Grubbs, 1969). Such simple univariate outlier detectors are, however, inappropriate for identifying outliers in a high-dimensional textual corpus. Subsequent work, such as the StahelDonoho Estimator (Stahel, 1981; Donoho, 1982), PCout (Filzmoser et al., 2008), LOF (Breunig and Kriegel, 2000) and ABOD (Kriegel et al., 2008) have generalized univariate methods to highdimensional data points. In his comprehensive review of outlier detection methods in textual data, Guthrie (2008) compares a variety of vectorization methods along with a variety of generic outlier methods. The vectorization methods employ a variety of lexical and syntactic stylistic features, while the outlier detection methods use a variety of similarity/distance measures such as cosine and Euclidean distance. Similar methods have also been used in the field of intrinsic plagiarism de</context>
</contexts>
<marker>Filzmoser, Maronna, Werner, 2008</marker>
<rawString>Peter Filzmoser, Ricardo Maronna and Mark Werner. 2008. Outlier identification in high dimensions. Computational Statistics and Data Analysis, 52:1694-1711.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Guthrie</author>
</authors>
<title>Unsupervised Detection of Anomalous Text.</title>
<date>2008</date>
<tech>PhD Thesis,</tech>
<institution>University of Sheffield.</institution>
<contexts>
<context position="4467" citStr="Guthrie (2008)" startWordPosition="710" endWordPosition="711">listic or proximity-based methods. A classical variant of such methods for univariate normally distributed data uses the the zscore (Grubbs, 1969). Such simple univariate outlier detectors are, however, inappropriate for identifying outliers in a high-dimensional textual corpus. Subsequent work, such as the StahelDonoho Estimator (Stahel, 1981; Donoho, 1982), PCout (Filzmoser et al., 2008), LOF (Breunig and Kriegel, 2000) and ABOD (Kriegel et al., 2008) have generalized univariate methods to highdimensional data points. In his comprehensive review of outlier detection methods in textual data, Guthrie (2008) compares a variety of vectorization methods along with a variety of generic outlier methods. The vectorization methods employ a variety of lexical and syntactic stylistic features, while the outlier detection methods use a variety of similarity/distance measures such as cosine and Euclidean distance. Similar methods have also been used in the field of intrinsic plagiarism detection, which involves segmenting a text and then identifying outlier segments (Stamatatos, 2009; Stein et al., 2010). 3 Proximity Methods Formally, the problem we wish to solve is defined as follows: Given a set of docum</context>
</contexts>
<marker>Guthrie, 2008</marker>
<rawString>David Guthrie. 2008. Unsupervised Detection of Anomalous Text. PhD Thesis, University of Sheffield.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank E Grubbs</author>
</authors>
<title>Procedures for detecting outlying observations in samples,</title>
<date>1969</date>
<tech>Technometrics.</tech>
<contexts>
<context position="3999" citStr="Grubbs, 1969" startWordPosition="642" endWordPosition="643">stin (2004) and Chandola et al. (2009). Since our prob1449 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1449–1454, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics lem setup does not entail obtaining any labeled examples of authentic or outlier documents, supervised and semi-supervised methods are inapplicable. The available methods are unsupervised, principally probabilistic or proximity-based methods. A classical variant of such methods for univariate normally distributed data uses the the zscore (Grubbs, 1969). Such simple univariate outlier detectors are, however, inappropriate for identifying outliers in a high-dimensional textual corpus. Subsequent work, such as the StahelDonoho Estimator (Stahel, 1981; Donoho, 1982), PCout (Filzmoser et al., 2008), LOF (Breunig and Kriegel, 2000) and ABOD (Kriegel et al., 2008) have generalized univariate methods to highdimensional data points. In his comprehensive review of outlier detection methods in textual data, Guthrie (2008) compares a variety of vectorization methods along with a variety of generic outlier methods. The vectorization methods employ a var</context>
</contexts>
<marker>Grubbs, 1969</marker>
<rawString>Frank E. Grubbs. 1969. Procedures for detecting outlying observations in samples, Technometrics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V J Hodge</author>
<author>J Austin</author>
</authors>
<title>A survey of outlier detection methodologies.</title>
<date>2004</date>
<journal>Artificial. Intelligence Review,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>85--126</pages>
<contexts>
<context position="3397" citStr="Hodge &amp; Austin (2004)" startWordPosition="554" endWordPosition="557">ng section, we briefly outline previous work. In Section 3 we provide a framework for outlier detection and in Section 4 we describe our method. In Section 5 we describe the experimental setting and give results and in Section 6 we present results for the plays of Shakespeare. 2 Related Work Identifying outlier texts consists of two main stages: first, representing each text as a numerical vector representing relevant linguistic features of the text and second, using generic methods to identify outlier vectors. There is a vast literature on generic methods for outlier detection, summarized in Hodge &amp; Austin (2004) and Chandola et al. (2009). Since our prob1449 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1449–1454, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics lem setup does not entail obtaining any labeled examples of authentic or outlier documents, supervised and semi-supervised methods are inapplicable. The available methods are unsupervised, principally probabilistic or proximity-based methods. A classical variant of such methods for univariate normally distributed data uses the the zscore (Grubbs, 196</context>
</contexts>
<marker>Hodge, Austin, 2004</marker>
<rawString>V.J. Hodge and J. Austin. 2004. A survey of outlier detection methodologies. Artificial. Intelligence Review, 22 (2). pp. 85-126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Juola</author>
<author>Efstathios Stamatatos</author>
</authors>
<title>Overview of the Author Identification Task at PAN</title>
<date>2013</date>
<booktitle>Tufis (eds) CLEF 2013 Evaluation Labs and Workshop –Working Notes Papers.</booktitle>
<contexts>
<context position="2257" citStr="Juola and Stamatatos, 2013" startWordPosition="355" endWordPosition="359"> observed that texts by a single author tend to be somewhat homogeneous in style. If this is indeed the case, we would expect that pseudepigrapha would be detectable as outliers. Identifying such outlier texts is, of course, a special case of general outlier identification, one of the central tasks of statistics. We will thus consider the pseudepigrapha problem in the context of the more general outlier detection problem. Typically, research on textual outliers assumes that we have a corpus of known authentic documents and are asked to decide if a specified other document is authentic or not (Juola and Stamatatos, 2013). One crucial aspect of our problem is that we do not assume that any specific text in a corpus is known a priori to be authentic or pseudepigraphic; we can assume only that most of the documents in the corpus are authentic. The method we introduce in this paper builds on the approach of Koppel and Winter (2013) for determining if two documents are by the same author. We apply that method to every pair of documents in a corpus and use properties of the resulting adjacency graph to identify outliers. In the following section, we briefly outline previous work. In Section 3 we provide a framework</context>
</contexts>
<marker>Juola, Stamatatos, 2013</marker>
<rawString>Patrick Juola and Efstathios Stamatatos. 2013. Overview of the Author Identification Task at PAN 2013. P. Forner, R. Navigli, and D. Tufis (eds) CLEF 2013 Evaluation Labs and Workshop –Working Notes Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Koppel</author>
<author>Jonathan Schler</author>
</authors>
<title>Authorship verification as a one-class classification problem.</title>
<date>2004</date>
<booktitle>In ICML ’04: Twentyfirst International Conference on Machine Learning,</booktitle>
<location>New York, NY, USA.</location>
<marker>Koppel, Schler, 2004</marker>
<rawString>Moshe Koppel and Jonathan Schler 2004. Authorship verification as a one-class classification problem. In ICML ’04: Twentyfirst International Conference on Machine Learning, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Koppel</author>
<author>Jonathan Schler</author>
<author>Shlomo Argamon</author>
</authors>
<title>Authorship attribution in the wild.</title>
<date>2011</date>
<journal>Language Resources and Evaluation,</journal>
<volume>45</volume>
<issue>1</issue>
<pages>83--94</pages>
<contexts>
<context position="7561" citStr="Koppel et al. 2011" startWordPosition="1228" endWordPosition="1231">dian method are both much more robust. 4. Choose some threshold beyond which a document is marked as an outlier. Choosing the threshold is one of the central issues in statistical approaches. For our purposes, however, the choice of threshold is simply a parameter trading off recall and precision. 4 Second-Order Similarity Our approach is to use an entirely different kind of similarity measure in Step 2. Rather than use a first-order similarity measure, as is customary, we employ a second-order similarity measure that is the output of an algorithm used for the authorship verification problem (Koppel et al. 2011), in which we need to determine if two, possibly short, documents were written by the same author. That algorithm, known as the “impostors method” (IM), works as follows. Given two docu1450 ments, d1 and d2, generate an appropriate set of impostor documents, p1,...,pm and represent each of the documents in terms of some large feature set (for example, the frequencies of various words or character n-grams in the document). For some random subset of the feature set, measure the similarity of d1 to d2 as well as to each of the documents p1,...,pm and note if d1 is closer to d2 than to any of the </context>
</contexts>
<marker>Koppel, Schler, Argamon, 2011</marker>
<rawString>Moshe Koppel, Jonathan Schler, and Shlomo Argamon. 2011. Authorship attribution in the wild. Language Resources and Evaluation, 45(1): 83–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Moshe Koppel M</author>
<author>Yaron Winter</author>
</authors>
<title>Determining If Two Documents Are by the Same Author.</title>
<date>2013</date>
<journal>J. Am. Soc. Inf. Sci. Technol.</journal>
<marker>M, Winter, 2013</marker>
<rawString>Moshe Koppel M. and Yaron Winter. 2013. Determining If Two Documents Are by the Same Author. J. Am. Soc. Inf. Sci. Technol.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Mosteller</author>
<author>David L Wallace</author>
</authors>
<title>Inference and Disputed Authorship: The Federalist.</title>
<date>1964</date>
<publisher>Addison Wesley.</publisher>
<location>Reading, Mass.</location>
<marker>Mosteller, Wallace, 1964</marker>
<rawString>Frederick Mosteller and David L. Wallace. 1964. Inference and Disputed Authorship: The Federalist. Reading, Mass. Addison Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans-Peter Kriegel</author>
<author>Matthias S Schubert</author>
<author>Arthur Zimek</author>
</authors>
<title>Angle-based outlier detection in high dimensional data.</title>
<date>2008</date>
<booktitle>Proc. KDD.</booktitle>
<contexts>
<context position="4310" citStr="Kriegel et al., 2008" startWordPosition="686" endWordPosition="689">led examples of authentic or outlier documents, supervised and semi-supervised methods are inapplicable. The available methods are unsupervised, principally probabilistic or proximity-based methods. A classical variant of such methods for univariate normally distributed data uses the the zscore (Grubbs, 1969). Such simple univariate outlier detectors are, however, inappropriate for identifying outliers in a high-dimensional textual corpus. Subsequent work, such as the StahelDonoho Estimator (Stahel, 1981; Donoho, 1982), PCout (Filzmoser et al., 2008), LOF (Breunig and Kriegel, 2000) and ABOD (Kriegel et al., 2008) have generalized univariate methods to highdimensional data points. In his comprehensive review of outlier detection methods in textual data, Guthrie (2008) compares a variety of vectorization methods along with a variety of generic outlier methods. The vectorization methods employ a variety of lexical and syntactic stylistic features, while the outlier detection methods use a variety of similarity/distance measures such as cosine and Euclidean distance. Similar methods have also been used in the field of intrinsic plagiarism detection, which involves segmenting a text and then identifying ou</context>
</contexts>
<marker>Kriegel, Schubert, Zimek, 2008</marker>
<rawString>Hans-Peter Kriegel, Matthias S. Schubert and Arthur Zimek. 2008. Angle-based outlier detection in high dimensional data. Proc. KDD.</rawString>
</citation>
<citation valid="false">
<title>The characteristic curves of composition,</title>
<journal>Science</journal>
<volume>9</volume>
<pages>237--259</pages>
<marker></marker>
<rawString>Thomas C. Mendenhall. 1887. The characteristic curves of composition, Science 9, 237-259.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sridhar Ramaswamy</author>
<author>Rajeev Rastogi</author>
<author>Kyuseok Shim</author>
</authors>
<title>Efficient Algorithms for Mining Outliers from Large Data Sets.</title>
<date>2000</date>
<booktitle>Proc. ACM SIDMOD Int. Conf. on Management of Data.</booktitle>
<marker>Ramaswamy, Rastogi, Shim, 2000</marker>
<rawString>Sridhar Ramaswamy, Rajeev Rastogi and Kyuseok Shim. 2000. Efficient Algorithms for Mining Outliers from Large Data Sets. Proc. ACM SIDMOD Int. Conf. on Management of Data.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter J Rousseeuw</author>
</authors>
<title>Least median of squares regression.</title>
<date>1984</date>
<journal>Journal of the American Statistical Association,</journal>
<pages>79--388</pages>
<marker>Rousseeuw, 1984</marker>
<rawString>Peter J. Rousseeuw. 1984. Least median of squares regression. Journal of the American Statistical Association, 79(388):87-880.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter J Rousseeuw</author>
<author>Annick M Leroy</author>
</authors>
<title>Robust Regression and Outlier Detection.</title>
<date>2003</date>
<publisher>John Wiley &amp; Sons.</publisher>
<contexts>
<context position="6786" citStr="Rousseeuw and Leroy, 2003" startWordPosition="1099" endWordPosition="1102">nts. One approach is to simply measure the distance from a document to the centroid of all the other documents (centroid method). Another approach is to first measure the similarity of a document to each other document and then to aggregate the results by averaging all the obtained values (mean method): Alternatively, we can average the values only for the k nearest neighbors (k-NN method): (where Dk = k nearest neighbors of di). Yet another method is to use median distance (median method). We note that the centroid method and mean method suffer from the masking effect (Bendre and Kale, 1987; Rousseeuw and Leroy, 2003): the presence of some outliers in the data can greatly distort the estimator&apos;s results regarding the presence of other outliers. The k-NN method and the median method are both much more robust. 4. Choose some threshold beyond which a document is marked as an outlier. Choosing the threshold is one of the central issues in statistical approaches. For our purposes, however, the choice of threshold is simply a parameter trading off recall and precision. 4 Second-Order Similarity Our approach is to use an entirely different kind of similarity measure in Step 2. Rather than use a first-order simila</context>
</contexts>
<marker>Rousseeuw, Leroy, 2003</marker>
<rawString>Peter J. Rousseeuw and Annick M. Leroy. 2003. Robust Regression and Outlier Detection. John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Schler</author>
<author>M Koppel</author>
<author>S Argamon</author>
<author>J Pennebaker</author>
</authors>
<title>Effects of Age and Gender on Blogging.</title>
<date>2006</date>
<booktitle>in Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs.</booktitle>
<contexts>
<context position="10485" citStr="Schler et al. (2006)" startWordPosition="1739" endWordPosition="1742">choices for these parameters. Using second-order similarity has several surface advantages over standard first-order measures. First, it is decisive: for most pairs, second-order similarity will be close to 0 or close to 1. Second, it is self-normalizing: scaling doesn’t depend on the size of the underlying feature sets or the lengths of the documents. As we will see, it is also simply much more effective for identifying outliers. 5 Experiments We begin by assembling a corpus consisting of 3540 blog posts written by 156 different bloggers. The blogs are taken from the blog corpus assembled by Schler et al. (2006) for use in authorship attribution tasks. Each of the blogs was written in English by a single author in 2004 and each post consists of 1000 words (excess is truncated). For our initial experiments, each trial consists of 10 blog posts, all but p of which are by a single blogger. The number of pseudepigraphic documents, p, is chosen from a uniform distribution over the set {0,1,2,3}. Our task is to identify which, if any, documents in the set are not by the main author of the set. The pseudepigraphic documents might be written by a single author or by multiple authors. To measure the performan</context>
</contexts>
<marker>Schler, Koppel, Argamon, Pennebaker, 2006</marker>
<rawString>J. Schler, M. Koppel, S. Argamon and J. Pennebaker. 2006. Effects of Age and Gender on Blogging. in Proceedings of 2006 AAAI Spring Symposium on Computational Approaches for Analyzing Weblogs.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Werner A Stahel</author>
</authors>
<title>Breakdown of covariance estimators.</title>
<date>1981</date>
<booktitle>Research Report 31, Fachgruppe f¨ur Statistik, Swiss Federal Institute of Technology (ETH),</booktitle>
<location>Zurich.</location>
<contexts>
<context position="4198" citStr="Stahel, 1981" startWordPosition="670" endWordPosition="671">ber 2013. c�2013 Association for Computational Linguistics lem setup does not entail obtaining any labeled examples of authentic or outlier documents, supervised and semi-supervised methods are inapplicable. The available methods are unsupervised, principally probabilistic or proximity-based methods. A classical variant of such methods for univariate normally distributed data uses the the zscore (Grubbs, 1969). Such simple univariate outlier detectors are, however, inappropriate for identifying outliers in a high-dimensional textual corpus. Subsequent work, such as the StahelDonoho Estimator (Stahel, 1981; Donoho, 1982), PCout (Filzmoser et al., 2008), LOF (Breunig and Kriegel, 2000) and ABOD (Kriegel et al., 2008) have generalized univariate methods to highdimensional data points. In his comprehensive review of outlier detection methods in textual data, Guthrie (2008) compares a variety of vectorization methods along with a variety of generic outlier methods. The vectorization methods employ a variety of lexical and syntactic stylistic features, while the outlier detection methods use a variety of similarity/distance measures such as cosine and Euclidean distance. Similar methods have also be</context>
</contexts>
<marker>Stahel, 1981</marker>
<rawString>Werner A. Stahel. 1981. Breakdown of covariance estimators. Research Report 31, Fachgruppe f¨ur Statistik, Swiss Federal Institute of Technology (ETH), Zurich.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Efstathios Stamatatos</author>
</authors>
<title>Intrinsic plagiarism detection using character n-gram profiles.</title>
<date>2009</date>
<booktitle>Proceedings of the SEPLN’09 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse.</booktitle>
<pages>38--46</pages>
<contexts>
<context position="4942" citStr="Stamatatos, 2009" startWordPosition="781" endWordPosition="783">d univariate methods to highdimensional data points. In his comprehensive review of outlier detection methods in textual data, Guthrie (2008) compares a variety of vectorization methods along with a variety of generic outlier methods. The vectorization methods employ a variety of lexical and syntactic stylistic features, while the outlier detection methods use a variety of similarity/distance measures such as cosine and Euclidean distance. Similar methods have also been used in the field of intrinsic plagiarism detection, which involves segmenting a text and then identifying outlier segments (Stamatatos, 2009; Stein et al., 2010). 3 Proximity Methods Formally, the problem we wish to solve is defined as follows: Given a set of documents D = {d1,...,dn}, all or most of which were written by author A, which, if any, documents in D were not written by A? We begin by considering the kinds of proximity methods for textual outlier detection considered by Guthrie (2008) and in the work on intrinsic plagiarism detection; these will serve as baseline methods for our approach. The idea is simple: mark as an outlier any document that is too far from the rest of the documents in the corpus. We briefly sketch t</context>
</contexts>
<marker>Stamatatos, 2009</marker>
<rawString>Efstathios Stamatatos. 2009. Intrinsic plagiarism detection using character n-gram profiles. Proceedings of the SEPLN’09 Workshop on Uncovering Plagiarism, Authorship and Social Software Misuse. pp. 38–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benno Stein B</author>
<author>Nedim Lipka</author>
<author>Peter Prettenhofer</author>
</authors>
<title>Intrinsic Plagiarism Analysis. Language Resources and Evaluation,</title>
<date>2010</date>
<marker>B, Lipka, Prettenhofer, 2010</marker>
<rawString>Benno Stein B, Nedim Lipka and Peter Prettenhofer. 2010. Intrinsic Plagiarism Analysis. Language Resources and Evaluation, 1–20. 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benno Stein B</author>
<author>Nedim Lipka</author>
<author>Peter Prettenhofer</author>
</authors>
<title>Intrinsic Plagiarism Analysis. Language Resources and Evaluation,</title>
<date>2010</date>
<marker>B, Lipka, Prettenhofer, 2010</marker>
<rawString>Benno Stein B, Nedim Lipka and Peter Prettenhofer. 2010. Intrinsic Plagiarism Analysis. Language Resources and Evaluation, 1–20. 2010.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>