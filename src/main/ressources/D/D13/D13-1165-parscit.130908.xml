<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.041325">
<title confidence="0.9892075">
Pair Language Models for Deriving Alternative
Pronunciations and Spellings from Pronunciation Dictionaries
</title>
<author confidence="0.956915">
Russell Beckley
</author>
<affiliation confidence="0.936197">
Oregon Health and Science University
</affiliation>
<email confidence="0.978837">
beckleyr@ohsu.com
</email>
<sectionHeader confidence="0.997187" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994845625">
Pronunciation dictionaries provide a readily
available parallel corpus for learning to trans-
duce between character strings and phoneme
strings or vice versa. Translation models can
be used to derive character-level paraphrases
on either side of this transduction, allowing
for the automatic derivation of alternative pro-
nunciations or spellings. We examine finite-
state and SMT-based methods for these related
tasks, and demonstrate that the tasks have
different characteristics – finding alternative
spellings is harder than alternative pronunci-
ations and benefits from round-trip algorithms
when the other does not. We also show that
we can increase accuracy by modeling sylla-
ble stress.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998538">
Robust processing of speech and language requires
dealing with variation in language production, ei-
ther in terms of pronunciation in the spoken domain
or spelling in the written domain. Predicting the
intended words of an acoustic or textual sequence
is an important recognition task, often required for
downstream processing such as spoken language un-
derstanding or knowledge extraction. Informal text
genres, such as those found in social media, share
some characteristics with speech; in fact such text is
often informed by pronunciation variation. For ex-
ample, consider the following tweet:
He aint gotta question my loyalty, cuz he knw
wen sh!t get real. Ill be right here!
where several tokens (e.g. “cuz”, “wen”) represent
spelling alternations related to pronunciation. Work
in text normalization and spelling correction – e.g.,
Toutanova and Moore (2002); Li and Liu (2012) –
has included pronunciation information to improve
recognition of the intended word, via grapheme to
</bodyText>
<note confidence="0.7174235">
Brian Roark
Google Inc.
</note>
<email confidence="0.854353">
roarkbr@gmail.com
</email>
<bodyText confidence="0.999107375">
phoneme (g2p) conversion modeling derived from
pronunciation dictionaries.
Pronunciation dictionaries provide natural par-
allel corpora, with strings of characters paired to
strings of phones. Thus, standard lexicons have
been used in recent years with machine transla-
tion systems such as Moses (Koehn et al., 2007),
to train g2p systems (Laurent et al., 2009; Gerosa
and Federico, 2009). Further, other algorithms us-
ing such dictionaries also use translation phrase
tables, but not for translation tasks. For exam-
ple, data-driven paraphrasing methods (Bannard and
Callison-Burch, 2005) use translation phrase-tables
as a “pivot” to learn sets of phrases which trans-
lated to the same target phrase. In a similar manner,
with a pronunciation dictionary instead of a phrse-
table, pivoting can be used to learn alternative pro-
nunciations (Karanasou and Lamel, 2010), i.e., di-
rect phoneme-to-phoneme (p2p) “translation” sys-
tems that yield alternative pronunciations. Alterna-
tively, round-trip translation could be used, e.g., to
map from letter strings to phone strings in one step,
then from the resulting phone strings to letter strings
in a second step, as the means to find alternative
spellings (Li and Liu, 2012).
In this study, we explore dictionary-derived mod-
els to find either alternative pronunciations or alter-
native spellings, using either direct (p2p or g2g) or
round-trip algorithms (p2g2p or g2p2g). We com-
pare methods based on weighted finite-state trans-
ducers (WFST) with phrase-based models trained
with Moses. Our main interest is to evaluate Karana-
sou and Lamel (2010) methods – shown to be useful
for deriving alternative pronunciations – for deriv-
ing alternative spellings, and thus to determine the
relative difficulty of these two tasks. We also exam-
ine when, if ever, round-trip processing yields ben-
efits over direct transduction. Our results indicate
that real alternative pronunciations are substantially
easier to find than real alternative spellings, partic-
</bodyText>
<page confidence="0.921246">
1584
</page>
<bodyText confidence="0.959588454545455">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1584–1589,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
ularly when pronunciation features such as syllable
stress are available. Second, round trip translation
yields no gain (and some loss) over direct transduc-
tion for finding alternative pronunciations, yet yields
some modest gains for finding alternative spellings.
Further, WFST methods perform as well as or bet-
ter than Moses trained models. Finally, combining
the methods yields further gains, indicating that the
models are learning complementary sets of patterns.
The primary contribution of this work is to in-
troduce a competitive method of building and us-
ing pair language model WFSTs for generating al-
ternative spellings and pronunciations which reflect
real-world variability. This could improve results for
downstream processes, e.g., epidemiological studies
(Chew and Eysenbach, 2010) or sentiment analysis
(Barbosa and Feng, 2010) derived from social me-
dia text. Further, we present a controlled compari-
son between the two tasks, and demonstrate that they
differ in terms of task difficulty
</bodyText>
<sectionHeader confidence="0.999855" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.999955833333333">
Text normalization has been a major focus in text-
to-speech (TTS) research for many years. Notably,
Sproat et al. (2001) deemed it a problem in itself,
rather than ad hoc preparatory work, and defined
many of the issues involved, as well as offering a va-
riety of initial solutions. Similar approaches apply to
automatic spelling correction, where Toutanova and
Moore (2002) extended the noisy channel spelling
correction method of Brill and Moore (2000), by
modeling pronunciation alternations to infer from
misspellings to correct spellings. Similarly, Li and
Liu (2012) extended the character-based translation
approach to text normalization of Pennell and Liu
(2011), by adding an additional round-trip trans-
lation to-and-from pronunciations. Karanasou and
Lamel (2010) used Moses to generate alternative
pronunciations from an English dictionary, using
both direct and round-trip methods. They validated
their systems on a set of words with multiple pro-
nunciations, measuring the degree to which alterna-
tive pronunciations are generated from one of the
given pronunciations. Our task and method of eval-
uation is similar to theirs, though we also look at
alternative spellings.
</bodyText>
<sectionHeader confidence="0.998619" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.986400166666667">
To generate alternative spellings and pronunciations,
we built phrase-based translation and finite-state
transduction models from a parallel corpus. When
pronunciations were part of the model – i.e., not
direct grapheme-to-grapheme – we included condi-
tions with and without vowel stress.
</bodyText>
<subsectionHeader confidence="0.999202">
3.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999938794117647">
Our training corpus is the CMU Pronouncing Dictio-
nary1, which contains nearly 130k entries. From this
corpus, we identified homophone sets, i.e., sets of
multiple spellings sharing the same pronunciation,
such as “colonel” and “kernel”. We found 9,977
such sets, and randomly selected 1000 for testing;
the rest we used for training. Each set had, on aver-
age, 2.46 members. We also identified homograph
sets, i.e., sets of multiple pronunciations all spelled
the same, such as potato (/potato/ and /pateto/). We
found 8,216 such homograph sets, and randomly se-
lected 1000 for testing; the rest we used for training.
These sets averaged 2.13 members.
We construct seven parallel training corpora from
the lexicon, each disjoint from its relevant test
set. For round-trip models, the parallel corpus is
each grapheme string in the lexicon aligned with
its phoneme string, if neither the grapheme string
nor phoneme string appear in the test set. There
are four such corpora, corresponding to these op-
tions: stress or no stress, and g2p2g or p2g2p. The
g2p2g and p2g2g conditions require different cor-
pora because they are differently partitioned for test-
ing. For direct grapheme-to-grapheme training sets,
non-homophone words are self-aligned; for homo-
phones, from each homophone set, each possible
pair of spellings are aligned. For example, for a
pronunciation with four spellings—a, b, c, and d—
there would be six alignments: a:b, a:c, a:d, b:c, b:d,
c:d. Similarly for direct phoneme-to-phoneme train-
ing sets, non-homograph words are self-aligned;
words from the training homograph sets are pairwise
aligned in all pairings. There are two direct p2p cor-
pora: with and without stress.
</bodyText>
<subsectionHeader confidence="0.999823">
3.2 Phrase-based translation models
</subsectionHeader>
<bodyText confidence="0.999947">
As a baseline system, we used the Moses statisti-
cal machine translation package (Koehn et al., 2007)
to build grapheme-based and phoneme-based trans-
lation systems, using a bigram language model.2
These are trained on the parallel corpus resulting
from the homophone or homograph sets detailed in
</bodyText>
<footnote confidence="0.999562">
1http://www.speech.cs.cmu.edu/cgi-bin/cmudict
2Higher order language models yielded no improvements.
</footnote>
<page confidence="0.991935">
1585
</page>
<bodyText confidence="0.9999195">
the previous section for the direct methods. For this
paper, we did not perform round-trip translation with
Moses, rather present it as a baseline for the direct
approach.
</bodyText>
<subsectionHeader confidence="0.999213">
3.3 Pair language models
</subsectionHeader>
<bodyText confidence="0.999787142857143">
Our weighted finite-state transducer approach is
based on pair language models (Bisani and Ney,
2008; Deligne and Bimbot, 1997; Ghoshal et al.,
2009), or, more recently, (Sagae et al., 2012).) The
basic idea in a pair LM is to align strings, then train a
language model over sequences whose symbols are
the input:output pairs of the alignment. This lan-
guage model can then be converted to transducers.
For a g2g example, homophones “their” and “there”
are aligned via the standard Levenshtein edit dis-
tance algorithm as “t:t h:h e:e i:E r:r E:e”. A trigram
model over these x:y strings would use standard n-
gram modeling to estimate, for example, P(E:e  |i:E
r:r); i.e., the probability of a silent “r” in a given con-
text.
Building the pair language model transducers re-
quires two phases. In the first phase we create new
corpora by aligning the elements of the parallel cor-
pora outlined above. In the second phase we use
these corpora of string alignments to build a pair lan-
guage model.
</bodyText>
<subsectionHeader confidence="0.92418">
3.3.1 Alignment and Corpora Building
</subsectionHeader>
<bodyText confidence="0.99963527027027">
We use extensions to the Levenshtein edit dis-
tance algorithm to align g2g, p2p and g2p strings,
with substitution matrices created to provide use-
ful alignments (Wagner and Fischer, 1974). As in
Brill and Moore (2000), we allow for certain multi-
symbol strings to be substituted with a single cost,
e.g., substituting ‘th’ with /B/ in g2p alignment. For
g2g alignment, our substitution cost is 0 for identity
and 2 for a few pairs of commonly interchangeable
graphemes, such as ‘c’ and ‘k’. Other substitutions
are not permitted, and delete and insertion have cost
10. For p2p alignment there are two conditions, with
and without stress. Without vowel stress, no substi-
tutions other than identity are allowed; with vowel
stress, substitution cost is 2.5 for the same vowel
with differing stress; and 5.0 if substituting a vowel
with another vowel. Other substitutions are not per-
mitted, and, again, delete and insertion have cost 10.
For training round-trip models, we have to per-
form g2p and p2g alignment, with differing al-
phabets on the input and output of the alignment.
We begin with a basic substitution table that al-
lows graphemes and their most likely phonemes to
align. We then re-estimate the substitution costs
based on relative frequency estimation (-logP), and
also aggregate sequences of consecutively deleted
graphemes so that they collectively map to a single
phoneme. For example, given the alignment ‘o:/a/
u:/E/ g:/E/ h:/E/ t:/t/’, (‘ought’, /at/), we make a new
rule: ough:/a/, and give it a cost based on its rela-
tive frequency. Grapheme strings that appear suffi-
ciently often with a given phoneme will thus accu-
mulate sufficient probability mass to compete.
Each alignment produced as described above is a
string in a training corpus for creating a pair lan-
guage model. As such, each alignment pair (e.g.
a:/a/) is a token.
</bodyText>
<subsectionHeader confidence="0.486516">
3.3.2 From Corpora to WFSTs
</subsectionHeader>
<bodyText confidence="0.999992133333333">
We use the open source OpenGrm NGram library
(Roark et al., 2012) to build 5-gram language mod-
els from the strings of input:output pairs. These lan-
gauge models are encoded as weighted finite-state
acceptors in the OpenFst format (Allauzen et al.,
2007). We shrink the models with the ngramshrink
command, using the relative entropy method (Stol-
cke, 1998), with the “theta” threshold set at 1.0e−6.
These finite state acceptors are then converted into
transducers by modifying the arcs: split the labels
of each arc, x:y, making x the input label for that
arc, and y the output label. Thus traversing such
an arc will consume an x a return a y. Such pair
language models we use for all WFST methods dis-
cussed here.
</bodyText>
<subsectionHeader confidence="0.997698">
3.4 Producing k-best output
</subsectionHeader>
<bodyText confidence="0.999988466666667">
Each tested input string, spelling or pronunciation,
is encoded as a cost-free linear chain WFST and
composed with a pair language model transducer de-
scribed in the previous section. The resulting lattice
is converted to an acceptor by projecting onto its out-
put labels, i.e., for each arc, the input label is set to
the value of the output label. Epsilons are then re-
moved and the result is determinized. The k-best
paths are extracted using the shortest path algorithm
in the OpenFst library.
For direct models (g2g and p2p), the k-best out-
put from this first transduction is our result, ranked
according the probability of each path. For round-
trip methods (e.g. g2p2g), however, we do a second
transduction in the other direction. For example, for
</bodyText>
<page confidence="0.964247">
1586
</page>
<bodyText confidence="0.999181363636364">
g2p2g, the first transduction would have transduced
from a spelling to a set of candidate pronunciations;
the second transduction will transduce from pronun-
ciations to spellings. For this second transduction,
we take each string s from the k-best list from the
first transduction, and process them as we did in the
first transduction, now using the inverse transducer.
So, for each s in the first k-best list, we now have a k-
best list from the second transduction. Thus, for the
original input string, we have up to k2 alternatives.
Finally, we score each alternative by combining their
scores from both transductions.
Let p� represent a phoneme string, and g� a
grapheme string. If we perform a transduction from
p� to g, the weights from the transducer provide the
(negative log) joint probability P(p, g). By perform-
ing a soft-max normalization over the k-best list out-
put, we obtain the (negative log) conditional proba-
bility P(g  |p). For round-trip methods, we take the
product of the conditional probability in each direc-
tion, and marginalize out the intermediate grapheme
sequence, i.e.,
</bodyText>
<equation confidence="0.9923605">
P(�p2  |p1) = � P(p2  |g) P(g  |p1).
s
</equation>
<sectionHeader confidence="0.997598" genericHeader="method">
4 Experimental results
</sectionHeader>
<bodyText confidence="0.9993568">
For evaluation purposes, we reserved a set of 1000
test homophone sets and 1000 test homograph sets,
as described in Section 3.1. From each set, we gen-
erate alternatives from the longest set member (ties
broken alphabetically) and examine the resulting k-
best list for presence of other members of the set.
Note that the input string itself is not a target, and,
before evaluation, is removed from the k-best list.
Recall is the proportion of the k-best list returned by
the system:
</bodyText>
<equation confidence="0.849370333333333">
Recall({k-best}) =  |{k-best} n {gold-list} |
 |{gold-list} |
.
</equation>
<bodyText confidence="0.9996508">
Results for generating alternative pronunciations
are listed in Table 1; those for generating alternative
spellings are in Table 2. For alternative spellings,
we also present results that combine the outputs of
direct, round-trip (no stress) and Moses into a sin-
gle list using a simple ranked voting scheme (simple
Borda count).
A noteworthy result is the apparent usefulness of
stress modeling for predicting pronunciation varia-
tion using WFSTs with the direct method; this is
</bodyText>
<table confidence="0.9972584">
Recall: Alternative Pronunciations
k- pair language model Moses
best Direct
size
Direct Roundtrip
stress none stress none stress none
1 0.43 0.54 0.38 0.37 0.44 0.46
3 0.77 0.71 0.59 0.58 0.60 0.62
5 0.82 0.77 0.66 0.66 0.64 0.65
10 0.86 0.80 0.73 0.76 0.68 0.69
</table>
<tableCaption confidence="0.999155">
Table 1: Recall for generating alternative pronunciations
</tableCaption>
<bodyText confidence="0.999985463414634">
seen in the first two data columns of 1. This sug-
gests that stress has an effect on phoneme alteration,
something we discuss in more detail in Section 5.
However, while providing a large gain in the p2p
condition, pronunciation modeling gives small or
negative effects elsewhere. In the round trip meth-
ods, the effects of stress are lost: stress has little
influence of how a particular phoneme is spelled.
Thus, graphemes do not retain much stress informa-
tion, hence any pass through the orthographic do-
main will shed it.
Recall is higher for alternative pronunciations
than for alternative spellings. One reason for this
is that spellings in our test set average eight let-
ters, whereas the pronunciations average around five
phonemes. Furthermore, the average Levenshtein
distance between original spellings and their tar-
get alternatives, is 2.6, while for pronunciations, it
is 2.2. Combining these factors, we see that, for
spellings, more edit operations are required, and
there are more symbols to which to apply them.
Therefore, for spellings, there are more incorrect
candidates.
The results also show gains resulting from the
roundtrip method when applied to finding alternative
spellings, but no such gains when roundtrip methods
are applied to alternative pronunciations. Suppose,
when seeking alternatives for some spelling, we al-
ter grapheme g1 to g2. With a direct method, we
must have instances of g1 mapping to g2 in the train-
ing set. The roundtrip method, however, is less con-
strained: there must exist some phoneme p1 in the
training set such that g1 maps to p1, and p1 maps to
g2; thus, the set of possible alternations at testing are
{g1 — p1} x {p1 — g2}. This argument also ap-
plies to finding alternative pronunciations. Thus the
roundtrip method offers more possible mappings.
These extra possible mappings may be helpful or
harmful, depending on how likely they are compared
to the possible mappings they displace. Why are
they helpful for alternative spellings, but not for al-
</bodyText>
<page confidence="0.977592">
1587
</page>
<table confidence="0.9993058">
Recall: Alternative Spellings
k- pair language model Moses Comb.
best Direct Direct
size
Direct Roundtrip
none stress none none none
1 0.19 0.19 0.19 0.20 0.30
3 0.36 0.38 0.37 0.39 0.52
5 0.45 0.49 0.48 0.48 0.60
10 0.55 0.63 0.62 0.60 0.69
</table>
<tableCaption confidence="0.990752">
Table 2: Recall for generating alternative spellings
</tableCaption>
<bodyText confidence="0.99903180952381">
ternative pronunciations? We discuss one possible
explanation in Section 5.
Comparing Moses to the pair language model
methods, Moses does slightly better for smaller n
(n = 1, 3), and slightly worse for larger n (n = 10).
Our only partial explanation for this is that Moses
does well at weighing alternatives but, possibly, does
not generate a large number of viable alternatives.
System combination yields solid gains in finding al-
ternative spellings, demonstrating that these differ-
ent systems are coming up with diverse options.
Finally, we note that many of the false positive
pronunciations given by the WFST system are plau-
sibly correct although they are not included in the
CMU dictionary. For example, for the spelling, ad-
equate, the CMU dictionary provides two pronun-
ciations: /ædakwat/ and /ædakwet/. Meanwhile,
the p2p WFST system (with stress modeling) pro-
duces /ædakwIt/. This suggests that we can learn
from CMU dictionary to predict actual pronuncia-
tions that CMU dictionary does not itself list.
</bodyText>
<sectionHeader confidence="0.991363" genericHeader="conclusions">
5 Discussion and Summary
</sectionHeader>
<bodyText confidence="0.999994118644068">
The experimental results demonstrated the utility of
stress modeling for generating alternative pronunci-
ations, which we suggested was due to the impact of
stress on phoneme alternation. To examine this more
closely, we looked at each phoneme, stress class,
(ph, s)—e.g. (/a/, primary)—and determined how
likely is an occurrence of (ph, s) to have an alter-
native phoneme in a homograph set. We found that
primary and secondary stressed vowels had an alter-
ation probability of 0.017, while non-stressed vow-
els had an alteration probability of 0.036. This dif-
ference should be picked up in the transition proba-
bilities of our WFSTs, resulting in a preference for
alterations of unstressed vowels. This is analogous
to results found in (Greenberg et al., 2002) for spon-
taneous American English discourse. A further anal-
ysis of the system output might shed more light on
relationships between stress and phoneme choice.
Why are round-trip methods useful for finding al-
ternative spellings but not for finding alternative pro-
nunciations? One possible explanation is that the
variety of orthographic alternations is greater than
that of pronunciation alternations. Thus, the train-
ing set for spelling may provide less relative cover-
age of the alternations in its test set than the training
set for pronunciation provides for its test set. This
is supported by the fact that pronunciation recall ex-
ceeds spelling recall. The roundtrip method allows
for finding mappings not seen in training. These ex-
tra mappings might be no better for spelling than
they are for pronunciation, but for spelling, the map-
pings they replace in the k-best list are worse, so
they yield an improvement. For pronunciation, the
mappings they replace in the k-best list are better,
so they yield a loss. Further research is required to
validate this explanation.
Ultimately, we would like to apply these meth-
ods to the normalization of social media text, espe-
cially to find alternative spellings based on alterna-
tive pronunciations. To apply such methods to, say,
Twitter normalization requires a sizable corpus map-
ping canonical spellings to non-standard spellings.
To assess domain portability, we applied a model
built from the CMU dictionary to just over 100 al-
ternative spellings observed in a small Twitter col-
lection. Using the direct g2g method, we generated
alternative spellings from the canonical spelling of
each term, and measured the recall of the output, i.e.,
whether the observed alternatives were present in the
k-best list. Recall was extremely low (less than 5%),
suggesting that the type of orthographic alterations
that are found in dictionary pronunciations are very
different from the orthographic variations found on
Twitter, and that those differences have a profound
effect on our ability to recover alternatives.
In sum, we have presented a small study of
the utility of pronunciation dictionaries for finding
spelling and pronunciation alternatives, demonstrat-
ing key differences between these tasks.
</bodyText>
<sectionHeader confidence="0.998812" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999872">
This work was supported in part by NSF grant
#BCS-1049308. Any opinions, findings, conclu-
sions or recommendations expressed in this publica-
tion are those of the authors and do not necessarily
reflect the views of the NSF.
</bodyText>
<page confidence="0.99108">
1588
</page>
<sectionHeader confidence="0.996243" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999818872340426">
Cyril Allauzen, Michael Riley, Johan Schalkwyk, Woj-
ciech Skut, and Mehryar Mohri. 2007. OpenFst: A
general and efficient weighted finite-state transducer
library. In Proceedings of the Twelfth International
Conference on Implementation and Application of Au-
tomata (CIAA 2007), Lecture Notes in Computer Sci-
ence, volume 4793, pages 11–23.
Colin Bannard and Chris Callison-Burch. 2005. Para-
phrasing with bilingual parallel corpora. In Proceed-
ings of the 43rd Annual Meeting on Association for
Computational Linguistics, pages 597–604.
Luciano Barbosa and Junlan Feng. 2010. Robust senti-
ment detection on twitter from biased and noisy data.
In Proceedings of the 23rd International Conference
on Computational Linguistics: Posters, pages 36–44.
Maximilian Bisani and Hermann Ney. 2008. Joint-
sequence models for grapheme-to-phoneme conver-
sion. Speech Communication, 50(5):434 – 451.
Eric Brill and Robert C Moore. 2000. An improved error
model for noisy channel spelling correction. In Pro-
ceedings of the 38th Annual Meeting on Association
for Computational Linguistics, pages 286–293.
Cynthia Chew and Gunther Eysenbach. 2010. Pan-
demics in the age of twitter: content analysis of
tweets during the 2009 h1n1 outbreak. PloS one,
5(11):e14118.
Sabine Deligne and Frdric Bimbot. 1997. Inference of
variable-length linguistic and acoustic units by multi-
grams. Speech Communication, 23(3):223 – 241.
Matteo Gerosa and Marcello Federico. 2009. Coping
with out-of-vocabulary words: open versus huge vo-
cabulary asr. In Proceedings of the IEEE International
Conference on Acoustics, Speech, and Signal Process-
ing (ICASSP), pages 4313–4316.
A. Ghoshal, M. Jansche, S. Khudanpur, M. Riley, and
M. Ulinski. 2009. Web-derived pronunciations. In
Proc. ICASSP.
Steven Greenberg, Hannah Carvey, and Leah Hitchcock.
2002. The relation between stress accent and pro-
nunciation variation in spontaneous american english
discourse. In In Proceedings of ISCA Workshop on
Prosody in Speech Processing (Speech Prosody 2002),
Aix-enProvence.
Panagiota Karanasou and Lori Lamel. 2010. Comparing
SMT methods for automatic generation of pronuncia-
tion variants. In Advances in Natural Language Pro-
cessing, pages 167–178. Springer.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris
Callison-Burch, Marcello Federico, Nicola Bertoldi,
Brooke Cowan, Wade Shen, Christine Moran, Richard
Zens, et al. 2007. Moses: Open source toolkit for sta-
tistical machine translation. In Proceedings of the 45th
Annual Meeting of the ACL on Interactive Poster and
Demonstration Sessions, pages 177–180.
Antoine Laurent, Paul Del´eglise, Sylvain Meignier, and
France Sp´ecinov-Tr´elaz´e. 2009. Grapheme to
phoneme conversion using an smt system. In Proceed-
ings of Interspeech, pages 708–711.
Chen Li and Yang Liu. 2012. Normalization of text mes-
sages using character-and phone-based machine trans-
lation approaches. In Proceedings of Interspeech.
Deana Pennell and Yang Liu. 2011. A character-level
machine translation approach for normalization of sms
abbreviations. In Proceedings of IJCNLP, pages 974–
982.
Brian Roark, Richard Sproat, Cyril Allauzen, Michael
Riley, Jeffrey Sorensen, and Terry Tai. 2012. The
OpenGrm open-source finite-state grammar software
libraries. In Proceedings of the ACL 2012 System
Demonstrations, pages 61–66.
Kenji Sagae, Maider Lehr, Emily Tucker
Prud’hommeaux, Puyang Xu, Nathan Glenn, Dami-
anos Karakos, Sanjeev Khudanpur, Brian Roark,
Murat Saraclar, Izhak Shafran, Daniel M. Bikel,
Chris Callison-Burch, Yuan Cao, Keith Hall, Eva
Hasler, Philipp Koehn, Adam Lopez, Matt Post, and
Darcey Riley. 2012. Hallucinated n-best lists for
discriminative language modeling. In ICASSP, pages
5001–5004. IEEE.
Richard Sproat, Alan W Black, Stanley Chen, Shankar
Kumar, Mari Ostendorf, and Christopher Richards.
2001. Normalization of non-standard words. Com-
puter Speech &amp; Language, 15(3):287–333.
Andreas Stolcke. 1998. Entropy-based pruning of back-
off language models. In Proc. DARPA Broadcast News
Transcription and Understanding Workshop, pages
270–274.
Kristina Toutanova and Robert C Moore. 2002. Pronun-
ciation modeling for improved spelling correction. In
Proceedings of the 40th Annual Meeting on Associa-
tion for Computational Linguistics, pages 144–151.
Robert A Wagner and Michael J Fischer. 1974. The
string-to-string correction problem. Journal of the
ACM (JACM), 21(1):168–173.
</reference>
<page confidence="0.995706">
1589
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.959734">
<title confidence="0.999846">Pair Language Models for Deriving Pronunciations and Spellings from Pronunciation Dictionaries</title>
<author confidence="0.988905">Russell Beckley</author>
<affiliation confidence="0.999963">Oregon Health and Science University</affiliation>
<email confidence="0.999219">beckleyr@ohsu.com</email>
<abstract confidence="0.998318882352941">Pronunciation dictionaries provide a readily available parallel corpus for learning to transduce between character strings and phoneme strings or vice versa. Translation models can be used to derive character-level paraphrases on either side of this transduction, allowing for the automatic derivation of alternative pronunciations or spellings. We examine finitestate and SMT-based methods for these related tasks, and demonstrate that the tasks have different characteristics – finding alternative spellings is harder than alternative pronunciations and benefits from round-trip algorithms when the other does not. We also show that we can increase accuracy by modeling syllable stress.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Cyril Allauzen</author>
<author>Michael Riley</author>
<author>Johan Schalkwyk</author>
<author>Wojciech Skut</author>
<author>Mehryar Mohri</author>
</authors>
<title>OpenFst: A general and efficient weighted finite-state transducer library.</title>
<date>2007</date>
<booktitle>In Proceedings of the Twelfth International Conference on Implementation and Application of Automata (CIAA 2007), Lecture Notes in Computer Science,</booktitle>
<volume>4793</volume>
<pages>11--23</pages>
<contexts>
<context position="12081" citStr="Allauzen et al., 2007" startWordPosition="1860" endWordPosition="1863">ve it a cost based on its relative frequency. Grapheme strings that appear sufficiently often with a given phoneme will thus accumulate sufficient probability mass to compete. Each alignment produced as described above is a string in a training corpus for creating a pair language model. As such, each alignment pair (e.g. a:/a/) is a token. 3.3.2 From Corpora to WFSTs We use the open source OpenGrm NGram library (Roark et al., 2012) to build 5-gram language models from the strings of input:output pairs. These langauge models are encoded as weighted finite-state acceptors in the OpenFst format (Allauzen et al., 2007). We shrink the models with the ngramshrink command, using the relative entropy method (Stolcke, 1998), with the “theta” threshold set at 1.0e−6. These finite state acceptors are then converted into transducers by modifying the arcs: split the labels of each arc, x:y, making x the input label for that arc, and y the output label. Thus traversing such an arc will consume an x a return a y. Such pair language models we use for all WFST methods discussed here. 3.4 Producing k-best output Each tested input string, spelling or pronunciation, is encoded as a cost-free linear chain WFST and composed </context>
</contexts>
<marker>Allauzen, Riley, Schalkwyk, Skut, Mohri, 2007</marker>
<rawString>Cyril Allauzen, Michael Riley, Johan Schalkwyk, Wojciech Skut, and Mehryar Mohri. 2007. OpenFst: A general and efficient weighted finite-state transducer library. In Proceedings of the Twelfth International Conference on Implementation and Application of Automata (CIAA 2007), Lecture Notes in Computer Science, volume 4793, pages 11–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Paraphrasing with bilingual parallel corpora.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>597--604</pages>
<contexts>
<context position="2503" citStr="Bannard and Callison-Burch, 2005" startWordPosition="359" endWordPosition="362">me to Brian Roark Google Inc. roarkbr@gmail.com phoneme (g2p) conversion modeling derived from pronunciation dictionaries. Pronunciation dictionaries provide natural parallel corpora, with strings of characters paired to strings of phones. Thus, standard lexicons have been used in recent years with machine translation systems such as Moses (Koehn et al., 2007), to train g2p systems (Laurent et al., 2009; Gerosa and Federico, 2009). Further, other algorithms using such dictionaries also use translation phrase tables, but not for translation tasks. For example, data-driven paraphrasing methods (Bannard and Callison-Burch, 2005) use translation phrase-tables as a “pivot” to learn sets of phrases which translated to the same target phrase. In a similar manner, with a pronunciation dictionary instead of a phrsetable, pivoting can be used to learn alternative pronunciations (Karanasou and Lamel, 2010), i.e., direct phoneme-to-phoneme (p2p) “translation” systems that yield alternative pronunciations. Alternatively, round-trip translation could be used, e.g., to map from letter strings to phone strings in one step, then from the resulting phone strings to letter strings in a second step, as the means to find alternative s</context>
</contexts>
<marker>Bannard, Callison-Burch, 2005</marker>
<rawString>Colin Bannard and Chris Callison-Burch. 2005. Paraphrasing with bilingual parallel corpora. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, pages 597–604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Luciano Barbosa</author>
<author>Junlan Feng</author>
</authors>
<title>Robust sentiment detection on twitter from biased and noisy data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics: Posters,</booktitle>
<pages>36--44</pages>
<contexts>
<context position="4946" citStr="Barbosa and Feng, 2010" startWordPosition="723" endWordPosition="726">odest gains for finding alternative spellings. Further, WFST methods perform as well as or better than Moses trained models. Finally, combining the methods yields further gains, indicating that the models are learning complementary sets of patterns. The primary contribution of this work is to introduce a competitive method of building and using pair language model WFSTs for generating alternative spellings and pronunciations which reflect real-world variability. This could improve results for downstream processes, e.g., epidemiological studies (Chew and Eysenbach, 2010) or sentiment analysis (Barbosa and Feng, 2010) derived from social media text. Further, we present a controlled comparison between the two tasks, and demonstrate that they differ in terms of task difficulty 2 Related work Text normalization has been a major focus in textto-speech (TTS) research for many years. Notably, Sproat et al. (2001) deemed it a problem in itself, rather than ad hoc preparatory work, and defined many of the issues involved, as well as offering a variety of initial solutions. Similar approaches apply to automatic spelling correction, where Toutanova and Moore (2002) extended the noisy channel spelling correction meth</context>
</contexts>
<marker>Barbosa, Feng, 2010</marker>
<rawString>Luciano Barbosa and Junlan Feng. 2010. Robust sentiment detection on twitter from biased and noisy data. In Proceedings of the 23rd International Conference on Computational Linguistics: Posters, pages 36–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maximilian Bisani</author>
<author>Hermann Ney</author>
</authors>
<title>Jointsequence models for grapheme-to-phoneme conversion.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<volume>50</volume>
<issue>5</issue>
<pages>451</pages>
<contexts>
<context position="9033" citStr="Bisani and Ney, 2008" startWordPosition="1347" endWordPosition="1350"> (Koehn et al., 2007) to build grapheme-based and phoneme-based translation systems, using a bigram language model.2 These are trained on the parallel corpus resulting from the homophone or homograph sets detailed in 1http://www.speech.cs.cmu.edu/cgi-bin/cmudict 2Higher order language models yielded no improvements. 1585 the previous section for the direct methods. For this paper, we did not perform round-trip translation with Moses, rather present it as a baseline for the direct approach. 3.3 Pair language models Our weighted finite-state transducer approach is based on pair language models (Bisani and Ney, 2008; Deligne and Bimbot, 1997; Ghoshal et al., 2009), or, more recently, (Sagae et al., 2012).) The basic idea in a pair LM is to align strings, then train a language model over sequences whose symbols are the input:output pairs of the alignment. This language model can then be converted to transducers. For a g2g example, homophones “their” and “there” are aligned via the standard Levenshtein edit distance algorithm as “t:t h:h e:e i:E r:r E:e”. A trigram model over these x:y strings would use standard ngram modeling to estimate, for example, P(E:e |i:E r:r); i.e., the probability of a silent “r”</context>
</contexts>
<marker>Bisani, Ney, 2008</marker>
<rawString>Maximilian Bisani and Hermann Ney. 2008. Jointsequence models for grapheme-to-phoneme conversion. Speech Communication, 50(5):434 – 451.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Robert C Moore</author>
</authors>
<title>An improved error model for noisy channel spelling correction.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>286--293</pages>
<contexts>
<context position="5574" citStr="Brill and Moore (2000)" startWordPosition="826" endWordPosition="829">ed from social media text. Further, we present a controlled comparison between the two tasks, and demonstrate that they differ in terms of task difficulty 2 Related work Text normalization has been a major focus in textto-speech (TTS) research for many years. Notably, Sproat et al. (2001) deemed it a problem in itself, rather than ad hoc preparatory work, and defined many of the issues involved, as well as offering a variety of initial solutions. Similar approaches apply to automatic spelling correction, where Toutanova and Moore (2002) extended the noisy channel spelling correction method of Brill and Moore (2000), by modeling pronunciation alternations to infer from misspellings to correct spellings. Similarly, Li and Liu (2012) extended the character-based translation approach to text normalization of Pennell and Liu (2011), by adding an additional round-trip translation to-and-from pronunciations. Karanasou and Lamel (2010) used Moses to generate alternative pronunciations from an English dictionary, using both direct and round-trip methods. They validated their systems on a set of words with multiple pronunciations, measuring the degree to which alternative pronunciations are generated from one of </context>
<context position="10173" citStr="Brill and Moore (2000)" startWordPosition="1544" endWordPosition="1547">g to estimate, for example, P(E:e |i:E r:r); i.e., the probability of a silent “r” in a given context. Building the pair language model transducers requires two phases. In the first phase we create new corpora by aligning the elements of the parallel corpora outlined above. In the second phase we use these corpora of string alignments to build a pair language model. 3.3.1 Alignment and Corpora Building We use extensions to the Levenshtein edit distance algorithm to align g2g, p2p and g2p strings, with substitution matrices created to provide useful alignments (Wagner and Fischer, 1974). As in Brill and Moore (2000), we allow for certain multisymbol strings to be substituted with a single cost, e.g., substituting ‘th’ with /B/ in g2p alignment. For g2g alignment, our substitution cost is 0 for identity and 2 for a few pairs of commonly interchangeable graphemes, such as ‘c’ and ‘k’. Other substitutions are not permitted, and delete and insertion have cost 10. For p2p alignment there are two conditions, with and without stress. Without vowel stress, no substitutions other than identity are allowed; with vowel stress, substitution cost is 2.5 for the same vowel with differing stress; and 5.0 if substitutin</context>
</contexts>
<marker>Brill, Moore, 2000</marker>
<rawString>Eric Brill and Robert C Moore. 2000. An improved error model for noisy channel spelling correction. In Proceedings of the 38th Annual Meeting on Association for Computational Linguistics, pages 286–293.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cynthia Chew</author>
<author>Gunther Eysenbach</author>
</authors>
<title>Pandemics in the age of twitter: content analysis of tweets during the 2009 h1n1 outbreak.</title>
<date>2010</date>
<journal>PloS one,</journal>
<volume>5</volume>
<issue>11</issue>
<contexts>
<context position="4899" citStr="Chew and Eysenbach, 2010" startWordPosition="716" endWordPosition="719">ing alternative pronunciations, yet yields some modest gains for finding alternative spellings. Further, WFST methods perform as well as or better than Moses trained models. Finally, combining the methods yields further gains, indicating that the models are learning complementary sets of patterns. The primary contribution of this work is to introduce a competitive method of building and using pair language model WFSTs for generating alternative spellings and pronunciations which reflect real-world variability. This could improve results for downstream processes, e.g., epidemiological studies (Chew and Eysenbach, 2010) or sentiment analysis (Barbosa and Feng, 2010) derived from social media text. Further, we present a controlled comparison between the two tasks, and demonstrate that they differ in terms of task difficulty 2 Related work Text normalization has been a major focus in textto-speech (TTS) research for many years. Notably, Sproat et al. (2001) deemed it a problem in itself, rather than ad hoc preparatory work, and defined many of the issues involved, as well as offering a variety of initial solutions. Similar approaches apply to automatic spelling correction, where Toutanova and Moore (2002) exte</context>
</contexts>
<marker>Chew, Eysenbach, 2010</marker>
<rawString>Cynthia Chew and Gunther Eysenbach. 2010. Pandemics in the age of twitter: content analysis of tweets during the 2009 h1n1 outbreak. PloS one, 5(11):e14118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Deligne</author>
<author>Frdric Bimbot</author>
</authors>
<title>Inference of variable-length linguistic and acoustic units by multigrams.</title>
<date>1997</date>
<journal>Speech Communication,</journal>
<volume>23</volume>
<issue>3</issue>
<pages>241</pages>
<contexts>
<context position="9059" citStr="Deligne and Bimbot, 1997" startWordPosition="1351" endWordPosition="1354">to build grapheme-based and phoneme-based translation systems, using a bigram language model.2 These are trained on the parallel corpus resulting from the homophone or homograph sets detailed in 1http://www.speech.cs.cmu.edu/cgi-bin/cmudict 2Higher order language models yielded no improvements. 1585 the previous section for the direct methods. For this paper, we did not perform round-trip translation with Moses, rather present it as a baseline for the direct approach. 3.3 Pair language models Our weighted finite-state transducer approach is based on pair language models (Bisani and Ney, 2008; Deligne and Bimbot, 1997; Ghoshal et al., 2009), or, more recently, (Sagae et al., 2012).) The basic idea in a pair LM is to align strings, then train a language model over sequences whose symbols are the input:output pairs of the alignment. This language model can then be converted to transducers. For a g2g example, homophones “their” and “there” are aligned via the standard Levenshtein edit distance algorithm as “t:t h:h e:e i:E r:r E:e”. A trigram model over these x:y strings would use standard ngram modeling to estimate, for example, P(E:e |i:E r:r); i.e., the probability of a silent “r” in a given context. Build</context>
</contexts>
<marker>Deligne, Bimbot, 1997</marker>
<rawString>Sabine Deligne and Frdric Bimbot. 1997. Inference of variable-length linguistic and acoustic units by multigrams. Speech Communication, 23(3):223 – 241.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matteo Gerosa</author>
<author>Marcello Federico</author>
</authors>
<title>Coping with out-of-vocabulary words: open versus huge vocabulary asr.</title>
<date>2009</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<pages>4313--4316</pages>
<contexts>
<context position="2304" citStr="Gerosa and Federico, 2009" startWordPosition="332" endWordPosition="335">ext normalization and spelling correction – e.g., Toutanova and Moore (2002); Li and Liu (2012) – has included pronunciation information to improve recognition of the intended word, via grapheme to Brian Roark Google Inc. roarkbr@gmail.com phoneme (g2p) conversion modeling derived from pronunciation dictionaries. Pronunciation dictionaries provide natural parallel corpora, with strings of characters paired to strings of phones. Thus, standard lexicons have been used in recent years with machine translation systems such as Moses (Koehn et al., 2007), to train g2p systems (Laurent et al., 2009; Gerosa and Federico, 2009). Further, other algorithms using such dictionaries also use translation phrase tables, but not for translation tasks. For example, data-driven paraphrasing methods (Bannard and Callison-Burch, 2005) use translation phrase-tables as a “pivot” to learn sets of phrases which translated to the same target phrase. In a similar manner, with a pronunciation dictionary instead of a phrsetable, pivoting can be used to learn alternative pronunciations (Karanasou and Lamel, 2010), i.e., direct phoneme-to-phoneme (p2p) “translation” systems that yield alternative pronunciations. Alternatively, round-trip</context>
</contexts>
<marker>Gerosa, Federico, 2009</marker>
<rawString>Matteo Gerosa and Marcello Federico. 2009. Coping with out-of-vocabulary words: open versus huge vocabulary asr. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pages 4313–4316.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ghoshal</author>
<author>M Jansche</author>
<author>S Khudanpur</author>
<author>M Riley</author>
<author>M Ulinski</author>
</authors>
<title>Web-derived pronunciations.</title>
<date>2009</date>
<booktitle>In Proc. ICASSP.</booktitle>
<contexts>
<context position="9082" citStr="Ghoshal et al., 2009" startWordPosition="1355" endWordPosition="1358">d phoneme-based translation systems, using a bigram language model.2 These are trained on the parallel corpus resulting from the homophone or homograph sets detailed in 1http://www.speech.cs.cmu.edu/cgi-bin/cmudict 2Higher order language models yielded no improvements. 1585 the previous section for the direct methods. For this paper, we did not perform round-trip translation with Moses, rather present it as a baseline for the direct approach. 3.3 Pair language models Our weighted finite-state transducer approach is based on pair language models (Bisani and Ney, 2008; Deligne and Bimbot, 1997; Ghoshal et al., 2009), or, more recently, (Sagae et al., 2012).) The basic idea in a pair LM is to align strings, then train a language model over sequences whose symbols are the input:output pairs of the alignment. This language model can then be converted to transducers. For a g2g example, homophones “their” and “there” are aligned via the standard Levenshtein edit distance algorithm as “t:t h:h e:e i:E r:r E:e”. A trigram model over these x:y strings would use standard ngram modeling to estimate, for example, P(E:e |i:E r:r); i.e., the probability of a silent “r” in a given context. Building the pair language m</context>
</contexts>
<marker>Ghoshal, Jansche, Khudanpur, Riley, Ulinski, 2009</marker>
<rawString>A. Ghoshal, M. Jansche, S. Khudanpur, M. Riley, and M. Ulinski. 2009. Web-derived pronunciations. In Proc. ICASSP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Greenberg</author>
<author>Hannah Carvey</author>
<author>Leah Hitchcock</author>
</authors>
<title>The relation between stress accent and pronunciation variation in spontaneous american english discourse. In</title>
<date>2002</date>
<booktitle>In Proceedings of ISCA Workshop on Prosody in Speech Processing (Speech Prosody</booktitle>
<location>Aix-enProvence.</location>
<contexts>
<context position="19920" citStr="Greenberg et al., 2002" startWordPosition="3155" endWordPosition="3158"> due to the impact of stress on phoneme alternation. To examine this more closely, we looked at each phoneme, stress class, (ph, s)—e.g. (/a/, primary)—and determined how likely is an occurrence of (ph, s) to have an alternative phoneme in a homograph set. We found that primary and secondary stressed vowels had an alteration probability of 0.017, while non-stressed vowels had an alteration probability of 0.036. This difference should be picked up in the transition probabilities of our WFSTs, resulting in a preference for alterations of unstressed vowels. This is analogous to results found in (Greenberg et al., 2002) for spontaneous American English discourse. A further analysis of the system output might shed more light on relationships between stress and phoneme choice. Why are round-trip methods useful for finding alternative spellings but not for finding alternative pronunciations? One possible explanation is that the variety of orthographic alternations is greater than that of pronunciation alternations. Thus, the training set for spelling may provide less relative coverage of the alternations in its test set than the training set for pronunciation provides for its test set. This is supported by the </context>
</contexts>
<marker>Greenberg, Carvey, Hitchcock, 2002</marker>
<rawString>Steven Greenberg, Hannah Carvey, and Leah Hitchcock. 2002. The relation between stress accent and pronunciation variation in spontaneous american english discourse. In In Proceedings of ISCA Workshop on Prosody in Speech Processing (Speech Prosody 2002), Aix-enProvence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Panagiota Karanasou</author>
<author>Lori Lamel</author>
</authors>
<title>Comparing SMT methods for automatic generation of pronunciation variants.</title>
<date>2010</date>
<booktitle>In Advances in Natural Language Processing,</booktitle>
<pages>167--178</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="2778" citStr="Karanasou and Lamel, 2010" startWordPosition="404" endWordPosition="407">recent years with machine translation systems such as Moses (Koehn et al., 2007), to train g2p systems (Laurent et al., 2009; Gerosa and Federico, 2009). Further, other algorithms using such dictionaries also use translation phrase tables, but not for translation tasks. For example, data-driven paraphrasing methods (Bannard and Callison-Burch, 2005) use translation phrase-tables as a “pivot” to learn sets of phrases which translated to the same target phrase. In a similar manner, with a pronunciation dictionary instead of a phrsetable, pivoting can be used to learn alternative pronunciations (Karanasou and Lamel, 2010), i.e., direct phoneme-to-phoneme (p2p) “translation” systems that yield alternative pronunciations. Alternatively, round-trip translation could be used, e.g., to map from letter strings to phone strings in one step, then from the resulting phone strings to letter strings in a second step, as the means to find alternative spellings (Li and Liu, 2012). In this study, we explore dictionary-derived models to find either alternative pronunciations or alternative spellings, using either direct (p2p or g2g) or round-trip algorithms (p2g2p or g2p2g). We compare methods based on weighted finite-state </context>
<context position="5893" citStr="Karanasou and Lamel (2010)" startWordPosition="868" endWordPosition="871">self, rather than ad hoc preparatory work, and defined many of the issues involved, as well as offering a variety of initial solutions. Similar approaches apply to automatic spelling correction, where Toutanova and Moore (2002) extended the noisy channel spelling correction method of Brill and Moore (2000), by modeling pronunciation alternations to infer from misspellings to correct spellings. Similarly, Li and Liu (2012) extended the character-based translation approach to text normalization of Pennell and Liu (2011), by adding an additional round-trip translation to-and-from pronunciations. Karanasou and Lamel (2010) used Moses to generate alternative pronunciations from an English dictionary, using both direct and round-trip methods. They validated their systems on a set of words with multiple pronunciations, measuring the degree to which alternative pronunciations are generated from one of the given pronunciations. Our task and method of evaluation is similar to theirs, though we also look at alternative spellings. 3 Methods To generate alternative spellings and pronunciations, we built phrase-based translation and finite-state transduction models from a parallel corpus. When pronunciations were part of</context>
</contexts>
<marker>Karanasou, Lamel, 2010</marker>
<rawString>Panagiota Karanasou and Lori Lamel. 2010. Comparing SMT methods for automatic generation of pronunciation variants. In Advances in Natural Language Processing, pages 167–178. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions,</booktitle>
<pages>177--180</pages>
<contexts>
<context position="2232" citStr="Koehn et al., 2007" startWordPosition="320" endWordPosition="323">present spelling alternations related to pronunciation. Work in text normalization and spelling correction – e.g., Toutanova and Moore (2002); Li and Liu (2012) – has included pronunciation information to improve recognition of the intended word, via grapheme to Brian Roark Google Inc. roarkbr@gmail.com phoneme (g2p) conversion modeling derived from pronunciation dictionaries. Pronunciation dictionaries provide natural parallel corpora, with strings of characters paired to strings of phones. Thus, standard lexicons have been used in recent years with machine translation systems such as Moses (Koehn et al., 2007), to train g2p systems (Laurent et al., 2009; Gerosa and Federico, 2009). Further, other algorithms using such dictionaries also use translation phrase tables, but not for translation tasks. For example, data-driven paraphrasing methods (Bannard and Callison-Burch, 2005) use translation phrase-tables as a “pivot” to learn sets of phrases which translated to the same target phrase. In a similar manner, with a pronunciation dictionary instead of a phrsetable, pivoting can be used to learn alternative pronunciations (Karanasou and Lamel, 2010), i.e., direct phoneme-to-phoneme (p2p) “translation” </context>
<context position="8434" citStr="Koehn et al., 2007" startWordPosition="1262" endWordPosition="1265">non-homophone words are self-aligned; for homophones, from each homophone set, each possible pair of spellings are aligned. For example, for a pronunciation with four spellings—a, b, c, and d— there would be six alignments: a:b, a:c, a:d, b:c, b:d, c:d. Similarly for direct phoneme-to-phoneme training sets, non-homograph words are self-aligned; words from the training homograph sets are pairwise aligned in all pairings. There are two direct p2p corpora: with and without stress. 3.2 Phrase-based translation models As a baseline system, we used the Moses statistical machine translation package (Koehn et al., 2007) to build grapheme-based and phoneme-based translation systems, using a bigram language model.2 These are trained on the parallel corpus resulting from the homophone or homograph sets detailed in 1http://www.speech.cs.cmu.edu/cgi-bin/cmudict 2Higher order language models yielded no improvements. 1585 the previous section for the direct methods. For this paper, we did not perform round-trip translation with Moses, rather present it as a baseline for the direct approach. 3.3 Pair language models Our weighted finite-state transducer approach is based on pair language models (Bisani and Ney, 2008;</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Chris Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, et al. 2007. Moses: Open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the ACL on Interactive Poster and Demonstration Sessions, pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Laurent</author>
<author>Paul Del´eglise</author>
<author>Sylvain Meignier</author>
<author>France Sp´ecinov-Tr´elaz´e</author>
</authors>
<title>Grapheme to phoneme conversion using an smt system.</title>
<date>2009</date>
<booktitle>In Proceedings of Interspeech,</booktitle>
<pages>708--711</pages>
<marker>Laurent, Del´eglise, Meignier, Sp´ecinov-Tr´elaz´e, 2009</marker>
<rawString>Antoine Laurent, Paul Del´eglise, Sylvain Meignier, and France Sp´ecinov-Tr´elaz´e. 2009. Grapheme to phoneme conversion using an smt system. In Proceedings of Interspeech, pages 708–711.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Li</author>
<author>Yang Liu</author>
</authors>
<title>Normalization of text messages using character-and phone-based machine translation approaches.</title>
<date>2012</date>
<booktitle>In Proceedings of Interspeech.</booktitle>
<contexts>
<context position="1773" citStr="Li and Liu (2012)" startWordPosition="255" endWordPosition="258">t recognition task, often required for downstream processing such as spoken language understanding or knowledge extraction. Informal text genres, such as those found in social media, share some characteristics with speech; in fact such text is often informed by pronunciation variation. For example, consider the following tweet: He aint gotta question my loyalty, cuz he knw wen sh!t get real. Ill be right here! where several tokens (e.g. “cuz”, “wen”) represent spelling alternations related to pronunciation. Work in text normalization and spelling correction – e.g., Toutanova and Moore (2002); Li and Liu (2012) – has included pronunciation information to improve recognition of the intended word, via grapheme to Brian Roark Google Inc. roarkbr@gmail.com phoneme (g2p) conversion modeling derived from pronunciation dictionaries. Pronunciation dictionaries provide natural parallel corpora, with strings of characters paired to strings of phones. Thus, standard lexicons have been used in recent years with machine translation systems such as Moses (Koehn et al., 2007), to train g2p systems (Laurent et al., 2009; Gerosa and Federico, 2009). Further, other algorithms using such dictionaries also use translat</context>
<context position="3130" citStr="Li and Liu, 2012" startWordPosition="459" endWordPosition="462">lation phrase-tables as a “pivot” to learn sets of phrases which translated to the same target phrase. In a similar manner, with a pronunciation dictionary instead of a phrsetable, pivoting can be used to learn alternative pronunciations (Karanasou and Lamel, 2010), i.e., direct phoneme-to-phoneme (p2p) “translation” systems that yield alternative pronunciations. Alternatively, round-trip translation could be used, e.g., to map from letter strings to phone strings in one step, then from the resulting phone strings to letter strings in a second step, as the means to find alternative spellings (Li and Liu, 2012). In this study, we explore dictionary-derived models to find either alternative pronunciations or alternative spellings, using either direct (p2p or g2g) or round-trip algorithms (p2g2p or g2p2g). We compare methods based on weighted finite-state transducers (WFST) with phrase-based models trained with Moses. Our main interest is to evaluate Karanasou and Lamel (2010) methods – shown to be useful for deriving alternative pronunciations – for deriving alternative spellings, and thus to determine the relative difficulty of these two tasks. We also examine when, if ever, round-trip processing yi</context>
<context position="5692" citStr="Li and Liu (2012)" startWordPosition="842" endWordPosition="845">fer in terms of task difficulty 2 Related work Text normalization has been a major focus in textto-speech (TTS) research for many years. Notably, Sproat et al. (2001) deemed it a problem in itself, rather than ad hoc preparatory work, and defined many of the issues involved, as well as offering a variety of initial solutions. Similar approaches apply to automatic spelling correction, where Toutanova and Moore (2002) extended the noisy channel spelling correction method of Brill and Moore (2000), by modeling pronunciation alternations to infer from misspellings to correct spellings. Similarly, Li and Liu (2012) extended the character-based translation approach to text normalization of Pennell and Liu (2011), by adding an additional round-trip translation to-and-from pronunciations. Karanasou and Lamel (2010) used Moses to generate alternative pronunciations from an English dictionary, using both direct and round-trip methods. They validated their systems on a set of words with multiple pronunciations, measuring the degree to which alternative pronunciations are generated from one of the given pronunciations. Our task and method of evaluation is similar to theirs, though we also look at alternative s</context>
</contexts>
<marker>Li, Liu, 2012</marker>
<rawString>Chen Li and Yang Liu. 2012. Normalization of text messages using character-and phone-based machine translation approaches. In Proceedings of Interspeech.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deana Pennell</author>
<author>Yang Liu</author>
</authors>
<title>A character-level machine translation approach for normalization of sms abbreviations.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP,</booktitle>
<pages>974--982</pages>
<contexts>
<context position="5790" citStr="Pennell and Liu (2011)" startWordPosition="855" endWordPosition="858">extto-speech (TTS) research for many years. Notably, Sproat et al. (2001) deemed it a problem in itself, rather than ad hoc preparatory work, and defined many of the issues involved, as well as offering a variety of initial solutions. Similar approaches apply to automatic spelling correction, where Toutanova and Moore (2002) extended the noisy channel spelling correction method of Brill and Moore (2000), by modeling pronunciation alternations to infer from misspellings to correct spellings. Similarly, Li and Liu (2012) extended the character-based translation approach to text normalization of Pennell and Liu (2011), by adding an additional round-trip translation to-and-from pronunciations. Karanasou and Lamel (2010) used Moses to generate alternative pronunciations from an English dictionary, using both direct and round-trip methods. They validated their systems on a set of words with multiple pronunciations, measuring the degree to which alternative pronunciations are generated from one of the given pronunciations. Our task and method of evaluation is similar to theirs, though we also look at alternative spellings. 3 Methods To generate alternative spellings and pronunciations, we built phrase-based tr</context>
</contexts>
<marker>Pennell, Liu, 2011</marker>
<rawString>Deana Pennell and Yang Liu. 2011. A character-level machine translation approach for normalization of sms abbreviations. In Proceedings of IJCNLP, pages 974– 982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Richard Sproat</author>
<author>Cyril Allauzen</author>
<author>Michael Riley</author>
<author>Jeffrey Sorensen</author>
<author>Terry Tai</author>
</authors>
<title>The OpenGrm open-source finite-state grammar software libraries.</title>
<date>2012</date>
<booktitle>In Proceedings of the ACL 2012 System Demonstrations,</booktitle>
<pages>61--66</pages>
<contexts>
<context position="11894" citStr="Roark et al., 2012" startWordPosition="1830" endWordPosition="1833">ted graphemes so that they collectively map to a single phoneme. For example, given the alignment ‘o:/a/ u:/E/ g:/E/ h:/E/ t:/t/’, (‘ought’, /at/), we make a new rule: ough:/a/, and give it a cost based on its relative frequency. Grapheme strings that appear sufficiently often with a given phoneme will thus accumulate sufficient probability mass to compete. Each alignment produced as described above is a string in a training corpus for creating a pair language model. As such, each alignment pair (e.g. a:/a/) is a token. 3.3.2 From Corpora to WFSTs We use the open source OpenGrm NGram library (Roark et al., 2012) to build 5-gram language models from the strings of input:output pairs. These langauge models are encoded as weighted finite-state acceptors in the OpenFst format (Allauzen et al., 2007). We shrink the models with the ngramshrink command, using the relative entropy method (Stolcke, 1998), with the “theta” threshold set at 1.0e−6. These finite state acceptors are then converted into transducers by modifying the arcs: split the labels of each arc, x:y, making x the input label for that arc, and y the output label. Thus traversing such an arc will consume an x a return a y. Such pair language mo</context>
</contexts>
<marker>Roark, Sproat, Allauzen, Riley, Sorensen, Tai, 2012</marker>
<rawString>Brian Roark, Richard Sproat, Cyril Allauzen, Michael Riley, Jeffrey Sorensen, and Terry Tai. 2012. The OpenGrm open-source finite-state grammar software libraries. In Proceedings of the ACL 2012 System Demonstrations, pages 61–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Maider Lehr</author>
<author>Emily Tucker Prud’hommeaux</author>
<author>Puyang Xu</author>
<author>Nathan Glenn</author>
<author>Damianos Karakos</author>
<author>Sanjeev Khudanpur</author>
<author>Brian Roark</author>
<author>Murat Saraclar</author>
<author>Izhak Shafran</author>
<author>Daniel M Bikel</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Hallucinated n-best lists for discriminative language modeling.</title>
<date>2012</date>
<booktitle>In ICASSP,</booktitle>
<pages>5001--5004</pages>
<publisher>IEEE.</publisher>
<location>Yuan Cao, Keith Hall, Eva Hasler, Philipp Koehn, Adam Lopez, Matt</location>
<marker>Sagae, Lehr, Prud’hommeaux, Xu, Glenn, Karakos, Khudanpur, Roark, Saraclar, Shafran, Bikel, Callison-Burch, 2012</marker>
<rawString>Kenji Sagae, Maider Lehr, Emily Tucker Prud’hommeaux, Puyang Xu, Nathan Glenn, Damianos Karakos, Sanjeev Khudanpur, Brian Roark, Murat Saraclar, Izhak Shafran, Daniel M. Bikel, Chris Callison-Burch, Yuan Cao, Keith Hall, Eva Hasler, Philipp Koehn, Adam Lopez, Matt Post, and Darcey Riley. 2012. Hallucinated n-best lists for discriminative language modeling. In ICASSP, pages 5001–5004. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Sproat</author>
<author>Alan W Black</author>
<author>Stanley Chen</author>
<author>Shankar Kumar</author>
<author>Mari Ostendorf</author>
<author>Christopher Richards</author>
</authors>
<title>Normalization of non-standard words.</title>
<date>2001</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>15</volume>
<issue>3</issue>
<contexts>
<context position="5241" citStr="Sproat et al. (2001)" startWordPosition="773" endWordPosition="776">oduce a competitive method of building and using pair language model WFSTs for generating alternative spellings and pronunciations which reflect real-world variability. This could improve results for downstream processes, e.g., epidemiological studies (Chew and Eysenbach, 2010) or sentiment analysis (Barbosa and Feng, 2010) derived from social media text. Further, we present a controlled comparison between the two tasks, and demonstrate that they differ in terms of task difficulty 2 Related work Text normalization has been a major focus in textto-speech (TTS) research for many years. Notably, Sproat et al. (2001) deemed it a problem in itself, rather than ad hoc preparatory work, and defined many of the issues involved, as well as offering a variety of initial solutions. Similar approaches apply to automatic spelling correction, where Toutanova and Moore (2002) extended the noisy channel spelling correction method of Brill and Moore (2000), by modeling pronunciation alternations to infer from misspellings to correct spellings. Similarly, Li and Liu (2012) extended the character-based translation approach to text normalization of Pennell and Liu (2011), by adding an additional round-trip translation to</context>
</contexts>
<marker>Sproat, Black, Chen, Kumar, Ostendorf, Richards, 2001</marker>
<rawString>Richard Sproat, Alan W Black, Stanley Chen, Shankar Kumar, Mari Ostendorf, and Christopher Richards. 2001. Normalization of non-standard words. Computer Speech &amp; Language, 15(3):287–333.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Entropy-based pruning of backoff language models.</title>
<date>1998</date>
<booktitle>In Proc. DARPA Broadcast News Transcription and Understanding Workshop,</booktitle>
<pages>270--274</pages>
<contexts>
<context position="12183" citStr="Stolcke, 1998" startWordPosition="1877" endWordPosition="1879">neme will thus accumulate sufficient probability mass to compete. Each alignment produced as described above is a string in a training corpus for creating a pair language model. As such, each alignment pair (e.g. a:/a/) is a token. 3.3.2 From Corpora to WFSTs We use the open source OpenGrm NGram library (Roark et al., 2012) to build 5-gram language models from the strings of input:output pairs. These langauge models are encoded as weighted finite-state acceptors in the OpenFst format (Allauzen et al., 2007). We shrink the models with the ngramshrink command, using the relative entropy method (Stolcke, 1998), with the “theta” threshold set at 1.0e−6. These finite state acceptors are then converted into transducers by modifying the arcs: split the labels of each arc, x:y, making x the input label for that arc, and y the output label. Thus traversing such an arc will consume an x a return a y. Such pair language models we use for all WFST methods discussed here. 3.4 Producing k-best output Each tested input string, spelling or pronunciation, is encoded as a cost-free linear chain WFST and composed with a pair language model transducer described in the previous section. The resulting lattice is conv</context>
</contexts>
<marker>Stolcke, 1998</marker>
<rawString>Andreas Stolcke. 1998. Entropy-based pruning of backoff language models. In Proc. DARPA Broadcast News Transcription and Understanding Workshop, pages 270–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Robert C Moore</author>
</authors>
<title>Pronunciation modeling for improved spelling correction.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>144--151</pages>
<contexts>
<context position="1754" citStr="Toutanova and Moore (2002)" startWordPosition="251" endWordPosition="254">tual sequence is an important recognition task, often required for downstream processing such as spoken language understanding or knowledge extraction. Informal text genres, such as those found in social media, share some characteristics with speech; in fact such text is often informed by pronunciation variation. For example, consider the following tweet: He aint gotta question my loyalty, cuz he knw wen sh!t get real. Ill be right here! where several tokens (e.g. “cuz”, “wen”) represent spelling alternations related to pronunciation. Work in text normalization and spelling correction – e.g., Toutanova and Moore (2002); Li and Liu (2012) – has included pronunciation information to improve recognition of the intended word, via grapheme to Brian Roark Google Inc. roarkbr@gmail.com phoneme (g2p) conversion modeling derived from pronunciation dictionaries. Pronunciation dictionaries provide natural parallel corpora, with strings of characters paired to strings of phones. Thus, standard lexicons have been used in recent years with machine translation systems such as Moses (Koehn et al., 2007), to train g2p systems (Laurent et al., 2009; Gerosa and Federico, 2009). Further, other algorithms using such dictionarie</context>
<context position="5494" citStr="Toutanova and Moore (2002)" startWordPosition="814" endWordPosition="817">dies (Chew and Eysenbach, 2010) or sentiment analysis (Barbosa and Feng, 2010) derived from social media text. Further, we present a controlled comparison between the two tasks, and demonstrate that they differ in terms of task difficulty 2 Related work Text normalization has been a major focus in textto-speech (TTS) research for many years. Notably, Sproat et al. (2001) deemed it a problem in itself, rather than ad hoc preparatory work, and defined many of the issues involved, as well as offering a variety of initial solutions. Similar approaches apply to automatic spelling correction, where Toutanova and Moore (2002) extended the noisy channel spelling correction method of Brill and Moore (2000), by modeling pronunciation alternations to infer from misspellings to correct spellings. Similarly, Li and Liu (2012) extended the character-based translation approach to text normalization of Pennell and Liu (2011), by adding an additional round-trip translation to-and-from pronunciations. Karanasou and Lamel (2010) used Moses to generate alternative pronunciations from an English dictionary, using both direct and round-trip methods. They validated their systems on a set of words with multiple pronunciations, mea</context>
</contexts>
<marker>Toutanova, Moore, 2002</marker>
<rawString>Kristina Toutanova and Robert C Moore. 2002. Pronunciation modeling for improved spelling correction. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, pages 144–151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert A Wagner</author>
<author>Michael J Fischer</author>
</authors>
<title>The string-to-string correction problem.</title>
<date>1974</date>
<journal>Journal of the ACM (JACM),</journal>
<volume>21</volume>
<issue>1</issue>
<contexts>
<context position="10143" citStr="Wagner and Fischer, 1974" startWordPosition="1538" endWordPosition="1541"> would use standard ngram modeling to estimate, for example, P(E:e |i:E r:r); i.e., the probability of a silent “r” in a given context. Building the pair language model transducers requires two phases. In the first phase we create new corpora by aligning the elements of the parallel corpora outlined above. In the second phase we use these corpora of string alignments to build a pair language model. 3.3.1 Alignment and Corpora Building We use extensions to the Levenshtein edit distance algorithm to align g2g, p2p and g2p strings, with substitution matrices created to provide useful alignments (Wagner and Fischer, 1974). As in Brill and Moore (2000), we allow for certain multisymbol strings to be substituted with a single cost, e.g., substituting ‘th’ with /B/ in g2p alignment. For g2g alignment, our substitution cost is 0 for identity and 2 for a few pairs of commonly interchangeable graphemes, such as ‘c’ and ‘k’. Other substitutions are not permitted, and delete and insertion have cost 10. For p2p alignment there are two conditions, with and without stress. Without vowel stress, no substitutions other than identity are allowed; with vowel stress, substitution cost is 2.5 for the same vowel with differing </context>
</contexts>
<marker>Wagner, Fischer, 1974</marker>
<rawString>Robert A Wagner and Michael J Fischer. 1974. The string-to-string correction problem. Journal of the ACM (JACM), 21(1):168–173.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>