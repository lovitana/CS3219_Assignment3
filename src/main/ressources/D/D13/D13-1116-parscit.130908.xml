<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000004">
<note confidence="0.643492">
S)
</note>
<title confidence="0.998418">
Combining PCFG-LA Models with Dual Decomposition: A Case Study with
Function Labels and Binarization
</title>
<author confidence="0.932515">
Joseph Le Roux†, Antoine Rozenknop†, Jennifer Foster*
</author>
<affiliation confidence="0.553202">
† Universit´e Paris 13, Sorbonne Paris Cit´e, LIPN, F-93430, Villetaneuse, France
</affiliation>
<address confidence="0.398133">
* NCLT/CNGL, School of Computing, Dublin City University, Dublin 9, Ireland
</address>
<email confidence="0.93899">
joseph.leroux@lipn.fr antoine.rozenknop@lipn.fr jfoster@computing.dcu.ie
</email>
<sectionHeader confidence="0.549462" genericHeader="abstract">
Abstract S
</sectionHeader>
<bodyText confidence="0.975368894736842">
b c d e f
It has recently been shown that different NLP S (a) Original example
models can be effectively combined using (S)
dual decomposition. In this paper we demon- �
strate that PCFG-LA parsing models are suit- �
able for combination in this way. We exper-
iment with the different models which result
from alternative methods of extracting a gram-
mar from a treebank (retaining or discarding
function labels, left binarization versus right
binarization) and achieve a labeled Parseval
F-score of 92.4 on Wall Street Journal Sec-
tion 23 – this represents an absolute improve-
ment of 0.7 and an error reduction rate of 7%
over a strong PCFG-LA product-model base-
line. Although we experiment only with bina-
rization and function labels in this study, there
is much scope for applying this approach to
other grammar extraction strategies.
</bodyText>
<sectionHeader confidence="0.998987" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.858513833333333">
Because of the large amount of possibly contra-
dictory information contained in a treebank, learn-
ing a phrase-structure-based parser implies making
several choices regarding the prevalent annotations
which have to be kept – or discarded – in order to
guide the learning algorithm. These choices, which
include whether to keep function labels and empty
nodes, how to binarize the trees and whether to alter
the granularity of the tagset, are often motivated em-
pirically by parsing performance rather than by the
different aspects of the language they may be able to
capture.
Recently Rush et al. (2010), Martins et al. (2011)
and Koo et al. (2010) have shown that Dual De-
composition or Lagrangian Relaxation is an elegant
1158 c
d
f e
</bodyText>
<note confidence="0.6628135">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1158–1169,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999965162790698">
sis on which CFGs rely and on which most popular
parsers are based may be too strong to learn the de-
pendencies between functions across the parse trees.
Also, the number of parameters increases with the
use of function labels and this can affect the learn-
ing process.
At first glance, binarization need not be an is-
sue, as CFGs admit a binarized form recognizing
exactly the same language. But binarization can be
associated with horizontal markovization and in this
case the recognized language will differ. Further-
more this can impose an unwanted emphasis on what
frontier information is more relevant to learning (be-
ginning or end of constituents). In the toy exam-
ple of Figure 1, the original grammar consisting of a
unique rule extracted from one tree only recognizes
the string bcdef, while the grammar learned from
the left binarized and markovized tree recognizes
(among others) bcdef and bdcef and the gram-
mar learned from the right binarized and markovized
tree recognizes (among others) bcdef and bcedf.
We find that i) retaining the function labels in non-
terminal categories loses its negative impact on pars-
ing as the number of grammars increases in PCFG-
LA product models, ii) the function labels them-
selves can be recovered with near state-of-the-art-
accuracy, iii) combining grammars with and without
function labels using dual decomposition is bene-
ficial, iv) combining left and right-binarized gram-
mars using dual decomposition also leads to bet-
ter trees and, v) our best results (a Parseval la-
beled F-score of 92.4, a Stanford labeled attach-
ment score (LAS) of 93.0 and a penn2malt unla-
beled attachment score (UAS) of 94.3 on Section 23
of the Wall Street Journal) are obtained by combin-
ing three grammars which encode different function
label/binarization decisions.
The paper is organized as follows. § 2 reviews
related work. § 3 presents approximate PCFG-LA
parsers as linear models, while § 4 shows how we
can use dual decomposition to derive an algorithm
for combining these models. Experimental results
are presented and discussed in § 5.
</bodyText>
<sectionHeader confidence="0.999792" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998689020408163">
Parser Model Combination It is well known that
improved parsing performance can be achieved by
leveraging the alternative perspectives provided by
several parsing models rather than relying on just
one. Examples are parser co-training (Steedman
et al., 2003; Sagae and Tsujii, 2007), voting over
phrase structure constituents or dependency arcs
(Henderson and Brill, 1999; Sagae and Tsujii, 2007;
Surdeanu and Manning, 2010), dependency pars-
ing stacking (Nivre and McDonald, 2008), product
model PCFG-LA parsing (Petrov, 2010), using dual
decomposition to combine dependency and phrase
structure models (Rush et al., 2010) or several non-
projective dependency parsing models (Koo et al.,
2010; Martins et al., 2011), and using expecta-
tion propagation, a related approach to dual decom-
position, to combine lexicalized, unlexicalized and
PCFG-LA models (Hall and Klein, 2012). In this
last example, the models must factor in the same
way: in other words, the grammars must use the
same binarization scheme. In our study, we employ
PCFG-LA product models with dual decomposition,
and we relax the constraints on factorization, as we
require only a loose coupling of the models.
Function Label Parsing Although function labels
have been available in the Penn Treebank (PTB) for
almost twenty years (Marcus et al., 1994), they have
been to a large extent overlooked in English parsing
research — most studies that report parsing results
on Section 23 of the Wall Street Journal (WSJ) use
parsing models that are trained on a version of the
WSJ trees where the function labels have been re-
moved. Notable exceptions are Merlo and Musillo
(2005) and Gabbard et al. (2006) who each trained
a parsing model on a version of the PTB with func-
tion labels intact. Gabbard et al. (2006) found that
parsing accuracy was not affected by keeping the
function labels. There have also been attempts to
use machine learning to recover the function labels
post-parsing (Blaheta and Charniak, 2000; Chrupala
et al., 2007). We recover function labels as part of
the parsing process, and use dual decomposition to
combine parsing models with and without function
labels. We are not aware of any other work that
leverages the benefits of both types of models.
Grammar Binarization Matsuzaki et al. (2005)
compare binarization strategies for PCFG-LA pars-
ing, and conclude that the differences between them
have a minor effect on parsing accuracy as the num-
</bodyText>
<page confidence="0.993599">
1159
</page>
<bodyText confidence="0.999926">
ber of latent annotations increases beyond two. Hall
and Klein (2012) are forced to use head binarization
when combining their lexicalized and unlexicalized
parsers. Dual decomposition allows us to combine
models with different binarization schemes.
</bodyText>
<sectionHeader confidence="0.752464" genericHeader="method">
3 Approximation of PCFG-LAs as Linear
Models
</sectionHeader>
<bodyText confidence="0.998838666666667">
In this section, we explain how we can use PCFG-
LAs to devise linear models suitable for the dual de-
composition framework.
</bodyText>
<subsectionHeader confidence="0.9921">
3.1 PCFG-LA
</subsectionHeader>
<bodyText confidence="0.828434">
Let us recall that PCFG-LAs are defined as tuples
G = (N, T , R, Rx, S, p) where:
</bodyText>
<listItem confidence="0.9845856">
• N is a set of observed non-terminals, among
which S is the distinguished initial symbol,
• T is a set of terminals (words),
• R is a set of latent annotations or hidden states,
• Rx is a set of annotated rules, of the form
</listItem>
<equation confidence="0.830166">
a[h1] b[h2] c[h3] for internal rules1 and
a[h1] w for lexical rules. Here a, b, c E N
</equation>
<bodyText confidence="0.9518618">
are non-terminals, w E T is a terminal and
h1, h2, h3 E R are latent annotations. Follow-
ing Cohen et al. (2012) we also define the set of
skeletal rules R, in other words, rules without
hidden states, of the form a —* b c or a —* w.
</bodyText>
<listItem confidence="0.983153857142857">
• p : Rx —* R&gt;0 defines the probabilities asso-
ciated with rules conditioned on their left-hand
side. Like Petrov and Klein (2007), we impose
that the initial symbol S has only one latent an-
notation. In other words, among rules with S
on the left-hand side, only those of the form
S[0] —* ry are in Rx.
</listItem>
<bodyText confidence="0.999763142857143">
With such a grammar G we can define probabil-
ities over trees in the following way. We will con-
sider two types of trees, annotated trees and skeletal
trees. An annotated tree is a sequence of rules from
Rx, while a skeletal tree is a sequence of skeletal
rules from R. An annotated tree Tx is obtained by
left-most derivation from S[0]. Its probability is:
</bodyText>
<footnote confidence="0.99909">
1For brevity and without loss of generality, we omit unary
and n-ary rules, as PCFG-LA admit a Chomsky normal form.
</footnote>
<equation confidence="0.9971675">
p(Tx) = 11 p(r) (1)
rETH
</equation>
<bodyText confidence="0.999726166666667">
We define a projection p from annotated trees to
skeletal trees. p(Tx) is a tree T isomorphic to Tx
with the same terminal and non-terminal symbols la-
beling nodes, without hidden states. The probability
of a skeletal tree T is a sum of the probabilities of
all annotated trees that admit T as their projection.
</bodyText>
<equation confidence="0.998272">
p(T) = E 11 p(r) (2)
THEp−1(T) rETH
</equation>
<bodyText confidence="0.9672355">
PCFG-LA parsing amounts to, given a sequence
of words, finding the most probable skeletal tree
with this sequence as its yield according to a gram-
mar G:
</bodyText>
<equation confidence="0.9993185">
T* = arg max
T
</equation>
<bodyText confidence="0.985243285714286">
Because of this alternation of sum and products,
the parsing problem is intractable. Moreover, the
PCFG-LAs do not belong to the family of linear
models that are assumed in the Lagrangian frame-
work of (Rush and Collins, 2012). We now turn to
approximations for the parsing problem in order to
address both issues.
</bodyText>
<subsectionHeader confidence="0.999905">
3.2 Variational Inference and MaxRule
</subsectionHeader>
<bodyText confidence="0.999983789473684">
Variational inference is a common technique to ap-
proximate a probability distribution p with a cruder
one q, as close as possible to the original one,
by minimizing the Kullback-Liebler divergence be-
tween the two – see for instance (Smith, 2011),
chapter 5 for an introduction. Matsuzaki et al.
(2005) showed that one can easily find such a cruder
distribution for PCFG-LAs and demonstrated exper-
imentally that this approximation gives good results.
More precisely, they find a PCFG that only rec-
ognizes the input sentence where the probabilities
q(rs) of the rules are set according to their marginal
probabilities in the original PCFG-LA parse forest.
The parameters rs are skeletal rules with span infor-
mation. Distribution q is defined in Figure 2.
Other approximations are possible. In particu-
lar, Petrov and Klein (2007) found that normaliz-
ing by the forest probability (in other words the in-
side probability of the root node) give better exper-
</bodyText>
<equation confidence="0.996031">
E 11 p(r) (3)
THEp−1(T) rETH
</equation>
<page confidence="0.912022">
1160
</page>
<table confidence="0.63304">
Escore(a → b c, i, j, k) = P i,k (a[x]) · p( a[x] → b[y] c[z] ) · P i,j (b[y]) · P j,k (c[z])
x,y,zEW out in in
Enorm(a → b c, i, j, k) = P i,k (a[x]) · P i,k (a[x])
xEW in out
Escore(a → w, i) = Pi,i (a[x]) · p(a[x] → w)
xEW out
Enorm(a → w, i) = P i,i (a[x]) · Pi,i (a[x])
xEW in out
</table>
<figure confidence="0.78681875">
q(rs) =
[norm(rs)
score(rs )Variational Inference)) or [Pscore( 0)) (MaxRule-Product))
in
</figure>
<figureCaption confidence="0.998527">
Figure 2: Variational Inference for PCFG-LA. Pin and Pout denote inside and outside probabilities.
</figureCaption>
<bodyText confidence="0.997604272727273">
imental results although its interpretation as varia-
tional inference is still unclear. This approximation
is called MaxRule-Product and amounts to replacing
the norm function (see Figure 2).
In both cases, the probability of a skeletal tree
now becomes a simple product of parameters asso-
ciated with anchored skeletal rules. For our purpose,
the consequence is twofold:
1. The parsing problem becomes tractable by ap-
plying standard PCFG algorithms relying on
dynamic programming (CKY for example).
</bodyText>
<subsectionHeader confidence="0.999932">
3.3 Products of PCFG-LAs
</subsectionHeader>
<bodyText confidence="0.998681111111111">
Although PCFG-LA training is beyond the scope
of this paper, it is worthwhile mentioning that the
most common way to learn their parameters relies
on Expectation-Maximization which is not guaran-
teed to find the optimal estimation. Fortunately, this
can be partly overcome by combining grammars that
only differ on the initial parameterization of the EM
algorithm. The probability of a skeletal tree is the
product of the probabilities assigned by each single
grammar Gi.
2. Equivalent to probability, a score u can be de- T* = arg max Yn qGi(T) (4)
fined as the logarithm of the probability. The T i=1
parsing problem becomes2:
YT* = arg max q(rs) Since grammars only differ by their numerical pa-
T rsET log q(rs) rameters (i.e. skeletal rules are the same), inference
X= arg max can be efficiently implemented using dynamic pro-
T rsET gramming (Petrov, 2010).
Scoring with n such grammars now becomes:
</bodyText>
<equation confidence="0.9287045">
X= arg max wrs · 11rs E T} T* = arg max Xn X log qGi(r) (5)
T rsEJ7 T i=1 rET
= arg max u(T) X= arg max Xn log qGi(r) (6)
T T rET i=1
</equation>
<bodyText confidence="0.9992977">
Thus, from a PCFG-LA we are able to de-
fine a linear model whose parameters are the log-
probabilities of the rules in distribution q.
2We denote the parse forest of a sentence by F and the char-
acteristic function of a set by 1.
The distributions qGi still have to be computed in-
dependently – and possibly in parallel – but the final
decoding can be performed jointly. This is still a
linear model for PCFG-LA parsing, but restricted to
grammars that share the same skeletal rules.
</bodyText>
<page confidence="0.98608">
1161
</page>
<sectionHeader confidence="0.996672" genericHeader="method">
4 Dual Decomposition
</sectionHeader>
<bodyText confidence="0.999977">
In this section, we show how we derive an algorithm
to work out the best parse according to a set of n
grammars that do not share the exact same skele-
tal rules. As such, the grammars’ product cannot
be easily conducted inside the parser to produce and
score a same and unique best tree, and we now con-
sider a c(ompound)-parse as a tuple (T1 ... Tn) of
n compatible trees. Each grammar Gi is responsi-
ble for scoring tree Ti, and we seek to obtain the
c-parse that maximizes the sum of the scores of its
different trees. For a c-parse to be consistent, we
have to precisely define the parts on which the trees
must agree to be compatible with each other, so that
we can model these as agreement constraints.
</bodyText>
<subsectionHeader confidence="0.985675">
4.1 Compound Parse Consistency
</subsectionHeader>
<bodyText confidence="0.998777228571429">
Let us suppose we have a set of phrase-structure
parsers trained on different versions of the same
treebank. Hence, some elements in the charts will
either be the same or can be mapped to each other
provided an equivalence relation and we define con-
sensus between parsers on these elements.
When the grammar is not functionally annotated,
phrase-structure trees can be decomposed into a set
of anchored (syntactical) categories Xs, asserting
that a category X is in the tree at position3 s. Thus,
such a tree T can be described by means of a boolean
vector z(T) indexed by anchored labels Xs, where
z(T)X, = 1 if Xs is in T and 0 otherwise.
We will differentiate the set of natural non-
terminals that occur in the treebanks from the set
of artificial non-terminals that do not occur in the
treebank and are the results of a binarization with
markovization. As these artificial non-terminals dis-
appear after reversing binarization in solution trees,
they do not play any role in the consensus between
parsers, and we only consider natural non-terminals
in the set of anchored labels.
When the grammar is functionally annotated,
each label X in a tree is a pair (X, F), where X
is a syntactical category and F is a function label.
In this case, in order to manage the consensus with
3The anchor s of a label is composed of the span (i, j), de-
noting that the label covers terminals of the input sentence from
index i to index j. In case the grammar contains unary non-
lexical rules, the anchor also discriminates the different posi-
tions in a sequence of unary rules.
non-functional grammars, we decompose such a tree
into two sets: a set of anchored categories Xs and a
set of anchored function labels Fs. Thus, a tree T
can be described by means of two boolean vectors:
</bodyText>
<listItem confidence="0.980492666666667">
• z(T) indexed by anchored categories Xs,
z(T)X, = 1 if there exists a function label F
so that (X, F)s is in T, and 0 otherwise;
• ((T) indexed by anchored function labels Fs,
((T)F9 = 1 if there exists a category X so that
(X, F)s is in T, and 0 otherwise.
</listItem>
<bodyText confidence="0.997365333333333">
In the present work, a compound parse (T1 ... Tn)
is said to be consistent iff every tree shares the same
set of anchored categories, i.e. iff:
</bodyText>
<equation confidence="0.952254">
d(i,j) E �1,n12, z(Ti) = z(Tj)
</equation>
<subsectionHeader confidence="0.799594">
4.2 Combining Parsers through Dual
Decomposition
</subsectionHeader>
<bodyText confidence="0.999977666666667">
Like previous applications, we base our reasoning
on the assumption that computing the optimal score
with each grammar Gi can be efficiently calculated,
which is the case for approximate PCFG-LA pars-
ing. We follow the presentation of the decomposi-
tion from (Martins et al., 2011) to explain how we
can combine several PCFG-LA parsers together.
For a sentence s, we want to obtain the best con-
sistent compound parse from a set of n parsers:
</bodyText>
<equation confidence="0.997302333333333">
(P) : find arg max
(T1...T,,,)EC
s.t. d(i, j) E Q1, n�2, z(Ti) = z(Tj) (8)
</equation>
<bodyText confidence="0.998666071428571">
where C = T1(s) x ... x Tn(s) is the product of
parse forests Ti(s), and Ti(s) is the set of trees in
grammar Gi whose yields are the input sentence s.
Solving this problem with an exact algorithm is
intractable. While artificial nodes could be inferred
using a traditional parsing algorithm based on dy-
namic programming (i.e. CKY), the natural nodes
require a coupling of the parsers’ items to enforce
the fact that natural daughter nodes must be identical
(or equivalent) with the same spans for all parsers.
Since the debinarization of markovized rules enables
the creation of arbitrarily long n-ary rules, in the
worst case the number of natural daughters to check
is exponential in the size of the span to infer. Even if
</bodyText>
<equation confidence="0.969542333333333">
n
E up(Tp) (7)
p=1
</equation>
<page confidence="0.930815">
1162
</page>
<bodyText confidence="0.9997363">
we bound the length of debinarized rules, the prob-
lem is hardly tractable.
As this problem is intractable, even for approxi-
mate PCFG-LA parsing, we apply the iterate method
presented in (Komodakis et al., 2007) for MRFs,
also applied for joint tasks in NLP such as combined
parsing and POS tagging in (Rush et al., 2010).
First, we introduce a witness vector u in order to
simplify constraints in (8). Problem (P) can then be
written in an equivalent form :
</bodyText>
<equation confidence="0.9554835">
(LP1) : oLP = min
A
</equation>
<bodyText confidence="0.999910714285714">
Finally, u can be removed from (LP1) by adding
the constraint: Ei Ai = 0. As a matter of fact,
one can see that if this constraint is not matched,
maxu,T,...n f(u, T1...n, A) = +oo and (LP1) can
not reach its minimum on such a point. We can now
find the maximum of f by maxing each Ti indepen-
dently of each other. The dual problem becomes:
</bodyText>
<equation confidence="0.9398263">
max f(u, T1...n, A)
u, TI...n
(P d n o max
find (T1...Tn)EC
s.t. di E Q1, n�, z(Ti) = u (10)
n
0i(Ti) (9)
i=1
(LP) : oLP = min n max (ui(Ti) + z(Ti) - Ai)
A i=1 TiE.7i
</equation>
<bodyText confidence="0.994939571428571">
Next, we proceed to a Lagrangian decomposition.
This decomposition is a two-step process:
Step 1 (Relaxation): the coupling constraints (10)
are removed by introducing a vector of Lagrange
multipliers Ai = (Ai,Xs)Xs for each parser i, in-
dexed by anchored categories Xs, and writing the
equivalent problem:
</bodyText>
<equation confidence="0.955563">
(RP) : oRP = max
u, T1...n min f(u, T1...n, A)
A
where:
�f(u, T1...n, A) = �Qi(Ti) + (z(Ti) − u) - Ai
i i
</equation>
<bodyText confidence="0.993581">
Intuitively, we can see the equivalence of (RP)
and (P) with the following reasoning:
</bodyText>
<listItem confidence="0.975443909090909">
• whenever all constraints (10) are met, the sec-
ond sum in f is nullified and f(u, T1...n, A) =
Ei ai(Ti), which is a finite value and precisely
the objective function maximized in (P);
• if there is at least one (i, X, s) such that
z(Ti)Xs =� uXs, then the value of Ei(z(Ti) −
u) - Ai can be made arbitrarily small by
an appropriate choice of Ai,Xs; in this case,
minA f(u, T1...n, A) = −oo. Thus, (RP) can
not reach its maximum at a point where con-
straints (10) are not satisfied.
</listItem>
<bodyText confidence="0.931468">
Step 2 (dualization): the dual problem (LP) is ob-
tained by permuting max and min in (RP):
</bodyText>
<equation confidence="0.986977">
�s.t. Ai = 0
i
</equation>
<bodyText confidence="0.997640483870968">
Minimization in (LP) can be solved iteratively
using the projected subgradient method. Finding a
subgradient amounts to computing the optimal so-
lution (Rush and Collins, 2012) for each of the n
subproblems (the slave problems in the terminol-
ogy of (Martins et al., 2011) and (Komodakis et al.,
2007)) which can be done efficiently, by incorpo-
rating the calculation of the penalties in the parsing
algorithm, and in parallel. Until the agreement con-
straints are met (or a maximal number of iterations
z), the Lagrangian multipliers are updated according
to the deviations from the average solutions (i.e. up-
dates are zeros for a natural span if the parsers agree
on it). This leads to Algorithm 1.
It should be noted that the DP charts are built and
pruned during the first iteration only (t = 0); fur-
ther iterations do not require recreating the DP chart,
which is memory intensive and time consuming, nor
recomputing the approximate distribution for varia-
tional inference. As DP on the pruned charts is a fast
process, the bottleneck of the algorithm still is in the
first calculation of slave solutions.
The stepsize sequence (αt)0&lt;t must be diminish-
ing and non-summable, that is to say: dt, αt &gt; 0,
limt,&apos; αt = 0 and E&apos;t=0 αt = oo. In practice, we
set αt = 1
1+c(t) where c(t) is the number of times the
objective function oP has increased since iterations
began.
Solving (P): it is easy to see that oLP is an up-
per bound of oP, but we do not necessarily have
</bodyText>
<page confidence="0.858814">
1163
</page>
<table confidence="0.5646175">
Algorithm 1 Find best compound parse with con-
straints on natural spans
Require: n parsers {pi}1&lt;i&lt;n
for all i, syntactical category X, anchor s do
</table>
<equation confidence="0.882056">
�(0)
i,X = 0
end for
fort = 0 → -r do
for all parsers pi do ( l
Ti
(t) � arg maxTE--t (ai(T) + z(T) • A(t))
end for
for all parsers pi do
Δ(t) i +_ at 1 z (Ti(t)) − &lt; E�&lt;, �z(
Λ(t+1) i*­ Λ(t) i+ Δ(t)
i
end for
if Δ(t) i= 0 for all i then
Exit loop
end if
end for
return (T (τ)
1 , � � � ,T(τ)
n )
</equation>
<bodyText confidence="0.9749865">
strong duality (i.e. oLP = oP) due to the facts that
parse forests are discrete sets. Furthermore, they get
pruned independently of each other. Thus, the algo-
rithm is not guaranteed to find a t such that z(� (t)
� )
is the same for every parser i. However – see (Koo
et al., 2010) – if it does reach such a state, then we
have the guarantee of having found an exact solution
of the primal problem (P). We show in the experi-
ments that this occurs very frequently.
</bodyText>
<sectionHeader confidence="0.999867" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.989475">
5.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999945833333333">
We perform our experiments on the WSJ sections of
the PTB with the usual split: sections 2 to 21 for
training, section 23 for testing, and we run bench-
marks on section 22. evalb is used for evaluation.
We use the LORG parser modified with Algo-
rithm 1. 4 All grammars are trained using 6
split/merge EM cycles. For the handling of unknown
words, we removed all words occurring once in the
training set and replaced them by their morpholog-
ical signature (Attia et al., 2010). Grammars for
products are obtained by training with 16 random
seeds for each setting. We use the approximate al-
</bodyText>
<footnote confidence="0.9860505">
4The LORG parser is available at https://github.
com/CNGLdlab/LORG-Release and the modification at
https://github.com/jihelhere/LORG-Release/
tree/functional_c11.
</footnote>
<bodyText confidence="0.9975315">
gorithm MaxRule-Product (Petrov and Klein, 2007).
The basic settings are a combination of the two
following parameters:
left or right binarization: we conjecture that this
affects the quality of the parsers by impacting the
recognition of left and right constituent frontiers.
We set vertical markovization to 1 (no parent anno-
tation) and horizontal markovization to 0 (we drop
all left/right annotations).
with or without functional annotations: in par-
ticular when non-terminals are annotated with mul-
tiple functions, all are kept.
</bodyText>
<subsectionHeader confidence="0.999563">
5.2 Products of Grammars
</subsectionHeader>
<bodyText confidence="0.9999224">
We first evaluate each setting on its own before com-
bining them. We test the 4 different settings on the
development set, using a single grammar or a prod-
uct of n grammars. Results are reported on Figure 3.
We can see that right binarization performs better
than left binarization. Contrary to the results of Gab-
bard et al. (2006), function labels are detrimental for
parsing performance for one grammar only. How-
ever, they do not penalize performance when using
the product model with 8 grammars or more.
</bodyText>
<figureCaption confidence="0.994324">
Figure 3: F1 for products of n grammars on the dev. set
</figureCaption>
<bodyText confidence="0.999833444444444">
EM is not guaranteed to find the optimal model
and the problem is made harder by the increased
number of parameters. Product models effectively
alleviate this curse of dimensionality by letting some
models compensate for the errors made by others.
On the other hand, as differences between left
and right binarization settings remain over all prod-
uct sizes, right binarization seems more useful on
its own. The first part of Table 1 gives F-score and
</bodyText>
<figure confidence="0.995809357142857">
F
Func
Func
n
1 2 4 8 16
93
92
91
90
89
Right
No Func Right
No Func Left
Left
</figure>
<page confidence="0.99456">
1164
</page>
<bodyText confidence="0.9966135">
Exact Match results of the product models with 16
grammars on the development set.
</bodyText>
<subsectionHeader confidence="0.999325">
5.3 Combinations with Dual Decomposition
</subsectionHeader>
<bodyText confidence="0.980928260869565">
We now turn to a series of experiments combining
product models of 16 grammars. In all these experi-
ments, we set the maximum number of iterations in
Algorithm 1 to 1000. The system then returns the
first element of the c-parse. We first try to combine
two settings in four different combinations:
DD Right Bin the two right-binarized systems –
with and without functions – the system returns
the function-labeled parse;
DD Left Bin the two left-binarized systems – with
and without functions – the system returns the
function-labeled parse;
DD Func the two systems with functions – left and
right binarization – the system returns the right-
binarized parse;
DD No Func the two systems without functions –
left and right binarization – the system returns
the right-binarized parse;
Results are in the second part of Table 1. Un-
surprisingly, the best configuration is the one com-
bining the two best product systems (with right bi-
narization) but all combined systems perform better
than their single components.
</bodyText>
<table confidence="0.999180818181818">
Setting F EX
No Func Right 92.26 42.97
No Func Left 91.92 42.91
Func Right 92.37 43.35
Func Left 91.95 43.15
DD Right Bin 92.71 44.44
DD Left Bin 92.23 43.97
DD Func 92.51 44.79
DD No Func 92.52 44.08
DD3 92.86 45.03
DD4 92.82 45.14
</table>
<tableCaption confidence="0.999941">
Table 1: Parse evaluation on development set.
</tableCaption>
<bodyText confidence="0.998929523809524">
We also combine 3 and 4 parsers to see if combin-
ing the above DD Right Bin setting with informa-
tion that could improve the recognition of beginning
of constituents can be helpful. We have 2 settings:
DD3 The 2 right-binarized parsers combined with
the left binarized parser without functions,
DD4 The 4 parsers together.
In both cases the system returns the right-
binarized function annotated parse. The results are
shown in the last part of Table 1. These 2 new con-
figurations give similar F-scores, better than all 2-
parser configurations.
We conclude from these results that left-
binarization and right-binarization capture different
linguistic aspects, even in the case of heavy horizon-
tal markovization, and that the method we propose
enables a practical integration of these models.
Table 2 shows for each setting how often the sys-
tems agree before 1000 iterations of Algorithm 1.
As one might expect, the more diverse the systems
are, the lower the rate of agreement.
</bodyText>
<table confidence="0.999008">
Setting Rate
DD Right Bin 99.24
DD Left Bin 99.12
DD Func 98.53
DD No Func 99.12
DD3 96.18
DD4 94.53
</table>
<tableCaption confidence="0.998387">
Table 2: Rate of certificates of optimality on the dev set.
</tableCaption>
<subsectionHeader confidence="0.997447">
5.4 Evaluation of Function Labeling
</subsectionHeader>
<bodyText confidence="0.998272333333333">
We also evaluate the quality of the function labels.
We compare the results obtained directly from the
parser output with results obtained with Funtag, a
state-of-the-art functional tagger that is applied on
parser output, using a gold model trained on sections
02 to 21 of the WSJ (Chrupala et al., 2007).
</bodyText>
<table confidence="0.999800272727273">
Setting SYSTEM FUN FUNTAG
No Func Right – 90.41
No Func Left – 90.26
Func Right 89.61 90.37
Func Left 89.29 90.40
DD Right Bin 89.50 90.38
DD Left Bin 89.11 90.31
DD Func 89.54 90.49
DD No Func – 90.36
DD3 89.48 90.42
DD4 89.57 90.45
</table>
<tableCaption confidence="0.999921">
Table 3: Function labeling F1 on development set.
</tableCaption>
<bodyText confidence="0.998444666666667">
The results are shown in Table 3. First, we can
see that the parser output is always outperformed by
Funtag. This is expected from a context-free parser
</bodyText>
<page confidence="0.982647">
1165
</page>
<bodyText confidence="0.99997">
that has a limited domain of locality with strong in-
dependence constraints, compared to a voted-SVM
classifier that can rely on arbitrarily rich features.
Second, the quality of the Funtag prediction seems
to be influenced by the fact that parser already han-
dle functions and by the accuracy of the parser (Par-
seval F-score). This is because we use a model
trained on the gold reference and so the closer the
parser output is from the reference, the better the
prediction. On the other hand, this is not the case
with parser predicted functions, where the best sys-
tem is the right-binarized product model with func-
tions, with very similar performance obtained by the
combinations consisting of 2 function parsers, set-
tings DD Func and DD4. This tends to indicate
that the constraints we have set to define consisten-
cies in c-parses, focusing on syntactical categories,
do not help in retrieving better function labels. This
suggests some possible further improvements where
parsers with functional annotations should be forced
to agree on these too.
</bodyText>
<subsectionHeader confidence="0.980009">
5.5 Evaluation of Dependencies
</subsectionHeader>
<table confidence="0.998735333333333">
Setting Stanford LTH p2m
LAS UAS LAS UAS UAS
Func Right 92.18 94.32 89.51 93.92 94.2
No Func Right 92.03 94.47 65.31 92.22 94.2
Func Left 91.86 94.06 89.28 93.75 93.9
No Func Left 91.83 94.29 65.33 92.18 94.1
DD Right Bin 92.56 94.60 89.81 94.17 94.5
DD Left Bin 92.01 94.38 89.62 94.05 94.2
DD Func 92.19 94.36 89.67 94.06 94.2
DD No Func 92.19 94.57 65.44 92.37 94.3
DD3 92.77 94.79 90.04 94.33 94.5
DD4 92.59 94.62 89.95 94.24 94.4
</table>
<tableCaption confidence="0.999257">
Table 4: Dependency accuracies on the dev set
</tableCaption>
<bodyText confidence="0.9993326">
Dependency-based evaluation of phrase structure
parser output has been used in recent years to pro-
vide a more rounded view on parser performance
and to compare with direct dependency parsers (Cer
et al., 2010; Petrov et al., 2010; Nivre et al., 2010;
Foster et al., 2011; Petrov and McDonald, 2012).
We evaluate our various parsing models on their
ability to recover three types of dependencies: basic
Stanford dependencies (de Marneffe and Manning,
2008)5, LTH dependencies (Johansson and Nugues,
</bodyText>
<footnote confidence="0.748833">
5We used the latest version at the time of writing, i.e. 3.20.
</footnote>
<bodyText confidence="0.999822">
2007)6 and penn2malt dependencies.7 The latter
are a simpler version of the LTH dependencies but
are still used when reporting unlabeled attachment
scores for dependency parsing.
The results, shown in Table 4, mirror the con-
stituency evaluation results in that the dual decom-
position results tend to outperform the basic product
model results, and combining three or four gram-
mars using dual decomposition yields the highest
scores. The differences between the Func and No
Func results highlight an important difference be-
tween the Stanford and LTH dependency schemes.
The tool used to produce Stanford dependencies has
been designed to work with phrase structure trees
that do not contain function labels. In contrast, the
LTH tool makes use of function label information
in phrase structure trees. Thus, their availability re-
sults in only a moderate improvement in LAS for the
Stanford dependencies and a very striking improve-
ment for the LTH dependencies. By retaining func-
tion labels during parsing, we have shown that LTH
dependencies can be recovered with a high level of
accuracy without having to resort to a post-parsing
function labeling step.
</bodyText>
<subsectionHeader confidence="0.999573">
5.6 Test Set Results
</subsectionHeader>
<bodyText confidence="0.932478">
We now evaluate our various systems on the test set
(the first half of Table 5) and compare these results
with state-of-the-art systems (the second half of Ta-
ble 5). We present parser accuracy results, measured
using Parseval F-score and penn2malt UAS, and, for
our systems, function label accuracy for labels pro-
duced during parsing and after parsing using Funtag.
We also carried out statistical significance testing8
on the F-score differences between our various sys-
tems on the development and test sets. The results
6nlp.cs.lth.se/software/treebank_converter. It
is recommended that LTH is used with the version of the Penn
Treebank which contains the more detailed NP bracketing pro-
vided by Vadas and Curran (2007). However, to facilitate com-
parison with other parsers and dependency schemes, we did not
use it in our experiments. We ran the converter with the right-
Branching=false option to indicate that we are using the version
without extra noun phrase bracketing.
7stp.lingfil.uu.se/˜nivre/research/Penn2Malt.
The English head-finding rules of Yamada and Mat-
sumoto (2003), supplied on the website, are employed.
</bodyText>
<footnote confidence="0.849268666666667">
8We used Dan Bikel’s compare.pl script which uses
stratified shuffling to compute significance. We consider a p
value &lt; 0.05 to indicate a statistically significant difference.
</footnote>
<page confidence="0.956958">
1166
</page>
<table confidence="0.9964065">
Setting F UAS Fun Funtag
Func Right 91.73 93.9 91.02 91.88
No Func Right 91.76 93.8 – 91.80
Func Left 91.45 93.7 90.41 91.80
No Func Left 91.57 93.7 – 91.74
DD Right Bin 92.16 94.1 90.85 91.86
DD Left Bin 91.89 93.9 90.10 91.85
DD Func 92.23 94.1 91.02 91.91
DD No Func 92.09 94.0 – 91.86
DD3 92.45 94.3 90.86 91.98
DD4 92.44 94.3 90.97 92.04
(Shindo et al., 2012) 92.4
(Zhang et al., 2009) 92.3
(Petrov, 2010) 91.8
(Huang, 2008) 91.7
(Bohnet and Nivre, 2012) 93.7
</table>
<tableCaption confidence="0.882068333333333">
Table 5: Test Set Results: Parseval F-score, penn2malt
UAS, Function Label Accuracy and Funtag Function La-
bel Accuracy
</tableCaption>
<table confidence="0.996535173913044">
are shown in Table 6.
Comparison Dev Test
Func Right vs. No Func Right X X
Func Left vs. No Func Left X X
Func Right vs. Func Left ✓ X
No Func Right vs. No Func Left X X
DD Right Bin vs. Func Right ✓ ✓
DD Right Bin vs. No Func Right ✓ ✓
DD Left Bin vs. Func Left ✓ ✓
DD Left Bin vs. No Func Left ✓ ✓
DD Right Bin vs DD Left Bin ✓ ✓
DD Func vs. Func Right X ✓
DD Func vs. Func Left ✓ ✓
DD No Func vs. No Func Right ✓ ✓
DD No Func vs. No Func Left ✓ ✓
DD Func vs. DD No Func X X
DD3 vs. DD Right Bin X ✓
DD3 vs. No Func Left ✓ ✓
DD3 vs. DD Func ✓ ✓
DD4 vs. DD. Right Bin X ✓
DD4 vs. DD. Left Bin ✓ ✓
DD4 vs. DD Func ✓ ✓
DD4 vs. DD3 X X
</table>
<tableCaption confidence="0.991514">
Table 6: Statistical Significance Testing
</tableCaption>
<bodyText confidence="0.999985032258064">
We measured the performance of DD4 on the test
set. It is approximately 3 times slower than the
slowest product model (left binarization with func-
tion labels) and 7 slower than the fastest one (right
binarization without function labels). This system
performs on average 85.5 iterations of the DD al-
gorithm. If we exclude the non-converging cases
(5.1% of the cases), this drops to 39.4.
Finally we compare our results with systems
trained and evaluated on the PTB, see the lower half
of Table 5. Our product models are not different
from those presented in (Petrov, 2010) and it is not
surprising to see that the F-scores are similar. More
interestingly our DD4 setting improves on these re-
sults and compares favorably with systems relying
on richer syntactic information, such as the discrim-
inative parser of (Huang, 2008) that makes use of
non-local features to score trees and the TSG parser
of (Shindo et al., 2012) that can take into account
larger tree fragments: this would indicate that by
combining our parsers we extend the domain of lo-
cality, horizontally with binarization schemes and
vertically with function labels. Our system also per-
forms better than the combination system presented
in (Zhang et al., 2009) that only relies on material
from the PTB9 but a more detailed comparison is
difficult: this system does not use products of la-
tent models and more generally their method is or-
thogonal to ours. We also include for comparison
state-of-the-art dependency parsing results (Bohnet
and Nivre, 2012).
</bodyText>
<sectionHeader confidence="0.999234" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999733">
We presented an algorithm and a set of experiments
showing that grammar extraction strategies can be
combined in an elegant way and give state-of-the-art
results when applied to high-quality phrase-based
parsers. As well as repeating these experiments for
languages which rely more on function annotation,
we also plan to apply our method to other types of
annotations, e.g. more linguistically motivated bina-
rization strategies or – of particular interest to us –
annotation of empty elements.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9970076">
We are grateful to the reviewers for their helpful
comments. We also thank Joachim Wagner for pro-
viding feedback on an early version of the paper.
This work has been partially funded by the Labex
EFL (ANR/CGI).
</bodyText>
<footnote confidence="0.9839345">
9Their other system relying on the self-trained version of the
BLLIP parser achieves 92.6 F1.
</footnote>
<page confidence="0.995429">
1167
</page>
<sectionHeader confidence="0.988371" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997557547169812">
Mohammed Attia, Jennifer Foster, Deirdre Hogan,
Joseph Le Roux, Lamia Tounsi, and Josef van Gen-
abith. 2010. Handling unknown words in statistical
latent-variable parsing models for Arabic, English and
French. In Proceedings of the First Workshop on Sta-
tistical Parsing of Morphologically Rich Languages
(SPMRL 2010).
Don Blaheta and Eugene Charniak. 2000. Assigning
function tags to parsed text. In Proceedings of the 1st
Annual Meeting of the North American chapter of the
ACL.
Bernd Bohnet and Joakim Nivre. 2012. A transition-
based system for joint part-of-speech tagging and la-
beled non-projective dependency parsing. In Proceed-
ings of the 2012 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Computa-
tional Natural Language Learning, pages 1455–1465.
Daniel Cer, Marie-Catherine de Marneffe, Daniel Juraf-
sky, and Christopher D. Manning. 2010. Parsing to
Stanford Dependencies: Trade-offs between speed and
accuracy. In Proceedings of LREC.
Grzegorz Chrupala, Nicolas Stroppa, Josef van Genabith,
and Georgiana Dinu. 2007. Better training for func-
tion labeling. In Proceedings of the 2007 Conference
on Recent Advances in Natural Language Processing
(RANLP).
Shay B. Cohen, Karl Stratos, Michael Collins, Dean P.
Foster, and Lyle Ungar. 2012. Spectral learning of
latent-variable PCFGs. In Proceedings of the 50th
Annual Meeting of the Association for Computational
Linguistics (ACL’12).
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. The Stanford typed dependencies repre-
sentation. In Proceedings of the COLING Workshop
on Cross-Framework and Cross-Domain Parser Eval-
uation.
Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner,
Joseph Le Roux, Joakim Nivre, Deirdre Hogan, and
Josef van Genabith. 2011. From news to comment:
Resources and benchmarks for parsing the language
of web 2.0. In Proceedings of IJCNLP.
Ryan Gabbard, Mitchell Marcus, and Seth Kulick. 2006.
Fully parsing the penn treebank. In Proceedings of the
Human Language Technology Conference of the North
American Chapter of the ACL, pages 184–191.
David Hall and Dan Klein. 2012. Training factored
PCFGs with expectation propagation. In Proceedings
of the 2012 Conference on Empirical Methods in Nat-
ural Language Processing, pages 649–652.
John C. Henderson and Eric Brill. 1999. Exploiting
diversity in natural language processing: Combining
parsers. In Proceedings of the 1999 Conference on
Empirical Methods in Natural Language Processing,
pages 187–194.
Liang Huang. 2008. Forest reranking: Discriminative
parsing with non-local features. In Proceedings of
ACL-08: HLT, pages 586–594.
Richard Johansson and Pierre Nugues. 2007. Extended
constituent-to-dependency conversion for english. In
Joakim Nivre, Heiki-Jaan Kaalep, Kadri Muischnek,
and Mare Koit, editors, Proceedings of NODALIDA
2007, pages 105–112.
Nikos Komodakis, Nikos Paragios, and Georgios Tziri-
tas. 2007. MRF optimization via dual decomposition:
Message-passing revisited. In Computer Vision, 2007.
ICCV 2007. IEEE 11th International Conference on,
pages 1–8. IEEE.
Terry Koo, Alexander M. Rush, Michael Collins, Tommi
Jaakkola, and David Sontag. 2010. Dual decompo-
sition for parsing with non-projective head automata.
In Proceedings of the 2010 Conference on Empirical
Methods in Natural Language Processing.
Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz,
Robert MacIntyre, Ann Bies, Mark Ferguson, Karen
Katz, and Britta Schasberger. 1994. The penn tree-
bank: Annotating predicate argument structure. In
Proceedings of the 1994 ARPA Speech and Natural
Language Workshop, pages 114–119.
Andr´e FT Martins, Noah A Smith, Pedro MQ Aguiar,
and M´ario AT Figueiredo. 2011. Dual decomposition
with many overlapping components. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing, pages 238–249.
Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii.
2005. Probabilistic CFG with latent annotations. In
Proceedings of the 43rd Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL’05), pages
75–82.
Paola Merlo and Gabriele Musillo. 2005. Accu-
rate function parsing. In Proceedings of Human
Language Technology Conference and Conference on
Empirical Methods in Natural Language Processing
(HLT/EMNLP), pages 620–627.
Joakim Nivre and Ryan McDonald. 2008. Integrating
graph-based and transition-based dependency parsers.
In Proceedings ofACL-08: HLT, pages 950–958.
Joakim Nivre, Laura Rimell, Ryan Mc Donald, and Car-
los G´omez-Rodriguez. 2010. Evaluation of depen-
dency parsers on unbounded dependencies. In Pro-
ceedings of COLING.
Slav Petrov and Dan Klein. 2007. Improved infer-
ence for unlexicalized parsing. In Proceedings of
the conference on Human Language Technologies and
the conference of the North American Chapter of
the Association for Computational Linguistics (HLT-
NAACL’07).
</reference>
<page confidence="0.914962">
1168
</page>
<reference confidence="0.977538824561404">
In Proceedings of the 2009 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1552–1560.
Slav Petrov and Ryan McDonald. 2012. Overview of
the 2012 shared task on parsing the web. In Working
Notes of the SANCL Workshop (NAACL-HLT).
Slav Petrov, Pi-Chuan Chang, Michael Ringgaard, and
Hiyan Alshawi. 2010. Uptraining for accurate deter-
ministic question parsing. In Proceedings of EMNLP.
Slav Petrov. 2010. Products of random latent variable
grammars. In Proceedings of the conference on Hu-
man Language Technologies and the conference of the
North American Chapter of the Association for Com-
putational Linguistics (HLT-NAACL’10), pages 19–27.
Alexander Rush and Michael Collins. 2012. A tutorial
on dual decomposition and lagrangian relaxation for
inference in natural language processing. Journal of
Artificial Intelligence Research, 45:305–362.
Alexander M Rush, David Sontag, Michael Collins, and
Tommi Jaakkola. 2010. On dual decomposition and
linear programming relaxations for natural language
processing. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing,
pages 1–11.
Kenji Sagae and Jun’ichi Tsujii. 2007. Dependency pars-
ing and domain adaptation with LR models and parser
ensembles. In Proceedings of the CoNLL shared task
session of EMNLP-CoNLL, pages 1044–1050.
Hiroyuki Shindo, Yusuke Miyao, Akinori Fujino, and
Masaaki Nagata. 2012. Bayesian symbol-refined tree
substitution grammars for syntactic parsing. In Pro-
ceedings of the 50th Annual Meeting of the Association
for Computational Linguistics: Long Papers-Volume
1, pages 440–448.
Noah A. Smith. 2011. Linguistic Structure Predic-
tion. Synthesis Lectures on Human Language Tech-
nologies. Morgan and Claypool, May.
Mark Steedman, Miles Osbourne, Anoop Sarkar, Stephen
Clark, Rebecca Hwa, Julia Hockenmaier, Paul Ruhlen,
Steven Baker, and Jeremiah Crim. 2003. Boot-
strapping statistical parsers from small datasets. In
Proceedings of EACL, pages 759–763.
Mihai Surdeanu and Christopher D. Manning. 2010. En-
semble models for dependency parsing: Cheap and
good? In Proceedings of the conference on Hu-
man Language Technologies and the conference of the
North American Chapter of the Association for Com-
putational Linguistics (HLT-NAACL’10), pages 649–
652.
David Vadas and James R. Curran. 2007. Adding noun
phrase structure to the penn treebank. In Proceedings
of ACL, pages 240–247.
Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical
dependency analysis with support vector machines. In
Proceedings of IWPT, pages 195–206.
Hui Zhang, Min Zhang, Chew Lim Tan, and Haizhou
Li. 2009. K-best combination of syntactic parsers.
</reference>
<page confidence="0.996869">
1169
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.478647">
<title confidence="0.9965455">Combining PCFG-LA Models with Dual Decomposition: A Case Study Function Labels and Binarization</title>
<author confidence="0.907882">Le_Antoine Jennifer</author>
<address confidence="0.774101">Paris 13, Sorbonne Paris Cit´e, LIPN, F-93430, Villetaneuse, School of Computing, Dublin City University, Dublin 9, Ireland</address>
<email confidence="0.80374">joseph.leroux@lipn.frantoine.rozenknop@lipn.frjfoster@computing.dcu.ie</email>
<abstract confidence="0.93217875">S b c d e f It has recently been shown that different NLP models can be effectively combined using dual decomposition. In this paper we demon-strate that PCFG-LA parsing models are suit-able for combination in this way. We exper-iment with the different models which result from alternative methods of extracting a gram-mar from a treebank (retaining or discarding function labels, left binarization versus right binarization) and achieve a labeled Parseval F-score of 92.4 on Wall Street Journal Sec-tion 23 – this represents an absolute improve-ment of 0.7 and an error reduction rate of 7% over a strong PCFG-LA product-model base-line. Although we experiment only with bina-rization and function labels in this study, there is much scope for applying this approach to other grammar extraction strategies. S (a) Original example �</abstract>
<intro confidence="0.833049"></intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mohammed Attia</author>
<author>Jennifer Foster</author>
<author>Deirdre Hogan</author>
<author>Joseph Le Roux</author>
<author>Lamia Tounsi</author>
<author>Josef van Genabith</author>
</authors>
<title>Handling unknown words in statistical latent-variable parsing models for Arabic, English and French.</title>
<date>2010</date>
<booktitle>In Proceedings of the First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL</booktitle>
<marker>Attia, Foster, Hogan, Le Roux, Tounsi, van Genabith, 2010</marker>
<rawString>Mohammed Attia, Jennifer Foster, Deirdre Hogan, Joseph Le Roux, Lamia Tounsi, and Josef van Genabith. 2010. Handling unknown words in statistical latent-variable parsing models for Arabic, English and French. In Proceedings of the First Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Don Blaheta</author>
<author>Eugene Charniak</author>
</authors>
<title>Assigning function tags to parsed text.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Annual Meeting of the North American chapter of the ACL.</booktitle>
<contexts>
<context position="6233" citStr="Blaheta and Charniak, 2000" startWordPosition="993" endWordPosition="996">t overlooked in English parsing research — most studies that report parsing results on Section 23 of the Wall Street Journal (WSJ) use parsing models that are trained on a version of the WSJ trees where the function labels have been removed. Notable exceptions are Merlo and Musillo (2005) and Gabbard et al. (2006) who each trained a parsing model on a version of the PTB with function labels intact. Gabbard et al. (2006) found that parsing accuracy was not affected by keeping the function labels. There have also been attempts to use machine learning to recover the function labels post-parsing (Blaheta and Charniak, 2000; Chrupala et al., 2007). We recover function labels as part of the parsing process, and use dual decomposition to combine parsing models with and without function labels. We are not aware of any other work that leverages the benefits of both types of models. Grammar Binarization Matsuzaki et al. (2005) compare binarization strategies for PCFG-LA parsing, and conclude that the differences between them have a minor effect on parsing accuracy as the num1159 ber of latent annotations increases beyond two. Hall and Klein (2012) are forced to use head binarization when combining their lexicalized a</context>
</contexts>
<marker>Blaheta, Charniak, 2000</marker>
<rawString>Don Blaheta and Eugene Charniak. 2000. Assigning function tags to parsed text. In Proceedings of the 1st Annual Meeting of the North American chapter of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
<author>Joakim Nivre</author>
</authors>
<title>A transitionbased system for joint part-of-speech tagging and labeled non-projective dependency parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1455--1465</pages>
<contexts>
<context position="32466" citStr="Bohnet and Nivre, 2012" startWordPosition="5623" endWordPosition="5626">’s compare.pl script which uses stratified shuffling to compute significance. We consider a p value &lt; 0.05 to indicate a statistically significant difference. 1166 Setting F UAS Fun Funtag Func Right 91.73 93.9 91.02 91.88 No Func Right 91.76 93.8 – 91.80 Func Left 91.45 93.7 90.41 91.80 No Func Left 91.57 93.7 – 91.74 DD Right Bin 92.16 94.1 90.85 91.86 DD Left Bin 91.89 93.9 90.10 91.85 DD Func 92.23 94.1 91.02 91.91 DD No Func 92.09 94.0 – 91.86 DD3 92.45 94.3 90.86 91.98 DD4 92.44 94.3 90.97 92.04 (Shindo et al., 2012) 92.4 (Zhang et al., 2009) 92.3 (Petrov, 2010) 91.8 (Huang, 2008) 91.7 (Bohnet and Nivre, 2012) 93.7 Table 5: Test Set Results: Parseval F-score, penn2malt UAS, Function Label Accuracy and Funtag Function Label Accuracy are shown in Table 6. Comparison Dev Test Func Right vs. No Func Right X X Func Left vs. No Func Left X X Func Right vs. Func Left ✓ X No Func Right vs. No Func Left X X DD Right Bin vs. Func Right ✓ ✓ DD Right Bin vs. No Func Right ✓ ✓ DD Left Bin vs. Func Left ✓ ✓ DD Left Bin vs. No Func Left ✓ ✓ DD Right Bin vs DD Left Bin ✓ ✓ DD Func vs. Func Right X ✓ DD Func vs. Func Left ✓ ✓ DD No Func vs. No Func Right ✓ ✓ DD No Func vs. No Func Left ✓ ✓ DD Func vs. DD No Func X </context>
<context position="34785" citStr="Bohnet and Nivre, 2012" startWordPosition="6067" endWordPosition="6070"> of (Shindo et al., 2012) that can take into account larger tree fragments: this would indicate that by combining our parsers we extend the domain of locality, horizontally with binarization schemes and vertically with function labels. Our system also performs better than the combination system presented in (Zhang et al., 2009) that only relies on material from the PTB9 but a more detailed comparison is difficult: this system does not use products of latent models and more generally their method is orthogonal to ours. We also include for comparison state-of-the-art dependency parsing results (Bohnet and Nivre, 2012). 6 Conclusion We presented an algorithm and a set of experiments showing that grammar extraction strategies can be combined in an elegant way and give state-of-the-art results when applied to high-quality phrase-based parsers. As well as repeating these experiments for languages which rely more on function annotation, we also plan to apply our method to other types of annotations, e.g. more linguistically motivated binarization strategies or – of particular interest to us – annotation of empty elements. Acknowledgments We are grateful to the reviewers for their helpful comments. We also thank</context>
</contexts>
<marker>Bohnet, Nivre, 2012</marker>
<rawString>Bernd Bohnet and Joakim Nivre. 2012. A transitionbased system for joint part-of-speech tagging and labeled non-projective dependency parsing. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1455–1465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Cer</author>
<author>Marie-Catherine de Marneffe</author>
<author>Daniel Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing to Stanford Dependencies: Trade-offs between speed and accuracy.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC.</booktitle>
<marker>Cer, de Marneffe, Jurafsky, Manning, 2010</marker>
<rawString>Daniel Cer, Marie-Catherine de Marneffe, Daniel Jurafsky, and Christopher D. Manning. 2010. Parsing to Stanford Dependencies: Trade-offs between speed and accuracy. In Proceedings of LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Chrupala</author>
<author>Nicolas Stroppa</author>
<author>Josef van Genabith</author>
<author>Georgiana Dinu</author>
</authors>
<title>Better training for function labeling.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Conference on Recent Advances in Natural Language Processing (RANLP).</booktitle>
<marker>Chrupala, Stroppa, van Genabith, Dinu, 2007</marker>
<rawString>Grzegorz Chrupala, Nicolas Stroppa, Josef van Genabith, and Georgiana Dinu. 2007. Better training for function labeling. In Proceedings of the 2007 Conference on Recent Advances in Natural Language Processing (RANLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shay B Cohen</author>
<author>Karl Stratos</author>
<author>Michael Collins</author>
<author>Dean P Foster</author>
<author>Lyle Ungar</author>
</authors>
<title>Spectral learning of latent-variable PCFGs.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL’12).</booktitle>
<contexts>
<context position="7626" citStr="Cohen et al. (2012)" startWordPosition="1240" endWordPosition="1243"> explain how we can use PCFGLAs to devise linear models suitable for the dual decomposition framework. 3.1 PCFG-LA Let us recall that PCFG-LAs are defined as tuples G = (N, T , R, Rx, S, p) where: • N is a set of observed non-terminals, among which S is the distinguished initial symbol, • T is a set of terminals (words), • R is a set of latent annotations or hidden states, • Rx is a set of annotated rules, of the form a[h1] b[h2] c[h3] for internal rules1 and a[h1] w for lexical rules. Here a, b, c E N are non-terminals, w E T is a terminal and h1, h2, h3 E R are latent annotations. Following Cohen et al. (2012) we also define the set of skeletal rules R, in other words, rules without hidden states, of the form a —* b c or a —* w. • p : Rx —* R&gt;0 defines the probabilities associated with rules conditioned on their left-hand side. Like Petrov and Klein (2007), we impose that the initial symbol S has only one latent annotation. In other words, among rules with S on the left-hand side, only those of the form S[0] —* ry are in Rx. With such a grammar G we can define probabilities over trees in the following way. We will consider two types of trees, annotated trees and skeletal trees. An annotated tree is</context>
</contexts>
<marker>Cohen, Stratos, Collins, Foster, Ungar, 2012</marker>
<rawString>Shay B. Cohen, Karl Stratos, Michael Collins, Dean P. Foster, and Lyle Ungar. 2012. Spectral learning of latent-variable PCFGs. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL’12).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The Stanford typed dependencies representation.</title>
<date>2008</date>
<booktitle>In Proceedings of the COLING Workshop on Cross-Framework and Cross-Domain Parser Evaluation.</booktitle>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The Stanford typed dependencies representation. In Proceedings of the COLING Workshop on Cross-Framework and Cross-Domain Parser Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jennifer Foster</author>
<author>Ozlem Cetinoglu</author>
<author>Joachim Wagner</author>
<author>Joseph Le Roux</author>
<author>Joakim Nivre</author>
<author>Deirdre Hogan</author>
<author>Josef van Genabith</author>
</authors>
<title>From news to comment: Resources and benchmarks for parsing the language of web 2.0.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCNLP.</booktitle>
<marker>Foster, Cetinoglu, Wagner, Le Roux, Nivre, Hogan, van Genabith, 2011</marker>
<rawString>Jennifer Foster, Ozlem Cetinoglu, Joachim Wagner, Joseph Le Roux, Joakim Nivre, Deirdre Hogan, and Josef van Genabith. 2011. From news to comment: Resources and benchmarks for parsing the language of web 2.0. In Proceedings of IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Gabbard</author>
<author>Mitchell Marcus</author>
<author>Seth Kulick</author>
</authors>
<title>Fully parsing the penn treebank.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL,</booktitle>
<pages>184--191</pages>
<contexts>
<context position="5922" citStr="Gabbard et al. (2006)" startWordPosition="941" endWordPosition="944">ct models with dual decomposition, and we relax the constraints on factorization, as we require only a loose coupling of the models. Function Label Parsing Although function labels have been available in the Penn Treebank (PTB) for almost twenty years (Marcus et al., 1994), they have been to a large extent overlooked in English parsing research — most studies that report parsing results on Section 23 of the Wall Street Journal (WSJ) use parsing models that are trained on a version of the WSJ trees where the function labels have been removed. Notable exceptions are Merlo and Musillo (2005) and Gabbard et al. (2006) who each trained a parsing model on a version of the PTB with function labels intact. Gabbard et al. (2006) found that parsing accuracy was not affected by keeping the function labels. There have also been attempts to use machine learning to recover the function labels post-parsing (Blaheta and Charniak, 2000; Chrupala et al., 2007). We recover function labels as part of the parsing process, and use dual decomposition to combine parsing models with and without function labels. We are not aware of any other work that leverages the benefits of both types of models. Grammar Binarization Matsuzak</context>
<context position="23307" citStr="Gabbard et al. (2006)" startWordPosition="4081" endWordPosition="4085">rontiers. We set vertical markovization to 1 (no parent annotation) and horizontal markovization to 0 (we drop all left/right annotations). with or without functional annotations: in particular when non-terminals are annotated with multiple functions, all are kept. 5.2 Products of Grammars We first evaluate each setting on its own before combining them. We test the 4 different settings on the development set, using a single grammar or a product of n grammars. Results are reported on Figure 3. We can see that right binarization performs better than left binarization. Contrary to the results of Gabbard et al. (2006), function labels are detrimental for parsing performance for one grammar only. However, they do not penalize performance when using the product model with 8 grammars or more. Figure 3: F1 for products of n grammars on the dev. set EM is not guaranteed to find the optimal model and the problem is made harder by the increased number of parameters. Product models effectively alleviate this curse of dimensionality by letting some models compensate for the errors made by others. On the other hand, as differences between left and right binarization settings remain over all product sizes, right bina</context>
</contexts>
<marker>Gabbard, Marcus, Kulick, 2006</marker>
<rawString>Ryan Gabbard, Mitchell Marcus, and Seth Kulick. 2006. Fully parsing the penn treebank. In Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 184–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hall</author>
<author>Dan Klein</author>
</authors>
<title>Training factored PCFGs with expectation propagation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>649--652</pages>
<contexts>
<context position="5132" citStr="Hall and Klein, 2012" startWordPosition="807" endWordPosition="810">, 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must use the same binarization scheme. In our study, we employ PCFG-LA product models with dual decomposition, and we relax the constraints on factorization, as we require only a loose coupling of the models. Function Label Parsing Although function labels have been available in the Penn Treebank (PTB) for almost twenty years (Marcus et al., 1994), they have been to a large extent overlooked in English parsing research — most studies that report parsing results on Section 23 of the Wall Street Journal </context>
<context position="6762" citStr="Hall and Klein (2012)" startWordPosition="1079" endWordPosition="1082">use machine learning to recover the function labels post-parsing (Blaheta and Charniak, 2000; Chrupala et al., 2007). We recover function labels as part of the parsing process, and use dual decomposition to combine parsing models with and without function labels. We are not aware of any other work that leverages the benefits of both types of models. Grammar Binarization Matsuzaki et al. (2005) compare binarization strategies for PCFG-LA parsing, and conclude that the differences between them have a minor effect on parsing accuracy as the num1159 ber of latent annotations increases beyond two. Hall and Klein (2012) are forced to use head binarization when combining their lexicalized and unlexicalized parsers. Dual decomposition allows us to combine models with different binarization schemes. 3 Approximation of PCFG-LAs as Linear Models In this section, we explain how we can use PCFGLAs to devise linear models suitable for the dual decomposition framework. 3.1 PCFG-LA Let us recall that PCFG-LAs are defined as tuples G = (N, T , R, Rx, S, p) where: • N is a set of observed non-terminals, among which S is the distinguished initial symbol, • T is a set of terminals (words), • R is a set of latent annotatio</context>
</contexts>
<marker>Hall, Klein, 2012</marker>
<rawString>David Hall and Dan Klein. 2012. Training factored PCFGs with expectation propagation. In Proceedings of the 2012 Conference on Empirical Methods in Natural Language Processing, pages 649–652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Henderson</author>
<author>Eric Brill</author>
</authors>
<title>Exploiting diversity in natural language processing: Combining parsers.</title>
<date>1999</date>
<booktitle>In Proceedings of the 1999 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>187--194</pages>
<contexts>
<context position="4631" citStr="Henderson and Brill, 1999" startWordPosition="733" endWordPosition="736">reviews related work. § 3 presents approximate PCFG-LA parsers as linear models, while § 4 shows how we can use dual decomposition to derive an algorithm for combining these models. Experimental results are presented and discussed in § 5. 2 Related Work Parser Model Combination It is well known that improved parsing performance can be achieved by leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must u</context>
</contexts>
<marker>Henderson, Brill, 1999</marker>
<rawString>John C. Henderson and Eric Brill. 1999. Exploiting diversity in natural language processing: Combining parsers. In Proceedings of the 1999 Conference on Empirical Methods in Natural Language Processing, pages 187–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
</authors>
<title>Forest reranking: Discriminative parsing with non-local features.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL-08: HLT,</booktitle>
<pages>586--594</pages>
<contexts>
<context position="32436" citStr="Huang, 2008" startWordPosition="5620" endWordPosition="5621"> 8We used Dan Bikel’s compare.pl script which uses stratified shuffling to compute significance. We consider a p value &lt; 0.05 to indicate a statistically significant difference. 1166 Setting F UAS Fun Funtag Func Right 91.73 93.9 91.02 91.88 No Func Right 91.76 93.8 – 91.80 Func Left 91.45 93.7 90.41 91.80 No Func Left 91.57 93.7 – 91.74 DD Right Bin 92.16 94.1 90.85 91.86 DD Left Bin 91.89 93.9 90.10 91.85 DD Func 92.23 94.1 91.02 91.91 DD No Func 92.09 94.0 – 91.86 DD3 92.45 94.3 90.86 91.98 DD4 92.44 94.3 90.97 92.04 (Shindo et al., 2012) 92.4 (Zhang et al., 2009) 92.3 (Petrov, 2010) 91.8 (Huang, 2008) 91.7 (Bohnet and Nivre, 2012) 93.7 Table 5: Test Set Results: Parseval F-score, penn2malt UAS, Function Label Accuracy and Funtag Function Label Accuracy are shown in Table 6. Comparison Dev Test Func Right vs. No Func Right X X Func Left vs. No Func Left X X Func Right vs. Func Left ✓ X No Func Right vs. No Func Left X X DD Right Bin vs. Func Right ✓ ✓ DD Right Bin vs. No Func Right ✓ ✓ DD Left Bin vs. Func Left ✓ ✓ DD Left Bin vs. No Func Left ✓ ✓ DD Right Bin vs DD Left Bin ✓ ✓ DD Func vs. Func Right X ✓ DD Func vs. Func Left ✓ ✓ DD No Func vs. No Func Right ✓ ✓ DD No Func vs. No Func Left</context>
<context position="34091" citStr="Huang, 2008" startWordPosition="5955" endWordPosition="5956"> without function labels). This system performs on average 85.5 iterations of the DD algorithm. If we exclude the non-converging cases (5.1% of the cases), this drops to 39.4. Finally we compare our results with systems trained and evaluated on the PTB, see the lower half of Table 5. Our product models are not different from those presented in (Petrov, 2010) and it is not surprising to see that the F-scores are similar. More interestingly our DD4 setting improves on these results and compares favorably with systems relying on richer syntactic information, such as the discriminative parser of (Huang, 2008) that makes use of non-local features to score trees and the TSG parser of (Shindo et al., 2012) that can take into account larger tree fragments: this would indicate that by combining our parsers we extend the domain of locality, horizontally with binarization schemes and vertically with function labels. Our system also performs better than the combination system presented in (Zhang et al., 2009) that only relies on material from the PTB9 but a more detailed comparison is difficult: this system does not use products of latent models and more generally their method is orthogonal to ours. We al</context>
</contexts>
<marker>Huang, 2008</marker>
<rawString>Liang Huang. 2008. Forest reranking: Discriminative parsing with non-local features. In Proceedings of ACL-08: HLT, pages 586–594.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Pierre Nugues</author>
</authors>
<title>Extended constituent-to-dependency conversion for english.</title>
<date>2007</date>
<booktitle>Proceedings of NODALIDA 2007,</booktitle>
<pages>105--112</pages>
<editor>In Joakim Nivre, Heiki-Jaan Kaalep, Kadri Muischnek, and Mare Koit, editors,</editor>
<marker>Johansson, Nugues, 2007</marker>
<rawString>Richard Johansson and Pierre Nugues. 2007. Extended constituent-to-dependency conversion for english. In Joakim Nivre, Heiki-Jaan Kaalep, Kadri Muischnek, and Mare Koit, editors, Proceedings of NODALIDA 2007, pages 105–112.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikos Komodakis</author>
<author>Nikos Paragios</author>
<author>Georgios Tziritas</author>
</authors>
<title>MRF optimization via dual decomposition: Message-passing revisited.</title>
<date>2007</date>
<booktitle>In Computer Vision,</booktitle>
<pages>1--8</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="17397" citStr="Komodakis et al., 2007" startWordPosition="2993" endWordPosition="2996">natural nodes require a coupling of the parsers’ items to enforce the fact that natural daughter nodes must be identical (or equivalent) with the same spans for all parsers. Since the debinarization of markovized rules enables the creation of arbitrarily long n-ary rules, in the worst case the number of natural daughters to check is exponential in the size of the span to infer. Even if n E up(Tp) (7) p=1 1162 we bound the length of debinarized rules, the problem is hardly tractable. As this problem is intractable, even for approximate PCFG-LA parsing, we apply the iterate method presented in (Komodakis et al., 2007) for MRFs, also applied for joint tasks in NLP such as combined parsing and POS tagging in (Rush et al., 2010). First, we introduce a witness vector u in order to simplify constraints in (8). Problem (P) can then be written in an equivalent form : (LP1) : oLP = min A Finally, u can be removed from (LP1) by adding the constraint: Ei Ai = 0. As a matter of fact, one can see that if this constraint is not matched, maxu,T,...n f(u, T1...n, A) = +oo and (LP1) can not reach its minimum on such a point. We can now find the maximum of f by maxing each Ti independently of each other. The dual problem b</context>
<context position="19558" citStr="Komodakis et al., 2007" startWordPosition="3408" endWordPosition="3411">of Ei(z(Ti) − u) - Ai can be made arbitrarily small by an appropriate choice of Ai,Xs; in this case, minA f(u, T1...n, A) = −oo. Thus, (RP) can not reach its maximum at a point where constraints (10) are not satisfied. Step 2 (dualization): the dual problem (LP) is obtained by permuting max and min in (RP): �s.t. Ai = 0 i Minimization in (LP) can be solved iteratively using the projected subgradient method. Finding a subgradient amounts to computing the optimal solution (Rush and Collins, 2012) for each of the n subproblems (the slave problems in the terminology of (Martins et al., 2011) and (Komodakis et al., 2007)) which can be done efficiently, by incorporating the calculation of the penalties in the parsing algorithm, and in parallel. Until the agreement constraints are met (or a maximal number of iterations z), the Lagrangian multipliers are updated according to the deviations from the average solutions (i.e. updates are zeros for a natural span if the parsers agree on it). This leads to Algorithm 1. It should be noted that the DP charts are built and pruned during the first iteration only (t = 0); further iterations do not require recreating the DP chart, which is memory intensive and time consumin</context>
</contexts>
<marker>Komodakis, Paragios, Tziritas, 2007</marker>
<rawString>Nikos Komodakis, Nikos Paragios, and Georgios Tziritas. 2007. MRF optimization via dual decomposition: Message-passing revisited. In Computer Vision, 2007. ICCV 2007. IEEE 11th International Conference on, pages 1–8. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Koo</author>
<author>Alexander M Rush</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
<author>David Sontag</author>
</authors>
<title>Dual decomposition for parsing with non-projective head automata.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="1894" citStr="Koo et al. (2010)" startWordPosition="293" endWordPosition="296">of possibly contradictory information contained in a treebank, learning a phrase-structure-based parser implies making several choices regarding the prevalent annotations which have to be kept – or discarded – in order to guide the learning algorithm. These choices, which include whether to keep function labels and empty nodes, how to binarize the trees and whether to alter the granularity of the tagset, are often motivated empirically by parsing performance rather than by the different aspects of the language they may be able to capture. Recently Rush et al. (2010), Martins et al. (2011) and Koo et al. (2010) have shown that Dual Decomposition or Lagrangian Relaxation is an elegant 1158 c d f e Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1158–1169, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics sis on which CFGs rely and on which most popular parsers are based may be too strong to learn the dependencies between functions across the parse trees. Also, the number of parameters increases with the use of function labels and this can affect the learning process. At first glance, binarization need not be an</context>
<context position="4951" citStr="Koo et al., 2010" startWordPosition="780" endWordPosition="783"> can be achieved by leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must use the same binarization scheme. In our study, we employ PCFG-LA product models with dual decomposition, and we relax the constraints on factorization, as we require only a loose coupling of the models. Function Label Parsing Although function labels have been available in the Penn Treebank (PTB) for almost twenty year</context>
<context position="21451" citStr="Koo et al., 2010" startWordPosition="3779" endWordPosition="3782"> i, syntactical category X, anchor s do �(0) i,X = 0 end for fort = 0 → -r do for all parsers pi do ( l Ti (t) � arg maxTE--t (ai(T) + z(T) • A(t)) end for for all parsers pi do Δ(t) i +_ at 1 z (Ti(t)) − &lt; E�&lt;, �z( Λ(t+1) i* Λ(t) i+ Δ(t) i end for if Δ(t) i= 0 for all i then Exit loop end if end for return (T (τ) 1 , � � � ,T(τ) n ) strong duality (i.e. oLP = oP) due to the facts that parse forests are discrete sets. Furthermore, they get pruned independently of each other. Thus, the algorithm is not guaranteed to find a t such that z(� (t) � ) is the same for every parser i. However – see (Koo et al., 2010) – if it does reach such a state, then we have the guarantee of having found an exact solution of the primal problem (P). We show in the experiments that this occurs very frequently. 5 Experiments 5.1 Experimental Setup We perform our experiments on the WSJ sections of the PTB with the usual split: sections 2 to 21 for training, section 23 for testing, and we run benchmarks on section 22. evalb is used for evaluation. We use the LORG parser modified with Algorithm 1. 4 All grammars are trained using 6 split/merge EM cycles. For the handling of unknown words, we removed all words occurring once</context>
</contexts>
<marker>Koo, Rush, Collins, Jaakkola, Sontag, 2010</marker>
<rawString>Terry Koo, Alexander M. Rush, Michael Collins, Tommi Jaakkola, and David Sontag. 2010. Dual decomposition for parsing with non-projective head automata. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Grace Kim</author>
<author>Mary Ann Marcinkiewicz</author>
<author>Robert MacIntyre</author>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Britta Schasberger</author>
</authors>
<title>The penn treebank: Annotating predicate argument structure.</title>
<date>1994</date>
<booktitle>In Proceedings of the 1994 ARPA Speech and Natural Language Workshop,</booktitle>
<pages>114--119</pages>
<contexts>
<context position="5574" citStr="Marcus et al., 1994" startWordPosition="880" endWordPosition="883">artins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must use the same binarization scheme. In our study, we employ PCFG-LA product models with dual decomposition, and we relax the constraints on factorization, as we require only a loose coupling of the models. Function Label Parsing Although function labels have been available in the Penn Treebank (PTB) for almost twenty years (Marcus et al., 1994), they have been to a large extent overlooked in English parsing research — most studies that report parsing results on Section 23 of the Wall Street Journal (WSJ) use parsing models that are trained on a version of the WSJ trees where the function labels have been removed. Notable exceptions are Merlo and Musillo (2005) and Gabbard et al. (2006) who each trained a parsing model on a version of the PTB with function labels intact. Gabbard et al. (2006) found that parsing accuracy was not affected by keeping the function labels. There have also been attempts to use machine learning to recover t</context>
</contexts>
<marker>Marcus, Kim, Marcinkiewicz, MacIntyre, Bies, Ferguson, Katz, Schasberger, 1994</marker>
<rawString>Mitchell Marcus, Grace Kim, Mary Ann Marcinkiewicz, Robert MacIntyre, Ann Bies, Mark Ferguson, Karen Katz, and Britta Schasberger. 1994. The penn treebank: Annotating predicate argument structure. In Proceedings of the 1994 ARPA Speech and Natural Language Workshop, pages 114–119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andr´e FT Martins</author>
<author>Noah A Smith</author>
<author>Pedro MQ Aguiar</author>
<author>M´ario AT Figueiredo</author>
</authors>
<title>Dual decomposition with many overlapping components.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>238--249</pages>
<contexts>
<context position="1872" citStr="Martins et al. (2011)" startWordPosition="288" endWordPosition="291">cause of the large amount of possibly contradictory information contained in a treebank, learning a phrase-structure-based parser implies making several choices regarding the prevalent annotations which have to be kept – or discarded – in order to guide the learning algorithm. These choices, which include whether to keep function labels and empty nodes, how to binarize the trees and whether to alter the granularity of the tagset, are often motivated empirically by parsing performance rather than by the different aspects of the language they may be able to capture. Recently Rush et al. (2010), Martins et al. (2011) and Koo et al. (2010) have shown that Dual Decomposition or Lagrangian Relaxation is an elegant 1158 c d f e Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1158–1169, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics sis on which CFGs rely and on which most popular parsers are based may be too strong to learn the dependencies between functions across the parse trees. Also, the number of parameters increases with the use of function labels and this can affect the learning process. At first glance, binar</context>
<context position="4974" citStr="Martins et al., 2011" startWordPosition="784" endWordPosition="787">y leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must use the same binarization scheme. In our study, we employ PCFG-LA product models with dual decomposition, and we relax the constraints on factorization, as we require only a loose coupling of the models. Function Label Parsing Although function labels have been available in the Penn Treebank (PTB) for almost twenty years (Marcus et al., 1994)</context>
<context position="16201" citStr="Martins et al., 2011" startWordPosition="2780" endWordPosition="2783">xed by anchored function labels Fs, ((T)F9 = 1 if there exists a category X so that (X, F)s is in T, and 0 otherwise. In the present work, a compound parse (T1 ... Tn) is said to be consistent iff every tree shares the same set of anchored categories, i.e. iff: d(i,j) E �1,n12, z(Ti) = z(Tj) 4.2 Combining Parsers through Dual Decomposition Like previous applications, we base our reasoning on the assumption that computing the optimal score with each grammar Gi can be efficiently calculated, which is the case for approximate PCFG-LA parsing. We follow the presentation of the decomposition from (Martins et al., 2011) to explain how we can combine several PCFG-LA parsers together. For a sentence s, we want to obtain the best consistent compound parse from a set of n parsers: (P) : find arg max (T1...T,,,)EC s.t. d(i, j) E Q1, n�2, z(Ti) = z(Tj) (8) where C = T1(s) x ... x Tn(s) is the product of parse forests Ti(s), and Ti(s) is the set of trees in grammar Gi whose yields are the input sentence s. Solving this problem with an exact algorithm is intractable. While artificial nodes could be inferred using a traditional parsing algorithm based on dynamic programming (i.e. CKY), the natural nodes require a cou</context>
<context position="19529" citStr="Martins et al., 2011" startWordPosition="3403" endWordPosition="3406">)Xs =� uXs, then the value of Ei(z(Ti) − u) - Ai can be made arbitrarily small by an appropriate choice of Ai,Xs; in this case, minA f(u, T1...n, A) = −oo. Thus, (RP) can not reach its maximum at a point where constraints (10) are not satisfied. Step 2 (dualization): the dual problem (LP) is obtained by permuting max and min in (RP): �s.t. Ai = 0 i Minimization in (LP) can be solved iteratively using the projected subgradient method. Finding a subgradient amounts to computing the optimal solution (Rush and Collins, 2012) for each of the n subproblems (the slave problems in the terminology of (Martins et al., 2011) and (Komodakis et al., 2007)) which can be done efficiently, by incorporating the calculation of the penalties in the parsing algorithm, and in parallel. Until the agreement constraints are met (or a maximal number of iterations z), the Lagrangian multipliers are updated according to the deviations from the average solutions (i.e. updates are zeros for a natural span if the parsers agree on it). This leads to Algorithm 1. It should be noted that the DP charts are built and pruned during the first iteration only (t = 0); further iterations do not require recreating the DP chart, which is memor</context>
</contexts>
<marker>Martins, Smith, Aguiar, Figueiredo, 2011</marker>
<rawString>Andr´e FT Martins, Noah A Smith, Pedro MQ Aguiar, and M´ario AT Figueiredo. 2011. Dual decomposition with many overlapping components. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 238–249.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takuya Matsuzaki</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Probabilistic CFG with latent annotations.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>75--82</pages>
<contexts>
<context position="6537" citStr="Matsuzaki et al. (2005)" startWordPosition="1043" endWordPosition="1046">. (2006) who each trained a parsing model on a version of the PTB with function labels intact. Gabbard et al. (2006) found that parsing accuracy was not affected by keeping the function labels. There have also been attempts to use machine learning to recover the function labels post-parsing (Blaheta and Charniak, 2000; Chrupala et al., 2007). We recover function labels as part of the parsing process, and use dual decomposition to combine parsing models with and without function labels. We are not aware of any other work that leverages the benefits of both types of models. Grammar Binarization Matsuzaki et al. (2005) compare binarization strategies for PCFG-LA parsing, and conclude that the differences between them have a minor effect on parsing accuracy as the num1159 ber of latent annotations increases beyond two. Hall and Klein (2012) are forced to use head binarization when combining their lexicalized and unlexicalized parsers. Dual decomposition allows us to combine models with different binarization schemes. 3 Approximation of PCFG-LAs as Linear Models In this section, we explain how we can use PCFGLAs to devise linear models suitable for the dual decomposition framework. 3.1 PCFG-LA Let us recall t</context>
<context position="9715" citStr="Matsuzaki et al. (2005)" startWordPosition="1619" endWordPosition="1622"> sum and products, the parsing problem is intractable. Moreover, the PCFG-LAs do not belong to the family of linear models that are assumed in the Lagrangian framework of (Rush and Collins, 2012). We now turn to approximations for the parsing problem in order to address both issues. 3.2 Variational Inference and MaxRule Variational inference is a common technique to approximate a probability distribution p with a cruder one q, as close as possible to the original one, by minimizing the Kullback-Liebler divergence between the two – see for instance (Smith, 2011), chapter 5 for an introduction. Matsuzaki et al. (2005) showed that one can easily find such a cruder distribution for PCFG-LAs and demonstrated experimentally that this approximation gives good results. More precisely, they find a PCFG that only recognizes the input sentence where the probabilities q(rs) of the rules are set according to their marginal probabilities in the original PCFG-LA parse forest. The parameters rs are skeletal rules with span information. Distribution q is defined in Figure 2. Other approximations are possible. In particular, Petrov and Klein (2007) found that normalizing by the forest probability (in other words the insid</context>
</contexts>
<marker>Matsuzaki, Miyao, Tsujii, 2005</marker>
<rawString>Takuya Matsuzaki, Yusuke Miyao, and Jun’ichi Tsujii. 2005. Probabilistic CFG with latent annotations. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 75–82.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Gabriele Musillo</author>
</authors>
<title>Accurate function parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP),</booktitle>
<pages>620--627</pages>
<contexts>
<context position="5896" citStr="Merlo and Musillo (2005)" startWordPosition="936" endWordPosition="939">tudy, we employ PCFG-LA product models with dual decomposition, and we relax the constraints on factorization, as we require only a loose coupling of the models. Function Label Parsing Although function labels have been available in the Penn Treebank (PTB) for almost twenty years (Marcus et al., 1994), they have been to a large extent overlooked in English parsing research — most studies that report parsing results on Section 23 of the Wall Street Journal (WSJ) use parsing models that are trained on a version of the WSJ trees where the function labels have been removed. Notable exceptions are Merlo and Musillo (2005) and Gabbard et al. (2006) who each trained a parsing model on a version of the PTB with function labels intact. Gabbard et al. (2006) found that parsing accuracy was not affected by keeping the function labels. There have also been attempts to use machine learning to recover the function labels post-parsing (Blaheta and Charniak, 2000; Chrupala et al., 2007). We recover function labels as part of the parsing process, and use dual decomposition to combine parsing models with and without function labels. We are not aware of any other work that leverages the benefits of both types of models. Gra</context>
</contexts>
<marker>Merlo, Musillo, 2005</marker>
<rawString>Paola Merlo and Gabriele Musillo. 2005. Accurate function parsing. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing (HLT/EMNLP), pages 620–627.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Ryan McDonald</author>
</authors>
<title>Integrating graph-based and transition-based dependency parsers.</title>
<date>2008</date>
<booktitle>In Proceedings ofACL-08: HLT,</booktitle>
<pages>950--958</pages>
<contexts>
<context position="4740" citStr="Nivre and McDonald, 2008" startWordPosition="749" endWordPosition="752">se dual decomposition to derive an algorithm for combining these models. Experimental results are presented and discussed in § 5. 2 Related Work Parser Model Combination It is well known that improved parsing performance can be achieved by leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must use the same binarization scheme. In our study, we employ PCFG-LA product models with dual decomposition, and </context>
</contexts>
<marker>Nivre, McDonald, 2008</marker>
<rawString>Joakim Nivre and Ryan McDonald. 2008. Integrating graph-based and transition-based dependency parsers. In Proceedings ofACL-08: HLT, pages 950–958.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Laura Rimell</author>
<author>Ryan Mc Donald</author>
<author>Carlos G´omez-Rodriguez</author>
</authors>
<title>Evaluation of dependency parsers on unbounded dependencies.</title>
<date>2010</date>
<booktitle>In Proceedings of COLING.</booktitle>
<marker>Nivre, Rimell, Donald, G´omez-Rodriguez, 2010</marker>
<rawString>Joakim Nivre, Laura Rimell, Ryan Mc Donald, and Carlos G´omez-Rodriguez. 2010. Evaluation of dependency parsers on unbounded dependencies. In Proceedings of COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved inference for unlexicalized parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the conference on Human Language Technologies and the conference of the North American Chapter of the Association for Computational Linguistics (HLTNAACL’07).</booktitle>
<contexts>
<context position="7877" citStr="Petrov and Klein (2007)" startWordPosition="1290" endWordPosition="1293">h S is the distinguished initial symbol, • T is a set of terminals (words), • R is a set of latent annotations or hidden states, • Rx is a set of annotated rules, of the form a[h1] b[h2] c[h3] for internal rules1 and a[h1] w for lexical rules. Here a, b, c E N are non-terminals, w E T is a terminal and h1, h2, h3 E R are latent annotations. Following Cohen et al. (2012) we also define the set of skeletal rules R, in other words, rules without hidden states, of the form a —* b c or a —* w. • p : Rx —* R&gt;0 defines the probabilities associated with rules conditioned on their left-hand side. Like Petrov and Klein (2007), we impose that the initial symbol S has only one latent annotation. In other words, among rules with S on the left-hand side, only those of the form S[0] —* ry are in Rx. With such a grammar G we can define probabilities over trees in the following way. We will consider two types of trees, annotated trees and skeletal trees. An annotated tree is a sequence of rules from Rx, while a skeletal tree is a sequence of skeletal rules from R. An annotated tree Tx is obtained by left-most derivation from S[0]. Its probability is: 1For brevity and without loss of generality, we omit unary and n-ary ru</context>
<context position="10240" citStr="Petrov and Klein (2007)" startWordPosition="1702" endWordPosition="1705">n the two – see for instance (Smith, 2011), chapter 5 for an introduction. Matsuzaki et al. (2005) showed that one can easily find such a cruder distribution for PCFG-LAs and demonstrated experimentally that this approximation gives good results. More precisely, they find a PCFG that only recognizes the input sentence where the probabilities q(rs) of the rules are set according to their marginal probabilities in the original PCFG-LA parse forest. The parameters rs are skeletal rules with span information. Distribution q is defined in Figure 2. Other approximations are possible. In particular, Petrov and Klein (2007) found that normalizing by the forest probability (in other words the inside probability of the root node) give better experE 11 p(r) (3) THEp−1(T) rETH 1160 Escore(a → b c, i, j, k) = P i,k (a[x]) · p( a[x] → b[y] c[z] ) · P i,j (b[y]) · P j,k (c[z]) x,y,zEW out in in Enorm(a → b c, i, j, k) = P i,k (a[x]) · P i,k (a[x]) xEW in out Escore(a → w, i) = Pi,i (a[x]) · p(a[x] → w) xEW out Enorm(a → w, i) = P i,i (a[x]) · Pi,i (a[x]) xEW in out q(rs) = [norm(rs) score(rs )Variational Inference)) or [Pscore( 0)) (MaxRule-Product)) in Figure 2: Variational Inference for PCFG-LA. Pin and Pout denote i</context>
<context position="22467" citStr="Petrov and Klein, 2007" startWordPosition="3944" endWordPosition="3947">valb is used for evaluation. We use the LORG parser modified with Algorithm 1. 4 All grammars are trained using 6 split/merge EM cycles. For the handling of unknown words, we removed all words occurring once in the training set and replaced them by their morphological signature (Attia et al., 2010). Grammars for products are obtained by training with 16 random seeds for each setting. We use the approximate al4The LORG parser is available at https://github. com/CNGLdlab/LORG-Release and the modification at https://github.com/jihelhere/LORG-Release/ tree/functional_c11. gorithm MaxRule-Product (Petrov and Klein, 2007). The basic settings are a combination of the two following parameters: left or right binarization: we conjecture that this affects the quality of the parsers by impacting the recognition of left and right constituent frontiers. We set vertical markovization to 1 (no parent annotation) and horizontal markovization to 0 (we drop all left/right annotations). with or without functional annotations: in particular when non-terminals are annotated with multiple functions, all are kept. 5.2 Products of Grammars We first evaluate each setting on its own before combining them. We test the 4 different s</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved inference for unlexicalized parsing. In Proceedings of the conference on Human Language Technologies and the conference of the North American Chapter of the Association for Computational Linguistics (HLTNAACL’07).</rawString>
</citation>
<citation valid="false">
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1552--1560</pages>
<marker></marker>
<rawString>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1552–1560.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
</authors>
<title>Overview of the 2012 shared task on parsing the web.</title>
<date>2012</date>
<booktitle>In Working Notes of the SANCL Workshop (NAACL-HLT).</booktitle>
<contexts>
<context position="29264" citStr="Petrov and McDonald, 2012" startWordPosition="5110" endWordPosition="5113">28 93.75 93.9 No Func Left 91.83 94.29 65.33 92.18 94.1 DD Right Bin 92.56 94.60 89.81 94.17 94.5 DD Left Bin 92.01 94.38 89.62 94.05 94.2 DD Func 92.19 94.36 89.67 94.06 94.2 DD No Func 92.19 94.57 65.44 92.37 94.3 DD3 92.77 94.79 90.04 94.33 94.5 DD4 92.59 94.62 89.95 94.24 94.4 Table 4: Dependency accuracies on the dev set Dependency-based evaluation of phrase structure parser output has been used in recent years to provide a more rounded view on parser performance and to compare with direct dependency parsers (Cer et al., 2010; Petrov et al., 2010; Nivre et al., 2010; Foster et al., 2011; Petrov and McDonald, 2012). We evaluate our various parsing models on their ability to recover three types of dependencies: basic Stanford dependencies (de Marneffe and Manning, 2008)5, LTH dependencies (Johansson and Nugues, 5We used the latest version at the time of writing, i.e. 3.20. 2007)6 and penn2malt dependencies.7 The latter are a simpler version of the LTH dependencies but are still used when reporting unlabeled attachment scores for dependency parsing. The results, shown in Table 4, mirror the constituency evaluation results in that the dual decomposition results tend to outperform the basic product model re</context>
</contexts>
<marker>Petrov, McDonald, 2012</marker>
<rawString>Slav Petrov and Ryan McDonald. 2012. Overview of the 2012 shared task on parsing the web. In Working Notes of the SANCL Workshop (NAACL-HLT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Pi-Chuan Chang</author>
<author>Michael Ringgaard</author>
<author>Hiyan Alshawi</author>
</authors>
<title>Uptraining for accurate deterministic question parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="29195" citStr="Petrov et al., 2010" startWordPosition="5098" endWordPosition="5101">c Right 92.03 94.47 65.31 92.22 94.2 Func Left 91.86 94.06 89.28 93.75 93.9 No Func Left 91.83 94.29 65.33 92.18 94.1 DD Right Bin 92.56 94.60 89.81 94.17 94.5 DD Left Bin 92.01 94.38 89.62 94.05 94.2 DD Func 92.19 94.36 89.67 94.06 94.2 DD No Func 92.19 94.57 65.44 92.37 94.3 DD3 92.77 94.79 90.04 94.33 94.5 DD4 92.59 94.62 89.95 94.24 94.4 Table 4: Dependency accuracies on the dev set Dependency-based evaluation of phrase structure parser output has been used in recent years to provide a more rounded view on parser performance and to compare with direct dependency parsers (Cer et al., 2010; Petrov et al., 2010; Nivre et al., 2010; Foster et al., 2011; Petrov and McDonald, 2012). We evaluate our various parsing models on their ability to recover three types of dependencies: basic Stanford dependencies (de Marneffe and Manning, 2008)5, LTH dependencies (Johansson and Nugues, 5We used the latest version at the time of writing, i.e. 3.20. 2007)6 and penn2malt dependencies.7 The latter are a simpler version of the LTH dependencies but are still used when reporting unlabeled attachment scores for dependency parsing. The results, shown in Table 4, mirror the constituency evaluation results in that the dua</context>
</contexts>
<marker>Petrov, Chang, Ringgaard, Alshawi, 2010</marker>
<rawString>Slav Petrov, Pi-Chuan Chang, Michael Ringgaard, and Hiyan Alshawi. 2010. Uptraining for accurate deterministic question parsing. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
</authors>
<title>Products of random latent variable grammars.</title>
<date>2010</date>
<booktitle>In Proceedings of the conference on Human Language Technologies and the conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL’10),</booktitle>
<pages>pages</pages>
<contexts>
<context position="4786" citStr="Petrov, 2010" startWordPosition="757" endWordPosition="758"> these models. Experimental results are presented and discussed in § 5. 2 Related Work Parser Model Combination It is well known that improved parsing performance can be achieved by leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must use the same binarization scheme. In our study, we employ PCFG-LA product models with dual decomposition, and we relax the constraints on factorization, as </context>
<context position="12253" citStr="Petrov, 2010" startWordPosition="2056" endWordPosition="2057">this can be partly overcome by combining grammars that only differ on the initial parameterization of the EM algorithm. The probability of a skeletal tree is the product of the probabilities assigned by each single grammar Gi. 2. Equivalent to probability, a score u can be de- T* = arg max Yn qGi(T) (4) fined as the logarithm of the probability. The T i=1 parsing problem becomes2: YT* = arg max q(rs) Since grammars only differ by their numerical paT rsET log q(rs) rameters (i.e. skeletal rules are the same), inference X= arg max can be efficiently implemented using dynamic proT rsET gramming (Petrov, 2010). Scoring with n such grammars now becomes: X= arg max wrs · 11rs E T} T* = arg max Xn X log qGi(r) (5) T rsEJ7 T i=1 rET = arg max u(T) X= arg max Xn log qGi(r) (6) T T rET i=1 Thus, from a PCFG-LA we are able to define a linear model whose parameters are the logprobabilities of the rules in distribution q. 2We denote the parse forest of a sentence by F and the characteristic function of a set by 1. The distributions qGi still have to be computed independently – and possibly in parallel – but the final decoding can be performed jointly. This is still a linear model for PCFG-LA parsing, but re</context>
<context position="32417" citStr="Petrov, 2010" startWordPosition="5617" endWordPosition="5618">bsite, are employed. 8We used Dan Bikel’s compare.pl script which uses stratified shuffling to compute significance. We consider a p value &lt; 0.05 to indicate a statistically significant difference. 1166 Setting F UAS Fun Funtag Func Right 91.73 93.9 91.02 91.88 No Func Right 91.76 93.8 – 91.80 Func Left 91.45 93.7 90.41 91.80 No Func Left 91.57 93.7 – 91.74 DD Right Bin 92.16 94.1 90.85 91.86 DD Left Bin 91.89 93.9 90.10 91.85 DD Func 92.23 94.1 91.02 91.91 DD No Func 92.09 94.0 – 91.86 DD3 92.45 94.3 90.86 91.98 DD4 92.44 94.3 90.97 92.04 (Shindo et al., 2012) 92.4 (Zhang et al., 2009) 92.3 (Petrov, 2010) 91.8 (Huang, 2008) 91.7 (Bohnet and Nivre, 2012) 93.7 Table 5: Test Set Results: Parseval F-score, penn2malt UAS, Function Label Accuracy and Funtag Function Label Accuracy are shown in Table 6. Comparison Dev Test Func Right vs. No Func Right X X Func Left vs. No Func Left X X Func Right vs. Func Left ✓ X No Func Right vs. No Func Left X X DD Right Bin vs. Func Right ✓ ✓ DD Right Bin vs. No Func Right ✓ ✓ DD Left Bin vs. Func Left ✓ ✓ DD Left Bin vs. No Func Left ✓ ✓ DD Right Bin vs DD Left Bin ✓ ✓ DD Func vs. Func Right X ✓ DD Func vs. Func Left ✓ ✓ DD No Func vs. No Func Right ✓ ✓ DD No Fu</context>
<context position="33839" citStr="Petrov, 2010" startWordPosition="5914" endWordPosition="5915">able 6: Statistical Significance Testing We measured the performance of DD4 on the test set. It is approximately 3 times slower than the slowest product model (left binarization with function labels) and 7 slower than the fastest one (right binarization without function labels). This system performs on average 85.5 iterations of the DD algorithm. If we exclude the non-converging cases (5.1% of the cases), this drops to 39.4. Finally we compare our results with systems trained and evaluated on the PTB, see the lower half of Table 5. Our product models are not different from those presented in (Petrov, 2010) and it is not surprising to see that the F-scores are similar. More interestingly our DD4 setting improves on these results and compares favorably with systems relying on richer syntactic information, such as the discriminative parser of (Huang, 2008) that makes use of non-local features to score trees and the TSG parser of (Shindo et al., 2012) that can take into account larger tree fragments: this would indicate that by combining our parsers we extend the domain of locality, horizontally with binarization schemes and vertically with function labels. Our system also performs better than the </context>
</contexts>
<marker>Petrov, 2010</marker>
<rawString>Slav Petrov. 2010. Products of random latent variable grammars. In Proceedings of the conference on Human Language Technologies and the conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL’10), pages 19–27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Rush</author>
<author>Michael Collins</author>
</authors>
<title>A tutorial on dual decomposition and lagrangian relaxation for inference in natural language processing.</title>
<date>2012</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>45--305</pages>
<contexts>
<context position="9287" citStr="Rush and Collins, 2012" startWordPosition="1549" endWordPosition="1552">minal and non-terminal symbols labeling nodes, without hidden states. The probability of a skeletal tree T is a sum of the probabilities of all annotated trees that admit T as their projection. p(T) = E 11 p(r) (2) THEp−1(T) rETH PCFG-LA parsing amounts to, given a sequence of words, finding the most probable skeletal tree with this sequence as its yield according to a grammar G: T* = arg max T Because of this alternation of sum and products, the parsing problem is intractable. Moreover, the PCFG-LAs do not belong to the family of linear models that are assumed in the Lagrangian framework of (Rush and Collins, 2012). We now turn to approximations for the parsing problem in order to address both issues. 3.2 Variational Inference and MaxRule Variational inference is a common technique to approximate a probability distribution p with a cruder one q, as close as possible to the original one, by minimizing the Kullback-Liebler divergence between the two – see for instance (Smith, 2011), chapter 5 for an introduction. Matsuzaki et al. (2005) showed that one can easily find such a cruder distribution for PCFG-LAs and demonstrated experimentally that this approximation gives good results. More precisely, they fi</context>
<context position="19434" citStr="Rush and Collins, 2012" startWordPosition="3385" endWordPosition="3388">sely the objective function maximized in (P); • if there is at least one (i, X, s) such that z(Ti)Xs =� uXs, then the value of Ei(z(Ti) − u) - Ai can be made arbitrarily small by an appropriate choice of Ai,Xs; in this case, minA f(u, T1...n, A) = −oo. Thus, (RP) can not reach its maximum at a point where constraints (10) are not satisfied. Step 2 (dualization): the dual problem (LP) is obtained by permuting max and min in (RP): �s.t. Ai = 0 i Minimization in (LP) can be solved iteratively using the projected subgradient method. Finding a subgradient amounts to computing the optimal solution (Rush and Collins, 2012) for each of the n subproblems (the slave problems in the terminology of (Martins et al., 2011) and (Komodakis et al., 2007)) which can be done efficiently, by incorporating the calculation of the penalties in the parsing algorithm, and in parallel. Until the agreement constraints are met (or a maximal number of iterations z), the Lagrangian multipliers are updated according to the deviations from the average solutions (i.e. updates are zeros for a natural span if the parsers agree on it). This leads to Algorithm 1. It should be noted that the DP charts are built and pruned during the first it</context>
</contexts>
<marker>Rush, Collins, 2012</marker>
<rawString>Alexander Rush and Michael Collins. 2012. A tutorial on dual decomposition and lagrangian relaxation for inference in natural language processing. Journal of Artificial Intelligence Research, 45:305–362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander M Rush</author>
<author>David Sontag</author>
<author>Michael Collins</author>
<author>Tommi Jaakkola</author>
</authors>
<title>On dual decomposition and linear programming relaxations for natural language processing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--11</pages>
<contexts>
<context position="1849" citStr="Rush et al. (2010)" startWordPosition="284" endWordPosition="287">s. 1 Introduction Because of the large amount of possibly contradictory information contained in a treebank, learning a phrase-structure-based parser implies making several choices regarding the prevalent annotations which have to be kept – or discarded – in order to guide the learning algorithm. These choices, which include whether to keep function labels and empty nodes, how to binarize the trees and whether to alter the granularity of the tagset, are often motivated empirically by parsing performance rather than by the different aspects of the language they may be able to capture. Recently Rush et al. (2010), Martins et al. (2011) and Koo et al. (2010) have shown that Dual Decomposition or Lagrangian Relaxation is an elegant 1158 c d f e Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1158–1169, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics sis on which CFGs rely and on which most popular parsers are based may be too strong to learn the dependencies between functions across the parse trees. Also, the number of parameters increases with the use of function labels and this can affect the learning process.</context>
<context position="4882" citStr="Rush et al., 2010" startWordPosition="769" endWordPosition="772">er Model Combination It is well known that improved parsing performance can be achieved by leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must use the same binarization scheme. In our study, we employ PCFG-LA product models with dual decomposition, and we relax the constraints on factorization, as we require only a loose coupling of the models. Function Label Parsing Although function labels </context>
<context position="17507" citStr="Rush et al., 2010" startWordPosition="3014" endWordPosition="3017">tical (or equivalent) with the same spans for all parsers. Since the debinarization of markovized rules enables the creation of arbitrarily long n-ary rules, in the worst case the number of natural daughters to check is exponential in the size of the span to infer. Even if n E up(Tp) (7) p=1 1162 we bound the length of debinarized rules, the problem is hardly tractable. As this problem is intractable, even for approximate PCFG-LA parsing, we apply the iterate method presented in (Komodakis et al., 2007) for MRFs, also applied for joint tasks in NLP such as combined parsing and POS tagging in (Rush et al., 2010). First, we introduce a witness vector u in order to simplify constraints in (8). Problem (P) can then be written in an equivalent form : (LP1) : oLP = min A Finally, u can be removed from (LP1) by adding the constraint: Ei Ai = 0. As a matter of fact, one can see that if this constraint is not matched, maxu,T,...n f(u, T1...n, A) = +oo and (LP1) can not reach its minimum on such a point. We can now find the maximum of f by maxing each Ti independently of each other. The dual problem becomes: max f(u, T1...n, A) u, TI...n (P d n o max find (T1...Tn)EC s.t. di E Q1, n�, z(Ti) = u (10) n 0i(Ti) </context>
</contexts>
<marker>Rush, Sontag, Collins, Jaakkola, 2010</marker>
<rawString>Alexander M Rush, David Sontag, Michael Collins, and Tommi Jaakkola. 2010. On dual decomposition and linear programming relaxations for natural language processing. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Dependency parsing and domain adaptation with LR models and parser ensembles.</title>
<date>2007</date>
<booktitle>In Proceedings of the CoNLL</booktitle>
<pages>1044--1050</pages>
<contexts>
<context position="4542" citStr="Sagae and Tsujii, 2007" startWordPosition="721" endWordPosition="724">ifferent function label/binarization decisions. The paper is organized as follows. § 2 reviews related work. § 3 presents approximate PCFG-LA parsers as linear models, while § 4 shows how we can use dual decomposition to derive an algorithm for combining these models. Experimental results are presented and discussed in § 5. 2 Related Work Parser Model Combination It is well known that improved parsing performance can be achieved by leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this </context>
</contexts>
<marker>Sagae, Tsujii, 2007</marker>
<rawString>Kenji Sagae and Jun’ichi Tsujii. 2007. Dependency parsing and domain adaptation with LR models and parser ensembles. In Proceedings of the CoNLL shared task session of EMNLP-CoNLL, pages 1044–1050.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Shindo</author>
<author>Yusuke Miyao</author>
<author>Akinori Fujino</author>
<author>Masaaki Nagata</author>
</authors>
<title>Bayesian symbol-refined tree substitution grammars for syntactic parsing.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume</booktitle>
<volume>1</volume>
<pages>440--448</pages>
<contexts>
<context position="32371" citStr="Shindo et al., 2012" startWordPosition="5607" endWordPosition="5610">es of Yamada and Matsumoto (2003), supplied on the website, are employed. 8We used Dan Bikel’s compare.pl script which uses stratified shuffling to compute significance. We consider a p value &lt; 0.05 to indicate a statistically significant difference. 1166 Setting F UAS Fun Funtag Func Right 91.73 93.9 91.02 91.88 No Func Right 91.76 93.8 – 91.80 Func Left 91.45 93.7 90.41 91.80 No Func Left 91.57 93.7 – 91.74 DD Right Bin 92.16 94.1 90.85 91.86 DD Left Bin 91.89 93.9 90.10 91.85 DD Func 92.23 94.1 91.02 91.91 DD No Func 92.09 94.0 – 91.86 DD3 92.45 94.3 90.86 91.98 DD4 92.44 94.3 90.97 92.04 (Shindo et al., 2012) 92.4 (Zhang et al., 2009) 92.3 (Petrov, 2010) 91.8 (Huang, 2008) 91.7 (Bohnet and Nivre, 2012) 93.7 Table 5: Test Set Results: Parseval F-score, penn2malt UAS, Function Label Accuracy and Funtag Function Label Accuracy are shown in Table 6. Comparison Dev Test Func Right vs. No Func Right X X Func Left vs. No Func Left X X Func Right vs. Func Left ✓ X No Func Right vs. No Func Left X X DD Right Bin vs. Func Right ✓ ✓ DD Right Bin vs. No Func Right ✓ ✓ DD Left Bin vs. Func Left ✓ ✓ DD Left Bin vs. No Func Left ✓ ✓ DD Right Bin vs DD Left Bin ✓ ✓ DD Func vs. Func Right X ✓ DD Func vs. Func Left</context>
<context position="34187" citStr="Shindo et al., 2012" startWordPosition="5971" endWordPosition="5974">orithm. If we exclude the non-converging cases (5.1% of the cases), this drops to 39.4. Finally we compare our results with systems trained and evaluated on the PTB, see the lower half of Table 5. Our product models are not different from those presented in (Petrov, 2010) and it is not surprising to see that the F-scores are similar. More interestingly our DD4 setting improves on these results and compares favorably with systems relying on richer syntactic information, such as the discriminative parser of (Huang, 2008) that makes use of non-local features to score trees and the TSG parser of (Shindo et al., 2012) that can take into account larger tree fragments: this would indicate that by combining our parsers we extend the domain of locality, horizontally with binarization schemes and vertically with function labels. Our system also performs better than the combination system presented in (Zhang et al., 2009) that only relies on material from the PTB9 but a more detailed comparison is difficult: this system does not use products of latent models and more generally their method is orthogonal to ours. We also include for comparison state-of-the-art dependency parsing results (Bohnet and Nivre, 2012). </context>
</contexts>
<marker>Shindo, Miyao, Fujino, Nagata, 2012</marker>
<rawString>Hiroyuki Shindo, Yusuke Miyao, Akinori Fujino, and Masaaki Nagata. 2012. Bayesian symbol-refined tree substitution grammars for syntactic parsing. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 440–448.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
</authors>
<title>Linguistic Structure Prediction. Synthesis Lectures on Human Language Technologies.</title>
<date>2011</date>
<publisher>Morgan</publisher>
<contexts>
<context position="9659" citStr="Smith, 2011" startWordPosition="1612" endWordPosition="1613">T* = arg max T Because of this alternation of sum and products, the parsing problem is intractable. Moreover, the PCFG-LAs do not belong to the family of linear models that are assumed in the Lagrangian framework of (Rush and Collins, 2012). We now turn to approximations for the parsing problem in order to address both issues. 3.2 Variational Inference and MaxRule Variational inference is a common technique to approximate a probability distribution p with a cruder one q, as close as possible to the original one, by minimizing the Kullback-Liebler divergence between the two – see for instance (Smith, 2011), chapter 5 for an introduction. Matsuzaki et al. (2005) showed that one can easily find such a cruder distribution for PCFG-LAs and demonstrated experimentally that this approximation gives good results. More precisely, they find a PCFG that only recognizes the input sentence where the probabilities q(rs) of the rules are set according to their marginal probabilities in the original PCFG-LA parse forest. The parameters rs are skeletal rules with span information. Distribution q is defined in Figure 2. Other approximations are possible. In particular, Petrov and Klein (2007) found that normali</context>
</contexts>
<marker>Smith, 2011</marker>
<rawString>Noah A. Smith. 2011. Linguistic Structure Prediction. Synthesis Lectures on Human Language Technologies. Morgan and Claypool, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
<author>Miles Osbourne</author>
<author>Anoop Sarkar</author>
<author>Stephen Clark</author>
<author>Rebecca Hwa</author>
<author>Julia Hockenmaier</author>
<author>Paul Ruhlen</author>
<author>Steven Baker</author>
<author>Jeremiah Crim</author>
</authors>
<title>Bootstrapping statistical parsers from small datasets.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>759--763</pages>
<contexts>
<context position="4517" citStr="Steedman et al., 2003" startWordPosition="717" endWordPosition="720">grammars which encode different function label/binarization decisions. The paper is organized as follows. § 2 reviews related work. § 3 presents approximate PCFG-LA parsers as linear models, while § 4 shows how we can use dual decomposition to derive an algorithm for combining these models. Experimental results are presented and discussed in § 5. 2 Related Work Parser Model Combination It is well known that improved parsing performance can be achieved by leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall a</context>
</contexts>
<marker>Steedman, Osbourne, Sarkar, Clark, Hwa, Hockenmaier, Ruhlen, Baker, Crim, 2003</marker>
<rawString>Mark Steedman, Miles Osbourne, Anoop Sarkar, Stephen Clark, Rebecca Hwa, Julia Hockenmaier, Paul Ruhlen, Steven Baker, and Jeremiah Crim. 2003. Bootstrapping statistical parsers from small datasets. In Proceedings of EACL, pages 759–763.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Christopher D Manning</author>
</authors>
<title>Ensemble models for dependency parsing: Cheap and good?</title>
<date>2010</date>
<booktitle>In Proceedings of the conference on Human Language Technologies and the conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL’10),</booktitle>
<pages>649--652</pages>
<contexts>
<context position="4684" citStr="Surdeanu and Manning, 2010" startWordPosition="741" endWordPosition="744">-LA parsers as linear models, while § 4 shows how we can use dual decomposition to derive an algorithm for combining these models. Experimental results are presented and discussed in § 5. 2 Related Work Parser Model Combination It is well known that improved parsing performance can be achieved by leveraging the alternative perspectives provided by several parsing models rather than relying on just one. Examples are parser co-training (Steedman et al., 2003; Sagae and Tsujii, 2007), voting over phrase structure constituents or dependency arcs (Henderson and Brill, 1999; Sagae and Tsujii, 2007; Surdeanu and Manning, 2010), dependency parsing stacking (Nivre and McDonald, 2008), product model PCFG-LA parsing (Petrov, 2010), using dual decomposition to combine dependency and phrase structure models (Rush et al., 2010) or several nonprojective dependency parsing models (Koo et al., 2010; Martins et al., 2011), and using expectation propagation, a related approach to dual decomposition, to combine lexicalized, unlexicalized and PCFG-LA models (Hall and Klein, 2012). In this last example, the models must factor in the same way: in other words, the grammars must use the same binarization scheme. In our study, we emp</context>
</contexts>
<marker>Surdeanu, Manning, 2010</marker>
<rawString>Mihai Surdeanu and Christopher D. Manning. 2010. Ensemble models for dependency parsing: Cheap and good? In Proceedings of the conference on Human Language Technologies and the conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL’10), pages 649– 652.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vadas</author>
<author>James R Curran</author>
</authors>
<title>Adding noun phrase structure to the penn treebank.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>240--247</pages>
<contexts>
<context position="31422" citStr="Vadas and Curran (2007)" startWordPosition="5450" endWordPosition="5453"> results with state-of-the-art systems (the second half of Table 5). We present parser accuracy results, measured using Parseval F-score and penn2malt UAS, and, for our systems, function label accuracy for labels produced during parsing and after parsing using Funtag. We also carried out statistical significance testing8 on the F-score differences between our various systems on the development and test sets. The results 6nlp.cs.lth.se/software/treebank_converter. It is recommended that LTH is used with the version of the Penn Treebank which contains the more detailed NP bracketing provided by Vadas and Curran (2007). However, to facilitate comparison with other parsers and dependency schemes, we did not use it in our experiments. We ran the converter with the rightBranching=false option to indicate that we are using the version without extra noun phrase bracketing. 7stp.lingfil.uu.se/˜nivre/research/Penn2Malt. The English head-finding rules of Yamada and Matsumoto (2003), supplied on the website, are employed. 8We used Dan Bikel’s compare.pl script which uses stratified shuffling to compute significance. We consider a p value &lt; 0.05 to indicate a statistically significant difference. 1166 Setting F UAS F</context>
</contexts>
<marker>Vadas, Curran, 2007</marker>
<rawString>David Vadas and James R. Curran. 2007. Adding noun phrase structure to the penn treebank. In Proceedings of ACL, pages 240–247.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyasu Yamada</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Statistical dependency analysis with support vector machines.</title>
<date>2003</date>
<booktitle>In Proceedings of IWPT,</booktitle>
<pages>195--206</pages>
<contexts>
<context position="31784" citStr="Yamada and Matsumoto (2003)" startWordPosition="5501" endWordPosition="5505">our various systems on the development and test sets. The results 6nlp.cs.lth.se/software/treebank_converter. It is recommended that LTH is used with the version of the Penn Treebank which contains the more detailed NP bracketing provided by Vadas and Curran (2007). However, to facilitate comparison with other parsers and dependency schemes, we did not use it in our experiments. We ran the converter with the rightBranching=false option to indicate that we are using the version without extra noun phrase bracketing. 7stp.lingfil.uu.se/˜nivre/research/Penn2Malt. The English head-finding rules of Yamada and Matsumoto (2003), supplied on the website, are employed. 8We used Dan Bikel’s compare.pl script which uses stratified shuffling to compute significance. We consider a p value &lt; 0.05 to indicate a statistically significant difference. 1166 Setting F UAS Fun Funtag Func Right 91.73 93.9 91.02 91.88 No Func Right 91.76 93.8 – 91.80 Func Left 91.45 93.7 90.41 91.80 No Func Left 91.57 93.7 – 91.74 DD Right Bin 92.16 94.1 90.85 91.86 DD Left Bin 91.89 93.9 90.10 91.85 DD Func 92.23 94.1 91.02 91.91 DD No Func 92.09 94.0 – 91.86 DD3 92.45 94.3 90.86 91.98 DD4 92.44 94.3 90.97 92.04 (Shindo et al., 2012) 92.4 (Zhang </context>
</contexts>
<marker>Yamada, Matsumoto, 2003</marker>
<rawString>Hiroyasu Yamada and Yuji Matsumoto. 2003. Statistical dependency analysis with support vector machines. In Proceedings of IWPT, pages 195–206.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hui Zhang</author>
<author>Min Zhang</author>
<author>Chew Lim Tan</author>
<author>Haizhou Li</author>
</authors>
<title>K-best combination of syntactic parsers.</title>
<date>2009</date>
<contexts>
<context position="32397" citStr="Zhang et al., 2009" startWordPosition="5612" endWordPosition="5615">(2003), supplied on the website, are employed. 8We used Dan Bikel’s compare.pl script which uses stratified shuffling to compute significance. We consider a p value &lt; 0.05 to indicate a statistically significant difference. 1166 Setting F UAS Fun Funtag Func Right 91.73 93.9 91.02 91.88 No Func Right 91.76 93.8 – 91.80 Func Left 91.45 93.7 90.41 91.80 No Func Left 91.57 93.7 – 91.74 DD Right Bin 92.16 94.1 90.85 91.86 DD Left Bin 91.89 93.9 90.10 91.85 DD Func 92.23 94.1 91.02 91.91 DD No Func 92.09 94.0 – 91.86 DD3 92.45 94.3 90.86 91.98 DD4 92.44 94.3 90.97 92.04 (Shindo et al., 2012) 92.4 (Zhang et al., 2009) 92.3 (Petrov, 2010) 91.8 (Huang, 2008) 91.7 (Bohnet and Nivre, 2012) 93.7 Table 5: Test Set Results: Parseval F-score, penn2malt UAS, Function Label Accuracy and Funtag Function Label Accuracy are shown in Table 6. Comparison Dev Test Func Right vs. No Func Right X X Func Left vs. No Func Left X X Func Right vs. Func Left ✓ X No Func Right vs. No Func Left X X DD Right Bin vs. Func Right ✓ ✓ DD Right Bin vs. No Func Right ✓ ✓ DD Left Bin vs. Func Left ✓ ✓ DD Left Bin vs. No Func Left ✓ ✓ DD Right Bin vs DD Left Bin ✓ ✓ DD Func vs. Func Right X ✓ DD Func vs. Func Left ✓ ✓ DD No Func vs. No Fun</context>
<context position="34491" citStr="Zhang et al., 2009" startWordPosition="6019" endWordPosition="6022">that the F-scores are similar. More interestingly our DD4 setting improves on these results and compares favorably with systems relying on richer syntactic information, such as the discriminative parser of (Huang, 2008) that makes use of non-local features to score trees and the TSG parser of (Shindo et al., 2012) that can take into account larger tree fragments: this would indicate that by combining our parsers we extend the domain of locality, horizontally with binarization schemes and vertically with function labels. Our system also performs better than the combination system presented in (Zhang et al., 2009) that only relies on material from the PTB9 but a more detailed comparison is difficult: this system does not use products of latent models and more generally their method is orthogonal to ours. We also include for comparison state-of-the-art dependency parsing results (Bohnet and Nivre, 2012). 6 Conclusion We presented an algorithm and a set of experiments showing that grammar extraction strategies can be combined in an elegant way and give state-of-the-art results when applied to high-quality phrase-based parsers. As well as repeating these experiments for languages which rely more on functi</context>
</contexts>
<marker>Zhang, Zhang, Tan, Li, 2009</marker>
<rawString>Hui Zhang, Min Zhang, Chew Lim Tan, and Haizhou Li. 2009. K-best combination of syntactic parsers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>