<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000012">
<title confidence="0.778641">
Regularized Minimum Error Rate Training
</title>
<author confidence="0.97032">
Michel Galley Chris Quirk Colin Cherry Kristina Toutanova
</author>
<affiliation confidence="0.966229">
Microsoft Research Microsoft Research National Research Council Microsoft Research
</affiliation>
<email confidence="0.970249">
mgalley@microsoft.com chrisq@microsoft.com colin.cherry@nrc-cnrc.gc.ca kristout@microsoft.com
</email>
<sectionHeader confidence="0.99386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99710725">
Minimum Error Rate Training (MERT) re-
mains one of the preferred methods for tun-
ing linear parameters in machine translation
systems, yet it faces significant issues. First,
MERT is an unregularized learner and is there-
fore prone to overfitting. Second, it is com-
monly used on a noisy, non-convex loss func-
tion that becomes more difficult to optimize
as the number of parameters increases. To ad-
dress these issues, we study the addition of
a regularization term to the MERT objective
function. Since standard regularizers such as
`2 are inapplicable to MERT due to the scale
invariance of its objective function, we turn to
two regularizers—`0 and a modification of `2—
and present methods for efficiently integrating
them during search. To improve search in large
parameter spaces, we also present a new direc-
tion finding algorithm that uses the gradient of
expected BLEU to orient MERT’s exact line
searches. Experiments with up to 3600 features
show that these extensions of MERT yield re-
sults comparable to PRO, a learner often used
with large feature sets.
</bodyText>
<sectionHeader confidence="0.998858" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999756358490566">
Minimum Error Rate Training emerged a decade
ago (Och, 2003) as a superior training method for
small numbers of linear model parameters of machine
translation systems, improving over prior work using
maximum likelihood criteria (Och and Ney, 2002).
This technique quickly rose to prominence, becom-
ing standard in many research and commercial MT
systems. Variants operating over lattices (Macherey
et al., 2008) or hypergraphs (Kumar et al., 2009) were
subsequently developed, with the benefit of reducing
the approximation error from n-best lists.
The primary advantages of MERT are twofold. It
directly optimizes the evaluation metric under consid-
eration (e.g., BLEU) instead of some surrogate loss.
Secondly, it offers a globally optimal line search. Un-
fortunately, there are several potential difficulties in
scaling MERT to larger numbers of features, due
to its non-convex loss function and its lack of reg-
ularization. These challenges have prompted some
researchers to move away from MERT, in favor of lin-
early decomposable approximations of the evaluation
metric (Chiang et al., 2009; Hopkins and May, 2011;
Cherry and Foster, 2012), which correspond to easier
optimization problems and which naturally incorpo-
rate regularization. In particular, recent work (Chiang
et al., 2009) has shown that adding thousands or tens
of thousands of features can improve MT quality
when weights are optimized using a margin-based
approximation. On simulated datasets, Hopkins and
May (2011) found that conventional MERT strug-
gles to find reasonable parameter vectors, where a
smooth loss function based on Pairwise Ranking Op-
timization (PRO) performs much better; on real data,
this PRO method appears at least as good as MERT
on small feature sets, and also scales better as the
number of features increases.
In this paper, we seek to preserve the advantages
of MERT while addressing its shortcomings in terms
of regularization and search. The idea of adding a
regularization term to the MERT objective function
can be perplexing at first, because the most common
regularizers, such as `1 and `2, are not directly appli-
cable to MERT. Indeed, these regularizers are scale
sensitive, while the MERT objective function is not:
scaling the weight vector neither changes the predic-
tions of the linear model nor affects the error count.
Hence, MERT can hedge any regularization penalty
by maximally scaling down linear model weights.
The first contribution of this paper is to analyze var-
ious forms of regularization that are not susceptible
to this scaling problem. We analyze and experiment
with `0, a form of regularization that is scale insen-
sitive. We also present new parameterizations of `2
</bodyText>
<page confidence="0.943069">
1948
</page>
<note confidence="0.7313825">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1948–1959,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999988833333333">
regularization, where we apply `2 regularization to
scale-senstive linear transforms of the original linear
model. In addition, we introduce efficient methods
of incorporating regularization in Och (2003)’s exact
line searches. For all of these regularizers, our meth-
ods let us find the true optimum of the regularized
objective function along the line.
Finally, we address the issue of searching in a
high-dimensional space by using the gradient of ex-
pected BLEU (Smith and Eisner, 2006) to find better
search directions for our line searches. This direction
finder addresses one of the serious concerns raised
by Hopkins and May (2011): MERT widely failed
to reach the optimum of a synthetic linear objective
function. In replicating Hopkins and May’s experi-
ments, we confirm that existing search algorithms for
MERT—including coordinate ascent, Powell’s algo-
rithm (Powell, 1964), and random direction sets (Cer
et al., 2008)—perform poorly in this experimental
condition. However, when using our gradient-based
direction finder, MERT has no problem finding the
true optimum even in a 1000-dimensional space.
Our results suggest that the combination of a reg-
ularized objective function and a gradient-informed
line search algorithm enables MERT to scale well
with a large number of features. Experiments with
up to 3600 features show that these extensions of
MERT yield results comparable to PRO (Hopkins
and May, 2011), a parameter tuning method known
to be effective with large feature sets.
</bodyText>
<sectionHeader confidence="0.99247" genericHeader="introduction">
2 Unregularized MERT
</sectionHeader>
<bodyText confidence="0.999318111111111">
Prior to introducing regularized MERT, we briefly
review standard unregularized MERT (Och, 2003).
We use fS1 = {f1 ... fS} to denote the S input sen-
tences of a given tuning set. For each sentence fs, let
Cs = {es,1 . . . es,M} denote the list of M-best can-
didate translations. Each input and output sentence
pair (fs, es,m) is weighted using a linear model that
applies model parameters w = (w1 ... wD) E RD
to D feature functions h1(f, e, —) ... hD(f, e, —),
where — is the hidden state associated with the
derivation from f to e, such as phrase segmenta-
tion and alignment. Furthermore, let hs,m E RD
denote the feature vector representing the translation
pair (fs, es,m).
In MERT, the goal is to minimize a loss function
E(r, e) that scores translation hypotheses against a
set of reference translations rS1 = {r1 ... rS}. This
yields the following optimization problem:
</bodyText>
<equation confidence="0.996846888888889">
( S l
w = arg mwin { E(rs, e(fs; w)) } _
l s=1 JJ
( S M
S E X E (rs, es,m)δ(es,m, e(fs; w))
l s=1 m=1
where (1)
e(fs; w) = arg max {wThs,m } (2)
mE{1...M}
</equation>
<bodyText confidence="0.999907">
While the error surface of Equation 1 is only an
approximation of the true error surface of the MT
decoder, the quality of this approximation depends
on the size of the hypothesis space represented by the
M-best list. Therefore, the hypothesis list is grown
iteratively: decoding with an initial parameter vector
seeds the M-best lists; next, parameter estimation
and M-best list gathering alternate until the cumula-
tive M-best list no longer grows, or until changes of
w between two decoding runs are deemed too small.
To increase the size of the hypothesis space, subse-
quent work (Macherey et al., 2008) instead operated
on lattices, but this paper focuses on M-best lists.
A crucial observation is that the unsmoothed error
count represented in Equation 1 is a piecewise con-
stant function. This enabled Och (2003) to devise a
line search algorithm guaranteed to find the optimum
point along the line. To extend the search from one
to multiple dimensions, MERT applies a sequence
of line optimizations along some fixed or variable
set of search directions {dt} until some convergence
criteria are met. Considering a given point wt and
a given direction dt at iteration t, finding the most
probable translation hypothesis in the set of candi-
dates translations Cs = {es,1 ... es,M} corresponds
to solving the following optimization problem:
</bodyText>
<equation confidence="0.9990395">
e(fs;γ) = arg max{ (wt + γ · dt)T hs,m� (3)
mE{1 ... M} l
</equation>
<bodyText confidence="0.999711166666667">
The function in this equation is piecewise linear (Pa-
pineni, 1999), which enables an efficient exhaustive
computation. Specifically, this function is optimized
by enumerating the up to M hypotheses that form
the upper envelope of the model score function. The
error count, then, is a piecewise constant function
</bodyText>
<figure confidence="0.6101765">
arg min
w
</figure>
<page confidence="0.769788">
1949
</page>
<bodyText confidence="0.612463">
defined by the points -y�9
</bodyText>
<equation confidence="0.619722">
1 &lt; · · · &lt; -y�9M at which an in-
</equation>
<bodyText confidence="0.999804041666667">
crease in -y causes a change of optimum in Equation 3.
Error counts for the whole corpus are simply the sums
of sentence-level piecewise constant functions aggre-
gated over all sentences of the corpus.1 The optimal -y
is finally computed by enumerating all piecewise con-
stant intervals of the corpus-level error function, and
by selecting the one that has the lowest error count
(or, correspondingly, highest BLEU score). Assum-
ing the optimum is found in the interval [-yk−1,-yk],
we define -yopt = (-yk−1 + -yk)/2 and change the pa-
rameters using the update wt+1 = wt + -yopt · dt.
Finally, this method is turned into a global D-
dimensional search using algorithms that repeat-
edly use the aforementioned exact line search algo-
rithm. Och (2003) first advocated the use of Powell’s
method (Powell, 1964; Press et al., 2007). Pharaoh
(Koehn, 2004) and subsequently Moses (Koehn et al.,
2007) instead use coordinate ascent, and more recent
work often uses random search directions (Cer et al.,
2008; Macherey et al., 2008). In Section 4, we will
present a novel direction finder for maximum-BLEU
optimization, which uses the gradient of expected
BLEU to find directions where the BLEU score is
most likely to increase.
</bodyText>
<sectionHeader confidence="0.999349" genericHeader="method">
3 Regularization for MERT
</sectionHeader>
<bodyText confidence="0.99994825">
Because MERT is prone to overfitting when a large
number of parameters must be optimized, we study
the addition of a regularization term to the objective
function. One conventional approach is to regularize
the objective function with a penalty based on the
��Euclidean norm ||w||2 = i w2i , also known as t2
regularization. In the case of MERT, this yields the
following objective function:2
</bodyText>
<equation confidence="0.993977666666667">
( S 2
w = arg min { E E(rs, e(fs; w)) + ��� |2 l (4)
l s=1 f
</equation>
<footnote confidence="0.985727555555555">
1This assumes that the sufficient statistics of the metric under
consideration are additively decomposable by sentence, which
is the case with most popular evaluation metrics such as BLEU
(Papineni et al., 2001).
2The 12 regularizer is often used in conjunction with log-
likelihood objectives. The regularization term of Equation 4
could similarly be added to the log of an objective—e.g.,
log(BLEU) instead of BLEU—but we found that the distinc-
tion doesn’t have much of an impact in practice.
</footnote>
<figure confidence="0.8134">
-0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4
-0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4
-0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4
-y, the step size in the current direction
</figure>
<figureCaption confidence="0.993213">
Figure 1: Example MERT values along one coordi-
</figureCaption>
<bodyText confidence="0.92817215">
nate, first unregularized. When regularized with t2, the
piecewise constant function becomes piecewise quadratic.
When using t0, the function remains piecewise constant
with a point discontinuity at 0.
where the regularization term 1/2Q2 is a free param-
eter that controls the strength of the regularization
penalty. Similar regularizers have also been used
in conjunction with other norms, such as t1 and t0
norms. The t1 norm, defined as ||w||1 = Ei |wi|,
applies a constant force toward zero, preferring vec-
tors with fewer non-zero components; t0, defined as
||w||0 = |{i  |wi =�&apos; 01|, simply counts the number of
non-zero components of the weight vector, encoding
a preference for sparse vectors.
Geometrically, t2 is a parabola, t1 is the wedge-
shaped absolute value function, and t0 is an impulse
function with a spike at 0. The original formulation
(Equation 1) of MERT consists of a piecewise con-
stant representation of the loss, as a function of the
step size in a given direction. But with these three reg-
</bodyText>
<figure confidence="0.994586073170732">
-0.2
0.8
0.6
0.4
0.2
1.4
1.2
0
1
MERT
Max at 0.225
X
X
-0.2
0.8
0.6
0.4
0.2
1.4
1.2
0
1
X
MERT − t2
Max at -0.018
−t2
X
-0.2
0.8
0.6
0.4
0.2
1.4
1.2
0
1
X
MERT − t0
Max at 0
t0
X
</figure>
<page confidence="0.908883">
1950
</page>
<bodyText confidence="0.9999715">
ularization terms, the function respectively becomes
piecewise quadratic, piecewise linear, or piecewise
constant with a potential impulse jump for each dis-
tinct choice of regularizer. Figure 1 demonstrates this
effect graphically.
As discussed in (McAllester and Keshet, 2011),
the problem with optimizing Equation 4 directly is
that the output of the underlying linear classifier, and
therefore the error count, are not sensitive to the scale
of w. Moreover, `2 regularization (as well as `1 reg-
ularization) is scale sensitive, which means any op-
timizer of this function can drive the regularization
term down to zero by scaling down w. As special
treatments for `2, we evaluate three linear transforms
of the weight vector, where the vector w of the regu-
larization term ||w||22/2σ2 is replaced with either:
</bodyText>
<listItem confidence="0.99869525">
1. an affine transform: w − w0
2. a vector with only (D − 1) free parameters, e.g.,
(1,w�2,··· ,w�D)
3. an `1 renormalization: w/||w||1
</listItem>
<bodyText confidence="0.999956095238095">
In (1), regularization is biased towards w0, a weight
vector previously optimized using a competitive yet
much smaller feature set, such as core features of
a phrase-based (Koehn et al., 2007) or hierarchical
(Chiang, 2007) system. The requirement that this
feature set be small is to prevent overfitting. Other-
wise, any regularization toward an overfit parameter
vector w0 would defeat the purpose of introducing
a regularization term in the first place.3 In (2), the
transformation is motivated by the observation that
the D-parameter linear model of Equation 2 only
needs (D − 1) degrees of freedom. Fixing one of
the components of w to any non-zero constant and
allowing the others to vary, the new linear model re-
tains the same modeling power, but the (D − 1) free
parameters are no longer scale invariant, i.e., scaling
the (D − 1)-dimensional vector now has an effect on
linear model predictions. In (3), the weight vector
is normalized as to have an `1-norm equal to 1. In
contrast, the `0 norm is scale insensitive, thus not
affected by this problem.
</bodyText>
<subsectionHeader confidence="0.999139">
3.1 Exact line search with regularization
</subsectionHeader>
<bodyText confidence="0.9992258">
Optimizing with a regularized error surface requires
a change in the line search algorithm presented in
3(Gimpel and Smith, 2012, footnote 6) briefly mentions the
use of such a regularizer with its ramp loss objective function.
Section 2, but the other aspects of MERT remain the
same, and we can still use global search algorithms
such as coordinate ascent, Powell, and random di-
rections exactly the same way as with unregularized
MERT. Line search with a regularization term is still
as efficient as in (Och, 2003), and it is still guar-
anteed to find the optimum of the (now regularized)
objective function along the line. Considering again a
given point wt and a given direction dt at line search
iteration t, finding the optimum γopt corresponds to
finding γ that minimizes:
</bodyText>
<equation confidence="0.973674">
E(rs,A(fs;γ)) + ||wt + γ · dt||2 2 (5)
2σ2
</equation>
<bodyText confidence="0.6051575">
Since regularization does not affect the points at
which e(fs; γ) changes its optimum, the points
</bodyText>
<equation confidence="0.985436">
γ��
1 &lt; · · · &lt; γM of intersection in the upper enve-
</equation>
<bodyText confidence="0.9999938">
lope remain the same, so the points of discontinuity
in the error surface remain the same. The difference
now is that the error count on each segment [γi−1, γi]
is no longer constant. This means we need to adjust
the final step of line search, which consists of enu-
merating all [γi−1, γi], and keeping the optimum of
Equation 5 for each segment. e(fs; γ) remains con-
stant within the segment, so we only need to consider
the expression ||wt + γ · dt||2 2 to select a segment
point. The optimum is either at the left edge, the right
edge, or in the middle if the vertex of the parabola
happens to lie within that segment.4 We compute
this optimum by finding the value γ for which the
derivative of the regularization term is zero. There is
an easy closed-form solution:
</bodyText>
<equation confidence="0.99440925">
d ~||wt + γ · dt||2 �
2 = 0
dγ 2σ2
~ X �
d
(w2 t,i + 2 · γ · wt,i · dt,i + γ2 · d2 t,i) = 0
dγ
i
X (2 · wt,i · dt,i + 2 · γ · d2t,i) = 0
i
d2— wtTdt
t,i) = dtTdt
</equation>
<bodyText confidence="0.9965675">
This closed-form solution is computed in time pro-
portional to D, which doesn’t slow down the com-
4When the optimum is either at the left edge γi−1 or right
edge γi of a segment, we select a point at a small relative distance
within the segment (.999γi−1 + .001γi, in the former case) to
avoid ties in objective values.
</bodyText>
<equation confidence="0.9755618">
S
X
s=1
γ = −�X wt,i · dt,i ��� X
i i
</equation>
<page confidence="0.901969">
1951
</page>
<bodyText confidence="0.9999605">
putation of Equation 5 for each segment (the con-
struction of each segment of the upper envelope is
proportional to D anyway).
We also use `0 regularization. While minimiza-
tion of the `0-norm is known to be NP-hard in gen-
eral (Hyder and Mahata, 2009), this optimization is
relatively trivial in the case of a line search. Indeed,
for a given segment, the value in Equation 5 is con-
stant everywhere except where we intersect any of
the coordinate hyperplanes, i.e., where one of the
coordinates is zero. Thus, our method consists of
evaluating Equation 5 at the intersection points be-
tween the line and coordinate hyperplanes, returning
the optimal point within the given segment. For any
segment that doesn’t cross any of these hyperplanes,
we evaluate the objective function at any point of the
segment (since the value is constant across the entire
segment).
</bodyText>
<sectionHeader confidence="0.998213" genericHeader="method">
4 Direction finding
</sectionHeader>
<subsectionHeader confidence="0.999778">
4.1 A Gradient-based direction finder
</subsectionHeader>
<bodyText confidence="0.999947325581395">
Perhaps the greatest obstacle in scaling MERT
to many dimensions is finding good search direc-
tions. In problems of lower dimensions, iterating
through all the coordinates is computationally feasi-
ble, though not guaranteed to find a global maximum
even in the case of a perfect line search. As the
number of dimensions increases by orders of mag-
nitude, this coordinate direction approach becomes
less and less tractable, and the quality of the search
also suffers (Hopkins and May, 2011).
Optimization has traditionally relied on finding the
direction of steepest ascent: the gradient. Unfortu-
nately, the objective function optimized by MERT is
piecewise constant; while it may admit a subgradi-
ent, this direction is generally not very informative.
Instead we may consider a smoothed variation of the
original approximation. While some variants have
been considered (Och, 2003; Flanigan et al., 2013),
we use an expected BLEU approximation, assum-
ing hypotheses are drawn from a log-linear distri-
bution according to their parameter values (Smith
and Eisner, 2006). That is, we assume the proba-
bility of a translation candidate es,m is proportional
to (exp (wThs,m))µ, where w are the parameters be-
ing optimized, hs,m is the vector of the features for
es,m, and µ is a scaling parameter. As µ approaches
where R is the sum of reference lengths across the
corpus, C is the sum of candidate lengths, mn is the
number of matched n-grams (potentially clipped),
and cn is the number of n-grams in all candidates.
Given a distribution over candidates, we can use
the expected value of the log of the BLEU score. This
is a smooth approximation to the BLEU score, which
asymptotically approaches the true BLEU score as
the scaling parameter µ approaches infinity. While
this expectation is difficult to compute exactly, we
can compute approximations thereof using Taylor se-
ries. Although prior work demonstrates that a second-
order Taylor approximation is feasible to compute
(Smith and Eisner, 2006), we find that a first-order
approximation is faster and very close to the second-
order approximation.5 The first order Taylor approxi-
mation is as follows:
</bodyText>
<equation confidence="0.997489285714286">
� � XN
1 − R + 1
min E[C], 0 (log E[mn] − log E[cn])
N
hi − X !h&apos;iP(h&apos;; w, µ)
P(h; w, µ)
h/
</equation>
<bodyText confidence="0.764734">
Using the chain rule, the gradient of the first order
approximation to BLEU is as follows:
</bodyText>
<equation confidence="0.991285888888889">
X �
1 cn(h)∂P (h; w, µ)
− E[cn] ∂wi
h
(
0 if E[C] &gt; R
+ P
R h c1(h)∂P(h;w,µ) otherwise
E[C]2 ∂wi
</equation>
<bodyText confidence="0.999886333333333">
5Experimentally, we compared our analytical gradient of
the first-order Taylor approximation with the finite-difference
gradients of the first- and second-order approximations, and we
found these three gradients to be very close in terms of cosine
similarity (&gt; 0.99). We performed these measurements both at
arbitrary points and at points of convergence of MERT.
</bodyText>
<equation confidence="0.932649526315789">
1 N
X
n=1
� 1 X
mn(h)
E[mn]
h
∂P(h; w, µ)
∂wi
N
infinity, the distribution places all its weight on the
highest scoring candidate.
The log of the BLEU score may be written as:
� � XN
1 − R + 1
min C , 0 (log mn − log cn)
N
n=1
n=1
</equation>
<bodyText confidence="0.958744">
where E is the expectation operator using the proba-
bility distribution P(h; w, µ).
First we note that the gradient ∂
</bodyText>
<equation confidence="0.500021">
∂wi P(h; w, µ) is
</equation>
<page confidence="0.920137">
1952
</page>
<bodyText confidence="0.999939333333333">
In the case of `2-regularized MERT, the final gradi-
ent also includes the partial derivative of the regular-
ization penalty of Equation 4, which is wi/a2 for a
given component i of the gradient. We do not update
the gradient in the case of t0 regularization since the
`0-norm is not differentiable.
</bodyText>
<subsectionHeader confidence="0.987608">
4.2 Search
</subsectionHeader>
<bodyText confidence="0.999949393939394">
Our search strategy consists of looking at the direc-
tions of steepest increase of expected BLEU, which
is similar to that of Smith and Eisner (2006), but with
the difference that we do so in the context of MERT.
We think this difference provides two benefits. First,
while the smooth approximation of BLEU reduces
the likelihood of remaining trapped in a local opti-
mum, we avoid approximation error by retaining the
original objective function. Second, the benefit of
exact line searches in MERT is that there is no need
to be concerned about step size, since step size in
MERT line searches is guaranteed to be optimal with
respect to the direction under consideration.
Finally, our gradient-based search algorithm oper-
ates as follows. Considering the current point wt, we
compute the gradient gt of the first order Taylor ap-
proximation at that point, using the current scaling pa-
rameter µ. (We initialize the search with µ = 0.01.)
We find the optimum along the line wt+-y·gt. When-
ever any given line search yields no improvement
larger than a small tolerance threshold, we multiply
µ by two and perform a new line search. The increase
of this parameter µ corresponds to a cooling schedule
(Smith and Eisner, 2006), which progressively sharp-
ens the objective function to get a better estimate of
BLEU as the search converges to an optimum. We
repeatedly perform new line searches until µ exceeds
1000. The inability to improve the current optimum
with a sharp approximation (µ &gt; 1000) doesn’t mean
line searches would fail with smaller values, so we
find it helpful to repeat the above procedure until a
full pass of updates of µ from 0.01 to 1000 yields no
improvement.
</bodyText>
<subsectionHeader confidence="0.998175">
4.3 Computational complexity
</subsectionHeader>
<bodyText confidence="0.999986">
Computing the gradient increases the computational
cost of MERT, though not its asymptotic complexity.
The cost of a single exhaustive line search is
</bodyText>
<equation confidence="0.803118">
O (SM(D + log M + log S))
</equation>
<bodyText confidence="0.99926281632653">
where S is the number of sentences, each with M
possible translations, and D is the number of features.
For each sentence, we first identify the model score
as a linear function of the step size, requiring two
dot products for an overall cost of O(SMD).6 Next
we construct the upper envelope for each sentence:
first the equations are sorted in increasing order of
slope, and then they are merged in linear time to form
an envelope, with an overall cost of O(SM log M).
A linear pass through the envelope converts these
into piecewise constant (or linear, or quadratic) repre-
sentations of the (regularized) loss function. Finally
the per-sentence envelopes are merged into a global
representation of the loss along that direction. Our
implementation successively merges adjacent pairs
of piecewise smooth loss function representations
until a single list remains. These log S passes lead to
a merging runtime of O(SM log S).
The time required to compute a gradient is pro-
portional to O(SMD). For each sentence, we first
gather the probability and its gradient, then use this to
compute expected n-gram counts and matches as well
as those gradients in time O(MD). A constant num-
ber of arithmetic operations suffice to compute the
final expected loss value and its gradient. Therefore,
computing the gradient does not increase the algo-
rithmic complexity when compared to conventional
approaches using coordinate ascent and random di-
rections. Likewise the runtime of a single iteration
is competitive with PRO, given that gradient finding
is generally the most expensive part of convex opti-
mization. Of course, it is difficult to compare overall
runtime of convex optimization with that of MERT,
as we know of no way to bound the number of gradi-
ent evaluations required for convergence with MERT.
Therefore, we resort to empirical comparison later in
the paper, and find that the two methods appear to
have comparable runtime.
6In the special case where the difference between the prior
direction and the current direction is sparse, we may update the
individual linear functions in time proportional to the number of
changed dimensions. Coordinate ascent in particular can update
the linear functions in time O(SM): to the intercept of the
equation for each translation, we may add the prior step size
multiplied by the feature value in the prior coordinate, and the
slope becomes the feature value in the new coordinate. However,
this optimization does not appear to be widely adopted, likely
because it does not lead to any speedup when random vectors,
conjugate directions, or other non-sparse directions are used.
</bodyText>
<page confidence="0.958962">
1953
</page>
<table confidence="0.985899625">
Language pair Train Tune Dev Test
Chinese-English 0.99M 1,797 1,000 1,082
(mt02+03) (mt05)
Finnish-English 2.20M 11,935 2,001 4,855
Chinese-English 3.51M 1,894 1,664 1,357
(mt05) (mt06) (mt08)
Arabic-English 1.49M 1,663 1,360 1,313
(mt06) (mt08) (mt09)
</table>
<tableCaption confidence="0.993099">
Table 1: Datasets for the two experimental conditions.
</tableCaption>
<sectionHeader confidence="0.994535" genericHeader="method">
5 Experimental Design
</sectionHeader>
<bodyText confidence="0.999903657142857">
Following Hopkins and May (2011), our experimen-
tal setup utilizes both real and synthetic data. The
motivation for using synthetic data is that it is a way
of gauging the quality of optimization methods, since
the data is constructed knowing the global optimum.
Hopkins and May also note that the use of an ob-
jective function that is linear in some gold weight
vector makes the search much simpler than in a real
translation setting, and they suggest that a learner
that performs poorly in such a simple scenario has
little hope of succeeding in a more complex one.
The setup of our synthetic data experiment is al-
most the same as that performed by Hopkins and
May (2011). We generate feature vectors of dimen-
sionality ranging from 10 to 1000. These features are
generated by drawing random numbers uniformly in
the interval [0, 500]. This synthetic dataset consists
of S=1000 source “sentences”, and M=500 “trans-
lation” hypotheses for each sentence. A pseudo
“BLEU” score is then computed for each hypothe-
sis, by computing the dot product between a prede-
fined gold weight vector w* and each feature vector
h,,,,,. By this linear construction, w* is guaranteed
to be a global optimum.7 The pseudo-BLEU score is
normalized for each M-best list, so that the transla-
tion with highest model score according to w* has
a BLEU score of 1, and so that the translation with
lowest model score for the sentence gets a BLEU of
zero. This normalization has no impact on search,
but makes results more interpretable.
For our translation experiments, we use multi-
stack phrase-based decoding (Koehn et al., 2007).
We report results for two feature sets: non-linear
features induced using Gradient Boosting Machines
(Toutanova and Ahn, 2013) and sparse lexicalized
</bodyText>
<footnote confidence="0.545303">
7The objective function remains piecewise constant, and the
plateau containing w* maps to the optimal value of the function.
</footnote>
<bodyText confidence="0.999956520833333">
reordering features (Cherry, 2013). We exploit these
feature sets (GBM and SparseHRM, respectively) in
two distinct experimental conditions, which we de-
tail in the two next paragraphs. Both GBM and
SparseHRM augment baseline features similar to
Moses’: relative frequency and lexicalized phrase
translation scores for both translation directions; one
or two language model features, depending on the
language pair; distortion penalty; word and phrase
count; six lexicalized reordering features. For both
experimental conditions, phrase tables have maxi-
mum phrase length of 7 words on either side. In
reference to Table 1, we used the training set (Train)
for extracting phrase tables and language models; the
Tune set for optimization with MERT or PRO; the
Dev set for selecting hyperparameters of PRO and
regularized MERT; and the Test set for reporting fi-
nal results. In each experimental condition, we first
trained weights for the base feature sets, and then
decoded the Tune, Dev, and Test datasets, generating
500-best lists for each set. All results report rerank-
ing performance on these lists with different feature
sets and optimization methods, based on lower-cased
BLEU (Papineni et al., 2001).
The GBM feature set (Toutanova and Ahn, 2013)
consists of about 230 features automatically induced
using decision tree weak learners, which derive fea-
tures using various word-level, phrase-level, and mor-
phological attributes. For Chinese-English, the train-
ing corpus consists of approximately one million sen-
tence pairs from the FBIS and Hong Kong portions
of the LDC data for the NIST MT evaluation and the
Tune and Test sets are from NIST competitions. A
4-gram language model was trained on the Xinhua
portion of the English Gigaword corpus and on the
target side of the bitext. For Finnish-English we used
a dataset from a technical domain of software man-
uals. For this language pair we used two language
models: one very large model trained on billions of
words, and another language model trained from the
target side of the parallel training set.
The SparseHRM set (Cherry, 2013) contains 3600
sparse reordering features. For each phrase, the fea-
tures take the form of indicators describing its orienta-
tion in the derivation, and its lexical content in terms
of word clusters or frequent words. For both Chinese-
English and Arabic-English, systems are trained on
data from the NIST 2012 MT evaluation. 4-gram
</bodyText>
<figure confidence="0.859768">
GBM
SparseHRM
1954
20 50 100 200 500 1000
number of features
20 50 100 200 500 1000
number of features
</figure>
<figureCaption confidence="0.913445428571429">
Figure 2: Change in BLEU score and cosine similarity
to the gold weight vector w* as the number of features
increases, using the noisy synthetic experiments. The
gradient-based direction finding method is barely affected
by the noise. The increase of the number of dimensions en-
ables our direction finder to find a slightly better optimum,
which moved away from w* due to noise.
</figureCaption>
<bodyText confidence="0.9999635">
language models were trained on the target side of
the parallel training data for both Arabic and Chinese.
The Chinese systems development set is taken from
the NIST mt05 evaluation set, augmented with some
material reserved from our NIST training corpora in
order to better cover newsgroup and weblog domains.
</bodyText>
<sectionHeader confidence="0.999831" genericHeader="method">
6 Results
</sectionHeader>
<bodyText confidence="0.9999315">
We conducted experiments with the synthetic data
scenario described in the previous section, as well
as with noise added to the data (Hopkins and May,
2011). The purpose of adding noise is to make the
optimization task more realistic. Specifically, af-
ter computing all pseudo-BLEU scores, we added
noise to each feature vector h,,,,, by drawing from
a zero-mean Gaussian with standard deviation 200.
Our results with both noiseless and noisy data yield
the same conclusion as Hopkins and May: standard
MERT struggles with many dimensions, and fails
to recover w*. However, our experiments with the
gradient direction finder of Section 4 are much more
positive. This direction finder not only recovers w*
</bodyText>
<figure confidence="0.6616355">
1 10 100 1000
line search iteration
</figure>
<figureCaption confidence="0.95979">
Figure 3: Comparison of rate of convergence between
coordinate ascent and our expected BLEU direction finder
(D = 500). Noisy refers to the noisy experimental setting.
</figureCaption>
<bodyText confidence="0.970291878787879">
(cosine &gt; 0.999) even with 1000 dimensions, but its
effectiveness is also visible with noisy data, as seen
in Figure 2. The decrease of its cosine is relatively
small compared to other search algorithms, and this
decrease is not necessarily a sign of search errors
since the addition of noise causes the true optimum
to be different from w*. Finally, Figure 3 shows our
rate of convergence compared to coordinate ascent.
Our experimental results with the GBM feature
set data are shown in Table 2. Each table is di-
vided into three sections corresponding respectively
to MERT (Och, 2003) with Koehn-style coordinate
ascent (Koehn, 2004), PRO, and our optimizer featur-
ing both regularization and the gradient-based direc-
tion finder. All variants of MERT are initialized with
a single starting point, which is either uniform weight
or w0. Instead of providing MERT with additional
random starting points as in Moses, we use random
walks as in (Moore and Quirk, 2008) to attempt to
move out of local optima.8 Since PRO and our opti-
mizer have hyperparameters, we use a held-out set
(Dev) for adjusting them. For PRO, we adjust three
parameters: a regularization penalty for f2, the pa-
rameter α in the add-α smoothed sentence-level ver-
sion of BLEU (Lin and Och, 2004), and a parameter
for scaling the corpus-level length of the references.
The latter scaling parameter is discussed in (He and
8In the case of the gradient-based direction finder, we also
use the following strategy whenever optimization converges to
a (possibly local) optimum. We run one round of coordinate
ascent, and continue with the gradient direction finder as soon as
the optimum improves. If the none of the coordinate directions
helped, we stop the search.
</bodyText>
<figure confidence="0.979399375">
expected BLEU gradient
random directions
Powell
coordinate ascent
cosine
0.8
0.6
0.4
0.2
0
1
expected BLEU gradient
random directions
Powell
coordinate ascent
expected BLEU gradient
(noisy) expected BLEU gradient
coordinate ascent
(noisy) coordinate ascent
BLEU 1
0.8
0.6
0.4
0.2
0
BLEU 100
90
80
70
60
50
40
</figure>
<page confidence="0.945675">
1955
</page>
<table confidence="0.997211181818182">
Method Starting pt. # feat. Chinese- Test # feat. Finnish- Test
English English
Tune Dev Tune Dev
MERT uniform 14 33.2 19.9 32.9 15 53.0 52.6 54.8
MERT uniform 224 33.0 19.2 32.1 232 53.2 51.7 53.8
MERT w0 224 34.1 20.1 33.0 232 53.9 52.5 54.7
PRO w0 224 33.4 20.1 33.3 232 53.3 52.9 55.3
f2 MERT (v1: ||w − w0||) w0 224 33.2 20.3 33.5 232 53.2 52.7 55.2
f2 MERT (v2: D − 1 dimensions) w0 224 33.0 20.4 33.2 232 52.9 52.6 55.0
f2 MERT (v3: f1-renormalized) w0 224 33.1 20.0 33.3 232 53.1 52.5 55.1
f0 MERT w0 224 33.4 20.3 33.2 232 53.2 52.6 55.1
</table>
<tableCaption confidence="0.994294333333333">
Table 2: BLEU scores for GBM features. Model parameters were optimized on the Tune set. For PRO and regularized
MERT, we optimized with different hyperparameters (regularization weight, etc.), and retained for each experimental
condition the model that worked best on Dev. The table shows the performance of these retained models.
</tableCaption>
<figure confidence="0.712405">
1e-05 0.0001 0.001 0.01 0.1 1 10
regularization weight
</figure>
<figureCaption confidence="0.814749">
Figure 4: BLEU score on the Finnish Dev set (GBM)
with different values for the 1/2u2 regularization weight.
To enable comparable results, the other hyperparameter
(length) is kept fixed.
</figureCaption>
<bodyText confidence="0.99981378">
Deng, 2012; Nakov et al., 2012) and addresses the
problem that systems tuned with PRO tend to pro-
duce sentences that are too short. On the other hand,
regularized MERT only requires one hyperparameter
to tune: a regularization penalty for f2 or f0. How-
ever, since PRO optimizes translation length on the
Dev dataset and MERT does so using the Tune set, a
comparison of the two systems would yield a discrep-
ancy in length that would be undesirable. Therefore,
we add another hyperparameter to regularized MERT
to tune length in the same manner using the Dev set.
Table 2 offers several findings. First, unregular-
ized MERT can achieve competitive results with a
small set of highly engineered features, but adding a
large set of more than 200 features causes MERT to
perform poorly, particularly on the test set. However,
unregularized MERT can recover much of this drop
of performance if it is given a good sparse initializer
w0. Regularized MERT (v1) provides an increase in
the order of 0.5 BLEU on the test set compared to
the best results with unregularized MERT. Regular-
ized MERT is competitive with PRO, even though the
number of features is relatively large. Using the same
GBM experimental setting, Figure 4 compares regu-
larized MERT using the gradient direction finder and
coordinate ascent. At the best regularization setting,
the two algorithms are comparable in terms of BLEU
(though coordinate ascent is slower due to its lack of
a good direction finder), but our method seems more
robust with suboptimal regularization parameters.
Our results with the SparseHRM feature set data
are shown in Table 3. As with the GBM feature set,
we find again that the version of f2 MERT regular-
ized towards ||w − w0 ||is competitive with PRO,
even though we train MERT with a large set of 3601
features.9 One remaining question is whether MERT
remains practical with large feature sets. As noted
in the complexity analysis of Section 4.3, MERT
has a dependence on the number of features that is
comparable to PRO, i.e., it is linear in both cases.
Practically, we find that optimization time is com-
parable between the two systems. In the case of
Chinese-English for the GBM feature set, one run of
the PRO optimizer took 26 minutes on average, while
regularized MERT with the gradient direction finder
took 37 minutes on average, taking into account the
time to compute w0. In the case of Chinese-English
for the SparseHRM feature set, average optimization
times for PRO and our method were 3.10 hours and
3.84 hours on average, respectively.
</bodyText>
<footnote confidence="0.9579716">
9We note that the experimental setup of (Cherry, 2013) inte-
grates the Sparse HRM features into the decoder, while we use
them in an M-best reranking scenario. The reranking setup of
this paper yields smaller improvements for both PRO and MERT
than those of (Cherry, 2013).
</footnote>
<figure confidence="0.991588">
BLEU
52.6
52.4
52.2
51.8
51.6
51.4
51.2
52
expected BLEU gradient
coordinate ascent
</figure>
<page confidence="0.937711">
1956
</page>
<table confidence="0.995372272727273">
Method Starting pt. # feat. Chinese Test # feat. Arabic-English Test
-English Tune Dev
Tune Dev
MERT uniform 14 25.7 34.0 27.8 14 43.2 42.8 45.5
MERT uniform 3601 25.4 33.1 27.3 3601 45.7 42.3 44.9
MERT w0 3601 27.7 33.5 27.5 3601 46.0 42.4 45.2
PRO w0 3601 25.9 34.3 28.1 3601 44.6 43.4 46.1
`2 MERT (v1: ||w − w0||) w0 3601 26.3 34.3 28.3 3601 45.2 43.2 46.0
`2 MERT (v2: D − 1 dimensions) w0 3601 26.4 34.1 28.2 3601 45.0 43.4 45.9
`2 MERT (v3: `1-renormalized) w0 3601 26.1 34.0 27.9 3601 44.9 43.3 45.7
`0 MERT w0 3601 26.5 34.2 28.1 3601 45.4 43.1 46.0
</table>
<tableCaption confidence="0.999781">
Table 3: BLEU scores for SparseHRM features. Notes in Table 2 also apply here.
</tableCaption>
<bodyText confidence="0.999989235294118">
Finally, as shown in Table 2, we see that MERT ex-
periments that rely on a good initial starting point w0
generally perform better than when starting from
a uniform vector. While having to compute w0 in
the first place is a bit of a disadvantage compared
to standard MERT, the need for good initializer is
hardly surprising in the context of non-convex op-
timization. Other non-convex problems in machine
learning, such as deep neural networks (DNN) and
word alignment models, commonly require such ini-
tializers in order to obtain decent performance. In
the case of DNN, extensive research is devoted to the
problem of finding good initializers.10 In the case of
word alignment, it is common practice to initialize
search in non-convex optimization problems—such
as IBM Model 3 and 4 (Brown et al., 1993)—with
solutions of simpler models—such as IBM Model 1.
</bodyText>
<sectionHeader confidence="0.999935" genericHeader="method">
7 Related work
</sectionHeader>
<bodyText confidence="0.993521566666667">
MERT and its extensions have been the target of ex-
tensive research (Och, 2003; Macherey et al., 2008;
Cer et al., 2008; Moore and Quirk, 2008; Kumar et
al., 2009; Galley and Quirk, 2011). More recent work
has focused on replacing MERT with a linearly de-
composable approximations of the evaluation metric
(Smith and Eisner, 2006; Liang et al., 2006; Watan-
abe et al., 2007; Chiang et al., 2008; Hopkins and
May, 2011; Rosti et al., 2011; Gimpel and Smith,
2012; Cherry and Foster, 2012), which generally
involve a surrogate loss function incorporating a reg-
ularization term such as the `2-norm. While we are
not aware of any previous work adding a penalty on
10For example, (Larochelle et al., 2009) presents a pre-trained
DNN that outperforms a shallow network, but the performance
of the DNN becomes much worse relative to the shallow network
once pre-training is turned off.
the weights in the context of MERT, (Cer et al., 2008)
achieves a related effect. Cer et al.’s goal is to achieve
a more regular or smooth objective function, while
ours is to obtain a more regular set of parameters.
The two approaches may be complementary.
More recently, new research has explored direction
finding using a smooth surrogate loss function (Flani-
gan et al., 2013). Although this method is successful
in helping MERT find better directions, it also exac-
erbates the tendency of MERT to overfit.11 As an
indirect way of controlling overfitting on the tuning
set, their line searches are performed over directions
estimated over a separate dataset.
</bodyText>
<sectionHeader confidence="0.997388" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.999954692307692">
In this paper, we have shown that MERT can scale to
a much larger number of features than previously
thought, thanks to regularization and a direction
finder that directs the search towards the greatest
increase of expected BLEU score. While our best
results are comparable to PRO and not significantly
better, we think that this paper provides a deeper un-
derstanding of why standard MERT can fail when
handling an increasingly larger number of features.
Furthermore, this paper complements the analysis
by Hopkins and May (2011) of the differences be-
tween MERT and optimization with a surrogate loss
function.
</bodyText>
<sectionHeader confidence="0.998026" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.8156656">
We thank the anonymous reviewers for their helpful
comments and suggestions.
11Indeed, in their Table 3, a comparison between HILS and
HOLS suggests tuning set performance improves substantially,
while held out performance degrades.
</bodyText>
<page confidence="0.994894">
1957
</page>
<sectionHeader confidence="0.983183" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999833807692307">
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathematics
of statistical machine translation: parameter estimation.
Comput. Linguist., 19(2):263–311.
Daniel Cer, Dan Jurafsky, and Christopher D. Manning.
2008. Regularization and search for minimum error
rate training. In Proceedings of the Third Workshop on
Statistical Machine Translation, pages 26–34.
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of the 2012 Conference of the North American
Chapter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 427–436.
Colin Cherry. 2013. Improved reordering for phrase-
based translation using sparse features. In Proceedings
of the 2013 Conference of the North American Chap-
ter of the Association for Computational Linguistics:
Human Language Technologies, pages 22–31.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and structural
translation features. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Language
Processing, pages 224–233.
David Chiang, Kevin Knight, and Wei Wang. 2009.
11,001 new features for statistical machine translation.
In Proceedings of Human Language Technologies: The
2009 Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics,
pages 218–226.
David Chiang. 2007. Hierarchical phrase-based transla-
tion. Computational Linguistics, 33(2):201–228.
Jeffrey Flanigan, Chris Dyer, and Jaime Carbonell. 2013.
Large-scale discriminative training for statistical ma-
chine translation using held-out line search. In Pro-
ceedings of the 2013 Conference of the North American
Chapter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 248–258.
Michel Galley and Chris Quirk. 2011. Optimal search
for minimum error rate training. In Proceedings of
the 2011 Conference on Empirical Methods in Natural
Language Processing, pages 38–49.
Kevin Gimpel and Noah A. Smith. 2012. Structured ramp
loss minimization for machine translation. In Proceed-
ings of the 2012 Conference of the North American
Chapter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 221–231.
Xiaodong He and Li Deng. 2012. Maximum expected
BLEU training of phrase and lexicon translation mod-
els. In Proceedings of the 50th Annual Meeting of
the Association for Computational Linguistics: Long
Papers - Volume 1, pages 292–301.
Mark Hopkins and Jonathan May. 2011. Tuning as rank-
ing. In Proceedings of the 2011 Conference on Empir-
ical Methods in Natural Language Processing, pages
1352–1362.
M. Hyder and K. Mahata. 2009. An approximate L0
norm minimization algorithm for compressed sens-
ing. In Acoustics, Speech and Signal Processing,
2009. ICASSP 2009. IEEE International Conference
on, pages 3365–3368.
Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne,
Christopher Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine Moran,
Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra
Constantin, and Evan Herbst. 2007. Moses: Open
source toolkit for statistical machine translation. In
Proc. ofACL, Demonstration Session.
Philipp Koehn. 2004. Pharaoh: a beam search decoder
for phrase-based statistical machine translation models.
In Proc. ofAMTA, pages 115–124.
Shankar Kumar, Wolfgang Macherey, Chris Dyer, and
Franz Och. 2009. Efficient minimum error rate train-
ing and minimum bayes-risk decoding for translation
hypergraphs and lattices. In Proceedings of the Joint
Conference of the 47th Annual Meeting of the ACL
and the 4th International Joint Conference on Natural
Language Processing of the AFNLP, pages 163–171.
Hugo Larochelle, Yoshua Bengio, J´erˆome Louradour, and
Pascal Lamblin. 2009. Exploring strategies for training
deep neural networks. J. Mach. Learn. Res., 10:1–40.
P. Liang, A. Bouchard-Cˆot´e, D. Klein, and B. Taskar.
2006. An end-to-end discriminative approach to ma-
chine translation. In International Conference on Com-
putational Linguistics and Association for Computa-
tional Linguistics (COLING/ACL).
Chin-Yew Lin and Franz Josef Och. 2004. ORANGE:
a method for evaluating automatic evaluation metrics
for machine translation. In Proceedings of the 20th
international conference on Computational Linguistics,
Stroudsburg, PA, USA.
Wolfgang Macherey, Franz Och, Ignacio Thayer, and
Jakob Uszkoreit. 2008. Lattice-based minimum error
rate training for statistical machine translation. In Pro-
ceedings of the 2008 Conference on Empirical Methods
in Natural Language Processing, pages 725–734.
David McAllester and Joseph Keshet. 2011. Generaliza-
tion bounds and consistency for latent structural probit
and ramp loss. In Advances in Neural Information
Processing Systems 24, pages 2205–2212.
Robert C. Moore and Chris Quirk. 2008. Random restarts
in minimum error rate training for statistical machine
translation. In Proceedings of the 22nd International
Conference on Computational Linguistics - Volume 1,
pages 585–592.
</reference>
<page confidence="0.87644">
1958
</page>
<reference confidence="0.999439208333333">
Preslav Nakov, Francisco Guzman, and Stephan Vogel.
2012. Optimizing for sentence-level BLEU+1 yields
short translations. In Proceedings of COLING 2012,
pages 1979–1994.
Franz Josef Och and Hermann Ney. 2002. Discriminative
training and maximum entropy models for statistical
machine translation. In Proceedings of 40th Annual
Meeting of the Association for Computational Linguis-
tics, pages 295–302.
Franz Josef Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting of the Association for Computa-
tional Linguistics, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2001. BLEU: a method for automatic evalu-
ation of machine translation. In Proc. ofACL.
Kishore Papineni. 1999. Discriminative training via linear
programming. In Proceedings IEEE International Con-
ference on Acoustics, Speech, and Signal Processing
(ICASSP), volume 2, pages 561–564, Vol. 2.
M.J.D. Powell. 1964. An efficient method for finding
the minimum of a function of several variables without
calculating derivatives. Comput. J., 7(2):155–162.
William H. Press, Saul A. Teukolsky, William T. Vetter-
ling, and Brian P. Flannery. 2007. Numerical Recipes:
The Art of Scientific Computing. Cambridge University
Press, 3rd edition.
Antti-Veikko Rosti, Bing Zhang, Spyros Matsoukas, and
Richard Schwartz. 2011. Expected BLEU training
for graphs: BBN system description for WMT11 sys-
tem combination task. In Proceedings of the Sixth
Workshop on Statistical Machine Translation, pages
159–165.
David A. Smith and Jason Eisner. 2006. Minimum risk
annealing for training log-linear models. In Proceed-
ings of the COLING/ACL 2006 Main Conference Poster
Sessions, pages 787–794.
Kristina Toutanova and Byung-Gyu Ahn. 2013. Learn-
ing non-linear features for machine translation using
gradient boosting machines. In Proceedings of the 51st
Annual Meeting of the Association for Computational
Linguistics (Volume 2: Short Papers), pages 406–411.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki
Isozaki. 2007. Online large-margin training for sta-
tistical machine translation. In Proceedings of the
2007 Joint Conference on Empirical Methods in Natu-
ral Language Processing and Computational Natural
Language Learning (EMNLP-CoNLL), pages 764–773.
</reference>
<page confidence="0.996859">
1959
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.974474">
<title confidence="0.999339">Regularized Minimum Error Rate Training</title>
<author confidence="0.999941">Michel Galley Chris Quirk Colin Cherry Kristina Toutanova</author>
<affiliation confidence="0.997937">Microsoft Research Microsoft Research National Research Council Microsoft Research</affiliation>
<email confidence="0.986651">mgalley@microsoft.comchrisq@microsoft.comcolin.cherry@nrc-cnrc.gc.cakristout@microsoft.com</email>
<abstract confidence="0.99961352">Minimum Error Rate Training (MERT) remains one of the preferred methods for tuning linear parameters in machine translation systems, yet it faces significant issues. First, MERT is an unregularized learner and is therefore prone to overfitting. Second, it is commonly used on a noisy, non-convex loss function that becomes more difficult to optimize as the number of parameters increases. To address these issues, we study the addition of a regularization term to the MERT objective function. Since standard regularizers such as inapplicable to MERT due to the scale invariance of its objective function, we turn to a modification of and present methods for efficiently integrating them during search. To improve search in large parameter spaces, we also present a new direction finding algorithm that uses the gradient of expected BLEU to orient MERT’s exact line searches. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Comput. Linguist.,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="39201" citStr="Brown et al., 1993" startWordPosition="6607" endWordPosition="6610">g to compute w0 in the first place is a bit of a disadvantage compared to standard MERT, the need for good initializer is hardly surprising in the context of non-convex optimization. Other non-convex problems in machine learning, such as deep neural networks (DNN) and word alignment models, commonly require such initializers in order to obtain decent performance. In the case of DNN, extensive research is devoted to the problem of finding good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss fun</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Comput. Linguist., 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Cer</author>
<author>Dan Jurafsky</author>
<author>Christopher D Manning</author>
</authors>
<title>Regularization and search for minimum error rate training.</title>
<date>2008</date>
<booktitle>In Proceedings of the Third Workshop on Statistical Machine Translation,</booktitle>
<pages>26--34</pages>
<contexts>
<context position="5178" citStr="Cer et al., 2008" startWordPosition="789" endWordPosition="792">ularized objective function along the line. Finally, we address the issue of searching in a high-dimensional space by using the gradient of expected BLEU (Smith and Eisner, 2006) to find better search directions for our line searches. This direction finder addresses one of the serious concerns raised by Hopkins and May (2011): MERT widely failed to reach the optimum of a synthetic linear objective function. In replicating Hopkins and May’s experiments, we confirm that existing search algorithms for MERT—including coordinate ascent, Powell’s algorithm (Powell, 1964), and random direction sets (Cer et al., 2008)—perform poorly in this experimental condition. However, when using our gradient-based direction finder, MERT has no problem finding the true optimum even in a 1000-dimensional space. Our results suggest that the combination of a regularized objective function and a gradient-informed line search algorithm enables MERT to scale well with a large number of features. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO (Hopkins and May, 2011), a parameter tuning method known to be effective with large feature sets. 2 Unregularized MERT Prior to i</context>
<context position="9573" citStr="Cer et al., 2008" startWordPosition="1545" endWordPosition="1548">t (or, correspondingly, highest BLEU score). Assuming the optimum is found in the interval [-yk−1,-yk], we define -yopt = (-yk−1 + -yk)/2 and change the parameters using the update wt+1 = wt + -yopt · dt. Finally, this method is turned into a global Ddimensional search using algorithms that repeatedly use the aforementioned exact line search algorithm. Och (2003) first advocated the use of Powell’s method (Powell, 1964; Press et al., 2007). Pharaoh (Koehn, 2004) and subsequently Moses (Koehn et al., 2007) instead use coordinate ascent, and more recent work often uses random search directions (Cer et al., 2008; Macherey et al., 2008). In Section 4, we will present a novel direction finder for maximum-BLEU optimization, which uses the gradient of expected BLEU to find directions where the BLEU score is most likely to increase. 3 Regularization for MERT Because MERT is prone to overfitting when a large number of parameters must be optimized, we study the addition of a regularization term to the objective function. One conventional approach is to regularize the objective function with a penalty based on the ��Euclidean norm ||w||2 = i w2i , also known as t2 regularization. In the case of MERT, this yi</context>
<context position="39389" citStr="Cer et al., 2008" startWordPosition="6640" endWordPosition="6643">n-convex problems in machine learning, such as deep neural networks (DNN) and word alignment models, commonly require such initializers in order to obtain decent performance. In the case of DNN, extensive research is devoted to the problem of finding good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-train</context>
</contexts>
<marker>Cer, Jurafsky, Manning, 2008</marker>
<rawString>Daniel Cer, Dan Jurafsky, and Christopher D. Manning. 2008. Regularization and search for minimum error rate training. In Proceedings of the Third Workshop on Statistical Machine Translation, pages 26–34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>George Foster</author>
</authors>
<title>Batch tuning strategies for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>427--436</pages>
<contexts>
<context position="2499" citStr="Cherry and Foster, 2012" startWordPosition="374" endWordPosition="377">imation error from n-best lists. The primary advantages of MERT are twofold. It directly optimizes the evaluation metric under consideration (e.g., BLEU) instead of some surrogate loss. Secondly, it offers a globally optimal line search. Unfortunately, there are several potential difficulties in scaling MERT to larger numbers of features, due to its non-convex loss function and its lack of regularization. These challenges have prompted some researchers to move away from MERT, in favor of linearly decomposable approximations of the evaluation metric (Chiang et al., 2009; Hopkins and May, 2011; Cherry and Foster, 2012), which correspond to easier optimization problems and which naturally incorporate regularization. In particular, recent work (Chiang et al., 2009) has shown that adding thousands or tens of thousands of features can improve MT quality when weights are optimized using a margin-based approximation. On simulated datasets, Hopkins and May (2011) found that conventional MERT struggles to find reasonable parameter vectors, where a smooth loss function based on Pairwise Ranking Optimization (PRO) performs much better; on real data, this PRO method appears at least as good as MERT on small feature se</context>
<context position="39755" citStr="Cherry and Foster, 2012" startWordPosition="6703" endWordPosition="6706">x optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 2008) achieves a related effect. Cer et al.’s goal is to achieve a more regular or smooth objective function, while ours is to obtain a more regular set of par</context>
</contexts>
<marker>Cherry, Foster, 2012</marker>
<rawString>Colin Cherry and George Foster. 2012. Batch tuning strategies for statistical machine translation. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 427–436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
</authors>
<title>Improved reordering for phrasebased translation using sparse features.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>22--31</pages>
<contexts>
<context position="27598" citStr="Cherry, 2013" startWordPosition="4658" endWordPosition="4659">cording to w* has a BLEU score of 1, and so that the translation with lowest model score for the sentence gets a BLEU of zero. This normalization has no impact on search, but makes results more interpretable. For our translation experiments, we use multistack phrase-based decoding (Koehn et al., 2007). We report results for two feature sets: non-linear features induced using Gradient Boosting Machines (Toutanova and Ahn, 2013) and sparse lexicalized 7The objective function remains piecewise constant, and the plateau containing w* maps to the optimal value of the function. reordering features (Cherry, 2013). We exploit these feature sets (GBM and SparseHRM, respectively) in two distinct experimental conditions, which we detail in the two next paragraphs. Both GBM and SparseHRM augment baseline features similar to Moses’: relative frequency and lexicalized phrase translation scores for both translation directions; one or two language model features, depending on the language pair; distortion penalty; word and phrase count; six lexicalized reordering features. For both experimental conditions, phrase tables have maximum phrase length of 7 words on either side. In reference to Table 1, we used the </context>
<context position="29656" citStr="Cherry, 2013" startWordPosition="4985" endWordPosition="4986">ts of approximately one million sentence pairs from the FBIS and Hong Kong portions of the LDC data for the NIST MT evaluation and the Tune and Test sets are from NIST competitions. A 4-gram language model was trained on the Xinhua portion of the English Gigaword corpus and on the target side of the bitext. For Finnish-English we used a dataset from a technical domain of software manuals. For this language pair we used two language models: one very large model trained on billions of words, and another language model trained from the target side of the parallel training set. The SparseHRM set (Cherry, 2013) contains 3600 sparse reordering features. For each phrase, the features take the form of indicators describing its orientation in the derivation, and its lexical content in terms of word clusters or frequent words. For both ChineseEnglish and Arabic-English, systems are trained on data from the NIST 2012 MT evaluation. 4-gram GBM SparseHRM 1954 20 50 100 200 500 1000 number of features 20 50 100 200 500 1000 number of features Figure 2: Change in BLEU score and cosine similarity to the gold weight vector w* as the number of features increases, using the noisy synthetic experiments. The gradie</context>
<context position="37453" citStr="Cherry, 2013" startWordPosition="6297" endWordPosition="6298">es that is comparable to PRO, i.e., it is linear in both cases. Practically, we find that optimization time is comparable between the two systems. In the case of Chinese-English for the GBM feature set, one run of the PRO optimizer took 26 minutes on average, while regularized MERT with the gradient direction finder took 37 minutes on average, taking into account the time to compute w0. In the case of Chinese-English for the SparseHRM feature set, average optimization times for PRO and our method were 3.10 hours and 3.84 hours on average, respectively. 9We note that the experimental setup of (Cherry, 2013) integrates the Sparse HRM features into the decoder, while we use them in an M-best reranking scenario. The reranking setup of this paper yields smaller improvements for both PRO and MERT than those of (Cherry, 2013). BLEU 52.6 52.4 52.2 51.8 51.6 51.4 51.2 52 expected BLEU gradient coordinate ascent 1956 Method Starting pt. # feat. Chinese Test # feat. Arabic-English Test -English Tune Dev Tune Dev MERT uniform 14 25.7 34.0 27.8 14 43.2 42.8 45.5 MERT uniform 3601 25.4 33.1 27.3 3601 45.7 42.3 44.9 MERT w0 3601 27.7 33.5 27.5 3601 46.0 42.4 45.2 PRO w0 3601 25.9 34.3 28.1 3601 44.6 43.4 46.1</context>
</contexts>
<marker>Cherry, 2013</marker>
<rawString>Colin Cherry. 2013. Improved reordering for phrasebased translation using sparse features. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 22–31.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>224--233</pages>
<contexts>
<context position="39662" citStr="Chiang et al., 2008" startWordPosition="6687" endWordPosition="6690">0 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 2008) achieves a related effect. Cer et al.’s goal is to achieve a</context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 224–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Kevin Knight</author>
<author>Wei Wang</author>
</authors>
<title>11,001 new features for statistical machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>218--226</pages>
<contexts>
<context position="2450" citStr="Chiang et al., 2009" startWordPosition="366" endWordPosition="369">ped, with the benefit of reducing the approximation error from n-best lists. The primary advantages of MERT are twofold. It directly optimizes the evaluation metric under consideration (e.g., BLEU) instead of some surrogate loss. Secondly, it offers a globally optimal line search. Unfortunately, there are several potential difficulties in scaling MERT to larger numbers of features, due to its non-convex loss function and its lack of regularization. These challenges have prompted some researchers to move away from MERT, in favor of linearly decomposable approximations of the evaluation metric (Chiang et al., 2009; Hopkins and May, 2011; Cherry and Foster, 2012), which correspond to easier optimization problems and which naturally incorporate regularization. In particular, recent work (Chiang et al., 2009) has shown that adding thousands or tens of thousands of features can improve MT quality when weights are optimized using a margin-based approximation. On simulated datasets, Hopkins and May (2011) found that conventional MERT struggles to find reasonable parameter vectors, where a smooth loss function based on Pairwise Ranking Optimization (PRO) performs much better; on real data, this PRO method app</context>
</contexts>
<marker>Chiang, Knight, Wang, 2009</marker>
<rawString>David Chiang, Kevin Knight, and Wei Wang. 2009. 11,001 new features for statistical machine translation. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 218–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>2</issue>
<contexts>
<context position="13335" citStr="Chiang, 2007" startWordPosition="2200" endWordPosition="2201">of this function can drive the regularization term down to zero by scaling down w. As special treatments for `2, we evaluate three linear transforms of the weight vector, where the vector w of the regularization term ||w||22/2σ2 is replaced with either: 1. an affine transform: w − w0 2. a vector with only (D − 1) free parameters, e.g., (1,w�2,··· ,w�D) 3. an `1 renormalization: w/||w||1 In (1), regularization is biased towards w0, a weight vector previously optimized using a competitive yet much smaller feature set, such as core features of a phrase-based (Koehn et al., 2007) or hierarchical (Chiang, 2007) system. The requirement that this feature set be small is to prevent overfitting. Otherwise, any regularization toward an overfit parameter vector w0 would defeat the purpose of introducing a regularization term in the first place.3 In (2), the transformation is motivated by the observation that the D-parameter linear model of Equation 2 only needs (D − 1) degrees of freedom. Fixing one of the components of w to any non-zero constant and allowing the others to vary, the new linear model retains the same modeling power, but the (D − 1) free parameters are no longer scale invariant, i.e., scali</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Flanigan</author>
<author>Chris Dyer</author>
<author>Jaime Carbonell</author>
</authors>
<title>Large-scale discriminative training for statistical machine translation using held-out line search.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>248--258</pages>
<contexts>
<context position="18294" citStr="Flanigan et al., 2013" startWordPosition="3082" endWordPosition="3085">line search. As the number of dimensions increases by orders of magnitude, this coordinate direction approach becomes less and less tractable, and the quality of the search also suffers (Hopkins and May, 2011). Optimization has traditionally relied on finding the direction of steepest ascent: the gradient. Unfortunately, the objective function optimized by MERT is piecewise constant; while it may admit a subgradient, this direction is generally not very informative. Instead we may consider a smoothed variation of the original approximation. While some variants have been considered (Och, 2003; Flanigan et al., 2013), we use an expected BLEU approximation, assuming hypotheses are drawn from a log-linear distribution according to their parameter values (Smith and Eisner, 2006). That is, we assume the probability of a translation candidate es,m is proportional to (exp (wThs,m))µ, where w are the parameters being optimized, hs,m is the vector of the features for es,m, and µ is a scaling parameter. As µ approaches where R is the sum of reference lengths across the corpus, C is the sum of candidate lengths, mn is the number of matched n-grams (potentially clipped), and cn is the number of n-grams in all candid</context>
<context position="40526" citStr="Flanigan et al., 2013" startWordPosition="6830" endWordPosition="6834">ork adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 2008) achieves a related effect. Cer et al.’s goal is to achieve a more regular or smooth objective function, while ours is to obtain a more regular set of parameters. The two approaches may be complementary. More recently, new research has explored direction finding using a smooth surrogate loss function (Flanigan et al., 2013). Although this method is successful in helping MERT find better directions, it also exacerbates the tendency of MERT to overfit.11 As an indirect way of controlling overfitting on the tuning set, their line searches are performed over directions estimated over a separate dataset. 8 Conclusion In this paper, we have shown that MERT can scale to a much larger number of features than previously thought, thanks to regularization and a direction finder that directs the search towards the greatest increase of expected BLEU score. While our best results are comparable to PRO and not significantly be</context>
</contexts>
<marker>Flanigan, Dyer, Carbonell, 2013</marker>
<rawString>Jeffrey Flanigan, Chris Dyer, and Jaime Carbonell. 2013. Large-scale discriminative training for statistical machine translation using held-out line search. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 248–258.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Chris Quirk</author>
</authors>
<title>Optimal search for minimum error rate training.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>38--49</pages>
<contexts>
<context position="39457" citStr="Galley and Quirk, 2011" startWordPosition="6652" endWordPosition="6655">tworks (DNN) and word alignment models, commonly require such initializers in order to obtain decent performance. In the case of DNN, extensive research is devoted to the problem of finding good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of th</context>
</contexts>
<marker>Galley, Quirk, 2011</marker>
<rawString>Michel Galley and Chris Quirk. 2011. Optimal search for minimum error rate training. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 38–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Noah A Smith</author>
</authors>
<title>Structured ramp loss minimization for machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>221--231</pages>
<contexts>
<context position="14342" citStr="Gimpel and Smith, 2012" startWordPosition="2368" endWordPosition="2371">g one of the components of w to any non-zero constant and allowing the others to vary, the new linear model retains the same modeling power, but the (D − 1) free parameters are no longer scale invariant, i.e., scaling the (D − 1)-dimensional vector now has an effect on linear model predictions. In (3), the weight vector is normalized as to have an `1-norm equal to 1. In contrast, the `0 norm is scale insensitive, thus not affected by this problem. 3.1 Exact line search with regularization Optimizing with a regularized error surface requires a change in the line search algorithm presented in 3(Gimpel and Smith, 2012, footnote 6) briefly mentions the use of such a regularizer with its ramp loss objective function. Section 2, but the other aspects of MERT remain the same, and we can still use global search algorithms such as coordinate ascent, Powell, and random directions exactly the same way as with unregularized MERT. Line search with a regularization term is still as efficient as in (Och, 2003), and it is still guaranteed to find the optimum of the (now regularized) objective function along the line. Considering again a given point wt and a given direction dt at line search iteration t, finding the opt</context>
<context position="39729" citStr="Gimpel and Smith, 2012" startWordPosition="6699" endWordPosition="6702">lize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 2008) achieves a related effect. Cer et al.’s goal is to achieve a more regular or smooth objective function, while ours is to obtain</context>
</contexts>
<marker>Gimpel, Smith, 2012</marker>
<rawString>Kevin Gimpel and Noah A. Smith. 2012. Structured ramp loss minimization for machine translation. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 221–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodong He</author>
<author>Li Deng</author>
</authors>
<title>Maximum expected BLEU training of phrase and lexicon translation models.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers -</booktitle>
<volume>1</volume>
<pages>292--301</pages>
<marker>He, Deng, 2012</marker>
<rawString>Xiaodong He and Li Deng. 2012. Maximum expected BLEU training of phrase and lexicon translation models. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, pages 292–301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hopkins</author>
<author>Jonathan May</author>
</authors>
<title>Tuning as ranking.</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1352--1362</pages>
<contexts>
<context position="2473" citStr="Hopkins and May, 2011" startWordPosition="370" endWordPosition="373"> of reducing the approximation error from n-best lists. The primary advantages of MERT are twofold. It directly optimizes the evaluation metric under consideration (e.g., BLEU) instead of some surrogate loss. Secondly, it offers a globally optimal line search. Unfortunately, there are several potential difficulties in scaling MERT to larger numbers of features, due to its non-convex loss function and its lack of regularization. These challenges have prompted some researchers to move away from MERT, in favor of linearly decomposable approximations of the evaluation metric (Chiang et al., 2009; Hopkins and May, 2011; Cherry and Foster, 2012), which correspond to easier optimization problems and which naturally incorporate regularization. In particular, recent work (Chiang et al., 2009) has shown that adding thousands or tens of thousands of features can improve MT quality when weights are optimized using a margin-based approximation. On simulated datasets, Hopkins and May (2011) found that conventional MERT struggles to find reasonable parameter vectors, where a smooth loss function based on Pairwise Ranking Optimization (PRO) performs much better; on real data, this PRO method appears at least as good a</context>
<context position="4888" citStr="Hopkins and May (2011)" startWordPosition="746" endWordPosition="749"> where we apply `2 regularization to scale-senstive linear transforms of the original linear model. In addition, we introduce efficient methods of incorporating regularization in Och (2003)’s exact line searches. For all of these regularizers, our methods let us find the true optimum of the regularized objective function along the line. Finally, we address the issue of searching in a high-dimensional space by using the gradient of expected BLEU (Smith and Eisner, 2006) to find better search directions for our line searches. This direction finder addresses one of the serious concerns raised by Hopkins and May (2011): MERT widely failed to reach the optimum of a synthetic linear objective function. In replicating Hopkins and May’s experiments, we confirm that existing search algorithms for MERT—including coordinate ascent, Powell’s algorithm (Powell, 1964), and random direction sets (Cer et al., 2008)—perform poorly in this experimental condition. However, when using our gradient-based direction finder, MERT has no problem finding the true optimum even in a 1000-dimensional space. Our results suggest that the combination of a regularized objective function and a gradient-informed line search algorithm ena</context>
<context position="17881" citStr="Hopkins and May, 2011" startWordPosition="3021" endWordPosition="3024">point of the segment (since the value is constant across the entire segment). 4 Direction finding 4.1 A Gradient-based direction finder Perhaps the greatest obstacle in scaling MERT to many dimensions is finding good search directions. In problems of lower dimensions, iterating through all the coordinates is computationally feasible, though not guaranteed to find a global maximum even in the case of a perfect line search. As the number of dimensions increases by orders of magnitude, this coordinate direction approach becomes less and less tractable, and the quality of the search also suffers (Hopkins and May, 2011). Optimization has traditionally relied on finding the direction of steepest ascent: the gradient. Unfortunately, the objective function optimized by MERT is piecewise constant; while it may admit a subgradient, this direction is generally not very informative. Instead we may consider a smoothed variation of the original approximation. While some variants have been considered (Och, 2003; Flanigan et al., 2013), we use an expected BLEU approximation, assuming hypotheses are drawn from a log-linear distribution according to their parameter values (Smith and Eisner, 2006). That is, we assume the </context>
<context position="25722" citStr="Hopkins and May (2011)" startWordPosition="4345" endWordPosition="4348">the slope becomes the feature value in the new coordinate. However, this optimization does not appear to be widely adopted, likely because it does not lead to any speedup when random vectors, conjugate directions, or other non-sparse directions are used. 1953 Language pair Train Tune Dev Test Chinese-English 0.99M 1,797 1,000 1,082 (mt02+03) (mt05) Finnish-English 2.20M 11,935 2,001 4,855 Chinese-English 3.51M 1,894 1,664 1,357 (mt05) (mt06) (mt08) Arabic-English 1.49M 1,663 1,360 1,313 (mt06) (mt08) (mt09) Table 1: Datasets for the two experimental conditions. 5 Experimental Design Following Hopkins and May (2011), our experimental setup utilizes both real and synthetic data. The motivation for using synthetic data is that it is a way of gauging the quality of optimization methods, since the data is constructed knowing the global optimum. Hopkins and May also note that the use of an objective function that is linear in some gold weight vector makes the search much simpler than in a real translation setting, and they suggest that a learner that performs poorly in such a simple scenario has little hope of succeeding in a more complex one. The setup of our synthetic data experiment is almost the same as t</context>
<context position="30944" citStr="Hopkins and May, 2011" startWordPosition="5198" endWordPosition="5201"> The increase of the number of dimensions enables our direction finder to find a slightly better optimum, which moved away from w* due to noise. language models were trained on the target side of the parallel training data for both Arabic and Chinese. The Chinese systems development set is taken from the NIST mt05 evaluation set, augmented with some material reserved from our NIST training corpora in order to better cover newsgroup and weblog domains. 6 Results We conducted experiments with the synthetic data scenario described in the previous section, as well as with noise added to the data (Hopkins and May, 2011). The purpose of adding noise is to make the optimization task more realistic. Specifically, after computing all pseudo-BLEU scores, we added noise to each feature vector h,,,,, by drawing from a zero-mean Gaussian with standard deviation 200. Our results with both noiseless and noisy data yield the same conclusion as Hopkins and May: standard MERT struggles with many dimensions, and fails to recover w*. However, our experiments with the gradient direction finder of Section 4 are much more positive. This direction finder not only recovers w* 1 10 100 1000 line search iteration Figure 3: Compar</context>
<context position="39685" citStr="Hopkins and May, 2011" startWordPosition="6691" endWordPosition="6694"> alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 2008) achieves a related effect. Cer et al.’s goal is to achieve a more regular or smooth</context>
</contexts>
<marker>Hopkins, May, 2011</marker>
<rawString>Mark Hopkins and Jonathan May. 2011. Tuning as ranking. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 1352–1362.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Hyder</author>
<author>K Mahata</author>
</authors>
<title>An approximate L0 norm minimization algorithm for compressed sensing.</title>
<date>2009</date>
<booktitle>In Acoustics, Speech and Signal Processing,</booktitle>
<pages>3365--3368</pages>
<contexts>
<context position="16726" citStr="Hyder and Mahata, 2009" startWordPosition="2834" endWordPosition="2837">t,i) = dtTdt This closed-form solution is computed in time proportional to D, which doesn’t slow down the com4When the optimum is either at the left edge γi−1 or right edge γi of a segment, we select a point at a small relative distance within the segment (.999γi−1 + .001γi, in the former case) to avoid ties in objective values. S X s=1 γ = −�X wt,i · dt,i ��� X i i 1951 putation of Equation 5 for each segment (the construction of each segment of the upper envelope is proportional to D anyway). We also use `0 regularization. While minimization of the `0-norm is known to be NP-hard in general (Hyder and Mahata, 2009), this optimization is relatively trivial in the case of a line search. Indeed, for a given segment, the value in Equation 5 is constant everywhere except where we intersect any of the coordinate hyperplanes, i.e., where one of the coordinates is zero. Thus, our method consists of evaluating Equation 5 at the intersection points between the line and coordinate hyperplanes, returning the optimal point within the given segment. For any segment that doesn’t cross any of these hyperplanes, we evaluate the objective function at any point of the segment (since the value is constant across the entire</context>
</contexts>
<marker>Hyder, Mahata, 2009</marker>
<rawString>M. Hyder and K. Mahata. 2009. An approximate L0 norm minimization algorithm for compressed sensing. In Acoustics, Speech and Signal Processing, 2009. ICASSP 2009. IEEE International Conference on, pages 3365–3368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch Mayne</author>
<author>Christopher Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proc. ofACL, Demonstration Session.</booktitle>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra</location>
<contexts>
<context position="9467" citStr="Koehn et al., 2007" startWordPosition="1528" endWordPosition="1531">onstant intervals of the corpus-level error function, and by selecting the one that has the lowest error count (or, correspondingly, highest BLEU score). Assuming the optimum is found in the interval [-yk−1,-yk], we define -yopt = (-yk−1 + -yk)/2 and change the parameters using the update wt+1 = wt + -yopt · dt. Finally, this method is turned into a global Ddimensional search using algorithms that repeatedly use the aforementioned exact line search algorithm. Och (2003) first advocated the use of Powell’s method (Powell, 1964; Press et al., 2007). Pharaoh (Koehn, 2004) and subsequently Moses (Koehn et al., 2007) instead use coordinate ascent, and more recent work often uses random search directions (Cer et al., 2008; Macherey et al., 2008). In Section 4, we will present a novel direction finder for maximum-BLEU optimization, which uses the gradient of expected BLEU to find directions where the BLEU score is most likely to increase. 3 Regularization for MERT Because MERT is prone to overfitting when a large number of parameters must be optimized, we study the addition of a regularization term to the objective function. One conventional approach is to regularize the objective function with a penalty ba</context>
<context position="13304" citStr="Koehn et al., 2007" startWordPosition="2194" endWordPosition="2197">sensitive, which means any optimizer of this function can drive the regularization term down to zero by scaling down w. As special treatments for `2, we evaluate three linear transforms of the weight vector, where the vector w of the regularization term ||w||22/2σ2 is replaced with either: 1. an affine transform: w − w0 2. a vector with only (D − 1) free parameters, e.g., (1,w�2,··· ,w�D) 3. an `1 renormalization: w/||w||1 In (1), regularization is biased towards w0, a weight vector previously optimized using a competitive yet much smaller feature set, such as core features of a phrase-based (Koehn et al., 2007) or hierarchical (Chiang, 2007) system. The requirement that this feature set be small is to prevent overfitting. Otherwise, any regularization toward an overfit parameter vector w0 would defeat the purpose of introducing a regularization term in the first place.3 In (2), the transformation is motivated by the observation that the D-parameter linear model of Equation 2 only needs (D − 1) degrees of freedom. Fixing one of the components of w to any non-zero constant and allowing the others to vary, the new linear model retains the same modeling power, but the (D − 1) free parameters are no long</context>
<context position="27287" citStr="Koehn et al., 2007" startWordPosition="4612" endWordPosition="4615">en computed for each hypothesis, by computing the dot product between a predefined gold weight vector w* and each feature vector h,,,,,. By this linear construction, w* is guaranteed to be a global optimum.7 The pseudo-BLEU score is normalized for each M-best list, so that the translation with highest model score according to w* has a BLEU score of 1, and so that the translation with lowest model score for the sentence gets a BLEU of zero. This normalization has no impact on search, but makes results more interpretable. For our translation experiments, we use multistack phrase-based decoding (Koehn et al., 2007). We report results for two feature sets: non-linear features induced using Gradient Boosting Machines (Toutanova and Ahn, 2013) and sparse lexicalized 7The objective function remains piecewise constant, and the plateau containing w* maps to the optimal value of the function. reordering features (Cherry, 2013). We exploit these feature sets (GBM and SparseHRM, respectively) in two distinct experimental conditions, which we detail in the two next paragraphs. Both GBM and SparseHRM augment baseline features similar to Moses’: relative frequency and lexicalized phrase translation scores for both </context>
</contexts>
<marker>Koehn, Hoang, Mayne, Callison-Burch, Federico, Bertoldi, Cowan, Shen, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In Proc. ofACL, Demonstration Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: a beam search decoder for phrase-based statistical machine translation models.</title>
<date>2004</date>
<booktitle>In Proc. ofAMTA,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="9423" citStr="Koehn, 2004" startWordPosition="1523" endWordPosition="1524">mputed by enumerating all piecewise constant intervals of the corpus-level error function, and by selecting the one that has the lowest error count (or, correspondingly, highest BLEU score). Assuming the optimum is found in the interval [-yk−1,-yk], we define -yopt = (-yk−1 + -yk)/2 and change the parameters using the update wt+1 = wt + -yopt · dt. Finally, this method is turned into a global Ddimensional search using algorithms that repeatedly use the aforementioned exact line search algorithm. Och (2003) first advocated the use of Powell’s method (Powell, 1964; Press et al., 2007). Pharaoh (Koehn, 2004) and subsequently Moses (Koehn et al., 2007) instead use coordinate ascent, and more recent work often uses random search directions (Cer et al., 2008; Macherey et al., 2008). In Section 4, we will present a novel direction finder for maximum-BLEU optimization, which uses the gradient of expected BLEU to find directions where the BLEU score is most likely to increase. 3 Regularization for MERT Because MERT is prone to overfitting when a large number of parameters must be optimized, we study the addition of a regularization term to the objective function. One conventional approach is to regular</context>
<context position="32331" citStr="Koehn, 2004" startWordPosition="5425" endWordPosition="5426">ith 1000 dimensions, but its effectiveness is also visible with noisy data, as seen in Figure 2. The decrease of its cosine is relatively small compared to other search algorithms, and this decrease is not necessarily a sign of search errors since the addition of noise causes the true optimum to be different from w*. Finally, Figure 3 shows our rate of convergence compared to coordinate ascent. Our experimental results with the GBM feature set data are shown in Table 2. Each table is divided into three sections corresponding respectively to MERT (Och, 2003) with Koehn-style coordinate ascent (Koehn, 2004), PRO, and our optimizer featuring both regularization and the gradient-based direction finder. All variants of MERT are initialized with a single starting point, which is either uniform weight or w0. Instead of providing MERT with additional random starting points as in Moses, we use random walks as in (Moore and Quirk, 2008) to attempt to move out of local optima.8 Since PRO and our optimizer have hyperparameters, we use a held-out set (Dev) for adjusting them. For PRO, we adjust three parameters: a regularization penalty for f2, the parameter α in the add-α smoothed sentence-level version o</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Pharaoh: a beam search decoder for phrase-based statistical machine translation models. In Proc. ofAMTA, pages 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>Wolfgang Macherey</author>
<author>Chris Dyer</author>
<author>Franz Och</author>
</authors>
<title>Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>163--171</pages>
<contexts>
<context position="1806" citStr="Kumar et al., 2009" startWordPosition="268" endWordPosition="271">rches. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets. 1 Introduction Minimum Error Rate Training emerged a decade ago (Och, 2003) as a superior training method for small numbers of linear model parameters of machine translation systems, improving over prior work using maximum likelihood criteria (Och and Ney, 2002). This technique quickly rose to prominence, becoming standard in many research and commercial MT systems. Variants operating over lattices (Macherey et al., 2008) or hypergraphs (Kumar et al., 2009) were subsequently developed, with the benefit of reducing the approximation error from n-best lists. The primary advantages of MERT are twofold. It directly optimizes the evaluation metric under consideration (e.g., BLEU) instead of some surrogate loss. Secondly, it offers a globally optimal line search. Unfortunately, there are several potential difficulties in scaling MERT to larger numbers of features, due to its non-convex loss function and its lack of regularization. These challenges have prompted some researchers to move away from MERT, in favor of linearly decomposable approximations o</context>
<context position="39432" citStr="Kumar et al., 2009" startWordPosition="6648" endWordPosition="6651">ch as deep neural networks (DNN) and word alignment models, commonly require such initializers in order to obtain decent performance. In the case of DNN, extensive research is devoted to the problem of finding good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, </context>
</contexts>
<marker>Kumar, Macherey, Dyer, Och, 2009</marker>
<rawString>Shankar Kumar, Wolfgang Macherey, Chris Dyer, and Franz Och. 2009. Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 163–171.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Larochelle</author>
<author>Yoshua Bengio</author>
<author>J´erˆome Louradour</author>
<author>Pascal Lamblin</author>
</authors>
<title>Exploring strategies for training deep neural networks.</title>
<date>2009</date>
<journal>J. Mach. Learn. Res.,</journal>
<pages>10--1</pages>
<contexts>
<context position="39968" citStr="Larochelle et al., 2009" startWordPosition="6738" endWordPosition="6741">2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 2008) achieves a related effect. Cer et al.’s goal is to achieve a more regular or smooth objective function, while ours is to obtain a more regular set of parameters. The two approaches may be complementary. More recently, new research has explored direction finding using a smooth surrogate loss function (Flanigan et al., 2013). Although this method is successful in he</context>
</contexts>
<marker>Larochelle, Bengio, Louradour, Lamblin, 2009</marker>
<rawString>Hugo Larochelle, Yoshua Bengio, J´erˆome Louradour, and Pascal Lamblin. 2009. Exploring strategies for training deep neural networks. J. Mach. Learn. Res., 10:1–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>A Bouchard-Cˆot´e</author>
<author>D Klein</author>
<author>B Taskar</author>
</authors>
<title>An end-to-end discriminative approach to machine translation.</title>
<date>2006</date>
<booktitle>In International Conference on Computational Linguistics and Association for Computational Linguistics (COLING/ACL).</booktitle>
<marker>Liang, Bouchard-Cˆot´e, Klein, Taskar, 2006</marker>
<rawString>P. Liang, A. Bouchard-Cˆot´e, D. Klein, and B. Taskar. 2006. An end-to-end discriminative approach to machine translation. In International Conference on Computational Linguistics and Association for Computational Linguistics (COLING/ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Franz Josef Och</author>
</authors>
<title>ORANGE: a method for evaluating automatic evaluation metrics for machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics,</booktitle>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="32957" citStr="Lin and Och, 2004" startWordPosition="5530" endWordPosition="5533">nd our optimizer featuring both regularization and the gradient-based direction finder. All variants of MERT are initialized with a single starting point, which is either uniform weight or w0. Instead of providing MERT with additional random starting points as in Moses, we use random walks as in (Moore and Quirk, 2008) to attempt to move out of local optima.8 Since PRO and our optimizer have hyperparameters, we use a held-out set (Dev) for adjusting them. For PRO, we adjust three parameters: a regularization penalty for f2, the parameter α in the add-α smoothed sentence-level version of BLEU (Lin and Och, 2004), and a parameter for scaling the corpus-level length of the references. The latter scaling parameter is discussed in (He and 8In the case of the gradient-based direction finder, we also use the following strategy whenever optimization converges to a (possibly local) optimum. We run one round of coordinate ascent, and continue with the gradient direction finder as soon as the optimum improves. If the none of the coordinate directions helped, we stop the search. expected BLEU gradient random directions Powell coordinate ascent cosine 0.8 0.6 0.4 0.2 0 1 expected BLEU gradient random directions </context>
</contexts>
<marker>Lin, Och, 2004</marker>
<rawString>Chin-Yew Lin and Franz Josef Och. 2004. ORANGE: a method for evaluating automatic evaluation metrics for machine translation. In Proceedings of the 20th international conference on Computational Linguistics, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Macherey</author>
<author>Franz Och</author>
<author>Ignacio Thayer</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Lattice-based minimum error rate training for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>725--734</pages>
<contexts>
<context position="1770" citStr="Macherey et al., 2008" startWordPosition="262" endWordPosition="265">ed BLEU to orient MERT’s exact line searches. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets. 1 Introduction Minimum Error Rate Training emerged a decade ago (Och, 2003) as a superior training method for small numbers of linear model parameters of machine translation systems, improving over prior work using maximum likelihood criteria (Och and Ney, 2002). This technique quickly rose to prominence, becoming standard in many research and commercial MT systems. Variants operating over lattices (Macherey et al., 2008) or hypergraphs (Kumar et al., 2009) were subsequently developed, with the benefit of reducing the approximation error from n-best lists. The primary advantages of MERT are twofold. It directly optimizes the evaluation metric under consideration (e.g., BLEU) instead of some surrogate loss. Secondly, it offers a globally optimal line search. Unfortunately, there are several potential difficulties in scaling MERT to larger numbers of features, due to its non-convex loss function and its lack of regularization. These challenges have prompted some researchers to move away from MERT, in favor of li</context>
<context position="7401" citStr="Macherey et al., 2008" startWordPosition="1177" endWordPosition="1180"> } (2) mE{1...M} While the error surface of Equation 1 is only an approximation of the true error surface of the MT decoder, the quality of this approximation depends on the size of the hypothesis space represented by the M-best list. Therefore, the hypothesis list is grown iteratively: decoding with an initial parameter vector seeds the M-best lists; next, parameter estimation and M-best list gathering alternate until the cumulative M-best list no longer grows, or until changes of w between two decoding runs are deemed too small. To increase the size of the hypothesis space, subsequent work (Macherey et al., 2008) instead operated on lattices, but this paper focuses on M-best lists. A crucial observation is that the unsmoothed error count represented in Equation 1 is a piecewise constant function. This enabled Och (2003) to devise a line search algorithm guaranteed to find the optimum point along the line. To extend the search from one to multiple dimensions, MERT applies a sequence of line optimizations along some fixed or variable set of search directions {dt} until some convergence criteria are met. Considering a given point wt and a given direction dt at iteration t, finding the most probable trans</context>
<context position="9597" citStr="Macherey et al., 2008" startWordPosition="1549" endWordPosition="1552">ngly, highest BLEU score). Assuming the optimum is found in the interval [-yk−1,-yk], we define -yopt = (-yk−1 + -yk)/2 and change the parameters using the update wt+1 = wt + -yopt · dt. Finally, this method is turned into a global Ddimensional search using algorithms that repeatedly use the aforementioned exact line search algorithm. Och (2003) first advocated the use of Powell’s method (Powell, 1964; Press et al., 2007). Pharaoh (Koehn, 2004) and subsequently Moses (Koehn et al., 2007) instead use coordinate ascent, and more recent work often uses random search directions (Cer et al., 2008; Macherey et al., 2008). In Section 4, we will present a novel direction finder for maximum-BLEU optimization, which uses the gradient of expected BLEU to find directions where the BLEU score is most likely to increase. 3 Regularization for MERT Because MERT is prone to overfitting when a large number of parameters must be optimized, we study the addition of a regularization term to the objective function. One conventional approach is to regularize the objective function with a penalty based on the ��Euclidean norm ||w||2 = i w2i , also known as t2 regularization. In the case of MERT, this yields the following objec</context>
<context position="39371" citStr="Macherey et al., 2008" startWordPosition="6636" endWordPosition="6639"> optimization. Other non-convex problems in machine learning, such as deep neural networks (DNN) and word alignment models, commonly require such initializers in order to obtain decent performance. In the case of DNN, extensive research is devoted to the problem of finding good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) pr</context>
</contexts>
<marker>Macherey, Och, Thayer, Uszkoreit, 2008</marker>
<rawString>Wolfgang Macherey, Franz Och, Ignacio Thayer, and Jakob Uszkoreit. 2008. Lattice-based minimum error rate training for statistical machine translation. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 725–734.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McAllester</author>
<author>Joseph Keshet</author>
</authors>
<title>Generalization bounds and consistency for latent structural probit and ramp loss.</title>
<date>2011</date>
<booktitle>In Advances in Neural Information Processing Systems 24,</booktitle>
<pages>2205--2212</pages>
<contexts>
<context position="12443" citStr="McAllester and Keshet, 2011" startWordPosition="2049" endWordPosition="2052">ulation (Equation 1) of MERT consists of a piecewise constant representation of the loss, as a function of the step size in a given direction. But with these three reg-0.2 0.8 0.6 0.4 0.2 1.4 1.2 0 1 MERT Max at 0.225 X X -0.2 0.8 0.6 0.4 0.2 1.4 1.2 0 1 X MERT − t2 Max at -0.018 −t2 X -0.2 0.8 0.6 0.4 0.2 1.4 1.2 0 1 X MERT − t0 Max at 0 t0 X 1950 ularization terms, the function respectively becomes piecewise quadratic, piecewise linear, or piecewise constant with a potential impulse jump for each distinct choice of regularizer. Figure 1 demonstrates this effect graphically. As discussed in (McAllester and Keshet, 2011), the problem with optimizing Equation 4 directly is that the output of the underlying linear classifier, and therefore the error count, are not sensitive to the scale of w. Moreover, `2 regularization (as well as `1 regularization) is scale sensitive, which means any optimizer of this function can drive the regularization term down to zero by scaling down w. As special treatments for `2, we evaluate three linear transforms of the weight vector, where the vector w of the regularization term ||w||22/2σ2 is replaced with either: 1. an affine transform: w − w0 2. a vector with only (D − 1) free p</context>
</contexts>
<marker>McAllester, Keshet, 2011</marker>
<rawString>David McAllester and Joseph Keshet. 2011. Generalization bounds and consistency for latent structural probit and ramp loss. In Advances in Neural Information Processing Systems 24, pages 2205–2212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert C Moore</author>
<author>Chris Quirk</author>
</authors>
<title>Random restarts in minimum error rate training for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics -</booktitle>
<volume>1</volume>
<pages>585--592</pages>
<contexts>
<context position="32659" citStr="Moore and Quirk, 2008" startWordPosition="5477" endWordPosition="5480"> Finally, Figure 3 shows our rate of convergence compared to coordinate ascent. Our experimental results with the GBM feature set data are shown in Table 2. Each table is divided into three sections corresponding respectively to MERT (Och, 2003) with Koehn-style coordinate ascent (Koehn, 2004), PRO, and our optimizer featuring both regularization and the gradient-based direction finder. All variants of MERT are initialized with a single starting point, which is either uniform weight or w0. Instead of providing MERT with additional random starting points as in Moses, we use random walks as in (Moore and Quirk, 2008) to attempt to move out of local optima.8 Since PRO and our optimizer have hyperparameters, we use a held-out set (Dev) for adjusting them. For PRO, we adjust three parameters: a regularization penalty for f2, the parameter α in the add-α smoothed sentence-level version of BLEU (Lin and Och, 2004), and a parameter for scaling the corpus-level length of the references. The latter scaling parameter is discussed in (He and 8In the case of the gradient-based direction finder, we also use the following strategy whenever optimization converges to a (possibly local) optimum. We run one round of coord</context>
<context position="39412" citStr="Moore and Quirk, 2008" startWordPosition="6644" endWordPosition="6647">in machine learning, such as deep neural networks (DNN) and word alignment models, commonly require such initializers in order to obtain decent performance. In the case of DNN, extensive research is devoted to the problem of finding good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms</context>
</contexts>
<marker>Moore, Quirk, 2008</marker>
<rawString>Robert C. Moore and Chris Quirk. 2008. Random restarts in minimum error rate training for statistical machine translation. In Proceedings of the 22nd International Conference on Computational Linguistics - Volume 1, pages 585–592.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Francisco Guzman</author>
<author>Stephan Vogel</author>
</authors>
<title>Optimizing for sentence-level BLEU+1 yields short translations.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<pages>1979--1994</pages>
<contexts>
<context position="34889" citStr="Nakov et al., 2012" startWordPosition="5861" endWordPosition="5864">3.2 52.6 55.1 Table 2: BLEU scores for GBM features. Model parameters were optimized on the Tune set. For PRO and regularized MERT, we optimized with different hyperparameters (regularization weight, etc.), and retained for each experimental condition the model that worked best on Dev. The table shows the performance of these retained models. 1e-05 0.0001 0.001 0.01 0.1 1 10 regularization weight Figure 4: BLEU score on the Finnish Dev set (GBM) with different values for the 1/2u2 regularization weight. To enable comparable results, the other hyperparameter (length) is kept fixed. Deng, 2012; Nakov et al., 2012) and addresses the problem that systems tuned with PRO tend to produce sentences that are too short. On the other hand, regularized MERT only requires one hyperparameter to tune: a regularization penalty for f2 or f0. However, since PRO optimizes translation length on the Dev dataset and MERT does so using the Tune set, a comparison of the two systems would yield a discrepancy in length that would be undesirable. Therefore, we add another hyperparameter to regularized MERT to tune length in the same manner using the Dev set. Table 2 offers several findings. First, unregularized MERT can achiev</context>
</contexts>
<marker>Nakov, Guzman, Vogel, 2012</marker>
<rawString>Preslav Nakov, Francisco Guzman, and Stephan Vogel. 2012. Optimizing for sentence-level BLEU+1 yields short translations. In Proceedings of COLING 2012, pages 1979–1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>295--302</pages>
<contexts>
<context position="1607" citStr="Och and Ney, 2002" startWordPosition="238" endWordPosition="241">integrating them during search. To improve search in large parameter spaces, we also present a new direction finding algorithm that uses the gradient of expected BLEU to orient MERT’s exact line searches. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets. 1 Introduction Minimum Error Rate Training emerged a decade ago (Och, 2003) as a superior training method for small numbers of linear model parameters of machine translation systems, improving over prior work using maximum likelihood criteria (Och and Ney, 2002). This technique quickly rose to prominence, becoming standard in many research and commercial MT systems. Variants operating over lattices (Macherey et al., 2008) or hypergraphs (Kumar et al., 2009) were subsequently developed, with the benefit of reducing the approximation error from n-best lists. The primary advantages of MERT are twofold. It directly optimizes the evaluation metric under consideration (e.g., BLEU) instead of some surrogate loss. Secondly, it offers a globally optimal line search. Unfortunately, there are several potential difficulties in scaling MERT to larger numbers of f</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Josef Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proceedings of 40th Annual Meeting of the Association for Computational Linguistics, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="1420" citStr="Och, 2003" startWordPosition="212" endWordPosition="213">as `2 are inapplicable to MERT due to the scale invariance of its objective function, we turn to two regularizers—`0 and a modification of `2— and present methods for efficiently integrating them during search. To improve search in large parameter spaces, we also present a new direction finding algorithm that uses the gradient of expected BLEU to orient MERT’s exact line searches. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO, a learner often used with large feature sets. 1 Introduction Minimum Error Rate Training emerged a decade ago (Och, 2003) as a superior training method for small numbers of linear model parameters of machine translation systems, improving over prior work using maximum likelihood criteria (Och and Ney, 2002). This technique quickly rose to prominence, becoming standard in many research and commercial MT systems. Variants operating over lattices (Macherey et al., 2008) or hypergraphs (Kumar et al., 2009) were subsequently developed, with the benefit of reducing the approximation error from n-best lists. The primary advantages of MERT are twofold. It directly optimizes the evaluation metric under consideration (e.g</context>
<context position="4455" citStr="Och (2003)" startWordPosition="676" endWordPosition="677">s of regularization that are not susceptible to this scaling problem. We analyze and experiment with `0, a form of regularization that is scale insensitive. We also present new parameterizations of `2 1948 Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1948–1959, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics regularization, where we apply `2 regularization to scale-senstive linear transforms of the original linear model. In addition, we introduce efficient methods of incorporating regularization in Och (2003)’s exact line searches. For all of these regularizers, our methods let us find the true optimum of the regularized objective function along the line. Finally, we address the issue of searching in a high-dimensional space by using the gradient of expected BLEU (Smith and Eisner, 2006) to find better search directions for our line searches. This direction finder addresses one of the serious concerns raised by Hopkins and May (2011): MERT widely failed to reach the optimum of a synthetic linear objective function. In replicating Hopkins and May’s experiments, we confirm that existing search algor</context>
<context position="5864" citStr="Och, 2003" startWordPosition="894" endWordPosition="895">ient-based direction finder, MERT has no problem finding the true optimum even in a 1000-dimensional space. Our results suggest that the combination of a regularized objective function and a gradient-informed line search algorithm enables MERT to scale well with a large number of features. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO (Hopkins and May, 2011), a parameter tuning method known to be effective with large feature sets. 2 Unregularized MERT Prior to introducing regularized MERT, we briefly review standard unregularized MERT (Och, 2003). We use fS1 = {f1 ... fS} to denote the S input sentences of a given tuning set. For each sentence fs, let Cs = {es,1 . . . es,M} denote the list of M-best candidate translations. Each input and output sentence pair (fs, es,m) is weighted using a linear model that applies model parameters w = (w1 ... wD) E RD to D feature functions h1(f, e, —) ... hD(f, e, —), where — is the hidden state associated with the derivation from f to e, such as phrase segmentation and alignment. Furthermore, let hs,m E RD denote the feature vector representing the translation pair (fs, es,m). In MERT, the goal is t</context>
<context position="7612" citStr="Och (2003)" startWordPosition="1213" endWordPosition="1214">-best list. Therefore, the hypothesis list is grown iteratively: decoding with an initial parameter vector seeds the M-best lists; next, parameter estimation and M-best list gathering alternate until the cumulative M-best list no longer grows, or until changes of w between two decoding runs are deemed too small. To increase the size of the hypothesis space, subsequent work (Macherey et al., 2008) instead operated on lattices, but this paper focuses on M-best lists. A crucial observation is that the unsmoothed error count represented in Equation 1 is a piecewise constant function. This enabled Och (2003) to devise a line search algorithm guaranteed to find the optimum point along the line. To extend the search from one to multiple dimensions, MERT applies a sequence of line optimizations along some fixed or variable set of search directions {dt} until some convergence criteria are met. Considering a given point wt and a given direction dt at iteration t, finding the most probable translation hypothesis in the set of candidates translations Cs = {es,1 ... es,M} corresponds to solving the following optimization problem: e(fs;γ) = arg max{ (wt + γ · dt)T hs,m� (3) mE{1 ... M} l The function in t</context>
<context position="9322" citStr="Och (2003)" startWordPosition="1507" endWordPosition="1508">ewise constant functions aggregated over all sentences of the corpus.1 The optimal -y is finally computed by enumerating all piecewise constant intervals of the corpus-level error function, and by selecting the one that has the lowest error count (or, correspondingly, highest BLEU score). Assuming the optimum is found in the interval [-yk−1,-yk], we define -yopt = (-yk−1 + -yk)/2 and change the parameters using the update wt+1 = wt + -yopt · dt. Finally, this method is turned into a global Ddimensional search using algorithms that repeatedly use the aforementioned exact line search algorithm. Och (2003) first advocated the use of Powell’s method (Powell, 1964; Press et al., 2007). Pharaoh (Koehn, 2004) and subsequently Moses (Koehn et al., 2007) instead use coordinate ascent, and more recent work often uses random search directions (Cer et al., 2008; Macherey et al., 2008). In Section 4, we will present a novel direction finder for maximum-BLEU optimization, which uses the gradient of expected BLEU to find directions where the BLEU score is most likely to increase. 3 Regularization for MERT Because MERT is prone to overfitting when a large number of parameters must be optimized, we study the</context>
<context position="14730" citStr="Och, 2003" startWordPosition="2436" endWordPosition="2437">ale insensitive, thus not affected by this problem. 3.1 Exact line search with regularization Optimizing with a regularized error surface requires a change in the line search algorithm presented in 3(Gimpel and Smith, 2012, footnote 6) briefly mentions the use of such a regularizer with its ramp loss objective function. Section 2, but the other aspects of MERT remain the same, and we can still use global search algorithms such as coordinate ascent, Powell, and random directions exactly the same way as with unregularized MERT. Line search with a regularization term is still as efficient as in (Och, 2003), and it is still guaranteed to find the optimum of the (now regularized) objective function along the line. Considering again a given point wt and a given direction dt at line search iteration t, finding the optimum γopt corresponds to finding γ that minimizes: E(rs,A(fs;γ)) + ||wt + γ · dt||2 2 (5) 2σ2 Since regularization does not affect the points at which e(fs; γ) changes its optimum, the points γ�� 1 &lt; · · · &lt; γM of intersection in the upper envelope remain the same, so the points of discontinuity in the error surface remain the same. The difference now is that the error count on each se</context>
<context position="18270" citStr="Och, 2003" startWordPosition="3080" endWordPosition="3081"> a perfect line search. As the number of dimensions increases by orders of magnitude, this coordinate direction approach becomes less and less tractable, and the quality of the search also suffers (Hopkins and May, 2011). Optimization has traditionally relied on finding the direction of steepest ascent: the gradient. Unfortunately, the objective function optimized by MERT is piecewise constant; while it may admit a subgradient, this direction is generally not very informative. Instead we may consider a smoothed variation of the original approximation. While some variants have been considered (Och, 2003; Flanigan et al., 2013), we use an expected BLEU approximation, assuming hypotheses are drawn from a log-linear distribution according to their parameter values (Smith and Eisner, 2006). That is, we assume the probability of a translation candidate es,m is proportional to (exp (wThs,m))µ, where w are the parameters being optimized, hs,m is the vector of the features for es,m, and µ is a scaling parameter. As µ approaches where R is the sum of reference lengths across the corpus, C is the sum of candidate lengths, mn is the number of matched n-grams (potentially clipped), and cn is the number </context>
<context position="32282" citStr="Och, 2003" startWordPosition="5419" endWordPosition="5420">y experimental setting. (cosine &gt; 0.999) even with 1000 dimensions, but its effectiveness is also visible with noisy data, as seen in Figure 2. The decrease of its cosine is relatively small compared to other search algorithms, and this decrease is not necessarily a sign of search errors since the addition of noise causes the true optimum to be different from w*. Finally, Figure 3 shows our rate of convergence compared to coordinate ascent. Our experimental results with the GBM feature set data are shown in Table 2. Each table is divided into three sections corresponding respectively to MERT (Och, 2003) with Koehn-style coordinate ascent (Koehn, 2004), PRO, and our optimizer featuring both regularization and the gradient-based direction finder. All variants of MERT are initialized with a single starting point, which is either uniform weight or w0. Instead of providing MERT with additional random starting points as in Moses, we use random walks as in (Moore and Quirk, 2008) to attempt to move out of local optima.8 Since PRO and our optimizer have hyperparameters, we use a held-out set (Dev) for adjusting them. For PRO, we adjust three parameters: a regularization penalty for f2, the parameter</context>
<context position="39348" citStr="Och, 2003" startWordPosition="6634" endWordPosition="6635"> non-convex optimization. Other non-convex problems in machine learning, such as deep neural networks (DNN) and word alignment models, commonly require such initializers in order to obtain decent performance. In the case of DNN, extensive research is devoted to the problem of finding good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Laro</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2001</date>
<booktitle>In Proc. ofACL.</booktitle>
<contexts>
<context position="10485" citStr="Papineni et al., 2001" startWordPosition="1702" endWordPosition="1705"> large number of parameters must be optimized, we study the addition of a regularization term to the objective function. One conventional approach is to regularize the objective function with a penalty based on the ��Euclidean norm ||w||2 = i w2i , also known as t2 regularization. In the case of MERT, this yields the following objective function:2 ( S 2 w = arg min { E E(rs, e(fs; w)) + ��� |2 l (4) l s=1 f 1This assumes that the sufficient statistics of the metric under consideration are additively decomposable by sentence, which is the case with most popular evaluation metrics such as BLEU (Papineni et al., 2001). 2The 12 regularizer is often used in conjunction with loglikelihood objectives. The regularization term of Equation 4 could similarly be added to the log of an objective—e.g., log(BLEU) instead of BLEU—but we found that the distinction doesn’t have much of an impact in practice. -0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4 -0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4 -0.4 -0.3 -0.2 -0.1 0 0.1 0.2 0.3 0.4 -y, the step size in the current direction Figure 1: Example MERT values along one coordinate, first unregularized. When regularized with t2, the piecewise constant function becomes piecewise quadratic. W</context>
<context position="28768" citStr="Papineni et al., 2001" startWordPosition="4837" endWordPosition="4840">n either side. In reference to Table 1, we used the training set (Train) for extracting phrase tables and language models; the Tune set for optimization with MERT or PRO; the Dev set for selecting hyperparameters of PRO and regularized MERT; and the Test set for reporting final results. In each experimental condition, we first trained weights for the base feature sets, and then decoded the Tune, Dev, and Test datasets, generating 500-best lists for each set. All results report reranking performance on these lists with different feature sets and optimization methods, based on lower-cased BLEU (Papineni et al., 2001). The GBM feature set (Toutanova and Ahn, 2013) consists of about 230 features automatically induced using decision tree weak learners, which derive features using various word-level, phrase-level, and morphological attributes. For Chinese-English, the training corpus consists of approximately one million sentence pairs from the FBIS and Hong Kong portions of the LDC data for the NIST MT evaluation and the Tune and Test sets are from NIST competitions. A 4-gram language model was trained on the Xinhua portion of the English Gigaword corpus and on the target side of the bitext. For Finnish-Engl</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2001</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2001. BLEU: a method for automatic evaluation of machine translation. In Proc. ofACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
</authors>
<title>Discriminative training via linear programming.</title>
<date>1999</date>
<booktitle>In Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<volume>2</volume>
<pages>561--564</pages>
<contexts>
<context position="8261" citStr="Papineni, 1999" startWordPosition="1323" endWordPosition="1325"> guaranteed to find the optimum point along the line. To extend the search from one to multiple dimensions, MERT applies a sequence of line optimizations along some fixed or variable set of search directions {dt} until some convergence criteria are met. Considering a given point wt and a given direction dt at iteration t, finding the most probable translation hypothesis in the set of candidates translations Cs = {es,1 ... es,M} corresponds to solving the following optimization problem: e(fs;γ) = arg max{ (wt + γ · dt)T hs,m� (3) mE{1 ... M} l The function in this equation is piecewise linear (Papineni, 1999), which enables an efficient exhaustive computation. Specifically, this function is optimized by enumerating the up to M hypotheses that form the upper envelope of the model score function. The error count, then, is a piecewise constant function arg min w 1949 defined by the points -y�9 1 &lt; · · · &lt; -y�9M at which an increase in -y causes a change of optimum in Equation 3. Error counts for the whole corpus are simply the sums of sentence-level piecewise constant functions aggregated over all sentences of the corpus.1 The optimal -y is finally computed by enumerating all piecewise constant inter</context>
</contexts>
<marker>Papineni, 1999</marker>
<rawString>Kishore Papineni. 1999. Discriminative training via linear programming. In Proceedings IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), volume 2, pages 561–564, Vol. 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J D Powell</author>
</authors>
<title>An efficient method for finding the minimum of a function of several variables without calculating derivatives.</title>
<date>1964</date>
<journal>Comput. J.,</journal>
<volume>7</volume>
<issue>2</issue>
<contexts>
<context position="5132" citStr="Powell, 1964" startWordPosition="783" endWordPosition="784">ds let us find the true optimum of the regularized objective function along the line. Finally, we address the issue of searching in a high-dimensional space by using the gradient of expected BLEU (Smith and Eisner, 2006) to find better search directions for our line searches. This direction finder addresses one of the serious concerns raised by Hopkins and May (2011): MERT widely failed to reach the optimum of a synthetic linear objective function. In replicating Hopkins and May’s experiments, we confirm that existing search algorithms for MERT—including coordinate ascent, Powell’s algorithm (Powell, 1964), and random direction sets (Cer et al., 2008)—perform poorly in this experimental condition. However, when using our gradient-based direction finder, MERT has no problem finding the true optimum even in a 1000-dimensional space. Our results suggest that the combination of a regularized objective function and a gradient-informed line search algorithm enables MERT to scale well with a large number of features. Experiments with up to 3600 features show that these extensions of MERT yield results comparable to PRO (Hopkins and May, 2011), a parameter tuning method known to be effective with large</context>
<context position="9379" citStr="Powell, 1964" startWordPosition="1516" endWordPosition="1517">of the corpus.1 The optimal -y is finally computed by enumerating all piecewise constant intervals of the corpus-level error function, and by selecting the one that has the lowest error count (or, correspondingly, highest BLEU score). Assuming the optimum is found in the interval [-yk−1,-yk], we define -yopt = (-yk−1 + -yk)/2 and change the parameters using the update wt+1 = wt + -yopt · dt. Finally, this method is turned into a global Ddimensional search using algorithms that repeatedly use the aforementioned exact line search algorithm. Och (2003) first advocated the use of Powell’s method (Powell, 1964; Press et al., 2007). Pharaoh (Koehn, 2004) and subsequently Moses (Koehn et al., 2007) instead use coordinate ascent, and more recent work often uses random search directions (Cer et al., 2008; Macherey et al., 2008). In Section 4, we will present a novel direction finder for maximum-BLEU optimization, which uses the gradient of expected BLEU to find directions where the BLEU score is most likely to increase. 3 Regularization for MERT Because MERT is prone to overfitting when a large number of parameters must be optimized, we study the addition of a regularization term to the objective funct</context>
</contexts>
<marker>Powell, 1964</marker>
<rawString>M.J.D. Powell. 1964. An efficient method for finding the minimum of a function of several variables without calculating derivatives. Comput. J., 7(2):155–162.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William H Press</author>
<author>Saul A Teukolsky</author>
<author>William T Vetterling</author>
<author>Brian P Flannery</author>
</authors>
<title>Numerical Recipes: The Art of Scientific Computing.</title>
<date>2007</date>
<publisher>Cambridge University Press,</publisher>
<note>3rd edition.</note>
<contexts>
<context position="9400" citStr="Press et al., 2007" startWordPosition="1518" endWordPosition="1521">1 The optimal -y is finally computed by enumerating all piecewise constant intervals of the corpus-level error function, and by selecting the one that has the lowest error count (or, correspondingly, highest BLEU score). Assuming the optimum is found in the interval [-yk−1,-yk], we define -yopt = (-yk−1 + -yk)/2 and change the parameters using the update wt+1 = wt + -yopt · dt. Finally, this method is turned into a global Ddimensional search using algorithms that repeatedly use the aforementioned exact line search algorithm. Och (2003) first advocated the use of Powell’s method (Powell, 1964; Press et al., 2007). Pharaoh (Koehn, 2004) and subsequently Moses (Koehn et al., 2007) instead use coordinate ascent, and more recent work often uses random search directions (Cer et al., 2008; Macherey et al., 2008). In Section 4, we will present a novel direction finder for maximum-BLEU optimization, which uses the gradient of expected BLEU to find directions where the BLEU score is most likely to increase. 3 Regularization for MERT Because MERT is prone to overfitting when a large number of parameters must be optimized, we study the addition of a regularization term to the objective function. One conventional</context>
</contexts>
<marker>Press, Teukolsky, Vetterling, Flannery, 2007</marker>
<rawString>William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. 2007. Numerical Recipes: The Art of Scientific Computing. Cambridge University Press, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko Rosti</author>
<author>Bing Zhang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Expected BLEU training for graphs: BBN system description for WMT11 system combination task.</title>
<date>2011</date>
<booktitle>In Proceedings of the Sixth Workshop on Statistical Machine Translation,</booktitle>
<pages>159--165</pages>
<contexts>
<context position="39705" citStr="Rosti et al., 2011" startWordPosition="6695" endWordPosition="6698">n practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 2008) achieves a related effect. Cer et al.’s goal is to achieve a more regular or smooth objective function,</context>
</contexts>
<marker>Rosti, Zhang, Matsoukas, Schwartz, 2011</marker>
<rawString>Antti-Veikko Rosti, Bing Zhang, Spyros Matsoukas, and Richard Schwartz. 2011. Expected BLEU training for graphs: BBN system description for WMT11 system combination task. In Proceedings of the Sixth Workshop on Statistical Machine Translation, pages 159–165.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Minimum risk annealing for training log-linear models.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>787--794</pages>
<contexts>
<context position="4739" citStr="Smith and Eisner, 2006" startWordPosition="722" endWordPosition="725">l Language Processing, pages 1948–1959, Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics regularization, where we apply `2 regularization to scale-senstive linear transforms of the original linear model. In addition, we introduce efficient methods of incorporating regularization in Och (2003)’s exact line searches. For all of these regularizers, our methods let us find the true optimum of the regularized objective function along the line. Finally, we address the issue of searching in a high-dimensional space by using the gradient of expected BLEU (Smith and Eisner, 2006) to find better search directions for our line searches. This direction finder addresses one of the serious concerns raised by Hopkins and May (2011): MERT widely failed to reach the optimum of a synthetic linear objective function. In replicating Hopkins and May’s experiments, we confirm that existing search algorithms for MERT—including coordinate ascent, Powell’s algorithm (Powell, 1964), and random direction sets (Cer et al., 2008)—perform poorly in this experimental condition. However, when using our gradient-based direction finder, MERT has no problem finding the true optimum even in a 1</context>
<context position="18456" citStr="Smith and Eisner, 2006" startWordPosition="3107" endWordPosition="3110"> the search also suffers (Hopkins and May, 2011). Optimization has traditionally relied on finding the direction of steepest ascent: the gradient. Unfortunately, the objective function optimized by MERT is piecewise constant; while it may admit a subgradient, this direction is generally not very informative. Instead we may consider a smoothed variation of the original approximation. While some variants have been considered (Och, 2003; Flanigan et al., 2013), we use an expected BLEU approximation, assuming hypotheses are drawn from a log-linear distribution according to their parameter values (Smith and Eisner, 2006). That is, we assume the probability of a translation candidate es,m is proportional to (exp (wThs,m))µ, where w are the parameters being optimized, hs,m is the vector of the features for es,m, and µ is a scaling parameter. As µ approaches where R is the sum of reference lengths across the corpus, C is the sum of candidate lengths, mn is the number of matched n-grams (potentially clipped), and cn is the number of n-grams in all candidates. Given a distribution over candidates, we can use the expected value of the log of the BLEU score. This is a smooth approximation to the BLEU score, which as</context>
<context position="21009" citStr="Smith and Eisner (2006)" startWordPosition="3573" endWordPosition="3576">log mn − log cn) N n=1 n=1 where E is the expectation operator using the probability distribution P(h; w, µ). First we note that the gradient ∂ ∂wi P(h; w, µ) is 1952 In the case of `2-regularized MERT, the final gradient also includes the partial derivative of the regularization penalty of Equation 4, which is wi/a2 for a given component i of the gradient. We do not update the gradient in the case of t0 regularization since the `0-norm is not differentiable. 4.2 Search Our search strategy consists of looking at the directions of steepest increase of expected BLEU, which is similar to that of Smith and Eisner (2006), but with the difference that we do so in the context of MERT. We think this difference provides two benefits. First, while the smooth approximation of BLEU reduces the likelihood of remaining trapped in a local optimum, we avoid approximation error by retaining the original objective function. Second, the benefit of exact line searches in MERT is that there is no need to be concerned about step size, since step size in MERT line searches is guaranteed to be optimal with respect to the direction under consideration. Finally, our gradient-based search algorithm operates as follows. Considering</context>
<context position="39598" citStr="Smith and Eisner, 2006" startWordPosition="6674" endWordPosition="6677">e research is devoted to the problem of finding good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 20</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>David A. Smith and Jason Eisner. 2006. Minimum risk annealing for training log-linear models. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 787–794.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Byung-Gyu Ahn</author>
</authors>
<title>Learning non-linear features for machine translation using gradient boosting machines.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>406--411</pages>
<contexts>
<context position="27415" citStr="Toutanova and Ahn, 2013" startWordPosition="4630" endWordPosition="4633">ector h,,,,,. By this linear construction, w* is guaranteed to be a global optimum.7 The pseudo-BLEU score is normalized for each M-best list, so that the translation with highest model score according to w* has a BLEU score of 1, and so that the translation with lowest model score for the sentence gets a BLEU of zero. This normalization has no impact on search, but makes results more interpretable. For our translation experiments, we use multistack phrase-based decoding (Koehn et al., 2007). We report results for two feature sets: non-linear features induced using Gradient Boosting Machines (Toutanova and Ahn, 2013) and sparse lexicalized 7The objective function remains piecewise constant, and the plateau containing w* maps to the optimal value of the function. reordering features (Cherry, 2013). We exploit these feature sets (GBM and SparseHRM, respectively) in two distinct experimental conditions, which we detail in the two next paragraphs. Both GBM and SparseHRM augment baseline features similar to Moses’: relative frequency and lexicalized phrase translation scores for both translation directions; one or two language model features, depending on the language pair; distortion penalty; word and phrase </context>
<context position="28815" citStr="Toutanova and Ahn, 2013" startWordPosition="4845" endWordPosition="4848">ed the training set (Train) for extracting phrase tables and language models; the Tune set for optimization with MERT or PRO; the Dev set for selecting hyperparameters of PRO and regularized MERT; and the Test set for reporting final results. In each experimental condition, we first trained weights for the base feature sets, and then decoded the Tune, Dev, and Test datasets, generating 500-best lists for each set. All results report reranking performance on these lists with different feature sets and optimization methods, based on lower-cased BLEU (Papineni et al., 2001). The GBM feature set (Toutanova and Ahn, 2013) consists of about 230 features automatically induced using decision tree weak learners, which derive features using various word-level, phrase-level, and morphological attributes. For Chinese-English, the training corpus consists of approximately one million sentence pairs from the FBIS and Hong Kong portions of the LDC data for the NIST MT evaluation and the Tune and Test sets are from NIST competitions. A 4-gram language model was trained on the Xinhua portion of the English Gigaword corpus and on the target side of the bitext. For Finnish-English we used a dataset from a technical domain o</context>
</contexts>
<marker>Toutanova, Ahn, 2013</marker>
<rawString>Kristina Toutanova and Byung-Gyu Ahn. 2013. Learning non-linear features for machine translation using gradient boosting machines. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 406–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Jun Suzuki</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
</authors>
<title>Online large-margin training for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL),</booktitle>
<pages>764--773</pages>
<contexts>
<context position="39641" citStr="Watanabe et al., 2007" startWordPosition="6682" endWordPosition="6686">ing good initializers.10 In the case of word alignment, it is common practice to initialize search in non-convex optimization problems—such as IBM Model 3 and 4 (Brown et al., 1993)—with solutions of simpler models—such as IBM Model 1. 7 Related work MERT and its extensions have been the target of extensive research (Och, 2003; Macherey et al., 2008; Cer et al., 2008; Moore and Quirk, 2008; Kumar et al., 2009; Galley and Quirk, 2011). More recent work has focused on replacing MERT with a linearly decomposable approximations of the evaluation metric (Smith and Eisner, 2006; Liang et al., 2006; Watanabe et al., 2007; Chiang et al., 2008; Hopkins and May, 2011; Rosti et al., 2011; Gimpel and Smith, 2012; Cherry and Foster, 2012), which generally involve a surrogate loss function incorporating a regularization term such as the `2-norm. While we are not aware of any previous work adding a penalty on 10For example, (Larochelle et al., 2009) presents a pre-trained DNN that outperforms a shallow network, but the performance of the DNN becomes much worse relative to the shallow network once pre-training is turned off. the weights in the context of MERT, (Cer et al., 2008) achieves a related effect. Cer et al.’s</context>
</contexts>
<marker>Watanabe, Suzuki, Tsukada, Isozaki, 2007</marker>
<rawString>Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki Isozaki. 2007. Online large-margin training for statistical machine translation. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL), pages 764–773.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>