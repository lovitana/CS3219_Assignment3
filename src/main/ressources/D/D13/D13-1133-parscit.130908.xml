<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007486">
<title confidence="0.9993025">
Using Topic Modeling to Improve Prediction of Neuroticism and Depression
in College Students
</title>
<author confidence="0.99811">
Philip Resnik
</author>
<affiliation confidence="0.998884">
University of Maryland
</affiliation>
<address confidence="0.946744">
College Park, MD 20742
</address>
<email confidence="0.999321">
resnik@umd.edu
</email>
<author confidence="0.996019">
Anderson Garron
</author>
<affiliation confidence="0.998601">
University of Maryland
</affiliation>
<address confidence="0.946735">
College Park, MD 20742
</address>
<email confidence="0.999211">
agarron@cs.umd.edu
</email>
<author confidence="0.953104">
Rebecca Resnik
</author>
<affiliation confidence="0.946399">
Mindwell Psychology Bethesda
</affiliation>
<address confidence="0.88729">
5602 Shields Drive
Bethesda, MD 20817
</address>
<email confidence="0.998148">
drrebeccaresnik@gmail.com
</email>
<sectionHeader confidence="0.995622" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998214">
We investigate the value-add of topic model-
ing in text analysis for depression, and for neu-
roticism as a strongly associated personality
measure. Using Pennebaker’s Linguistic In-
quiry and Word Count (LIWC) lexicon to pro-
vide baseline features, we show that straight-
forward topic modeling using Latent Dirich-
let Allocation (LDA) yields interpretable, psy-
chologically relevant “themes” that add value
in prediction of clinical assessments.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999347052631579">
In the United States, where 25 million adults per
year suffer a major depressive episode (NAMI,
2013), identifying people with mental health prob-
lems is a key challenge. For clinical psychologists,
language plays a central role in diagnosis: many
clinical instruments fundamentally rely on what is,
in effect, manual coding of patient language. Au-
tomating language assessment in this domain poten-
tially has enormous impact, for two reasons. First,
conventional clinical assessments for affective dis-
orders (e.g. The Minnesota Multiphasic Personal-
ity Inventory, MMPI) are based on norm-referenced
self-report, and therefore depend on patients’ will-
ingness and ability to report symptoms. However,
some individuals are motivated to underreport symp-
toms to avoid negative consequences (e.g. active
duty soldiers, parents undergoing child custody eval-
uations), and others lack the self awareness to report
accurately.1 Second, many people – e.g. those with-
</bodyText>
<footnote confidence="0.9228575">
1As evidenced by the fact that assessments such as the MMPI-2-
RF include validity scales to detect, e.g., defensiveness, atyp-
</footnote>
<bodyText confidence="0.999253629629629">
out adequate insurance or in rural areas – cannot ac-
cess a clinician qualified to perform a psychological
evaluation (Sibelius, 2013; APA, 2013). There is
enormous value in inexpensive screening measures
that could be administered in primary care and by
social workers and other providers.
We take as a starting point the well known
lexicon-driven methods of Pennebaker and col-
leagues (LIWC, Pennebaker and King (1999)),
which relate language use to psychological vari-
ables, and improve on them straightforwardly using
topic modeling (LDA, Blei et al. (2003)). First, we
show that taking automatically derived topics into
account improves prediction of neuroticism (emo-
tional instability, John and Srivastava (1999)), as
measured by correlation with widely used clinical
instruments, when compared with lexically-based
prediction alone. Neuroticism is of particular inter-
est as a personality measure because higher scores
on neuroticism scales are consistent with increased
distress and more difficulty coping; individuals with
high levels of neuroticism may also be at higher risk
of psychiatric problems categorized as Axis I in the
DSM-IV (Association, 2000), including the inter-
nalizing disorders (depression, anxiety).2 Second,
we show a similar correlation improvement result
for prediction of depression, adding improvement
</bodyText>
<footnote confidence="0.97287975">
ical responses, and overly positive self-portrayals (Tellegen et
al., 2003).
2The Diagnostic and Statistical Manual of Mental Disorders is a
widely used organization of mental health conditions; it served
as the standard for diagnosis from 1994 until the release of
the (quite controversial) DSM-5 in May, 2013. Axis I in the
DSM-IV includes all the major diagnostic categories, exclud-
ing mental retardation and personality disorders.
</footnote>
<page confidence="0.944186">
1348
</page>
<bodyText confidence="0.884997">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1348–1353,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
on precision (with no decrease in recall), as well
as comparison with human performance by clinical
psychologists. Third, we show that LDA has iden-
tified meaningful, population-specific themes that
go beyond the pre-defined LIWC categories and are
psychologically relevant.
</bodyText>
<sectionHeader confidence="0.596117" genericHeader="method">
2 Predicting neuroticism
</sectionHeader>
<subsectionHeader confidence="0.896344">
2.1 Experimental framework
</subsectionHeader>
<bodyText confidence="0.999950070175439">
Data. We utilize a collection of 6,459 stream-of-
consciousness essays collected from college stu-
dents by Pennebaker and King (1999) between 1997
and 2008, averaging approximately 780 words each.
Students were asked to think about their thoughts,
sensations, and feelings in the moment and “write
your thoughts as they come to you”.
Each essay is accompanied by metadata for its
author, which includes scores for the Big-5 person-
ality traits (John and Srivastava, 1999): agreeable-
ness, conscientiousness, extraversion, neuroticism,
and openness. Because Big-5 assessment can be
done using a variety of different survey instruments
(John et al., 2008), and different instruments were
used from year to year, we treat the data from each
year as an independent dataset.
Any author missing any Big-5 attribute was ex-
cluded. Essays were tokenized using NLTK (Bird
et al., 2009) and lowercased, eliminating those that
failed tokenization because of encoding issues. This
resulted in a dataset containing 4,777 essays with as-
sociated Big-5 metadata.
LIWC features. For each document, we calcu-
late the number of observed words in each of Pen-
nebaker and King’s 64 LIWC categories. These in-
clude, among others, syntactic categories (e.g. pro-
nouns, verbs), affect categories (e.g. negative emo-
tion words, anger words), semantic categories (e.g.
causation words, cognitive words), and topical cat-
egories (e.g. health, religion). For instance, the
anger category contains 190 word patterns specify-
ing, for example, words descriptive of contexts in-
volving anger (e.g. brutal, hostile, shoot) and words
that would be used by someone when angry (e.g.
bullshit, hate, moron). We also explored includ-
ing essays’ average sentence length and total word-
count, as an initial proxy for language complexity,
which often figures into psychological assessments.
However, results adding these features to LIWC did
not differ significantly from LIWC alone, and for
brevity we do not report them.3
LDA features. We use vanilla LDA as imple-
mented in the Mallet toolkit (McCallum, 2002), de-
veloping a k-topic model on just training documents,
and using the posterior topic distribution for each
training and test document as a set of k features.
Mallet’s stoplist and default parameters were used
for burn-in, lag, number of iterations, priors, etc.
Details on train/test splits and number k of topics
appear below.
LIWC+LDA features. The union of the LIWC
features (one feature per category) and LDA features
(one feature per topic).
Prediction. We utilize linear regression in the
WEKA toolkit (Hall et al., 2009), estimated on train-
ing documents, to predict the neuroticism score as-
sociated with the author of each test document.4
</bodyText>
<subsectionHeader confidence="0.852474">
2.2 Results
</subsectionHeader>
<bodyText confidence="0.9999841875">
Table 1 shows the quality of prediction via linear
regression, averaged over the eleven datasets, 1997
through 2008, using Pearson correlation (r) as the
evaluation metric. For each year, we used 10-fold
cross-validation to ensure proper separation of train-
ing and test data. We experimented with LDA us-
ing 20, 30, 40, and 50 topics.5
A first thing to observe is that the multiple re-
gressions using all LIWC categories produce much
stronger correlations with neuroticism than the indi-
vidual category correlations reported by Pennebaker
and King.6 There the strongest individual corre-
lations with neuroticism for any LIWC categories
are .16 (negative emotion words) and -.13 (positive
emotion words), though it should be noted that their
goal was to validate their categories as a meaningful
</bodyText>
<footnote confidence="0.993128818181818">
3Using richer measures of complexity, e.g. Pakhomov et al.
(2011), is a topic for future work.
4In previous work we have found that multiple linear regression
is competitive with more complicated techniques such as SVM
regression, though we plan to explore the latter in future work.
5Full year-by-year data appears in supplemental materi-
als at http://umiacs.umd.edu/˜resnik/papers/
emnlp2013-supplemental/.
6The comparison is not perfect, since they used Big-5 data col-
lected between 1993 and 1998, and we also eliminated some
files during preprocessing.
</footnote>
<page confidence="0.983945">
1349
</page>
<table confidence="0.785273">
Feature set LIWC LDA20 LIWC+LDA20 LDA30 LIWC+LDA30 LDA40 LIWC+LDA40 LDA50 LIWC+LDA50
Average r 0.413 0.384 0.430 0.407 0.442* 0.420 0.459** 0.440 0.443*
</table>
<tableCaption confidence="0.999391">
Table 1: Prediction quality for neuroticism, for alternative feature sets (Pearson’s r). *p&lt; .03, **p &lt; .02
</tableCaption>
<bodyText confidence="0.999864777777778">
way to explore personality differences, not predic-
tion.
As noted in Table 1, paired t-tests (df=10, α =
.05) establish that, in comparing the cross-year av-
erages, augmenting LIWC with topic features im-
proves average correlation significantly over using
LIWC features alone for 30, 40, and 50 topics.
LDA features alone do not improve significantly
over LIWC.
</bodyText>
<sectionHeader confidence="0.978313" genericHeader="method">
3 Predicting Depression
</sectionHeader>
<subsectionHeader confidence="0.960998">
3.1 Experimental framework
</subsectionHeader>
<bodyText confidence="0.989468565217391">
Data. We use essays collected by Rude et al.
(2004) similarly to §2.1; in this case, students were
asked to “describe your deepest thoughts and feel-
ings about being in college”. Each essay is accom-
panied by the author’s Beck Depression Inventory
score (BDI). BDI (Beck et al., 1961) is a widely
used 21-question instrument that correlates strongly
with ratings of depression by psychiatrists. Follow-
ing Rude et al., we treat BDI &gt; 14 as the threshold
for a positive instance of depression.7 Text prepro-
cessing was done as in §2.1, with 124 documents in
total averaging around 390 words each.
Training/test split. Because only 12 of 124 au-
thors met the BDI &gt; 14 threshold, we did not split
randomly, lest the test sample include too few pos-
itive instances to be useful. Instead we included a
random 6 of the 12 above-threshold cases, plus 24
more items sampled at random, to create a 30-item
test set. To form the training set from the comple-
mentary items, we added two more copies of each
positive instance to help address class imbalance
(Batista et al., 2004) and, following Rude et al., we
excluded items with with BDI of 0 or 1 as potentially
invalid.
Human comparison. We created a set of expert
human results for comparison by asking three prac-
ticing clinical psychologists to review the test doc-
uments and rate whether or not the author is suffer-
7Each question contributes a score value from 0 to 3, so BDI
scores range from 0 to 63.
ing depression.8 They were asked to “decide how
at-risk this person might be for depression”, assign-
ing 0 (no significant concerns), 1 (mild concerns, but
does not require futher evaluation), or 2 (requires at-
tention, refer for further evaluation). Following rec-
ommended practice for cases where different labels
are not equally distinct from each other (Artstein
and Poesio, 2008), we evaluate inter-coder agree-
ment using Krippendorff’s α; our α, computed for
ordinal data, is 0.722.
Features. We ran 50-topic LDA on the 4,777 es-
says from §2.1 plus the BDI training items, using the
posterior topic distributions as features as in §2.1.
As in §2.1, the LIWC features comprised one count
per LIWC category, and LIWC+LDA features were
the union of the two.
</bodyText>
<subsectionHeader confidence="0.836665">
3.2 Results
</subsectionHeader>
<bodyText confidence="0.99388408">
Regression on LIWC features alone achieved r =
.288, and adding topic features improved this sub-
stantially to r = .416. Treating BDI &gt; 14 as the
threshold for positive instances (i.e. that an author is
depressed), Table 2 shows that adding topic features
improves precision without harming recall. Auto-
matic prediction is more conservative than human
ratings, trading recall for precision to achieve com-
parable F-measure on this test set.9
8These psychologists all have doctoral degrees, are licensed,
and spend significant time primarily in assessment and diag-
nosis of psychological disorders. None were familiar with the
specifics of this study.
9A reviewer observes, correctly, that in a scenario where a sys-
tem is providing preliminary screenings to aid psychologists,
the precision/recall tradeoff demonstrated here would poten-
tially be undesirable, since a presumed goal would be to not
miss any cases, even at the risk of some false positives. We
note, however, that the real world is unfortunately replete with
situations where there is significant cost or social/professional
stigma associated with interventions or follow-up testing; in
such situations it might be high precision that is desirable.
These are challenging questions, and the ability to trade off
precision versus recall more flexibly is a topic we are inter-
ested in investigating in future work.
</bodyText>
<page confidence="0.969607">
1350
</page>
<table confidence="0.999688833333333">
P R F1
LIWC .43 .50 .46
LIWC+LDA .50 .50 .50
Rater 1 .38 .83 .52
Rater 2 .33 .83 .47
Rater 3 .33 .66 .44
</table>
<tableCaption confidence="0.999007">
Table 2: Prediction quality for depression.
</tableCaption>
<sectionHeader confidence="0.986008" genericHeader="method">
4 Qualitative themes
</sectionHeader>
<bodyText confidence="0.9999955">
In order to explore the relevance of the themes
uncovered by LDA, the third author, a practicing
clinical psychologist, reviewed the 50 LDA cate-
gories created in §3.1. Each category, represented
by its 20 highest-probability words, was given a
readable description. Then, for each category, she
was asked: “If you were conducting a clinical in-
terview, would observing these themes in a patient’s
responses make you more (less) likely to feel that the
patient merited further evaluation for depression?”
Table 3 shows the seven topics selected as par-
ticularly indicative of further evaluation.10 These
capture population-specific properties in ways that
LIWC cannot — for example, although LIWC does
have a body category, it does not have a category
that corresponds to somatic complaints, which often
co-occur with depression. Similarly, some words re-
lated to energy level, e.g. tired, would be captured
in LIWC’s body, bio, and/or health category, but
the LDA theme corresponding to low energy or lack
of sleep, another potential depression cue, contains
words that make sense there only in context (e.g. to-
morrow, late). Other themes, such as the one labeled
HOMESICKNESS, are clearly relevant (potentially in-
dicative of an adjustment disorder), but even more
specific to the population and context.
</bodyText>
<sectionHeader confidence="0.999943" genericHeader="evaluation">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999681428571429">
The application of NLP to psychological variables
has seen a recent uptick in community activity. One
recent shared task brings together research on the
Big-5 personality traits (Celli et al., 2013; Kosin-
ski et al., 2013), and another involved research on
identification of emotion in suicide notes (Pestian et
al., 2012). Other examples include NLP research on
</bodyText>
<footnote confidence="0.745162333333333">
10All 50 can be found in the supplemental materials at
http://umiacs.umd.edu/˜resnik/papers/
emnlp2013-supplemental/.
</footnote>
<bodyText confidence="0.984031444444444">
autistic spectrum disorders (Van Santen et al., 2010;
Prudhommeaux et al., 2011; Lehr et al., 2013) and
dementia (Pakhomov et al., 2011; Lehr et al., 2012;
Roark et al., 2011).
With regard to depression, Neuman et al. (2012)
develop a corpus-based “depression lexicon” and
produce promising screening results, and De Choud-
hury et al. (2013) predict social network behav-
ior changes related to post-partum depression. Nei-
ther, however, evaluates using formal instruments
for clinical assessment.
Related investigations involving LDA include
Zhai et al. (2012), who use LIWC to provide pri-
ors for corpus-specific emotion categories; Stark et
al. (2012), who combine LIWC and LDA-based
features in classification of social relationships; and
Schwartz et al. (2013), who use lexical and topic-
based features in Twitter to predict life satisfaction.
</bodyText>
<sectionHeader confidence="0.99836" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999923277777778">
In this paper, we have aimed for a small, fo-
cused contribution, investigating the value-add of
topic modeling in text analysis for depression, and
for neuroticism as a strongly associated personal-
ity measure. Our contribution here is not techni-
cal: corpus-specific topics/themes are anticipated by
Zhai et al. (2012), and Stark et al. (2012) employ
topic-based features for prediction in a supervised
setting. Rather, our contribution here has been to
show that topic models can get us beyond the LIWC
categories to relevant, population-specific themes
related to neuroticism and depression, and to sup-
port that claim using evaluation against formal clin-
ical assessments. More data (e.g. Kosinski et al.
(2013)) and more sophisticated models (e.g. super-
vised LDA, Blei and McAuliffe (2008), and exten-
sions such as Nguyen et al. (2013)) will be the key
to further progress.
</bodyText>
<sectionHeader confidence="0.989775" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998655">
We are grateful to Jamie Pennebaker for the LIWC
lexicon and for allowing us to use data from Pen-
nebaker and King (1999) and Rude et al. (2004),
to the three psychologists who kindly took the time
to provide human ratings, and to our reviewers for
helpful comments. This work has been supported in
part by NSF grant IIS-1211153.
</bodyText>
<page confidence="0.961535">
1351
</page>
<table confidence="0.998298636363636">
VEGETATIVE/ENERGY LEVEL sleep tired night bed morning class early tomorrow wake late asleep long hours day sleeping nap today fall stay
time
SOMATIC hurts sick eyes hurt cold head tired back nose itches hate stop starting water neck hand stomach feels kind sore
NEGATIVE/TROUBLE COPING don(’t) hate doesn care didn(’t) understand anymore feel isn(’t) stupid make won(’t) wouldn talk scared wanted
wrong mad stop shouldn(’t)
ANGER/FRUSTRATION hate damn stupid sucks hell shit crap man ass god don blah thing bad suck doesn fucking fuck freaking real
HOMESICKNESS home miss friends back school family weekend austin parents college mom lot boyfriend left houston visit weeks
wait high homesick
EMOTIONAL STRESS feel feeling thinking makes make felt feels things nervous scared lonely feelings afraid moment happy worry
comfortable stress excited guilty
ANXIETY feel happy things lot sad good makes bad make hard mind happen crazy cry day worry times talk great wanted
</table>
<tableCaption confidence="0.999738">
Table 3: LDA-induced themes related to depression.
</tableCaption>
<sectionHeader confidence="0.966446" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.968121779220779">
[APA2013] APA. 2013. The critical
need for psychologists in rural america.
http://www.apa.org/about/gr/education/rural-
need.aspx, Downloaded September 16, 2013.
[Artstein and Poesio2008] Ron Artstein and Massimo
Poesio. 2008. Inter-coder agreement for computa-
tional linguistics. Comput. Linguist., 34(4):555–596,
December.
[Association2000] American Psychiatric Association.
2000. Diagnostic and Statistical Manual of Mental
Disorders, 4th Edition, Text Revision (DSM-IV-TR).
American Psychiatric Association, 4th edition, July.
[Batista et al.2004] Gustavo E. A. P. A. Batista,
Ronaldo C. Prati, and Maria Carolina Monard.
2004. A study of the behavior of several methods for
balancing machine learning training data. SIGKDD
Explor. Newsl., 6(1):20–29, June.
[Becket al.1961] Aaron T Beck, Calvin H Ward, Mock
Mendelson, Jeremiah Mock, and J1 Erbaugh. 1961.
An inventory for measuring depression. Archives of
general psychiatry, 4(6):561.
[Bird et al.2009] Steven Bird, Ewan Klein, and Edward
Loper. 2009. Natural language processing with
Python. O’Reilly.
[Blei and McAuliffe2008] David Blei and Jon McAuliffe.
2008. Supervised topic models. In J.C. Platt,
D. Koller, Y. Singer, and S. Roweis, editors, Advances
in Neural Information Processing Systems 20, pages
121–128. MIT Press, Cambridge, MA.
[Blei et al.2003] David M Blei, Andrew Y Ng, and
Michael I Jordan. 2003. Latent dirichlet allocation.
The Journal of Machine Learning Research, 3:993–
1022.
[Celli et al.2013] Fabio Celli, Fabio Pianesi, David Still-
well, and Michal Kosinski. 2013. Computational per-
sonality recognition (shared task) workshop. In In-
ternational Conference on Weblogs and Social Media.
AAAI.
[De Choudhury et al.2013] Munmun De Choudhury,
Scott Counts, and Eric Horvitz. 2013. Predicting
postpartum changes in emotion and behavior via
social media. In Proceedings of the 2013 ACM annual
conference on Human factors in computing systems,
pages 3267–3276. ACM.
[Hall et al.2009] Mark Hall, Eibe Frank, Geoffrey
Holmes, Bernhard Pfahringer, Peter Reutemann, and
Ian H Witten. 2009. The weka data mining software:
an update. ACM SIGKDD Explorations Newsletter,
11(1):10–18.
[John and Srivastava1999] Oliver P John and Sanjay Sri-
vastava. 1999. The big five trait taxonomy: History,
measurement, and theoretical perspectives. Handbook
ofpersonality: Theory and research, 2:102–138.
[John et al.2008] O. P. John, L. P. Naumann, and C. J.
Soto. 2008. Paradigm shift to the integrative big five
trait taxonomy: History, measurement, and conceptual
issues. In Handbook of personality: Theory and re-
search, pages 114–158.
[Kosinski et al.2013] Michal Kosinski, David Stillwell,
and Thore Graepel. 2013. Private traits and attributes
are predictable from digital records of human behav-
ior. Proceedings of the National Academy of Sciences,
110(15):5802–5805.
[Lehr et al.2012] Maider Lehr, Emily Tucker
Prud’hommeaux, Izhak Shafran, and Brian Roark.
2012. Fully automated neuropsychological assess-
ment for detecting mild cognitive impairment. In
INTERSPEECH.
[Lehr et al.2013] Maider Lehr, Izhak Shafran, Emily
Prudhommeaux, and Brian Roark. 2013. Discrimi-
native joint modeling of lexical variation and acous-
tic confusion for automated narrative retelling assess-
ment. In Proceedings of NAACL-HLT, pages 211–220.
[McCallum2002] Andrew Kachites McCallum. 2002.
Mallet: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
[NAMI2013] NAMI. 2013. Ma-
</reference>
<bodyText confidence="0.4931846">
jor depression fact sheet, April.
http://www.nami.org/Template.cfm?Section=depression.
[Neuman et al.2012] Yair Neuman, Yohai Cohen, Dan
Assaf, and Gabbi Kedma. 2012. Proactive screen-
ing for depression through metaphorical and automatic
</bodyText>
<page confidence="0.970277">
1352
</page>
<reference confidence="0.99861436231884">
text analysis. Artif. Intell. Med., 56(1):19–25, Septem-
ber.
[Nguyen et al.2013] Viet-An Nguyen, Jordan Boyd-
Graber, and Philip Resnik. 2013. Lexical and
hierarchical topic regression. In Neural Information
Processing Systems.
[Pakhomov et al.2011] Serguei Pakhomov, Dustin Cha-
con, Mark Wicklund, and Jeanette Gundel. 2011.
Computerized assessment of syntactic complexity in
alzheimers disease: a case study of iris murdochs writ-
ing. Behavior Research Methods, 43(1):136–144.
[Pennebaker and King1999] James W Pennebaker and
Laura A King. 1999. Linguistic styles: language use
as an individual difference. Journal ofpersonality and
social psychology, 77(6):1296.
[Pestian et al.2012] John P Pestian, Pawel Matykiewicz,
Michelle Linn-Gust, Brett South, Ozlem Uzuner, Jan
Wiebe, K Bretonnel Cohen, John Hurdle, Christopher
Brew, et al. 2012. Sentiment analysis of suicide
notes: A shared task. Biomedical Informatics Insights,
5(Suppl. 1):3.
[Prudhommeaux et al.2011] Emily T Prudhommeaux,
Brian Roark, Lois M Black, and Jan van Santen.
2011. Classification of atypical language in autism.
ACL HLT 2011, page 88.
[Roark et al.2011] Brian Roark, Margaret Mitchell, J Ho-
som, Kristy Hollingshead, and Jeffrey Kaye. 2011.
Spoken language derived measures for detecting mild
cognitive impairment. Audio, Speech, and Language
Processing, IEEE Transactions on, 19(7):2081–2090.
[Rude et al.2004] Stephanie Rude, Eva-Maria Gortner,
and James Pennebaker. 2004. Language use of de-
pressed and depression-vulnerable college students.
Cognition &amp; Emotion, 18(8):1121–1133.
[Schwartz et al.2013] H. Andrew Schwartz, Johannes C.
Eichstaedt, Margaret L. Kern, Lukasz Dziurzynski,
Megha Agrawal, Gregory J. Park, Shrinidhi K. Lak-
shmikanth, Sneha Jha, Martin E. P. Seligman, and
Lyle Ungar. 2013. Characterizing geographic varia-
tion in well-being using tweets. In Seventh Interna-
tional AAAI Conference on Weblogs and Social Media
(ICWSM 2013).
[Sibelius2013] Kathleen Sibelius. 2013. Increas-
ing access to mental health services, April.
http://www.whitehouse.gov/blog/2013/04/10/increasing-
access-mental-health-services.
[Stark et al.2012] Anthony Stark, Izhak Shafran, and Jef-
frey Kaye. 2012. Hello, who is calling?: can words
reveal the social nature of conversations? In Proceed-
ings of the 2012 Conference of the North American
Chapter of the Association for Computational Linguis-
tics: Human Language Technologies, pages 112–119.
Association for Computational Linguistics.
[Tellegen et al.2003] A. Tellegen, Y.S. Ben-Porath, J.L.
McNulty, P.A. Arbisi, and B. Graham, J.R.and Kaem-
mer. 2003. The MMPI-2 Restructured Clinical
Scales: Development, validation, and interpretation.
Minneapolis, MN: University of Minnesota Press.
[Van Santen et al.2010] Jan PH Van Santen, Emily T
Prud’hommeaux, Lois M Black, and Margaret
Mitchell. 2010. Computational prosodic markers for
autism. Autism, 14(3):215–236.
[Zhai et al.2012] Ke Zhai, Jordan Boyd-Graber, Nima
Asadi, and Mohamad L. Alkhouja. 2012. Mr. lda:
a flexible large scale topic modeling package using
variational inference in mapreduce. In Proceedings of
the 21st international conference on World Wide Web,
WWW ’12, pages 879–888, New York, NY, USA.
ACM.
</reference>
<page confidence="0.979063">
1353
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.370748">
<title confidence="0.998833">Using Topic Modeling to Improve Prediction of Neuroticism and Depression in College Students</title>
<author confidence="0.994262">Philip</author>
<affiliation confidence="0.9997">University of</affiliation>
<address confidence="0.985584">College Park, MD</address>
<email confidence="0.999249">resnik@umd.edu</email>
<author confidence="0.780698">Anderson</author>
<affiliation confidence="0.999127">University of</affiliation>
<address confidence="0.981883">College Park, MD</address>
<email confidence="0.99641">agarron@cs.umd.edu</email>
<author confidence="0.524431">Rebecca</author>
<affiliation confidence="0.968221">Mindwell Psychology</affiliation>
<address confidence="0.9908085">5602 Shields Bethesda, MD</address>
<email confidence="0.999611">drrebeccaresnik@gmail.com</email>
<abstract confidence="0.999043454545455">We investigate the value-add of topic modeling in text analysis for depression, and for neuroticism as a strongly associated personality measure. Using Pennebaker’s Linguistic Inquiry and Word Count (LIWC) lexicon to provide baseline features, we show that straightforward topic modeling using Latent Dirichlet Allocation (LDA) yields interpretable, psychologically relevant “themes” that add value in prediction of clinical assessments.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>APA</author>
</authors>
<title>The critical need for psychologists in rural america. http://www.apa.org/about/gr/education/ruralneed.aspx,</title>
<date>2013</date>
<location>Downloaded</location>
<marker>[APA2013]</marker>
<rawString>APA. 2013. The critical need for psychologists in rural america. http://www.apa.org/about/gr/education/ruralneed.aspx, Downloaded September 16, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ron Artstein</author>
<author>Massimo Poesio</author>
</authors>
<title>Inter-coder agreement for computational linguistics.</title>
<date>2008</date>
<journal>Comput. Linguist.,</journal>
<volume>34</volume>
<issue>4</issue>
<marker>[Artstein and Poesio2008]</marker>
<rawString>Ron Artstein and Massimo Poesio. 2008. Inter-coder agreement for computational linguistics. Comput. Linguist., 34(4):555–596, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>American Psychiatric Association</author>
</authors>
<date>2000</date>
<booktitle>Diagnostic and Statistical Manual of Mental Disorders, 4th Edition, Text Revision (DSM-IV-TR). American Psychiatric Association, 4th edition,</booktitle>
<marker>[Association2000]</marker>
<rawString>American Psychiatric Association. 2000. Diagnostic and Statistical Manual of Mental Disorders, 4th Edition, Text Revision (DSM-IV-TR). American Psychiatric Association, 4th edition, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gustavo E A P A Batista</author>
<author>Ronaldo C Prati</author>
<author>Maria Carolina Monard</author>
</authors>
<title>A study of the behavior of several methods for balancing machine learning training data.</title>
<date>2004</date>
<journal>SIGKDD Explor. Newsl.,</journal>
<volume>6</volume>
<issue>1</issue>
<marker>[Batista et al.2004]</marker>
<rawString>Gustavo E. A. P. A. Batista, Ronaldo C. Prati, and Maria Carolina Monard. 2004. A study of the behavior of several methods for balancing machine learning training data. SIGKDD Explor. Newsl., 6(1):20–29, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aaron T Beck</author>
<author>Calvin H Ward</author>
<author>Mock Mendelson</author>
<author>Jeremiah Mock</author>
<author>J1 Erbaugh</author>
</authors>
<title>An inventory for measuring depression. Archives of general psychiatry,</title>
<date>1961</date>
<pages>4--6</pages>
<marker>[Becket al.1961]</marker>
<rawString>Aaron T Beck, Calvin H Ward, Mock Mendelson, Jeremiah Mock, and J1 Erbaugh. 1961. An inventory for measuring depression. Archives of general psychiatry, 4(6):561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bird</author>
<author>Ewan Klein</author>
<author>Edward Loper</author>
</authors>
<title>Natural language processing with Python.</title>
<date>2009</date>
<tech>O’Reilly.</tech>
<marker>[Bird et al.2009]</marker>
<rawString>Steven Bird, Ewan Klein, and Edward Loper. 2009. Natural language processing with Python. O’Reilly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Jon McAuliffe</author>
</authors>
<title>Supervised topic models.</title>
<date>2008</date>
<booktitle>Advances in Neural Information Processing Systems 20,</booktitle>
<pages>121--128</pages>
<editor>In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>[Blei and McAuliffe2008]</marker>
<rawString>David Blei and Jon McAuliffe. 2008. Supervised topic models. In J.C. Platt, D. Koller, Y. Singer, and S. Roweis, editors, Advances in Neural Information Processing Systems 20, pages 121–128. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research,</journal>
<volume>3</volume>
<pages>1022</pages>
<marker>[Blei et al.2003]</marker>
<rawString>David M Blei, Andrew Y Ng, and Michael I Jordan. 2003. Latent dirichlet allocation. The Journal of Machine Learning Research, 3:993– 1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabio Celli</author>
<author>Fabio Pianesi</author>
<author>David Stillwell</author>
<author>Michal Kosinski</author>
</authors>
<title>Computational personality recognition (shared task) workshop.</title>
<date>2013</date>
<booktitle>In International Conference on Weblogs and Social Media.</booktitle>
<publisher>AAAI.</publisher>
<marker>[Celli et al.2013]</marker>
<rawString>Fabio Celli, Fabio Pianesi, David Stillwell, and Michal Kosinski. 2013. Computational personality recognition (shared task) workshop. In International Conference on Weblogs and Social Media. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Munmun De Choudhury</author>
<author>Scott Counts</author>
<author>Eric Horvitz</author>
</authors>
<title>Predicting postpartum changes in emotion and behavior via social media.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 ACM annual conference on Human factors in computing systems,</booktitle>
<pages>3267--3276</pages>
<publisher>ACM.</publisher>
<marker>[De Choudhury et al.2013]</marker>
<rawString>Munmun De Choudhury, Scott Counts, and Eric Horvitz. 2013. Predicting postpartum changes in emotion and behavior via social media. In Proceedings of the 2013 ACM annual conference on Human factors in computing systems, pages 3267–3276. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: an update.</title>
<date>2009</date>
<journal>ACM SIGKDD Explorations Newsletter,</journal>
<volume>11</volume>
<issue>1</issue>
<marker>[Hall et al.2009]</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H Witten. 2009. The weka data mining software: an update. ACM SIGKDD Explorations Newsletter, 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver P John</author>
<author>Sanjay Srivastava</author>
</authors>
<title>The big five trait taxonomy: History, measurement, and theoretical perspectives. Handbook ofpersonality: Theory and research,</title>
<date>1999</date>
<pages>2--102</pages>
<marker>[John and Srivastava1999]</marker>
<rawString>Oliver P John and Sanjay Srivastava. 1999. The big five trait taxonomy: History, measurement, and theoretical perspectives. Handbook ofpersonality: Theory and research, 2:102–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O P John</author>
<author>L P Naumann</author>
<author>C J Soto</author>
</authors>
<title>Paradigm shift to the integrative big five trait taxonomy: History, measurement, and conceptual issues.</title>
<date>2008</date>
<booktitle>In Handbook of personality: Theory and research,</booktitle>
<pages>114--158</pages>
<marker>[John et al.2008]</marker>
<rawString>O. P. John, L. P. Naumann, and C. J. Soto. 2008. Paradigm shift to the integrative big five trait taxonomy: History, measurement, and conceptual issues. In Handbook of personality: Theory and research, pages 114–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michal Kosinski</author>
<author>David Stillwell</author>
<author>Thore Graepel</author>
</authors>
<title>Private traits and attributes are predictable from digital records of human behavior.</title>
<date>2013</date>
<booktitle>Proceedings of the National Academy of Sciences,</booktitle>
<volume>110</volume>
<issue>15</issue>
<marker>[Kosinski et al.2013]</marker>
<rawString>Michal Kosinski, David Stillwell, and Thore Graepel. 2013. Private traits and attributes are predictable from digital records of human behavior. Proceedings of the National Academy of Sciences, 110(15):5802–5805.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maider Lehr</author>
<author>Emily Tucker Prud’hommeaux</author>
<author>Izhak Shafran</author>
<author>Brian Roark</author>
</authors>
<title>Fully automated neuropsychological assessment for detecting mild cognitive impairment.</title>
<date>2012</date>
<booktitle>In INTERSPEECH.</booktitle>
<marker>[Lehr et al.2012]</marker>
<rawString>Maider Lehr, Emily Tucker Prud’hommeaux, Izhak Shafran, and Brian Roark. 2012. Fully automated neuropsychological assessment for detecting mild cognitive impairment. In INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maider Lehr</author>
<author>Izhak Shafran</author>
<author>Emily Prudhommeaux</author>
<author>Brian Roark</author>
</authors>
<title>Discriminative joint modeling of lexical variation and acoustic confusion for automated narrative retelling assessment.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>211--220</pages>
<marker>[Lehr et al.2013]</marker>
<rawString>Maider Lehr, Izhak Shafran, Emily Prudhommeaux, and Brian Roark. 2013. Discriminative joint modeling of lexical variation and acoustic confusion for automated narrative retelling assessment. In Proceedings of NAACL-HLT, pages 211–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<marker>[McCallum2002]</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>NAMI</author>
</authors>
<title>Matext analysis.</title>
<date>2013</date>
<journal>Artif. Intell. Med.,</journal>
<volume>56</volume>
<issue>1</issue>
<marker>[NAMI2013]</marker>
<rawString>NAMI. 2013. Matext analysis. Artif. Intell. Med., 56(1):19–25, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet-An Nguyen</author>
<author>Jordan BoydGraber</author>
<author>Philip Resnik</author>
</authors>
<title>Lexical and hierarchical topic regression.</title>
<date>2013</date>
<booktitle>In Neural Information Processing Systems.</booktitle>
<marker>[Nguyen et al.2013]</marker>
<rawString>Viet-An Nguyen, Jordan BoydGraber, and Philip Resnik. 2013. Lexical and hierarchical topic regression. In Neural Information Processing Systems.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Serguei Pakhomov</author>
<author>Dustin Chacon</author>
<author>Mark Wicklund</author>
<author>Jeanette Gundel</author>
</authors>
<title>Computerized assessment of syntactic complexity in alzheimers disease: a case study of iris murdochs writing.</title>
<date>2011</date>
<journal>Behavior Research Methods,</journal>
<volume>43</volume>
<issue>1</issue>
<marker>[Pakhomov et al.2011]</marker>
<rawString>Serguei Pakhomov, Dustin Chacon, Mark Wicklund, and Jeanette Gundel. 2011. Computerized assessment of syntactic complexity in alzheimers disease: a case study of iris murdochs writing. Behavior Research Methods, 43(1):136–144.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Laura A King</author>
</authors>
<title>Linguistic styles: language use as an individual difference. Journal ofpersonality and social psychology,</title>
<date>1999</date>
<pages>77--6</pages>
<marker>[Pennebaker and King1999]</marker>
<rawString>James W Pennebaker and Laura A King. 1999. Linguistic styles: language use as an individual difference. Journal ofpersonality and social psychology, 77(6):1296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John P Pestian</author>
<author>Pawel Matykiewicz</author>
<author>Michelle Linn-Gust</author>
<author>Brett South</author>
<author>Ozlem Uzuner</author>
<author>Jan Wiebe</author>
<author>K Bretonnel Cohen</author>
<author>John Hurdle</author>
<author>Christopher Brew</author>
</authors>
<title>Sentiment analysis of suicide notes: A shared task. Biomedical Informatics Insights,</title>
<date>2012</date>
<pages>5--1</pages>
<marker>[Pestian et al.2012]</marker>
<rawString>John P Pestian, Pawel Matykiewicz, Michelle Linn-Gust, Brett South, Ozlem Uzuner, Jan Wiebe, K Bretonnel Cohen, John Hurdle, Christopher Brew, et al. 2012. Sentiment analysis of suicide notes: A shared task. Biomedical Informatics Insights, 5(Suppl. 1):3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily T Prudhommeaux</author>
<author>Brian Roark</author>
<author>Lois M Black</author>
<author>Jan van Santen</author>
</authors>
<title>Classification of atypical language in autism.</title>
<date>2011</date>
<booktitle>ACL HLT 2011,</booktitle>
<pages>88</pages>
<marker>[Prudhommeaux et al.2011]</marker>
<rawString>Emily T Prudhommeaux, Brian Roark, Lois M Black, and Jan van Santen. 2011. Classification of atypical language in autism. ACL HLT 2011, page 88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brian Roark</author>
<author>Margaret Mitchell</author>
<author>J Hosom</author>
<author>Kristy Hollingshead</author>
<author>Jeffrey Kaye</author>
</authors>
<title>Spoken language derived measures for detecting mild cognitive impairment. Audio, Speech, and Language Processing,</title>
<date>2011</date>
<journal>IEEE Transactions on,</journal>
<volume>19</volume>
<issue>7</issue>
<marker>[Roark et al.2011]</marker>
<rawString>Brian Roark, Margaret Mitchell, J Hosom, Kristy Hollingshead, and Jeffrey Kaye. 2011. Spoken language derived measures for detecting mild cognitive impairment. Audio, Speech, and Language Processing, IEEE Transactions on, 19(7):2081–2090.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Rude</author>
<author>Eva-Maria Gortner</author>
<author>James Pennebaker</author>
</authors>
<title>Language use of depressed and depression-vulnerable college students.</title>
<date>2004</date>
<journal>Cognition &amp; Emotion,</journal>
<volume>18</volume>
<issue>8</issue>
<marker>[Rude et al.2004]</marker>
<rawString>Stephanie Rude, Eva-Maria Gortner, and James Pennebaker. 2004. Language use of depressed and depression-vulnerable college students. Cognition &amp; Emotion, 18(8):1121–1133.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Andrew Schwartz</author>
<author>Johannes C Eichstaedt</author>
<author>Margaret L Kern</author>
<author>Lukasz Dziurzynski</author>
<author>Megha Agrawal</author>
<author>Gregory J Park</author>
<author>Shrinidhi K Lakshmikanth</author>
<author>Sneha Jha</author>
<author>Martin E P Seligman</author>
<author>Lyle Ungar</author>
</authors>
<title>Characterizing geographic variation in well-being using tweets.</title>
<date>2013</date>
<booktitle>In Seventh International AAAI Conference on Weblogs and Social Media (ICWSM</booktitle>
<marker>[Schwartz et al.2013]</marker>
<rawString>H. Andrew Schwartz, Johannes C. Eichstaedt, Margaret L. Kern, Lukasz Dziurzynski, Megha Agrawal, Gregory J. Park, Shrinidhi K. Lakshmikanth, Sneha Jha, Martin E. P. Seligman, and Lyle Ungar. 2013. Characterizing geographic variation in well-being using tweets. In Seventh International AAAI Conference on Weblogs and Social Media (ICWSM 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen Sibelius</author>
</authors>
<title>Increasing access to mental health services,</title>
<date>2013</date>
<note>http://www.whitehouse.gov/blog/2013/04/10/increasingaccess-mental-health-services.</note>
<marker>[Sibelius2013]</marker>
<rawString>Kathleen Sibelius. 2013. Increasing access to mental health services, April. http://www.whitehouse.gov/blog/2013/04/10/increasingaccess-mental-health-services.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony Stark</author>
<author>Izhak Shafran</author>
<author>Jeffrey Kaye</author>
</authors>
<title>Hello, who is calling?: can words reveal the social nature of conversations?</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>112--119</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>[Stark et al.2012]</marker>
<rawString>Anthony Stark, Izhak Shafran, and Jeffrey Kaye. 2012. Hello, who is calling?: can words reveal the social nature of conversations? In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 112–119. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Tellegen</author>
<author>Y S Ben-Porath</author>
<author>J L McNulty</author>
<author>P A Arbisi</author>
<author>B Graham</author>
<author>J R and Kaemmer</author>
</authors>
<date>2003</date>
<booktitle>The MMPI-2 Restructured Clinical Scales: Development, validation, and interpretation.</booktitle>
<publisher>University of Minnesota Press.</publisher>
<location>Minneapolis, MN:</location>
<marker>[Tellegen et al.2003]</marker>
<rawString>A. Tellegen, Y.S. Ben-Porath, J.L. McNulty, P.A. Arbisi, and B. Graham, J.R.and Kaemmer. 2003. The MMPI-2 Restructured Clinical Scales: Development, validation, and interpretation. Minneapolis, MN: University of Minnesota Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan PH Van Santen</author>
<author>Emily T Prud’hommeaux</author>
<author>Lois M Black</author>
<author>Margaret Mitchell</author>
</authors>
<title>Computational prosodic markers for autism.</title>
<date>2010</date>
<journal>Autism,</journal>
<volume>14</volume>
<issue>3</issue>
<marker>[Van Santen et al.2010]</marker>
<rawString>Jan PH Van Santen, Emily T Prud’hommeaux, Lois M Black, and Margaret Mitchell. 2010. Computational prosodic markers for autism. Autism, 14(3):215–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ke Zhai</author>
<author>Jordan Boyd-Graber</author>
<author>Nima Asadi</author>
<author>Mohamad L Alkhouja</author>
</authors>
<title>Mr. lda: a flexible large scale topic modeling package using variational inference in mapreduce.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st international conference on World Wide Web, WWW ’12,</booktitle>
<pages>879--888</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<marker>[Zhai et al.2012]</marker>
<rawString>Ke Zhai, Jordan Boyd-Graber, Nima Asadi, and Mohamad L. Alkhouja. 2012. Mr. lda: a flexible large scale topic modeling package using variational inference in mapreduce. In Proceedings of the 21st international conference on World Wide Web, WWW ’12, pages 879–888, New York, NY, USA. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>