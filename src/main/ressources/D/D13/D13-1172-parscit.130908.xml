<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.975511">
Exploiting Domain Knowledge in Aspect Extraction
</title>
<author confidence="0.9795075">
Zhiyuan Chen, Arjun Mukherjee, Meichun Hsu, Malu Castellanos,
Bing Liu Riddhiman Ghosh
</author>
<affiliation confidence="0.9108115">
University of Illinois at Chicago HP Labs
Chicago, IL 60607, USA Palo Alto, CA 94304, USA
</affiliation>
<email confidence="0.721606">
{czyuanacm,arjun4787}@gmail.com,
liub@cs.uic.edu
{meichun.hsu, malu.castellanos,
riddhiman.ghosh}@hp.com
</email>
<sectionHeader confidence="0.995121" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99829825">
Aspect extraction is one of the key tasks in
sentiment analysis. In recent years, statistical
models have been used for the task. However,
such models without any domain knowledge
often produce aspects that are not interpreta-
ble in applications. To tackle the issue, some
knowledge-based topic models have been
proposed, which allow the user to input some
prior domain knowledge to generate coherent
aspects. However, existing knowledge-based
topic models have several major shortcom-
ings, e.g., little work has been done to incor-
porate the cannot-link type of knowledge or
to automatically adjust the number of topics
based on domain knowledge. This paper pro-
poses a more advanced topic model, called
MC-LDA (LDA with m-set and c-set), to ad-
dress these problems, which is based on an
Extended generalized PÃ³lya urn (E-GPU)
model (which is also proposed in this paper).
Experiments on real-life product reviews
from a variety of domains show that MC-
LDA outperforms the existing state-of-the-art
models markedly.
</bodyText>
<sectionHeader confidence="0.999477" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999701">
In sentiment analysis and opinion mining, aspect
extraction aims to extract entity aspects or features
on which opinions have been expressed (Hu and
Liu, 2004; Liu, 2012). For example, in a sentence
â€œThe picture looks great,â€ the aspect is â€œpicture.â€
Aspect extraction consists of two sub-tasks: (1)
extracting all aspect terms (e.g., â€œpictureâ€) from
the corpus, and (2) clustering aspect terms with
similar meanings (e.g., cluster â€œpictureâ€ and â€œpho-
toâ€ into one aspect category as they mean the
same in the domain â€œCameraâ€). In this work, we
adopt the topic modeling approach as it can per-
form both sub-tasks simultaneously (see Â§ 2).
Topic models, such as LDA (Blei et al., 2003),
provide an unsupervised framework for extracting
latent topics in text documents. Topics are aspect
categories (or simply aspects) in our context.
However, in recent years, researchers have found
that fully unsupervised topic models may not pro-
duce topics that are very coherent for a particular
application. This is because the objective functions
of topic models do not always correlate well with
human judgments and needs (Chang et al., 2009).
To address the issue, several knowledge-based
topic models have been proposed. The DF-LDA
model (Andrzejewski et al., 2009) incorporates
two forms of prior knowledge, also called two
types of constraints: must-links and cannot-links.
A must-link states that two words (or terms)
should belong to the same topic whereas a cannot-
link indicates that two words should not be in the
same topic. In (Andrzejewski et al., 2011), more
general knowledge can be specified using first-
order logic. In (Burns et al., 2012; Jagarlamudi et
al., 2012; Lu et al., 2011; Mukherjee and Liu,
2012), seeded models were proposed. They enable
the user to specify prior knowledge as seed
words/terms for some topics. Petterson et al. (2010)
also used word similarity as priors for guidance.
However, none of the existing models is capable
of incorporating the cannot-link type of knowledge
except DF-LDA (Andrzejewski et al., 2009). Fur-
thermore, none of the existing models, including
DF-LDA, is able to automatically adjust the num-
ber of topics based on domain knowledge. The
domain knowledge, such as cannot-links, may
change the number of topics. There are two types
of cannot-links: consistent and inconsistent with
the domain corpus. For example, in the reviews of
</bodyText>
<page confidence="0.934123">
1655
</page>
<note confidence="0.7326955">
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1655â€“1667,
Seattle, Washington, USA, 18-21 October 2013. cï¿½2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.99130243373494">
domain â€œComputerâ€, a topic model may generate
two topics Battery and Screen that represent two
different aspects. A cannot-link {battery, screen}
as the domain knowledge is thus consistent with
the corpus. However, words Amazon and Price
may appear in the same topic due to their high co-
occurrences in the Amazon.com review corpus. To
separate them, a cannot-link {amazon, price} can
be added as the domain knowledge, which is in-
consistent with the corpus as these two words have
high co-occurrences in the corpus. In this case, the
number of topics needs to be increased by 1 since
the mixed topic has to be separated into two indi-
vidual topics Amazon and Price. Apart from the
above shortcoming, earlier knowledge-based topic
models also have some major shortcomings:
Incapability of handling multiple senses: A
word typically has multiple meanings or senses.
For example, light can mean â€œof little weightâ€ or
â€œsomething that makes things visible.â€ DF-LDA
cannot handle multiple senses because its defini-
tion of must-link is transitive. That is, if A and B
form a must-link, and B and C form a must-link, it
implies a must-link between A and C, indicating A,
B, and C should be in the same topic. This case
also applies to the models in (Andrzejewski et al.,
2011), (Petterson et al., 2010), and (Mukherjee and
Liu, 2012). Although the model in (Jagarlamudi et
al., 2012) allows multiple senses, it requires that
each topic has at most one set of seed words (seed
set), which is restrictive as the amount of
knowledge should not be limited.
Sensitivity to the adverse effect of knowledge:
When using must-links or seeds, existing models
basically try to ensure that the words in a must-
link or a seed set have similar probabilities under a
topic. This causes a problem: if a must-link com-
prises of a frequent word and an infrequent word,
due to the redistribution of probability mass, the
probability of the frequent word will decrease
while the probability of the infrequent word will
increase. This can harm the final topics because
the attenuation of the frequent (often domain im-
portant) words can result in some irrelevant words
being ranked higher (with higher probabilities).
To address the above shortcomings, we define
m-set (for must-set) as a set of words that should
belong to the same topic and c-set (cannot-set) as a
set of words that should not be in the same topic.
They are similar to must-link and cannot-link but
m-sets do not enforce transitivity. Transitivity is
the main cause of the inability to handle multiple
senses. Our m-sets and c-sets are also more con-
cise providing knowledge in the context of a set.
As in (Andrzejewski et al., 2009), we assume that
there is no conflict between m-sets and c-sets, i.e.,
if w1 is a cannot-word of w2 (i.e., shares a c-set
with w2), any word that shares an m-set with w1 is
also a cannot-word of w2. Note that knowledge as
m-sets has also been used in (Chen et al., 2013a)
and (Chen et al., 2013b).
We then propose a new topic model, called MC-
LDA (LDA with m-set and c-set), which is not on-
ly able to deal with c-sets and automatically adjust
the number of topics, but also deal with the multi-
ple senses and adverse effect of knowledge prob-
lems at the same time. For the issue of multiple
senses, a new latent variable s is added to LDA to
distinguish multiple senses (Â§ 3). Then, we employ
the generalized PÃ³lya urn (GPU) model
(Mahmoud, 2008) to address the issue of adverse
effect of knowledge (Â§ 4). Deviating from the
standard topic modeling approaches, we propose
the Extended generalized PÃ³lya urn (E-GPU)
model (Â§ 5). E-GPU extends the GPU model to
enable multi-urn interactions. This is necessary for
handling c-sets and for adjusting the number of
topics. E-GPU is the heart of MC-LDA. Due to the
extension, a new inference mechanism is designed
for MC-LDA (Â§ 6). Note that E-GPU is generic
and can be used in any appropriate application.
In summary, this paper makes the following
three contributions:
</bodyText>
<listItem confidence="0.998995736842105">
1. It proposed a new knowledge-based topic mod-
el called MC-LDA, which is able to use both
m-sets and c-sets, as well as automatically ad-
just the number of topics based on domain
knowledge. At the same time, it can deal with
some other major shortcomings of early exist-
ing models. To our knowledge, none of the ex-
isting knowledge-based models is as compre-
hensive as MC-LDA in terms of capabilities.
2. It proposed the E-GPU model to enable multi-
urn interactions, which enables c-sets to be nat-
urally integrated into a topic model. To the best
of our knowledge, E-GPU has not been pro-
posed and used before.
3. A comprehensive evaluation has been conduct-
ed to compare MC-LDA with several state-of-
the-art models. Experimental results based on
both qualitative and quantitative measures
demonstrate the superiority of MC-LDA.
</listItem>
<page confidence="0.996051">
1656
</page>
<sectionHeader confidence="0.99988" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.992397">
Sentiment analysis has been studied extensively in
recent years (Hu and Liu, 2004; Pang and Lee,
2008; Wiebe and Riloff, 2005; Wiebe et al., 2004).
According to (Liu, 2012), there are three main ap-
proaches to aspect extraction: 1) Using word fre-
quency and syntactic dependency of aspects and
sentiment words for extraction (e.g., Blair-
</bodyText>
<figureCaption confidence="0.902963923076923">
goldensohn et al., 2008; Hu and Liu, 2004; Ku et
al., 2006; Popescu and Etzioni, 2005; Qiu et al.,
2011; Somasundaran and Wiebe, 2009; Wu et al.,
2009; Yu et al., 2011; Zhang and Liu, 2011;
Zhuang et al., 2006); 2) Using supervised se-
quence labeling/classification (e.g., Choi and
Cardie, 2010; Jakob and Gurevych, 2010;
Kobayashi et al., 2007; Li et al., 2010); 3) Topic
models (Branavan et al., 2008; Brody and Elhadad,
2010; Fang and Huang, 2012; Jo and Oh, 2011;
Kim et al., 2013; Lazaridou et al., 2013; Li et al.,
2011; Lin and He, 2009; Lu et al., 2009, 2012,
2011; Lu and Zhai, 2008; Mei et al., 2007;
</figureCaption>
<bodyText confidence="0.987584847457627">
Moghaddam and Ester, 2011; Mukherjee and Liu,
2012; Sauper et al., 2011; Titov and McDonald,
2008; Wang et al., 2010, 2011; Zhao et al., 2010).
Other approaches include shallow semantic pars-
ing (Li et al., 2012b), bootstrapping (Xia et al.,
2009), Non-English techniques (Abu-Jbara et al.,
2013; Zhou et al., 2012), graph-based representa-
tion (Wu et al., 2011), convolution kernels
(Wiegand and Klakow, 2010) and domain adap-
tion (Li et al., 2012). Stoyanov and Cardie (2011),
Wang and Liu (2011), and Meng et al. (2012)
studied opinion summarization outside the reviews.
Some other works related with sentiment analysis
include (Agarwal and Sabharwal, 2012; Kennedy
and Inkpen, 2006; Kim et al., 2009; Mohammad et
al., 2009).
In this work, we focus on topic models owing to
their advantage of performing both aspect extrac-
tion and clustering simultaneously. All other ap-
proaches only perform extraction. Although there
are several related works on clustering aspect
terms (e.g., Carenini et al., 2005; Guo et al., 2009;
Zhai et al., 2011), they all assume that the aspect
terms have been extracted beforehand. We also
notice that some aspect extraction models in sen-
timent analysis separately discover aspect words
and aspect specific sentiment words (e.g., Sauper
and Barzilay, 2013; Zhao et al., 2010). Our pro-
posed model does not separate them as most sen-
timent words also imply aspects and most adjec-
tives modify specific attributes of objects. For ex-
ample, sentiment words expensive and beautiful
imply aspects price and appearance respectively.
Regarding the knowledge-based models, be-
sides those discussed in Â§ 1, the model (Hu et al.,
2011) enables the user to provide guidance interac-
tively. Blei and McAuliffe (2007) and Ramage et
al. (2009) used document labels in supervised set-
ting. In (Chen et al., 2013a), we proposed MDK-
LDA to leverage multi-domain knowledge, which
serves as the basic mechanism to exploit m-sets in
MC-LDA. In (Chen et al., 2013b), we proposed a
framework (called GK-LDA) to explicitly deal
with the wrong knowledge when exploring the
lexical semantic relations as the general (domain
independent) knowledge in topic models. But
these models above did not consider the
knowledge in the form of c-sets (or cannot-links).
The generalized PÃ³lya urn (GPU) model
(Mahmoud, 2008) was first introduced in LDA by
Mimno et al. (2011). However, Mimno et al. (2011)
did not use domain knowledge. Our results in Â§ 7
show that using domain knowledge can signifi-
cantly improve aspect extraction. The GPU model
was also employed in topic models in our work of
(Chen et al., 2013a, 2013b). In this paper, we pro-
pose the Extended GPU (E-GPU) model. The E-
GPU model is more powerful in handling complex
situations in dealing with c-sets.
</bodyText>
<sectionHeader confidence="0.796628" genericHeader="method">
3 Dealing with M-sets and Multiple Senses
</sectionHeader>
<bodyText confidence="0.999847583333333">
Since the proposed MC-LDA model is a major
extension to our earlier work in (Chen et al.,
2013a), which can deal with m-sets, we include
this earlier work here as the background.
To incorporate m-sets and deal with multiple
senses of a word, the MDK-LDA(b) model was
proposed in (Chen et al., 2013a), which adds a
new latent variable s into LDA. The rationale here
is that this new latent variable s guides the model
to choose the right sense represented by an m-set.
The generative process of MDK-LDA(b) is (the
notations are explained in Table 1):
</bodyText>
<equation confidence="0.996530666666667">
0 ~ Dirichlet(a)
zi|0â€ ~ Multinomial(0â€)
T ~ Dirichlet(fl)
si|zi,T ~ Multinomial(TzL)
0 ~ Dirichlet(y)
wi |zi, si, 0 ~ Multinomial (0zL,SL)
</equation>
<page confidence="0.978805">
1657
</page>
<figureCaption confidence="0.999551">
Figure 1. Plate notation for MDK-LDA(b) and MC-LDA.
</figureCaption>
<bodyText confidence="0.99977">
The corresponding plate is shown in Figure 1. Un-
der MDK-LDA(b), the probability of word ğ‘¤ giv-
en topic ğ‘¡, i.e., ğœ‹ğ‘¡(ğ‘¤), is given by:
</bodyText>
<equation confidence="0.999375666666667">
ğœ‹ğ‘¡(ğ‘¤) = âˆ‘ ğœ‘ğ‘¡(ğ‘ ) âˆ™ ğœ‚ğ‘¡,ğ‘ (ğ‘¤)
ğ‘† (1)
ğ‘ =1
</equation>
<bodyText confidence="0.999232166666667">
where ğœ‘ğ‘¡(ğ‘ ) denotes the probability of m-set ğ‘ 
occurring under topic ğ‘¡ and ğœ‚ğ‘¡,ğ‘ (ğ‘¤) is the proba-
bility of word ğ‘¤ appearing in m-set ğ‘  under topic ğ‘¡.
According to (Chen et al., 2013a), the condi-
tional probability of Gibbs sampler for MDK-
LDA(b) is given by (see notations in Table 1):
</bodyText>
<equation confidence="0.999318285714286">
ğ‘ƒï¿½ğ‘§ğ‘– = ğ‘¡, ğ‘ ğ‘– = ğ‘  ï¿½ğ’›âˆ’ğ‘–, ğ’”âˆ’ğ‘–, ğ’˜, ğ›¼,ğ›½, ğ›¾ï¿½ âˆ
ğ‘›ğ‘š,ğ‘¡
âˆ’ğ‘– + ğ›¼
Ã—
âˆ‘ï¿½ğ‘›ğ‘š,ğ‘¡â€²
ğ‘‡ âˆ’ğ‘– + ğ›¼ï¿½
ğ‘¡â€²=1
</equation>
<bodyText confidence="0.9944795">
The superscript âˆ’ğ‘– denotes the counts excluding
the current assignments (ğ‘§ğ‘– and ğ‘ ğ‘–) for word ğ‘¤ğ‘–.
</bodyText>
<sectionHeader confidence="0.927521" genericHeader="method">
4 Handling Adverse Effect of Knowledge
</sectionHeader>
<subsectionHeader confidence="0.976854">
4.1 Generalized PÃ³lya urn (GPU) Model
</subsectionHeader>
<bodyText confidence="0.999964388888889">
The PÃ³lya urn model involves an urn containing
balls of different colors. At discrete time intervals,
balls are added or removed from the urn according
to their color distributions.
In the simple PÃ³lya urn (SPU) model, a ball is
first drawn randomly from the urn and its color is
recorded, then that ball is put back along with a
new ball of the same color. This selection process
is repeated and the contents of the urn change over
time, with a self-reinforcing property sometimes
expressed as â€œthe rich get richer.â€ SPU is actually
exhibited in the Gibbs sampling for LDA.
The generalized PÃ³lya urn (GPU) model differs
from the SPU model in the replacement scheme
during sampling. Specifically, when a ball is ran-
domly drawn, certain numbers of additional balls
of each color are returned to the urn, rather than
just two balls of the same color as in SPU.
</bodyText>
<table confidence="0.999204137931034">
Hyperparameters
ğ›¼, ğ›½, ğ›¾ Dirichlet priors for ğœƒ, ğœ‘, ğœ‚
Latent &amp; Visible Variables
ğ‘§ Topic (Aspect)
ğ‘  M-set
ğ‘¤ Word
ğœƒ Document-Topic distribution
ğœƒğ‘š Topic distribution of document ğ‘š
ğœ‘ Topic-M-set distribution
ğœ‘ğ‘¡ M-set distribution of topic ğ‘¡
ğœ‚ Topic-M-set-Word distribution
ğœ‚ ğ‘¡,ğ‘  Word distribution of topic ğ‘¡, m-set ğ‘ 
Cardinalities
ğ‘€ Number of documents
ğ‘ğ‘š Number of words in document ğ‘š
ğ‘‡ Number of topics
ğ‘† Number of m-sets
ğ‘‰ The vocabulary size
Sampling &amp; Count Notations
ğ‘§ğ‘– Topic assignment for word ğ‘¤ğ‘–
ğ‘ ğ‘– M-set assignment for word ğ‘¤ğ‘–
ğ’›âˆ’ğ‘– Topic assignments for all words except ğ‘¤ğ‘–
ğ’”âˆ’ğ‘– M-set assignments for all words except ğ‘¤ğ‘–
ğ‘›ğ‘š,ğ‘¡ Number of times that topic ğ‘¡ is assigned
ğ‘›ğ‘¡,ğ‘  to word tokens in document ğ‘š
ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ Number of times that m-set ğ‘  occurs un-
der topic ğ‘¡
Number of times that word ğ‘¤ appears in
m-set ğ‘  under topic ğ‘¡
</table>
<tableCaption confidence="0.99963">
Table 1. Meanings of symbols.
</tableCaption>
<subsectionHeader confidence="0.997254">
4.2 Promoting M-sets using GPU
</subsectionHeader>
<bodyText confidence="0.999988733333333">
To deal with the issue of sensitivity to the adverse
effect of knowledge, MDK-LDA(b) is extended to
MDK-LDA which employs the generalized PÃ³lya
urn (GPU) sampling scheme.
As discussed in Â§ 1, due to the problem of the
adverse effect of knowledge, important words may
suffer from the presence of rare words in the same
m-set. This problem can be dealt with the very
sampling scheme of the GPU model (Chen et al.,
2013a). Specifically, by adding additional ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤
balls of color ğ‘  into ğ‘ˆğ‘¡ğ‘† while keeping the drawn
ball, we increase the proportion (probability) of
seeing the m-set ğ‘  under topic ğ‘¡ and thus promote
m-set ğ‘  as a whole. Consequently, each word in ğ‘ 
is more likely to be emitted. We define ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ as:
</bodyText>
<equation confidence="0.959847727272727">
1 ğ‘¤= ğ‘¤â€²
T
ï¿½
IP s z y
w
Nm
M
0
Î±
ti
TÃ—S
ğ‘›ğ‘¡,ğ‘ 
âˆ’ğ‘– + ğ›½ Ã—
âˆ‘ï¿½ğ‘›ğ‘¡,ğ‘ â€²
ğ‘† âˆ’ğ‘– + ğ›½ï¿½
ğ‘ â€²=1
ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ğ‘– âˆ’ğ‘–+ ğ›¾ğ‘  (2)
âˆ‘ï¿½ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€²
ğ‘‰ âˆ’ğ‘– + ğ›¾ğ‘ ï¿½
ğ‘£â€²=1
ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ = ï¿½ğœ ğ‘¤ âˆˆ ğ‘ , ğ‘¤â€² âˆˆ ğ‘ , ğ‘¤â‰  ğ‘¤â€² (3)
0 otherwise
</equation>
<bodyText confidence="0.987003">
The corresponding Gibbs sampler for MDK-LDA
will be introduced in Â§ 6.
</bodyText>
<page confidence="0.985825">
1658
</page>
<sectionHeader confidence="0.999779" genericHeader="method">
5 Incorporating C-sets
</sectionHeader>
<subsectionHeader confidence="0.999326">
5.1 Extended Generalized PÃ³lya urn Model
</subsectionHeader>
<bodyText confidence="0.968956071428572">
To handle the complex situation resulted from in-
corporating c-sets, we propose an Extended gener-
alized PÃ³lya urn (E-GPU) model. Instead of
involving only one urn as in SPU and GPU, E-
GPU model considers a set of urns in the sampling
process. The E-GPU model allows a ball to be
transferred from one urn to another, enabling mul-
ti-urn interactions. Thus, during sampling, the
populations of several urns will evolve even if on-
ly one ball is drawn from one urn. This capability
makes the E-GPU model more powerful as it
models relationships among multiple urns.
We define three sets of urns which will be used
in the new sampling scheme in the proposed MC-
LDA model. The first set of urns is the topic urns
ğ‘ˆğ‘šâˆˆ{1...ğ‘€}
ğ‘‡ , where each topic urn contains ğ‘‡ colors
(topics) and each ball inside has a color ğ‘¡ âˆˆ
{1 ... ğ‘‡}. It corresponds to the document-topic dis-
tribution ğœƒ in Table 1. The second set of urns (m-
set urn ğ‘ˆğ‘¡âˆˆ {1...ğ‘‡}
ğ‘† ) corresponds to the topic-m-set
distribution ğœ‘ , with balls of colors (m-sets)
ğ‘  âˆˆ {1 ... ğ‘†} in each m-set urn. The third set of
urns is the word urns ğ‘ˆğ‘¡,ğ‘ ğ‘Š,where ğ‘¡ âˆˆ {1... ğ‘‡} and
ğ‘  âˆˆ {1 ...ğ‘†}. Each ball inside a word urn has a
color (word) ğ‘¤ âˆˆ {1 ... ğ‘‰}. The distribution ğœ‚ can
be reflected in this set of urns.
</bodyText>
<subsectionHeader confidence="0.999695">
5.2 Handling C-sets using E-GPU
</subsectionHeader>
<bodyText confidence="0.999986333333333">
As MDK-LDA can only use m-sets but not c-sets,
we now extend MDK-LDA to the MC-LDA model
in order to exploit c-sets. As pointed out in Â§ 1, c-
sets may be inconsistent with the corpus domain,
which makes them considerably harder to deal
with. To tackle the issue, we utilize the proposed
E-GPU model and incorporate c-sets handling in-
side the E-GPU sampling scheme, which is also
designed to enable automated adjustment of the
number of topics based on domain knowledge.
Based on the definition of c-set, each pair of
words in a c-set cannot both have large probabili-
ties under the same topic. As the E-GPU model
allows multi-urn interactions, when sampling a
ball represents word ğ‘¤ from a word urn ğ‘ˆğ‘¡,ğ‘ ğ‘Š, we
want to transfer the balls representing cannot-
words of ğ‘¤ (sharing a c-set with ğ‘¤) to other urns
(see Step 3 a below). That is, decrease the proba-
bilities of those cannot-words under this topic
while increasing their corresponding probabilities
under some other topics. In order to correctly
transfer a ball that represents word ğ‘¤, it should be
transferred to an urn which has a higher proportion
of ğ‘¤ and its related words (i.e., words sharing m-
sets with ğ‘¤). That is, we randomly sample an urn
that has a higher proportion of any m-set of ğ‘¤ to
transfer ğ‘¤ to (Step 3 b below). However, the situa-
tion becomes more involved when a c-set is not
consistent with the corpus. For example, aspects
price and amazon may be mixed under one topic
(say ğ‘¡) in LDA. The user may want to separate
them by providing a c-set {price, amazon}. In this
case, according to LDA, word price has no topic
with a higher proportion of it (and its related
words) than topic ğ‘¡. To transfer it, we need to in-
crement the number of topics by 1 and then trans-
fer the word to this new topic urn (step 3 c below).
Based on these ideas, we propose the E-GPU sam-
pling scheme for the MC-LDA model below:
</bodyText>
<listItem confidence="0.95609575">
1. Sample a topic ğ‘¡ from ğ‘ˆğ‘šğ‘‡ , an m-set ğ‘  from ğ‘ˆğ‘¡ğ‘† , and
a word ğ‘¤ from ğ‘ˆğ‘¡,ğ‘ ğ‘Š sequentially, where ğ‘š is the
ğ‘šth document.
2. Record ğ‘¡, ğ‘  and ğ‘¤, put back two balls of color ğ‘¡ in-
to urn ğ‘ˆğ‘šğ‘‡, one ball of color ğ‘  into urn ğ‘ˆğ‘¡ğ‘†, and two
balls of color ğ‘¤ into urn ğ‘ˆğ‘¡,ğ‘ ğ‘Š. Given the matrix ğ”¸
(in Equation 3), for each word ğ‘¤â€² âˆˆ ğ‘ , we put back
ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ number of balls of color ğ‘  into urn ğ‘ˆğ‘¡ğ‘† .
3. For each word ğ‘¤ğ‘ that shares a c-set with ğ‘¤:
a) Sample an m-set ğ‘ ğ‘ from ğ‘ˆğ‘¡ğ‘† which satisfies
ğ‘¤ğ‘ âˆˆ ğ‘ ğ‘. Draw a ball ğ‘ of color ğ‘¤ğ‘ (to be trans-
ferred) from ğ‘ˆğ‘¡,ğ‘ ğ‘
</listItem>
<bodyText confidence="0.8316858">
ğ‘Š and remove it from ğ‘ˆğ‘¡,ğ‘ ğ‘
ğ‘Š . The
document of ball ğ‘ is denoted by ğ‘šğ‘. If no ball
of color ğ‘¤ğ‘ can be drawn (i.e., there is no ball
of color ğ‘¤ğ‘ in ğ‘ˆğ‘¡,ğ‘ ğ‘
</bodyText>
<equation confidence="0.979938">
ğ‘Š ), skip steps b) to d).
b) Produce an urn set {ğ‘ˆğ‘¡â€²,ğ‘ â€²
ğ‘Š } such that each urn in
</equation>
<bodyText confidence="0.712846">
it satisfies the following conditions:
</bodyText>
<equation confidence="0.903956">
i) ğ‘¡â€² â‰  ğ‘¡, ğ‘¤ğ‘ âˆˆ ğ‘ â€²
</equation>
<bodyText confidence="0.9442275">
ii) The proportion of balls of color ğ‘ â€² in ğ‘ˆğ‘¡â€²ğ‘† is
higher than that of balls of color ğ‘ ğ‘ in ğ‘ˆğ‘¡ğ‘† .
</bodyText>
<equation confidence="0.946632555555556">
c) If {ğ‘ˆğ‘¡â€²,ğ‘ â€²
ğ‘Š } is not empty, randomly select one urn
ğ‘ˆğ‘¡â€²,ğ‘ â€²
ğ‘Š from it. If {ğ‘ˆğ‘¡â€²,ğ‘ â€²
ğ‘Š } is empty, set ğ‘‡ = ğ‘‡ +
1, ğ‘¡â€² = ğ‘‡, draw an m-set ğ‘ â€² from ğ‘ˆğ‘¡â€²ğ‘† which sat-
isfies ğ‘¤ğ‘ âˆˆ ğ‘ â€². Record ğ‘ â€² for step d).
d) Put the ball ğ‘ drawn from Step a) into ğ‘ˆğ‘¡â€²,ğ‘ â€²
ğ‘Š , as
</equation>
<bodyText confidence="0.89826475">
well as a ball of color ğ‘ â€² into ğ‘ˆğ‘¡â€²ğ‘† and a ball of
color ğ‘¡â€² into ğ‘ˆğ‘šğ‘‡ ğ‘.
Note that the E-GPU model cannot be reflected in
the graphical model in Figure 1 as it is essentially
</bodyText>
<page confidence="0.93618">
1659
</page>
<table confidence="0.988773923076923">
Algorithm 1. GibbsSampling(ğ‘š, ğ‘¤ğ‘–, ğ”¸, ğœ‡, ğ›º)
Input: Document ğ‘š, Word ğ‘¤ğ‘–, Matrix ğ”¸,
Transfer cannot-word flag ğœ‡,
A set of valid topics ğ›º to be assigned to ğ‘¤ğ‘–
1: ğ‘›ğ‘š,ğ‘§ğ‘– â† ğ‘›ğ‘š,ğ‘§ğ‘– âˆ’ 1;
2: for each word ğ‘¤â€² in ğ‘ ğ‘– do
ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– âˆ’ ğ”¸ğ‘ ğ‘–,ğ‘¤â€²,ğ‘¤ğ‘–;
end for
ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– âˆ’ 1;
Jointly sample ğ‘§ğ‘– âˆˆ ğ›º and ğ‘ ğ‘– âˆ‹ ğ‘¤ğ‘– using Equation 2;
ğ‘›ğ‘š,ğ‘§ğ‘– â† ğ‘›ğ‘š,ğ‘§ğ‘– + 1;
for each word ğ‘¤â€² in ğ‘ ğ‘– do
ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– + ğ”¸ğ‘ ğ‘–,ğ‘¤â€²,ğ‘¤ğ‘–;
</table>
<figure confidence="0.5971564">
10: end for
11: ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– + 1;
12: if ğœ‡ is true then
13: TransferCannotWords(ğ‘¤ğ‘–, ğ‘§ğ‘–);
14: end if
</figure>
<figureCaption confidence="0.998611">
Figure 2. Gibbs sampling for MC-LDA.
</figureCaption>
<bodyText confidence="0.9706115">
sampling scheme, and hence MC-LDA shares the
same plate as MDK-LDA(b).
</bodyText>
<sectionHeader confidence="0.997377" genericHeader="method">
6 Collapsed Gibbs Sampling
</sectionHeader>
<bodyText confidence="0.999951777777778">
We now describe the collapsed Gibbs sampler
(Griffiths and Steyvers, 2004) with the detailed
conditional distributions and algorithms for MC-
LDA. Inference of ğ‘§ and ğ‘  can be computationally
expensive due to the non-exchangeability of words
under the E-GPU models. We take the approach of
(Mimno et al., 2011) which approximates the true
Gibbs sampling distribution by treating each word
as if it were the last.
For each word ğ‘¤ğ‘– , we perform hierarchical
sampling consisting of the following three steps
(the detailed algorithms are given in Figures 2 and
3):
Step 1 (Lines 1-11 in Figure 2): We jointly
sample a topic ğ‘§ğ‘– and an m-set ğ‘ ğ‘– (containing ğ‘¤ğ‘–)
for ğ‘¤ğ‘–, which gives us a blocked Gibbs sampler
(Ishwaran and James, 2001), with the conditional
probability given by:
</bodyText>
<equation confidence="0.995238166666667">
ğ‘ƒ(ğ‘§ğ‘– = ğ‘¡, ğ‘ ğ‘– = ğ‘ |ğ’›âˆ’ğ‘–,ğ’”âˆ’ğ‘–, ğ’˜, ğ›¼, ğ›½, ğ›¾,ğ”¸) âˆ
âˆ‘ âˆ‘ ğ”¸ğ‘ ,ğ‘£â€²,ğ‘¤â€² âˆ™ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€²
ğ‘‰ ğ‘‰ âˆ’ğ‘– +ğ›½
ğ‘¤â€²=1 ğ‘£â€²=1 Ã—
âˆ‘ ï¿½âˆ‘ âˆ‘ ğ”¸ğ‘ â€²,ğ‘£â€²,ğ‘¤â€²âˆ™ğ‘›ğ‘¡,ğ‘ â€²,ğ‘£â€²
ğ‘† ğ‘‰ ğ‘‰ âˆ’ğ‘– +ğ›½ï¿½
ğ‘ â€²=1 ğ‘¤â€²=1 ğ‘£â€²=1
âˆ’ğ‘–
ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ğ‘–+ğ›¾ğ‘ 
âˆ‘ ï¿½ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€²
ğ‘‰ âˆ’ğ‘– +ğ›¾ğ‘ ï¿½
ğ‘£â€²=1
</equation>
<bodyText confidence="0.826186">
This step is the same as the Gibbs sampling for the
MDK-LDA model.
</bodyText>
<table confidence="0.776784">
Algorithm 2.TransferCannotWords(ğ‘¤ğ‘–, ğ‘§ğ‘–)
Input: Word ğ‘¤ğ‘–, Topic ğ‘§ğ‘–,
1: for each cannot-word ğ‘¤ğ‘ of ğ‘¤ğ‘– do
</table>
<listItem confidence="0.951236133333333">
2: Randomly select an m-set ğ‘ ğ‘ from all m-sets of ğ‘¤ğ‘;
3: Build a set ğ›¹ containing all the instances of ğ‘¤ğ‘
from the corpus with topic and m-set assign-
ments being ğ‘§ğ‘– and ğ‘ ğ‘;
4: if ğ›¹ is not empty then
5: Draw an instance of ğ‘¤ğ‘ from ğ›¹ (denoting the
document of this instance by ğ‘šğ‘) using
Equation 5;
6: Generate a topic set ğ›ºâ€² that each topic ğ‘¡â€² inside
satisfies ğ‘šğ‘ğ‘¥ğ‘ â€²âˆ‹ğ‘¤ğ‘(ğœ‘ğ‘¡â€²(ğ‘ â€² )) &gt; ğœ‘ğ‘§ğ‘–(ğ‘ ğ‘).
7: if ğ›ºâ€² is not empty then
8: GibbsSampling(ğ‘šğ‘, ğ‘¤ğ‘, ğ”¸, false, ğ›ºâ€²);
9: else
10: ğ·ğ‘¢ğ‘šğ‘šğ‘¦ = ğ‘‡ + 1; // ğ‘‡ is #Topics.
11: GibbsSampling(ğ‘šğ‘, ğ‘¤ğ‘, ğ”¸, false, {ğ·ğ‘¢ğ‘šğ‘šğ‘¦});
</listItem>
<figure confidence="0.454445333333333">
12: end if
13: end if
14: end for
</figure>
<figureCaption confidence="0.938550333333333">
Figure 3. Transfer cannot-words in Gibbs sampling.
Step 2 (lines 1-5 in Figure 3): For every cannot-
word (say ğ‘¤ğ‘) of ğ‘¤ğ‘–, randomly pick an urn ğ‘ˆğ‘§ğ‘–,ğ‘ ğ‘
</figureCaption>
<equation confidence="0.773965545454546">
ğ‘Š
from the urn set {ğ‘ˆğ‘§ğ‘–,ğ‘ Ì…
ğ‘Š } where ğ‘ Ì… âˆ‹ ğ‘¤ğ‘. If there ex-
ists at least one ball of color ğ‘¤ğ‘ in urn ğ‘ˆğ‘§ğ‘–,ğ‘ ğ‘
ğ‘Š , we
sample one ball (say ğ‘ğ‘) of color ğ‘¤ğ‘ from urn
ğ‘ˆğ‘§ğ‘–,ğ‘ ğ‘
ğ‘Š , based on the following conditional distribu-
tion:
ğ‘ƒ (ğ‘ = ğ‘ğ‘ |ğ’›, ğ’”, ğ’˜, ğ›¼, ğ›½, ğ›¾, ğ”¸) âˆ ğ‘‡ ğ‘›ğ‘šğ‘,ğ‘¡+ğ›¼ (5)
âˆ‘ğ‘¡â€²=1 ï¿½ğ‘›ğ‘šğ‘,ğ‘¡â€²+ğ›¼ï¿½
</equation>
<bodyText confidence="0.999355333333333">
where ğ‘šğ‘ denotes the document of the ball ğ‘ğ‘ of
color ğ‘¤ğ‘.
Step 3 (lines 6-12 in Figure 3): For each drawn
ball ğ‘ from Step 2, resample a topic ğ‘¡ and an m-set
ğ‘  (containing ğ‘¤ğ‘) based on the following condi-
tional distribution:
</bodyText>
<equation confidence="0.982268833333333">
ğ‘ƒ (ğ‘§ğ‘ = ğ‘¡, ğ‘ ğ‘ = ğ‘  |ğ’›âˆ’ğ‘, ğ’”âˆ’ğ‘, ğ’˜, ğ›¼, ğ›½, ğ›¾, ğ”¸, ğ‘ = ğ‘ğ‘)
ğ‘‡ âˆ’ğ‘
âˆ ğˆï¿½0, ğ‘šğ‘ğ‘¥ (ğœ‘ğ‘¡ï¿½ğ‘ â€²ï¿½)ï¿½ ï¿½ğœ‘ğ‘§ğ‘(ğ‘ ğ‘)ï¿½ Ã— ğ‘›ğ‘š,ğ‘¡
âˆ’ğ‘ + ğ›¼
âˆ‘ ï¿½ğ‘›ğ‘š,ğ‘¡â€²
ğ‘ â€²âˆ‹ğ‘¤ğ‘ ğ‘¡â€²=1
</equation>
<bodyText confidence="0.999600666666667">
where ğ‘§ğ‘ (same as ğ‘§ğ‘– in Figure 3) and ğ‘ ğ‘ are the
original topic and m-set assignments. The super-
script âˆ’ğ‘ denotes the counts excluding the original
</bodyText>
<figure confidence="0.980286714285714">
âˆ‘ï¿½âˆ‘ âˆ‘ ğ”¸ğ‘ â€²,ğ‘£â€²,ğ‘¤â€² âˆ™ ğ‘›ğ‘¡,ğ‘ â€²,ğ‘£â€²
ğ‘† ğ‘‰ ğ‘‰ âˆ’ğ‘ + ğ›½ï¿½
ğ‘ â€²=1 ğ‘¤â€²=1 ğ‘£â€²=1
âˆ’ğ‘
Ã—
ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ğ‘ + ğ›¾ğ‘ 
âˆ‘âˆ‘ ğ”¸ğ‘ ,ğ‘£â€²,ğ‘¤â€² âˆ™ ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€²
ğ‘‰ ğ‘‰ âˆ’ğ‘ + ğ›½
ğ‘¤â€²=1 ğ‘£â€²=1
Ã—
âˆ‘ï¿½ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€²
ğ‘‰ âˆ’ğ‘ + ğ›¾ğ‘ ï¿½
ğ‘£â€²=1
ğ‘›ğ‘š,ğ‘¡
âˆ’ğ‘– +ğ›¼ Ã—
âˆ‘ ï¿½ğ‘›ğ‘š,ğ‘¡â€²
ğ‘‡ âˆ’ğ‘– +ğ›¼ï¿½
ğ‘¡â€²=1
(4)
+ ğ›¼ï¿½
(6)
</figure>
<page confidence="0.945603">
1660
</page>
<bodyText confidence="0.999619555555556">
assignments. I() is an indicator function, which
restricts the ball to be transferred only to an urn
that contains a higher proportion of its m-set.
When no topic t can be successfully sampled and
the current sweep (iteration) of Gibbs sampling
has the same number of topic (T) as the previous
sweep, we increment T by 1. And then assign T to
zb . The counts and parameters are also updated
accordingly.
</bodyText>
<sectionHeader confidence="0.999591" genericHeader="evaluation">
7 Experiments
</sectionHeader>
<bodyText confidence="0.9989995">
We now evaluate the proposed MC-LDA model
and compare it with state-of-the-art existing mod-
els. Two unsupervised baseline models that we
compare with are:
</bodyText>
<listItem confidence="0.9685522">
â€¢ LDA: LDA is the basic unsupervised topic
model (Blei et al., 2003).
â€¢ LDA-GPU: LDA with GPU (Mimno et al.,
2011). Specifically, LDA-GPU applies GPU in
LDA using co-document frequency.
</listItem>
<bodyText confidence="0.998109428571429">
As for knowledge-based models, we focus on
comparing with DF-LDA model (Andrzejewski et
al., 2009), which is perhaps the best known
knowledge-based model and it allows both must-
links and cannot-links.
For a comprehensive evaluation, we consider
the following variations of MC-LDA and DF-LDA:
</bodyText>
<listItem confidence="0.97575675">
â€¢ MC-LDA: MC-LDA with both m-sets and c-
sets. This is the newly proposed model.
â€¢ M-LDA: MC-LDA with m-sets only. This is
the MDK-LDA model in (Chen et al., 2013a).
â€¢ DF-M: DF-LDA with must-links only.
â€¢ DF-MC: DF-LDA with both must-links and
cannot-links. This is the full DF-LDA model in
(Andrzejewski et al., 2009).
</listItem>
<bodyText confidence="0.9992562">
We do not compare with seeded models in (Burns
et al., 2012; Jagarlamudi et al., 2012; Lu et al.,
2011; Mukherjee and Liu, 2012) as seed sets are
special cases of must-links and they also do not
allow c-sets (or cannot-links).
</bodyText>
<subsectionHeader confidence="0.983286">
7.1 Datasets and Settings
</subsectionHeader>
<bodyText confidence="0.998980285714286">
Datasets: We use product reviews from four do-
mains (types of products) from Amazon.com for
evaluation. The corpus statistics are shown in Ta-
ble 2 (columns 2 and 3). The domains are â€œCam-
era,â€ â€œFood,â€ â€œComputer,â€ and â€œCareâ€ (short for
â€œPersonal Careâ€). We have made the datasets pub-
lically available at the website of the first author.
</bodyText>
<table confidence="0.9998625">
Domain #Reviews #Sentences #M-sets #C-sets
Camera 500 5171 173 18
Food 500 2416 85 10
Computer 500 2864 92 6
Care 500 3008 119 13
Average 500 3116 103 9
</table>
<tableCaption confidence="0.9862405">
Table 2. Corpus statistics with #m-sets and #c-sets
having at least two words.
</tableCaption>
<bodyText confidence="0.999843375000001">
Pre-processing: We ran the Stanford Core NLP
Tools1 to perform sentence detection and lemmati-
zation. Punctuations, stopwords 2 , numbers and
words appearing less than 5 times in each corpus
were removed. The domain name was also re-
moved, e.g., word camera in the domain â€œCameraâ€,
since it co-occurs with most words in the corpus,
leading to high similarity among topics/aspects.
Sentences as documents: As noted in (Titov and
McDonald, 2008), when standard topic models are
applied to reviews as documents, they tend to pro-
duce topics that correspond to global properties of
products (e.g., brand name), which make topics
overlapping with each other. The reason is that all
reviews of the same type of products discuss about
the same aspects of these products. Only the brand
names and product names are different. Thus, us-
ing individual reviews for modeling is not very
effective. Although there are approaches which
model sentences (Jo and Oh, 2011; Titov and
McDonald, 2008), we take the approach of (Brody
and Elhadad, 2010), dividing each review into sen-
tences and treating each sentence as an independ-
ent document. Sentences can be used by all three
baselines without any change to their models. Alt-
hough the relationships between sentences are lost,
the data is fair to all models.
Parameter settings: For all models, posterior in-
ference was drawn using 1000 Gibbs iterations
with an initial burn-in of 100 iterations. For all
models, we set a = 1 and fl = 0.1. We found that
small changes of a and fl did not affect the results
much, which was also reported in (Jo and Oh,
2011) who also used online reviews. For the num-
ber of topics T, we tried different values (see Â§7.2)
as it is hard to know the exact number of topics.
While non-parametric Bayesian approaches (Teh
et al., 2006) aim to estimate T from the corpus,
they are often sensitive to the hyper-parameters
(Heinrich, 2009).
</bodyText>
<footnote confidence="0.999054">
1 http://nlp.stanford.edu/software/corenlp.shtml
2 http://jmlr.org/papers/volume5/lewis04a/a11-smart-stop-list
</footnote>
<page confidence="0.990869">
1661
</page>
<figure confidence="0.9994858">
3 6 9 12 15
MC-LDA M-LDA LDA
DF-M DF-MC LDA-GPU
0% 25% 50% 100%
MC-LDA M-LDA DF-M DF-MC
-1200
-1300
-1400
-1500
-1600
-1240
-1260
-1280
-1300
-1320
</figure>
<figureCaption confidence="0.997395">
Figure 4. Avg. Topic Coherence score of each model
across different number of topics.
</figureCaption>
<bodyText confidence="0.99993884375">
For DF-LDA, we followed (Andrzejewski et al.,
2009) to generate must-links and cannot-links
from our domain knowledge. We then ran DF-
LDA3 while keeping its parameters as proposed in
(Andrzejewski et al., 2009) (we also experimented
with different parameter settings but they did not
produce better results). For our proposed model,
we estimated the thresholds using cross validation
in our pilot experiments. Estimated value ğœ = 0.2
in equation 3 yielded good results. The second
stage (steps 2 and 3) of the Gibbs sampler for MC-
LDA (for dealing with c-sets) is applied after
burn-in phrase.
Domain knowledge: User knowledge about a do-
main can vary a great deal. Different users may
have very different knowledge. To reduce this var-
iance for a more reliable evaluation, instead of
asking a human user to provide m-sets, we obtain
the synonym sets and the antonym sets of each
word that is a noun or adjective (as words of other
parts-of-speech usually do not indicate aspects)
from WordNet (Miller, 1995) and manually verify
the words in those sets for the domain. Note that if
a word ğ‘¤ is not provided with any m-set, it is
treated as a singleton m-set {ğ‘¤}. For c-sets, we ran
LDA in each domain and provide c-sets based on
the wrong results of LDA as in (Andrzejewski et
al., 2009). Then, the knowledge is provided to
each model in the format required by each model.
The numbers of m-sets and c-sets are listed in col-
umns 4 and 5 of Table 2. Duplicate sets have been
removed.
</bodyText>
<subsectionHeader confidence="0.985269">
7.2 Objective Evaluation
</subsectionHeader>
<bodyText confidence="0.942915">
In this section, we evaluate our proposed MC-
</bodyText>
<footnote confidence="0.844888">
3 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html
</footnote>
<figureCaption confidence="0.997729">
Figure 5. Avg. Topic Coherence score for different
proportions of knowledge.
</figureCaption>
<bodyText confidence="0.999900347826087">
LDA model objectively. Topic models are often
evaluated using perplexity on held-out test data.
However, the perplexity metric does not reflect the
semantic coherence of individual topics learned by
a topic model (Newman et al., 2010). Recent re-
search has shown potential issues with perplexity
as a measure: (Chang et al., 2009) suggested that
the perplexity can sometimes be contrary to human
judgments. Also, perplexity does not really reflect
our goal of finding coherent aspects with accurate
semantic clustering. It only provides a measure of
how well the model fits the data.
The Topic Coherence metric (Mimno et al.,
2011) (also called the â€œUMassâ€ measure (Stevens
and Buttler, 2012)) was proposed as a better alter-
native for assessing topic quality. This metric re-
lies upon word co-occurrence statistics within the
documents, and does not depend on external re-
sources or human labeling. It was shown that topic
coherence is highly consistent with human expert
labeling by Mimno et al. (2011). Higher topic co-
herence score indicates higher quality of topics,
i.e., better topic interpretability.
</bodyText>
<subsectionHeader confidence="0.997802">
Effects of Number of Topics
</subsectionHeader>
<bodyText confidence="0.998545333333333">
Since our proposed models and the baseline mod-
els are all parametric models, we first compare
each model given different numbers of topics.
Figure 4 shows the average Topic Coherence score
of each model given different numbers of topics.
From Figure 4, we note the following:
</bodyText>
<listItem confidence="0.977526">
1. MC-LDA consistently achieves the highest To-
pic Coherence scores given different numbers
of topics. M-LDA also works better than the
other baseline models, but not as well as MC-
LDA. This shows that both m-sets and c-sets
are beneficial in producing coherent aspects.
2. DF-LDA variants, DF-M and DF-MC, do not
perform well due to the shortcomings discussed
</listItem>
<page confidence="0.98926">
1662
</page>
<figure confidence="0.996032111111111">
1.0
0.9
0.8
0.7
0.6
0.5
Camera Food Computer Care
MC-LDA M-LDA LDA
DF-M DF-MC LDA-GPU
</figure>
<figureCaption confidence="0.989983">
Figure 6. Avg. p@5 of good topics for each model
across different domains.
</figureCaption>
<bodyText confidence="0.7778535">
The models of each bar from left to rights are MC-LDA, M-
LDA, LDA, DF-M, DF-MC, LDA-GPU. (Same for Figure 7)
</bodyText>
<figure confidence="0.995074833333333">
1.0
0.9
0.8
0.7
0.6
0.5
</figure>
<figureCaption confidence="0.993774">
Figure 7. Avg. p@10 of good topics for each model
across different domains.
</figureCaption>
<bodyText confidence="0.996545653846154">
in Â§ 1. It is slightly better than LDA when T =
15, but worse than LDA in other cases. We will
further analyze the effects of knowledge on
MC-LDA and DF-LDA shortly.
3. LDA-GPU does not perform well due to its use
of co-document frequency. As frequent words
usually have high co-document frequency with
many other words, the frequent words are
ranked top in many topics. This shows that the
guidance using domain knowledge is more ef-
fective than using co-document frequency.
In terms of improvements, MC-LDA outperforms
M-LDA significantly ( p &lt; 0.03 ) and all other
baseline models significantly (p &lt; 0.01) based on
a paired t-test. It is important to note that by no
means do we say that LDA-GPU and DF-LDA are
not effective. We only say that for the task of as-
pect extraction and leveraging domain knowledge,
these models do not generate as coherent aspects
as ours because of their shortcomings discussed in
Â§ 1. In general, with more topics, the Topic Coher-
ence scores increase. We found that when T is
larger than 15, aspects found by each model be-
came more and more overlapping, with several
aspects expressing the same features of products.
So we fix T = 15 in the subsequent experiments.
</bodyText>
<subsectionHeader confidence="0.996522">
Effects of Knowledge
</subsectionHeader>
<bodyText confidence="0.999973">
To further analyze the effects of knowledge on
models, in each domain, we randomly sampled
different proportions of knowledge (i.e., different
numbers of m-sets/must-links and c-sets/cannot-
links) as shown in Figure 5, where 0% means no
knowledge (same as LDA and LDA-GPU, which
do not incorporate knowledge) and 100% means
all knowledge. From Figure 5, we see that MC-
LDA and M-LDA both perform consistently better
than DF-MC and DF-M across different propor-
tions of knowledge. With the increasing number of
knowledge sets, MC-LDA and M-LDA achieve
higher Topic Coherence scores (i.e., produce more
coherent aspects). In general, MC-LDA performs
the best. For both DF-MC and DF-M, the Topic
Coherence score increases from 0% to 25%
knowledge, but decreases with more knowledge
(50% and 100%). This shows that with limited
amount of knowledge, the shortcomings of DF-
LDA are not very obvious, but with more
knowledge, these issues become more serious and
thus degrade the performance of DF-LDA.
</bodyText>
<subsectionHeader confidence="0.998781">
7.3 Human Evaluation
</subsectionHeader>
<bodyText confidence="0.999821208333333">
Since our aim is to make topics more interpretable
and conformable to human judgments, we worked
with two judges who are familiar with Amazon
products and reviews to evaluate the models sub-
jectively. Since topics from topic models are rank-
ings based on word probability and we do not
know the number of correct topical words, a natu-
ral way to evaluate these rankings is to use Preci-
sion@n (or p@n) which was also used in
(Mukherjee and Liu, 2012; Zhao et al., 2010),
where n is the rank position. We give p@n for n =
5 and 10. There are two steps in human evaluation:
topic labeling and word labeling.
Topic Labeling: We followed the instructions in
(Mimno et al., 2011) and asked the judges to label
each topic as good or bad. Each topic was present-
ed as a list of 10 most probable words in descend-
ing order of their probabilities under that topic.
The models which generated the topics for label-
ing were obscure to the judges. In general, each
topic was annotated as good if it had more than
half of its words coherently related to each other
representing a semantic concept together; other-
wise bad. Agreement of human judges on topic
</bodyText>
<figure confidence="0.630801">
Camera Food Computer Care
MC-LDA M-LDA LDA
DF-M DF-MC LDA-GPU
</figure>
<page confidence="0.943897">
1663
</page>
<bodyText confidence="0.999756352941177">
labeling using Cohenâ€™s Kappa yielded a score of
0.92 indicating almost perfect agreements accord-
ing to the scale in (Landis and Koch, 1977). This
is reasonable as topic labeling is an easy task and
semantic coherence can be judged well by humans.
Word Labeling: After topic labeling, we chose
the topics, which were labeled as good by both
judges, as good topics. Then, we asked the two
judges to label each word of the top 10 words in
these good topics. Each word was annotated as
correct if it was coherently related to the concept
represented by the topic; otherwise incorrect.
Since judges already had the conception of each
topic in mind when they were labeling topics, la-
beling each word was not difficult which explains
the high Kappa score for this labeling task (score =
0.892).
</bodyText>
<subsectionHeader confidence="0.48694">
Quantitative Results
</subsectionHeader>
<bodyText confidence="0.999902388888889">
Figures 6 and 7 give the average p@S and p@10
of all good topics over all four domains. The num-
bers of good topics generated by each model are
shown in Table 3. We can see that the human
evaluation results are highly consistent with Topic
Coherence results in Â§7.2. MC-LDA improves
over M-LDA significantly (ğ‘ &lt; 0.01) and both
MC-LDA and M-LDA outperforms the other base-
line models significantly ( ğ‘ &lt; 0.005 ) using a
paired t-test. We also found that when the domain
knowledge is simple with one word usually ex-
pressing only one meaning/sense (e.g., in the do-
main â€œComputerâ€), DF-LDA performs better than
LDA. In other domains, it performs similarly or
worse than LDA. Again, it shows that DF-LDA is
not effective to handle complex knowledge, which
is consistent with the results of effects of
knowledge on DF-LDA in Â§7.2.
</bodyText>
<subsectionHeader confidence="0.698388">
Qualitative Results
</subsectionHeader>
<bodyText confidence="0.983879916666667">
We now show some qualitative results to give an
intuitive feeling of the outputs from different mod-
els. There are a large number of aspects that are
dramatically improved by MC-LDA. Due to space
constraints, we only show some examples. To fur-
ther focus, we just show some results of MC-LDA,
M-LDA and LDA. The results from LDA-GPU
and DF-LDA were inferior and hard for the human
judges to match them with aspects found by the
other models for qualitative comparison.
Table 4 shows three aspects Amazon, Price,
Battery generated by each model in the domain
</bodyText>
<table confidence="0.999364571428571">
#Good MC-LDA M-LDA LDA DF-M DF-MC LDA-GPU
Topics
Camera 15/18 12 11 9 7 3
Food 8/16 7 7 5 4 5
Computer 12/16 10 7 9 6 4
Care 11/16 10 9 10 9 3
Average 11.5/16.5 9.75/15 8.5/15 8.25/15 6.5/15 3.75/15
</table>
<tableCaption confidence="0.994484">
Table 3. Number of good topics of each model.
</tableCaption>
<bodyText confidence="0.681107">
In x/y, x is the number of discovered good topics, and y is the
total number of topics generated.
MC-LDA M-LDA LDA
Amazon Price Battery Price Battery Amazon Battery
review price battery price battery card battery
amazon perform life lot review day screen
software money day money amazon amazon life
customer expensive extra big life memory lcd
month cost charger expensive extra product water
support week water point day sd usb
warranty cheap time cost power week cable
package purchase power photo time month case
product deal hour dot support item charger
hardware product aa purchase customer class hour
</bodyText>
<tableCaption confidence="0.9941085">
Table 4. Example aspects in the domain â€œCameraâ€;
errors are marked in red/italic.
</tableCaption>
<bodyText confidence="0.9989738">
â€œCameraâ€. Both LDA and M-LDA can only dis-
cover two aspects but M-LDA has a higher aver-
age precision. Given the c-set {amazon, price,
battery}, MC-LDA can discover all three aspects
with the highest average precision.
</bodyText>
<sectionHeader confidence="0.998661" genericHeader="conclusions">
8 Conclusion
</sectionHeader>
<bodyText confidence="0.9999388125">
This paper proposed a new model to exploit do-
main knowledge in the form of m-sets and c-sets
to generate coherent aspects (topics) from online
reviews. The paper first identified and character-
ized some shortcomings of the existing
knowledge-based models. A new model called
MC-LDA was then proposed, whose sampling
scheme was based on the proposed Extended GPU
(E-GPU) model enabling multi-urn interactions. A
comprehensive evaluation using real-life online
reviews from multiple domains shows that MC-
LDA outperforms the state-of-the-art models sig-
nificantly and discovers aspects with high seman-
tic coherence. In our future work, we plan to
incorporate aspect specific sentiments in the MC-
LDA model.
</bodyText>
<sectionHeader confidence="0.999024" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.69070975">
This work was supported in part by a grant from
National Science Foundation (NSF) under grant no.
IIS-1111092, and a grant from HP Labs Innova-
tion Research Program.
</bodyText>
<page confidence="0.994664">
1664
</page>
<sectionHeader confidence="0.996098" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999690509090909">
Amjad Abu-Jbara, Ben King, Mona Diab, and
Dragomir Radev. 2013. Identifying Opinion
Subgroups in Arabic Online Discussions. In
Proceedings of ACL.
Apoorv Agarwal and Jasneet Sabharwal. 2012. End-to-
End Sentiment Analysis of Twitter Data. In
Proceedings of the Workshop on Information
Extraction and Entity Analytics on Social Media
Data, at the 24th International Conference on
Computational Linguistics (IEEASMD-COLING
2012), Vol. 2.
David Andrzejewski, Xiaojin Zhu, and Mark Craven.
2009. Incorporating domain knowledge into topic
modeling via Dirichlet Forest priors. In Proceedings
of ICML, pages 25â€“32.
David Andrzejewski, Xiaojin Zhu, Mark Craven, and
Benjamin Recht. 2011. A framework for
incorporating general domain knowledge into latent
Dirichlet allocation using first-order logic. In
Proceedings of IJCAI, pages 1171â€“1177.
Sasha Blair-goldensohn, Tyler Neylon, Kerry Hannan,
George A. Reis, Ryan Mcdonald, and Jeff Reynar.
2008. Building a sentiment summarizer for local
service reviews. In Proceedings of In NLP in the
Information Explosion Era.
David M. Blei and Jon D. McAuliffe. 2007. Supervised
Topic Models. In Proceedings of NIPS.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent Dirichlet Allocation. Journal of
Machine Learning Research, 3, 993â€“1022.
S. R. K. Branavan, Harr Chen, Jacob Eisenstein, and
Regina Barzilay. 2008. Learning Document-Level
Semantic Properties from Free-Text Annotations. In
Proceedings of ACL, pages 263â€“271.
Samuel Brody and Noemie Elhadad. 2010. An
unsupervised aspect-sentiment model for online
reviews. In Proceedings of NAACL, pages 804â€“812.
Nicola Burns, Yaxin Bi, Hui Wang, and Terry
Anderson. 2012. Extended Twofold-LDA Model for
Two Aspects in One Sentence. Advances in
Computational Intelligence, Vol. 298, pages 265â€“
275. Springer Berlin Heidelberg.
Giuseppe Carenini, Raymond T. Ng, and Ed Zwart.
2005. Extracting knowledge from evaluative text. In
Proceedings of K-CAP, pages 11â€“18.
Jonathan Chang, Jordan Boyd-Graber, Wang Chong,
Sean Gerrish, and David Blei, M. 2009. Reading Tea
Leaves: How Humans Interpret Topic Models. In
Proceedings of NIPS, pages 288â€“296.
Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun
Hsu, Malu Castellanos, and Riddhiman Ghosh.
2013a. Leveraging Multi-Domain Prior Knowledge
in Topic Models. In Proceedings of IJCAI, pages
2071â€“2077.
Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun
Hsu, Malu Castellanos, and Riddhiman Ghosh.
2013b. Discovering Coherent Topics Using General
Knowledge. In Proceedings of CIKM.
Yejin Choi and Claire Cardie. 2010. Hierarchical
Sequential Learning for Extracting Opinions and
their Attributes, pages 269â€“274.
Lei Fang and Minlie Huang. 2012. Fine Granular
Aspect Analysis using Latent Structural Models. In
Proceedings of ACL, pages 333â€“337.
Thomas L. Griffiths and Mark Steyvers. 2004. Finding
Scientific Topics. PNAS, 101 Suppl, 5228â€“5235.
Honglei Guo, Huijia Zhu, Zhili Guo, Xiaoxun Zhang,
and Zhong Su. 2009. Product feature categorization
with multilevel latent semantic association. In
Proceedings of CIKM, pages 1087â€“1096.
Gregor Heinrich. 2009. A Generic Approach to Topic
Models. In Proceedings of ECML PKDD, pages 517
â€“ 532.
Minqing Hu and Bing Liu. 2004. Mining and
Summarizing Customer Reviews. In Proceedings of
KDD, pages 168â€“177.
Yuening Hu, Jordan Boyd-Graber, and Brianna
Satinoff. 2011. Interactive Topic Modeling. In
Proceedings of ACL, pages 248â€“257.
Hemant Ishwaran and LF James. 2001. Gibbs sampling
methods for stick-breaking priors. Journal of the
American Statistical Association, 96(453), 161â€“173.
Jagadeesh Jagarlamudi, Hal DaumÃ© III, and
Raghavendra Udupa. 2012. Incorporating Lexical
Priors into Topic Models. In Proceedings of EACL,
pages 204â€“213.
Niklas Jakob and Iryna Gurevych. 2010. Extracting
Opinion Targets in a Single- and Cross-Domain
Setting with Conditional Random Fields. In
Proceedings of EMNLP, pages 1035â€“1045.
Yohan Jo and Alice H. Oh. 2011. Aspect and sentiment
unification model for online review analysis. In
Proceedings of WSDM, pages 815â€“824.
Alistair Kennedy and Diana Inkpen. 2006. Sentiment
Classification of Movie Reviews Using Contextual
Valence Shifters. Computational Intelligence, 22(2),
110â€“125.
Jungi Kim, Jinji Li, and Jong-Hyeok Lee. 2009.
Discovering the Discriminative Views: Measuring
Term Weights for Sentiment Analysis. In
Proceedings of ACL/IJCNLP, pages 253â€“261.
Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, and
Shixia Liu. 2013. A Hierarchical Aspect-Sentiment
Model for Online Reviews. In Proceedings of AAAI.
Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto.
2007. Extracting Aspect-Evaluation and Aspect-of
Relations in Opinion Mining. In Proceedings of
EMNLP, pages 1065â€“1074.
Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen. 2006.
Opinion Extraction, Summarization and Tracking in
</reference>
<page confidence="0.917391">
1665
</page>
<reference confidence="0.9992344375">
News and Blog Corpora. In Proceedings of AAAI
Spring Symposium: Computational Approaches to
Analyzing Weblogs, pages 100â€“107.
JR Landis and GG Koch. 1977. The measurement of
observer agreement for categorical data. biometrics,
33.
Angeliki Lazaridou, Ivan Titov, and Caroline Sporleder.
2013. A Bayesian Model for Joint Unsupervised
Induction of Sentiment, Aspect and Discourse
Representations. In Proceedings of ACL.
Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu,
Yingju Xia, Shu Zhang, and Hao Yu. 2010.
Structure-Aware Review Mining and
Summarization. In Proceedings of COLING, pages
653â€“661.
Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang, and
Xiaoyan Zhu. 2012a. Cross-Domain Co-Extraction
of Sentiment and Topic Lexicons. In Proceedings of
ACL (1), pages 410â€“419.
Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang. 2011.
Generating Aspect-oriented Multi-Document
Summarization with Event-aspect model. In
Proceedings of EMNLP, pages 1137â€“1146.
Shoushan Li, Rongyang Wang, and Guodong Zhou.
2012b. Opinion Target Extraction Using a Shallow
Semantic Parsing Framework. In Proceedings of
AAAI.
Chenghua Lin and Yulan He. 2009. Joint
sentiment/topic model for sentiment analysis. In
Proceedings of CIKM, pages 375â€“384.
Bing Liu. 2012. Sentiment Analysis and Opinion
Mining. Morgan &amp; Claypool Publishers.
Bin Lu, Myle Ott, Claire Cardie, and Benjamin K.
Tsou. 2011. Multi-aspect Sentiment Analysis with
Topic Models. In Proceedings of ICDM Workshops,
pages 81â€“88.
Yue Lu, Hongning Wang, ChengXiang Zhai, and Dan
Roth. 2012. Unsupervised discovery of opposing
opinion networks from forum discussions. In
Proceedings of CIKM, pages 1642â€“1646.
Yue Lu and Chengxiang Zhai. 2008. Opinion
integration through semi-supervised topic modeling.
In Proceedings of WWW, pages 121â€“130.
Yue Lu, ChengXiang Zhai, and Neel Sundaresan. 2009.
Rated aspect summarization of short comments. In
Proceedings of WWW, pages 131â€“140.
Hosam Mahmoud. 2008. Polya Urn Models. Chapman
&amp; Hall/CRC Texts in Statistical Science.
Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su,
and ChengXiang Zhai. 2007. Topic sentiment
mixture: modeling facets and opinions in weblogs. In
Proceedings of WWW, pages 171â€“180.
Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou,
Sujian Li, and Houfeng Wang. 2012. Entity-centric
topic-oriented opinion summarization in twitter. In
Proceedings of KDD, pages 379â€“387.
George A. Miller. 1995. WordNet: A Lexical Database
for English. Commun. ACM, 38(11), 39â€“41.
David Mimno, Hanna M. Wallach, Edmund Talley,
Miriam Leenders, and Andrew McCallum. 2011.
Optimizing semantic coherence in topic models. In
Proceedings of EMNLP, pages 262â€“272.
Samaneh Moghaddam and Martin Ester. 2011. ILDA:
interdependent LDA model for learning latent
aspects and their ratings from online product
reviews. In Proceedings of SIGIR, pages 665â€“674.
Saif Mohammad, Cody Dunne, and Bonnie J. Dorr.
2009. Generating High-Coverage Semantic
Orientation Lexicons From Overtly Marked Words
and a Thesaurus. In Proceedings of EMNLP, pages
599â€“608.
Arjun Mukherjee and Bing Liu. 2012. Aspect
Extraction through Semi-Supervised Modeling. In
Proceedings of ACL, pages 339â€“348.
David Newman, Youn Noh, Edmund Talley, Sarvnaz
Karimi, and Timothy Baldwin. 2010. Evaluating
topic models for digital libraries. In Proceedings of
JCDL, pages 215â€“224.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and Trends in
Information Retrieval, 2(1-2), 1â€“135.
James Petterson, Alex Smola, TibÃ©rio Caetano, Wray
Buntine, and Shravan Narayanamurthy. 2010. Word
Features for Latent Dirichlet Allocation. In
Proceedings of NIPS, pages 1921â€“1929.
AM Popescu and Oren Etzioni. 2005. Extracting
product features and opinions from reviews. In
Proceedings of HLT, pages 339â€“346.
Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011.
Opinion Word Expansion and Target Extraction
through Double Propagation. Computational
Linguistics, 37(1), 9â€“27.
Daniel Ramage, David Hall, Ramesh Nallapati, and
Christopher D. Manning. 2009. Labeled LDA: a
supervised topic model for credit attribution in multi-
labeled corpora. In Proceedings of EMNLP, pages
248â€“256.
Christina Sauper and Regina Barzilay. 2013. Automatic
Aggregation by Joint Modeling of Aspects and
Values. J. Artif. Intell. Res. (JAIR), 46, 89â€“127.
Christina Sauper, Aria Haghighi, and Regina Barzilay.
2011. Content Models with Attitude. In Proceedings
of ACL, pages 350â€“358.
Swapna Somasundaran and J. Wiebe. 2009.
Recognizing stances in online debates. In
Proceedings of ACL, pages 226â€“234.
Keith Stevens and PKDAD Buttler. 2012. Exploring
Topic Coherence over many models and many
topics. In Proceedings of EMNLP-CoNLL, pages
952â€“961.
Veselin Stoyanov and Claire Cardie. 2011.
Automatically Creating General-Purpose Opinion
</reference>
<page confidence="0.814379">
1666
</page>
<reference confidence="0.999907338461539">
Summaries from Text. In Proceedings of RANLP,
pages 202â€“209.
Yee Whye Teh, Michael I. Jordan, Matthew J. Beal,
and David M. Blei. 2006. Hierarchical dirichlet
processes. Journal of the American Statistical
Association, 1â€“30.
Ivan Titov and Ryan McDonald. 2008. Modeling online
reviews with multi-grain topic models. In
Proceedings of WWW, pages 111â€“120.
Dong Wang and Yang Liu. 2011. A Pilot Study of
Opinion Summarization in Conversations. In
Proceedings of ACL, pages 331â€“339.
Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010.
Latent aspect rating analysis on review text data: a
rating regression approach. In Proceedings of KDD,
pages 783â€“792.
Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011.
Latent aspect rating analysis without aspect keyword
supervision. In Proceedings of KDD, pages 618â€“626.
Janyce Wiebe and Ellen Riloff. 2005. Creating
Subjective and Objective Sentence Classifiers from
Unannotated Texts. In Proceedings of CICLing,
pages 486â€“497.
Janyce Wiebe, Theresa Wilson, Rebecca F. Bruce,
Matthew Bell, and Melanie Martin. 2004. Learning
Subjective Language. Computational Linguistics,
30(3), 277â€“308.
Michael Wiegand and Dietrich Klakow. 2010.
Convolution Kernels for Opinion Holder Extraction.
In Proceedings of HLT-NAACL, pages 795â€“803.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide
Wu. 2009. Phrase dependency parsing for opinion
mining. In Proceedings of EMNLP, pages 1533â€“
1541.
Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide
Wu. 2011. Structural Opinion Mining for Graph-
based Sentiment Representation. In Proceedings of
EMNLP, pages 1332â€“1341.
Yunqing Xia, Boyi Hao, and Kam-Fai Wong. 2009.
Opinion Target Network and Bootstrapping Method
for Chinese Opinion Target Extraction. In
Proceedings of AIRS, pages 339â€“350.
Jianxing Yu, Zheng-Jun Zha, Meng Wang, and Tat-
Seng Chua. 2011. Aspect Ranking: Identifying
Important Product Aspects from Online Consumer
Reviews. In Proceedings of ACL, pages 1496â€“1505.
Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia. 2011.
Constrained LDA for grouping product features in
opinion mining. In Proceedings of the 15th Pacific-
Asia Conference on Knowledge Discovery and Data
Mining (PAKDD), pages 448â€“459.
Lei Zhang and Bing Liu. 2011. Identifying Noun
Product Features that Imply Opinions. In
Proceedings of ACL (Short Papers), pages 575â€“580.
Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and
Xiaoming Li. 2010. Jointly Modeling Aspects and
Opinions with a MaxEnt-LDA Hybrid. In
Proceedings of EMNLP, pages 56â€“65.
Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2012.
Cross-Language Opinion Target Extraction in
Review Texts. In Proceedings of ICDM, pages
1200â€“1205.
Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006. Movie
review mining and summarization. In Proceedings of
CIKM, pages 43â€“50. ACM Press.
</reference>
<page confidence="0.993625">
1667
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.711456">
<title confidence="0.999977">Exploiting Domain Knowledge in Aspect Extraction</title>
<author confidence="0.9671825">Zhiyuan Chen</author>
<author confidence="0.9671825">Arjun Mukherjee</author>
<author confidence="0.9671825">Meichun Hsu</author>
<author confidence="0.9671825">Malu Castellanos</author>
<author confidence="0.9671825">Bing Liu Riddhiman Ghosh</author>
<affiliation confidence="0.999939">University of Illinois at Chicago HP Labs</affiliation>
<address confidence="0.993592">Chicago, IL 60607, USA Palo Alto, CA 94304, USA</address>
<email confidence="0.9421825">czyuanacm@hp.com</email>
<email confidence="0.9421825">arjun4787}@gmail.com@hp.com</email>
<email confidence="0.9421825">liub@cs.uic.edu{meichun.hsu@hp.com</email>
<email confidence="0.9421825">malu.castellanos@hp.com</email>
<email confidence="0.9421825">riddhiman.ghosh@hp.com</email>
<abstract confidence="0.99902084">Aspect extraction is one of the key tasks in sentiment analysis. In recent years, statistical models have been used for the task. However, such models without any domain knowledge often produce aspects that are not interpretable in applications. To tackle the issue, some knowledge-based topic models have been proposed, which allow the user to input some prior domain knowledge to generate coherent aspects. However, existing knowledge-based topic models have several major shortcomings, e.g., little work has been done to incorporate the cannot-link type of knowledge or to automatically adjust the number of topics based on domain knowledge. This paper proposes a more advanced topic model, called with m-set and c-set), to address these problems, which is based on an generalized PÃ³lya urn model (which is also proposed in this paper). Experiments on real-life product reviews from a variety of domains show that MC- LDA outperforms the existing state-of-the-art models markedly.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Amjad Abu-Jbara</author>
<author>Ben King</author>
<author>Mona Diab</author>
<author>Dragomir Radev</author>
</authors>
<title>Identifying Opinion Subgroups in Arabic Online Discussions.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="10006" citStr="Abu-Jbara et al., 2013" startWordPosition="1646" endWordPosition="1649">ardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform ex</context>
</contexts>
<marker>Abu-Jbara, King, Diab, Radev, 2013</marker>
<rawString>Amjad Abu-Jbara, Ben King, Mona Diab, and Dragomir Radev. 2013. Identifying Opinion Subgroups in Arabic Online Discussions. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Apoorv Agarwal</author>
<author>Jasneet Sabharwal</author>
</authors>
<title>End-toEnd Sentiment Analysis of Twitter Data.</title>
<date>2012</date>
<booktitle>In Proceedings of the Workshop on Information Extraction and Entity Analytics on Social Media Data, at the 24th International Conference on Computational Linguistics (IEEASMD-COLING</booktitle>
<volume>2</volume>
<contexts>
<context position="10368" citStr="Agarwal and Sabharwal, 2012" startWordPosition="1702" endWordPosition="1705">kherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g.</context>
</contexts>
<marker>Agarwal, Sabharwal, 2012</marker>
<rawString>Apoorv Agarwal and Jasneet Sabharwal. 2012. End-toEnd Sentiment Analysis of Twitter Data. In Proceedings of the Workshop on Information Extraction and Entity Analytics on Social Media Data, at the 24th International Conference on Computational Linguistics (IEEASMD-COLING 2012), Vol. 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Andrzejewski</author>
<author>Xiaojin Zhu</author>
<author>Mark Craven</author>
</authors>
<title>Incorporating domain knowledge into topic modeling via Dirichlet Forest priors.</title>
<date>2009</date>
<booktitle>In Proceedings of ICML,</booktitle>
<pages>25--32</pages>
<contexts>
<context position="2619" citStr="Andrzejewski et al., 2009" startWordPosition="396" endWordPosition="399">ee Â§ 2). Topic models, such as LDA (Blei et al., 2003), provide an unsupervised framework for extracting latent topics in text documents. Topics are aspect categories (or simply aspects) in our context. However, in recent years, researchers have found that fully unsupervised topic models may not produce topics that are very coherent for a particular application. This is because the objective functions of topic models do not always correlate well with human judgments and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were proposed. They enable the user to specify prior knowledge as seed words/terms for some topics. Petterson et al. (2010) also u</context>
<context position="6614" citStr="Andrzejewski et al., 2009" startWordPosition="1055" endWordPosition="1058">ttenuation of the frequent (often domain important) words can result in some irrelevant words being ranked higher (with higher probabilities). To address the above shortcomings, we define m-set (for must-set) as a set of words that should belong to the same topic and c-set (cannot-set) as a set of words that should not be in the same topic. They are similar to must-link and cannot-link but m-sets do not enforce transitivity. Transitivity is the main cause of the inability to handle multiple senses. Our m-sets and c-sets are also more concise providing knowledge in the context of a set. As in (Andrzejewski et al., 2009), we assume that there is no conflict between m-sets and c-sets, i.e., if w1 is a cannot-word of w2 (i.e., shares a c-set with w2), any word that shares an m-set with w1 is also a cannot-word of w2. Note that knowledge as m-sets has also been used in (Chen et al., 2013a) and (Chen et al., 2013b). We then propose a new topic model, called MCLDA (LDA with m-set and c-set), which is not only able to deal with c-sets and automatically adjust the number of topics, but also deal with the multiple senses and adverse effect of knowledge problems at the same time. For the issue of multiple senses, a ne</context>
<context position="25556" citStr="Andrzejewski et al., 2009" startWordPosition="4564" endWordPosition="4567">ibbs sampling has the same number of topic (T) as the previous sweep, we increment T by 1. And then assign T to zb . The counts and parameters are also updated accordingly. 7 Experiments We now evaluate the proposed MC-LDA model and compare it with state-of-the-art existing models. Two unsupervised baseline models that we compare with are: â€¢ LDA: LDA is the basic unsupervised topic model (Blei et al., 2003). â€¢ LDA-GPU: LDA with GPU (Mimno et al., 2011). Specifically, LDA-GPU applies GPU in LDA using co-document frequency. As for knowledge-based models, we focus on comparing with DF-LDA model (Andrzejewski et al., 2009), which is perhaps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-links and cannot-links. This is the full DF-LDA model in (Andrzejewski et al., 2009). We do not compare with seeded models in (Burns et al., 2012; Jagarlamudi et al., 2012; L</context>
<context position="29182" citStr="Andrzejewski et al., 2009" startWordPosition="5172" endWordPosition="5175">s (see Â§7.2) as it is hard to know the exact number of topics. While non-parametric Bayesian approaches (Teh et al., 2006) aim to estimate T from the corpus, they are often sensitive to the hyper-parameters (Heinrich, 2009). 1 http://nlp.stanford.edu/software/corenlp.shtml 2 http://jmlr.org/papers/volume5/lewis04a/a11-smart-stop-list 1661 3 6 9 12 15 MC-LDA M-LDA LDA DF-M DF-MC LDA-GPU 0% 25% 50% 100% MC-LDA M-LDA DF-M DF-MC -1200 -1300 -1400 -1500 -1600 -1240 -1260 -1280 -1300 -1320 Figure 4. Avg. Topic Coherence score of each model across different number of topics. For DF-LDA, we followed (Andrzejewski et al., 2009) to generate must-links and cannot-links from our domain knowledge. We then ran DFLDA3 while keeping its parameters as proposed in (Andrzejewski et al., 2009) (we also experimented with different parameter settings but they did not produce better results). For our proposed model, we estimated the thresholds using cross validation in our pilot experiments. Estimated value ğœ = 0.2 in equation 3 yielded good results. The second stage (steps 2 and 3) of the Gibbs sampler for MCLDA (for dealing with c-sets) is applied after burn-in phrase. Domain knowledge: User knowledge about a domain can vary a </context>
<context position="30414" citStr="Andrzejewski et al., 2009" startWordPosition="5386" endWordPosition="5389">deal. Different users may have very different knowledge. To reduce this variance for a more reliable evaluation, instead of asking a human user to provide m-sets, we obtain the synonym sets and the antonym sets of each word that is a noun or adjective (as words of other parts-of-speech usually do not indicate aspects) from WordNet (Miller, 1995) and manually verify the words in those sets for the domain. Note that if a word ğ‘¤ is not provided with any m-set, it is treated as a singleton m-set {ğ‘¤}. For c-sets, we ran LDA in each domain and provide c-sets based on the wrong results of LDA as in (Andrzejewski et al., 2009). Then, the knowledge is provided to each model in the format required by each model. The numbers of m-sets and c-sets are listed in columns 4 and 5 of Table 2. Duplicate sets have been removed. 7.2 Objective Evaluation In this section, we evaluate our proposed MC3 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html Figure 5. Avg. Topic Coherence score for different proportions of knowledge. LDA model objectively. Topic models are often evaluated using perplexity on held-out test data. However, the perplexity metric does not reflect the semantic coherence of individual topics learned by a </context>
</contexts>
<marker>Andrzejewski, Zhu, Craven, 2009</marker>
<rawString>David Andrzejewski, Xiaojin Zhu, and Mark Craven. 2009. Incorporating domain knowledge into topic modeling via Dirichlet Forest priors. In Proceedings of ICML, pages 25â€“32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Andrzejewski</author>
<author>Xiaojin Zhu</author>
<author>Mark Craven</author>
<author>Benjamin Recht</author>
</authors>
<title>A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic.</title>
<date>2011</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>1171--1177</pages>
<contexts>
<context position="2916" citStr="Andrzejewski et al., 2011" startWordPosition="445" endWordPosition="448">produce topics that are very coherent for a particular application. This is because the objective functions of topic models do not always correlate well with human judgments and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were proposed. They enable the user to specify prior knowledge as seed words/terms for some topics. Petterson et al. (2010) also used word similarity as priors for guidance. However, none of the existing models is capable of incorporating the cannot-link type of knowledge except DF-LDA (Andrzejewski et al., 2009). Furthermore, none of the existing models, including DF-LDA, is able to automatically adjust the number of topic</context>
<context position="5213" citStr="Andrzejewski et al., 2011" startWordPosition="817" endWordPosition="820">opics Amazon and Price. Apart from the above shortcoming, earlier knowledge-based topic models also have some major shortcomings: Incapability of handling multiple senses: A word typically has multiple meanings or senses. For example, light can mean â€œof little weightâ€ or â€œsomething that makes things visible.â€ DF-LDA cannot handle multiple senses because its definition of must-link is transitive. That is, if A and B form a must-link, and B and C form a must-link, it implies a must-link between A and C, indicating A, B, and C should be in the same topic. This case also applies to the models in (Andrzejewski et al., 2011), (Petterson et al., 2010), and (Mukherjee and Liu, 2012). Although the model in (Jagarlamudi et al., 2012) allows multiple senses, it requires that each topic has at most one set of seed words (seed set), which is restrictive as the amount of knowledge should not be limited. Sensitivity to the adverse effect of knowledge: When using must-links or seeds, existing models basically try to ensure that the words in a mustlink or a seed set have similar probabilities under a topic. This causes a problem: if a must-link comprises of a frequent word and an infrequent word, due to the redistribution o</context>
</contexts>
<marker>Andrzejewski, Zhu, Craven, Recht, 2011</marker>
<rawString>David Andrzejewski, Xiaojin Zhu, Mark Craven, and Benjamin Recht. 2011. A framework for incorporating general domain knowledge into latent Dirichlet allocation using first-order logic. In Proceedings of IJCAI, pages 1171â€“1177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sasha Blair-goldensohn</author>
<author>Tyler Neylon</author>
<author>Kerry Hannan</author>
<author>George A Reis</author>
<author>Ryan Mcdonald</author>
<author>Jeff Reynar</author>
</authors>
<title>Building a sentiment summarizer for local service reviews.</title>
<date>2008</date>
<booktitle>In Proceedings of In NLP in the Information Explosion Era.</booktitle>
<marker>Blair-goldensohn, Neylon, Hannan, Reis, Mcdonald, Reynar, 2008</marker>
<rawString>Sasha Blair-goldensohn, Tyler Neylon, Kerry Hannan, George A. Reis, Ryan Mcdonald, and Jeff Reynar. 2008. Building a sentiment summarizer for local service reviews. In Proceedings of In NLP in the Information Explosion Era.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Jon D McAuliffe</author>
</authors>
<title>Supervised Topic Models.</title>
<date>2007</date>
<booktitle>In Proceedings of NIPS.</booktitle>
<contexts>
<context position="11438" citStr="Blei and McAuliffe (2007)" startWordPosition="1874" endWordPosition="1877">orehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides those discussed in Â§ 1, the model (Hu et al., 2011) enables the user to provide guidance interactively. Blei and McAuliffe (2007) and Ramage et al. (2009) used document labels in supervised setting. In (Chen et al., 2013a), we proposed MDKLDA to leverage multi-domain knowledge, which serves as the basic mechanism to exploit m-sets in MC-LDA. In (Chen et al., 2013b), we proposed a framework (called GK-LDA) to explicitly deal with the wrong knowledge when exploring the lexical semantic relations as the general (domain independent) knowledge in topic models. But these models above did not consider the knowledge in the form of c-sets (or cannot-links). The generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) was first introduc</context>
</contexts>
<marker>Blei, McAuliffe, 2007</marker>
<rawString>David M. Blei and Jon D. McAuliffe. 2007. Supervised Topic Models. In Proceedings of NIPS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent Dirichlet Allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>3</volume>
<pages>993--1022</pages>
<contexts>
<context position="2047" citStr="Blei et al., 2003" startWordPosition="309" endWordPosition="312">s to extract entity aspects or features on which opinions have been expressed (Hu and Liu, 2004; Liu, 2012). For example, in a sentence â€œThe picture looks great,â€ the aspect is â€œpicture.â€ Aspect extraction consists of two sub-tasks: (1) extracting all aspect terms (e.g., â€œpictureâ€) from the corpus, and (2) clustering aspect terms with similar meanings (e.g., cluster â€œpictureâ€ and â€œphotoâ€ into one aspect category as they mean the same in the domain â€œCameraâ€). In this work, we adopt the topic modeling approach as it can perform both sub-tasks simultaneously (see Â§ 2). Topic models, such as LDA (Blei et al., 2003), provide an unsupervised framework for extracting latent topics in text documents. Topics are aspect categories (or simply aspects) in our context. However, in recent years, researchers have found that fully unsupervised topic models may not produce topics that are very coherent for a particular application. This is because the objective functions of topic models do not always correlate well with human judgments and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of p</context>
<context position="25340" citStr="Blei et al., 2003" startWordPosition="4531" endWordPosition="4534">indicator function, which restricts the ball to be transferred only to an urn that contains a higher proportion of its m-set. When no topic t can be successfully sampled and the current sweep (iteration) of Gibbs sampling has the same number of topic (T) as the previous sweep, we increment T by 1. And then assign T to zb . The counts and parameters are also updated accordingly. 7 Experiments We now evaluate the proposed MC-LDA model and compare it with state-of-the-art existing models. Two unsupervised baseline models that we compare with are: â€¢ LDA: LDA is the basic unsupervised topic model (Blei et al., 2003). â€¢ LDA-GPU: LDA with GPU (Mimno et al., 2011). Specifically, LDA-GPU applies GPU in LDA using co-document frequency. As for knowledge-based models, we focus on comparing with DF-LDA model (Andrzejewski et al., 2009), which is perhaps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-l</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent Dirichlet Allocation. Journal of Machine Learning Research, 3, 993â€“1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R K Branavan</author>
<author>Harr Chen</author>
<author>Jacob Eisenstein</author>
<author>Regina Barzilay</author>
</authors>
<title>Learning Document-Level Semantic Properties from Free-Text Annotations.</title>
<date>2008</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>263--271</pages>
<contexts>
<context position="9503" citStr="Branavan et al., 2008" startWordPosition="1557" endWordPosition="1560">loff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand </context>
</contexts>
<marker>Branavan, Chen, Eisenstein, Barzilay, 2008</marker>
<rawString>S. R. K. Branavan, Harr Chen, Jacob Eisenstein, and Regina Barzilay. 2008. Learning Document-Level Semantic Properties from Free-Text Annotations. In Proceedings of ACL, pages 263â€“271.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel Brody</author>
<author>Noemie Elhadad</author>
</authors>
<title>An unsupervised aspect-sentiment model for online reviews.</title>
<date>2010</date>
<booktitle>In Proceedings of NAACL,</booktitle>
<pages>804--812</pages>
<contexts>
<context position="9528" citStr="Brody and Elhadad, 2010" startWordPosition="1561" endWordPosition="1564">., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and dom</context>
<context position="27915" citStr="Brody and Elhadad, 2010" startWordPosition="4962" endWordPosition="4965">s noted in (Titov and McDonald, 2008), when standard topic models are applied to reviews as documents, they tend to produce topics that correspond to global properties of products (e.g., brand name), which make topics overlapping with each other. The reason is that all reviews of the same type of products discuss about the same aspects of these products. Only the brand names and product names are different. Thus, using individual reviews for modeling is not very effective. Although there are approaches which model sentences (Jo and Oh, 2011; Titov and McDonald, 2008), we take the approach of (Brody and Elhadad, 2010), dividing each review into sentences and treating each sentence as an independent document. Sentences can be used by all three baselines without any change to their models. Although the relationships between sentences are lost, the data is fair to all models. Parameter settings: For all models, posterior inference was drawn using 1000 Gibbs iterations with an initial burn-in of 100 iterations. For all models, we set a = 1 and fl = 0.1. We found that small changes of a and fl did not affect the results much, which was also reported in (Jo and Oh, 2011) who also used online reviews. For the num</context>
</contexts>
<marker>Brody, Elhadad, 2010</marker>
<rawString>Samuel Brody and Noemie Elhadad. 2010. An unsupervised aspect-sentiment model for online reviews. In Proceedings of NAACL, pages 804â€“812.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Burns</author>
<author>Yaxin Bi</author>
<author>Hui Wang</author>
<author>Terry Anderson</author>
</authors>
<title>Extended Twofold-LDA Model for Two Aspects in One Sentence.</title>
<date>2012</date>
<journal>Advances in Computational Intelligence,</journal>
<volume>298</volume>
<pages>265--275</pages>
<publisher>Springer</publisher>
<location>Berlin Heidelberg.</location>
<contexts>
<context position="3004" citStr="Burns et al., 2012" startWordPosition="460" endWordPosition="463">e functions of topic models do not always correlate well with human judgments and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were proposed. They enable the user to specify prior knowledge as seed words/terms for some topics. Petterson et al. (2010) also used word similarity as priors for guidance. However, none of the existing models is capable of incorporating the cannot-link type of knowledge except DF-LDA (Andrzejewski et al., 2009). Furthermore, none of the existing models, including DF-LDA, is able to automatically adjust the number of topics based on domain knowledge. The domain knowledge, such as cannot-links, may change the </context>
<context position="26127" citStr="Burns et al., 2012" startWordPosition="4661" endWordPosition="4664">g with DF-LDA model (Andrzejewski et al., 2009), which is perhaps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-links and cannot-links. This is the full DF-LDA model in (Andrzejewski et al., 2009). We do not compare with seeded models in (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012) as seed sets are special cases of must-links and they also do not allow c-sets (or cannot-links). 7.1 Datasets and Settings Datasets: We use product reviews from four domains (types of products) from Amazon.com for evaluation. The corpus statistics are shown in Table 2 (columns 2 and 3). The domains are â€œCamera,â€ â€œFood,â€ â€œComputer,â€ and â€œCareâ€ (short for â€œPersonal Careâ€). We have made the datasets publically available at the website of the first author. Domain #Reviews #Sentences #M-sets #C-sets Camera 500 5171 173 18 Food 5</context>
</contexts>
<marker>Burns, Bi, Wang, Anderson, 2012</marker>
<rawString>Nicola Burns, Yaxin Bi, Hui Wang, and Terry Anderson. 2012. Extended Twofold-LDA Model for Two Aspects in One Sentence. Advances in Computational Intelligence, Vol. 298, pages 265â€“ 275. Springer Berlin Heidelberg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giuseppe Carenini</author>
<author>Raymond T Ng</author>
<author>Ed Zwart</author>
</authors>
<title>Extracting knowledge from evaluative text.</title>
<date>2005</date>
<booktitle>In Proceedings of K-CAP,</booktitle>
<pages>11--18</pages>
<contexts>
<context position="10712" citStr="Carenini et al., 2005" startWordPosition="1757" endWordPosition="1760">ls (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides tho</context>
</contexts>
<marker>Carenini, Ng, Zwart, 2005</marker>
<rawString>Giuseppe Carenini, Raymond T. Ng, and Ed Zwart. 2005. Extracting knowledge from evaluative text. In Proceedings of K-CAP, pages 11â€“18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Chang</author>
<author>Jordan Boyd-Graber</author>
<author>Wang Chong</author>
<author>Sean Gerrish</author>
<author>David Blei</author>
<author>M</author>
</authors>
<title>Reading Tea Leaves: How Humans Interpret Topic Models.</title>
<date>2009</date>
<booktitle>In Proceedings of NIPS,</booktitle>
<pages>288--296</pages>
<contexts>
<context position="2494" citStr="Chang et al., 2009" startWordPosition="378" endWordPosition="381">omain â€œCameraâ€). In this work, we adopt the topic modeling approach as it can perform both sub-tasks simultaneously (see Â§ 2). Topic models, such as LDA (Blei et al., 2003), provide an unsupervised framework for extracting latent topics in text documents. Topics are aspect categories (or simply aspects) in our context. However, in recent years, researchers have found that fully unsupervised topic models may not produce topics that are very coherent for a particular application. This is because the objective functions of topic models do not always correlate well with human judgments and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were </context>
<context position="31142" citStr="Chang et al., 2009" startWordPosition="5499" endWordPosition="5502">nd c-sets are listed in columns 4 and 5 of Table 2. Duplicate sets have been removed. 7.2 Objective Evaluation In this section, we evaluate our proposed MC3 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html Figure 5. Avg. Topic Coherence score for different proportions of knowledge. LDA model objectively. Topic models are often evaluated using perplexity on held-out test data. However, the perplexity metric does not reflect the semantic coherence of individual topics learned by a topic model (Newman et al., 2010). Recent research has shown potential issues with perplexity as a measure: (Chang et al., 2009) suggested that the perplexity can sometimes be contrary to human judgments. Also, perplexity does not really reflect our goal of finding coherent aspects with accurate semantic clustering. It only provides a measure of how well the model fits the data. The Topic Coherence metric (Mimno et al., 2011) (also called the â€œUMassâ€ measure (Stevens and Buttler, 2012)) was proposed as a better alternative for assessing topic quality. This metric relies upon word co-occurrence statistics within the documents, and does not depend on external resources or human labeling. It was shown that topic coherence</context>
</contexts>
<marker>Chang, Boyd-Graber, Chong, Gerrish, Blei, M, 2009</marker>
<rawString>Jonathan Chang, Jordan Boyd-Graber, Wang Chong, Sean Gerrish, and David Blei, M. 2009. Reading Tea Leaves: How Humans Interpret Topic Models. In Proceedings of NIPS, pages 288â€“296.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Chen</author>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
<author>Meichun Hsu</author>
<author>Malu Castellanos</author>
<author>Riddhiman Ghosh</author>
</authors>
<title>Leveraging Multi-Domain Prior Knowledge in Topic Models.</title>
<date>2013</date>
<booktitle>In Proceedings of IJCAI,</booktitle>
<pages>2071--2077</pages>
<contexts>
<context position="6883" citStr="Chen et al., 2013" startWordPosition="1108" endWordPosition="1111">not-set) as a set of words that should not be in the same topic. They are similar to must-link and cannot-link but m-sets do not enforce transitivity. Transitivity is the main cause of the inability to handle multiple senses. Our m-sets and c-sets are also more concise providing knowledge in the context of a set. As in (Andrzejewski et al., 2009), we assume that there is no conflict between m-sets and c-sets, i.e., if w1 is a cannot-word of w2 (i.e., shares a c-set with w2), any word that shares an m-set with w1 is also a cannot-word of w2. Note that knowledge as m-sets has also been used in (Chen et al., 2013a) and (Chen et al., 2013b). We then propose a new topic model, called MCLDA (LDA with m-set and c-set), which is not only able to deal with c-sets and automatically adjust the number of topics, but also deal with the multiple senses and adverse effect of knowledge problems at the same time. For the issue of multiple senses, a new latent variable s is added to LDA to distinguish multiple senses (Â§ 3). Then, we employ the generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) to address the issue of adverse effect of knowledge (Â§ 4). Deviating from the standard topic modeling approaches, we propose </context>
<context position="11529" citStr="Chen et al., 2013" startWordPosition="1891" endWordPosition="1894">r aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides those discussed in Â§ 1, the model (Hu et al., 2011) enables the user to provide guidance interactively. Blei and McAuliffe (2007) and Ramage et al. (2009) used document labels in supervised setting. In (Chen et al., 2013a), we proposed MDKLDA to leverage multi-domain knowledge, which serves as the basic mechanism to exploit m-sets in MC-LDA. In (Chen et al., 2013b), we proposed a framework (called GK-LDA) to explicitly deal with the wrong knowledge when exploring the lexical semantic relations as the general (domain independent) knowledge in topic models. But these models above did not consider the knowledge in the form of c-sets (or cannot-links). The generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) was first introduced in LDA by Mimno et al. (2011). However, Mimno et al. (2011) did not use domain knowledge</context>
<context position="12804" citStr="Chen et al., 2013" startWordPosition="2107" endWordPosition="2110">significantly improve aspect extraction. The GPU model was also employed in topic models in our work of (Chen et al., 2013a, 2013b). In this paper, we propose the Extended GPU (E-GPU) model. The EGPU model is more powerful in handling complex situations in dealing with c-sets. 3 Dealing with M-sets and Multiple Senses Since the proposed MC-LDA model is a major extension to our earlier work in (Chen et al., 2013a), which can deal with m-sets, we include this earlier work here as the background. To incorporate m-sets and deal with multiple senses of a word, the MDK-LDA(b) model was proposed in (Chen et al., 2013a), which adds a new latent variable s into LDA. The rationale here is that this new latent variable s guides the model to choose the right sense represented by an m-set. The generative process of MDK-LDA(b) is (the notations are explained in Table 1): 0 ~ Dirichlet(a) zi|0â€ ~ Multinomial(0â€) T ~ Dirichlet(fl) si|zi,T ~ Multinomial(TzL) 0 ~ Dirichlet(y) wi |zi, si, 0 ~ Multinomial (0zL,SL) 1657 Figure 1. Plate notation for MDK-LDA(b) and MC-LDA. The corresponding plate is shown in Figure 1. Under MDK-LDA(b), the probability of word ğ‘¤ given topic ğ‘¡, i.e., ğœ‹ğ‘¡(ğ‘¤), is given by: ğœ‹ğ‘¡(ğ‘¤) = âˆ‘ ğœ‘ğ‘¡(ğ‘ ) âˆ™ ğœ‚</context>
<context position="16115" citStr="Chen et al., 2013" startWordPosition="2701" endWordPosition="2704"> tokens in document ğ‘š ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ Number of times that m-set ğ‘  occurs under topic ğ‘¡ Number of times that word ğ‘¤ appears in m-set ğ‘  under topic ğ‘¡ Table 1. Meanings of symbols. 4.2 Promoting M-sets using GPU To deal with the issue of sensitivity to the adverse effect of knowledge, MDK-LDA(b) is extended to MDK-LDA which employs the generalized PÃ³lya urn (GPU) sampling scheme. As discussed in Â§ 1, due to the problem of the adverse effect of knowledge, important words may suffer from the presence of rare words in the same m-set. This problem can be dealt with the very sampling scheme of the GPU model (Chen et al., 2013a). Specifically, by adding additional ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ balls of color ğ‘  into ğ‘ˆğ‘¡ğ‘† while keeping the drawn ball, we increase the proportion (probability) of seeing the m-set ğ‘  under topic ğ‘¡ and thus promote m-set ğ‘  as a whole. Consequently, each word in ğ‘  is more likely to be emitted. We define ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ as: 1 ğ‘¤= ğ‘¤â€² T ï¿½ IP s z y w Nm M 0 Î± ti TÃ—S ğ‘›ğ‘¡,ğ‘  âˆ’ğ‘– + ğ›½ Ã— âˆ‘ï¿½ğ‘›ğ‘¡,ğ‘ â€² ğ‘† âˆ’ğ‘– + ğ›½ï¿½ ğ‘ â€²=1 ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ğ‘– âˆ’ğ‘–+ ğ›¾ğ‘  (2) âˆ‘ï¿½ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€² ğ‘‰ âˆ’ğ‘– + ğ›¾ğ‘ ï¿½ ğ‘£â€²=1 ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ = ï¿½ğœ ğ‘¤ âˆˆ ğ‘ , ğ‘¤â€² âˆˆ ğ‘ , ğ‘¤â‰  ğ‘¤â€² (3) 0 otherwise The corresponding Gibbs sampler for MDK-LDA will be introduced in Â§ 6. 1658 5 Incorporating C-sets 5.1 Extended Generalized PÃ³lya u</context>
<context position="25910" citStr="Chen et al., 2013" startWordPosition="4624" endWordPosition="4627">ic unsupervised topic model (Blei et al., 2003). â€¢ LDA-GPU: LDA with GPU (Mimno et al., 2011). Specifically, LDA-GPU applies GPU in LDA using co-document frequency. As for knowledge-based models, we focus on comparing with DF-LDA model (Andrzejewski et al., 2009), which is perhaps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-links and cannot-links. This is the full DF-LDA model in (Andrzejewski et al., 2009). We do not compare with seeded models in (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012) as seed sets are special cases of must-links and they also do not allow c-sets (or cannot-links). 7.1 Datasets and Settings Datasets: We use product reviews from four domains (types of products) from Amazon.com for evaluation. The corpus statistics are shown in Table 2 (columns 2 and 3). The domains are â€œCamera,</context>
</contexts>
<marker>Chen, Mukherjee, Liu, Hsu, Castellanos, Ghosh, 2013</marker>
<rawString>Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013a. Leveraging Multi-Domain Prior Knowledge in Topic Models. In Proceedings of IJCAI, pages 2071â€“2077.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Chen</author>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
<author>Meichun Hsu</author>
<author>Malu Castellanos</author>
<author>Riddhiman Ghosh</author>
</authors>
<title>Discovering Coherent Topics Using General Knowledge.</title>
<date>2013</date>
<booktitle>In Proceedings of CIKM.</booktitle>
<contexts>
<context position="6883" citStr="Chen et al., 2013" startWordPosition="1108" endWordPosition="1111">not-set) as a set of words that should not be in the same topic. They are similar to must-link and cannot-link but m-sets do not enforce transitivity. Transitivity is the main cause of the inability to handle multiple senses. Our m-sets and c-sets are also more concise providing knowledge in the context of a set. As in (Andrzejewski et al., 2009), we assume that there is no conflict between m-sets and c-sets, i.e., if w1 is a cannot-word of w2 (i.e., shares a c-set with w2), any word that shares an m-set with w1 is also a cannot-word of w2. Note that knowledge as m-sets has also been used in (Chen et al., 2013a) and (Chen et al., 2013b). We then propose a new topic model, called MCLDA (LDA with m-set and c-set), which is not only able to deal with c-sets and automatically adjust the number of topics, but also deal with the multiple senses and adverse effect of knowledge problems at the same time. For the issue of multiple senses, a new latent variable s is added to LDA to distinguish multiple senses (Â§ 3). Then, we employ the generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) to address the issue of adverse effect of knowledge (Â§ 4). Deviating from the standard topic modeling approaches, we propose </context>
<context position="11529" citStr="Chen et al., 2013" startWordPosition="1891" endWordPosition="1894">r aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides those discussed in Â§ 1, the model (Hu et al., 2011) enables the user to provide guidance interactively. Blei and McAuliffe (2007) and Ramage et al. (2009) used document labels in supervised setting. In (Chen et al., 2013a), we proposed MDKLDA to leverage multi-domain knowledge, which serves as the basic mechanism to exploit m-sets in MC-LDA. In (Chen et al., 2013b), we proposed a framework (called GK-LDA) to explicitly deal with the wrong knowledge when exploring the lexical semantic relations as the general (domain independent) knowledge in topic models. But these models above did not consider the knowledge in the form of c-sets (or cannot-links). The generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) was first introduced in LDA by Mimno et al. (2011). However, Mimno et al. (2011) did not use domain knowledge</context>
<context position="12804" citStr="Chen et al., 2013" startWordPosition="2107" endWordPosition="2110">significantly improve aspect extraction. The GPU model was also employed in topic models in our work of (Chen et al., 2013a, 2013b). In this paper, we propose the Extended GPU (E-GPU) model. The EGPU model is more powerful in handling complex situations in dealing with c-sets. 3 Dealing with M-sets and Multiple Senses Since the proposed MC-LDA model is a major extension to our earlier work in (Chen et al., 2013a), which can deal with m-sets, we include this earlier work here as the background. To incorporate m-sets and deal with multiple senses of a word, the MDK-LDA(b) model was proposed in (Chen et al., 2013a), which adds a new latent variable s into LDA. The rationale here is that this new latent variable s guides the model to choose the right sense represented by an m-set. The generative process of MDK-LDA(b) is (the notations are explained in Table 1): 0 ~ Dirichlet(a) zi|0â€ ~ Multinomial(0â€) T ~ Dirichlet(fl) si|zi,T ~ Multinomial(TzL) 0 ~ Dirichlet(y) wi |zi, si, 0 ~ Multinomial (0zL,SL) 1657 Figure 1. Plate notation for MDK-LDA(b) and MC-LDA. The corresponding plate is shown in Figure 1. Under MDK-LDA(b), the probability of word ğ‘¤ given topic ğ‘¡, i.e., ğœ‹ğ‘¡(ğ‘¤), is given by: ğœ‹ğ‘¡(ğ‘¤) = âˆ‘ ğœ‘ğ‘¡(ğ‘ ) âˆ™ ğœ‚</context>
<context position="16115" citStr="Chen et al., 2013" startWordPosition="2701" endWordPosition="2704"> tokens in document ğ‘š ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ Number of times that m-set ğ‘  occurs under topic ğ‘¡ Number of times that word ğ‘¤ appears in m-set ğ‘  under topic ğ‘¡ Table 1. Meanings of symbols. 4.2 Promoting M-sets using GPU To deal with the issue of sensitivity to the adverse effect of knowledge, MDK-LDA(b) is extended to MDK-LDA which employs the generalized PÃ³lya urn (GPU) sampling scheme. As discussed in Â§ 1, due to the problem of the adverse effect of knowledge, important words may suffer from the presence of rare words in the same m-set. This problem can be dealt with the very sampling scheme of the GPU model (Chen et al., 2013a). Specifically, by adding additional ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ balls of color ğ‘  into ğ‘ˆğ‘¡ğ‘† while keeping the drawn ball, we increase the proportion (probability) of seeing the m-set ğ‘  under topic ğ‘¡ and thus promote m-set ğ‘  as a whole. Consequently, each word in ğ‘  is more likely to be emitted. We define ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ as: 1 ğ‘¤= ğ‘¤â€² T ï¿½ IP s z y w Nm M 0 Î± ti TÃ—S ğ‘›ğ‘¡,ğ‘  âˆ’ğ‘– + ğ›½ Ã— âˆ‘ï¿½ğ‘›ğ‘¡,ğ‘ â€² ğ‘† âˆ’ğ‘– + ğ›½ï¿½ ğ‘ â€²=1 ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ğ‘– âˆ’ğ‘–+ ğ›¾ğ‘  (2) âˆ‘ï¿½ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€² ğ‘‰ âˆ’ğ‘– + ğ›¾ğ‘ ï¿½ ğ‘£â€²=1 ğ”¸ğ‘ ,ğ‘¤â€²,ğ‘¤ = ï¿½ğœ ğ‘¤ âˆˆ ğ‘ , ğ‘¤â€² âˆˆ ğ‘ , ğ‘¤â‰  ğ‘¤â€² (3) 0 otherwise The corresponding Gibbs sampler for MDK-LDA will be introduced in Â§ 6. 1658 5 Incorporating C-sets 5.1 Extended Generalized PÃ³lya u</context>
<context position="25910" citStr="Chen et al., 2013" startWordPosition="4624" endWordPosition="4627">ic unsupervised topic model (Blei et al., 2003). â€¢ LDA-GPU: LDA with GPU (Mimno et al., 2011). Specifically, LDA-GPU applies GPU in LDA using co-document frequency. As for knowledge-based models, we focus on comparing with DF-LDA model (Andrzejewski et al., 2009), which is perhaps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-links and cannot-links. This is the full DF-LDA model in (Andrzejewski et al., 2009). We do not compare with seeded models in (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012) as seed sets are special cases of must-links and they also do not allow c-sets (or cannot-links). 7.1 Datasets and Settings Datasets: We use product reviews from four domains (types of products) from Amazon.com for evaluation. The corpus statistics are shown in Table 2 (columns 2 and 3). The domains are â€œCamera,</context>
</contexts>
<marker>Chen, Mukherjee, Liu, Hsu, Castellanos, Ghosh, 2013</marker>
<rawString>Zhiyuan Chen, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013b. Discovering Coherent Topics Using General Knowledge. In Proceedings of CIKM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Hierarchical Sequential Learning for Extracting Opinions and their Attributes,</title>
<date>2010</date>
<pages>269--274</pages>
<contexts>
<context position="9395" citStr="Choi and Cardie, 2010" startWordPosition="1538" endWordPosition="1541">nt analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara e</context>
</contexts>
<marker>Choi, Cardie, 2010</marker>
<rawString>Yejin Choi and Claire Cardie. 2010. Hierarchical Sequential Learning for Extracting Opinions and their Attributes, pages 269â€“274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Fang</author>
<author>Minlie Huang</author>
</authors>
<title>Fine Granular Aspect Analysis using Latent Structural Models.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>333--337</pages>
<contexts>
<context position="9550" citStr="Fang and Huang, 2012" startWordPosition="1565" endWordPosition="1568">iu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al</context>
</contexts>
<marker>Fang, Huang, 2012</marker>
<rawString>Lei Fang and Minlie Huang. 2012. Fine Granular Aspect Analysis using Latent Structural Models. In Proceedings of ACL, pages 333â€“337.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Mark Steyvers</author>
</authors>
<title>Finding Scientific Topics.</title>
<date>2004</date>
<booktitle>PNAS, 101 Suppl,</booktitle>
<pages>5228--5235</pages>
<contexts>
<context position="21948" citStr="Griffiths and Steyvers, 2004" startWordPosition="3865" endWordPosition="3868">sfer cannot-word flag ğœ‡, A set of valid topics ğ›º to be assigned to ğ‘¤ğ‘– 1: ğ‘›ğ‘š,ğ‘§ğ‘– â† ğ‘›ğ‘š,ğ‘§ğ‘– âˆ’ 1; 2: for each word ğ‘¤â€² in ğ‘ ğ‘– do ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– âˆ’ ğ”¸ğ‘ ğ‘–,ğ‘¤â€²,ğ‘¤ğ‘–; end for ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– âˆ’ 1; Jointly sample ğ‘§ğ‘– âˆˆ ğ›º and ğ‘ ğ‘– âˆ‹ ğ‘¤ğ‘– using Equation 2; ğ‘›ğ‘š,ğ‘§ğ‘– â† ğ‘›ğ‘š,ğ‘§ğ‘– + 1; for each word ğ‘¤â€² in ğ‘ ğ‘– do ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– + ğ”¸ğ‘ ğ‘–,ğ‘¤â€²,ğ‘¤ğ‘–; 10: end for 11: ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– + 1; 12: if ğœ‡ is true then 13: TransferCannotWords(ğ‘¤ğ‘–, ğ‘§ğ‘–); 14: end if Figure 2. Gibbs sampling for MC-LDA. sampling scheme, and hence MC-LDA shares the same plate as MDK-LDA(b). 6 Collapsed Gibbs Sampling We now describe the collapsed Gibbs sampler (Griffiths and Steyvers, 2004) with the detailed conditional distributions and algorithms for MCLDA. Inference of ğ‘§ and ğ‘  can be computationally expensive due to the non-exchangeability of words under the E-GPU models. We take the approach of (Mimno et al., 2011) which approximates the true Gibbs sampling distribution by treating each word as if it were the last. For each word ğ‘¤ğ‘– , we perform hierarchical sampling consisting of the following three steps (the detailed algorithms are given in Figures 2 and 3): Step 1 (Lines 1-11 in Figure 2): We jointly sample a topic ğ‘§ğ‘– and an m-set ğ‘ ğ‘– (containing ğ‘¤ğ‘–) for ğ‘¤ğ‘–, which gives us</context>
</contexts>
<marker>Griffiths, Steyvers, 2004</marker>
<rawString>Thomas L. Griffiths and Mark Steyvers. 2004. Finding Scientific Topics. PNAS, 101 Suppl, 5228â€“5235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Honglei Guo</author>
<author>Huijia Zhu</author>
<author>Zhili Guo</author>
<author>Xiaoxun Zhang</author>
<author>Zhong Su</author>
</authors>
<title>Product feature categorization with multilevel latent semantic association.</title>
<date>2009</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>1087--1096</pages>
<contexts>
<context position="10730" citStr="Guo et al., 2009" startWordPosition="1761" endWordPosition="1764"> 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides those discussed in Â§ </context>
</contexts>
<marker>Guo, Zhu, Guo, Zhang, Su, 2009</marker>
<rawString>Honglei Guo, Huijia Zhu, Zhili Guo, Xiaoxun Zhang, and Zhong Su. 2009. Product feature categorization with multilevel latent semantic association. In Proceedings of CIKM, pages 1087â€“1096.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregor Heinrich</author>
</authors>
<title>A Generic Approach to Topic Models.</title>
<date>2009</date>
<booktitle>In Proceedings of ECML PKDD,</booktitle>
<pages>517--532</pages>
<contexts>
<context position="28779" citStr="Heinrich, 2009" startWordPosition="5118" endWordPosition="5119">all models. Parameter settings: For all models, posterior inference was drawn using 1000 Gibbs iterations with an initial burn-in of 100 iterations. For all models, we set a = 1 and fl = 0.1. We found that small changes of a and fl did not affect the results much, which was also reported in (Jo and Oh, 2011) who also used online reviews. For the number of topics T, we tried different values (see Â§7.2) as it is hard to know the exact number of topics. While non-parametric Bayesian approaches (Teh et al., 2006) aim to estimate T from the corpus, they are often sensitive to the hyper-parameters (Heinrich, 2009). 1 http://nlp.stanford.edu/software/corenlp.shtml 2 http://jmlr.org/papers/volume5/lewis04a/a11-smart-stop-list 1661 3 6 9 12 15 MC-LDA M-LDA LDA DF-M DF-MC LDA-GPU 0% 25% 50% 100% MC-LDA M-LDA DF-M DF-MC -1200 -1300 -1400 -1500 -1600 -1240 -1260 -1280 -1300 -1320 Figure 4. Avg. Topic Coherence score of each model across different number of topics. For DF-LDA, we followed (Andrzejewski et al., 2009) to generate must-links and cannot-links from our domain knowledge. We then ran DFLDA3 while keeping its parameters as proposed in (Andrzejewski et al., 2009) (we also experimented with different p</context>
</contexts>
<marker>Heinrich, 2009</marker>
<rawString>Gregor Heinrich. 2009. A Generic Approach to Topic Models. In Proceedings of ECML PKDD, pages 517 â€“ 532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and Summarizing Customer Reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="1524" citStr="Hu and Liu, 2004" startWordPosition="222" endWordPosition="225">e or to automatically adjust the number of topics based on domain knowledge. This paper proposes a more advanced topic model, called MC-LDA (LDA with m-set and c-set), to address these problems, which is based on an Extended generalized PÃ³lya urn (E-GPU) model (which is also proposed in this paper). Experiments on real-life product reviews from a variety of domains show that MCLDA outperforms the existing state-of-the-art models markedly. 1 Introduction In sentiment analysis and opinion mining, aspect extraction aims to extract entity aspects or features on which opinions have been expressed (Hu and Liu, 2004; Liu, 2012). For example, in a sentence â€œThe picture looks great,â€ the aspect is â€œpicture.â€ Aspect extraction consists of two sub-tasks: (1) extracting all aspect terms (e.g., â€œpictureâ€) from the corpus, and (2) clustering aspect terms with similar meanings (e.g., cluster â€œpictureâ€ and â€œphotoâ€ into one aspect category as they mean the same in the domain â€œCameraâ€). In this work, we adopt the topic modeling approach as it can perform both sub-tasks simultaneously (see Â§ 2). Topic models, such as LDA (Blei et al., 2003), provide an unsupervised framework for extracting latent topics in text docu</context>
<context position="8848" citStr="Hu and Liu, 2004" startWordPosition="1445" endWordPosition="1448">the existing knowledge-based models is as comprehensive as MC-LDA in terms of capabilities. 2. It proposed the E-GPU model to enable multiurn interactions, which enables c-sets to be naturally integrated into a topic model. To the best of our knowledge, E-GPU has not been proposed and used before. 3. A comprehensive evaluation has been conducted to compare MC-LDA with several state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; L</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and Summarizing Customer Reviews. In Proceedings of KDD, pages 168â€“177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuening Hu</author>
<author>Jordan Boyd-Graber</author>
<author>Brianna Satinoff</author>
</authors>
<title>Interactive Topic Modeling.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>248--257</pages>
<contexts>
<context position="11360" citStr="Hu et al., 2011" startWordPosition="1862" endWordPosition="1865"> 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides those discussed in Â§ 1, the model (Hu et al., 2011) enables the user to provide guidance interactively. Blei and McAuliffe (2007) and Ramage et al. (2009) used document labels in supervised setting. In (Chen et al., 2013a), we proposed MDKLDA to leverage multi-domain knowledge, which serves as the basic mechanism to exploit m-sets in MC-LDA. In (Chen et al., 2013b), we proposed a framework (called GK-LDA) to explicitly deal with the wrong knowledge when exploring the lexical semantic relations as the general (domain independent) knowledge in topic models. But these models above did not consider the knowledge in the form of c-sets (or cannot-li</context>
</contexts>
<marker>Hu, Boyd-Graber, Satinoff, 2011</marker>
<rawString>Yuening Hu, Jordan Boyd-Graber, and Brianna Satinoff. 2011. Interactive Topic Modeling. In Proceedings of ACL, pages 248â€“257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hemant Ishwaran</author>
<author>LF James</author>
</authors>
<title>Gibbs sampling methods for stick-breaking priors.</title>
<date>2001</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>96</volume>
<issue>453</issue>
<pages>161--173</pages>
<contexts>
<context position="22599" citStr="Ishwaran and James, 2001" startWordPosition="3977" endWordPosition="3980">onal distributions and algorithms for MCLDA. Inference of ğ‘§ and ğ‘  can be computationally expensive due to the non-exchangeability of words under the E-GPU models. We take the approach of (Mimno et al., 2011) which approximates the true Gibbs sampling distribution by treating each word as if it were the last. For each word ğ‘¤ğ‘– , we perform hierarchical sampling consisting of the following three steps (the detailed algorithms are given in Figures 2 and 3): Step 1 (Lines 1-11 in Figure 2): We jointly sample a topic ğ‘§ğ‘– and an m-set ğ‘ ğ‘– (containing ğ‘¤ğ‘–) for ğ‘¤ğ‘–, which gives us a blocked Gibbs sampler (Ishwaran and James, 2001), with the conditional probability given by: ğ‘ƒ(ğ‘§ğ‘– = ğ‘¡, ğ‘ ğ‘– = ğ‘ |ğ’›âˆ’ğ‘–,ğ’”âˆ’ğ‘–, ğ’˜, ğ›¼, ğ›½, ğ›¾,ğ”¸) âˆ âˆ‘ âˆ‘ ğ”¸ğ‘ ,ğ‘£â€²,ğ‘¤â€² âˆ™ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€² ğ‘‰ ğ‘‰ âˆ’ğ‘– +ğ›½ ğ‘¤â€²=1 ğ‘£â€²=1 Ã— âˆ‘ ï¿½âˆ‘ âˆ‘ ğ”¸ğ‘ â€²,ğ‘£â€²,ğ‘¤â€²âˆ™ğ‘›ğ‘¡,ğ‘ â€²,ğ‘£â€² ğ‘† ğ‘‰ ğ‘‰ âˆ’ğ‘– +ğ›½ï¿½ ğ‘ â€²=1 ğ‘¤â€²=1 ğ‘£â€²=1 âˆ’ğ‘– ğ‘›ğ‘¡,ğ‘ ,ğ‘¤ğ‘–+ğ›¾ğ‘  âˆ‘ ï¿½ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€² ğ‘‰ âˆ’ğ‘– +ğ›¾ğ‘ ï¿½ ğ‘£â€²=1 This step is the same as the Gibbs sampling for the MDK-LDA model. Algorithm 2.TransferCannotWords(ğ‘¤ğ‘–, ğ‘§ğ‘–) Input: Word ğ‘¤ğ‘–, Topic ğ‘§ğ‘–, 1: for each cannot-word ğ‘¤ğ‘ of ğ‘¤ğ‘– do 2: Randomly select an m-set ğ‘ ğ‘ from all m-sets of ğ‘¤ğ‘; 3: Build a set ğ›¹ containing all the instances of ğ‘¤ğ‘ from the corpus with topic and m-set assignments being ğ‘§ğ‘– and ğ‘ ğ‘; 4: if ğ›¹ is not empty then 5: Draw </context>
</contexts>
<marker>Ishwaran, James, 2001</marker>
<rawString>Hemant Ishwaran and LF James. 2001. Gibbs sampling methods for stick-breaking priors. Journal of the American Statistical Association, 96(453), 161â€“173.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jagadeesh Jagarlamudi</author>
<author>Hal DaumÃ©</author>
<author>Raghavendra Udupa</author>
</authors>
<title>Incorporating Lexical Priors into Topic Models.</title>
<date>2012</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>204--213</pages>
<contexts>
<context position="3030" citStr="Jagarlamudi et al., 2012" startWordPosition="464" endWordPosition="467"> models do not always correlate well with human judgments and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were proposed. They enable the user to specify prior knowledge as seed words/terms for some topics. Petterson et al. (2010) also used word similarity as priors for guidance. However, none of the existing models is capable of incorporating the cannot-link type of knowledge except DF-LDA (Andrzejewski et al., 2009). Furthermore, none of the existing models, including DF-LDA, is able to automatically adjust the number of topics based on domain knowledge. The domain knowledge, such as cannot-links, may change the number of topics. There ar</context>
<context position="5320" citStr="Jagarlamudi et al., 2012" startWordPosition="834" endWordPosition="837">e major shortcomings: Incapability of handling multiple senses: A word typically has multiple meanings or senses. For example, light can mean â€œof little weightâ€ or â€œsomething that makes things visible.â€ DF-LDA cannot handle multiple senses because its definition of must-link is transitive. That is, if A and B form a must-link, and B and C form a must-link, it implies a must-link between A and C, indicating A, B, and C should be in the same topic. This case also applies to the models in (Andrzejewski et al., 2011), (Petterson et al., 2010), and (Mukherjee and Liu, 2012). Although the model in (Jagarlamudi et al., 2012) allows multiple senses, it requires that each topic has at most one set of seed words (seed set), which is restrictive as the amount of knowledge should not be limited. Sensitivity to the adverse effect of knowledge: When using must-links or seeds, existing models basically try to ensure that the words in a mustlink or a seed set have similar probabilities under a topic. This causes a problem: if a must-link comprises of a frequent word and an infrequent word, due to the redistribution of probability mass, the probability of the frequent word will decrease while the probability of the infrequ</context>
<context position="26153" citStr="Jagarlamudi et al., 2012" startWordPosition="4665" endWordPosition="4668">(Andrzejewski et al., 2009), which is perhaps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-links and cannot-links. This is the full DF-LDA model in (Andrzejewski et al., 2009). We do not compare with seeded models in (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012) as seed sets are special cases of must-links and they also do not allow c-sets (or cannot-links). 7.1 Datasets and Settings Datasets: We use product reviews from four domains (types of products) from Amazon.com for evaluation. The corpus statistics are shown in Table 2 (columns 2 and 3). The domains are â€œCamera,â€ â€œFood,â€ â€œComputer,â€ and â€œCareâ€ (short for â€œPersonal Careâ€). We have made the datasets publically available at the website of the first author. Domain #Reviews #Sentences #M-sets #C-sets Camera 500 5171 173 18 Food 500 2416 85 10 Computer 500</context>
</contexts>
<marker>Jagarlamudi, DaumÃ©, Udupa, 2012</marker>
<rawString>Jagadeesh Jagarlamudi, Hal DaumÃ© III, and Raghavendra Udupa. 2012. Incorporating Lexical Priors into Topic Models. In Proceedings of EACL, pages 204â€“213.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting Opinion Targets in a Single- and Cross-Domain Setting with Conditional Random Fields.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1035--1045</pages>
<contexts>
<context position="9421" citStr="Jakob and Gurevych, 2010" startWordPosition="1542" endWordPosition="1545">udied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., </context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. 2010. Extracting Opinion Targets in a Single- and Cross-Domain Setting with Conditional Random Fields. In Proceedings of EMNLP, pages 1035â€“1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yohan Jo</author>
<author>Alice H Oh</author>
</authors>
<title>Aspect and sentiment unification model for online review analysis.</title>
<date>2011</date>
<booktitle>In Proceedings of WSDM,</booktitle>
<pages>815--824</pages>
<contexts>
<context position="9567" citStr="Jo and Oh, 2011" startWordPosition="1569" endWordPosition="1572">hree main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyano</context>
<context position="27837" citStr="Jo and Oh, 2011" startWordPosition="4949" endWordPosition="4952">ng to high similarity among topics/aspects. Sentences as documents: As noted in (Titov and McDonald, 2008), when standard topic models are applied to reviews as documents, they tend to produce topics that correspond to global properties of products (e.g., brand name), which make topics overlapping with each other. The reason is that all reviews of the same type of products discuss about the same aspects of these products. Only the brand names and product names are different. Thus, using individual reviews for modeling is not very effective. Although there are approaches which model sentences (Jo and Oh, 2011; Titov and McDonald, 2008), we take the approach of (Brody and Elhadad, 2010), dividing each review into sentences and treating each sentence as an independent document. Sentences can be used by all three baselines without any change to their models. Although the relationships between sentences are lost, the data is fair to all models. Parameter settings: For all models, posterior inference was drawn using 1000 Gibbs iterations with an initial burn-in of 100 iterations. For all models, we set a = 1 and fl = 0.1. We found that small changes of a and fl did not affect the results much, which wa</context>
</contexts>
<marker>Jo, Oh, 2011</marker>
<rawString>Yohan Jo and Alice H. Oh. 2011. Aspect and sentiment unification model for online review analysis. In Proceedings of WSDM, pages 815â€“824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Kennedy</author>
<author>Diana Inkpen</author>
</authors>
<title>Sentiment Classification of Movie Reviews Using Contextual Valence Shifters.</title>
<date>2006</date>
<journal>Computational Intelligence,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>110--125</pages>
<contexts>
<context position="10394" citStr="Kennedy and Inkpen, 2006" startWordPosition="1706" endWordPosition="1709"> et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 201</context>
</contexts>
<marker>Kennedy, Inkpen, 2006</marker>
<rawString>Alistair Kennedy and Diana Inkpen. 2006. Sentiment Classification of Movie Reviews Using Contextual Valence Shifters. Computational Intelligence, 22(2), 110â€“125.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jungi Kim</author>
<author>Jinji Li</author>
<author>Jong-Hyeok Lee</author>
</authors>
<title>Discovering the Discriminative Views: Measuring Term Weights for Sentiment Analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL/IJCNLP,</booktitle>
<pages>253--261</pages>
<contexts>
<context position="10412" citStr="Kim et al., 2009" startWordPosition="1710" endWordPosition="1713">cDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 20</context>
</contexts>
<marker>Kim, Li, Lee, 2009</marker>
<rawString>Jungi Kim, Jinji Li, and Jong-Hyeok Lee. 2009. Discovering the Discriminative Views: Measuring Term Weights for Sentiment Analysis. In Proceedings of ACL/IJCNLP, pages 253â€“261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suin Kim</author>
<author>Jianwen Zhang</author>
<author>Zheng Chen</author>
<author>Alice Oh</author>
<author>Shixia Liu</author>
</authors>
<title>A Hierarchical Aspect-Sentiment Model for Online Reviews.</title>
<date>2013</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="9585" citStr="Kim et al., 2013" startWordPosition="1573" endWordPosition="1576">hes to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011</context>
</contexts>
<marker>Kim, Zhang, Chen, Oh, Liu, 2013</marker>
<rawString>Suin Kim, Jianwen Zhang, Zheng Chen, Alice Oh, and Shixia Liu. 2013. A Hierarchical Aspect-Sentiment Model for Online Reviews. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nozomi Kobayashi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Extracting Aspect-Evaluation and Aspect-of Relations in Opinion Mining.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1065--1074</pages>
<contexts>
<context position="9445" citStr="Kobayashi et al., 2007" startWordPosition="1546" endWordPosition="1549">t years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based repre</context>
</contexts>
<marker>Kobayashi, Inui, Matsumoto, 2007</marker>
<rawString>Nozomi Kobayashi, Kentaro Inui, and Yuji Matsumoto. 2007. Extracting Aspect-Evaluation and Aspect-of Relations in Opinion Mining. In Proceedings of EMNLP, pages 1065â€“1074.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lun-Wei Ku</author>
<author>Yu-Ting Liang</author>
<author>Hsin-Hsi Chen</author>
</authors>
<title>Opinion Extraction, Summarization and Tracking in News and Blog Corpora.</title>
<date>2006</date>
<booktitle>In Proceedings of AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs,</booktitle>
<pages>100--107</pages>
<contexts>
<context position="9160" citStr="Ku et al., 2006" startWordPosition="1499" endWordPosition="1502">sive evaluation has been conducted to compare MC-LDA with several state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 20</context>
</contexts>
<marker>Ku, Liang, Chen, 2006</marker>
<rawString>Lun-Wei Ku, Yu-Ting Liang, and Hsin-Hsi Chen. 2006. Opinion Extraction, Summarization and Tracking in News and Blog Corpora. In Proceedings of AAAI Spring Symposium: Computational Approaches to Analyzing Weblogs, pages 100â€“107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>JR Landis</author>
<author>GG Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data.</title>
<date>1977</date>
<journal>biometrics,</journal>
<volume>33</volume>
<contexts>
<context position="36528" citStr="Landis and Koch, 1977" startWordPosition="6418" endWordPosition="6421">r bad. Each topic was presented as a list of 10 most probable words in descending order of their probabilities under that topic. The models which generated the topics for labeling were obscure to the judges. In general, each topic was annotated as good if it had more than half of its words coherently related to each other representing a semantic concept together; otherwise bad. Agreement of human judges on topic Camera Food Computer Care MC-LDA M-LDA LDA DF-M DF-MC LDA-GPU 1663 labeling using Cohenâ€™s Kappa yielded a score of 0.92 indicating almost perfect agreements according to the scale in (Landis and Koch, 1977). This is reasonable as topic labeling is an easy task and semantic coherence can be judged well by humans. Word Labeling: After topic labeling, we chose the topics, which were labeled as good by both judges, as good topics. Then, we asked the two judges to label each word of the top 10 words in these good topics. Each word was annotated as correct if it was coherently related to the concept represented by the topic; otherwise incorrect. Since judges already had the conception of each topic in mind when they were labeling topics, labeling each word was not difficult which explains the high Kap</context>
</contexts>
<marker>Landis, Koch, 1977</marker>
<rawString>JR Landis and GG Koch. 1977. The measurement of observer agreement for categorical data. biometrics, 33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angeliki Lazaridou</author>
<author>Ivan Titov</author>
<author>Caroline Sporleder</author>
</authors>
<title>A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="9609" citStr="Lazaridou et al., 2013" startWordPosition="1577" endWordPosition="1580">action: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), </context>
</contexts>
<marker>Lazaridou, Titov, Sporleder, 2013</marker>
<rawString>Angeliki Lazaridou, Ivan Titov, and Caroline Sporleder. 2013. A Bayesian Model for Joint Unsupervised Induction of Sentiment, Aspect and Discourse Representations. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
</authors>
<title>Chao Han, Minlie Huang, Xiaoyan Zhu,</title>
<date>2010</date>
<location>Yingju Xia, Shu</location>
<marker>Li, 2010</marker>
<rawString>Fangtao Li, Chao Han, Minlie Huang, Xiaoyan Zhu, Yingju Xia, Shu Zhang, and Hao Yu. 2010.</rawString>
</citation>
<citation valid="false">
<title>Structure-Aware Review Mining and Summarization.</title>
<booktitle>In Proceedings of COLING,</booktitle>
<pages>653--661</pages>
<marker></marker>
<rawString>Structure-Aware Review Mining and Summarization. In Proceedings of COLING, pages 653â€“661.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fangtao Li</author>
<author>Sinno Jialin Pan</author>
<author>Ou Jin</author>
<author>Qiang Yang</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Cross-Domain Co-Extraction of Sentiment and Topic Lexicons.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL</booktitle>
<volume>1</volume>
<pages>410--419</pages>
<contexts>
<context position="9922" citStr="Li et al., 2012" startWordPosition="1635" endWordPosition="1638">2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both a</context>
</contexts>
<marker>Li, Pan, Jin, Yang, Zhu, 2012</marker>
<rawString>Fangtao Li, Sinno Jialin Pan, Ou Jin, Qiang Yang, and Xiaoyan Zhu. 2012a. Cross-Domain Co-Extraction of Sentiment and Topic Lexicons. In Proceedings of ACL (1), pages 410â€“419.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peng Li</author>
<author>Yinglin Wang</author>
<author>Wei Gao</author>
<author>Jing Jiang</author>
</authors>
<title>Generating Aspect-oriented Multi-Document Summarization with Event-aspect model.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1137--1146</pages>
<contexts>
<context position="9626" citStr="Li et al., 2011" startWordPosition="1581" endWordPosition="1584">equency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (</context>
</contexts>
<marker>Li, Wang, Gao, Jiang, 2011</marker>
<rawString>Peng Li, Yinglin Wang, Wei Gao, and Jing Jiang. 2011. Generating Aspect-oriented Multi-Document Summarization with Event-aspect model. In Proceedings of EMNLP, pages 1137â€“1146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shoushan Li</author>
<author>Rongyang Wang</author>
<author>Guodong Zhou</author>
</authors>
<title>Opinion Target Extraction Using a Shallow Semantic Parsing Framework.</title>
<date>2012</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="9922" citStr="Li et al., 2012" startWordPosition="1635" endWordPosition="1638">2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both a</context>
</contexts>
<marker>Li, Wang, Zhou, 2012</marker>
<rawString>Shoushan Li, Rongyang Wang, and Guodong Zhou. 2012b. Opinion Target Extraction Using a Shallow Semantic Parsing Framework. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenghua Lin</author>
<author>Yulan He</author>
</authors>
<title>Joint sentiment/topic model for sentiment analysis.</title>
<date>2009</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>375--384</pages>
<contexts>
<context position="9644" citStr="Lin and He, 2009" startWordPosition="1585" endWordPosition="1588">ctic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opin</context>
</contexts>
<marker>Lin, He, 2009</marker>
<rawString>Chenghua Lin and Yulan He. 2009. Joint sentiment/topic model for sentiment analysis. In Proceedings of CIKM, pages 375â€“384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1536" citStr="Liu, 2012" startWordPosition="226" endWordPosition="227">lly adjust the number of topics based on domain knowledge. This paper proposes a more advanced topic model, called MC-LDA (LDA with m-set and c-set), to address these problems, which is based on an Extended generalized PÃ³lya urn (E-GPU) model (which is also proposed in this paper). Experiments on real-life product reviews from a variety of domains show that MCLDA outperforms the existing state-of-the-art models markedly. 1 Introduction In sentiment analysis and opinion mining, aspect extraction aims to extract entity aspects or features on which opinions have been expressed (Hu and Liu, 2004; Liu, 2012). For example, in a sentence â€œThe picture looks great,â€ the aspect is â€œpicture.â€ Aspect extraction consists of two sub-tasks: (1) extracting all aspect terms (e.g., â€œpictureâ€) from the corpus, and (2) clustering aspect terms with similar meanings (e.g., cluster â€œpictureâ€ and â€œphotoâ€ into one aspect category as they mean the same in the domain â€œCameraâ€). In this work, we adopt the topic modeling approach as it can perform both sub-tasks simultaneously (see Â§ 2). Topic models, such as LDA (Blei et al., 2003), provide an unsupervised framework for extracting latent topics in text documents. Topic</context>
<context position="3073" citStr="Liu, 2012" startWordPosition="474" endWordPosition="475"> and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were proposed. They enable the user to specify prior knowledge as seed words/terms for some topics. Petterson et al. (2010) also used word similarity as priors for guidance. However, none of the existing models is capable of incorporating the cannot-link type of knowledge except DF-LDA (Andrzejewski et al., 2009). Furthermore, none of the existing models, including DF-LDA, is able to automatically adjust the number of topics based on domain knowledge. The domain knowledge, such as cannot-links, may change the number of topics. There are two types of cannot-links: consistent and</context>
<context position="5270" citStr="Liu, 2012" startWordPosition="828" endWordPosition="829">ge-based topic models also have some major shortcomings: Incapability of handling multiple senses: A word typically has multiple meanings or senses. For example, light can mean â€œof little weightâ€ or â€œsomething that makes things visible.â€ DF-LDA cannot handle multiple senses because its definition of must-link is transitive. That is, if A and B form a must-link, and B and C form a must-link, it implies a must-link between A and C, indicating A, B, and C should be in the same topic. This case also applies to the models in (Andrzejewski et al., 2011), (Petterson et al., 2010), and (Mukherjee and Liu, 2012). Although the model in (Jagarlamudi et al., 2012) allows multiple senses, it requires that each topic has at most one set of seed words (seed set), which is restrictive as the amount of knowledge should not be limited. Sensitivity to the adverse effect of knowledge: When using must-links or seeds, existing models basically try to ensure that the words in a mustlink or a seed set have similar probabilities under a topic. This causes a problem: if a must-link comprises of a frequent word and an infrequent word, due to the redistribution of probability mass, the probability of the frequent word </context>
<context position="8939" citStr="Liu, 2012" startWordPosition="1463" endWordPosition="1464"> proposed the E-GPU model to enable multiurn interactions, which enables c-sets to be naturally integrated into a topic model. To the best of our knowledge, E-GPU has not been proposed and used before. 3. A comprehensive evaluation has been conducted to compare MC-LDA with several state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and </context>
<context position="26196" citStr="Liu, 2012" startWordPosition="4675" endWordPosition="4676">own knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-links and cannot-links. This is the full DF-LDA model in (Andrzejewski et al., 2009). We do not compare with seeded models in (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012) as seed sets are special cases of must-links and they also do not allow c-sets (or cannot-links). 7.1 Datasets and Settings Datasets: We use product reviews from four domains (types of products) from Amazon.com for evaluation. The corpus statistics are shown in Table 2 (columns 2 and 3). The domains are â€œCamera,â€ â€œFood,â€ â€œComputer,â€ and â€œCareâ€ (short for â€œPersonal Careâ€). We have made the datasets publically available at the website of the first author. Domain #Reviews #Sentences #M-sets #C-sets Camera 500 5171 173 18 Food 500 2416 85 10 Computer 500 2864 92 6 Care 500 3008 119 13 Average 500</context>
<context position="35630" citStr="Liu, 2012" startWordPosition="6259" endWordPosition="6260">rtcomings of DFLDA are not very obvious, but with more knowledge, these issues become more serious and thus degrade the performance of DF-LDA. 7.3 Human Evaluation Since our aim is to make topics more interpretable and conformable to human judgments, we worked with two judges who are familiar with Amazon products and reviews to evaluate the models subjectively. Since topics from topic models are rankings based on word probability and we do not know the number of correct topical words, a natural way to evaluate these rankings is to use Precision@n (or p@n) which was also used in (Mukherjee and Liu, 2012; Zhao et al., 2010), where n is the rank position. We give p@n for n = 5 and 10. There are two steps in human evaluation: topic labeling and word labeling. Topic Labeling: We followed the instructions in (Mimno et al., 2011) and asked the judges to label each topic as good or bad. Each topic was presented as a list of 10 most probable words in descending order of their probabilities under that topic. The models which generated the topics for labeling were obscure to the judges. In general, each topic was annotated as good if it had more than half of its words coherently related to each other </context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Benjamin K Tsou</author>
</authors>
<title>Multi-aspect Sentiment Analysis with Topic Models.</title>
<date>2011</date>
<booktitle>In Proceedings of ICDM Workshops,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="3047" citStr="Lu et al., 2011" startWordPosition="468" endWordPosition="471">elate well with human judgments and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were proposed. They enable the user to specify prior knowledge as seed words/terms for some topics. Petterson et al. (2010) also used word similarity as priors for guidance. However, none of the existing models is capable of incorporating the cannot-link type of knowledge except DF-LDA (Andrzejewski et al., 2009). Furthermore, none of the existing models, including DF-LDA, is able to automatically adjust the number of topics based on domain knowledge. The domain knowledge, such as cannot-links, may change the number of topics. There are two types of ca</context>
<context position="26170" citStr="Lu et al., 2011" startWordPosition="4669" endWordPosition="4672">), which is perhaps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-links and cannot-links. This is the full DF-LDA model in (Andrzejewski et al., 2009). We do not compare with seeded models in (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012) as seed sets are special cases of must-links and they also do not allow c-sets (or cannot-links). 7.1 Datasets and Settings Datasets: We use product reviews from four domains (types of products) from Amazon.com for evaluation. The corpus statistics are shown in Table 2 (columns 2 and 3). The domains are â€œCamera,â€ â€œFood,â€ â€œComputer,â€ and â€œCareâ€ (short for â€œPersonal Careâ€). We have made the datasets publically available at the website of the first author. Domain #Reviews #Sentences #M-sets #C-sets Camera 500 5171 173 18 Food 500 2416 85 10 Computer 500 2864 92 6 Care 5</context>
</contexts>
<marker>Lu, Ott, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Myle Ott, Claire Cardie, and Benjamin K. Tsou. 2011. Multi-aspect Sentiment Analysis with Topic Models. In Proceedings of ICDM Workshops, pages 81â€“88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Hongning Wang</author>
<author>ChengXiang Zhai</author>
<author>Dan Roth</author>
</authors>
<title>Unsupervised discovery of opposing opinion networks from forum discussions.</title>
<date>2012</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>1642--1646</pages>
<marker>Lu, Wang, Zhai, Roth, 2012</marker>
<rawString>Yue Lu, Hongning Wang, ChengXiang Zhai, and Dan Roth. 2012. Unsupervised discovery of opposing opinion networks from forum discussions. In Proceedings of CIKM, pages 1642â€“1646.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Opinion integration through semi-supervised topic modeling.</title>
<date>2008</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>121--130</pages>
<contexts>
<context position="9692" citStr="Lu and Zhai, 2008" startWordPosition="1595" endWordPosition="1598">for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some othe</context>
</contexts>
<marker>Lu, Zhai, 2008</marker>
<rawString>Yue Lu and Chengxiang Zhai. 2008. Opinion integration through semi-supervised topic modeling. In Proceedings of WWW, pages 121â€“130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
<author>Neel Sundaresan</author>
</authors>
<title>Rated aspect summarization of short comments.</title>
<date>2009</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>131--140</pages>
<contexts>
<context position="9661" citStr="Lu et al., 2009" startWordPosition="1589" endWordPosition="1592"> aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization</context>
</contexts>
<marker>Lu, Zhai, Sundaresan, 2009</marker>
<rawString>Yue Lu, ChengXiang Zhai, and Neel Sundaresan. 2009. Rated aspect summarization of short comments. In Proceedings of WWW, pages 131â€“140.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hosam Mahmoud</author>
</authors>
<title>Polya Urn Models.</title>
<date>2008</date>
<journal>Chapman &amp; Hall/CRC Texts in Statistical Science.</journal>
<contexts>
<context position="7357" citStr="Mahmoud, 2008" startWordPosition="1198" endWordPosition="1199">), any word that shares an m-set with w1 is also a cannot-word of w2. Note that knowledge as m-sets has also been used in (Chen et al., 2013a) and (Chen et al., 2013b). We then propose a new topic model, called MCLDA (LDA with m-set and c-set), which is not only able to deal with c-sets and automatically adjust the number of topics, but also deal with the multiple senses and adverse effect of knowledge problems at the same time. For the issue of multiple senses, a new latent variable s is added to LDA to distinguish multiple senses (Â§ 3). Then, we employ the generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) to address the issue of adverse effect of knowledge (Â§ 4). Deviating from the standard topic modeling approaches, we propose the Extended generalized PÃ³lya urn (E-GPU) model (Â§ 5). E-GPU extends the GPU model to enable multi-urn interactions. This is necessary for handling c-sets and for adjusting the number of topics. E-GPU is the heart of MC-LDA. Due to the extension, a new inference mechanism is designed for MC-LDA (Â§ 6). Note that E-GPU is generic and can be used in any appropriate application. In summary, this paper makes the following three contributions: 1. It proposed a new knowledge-</context>
<context position="12019" citStr="Mahmoud, 2008" startWordPosition="1969" endWordPosition="1970">tively. Blei and McAuliffe (2007) and Ramage et al. (2009) used document labels in supervised setting. In (Chen et al., 2013a), we proposed MDKLDA to leverage multi-domain knowledge, which serves as the basic mechanism to exploit m-sets in MC-LDA. In (Chen et al., 2013b), we proposed a framework (called GK-LDA) to explicitly deal with the wrong knowledge when exploring the lexical semantic relations as the general (domain independent) knowledge in topic models. But these models above did not consider the knowledge in the form of c-sets (or cannot-links). The generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) was first introduced in LDA by Mimno et al. (2011). However, Mimno et al. (2011) did not use domain knowledge. Our results in Â§ 7 show that using domain knowledge can significantly improve aspect extraction. The GPU model was also employed in topic models in our work of (Chen et al., 2013a, 2013b). In this paper, we propose the Extended GPU (E-GPU) model. The EGPU model is more powerful in handling complex situations in dealing with c-sets. 3 Dealing with M-sets and Multiple Senses Since the proposed MC-LDA model is a major extension to our earlier work in (Chen et al., 2013a), which can deal</context>
</contexts>
<marker>Mahmoud, 2008</marker>
<rawString>Hosam Mahmoud. 2008. Polya Urn Models. Chapman &amp; Hall/CRC Texts in Statistical Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qiaozhu Mei</author>
<author>Xu Ling</author>
<author>Matthew Wondra</author>
<author>Hang Su</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Topic sentiment mixture: modeling facets and opinions in weblogs.</title>
<date>2007</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>171--180</pages>
<contexts>
<context position="9710" citStr="Mei et al., 2007" startWordPosition="1599" endWordPosition="1602">., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related wi</context>
</contexts>
<marker>Mei, Ling, Wondra, Su, Zhai, 2007</marker>
<rawString>Qiaozhu Mei, Xu Ling, Matthew Wondra, Hang Su, and ChengXiang Zhai. 2007. Topic sentiment mixture: modeling facets and opinions in weblogs. In Proceedings of WWW, pages 171â€“180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinfan Meng</author>
<author>Furu Wei</author>
<author>Xiaohua Liu</author>
<author>Ming Zhou</author>
<author>Sujian Li</author>
<author>Houfeng Wang</author>
</authors>
<title>Entity-centric topic-oriented opinion summarization in twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>379--387</pages>
<contexts>
<context position="10231" citStr="Meng et al. (2012)" startWordPosition="1684" endWordPosition="1687"> et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also n</context>
</contexts>
<marker>Meng, Wei, Liu, Zhou, Li, Wang, 2012</marker>
<rawString>Xinfan Meng, Furu Wei, Xiaohua Liu, Ming Zhou, Sujian Li, and Houfeng Wang. 2012. Entity-centric topic-oriented opinion summarization in twitter. In Proceedings of KDD, pages 379â€“387.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: A Lexical Database for English.</title>
<date>1995</date>
<journal>Commun. ACM,</journal>
<volume>38</volume>
<issue>11</issue>
<pages>39--41</pages>
<contexts>
<context position="30135" citStr="Miller, 1995" startWordPosition="5333" endWordPosition="5334">ilot experiments. Estimated value ğœ = 0.2 in equation 3 yielded good results. The second stage (steps 2 and 3) of the Gibbs sampler for MCLDA (for dealing with c-sets) is applied after burn-in phrase. Domain knowledge: User knowledge about a domain can vary a great deal. Different users may have very different knowledge. To reduce this variance for a more reliable evaluation, instead of asking a human user to provide m-sets, we obtain the synonym sets and the antonym sets of each word that is a noun or adjective (as words of other parts-of-speech usually do not indicate aspects) from WordNet (Miller, 1995) and manually verify the words in those sets for the domain. Note that if a word ğ‘¤ is not provided with any m-set, it is treated as a singleton m-set {ğ‘¤}. For c-sets, we ran LDA in each domain and provide c-sets based on the wrong results of LDA as in (Andrzejewski et al., 2009). Then, the knowledge is provided to each model in the format required by each model. The numbers of m-sets and c-sets are listed in columns 4 and 5 of Table 2. Duplicate sets have been removed. 7.2 Objective Evaluation In this section, we evaluate our proposed MC3 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. WordNet: A Lexical Database for English. Commun. ACM, 38(11), 39â€“41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Mimno</author>
<author>Hanna M Wallach</author>
<author>Edmund Talley</author>
<author>Miriam Leenders</author>
<author>Andrew McCallum</author>
</authors>
<title>Optimizing semantic coherence in topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>262--272</pages>
<contexts>
<context position="12070" citStr="Mimno et al. (2011)" startWordPosition="1977" endWordPosition="1980">t al. (2009) used document labels in supervised setting. In (Chen et al., 2013a), we proposed MDKLDA to leverage multi-domain knowledge, which serves as the basic mechanism to exploit m-sets in MC-LDA. In (Chen et al., 2013b), we proposed a framework (called GK-LDA) to explicitly deal with the wrong knowledge when exploring the lexical semantic relations as the general (domain independent) knowledge in topic models. But these models above did not consider the knowledge in the form of c-sets (or cannot-links). The generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) was first introduced in LDA by Mimno et al. (2011). However, Mimno et al. (2011) did not use domain knowledge. Our results in Â§ 7 show that using domain knowledge can significantly improve aspect extraction. The GPU model was also employed in topic models in our work of (Chen et al., 2013a, 2013b). In this paper, we propose the Extended GPU (E-GPU) model. The EGPU model is more powerful in handling complex situations in dealing with c-sets. 3 Dealing with M-sets and Multiple Senses Since the proposed MC-LDA model is a major extension to our earlier work in (Chen et al., 2013a), which can deal with m-sets, we include this earlier work here as </context>
<context position="22181" citStr="Mimno et al., 2011" startWordPosition="3903" endWordPosition="3906">â† ğ‘›ğ‘š,ğ‘§ğ‘– + 1; for each word ğ‘¤â€² in ğ‘ ğ‘– do ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘– + ğ”¸ğ‘ ğ‘–,ğ‘¤â€²,ğ‘¤ğ‘–; 10: end for 11: ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– â† ğ‘›ğ‘§ğ‘–,ğ‘ ğ‘–,ğ‘¤ğ‘– + 1; 12: if ğœ‡ is true then 13: TransferCannotWords(ğ‘¤ğ‘–, ğ‘§ğ‘–); 14: end if Figure 2. Gibbs sampling for MC-LDA. sampling scheme, and hence MC-LDA shares the same plate as MDK-LDA(b). 6 Collapsed Gibbs Sampling We now describe the collapsed Gibbs sampler (Griffiths and Steyvers, 2004) with the detailed conditional distributions and algorithms for MCLDA. Inference of ğ‘§ and ğ‘  can be computationally expensive due to the non-exchangeability of words under the E-GPU models. We take the approach of (Mimno et al., 2011) which approximates the true Gibbs sampling distribution by treating each word as if it were the last. For each word ğ‘¤ğ‘– , we perform hierarchical sampling consisting of the following three steps (the detailed algorithms are given in Figures 2 and 3): Step 1 (Lines 1-11 in Figure 2): We jointly sample a topic ğ‘§ğ‘– and an m-set ğ‘ ğ‘– (containing ğ‘¤ğ‘–) for ğ‘¤ğ‘–, which gives us a blocked Gibbs sampler (Ishwaran and James, 2001), with the conditional probability given by: ğ‘ƒ(ğ‘§ğ‘– = ğ‘¡, ğ‘ ğ‘– = ğ‘ |ğ’›âˆ’ğ‘–,ğ’”âˆ’ğ‘–, ğ’˜, ğ›¼, ğ›½, ğ›¾,ğ”¸) âˆ âˆ‘ âˆ‘ ğ”¸ğ‘ ,ğ‘£â€²,ğ‘¤â€² âˆ™ğ‘›ğ‘¡,ğ‘ ,ğ‘£â€² ğ‘‰ ğ‘‰ âˆ’ğ‘– +ğ›½ ğ‘¤â€²=1 ğ‘£â€²=1 Ã— âˆ‘ ï¿½âˆ‘ âˆ‘ ğ”¸ğ‘ â€²,ğ‘£â€²,ğ‘¤â€²âˆ™ğ‘›ğ‘¡,ğ‘ â€²,ğ‘£â€² ğ‘† ğ‘‰ ğ‘‰ âˆ’ğ‘– +ğ›½ï¿½ ğ‘ â€²=1 ğ‘¤â€²=1 ğ‘£â€²</context>
<context position="25386" citStr="Mimno et al., 2011" startWordPosition="4540" endWordPosition="4543">to be transferred only to an urn that contains a higher proportion of its m-set. When no topic t can be successfully sampled and the current sweep (iteration) of Gibbs sampling has the same number of topic (T) as the previous sweep, we increment T by 1. And then assign T to zb . The counts and parameters are also updated accordingly. 7 Experiments We now evaluate the proposed MC-LDA model and compare it with state-of-the-art existing models. Two unsupervised baseline models that we compare with are: â€¢ LDA: LDA is the basic unsupervised topic model (Blei et al., 2003). â€¢ LDA-GPU: LDA with GPU (Mimno et al., 2011). Specifically, LDA-GPU applies GPU in LDA using co-document frequency. As for knowledge-based models, we focus on comparing with DF-LDA model (Andrzejewski et al., 2009), which is perhaps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-link</context>
<context position="31443" citStr="Mimno et al., 2011" startWordPosition="5547" endWordPosition="5550">bjectively. Topic models are often evaluated using perplexity on held-out test data. However, the perplexity metric does not reflect the semantic coherence of individual topics learned by a topic model (Newman et al., 2010). Recent research has shown potential issues with perplexity as a measure: (Chang et al., 2009) suggested that the perplexity can sometimes be contrary to human judgments. Also, perplexity does not really reflect our goal of finding coherent aspects with accurate semantic clustering. It only provides a measure of how well the model fits the data. The Topic Coherence metric (Mimno et al., 2011) (also called the â€œUMassâ€ measure (Stevens and Buttler, 2012)) was proposed as a better alternative for assessing topic quality. This metric relies upon word co-occurrence statistics within the documents, and does not depend on external resources or human labeling. It was shown that topic coherence is highly consistent with human expert labeling by Mimno et al. (2011). Higher topic coherence score indicates higher quality of topics, i.e., better topic interpretability. Effects of Number of Topics Since our proposed models and the baseline models are all parametric models, we first compare each</context>
<context position="35855" citStr="Mimno et al., 2011" startWordPosition="6299" endWordPosition="6302">and conformable to human judgments, we worked with two judges who are familiar with Amazon products and reviews to evaluate the models subjectively. Since topics from topic models are rankings based on word probability and we do not know the number of correct topical words, a natural way to evaluate these rankings is to use Precision@n (or p@n) which was also used in (Mukherjee and Liu, 2012; Zhao et al., 2010), where n is the rank position. We give p@n for n = 5 and 10. There are two steps in human evaluation: topic labeling and word labeling. Topic Labeling: We followed the instructions in (Mimno et al., 2011) and asked the judges to label each topic as good or bad. Each topic was presented as a list of 10 most probable words in descending order of their probabilities under that topic. The models which generated the topics for labeling were obscure to the judges. In general, each topic was annotated as good if it had more than half of its words coherently related to each other representing a semantic concept together; otherwise bad. Agreement of human judges on topic Camera Food Computer Care MC-LDA M-LDA LDA DF-M DF-MC LDA-GPU 1663 labeling using Cohenâ€™s Kappa yielded a score of 0.92 indicating al</context>
</contexts>
<marker>Mimno, Wallach, Talley, Leenders, McCallum, 2011</marker>
<rawString>David Mimno, Hanna M. Wallach, Edmund Talley, Miriam Leenders, and Andrew McCallum. 2011. Optimizing semantic coherence in topic models. In Proceedings of EMNLP, pages 262â€“272.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samaneh Moghaddam</author>
<author>Martin Ester</author>
</authors>
<title>ILDA: interdependent LDA model for learning latent aspects and their ratings from online product reviews.</title>
<date>2011</date>
<booktitle>In Proceedings of SIGIR,</booktitle>
<pages>665--674</pages>
<contexts>
<context position="9737" citStr="Moghaddam and Ester, 2011" startWordPosition="1603" endWordPosition="1606"> et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis inclu</context>
</contexts>
<marker>Moghaddam, Ester, 2011</marker>
<rawString>Samaneh Moghaddam and Martin Ester. 2011. ILDA: interdependent LDA model for learning latent aspects and their ratings from online product reviews. In Proceedings of SIGIR, pages 665â€“674.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif Mohammad</author>
<author>Cody Dunne</author>
<author>Bonnie J Dorr</author>
</authors>
<title>Generating High-Coverage Semantic Orientation Lexicons From Overtly Marked Words and a Thesaurus.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>599--608</pages>
<contexts>
<context position="10436" citStr="Mohammad et al., 2009" startWordPosition="1714" endWordPosition="1717">g et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model </context>
</contexts>
<marker>Mohammad, Dunne, Dorr, 2009</marker>
<rawString>Saif Mohammad, Cody Dunne, and Bonnie J. Dorr. 2009. Generating High-Coverage Semantic Orientation Lexicons From Overtly Marked Words and a Thesaurus. In Proceedings of EMNLP, pages 599â€“608.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
</authors>
<title>Aspect Extraction through Semi-Supervised Modeling.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>339--348</pages>
<contexts>
<context position="3073" citStr="Mukherjee and Liu, 2012" startWordPosition="472" endWordPosition="475">uman judgments and needs (Chang et al., 2009). To address the issue, several knowledge-based topic models have been proposed. The DF-LDA model (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were proposed. They enable the user to specify prior knowledge as seed words/terms for some topics. Petterson et al. (2010) also used word similarity as priors for guidance. However, none of the existing models is capable of incorporating the cannot-link type of knowledge except DF-LDA (Andrzejewski et al., 2009). Furthermore, none of the existing models, including DF-LDA, is able to automatically adjust the number of topics based on domain knowledge. The domain knowledge, such as cannot-links, may change the number of topics. There are two types of cannot-links: consistent and</context>
<context position="5270" citStr="Mukherjee and Liu, 2012" startWordPosition="826" endWordPosition="829">arlier knowledge-based topic models also have some major shortcomings: Incapability of handling multiple senses: A word typically has multiple meanings or senses. For example, light can mean â€œof little weightâ€ or â€œsomething that makes things visible.â€ DF-LDA cannot handle multiple senses because its definition of must-link is transitive. That is, if A and B form a must-link, and B and C form a must-link, it implies a must-link between A and C, indicating A, B, and C should be in the same topic. This case also applies to the models in (Andrzejewski et al., 2011), (Petterson et al., 2010), and (Mukherjee and Liu, 2012). Although the model in (Jagarlamudi et al., 2012) allows multiple senses, it requires that each topic has at most one set of seed words (seed set), which is restrictive as the amount of knowledge should not be limited. Sensitivity to the adverse effect of knowledge: When using must-links or seeds, existing models basically try to ensure that the words in a mustlink or a seed set have similar probabilities under a topic. This causes a problem: if a must-link comprises of a frequent word and an infrequent word, due to the redistribution of probability mass, the probability of the frequent word </context>
<context position="9762" citStr="Mukherjee and Liu, 2012" startWordPosition="1607" endWordPosition="1610">2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal</context>
<context position="26196" citStr="Mukherjee and Liu, 2012" startWordPosition="4673" endWordPosition="4676">ps the best known knowledge-based model and it allows both mustlinks and cannot-links. For a comprehensive evaluation, we consider the following variations of MC-LDA and DF-LDA: â€¢ MC-LDA: MC-LDA with both m-sets and csets. This is the newly proposed model. â€¢ M-LDA: MC-LDA with m-sets only. This is the MDK-LDA model in (Chen et al., 2013a). â€¢ DF-M: DF-LDA with must-links only. â€¢ DF-MC: DF-LDA with both must-links and cannot-links. This is the full DF-LDA model in (Andrzejewski et al., 2009). We do not compare with seeded models in (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012) as seed sets are special cases of must-links and they also do not allow c-sets (or cannot-links). 7.1 Datasets and Settings Datasets: We use product reviews from four domains (types of products) from Amazon.com for evaluation. The corpus statistics are shown in Table 2 (columns 2 and 3). The domains are â€œCamera,â€ â€œFood,â€ â€œComputer,â€ and â€œCareâ€ (short for â€œPersonal Careâ€). We have made the datasets publically available at the website of the first author. Domain #Reviews #Sentences #M-sets #C-sets Camera 500 5171 173 18 Food 500 2416 85 10 Computer 500 2864 92 6 Care 500 3008 119 13 Average 500</context>
<context position="35630" citStr="Mukherjee and Liu, 2012" startWordPosition="6257" endWordPosition="6260">ledge, the shortcomings of DFLDA are not very obvious, but with more knowledge, these issues become more serious and thus degrade the performance of DF-LDA. 7.3 Human Evaluation Since our aim is to make topics more interpretable and conformable to human judgments, we worked with two judges who are familiar with Amazon products and reviews to evaluate the models subjectively. Since topics from topic models are rankings based on word probability and we do not know the number of correct topical words, a natural way to evaluate these rankings is to use Precision@n (or p@n) which was also used in (Mukherjee and Liu, 2012; Zhao et al., 2010), where n is the rank position. We give p@n for n = 5 and 10. There are two steps in human evaluation: topic labeling and word labeling. Topic Labeling: We followed the instructions in (Mimno et al., 2011) and asked the judges to label each topic as good or bad. Each topic was presented as a list of 10 most probable words in descending order of their probabilities under that topic. The models which generated the topics for labeling were obscure to the judges. In general, each topic was annotated as good if it had more than half of its words coherently related to each other </context>
</contexts>
<marker>Mukherjee, Liu, 2012</marker>
<rawString>Arjun Mukherjee and Bing Liu. 2012. Aspect Extraction through Semi-Supervised Modeling. In Proceedings of ACL, pages 339â€“348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Newman</author>
<author>Youn Noh</author>
<author>Edmund Talley</author>
<author>Sarvnaz Karimi</author>
<author>Timothy Baldwin</author>
</authors>
<title>Evaluating topic models for digital libraries.</title>
<date>2010</date>
<booktitle>In Proceedings of JCDL,</booktitle>
<pages>215--224</pages>
<contexts>
<context position="31047" citStr="Newman et al., 2010" startWordPosition="5483" endWordPosition="5486">nowledge is provided to each model in the format required by each model. The numbers of m-sets and c-sets are listed in columns 4 and 5 of Table 2. Duplicate sets have been removed. 7.2 Objective Evaluation In this section, we evaluate our proposed MC3 http://pages.cs.wisc.edu/~andrzeje/research/df_lda.html Figure 5. Avg. Topic Coherence score for different proportions of knowledge. LDA model objectively. Topic models are often evaluated using perplexity on held-out test data. However, the perplexity metric does not reflect the semantic coherence of individual topics learned by a topic model (Newman et al., 2010). Recent research has shown potential issues with perplexity as a measure: (Chang et al., 2009) suggested that the perplexity can sometimes be contrary to human judgments. Also, perplexity does not really reflect our goal of finding coherent aspects with accurate semantic clustering. It only provides a measure of how well the model fits the data. The Topic Coherence metric (Mimno et al., 2011) (also called the â€œUMassâ€ measure (Stevens and Buttler, 2012)) was proposed as a better alternative for assessing topic quality. This metric relies upon word co-occurrence statistics within the documents,</context>
</contexts>
<marker>Newman, Noh, Talley, Karimi, Baldwin, 2010</marker>
<rawString>David Newman, Youn Noh, Edmund Talley, Sarvnaz Karimi, and Timothy Baldwin. 2010. Evaluating topic models for digital libraries. In Proceedings of JCDL, pages 215â€“224.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<booktitle>Foundations and Trends in Information Retrieval,</booktitle>
<pages>2--1</pages>
<contexts>
<context position="8868" citStr="Pang and Lee, 2008" startWordPosition="1449" endWordPosition="1452">edge-based models is as comprehensive as MC-LDA in terms of capabilities. 2. It proposed the E-GPU model to enable multiurn interactions, which enables c-sets to be naturally integrated into a topic model. To the best of our knowledge, E-GPU has not been proposed and used before. 3. A comprehensive evaluation has been conducted to compare MC-LDA with several state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) </context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and Trends in Information Retrieval, 2(1-2), 1â€“135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Petterson</author>
<author>Alex Smola</author>
<author>TibÃ©rio Caetano</author>
<author>Wray Buntine</author>
<author>Shravan Narayanamurthy</author>
</authors>
<title>Word Features for Latent Dirichlet Allocation.</title>
<date>2010</date>
<booktitle>In Proceedings of NIPS,</booktitle>
<pages>1921--1929</pages>
<contexts>
<context position="3212" citStr="Petterson et al. (2010)" startWordPosition="494" endWordPosition="497">el (Andrzejewski et al., 2009) incorporates two forms of prior knowledge, also called two types of constraints: must-links and cannot-links. A must-link states that two words (or terms) should belong to the same topic whereas a cannotlink indicates that two words should not be in the same topic. In (Andrzejewski et al., 2011), more general knowledge can be specified using firstorder logic. In (Burns et al., 2012; Jagarlamudi et al., 2012; Lu et al., 2011; Mukherjee and Liu, 2012), seeded models were proposed. They enable the user to specify prior knowledge as seed words/terms for some topics. Petterson et al. (2010) also used word similarity as priors for guidance. However, none of the existing models is capable of incorporating the cannot-link type of knowledge except DF-LDA (Andrzejewski et al., 2009). Furthermore, none of the existing models, including DF-LDA, is able to automatically adjust the number of topics based on domain knowledge. The domain knowledge, such as cannot-links, may change the number of topics. There are two types of cannot-links: consistent and inconsistent with the domain corpus. For example, in the reviews of 1655 Proceedings of the 2013 Conference on Empirical Methods in Natura</context>
<context position="5239" citStr="Petterson et al., 2010" startWordPosition="821" endWordPosition="824"> from the above shortcoming, earlier knowledge-based topic models also have some major shortcomings: Incapability of handling multiple senses: A word typically has multiple meanings or senses. For example, light can mean â€œof little weightâ€ or â€œsomething that makes things visible.â€ DF-LDA cannot handle multiple senses because its definition of must-link is transitive. That is, if A and B form a must-link, and B and C form a must-link, it implies a must-link between A and C, indicating A, B, and C should be in the same topic. This case also applies to the models in (Andrzejewski et al., 2011), (Petterson et al., 2010), and (Mukherjee and Liu, 2012). Although the model in (Jagarlamudi et al., 2012) allows multiple senses, it requires that each topic has at most one set of seed words (seed set), which is restrictive as the amount of knowledge should not be limited. Sensitivity to the adverse effect of knowledge: When using must-links or seeds, existing models basically try to ensure that the words in a mustlink or a seed set have similar probabilities under a topic. This causes a problem: if a must-link comprises of a frequent word and an infrequent word, due to the redistribution of probability mass, the pr</context>
</contexts>
<marker>Petterson, Smola, Caetano, Buntine, Narayanamurthy, 2010</marker>
<rawString>James Petterson, Alex Smola, TibÃ©rio Caetano, Wray Buntine, and Shravan Narayanamurthy. 2010. Word Features for Latent Dirichlet Allocation. In Proceedings of NIPS, pages 1921â€“1929.</rawString>
</citation>
<citation valid="true">
<authors>
<author>AM Popescu</author>
<author>Oren Etzioni</author>
</authors>
<title>Extracting product features and opinions from reviews.</title>
<date>2005</date>
<booktitle>In Proceedings of HLT,</booktitle>
<pages>339--346</pages>
<contexts>
<context position="9187" citStr="Popescu and Etzioni, 2005" startWordPosition="1503" endWordPosition="1506">as been conducted to compare MC-LDA with several state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Ti</context>
</contexts>
<marker>Popescu, Etzioni, 2005</marker>
<rawString>AM Popescu and Oren Etzioni. 2005. Extracting product features and opinions from reviews. In Proceedings of HLT, pages 339â€“346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guang Qiu</author>
<author>Bing Liu</author>
<author>Jiajun Bu</author>
<author>Chun Chen</author>
</authors>
<title>Opinion Word Expansion and Target Extraction through Double Propagation.</title>
<date>2011</date>
<journal>Computational Linguistics,</journal>
<volume>37</volume>
<issue>1</issue>
<pages>9--27</pages>
<contexts>
<context position="9205" citStr="Qiu et al., 2011" startWordPosition="1507" endWordPosition="1510">e MC-LDA with several state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, </context>
</contexts>
<marker>Qiu, Liu, Bu, Chen, 2011</marker>
<rawString>Guang Qiu, Bing Liu, Jiajun Bu, and Chun Chen. 2011. Opinion Word Expansion and Target Extraction through Double Propagation. Computational Linguistics, 37(1), 9â€“27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Ramage</author>
<author>David Hall</author>
<author>Ramesh Nallapati</author>
<author>Christopher D Manning</author>
</authors>
<title>Labeled LDA: a supervised topic model for credit attribution in multilabeled corpora.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>248--256</pages>
<contexts>
<context position="11463" citStr="Ramage et al. (2009)" startWordPosition="1879" endWordPosition="1882">ome aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides those discussed in Â§ 1, the model (Hu et al., 2011) enables the user to provide guidance interactively. Blei and McAuliffe (2007) and Ramage et al. (2009) used document labels in supervised setting. In (Chen et al., 2013a), we proposed MDKLDA to leverage multi-domain knowledge, which serves as the basic mechanism to exploit m-sets in MC-LDA. In (Chen et al., 2013b), we proposed a framework (called GK-LDA) to explicitly deal with the wrong knowledge when exploring the lexical semantic relations as the general (domain independent) knowledge in topic models. But these models above did not consider the knowledge in the form of c-sets (or cannot-links). The generalized PÃ³lya urn (GPU) model (Mahmoud, 2008) was first introduced in LDA by Mimno et al.</context>
</contexts>
<marker>Ramage, Hall, Nallapati, Manning, 2009</marker>
<rawString>Daniel Ramage, David Hall, Ramesh Nallapati, and Christopher D. Manning. 2009. Labeled LDA: a supervised topic model for credit attribution in multilabeled corpora. In Proceedings of EMNLP, pages 248â€“256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Sauper</author>
<author>Regina Barzilay</author>
</authors>
<title>Automatic Aggregation by Joint Modeling of Aspects and Values.</title>
<date>2013</date>
<journal>J. Artif. Intell. Res. (JAIR),</journal>
<volume>46</volume>
<pages>89--127</pages>
<contexts>
<context position="10995" citStr="Sauper and Barzilay, 2013" startWordPosition="1802" endWordPosition="1805">Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides those discussed in Â§ 1, the model (Hu et al., 2011) enables the user to provide guidance interactively. Blei and McAuliffe (2007) and Ramage et al. (2009) used document labels in supervised setting. In (Chen et al., 2013a), we proposed MDKLDA to leverage multi-domain knowledge, which s</context>
</contexts>
<marker>Sauper, Barzilay, 2013</marker>
<rawString>Christina Sauper and Regina Barzilay. 2013. Automatic Aggregation by Joint Modeling of Aspects and Values. J. Artif. Intell. Res. (JAIR), 46, 89â€“127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christina Sauper</author>
<author>Aria Haghighi</author>
<author>Regina Barzilay</author>
</authors>
<title>Content Models with Attitude.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>350--358</pages>
<contexts>
<context position="9783" citStr="Sauper et al., 2011" startWordPosition="1611" endWordPosition="1614">pescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and I</context>
</contexts>
<marker>Sauper, Haghighi, Barzilay, 2011</marker>
<rawString>Christina Sauper, Aria Haghighi, and Regina Barzilay. 2011. Content Models with Attitude. In Proceedings of ACL, pages 350â€“358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Swapna Somasundaran</author>
<author>J Wiebe</author>
</authors>
<title>Recognizing stances in online debates.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>226--234</pages>
<contexts>
<context position="9235" citStr="Somasundaran and Wiebe, 2009" startWordPosition="1511" endWordPosition="1514">ral state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011;</context>
</contexts>
<marker>Somasundaran, Wiebe, 2009</marker>
<rawString>Swapna Somasundaran and J. Wiebe. 2009. Recognizing stances in online debates. In Proceedings of ACL, pages 226â€“234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Keith Stevens</author>
<author>PKDAD Buttler</author>
</authors>
<title>Exploring Topic Coherence over many models and many topics.</title>
<date>2012</date>
<booktitle>In Proceedings of EMNLP-CoNLL,</booktitle>
<pages>952--961</pages>
<contexts>
<context position="31504" citStr="Stevens and Buttler, 2012" startWordPosition="5556" endWordPosition="5559">plexity on held-out test data. However, the perplexity metric does not reflect the semantic coherence of individual topics learned by a topic model (Newman et al., 2010). Recent research has shown potential issues with perplexity as a measure: (Chang et al., 2009) suggested that the perplexity can sometimes be contrary to human judgments. Also, perplexity does not really reflect our goal of finding coherent aspects with accurate semantic clustering. It only provides a measure of how well the model fits the data. The Topic Coherence metric (Mimno et al., 2011) (also called the â€œUMassâ€ measure (Stevens and Buttler, 2012)) was proposed as a better alternative for assessing topic quality. This metric relies upon word co-occurrence statistics within the documents, and does not depend on external resources or human labeling. It was shown that topic coherence is highly consistent with human expert labeling by Mimno et al. (2011). Higher topic coherence score indicates higher quality of topics, i.e., better topic interpretability. Effects of Number of Topics Since our proposed models and the baseline models are all parametric models, we first compare each model given different numbers of topics. Figure 4 shows the </context>
</contexts>
<marker>Stevens, Buttler, 2012</marker>
<rawString>Keith Stevens and PKDAD Buttler. 2012. Exploring Topic Coherence over many models and many topics. In Proceedings of EMNLP-CoNLL, pages 952â€“961.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veselin Stoyanov</author>
<author>Claire Cardie</author>
</authors>
<title>Automatically Creating General-Purpose Opinion Summaries from Text.</title>
<date>2011</date>
<booktitle>In Proceedings of RANLP,</booktitle>
<pages>202--209</pages>
<contexts>
<context position="10186" citStr="Stoyanov and Cardie (2011)" startWordPosition="1675" endWordPosition="1678">h, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect te</context>
</contexts>
<marker>Stoyanov, Cardie, 2011</marker>
<rawString>Veselin Stoyanov and Claire Cardie. 2011. Automatically Creating General-Purpose Opinion Summaries from Text. In Proceedings of RANLP, pages 202â€“209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
<author>Michael I Jordan</author>
<author>Matthew J Beal</author>
<author>David M Blei</author>
</authors>
<title>Hierarchical dirichlet processes.</title>
<date>2006</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>1</volume>
<contexts>
<context position="28678" citStr="Teh et al., 2006" startWordPosition="5100" endWordPosition="5103">any change to their models. Although the relationships between sentences are lost, the data is fair to all models. Parameter settings: For all models, posterior inference was drawn using 1000 Gibbs iterations with an initial burn-in of 100 iterations. For all models, we set a = 1 and fl = 0.1. We found that small changes of a and fl did not affect the results much, which was also reported in (Jo and Oh, 2011) who also used online reviews. For the number of topics T, we tried different values (see Â§7.2) as it is hard to know the exact number of topics. While non-parametric Bayesian approaches (Teh et al., 2006) aim to estimate T from the corpus, they are often sensitive to the hyper-parameters (Heinrich, 2009). 1 http://nlp.stanford.edu/software/corenlp.shtml 2 http://jmlr.org/papers/volume5/lewis04a/a11-smart-stop-list 1661 3 6 9 12 15 MC-LDA M-LDA LDA DF-M DF-MC LDA-GPU 0% 25% 50% 100% MC-LDA M-LDA DF-M DF-MC -1200 -1300 -1400 -1500 -1600 -1240 -1260 -1280 -1300 -1320 Figure 4. Avg. Topic Coherence score of each model across different number of topics. For DF-LDA, we followed (Andrzejewski et al., 2009) to generate must-links and cannot-links from our domain knowledge. We then ran DFLDA3 while kee</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Yee Whye Teh, Michael I. Jordan, Matthew J. Beal, and David M. Blei. 2006. Hierarchical dirichlet processes. Journal of the American Statistical Association, 1â€“30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Titov</author>
<author>Ryan McDonald</author>
</authors>
<title>Modeling online reviews with multi-grain topic models.</title>
<date>2008</date>
<booktitle>In Proceedings of WWW,</booktitle>
<pages>111--120</pages>
<contexts>
<context position="9809" citStr="Titov and McDonald, 2008" startWordPosition="1615" endWordPosition="1618">05; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2</context>
<context position="27328" citStr="Titov and McDonald, 2008" startWordPosition="4865" endWordPosition="4868">a 500 5171 173 18 Food 500 2416 85 10 Computer 500 2864 92 6 Care 500 3008 119 13 Average 500 3116 103 9 Table 2. Corpus statistics with #m-sets and #c-sets having at least two words. Pre-processing: We ran the Stanford Core NLP Tools1 to perform sentence detection and lemmatization. Punctuations, stopwords 2 , numbers and words appearing less than 5 times in each corpus were removed. The domain name was also removed, e.g., word camera in the domain â€œCameraâ€, since it co-occurs with most words in the corpus, leading to high similarity among topics/aspects. Sentences as documents: As noted in (Titov and McDonald, 2008), when standard topic models are applied to reviews as documents, they tend to produce topics that correspond to global properties of products (e.g., brand name), which make topics overlapping with each other. The reason is that all reviews of the same type of products discuss about the same aspects of these products. Only the brand names and product names are different. Thus, using individual reviews for modeling is not very effective. Although there are approaches which model sentences (Jo and Oh, 2011; Titov and McDonald, 2008), we take the approach of (Brody and Elhadad, 2010), dividing ea</context>
</contexts>
<marker>Titov, McDonald, 2008</marker>
<rawString>Ivan Titov and Ryan McDonald. 2008. Modeling online reviews with multi-grain topic models. In Proceedings of WWW, pages 111â€“120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong Wang</author>
<author>Yang Liu</author>
</authors>
<title>A Pilot Study of Opinion Summarization in Conversations.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>331--339</pages>
<contexts>
<context position="10207" citStr="Wang and Liu (2011)" startWordPosition="1679" endWordPosition="1682">azaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extract</context>
</contexts>
<marker>Wang, Liu, 2011</marker>
<rawString>Dong Wang and Yang Liu. 2011. A Pilot Study of Opinion Summarization in Conversations. In Proceedings of ACL, pages 331â€“339.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>Chengxiang Zhai</author>
</authors>
<title>Latent aspect rating analysis on review text data: a rating regression approach.</title>
<date>2010</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>783--792</pages>
<contexts>
<context position="9828" citStr="Wang et al., 2010" startWordPosition="1619" endWordPosition="1622">sundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al</context>
</contexts>
<marker>Wang, Lu, Zhai, 2010</marker>
<rawString>Hongning Wang, Yue Lu, and Chengxiang Zhai. 2010. Latent aspect rating analysis on review text data: a rating regression approach. In Proceedings of KDD, pages 783â€“792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongning Wang</author>
<author>Yue Lu</author>
<author>ChengXiang Zhai</author>
</authors>
<title>Latent aspect rating analysis without aspect keyword supervision.</title>
<date>2011</date>
<booktitle>In Proceedings of KDD,</booktitle>
<pages>618--626</pages>
<marker>Wang, Lu, Zhai, 2011</marker>
<rawString>Hongning Wang, Yue Lu, and ChengXiang Zhai. 2011. Latent aspect rating analysis without aspect keyword supervision. In Proceedings of KDD, pages 618â€“626.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Ellen Riloff</author>
</authors>
<title>Creating Subjective and Objective Sentence Classifiers from Unannotated Texts.</title>
<date>2005</date>
<booktitle>In Proceedings of CICLing,</booktitle>
<pages>486--497</pages>
<contexts>
<context position="8892" citStr="Wiebe and Riloff, 2005" startWordPosition="1453" endWordPosition="1456"> as comprehensive as MC-LDA in terms of capabilities. 2. It proposed the E-GPU model to enable multiurn interactions, which enables c-sets to be naturally integrated into a topic model. To the best of our knowledge, E-GPU has not been proposed and used before. 3. A comprehensive evaluation has been conducted to compare MC-LDA with several state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan e</context>
</contexts>
<marker>Wiebe, Riloff, 2005</marker>
<rawString>Janyce Wiebe and Ellen Riloff. 2005. Creating Subjective and Objective Sentence Classifiers from Unannotated Texts. In Proceedings of CICLing, pages 486â€“497.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Rebecca F Bruce</author>
<author>Matthew Bell</author>
<author>Melanie Martin</author>
</authors>
<title>Learning Subjective Language.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<pages>277--308</pages>
<contexts>
<context position="8913" citStr="Wiebe et al., 2004" startWordPosition="1457" endWordPosition="1460">LDA in terms of capabilities. 2. It proposed the E-GPU model to enable multiurn interactions, which enables c-sets to be naturally integrated into a topic model. To the best of our knowledge, E-GPU has not been proposed and used before. 3. A comprehensive evaluation has been conducted to compare MC-LDA with several state-ofthe-art models. Experimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody an</context>
</contexts>
<marker>Wiebe, Wilson, Bruce, Bell, Martin, 2004</marker>
<rawString>Janyce Wiebe, Theresa Wilson, Rebecca F. Bruce, Matthew Bell, and Melanie Martin. 2004. Learning Subjective Language. Computational Linguistics, 30(3), 277â€“308.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Wiegand</author>
<author>Dietrich Klakow</author>
</authors>
<title>Convolution Kernels for Opinion Holder Extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of HLT-NAACL,</booktitle>
<pages>795--803</pages>
<contexts>
<context position="10120" citStr="Wiegand and Klakow, 2010" startWordPosition="1663" endWordPosition="1666">l., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et</context>
</contexts>
<marker>Wiegand, Klakow, 2010</marker>
<rawString>Michael Wiegand and Dietrich Klakow. 2010. Convolution Kernels for Opinion Holder Extraction. In Proceedings of HLT-NAACL, pages 795â€“803.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Phrase dependency parsing for opinion mining.</title>
<date>2009</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1533--1541</pages>
<contexts>
<context position="9252" citStr="Wu et al., 2009" startWordPosition="1515" endWordPosition="1518">perimental results based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 201</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2009</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2009. Phrase dependency parsing for opinion mining. In Proceedings of EMNLP, pages 1533â€“ 1541.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuanbin Wu</author>
<author>Qi Zhang</author>
<author>Xuanjing Huang</author>
<author>Lide Wu</author>
</authors>
<title>Structural Opinion Mining for Graphbased Sentiment Representation.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>1332--1341</pages>
<contexts>
<context position="10072" citStr="Wu et al., 2011" startWordPosition="1657" endWordPosition="1660">, 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering a</context>
</contexts>
<marker>Wu, Zhang, Huang, Wu, 2011</marker>
<rawString>Yuanbin Wu, Qi Zhang, Xuanjing Huang, and Lide Wu. 2011. Structural Opinion Mining for Graphbased Sentiment Representation. In Proceedings of EMNLP, pages 1332â€“1341.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunqing Xia</author>
<author>Boyi Hao</author>
<author>Kam-Fai Wong</author>
</authors>
<title>Opinion Target Network and Bootstrapping Method for Chinese Opinion Target Extraction.</title>
<date>2009</date>
<booktitle>In Proceedings of AIRS,</booktitle>
<pages>339--350</pages>
<contexts>
<context position="9958" citStr="Xia et al., 2009" startWordPosition="1640" endWordPosition="1643">e labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simu</context>
</contexts>
<marker>Xia, Hao, Wong, 2009</marker>
<rawString>Yunqing Xia, Boyi Hao, and Kam-Fai Wong. 2009. Opinion Target Network and Bootstrapping Method for Chinese Opinion Target Extraction. In Proceedings of AIRS, pages 339â€“350.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianxing Yu</author>
<author>Zheng-Jun Zha</author>
<author>Meng Wang</author>
<author>TatSeng Chua</author>
</authors>
<title>Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1496--1505</pages>
<contexts>
<context position="9269" citStr="Yu et al., 2011" startWordPosition="1519" endWordPosition="1522">s based on both qualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approac</context>
</contexts>
<marker>Yu, Zha, Wang, Chua, 2011</marker>
<rawString>Jianxing Yu, Zheng-Jun Zha, Meng Wang, and TatSeng Chua. 2011. Aspect Ranking: Identifying Important Product Aspects from Online Consumer Reviews. In Proceedings of ACL, pages 1496â€“1505.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongwu Zhai</author>
<author>Bing Liu</author>
<author>Hua Xu</author>
<author>Peifa Jia</author>
</authors>
<title>Constrained LDA for grouping product features in opinion mining.</title>
<date>2011</date>
<booktitle>In Proceedings of the 15th PacificAsia Conference on Knowledge Discovery and Data Mining (PAKDD),</booktitle>
<pages>448--459</pages>
<contexts>
<context position="10750" citStr="Zhai et al., 2011" startWordPosition="1765" endWordPosition="1768">adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although there are several related works on clustering aspect terms (e.g., Carenini et al., 2005; Guo et al., 2009; Zhai et al., 2011), they all assume that the aspect terms have been extracted beforehand. We also notice that some aspect extraction models in sentiment analysis separately discover aspect words and aspect specific sentiment words (e.g., Sauper and Barzilay, 2013; Zhao et al., 2010). Our proposed model does not separate them as most sentiment words also imply aspects and most adjectives modify specific attributes of objects. For example, sentiment words expensive and beautiful imply aspects price and appearance respectively. Regarding the knowledge-based models, besides those discussed in Â§ 1, the model (Hu et </context>
</contexts>
<marker>Zhai, Liu, Xu, Jia, 2011</marker>
<rawString>Zhongwu Zhai, Bing Liu, Hua Xu, and Peifa Jia. 2011. Constrained LDA for grouping product features in opinion mining. In Proceedings of the 15th PacificAsia Conference on Knowledge Discovery and Data Mining (PAKDD), pages 448â€“459.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Zhang</author>
<author>Bing Liu</author>
</authors>
<title>Identifying Noun Product Features that Imply Opinions.</title>
<date>2011</date>
<booktitle>In Proceedings of ACL (Short Papers),</booktitle>
<pages>575--580</pages>
<contexts>
<context position="9290" citStr="Zhang and Liu, 2011" startWordPosition="1523" endWordPosition="1526">ualitative and quantitative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow s</context>
</contexts>
<marker>Zhang, Liu, 2011</marker>
<rawString>Lei Zhang and Bing Liu. 2011. Identifying Noun Product Features that Imply Opinions. In Proceedings of ACL (Short Papers), pages 575â€“580.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Xin Zhao</author>
<author>Jing Jiang</author>
<author>Hongfei Yan</author>
<author>Xiaoming Li</author>
</authors>
<title>Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid.</title>
<date>2010</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>56--65</pages>
<contexts>
<context position="9854" citStr="Zhao et al., 2010" startWordPosition="1624" endWordPosition="1627"> Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we</context>
<context position="35650" citStr="Zhao et al., 2010" startWordPosition="6261" endWordPosition="6264">f DFLDA are not very obvious, but with more knowledge, these issues become more serious and thus degrade the performance of DF-LDA. 7.3 Human Evaluation Since our aim is to make topics more interpretable and conformable to human judgments, we worked with two judges who are familiar with Amazon products and reviews to evaluate the models subjectively. Since topics from topic models are rankings based on word probability and we do not know the number of correct topical words, a natural way to evaluate these rankings is to use Precision@n (or p@n) which was also used in (Mukherjee and Liu, 2012; Zhao et al., 2010), where n is the rank position. We give p@n for n = 5 and 10. There are two steps in human evaluation: topic labeling and word labeling. Topic Labeling: We followed the instructions in (Mimno et al., 2011) and asked the judges to label each topic as good or bad. Each topic was presented as a list of 10 most probable words in descending order of their probabilities under that topic. The models which generated the topics for labeling were obscure to the judges. In general, each topic was annotated as good if it had more than half of its words coherently related to each other representing a seman</context>
</contexts>
<marker>Zhao, Jiang, Yan, Li, 2010</marker>
<rawString>Wayne Xin Zhao, Jing Jiang, Hongfei Yan, and Xiaoming Li. 2010. Jointly Modeling Aspects and Opinions with a MaxEnt-LDA Hybrid. In Proceedings of EMNLP, pages 56â€“65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinjie Zhou</author>
<author>Xiaojun Wan</author>
<author>Jianguo Xiao</author>
</authors>
<title>Cross-Language Opinion Target Extraction in Review Texts.</title>
<date>2012</date>
<booktitle>In Proceedings of ICDM,</booktitle>
<pages>1200--1205</pages>
<contexts>
<context position="10026" citStr="Zhou et al., 2012" startWordPosition="1650" endWordPosition="1653">urevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et al., 2012b), bootstrapping (Xia et al., 2009), Non-English techniques (Abu-Jbara et al., 2013; Zhou et al., 2012), graph-based representation (Wu et al., 2011), convolution kernels (Wiegand and Klakow, 2010) and domain adaption (Li et al., 2012). Stoyanov and Cardie (2011), Wang and Liu (2011), and Meng et al. (2012) studied opinion summarization outside the reviews. Some other works related with sentiment analysis include (Agarwal and Sabharwal, 2012; Kennedy and Inkpen, 2006; Kim et al., 2009; Mohammad et al., 2009). In this work, we focus on topic models owing to their advantage of performing both aspect extraction and clustering simultaneously. All other approaches only perform extraction. Although t</context>
</contexts>
<marker>Zhou, Wan, Xiao, 2012</marker>
<rawString>Xinjie Zhou, Xiaojun Wan, and Jianguo Xiao. 2012. Cross-Language Opinion Target Extraction in Review Texts. In Proceedings of ICDM, pages 1200â€“1205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Li Zhuang</author>
<author>Feng Jing</author>
<author>Xiao-Yan Zhu</author>
</authors>
<title>Movie review mining and summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of CIKM,</booktitle>
<pages>43--50</pages>
<publisher>ACM Press.</publisher>
<contexts>
<context position="9312" citStr="Zhuang et al., 2006" startWordPosition="1527" endWordPosition="1530">tative measures demonstrate the superiority of MC-LDA. 1656 2 Related Work Sentiment analysis has been studied extensively in recent years (Hu and Liu, 2004; Pang and Lee, 2008; Wiebe and Riloff, 2005; Wiebe et al., 2004). According to (Liu, 2012), there are three main approaches to aspect extraction: 1) Using word frequency and syntactic dependency of aspects and sentiment words for extraction (e.g., Blairgoldensohn et al., 2008; Hu and Liu, 2004; Ku et al., 2006; Popescu and Etzioni, 2005; Qiu et al., 2011; Somasundaran and Wiebe, 2009; Wu et al., 2009; Yu et al., 2011; Zhang and Liu, 2011; Zhuang et al., 2006); 2) Using supervised sequence labeling/classification (e.g., Choi and Cardie, 2010; Jakob and Gurevych, 2010; Kobayashi et al., 2007; Li et al., 2010); 3) Topic models (Branavan et al., 2008; Brody and Elhadad, 2010; Fang and Huang, 2012; Jo and Oh, 2011; Kim et al., 2013; Lazaridou et al., 2013; Li et al., 2011; Lin and He, 2009; Lu et al., 2009, 2012, 2011; Lu and Zhai, 2008; Mei et al., 2007; Moghaddam and Ester, 2011; Mukherjee and Liu, 2012; Sauper et al., 2011; Titov and McDonald, 2008; Wang et al., 2010, 2011; Zhao et al., 2010). Other approaches include shallow semantic parsing (Li et</context>
</contexts>
<marker>Zhuang, Jing, Zhu, 2006</marker>
<rawString>Li Zhuang, Feng Jing, and Xiao-Yan Zhu. 2006. Movie review mining and summarization. In Proceedings of CIKM, pages 43â€“50. ACM Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>