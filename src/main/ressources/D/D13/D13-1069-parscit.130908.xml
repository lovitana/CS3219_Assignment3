<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.9702385">
Automatically Determining a Proper Length for Multi-document
Summarization: A Bayesian Nonparametric Approach
</title>
<author confidence="0.977185">
Tengfei Ma and Hiroshi Nakagawa
</author>
<affiliation confidence="0.973923">
The University of Tokyo
</affiliation>
<address confidence="0.842789">
7-3-1 Hongo, Bunkyo-ku, Tokyo
</address>
<email confidence="0.993">
{matf@r., nakagawa@}dl.itc.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.984608" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998928038461539">
Document summarization is an important task
in the area of natural language processing,
which aims to extract the most important in-
formation from a single document or a clus-
ter of documents. In various summarization
tasks, the summary length is manually de-
fined. However, how to find the proper sum-
mary length is quite a problem; and keeping
all summaries restricted to the same length
is not always a good choice. It is obvi-
ously improper to generate summaries with
the same length for two clusters of docu-
ments which contain quite different quantity
of information. In this paper, we propose
a Bayesian nonparametric model for multi-
document summarization in order to automat-
ically determine the proper lengths of sum-
maries. Assuming that an original document
can be reconstructed from its summary, we
describe the ”reconstruction” by a Bayesian
framework which selects sentences to form
a good summary. Experimental results on
DUC2004 data sets and some expanded data
demonstrate the good quality of our sum-
maries and the rationality of the length deter-
mination.
</bodyText>
<sectionHeader confidence="0.992427" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999937">
Text summarization is the process of generating a
short version of a given text to indicate its main top-
ics. As the number of documents on the web expo-
nentially increases, text summarization has attracted
increasing attention, because it can help people get
the most important information within a short time.
In most of the existing summarization systems,
people need to first define a constant length to re-
strict all the output summaries. However, in many
cases it is improper to require all summaries are of
the same length. Take the multi-document summa-
rization as an example, generating the summaries
of the same length for a 5-document cluster and a
50-document cluster is intuitively improper. More
specifically, consider two different clusters of doc-
uments: one cluster contains very similar articles
which all focus on the same event at the same time;
the other contains different steps of the event but
each step has its own topics. The former cluster may
need only one or two sentences to explain its infor-
mation, while the latter needs to include more.
Research on summary length dates back in the
late 90s. Goldstein et al. (1999) studied the char-
acteristics of a good summary (single-document
summarization for news) and showed an empiri-
cal distribution of summary length over document
size. However, the length problem has been grad-
ually ignored later, since researchers need to fix
the length so as to estimate different summarization
models conveniently. A typical instance is the Doc-
ument Understanding Conferences (DUC)1, which
provide authoritative evaluation for summarization
systems. The DUC conferences collect news arit-
cles as the input data and define various summariza-
tion tasks, such as generic multi-document summa-
rization, query-focused summarization and update
summarization. In all the DUC tasks, the output is
restricted within a length. Then human-generated
</bodyText>
<note confidence="0.7309">
1After 2007, the DUC tasks are incorporated into the Text
Analysis Conference (TAC).
736
Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 736–746,
Seattle, Washington, USA, 18-21 October 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.998186040816327">
summaries are provided to evaluate the results of dif-
ferent summarization systems. Limiting the length
of summaries contributed a lot to the development
of summarization techniques, but as we discussed
before, in many cases keeping the summaries of the
same size is not a good choice.
Moreover, even in constant-length summariza-
tion, how to define a proper size of summaries for
the summarization tasks is quite a problem. Why
does DUC2007 main task require 250 words while
Update task require 100 words? Is it reasonable?
A short summary may sacrifice the coverage, while
a long summary may cause redundance. Automati-
cally determining the best size of summaries accord-
ing to the input documents is valuable, and it may
deepen our understanding of summarization.
In this work, we aim to find the proper length
for document summarization automatically and gen-
erate varying-length summaries based on the doc-
ument itself. The varying-length summarization is
more robust for unbalanced clusters. It can also
provide a recommended size as the predefined sum-
mary length for general constant-length summariza-
tion systems. We advance a Bayesian nonparametric
model of extractive multi-document summarization
to achieve this goal. As far as we are concerned, it is
the first model that can learn appropriate lengths of
summaries.
Bayesian nonparametric (BNP) methods are pow-
erful tools to determine the size of latent vari-
ables (Gershman and Blei, 2011). They let the data
”speak for itself” and allow the dimension of la-
tent variables to grow with the data. In order to
integrate the BNP methods into document summa-
rization, we follow the assumption that the original
documents should be recovered from the reconstruc-
tion of summaries (Ma and Wan, 2010; He et al.,
2012). We use the Beta process as a prior to gen-
erate binary vectors for selecting active sentences
that reconstruct the original documents. Then we
construct a Bayesian framework for summarization
and use the variational approximation for inference.
Experimental results on DUC2004 dataset demon-
strate the effectiveness of our model. Besides, we
reorganize the original documents to generate some
new datasets, and examine how the summary length
changes on the new data. The results prove that our
summary length determination is rational and neces-
sary on unbalanced data.
</bodyText>
<sectionHeader confidence="0.999772" genericHeader="related work">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.999228">
2.1 Research on Summary Length
</subsectionHeader>
<bodyText confidence="0.999917638888889">
Summary length is an important aspect for gener-
ating and evaluating summaries. Early research on
summary length (Goldstein et al., 1999) focused on
discovering the properties of human-generated sum-
maries and analyzing the effect of compression ratio.
It demonstrated that an evaluation of summarization
systems must take into account both the compres-
sion ratios and the characteristics of the documents.
Radev and Fan (2000) compared the readability and
speedup in reading time of 10% summaries and 20%
summaries2 for topic sets with different number of
documents. Sweeney et al. (2008) developed an in-
cremental summary containing additional sentences
that provide context. Kaisser et al. (2008) studied
the impact of query types on summary length of
search results. Other than the content of original
documents, there are also some other factors affect-
ing summary length especially in specific applica-
tions. For example, Sweeney and Crestani (2006)
studied the relation between screen size and sum-
mary length on mobile platforms. The conclusion of
their work is the optimal summary size always falls
into the shorter one regardless of the screen size.
In sum, the previous works on summary length
mostly put their attention on the empirical study of
the phenomenon, factors and impacts of summary
length. None of them automatically find the best
length, which is our main task in this paper. Nev-
ertheless, they demonstrated the importance of sum-
mary length in summarization and the reasonability
of determining summary length based on content of
news documents (Goldstein et al., 1999) or search
results (Kaisser et al., 2008). As our model is mainly
applied for generic summarization of news articles,
we do not consider the factor of screen size in mo-
bile applications.
</bodyText>
<subsectionHeader confidence="0.989476">
2.2 BNP Methods in Document Summarization
</subsectionHeader>
<bodyText confidence="0.9626346">
Bayesian nonparametric methods provide a
Bayesian framework for model selection and
adaptation using nonparametric models (Gershman
210% and 20% are the compression rates, and the documents
are from search results in information retrieval systems.
</bodyText>
<page confidence="0.761627">
737
</page>
<bodyText confidence="0.999233518518518">
and Blei, 2011). A BNP model uses an infinite-
dimensional parameter space, but invokes only a
finite subset of the available parameters on any
given finite data set. This subset generally grows
with the data set. Thus BNP models address the
problem of choosing the number of mixture compo-
nents or latent factors. For example, the hierarchical
Dirichlet process (HDP) can be used to infer the
number of topics in topic models or the number of
states in the infinite Hidden Markov model (Teh et
al., 2006).
Recently, some BNP models are also involved in
document summarization approaches (Celikyilmaz
and Hakkani-T¨ur, 2010; Chang et al., 2011; Darling
and Song, 2011). BNP priors such as the nested Chi-
nese restaurant process (nCRP) are associated with
topic analysis in these models. Then the topic dis-
tributions are used to get the sentence scores and
rank sentences. BNP here only impacts the number
and the structure of the latent topics, but the sum-
marization framework is still constant-length. Our
BNP summarization model differs from the previous
models. Besides using the HDP for topic analysis,
our approach further integrates the beta process into
sentence selection. The BNP method in our model
are directly used to determine the number of sum-
mary sentences but not latent topics.
</bodyText>
<sectionHeader confidence="0.983943" genericHeader="method">
3 BNP Summarization
</sectionHeader>
<bodyText confidence="0.999737333333333">
In this section, we first introduce the BNP priors
which will be used in our model. Then we propose
our model called BNP summarization.
</bodyText>
<subsectionHeader confidence="0.999721">
3.1 The Beta Process and the Bernoulli process
</subsectionHeader>
<bodyText confidence="0.999197888888889">
The beta process(BP) (Thibaux and Jordan, 2007;
Paisley and Carin, 2009) and the related Indian buf-
fet process(IBP) (Griffiths and Ghahramani, 2005)
are widely applied to factor/feature analysis. By
defining the infinite dimensional priors, these factor
analysis models need not to specify the number of
latent factors but automatically determine it.
Definition of BP (Paisley et al., 2010): Let B0 be
a continuous measure on a space Θ and B0(Θ) = γ.
</bodyText>
<equation confidence="0.958438428571428">
If Bk is defined as follows,
Bk = N πkδθk,
E
k=1
πk — Beta(αγN , α(1 — γN))
θk — 1 B0 (1)
γ
</equation>
<bodyText confidence="0.88370325">
(where δθk is the atom at the location θk; and α is a
positive scalar), then as N —* oc, Bk —* B and B is
a beta process: B — BP(αB0).
Finite Approximation: The beta process is de-
fined on an infinite parameter space, but sometimes
we can also use its finite approximation by sim-
ply setting N to a large number (Paisley and Carin,
2009).
</bodyText>
<listItem confidence="0.9729705">
Bernoulli Process: The beta process is conju-
gate to a class of Bernoulli processes, denoted by
X — Bep(B). If B is discrete, of the form in
(1), then X = Ek bkδθk where the bk are indepen-
dent Bernoulli variables with the probability p(bk =
1) = πk. Due to the conjugation between the
beta process priors and Bernoulli process, the pos-
terior of B given M samples X1, X2, ...XM where
</listItem>
<equation confidence="0.941202">
Xi — Bep(B)fori = 1, , , M. is also a beta process
which has updated parameters:
B|X1, X2, ..., XM
— BP(α + M, α+M B0 + c+M Ei Xi) (2)
</equation>
<bodyText confidence="0.9990195">
Application of BP: Furthermore, marginalizing
over the beta process measure B and taking α =
1, provides a predictive distribution on indicators
known as the Indian buffet process (IBP) (Thibaux
and Jordan, 2007). The beta process or the IBP is
often used in a feature analysis model to generate
infinite vectors of binary indicator variables(Paisley
and Carin, 2009), which indicates whether a feature
is used to represent a sample. In this paper, we use
the beta process as the prior to select sentences.
</bodyText>
<subsectionHeader confidence="0.999805">
3.2 Framework of BNP Summarization
</subsectionHeader>
<bodyText confidence="0.9999762">
Most existing approaches for generic extractive
summarization are based on sentence ranking. How-
ever, these methods suffer from a severe problem
that they cannot make a good trade-off between
the coverage and minimum redundancy (He et al.,
</bodyText>
<page confidence="0.583269">
738
</page>
<bodyText confidence="0.999547117647059">
2012). Some global optimization algorithms are de-
veloped, instead of greedy search, to select the best
overall summaries (Nenkova and McKeown, 2012).
One approach to global optimization of summariza-
tion is to regard the summarization as a reconstruc-
tion process (Ma and Wan, 2010; He et al., 2012)
. Considering a good summary must catch most of
the important information in original documents, the
original documents are assumed able to be recov-
ered from summaries with some information loss.
Then the summarization problem is turned into find-
ing the sentences that cause the least reconstruction
error (or information loss). In this paper, we fol-
low the assumption and formulate summarization as
a Bayesian framework.
First we review the models of (Ma and Wan,
2010) and (He et al., 2012). Given a cluster of
M documents x1, x2, ..., xM and the sentence set
contained in the documents as S = [s1, s2, ..., sN],
we denote all corresponding summary sentences as
V = [v1, ..., vn], where n is the number of summary
sentences and N is the number of all sentences in
the cluster. A document xi and a sentence vi or si
here are all represented by weighted term frequency
vectors in the space Rd, where d is the number of
total terms (words).
Following the reconstruction assumption, a can-
didate sentence vi can be approximated by the
linear combination of summary sentences: si �
�n j=1 wjvj, where w� is the weight for summary
sentence vj. Thus the document can also be ap-
proximately represented by a linear combination of
summary sentences (because it is the sum of the sen-
tences).
</bodyText>
<equation confidence="0.966533">
wjvj. (3)
</equation>
<bodyText confidence="0.9999478125">
Then the work in (He et al., 2012) aims to find
the summary sentence set that can minimize the re-
construction error EN i=1 ||si − En j=1 w�jvj||2; while
the work in (Ma and Wan, 2010) defines the prob-
lem as finding the sentences that minimize the dis-
tortion between documents and its reconstruction
dis(xi, En j=1 wjvj) where this distortion function
can also be a squared error function.
Now we consider the reconstruction for each doc-
ument, if we see the document xi as the dependent
variable, and the summary sentence set S as the
independent variable, the problem to minimize the
reconstruction error can be seen as a linear regres-
sion model. The model can be easily changed to a
Bayesian regression model by adding a zero-mean
Gaussian noise c (Bishop, 2006), as follows.
</bodyText>
<equation confidence="0.992203">
n
xi = E wjvj + Ci (4)
j=1
</equation>
<bodyText confidence="0.999978842105263">
where the weights wj are also assigned a Gaussian
prior.
The next step is sentence selection. As our sys-
tem is an extractive summarization model, all the
summary sentences are from the original document
cluster. So we can use a binary vector zi =&lt;
zi1, ..., ziN &gt;T to choose the active sentences V
(i.e. summary sentences) from the original sen-
tence set S. The Equation (4) is turned into xi =
ENj=1 φij ∗zijsj +~i. Using a beta process as a prior
for the binary vector zi, we can automatically infer
the number of active component associated with zi.
As to the weights of the sentences, we use a random
vector φi which has the multivariate normal distri-
bution because of the conjugacy. φi ∈ RN is an
extension to the weights {w1, ...wn} in (4).
Integrating the linear reconstruction (4) and the
beta process3 (1), we get the complete process of
summary sentence selection as follows.
</bodyText>
<equation confidence="0.992994333333333">
xi = S(φi ◦ zi) + Ci
S = [s1,s2, ..., sN]
zij ∼ Bernoulli(πj)
</equation>
<bodyText confidence="0.999872">
where N is the number of sentences in the whole
document cluster. The symbol ◦ represents the ele-
mentwise multiplication of two vectors.
One problem of the reconstruction model is that
the word vector representation of the sentences are
sparse, which dramatically increase the reconstruc-
tion error. So we bring in topic models to reduce the
</bodyText>
<equation confidence="0.991796">
φi ∼ N(0, σ2φI)
Ei ∼ N(0, σ2, I) (5)
</equation>
<bodyText confidence="0.564884">
3We use the finite approximation because the number of sen-
tences is large but finite
</bodyText>
<equation confidence="0.96531125">
n
E
j=1
xi —
αγγ
πj ∼ Beta( N ,α(1−
N ))
739
</equation>
<bodyText confidence="0.999830142857143">
dimension of the data. We use a HDP-LDA (Teh et
al., 2006) to get topic distributions for each sentence,
and we represent the sentences and documents as
the topic weight vectors instead of word weight vec-
tors. Finally xi is a K-dimensional vector and S is
a K ∗ N matrix, where K is the number of topics in
topic models.
</bodyText>
<sectionHeader confidence="0.989552" genericHeader="method">
4 Variational Inference
</sectionHeader>
<bodyText confidence="0.999838090909091">
In this section, we derive a variational Bayesian al-
gorithm for fast inference of our sentence selec-
tion model. Variational inference (Bishop, 2006)
is a framework for approximating the true posterior
with the best from a set of distributions Q : q∗ =
arg minq∈Q KL(q(Z)|p(Z|X)). Supposeq(Z) can
be partitioned into disjoint groups denoted by Zj,
and the q distribution factorizes with respect to these
groups: q(Z) = JIMj=1 q(Zj). We can obtain a gen-
eral expression for the optimal solution q∗j (Zj) given
by
</bodyText>
<equation confidence="0.747332">
ln q∗j (Zj) = Ei#j[ln p(X, Z)] + const. (6)
</equation>
<bodyText confidence="0.969954083333333">
where Ei#j[ln p(X, Z)] is the expectation of the log-
arithm of the joint probability of the data and latent
variables, taken over all variables not in the parti-
tion. We will therefore seek a consistent solution
by first initializing all of the factors qj(Zj) appro-
priately and then cycling through the factors and re-
placing each in turn with a revised estimate given by
(6) evaluated using the current estimates for all of
the other factors.
Update for Z
p(zij|πj, xi, S, φi) ∝ p(xi|zij, sj, φi)p(zij|πj)
We use q(zij) to approximate the posterior:
</bodyText>
<equation confidence="0.879450222222222">
q(ij)
z
∝ exp{E[ln(p(xi|zij, z−j
i ,S, φi)) + ln(p(zij|π))]}
∝ exp{E[ln(πj)]}∗
where x−j
i = xi − S−j(φ−j
i ◦ z−j
i ), and the symbol
</equation>
<bodyText confidence="0.9972115">
¯ indicates the expectation value. The φ2 ijcan be
extended to this form:
</bodyText>
<equation confidence="0.982055">
φ2ij = φij 2+ Δj (8)
i
</equation>
<bodyText confidence="0.99742525">
where Δji means the jth diagonal element of Δi
which is defined by Equation 13.
As zi is a binary vector, we only calculate the
probability of zij = 1 and zij = 0.
</bodyText>
<equation confidence="0.990598444444444">
q(zij = 1) ∝ exp{ln(πj)} ∗
1 (1�,
exp{− 2σE (0?.U ∗ sTj sj − 2φij ∗ sT ∗ x j
ji ) }
q(zij = 0) ∝ exp{ln(1 − πj)} (9)
The expectations can be calculated as
ln(πj) = ϕ(αγ N + nj) − ϕ(α + M) (10)
ln(1 −πj) = ϕ(α(1−γN)+M−nj)−ϕ(α+M)
(11)
</equation>
<bodyText confidence="0.824061">
where nj = EMi=1 zij.
</bodyText>
<equation confidence="0.8606985">
Update for π
p(πj|Z) ∝ p(πj|α,γ,N)p(Z|πj)
</equation>
<bodyText confidence="0.998602666666667">
Because of the conjugacy of the beta to Bernoulli
distribution, the posterior of π is still a beta distribu-
tion:
</bodyText>
<equation confidence="0.976088162790698">
πj ∼ Beta(αγN + nj, α(1 − γN) + M − nj) (12)
Update for Φ
p(φi|xi, Z, S) ∝ p(xi|φi, Z, S)p(φi|σ2φ)
The posterior is also a normal distribution with mean
μi and covariance Δi.
σ
� −1
Δi = 1 S˜T ˜ 1 φ )
i
i
σ
2
+
2 I (13)
E
(xi j − sjzijφij)T (xi j − sjzijφij)]}
E
1
exp{E[− 2σ2
E
1 T
i Si
(
2
Δ
x
σ
∝ exp{ln(πj)}∗
exp{ 2σ2�
(φ2ji∗ z2ij ∗ sTj sj − 2φij ∗ zij ∗ sjT ∗ xi j) }
(7)
i
(14)
Here
S
and
[zi, ..., zi]T is a K
N
matri
˜Si≡
◦˜zi
˜zi≡
×
</equation>
<bodyText confidence="0.8927275">
x with the vector zi repeated K(the number of
the latent topics) times.
</bodyText>
<equation confidence="0.998664833333333">
˜Si = S ∗ ˜zi (15)
740
˜SiT˜Si = (STS) 0 (zi * ziT +Bcovi) (16)
Bcovi = diag[zi1(1 − zi1), ..., ziN(1 − ziN)] (17)
Update for σ2�
p(σ2 |Φ,X, Z, S) a p(X|Φ,Z,S,σ2E)p(σ2 )
</equation>
<bodyText confidence="0.9978645">
By using a conjugate prior, inverse gamma prior
InvGamma(u, v), the posterior can be calculated
as a new inverse gamma distribution with parame-
ters
</bodyText>
<equation confidence="0.919996428571429">
u� = u + MK/2
(||xi − S(zi 0 φi) ||+ ξi)
where
ξi = ENj=1(z2ij * φ2ij * sTj sj − zij2 * φij2 * sTj sj)
+ Ej54l zij * zil * Δi,jl * sTj sl
Update for σ2 φ
p(σ2φ|Φ) a p(Φ|σ2φ)p(σ2φ)
</equation>
<bodyText confidence="0.997632">
By using a conjugate prior, inverse gamma prior
InvGamma(e, f), the posterior can be calculated
as a new inverse gamma distribution with parame-
ters
</bodyText>
<equation confidence="0.999076">
e� = e + MN/2
M
f� = f +2� ((Φ)T Φ + trace(Δ&apos;))
i=1
</equation>
<sectionHeader confidence="0.994199" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.818372166666666">
To test the capability of our BNP summarization sys-
tems, we design a series of experiments. The aim of
the experiments mainly includes three aspects:
1. To demonstrate the summaries extracted by our
model have good qualities and the summary
length determined by the model is reasonable.
</bodyText>
<listItem confidence="0.961674">
2. To give examples where varying summary
length is necessary.
3. To observe the distribution of summary length.
</listItem>
<bodyText confidence="0.999827">
We evaluate the performance on the dataset of
DUC2004 task2. The data contains 50 document
clusters, with 10 news articles in each cluster. Be-
sides, we construct three new datasets from the
DUC2004 dataset to further prove the advantage of
variable-length summarization. We separate each
cluster in the original dataset into two parts where
each has 5 documents, hence getting the Separate
Dataset; Then we randomly combine two origi-
nal clusters in the DUC2004 dataset, and get two
datasets called Combined1 and Combined2. Thus
each of the clusters in the combined datasets include
20 documents with two different themes.
</bodyText>
<subsectionHeader confidence="0.995839">
5.1 Evaluation of Summary Qualities
</subsectionHeader>
<bodyText confidence="0.999767090909091">
First, we implement our BNP summarization model
on the DUC2004 dataset, with summary length not
limited. At the topic analysis step, we use the HDP
model and follow the inference in (Teh et al., 2006).
For the sentence selection step, we use the varia-
tional inference described in Section 4, where the
parameters in the beta process (5) are set as γ =
1, α = 1. The summaries that we finally generate
have an average length of 164 words. We design sev-
eral popular unsupervised summarization systems
and compare them with our model.
</bodyText>
<listItem confidence="0.932095357142857">
• The Random model selects sentences randomly
for each document cluster.
• The MMR (Carbonell and Goldstein, 1998)
strives to reduce redundancy while maintaining
relevance. For generic summarization, we re-
place the query relevance with the relevance to
documents.
• The Lexrank model (Erkan and Radev, 2004) is
a graph-based method which choose sentences
based on the concept of eigenvector centrality.
• The Linear Representation model (Ma and
Wan, 2010) has the same assumption as ours
and it can be seen as an approximation of the
constant-length version of our model.
</listItem>
<figure confidence="0.981502142857143">
1
2
v�=v+
M
i=1
741
742
0.45
0.4
0.35
0.3
0.25
0.2
0.15
0.1
0.05
Rate-dist
Rouge-1
Rouge-L
Rouge-2
Rouge-SU
</figure>
<figureCaption confidence="0.9960715">
Figure 1: Rouge-1 values on DUC2004 dataset.
Figure 2: Rouge-2 values on DUC2004 dataset.
</figureCaption>
<figure confidence="0.999718214285714">
Rouge-L
0.35
0.25
0.15
0.3
0.2
0.1
0 100 200 300 400
Summary Length (Number of Words)
Random
MMR
Lexrank
Linear
BNP
</figure>
<figureCaption confidence="0.885459">
Figure 3: Rouge-L values on DUC2004 dataset.
</figureCaption>
<bodyText confidence="0.7299565">
All the compared systems are implemented at dif-
ferent predefined lengths from 50 to 300 words.
Then we evaluate the summaries with ROUGE4
tools (Lin and Hovy, 2003) in terms of the f-measure
</bodyText>
<figure confidence="0.997810071428571">
4we use ROUGE1.5.5 in this work.
Rouge-1
0.35
0.25
0.15
0.4
0.3
0.2
Random
MMR
Lexrank
Linear
BNP
Rouge-2
0.09
0.08
0.07
0.06
0.05
0.04
0.03
0.02
0.1
Random
MMR
Lexrank
Linear
BNP
</figure>
<bodyText confidence="0.989334785714285">
scores of Rouge-1 Rouge-2, and Rouge-L. The met-
ric of Rouge f-measure takes into consideration the
summary length in evaluation, so it is proper for
our experiments. From Fig.1, Fig.2 and Fig.3, we
can see that the result of BNP summarization (the
dashed line) gets the second best value among all
systems. It is only defeated by the Linear model
but the result is comparable to the best in Fig.1 and
Fig.3; while it exceeds other systems at all lengths.
This proves the good qualities of our BNP sum-
maries. The reason that the Linear system gets a
little better result may be its weights for linear com-
bination of summary sentences are guaranteed non-
negative while in our model the weights are zero-
mean Gaussian variables. This may lead to less re-
dundance in sentence selection for the Linear Rep-
resentation model.
Turn to the length determination. We take ad-
vantage of the Linear Representation model to ap-
proximate the constant-length version of our model.
Comparing the summaries generated at different
predefined lengths, Fig.4 shows the the model gets
the best performance (Rouge values) at the length
around 164 words, the length learned by our BNP
model. This result partly demonstrates our length
determination is rational and it can be used as the
recommended length for some constant-length sum-
marization systems, such as the Linear.
</bodyText>
<figureCaption confidence="0.983687">
Figure 4: Rate-dist value V.S. summary word length.
</figureCaption>
<figure confidence="0.956086166666667">
0 100 200 300 400
Summary Word Count
0 100 200 300 400
Summary length (Number of Words)
0 100 200 300 400
Summary Length (Number of Words)
</figure>
<subsectionHeader confidence="0.986771">
5.2 A New Evaluation Metric
</subsectionHeader>
<bodyText confidence="0.99996452173913">
The Rouge evaluation requires golden standard sum-
maries as the base. However, in many cases we
cannot get the reference summaries. For example,
when we implement experiments on our expanded
datasets (the separate and combined clusters of doc-
uments), we do not have exact reference summaries.
Louis and Nenkova (2009) advanced an automatic
summary evaluation without human models. They
used the Jensen-Shannon divergence(JSD) between
the input documents and the summaries as a fea-
ture, and got high correlation with human evalua-
tions and the rouge metric. Unfortunately, it was
designed for comparison at a constant-length, which
cannot meet our needs. To extend the JSD evaluation
to compare varying-length summaries, we propose a
new measure based on information theory, the rate-
distortion (Cover and Thomas, 2006).
Rate-Distortion: The distortion function d(x, ˆx)
is a measure of the cost of representing the symbol
x to a new symbol ˆx; and the rate can indicate how
much compression can be achieved. The problem of
finding the minimum rate can be solved by minimiz-
ing the functional
</bodyText>
<equation confidence="0.999116">
F[p(ˆx|x)] = I(X; ˆX) + QE(d(x, ˆx)). (20)
</equation>
<bodyText confidence="0.999806487179487">
where I(X; ˆX) denotes the mutual information.
The rate-distortion theory is a fundamental the-
ory for lossy data compression. Recently, it has
also been successfully employed for text cluster-
ing (Slonim, 2002) and document summarization
(Ma and Wan, 2010). Slonim (2002) claims that
the mutual information I(X; ˆX) measures the com-
pactness of the new representation. Thus the rate-
distortion function is a trade-off between the com-
pactness of new representation and the expected dis-
tortion. Specifically in summarization, the sum-
maries can be seen as the new representation Xˆ of
original documents X. A good summary balances
the compression ratio and the information loss, thus
minimizing the function (20). So we use the func-
tion (20)(we set Q = 1) to compare which summary
is a better compression. The JS-divergence (JSD),
which has been proved to have high correlation with
manual evaluation (Louis and Nenkova, 2009) for
constant-length summary evaluation, is utilized as
the distortion in the function. In the following sec-
tions, we simply call the values of the function (20)
rate-dist. In fact, the rate-dist values can be seen as
the JSD measure with length regularization.
To check the effectiveness of rate-dist measure,
we evaluate all summaries generated in Section 5.1
with the new measure (the lower the better). Fig. 5
shows that the results accord with the ones in Fig. 1
and Fig. 3. Moreover, in Fig. 4, the curve of rate-
dist values has a inverse tendency of Rouge mea-
sures (Rouge-1, Rouge-2, Rouge-L and Rouge-SU4
are all listed here), and the best performance also oc-
curs around the summary length of 164 words. This
even more clearly reveals that the BNP summariza-
tion achieves a perfect tradeoff between compact-
ness and informativeness. Due to the accordance
with rouge measures, it is promising to be regarded
as an alternative to the rouge measures in case we do
not have reference summaries.
</bodyText>
<figure confidence="0.759670625">
Rate-dist 0.55 Random
0.5 MMR
0.45 Lexrank
0.4 Linear
0.35 BNP
0.3
0 100 200 300 400
Summary Word Count
</figure>
<figureCaption confidence="0.9900255">
Figure 5: Comparison of BNP Summarization with other
systems using rate-dist measure.
</figureCaption>
<subsectionHeader confidence="0.996316">
5.3 Necessity of Varying Summary Length
</subsectionHeader>
<bodyText confidence="0.999990857142857">
In this section, we discuss the necessity of length
determination and how summary length changes ac-
cording to the input data. As explained before,
we generate three new datasets from the original
DUC2004 dataset. Now we use them to indicate
varying summary length is necessary when the in-
put data varies a lot.
Table 1 shows the average summary length of dif-
ferent data sets. The results satisfy the intuitive ex-
pectation of summary length change. When we split
a 10-document cluster into two 5-document parts,
we expect the average summary length of the new
clusters to be a little smaller than the original clus-
ter but much larger than half of the original length,
</bodyText>
<page confidence="0.772504">
743
</page>
<bodyText confidence="0.999458428571429">
because all the documents concentrate on the same
themes. When we combine two clusters into one, the
summary length should be smaller than the sum of
the summary lengths of two original clusters due to
some unavoidable common background information
but much larger than the summary length of original
clusters.
</bodyText>
<table confidence="0.9739105">
Original Separate Combined1 Combined2
164 115 250 231
</table>
<tableCaption confidence="0.988336">
Table 1: Average summary length (number of words) on
different datasets
</tableCaption>
<bodyText confidence="0.999697285714286">
We also run the Linear Representation system at
different lengths on the new datasets and evaluate
the qualities. As we do not have golden standard
for the new datasets, so we only use the rate-dist
measure here. Results in Table 2,3,4 show the sum-
maries which do not change the predefined length
5 perform significantly worse than the BNP sum-
marization. All the comparison is statistically sig-
nificant. So varying summary length is necessary
when the input changes a lot, and our model can just
give a good match to the new data. This characteris-
tic also can be used to give recommended summary
length for extractive summarization systems when
given unknown data.
</bodyText>
<table confidence="0.998149666666667">
Predefined Unchanged BNP
Length 665 bytes 164 words 115 words
Rate-dist 0.4130 0.4404 0.4007
</table>
<tableCaption confidence="0.9171">
Table 2: Comparison of summary lengths on Separate
Dataset.
</tableCaption>
<table confidence="0.999802666666667">
Predefined Unchanged BNP
Length 665 bytes 164 words 250 words
Rate-dist 0.3768 0.3450 0.3238
</table>
<tableCaption confidence="0.9767685">
Table 3: Comparison of summary lengths on Combined1
Dataset.
</tableCaption>
<bodyText confidence="0.864271666666667">
Then we observe the summary length distribu-
tions and compression ratios according to document
size(the length of the whole documents in a clus-
ter). The average summary length increases (Fig. 6),
5665 bytes is the DUC2004 requirement and 164 words is
the best length on original data
</bodyText>
<table confidence="0.998814333333333">
Predefined Unchanged BNP
Length 665 bytes 164 words 231 words
Rate-dist 0.3739 0.3464 0.3326
</table>
<tableCaption confidence="0.976739">
Table 4: Comparison of summary lengths on Combined2
Dataset.
</tableCaption>
<bodyText confidence="0.9993324">
while the compression ratios decreases (Fig. 7) as
document size grows. The rule of the compres-
sion ratio here agrees with the rule in (Goldstein
et al., 1999), although that work is done for single-
document summarization.
</bodyText>
<figureCaption confidence="0.947988666666667">
Figure 6: The distribution of summary word length.
Figure 7: Compression ratio versus document word
length.
</figureCaption>
<figure confidence="0.9895233125">
Summary Word Count
400
350
300
250
200
150
100
50
0
0 5000 10000 15000 20000 25000
Number of Words in Original Documents
Combined1
Combined2
Separate
Original
0.14
0.12
0.1
Original
Combined1
Combined2
Seperate
0.04
0.02
0
0 5000 10000 15000 20000 25000
Compression Ratio
0.08
0.06
Number of Words in Original Documents
744
</figure>
<sectionHeader confidence="0.818528" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999973">
In this paper, we present a new problem of finding a
proper summary length for multi-document summa-
rization based on the document content. A Bayesian
nonparametric model is proposed to solve this prob-
lem. We use the beta process as the prior to construct
a Bayesian framework for summary sentence selec-
tion. Experimental results are shown on DUC2004
dataset, as well as some expanded datasets. We
demonstrate the summaries we extract have good
qualities and the length determination of our system
is rational.
However, there is still much work to do for
variable-length summarization. First, Our sys-
tem is extractive-base summarization, which cannot
achieve the perfect coherence and readability. A sys-
tem which can determine the best length even for
abstractive summarization will be better. Moreover,
in this work we only consider the aspect of data
compression and evaluate the performance using an
information-theoretic measure. In future we may
consider more human factors, and prove the sum-
mary length determined by our system agrees with
human preference. In addition, in the experiments,
we only use the imbalanced datasets as the example
that intuitively needs varying the summary length.
However, the data type is also important to impact
the summary length. In future, we may extend the
work by studying more cases that need varying sum-
mary length.
</bodyText>
<sectionHeader confidence="0.994338" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999867470588236">
Christopher M. Bishop. 2006. Pattern recognition and
machine learning.. Vol. 4. No. 4. New York: springer.
Jaime Carbonell, and Jade Goldstein. 1998. The Use
Of Mmr, Diversity-Based Reranking For Reordering
Documents And Producing Summaries. Proceedings
of the 21st annual international ACM SIGIR confer-
ence on Research and development in information re-
trieval. ACM, 1998.
Asli Celikyilmaz and Dilek Hakkani-T¨ur. 2010. A Hy-
brid Hierarchical Model for Multi-Document Summa-
rization. Proceedings of the 48th Annual Meeting of
the Association for Computational Linguistics, pages
815-824.
Ying-Lan Chang, Jui-Jung Hung and Jen-Tzung Chien
2011. Bayesian Nonparametric Modeling Of Hier-
archical Topics And Sentences. IEEE International
Workshop on Machine Learning for Signal Processing,
September 18-21, 2011, Beijing, China.
Thomas M. Cover, and Joy A. Thomas. 2006. Elements
of information theory. Wiley-interscience, 2006.
William M. Darling and Fei Song. 2011. PathSum:
A Summarization Framework Based on Hierarchical
Topics. Canadian AI Workshop on Text Summariza-
tion, St. John’s, Newfoundland.
Samuel J. Gershman and David M. Blei. 2011. A Tuto-
rial On Bayesian Nonparametric Models. Journal of
Mathematical Psychology(2011).
Thomas L. Griffiths and Zoubin Ghahramani. 2005. Infi-
nite Latent Feature Models and the Indian Buffet Pro-
cess. Advances in Neural Information Processing Sys-
tems 18.
Jade Goldstein, Mark Kantrowitz, Vibhu Mittal and
Jaime Carbonelly. 1999. Summarizing Text Doc-
uments: Sentence Selection and Evaluation Metrics.
Proceedings of SIGIR’99 , pages 121-128.
Zhanying He, Chun Chen, Jiajun Bu, CanWang, Lijun
Zhang, Deng Cai and Xiaofei He. 2012. Document
Summarization Based on Data Reconstruction. Pro-
ceedings of the Twenty-Sixth AAAI Conference on Ar-
tificial Intelligence.
Michael Kaisser, Marti A. Hearst, John B. Lowe. 2008.
Improving Search Results Quality by Customizing
Summary Lengths. Proceedings of ACL-08: HLT,
pages 701-709.
Chin-Yew Lin, Guihong Cao, Jianfeng Gao, and Jian-Yun
Nie. 2006. An Information-Theoretic Approach to
Automatic Evaluation of Summaries. Proceedings of
NAACL2006, pages 463-470.
Chin-Yew Lin, and Eduard Hovy. 2003. Automatic
evaluation of summaries using n-gram co-occurrence
statistics. Proceedings of NAACL2003.
Annie Louis and Ani Nenkova. 2009. Automatically
Evaluating Content Selection in Summarization with-
out Human Models. Proceedings of the 2009 Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 306-314. Singapore, 6-7 August 2009.
Tengfei Ma and Xiaojun Wan. 2010. Multi-
document Summarization Using Minimum Distortion.
IEEE 10th International Conference on Data Mining
(ICDM).
Ani Nenkova and Kathleen McKeown. 2012. A sur-
vey of text summarization techniques. Mining Text
Data, Chapter 3, Springer Science+Business Media,
LLC (2012).
John Paisley and Lawrence Carin. 2009. Nonparametric
Factor Analysis with Beta Process Priors. Proceed-
ings of the 26th International Conference on Machine
Learning, Montreal, Canada.
</reference>
<page confidence="0.54868">
745
</page>
<reference confidence="0.999806028571428">
John Paisley, Aimee Zaas, Christopher W. Woods, Geof-
frey S. Ginsburg and Lawrence Carin. 2010. A Stick-
Breaking Construction of the Beta Process. Proceed-
ings of the 27 th International Confer- ence on Ma-
chine Learning, Haifa, Israel, 2010.
Dragomir R. Radev and Weiguo Fan. 2000. Effective
search results summary size and device screen size:
Is there a relationship. Proceedings of the ACL-2000
workshop on Recent advances in natural language
processing and information retrieval
G¨unes Erkan, and Dragomir R. Radev. 2004. LexRank:
Graph-based Lexical Centrality as Salience in Text
Summarization. Journal of Artificial Intelligence Re-
search, 22 (2004) 457-479.
Noam Slonim. 2002. The Information Bottleneck: The-
ory and Applications. PHD Thesis of the Hebrew Uni-
versity .
Simon Sweeney and Fabio Crestani. 2006. Effective
search results summary size and device screen size: Is
there a relationship. Information Processing and Man-
agement 42 (2006) 1056-1074.
Simon Sweeney, Fabio Crestani and David E. Losada.
2008. ’Show me more’: Incremental length summari-
sation using novelty detection. Information Process-
ing and Management 44 (2008) 663-686.
Yee Whye Teh, Dilan G¨or¨ur, and Zoubin Ghahramani.
2007. Stick-breaking Construction for the Indian Buf-
fet Process. Proceedings of the International Confer-
ence on Artificial Intelligence and Statistics.
Y.W. Teh, M.I. Jordan, M.J. Beal and D.M. Blei.
2006. Hierarchical Dirichlet Processes. JASA ,
101(476):1566-1581.
Romain Thibaux and Michael I. Jordan. 2009. Hierar-
chical Beta Processes and the Indian Buffet Process.
AISTATS2007.
</reference>
<page confidence="0.925558">
746
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.723871">
<title confidence="0.999412">Automatically Determining a Proper Length for Summarization: A Bayesian Nonparametric Approach</title>
<author confidence="0.995927">Tengfei Ma</author>
<author confidence="0.995927">Hiroshi</author>
<affiliation confidence="0.998066">The University of</affiliation>
<address confidence="0.947157">7-3-1 Hongo, Bunkyo-ku,</address>
<abstract confidence="0.991338518518519">Document summarization is an important task in the area of natural language processing, which aims to extract the most important information from a single document or a cluster of documents. In various summarization tasks, the summary length is manually defined. However, how to find the proper summary length is quite a problem; and keeping all summaries restricted to the same length is not always a good choice. It is obviously improper to generate summaries with the same length for two clusters of documents which contain quite different quantity of information. In this paper, we propose a Bayesian nonparametric model for multidocument summarization in order to automatically determine the proper lengths of summaries. Assuming that an original document can be reconstructed from its summary, we describe the ”reconstruction” by a Bayesian framework which selects sentences to form a good summary. Experimental results on DUC2004 data sets and some expanded data demonstrate the good quality of our summaries and the rationality of the length determination.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Christopher M Bishop</author>
</authors>
<title>Pattern recognition and machine learning..</title>
<date>2006</date>
<volume>4</volume>
<publisher>springer.</publisher>
<location>New York:</location>
<contexts>
<context position="13979" citStr="Bishop, 2006" startWordPosition="2295" endWordPosition="2296">le the work in (Ma and Wan, 2010) defines the problem as finding the sentences that minimize the distortion between documents and its reconstruction dis(xi, En j=1 wjvj) where this distortion function can also be a squared error function. Now we consider the reconstruction for each document, if we see the document xi as the dependent variable, and the summary sentence set S as the independent variable, the problem to minimize the reconstruction error can be seen as a linear regression model. The model can be easily changed to a Bayesian regression model by adding a zero-mean Gaussian noise c (Bishop, 2006), as follows. n xi = E wjvj + Ci (4) j=1 where the weights wj are also assigned a Gaussian prior. The next step is sentence selection. As our system is an extractive summarization model, all the summary sentences are from the original document cluster. So we can use a binary vector zi =&lt; zi1, ..., ziN &gt;T to choose the active sentences V (i.e. summary sentences) from the original sentence set S. The Equation (4) is turned into xi = ENj=1 φij ∗zijsj +~i. Using a beta process as a prior for the binary vector zi, we can automatically infer the number of active component associated with zi. As to t</context>
<context position="15968" citStr="Bishop, 2006" startWordPosition="2661" endWordPosition="2662">e finite approximation because the number of sentences is large but finite n E j=1 xi — αγγ πj ∼ Beta( N ,α(1− N )) 739 dimension of the data. We use a HDP-LDA (Teh et al., 2006) to get topic distributions for each sentence, and we represent the sentences and documents as the topic weight vectors instead of word weight vectors. Finally xi is a K-dimensional vector and S is a K ∗ N matrix, where K is the number of topics in topic models. 4 Variational Inference In this section, we derive a variational Bayesian algorithm for fast inference of our sentence selection model. Variational inference (Bishop, 2006) is a framework for approximating the true posterior with the best from a set of distributions Q : q∗ = arg minq∈Q KL(q(Z)|p(Z|X)). Supposeq(Z) can be partitioned into disjoint groups denoted by Zj, and the q distribution factorizes with respect to these groups: q(Z) = JIMj=1 q(Zj). We can obtain a general expression for the optimal solution q∗j (Zj) given by ln q∗j (Zj) = Ei#j[ln p(X, Z)] + const. (6) where Ei#j[ln p(X, Z)] is the expectation of the logarithm of the joint probability of the data and latent variables, taken over all variables not in the partition. We will therefore seek a cons</context>
</contexts>
<marker>Bishop, 2006</marker>
<rawString>Christopher M. Bishop. 2006. Pattern recognition and machine learning.. Vol. 4. No. 4. New York: springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime Carbonell</author>
<author>Jade Goldstein</author>
</authors>
<title>The Use Of Mmr, Diversity-Based Reranking For Reordering Documents And Producing Summaries.</title>
<date>1998</date>
<booktitle>Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval. ACM,</booktitle>
<contexts>
<context position="20657" citStr="Carbonell and Goldstein, 1998" startWordPosition="3547" endWordPosition="3550">ent our BNP summarization model on the DUC2004 dataset, with summary length not limited. At the topic analysis step, we use the HDP model and follow the inference in (Teh et al., 2006). For the sentence selection step, we use the variational inference described in Section 4, where the parameters in the beta process (5) are set as γ = 1, α = 1. The summaries that we finally generate have an average length of 164 words. We design several popular unsupervised summarization systems and compare them with our model. • The Random model selects sentences randomly for each document cluster. • The MMR (Carbonell and Goldstein, 1998) strives to reduce redundancy while maintaining relevance. For generic summarization, we replace the query relevance with the relevance to documents. • The Lexrank model (Erkan and Radev, 2004) is a graph-based method which choose sentences based on the concept of eigenvector centrality. • The Linear Representation model (Ma and Wan, 2010) has the same assumption as ours and it can be seen as an approximation of the constant-length version of our model. 1 2 v�=v+ M i=1 741 742 0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 Rate-dist Rouge-1 Rouge-L Rouge-2 Rouge-SU Figure 1: Rouge-1 values on DUC200</context>
</contexts>
<marker>Carbonell, Goldstein, 1998</marker>
<rawString>Jaime Carbonell, and Jade Goldstein. 1998. The Use Of Mmr, Diversity-Based Reranking For Reordering Documents And Producing Summaries. Proceedings of the 21st annual international ACM SIGIR conference on Research and development in information retrieval. ACM, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Asli Celikyilmaz</author>
<author>Dilek Hakkani-T¨ur</author>
</authors>
<title>A Hybrid Hierarchical Model for Multi-Document Summarization.</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>815--824</pages>
<marker>Celikyilmaz, Hakkani-T¨ur, 2010</marker>
<rawString>Asli Celikyilmaz and Dilek Hakkani-T¨ur. 2010. A Hybrid Hierarchical Model for Multi-Document Summarization. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 815-824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ying-Lan Chang</author>
</authors>
<title>Jui-Jung Hung and Jen-Tzung Chien 2011. Bayesian Nonparametric Modeling Of Hierarchical Topics And Sentences.</title>
<date>2011</date>
<booktitle>IEEE International Workshop on Machine Learning for Signal Processing,</booktitle>
<location>Beijing, China.</location>
<marker>Chang, 2011</marker>
<rawString>Ying-Lan Chang, Jui-Jung Hung and Jen-Tzung Chien 2011. Bayesian Nonparametric Modeling Of Hierarchical Topics And Sentences. IEEE International Workshop on Machine Learning for Signal Processing, September 18-21, 2011, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M Cover</author>
<author>Joy A Thomas</author>
</authors>
<title>Elements of information theory.</title>
<date>2006</date>
<publisher>Wiley-interscience,</publisher>
<contexts>
<context position="24224" citStr="Cover and Thomas, 2006" startWordPosition="4142" endWordPosition="4145">tasets (the separate and combined clusters of documents), we do not have exact reference summaries. Louis and Nenkova (2009) advanced an automatic summary evaluation without human models. They used the Jensen-Shannon divergence(JSD) between the input documents and the summaries as a feature, and got high correlation with human evaluations and the rouge metric. Unfortunately, it was designed for comparison at a constant-length, which cannot meet our needs. To extend the JSD evaluation to compare varying-length summaries, we propose a new measure based on information theory, the ratedistortion (Cover and Thomas, 2006). Rate-Distortion: The distortion function d(x, ˆx) is a measure of the cost of representing the symbol x to a new symbol ˆx; and the rate can indicate how much compression can be achieved. The problem of finding the minimum rate can be solved by minimizing the functional F[p(ˆx|x)] = I(X; ˆX) + QE(d(x, ˆx)). (20) where I(X; ˆX) denotes the mutual information. The rate-distortion theory is a fundamental theory for lossy data compression. Recently, it has also been successfully employed for text clustering (Slonim, 2002) and document summarization (Ma and Wan, 2010). Slonim (2002) claims that t</context>
</contexts>
<marker>Cover, Thomas, 2006</marker>
<rawString>Thomas M. Cover, and Joy A. Thomas. 2006. Elements of information theory. Wiley-interscience, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William M Darling</author>
<author>Fei Song</author>
</authors>
<title>PathSum: A Summarization Framework Based on Hierarchical Topics.</title>
<date>2011</date>
<booktitle>Canadian AI Workshop on Text Summarization,</booktitle>
<location>St. John’s, Newfoundland.</location>
<contexts>
<context position="8614" citStr="Darling and Song, 2011" startWordPosition="1350" endWordPosition="1353">itedimensional parameter space, but invokes only a finite subset of the available parameters on any given finite data set. This subset generally grows with the data set. Thus BNP models address the problem of choosing the number of mixture components or latent factors. For example, the hierarchical Dirichlet process (HDP) can be used to infer the number of topics in topic models or the number of states in the infinite Hidden Markov model (Teh et al., 2006). Recently, some BNP models are also involved in document summarization approaches (Celikyilmaz and Hakkani-T¨ur, 2010; Chang et al., 2011; Darling and Song, 2011). BNP priors such as the nested Chinese restaurant process (nCRP) are associated with topic analysis in these models. Then the topic distributions are used to get the sentence scores and rank sentences. BNP here only impacts the number and the structure of the latent topics, but the summarization framework is still constant-length. Our BNP summarization model differs from the previous models. Besides using the HDP for topic analysis, our approach further integrates the beta process into sentence selection. The BNP method in our model are directly used to determine the number of summary sentenc</context>
</contexts>
<marker>Darling, Song, 2011</marker>
<rawString>William M. Darling and Fei Song. 2011. PathSum: A Summarization Framework Based on Hierarchical Topics. Canadian AI Workshop on Text Summarization, St. John’s, Newfoundland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Samuel J Gershman</author>
<author>David M Blei</author>
</authors>
<title>A Tutorial On Bayesian Nonparametric Models.</title>
<date>2011</date>
<journal>Journal of Mathematical Psychology(2011).</journal>
<contexts>
<context position="4949" citStr="Gershman and Blei, 2011" startWordPosition="767" endWordPosition="770">nt summarization automatically and generate varying-length summaries based on the document itself. The varying-length summarization is more robust for unbalanced clusters. It can also provide a recommended size as the predefined summary length for general constant-length summarization systems. We advance a Bayesian nonparametric model of extractive multi-document summarization to achieve this goal. As far as we are concerned, it is the first model that can learn appropriate lengths of summaries. Bayesian nonparametric (BNP) methods are powerful tools to determine the size of latent variables (Gershman and Blei, 2011). They let the data ”speak for itself” and allow the dimension of latent variables to grow with the data. In order to integrate the BNP methods into document summarization, we follow the assumption that the original documents should be recovered from the reconstruction of summaries (Ma and Wan, 2010; He et al., 2012). We use the Beta process as a prior to generate binary vectors for selecting active sentences that reconstruct the original documents. Then we construct a Bayesian framework for summarization and use the variational approximation for inference. Experimental results on DUC2004 data</context>
</contexts>
<marker>Gershman, Blei, 2011</marker>
<rawString>Samuel J. Gershman and David M. Blei. 2011. A Tutorial On Bayesian Nonparametric Models. Journal of Mathematical Psychology(2011).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas L Griffiths</author>
<author>Zoubin Ghahramani</author>
</authors>
<date>2005</date>
<booktitle>Infinite Latent Feature Models and the Indian Buffet Process. Advances in Neural Information Processing Systems 18.</booktitle>
<contexts>
<context position="9591" citStr="Griffiths and Ghahramani, 2005" startWordPosition="1509" endWordPosition="1512">arization model differs from the previous models. Besides using the HDP for topic analysis, our approach further integrates the beta process into sentence selection. The BNP method in our model are directly used to determine the number of summary sentences but not latent topics. 3 BNP Summarization In this section, we first introduce the BNP priors which will be used in our model. Then we propose our model called BNP summarization. 3.1 The Beta Process and the Bernoulli process The beta process(BP) (Thibaux and Jordan, 2007; Paisley and Carin, 2009) and the related Indian buffet process(IBP) (Griffiths and Ghahramani, 2005) are widely applied to factor/feature analysis. By defining the infinite dimensional priors, these factor analysis models need not to specify the number of latent factors but automatically determine it. Definition of BP (Paisley et al., 2010): Let B0 be a continuous measure on a space Θ and B0(Θ) = γ. If Bk is defined as follows, Bk = N πkδθk, E k=1 πk — Beta(αγN , α(1 — γN)) θk — 1 B0 (1) γ (where δθk is the atom at the location θk; and α is a positive scalar), then as N —* oc, Bk —* B and B is a beta process: B — BP(αB0). Finite Approximation: The beta process is defined on an infinite param</context>
</contexts>
<marker>Griffiths, Ghahramani, 2005</marker>
<rawString>Thomas L. Griffiths and Zoubin Ghahramani. 2005. Infinite Latent Feature Models and the Indian Buffet Process. Advances in Neural Information Processing Systems 18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jade Goldstein</author>
<author>Mark Kantrowitz</author>
<author>Vibhu Mittal</author>
<author>Jaime Carbonelly</author>
</authors>
<title>Summarizing Text Documents: Sentence Selection and Evaluation Metrics.</title>
<date>1999</date>
<booktitle>Proceedings of SIGIR’99 ,</booktitle>
<pages>121--128</pages>
<contexts>
<context position="2469" citStr="Goldstein et al. (1999)" startWordPosition="392" endWordPosition="395">length. Take the multi-document summarization as an example, generating the summaries of the same length for a 5-document cluster and a 50-document cluster is intuitively improper. More specifically, consider two different clusters of documents: one cluster contains very similar articles which all focus on the same event at the same time; the other contains different steps of the event but each step has its own topics. The former cluster may need only one or two sentences to explain its information, while the latter needs to include more. Research on summary length dates back in the late 90s. Goldstein et al. (1999) studied the characteristics of a good summary (single-document summarization for news) and showed an empirical distribution of summary length over document size. However, the length problem has been gradually ignored later, since researchers need to fix the length so as to estimate different summarization models conveniently. A typical instance is the Document Understanding Conferences (DUC)1, which provide authoritative evaluation for summarization systems. The DUC conferences collect news aritcles as the input data and define various summarization tasks, such as generic multi-document summa</context>
<context position="6018" citStr="Goldstein et al., 1999" startWordPosition="939" endWordPosition="942">uments. Then we construct a Bayesian framework for summarization and use the variational approximation for inference. Experimental results on DUC2004 dataset demonstrate the effectiveness of our model. Besides, we reorganize the original documents to generate some new datasets, and examine how the summary length changes on the new data. The results prove that our summary length determination is rational and necessary on unbalanced data. 2 Related Work 2.1 Research on Summary Length Summary length is an important aspect for generating and evaluating summaries. Early research on summary length (Goldstein et al., 1999) focused on discovering the properties of human-generated summaries and analyzing the effect of compression ratio. It demonstrated that an evaluation of summarization systems must take into account both the compression ratios and the characteristics of the documents. Radev and Fan (2000) compared the readability and speedup in reading time of 10% summaries and 20% summaries2 for topic sets with different number of documents. Sweeney et al. (2008) developed an incremental summary containing additional sentences that provide context. Kaisser et al. (2008) studied the impact of query types on sum</context>
<context position="7468" citStr="Goldstein et al., 1999" startWordPosition="1167" endWordPosition="1170">elation between screen size and summary length on mobile platforms. The conclusion of their work is the optimal summary size always falls into the shorter one regardless of the screen size. In sum, the previous works on summary length mostly put their attention on the empirical study of the phenomenon, factors and impacts of summary length. None of them automatically find the best length, which is our main task in this paper. Nevertheless, they demonstrated the importance of summary length in summarization and the reasonability of determining summary length based on content of news documents (Goldstein et al., 1999) or search results (Kaisser et al., 2008). As our model is mainly applied for generic summarization of news articles, we do not consider the factor of screen size in mobile applications. 2.2 BNP Methods in Document Summarization Bayesian nonparametric methods provide a Bayesian framework for model selection and adaptation using nonparametric models (Gershman 210% and 20% are the compression rates, and the documents are from search results in information retrieval systems. 737 and Blei, 2011). A BNP model uses an infinitedimensional parameter space, but invokes only a finite subset of the avail</context>
<context position="29362" citStr="Goldstein et al., 1999" startWordPosition="4994" endWordPosition="4997">gths on Combined1 Dataset. Then we observe the summary length distributions and compression ratios according to document size(the length of the whole documents in a cluster). The average summary length increases (Fig. 6), 5665 bytes is the DUC2004 requirement and 164 words is the best length on original data Predefined Unchanged BNP Length 665 bytes 164 words 231 words Rate-dist 0.3739 0.3464 0.3326 Table 4: Comparison of summary lengths on Combined2 Dataset. while the compression ratios decreases (Fig. 7) as document size grows. The rule of the compression ratio here agrees with the rule in (Goldstein et al., 1999), although that work is done for singledocument summarization. Figure 6: The distribution of summary word length. Figure 7: Compression ratio versus document word length. Summary Word Count 400 350 300 250 200 150 100 50 0 0 5000 10000 15000 20000 25000 Number of Words in Original Documents Combined1 Combined2 Separate Original 0.14 0.12 0.1 Original Combined1 Combined2 Seperate 0.04 0.02 0 0 5000 10000 15000 20000 25000 Compression Ratio 0.08 0.06 Number of Words in Original Documents 744 6 Conclusion and Future Work In this paper, we present a new problem of finding a proper summary length f</context>
</contexts>
<marker>Goldstein, Kantrowitz, Mittal, Carbonelly, 1999</marker>
<rawString>Jade Goldstein, Mark Kantrowitz, Vibhu Mittal and Jaime Carbonelly. 1999. Summarizing Text Documents: Sentence Selection and Evaluation Metrics. Proceedings of SIGIR’99 , pages 121-128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhanying He</author>
<author>Chun Chen</author>
<author>Jiajun Bu</author>
</authors>
<title>CanWang, Lijun Zhang, Deng Cai and Xiaofei He.</title>
<date>2012</date>
<booktitle>Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="5267" citStr="He et al., 2012" startWordPosition="823" endWordPosition="826">tric model of extractive multi-document summarization to achieve this goal. As far as we are concerned, it is the first model that can learn appropriate lengths of summaries. Bayesian nonparametric (BNP) methods are powerful tools to determine the size of latent variables (Gershman and Blei, 2011). They let the data ”speak for itself” and allow the dimension of latent variables to grow with the data. In order to integrate the BNP methods into document summarization, we follow the assumption that the original documents should be recovered from the reconstruction of summaries (Ma and Wan, 2010; He et al., 2012). We use the Beta process as a prior to generate binary vectors for selecting active sentences that reconstruct the original documents. Then we construct a Bayesian framework for summarization and use the variational approximation for inference. Experimental results on DUC2004 dataset demonstrate the effectiveness of our model. Besides, we reorganize the original documents to generate some new datasets, and examine how the summary length changes on the new data. The results prove that our summary length determination is rational and necessary on unbalanced data. 2 Related Work 2.1 Research on </context>
<context position="11923" citStr="He et al., 2012" startWordPosition="1930" endWordPosition="1933">ocess as the prior to select sentences. 3.2 Framework of BNP Summarization Most existing approaches for generic extractive summarization are based on sentence ranking. However, these methods suffer from a severe problem that they cannot make a good trade-off between the coverage and minimum redundancy (He et al., 738 2012). Some global optimization algorithms are developed, instead of greedy search, to select the best overall summaries (Nenkova and McKeown, 2012). One approach to global optimization of summarization is to regard the summarization as a reconstruction process (Ma and Wan, 2010; He et al., 2012) . Considering a good summary must catch most of the important information in original documents, the original documents are assumed able to be recovered from summaries with some information loss. Then the summarization problem is turned into finding the sentences that cause the least reconstruction error (or information loss). In this paper, we follow the assumption and formulate summarization as a Bayesian framework. First we review the models of (Ma and Wan, 2010) and (He et al., 2012). Given a cluster of M documents x1, x2, ..., xM and the sentence set contained in the documents as S = [s1</context>
<context position="13250" citStr="He et al., 2012" startWordPosition="2166" endWordPosition="2169">mmary sentences and N is the number of all sentences in the cluster. A document xi and a sentence vi or si here are all represented by weighted term frequency vectors in the space Rd, where d is the number of total terms (words). Following the reconstruction assumption, a candidate sentence vi can be approximated by the linear combination of summary sentences: si � �n j=1 wjvj, where w� is the weight for summary sentence vj. Thus the document can also be approximately represented by a linear combination of summary sentences (because it is the sum of the sentences). wjvj. (3) Then the work in (He et al., 2012) aims to find the summary sentence set that can minimize the reconstruction error EN i=1 ||si − En j=1 w�jvj||2; while the work in (Ma and Wan, 2010) defines the problem as finding the sentences that minimize the distortion between documents and its reconstruction dis(xi, En j=1 wjvj) where this distortion function can also be a squared error function. Now we consider the reconstruction for each document, if we see the document xi as the dependent variable, and the summary sentence set S as the independent variable, the problem to minimize the reconstruction error can be seen as a linear regre</context>
</contexts>
<marker>He, Chen, Bu, 2012</marker>
<rawString>Zhanying He, Chun Chen, Jiajun Bu, CanWang, Lijun Zhang, Deng Cai and Xiaofei He. 2012. Document Summarization Based on Data Reconstruction. Proceedings of the Twenty-Sixth AAAI Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Kaisser</author>
<author>Marti A Hearst</author>
<author>John B Lowe</author>
</authors>
<title>Improving Search Results Quality by Customizing Summary Lengths.</title>
<date>2008</date>
<booktitle>Proceedings of ACL-08: HLT,</booktitle>
<pages>701--709</pages>
<contexts>
<context position="6577" citStr="Kaisser et al. (2008)" startWordPosition="1023" endWordPosition="1026">ies. Early research on summary length (Goldstein et al., 1999) focused on discovering the properties of human-generated summaries and analyzing the effect of compression ratio. It demonstrated that an evaluation of summarization systems must take into account both the compression ratios and the characteristics of the documents. Radev and Fan (2000) compared the readability and speedup in reading time of 10% summaries and 20% summaries2 for topic sets with different number of documents. Sweeney et al. (2008) developed an incremental summary containing additional sentences that provide context. Kaisser et al. (2008) studied the impact of query types on summary length of search results. Other than the content of original documents, there are also some other factors affecting summary length especially in specific applications. For example, Sweeney and Crestani (2006) studied the relation between screen size and summary length on mobile platforms. The conclusion of their work is the optimal summary size always falls into the shorter one regardless of the screen size. In sum, the previous works on summary length mostly put their attention on the empirical study of the phenomenon, factors and impacts of summa</context>
</contexts>
<marker>Kaisser, Hearst, Lowe, 2008</marker>
<rawString>Michael Kaisser, Marti A. Hearst, John B. Lowe. 2008. Improving Search Results Quality by Customizing Summary Lengths. Proceedings of ACL-08: HLT, pages 701-709.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Guihong Cao</author>
<author>Jianfeng Gao</author>
<author>Jian-Yun Nie</author>
</authors>
<title>An Information-Theoretic Approach to Automatic Evaluation of Summaries.</title>
<date>2006</date>
<booktitle>Proceedings of NAACL2006,</booktitle>
<pages>463--470</pages>
<marker>Lin, Cao, Gao, Nie, 2006</marker>
<rawString>Chin-Yew Lin, Guihong Cao, Jianfeng Gao, and Jian-Yun Nie. 2006. An Information-Theoretic Approach to Automatic Evaluation of Summaries. Proceedings of NAACL2006, pages 463-470.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>Automatic evaluation of summaries using n-gram co-occurrence statistics.</title>
<date>2003</date>
<booktitle>Proceedings of NAACL2003.</booktitle>
<contexts>
<context position="21638" citStr="Lin and Hovy, 2003" startWordPosition="3712" endWordPosition="3715">ion as ours and it can be seen as an approximation of the constant-length version of our model. 1 2 v�=v+ M i=1 741 742 0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 Rate-dist Rouge-1 Rouge-L Rouge-2 Rouge-SU Figure 1: Rouge-1 values on DUC2004 dataset. Figure 2: Rouge-2 values on DUC2004 dataset. Rouge-L 0.35 0.25 0.15 0.3 0.2 0.1 0 100 200 300 400 Summary Length (Number of Words) Random MMR Lexrank Linear BNP Figure 3: Rouge-L values on DUC2004 dataset. All the compared systems are implemented at different predefined lengths from 50 to 300 words. Then we evaluate the summaries with ROUGE4 tools (Lin and Hovy, 2003) in terms of the f-measure 4we use ROUGE1.5.5 in this work. Rouge-1 0.35 0.25 0.15 0.4 0.3 0.2 Random MMR Lexrank Linear BNP Rouge-2 0.09 0.08 0.07 0.06 0.05 0.04 0.03 0.02 0.1 Random MMR Lexrank Linear BNP scores of Rouge-1 Rouge-2, and Rouge-L. The metric of Rouge f-measure takes into consideration the summary length in evaluation, so it is proper for our experiments. From Fig.1, Fig.2 and Fig.3, we can see that the result of BNP summarization (the dashed line) gets the second best value among all systems. It is only defeated by the Linear model but the result is comparable to the best in Fi</context>
</contexts>
<marker>Lin, Hovy, 2003</marker>
<rawString>Chin-Yew Lin, and Eduard Hovy. 2003. Automatic evaluation of summaries using n-gram co-occurrence statistics. Proceedings of NAACL2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Louis</author>
<author>Ani Nenkova</author>
</authors>
<title>Automatically Evaluating Content Selection in Summarization without Human Models.</title>
<date>2009</date>
<booktitle>Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>306--314</pages>
<contexts>
<context position="23725" citStr="Louis and Nenkova (2009)" startWordPosition="4067" endWordPosition="4070">e recommended length for some constant-length summarization systems, such as the Linear. Figure 4: Rate-dist value V.S. summary word length. 0 100 200 300 400 Summary Word Count 0 100 200 300 400 Summary length (Number of Words) 0 100 200 300 400 Summary Length (Number of Words) 5.2 A New Evaluation Metric The Rouge evaluation requires golden standard summaries as the base. However, in many cases we cannot get the reference summaries. For example, when we implement experiments on our expanded datasets (the separate and combined clusters of documents), we do not have exact reference summaries. Louis and Nenkova (2009) advanced an automatic summary evaluation without human models. They used the Jensen-Shannon divergence(JSD) between the input documents and the summaries as a feature, and got high correlation with human evaluations and the rouge metric. Unfortunately, it was designed for comparison at a constant-length, which cannot meet our needs. To extend the JSD evaluation to compare varying-length summaries, we propose a new measure based on information theory, the ratedistortion (Cover and Thomas, 2006). Rate-Distortion: The distortion function d(x, ˆx) is a measure of the cost of representing the symb</context>
<context position="25460" citStr="Louis and Nenkova, 2009" startWordPosition="4345" endWordPosition="4348">formation I(X; ˆX) measures the compactness of the new representation. Thus the ratedistortion function is a trade-off between the compactness of new representation and the expected distortion. Specifically in summarization, the summaries can be seen as the new representation Xˆ of original documents X. A good summary balances the compression ratio and the information loss, thus minimizing the function (20). So we use the function (20)(we set Q = 1) to compare which summary is a better compression. The JS-divergence (JSD), which has been proved to have high correlation with manual evaluation (Louis and Nenkova, 2009) for constant-length summary evaluation, is utilized as the distortion in the function. In the following sections, we simply call the values of the function (20) rate-dist. In fact, the rate-dist values can be seen as the JSD measure with length regularization. To check the effectiveness of rate-dist measure, we evaluate all summaries generated in Section 5.1 with the new measure (the lower the better). Fig. 5 shows that the results accord with the ones in Fig. 1 and Fig. 3. Moreover, in Fig. 4, the curve of ratedist values has a inverse tendency of Rouge measures (Rouge-1, Rouge-2, Rouge-L an</context>
</contexts>
<marker>Louis, Nenkova, 2009</marker>
<rawString>Annie Louis and Ani Nenkova. 2009. Automatically Evaluating Content Selection in Summarization without Human Models. Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 306-314. Singapore, 6-7 August 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tengfei Ma</author>
<author>Xiaojun Wan</author>
</authors>
<title>Multidocument Summarization Using Minimum Distortion.</title>
<date>2010</date>
<booktitle>IEEE 10th International Conference on Data Mining (ICDM).</booktitle>
<contexts>
<context position="5249" citStr="Ma and Wan, 2010" startWordPosition="819" endWordPosition="822">Bayesian nonparametric model of extractive multi-document summarization to achieve this goal. As far as we are concerned, it is the first model that can learn appropriate lengths of summaries. Bayesian nonparametric (BNP) methods are powerful tools to determine the size of latent variables (Gershman and Blei, 2011). They let the data ”speak for itself” and allow the dimension of latent variables to grow with the data. In order to integrate the BNP methods into document summarization, we follow the assumption that the original documents should be recovered from the reconstruction of summaries (Ma and Wan, 2010; He et al., 2012). We use the Beta process as a prior to generate binary vectors for selecting active sentences that reconstruct the original documents. Then we construct a Bayesian framework for summarization and use the variational approximation for inference. Experimental results on DUC2004 dataset demonstrate the effectiveness of our model. Besides, we reorganize the original documents to generate some new datasets, and examine how the summary length changes on the new data. The results prove that our summary length determination is rational and necessary on unbalanced data. 2 Related Wor</context>
<context position="11905" citStr="Ma and Wan, 2010" startWordPosition="1926" endWordPosition="1929">we use the beta process as the prior to select sentences. 3.2 Framework of BNP Summarization Most existing approaches for generic extractive summarization are based on sentence ranking. However, these methods suffer from a severe problem that they cannot make a good trade-off between the coverage and minimum redundancy (He et al., 738 2012). Some global optimization algorithms are developed, instead of greedy search, to select the best overall summaries (Nenkova and McKeown, 2012). One approach to global optimization of summarization is to regard the summarization as a reconstruction process (Ma and Wan, 2010; He et al., 2012) . Considering a good summary must catch most of the important information in original documents, the original documents are assumed able to be recovered from summaries with some information loss. Then the summarization problem is turned into finding the sentences that cause the least reconstruction error (or information loss). In this paper, we follow the assumption and formulate summarization as a Bayesian framework. First we review the models of (Ma and Wan, 2010) and (He et al., 2012). Given a cluster of M documents x1, x2, ..., xM and the sentence set contained in the do</context>
<context position="13399" citStr="Ma and Wan, 2010" startWordPosition="2195" endWordPosition="2198"> frequency vectors in the space Rd, where d is the number of total terms (words). Following the reconstruction assumption, a candidate sentence vi can be approximated by the linear combination of summary sentences: si � �n j=1 wjvj, where w� is the weight for summary sentence vj. Thus the document can also be approximately represented by a linear combination of summary sentences (because it is the sum of the sentences). wjvj. (3) Then the work in (He et al., 2012) aims to find the summary sentence set that can minimize the reconstruction error EN i=1 ||si − En j=1 w�jvj||2; while the work in (Ma and Wan, 2010) defines the problem as finding the sentences that minimize the distortion between documents and its reconstruction dis(xi, En j=1 wjvj) where this distortion function can also be a squared error function. Now we consider the reconstruction for each document, if we see the document xi as the dependent variable, and the summary sentence set S as the independent variable, the problem to minimize the reconstruction error can be seen as a linear regression model. The model can be easily changed to a Bayesian regression model by adding a zero-mean Gaussian noise c (Bishop, 2006), as follows. n xi =</context>
<context position="20998" citStr="Ma and Wan, 2010" startWordPosition="3599" endWordPosition="3602">aries that we finally generate have an average length of 164 words. We design several popular unsupervised summarization systems and compare them with our model. • The Random model selects sentences randomly for each document cluster. • The MMR (Carbonell and Goldstein, 1998) strives to reduce redundancy while maintaining relevance. For generic summarization, we replace the query relevance with the relevance to documents. • The Lexrank model (Erkan and Radev, 2004) is a graph-based method which choose sentences based on the concept of eigenvector centrality. • The Linear Representation model (Ma and Wan, 2010) has the same assumption as ours and it can be seen as an approximation of the constant-length version of our model. 1 2 v�=v+ M i=1 741 742 0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 Rate-dist Rouge-1 Rouge-L Rouge-2 Rouge-SU Figure 1: Rouge-1 values on DUC2004 dataset. Figure 2: Rouge-2 values on DUC2004 dataset. Rouge-L 0.35 0.25 0.15 0.3 0.2 0.1 0 100 200 300 400 Summary Length (Number of Words) Random MMR Lexrank Linear BNP Figure 3: Rouge-L values on DUC2004 dataset. All the compared systems are implemented at different predefined lengths from 50 to 300 words. Then we evaluate the summarie</context>
<context position="24795" citStr="Ma and Wan, 2010" startWordPosition="4237" endWordPosition="4240">y, the ratedistortion (Cover and Thomas, 2006). Rate-Distortion: The distortion function d(x, ˆx) is a measure of the cost of representing the symbol x to a new symbol ˆx; and the rate can indicate how much compression can be achieved. The problem of finding the minimum rate can be solved by minimizing the functional F[p(ˆx|x)] = I(X; ˆX) + QE(d(x, ˆx)). (20) where I(X; ˆX) denotes the mutual information. The rate-distortion theory is a fundamental theory for lossy data compression. Recently, it has also been successfully employed for text clustering (Slonim, 2002) and document summarization (Ma and Wan, 2010). Slonim (2002) claims that the mutual information I(X; ˆX) measures the compactness of the new representation. Thus the ratedistortion function is a trade-off between the compactness of new representation and the expected distortion. Specifically in summarization, the summaries can be seen as the new representation Xˆ of original documents X. A good summary balances the compression ratio and the information loss, thus minimizing the function (20). So we use the function (20)(we set Q = 1) to compare which summary is a better compression. The JS-divergence (JSD), which has been proved to have </context>
</contexts>
<marker>Ma, Wan, 2010</marker>
<rawString>Tengfei Ma and Xiaojun Wan. 2010. Multidocument Summarization Using Minimum Distortion. IEEE 10th International Conference on Data Mining (ICDM).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ani Nenkova</author>
<author>Kathleen McKeown</author>
</authors>
<title>A survey of text summarization techniques.</title>
<date>2012</date>
<booktitle>Mining Text Data, Chapter 3, Springer Science+Business</booktitle>
<location>Media, LLC</location>
<contexts>
<context position="11774" citStr="Nenkova and McKeown, 2012" startWordPosition="1904" endWordPosition="1907">tors of binary indicator variables(Paisley and Carin, 2009), which indicates whether a feature is used to represent a sample. In this paper, we use the beta process as the prior to select sentences. 3.2 Framework of BNP Summarization Most existing approaches for generic extractive summarization are based on sentence ranking. However, these methods suffer from a severe problem that they cannot make a good trade-off between the coverage and minimum redundancy (He et al., 738 2012). Some global optimization algorithms are developed, instead of greedy search, to select the best overall summaries (Nenkova and McKeown, 2012). One approach to global optimization of summarization is to regard the summarization as a reconstruction process (Ma and Wan, 2010; He et al., 2012) . Considering a good summary must catch most of the important information in original documents, the original documents are assumed able to be recovered from summaries with some information loss. Then the summarization problem is turned into finding the sentences that cause the least reconstruction error (or information loss). In this paper, we follow the assumption and formulate summarization as a Bayesian framework. First we review the models o</context>
</contexts>
<marker>Nenkova, McKeown, 2012</marker>
<rawString>Ani Nenkova and Kathleen McKeown. 2012. A survey of text summarization techniques. Mining Text Data, Chapter 3, Springer Science+Business Media, LLC (2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Paisley</author>
<author>Lawrence Carin</author>
</authors>
<title>Nonparametric Factor Analysis with Beta Process Priors.</title>
<date>2009</date>
<booktitle>Proceedings of the 26th International Conference on Machine Learning,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="9515" citStr="Paisley and Carin, 2009" startWordPosition="1498" endWordPosition="1501">ut the summarization framework is still constant-length. Our BNP summarization model differs from the previous models. Besides using the HDP for topic analysis, our approach further integrates the beta process into sentence selection. The BNP method in our model are directly used to determine the number of summary sentences but not latent topics. 3 BNP Summarization In this section, we first introduce the BNP priors which will be used in our model. Then we propose our model called BNP summarization. 3.1 The Beta Process and the Bernoulli process The beta process(BP) (Thibaux and Jordan, 2007; Paisley and Carin, 2009) and the related Indian buffet process(IBP) (Griffiths and Ghahramani, 2005) are widely applied to factor/feature analysis. By defining the infinite dimensional priors, these factor analysis models need not to specify the number of latent factors but automatically determine it. Definition of BP (Paisley et al., 2010): Let B0 be a continuous measure on a space Θ and B0(Θ) = γ. If Bk is defined as follows, Bk = N πkδθk, E k=1 πk — Beta(αγN , α(1 — γN)) θk — 1 B0 (1) γ (where δθk is the atom at the location θk; and α is a positive scalar), then as N —* oc, Bk —* B and B is a beta process: B — BP(</context>
<context position="11207" citStr="Paisley and Carin, 2009" startWordPosition="1814" endWordPosition="1817">conjugation between the beta process priors and Bernoulli process, the posterior of B given M samples X1, X2, ...XM where Xi — Bep(B)fori = 1, , , M. is also a beta process which has updated parameters: B|X1, X2, ..., XM — BP(α + M, α+M B0 + c+M Ei Xi) (2) Application of BP: Furthermore, marginalizing over the beta process measure B and taking α = 1, provides a predictive distribution on indicators known as the Indian buffet process (IBP) (Thibaux and Jordan, 2007). The beta process or the IBP is often used in a feature analysis model to generate infinite vectors of binary indicator variables(Paisley and Carin, 2009), which indicates whether a feature is used to represent a sample. In this paper, we use the beta process as the prior to select sentences. 3.2 Framework of BNP Summarization Most existing approaches for generic extractive summarization are based on sentence ranking. However, these methods suffer from a severe problem that they cannot make a good trade-off between the coverage and minimum redundancy (He et al., 738 2012). Some global optimization algorithms are developed, instead of greedy search, to select the best overall summaries (Nenkova and McKeown, 2012). One approach to global optimiza</context>
</contexts>
<marker>Paisley, Carin, 2009</marker>
<rawString>John Paisley and Lawrence Carin. 2009. Nonparametric Factor Analysis with Beta Process Priors. Proceedings of the 26th International Conference on Machine Learning, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Paisley</author>
<author>Aimee Zaas</author>
<author>Christopher W Woods</author>
<author>Geoffrey S Ginsburg</author>
<author>Lawrence Carin</author>
</authors>
<title>A StickBreaking Construction of the Beta Process.</title>
<date>2010</date>
<booktitle>Proceedings of the 27 th International Confer- ence on Machine Learning,</booktitle>
<location>Haifa, Israel,</location>
<contexts>
<context position="9833" citStr="Paisley et al., 2010" startWordPosition="1545" endWordPosition="1548">nces but not latent topics. 3 BNP Summarization In this section, we first introduce the BNP priors which will be used in our model. Then we propose our model called BNP summarization. 3.1 The Beta Process and the Bernoulli process The beta process(BP) (Thibaux and Jordan, 2007; Paisley and Carin, 2009) and the related Indian buffet process(IBP) (Griffiths and Ghahramani, 2005) are widely applied to factor/feature analysis. By defining the infinite dimensional priors, these factor analysis models need not to specify the number of latent factors but automatically determine it. Definition of BP (Paisley et al., 2010): Let B0 be a continuous measure on a space Θ and B0(Θ) = γ. If Bk is defined as follows, Bk = N πkδθk, E k=1 πk — Beta(αγN , α(1 — γN)) θk — 1 B0 (1) γ (where δθk is the atom at the location θk; and α is a positive scalar), then as N —* oc, Bk —* B and B is a beta process: B — BP(αB0). Finite Approximation: The beta process is defined on an infinite parameter space, but sometimes we can also use its finite approximation by simply setting N to a large number (Paisley and Carin, 2009). Bernoulli Process: The beta process is conjugate to a class of Bernoulli processes, denoted by X — Bep(B). If </context>
</contexts>
<marker>Paisley, Zaas, Woods, Ginsburg, Carin, 2010</marker>
<rawString>John Paisley, Aimee Zaas, Christopher W. Woods, Geoffrey S. Ginsburg and Lawrence Carin. 2010. A StickBreaking Construction of the Beta Process. Proceedings of the 27 th International Confer- ence on Machine Learning, Haifa, Israel, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Weiguo Fan</author>
</authors>
<title>Effective search results summary size and device screen size: Is there a relationship.</title>
<date>2000</date>
<booktitle>Proceedings of the ACL-2000 workshop on Recent advances in natural language processing and information retrieval</booktitle>
<contexts>
<context position="6306" citStr="Radev and Fan (2000)" startWordPosition="982" endWordPosition="985">how the summary length changes on the new data. The results prove that our summary length determination is rational and necessary on unbalanced data. 2 Related Work 2.1 Research on Summary Length Summary length is an important aspect for generating and evaluating summaries. Early research on summary length (Goldstein et al., 1999) focused on discovering the properties of human-generated summaries and analyzing the effect of compression ratio. It demonstrated that an evaluation of summarization systems must take into account both the compression ratios and the characteristics of the documents. Radev and Fan (2000) compared the readability and speedup in reading time of 10% summaries and 20% summaries2 for topic sets with different number of documents. Sweeney et al. (2008) developed an incremental summary containing additional sentences that provide context. Kaisser et al. (2008) studied the impact of query types on summary length of search results. Other than the content of original documents, there are also some other factors affecting summary length especially in specific applications. For example, Sweeney and Crestani (2006) studied the relation between screen size and summary length on mobile plat</context>
</contexts>
<marker>Radev, Fan, 2000</marker>
<rawString>Dragomir R. Radev and Weiguo Fan. 2000. Effective search results summary size and device screen size: Is there a relationship. Proceedings of the ACL-2000 workshop on Recent advances in natural language processing and information retrieval</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graph-based Lexical Centrality as Salience in Text Summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<volume>22</volume>
<pages>457--479</pages>
<contexts>
<context position="20850" citStr="Erkan and Radev, 2004" startWordPosition="3576" endWordPosition="3579">e selection step, we use the variational inference described in Section 4, where the parameters in the beta process (5) are set as γ = 1, α = 1. The summaries that we finally generate have an average length of 164 words. We design several popular unsupervised summarization systems and compare them with our model. • The Random model selects sentences randomly for each document cluster. • The MMR (Carbonell and Goldstein, 1998) strives to reduce redundancy while maintaining relevance. For generic summarization, we replace the query relevance with the relevance to documents. • The Lexrank model (Erkan and Radev, 2004) is a graph-based method which choose sentences based on the concept of eigenvector centrality. • The Linear Representation model (Ma and Wan, 2010) has the same assumption as ours and it can be seen as an approximation of the constant-length version of our model. 1 2 v�=v+ M i=1 741 742 0.45 0.4 0.35 0.3 0.25 0.2 0.15 0.1 0.05 Rate-dist Rouge-1 Rouge-L Rouge-2 Rouge-SU Figure 1: Rouge-1 values on DUC2004 dataset. Figure 2: Rouge-2 values on DUC2004 dataset. Rouge-L 0.35 0.25 0.15 0.3 0.2 0.1 0 100 200 300 400 Summary Length (Number of Words) Random MMR Lexrank Linear BNP Figure 3: Rouge-L val</context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes Erkan, and Dragomir R. Radev. 2004. LexRank: Graph-based Lexical Centrality as Salience in Text Summarization. Journal of Artificial Intelligence Research, 22 (2004) 457-479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Slonim</author>
</authors>
<title>The Information Bottleneck: Theory and Applications.</title>
<date>2002</date>
<booktitle>PHD Thesis of the Hebrew University .</booktitle>
<contexts>
<context position="24749" citStr="Slonim, 2002" startWordPosition="4232" endWordPosition="4233">e a new measure based on information theory, the ratedistortion (Cover and Thomas, 2006). Rate-Distortion: The distortion function d(x, ˆx) is a measure of the cost of representing the symbol x to a new symbol ˆx; and the rate can indicate how much compression can be achieved. The problem of finding the minimum rate can be solved by minimizing the functional F[p(ˆx|x)] = I(X; ˆX) + QE(d(x, ˆx)). (20) where I(X; ˆX) denotes the mutual information. The rate-distortion theory is a fundamental theory for lossy data compression. Recently, it has also been successfully employed for text clustering (Slonim, 2002) and document summarization (Ma and Wan, 2010). Slonim (2002) claims that the mutual information I(X; ˆX) measures the compactness of the new representation. Thus the ratedistortion function is a trade-off between the compactness of new representation and the expected distortion. Specifically in summarization, the summaries can be seen as the new representation Xˆ of original documents X. A good summary balances the compression ratio and the information loss, thus minimizing the function (20). So we use the function (20)(we set Q = 1) to compare which summary is a better compression. The JS-di</context>
</contexts>
<marker>Slonim, 2002</marker>
<rawString>Noam Slonim. 2002. The Information Bottleneck: Theory and Applications. PHD Thesis of the Hebrew University .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Sweeney</author>
<author>Fabio Crestani</author>
</authors>
<title>Effective search results summary size and device screen size: Is there a relationship.</title>
<date>2006</date>
<journal>Information Processing and Management</journal>
<volume>42</volume>
<pages>1056--1074</pages>
<contexts>
<context position="6831" citStr="Sweeney and Crestani (2006)" startWordPosition="1063" endWordPosition="1066">nto account both the compression ratios and the characteristics of the documents. Radev and Fan (2000) compared the readability and speedup in reading time of 10% summaries and 20% summaries2 for topic sets with different number of documents. Sweeney et al. (2008) developed an incremental summary containing additional sentences that provide context. Kaisser et al. (2008) studied the impact of query types on summary length of search results. Other than the content of original documents, there are also some other factors affecting summary length especially in specific applications. For example, Sweeney and Crestani (2006) studied the relation between screen size and summary length on mobile platforms. The conclusion of their work is the optimal summary size always falls into the shorter one regardless of the screen size. In sum, the previous works on summary length mostly put their attention on the empirical study of the phenomenon, factors and impacts of summary length. None of them automatically find the best length, which is our main task in this paper. Nevertheless, they demonstrated the importance of summary length in summarization and the reasonability of determining summary length based on content of ne</context>
</contexts>
<marker>Sweeney, Crestani, 2006</marker>
<rawString>Simon Sweeney and Fabio Crestani. 2006. Effective search results summary size and device screen size: Is there a relationship. Information Processing and Management 42 (2006) 1056-1074.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Sweeney</author>
<author>Fabio Crestani</author>
<author>David E Losada</author>
</authors>
<title>Show me more’: Incremental length summarisation using novelty detection.</title>
<date>2008</date>
<journal>Information Processing and Management</journal>
<volume>44</volume>
<pages>663--686</pages>
<contexts>
<context position="6468" citStr="Sweeney et al. (2008)" startWordPosition="1008" endWordPosition="1011">ork 2.1 Research on Summary Length Summary length is an important aspect for generating and evaluating summaries. Early research on summary length (Goldstein et al., 1999) focused on discovering the properties of human-generated summaries and analyzing the effect of compression ratio. It demonstrated that an evaluation of summarization systems must take into account both the compression ratios and the characteristics of the documents. Radev and Fan (2000) compared the readability and speedup in reading time of 10% summaries and 20% summaries2 for topic sets with different number of documents. Sweeney et al. (2008) developed an incremental summary containing additional sentences that provide context. Kaisser et al. (2008) studied the impact of query types on summary length of search results. Other than the content of original documents, there are also some other factors affecting summary length especially in specific applications. For example, Sweeney and Crestani (2006) studied the relation between screen size and summary length on mobile platforms. The conclusion of their work is the optimal summary size always falls into the shorter one regardless of the screen size. In sum, the previous works on sum</context>
</contexts>
<marker>Sweeney, Crestani, Losada, 2008</marker>
<rawString>Simon Sweeney, Fabio Crestani and David E. Losada. 2008. ’Show me more’: Incremental length summarisation using novelty detection. Information Processing and Management 44 (2008) 663-686.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yee Whye Teh</author>
<author>Dilan G¨or¨ur</author>
<author>Zoubin Ghahramani</author>
</authors>
<title>Stick-breaking Construction for the Indian Buffet Process.</title>
<date>2007</date>
<booktitle>Proceedings of the International Conference on Artificial Intelligence and Statistics.</booktitle>
<marker>Teh, G¨or¨ur, Ghahramani, 2007</marker>
<rawString>Yee Whye Teh, Dilan G¨or¨ur, and Zoubin Ghahramani. 2007. Stick-breaking Construction for the Indian Buffet Process. Proceedings of the International Conference on Artificial Intelligence and Statistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Teh</author>
<author>M I Jordan</author>
<author>M J Beal</author>
<author>D M Blei</author>
</authors>
<date>2006</date>
<booktitle>Hierarchical Dirichlet Processes. JASA ,</booktitle>
<pages>101--476</pages>
<contexts>
<context position="8451" citStr="Teh et al., 2006" startWordPosition="1327" endWordPosition="1330">and 20% are the compression rates, and the documents are from search results in information retrieval systems. 737 and Blei, 2011). A BNP model uses an infinitedimensional parameter space, but invokes only a finite subset of the available parameters on any given finite data set. This subset generally grows with the data set. Thus BNP models address the problem of choosing the number of mixture components or latent factors. For example, the hierarchical Dirichlet process (HDP) can be used to infer the number of topics in topic models or the number of states in the infinite Hidden Markov model (Teh et al., 2006). Recently, some BNP models are also involved in document summarization approaches (Celikyilmaz and Hakkani-T¨ur, 2010; Chang et al., 2011; Darling and Song, 2011). BNP priors such as the nested Chinese restaurant process (nCRP) are associated with topic analysis in these models. Then the topic distributions are used to get the sentence scores and rank sentences. BNP here only impacts the number and the structure of the latent topics, but the summarization framework is still constant-length. Our BNP summarization model differs from the previous models. Besides using the HDP for topic analysis,</context>
<context position="15533" citStr="Teh et al., 2006" startWordPosition="2584" endWordPosition="2587"> zi) + Ci S = [s1,s2, ..., sN] zij ∼ Bernoulli(πj) where N is the number of sentences in the whole document cluster. The symbol ◦ represents the elementwise multiplication of two vectors. One problem of the reconstruction model is that the word vector representation of the sentences are sparse, which dramatically increase the reconstruction error. So we bring in topic models to reduce the φi ∼ N(0, σ2φI) Ei ∼ N(0, σ2, I) (5) 3We use the finite approximation because the number of sentences is large but finite n E j=1 xi — αγγ πj ∼ Beta( N ,α(1− N )) 739 dimension of the data. We use a HDP-LDA (Teh et al., 2006) to get topic distributions for each sentence, and we represent the sentences and documents as the topic weight vectors instead of word weight vectors. Finally xi is a K-dimensional vector and S is a K ∗ N matrix, where K is the number of topics in topic models. 4 Variational Inference In this section, we derive a variational Bayesian algorithm for fast inference of our sentence selection model. Variational inference (Bishop, 2006) is a framework for approximating the true posterior with the best from a set of distributions Q : q∗ = arg minq∈Q KL(q(Z)|p(Z|X)). Supposeq(Z) can be partitioned in</context>
<context position="20211" citStr="Teh et al., 2006" startWordPosition="3470" endWordPosition="3473">ariable-length summarization. We separate each cluster in the original dataset into two parts where each has 5 documents, hence getting the Separate Dataset; Then we randomly combine two original clusters in the DUC2004 dataset, and get two datasets called Combined1 and Combined2. Thus each of the clusters in the combined datasets include 20 documents with two different themes. 5.1 Evaluation of Summary Qualities First, we implement our BNP summarization model on the DUC2004 dataset, with summary length not limited. At the topic analysis step, we use the HDP model and follow the inference in (Teh et al., 2006). For the sentence selection step, we use the variational inference described in Section 4, where the parameters in the beta process (5) are set as γ = 1, α = 1. The summaries that we finally generate have an average length of 164 words. We design several popular unsupervised summarization systems and compare them with our model. • The Random model selects sentences randomly for each document cluster. • The MMR (Carbonell and Goldstein, 1998) strives to reduce redundancy while maintaining relevance. For generic summarization, we replace the query relevance with the relevance to documents. • Th</context>
</contexts>
<marker>Teh, Jordan, Beal, Blei, 2006</marker>
<rawString>Y.W. Teh, M.I. Jordan, M.J. Beal and D.M. Blei. 2006. Hierarchical Dirichlet Processes. JASA , 101(476):1566-1581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Romain Thibaux</author>
<author>Michael I Jordan</author>
</authors>
<date>2009</date>
<booktitle>Hierarchical Beta Processes and the Indian Buffet Process. AISTATS2007.</booktitle>
<marker>Thibaux, Jordan, 2009</marker>
<rawString>Romain Thibaux and Michael I. Jordan. 2009. Hierarchical Beta Processes and the Indian Buffet Process. AISTATS2007.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>