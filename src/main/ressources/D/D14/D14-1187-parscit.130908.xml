<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000090">
<title confidence="0.993229">
Cross-Lingual Part-of-Speech Tagging through Ambiguous Learning
</title>
<author confidence="0.902199">
Guillaume Wisniewski Nicolas Pécheux Souhir Gahbiche-Braham François Yvon
</author>
<note confidence="0.490523333333333">
Université Paris Sud
LIMSI-CNRS
91403 ORSAY CEDEX, France
</note>
<email confidence="0.98735">
{wisniews,pecheux,souhir,yvon}@limsi.fr
</email>
<sectionHeader confidence="0.997979" genericHeader="abstract">
Abstract
</sectionHeader>
<subsectionHeader confidence="0.942643">
When Part-of-Speech annotated data is
</subsectionHeader>
<bodyText confidence="0.999810111111111">
scarce, e.g. for under-resourced lan-
guages, one can turn to cross-lingual trans-
fer and crawled dictionaries to collect par-
tially supervised data. We cast this prob-
lem in the framework of ambiguous learn-
ing and show how to learn an accurate
history-based model. Experiments on ten
languages show significant improvements
over prior state of the art performance.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999462">
In the past two decades, supervised Machine
Learning techniques have established new perfor-
mance standards for many NLP tasks. Their suc-
cess however crucially depends on the availability
of annotated in-domain data, a not so common sit-
uation. This means that for many application do-
mains and/or less-resourced languages, alternative
ML techniques need to be designed to accommo-
date unannotated or partially annotated data.
Several attempts have recently been made to
mitigate the lack of annotated corpora using par-
allel data pairing a (source) text in a resource-rich
language with its counterpart in a less-resourced
language. By transferring labels from the source
to the target, it becomes possible to obtain noisy,
yet useful, annotations that can be used to train a
model for the target language in a weakly super-
vised manner. This research trend was initiated
by Yarowsky et al. (2001), who consider the trans-
fer of POS and other syntactic information, and
further developed in (Hwa et al., 2005; Ganchev
et al., 2009) for syntactic dependencies, in (Padó
and Lapata, 2009; Kozhevnikov and Titov, 2013;
van der Plas et al., 2014) for semantic role la-
beling and in (Kim et al., 2012) for named-entity
recognition, to name a few.
Assuming that labels can actually be projected
across languages, these techniques face the issue
of extending standard supervised techniques with
partial and/or uncertain labels in the presence of
alignment noise. In comparison to the early ap-
proach of Yarowsky et al. (2001) in which POS
are directly transferred, subject to heuristic fil-
tering rules, recent works consider the integra-
tion of softer constraints using expectation regu-
larization techniques (Wang and Manning, 2014),
the combination of alignment-based POS transfer
with additional information sources such as dic-
tionaries (Li et al., 2012; Täckström et al., 2013)
(Section 2), or even the simultaneous use of both
techniques (Ganchev and Das, 2013).
In this paper, we reproduce the weakly super-
vised setting of Täckström et al. (2013). By re-
casting this setting in the framework of ambiguous
learning (Bordes et al., 2010; Cour et al., 2011)
(Section 3), we propose an alternative learning
methodology and show that it improves the state of
the art performance on a large array of languages
(Section 4). Our analysis of the remaining errors
suggests that in cross-lingual settings, improve-
ments of error rates can have multiple causes and
should be looked at with great care (Section 4.2).
All tools and resources used in this study
are available at http://perso.limsi.fr/
wisniews/ambiguous.
</bodyText>
<sectionHeader confidence="0.9819865" genericHeader="method">
2 Projecting Labels across Aligned
Corpora
</sectionHeader>
<bodyText confidence="0.999176">
Projecting POS information across languages re-
lies on a rather strong assumption that morpho-
syntactic categories in the source language can
be directly related to the categories in the tar-
get language, which might not always be war-
ranted (Evans and Levinson, 2009; Broschart,
2009). The universal reduced POS tagset pro-
posed by Petrov et al. (2012) defines an opera-
tional, albeit rather empirical, ground to perform
this mapping. It is made of the following 12 cat-
egories: NOUN (nouns), VERB (verbs), ADJ (ad-
</bodyText>
<page confidence="0.939176">
1779
</page>
<bodyText confidence="0.2612483">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1779–1785,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
ar cs de el es fi fr id it sv
% of test covered tokens (type) 83.2 93.2 95.6 97.4 96.7 83.0 98.3 90.5 95.8 95.3
% of test correctly covered token (type) 72.9 94.2 93.7 92.9 93.8 93.6 92.1 89.6 93.6 94.1
avg. number of labels per token (type) 2.1 1.3 1.3 1.3 1.3 1.4 1.3 1.2 1.3 1.3
avg. number of labels per token (type+token) 1.7 1.1 1.1 1.1 1.1 1.2 1.2 1.1 1.1 1.1
% of aligned tokens 53.0 77.8 66.7 69.3 74.0 73.1 64.7 81.6 72.2 79.9
% of token const. violating type const. 2.5 16.0 15.8 21.4 16.9 14.3 16.1 19.3 17.5 13.6
% informative token const. 79.7 27.5 15.7 29.8 21.3 36.0 25.5 16.2 28.2 26.4
</bodyText>
<tableCaption confidence="0.987476">
Table 1: Interplay between token and type constraints on our training parallel corpora. ‘Informative’
</tableCaption>
<bodyText confidence="0.973524538461539">
token constraints correspond to tokens for which (a) a POS is actually transfered and (b) type constraints
do not disambiguate the label, but type+token constraints do.
jectives), ADV (adverbs), PRON (pronouns), DET
(determiners and articles), ADP (prepositions and
postpositions), NUM (numerals), CONJ (conjunc-
tions), PRT (particles), ‘.’ (punctuation marks)
and X (a catch-all for other categories). These
labels have been chosen for their stability across
languages and for their usefulness in various mul-
tilingual applications. In the rest of this work, all
annotations are mapped to this universal tagset.
Transfer-based methods have shown to be very
effective, even if projected labels only deliver a
noisy supervision, due to tagging (of the source
language) and other alignment errors (Yarowsky
et al., 2001). While this uncertainty can be ad-
dressed in several ways, recent works have pro-
posed to combine projected labels with monolin-
gual information in order to filter out invalid la-
bel sequences (Das and Petrov, 2011; Täckstr6m
et al., 2013). In this work we follow Täckstr6m et
al. (2013) and use two families of constraints:
Token constraints rely on word alignments to
project labels of source words to target words
through alignment links. Table 1 shows that, de-
pendening on the language, only 50−80% of the
target tokens would benefit from label transfer.
Type constraints rely on a tag dictionary to
define the set of possible tags for each word
type. Type constraints reduce the possible la-
bels for a given word and help filtering out cross-
lingual transfer errors (up to 20%, as shown in Ta-
ble 1). As in (Täckstr6m et al., 2013), we con-
sider two different dictionaries. The first one is
extracted automatically from Wiktionary,1 us-
ing the method of (Li et al., 2012). The second
tag dictionary is built by using for each word the
two most frequently projected POS labels from
the training data.2 In contrast to Täckstr6m et al.
</bodyText>
<footnote confidence="0.9961295">
1http://www.wiktionary.org/
2This heuristic is similar to the way Täckstr6m et al.
</footnote>
<bodyText confidence="0.999881541666667">
(2013) we use the intersection3 of the two type
constraints instead of their union. Table 1 shows
the precision and recall of the resulting constraints
on the test data.
These two information sources are merged ac-
cording to the rules of Täckstr6m et al. (2013).
These rules assume that type constraints are more
reliable than token constraints and should take
precedence: by default, a given word is associated
to the set of possible tags licensed type constraints;
additionally, when a POS tag can be projected
through alignment and also satisfies the type con-
straints, then it is actually projected, thereby pro-
viding a full (yet noisy) supervision.
As shown in Table 1, token and type con-
straints complement each other effectively and
greatly reduce label ambiguity. However, the
transfer method sketched above associates each
target word with a set of possible labels, of which
only one is true. This situation is less favorable
than standard supervised learning in which one
unique gold label is available for each occurrence.
We describe in the following section how to learn
from this ambiguous supervision information.
</bodyText>
<sectionHeader confidence="0.9836705" genericHeader="method">
3 Modeling Sequences under Ambiguous
Supervision
</sectionHeader>
<bodyText confidence="0.999913142857143">
We use a history-based model (Black et al., 1992)
with a LaSO-like training method (Daumé and
Marcu, 2005). History-based models reduce struc-
tured prediction to a sequence of multi-class clas-
sification problems. The prediction of a complex
structure (here, a sequence of POS tags) is thus
modeled as a sequential decision problem: at each
</bodyText>
<footnote confidence="0.652333">
(2013) filter the tag distribution with a threshold to build the
projected type constraints.
3If the intersection is empty we use the constraints
from Wiktionary first, if also empty, the projected con-
straints then, and by default the whole tag set.
</footnote>
<page confidence="0.978484">
1780
</page>
<bodyText confidence="0.9999871">
position in the sequence, a multiclass classifier
is used to make a decision, using features that
describe both the input structure and the history
of past decisions (i.e. the partially annotated se-
quence).
Let x = (xi)ni=1 denote the observed sequence
and Y be the set of possible labels (in our case
the 12 universal POS tags). Inference consists in
predicting labels one after the other using, for in-
stance, a linear model:
</bodyText>
<equation confidence="0.9861895">
y∗i = arg max hw|0(x, i, y, hi)i (1)
y∈Y
</equation>
<bodyText confidence="0.999924909090909">
where h·|·i is the standard dot product operation,
y∗i the predicted label for position i, w the weight
vector, hi = y∗1, ..., y∗i−1 the history of past de-
cisions and 0 a joint feature map. Inference can
therefore be seen as a greedy search in the space
of the # {Y} n possible labelings of the input se-
quence. Trading off the global optimality of in-
ference for additional flexibility in the design of
features and long range dependencies between la-
bels has proved useful for many sequence labeling
tasks in NLP (Tsuruoka et al., 2011).
The training procedure, sketched in Algo-
rithm 1, consists in performing inference on each
input sentence and correcting the weight vector
each time a wrong decision is made. Impor-
tantly (Ross and Bagnell, 2010), the history used
during training has to be made of the previous pre-
dicted labels so that the training samples reflect the
fact that the history will be imperfectly known at
test time.
This reduction of sequence labeling to multi-
class classification allows us to learn a sequence
model in an ambiguous setting by building on the
theoretical results of Bordes et al. (2010) and Cour
et al. (2011). The decision about the correctness of
a prediction and the weight updates can be adapted
to the amount of supervision information that is
available.
Full Supervision In a fully supervised setting,
the correct label is known for each word token: a
decision is thus considered wrong when this gold
label is not predicted. In this case, a standard per-
ceptron update is performed:
</bodyText>
<equation confidence="0.921468">
wt+1 ← wt−0 (x, i, y∗i , hi)+0 (x, i, ˆyi, hi) (2)
</equation>
<bodyText confidence="0.999951777777778">
where y∗i and ˆyi are the predicted and the gold la-
bel, respectively. This update is a stochastic gra-
dient step that increases the score of the gold label
while decreasing the score of the predicted label.
Ambiguous Supervision During training, each
observation i is now associated with a set of possi-
ble labels, denoted by ˆYi. In this case, a decision is
considered wrong when the predicted label is not
in ˆYi and the weight vector is updated as follows:
</bodyText>
<equation confidence="0.794205">
�wt+1 ← wt−0 (x, i, y∗i , hi)+ 0 (x, i, ˆyi, hi)
ˆyi∈ˆYi
(3)
</equation>
<bodyText confidence="0.970367">
Compared to (2), this rule uniformly increases the
scores of all the labels in ˆYi.
It can be shown (Bordes et al., 2010; Cour et
al., 2011), under mild assumptions (namely that
two labels never systematically co-occur in the
supervision information), that the update rule (3)
enables to learn a classifier in an ambiguous set-
ting, as if the gold labels were known. Intuitively,
as long as two labels are not systematically co-
occurring in ˆY, updates will reinforce the correct
labels more often than the spurious ones; at the
end of training, the highest scoring label should
therefore be the correct one.
Algorithm 1 Training algorithm. In the ambigu-
ous setting, ˆYi contains all possible labels; in the
supervised setting, it only contains the gold label.
</bodyText>
<equation confidence="0.946874">
w0 ← 0
for t ∈ Q1, T� do
Randomly pick example x, yˆ
h ← empty list
for i ∈ Q1, n� do
y∗i = arg maxy∈Y hwt|0(x, i, y, hi)i
if y∗i ∈/ ˆYi then
wt+1 ← update(wt, x, i, ˆYi, y∗i , hi)
end if
push(y∗i , h)
end for
end for
return T �t 1 wt
</equation>
<sectionHeader confidence="0.994353" genericHeader="method">
4 Empirical Study
</sectionHeader>
<bodyText confidence="0.9998192">
Datasets Our approach is evaluated on 10 lan-
guages that present very different characteristics
and cover several language families.4 In all our ex-
periments we use English as the source language.
Parallel sentences5 are aligned with the standard
</bodyText>
<footnote confidence="0.998927">
4Resources considered in the related works are not freely
available, which prevents us from presenting a more complete
comparison.
5All resources and features used in our experiments are
thoroughly documented in the supplementary material.
</footnote>
<page confidence="0.811027">
1781
</page>
<table confidence="0.99260425">
ar cs de el es fi fr id it sv
HBAL 27.9 10.4 8.8 8.1 8.2 13.3 10.2 11.3 9.1 10.1
Partially observed CRF 33.9 11.6 12.2 10.9 10.7 12.9 11.6 16.3 10.4 11.6
HBSL — 1.5 5.0 — 2.4 5.9 3.5 4.8 2.8 3.8
HBAL + matched POS 24.1 7.6 8.0 7.3 7.4 12.2 7.4 9.8 8.3 8.8
(Ganchev and Das, 2013) 49.9 19.3 9.6 9.4 12.8 — 12.5 — 10.1 10.8
(Täckström et al., 2013) — 18.9 9.5 10.5 10.9 — 11.6 — 10.2 11.1
(Li et al., 2012) — — 14.2 20.8 13.6 — — — 13.5 13.9
</table>
<tableCaption confidence="0.9801815">
Table 2: Error rate (in %) achieved by the method described in Sec. 3 trained in an ambiguous (HBAL)
or in a supervised setting (HBSL), a partially observed CRF and different state-of-the-art results.
</tableCaption>
<bodyText confidence="0.99847485">
MOSES pipeline, using the intersection heuristic
that only retains the most reliable alignment links.
The English side of the bitext is tagged using a
standard linear CRF trained on the Penn Treebank.
Tags are then transferred to the target language us-
ing the procedure described in Section 2. For each
language, we train a tagger using the method de-
scribed in Section 3 with T = 100 000 iterations6
using a feature set similar to the one of Li et al.
(2012) and Täckström et al. (2013). The baseline
system is our reimplementation of the partially
observed CRF model of Täckström et al. (2013).
Evaluation is carried out on the test sets of tree-
banks for which manual gold tags are known. For
Czech and Greek, we use the CoNLL’07 Shared
Task on Dependency Parsing; for Arabic, the Ara-
bic Treebank; and otherwise the data of the Uni-
versal Dependency Treebank Project (McDonald
et al., 2013). Tagging performance is evaluated
with the standard error rate.
</bodyText>
<subsectionHeader confidence="0.501351">
4.1 Results
</subsectionHeader>
<bodyText confidence="0.947522814814815">
Table 2 summarizes the performance achieved
by our method trained in the ambiguous setting
(HBAL) and by our re-implementation of the
partially supervised CRF baseline. As an upper
bound, we also report the score of our method
when trained in a supervised (HBSL) settings
considering the training part of the various tree-
banks, when it is available.7 For the sake of com-
parison, we also list the best scores of previous
studies. Note, however, that a direct comparison
with these results is not completely fair as these
6Preliminary experiments showed that increasing the
number of iterations T in Algorithm 1 has no significant
impact.
7In this setting, HBSL implements an averaged percep-
tron, and achieves results that are similar to those obtained
with standard linear CRF.
systems were not trained and evaluated with the
same exact resources (corpora,8 type constraints,
alignments, etc). Also note that the state-of-the-
art scores have been achieved by different models,
which have been selected based on their scores on
the test set and not on a validation set.9
Experimental results show that HBAL signif-
icantly outperforms, on all considered languages
but one, the partially observed CRF that was
trained and tested in the same setting.
</bodyText>
<subsectionHeader confidence="0.888785">
4.2 Discussion
</subsectionHeader>
<bodyText confidence="0.995450714285714">
The performance of our new method still falls
short of the performance of a fully supervised POS
tagger: for instance, in Spanish, full supervision
reduces the error rate by a factor of 4. A fine-
grained error analysis shows that many errors of
HBAL directly result from the fact that, contrary
to the fully supervised learner HBSL, our am-
biguous setting suffers from a train/test mismatch,
which has two main consequences. First, the train
and test sets do not follow exactly the same nor-
malization and tokenization conventions, which is
an obvious source of mistakes. Second, and more
importantly, many errors are caused by systematic
differences between the test tags and the super-
vised tags (i.e. the English side of the bitext and
Wiktionary). While some of these differences
are linguistically well-justified and reflect funda-
mental differences in the language structure and
usage, others seem to be merely due to arbitrary
annotation conventions.
For instance, in Greek, proper names are labeled
</bodyText>
<footnote confidence="0.996596166666667">
8The test sets are only the same for Czech, Greek and
Swedish.
9The partially observed CRF is the best model in (Täck-
ström et al., 2013) only for German (de), Greek (el) and
Swedish (sv), and uses only type constraints extracted from
Wiktionary.
</footnote>
<page confidence="0.996197">
1782
</page>
<bodyText confidence="0.999944060606061">
either as X (when they refer to a foreigner and are
not transliterated) or as NOUN (in all other cases),
while they are always labeled as NOUN in English.
In French and in Greek, contractions of a prepo-
sition and a determiner such as ‘στο’ (‘σε το’,
meaning ‘to the’) or ‘aux’ (‘à les’ also meaning
‘to the’) are labeled as ADP in the Universal De-
pendency Treebank but as DET in Wiktionary
and are usually aligned with a determiner in the
parallel corpora. In the Penn Treebank, quanti-
fiers like ‘few’ or ‘little’ are generally used in con-
junction with a determiner (‘a few years’, ‘a little
parable’, ...) and labeled as ADJ; the correspond-
ing Spanish constructions lack an article (‘mucho
tempio’, ‘pocos años’, ...) and the quantifiers are
therefore labeled as DET. Capturing such subtle
differences is hardly possible without prior knowl-
edge and specifically tailored features.
This annotation mismatch problem is all the
more important in settings like ours, that rely
on several, independently designed, information
sources, which follow contradictory annotation
conventions and for which the mapping to the uni-
versal tagset is actually error-prone (Zhang et al.,
2012). To illustrate this point, we ran three ad-
ditional experiments to assess the impact of the
train/test mismatch.
We first designed a control experiment in which
the type constraints were manually completed
with the gold labels of the most frequent errors of
HBAL. These errors generally concern function
words and can be assumed to result from system-
atic differences in the annotations rather than pre-
diction errors. For instance, for French the type
constraints for ‘du’, ‘des’, ‘au’ and ‘aux’ were cor-
rected from DET to ADP. The resulting model,
denoted ‘HBAL + matched POS’ in Table 2, sig-
nificantly outperforms HBAL, stressing the diver-
gence in the different annotation conventions.
Additionally, in order to approximate the am-
biguous setting train/test mismatch, we learn two
fully supervised Spanish taggers on the same train-
ing data as HBAL, using two different strategies
to obtain labeled data. We first use HBSL (which
was trained on the treebank) to automatically la-
bel the target side of the parallel corpus. In this
setting, the POS tagger is trained with data from
a different domain, but labeled with the same an-
notation scheme as a the test set. Learning with
this fully supervised data yields an error rate of
4.2% for Spanish, almost twice as much as HBSL,
bringing into light the impact of domain shift. We
then use a generic tagger, FREELING,10 to label
the training data, this time with possible addi-
tional inconsistent annotations. The correspond-
ing error rate for Spanish was 6.1%, to be com-
pared with the 8.2% achieved by HBAL. The last
two control experiments show that many of the re-
maining labeling errors seem to be due to domain
and convention mismatches rather to the trans-
fer/ambiguous setting, as supervised models also
suffer from very similar conditions.
These observations show that the evaluation of
transfer-based methods suffer from several biases.
Their results must therefore be interpreted with
great care.
</bodyText>
<sectionHeader confidence="0.996545" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999978315789474">
In this paper, we have presented a novel learning
methodology to learn from ambiguous supervision
information, and used it to train several POS tag-
gers. Using this method, we have been able to
achieve performance that surpasses the best re-
ported results, sometimes by a wide margin. Fur-
ther work will attempt to better analyse these re-
sults, which could be caused by several subtle
differences between HBAL and the baseline sys-
tem. Nonetheless, these experiments confirm that
cross-lingual projection of annotations have the
potential to help in building very efficient POS
taggers with very little monolingual supervision
data. Our analysis of these results also suggests
that, for this task, additional gains might be more
easily obtained by fixing systematic biases intro-
duced by conflicting mappings between tags or
by train/test domain mismatch than by designing
more sophisticated weakly supervised learners.
</bodyText>
<sectionHeader confidence="0.984399" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999861">
We wish to thank Thomas Lavergne and Alexan-
dre Allauzen for early feedback and for providing
us with the partially observed CRF implementa-
tion. We also thank the anonymous reviewers for
their helpful comments.
</bodyText>
<sectionHeader confidence="0.99853" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.969383">
Ezra Black, Fred Jelinek, John Lafferty, David M.
Magerman, Robert Mercer, and Salim Roukos.
1992. Towards history-based grammars: Using
</reference>
<footnote confidence="0.629011">
10http://nlp.lsi.upc.edu/freeling/
</footnote>
<page confidence="0.912921">
1783
</page>
<reference confidence="0.991845481818182">
richer models for probabilistic parsing. In Proceed-
ings of the Workshop on Speech and Natural Lan-
guage, HLT ’91, pages 134–139, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Antoine Bordes, Nicolas Usunier, and Jason Weston.
2010. Label ranking under ambiguous supervision
for learning semantic correspondences. In ICML,
pages 103–110.
Jürgen Broschart. 2009. Why Tongan does it differ-
ently: Categorial distinctions in a language without
nouns and verbs. Linguistic Typology, 1:123–166,
10.
Timothee Cour, Ben Sapp, and Ben Taskar. 2011.
Learning from partial labels. Journal of Machine
Learning Research, 12:1501–1536, July.
Dipanjan Das and Slav Petrov. 2011. Unsupervised
part-of-speech tagging with bilingual graph-based
projections. In Proceedings of the 49th Annual
Meeting of the Association for Computational Lin-
guistics: Human Language Technologies - Volume
1, HLT ’11, pages 600–609, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Hal Daumé, III and Daniel Marcu. 2005. Learning
as search optimization: Approximate large margin
methods for structured prediction. In Proceedings
of the 22Nd International Conference on Machine
Learning, ICML ’05, pages 169–176, New York,
NY, USA. ACM.
Nicholas Evans and Stephen C. Levinson. 2009. The
myth of language universals: Language diversity
and its importance for cognitive science. Behavioral
and Brain Sciences, 32:429–448, 10.
Kuzman Ganchev and Dipanjan Das. 2013. Cross-
lingual discriminative learning of sequence models
with posterior regularization. In Proceedings of the
2013 Conference on Empirical Methods in Natu-
ral Language Processing, pages 1996–2006, Seattle,
Washington, USA, October. Association for Compu-
tational Linguistics.
Kuzman Ganchev, Jennifer Gillenwater, and Ben
Taskar. 2009. Dependency grammar induction
via bitext projection constraints. In Proceedings of
the Joint Conference of the 47th Annual Meeting of
the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP:
Volume 1 - Volume 1, ACL ’09, pages 369–377,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara
Cabezas, and Okan Kolak. 2005. Bootstrapping
parsers via syntactic projection across parallel texts.
Nat. Lang. Eng., 11(3):311–325, September.
Sungchul Kim, Kristina Toutanova, and Hwanjo Yu.
2012. Multilingual named entity recognition using
parallel data and metadata from wikipedia. In Pro-
ceedings of the 50th Annual Meeting of the Associ-
ation for Computational Linguistics: Long Papers
- Volume 1, ACL ’12, pages 694–702, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Mikhail Kozhevnikov and Ivan Titov. 2013. Cross-
lingual transfer of semantic role labeling models.
In Proceedings of the 51st Annual Meeting of the
Association for Computational Linguistics (Volume
1: Long Papers), pages 1190–1200, Sofia, Bulgaria,
August. Association for Computational Linguistics.
Shen Li, João V. Graça, and Ben Taskar. 2012. Wiki-ly
supervised part-of-speech tagging. In Proceedings
of the 2012 Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning, EMNLP-CoNLL ’12,
pages 1389–1398, Stroudsburg, PA, USA. Associa-
tion for Computational Linguistics.
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuz-
man Ganchev, Keith Hall, Slav Petrov, Hao
Zhang, Oscar Täckström, Claudia Bedini, Núria
Bertomeu Castelló, and Jungmee Lee. 2013. Uni-
versal dependency annotation for multilingual pars-
ing. In Proceedings of the 51st Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 92–97, Sofia, Bulgaria,
August. Association for Computational Linguistics.
Sebastian Padó and Mirella Lapata. 2009. Cross-
lingual annotation projection of semantic roles. J.
Artif. Int. Res., 36(1):307–340, September.
Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012.
A universal part-of-speech tagset. In Nicoletta Cal-
zolari (Conference Chair), Khalid Choukri, Thierry
Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard,
Joseph Mariani, Jan Odijk, and Stelios Piperidis, ed-
itors, Proceedings of the Eight International Con-
ference on Language Resources and Evaluation
(LREC’12), Istanbul, Turkey, may. European Lan-
guage Resources Association (ELRA).
Stéphane Ross and Drew Bagnell. 2010. Efficient re-
ductions for imitation learning. In AISTATS, pages
661–668.
Yoshimasa Tsuruoka, Yusuke Miyao, and Jun’ichi
Kazama. 2011. Learning with lookahead: Can
history-based models rival globally optimized mod-
els? In Proceedings of the Fifteenth Conference on
Computational Natural Language Learning, pages
238–246, Portland, Oregon, USA, June. Association
for Computational Linguistics.
Oscar Täckström, Dipanjan Das, Slav Petrov, Ryan
McDonald, and Joakim Nivre. 2013. Token and
type constraints for cross-lingual part-of-speech tag-
ging. Transactions of the Association for Computa-
tional Linguistics, 1:1–12.
</reference>
<page confidence="0.869446">
1784
</page>
<reference confidence="0.999019333333333">
Lonneke van der Plas, Marianna Apidianaki, and Chen-
hua Chen. 2014. Global methods for cross-lingual
semantic role and predicate labelling. In Proceed-
ings of COLING 2014, the 25th International Con-
ference on Computational Linguistics: Technical
Papers, pages 1279–1290, Dublin, Ireland, August.
Dublin City University and Association for Compu-
tational Linguistics.
Mengqiu Wang and Christopher D. Manning. 2014.
Cross-lingual projected expectation regularization
for weakly supervised learning. Transactions of the
ACL, 2:55–66, February.
David Yarowsky, Grace Ngai, and Richard Wicen-
towski. 2001. Inducing multilingual text analy-
sis tools via robust projection across aligned cor-
pora. In Proceedings of the First International Con-
ference on Human Language Technology Research,
HLT ’01, pages 1–8, Stroudsburg, PA, USA. Asso-
ciation for Computational Linguistics.
Yuan Zhang, Roi Reichart, Regina Barzilay, and Amir
Globerson. 2012. Learning to map into a univer-
sal pos tagset. In Proceedings of the 2012 Joint
Conference on Empirical Methods in Natural Lan-
guage Processing and Computational Natural Lan-
guage Learning, EMNLP-CoNLL ’12, pages 1368–
1378, Stroudsburg, PA, USA. Association for Com-
putational Linguistics.
</reference>
<page confidence="0.992363">
1785
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.903113">
<title confidence="0.998331">Cross-Lingual Part-of-Speech Tagging through Ambiguous Learning</title>
<author confidence="0.995114">Guillaume Wisniewski Nicolas Pécheux Souhir Gahbiche-Braham François Yvon</author>
<affiliation confidence="0.983545">Université Paris</affiliation>
<address confidence="0.997708">91403 ORSAY CEDEX,</address>
<email confidence="0.992164">wisniews@limsi.fr</email>
<email confidence="0.992164">pecheux@limsi.fr</email>
<email confidence="0.992164">souhir@limsi.fr</email>
<email confidence="0.992164">yvon@limsi.fr</email>
<abstract confidence="0.993815090909091">When Part-of-Speech annotated data is e.g. for under-resourced guages, one can turn to cross-lingual transfer and crawled dictionaries to collect partially supervised data. We cast this probin the framework of learnshow how to learn an accurate history-based model. Experiments on ten languages show significant improvements over prior state of the art performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ezra Black</author>
<author>Fred Jelinek</author>
<author>John Lafferty</author>
<author>David M Magerman</author>
<author>Robert Mercer</author>
<author>Salim Roukos</author>
</authors>
<title>Towards history-based grammars: Using richer models for probabilistic parsing.</title>
<date>1992</date>
<booktitle>In Proceedings of the Workshop on Speech and Natural Language, HLT ’91,</booktitle>
<pages>134--139</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="7964" citStr="Black et al., 1992" startWordPosition="1274" endWordPosition="1277">eby providing a full (yet noisy) supervision. As shown in Table 1, token and type constraints complement each other effectively and greatly reduce label ambiguity. However, the transfer method sketched above associates each target word with a set of possible labels, of which only one is true. This situation is less favorable than standard supervised learning in which one unique gold label is available for each occurrence. We describe in the following section how to learn from this ambiguous supervision information. 3 Modeling Sequences under Ambiguous Supervision We use a history-based model (Black et al., 1992) with a LaSO-like training method (Daumé and Marcu, 2005). History-based models reduce structured prediction to a sequence of multi-class classification problems. The prediction of a complex structure (here, a sequence of POS tags) is thus modeled as a sequential decision problem: at each (2013) filter the tag distribution with a threshold to build the projected type constraints. 3If the intersection is empty we use the constraints from Wiktionary first, if also empty, the projected constraints then, and by default the whole tag set. 1780 position in the sequence, a multiclass classifier is us</context>
</contexts>
<marker>Black, Jelinek, Lafferty, Magerman, Mercer, Roukos, 1992</marker>
<rawString>Ezra Black, Fred Jelinek, John Lafferty, David M. Magerman, Robert Mercer, and Salim Roukos. 1992. Towards history-based grammars: Using richer models for probabilistic parsing. In Proceedings of the Workshop on Speech and Natural Language, HLT ’91, pages 134–139, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Bordes</author>
<author>Nicolas Usunier</author>
<author>Jason Weston</author>
</authors>
<title>Label ranking under ambiguous supervision for learning semantic correspondences.</title>
<date>2010</date>
<booktitle>In ICML,</booktitle>
<pages>103--110</pages>
<contexts>
<context position="2781" citStr="Bordes et al., 2010" startWordPosition="423" endWordPosition="426"> (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Manning, 2014), the combination of alignment-based POS transfer with additional information sources such as dictionaries (Li et al., 2012; Täckström et al., 2013) (Section 2), or even the simultaneous use of both techniques (Ganchev and Das, 2013). In this paper, we reproduce the weakly supervised setting of Täckström et al. (2013). By recasting this setting in the framework of ambiguous learning (Bordes et al., 2010; Cour et al., 2011) (Section 3), we propose an alternative learning methodology and show that it improves the state of the art performance on a large array of languages (Section 4). Our analysis of the remaining errors suggests that in cross-lingual settings, improvements of error rates can have multiple causes and should be looked at with great care (Section 4.2). All tools and resources used in this study are available at http://perso.limsi.fr/ wisniews/ambiguous. 2 Projecting Labels across Aligned Corpora Projecting POS information across languages relies on a rather strong assumption that</context>
<context position="10097" citStr="Bordes et al. (2010)" startWordPosition="1639" endWordPosition="1642">asks in NLP (Tsuruoka et al., 2011). The training procedure, sketched in Algorithm 1, consists in performing inference on each input sentence and correcting the weight vector each time a wrong decision is made. Importantly (Ross and Bagnell, 2010), the history used during training has to be made of the previous predicted labels so that the training samples reflect the fact that the history will be imperfectly known at test time. This reduction of sequence labeling to multiclass classification allows us to learn a sequence model in an ambiguous setting by building on the theoretical results of Bordes et al. (2010) and Cour et al. (2011). The decision about the correctness of a prediction and the weight updates can be adapted to the amount of supervision information that is available. Full Supervision In a fully supervised setting, the correct label is known for each word token: a decision is thus considered wrong when this gold label is not predicted. In this case, a standard perceptron update is performed: wt+1 ← wt−0 (x, i, y∗i , hi)+0 (x, i, ˆyi, hi) (2) where y∗i and ˆyi are the predicted and the gold label, respectively. This update is a stochastic gradient step that increases the score of the gol</context>
</contexts>
<marker>Bordes, Usunier, Weston, 2010</marker>
<rawString>Antoine Bordes, Nicolas Usunier, and Jason Weston. 2010. Label ranking under ambiguous supervision for learning semantic correspondences. In ICML, pages 103–110.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jürgen Broschart</author>
</authors>
<title>Why Tongan does it differently: Categorial distinctions in a language without nouns and verbs. Linguistic Typology,</title>
<date>2009</date>
<pages>1--123</pages>
<contexts>
<context position="3577" citStr="Broschart, 2009" startWordPosition="550" endWordPosition="551">). Our analysis of the remaining errors suggests that in cross-lingual settings, improvements of error rates can have multiple causes and should be looked at with great care (Section 4.2). All tools and resources used in this study are available at http://perso.limsi.fr/ wisniews/ambiguous. 2 Projecting Labels across Aligned Corpora Projecting POS information across languages relies on a rather strong assumption that morphosyntactic categories in the source language can be directly related to the categories in the target language, which might not always be warranted (Evans and Levinson, 2009; Broschart, 2009). The universal reduced POS tagset proposed by Petrov et al. (2012) defines an operational, albeit rather empirical, ground to perform this mapping. It is made of the following 12 categories: NOUN (nouns), VERB (verbs), ADJ (ad1779 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1779–1785, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics ar cs de el es fi fr id it sv % of test covered tokens (type) 83.2 93.2 95.6 97.4 96.7 83.0 98.3 90.5 95.8 95.3 % of test correctly covered token (type) 72.9 94.2 93.7 92.9</context>
</contexts>
<marker>Broschart, 2009</marker>
<rawString>Jürgen Broschart. 2009. Why Tongan does it differently: Categorial distinctions in a language without nouns and verbs. Linguistic Typology, 1:123–166, 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothee Cour</author>
<author>Ben Sapp</author>
<author>Ben Taskar</author>
</authors>
<title>Learning from partial labels.</title>
<date>2011</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>12--1501</pages>
<contexts>
<context position="2801" citStr="Cour et al., 2011" startWordPosition="427" endWordPosition="430">are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Manning, 2014), the combination of alignment-based POS transfer with additional information sources such as dictionaries (Li et al., 2012; Täckström et al., 2013) (Section 2), or even the simultaneous use of both techniques (Ganchev and Das, 2013). In this paper, we reproduce the weakly supervised setting of Täckström et al. (2013). By recasting this setting in the framework of ambiguous learning (Bordes et al., 2010; Cour et al., 2011) (Section 3), we propose an alternative learning methodology and show that it improves the state of the art performance on a large array of languages (Section 4). Our analysis of the remaining errors suggests that in cross-lingual settings, improvements of error rates can have multiple causes and should be looked at with great care (Section 4.2). All tools and resources used in this study are available at http://perso.limsi.fr/ wisniews/ambiguous. 2 Projecting Labels across Aligned Corpora Projecting POS information across languages relies on a rather strong assumption that morphosyntactic cat</context>
<context position="10120" citStr="Cour et al. (2011)" startWordPosition="1644" endWordPosition="1647">al., 2011). The training procedure, sketched in Algorithm 1, consists in performing inference on each input sentence and correcting the weight vector each time a wrong decision is made. Importantly (Ross and Bagnell, 2010), the history used during training has to be made of the previous predicted labels so that the training samples reflect the fact that the history will be imperfectly known at test time. This reduction of sequence labeling to multiclass classification allows us to learn a sequence model in an ambiguous setting by building on the theoretical results of Bordes et al. (2010) and Cour et al. (2011). The decision about the correctness of a prediction and the weight updates can be adapted to the amount of supervision information that is available. Full Supervision In a fully supervised setting, the correct label is known for each word token: a decision is thus considered wrong when this gold label is not predicted. In this case, a standard perceptron update is performed: wt+1 ← wt−0 (x, i, y∗i , hi)+0 (x, i, ˆyi, hi) (2) where y∗i and ˆyi are the predicted and the gold label, respectively. This update is a stochastic gradient step that increases the score of the gold label while decreasin</context>
</contexts>
<marker>Cour, Sapp, Taskar, 2011</marker>
<rawString>Timothee Cour, Ben Sapp, and Ben Taskar. 2011. Learning from partial labels. Journal of Machine Learning Research, 12:1501–1536, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
</authors>
<title>Unsupervised part-of-speech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>600--609</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="5737" citStr="Das and Petrov, 2011" startWordPosition="906" endWordPosition="909"> labels have been chosen for their stability across languages and for their usefulness in various multilingual applications. In the rest of this work, all annotations are mapped to this universal tagset. Transfer-based methods have shown to be very effective, even if projected labels only deliver a noisy supervision, due to tagging (of the source language) and other alignment errors (Yarowsky et al., 2001). While this uncertainty can be addressed in several ways, recent works have proposed to combine projected labels with monolingual information in order to filter out invalid label sequences (Das and Petrov, 2011; Täckstr6m et al., 2013). In this work we follow Täckstr6m et al. (2013) and use two families of constraints: Token constraints rely on word alignments to project labels of source words to target words through alignment links. Table 1 shows that, dependening on the language, only 50−80% of the target tokens would benefit from label transfer. Type constraints rely on a tag dictionary to define the set of possible tags for each word type. Type constraints reduce the possible labels for a given word and help filtering out crosslingual transfer errors (up to 20%, as shown in Table 1). As in (Täck</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>Dipanjan Das and Slav Petrov. 2011. Unsupervised part-of-speech tagging with bilingual graph-based projections. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 600–609, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daumé</author>
<author>Daniel Marcu</author>
</authors>
<title>Learning as search optimization: Approximate large margin methods for structured prediction.</title>
<date>2005</date>
<booktitle>In Proceedings of the 22Nd International Conference on Machine Learning, ICML ’05,</booktitle>
<pages>169--176</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="8021" citStr="Daumé and Marcu, 2005" startWordPosition="1283" endWordPosition="1286"> in Table 1, token and type constraints complement each other effectively and greatly reduce label ambiguity. However, the transfer method sketched above associates each target word with a set of possible labels, of which only one is true. This situation is less favorable than standard supervised learning in which one unique gold label is available for each occurrence. We describe in the following section how to learn from this ambiguous supervision information. 3 Modeling Sequences under Ambiguous Supervision We use a history-based model (Black et al., 1992) with a LaSO-like training method (Daumé and Marcu, 2005). History-based models reduce structured prediction to a sequence of multi-class classification problems. The prediction of a complex structure (here, a sequence of POS tags) is thus modeled as a sequential decision problem: at each (2013) filter the tag distribution with a threshold to build the projected type constraints. 3If the intersection is empty we use the constraints from Wiktionary first, if also empty, the projected constraints then, and by default the whole tag set. 1780 position in the sequence, a multiclass classifier is used to make a decision, using features that describe both </context>
</contexts>
<marker>Daumé, Marcu, 2005</marker>
<rawString>Hal Daumé, III and Daniel Marcu. 2005. Learning as search optimization: Approximate large margin methods for structured prediction. In Proceedings of the 22Nd International Conference on Machine Learning, ICML ’05, pages 169–176, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Evans</author>
<author>Stephen C Levinson</author>
</authors>
<title>The myth of language universals: Language diversity and its importance for cognitive science. Behavioral and Brain Sciences,</title>
<date>2009</date>
<pages>32--429</pages>
<contexts>
<context position="3559" citStr="Evans and Levinson, 2009" startWordPosition="546" endWordPosition="549">ay of languages (Section 4). Our analysis of the remaining errors suggests that in cross-lingual settings, improvements of error rates can have multiple causes and should be looked at with great care (Section 4.2). All tools and resources used in this study are available at http://perso.limsi.fr/ wisniews/ambiguous. 2 Projecting Labels across Aligned Corpora Projecting POS information across languages relies on a rather strong assumption that morphosyntactic categories in the source language can be directly related to the categories in the target language, which might not always be warranted (Evans and Levinson, 2009; Broschart, 2009). The universal reduced POS tagset proposed by Petrov et al. (2012) defines an operational, albeit rather empirical, ground to perform this mapping. It is made of the following 12 categories: NOUN (nouns), VERB (verbs), ADJ (ad1779 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1779–1785, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics ar cs de el es fi fr id it sv % of test covered tokens (type) 83.2 93.2 95.6 97.4 96.7 83.0 98.3 90.5 95.8 95.3 % of test correctly covered token (type) 7</context>
</contexts>
<marker>Evans, Levinson, 2009</marker>
<rawString>Nicholas Evans and Stephen C. Levinson. 2009. The myth of language universals: Language diversity and its importance for cognitive science. Behavioral and Brain Sciences, 32:429–448, 10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Dipanjan Das</author>
</authors>
<title>Crosslingual discriminative learning of sequence models with posterior regularization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1996--2006</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="2608" citStr="Ganchev and Das, 2013" startWordPosition="393" endWordPosition="396">ssue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Manning, 2014), the combination of alignment-based POS transfer with additional information sources such as dictionaries (Li et al., 2012; Täckström et al., 2013) (Section 2), or even the simultaneous use of both techniques (Ganchev and Das, 2013). In this paper, we reproduce the weakly supervised setting of Täckström et al. (2013). By recasting this setting in the framework of ambiguous learning (Bordes et al., 2010; Cour et al., 2011) (Section 3), we propose an alternative learning methodology and show that it improves the state of the art performance on a large array of languages (Section 4). Our analysis of the remaining errors suggests that in cross-lingual settings, improvements of error rates can have multiple causes and should be looked at with great care (Section 4.2). All tools and resources used in this study are available a</context>
<context position="12850" citStr="Ganchev and Das, 2013" startWordPosition="2142" endWordPosition="2145">eriments we use English as the source language. Parallel sentences5 are aligned with the standard 4Resources considered in the related works are not freely available, which prevents us from presenting a more complete comparison. 5All resources and features used in our experiments are thoroughly documented in the supplementary material. 1781 ar cs de el es fi fr id it sv HBAL 27.9 10.4 8.8 8.1 8.2 13.3 10.2 11.3 9.1 10.1 Partially observed CRF 33.9 11.6 12.2 10.9 10.7 12.9 11.6 16.3 10.4 11.6 HBSL — 1.5 5.0 — 2.4 5.9 3.5 4.8 2.8 3.8 HBAL + matched POS 24.1 7.6 8.0 7.3 7.4 12.2 7.4 9.8 8.3 8.8 (Ganchev and Das, 2013) 49.9 19.3 9.6 9.4 12.8 — 12.5 — 10.1 10.8 (Täckström et al., 2013) — 18.9 9.5 10.5 10.9 — 11.6 — 10.2 11.1 (Li et al., 2012) — — 14.2 20.8 13.6 — — — 13.5 13.9 Table 2: Error rate (in %) achieved by the method described in Sec. 3 trained in an ambiguous (HBAL) or in a supervised setting (HBSL), a partially observed CRF and different state-of-the-art results. MOSES pipeline, using the intersection heuristic that only retains the most reliable alignment links. The English side of the bitext is tagged using a standard linear CRF trained on the Penn Treebank. Tags are then transferred to the targ</context>
</contexts>
<marker>Ganchev, Das, 2013</marker>
<rawString>Kuzman Ganchev and Dipanjan Das. 2013. Crosslingual discriminative learning of sequence models with posterior regularization. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 1996–2006, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuzman Ganchev</author>
<author>Jennifer Gillenwater</author>
<author>Ben Taskar</author>
</authors>
<title>Dependency grammar induction via bitext projection constraints.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ’09,</booktitle>
<pages>369--377</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1684" citStr="Ganchev et al., 2009" startWordPosition="249" endWordPosition="252">ly annotated data. Several attempts have recently been made to mitigate the lack of annotated corpora using parallel data pairing a (source) text in a resource-rich language with its counterpart in a less-resourced language. By transferring labels from the source to the target, it becomes possible to obtain noisy, yet useful, annotations that can be used to train a model for the target language in a weakly supervised manner. This research trend was initiated by Yarowsky et al. (2001), who consider the transfer of POS and other syntactic information, and further developed in (Hwa et al., 2005; Ganchev et al., 2009) for syntactic dependencies, in (Padó and Lapata, 2009; Kozhevnikov and Titov, 2013; van der Plas et al., 2014) for semantic role labeling and in (Kim et al., 2012) for named-entity recognition, to name a few. Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration</context>
</contexts>
<marker>Ganchev, Gillenwater, Taskar, 2009</marker>
<rawString>Kuzman Ganchev, Jennifer Gillenwater, and Ben Taskar. 2009. Dependency grammar induction via bitext projection constraints. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 1 - Volume 1, ACL ’09, pages 369–377, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
<author>Philip Resnik</author>
<author>Amy Weinberg</author>
<author>Clara Cabezas</author>
<author>Okan Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts.</title>
<date>2005</date>
<journal>Nat. Lang. Eng.,</journal>
<volume>11</volume>
<issue>3</issue>
<contexts>
<context position="1661" citStr="Hwa et al., 2005" startWordPosition="245" endWordPosition="248">notated or partially annotated data. Several attempts have recently been made to mitigate the lack of annotated corpora using parallel data pairing a (source) text in a resource-rich language with its counterpart in a less-resourced language. By transferring labels from the source to the target, it becomes possible to obtain noisy, yet useful, annotations that can be used to train a model for the target language in a weakly supervised manner. This research trend was initiated by Yarowsky et al. (2001), who consider the transfer of POS and other syntactic information, and further developed in (Hwa et al., 2005; Ganchev et al., 2009) for syntactic dependencies, in (Padó and Lapata, 2009; Kozhevnikov and Titov, 2013; van der Plas et al., 2014) for semantic role labeling and in (Kim et al., 2012) for named-entity recognition, to name a few. Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works c</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>Rebecca Hwa, Philip Resnik, Amy Weinberg, Clara Cabezas, and Okan Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Nat. Lang. Eng., 11(3):311–325, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungchul Kim</author>
<author>Kristina Toutanova</author>
<author>Hwanjo Yu</author>
</authors>
<title>Multilingual named entity recognition using parallel data and metadata from wikipedia.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12,</booktitle>
<pages>694--702</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1848" citStr="Kim et al., 2012" startWordPosition="278" endWordPosition="281">guage with its counterpart in a less-resourced language. By transferring labels from the source to the target, it becomes possible to obtain noisy, yet useful, annotations that can be used to train a model for the target language in a weakly supervised manner. This research trend was initiated by Yarowsky et al. (2001), who consider the transfer of POS and other syntactic information, and further developed in (Hwa et al., 2005; Ganchev et al., 2009) for syntactic dependencies, in (Padó and Lapata, 2009; Kozhevnikov and Titov, 2013; van der Plas et al., 2014) for semantic role labeling and in (Kim et al., 2012) for named-entity recognition, to name a few. Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Manning, 2014), the combination of alignment-based POS transfer with additional informa</context>
</contexts>
<marker>Kim, Toutanova, Yu, 2012</marker>
<rawString>Sungchul Kim, Kristina Toutanova, and Hwanjo Yu. 2012. Multilingual named entity recognition using parallel data and metadata from wikipedia. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers - Volume 1, ACL ’12, pages 694–702, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mikhail Kozhevnikov</author>
<author>Ivan Titov</author>
</authors>
<title>Crosslingual transfer of semantic role labeling models.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>1190--1200</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="1767" citStr="Kozhevnikov and Titov, 2013" startWordPosition="261" endWordPosition="264">ack of annotated corpora using parallel data pairing a (source) text in a resource-rich language with its counterpart in a less-resourced language. By transferring labels from the source to the target, it becomes possible to obtain noisy, yet useful, annotations that can be used to train a model for the target language in a weakly supervised manner. This research trend was initiated by Yarowsky et al. (2001), who consider the transfer of POS and other syntactic information, and further developed in (Hwa et al., 2005; Ganchev et al., 2009) for syntactic dependencies, in (Padó and Lapata, 2009; Kozhevnikov and Titov, 2013; van der Plas et al., 2014) for semantic role labeling and in (Kim et al., 2012) for named-entity recognition, to name a few. Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Mannin</context>
</contexts>
<marker>Kozhevnikov, Titov, 2013</marker>
<rawString>Mikhail Kozhevnikov and Ivan Titov. 2013. Crosslingual transfer of semantic role labeling models. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 1190–1200, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shen Li</author>
<author>João V Graça</author>
<author>Ben Taskar</author>
</authors>
<title>Wiki-ly supervised part-of-speech tagging.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12,</booktitle>
<pages>1389--1398</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2498" citStr="Li et al., 2012" startWordPosition="375" endWordPosition="378">ame a few. Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Manning, 2014), the combination of alignment-based POS transfer with additional information sources such as dictionaries (Li et al., 2012; Täckström et al., 2013) (Section 2), or even the simultaneous use of both techniques (Ganchev and Das, 2013). In this paper, we reproduce the weakly supervised setting of Täckström et al. (2013). By recasting this setting in the framework of ambiguous learning (Bordes et al., 2010; Cour et al., 2011) (Section 3), we propose an alternative learning methodology and show that it improves the state of the art performance on a large array of languages (Section 4). Our analysis of the remaining errors suggests that in cross-lingual settings, improvements of error rates can have multiple causes and</context>
<context position="6494" citStr="Li et al., 2012" startWordPosition="1038" endWordPosition="1041"> alignments to project labels of source words to target words through alignment links. Table 1 shows that, dependening on the language, only 50−80% of the target tokens would benefit from label transfer. Type constraints rely on a tag dictionary to define the set of possible tags for each word type. Type constraints reduce the possible labels for a given word and help filtering out crosslingual transfer errors (up to 20%, as shown in Table 1). As in (Täckstr6m et al., 2013), we consider two different dictionaries. The first one is extracted automatically from Wiktionary,1 using the method of (Li et al., 2012). The second tag dictionary is built by using for each word the two most frequently projected POS labels from the training data.2 In contrast to Täckstr6m et al. 1http://www.wiktionary.org/ 2This heuristic is similar to the way Täckstr6m et al. (2013) we use the intersection3 of the two type constraints instead of their union. Table 1 shows the precision and recall of the resulting constraints on the test data. These two information sources are merged according to the rules of Täckstr6m et al. (2013). These rules assume that type constraints are more reliable than token constraints and should </context>
<context position="12975" citStr="Li et al., 2012" startWordPosition="2170" endWordPosition="2173">ted works are not freely available, which prevents us from presenting a more complete comparison. 5All resources and features used in our experiments are thoroughly documented in the supplementary material. 1781 ar cs de el es fi fr id it sv HBAL 27.9 10.4 8.8 8.1 8.2 13.3 10.2 11.3 9.1 10.1 Partially observed CRF 33.9 11.6 12.2 10.9 10.7 12.9 11.6 16.3 10.4 11.6 HBSL — 1.5 5.0 — 2.4 5.9 3.5 4.8 2.8 3.8 HBAL + matched POS 24.1 7.6 8.0 7.3 7.4 12.2 7.4 9.8 8.3 8.8 (Ganchev and Das, 2013) 49.9 19.3 9.6 9.4 12.8 — 12.5 — 10.1 10.8 (Täckström et al., 2013) — 18.9 9.5 10.5 10.9 — 11.6 — 10.2 11.1 (Li et al., 2012) — — 14.2 20.8 13.6 — — — 13.5 13.9 Table 2: Error rate (in %) achieved by the method described in Sec. 3 trained in an ambiguous (HBAL) or in a supervised setting (HBSL), a partially observed CRF and different state-of-the-art results. MOSES pipeline, using the intersection heuristic that only retains the most reliable alignment links. The English side of the bitext is tagged using a standard linear CRF trained on the Penn Treebank. Tags are then transferred to the target language using the procedure described in Section 2. For each language, we train a tagger using the method described in Se</context>
</contexts>
<marker>Li, Graça, Taskar, 2012</marker>
<rawString>Shen Li, João V. Graça, and Ben Taskar. 2012. Wiki-ly supervised part-of-speech tagging. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12, pages 1389–1398, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
<author>Yvonne QuirmbachBrundage</author>
</authors>
<title>Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar Täckström, Claudia Bedini, Núria Bertomeu Castelló, and Jungmee Lee.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>92--97</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="14102" citStr="McDonald et al., 2013" startWordPosition="2369" endWordPosition="2372">e described in Section 2. For each language, we train a tagger using the method described in Section 3 with T = 100 000 iterations6 using a feature set similar to the one of Li et al. (2012) and Täckström et al. (2013). The baseline system is our reimplementation of the partially observed CRF model of Täckström et al. (2013). Evaluation is carried out on the test sets of treebanks for which manual gold tags are known. For Czech and Greek, we use the CoNLL’07 Shared Task on Dependency Parsing; for Arabic, the Arabic Treebank; and otherwise the data of the Universal Dependency Treebank Project (McDonald et al., 2013). Tagging performance is evaluated with the standard error rate. 4.1 Results Table 2 summarizes the performance achieved by our method trained in the ambiguous setting (HBAL) and by our re-implementation of the partially supervised CRF baseline. As an upper bound, we also report the score of our method when trained in a supervised (HBSL) settings considering the training part of the various treebanks, when it is available.7 For the sake of comparison, we also list the best scores of previous studies. Note, however, that a direct comparison with these results is not completely fair as these 6Pr</context>
</contexts>
<marker>McDonald, Nivre, QuirmbachBrundage, 2013</marker>
<rawString>Ryan McDonald, Joakim Nivre, Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar Täckström, Claudia Bedini, Núria Bertomeu Castelló, and Jungmee Lee. 2013. Universal dependency annotation for multilingual parsing. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 92–97, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Padó</author>
<author>Mirella Lapata</author>
</authors>
<title>Crosslingual annotation projection of semantic roles.</title>
<date>2009</date>
<journal>J. Artif. Int. Res.,</journal>
<volume>36</volume>
<issue>1</issue>
<contexts>
<context position="1738" citStr="Padó and Lapata, 2009" startWordPosition="257" endWordPosition="260"> made to mitigate the lack of annotated corpora using parallel data pairing a (source) text in a resource-rich language with its counterpart in a less-resourced language. By transferring labels from the source to the target, it becomes possible to obtain noisy, yet useful, annotations that can be used to train a model for the target language in a weakly supervised manner. This research trend was initiated by Yarowsky et al. (2001), who consider the transfer of POS and other syntactic information, and further developed in (Hwa et al., 2005; Ganchev et al., 2009) for syntactic dependencies, in (Padó and Lapata, 2009; Kozhevnikov and Titov, 2013; van der Plas et al., 2014) for semantic role labeling and in (Kim et al., 2012) for named-entity recognition, to name a few. Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularizatio</context>
</contexts>
<marker>Padó, Lapata, 2009</marker>
<rawString>Sebastian Padó and Mirella Lapata. 2009. Crosslingual annotation projection of semantic roles. J. Artif. Int. Res., 36(1):307–340, September.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Slav Petrov</author>
<author>Dipanjan Das</author>
<author>Ryan McDonald</author>
</authors>
<title>A universal part-of-speech tagset.</title>
<date>2012</date>
<booktitle>Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<editor>In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors,</editor>
<location>Istanbul, Turkey,</location>
<contexts>
<context position="3644" citStr="Petrov et al. (2012)" startWordPosition="560" endWordPosition="563">lingual settings, improvements of error rates can have multiple causes and should be looked at with great care (Section 4.2). All tools and resources used in this study are available at http://perso.limsi.fr/ wisniews/ambiguous. 2 Projecting Labels across Aligned Corpora Projecting POS information across languages relies on a rather strong assumption that morphosyntactic categories in the source language can be directly related to the categories in the target language, which might not always be warranted (Evans and Levinson, 2009; Broschart, 2009). The universal reduced POS tagset proposed by Petrov et al. (2012) defines an operational, albeit rather empirical, ground to perform this mapping. It is made of the following 12 categories: NOUN (nouns), VERB (verbs), ADJ (ad1779 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1779–1785, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics ar cs de el es fi fr id it sv % of test covered tokens (type) 83.2 93.2 95.6 97.4 96.7 83.0 98.3 90.5 95.8 95.3 % of test correctly covered token (type) 72.9 94.2 93.7 92.9 93.8 93.6 92.1 89.6 93.6 94.1 avg. number of labels per token (typ</context>
</contexts>
<marker>Petrov, Das, McDonald, 2012</marker>
<rawString>Slav Petrov, Dipanjan Das, and Ryan McDonald. 2012. A universal part-of-speech tagset. In Nicoletta Calzolari (Conference Chair), Khalid Choukri, Thierry Declerck, Mehmet U˘gur Do˘gan, Bente Maegaard, Joseph Mariani, Jan Odijk, and Stelios Piperidis, editors, Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stéphane Ross</author>
<author>Drew Bagnell</author>
</authors>
<title>Efficient reductions for imitation learning.</title>
<date>2010</date>
<booktitle>In AISTATS,</booktitle>
<pages>661--668</pages>
<contexts>
<context position="9724" citStr="Ross and Bagnell, 2010" startWordPosition="1575" endWordPosition="1578">., y∗i−1 the history of past decisions and 0 a joint feature map. Inference can therefore be seen as a greedy search in the space of the # {Y} n possible labelings of the input sequence. Trading off the global optimality of inference for additional flexibility in the design of features and long range dependencies between labels has proved useful for many sequence labeling tasks in NLP (Tsuruoka et al., 2011). The training procedure, sketched in Algorithm 1, consists in performing inference on each input sentence and correcting the weight vector each time a wrong decision is made. Importantly (Ross and Bagnell, 2010), the history used during training has to be made of the previous predicted labels so that the training samples reflect the fact that the history will be imperfectly known at test time. This reduction of sequence labeling to multiclass classification allows us to learn a sequence model in an ambiguous setting by building on the theoretical results of Bordes et al. (2010) and Cour et al. (2011). The decision about the correctness of a prediction and the weight updates can be adapted to the amount of supervision information that is available. Full Supervision In a fully supervised setting, the c</context>
</contexts>
<marker>Ross, Bagnell, 2010</marker>
<rawString>Stéphane Ross and Drew Bagnell. 2010. Efficient reductions for imitation learning. In AISTATS, pages 661–668.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Yusuke Miyao</author>
<author>Jun’ichi Kazama</author>
</authors>
<title>Learning with lookahead: Can history-based models rival globally optimized models?</title>
<date>2011</date>
<booktitle>In Proceedings of the Fifteenth Conference on Computational Natural Language Learning,</booktitle>
<pages>238--246</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="9512" citStr="Tsuruoka et al., 2011" startWordPosition="1541" endWordPosition="1544">he other using, for instance, a linear model: y∗i = arg max hw|0(x, i, y, hi)i (1) y∈Y where h·|·i is the standard dot product operation, y∗i the predicted label for position i, w the weight vector, hi = y∗1, ..., y∗i−1 the history of past decisions and 0 a joint feature map. Inference can therefore be seen as a greedy search in the space of the # {Y} n possible labelings of the input sequence. Trading off the global optimality of inference for additional flexibility in the design of features and long range dependencies between labels has proved useful for many sequence labeling tasks in NLP (Tsuruoka et al., 2011). The training procedure, sketched in Algorithm 1, consists in performing inference on each input sentence and correcting the weight vector each time a wrong decision is made. Importantly (Ross and Bagnell, 2010), the history used during training has to be made of the previous predicted labels so that the training samples reflect the fact that the history will be imperfectly known at test time. This reduction of sequence labeling to multiclass classification allows us to learn a sequence model in an ambiguous setting by building on the theoretical results of Bordes et al. (2010) and Cour et al</context>
</contexts>
<marker>Tsuruoka, Miyao, Kazama, 2011</marker>
<rawString>Yoshimasa Tsuruoka, Yusuke Miyao, and Jun’ichi Kazama. 2011. Learning with lookahead: Can history-based models rival globally optimized models? In Proceedings of the Fifteenth Conference on Computational Natural Language Learning, pages 238–246, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oscar Täckström</author>
<author>Dipanjan Das</author>
<author>Slav Petrov</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Token and type constraints for cross-lingual part-of-speech tagging.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<pages>1--1</pages>
<contexts>
<context position="2523" citStr="Täckström et al., 2013" startWordPosition="379" endWordPosition="382">ng that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Manning, 2014), the combination of alignment-based POS transfer with additional information sources such as dictionaries (Li et al., 2012; Täckström et al., 2013) (Section 2), or even the simultaneous use of both techniques (Ganchev and Das, 2013). In this paper, we reproduce the weakly supervised setting of Täckström et al. (2013). By recasting this setting in the framework of ambiguous learning (Bordes et al., 2010; Cour et al., 2011) (Section 3), we propose an alternative learning methodology and show that it improves the state of the art performance on a large array of languages (Section 4). Our analysis of the remaining errors suggests that in cross-lingual settings, improvements of error rates can have multiple causes and should be looked at with</context>
<context position="12917" citStr="Täckström et al., 2013" startWordPosition="2156" endWordPosition="2159">5 are aligned with the standard 4Resources considered in the related works are not freely available, which prevents us from presenting a more complete comparison. 5All resources and features used in our experiments are thoroughly documented in the supplementary material. 1781 ar cs de el es fi fr id it sv HBAL 27.9 10.4 8.8 8.1 8.2 13.3 10.2 11.3 9.1 10.1 Partially observed CRF 33.9 11.6 12.2 10.9 10.7 12.9 11.6 16.3 10.4 11.6 HBSL — 1.5 5.0 — 2.4 5.9 3.5 4.8 2.8 3.8 HBAL + matched POS 24.1 7.6 8.0 7.3 7.4 12.2 7.4 9.8 8.3 8.8 (Ganchev and Das, 2013) 49.9 19.3 9.6 9.4 12.8 — 12.5 — 10.1 10.8 (Täckström et al., 2013) — 18.9 9.5 10.5 10.9 — 11.6 — 10.2 11.1 (Li et al., 2012) — — 14.2 20.8 13.6 — — — 13.5 13.9 Table 2: Error rate (in %) achieved by the method described in Sec. 3 trained in an ambiguous (HBAL) or in a supervised setting (HBSL), a partially observed CRF and different state-of-the-art results. MOSES pipeline, using the intersection heuristic that only retains the most reliable alignment links. The English side of the bitext is tagged using a standard linear CRF trained on the Penn Treebank. Tags are then transferred to the target language using the procedure described in Section 2. For each la</context>
<context position="16576" citStr="Täckström et al., 2013" startWordPosition="2768" endWordPosition="2772"> conventions, which is an obvious source of mistakes. Second, and more importantly, many errors are caused by systematic differences between the test tags and the supervised tags (i.e. the English side of the bitext and Wiktionary). While some of these differences are linguistically well-justified and reflect fundamental differences in the language structure and usage, others seem to be merely due to arbitrary annotation conventions. For instance, in Greek, proper names are labeled 8The test sets are only the same for Czech, Greek and Swedish. 9The partially observed CRF is the best model in (Täckström et al., 2013) only for German (de), Greek (el) and Swedish (sv), and uses only type constraints extracted from Wiktionary. 1782 either as X (when they refer to a foreigner and are not transliterated) or as NOUN (in all other cases), while they are always labeled as NOUN in English. In French and in Greek, contractions of a preposition and a determiner such as ‘στο’ (‘σε το’, meaning ‘to the’) or ‘aux’ (‘à les’ also meaning ‘to the’) are labeled as ADP in the Universal Dependency Treebank but as DET in Wiktionary and are usually aligned with a determiner in the parallel corpora. In the Penn Treebank, quanti</context>
</contexts>
<marker>Täckström, Das, Petrov, McDonald, Nivre, 2013</marker>
<rawString>Oscar Täckström, Dipanjan Das, Slav Petrov, Ryan McDonald, and Joakim Nivre. 2013. Token and type constraints for cross-lingual part-of-speech tagging. Transactions of the Association for Computational Linguistics, 1:1–12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lonneke van der Plas</author>
<author>Marianna Apidianaki</author>
<author>Chenhua Chen</author>
</authors>
<title>Global methods for cross-lingual semantic role and predicate labelling.</title>
<date>2014</date>
<booktitle>In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers,</booktitle>
<pages>1279--1290</pages>
<institution>Dublin City University and Association for Computational Linguistics.</institution>
<location>Dublin, Ireland,</location>
<marker>van der Plas, Apidianaki, Chen, 2014</marker>
<rawString>Lonneke van der Plas, Marianna Apidianaki, and Chenhua Chen. 2014. Global methods for cross-lingual semantic role and predicate labelling. In Proceedings of COLING 2014, the 25th International Conference on Computational Linguistics: Technical Papers, pages 1279–1290, Dublin, Ireland, August. Dublin City University and Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mengqiu Wang</author>
<author>Christopher D Manning</author>
</authors>
<title>Cross-lingual projected expectation regularization for weakly supervised learning.</title>
<date>2014</date>
<journal>Transactions of the ACL,</journal>
<pages>2--55</pages>
<contexts>
<context position="2375" citStr="Wang and Manning, 2014" startWordPosition="357" endWordPosition="360">and Titov, 2013; van der Plas et al., 2014) for semantic role labeling and in (Kim et al., 2012) for named-entity recognition, to name a few. Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yarowsky et al. (2001) in which POS are directly transferred, subject to heuristic filtering rules, recent works consider the integration of softer constraints using expectation regularization techniques (Wang and Manning, 2014), the combination of alignment-based POS transfer with additional information sources such as dictionaries (Li et al., 2012; Täckström et al., 2013) (Section 2), or even the simultaneous use of both techniques (Ganchev and Das, 2013). In this paper, we reproduce the weakly supervised setting of Täckström et al. (2013). By recasting this setting in the framework of ambiguous learning (Bordes et al., 2010; Cour et al., 2011) (Section 3), we propose an alternative learning methodology and show that it improves the state of the art performance on a large array of languages (Section 4). Our analysi</context>
</contexts>
<marker>Wang, Manning, 2014</marker>
<rawString>Mengqiu Wang and Christopher D. Manning. 2014. Cross-lingual projected expectation regularization for weakly supervised learning. Transactions of the ACL, 2:55–66, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
<author>Grace Ngai</author>
<author>Richard Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the First International Conference on Human Language Technology Research, HLT ’01,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1551" citStr="Yarowsky et al. (2001)" startWordPosition="226" endWordPosition="229">plication domains and/or less-resourced languages, alternative ML techniques need to be designed to accommodate unannotated or partially annotated data. Several attempts have recently been made to mitigate the lack of annotated corpora using parallel data pairing a (source) text in a resource-rich language with its counterpart in a less-resourced language. By transferring labels from the source to the target, it becomes possible to obtain noisy, yet useful, annotations that can be used to train a model for the target language in a weakly supervised manner. This research trend was initiated by Yarowsky et al. (2001), who consider the transfer of POS and other syntactic information, and further developed in (Hwa et al., 2005; Ganchev et al., 2009) for syntactic dependencies, in (Padó and Lapata, 2009; Kozhevnikov and Titov, 2013; van der Plas et al., 2014) for semantic role labeling and in (Kim et al., 2012) for named-entity recognition, to name a few. Assuming that labels can actually be projected across languages, these techniques face the issue of extending standard supervised techniques with partial and/or uncertain labels in the presence of alignment noise. In comparison to the early approach of Yaro</context>
<context position="5526" citStr="Yarowsky et al., 2001" startWordPosition="870" endWordPosition="873"> PRON (pronouns), DET (determiners and articles), ADP (prepositions and postpositions), NUM (numerals), CONJ (conjunctions), PRT (particles), ‘.’ (punctuation marks) and X (a catch-all for other categories). These labels have been chosen for their stability across languages and for their usefulness in various multilingual applications. In the rest of this work, all annotations are mapped to this universal tagset. Transfer-based methods have shown to be very effective, even if projected labels only deliver a noisy supervision, due to tagging (of the source language) and other alignment errors (Yarowsky et al., 2001). While this uncertainty can be addressed in several ways, recent works have proposed to combine projected labels with monolingual information in order to filter out invalid label sequences (Das and Petrov, 2011; Täckstr6m et al., 2013). In this work we follow Täckstr6m et al. (2013) and use two families of constraints: Token constraints rely on word alignments to project labels of source words to target words through alignment links. Table 1 shows that, dependening on the language, only 50−80% of the target tokens would benefit from label transfer. Type constraints rely on a tag dictionary to</context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>David Yarowsky, Grace Ngai, and Richard Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of the First International Conference on Human Language Technology Research, HLT ’01, pages 1–8, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuan Zhang</author>
<author>Roi Reichart</author>
<author>Regina Barzilay</author>
<author>Amir Globerson</author>
</authors>
<title>Learning to map into a universal pos tagset.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12,</booktitle>
<pages>1368--1378</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="17866" citStr="Zhang et al., 2012" startWordPosition="2980" endWordPosition="2983">eterminer (‘a few years’, ‘a little parable’, ...) and labeled as ADJ; the corresponding Spanish constructions lack an article (‘mucho tempio’, ‘pocos años’, ...) and the quantifiers are therefore labeled as DET. Capturing such subtle differences is hardly possible without prior knowledge and specifically tailored features. This annotation mismatch problem is all the more important in settings like ours, that rely on several, independently designed, information sources, which follow contradictory annotation conventions and for which the mapping to the universal tagset is actually error-prone (Zhang et al., 2012). To illustrate this point, we ran three additional experiments to assess the impact of the train/test mismatch. We first designed a control experiment in which the type constraints were manually completed with the gold labels of the most frequent errors of HBAL. These errors generally concern function words and can be assumed to result from systematic differences in the annotations rather than prediction errors. For instance, for French the type constraints for ‘du’, ‘des’, ‘au’ and ‘aux’ were corrected from DET to ADP. The resulting model, denoted ‘HBAL + matched POS’ in Table 2, significant</context>
</contexts>
<marker>Zhang, Reichart, Barzilay, Globerson, 2012</marker>
<rawString>Yuan Zhang, Roi Reichart, Regina Barzilay, and Amir Globerson. 2012. Learning to map into a universal pos tagset. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, EMNLP-CoNLL ’12, pages 1368– 1378, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>