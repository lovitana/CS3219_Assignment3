<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000272">
<title confidence="0.999225">
Keystroke Patterns as Prosody in Digital Writings:
A Case Study with Deceptive Reviews and Essays
</title>
<author confidence="0.973864">
Yejin Choi
</author>
<affiliation confidence="0.9757525">
Computer Science &amp; Engineering
University of Washington
</affiliation>
<email confidence="0.987851">
yejin@cs.washington.edu
</email>
<author confidence="0.927858">
Ritwik Banerjee Song Feng Jun S. Kang
</author>
<affiliation confidence="0.8099285">
Computer Science
Stony Brook University
</affiliation>
<address confidence="0.667054">
{rbanerjee, songfeng, junkang}
</address>
<email confidence="0.992127">
@cs.stonybrook.edu
</email>
<sectionHeader confidence="0.99738" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999868416666667">
In this paper, we explore the use of keyboard
strokes as a means to access the real-time writ-
ing process of online authors, analogously to
prosody in speech analysis, in the context of
deception detection. We show that differences
in keystroke patterns like editing maneuvers
and duration of pauses can help distinguish be-
tween truthful and deceptive writing. Empiri-
cal results show that incorporating keystroke-
based features lead to improved performance
in deception detection in two different do-
mains: online reviews and essays.
</bodyText>
<sectionHeader confidence="0.999393" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999831604166666">
Due to the practical importance of detecting deceit, in-
terest in it is ancient, appearing in papyrus dated back
to 900 B.C. (Trovillo, 1939). In more recent years, sev-
eral studies have shown that the deceiver often exhibits
behavior that belies the content of communication, thus
providing cues of deception to an observer. These in-
clude linguistic (e.g., Newman et al. (2003), Hancock
et al. (2004)) as well as paralinguistic (e.g., Ekman et
al. (1991), DePaulo et al. (2003)) cues. Recognizing
deception, however, remains a hard task for humans,
who perform only marginally better than chance (Bond
and DePaulo, 2006; Ott et al., 2011).
Recent studies suggest that computers can be sur-
prisingly effective in this task, albeit in limited domains
such as product reviews. Prior research has employed
lexico-syntactic patterns (Ott et al., 2011; Feng et al.,
2012) as well as online user behavior (Fei et al., 2013;
Mukherjee et al., 2013). In this paper, we study the
effect of keystroke patterns for deception detection in
digital communications, which might be helpful in un-
derstanding the psychology of deception and help to-
ward trustful online communities. This allows us to in-
vestigate differences in the writing and revisional pro-
cesses of truthful and fake writers. Our work thus
shares intuition with HCI research linking keystroke
analysis to cognitive processes (Vizer et al., 2009; Epp
et al., 2011) and psychology research connecting cog-
nitive differences to deception (Ekman, 2003; Vrij et
al., 2006).
Recent research has shown that lying generally im-
poses a cognitive burden (e.g., McCornack (1997), Vrij
et al. (2006)) which increases in real-time scenar-
ios (Ekman, 2003). Cognitive burden has been known
to produce differences in keytroke features (Vizer et
al., 2009; Epp et al., 2011). Previous research has not,
however, directly investigated any quantitative connec-
tion between keystroke patterns and deceptive writing.
In this paper, we posit that cognitive burdens in
deception may lead to measurable characteristics in
keystroke patterns. Our contributions are as follows:
(1) introducing keystroke logs as an extended linguis-
tic signal capturing the real-time writing process (anal-
ogous to prosody in speech analysis) by measuring the
writing rate, pauses and revision rate. (2) showing
their empirical value in deception detection, (3) provid-
ing novel domain-specific insights into deceptive writ-
ing, and (4) releasing a new corpus of deception writ-
ings in new domains.1
</bodyText>
<sectionHeader confidence="0.999876" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9998634">
Prior research has focused mainly on using keystroke
traits as a behvioral biometric. Forsen et al. (1977)
first demonstrated that users can be distinguished by the
way they type their names. Subsequent work showed
that typing patterns are unique to individuals (Leggett
and Williams, 1988), and can be used for authentica-
tion (Cho et al., 2000; Bergadano et al., 2002) and in-
trusion detection (Killourhy and Maxion, 2009).
Keystroke pauses have been linked to linguistic pat-
terns in discourse (e.g. Matsuhashi (1981), van Hell et
al. (2008)) and regarded as indications of cognitive bur-
den (e.g., Johansson (2009), Zulkifli (2013)). In this pa-
per, we present the first empirical study that quantita-
tively measures the deception cues in real-time writing
process as manifested in keystroke logs.
</bodyText>
<sectionHeader confidence="0.994149" genericHeader="method">
3 Data Collection
</sectionHeader>
<bodyText confidence="0.999943428571429">
As discussed by Gokhman et al. (2012), the crowd-
sourcing approach to soliciting deceptive content sim-
ulates the real world of online deceptive content cre-
ators. We collected the data via Amazon Mechanical
Turk.2 Turkers were led to a separate website where
keylogging was enabled, and asked to write truthful
and deceptive texts (≥ 100 words) on one of three top-
</bodyText>
<footnote confidence="0.999981666666667">
1Available at http://www3.cs.stonybrook.
edu/˜junkang/keystroke/
2https://www.mturk.com/mturk
</footnote>
<page confidence="0.880597">
1469
</page>
<note confidence="0.649889">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1469–1473,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<figureCaption confidence="0.9833125">
Figure 1: Number of keystrokes corresponding to the three
types of edit patterns (E3): (a) use of arrow keys, (b) deletion
</figureCaption>
<subsectionHeader confidence="0.581279">
(Delete and Backspace) and (c) text selection with mouse.
</subsectionHeader>
<bodyText confidence="0.999819432432432">
ics: restaurant review, gay marriage and gun control.
Each Turker was required to agree to their typing be-
ing logged. Since copy/paste operations defeat our pur-
pose of studying keystrokes in the typing process, they
were disabled. This restriction also acts as a hindrance
to plagiarism. All texts were reviewed manually, and
those not meeting the requirements (due to the being
too short, plagiarized content, etc.) were disregarded.
Writing task design: The task was designed such
that each Turker wrote a pair of texts, one truthful and
one deceptive, on the same topic. For restaurant re-
views, they were asked to write a truthful review of
a restaurant they liked, and a deceptive review of a
restaurant they have never been to or did not like. For
the other two topics – ‘gun control’ and ‘gay marriage’
– we asked their opinion: support, neutral, or against.
Then, they were asked to write a truthful and a decep-
tive essay articulating, respectively, their actual opin-
ion and its opposite.3 The tasks further were divided
into two ‘flows’: writing the truthful text before the de-
ceptive one, and vice versa. Each Turker was assigned
only one flow, and was not allowed to participate in the
other. After completing this, each Turker was asked to
copy their own typing, i.e., re-type the two texts.
Finally, in order to get an idea of the cognitive bur-
den associated with truthful and deceptive writing, we
asked the Turkers which task was easier for them. Of
the 196 participants, 152 answered “truthful”, 40 an-
swered “deceptive” and only 4 opted for “not sure”.
What are logged: We deployed a keylogger to cap-
ture the mouse and keyboard events in the “text area”.
The events KeyUp, KeyDown and MouseUp, along with
the keycode and timestamp were logged.4 For the three
topics restaurant review, gay marriage and gun control
we obtained 1000, 800 and 800 texts, respectively.
In the remainder of this paper, kdn and kup denote
the KeyDown and KeyUp events for a key k. For any
</bodyText>
<footnote confidence="0.9921094">
3To prevent a change in opinion depending on task avail-
ability, Turkers were redirected to other tasks if their opinion
was neutral, or if we had enough essays of their opinion.
4Printable (e.g., alphanumeric characters) as well as non-
printable keystrokes like (e.g., ‘Backspace’), are logged.
</footnote>
<figureCaption confidence="0.984848">
Figure 2: Average normalized timespan S(e) for documents,
sentences, words and key presses. The top row considers only
the first text, while the bottom row considers both flows.
</figureCaption>
<bodyText confidence="0.983999">
event e, its timespan, i.e., the time interval between the
beginning and end of e, is denoted by δ(e).
</bodyText>
<sectionHeader confidence="0.996969" genericHeader="method">
4 Feature Design
</sectionHeader>
<bodyText confidence="0.999973352941177">
Keystroke logging enables the study of two types of in-
formation that go beyond conventional linguistic anal-
ysis. First, it captures editing processes (e.g., deletions,
insertions made by changing cursor position, etc.).
Second, it reveals the temporal aspect of text generation
(e.g., duration, latency). Our exploration of these fea-
tures and their application in deception detection is mo-
tivated by the similarities between text and speech gen-
eration. Editing patterns, for instance, can be viewed as
attempts to veil incoherence in deceptive writing and
temporal patterns like latency or pause can be treated
as analogous to disfiuency.
Different people, of course, have varying typing
skills, and some may type faster than others. In or-
der to control for this variation, we normalize all event
timespans δ(e) with respect to the corresponding event
timespan in the copy task: �δ(e) = δ(e)/δ(ecopy).
</bodyText>
<subsectionHeader confidence="0.997915">
4.1 Editing Patterns
</subsectionHeader>
<bodyText confidence="0.999075625">
In this work, we treat keys that are used only for edit-
ing as different from others. Text editing is done by
employing a small subset of available keys: deletion
keys (‘Backspace’ and ‘Delete’), arrow keys (+—, →,
T and t) and by using the mouse for text selection
(i.e., the ‘MouseUp’ event). The three types of editing
keystrokes are collectively denoted by
where E3 = (|DEL |, |MSELECT |, |ARROW|)
</bodyText>
<listItem confidence="0.810667666666667">
(i) |DEL |= number of deletion keystrokes
(ii) |MSELECT |=number of ‘MouseUp’ events, and
(iii) |ARROW |= number of arrow keystrokes
</listItem>
<bodyText confidence="0.7533495">
The editing differences between truthful and deceptive
writing across all three topics are shown in Fig. 1.
</bodyText>
<subsectionHeader confidence="0.986662">
4.2 Temporal Aspects
</subsectionHeader>
<bodyText confidence="0.999933666666667">
Each event is logged with a keycode and a timestamp.
In order to study the temporal aspects of digital writ-
ing, we calculate the timespan of different linguistic
</bodyText>
<figure confidence="0.974284756097561">
GayMarriage GunControl Restaurant GayMarriage GunControl Restaurant GayMarriage GunControl Restaurant
Frequency of editing keystrokes
10
5
0
ArrowKey
Deceptive Truthful
Del
MouseUp
GayMarriage GunControl Restaurant GayMarriage GunControl Restaurant GayMarriage GunControl Restaurant GayMarriage GunControl Restaurant
Time taken (rel. to copy task)
2.5
2.0
2.5
2.0
1.5
1.5
Document
Sentence
Deceptive Truthful
Word
Key Press
First−only
First+Second
1470
Topic Features Flow
First + Second First-only
tS(W) �δ(kprv + W)
D &gt; T T &gt; D D &gt; T T &gt; D
BoW 73.9 78.8
Restaurants BoW + T6 74.3 79.1
BoW + T6 + E3 74.6 80.3*
Gun Control
(Support)
Gun Control
(Oppose)
Gay Marriage
(Support)
Gay Marriage
(Oppose)
BoW 86.5 80.0
</figure>
<equation confidence="0.985621090909091">
BoW + T6 86.8 82.5*
BoW + T6 + E3 88.0§ 83.5*
BoW 88.5 88.0
BoW + T6 89.8 87.5
BoW + T6 + E3 90.8* 89.1
BoW 92.5 92.0
BoW + T6 93.8 92.5
BoW + T6 + E3 94.3* 92.0
BoW 84.5 86.5
BoW + T6 85.0 87.0
BoW + T6 + E3 85.3 86.8
</equation>
<figure confidence="0.989332666666667">
our best
if get
when well
were your
it’s fresh
quality not
dishes my
the one
i’ve had
on hat
they of
we other
friendly very
has love
at service
wait great
an really
go you
when one
quality other
even get
on service
by been
me their
has not
also with
go friendly
we great
had an
is our
at are
which really
from but
dishes favorite
or very
re about
</figure>
<tableCaption confidence="0.872428666666667">
Table 1: SVM classifier performance for truthful vs. de-
ceptive writing. Statistically significant improvements over
the baseline are marked * (p &lt; 0.05) and §(p &lt; 0.1).
</tableCaption>
<bodyText confidence="0.930443076923077">
E3 = (|DEL |, |MSELECT |, |ARROW|) denotes the editing
keystrokes, and T6 is the set of normalized timespans of
documents, words (plus preceding keystroke), all keystrokes,
spaces, non-whitespace keystrokes and inter-word intervals:
T6 = {�δ(D), 6(k), 6(SP), 6(-SP), 6(-W), 6(kprv + W)}
units such as words, sentences and even entire docu-
ments. Further, we separately inspect the timespans
of different parts of speech, function words and con-
tent words. In addition to event timespans, intervals
between successive events (e.g., inter-word and inter-
sentence pauses) and pauses preceding or succeeding
and event (e.g., time interval before and after a function
word) are measured as well.
</bodyText>
<sectionHeader confidence="0.997648" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999034">
This section describes our experimental setup and
presents insights based on the obtained results. All
classification experiments use 5-fold cross validation
with 80/20 division for training and testing. In addition
to experimenting on the entire dataset, we also sepa-
rately analyze the texts written first (of the two texts in
each ‘flow’). This additional step is taken in order to
eliminate the possibility of a text being primed by its
preceding text.
Deception cues in keystroke patterns: To empiri-
cally check whether keystroke features can help distin-
guish between truthful and deceptive writing, we de-
sign binary SVM classifiers.5 Unigrams with tf-idf
encoding is used as the baseline. The average baseline
accuracy across all topics is 82.58% when considering
both texts of a flow, and 83.62% when considering only
the first text of each flow. The better performance in the
latter possibly indicates that the second text of a flow
exhibits some amount of lexical priming with the first.
The high accuracy of the baseline is not surprising.
Previous work by Ott et al. (2011) reported similar per-
</bodyText>
<footnote confidence="0.773709">
5We use the LIBLINEAR (Fan et al., 2008) package.
is but
</footnote>
<tableCaption confidence="0.776297333333333">
which been
Table 2: Top 20 words in restaurant reviews with greatest
timespan difference between deceptive and truthful writing.
</tableCaption>
<bodyText confidence="0.999761818181818">
formance of unigram models. The focus of our work
is to explore the completely new feature space of ty-
pographic patterns in deception detection. We draw
motivation from parallels between the text generation
and speech generation processes. Prosodic concepts
such as speed, disfiuency and coherence can be real-
ized in typographic behavior by analyzing timestamp
of keystrokes, pauses and editing patterns, respectively.
Based on the differences in the temporal aspects of
keystrokes, we extract six timespan features to improve
this baseline. This set, denoted by T6, comprises of
</bodyText>
<equation confidence="0.979867875">
6(D) = timespan of entire document
�6(kprv+W) = average timespan of word plus pre-
ceding keystroke
6(k) = average keystroke timespan
�6(SP) = average timespan of spaces
�6(¬SP) = average timespan of non whitesp-
ace keystrokes
�6(¬W) = average interval between words.
</equation>
<bodyText confidence="0.997895875">
The improvements attained by adding T6 to the base-
line are shown in Table 1. Adding the edit patterns (E3)
(cf. § 4.1) further improves the performance (with the
exception of two cases) by 0.7–3.5%.
Writing speed, pauses and revisions: To study the
temporal aspect of language units across all topics,
we first consider all texts, and then restrict to only
the first of each ‘flow’. The timespan measurements
are presented in Fig. 2, showing the average duration
of typing documents, sentences, words and individual
keystrokes. The timespans are measured as the inter-
val between the first and the last keystrokes. The sen-
tence timespan, for instance, does not include the gap
between a sentence end and the first keystroke marking
the beginning of the next.
The sentence timespans for “gay marriage” and “gun
</bodyText>
<figure confidence="0.982119416666667">
would will
just here
1471
DT+TD
(a)
Timespan (ms)
170
160
150
140
130
120
Deceptive
Truthful
DT+TD
Deceptive
Truthful
(b)
550
Timespan (ms)
500
450
400
350
</figure>
<figureCaption confidence="0.999916">
Figure 3: Event timespans in restaurant reviews: (a) language units, and (b) language units including their preceding kdn.
</figureCaption>
<bodyText confidence="0.999585712328767">
control” are lower in truthful writing, even though the
document timespans are higher. This difference implies
that the writer is spending a longer period of time to
think before commencing the next sentence, but once
started, the actual typing proceeds rapidly.
Apart from restaurant reviews, truthful writers have
typed slower. This may be due to exercising better care
while expressing their honest opinion.
For restaurant reviews, the document, sentence and
word timespans are significantly higher in deceptive
writing. This, however, is not the case for documents
and words in the other two topics. We conjecture that
this is because deception is harder to write for prod-
uct reviews, due to their dependence on factual details.
Gun control and gay marriage, on the other hand, are
topics well discussed in media, and it is possible that
the writers are aware of the arguments that go against
their personal belief. The frequency of revisional oc-
currences (i.e., keys used for editing) shown in Fig. 1,
too, supports the thought that writing fake reviews may
be harder than adopting a fake stance on well-known
issues. Deceptive reviews exhibit a higher number of
revisions than truthful ones, but essays show the oppo-
site trend. Our findings align with previous studies (Ott
et al., 2011) which showed that deception cues are do-
main dependent.
Writing speed variations over word categories:
Next, we investigate whether there is any quantitative
difference in the writing rate over different words with
respect to the deceptive and truthful intent of the author.
In an attempt to understand this, we analyze words
which show the highest timespan difference between
deceptive and truthful writings.
Table 2 presents words in the restaurant review
topic for which deceptive writers took a lot longer
than truthful writers, and vice versa. Some word cat-
egories exhibit common trends across all three top-
ics. Highly subjective words, for instance (e.g., “love”,
“best”, “great”) are words over which truthful writers
spent more time.
Deceptive and truthful texts differ in the typing rate
of first- and second-person pronouns. Deceptive re-
views reveal more time spent in using 2nd-person pro-
nouns, as shown by “you” and “your”. This finding
throws some light on how people perceive text cues.
Toma and Hancock (2012) showed that readers per-
form poorly at deception detection because they rely on
unrelated text cues such as 2nd-person pronouns. Our
analysis indicates that people associate the use of 2nd-
person pronouns more with deception not only while
reading, but while writing as well.
Deceptive reviews also exhibit longer time spans for
1st-person pronouns (e.g., “we”, “me”), which have
been known to be useful in deception detection (New-
man et al., 2003; Ott et al., 2011). Newman et al.
(2003) attributed the less frequent usage of 1st-person
pronouns to psychological distancing. The longer time
taken by deceptive writers in our data is a possible sign
of increased cognitive burden when the writer is unable
to maintain the psychological distance. Deceptive re-
viewers also paused a lot more around relative clauses,
e.g., “if”, “when”, and “which”.
In essays, however, the difference in timespans of
1st-person and 2nd-person pronouns as well as the
timespan difference in relative clauses were insignifi-
cant (&lt; 50 ms).
A broader picture of the temporal difference in using
different types of words is presented in Fig. 3, which
shows deceptive reviewers spending less time on ad-
verbs as compared to truthful writers, but more time on
nouns, verbs, adjectives, function words and content
words. They also exhibited significantly longer pauses
before nouns, verbs and function words.
</bodyText>
<sectionHeader confidence="0.999384" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999969461538462">
In this paper, we investigated the use of typographic
style in deception detection and presented distinct tem-
poral and revisional aspects of keystroke patterns that
improve the characterization of deceptive writing. Our
study provides novel empirically supported insights
into the writing and editing processes of truthful and
deceptive writers. It also presents the first application
of keylogger data used to distinguish between true and
fake texts, and opens up a new range of questions to
better understand what affects these different keystroke
patterns and what they exhibit. It also suggests new
possibilities for making use of keystroke information
as an extended linguistic signal to accompany writings.
</bodyText>
<sectionHeader confidence="0.998168" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<footnote confidence="0.502798">
This research is supported in part by gift from Google.
</footnote>
<page confidence="0.993736">
1472
</page>
<sectionHeader confidence="0.996158" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999866509090909">
Francesco Bergadano, Daniele Gunetti, and Claudia Pi-
cardi. 2002. User Authentication through Keystroke
Dynamics. ACM Transactions on Information and
System Security (TISSEC), 5(4):367–397.
Charles F Bond and Bella M DePaulo. 2006. Accu-
racy of Deception Judgments. Personality and So-
cial Psychology Review, 10(3):214–234.
Sungzoon Cho, Chigeun Han, Dae Hee Han, and
Hyung-Il Kim. 2000. Web-based Keystroke Dy-
namics Identity Verification Using Neural Network.
Journal of Organizationl Computing and Electronic
Commerce, 10(4):295–307.
Bella M DePaulo, James J Lindsay, Brian E Mal-
one, Laura Muhlenbruck, Kelly Charlton, and Harris
Cooper. 2003. Cues to Deception. Psychological
Bulletin, 129(1):74.
Paul Ekman, Maureen O’Sullivan, Wallace V Friesen,
and Klaus R Scherer. 1991. Invited Article: Face,
Voice and Body in Detecting Deceit. Journal of
Nonverbal Behavior, 15(2):125–135.
Paul Ekman. 2003. Darwin, Deception, and Facial Ex-
pression. Annals of the New York Academy of Sci-
ences, 1000(1):205–221.
Clayton Epp, Michael Lippold, and Regan L Mandryk.
2011. Identifying Emotional States Using Keystroke
Dynamics. In Proc. of the SIGCHI Conference on
Human Factors in Computing Systems, pages 715–
724. ACM.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR:
A Library for Large Linear Classification. The Jour-
nal of Machine Learning Research, 9:1871–1874.
Geli Fei, Arjun Mukherjee, Bing Liu, Meichun Hsu,
Malu Castellanos, and Riddhiman Ghosh. 2013.
Exploiting Burstiness in Reviews for Review Spam-
mer Detection. In ICWSM, pages 175–184.
Song Feng, Ritwik Banerjee, and Yejin Choi. 2012.
Syntactic Stylometry for Deception Detection. In
Proc. 50th Annual Meeting of the ACL, pages 171–
175. ACL.
George E Forsen, Mark R Nelson, and Raymond J
Staron Jr. 1977. Personal Attributes Authentication
Techniques. Technical report, DTIC Document.
Stephanie Gokhman, Jeff Hancock, Poornima Prabhu,
Myle Ott, and Claire Cardie. 2012. In Search of a
Gold Standard in Studies of Deception. In Compu-
tational Approaches to Deception Detection, pages
23–30. ACL.
Jeffrey T Hancock, L Curry, Saurabh Goorha, and
Michael T Woodworth. 2004. Lies in Conversa-
tion: An Examination of Deception Using Auto-
mated Linguistic Analysis. In Annual Conference
of the Cognitive Science Society, volume 26, pages
534–540.
Victoria Johansson. 2009. Developmental Aspects of
Text Production in Writing and Speech. Ph.D. thesis,
Lund University.
Kevin S Killourhy and Roy A Maxion. 2009. Compar-
ing Anomaly-Detection Algorithms for Keystroke
Dynamics. In Dependable Systems &amp; Networks,
2009. DSN’09., pages 125–134. IEEE.
John Leggett and Glen Williams. 1988. Verifying
Identity Via Keystroke Characteristics. Interna-
tional Journal of Man-Machine Studies, 28(1):67–
76.
Ann Matsuhashi. 1981. Pausing and Planning: The
Tempo of Written Discourse Production. Research
in the Teaching of English, pages 113–134.
Steven A McCornack. 1997. The Generation of De-
ceptive Messages: Laying the Groundwork for a Vi-
able Theory of Interpersonal Deception. In John O
Greene, editor, Message Production: Advances in
Communication Theory. Erlbaum, Mahwah, NJ.
Arjun Mukherjee, Vivek Venkataraman, Bing Liu, and
Natalie Glance. 2013. What Yelp Fake Review Fil-
ter Might be Doing. In ICSWM, pages 409–418.
Matthew L Newman, James W Pennebaker, Diane S
Berry, and Jane M Richards. 2003. Lying Words:
Predicting Deception from Linguistic Styles. Per-
sonality and Social Psychology Bulletin, 29(5):665–
675.
Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T
Hancock. 2011. Finding Deceptive Opinion Spam
by Any Stretch of the Imagination. In Proc. 49th
Annual Meeting of the ACL: HLT, pages 309–319.
ACL.
Catalina L Toma and Jeffrey T Hancock. 2012. What
Lies Beneath: The Linguistic Traces of Deception in
Online Dating Profiles. Journal of Communication,
62(1):78–97.
Paul V Trovillo. 1939. A History of Lie Detection.
Journal of Criminal Law and Criminology (1931-
1951), 29:848–881.
Janet G van Hell, Ludo Verhoeven, and Liesbeth M van
Beijsterveldt. 2008. Pause Time Patterns in Writ-
ing Narrative and Expository Texts by Children and
Adults. Discourse Processes, 45(4-5):406–427.
Lisa M Vizer, Lina Zhou, and Andrew Sears. 2009.
Automated Stress Detection Using Keystroke and
Linguistic Features: An Exploratory Study. In-
ternational Journal of Human-Computer Studies,
67(10):870–886.
Aldert Vrij, Ronald Fisher, Samantha Mann, and
Sharon Leal. 2006. Detecting Deception by Ma-
nipulating Cognitive Load. Trends in Cognitive Sci-
ences, 10(4):141–142.
Putri Zulkifli. 2013. Applying Pause Analysis to Ex-
plore Cognitive Processes in the Copying of Sen-
tences by Second Language Users. Ph.D. thesis,
University of Sussex.
</reference>
<page confidence="0.985011">
1473
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.623546">
<title confidence="0.9990245">Keystroke Patterns as Prosody in Digital A Case Study with Deceptive Reviews and Essays</title>
<author confidence="0.922027">Yejin</author>
<affiliation confidence="0.9996985">Computer Science &amp; University of</affiliation>
<email confidence="0.998566">yejin@cs.washington.edu</email>
<author confidence="0.998424">Ritwik Banerjee Song Feng Jun S Kang</author>
<affiliation confidence="0.9833875">Computer Science Stony Brook University</affiliation>
<email confidence="0.866893">songfeng,@cs.stonybrook.edu</email>
<abstract confidence="0.997186076923077">In this paper, we explore the use of keyboard strokes as a means to access the real-time writing process of online authors, analogously to prosody in speech analysis, in the context of deception detection. We show that differences in keystroke patterns like editing maneuvers and duration of pauses can help distinguish between truthful and deceptive writing. Empirical results show that incorporating keystrokebased features lead to improved performance in deception detection in two different domains: online reviews and essays.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Francesco Bergadano</author>
<author>Daniele Gunetti</author>
<author>Claudia Picardi</author>
</authors>
<title>User Authentication through Keystroke Dynamics.</title>
<date>2002</date>
<journal>ACM Transactions on Information and System Security (TISSEC),</journal>
<volume>5</volume>
<issue>4</issue>
<contexts>
<context position="3752" citStr="Bergadano et al., 2002" startWordPosition="577" endWordPosition="580">e writing rate, pauses and revision rate. (2) showing their empirical value in deception detection, (3) providing novel domain-specific insights into deceptive writing, and (4) releasing a new corpus of deception writings in new domains.1 2 Related Work Prior research has focused mainly on using keystroke traits as a behvioral biometric. Forsen et al. (1977) first demonstrated that users can be distinguished by the way they type their names. Subsequent work showed that typing patterns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively measures the deception cues in real-time writing process as manifested in keystroke logs. 3 Data Collection As discussed by Gokhman et al. (2012), the crowdsourcing approach to soliciting deceptive content simulates the real world of online deceptive content crea</context>
</contexts>
<marker>Bergadano, Gunetti, Picardi, 2002</marker>
<rawString>Francesco Bergadano, Daniele Gunetti, and Claudia Picardi. 2002. User Authentication through Keystroke Dynamics. ACM Transactions on Information and System Security (TISSEC), 5(4):367–397.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles F Bond</author>
<author>Bella M DePaulo</author>
</authors>
<date>2006</date>
<journal>Accuracy of Deception Judgments. Personality and Social Psychology Review,</journal>
<volume>10</volume>
<issue>3</issue>
<contexts>
<context position="1490" citStr="Bond and DePaulo, 2006" startWordPosition="223" endWordPosition="226">ion Due to the practical importance of detecting deceit, interest in it is ancient, appearing in papyrus dated back to 900 B.C. (Trovillo, 1939). In more recent years, several studies have shown that the deceiver often exhibits behavior that belies the content of communication, thus providing cues of deception to an observer. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited domains such as product reviews. Prior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing </context>
</contexts>
<marker>Bond, DePaulo, 2006</marker>
<rawString>Charles F Bond and Bella M DePaulo. 2006. Accuracy of Deception Judgments. Personality and Social Psychology Review, 10(3):214–234.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sungzoon Cho</author>
<author>Chigeun Han</author>
<author>Dae Hee Han</author>
<author>Hyung-Il Kim</author>
</authors>
<title>Web-based Keystroke Dynamics Identity Verification Using Neural Network.</title>
<date>2000</date>
<journal>Journal of Organizationl Computing and Electronic Commerce,</journal>
<volume>10</volume>
<issue>4</issue>
<contexts>
<context position="3727" citStr="Cho et al., 2000" startWordPosition="573" endWordPosition="576">s) by measuring the writing rate, pauses and revision rate. (2) showing their empirical value in deception detection, (3) providing novel domain-specific insights into deceptive writing, and (4) releasing a new corpus of deception writings in new domains.1 2 Related Work Prior research has focused mainly on using keystroke traits as a behvioral biometric. Forsen et al. (1977) first demonstrated that users can be distinguished by the way they type their names. Subsequent work showed that typing patterns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively measures the deception cues in real-time writing process as manifested in keystroke logs. 3 Data Collection As discussed by Gokhman et al. (2012), the crowdsourcing approach to soliciting deceptive content simulates the real world of onli</context>
</contexts>
<marker>Cho, Han, Han, Kim, 2000</marker>
<rawString>Sungzoon Cho, Chigeun Han, Dae Hee Han, and Hyung-Il Kim. 2000. Web-based Keystroke Dynamics Identity Verification Using Neural Network. Journal of Organizationl Computing and Electronic Commerce, 10(4):295–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bella M DePaulo</author>
<author>James J Lindsay</author>
<author>Brian E Malone</author>
<author>Laura Muhlenbruck</author>
<author>Kelly Charlton</author>
<author>Harris Cooper</author>
</authors>
<title>Cues to Deception.</title>
<date>2003</date>
<journal>Psychological Bulletin,</journal>
<volume>129</volume>
<issue>1</issue>
<contexts>
<context position="1348" citStr="DePaulo et al. (2003)" startWordPosition="202" endWordPosition="205"> keystrokebased features lead to improved performance in deception detection in two different domains: online reviews and essays. 1 Introduction Due to the practical importance of detecting deceit, interest in it is ancient, appearing in papyrus dated back to 900 B.C. (Trovillo, 1939). In more recent years, several studies have shown that the deceiver often exhibits behavior that belies the content of communication, thus providing cues of deception to an observer. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited domains such as product reviews. Prior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in un</context>
</contexts>
<marker>DePaulo, Lindsay, Malone, Muhlenbruck, Charlton, Cooper, 2003</marker>
<rawString>Bella M DePaulo, James J Lindsay, Brian E Malone, Laura Muhlenbruck, Kelly Charlton, and Harris Cooper. 2003. Cues to Deception. Psychological Bulletin, 129(1):74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
<author>Maureen O’Sullivan</author>
<author>Wallace V Friesen</author>
<author>Klaus R Scherer</author>
</authors>
<title>Invited Article: Face, Voice and Body in Detecting Deceit.</title>
<date>1991</date>
<journal>Journal of Nonverbal Behavior,</journal>
<volume>15</volume>
<issue>2</issue>
<marker>Ekman, O’Sullivan, Friesen, Scherer, 1991</marker>
<rawString>Paul Ekman, Maureen O’Sullivan, Wallace V Friesen, and Klaus R Scherer. 1991. Invited Article: Face, Voice and Body in Detecting Deceit. Journal of Nonverbal Behavior, 15(2):125–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Ekman</author>
</authors>
<title>Darwin, Deception, and Facial Expression.</title>
<date>2003</date>
<journal>Annals of the New York Academy of Sciences,</journal>
<volume>1000</volume>
<issue>1</issue>
<contexts>
<context position="2365" citStr="Ekman, 2003" startWordPosition="364" endWordPosition="365">user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional processes of truthful and fake writers. Our work thus shares intuition with HCI research linking keystroke analysis to cognitive processes (Vizer et al., 2009; Epp et al., 2011) and psychology research connecting cognitive differences to deception (Ekman, 2003; Vrij et al., 2006). Recent research has shown that lying generally imposes a cognitive burden (e.g., McCornack (1997), Vrij et al. (2006)) which increases in real-time scenarios (Ekman, 2003). Cognitive burden has been known to produce differences in keytroke features (Vizer et al., 2009; Epp et al., 2011). Previous research has not, however, directly investigated any quantitative connection between keystroke patterns and deceptive writing. In this paper, we posit that cognitive burdens in deception may lead to measurable characteristics in keystroke patterns. Our contributions are as follow</context>
</contexts>
<marker>Ekman, 2003</marker>
<rawString>Paul Ekman. 2003. Darwin, Deception, and Facial Expression. Annals of the New York Academy of Sciences, 1000(1):205–221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clayton Epp</author>
<author>Michael Lippold</author>
<author>Regan L Mandryk</author>
</authors>
<title>Identifying Emotional States Using Keystroke Dynamics.</title>
<date>2011</date>
<booktitle>In Proc. of the SIGCHI Conference on Human Factors in Computing Systems,</booktitle>
<pages>715--724</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="2282" citStr="Epp et al., 2011" startWordPosition="351" endWordPosition="354">ployed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional processes of truthful and fake writers. Our work thus shares intuition with HCI research linking keystroke analysis to cognitive processes (Vizer et al., 2009; Epp et al., 2011) and psychology research connecting cognitive differences to deception (Ekman, 2003; Vrij et al., 2006). Recent research has shown that lying generally imposes a cognitive burden (e.g., McCornack (1997), Vrij et al. (2006)) which increases in real-time scenarios (Ekman, 2003). Cognitive burden has been known to produce differences in keytroke features (Vizer et al., 2009; Epp et al., 2011). Previous research has not, however, directly investigated any quantitative connection between keystroke patterns and deceptive writing. In this paper, we posit that cognitive burdens in deception may lead t</context>
</contexts>
<marker>Epp, Lippold, Mandryk, 2011</marker>
<rawString>Clayton Epp, Michael Lippold, and Regan L Mandryk. 2011. Identifying Emotional States Using Keystroke Dynamics. In Proc. of the SIGCHI Conference on Human Factors in Computing Systems, pages 715– 724. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A Library for Large Linear Classification.</title>
<date>2008</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="12659" citStr="Fan et al., 2008" startWordPosition="2046" endWordPosition="2049">stroke features can help distinguish between truthful and deceptive writing, we design binary SVM classifiers.5 Unigrams with tf-idf encoding is used as the baseline. The average baseline accuracy across all topics is 82.58% when considering both texts of a flow, and 83.62% when considering only the first text of each flow. The better performance in the latter possibly indicates that the second text of a flow exhibits some amount of lexical priming with the first. The high accuracy of the baseline is not surprising. Previous work by Ott et al. (2011) reported similar per5We use the LIBLINEAR (Fan et al., 2008) package. is but which been Table 2: Top 20 words in restaurant reviews with greatest timespan difference between deceptive and truthful writing. formance of unigram models. The focus of our work is to explore the completely new feature space of typographic patterns in deception detection. We draw motivation from parallels between the text generation and speech generation processes. Prosodic concepts such as speed, disfiuency and coherence can be realized in typographic behavior by analyzing timestamp of keystrokes, pauses and editing patterns, respectively. Based on the differences in the tem</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A Library for Large Linear Classification. The Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geli Fei</author>
<author>Arjun Mukherjee</author>
<author>Bing Liu</author>
<author>Meichun Hsu</author>
<author>Malu Castellanos</author>
<author>Riddhiman Ghosh</author>
</authors>
<title>Exploiting Burstiness in Reviews for Review Spammer Detection. In</title>
<date>2013</date>
<booktitle>ICWSM,</booktitle>
<pages>175--184</pages>
<contexts>
<context position="1785" citStr="Fei et al., 2013" startWordPosition="272" endWordPosition="275"> deception to an observer. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited domains such as product reviews. Prior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional processes of truthful and fake writers. Our work thus shares intuition with HCI research linking keystroke analysis to cognitive processes (Vizer et al., 2009; Epp et al., 2011) and psychology research connecting cognitive differences to deception (Ekman, 2003; Vrij et al., 2006)</context>
</contexts>
<marker>Fei, Mukherjee, Liu, Hsu, Castellanos, Ghosh, 2013</marker>
<rawString>Geli Fei, Arjun Mukherjee, Bing Liu, Meichun Hsu, Malu Castellanos, and Riddhiman Ghosh. 2013. Exploiting Burstiness in Reviews for Review Spammer Detection. In ICWSM, pages 175–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Ritwik Banerjee</author>
<author>Yejin Choi</author>
</authors>
<title>Syntactic Stylometry for Deception Detection.</title>
<date>2012</date>
<booktitle>In Proc. 50th Annual Meeting of the ACL,</booktitle>
<pages>171--175</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1735" citStr="Feng et al., 2012" startWordPosition="262" endWordPosition="265">the content of communication, thus providing cues of deception to an observer. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited domains such as product reviews. Prior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional processes of truthful and fake writers. Our work thus shares intuition with HCI research linking keystroke analysis to cognitive processes (Vizer et al., 2009; Epp et al., 2011) and psychology research connecting cognitive differe</context>
</contexts>
<marker>Feng, Banerjee, Choi, 2012</marker>
<rawString>Song Feng, Ritwik Banerjee, and Yejin Choi. 2012. Syntactic Stylometry for Deception Detection. In Proc. 50th Annual Meeting of the ACL, pages 171– 175. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George E Forsen</author>
<author>Mark R Nelson</author>
<author>Raymond J Staron Jr</author>
</authors>
<title>Personal Attributes Authentication Techniques.</title>
<date>1977</date>
<tech>Technical report, DTIC Document.</tech>
<contexts>
<context position="3489" citStr="Forsen et al. (1977)" startWordPosition="534" endWordPosition="537">on may lead to measurable characteristics in keystroke patterns. Our contributions are as follows: (1) introducing keystroke logs as an extended linguistic signal capturing the real-time writing process (analogous to prosody in speech analysis) by measuring the writing rate, pauses and revision rate. (2) showing their empirical value in deception detection, (3) providing novel domain-specific insights into deceptive writing, and (4) releasing a new corpus of deception writings in new domains.1 2 Related Work Prior research has focused mainly on using keystroke traits as a behvioral biometric. Forsen et al. (1977) first demonstrated that users can be distinguished by the way they type their names. Subsequent work showed that typing patterns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively </context>
</contexts>
<marker>Forsen, Nelson, Jr, 1977</marker>
<rawString>George E Forsen, Mark R Nelson, and Raymond J Staron Jr. 1977. Personal Attributes Authentication Techniques. Technical report, DTIC Document.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Gokhman</author>
<author>Jeff Hancock</author>
<author>Poornima Prabhu</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
</authors>
<date>2012</date>
<booktitle>In Search of a Gold Standard in Studies of Deception. In Computational Approaches to Deception Detection,</booktitle>
<pages>23--30</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="4234" citStr="Gokhman et al. (2012)" startWordPosition="653" endWordPosition="656">terns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively measures the deception cues in real-time writing process as manifested in keystroke logs. 3 Data Collection As discussed by Gokhman et al. (2012), the crowdsourcing approach to soliciting deceptive content simulates the real world of online deceptive content creators. We collected the data via Amazon Mechanical Turk.2 Turkers were led to a separate website where keylogging was enabled, and asked to write truthful and deceptive texts (≥ 100 words) on one of three top1Available at http://www3.cs.stonybrook. edu/˜junkang/keystroke/ 2https://www.mturk.com/mturk 1469 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1469–1473, October 25-29, 2014, Doha, Qatar. c�2014 Association for Comput</context>
</contexts>
<marker>Gokhman, Hancock, Prabhu, Ott, Cardie, 2012</marker>
<rawString>Stephanie Gokhman, Jeff Hancock, Poornima Prabhu, Myle Ott, and Claire Cardie. 2012. In Search of a Gold Standard in Studies of Deception. In Computational Approaches to Deception Detection, pages 23–30. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey T Hancock</author>
<author>L Curry</author>
<author>Saurabh Goorha</author>
<author>Michael T Woodworth</author>
</authors>
<title>Lies in Conversation: An Examination of Deception Using Automated Linguistic Analysis.</title>
<date>2004</date>
<booktitle>In Annual Conference of the Cognitive Science Society,</booktitle>
<volume>26</volume>
<pages>534--540</pages>
<contexts>
<context position="1271" citStr="Hancock et al. (2004)" startWordPosition="189" endWordPosition="192">een truthful and deceptive writing. Empirical results show that incorporating keystrokebased features lead to improved performance in deception detection in two different domains: online reviews and essays. 1 Introduction Due to the practical importance of detecting deceit, interest in it is ancient, appearing in papyrus dated back to 900 B.C. (Trovillo, 1939). In more recent years, several studies have shown that the deceiver often exhibits behavior that belies the content of communication, thus providing cues of deception to an observer. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited domains such as product reviews. Prior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns fo</context>
</contexts>
<marker>Hancock, Curry, Goorha, Woodworth, 2004</marker>
<rawString>Jeffrey T Hancock, L Curry, Saurabh Goorha, and Michael T Woodworth. 2004. Lies in Conversation: An Examination of Deception Using Automated Linguistic Analysis. In Annual Conference of the Cognitive Science Society, volume 26, pages 534–540.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Victoria Johansson</author>
</authors>
<title>Developmental Aspects of Text Production in Writing and Speech.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>Lund University.</institution>
<contexts>
<context position="3997" citStr="Johansson (2009)" startWordPosition="617" endWordPosition="618">k Prior research has focused mainly on using keystroke traits as a behvioral biometric. Forsen et al. (1977) first demonstrated that users can be distinguished by the way they type their names. Subsequent work showed that typing patterns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively measures the deception cues in real-time writing process as manifested in keystroke logs. 3 Data Collection As discussed by Gokhman et al. (2012), the crowdsourcing approach to soliciting deceptive content simulates the real world of online deceptive content creators. We collected the data via Amazon Mechanical Turk.2 Turkers were led to a separate website where keylogging was enabled, and asked to write truthful and deceptive texts (≥ 100 words) on one of three top1Available at http://www3.cs.stonybroo</context>
</contexts>
<marker>Johansson, 2009</marker>
<rawString>Victoria Johansson. 2009. Developmental Aspects of Text Production in Writing and Speech. Ph.D. thesis, Lund University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin S Killourhy</author>
<author>Roy A Maxion</author>
</authors>
<title>Comparing Anomaly-Detection Algorithms for Keystroke Dynamics.</title>
<date>2009</date>
<booktitle>In Dependable Systems &amp; Networks, 2009. DSN’09.,</booktitle>
<pages>125--134</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="3805" citStr="Killourhy and Maxion, 2009" startWordPosition="585" endWordPosition="588">wing their empirical value in deception detection, (3) providing novel domain-specific insights into deceptive writing, and (4) releasing a new corpus of deception writings in new domains.1 2 Related Work Prior research has focused mainly on using keystroke traits as a behvioral biometric. Forsen et al. (1977) first demonstrated that users can be distinguished by the way they type their names. Subsequent work showed that typing patterns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively measures the deception cues in real-time writing process as manifested in keystroke logs. 3 Data Collection As discussed by Gokhman et al. (2012), the crowdsourcing approach to soliciting deceptive content simulates the real world of online deceptive content creators. We collected the data via Amazon Mechanical Tur</context>
</contexts>
<marker>Killourhy, Maxion, 2009</marker>
<rawString>Kevin S Killourhy and Roy A Maxion. 2009. Comparing Anomaly-Detection Algorithms for Keystroke Dynamics. In Dependable Systems &amp; Networks, 2009. DSN’09., pages 125–134. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Leggett</author>
<author>Glen Williams</author>
</authors>
<title>Verifying Identity Via Keystroke Characteristics.</title>
<date>1988</date>
<journal>International Journal of Man-Machine Studies,</journal>
<volume>28</volume>
<issue>1</issue>
<pages>76</pages>
<contexts>
<context position="3673" citStr="Leggett and Williams, 1988" startWordPosition="562" endWordPosition="565">real-time writing process (analogous to prosody in speech analysis) by measuring the writing rate, pauses and revision rate. (2) showing their empirical value in deception detection, (3) providing novel domain-specific insights into deceptive writing, and (4) releasing a new corpus of deception writings in new domains.1 2 Related Work Prior research has focused mainly on using keystroke traits as a behvioral biometric. Forsen et al. (1977) first demonstrated that users can be distinguished by the way they type their names. Subsequent work showed that typing patterns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively measures the deception cues in real-time writing process as manifested in keystroke logs. 3 Data Collection As discussed by Gokhman et al. (2012), the crowdsourcing approach to solicit</context>
</contexts>
<marker>Leggett, Williams, 1988</marker>
<rawString>John Leggett and Glen Williams. 1988. Verifying Identity Via Keystroke Characteristics. International Journal of Man-Machine Studies, 28(1):67– 76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ann Matsuhashi</author>
</authors>
<title>Pausing and Planning: The Tempo of Written Discourse Production. Research in the Teaching of English,</title>
<date>1981</date>
<pages>113--134</pages>
<contexts>
<context position="3900" citStr="Matsuhashi (1981)" startWordPosition="601" endWordPosition="602">ptive writing, and (4) releasing a new corpus of deception writings in new domains.1 2 Related Work Prior research has focused mainly on using keystroke traits as a behvioral biometric. Forsen et al. (1977) first demonstrated that users can be distinguished by the way they type their names. Subsequent work showed that typing patterns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively measures the deception cues in real-time writing process as manifested in keystroke logs. 3 Data Collection As discussed by Gokhman et al. (2012), the crowdsourcing approach to soliciting deceptive content simulates the real world of online deceptive content creators. We collected the data via Amazon Mechanical Turk.2 Turkers were led to a separate website where keylogging was enabled, and asked to write tru</context>
</contexts>
<marker>Matsuhashi, 1981</marker>
<rawString>Ann Matsuhashi. 1981. Pausing and Planning: The Tempo of Written Discourse Production. Research in the Teaching of English, pages 113–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven A McCornack</author>
</authors>
<title>The Generation of Deceptive Messages: Laying the Groundwork for a Viable Theory of Interpersonal Deception. In</title>
<date>1997</date>
<booktitle>Message Production: Advances in Communication Theory. Erlbaum,</booktitle>
<editor>John O Greene, editor,</editor>
<location>Mahwah, NJ.</location>
<contexts>
<context position="2484" citStr="McCornack (1997)" startWordPosition="383" endWordPosition="384"> for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional processes of truthful and fake writers. Our work thus shares intuition with HCI research linking keystroke analysis to cognitive processes (Vizer et al., 2009; Epp et al., 2011) and psychology research connecting cognitive differences to deception (Ekman, 2003; Vrij et al., 2006). Recent research has shown that lying generally imposes a cognitive burden (e.g., McCornack (1997), Vrij et al. (2006)) which increases in real-time scenarios (Ekman, 2003). Cognitive burden has been known to produce differences in keytroke features (Vizer et al., 2009; Epp et al., 2011). Previous research has not, however, directly investigated any quantitative connection between keystroke patterns and deceptive writing. In this paper, we posit that cognitive burdens in deception may lead to measurable characteristics in keystroke patterns. Our contributions are as follows: (1) introducing keystroke logs as an extended linguistic signal capturing the real-time writing process (analogous t</context>
</contexts>
<marker>McCornack, 1997</marker>
<rawString>Steven A McCornack. 1997. The Generation of Deceptive Messages: Laying the Groundwork for a Viable Theory of Interpersonal Deception. In John O Greene, editor, Message Production: Advances in Communication Theory. Erlbaum, Mahwah, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arjun Mukherjee</author>
<author>Vivek Venkataraman</author>
<author>Bing Liu</author>
<author>Natalie Glance</author>
</authors>
<title>What Yelp Fake Review Filter Might be Doing. In</title>
<date>2013</date>
<booktitle>ICSWM,</booktitle>
<pages>409--418</pages>
<contexts>
<context position="1810" citStr="Mukherjee et al., 2013" startWordPosition="276" endWordPosition="279">bserver. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited domains such as product reviews. Prior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional processes of truthful and fake writers. Our work thus shares intuition with HCI research linking keystroke analysis to cognitive processes (Vizer et al., 2009; Epp et al., 2011) and psychology research connecting cognitive differences to deception (Ekman, 2003; Vrij et al., 2006). Recent research has sho</context>
</contexts>
<marker>Mukherjee, Venkataraman, Liu, Glance, 2013</marker>
<rawString>Arjun Mukherjee, Vivek Venkataraman, Bing Liu, and Natalie Glance. 2013. What Yelp Fake Review Filter Might be Doing. In ICSWM, pages 409–418.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew L Newman</author>
<author>James W Pennebaker</author>
<author>Diane S Berry</author>
<author>Jane M Richards</author>
</authors>
<title>Lying Words: Predicting Deception from Linguistic Styles. Personality and Social Psychology Bulletin,</title>
<date>2003</date>
<volume>29</volume>
<issue>5</issue>
<pages>675</pages>
<contexts>
<context position="1248" citStr="Newman et al. (2003)" startWordPosition="185" endWordPosition="188"> help distinguish between truthful and deceptive writing. Empirical results show that incorporating keystrokebased features lead to improved performance in deception detection in two different domains: online reviews and essays. 1 Introduction Due to the practical importance of detecting deceit, interest in it is ancient, appearing in papyrus dated back to 900 B.C. (Trovillo, 1939). In more recent years, several studies have shown that the deceiver often exhibits behavior that belies the content of communication, thus providing cues of deception to an observer. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited domains such as product reviews. Prior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect o</context>
<context position="17501" citStr="Newman et al., 2003" startWordPosition="2821" endWordPosition="2825">s reveal more time spent in using 2nd-person pronouns, as shown by “you” and “your”. This finding throws some light on how people perceive text cues. Toma and Hancock (2012) showed that readers perform poorly at deception detection because they rely on unrelated text cues such as 2nd-person pronouns. Our analysis indicates that people associate the use of 2ndperson pronouns more with deception not only while reading, but while writing as well. Deceptive reviews also exhibit longer time spans for 1st-person pronouns (e.g., “we”, “me”), which have been known to be useful in deception detection (Newman et al., 2003; Ott et al., 2011). Newman et al. (2003) attributed the less frequent usage of 1st-person pronouns to psychological distancing. The longer time taken by deceptive writers in our data is a possible sign of increased cognitive burden when the writer is unable to maintain the psychological distance. Deceptive reviewers also paused a lot more around relative clauses, e.g., “if”, “when”, and “which”. In essays, however, the difference in timespans of 1st-person and 2nd-person pronouns as well as the timespan difference in relative clauses were insignificant (&lt; 50 ms). A broader picture of the temp</context>
</contexts>
<marker>Newman, Pennebaker, Berry, Richards, 2003</marker>
<rawString>Matthew L Newman, James W Pennebaker, Diane S Berry, and Jane M Richards. 2003. Lying Words: Predicting Deception from Linguistic Styles. Personality and Social Psychology Bulletin, 29(5):665– 675.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Myle Ott</author>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
<author>Jeffrey T Hancock</author>
</authors>
<title>Finding Deceptive Opinion Spam by Any Stretch of the Imagination.</title>
<date>2011</date>
<booktitle>In Proc. 49th Annual Meeting of the ACL: HLT,</booktitle>
<pages>309--319</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1509" citStr="Ott et al., 2011" startWordPosition="227" endWordPosition="230"> importance of detecting deceit, interest in it is ancient, appearing in papyrus dated back to 900 B.C. (Trovillo, 1939). In more recent years, several studies have shown that the deceiver often exhibits behavior that belies the content of communication, thus providing cues of deception to an observer. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited domains such as product reviews. Prior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional proc</context>
<context position="12598" citStr="Ott et al. (2011)" startWordPosition="2035" endWordPosition="2038"> cues in keystroke patterns: To empirically check whether keystroke features can help distinguish between truthful and deceptive writing, we design binary SVM classifiers.5 Unigrams with tf-idf encoding is used as the baseline. The average baseline accuracy across all topics is 82.58% when considering both texts of a flow, and 83.62% when considering only the first text of each flow. The better performance in the latter possibly indicates that the second text of a flow exhibits some amount of lexical priming with the first. The high accuracy of the baseline is not surprising. Previous work by Ott et al. (2011) reported similar per5We use the LIBLINEAR (Fan et al., 2008) package. is but which been Table 2: Top 20 words in restaurant reviews with greatest timespan difference between deceptive and truthful writing. formance of unigram models. The focus of our work is to explore the completely new feature space of typographic patterns in deception detection. We draw motivation from parallels between the text generation and speech generation processes. Prosodic concepts such as speed, disfiuency and coherence can be realized in typographic behavior by analyzing timestamp of keystrokes, pauses and editin</context>
<context position="16031" citStr="Ott et al., 2011" startWordPosition="2588" endWordPosition="2591">uct reviews, due to their dependence on factual details. Gun control and gay marriage, on the other hand, are topics well discussed in media, and it is possible that the writers are aware of the arguments that go against their personal belief. The frequency of revisional occurrences (i.e., keys used for editing) shown in Fig. 1, too, supports the thought that writing fake reviews may be harder than adopting a fake stance on well-known issues. Deceptive reviews exhibit a higher number of revisions than truthful ones, but essays show the opposite trend. Our findings align with previous studies (Ott et al., 2011) which showed that deception cues are domain dependent. Writing speed variations over word categories: Next, we investigate whether there is any quantitative difference in the writing rate over different words with respect to the deceptive and truthful intent of the author. In an attempt to understand this, we analyze words which show the highest timespan difference between deceptive and truthful writings. Table 2 presents words in the restaurant review topic for which deceptive writers took a lot longer than truthful writers, and vice versa. Some word categories exhibit common trends across a</context>
<context position="17520" citStr="Ott et al., 2011" startWordPosition="2826" endWordPosition="2829">ent in using 2nd-person pronouns, as shown by “you” and “your”. This finding throws some light on how people perceive text cues. Toma and Hancock (2012) showed that readers perform poorly at deception detection because they rely on unrelated text cues such as 2nd-person pronouns. Our analysis indicates that people associate the use of 2ndperson pronouns more with deception not only while reading, but while writing as well. Deceptive reviews also exhibit longer time spans for 1st-person pronouns (e.g., “we”, “me”), which have been known to be useful in deception detection (Newman et al., 2003; Ott et al., 2011). Newman et al. (2003) attributed the less frequent usage of 1st-person pronouns to psychological distancing. The longer time taken by deceptive writers in our data is a possible sign of increased cognitive burden when the writer is unable to maintain the psychological distance. Deceptive reviewers also paused a lot more around relative clauses, e.g., “if”, “when”, and “which”. In essays, however, the difference in timespans of 1st-person and 2nd-person pronouns as well as the timespan difference in relative clauses were insignificant (&lt; 50 ms). A broader picture of the temporal difference in </context>
</contexts>
<marker>Ott, Choi, Cardie, Hancock, 2011</marker>
<rawString>Myle Ott, Yejin Choi, Claire Cardie, and Jeffrey T Hancock. 2011. Finding Deceptive Opinion Spam by Any Stretch of the Imagination. In Proc. 49th Annual Meeting of the ACL: HLT, pages 309–319. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catalina L Toma</author>
<author>Jeffrey T Hancock</author>
</authors>
<title>What Lies Beneath: The Linguistic Traces of Deception in Online Dating Profiles.</title>
<date>2012</date>
<journal>Journal of Communication,</journal>
<volume>62</volume>
<issue>1</issue>
<contexts>
<context position="17055" citStr="Toma and Hancock (2012)" startWordPosition="2750" endWordPosition="2753">ritings. Table 2 presents words in the restaurant review topic for which deceptive writers took a lot longer than truthful writers, and vice versa. Some word categories exhibit common trends across all three topics. Highly subjective words, for instance (e.g., “love”, “best”, “great”) are words over which truthful writers spent more time. Deceptive and truthful texts differ in the typing rate of first- and second-person pronouns. Deceptive reviews reveal more time spent in using 2nd-person pronouns, as shown by “you” and “your”. This finding throws some light on how people perceive text cues. Toma and Hancock (2012) showed that readers perform poorly at deception detection because they rely on unrelated text cues such as 2nd-person pronouns. Our analysis indicates that people associate the use of 2ndperson pronouns more with deception not only while reading, but while writing as well. Deceptive reviews also exhibit longer time spans for 1st-person pronouns (e.g., “we”, “me”), which have been known to be useful in deception detection (Newman et al., 2003; Ott et al., 2011). Newman et al. (2003) attributed the less frequent usage of 1st-person pronouns to psychological distancing. The longer time taken by </context>
</contexts>
<marker>Toma, Hancock, 2012</marker>
<rawString>Catalina L Toma and Jeffrey T Hancock. 2012. What Lies Beneath: The Linguistic Traces of Deception in Online Dating Profiles. Journal of Communication, 62(1):78–97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul V Trovillo</author>
</authors>
<title>A History of Lie Detection.</title>
<date>1939</date>
<journal>Journal of Criminal Law and Criminology</journal>
<pages>29--848</pages>
<contexts>
<context position="1012" citStr="Trovillo, 1939" startWordPosition="149" endWordPosition="150">ess the real-time writing process of online authors, analogously to prosody in speech analysis, in the context of deception detection. We show that differences in keystroke patterns like editing maneuvers and duration of pauses can help distinguish between truthful and deceptive writing. Empirical results show that incorporating keystrokebased features lead to improved performance in deception detection in two different domains: online reviews and essays. 1 Introduction Due to the practical importance of detecting deceit, interest in it is ancient, appearing in papyrus dated back to 900 B.C. (Trovillo, 1939). In more recent years, several studies have shown that the deceiver often exhibits behavior that belies the content of communication, thus providing cues of deception to an observer. These include linguistic (e.g., Newman et al. (2003), Hancock et al. (2004)) as well as paralinguistic (e.g., Ekman et al. (1991), DePaulo et al. (2003)) cues. Recognizing deception, however, remains a hard task for humans, who perform only marginally better than chance (Bond and DePaulo, 2006; Ott et al., 2011). Recent studies suggest that computers can be surprisingly effective in this task, albeit in limited d</context>
</contexts>
<marker>Trovillo, 1939</marker>
<rawString>Paul V Trovillo. 1939. A History of Lie Detection. Journal of Criminal Law and Criminology (1931-1951), 29:848–881.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janet G van Hell</author>
<author>Ludo Verhoeven</author>
<author>Liesbeth M van Beijsterveldt</author>
</authors>
<date>2008</date>
<booktitle>Pause Time Patterns in Writing Narrative and Expository Texts by Children and Adults. Discourse Processes,</booktitle>
<pages>45--4</pages>
<marker>van Hell, Verhoeven, van Beijsterveldt, 2008</marker>
<rawString>Janet G van Hell, Ludo Verhoeven, and Liesbeth M van Beijsterveldt. 2008. Pause Time Patterns in Writing Narrative and Expository Texts by Children and Adults. Discourse Processes, 45(4-5):406–427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa M Vizer</author>
<author>Lina Zhou</author>
<author>Andrew Sears</author>
</authors>
<title>Automated Stress Detection Using Keystroke and Linguistic Features: An Exploratory Study.</title>
<date>2009</date>
<journal>International Journal of Human-Computer Studies,</journal>
<volume>67</volume>
<issue>10</issue>
<contexts>
<context position="2263" citStr="Vizer et al., 2009" startWordPosition="347" endWordPosition="350">rior research has employed lexico-syntactic patterns (Ott et al., 2011; Feng et al., 2012) as well as online user behavior (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional processes of truthful and fake writers. Our work thus shares intuition with HCI research linking keystroke analysis to cognitive processes (Vizer et al., 2009; Epp et al., 2011) and psychology research connecting cognitive differences to deception (Ekman, 2003; Vrij et al., 2006). Recent research has shown that lying generally imposes a cognitive burden (e.g., McCornack (1997), Vrij et al. (2006)) which increases in real-time scenarios (Ekman, 2003). Cognitive burden has been known to produce differences in keytroke features (Vizer et al., 2009; Epp et al., 2011). Previous research has not, however, directly investigated any quantitative connection between keystroke patterns and deceptive writing. In this paper, we posit that cognitive burdens in d</context>
</contexts>
<marker>Vizer, Zhou, Sears, 2009</marker>
<rawString>Lisa M Vizer, Lina Zhou, and Andrew Sears. 2009. Automated Stress Detection Using Keystroke and Linguistic Features: An Exploratory Study. International Journal of Human-Computer Studies, 67(10):870–886.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aldert Vrij</author>
<author>Ronald Fisher</author>
<author>Samantha Mann</author>
<author>Sharon Leal</author>
</authors>
<title>Detecting Deception by Manipulating Cognitive Load. Trends in Cognitive Sciences,</title>
<date>2006</date>
<pages>10--4</pages>
<contexts>
<context position="2385" citStr="Vrij et al., 2006" startWordPosition="366" endWordPosition="369"> (Fei et al., 2013; Mukherjee et al., 2013). In this paper, we study the effect of keystroke patterns for deception detection in digital communications, which might be helpful in understanding the psychology of deception and help toward trustful online communities. This allows us to investigate differences in the writing and revisional processes of truthful and fake writers. Our work thus shares intuition with HCI research linking keystroke analysis to cognitive processes (Vizer et al., 2009; Epp et al., 2011) and psychology research connecting cognitive differences to deception (Ekman, 2003; Vrij et al., 2006). Recent research has shown that lying generally imposes a cognitive burden (e.g., McCornack (1997), Vrij et al. (2006)) which increases in real-time scenarios (Ekman, 2003). Cognitive burden has been known to produce differences in keytroke features (Vizer et al., 2009; Epp et al., 2011). Previous research has not, however, directly investigated any quantitative connection between keystroke patterns and deceptive writing. In this paper, we posit that cognitive burdens in deception may lead to measurable characteristics in keystroke patterns. Our contributions are as follows: (1) introducing k</context>
</contexts>
<marker>Vrij, Fisher, Mann, Leal, 2006</marker>
<rawString>Aldert Vrij, Ronald Fisher, Samantha Mann, and Sharon Leal. 2006. Detecting Deception by Manipulating Cognitive Load. Trends in Cognitive Sciences, 10(4):141–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Putri Zulkifli</author>
</authors>
<title>Applying Pause Analysis to Explore Cognitive Processes in the Copying of Sentences by Second Language Users.</title>
<date>2013</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sussex.</institution>
<contexts>
<context position="4014" citStr="Zulkifli (2013)" startWordPosition="619" endWordPosition="620">as focused mainly on using keystroke traits as a behvioral biometric. Forsen et al. (1977) first demonstrated that users can be distinguished by the way they type their names. Subsequent work showed that typing patterns are unique to individuals (Leggett and Williams, 1988), and can be used for authentication (Cho et al., 2000; Bergadano et al., 2002) and intrusion detection (Killourhy and Maxion, 2009). Keystroke pauses have been linked to linguistic patterns in discourse (e.g. Matsuhashi (1981), van Hell et al. (2008)) and regarded as indications of cognitive burden (e.g., Johansson (2009), Zulkifli (2013)). In this paper, we present the first empirical study that quantitatively measures the deception cues in real-time writing process as manifested in keystroke logs. 3 Data Collection As discussed by Gokhman et al. (2012), the crowdsourcing approach to soliciting deceptive content simulates the real world of online deceptive content creators. We collected the data via Amazon Mechanical Turk.2 Turkers were led to a separate website where keylogging was enabled, and asked to write truthful and deceptive texts (≥ 100 words) on one of three top1Available at http://www3.cs.stonybrook. edu/˜junkang/k</context>
</contexts>
<marker>Zulkifli, 2013</marker>
<rawString>Putri Zulkifli. 2013. Applying Pause Analysis to Explore Cognitive Processes in the Copying of Sentences by Second Language Users. Ph.D. thesis, University of Sussex.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>