<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99698">
Search-Aware Tuning for Machine Translation
</title>
<author confidence="0.994026">
Lemao Liu
</author>
<affiliation confidence="0.9927135">
Queens College
City University of New York
</affiliation>
<email confidence="0.976494">
lemaoliu@gmail.com
</email>
<sectionHeader confidence="0.994395" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9993729375">
Parameter tuning is an important problem in
statistical machine translation, but surpris-
ingly, most existing methods such as MERT,
MIRA and PRO are agnostic about search,
while search errors could severely degrade
translation quality. We propose a search-
aware framework to promote promising par-
tial translations, preventing them from be-
ing pruned. To do so we develop two met-
rics to evaluate partial derivations. Our tech-
nique can be applied to all of the three
above-mentioned tuning methods, and ex-
tensive experiments on Chinese-to-English
and English-to-Chinese translation show up
to +2.6 BLEU gains over search-agnostic
baselines.
</bodyText>
<sectionHeader confidence="0.998422" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999900217391305">
Parameter tuning has been a key problem for ma-
chine translation since the statistical revolution.
However, most existing tuning algorithms treat the
decoder as a black box (Och, 2003; Hopkins and
May, 2011; Chiang, 2012), ignoring the fact that
many potentially promising partial translations are
pruned by the decoder due to the prohibitively
large search space. For example, the popular
beam-search decoding algorithm for phrase-based
MT (Koehn, 2004) only explores O(nb) items for
a sentence of n words (with a beam width of b),
while the full search space is O(2nn2) or worse
(Knight, 1999).
As one of the very few exceptions to the
“search-agnostic” majority, Yu et al. (2013) and
Zhao et al. (2014) propose a variant of the per-
ceptron algorithm that learns to keep the refer-
ence translations in the beam or chart. How-
ever, there are several obstacles that prevent their
method from becoming popular: First of all, they
rely on “forced decoding” to track gold derivations
that lead to the reference translation, but in practice
only a small portion of (mostly very short) sen-
</bodyText>
<note confidence="0.73147675">
Liang Huang
Queens College and Graduate Center
City University of New York
liang.huang.sh@gmail.com
</note>
<figure confidence="0.924349">
0 1 2 3 4
</figure>
<figureCaption confidence="0.9364752">
Figure 1: (a) Some potentially promising partial trans-
lations (in red) fall out of the beam (bin 2); (b) We
identify such partial translations and assign them higher
model scores so that they are more likely to survive the
search.
</figureCaption>
<bodyText confidence="0.999788357142857">
tence pairs have at least one such derivation. Sec-
ondly, they learn the model on the training set, and
while this does enable a sparse feature set, it is or-
ders of magnitude slower compared to MERT and
PRO.
We instead propose a very simple framework,
search-aware tuning, which does not depend on
forced decoding, and thus can be trained on all sen-
tence pairs of any dataset. The key idea is that,
besides caring about the rankings of the complete
translations, we also promote potentially promis-
ing partial translations so that they are more likely
to survive throughout the search, see Figure 1 for
illustration. We make the following contributions:
</bodyText>
<listItem confidence="0.989552153846154">
• Our idea of search-aware tuning can be ap-
plied (as a patch) to all of the three most
popular tuning methods (MERT, PRO, and
MIRA) by defining a modified objective func-
tion (Section 4).
• To measure the “promise” or “potential” of a
partial translation, we define a new concept
“potential BLEU” inspired by future cost in
MT decoding (Koehn, 2004) and heuristics in
A* search (Hart et al., 1968) (Section 3.2).
This work is the first study of evaluating met-
rics for partial translations.
• Our method obtains substantial and consistent
</listItem>
<page confidence="0.960285">
1942
</page>
<note confidence="0.914425">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1942–1952,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.982222727272727">
{d o r  |dEBi_j(x), |c(r)|=j})
improvements on both the large-scale NIST
Chinese-to-English and English-to-Chinese
translation tasks on top of MERT, MIRA, and
PRO baselines. This is the first time that con-
sistent improvements can be achieved with a
new learning algorithm under dense feature
settings (Section 5).
For simplicity reasons, in this paper we use
phrase-based translation, but our work has the po-
tential to be applied to other translation paradigms.
</bodyText>
<sectionHeader confidence="0.958233" genericHeader="introduction">
2 Review: Beam Search for PBMT
Decoding
</sectionHeader>
<bodyText confidence="0.999616">
We review beam search for phrase-based decoding
in our notations which will facilitate the discussion
of search-aware tuning in Section 4. Following Yu
et al. (2013), let (x, y) be a Chinese-English sen-
tence pair in the tuning set D, and
</bodyText>
<equation confidence="0.582471833333333">
d = r1 o r2 o ... o r|d|
be a (partial) derivation, where each ri =
(c(ri), e(ri)) is a rule, i.e., a phrase-pair. Let |c(r)|
be the number of Chinese words in rule r, and
e(d) Δ = e(r1) o e(r2) ... o e(r|d|) be the English
prefix (i.e., partial translation) generated so far.
</equation>
<bodyText confidence="0.9996535">
In beam search, each bin Bi(x) contains the best
k derivations covering exactly i Chinese words,
based on items in previous bins (see Figures 1
and 2):
</bodyText>
<equation confidence="0.993967">
B0(x) = {E}
�
Bi(x) = topk w0 (
j=1..i
</equation>
<bodyText confidence="0.999784666666667">
where r is a rule covering j Chinese words, and
topkw0(·) returns the top k derivations according
to the current model w0. As a special case, note
that top1w0(S) = argmaxdES w0 · Φ(d), so
top1w0(B|x|(x)) is the final 1-best result.1 See Fig-
ure 2 for an illustration.
</bodyText>
<sectionHeader confidence="0.992318" genericHeader="method">
3 Challenge: Evaluating Partial
Derivations
</sectionHeader>
<bodyText confidence="0.9972695">
As mentioned in Section 1, the current mainstream
tuning methods such as MERT, MIRA, and PRO are
</bodyText>
<footnote confidence="0.982265">
1Actually Bl,l(x) is an approximation to the k-best list
since some derivations are merged by dynamic programming;
to recover those we can use Alg. 3 of Huang and Chiang
(2005).
</footnote>
<equation confidence="0.980486">
0 1 2 3 4
B0(x) B1(x) B2(x) B3(x) B4(x)
</equation>
<figureCaption confidence="0.98846425">
Figure 2: Beam search for phrase-based decoding. The
item in red is top1w0(B4(x)), i.e., the 1-best result.
Traditional tuning only uses the final bin B4(x) while
search-aware tuning considers all bins Bi(x) (i = 1..4).
</figureCaption>
<bodyText confidence="0.991959588235294">
all search-agnostic: they only care about the com-
plete translations from the last bin, B|x|(x), ignor-
ing all partial ones, i.e., Bi(x) for all i &lt; |x|. As
a result, many potentially promising partial deriva-
tions never reach the final bin (See Figure 1).
To address this problem, our new “search-aware
tuning” aims to promote not only the accurate
translations in the final bin, but more importantly
those potentially promising partial derivations in
non-final bins. The key challenge, however, is
how to evaluate the “promise” or “potential” of
a partial derivation. In this Section, we develop
two such measures, a simple “partial BLEU” (Sec-
tion 3.1) and a more principled “potential BLEU”
(Section 3.2). In Section 4, we will then adapt tra-
ditional tuning methods to their search-aware ver-
sions using these partial evaluation metrics.
</bodyText>
<subsectionHeader confidence="0.999593">
3.1 Solution 1: Simple and Naive Partial BLEU
</subsectionHeader>
<bodyText confidence="0.9674414375">
Inspired by a trick in (Li and Khudanpur, 2009)
and (Chiang, 2012) for oracle or hope extraction,
we use a very simple metric to evaluate partial
translations for tuning. For a given derivation d,
the basic idea is to evaluate the (short) partial trans-
lation e(d) against the (full) reference y, but using
a “prorated” reference length proportional to c(d)
which is the number of Chinese words covered so
far in d:
|y |· |c(d)|/|x|
For example, if d has covered 2 words on a 8-
word Chinese sentence with a 12-word English
reference, then the “effective reference length” is
12 x 2/8 = 3. We call this method “partial BLEU”
since it does not complete the translation, and de-
note it by
</bodyText>
<equation confidence="0.974200444444444">
¯δ|x|
y (d) = −δ(y, e(d); reflen = |y |· |c(d)|/|x|).
(1)
1943
S(y, y&apos;) = −Bleu+1(y, y&apos;) string distance metric
Sy(d) = S(y, e(d)) full derivations eval
Sxy (d) = S|x|
y (d) partial bleu (Sec. 3.1)
S(y, ¯ex(d)) potential
</equation>
<tableCaption confidence="0.8319495">
Table 1: Notations for evaluating full and partial deriva-
tions. Functions ¯S|x|
</tableCaption>
<bodyText confidence="0.8049435">
y (·) and ¯ex(·) are defined by Equa-
tions 1 and 3, respectively.
where reflen is the effective length of reference
translations, see (Papineni et al., 2002) for details.
</bodyText>
<subsectionHeader confidence="0.983378">
3.1.1 Problem with Partial BLEU
</subsectionHeader>
<bodyText confidence="0.951765916666666">
Simple as it is, this method does not work well in
practice because comparison of partial derivations
might be unfair for different derivations covering
different set of Chinese words, as it will naturally
favor those covering “easier” portions of the in-
put sentence (which we do observe empirically).
For instance, consider the following Chinese-to-
English example which involves a reordering of
the Chinese PP:
d`ao Bˇeijing
to Beijing
“I flew from Shanghai to Beijing”
Partial BLEU will prefer subtranslation “I from” to
“I fly” in bin 2 (covering 2 Chinese words) because
the former has 2 unigram mathces while the latter
only 1, even though the latter is almost identical
to the reference and will eventually lead to a com-
plete translation with substantially higher Bleu+1
score (matching a 4-gram “from Shanghai to Bei-
jing”). Similarly, it will prefer “I from Shanghai”
to “I fly from” in bin 3, without knowing that the
former will eventually pay the price of word-order
difference. This example suggests that we need a
more “global” or less greedy metric (see below).
</bodyText>
<subsectionHeader confidence="0.997835">
3.2 Solution 2: Potential BLEU via Extension
</subsectionHeader>
<bodyText confidence="0.97175">
Inspired by future cost computation in MT decod-
ing (Koehn, 2004), we define a very simple fu-
ture string by simply concatenating the best model-
score translation (with no reorderings) in each un-
covered span. Let bestw(x[i:j]) denote the best
monotonic derivation for span [i : j], then
future(d, x) = o[i:j]Euncov(d,x) e(bestw(x[i:j]))
where o is the concatenation operator and
uncov(d, x) returns an ordered list of uncovered
</bodyText>
<figureCaption confidence="0.975025">
Figure 3: Example of the extension function ¯ex(·) (and
future string) on an incomplete derivation d.
</figureCaption>
<bodyText confidence="0.9867406">
spans of x. See Figure 3 for an example. This fu-
ture string resembles (inadmissible) heuristic func-
tion (Hart et al., 1968). Now the “extended trans-
lation” is simply a concatenation of the exist-
ing partial translation e(d) and the future string
</bodyText>
<equation confidence="0.86553">
future(d, x):
¯ex(d) = e(d) o future(d, x). (3)
</equation>
<bodyText confidence="0.9960044">
Instead of calculating bestw(x[i:j]) on-the-fly
for each derivation d, we can precompute it for
each span [i : j] during future-cost computa-
tion, since the score of bestw(x[i:j]) is context-
free (Koehn, 2004). Algorithm 1 shows the
pseudo-code of computing bestw(x[i:j]). In prac-
tice, since future-cost precomputation already
solves the best (monotonic) model-score for each
span, is the only extra work for potential BLEU
is to record (for each span) the subtranslation that
achieves that best score. Therefore, the extra time
for potential BLEU is negligible (the time com-
plexity is O(n2), but just as in future cost, the con-
stant is much smaller than real decoding). The im-
plementation should require minimal hacking on a
phrase-based decoder (such as Moses).
To summarize the notation, we use Sxy (d) to
denote a generic evaluation function for par-
tial derivation d, which could be instantiated in
two ways, partial bleu (¯S|x|
y (d)) or potential bleu
(S(y, ¯ex(d))). See Table 1 for details. The next
Section will only use the generic notation Sxy (d).
Finally, it is important to note that although
both partial and potential metrics are not BLEU-
specific, the latter is much easier to adapt to other
metrics such as TER since it does not change the
original Bleu+1 definition. By contrast, it is not
clear to us at all how to generalize partial BLEU to
partial TER.
</bodyText>
<sectionHeader confidence="0.990653" genericHeader="method">
4 Search-Aware MERT, MIRA, and PRO
</sectionHeader>
<bodyText confidence="0.999012666666667">
Parameter tuning aims to optimize the weight vec-
tor w so that the rankings based on model score de-
fined by w is positively correlated with those based
</bodyText>
<figure confidence="0.762191222222222">
X =
Ex(d) =
reordering
monotonic
e(d)
future(d, x)
bleu (Sec. 3. 2)
(2) wˇo c´ong Sh`anghˇai f¯ei
I from Shanghai fly
</figure>
<page confidence="0.659822">
1944
</page>
<bodyText confidence="0.480728">
Algorithm 1 Computation of best Translations for Potential BLEU.
Input: Source sentence x, a rule set R for x, and w.
Output: Best translations e(bestw(x[i : j])) for all spans [i : j].
</bodyText>
<listItem confidence="0.912189933333333">
1: for l in (0..|x|) do
2: for i in (0..|x |− l) do
3: j = i + l + 1
4: best score = −oo
5: if R[i : j] =� 0 then &gt; R[i : j] is a subset of rules R for span [i : j].
6: bestw(x[i : j]) = argmaxr∈�[i:j] w · Φ({r}) &gt; {r} is a derivation consisting of one rule r.
7: best score = w · Φ(bestw(x[i : j]))
8: for k in (i + 1 .. i + p) do &gt; p is the phrase length limit
9: if best score &lt; w · Φ (bestw (x [i : k]) o bestw(x[k : j])) then
w
10: best(x[i : j]) = bestw (x [i : k]) o bestw(x[k : j]) /
11: best score = w · Φ(bestw(x[i : j]))
on some translation metric (such as BLEU (Pap-
ineni et al., 2002)). In other words, for a train-
ing sentence pair (x, y), if a pair of its trans-
</listItem>
<equation confidence="0.646484">
lations y1 = e(d1) and y2 = e(d2) satisfies
BLEU(y, y1) &gt; BLEU(y, y2), then we expect w ·
Φ(d1) &gt; w · Φ(d2) to hold after tuning.
</equation>
<subsectionHeader confidence="0.937708">
4.1 From MERT to Search-Aware MERT
</subsectionHeader>
<bodyText confidence="0.992752086956522">
Suppose D is a tuning set of (x, y) pairs. Tra-
ditional MERT learns the weight by iteratively
reranking the complete translations towards those
with higher BLEU in the final bin B|x|(x) for
each x in D. Formally, it tries to minimize the
document-level error of 1-best translations:
� )
Sy top1 w(B|x|(x)) ,
(x,y)ED
where top1w(5) is the best derivation in 5 under
model w, and S·(·) is the full derivation metric as
defined in Table 1; in this paper we use Sy(y&apos;) =
−BLEU(y, y&apos;). Here we follow Och (2003) and
Lopez (2008) to simplify the notations, where the
® operator (similar to E) is an over-simplification
for BLEU which, as a document-level metric, is ac-
tually not factorizable across sentences.
Besides reranking the complete translations as
traditional MERT, our search-aware MERT (SA-
MERT) also reranks the partial translations such
that potential translations may survive in the mid-
dle bins during search. Formally, its objective
function is defined as follows:
</bodyText>
<equation confidence="0.604922">
�ESA-MERT(D, w)=
(x,y)ED
</equation>
<bodyText confidence="0.996592555555556">
where top1w(·) is defined in Eq. (4), and Sxy(d),
defined in Table 1, is the generic metric for eval-
uating a partial derivation d which has two imple-
mentations (partial bleu or potential bleu). In or-
der words we can obtain two implementations of
search-aware MERT methods, SA-MERTpar and
SA-MERTpot.
Notice that the traditional MERT is a special
case of SA-MERT where i is fixed to |x|.
</bodyText>
<subsectionHeader confidence="0.95873">
4.2 From MIRA to Search-Aware MIRA
</subsectionHeader>
<bodyText confidence="0.999974461538461">
MIRA is another popular tuning method for SMT.
It firstly introduced in (Watanabe et al., 2007), and
then was improved in (Chiang et al., 2008; Chiang,
2012; Cherry and Foster, 2012). Its main idea is to
optimize a weight such that the model score dif-
ference of a pair of derivations is greater than their
loss difference.
In this paper, we follow the objective function
in (Chiang, 2012; Cherry and Foster, 2012), where
only the violation between hope and fear deriva-
tions is concerned. Formally, we define d+(x, y)
and d−(x, y) as the hope and fear derivations in
the final bin (i.e., complete derivations):
</bodyText>
<equation confidence="0.999058">
d+(x, y) = argmax w0 · Φ(d) − Sy(d) (10)
dEB|x|(x)
d−(x, y) = argmax w0 · Φ(d) + Sy(d) (11)
dEB|x|(x)
</equation>
<bodyText confidence="0.9926434">
where w0 is the current model. The loss function
of MIRA is in Figure 4. The update will be be-
tween d+(x, y) and d−(x, y).
To adapt MIRA to search-aware MIRA (SA-
MIRA), we need to extend the definitions of hope
</bodyText>
<equation confidence="0.8496525">
�EMERT(D, w) =
(top1w(Bi (x)))
</equation>
<page confidence="0.7259586">
�
i=1..|x|
Sx
y
1945
</page>
<table confidence="0.900853083333333">
1 E `MIRA(D, w) = 2C 11w−w0112 + [Aδy(d+(x, y), d (x, y))−w·AΦ(d+(x, y), d (x, y))]+
(x,y)ED
1 (x, y), (x, y))−w·AΦ(d+ (x, y), (x, y))] +
`SA
-MIRA(D, w)= 2C 11w−w0112+ E
� |x |
i=1
[Aδx � d+i d i i d i
y
(x,y)ED
E`PRO(D, w) = E � �
(x,y)ED d1,d2EB|x|(x), Δδy(d1,d2)&gt;0 log 1 + exp(−w·AΦ(d1, d2)) (8)
</table>
<figure confidence="0.7313489">
E
� |x |
i=1
d1,d2E Bi (x),
(d1,d2)&gt;0
Aδxy
� �
log 1 + exp(−w·AΦ(d1, d2)) (9)
E`SA-PRO(D, w) =
(x,y)ED
</figure>
<figureCaption confidence="0.929514666666667">
Figure 4: Loss functions of MIRA, SA-MIRA, PRO, and SA-PRO. The differences between traditional and search-
aware versions are highlighted in gray. The hope and fear derivations are defined in Equations 10–13, and we
define Aδy(d1, d2) = δy(d1) − δy(d2), and Aδxy (d1, d2) = δxy (d1) − δxy (d2). In addition, [θ]+ = max{θ, 01.
</figureCaption>
<bodyText confidence="0.975132">
and fear derivations from the final bin to all bins:
</bodyText>
<equation confidence="0.993439">
d+i (x, y) = argmax w0 · Φ(d) − δy(d) (12)
dE Bi (x)
</equation>
<bodyText confidence="0.92661325">
negative example Φ(d2) − Φ(d1). In sum, search-
aware PRO has |x |times more examples than tradi-
tional PRO. The loss functions of PRO and search-
aware PRO are defined in Figure 4.
</bodyText>
<equation confidence="0.287273">
d i (x, y) = argmax w0 · Φ(d) + δy(d) (13) 5 Experiments
dE Bi (x)
</equation>
<bodyText confidence="0.575113">
The new loss function for SA-MIRA is Eq. 7 in
Figure 4. Now instead of one update per sentence,
we will perform |x |updates, each based on a pair
d+i (x, y) and d i (x, y).
</bodyText>
<subsectionHeader confidence="0.98136">
4.3 From PRO to Search-Aware PRO
</subsectionHeader>
<bodyText confidence="0.99729445">
Finally, the PRO algorithm (Hopkins and May,
2011; Green et al., 2013) aims to correlate the
ranking under model score and the ranking un-
der BLEU score, among all complete derivations
in the final bin. For each preference-pair d1, d2 E
B|x|(x) such that d1 has a higher BLEU score than
d2 (i.e., δy(d1) &lt; δy(d2)), we add one positive ex-
ample Φ(d1) − Φ(d2) and one negative example
Φ(d2) − Φ(d1).
Now to adapt it to search-aware PRO (SA-
PRO), we will have many more examples to con-
sider: besides the final bin, we will include all
preference-pairs in the non-final bins as well. For
each bin Bi(x), for each preference-pairs d1, d2 E
Bi(x) such that d1 has a higher partial or potential
BLEU score than d2 (i.e., δxy (d1) &lt; δxy (d2)), we
add one positive example Φ(d1) − Φ(d2) and one
We evaluate our new tuning methods on two large
scale NIST translation tasks: Chinese-to-English
(CH-EN) and English-to-Chinese (EN-CH) tasks.
</bodyText>
<subsectionHeader confidence="0.994743">
5.1 System Preparation and Data
</subsectionHeader>
<bodyText confidence="0.999717444444445">
We base our experiments on Cubit2 (Huang and
Chiang, 2007), a state-of-art phrase-based system
in Python. We set phrase-limit to 7, beam size to
30 and distortion limit 6. We use the 11 dense
features from Moses (Koehn et al., 2007), which
can lead to good performance and are widely used
in almost all SMT systems. The baseline tuning
methods MERT (Och, 2003), MIRA (Cherry and
Foster, 2012), and PRO (Hopkins and May, 2011)
are from the Moses toolkit, which are batch tuning
methods based on k-best translations. The search-
aware tuning methods are called SA-MERT, SA-
MIRA, and SA-PRO, respectively. Their partial
BLEU versions are marked with superscript 1 and
their potential BLEU versions are marked with su-
perscript 2, as explained in Section 3. All these
search-aware tuning methods are implemented on
the basis of Moses toolkit. They employ the de-
</bodyText>
<footnote confidence="0.979279">
2http://www.cis.upenn.edu/˜lhuang3/cubit/
</footnote>
<page confidence="0.888929">
1946
</page>
<table confidence="0.9999598">
Methods nist03 nist04 nist05 nist06 nist08 avg
MERT 33.6 35.1 33.4 31.6 27.9 –
SA-MERTpar -0.2 +0.0 +0.1 -0.1 -0.1 –
SA-MERTpot +0.8 +1.1 +0.9 +1.7 +1.5 +1.2
MIRA 33.5 35.2 33.5 31.6 27.6 –
SA-MIRApar +0.3 +0.3 +0.4 +0.4 +0.6 –
SA-MIRApot +1.3 +1.6 +1.4 +2.2 +2.6 +1.8
PRO 33.3 35.1 33.3 31.1 27.5 –
*SA-PROpar -2.0 -2.7 -2.2 -1.0 -1.7 –
*SA-PROpot +0.8 +0.5 +1.0 +1.6 +1.6 +1.1
</table>
<tableCaption confidence="0.94398">
Table 2: CH-EN task: BLEU scores on test sets (nist03, nist04, nist05, nist06, and nist08). par: partial BLEU; pot:
potential BLEU. ∗: SA-PRO tunes on only 109 short sentences (with less than 10 words) from nist02.
</tableCaption>
<table confidence="0.999712333333333">
Final bin All bins
MERT 35.5 28.2
SA-MERT -0.1 +3.1
</table>
<tableCaption confidence="0.821797142857143">
Table 3: Evaluation on nist02 tuning set using two
methods: BLEU is used to evaluate 1-best complete
translations in the final bin; while potential BLEU is
used to evaluate 1-best partial translations in all bins.
The search-aware objective cares about (the potential
of) all bins, not just the final bin, which can explain this
result.
</tableCaption>
<bodyText confidence="0.999152181818182">
fault settings following Moses toolkit: for MERT
and SA-MERT, the stop condition is defined by the
weight difference threshold; for MIRA, SA-MIRA,
PRO and SA-PRO, their stop condition is defined
by max iteration set to 25; for all tuning methods,
we use the final weight for testing.
The training data for both CH-EN and EN-CH
tasks is the same, and it is collected from the
NIST2008 Open Machine Translation Campaign.
It consists of about 1.8M sentence pairs, including
about 40M/48M words in Chinese/English sides.
For CH-EN task, the tuning set is nist02 (878
sents), and test sets are nist03 (919 sents), nist04
(1788 sents), nist05 (1082 sents), nist06 (616 sents
from news portion) and nist08 (691 from news por-
tion). For EN-CH task, the tuning set is ssmt07
(995 sents)3, and the test set is nist08 (1859 sents).
For both tasks, all the tuning and test sets contain
4 references.
We use GIZA++ (Och and Ney, 2003) for word
alignment, and SRILM (Stolcke, 2002) for 4-gram
language models with the Kneser-Ney smoothing
</bodyText>
<footnote confidence="0.98194825">
3On EN-CH task, there is only one test set available for us,
and thus we use ssmt07 as the tuning set, which is provided
at the Third Symposium on Statistical Machine Translation
(http://mitlab.hit.edu.cn/ssmt2007.html).
</footnote>
<bodyText confidence="0.9984783">
option. The LM for EN-CH is trained on its target
side; and that for CH-EN is trained on the Xin-
hua portion of Gigaword. We use BLEU-4 (Pap-
ineni et al., 2002) with “average ref-len” to evalu-
ate the translation performance for all experiments.
In particular, the character-based BLEU-4 is em-
ployed for EN-CH task. Since all tuning meth-
ods involve randomness, all scores reported are av-
erage of three runs, as suggested by Clark et al.
(2011) for fairer comparisons.
</bodyText>
<subsectionHeader confidence="0.9962">
5.2 Main Results on CH-EN Task
</subsectionHeader>
<bodyText confidence="0.99996184">
Table 2 depicts the main results of our methods on
CH-EN translation task. On all five test sets, our
methods consistently achieve substantial improve-
ments with two pruning options: SA-MERT pot
gains +1.2 BLEU points over MERT on average;
and SA-MIRApot gains +1.8 BLEU points over
MIRA on average as well. SA-PROpot, however,
does not work out of the box when we use the en-
tire nist02 as the tuning set, which might be at-
tributed to the “Monster” behavior (Nakov et al.,
2013). To alleviate this problem, we only use the
109 short sentences with less than 10 words from
nist02 as our new tuning data. To our supurise,
this trick works really well (despite using much
less data), and also made SA-PROpot an order of
magnitude faster. This further confirms that our
search-aware tuning is consistent across all tuning
methods and datasets.
As discussed in Section 3, evaluation metrics
of partial derivations are crucial for search-aware
tuning. Besides the principled “potential BLEU”
version of search-aware tuning (i.e. SA-MERTpot,
SA-MIRApot, and SA-PROpot), we also run the
simple “partial BLEU” version of search-aware
tuning (i.e. SA-MERTpar, SA-MIRApar, and SA-
</bodyText>
<page confidence="0.972675">
1947
</page>
<figure confidence="0.99767">
1 2 4 8 16 32 64
Beam Size
</figure>
<figureCaption confidence="0.9957055">
Figure 5: BLEU scores against beam size on nist05.
Our search-aware tuning can achieve (almost) the same
BLEU scores with much smaller beam size (beam of 4
vs. 16).
</figureCaption>
<table confidence="0.9992454">
methods nist02 nist05
1-best MERT 35.5 33.4
SA-MERT -0.1 +0.9
Oracle MERT 44.3 41.1
SA-MERT +0.5 +1.6
</table>
<tableCaption confidence="0.96052">
Table 4: The k-best oracle BLEU comparison between
MERT and SA-MERT.
</tableCaption>
<bodyText confidence="0.999487777777778">
PROpar). In Table 2, we can see that they may
achieve slight improvements over tradition tuning
on some datasets, but SA-MERTp°t, SA-MIRAp°t,
and SA-PROp°t using potential BLEU consistently
outperform them on all the datasets.
Even though our search-aware tuning gains sub-
stantially on all test sets, it does not gain signif-
icantly on nist02 tuning set. The main reason is
that, search-aware tuning optimizes an objective
(i.e. BLEU for all bins) which is different from
the objective for evaluation (i.e. BLEU for the final
bin), and thus it is not quite fair to evaluate the
complete translations for search-aware tuning as
the same done for traditional tuning on the tuning
set. Actally, if we evaluate the potential BLEU for
all partial translations, we find that search-aware
tuning gains about 3.0 BLEU on nist02 tuning set,
as shown in Table 3.
</bodyText>
<subsectionHeader confidence="0.991022">
5.3 Analysis on CH-EN Task
</subsectionHeader>
<bodyText confidence="0.9983754">
Different beam size. Since our search-aware tun-
ing considers the rankings of partial derivations
in the middle bins besides complete ones in the
last bin, ideally, if the weight learned by search-
aware tuning can exactly evaluate partial deriva-
</bodyText>
<table confidence="0.996176">
Diversity nist02 nist05
MERT 0.216 0.204
SA-MERT 0.227 0.213
</table>
<tableCaption confidence="0.91113425">
Table 5: The diversity comparison based on the k-best
list in the final bin on both tuning and nist05 test sets
by tuning methods. The higher the metric is, the more
diverse the k-best list is.
</tableCaption>
<bodyText confidence="0.997522684210526">
tions, then accurate partial derivations will rank
higher according to model score. In this way, even
with small beam size, these accurate partial deriva-
tions may still survive in the bins. Therefore, it
is expected that search-aware tuning can achieve
good performance with smaller beam size. To
justify our conjecture, we run SA-MERTp°t with
different beam size (2,4,8,16,30,100), its testing
results on nist05 are depicted in Figure 5. our
mehtods achieve better trade-off between perfor-
mance and efficiey. Figure 5 shows that search-
aware tuning is consistent with all beam sizes, and
as a by-product, search-aware MERT with a beam
of 4 can achieve almost identical BLEU scores to
MERT with beam of 16.
Oracle BLEU. In addition, we examine the BLEU
ponits of oracle for MERT and SA-MERT. We
use the weight tuned by MERT and SA-MERT for
k-best decoding on nist05 test set, and calculate
the oracle over these two k-best lists. The oracle
BLEU comparison is shown in Table 4. On nist05
test set, for MERT the oracle BLEU is 41.1; while
for SA-MERT its oracle BLEU is 42.7, i.e. with 1.6
BLEU improvements. Although search-aware tun-
ing employs the objective different from the objec-
tive of evaluation on nist02 tuning set, it still gains
0.5 BLEU improvements.
Diversity. A k-best list with higher diversity can
better represent the entire decoding space, and thus
tuning on such a k-best list may lead to better
tesing performance (Gimpel et al., 2013). Intu-
itively, tuning with all bins will encourage the di-
versity in prefix, infix and suffix of complete trans-
lations in the final bin. To testify this, we need a
diversity metric.
Indeed, Gimpel et al. (2013) define a diversity
metric based on the n-gram matches between two
sentences y and y&apos; as follows:
</bodyText>
<figure confidence="0.4547157">
Qyi:i+q = y&apos;j:j+q]
Traditional MERT Tuning
Search-aware MERT Tuning
BLEU 35
34
33
32
31
30
d(y, y&apos;) = −
</figure>
<page confidence="0.603847">
|y|−q
i=1
|y&apos;|−q
�
j=1
1948
</page>
<table confidence="0.999291">
Methods set tuning set # words nist03 test sets (4-refs) nist08
# refs # sents nist04 nist05 nist06
MERT nist02 4 878 23181 33.6 35.1 33.4 31.6 27.9
SA-MERTpot nist02 4 878 23181 34.4 36.2 34.3 33.3 29.4
MAXFORCE nist02-px 1 434 6227 29.0 30.3 28.7 26.8 24.1
MAXFORCE train-r-part 1 1225 22684 31.7 33.5 31.5 30.3 26.7
MERT nist02-r 1 92 1173 31.6 32.7 31.3 29.3 25.9
SA-MERTpot nist02-r 1 92 1173 33.5 35.0 33.4 31.5 28.0
</table>
<tableCaption confidence="0.986921">
Table 6: Comparisons with MAXFORCE in terms of BLEU. nist02-px is the non-trivial reachable prefix-data from
nist02 via forced decoding; nist02-r is a subset of nist02-px consisting of the fully reachable data; train-r is a
subset of fully reachable data from training data that is comparable in size to nist02. All experiments use only
dense features.
</tableCaption>
<bodyText confidence="0.990107333333333">
where q = n − 1, and Qx] equals to 1 if x is true, 0
otherwise. This metric, however, has the following
critical problems:
</bodyText>
<listItem confidence="0.82710125">
• it is not length-normalized: longer strings will
look as if they are more different.
• it suffers from duplicates in n-grams. Af-
ter normalization, d(y, y) will exceed -1 for
any y. In the extreme case, consider y1 =
“the the the the” and y2 = “the ... the” with
10 the’s then will be considered identical af-
ter normalization by length.
</listItem>
<bodyText confidence="0.996738">
So we define a balanced metric based on their met-
ric
</bodyText>
<equation confidence="0.999420666666667">
2 x d(y, y0)
d0(y, y0) = 1 −
d(y, y) + d(y0, y0)
</equation>
<bodyText confidence="0.987851">
which satisfies the following nice properties:
</bodyText>
<listItem confidence="0.991248666666667">
• d0(y, y) = 0 for all y;
• 0 &lt; d0(y, y0) &lt; 1 for all y, y0;
• d0(y, y0) = 1 if y and y0 is completely dis-
joint.
• it does not suffer from duplicates, and can dif-
ferentiate y1 and y2 defined above.
</listItem>
<bodyText confidence="0.99998225">
With this new metric, we evaluate the diversity
of k-best lists for both MERT and SA-MERT. As
shown in Table 5, on both tuning and test sets the
k-best list generated by SA-MERT is more diverse.
</bodyText>
<subsectionHeader confidence="0.9984465">
5.4 Comparison with Max-Violation
Perceptron
</subsectionHeader>
<bodyText confidence="0.991956">
Our method considers the rankings of partial
derivations, which is simlar to MAXFORCE
</bodyText>
<table confidence="0.974901333333333">
B`ush´ı yˇu Sh¯al´ong jˇux´ıng hu`ıt´an Bush and Sharon held a meeting
Bush held talks with Sharon
qi¯angshˇou b`ei jˇıngf¯ang j¯ıb`ı police killed the gunman
the gunman was shot dead
⇓
B`ush´ı yˇu Sh¯al´ong jˇux´ıng hu`ıt´an Bush and Sharon held a meeting
B`ush´ı yˇu Sh¯al´ong jˇux´ıng hu`ıt´an Bush held talks with Sharon
qi¯angshˇou b`ei jˇıngf¯ang j¯ıb`ı police killed the gunman
qi¯angshˇou b`ei jˇıngf¯ang j¯ıb`ı the gunman was shot dead
</table>
<figureCaption confidence="0.9211552">
Figure 6: Transformation of a tuning set in forced de-
coding for MAXFORCE: the original tuning set (on the
top) contains 2 source sentences with 2 references for
each; while the transformed set (on the bottom) con-
tains 4 source sentences with one reference for each.
</figureCaption>
<bodyText confidence="0.99994012">
method (Yu et al., 2013), and thus we re-
implement MAXFORCE method. Since the nist02
tuning set contains 4 references and forced decod-
ing is performed for only one reference, we enlarge
the nist02 set to a variant set following the trans-
formation in Figure 6, and obtain a variant tun-
ing set denoted as nist02-px, which consists of 4-
times sentence-pairs. On nist02-px, the non-trivial
reachable prefix-data only accounts for 12% sen-
tences and 7% words. Both these sentence-level
and the word-level percentages are much lower
than those on the training data as shown in Ta-
ble 3 from (Yu et al., 2013). This is because there
are many OOV words on a tuning set. We run the
MAXFORCE with dense feature setting on nist02-
px and its testing results are shown in Table 6. We
can see that on all the test sets, its testing perfor-
mance is lower than that of SA-MERTpot tuning on
nist02 with about 5 BLEU points.
For more direct comparisons, we run MERT and
SA-MERTpot on a data set similar to nist02-px. We
pick up the fully reachable sentences from nist02-
px, remove the sentence pairs with the same source
side, and get a new tuning set denoted as nist02-r.
When tuning on nist02-r, we find that MERT is bet-
</bodyText>
<page confidence="0.986903">
1949
</page>
<table confidence="0.9979796">
Methods tuning-set nist08
MERT ssmt07 31.3
MAXFORCE train-r-part 29.9
SA-MERTpar ssmt07 31.3
SA-MERTpot ssmt07 31.7
</table>
<tableCaption confidence="0.9677766">
Table 7: EN-CH task: BLEU scores on nist08 test set for
MERT, SA-MERT, and MAXFORCE on different tun-
ing sets. train-r-part is a part of fully reachable data
from training data via forced decoding. All the tuning
methods run with dense feature set.
</tableCaption>
<bodyText confidence="0.999924333333333">
ter than MAXFORCE,4 and SA-MERTpot are much
better than MERT on all the test sets. In addition,
we select about 1.2k fully reachable sentence pairs
from training data, and run the forced decoding
on this new tuning data (denoted as train-r-part),
which is with similar size to nist02. 5 With more
tuning data, the performance of max-violation is
improved largely, but it is still underperformed by
SA-MERTpot.
</bodyText>
<subsectionHeader confidence="0.890798">
5.5 Results on EN-CH Translation Task
</subsectionHeader>
<bodyText confidence="0.999985666666667">
We also run our search-aware tuning method on
EN-CH task. We use SA-MERT as the representa-
tive of search-aware tuning methods, and compare
its two versions with other tuning methods MERT,
MAXFORCE. For MAXFORCE, we first run forced
decoding on the training data and then select about
1.2k fully reachable sentence pairs as its tuning
set (denoted as train-r-part). For MERT, SA-
MERTpot, and SA-MERTpar, their tuning set is
ssmt07. Table 7 shows that SA-MERTpot is much
better than MAXFORCE, i.e. it achieves 0.4 BLEU
improvements over MERT. Finally, comparison
between SA-MERTpot and SA-MERTpar shows
that the potential BLEU is better for evaluation of
partial derivations.
</bodyText>
<subsectionHeader confidence="0.999166">
5.6 Discussions on Tuning Efficiency
</subsectionHeader>
<bodyText confidence="0.999592">
As shown in Figure 2, search-aware tuning consid-
ers all partial translations in the middle bins beside
all complete translations in the last bin, and thus its
total number of training examples is much greater
than that of the traditional tuning. In details, sup-
</bodyText>
<footnote confidence="0.963182625">
4Under the dense feature setting, MAXFORCE is worse
than standard MERT. This result is consistent with that in
Figure 12 of (Yu et al., 2013).
5We run MAXFORCE on train-r-part, i.e. a part of reach-
able data instead of the entire reachable data, as we found
that more tuning data does not necessarily lead to better test-
ing performance under dense feature setting in our internal
experiments.
</footnote>
<table confidence="0.969450333333333">
Optimization time MERT MIRA PRO
basline 3 2 2
search-aware 50 7 6
</table>
<tableCaption confidence="0.971558">
Table 8: Search-aware tuning slows down MERT sig-
</tableCaption>
<bodyText confidence="0.98244224">
nificantly, and MIRA and PRO moderately. The time (in
minutes) is for optimization only (excluding decoding)
and measured at the last iteration during the entire tun-
ing (search aware tuning does not increase the number
of iterations in our experiments). The decoding time is
20 min. on a single CPU but can be parallelized.
pose the tuning data consists of two sentences with
length 10 and 30, respectively. Then, for tradi-
tional tuning its number of training examples is 2;
but for search-aware tuning, the total number is 40.
More training examples makes our search-aware
tuning slower than the traditional tuning.
Table 8 shows the training time comparisons
between search-aware tuning and the traditional
tuning. From this Table, one can see that both
SA-MIRA and SA-PRO are with the same order
of magtitude as MIRA and PRO; but SA-MERT
is much slower than MERT. The main reason is
that, as the training examples increase dramati-
cally, the envelope calculation for exact line search
(see (Och, 2003)) in MERT is less efficient than the
update based on (sub-)gradient with inexact line
search in MIRA and PRO.
One possible solution to speed up SA-MERT is
the parallelization but we leave it for future work.
</bodyText>
<sectionHeader confidence="0.999965" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999723210526316">
Many tuning methods have been proposed for
SMT so far. These methods differ by the ob-
jective function or training mode: their objective
functions are based on either evaluation-directed
loss (Och, 2003; Galley and Quirk, 2011; Gal-
ley et al., 2013) or surrogate loss (Hopkins and
May, 2011; Gimpel and Smith, 2012; Eidelman
et al., 2013); they are either batch (Och, 2003;
Hopkins and May, 2011; Cherry and Foster, 2012)
or online mode (Watanabe, 2012; Simianer et al.,
2012; Flanigan et al., 2013; Green et al., 2013).
These methods share a common characteristic:
they learn a weight by iteratively reranking a set of
complete translations represented by k-best (Och,
2003; Watanabe et al., 2007; Chiang et al., 2008)
or lattice (hypergraph) (Tromble et al., 2008; Ku-
mar et al., 2009), and they do not care about search
errors that potential partial translations may be
pruned during decoding, even if they agree with
</bodyText>
<page confidence="0.977754">
1950
</page>
<bodyText confidence="0.999912085714286">
that their decoders are built on the beam pruning
based search.
On the other hand, it is well-known that search
errors can undermine the standard training for
many beam search based NLP systems (Huang et
al., 2012). As a result, Collins and Roark (2004)
and Huang et al. (2012) propose the early-update
and max-violation update to deal with the search
errors. Their idea is to update on prefix or par-
tial hypotheses when the correct solution falls out
of the beam. This idea has been successfully
used in many NLP tasks and improves the perfor-
mance over the state-of-art NLP systems (Huang
and Sagae, 2010; Huang et al., 2012; Zhang et al.,
2013).
Goldberg and Nivre (2012) propose the concept
of “dynamic oracle” which is the absolute best po-
tential of a partial derivation, and is more akin to
a strictly admissible heuristic. This idea inspired
and is closely related to our potential BLEU, except
that in our case, computing an admissible heuristic
is too costly, so our potential BLEU is more like an
average potential.
Gesmundo and Henderson (2014) also consider
the rankings between partial translation pairs as
well. However, they evaluate a partial translation
through extending it to a complete translation by
re-decoding, and thus they need many passes of
decoding for many partial translations, while ours
only need one pass of decoding for all partial trans-
lations and thus is much more efficient. In sum-
mary, our tuning framework is more general and
has potential to be employed over all the state-of-
art tuning methods mentioned above, even though
ours is only tested on three popular methods.
</bodyText>
<sectionHeader confidence="0.996438" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999996384615385">
We have presented a simple yet powerful approach
of “search-aware tuning” by promoting promising
partial derivations, and this idea can be applied to
all three popular tuning methods. To solve the key
challenge of evaluating partial derivations, we de-
velop a concept of “potential BLEU” inspired by
future cost in MT decoding. Extensive experi-
ments confirmed substantial BLEU gains with only
dense features. We believe our framework can be
applied to sparse feature settings and other transla-
tion paradigms, and potentially to other structured
prediction problems (such as incremental parsing)
as well.
</bodyText>
<sectionHeader confidence="0.990993" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.995463875">
We thank the three anonymous reviewers for sug-
gestions, and Kai Zhao and Feifei Zhai for dis-
cussions. In particular, we thank reviewer #3 and
Chin-Yew Lin for pushing us to think about di-
versity. This project was supported by DARPA
FA8750-13-2-0041 (DEFT), NSF IIS-1449278, a
Google Faculty Research Award, and a PSC-
CUNY Award.
</bodyText>
<sectionHeader confidence="0.997547" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999475225">
Colin Cherry and George Foster. 2012. Batch tuning
strategies for statistical machine translation. In Pro-
ceedings of NAACL-HLT, pages 427–436, Montr´eal,
Canada, June.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of EMNLP
2008.
David Chiang. 2012. Hope and fear for discriminative
training of statistical translation models. J. Machine
Learning Research (JMLR), 13:1159–1187.
Jonathan H. Clark, Chris Dyer, Alon Lavie, and
Noah A. Smith. 2011. Better hypothesis testing for
statistical machine translation: Controlling for opti-
mizer instability. In Proc. of ACL 2011.
Michael Collins and Brian Roark. 2004. Incremental
parsing with the perceptron algorithm. In Proceed-
ings of ACL.
Vladimir Eidelman, Yuval Marton, and Philip Resnik.
2013. Online relative margin maximization for sta-
tistical machine translation. In Proceedings of ACL,
pages 1116–1126, Sofia, Bulgaria, August.
Jeffrey Flanigan, Chris Dyer, and Jaime Carbonell.
2013. Large-scale discriminative training for statis-
tical machine translation using held-out line search.
In Proceedings of NAACL-HLT, pages 248–258, At-
lanta, Georgia, June.
Michel Galley and Chris Quirk. 2011. Optimal search
for minimum error rate training. In Proceedings of
EMNLP, pages 38–49, Edinburgh, Scotland, UK.,
July.
Michel Galley, Chris Quirk, Colin Cherry, and Kristina
Toutanova. 2013. Regularized minimum error rate
training. In Proceedings of EMNLP, pages 1948–
1959, Seattle, Washington, USA, October.
Andrea Gesmundo and James Henderson. 2014. Undi-
rected machine translation with discriminative rein-
forcement learning. In Proceedings of the 14th Con-
ference of the European Chapter of the Association
for Computational Linguistics, April.
</reference>
<page confidence="0.868147">
1951
</page>
<reference confidence="0.999933643564357">
Kevin Gimpel and Noah A. Smith. 2012. Struc-
tured ramp loss minimization for machine transla-
tion. In Proceedings of NAACL-HLT, pages 221–
231, Montr´eal, Canada, June.
Kevin Gimpel, Dhruv Batra, Chris Dyer, and Gregory
Shakhnarovich. 2013. A systematic exploration of
diversity in machine translation. In Proceedings of
the 2013 Conference on Empirical Methods in Natu-
ral Language Processing, October.
Yoav Goldberg and Joakim Nivre. 2012. Training
deterministic parsers with non-deterministic oracles.
In Proceedings of COLING 2012.
Spence Green, Sida Wang, Daniel Cer, and Christopher
Manning. 2013. Fast and adaptive online training
of feature-rich translation models. In Proc. of ACL
2013.
P. E. Hart, N. J. Nilsson, and B. Raphael. 1968. A for-
mal basis for the heuristic determination of minimum
cost paths. IEEE Transactions on Systems Science
and Cybernetics, 4(2):100–107.
Mark Hopkins and Jonathan May. 2011. Tuning as
ranking. In Proceedings of EMNLP.
Liang Huang and David Chiang. 2005. Better k-best
Parsing. In Proceedings of the Ninth International
Workshop on Parsing Technologies (IWPT-2005).
Liang Huang and David Chiang. 2007. Forest rescor-
ing: Fast decoding with integrated language models.
In Proceedings of ACL, Prague, Czech Rep., June.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In
Proceedings of ACL 2010.
Liang Huang, Suphan Fayong, and Yang Guo. 2012.
Structured perceptron with inexact search. In Pro-
ceedings of NAACL.
Kevin Knight. 1999. Decoding complexity in word-
replacement translation models. Computational Lin-
guistics, 25(4):607–615.
P. Koehn, H. Hoang, A. Birch, C. Callison-Burch,
M. Federico, N. Bertoldi, B. Cowan, W. Shen,
C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin,
and E. Herbst. 2007. Moses: open source toolkit
for statistical machine translation. In Proceedings of
ACL: Demonstrations.
Philipp Koehn. 2004. Pharaoh: a beam search decoder
for phrase-based statistical machine translation mod-
els. In Proceedings of AMTA, pages 115–124.
Shankar Kumar, Wolfgang Macherey, Chris Dyer, and
Franz Och. 2009. Efficient minimum error rate
training and minimum bayes-risk decoding for trans-
lation hypergraphs and lattices. In Proceedings of
ACL-IJCNLP, Suntec, Singapore, August.
Zhifei Li and Sanjeev Khudanpur. 2009. Efficient
extraction of oracle-best translations from hyper-
graphs. In Proceedings of HLT-NAACL Short Pa-
pers.
Adam Lopez. 2008. Statistical machine translation.
ACM Comput. Surv., 40(3).
Preslav Nakov, Francisco Guzmn, and Stephan Voge.
2013. A tale about pro and monsters. In Proceedings
of ACL Short Papers.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Comput. Linguist., 29(1):19–51, March.
Franz Joseph Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
ACL, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalu-
ation of machine translation. In Proceedings ofACL,
pages 311–318, Philadephia, USA, July.
Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012.
Joint feature selection in distributed stochastic learn-
ing for large-scale discriminative training in smt. In
Proceedings of ACL, pages 11–21, Jeju Island, Ko-
rea, July.
Andreas Stolcke. 2002. Srilm - an extensible lan-
guage modeling toolkit. In Proceedings of ICSLP,
volume 30, pages 901–904.
Roy Tromble, Shankar Kumar, Franz Och, and Wolf-
gang Macherey. 2008. Lattice Minimum Bayes-
Risk decoding for statistical machine translation. In
Proceedings of EMNLP, pages 620–629, Honolulu,
Hawaii, October.
Taro Watanabe, Jun Suzuki, Hajime Tsukada, and
Hideki Isozaki. 2007. Online large-margin training
for statistical machine translation. In Proceedings of
EMNLP-CoNLL.
Taro Watanabe. 2012. Optimized online rank learning
for machine translation. In Proceedings of NAACL-
HLT, pages 253–262, Montr´eal, Canada, June.
Heng Yu, Liang Huang, Haitao Mi, and Kai Zhao.
2013. Max-violation perceptron and forced decod-
ing for scalable mt training. In Proceedings of
EMNLP 2013.
Hao Zhang, Liang Huang, Kai Zhao, and Ryan McDon-
ald. 2013. Online learning with inexact hypergraph
search. In Proceedings of EMNLP 2013.
Kai Zhao, Liang Huang, Haitao Mi, and Abe Itty-
cheriah. 2014. Hierarchical mt training using max-
violation perceptron. In Proceedings of ACL, Balti-
more, Maryland, June.
</reference>
<page confidence="0.995761">
1952
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.487988">
<title confidence="0.841082333333333">Search-Aware Tuning for Machine Translation Lemao Queens</title>
<affiliation confidence="0.886741">City University of New</affiliation>
<email confidence="0.99944">lemaoliu@gmail.com</email>
<abstract confidence="0.996666176470588">Parameter tuning is an important problem in statistical machine translation, but surprisingly, most existing methods such as MERT, and PRO are search, while search errors could severely degrade translation quality. We propose a searchframework to promote partial translations, preventing them from being pruned. To do so we develop two metrics to evaluate partial derivations. Our technique can be applied to all of the three above-mentioned tuning methods, and extensive experiments on Chinese-to-English and English-to-Chinese translation show up +2.6 over search-agnostic baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>George Foster</author>
</authors>
<title>Batch tuning strategies for statistical machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>427--436</pages>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="13958" citStr="Cherry and Foster, 2012" startWordPosition="2398" endWordPosition="2401">MERT(D, w)= (x,y)ED where top1w(·) is defined in Eq. (4), and Sxy(d), defined in Table 1, is the generic metric for evaluating a partial derivation d which has two implementations (partial bleu or potential bleu). In order words we can obtain two implementations of search-aware MERT methods, SA-MERTpar and SA-MERTpot. Notice that the traditional MERT is a special case of SA-MERT where i is fixed to |x|. 4.2 From MIRA to Search-Aware MIRA MIRA is another popular tuning method for SMT. It firstly introduced in (Watanabe et al., 2007), and then was improved in (Chiang et al., 2008; Chiang, 2012; Cherry and Foster, 2012). Its main idea is to optimize a weight such that the model score difference of a pair of derivations is greater than their loss difference. In this paper, we follow the objective function in (Chiang, 2012; Cherry and Foster, 2012), where only the violation between hope and fear derivations is concerned. Formally, we define d+(x, y) and d−(x, y) as the hope and fear derivations in the final bin (i.e., complete derivations): d+(x, y) = argmax w0 · Φ(d) − Sy(d) (10) dEB|x|(x) d−(x, y) = argmax w0 · Φ(d) + Sy(d) (11) dEB|x|(x) where w0 is the current model. The loss function of MIRA is in Figure </context>
<context position="17384" citStr="Cherry and Foster, 2012" startWordPosition="3042" endWordPosition="3045">(d2)), we add one positive example Φ(d1) − Φ(d2) and one We evaluate our new tuning methods on two large scale NIST translation tasks: Chinese-to-English (CH-EN) and English-to-Chinese (EN-CH) tasks. 5.1 System Preparation and Data We base our experiments on Cubit2 (Huang and Chiang, 2007), a state-of-art phrase-based system in Python. We set phrase-limit to 7, beam size to 30 and distortion limit 6. We use the 11 dense features from Moses (Koehn et al., 2007), which can lead to good performance and are widely used in almost all SMT systems. The baseline tuning methods MERT (Och, 2003), MIRA (Cherry and Foster, 2012), and PRO (Hopkins and May, 2011) are from the Moses toolkit, which are batch tuning methods based on k-best translations. The searchaware tuning methods are called SA-MERT, SAMIRA, and SA-PRO, respectively. Their partial BLEU versions are marked with superscript 1 and their potential BLEU versions are marked with superscript 2, as explained in Section 3. All these search-aware tuning methods are implemented on the basis of Moses toolkit. They employ the de2http://www.cis.upenn.edu/˜lhuang3/cubit/ 1946 Methods nist03 nist04 nist05 nist06 nist08 avg MERT 33.6 35.1 33.4 31.6 27.9 – SA-MERTpar -0</context>
<context position="33183" citStr="Cherry and Foster, 2012" startWordPosition="5726" endWordPosition="5729">efficient than the update based on (sub-)gradient with inexact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-kn</context>
</contexts>
<marker>Cherry, Foster, 2012</marker>
<rawString>Colin Cherry and George Foster. 2012. Batch tuning strategies for statistical machine translation. In Proceedings of NAACL-HLT, pages 427–436, Montr´eal, Canada, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="13918" citStr="Chiang et al., 2008" startWordPosition="2392" endWordPosition="2395">nction is defined as follows: �ESA-MERT(D, w)= (x,y)ED where top1w(·) is defined in Eq. (4), and Sxy(d), defined in Table 1, is the generic metric for evaluating a partial derivation d which has two implementations (partial bleu or potential bleu). In order words we can obtain two implementations of search-aware MERT methods, SA-MERTpar and SA-MERTpot. Notice that the traditional MERT is a special case of SA-MERT where i is fixed to |x|. 4.2 From MIRA to Search-Aware MIRA MIRA is another popular tuning method for SMT. It firstly introduced in (Watanabe et al., 2007), and then was improved in (Chiang et al., 2008; Chiang, 2012; Cherry and Foster, 2012). Its main idea is to optimize a weight such that the model score difference of a pair of derivations is greater than their loss difference. In this paper, we follow the objective function in (Chiang, 2012; Cherry and Foster, 2012), where only the violation between hope and fear derivations is concerned. Formally, we define d+(x, y) and d−(x, y) as the hope and fear derivations in the final bin (i.e., complete derivations): d+(x, y) = argmax w0 · Φ(d) − Sy(d) (10) dEB|x|(x) d−(x, y) = argmax w0 · Φ(d) + Sy(d) (11) dEB|x|(x) where w0 is the current model.</context>
<context position="33481" citStr="Chiang et al., 2008" startWordPosition="5774" endWordPosition="5777">tion or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea is to update on prefix </context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proceedings of EMNLP 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hope and fear for discriminative training of statistical translation models.</title>
<date>2012</date>
<journal>J. Machine Learning Research (JMLR),</journal>
<pages>13--1159</pages>
<contexts>
<context position="996" citStr="Chiang, 2012" startWordPosition="147" endWordPosition="148">e framework to promote promising partial translations, preventing them from being pruned. To do so we develop two metrics to evaluate partial derivations. Our technique can be applied to all of the three above-mentioned tuning methods, and extensive experiments on Chinese-to-English and English-to-Chinese translation show up to +2.6 BLEU gains over search-agnostic baselines. 1 Introduction Parameter tuning has been a key problem for machine translation since the statistical revolution. However, most existing tuning algorithms treat the decoder as a black box (Och, 2003; Hopkins and May, 2011; Chiang, 2012), ignoring the fact that many potentially promising partial translations are pruned by the decoder due to the prohibitively large search space. For example, the popular beam-search decoding algorithm for phrase-based MT (Koehn, 2004) only explores O(nb) items for a sentence of n words (with a beam width of b), while the full search space is O(2nn2) or worse (Knight, 1999). As one of the very few exceptions to the “search-agnostic” majority, Yu et al. (2013) and Zhao et al. (2014) propose a variant of the perceptron algorithm that learns to keep the reference translations in the beam or chart. </context>
<context position="6589" citStr="Chiang, 2012" startWordPosition="1091" endWordPosition="1092">e accurate translations in the final bin, but more importantly those potentially promising partial derivations in non-final bins. The key challenge, however, is how to evaluate the “promise” or “potential” of a partial derivation. In this Section, we develop two such measures, a simple “partial BLEU” (Section 3.1) and a more principled “potential BLEU” (Section 3.2). In Section 4, we will then adapt traditional tuning methods to their search-aware versions using these partial evaluation metrics. 3.1 Solution 1: Simple and Naive Partial BLEU Inspired by a trick in (Li and Khudanpur, 2009) and (Chiang, 2012) for oracle or hope extraction, we use a very simple metric to evaluate partial translations for tuning. For a given derivation d, the basic idea is to evaluate the (short) partial translation e(d) against the (full) reference y, but using a “prorated” reference length proportional to c(d) which is the number of Chinese words covered so far in d: |y |· |c(d)|/|x| For example, if d has covered 2 words on a 8- word Chinese sentence with a 12-word English reference, then the “effective reference length” is 12 x 2/8 = 3. We call this method “partial BLEU” since it does not complete the translation</context>
<context position="13932" citStr="Chiang, 2012" startWordPosition="2396" endWordPosition="2397">follows: �ESA-MERT(D, w)= (x,y)ED where top1w(·) is defined in Eq. (4), and Sxy(d), defined in Table 1, is the generic metric for evaluating a partial derivation d which has two implementations (partial bleu or potential bleu). In order words we can obtain two implementations of search-aware MERT methods, SA-MERTpar and SA-MERTpot. Notice that the traditional MERT is a special case of SA-MERT where i is fixed to |x|. 4.2 From MIRA to Search-Aware MIRA MIRA is another popular tuning method for SMT. It firstly introduced in (Watanabe et al., 2007), and then was improved in (Chiang et al., 2008; Chiang, 2012; Cherry and Foster, 2012). Its main idea is to optimize a weight such that the model score difference of a pair of derivations is greater than their loss difference. In this paper, we follow the objective function in (Chiang, 2012; Cherry and Foster, 2012), where only the violation between hope and fear derivations is concerned. Formally, we define d+(x, y) and d−(x, y) as the hope and fear derivations in the final bin (i.e., complete derivations): d+(x, y) = argmax w0 · Φ(d) − Sy(d) (10) dEB|x|(x) d−(x, y) = argmax w0 · Φ(d) + Sy(d) (11) dEB|x|(x) where w0 is the current model. The loss func</context>
</contexts>
<marker>Chiang, 2012</marker>
<rawString>David Chiang. 2012. Hope and fear for discriminative training of statistical translation models. J. Machine Learning Research (JMLR), 13:1159–1187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan H Clark</author>
<author>Chris Dyer</author>
<author>Alon Lavie</author>
<author>Noah A Smith</author>
</authors>
<title>Better hypothesis testing for statistical machine translation: Controlling for optimizer instability.</title>
<date>2011</date>
<booktitle>In Proc. of ACL</booktitle>
<contexts>
<context position="20560" citStr="Clark et al. (2011)" startWordPosition="3573" endWordPosition="3576"> available for us, and thus we use ssmt07 as the tuning set, which is provided at the Third Symposium on Statistical Machine Translation (http://mitlab.hit.edu.cn/ssmt2007.html). option. The LM for EN-CH is trained on its target side; and that for CH-EN is trained on the Xinhua portion of Gigaword. We use BLEU-4 (Papineni et al., 2002) with “average ref-len” to evaluate the translation performance for all experiments. In particular, the character-based BLEU-4 is employed for EN-CH task. Since all tuning methods involve randomness, all scores reported are average of three runs, as suggested by Clark et al. (2011) for fairer comparisons. 5.2 Main Results on CH-EN Task Table 2 depicts the main results of our methods on CH-EN translation task. On all five test sets, our methods consistently achieve substantial improvements with two pruning options: SA-MERT pot gains +1.2 BLEU points over MERT on average; and SA-MIRApot gains +1.8 BLEU points over MIRA on average as well. SA-PROpot, however, does not work out of the box when we use the entire nist02 as the tuning set, which might be attributed to the “Monster” behavior (Nakov et al., 2013). To alleviate this problem, we only use the 109 short sentences wi</context>
</contexts>
<marker>Clark, Dyer, Lavie, Smith, 2011</marker>
<rawString>Jonathan H. Clark, Chris Dyer, Alon Lavie, and Noah A. Smith. 2011. Better hypothesis testing for statistical machine translation: Controlling for optimizer instability. In Proc. of ACL 2011.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental parsing with the perceptron algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="33940" citStr="Collins and Roark (2004)" startWordPosition="5853" endWordPosition="5856">acteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea is to update on prefix or partial hypotheses when the correct solution falls out of the beam. This idea has been successfully used in many NLP tasks and improves the performance over the state-of-art NLP systems (Huang and Sagae, 2010; Huang et al., 2012; Zhang et al., 2013). Goldberg and Nivre (2012) propose the concept of “dynamic oracle” which is the absolute best potential of a partial derivation, and is more akin to a strictly admissible heuristic. This idea inspired and i</context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Michael Collins and Brian Roark. 2004. Incremental parsing with the perceptron algorithm. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Eidelman</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online relative margin maximization for statistical machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>1116--1126</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="33100" citStr="Eidelman et al., 2013" startWordPosition="5712" endWordPosition="5715">the envelope calculation for exact line search (see (Och, 2003)) in MERT is less efficient than the update based on (sub-)gradient with inexact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their de</context>
</contexts>
<marker>Eidelman, Marton, Resnik, 2013</marker>
<rawString>Vladimir Eidelman, Yuval Marton, and Philip Resnik. 2013. Online relative margin maximization for statistical machine translation. In Proceedings of ACL, pages 1116–1126, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Flanigan</author>
<author>Chris Dyer</author>
<author>Jaime Carbonell</author>
</authors>
<title>Large-scale discriminative training for statistical machine translation using held-out line search.</title>
<date>2013</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>248--258</pages>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="33260" citStr="Flanigan et al., 2013" startWordPosition="5739" endWordPosition="5742">RA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam sear</context>
</contexts>
<marker>Flanigan, Dyer, Carbonell, 2013</marker>
<rawString>Jeffrey Flanigan, Chris Dyer, and Jaime Carbonell. 2013. Large-scale discriminative training for statistical machine translation using held-out line search. In Proceedings of NAACL-HLT, pages 248–258, Atlanta, Georgia, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Chris Quirk</author>
</authors>
<title>Optimal search for minimum error rate training.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>38--49</pages>
<location>Edinburgh, Scotland, UK.,</location>
<contexts>
<context position="32989" citStr="Galley and Quirk, 2011" startWordPosition="5692" endWordPosition="5695">but SA-MERT is much slower than MERT. The main reason is that, as the training examples increase dramatically, the envelope calculation for exact line search (see (Och, 2003)) in MERT is less efficient than the update based on (sub-)gradient with inexact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search error</context>
</contexts>
<marker>Galley, Quirk, 2011</marker>
<rawString>Michel Galley and Chris Quirk. 2011. Optimal search for minimum error rate training. In Proceedings of EMNLP, pages 38–49, Edinburgh, Scotland, UK., July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Chris Quirk</author>
<author>Colin Cherry</author>
<author>Kristina Toutanova</author>
</authors>
<title>Regularized minimum error rate training.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>pages</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="33011" citStr="Galley et al., 2013" startWordPosition="5696" endWordPosition="5700">er than MERT. The main reason is that, as the training examples increase dramatically, the envelope calculation for exact line search (see (Och, 2003)) in MERT is less efficient than the update based on (sub-)gradient with inexact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential parti</context>
</contexts>
<marker>Galley, Quirk, Cherry, Toutanova, 2013</marker>
<rawString>Michel Galley, Chris Quirk, Colin Cherry, and Kristina Toutanova. 2013. Regularized minimum error rate training. In Proceedings of EMNLP, pages 1948– 1959, Seattle, Washington, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Gesmundo</author>
<author>James Henderson</author>
</authors>
<title>Undirected machine translation with discriminative reinforcement learning.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<contexts>
<context position="34741" citStr="Gesmundo and Henderson (2014)" startWordPosition="5989" endWordPosition="5992">correct solution falls out of the beam. This idea has been successfully used in many NLP tasks and improves the performance over the state-of-art NLP systems (Huang and Sagae, 2010; Huang et al., 2012; Zhang et al., 2013). Goldberg and Nivre (2012) propose the concept of “dynamic oracle” which is the absolute best potential of a partial derivation, and is more akin to a strictly admissible heuristic. This idea inspired and is closely related to our potential BLEU, except that in our case, computing an admissible heuristic is too costly, so our potential BLEU is more like an average potential. Gesmundo and Henderson (2014) also consider the rankings between partial translation pairs as well. However, they evaluate a partial translation through extending it to a complete translation by re-decoding, and thus they need many passes of decoding for many partial translations, while ours only need one pass of decoding for all partial translations and thus is much more efficient. In summary, our tuning framework is more general and has potential to be employed over all the state-ofart tuning methods mentioned above, even though ours is only tested on three popular methods. 7 Conclusions and Future Work We have presente</context>
</contexts>
<marker>Gesmundo, Henderson, 2014</marker>
<rawString>Andrea Gesmundo and James Henderson. 2014. Undirected machine translation with discriminative reinforcement learning. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Noah A Smith</author>
</authors>
<title>Structured ramp loss minimization for machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL-HLT,</booktitle>
<pages>221--231</pages>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="33076" citStr="Gimpel and Smith, 2012" startWordPosition="5708" endWordPosition="5711"> increase dramatically, the envelope calculation for exact line search (see (Och, 2003)) in MERT is less efficient than the update based on (sub-)gradient with inexact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree</context>
</contexts>
<marker>Gimpel, Smith, 2012</marker>
<rawString>Kevin Gimpel and Noah A. Smith. 2012. Structured ramp loss minimization for machine translation. In Proceedings of NAACL-HLT, pages 221– 231, Montr´eal, Canada, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Dhruv Batra</author>
<author>Chris Dyer</author>
<author>Gregory Shakhnarovich</author>
</authors>
<title>A systematic exploration of diversity in machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<contexts>
<context position="24981" citStr="Gimpel et al., 2013" startWordPosition="4310" endWordPosition="4313">T for k-best decoding on nist05 test set, and calculate the oracle over these two k-best lists. The oracle BLEU comparison is shown in Table 4. On nist05 test set, for MERT the oracle BLEU is 41.1; while for SA-MERT its oracle BLEU is 42.7, i.e. with 1.6 BLEU improvements. Although search-aware tuning employs the objective different from the objective of evaluation on nist02 tuning set, it still gains 0.5 BLEU improvements. Diversity. A k-best list with higher diversity can better represent the entire decoding space, and thus tuning on such a k-best list may lead to better tesing performance (Gimpel et al., 2013). Intuitively, tuning with all bins will encourage the diversity in prefix, infix and suffix of complete translations in the final bin. To testify this, we need a diversity metric. Indeed, Gimpel et al. (2013) define a diversity metric based on the n-gram matches between two sentences y and y&apos; as follows: Qyi:i+q = y&apos;j:j+q] Traditional MERT Tuning Search-aware MERT Tuning BLEU 35 34 33 32 31 30 d(y, y&apos;) = − |y|−q i=1 |y&apos;|−q � j=1 1948 Methods set tuning set # words nist03 test sets (4-refs) nist08 # refs # sents nist04 nist05 nist06 MERT nist02 4 878 23181 33.6 35.1 33.4 31.6 27.9 SA-MERTpot n</context>
</contexts>
<marker>Gimpel, Batra, Dyer, Shakhnarovich, 2013</marker>
<rawString>Kevin Gimpel, Dhruv Batra, Chris Dyer, and Gregory Shakhnarovich. 2013. A systematic exploration of diversity in machine translation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Joakim Nivre</author>
</authors>
<title>Training deterministic parsers with non-deterministic oracles.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING</booktitle>
<contexts>
<context position="34360" citStr="Goldberg and Nivre (2012)" startWordPosition="5926" endWordPosition="5929">g based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea is to update on prefix or partial hypotheses when the correct solution falls out of the beam. This idea has been successfully used in many NLP tasks and improves the performance over the state-of-art NLP systems (Huang and Sagae, 2010; Huang et al., 2012; Zhang et al., 2013). Goldberg and Nivre (2012) propose the concept of “dynamic oracle” which is the absolute best potential of a partial derivation, and is more akin to a strictly admissible heuristic. This idea inspired and is closely related to our potential BLEU, except that in our case, computing an admissible heuristic is too costly, so our potential BLEU is more like an average potential. Gesmundo and Henderson (2014) also consider the rankings between partial translation pairs as well. However, they evaluate a partial translation through extending it to a complete translation by re-decoding, and thus they need many passes of decodi</context>
</contexts>
<marker>Goldberg, Nivre, 2012</marker>
<rawString>Yoav Goldberg and Joakim Nivre. 2012. Training deterministic parsers with non-deterministic oracles. In Proceedings of COLING 2012.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Spence Green</author>
<author>Sida Wang</author>
<author>Daniel Cer</author>
<author>Christopher Manning</author>
</authors>
<title>Fast and adaptive online training of feature-rich translation models.</title>
<date>2013</date>
<booktitle>In Proc. of ACL</booktitle>
<contexts>
<context position="16104" citStr="Green et al., 2013" startWordPosition="2817" endWordPosition="2820">r derivations from the final bin to all bins: d+i (x, y) = argmax w0 · Φ(d) − δy(d) (12) dE Bi (x) negative example Φ(d2) − Φ(d1). In sum, searchaware PRO has |x |times more examples than traditional PRO. The loss functions of PRO and searchaware PRO are defined in Figure 4. d i (x, y) = argmax w0 · Φ(d) + δy(d) (13) 5 Experiments dE Bi (x) The new loss function for SA-MIRA is Eq. 7 in Figure 4. Now instead of one update per sentence, we will perform |x |updates, each based on a pair d+i (x, y) and d i (x, y). 4.3 From PRO to Search-Aware PRO Finally, the PRO algorithm (Hopkins and May, 2011; Green et al., 2013) aims to correlate the ranking under model score and the ranking under BLEU score, among all complete derivations in the final bin. For each preference-pair d1, d2 E B|x|(x) such that d1 has a higher BLEU score than d2 (i.e., δy(d1) &lt; δy(d2)), we add one positive example Φ(d1) − Φ(d2) and one negative example Φ(d2) − Φ(d1). Now to adapt it to search-aware PRO (SAPRO), we will have many more examples to consider: besides the final bin, we will include all preference-pairs in the non-final bins as well. For each bin Bi(x), for each preference-pairs d1, d2 E Bi(x) such that d1 has a higher partia</context>
<context position="33281" citStr="Green et al., 2013" startWordPosition="5743" endWordPosition="5746">e solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems </context>
</contexts>
<marker>Green, Wang, Cer, Manning, 2013</marker>
<rawString>Spence Green, Sida Wang, Daniel Cer, and Christopher Manning. 2013. Fast and adaptive online training of feature-rich translation models. In Proc. of ACL 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P E Hart</author>
<author>N J Nilsson</author>
<author>B Raphael</author>
</authors>
<title>A formal basis for the heuristic determination of minimum cost paths.</title>
<date>1968</date>
<journal>IEEE Transactions on Systems Science and Cybernetics,</journal>
<volume>4</volume>
<issue>2</issue>
<contexts>
<context position="3245" citStr="Hart et al., 1968" startWordPosition="529" endWordPosition="532">s of the complete translations, we also promote potentially promising partial translations so that they are more likely to survive throughout the search, see Figure 1 for illustration. We make the following contributions: • Our idea of search-aware tuning can be applied (as a patch) to all of the three most popular tuning methods (MERT, PRO, and MIRA) by defining a modified objective function (Section 4). • To measure the “promise” or “potential” of a partial translation, we define a new concept “potential BLEU” inspired by future cost in MT decoding (Koehn, 2004) and heuristics in A* search (Hart et al., 1968) (Section 3.2). This work is the first study of evaluating metrics for partial translations. • Our method obtains substantial and consistent 1942 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1942–1952, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics {d o r |dEBi_j(x), |c(r)|=j}) improvements on both the large-scale NIST Chinese-to-English and English-to-Chinese translation tasks on top of MERT, MIRA, and PRO baselines. This is the first time that consistent improvements can be achieved with a new learni</context>
<context position="9481" citStr="Hart et al., 1968" startWordPosition="1577" endWordPosition="1580">ion in MT decoding (Koehn, 2004), we define a very simple future string by simply concatenating the best modelscore translation (with no reorderings) in each uncovered span. Let bestw(x[i:j]) denote the best monotonic derivation for span [i : j], then future(d, x) = o[i:j]Euncov(d,x) e(bestw(x[i:j])) where o is the concatenation operator and uncov(d, x) returns an ordered list of uncovered Figure 3: Example of the extension function ¯ex(·) (and future string) on an incomplete derivation d. spans of x. See Figure 3 for an example. This future string resembles (inadmissible) heuristic function (Hart et al., 1968). Now the “extended translation” is simply a concatenation of the existing partial translation e(d) and the future string future(d, x): ¯ex(d) = e(d) o future(d, x). (3) Instead of calculating bestw(x[i:j]) on-the-fly for each derivation d, we can precompute it for each span [i : j] during future-cost computation, since the score of bestw(x[i:j]) is contextfree (Koehn, 2004). Algorithm 1 shows the pseudo-code of computing bestw(x[i:j]). In practice, since future-cost precomputation already solves the best (monotonic) model-score for each span, is the only extra work for potential BLEU is to re</context>
</contexts>
<marker>Hart, Nilsson, Raphael, 1968</marker>
<rawString>P. E. Hart, N. J. Nilsson, and B. Raphael. 1968. A formal basis for the heuristic determination of minimum cost paths. IEEE Transactions on Systems Science and Cybernetics, 4(2):100–107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hopkins</author>
<author>Jonathan May</author>
</authors>
<title>Tuning as ranking.</title>
<date>2011</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="981" citStr="Hopkins and May, 2011" startWordPosition="143" endWordPosition="146">We propose a searchaware framework to promote promising partial translations, preventing them from being pruned. To do so we develop two metrics to evaluate partial derivations. Our technique can be applied to all of the three above-mentioned tuning methods, and extensive experiments on Chinese-to-English and English-to-Chinese translation show up to +2.6 BLEU gains over search-agnostic baselines. 1 Introduction Parameter tuning has been a key problem for machine translation since the statistical revolution. However, most existing tuning algorithms treat the decoder as a black box (Och, 2003; Hopkins and May, 2011; Chiang, 2012), ignoring the fact that many potentially promising partial translations are pruned by the decoder due to the prohibitively large search space. For example, the popular beam-search decoding algorithm for phrase-based MT (Koehn, 2004) only explores O(nb) items for a sentence of n words (with a beam width of b), while the full search space is O(2nn2) or worse (Knight, 1999). As one of the very few exceptions to the “search-agnostic” majority, Yu et al. (2013) and Zhao et al. (2014) propose a variant of the perceptron algorithm that learns to keep the reference translations in the </context>
<context position="16083" citStr="Hopkins and May, 2011" startWordPosition="2813" endWordPosition="2816">]+ = max{θ, 01. and fear derivations from the final bin to all bins: d+i (x, y) = argmax w0 · Φ(d) − δy(d) (12) dE Bi (x) negative example Φ(d2) − Φ(d1). In sum, searchaware PRO has |x |times more examples than traditional PRO. The loss functions of PRO and searchaware PRO are defined in Figure 4. d i (x, y) = argmax w0 · Φ(d) + δy(d) (13) 5 Experiments dE Bi (x) The new loss function for SA-MIRA is Eq. 7 in Figure 4. Now instead of one update per sentence, we will perform |x |updates, each based on a pair d+i (x, y) and d i (x, y). 4.3 From PRO to Search-Aware PRO Finally, the PRO algorithm (Hopkins and May, 2011; Green et al., 2013) aims to correlate the ranking under model score and the ranking under BLEU score, among all complete derivations in the final bin. For each preference-pair d1, d2 E B|x|(x) such that d1 has a higher BLEU score than d2 (i.e., δy(d1) &lt; δy(d2)), we add one positive example Φ(d1) − Φ(d2) and one negative example Φ(d2) − Φ(d1). Now to adapt it to search-aware PRO (SAPRO), we will have many more examples to consider: besides the final bin, we will include all preference-pairs in the non-final bins as well. For each bin Bi(x), for each preference-pairs d1, d2 E Bi(x) such that d</context>
<context position="17417" citStr="Hopkins and May, 2011" startWordPosition="3048" endWordPosition="3051">Φ(d1) − Φ(d2) and one We evaluate our new tuning methods on two large scale NIST translation tasks: Chinese-to-English (CH-EN) and English-to-Chinese (EN-CH) tasks. 5.1 System Preparation and Data We base our experiments on Cubit2 (Huang and Chiang, 2007), a state-of-art phrase-based system in Python. We set phrase-limit to 7, beam size to 30 and distortion limit 6. We use the 11 dense features from Moses (Koehn et al., 2007), which can lead to good performance and are widely used in almost all SMT systems. The baseline tuning methods MERT (Och, 2003), MIRA (Cherry and Foster, 2012), and PRO (Hopkins and May, 2011) are from the Moses toolkit, which are batch tuning methods based on k-best translations. The searchaware tuning methods are called SA-MERT, SAMIRA, and SA-PRO, respectively. Their partial BLEU versions are marked with superscript 1 and their potential BLEU versions are marked with superscript 2, as explained in Section 3. All these search-aware tuning methods are implemented on the basis of Moses toolkit. They employ the de2http://www.cis.upenn.edu/˜lhuang3/cubit/ 1946 Methods nist03 nist04 nist05 nist06 nist08 avg MERT 33.6 35.1 33.4 31.6 27.9 – SA-MERTpar -0.2 +0.0 +0.1 -0.1 -0.1 – SA-MERTp</context>
<context position="33052" citStr="Hopkins and May, 2011" startWordPosition="5704" endWordPosition="5707">s the training examples increase dramatically, the envelope calculation for exact line search (see (Och, 2003)) in MERT is less efficient than the update based on (sub-)gradient with inexact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during deco</context>
</contexts>
<marker>Hopkins, May, 2011</marker>
<rawString>Mark Hopkins and Jonathan May. 2011. Tuning as ranking. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Better k-best Parsing.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT-2005).</booktitle>
<contexts>
<context position="5378" citStr="Huang and Chiang (2005)" startWordPosition="889" endWordPosition="892">B0(x) = {E} � Bi(x) = topk w0 ( j=1..i where r is a rule covering j Chinese words, and topkw0(·) returns the top k derivations according to the current model w0. As a special case, note that top1w0(S) = argmaxdES w0 · Φ(d), so top1w0(B|x|(x)) is the final 1-best result.1 See Figure 2 for an illustration. 3 Challenge: Evaluating Partial Derivations As mentioned in Section 1, the current mainstream tuning methods such as MERT, MIRA, and PRO are 1Actually Bl,l(x) is an approximation to the k-best list since some derivations are merged by dynamic programming; to recover those we can use Alg. 3 of Huang and Chiang (2005). 0 1 2 3 4 B0(x) B1(x) B2(x) B3(x) B4(x) Figure 2: Beam search for phrase-based decoding. The item in red is top1w0(B4(x)), i.e., the 1-best result. Traditional tuning only uses the final bin B4(x) while search-aware tuning considers all bins Bi(x) (i = 1..4). all search-agnostic: they only care about the complete translations from the last bin, B|x|(x), ignoring all partial ones, i.e., Bi(x) for all i &lt; |x|. As a result, many potentially promising partial derivations never reach the final bin (See Figure 1). To address this problem, our new “search-aware tuning” aims to promote not only the </context>
</contexts>
<marker>Huang, Chiang, 2005</marker>
<rawString>Liang Huang and David Chiang. 2005. Better k-best Parsing. In Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT-2005).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>David Chiang</author>
</authors>
<title>Forest rescoring: Fast decoding with integrated language models.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Prague, Czech Rep.,</location>
<contexts>
<context position="17050" citStr="Huang and Chiang, 2007" startWordPosition="2984" endWordPosition="2987">). Now to adapt it to search-aware PRO (SAPRO), we will have many more examples to consider: besides the final bin, we will include all preference-pairs in the non-final bins as well. For each bin Bi(x), for each preference-pairs d1, d2 E Bi(x) such that d1 has a higher partial or potential BLEU score than d2 (i.e., δxy (d1) &lt; δxy (d2)), we add one positive example Φ(d1) − Φ(d2) and one We evaluate our new tuning methods on two large scale NIST translation tasks: Chinese-to-English (CH-EN) and English-to-Chinese (EN-CH) tasks. 5.1 System Preparation and Data We base our experiments on Cubit2 (Huang and Chiang, 2007), a state-of-art phrase-based system in Python. We set phrase-limit to 7, beam size to 30 and distortion limit 6. We use the 11 dense features from Moses (Koehn et al., 2007), which can lead to good performance and are widely used in almost all SMT systems. The baseline tuning methods MERT (Och, 2003), MIRA (Cherry and Foster, 2012), and PRO (Hopkins and May, 2011) are from the Moses toolkit, which are batch tuning methods based on k-best translations. The searchaware tuning methods are called SA-MERT, SAMIRA, and SA-PRO, respectively. Their partial BLEU versions are marked with superscript 1 </context>
</contexts>
<marker>Huang, Chiang, 2007</marker>
<rawString>Liang Huang and David Chiang. 2007. Forest rescoring: Fast decoding with integrated language models. In Proceedings of ACL, Prague, Czech Rep., June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of ACL</booktitle>
<contexts>
<context position="34292" citStr="Huang and Sagae, 2010" startWordPosition="5914" endWordPosition="5917">agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea is to update on prefix or partial hypotheses when the correct solution falls out of the beam. This idea has been successfully used in many NLP tasks and improves the performance over the state-of-art NLP systems (Huang and Sagae, 2010; Huang et al., 2012; Zhang et al., 2013). Goldberg and Nivre (2012) propose the concept of “dynamic oracle” which is the absolute best potential of a partial derivation, and is more akin to a strictly admissible heuristic. This idea inspired and is closely related to our potential BLEU, except that in our case, computing an admissible heuristic is too costly, so our potential BLEU is more like an average potential. Gesmundo and Henderson (2014) also consider the rankings between partial translation pairs as well. However, they evaluate a partial translation through extending it to a complete </context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of ACL 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Suphan Fayong</author>
<author>Yang Guo</author>
</authors>
<title>Structured perceptron with inexact search.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL.</booktitle>
<contexts>
<context position="33901" citStr="Huang et al., 2012" startWordPosition="5846" endWordPosition="5849"> These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea is to update on prefix or partial hypotheses when the correct solution falls out of the beam. This idea has been successfully used in many NLP tasks and improves the performance over the state-of-art NLP systems (Huang and Sagae, 2010; Huang et al., 2012; Zhang et al., 2013). Goldberg and Nivre (2012) propose the concept of “dynamic oracle” which is the absolute best potential of a partial derivation, and is more akin to a strictly admissi</context>
</contexts>
<marker>Huang, Fayong, Guo, 2012</marker>
<rawString>Liang Huang, Suphan Fayong, and Yang Guo. 2012. Structured perceptron with inexact search. In Proceedings of NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Decoding complexity in wordreplacement translation models.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>4</issue>
<contexts>
<context position="1370" citStr="Knight, 1999" startWordPosition="207" endWordPosition="208">es. 1 Introduction Parameter tuning has been a key problem for machine translation since the statistical revolution. However, most existing tuning algorithms treat the decoder as a black box (Och, 2003; Hopkins and May, 2011; Chiang, 2012), ignoring the fact that many potentially promising partial translations are pruned by the decoder due to the prohibitively large search space. For example, the popular beam-search decoding algorithm for phrase-based MT (Koehn, 2004) only explores O(nb) items for a sentence of n words (with a beam width of b), while the full search space is O(2nn2) or worse (Knight, 1999). As one of the very few exceptions to the “search-agnostic” majority, Yu et al. (2013) and Zhao et al. (2014) propose a variant of the perceptron algorithm that learns to keep the reference translations in the beam or chart. However, there are several obstacles that prevent their method from becoming popular: First of all, they rely on “forced decoding” to track gold derivations that lead to the reference translation, but in practice only a small portion of (mostly very short) senLiang Huang Queens College and Graduate Center City University of New York liang.huang.sh@gmail.com 0 1 2 3 4 Figu</context>
</contexts>
<marker>Knight, 1999</marker>
<rawString>Kevin Knight. 1999. Decoding complexity in wordreplacement translation models. Computational Linguistics, 25(4):607–615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Koehn</author>
<author>H Hoang</author>
<author>A Birch</author>
<author>C Callison-Burch</author>
<author>M Federico</author>
<author>N Bertoldi</author>
<author>B Cowan</author>
<author>W Shen</author>
<author>C Moran</author>
<author>R Zens</author>
<author>C Dyer</author>
<author>O Bojar</author>
<author>A Constantin</author>
<author>E Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of ACL:</booktitle>
<publisher>Demonstrations.</publisher>
<contexts>
<context position="17224" citStr="Koehn et al., 2007" startWordPosition="3015" endWordPosition="3018">well. For each bin Bi(x), for each preference-pairs d1, d2 E Bi(x) such that d1 has a higher partial or potential BLEU score than d2 (i.e., δxy (d1) &lt; δxy (d2)), we add one positive example Φ(d1) − Φ(d2) and one We evaluate our new tuning methods on two large scale NIST translation tasks: Chinese-to-English (CH-EN) and English-to-Chinese (EN-CH) tasks. 5.1 System Preparation and Data We base our experiments on Cubit2 (Huang and Chiang, 2007), a state-of-art phrase-based system in Python. We set phrase-limit to 7, beam size to 30 and distortion limit 6. We use the 11 dense features from Moses (Koehn et al., 2007), which can lead to good performance and are widely used in almost all SMT systems. The baseline tuning methods MERT (Och, 2003), MIRA (Cherry and Foster, 2012), and PRO (Hopkins and May, 2011) are from the Moses toolkit, which are batch tuning methods based on k-best translations. The searchaware tuning methods are called SA-MERT, SAMIRA, and SA-PRO, respectively. Their partial BLEU versions are marked with superscript 1 and their potential BLEU versions are marked with superscript 2, as explained in Section 3. All these search-aware tuning methods are implemented on the basis of Moses toolki</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>P. Koehn, H. Hoang, A. Birch, C. Callison-Burch, M. Federico, N. Bertoldi, B. Cowan, W. Shen, C. Moran, R. Zens, C. Dyer, O. Bojar, A. Constantin, and E. Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of ACL: Demonstrations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
</authors>
<title>Pharaoh: a beam search decoder for phrase-based statistical machine translation models.</title>
<date>2004</date>
<booktitle>In Proceedings of AMTA,</booktitle>
<pages>115--124</pages>
<contexts>
<context position="1229" citStr="Koehn, 2004" startWordPosition="180" endWordPosition="181">, and extensive experiments on Chinese-to-English and English-to-Chinese translation show up to +2.6 BLEU gains over search-agnostic baselines. 1 Introduction Parameter tuning has been a key problem for machine translation since the statistical revolution. However, most existing tuning algorithms treat the decoder as a black box (Och, 2003; Hopkins and May, 2011; Chiang, 2012), ignoring the fact that many potentially promising partial translations are pruned by the decoder due to the prohibitively large search space. For example, the popular beam-search decoding algorithm for phrase-based MT (Koehn, 2004) only explores O(nb) items for a sentence of n words (with a beam width of b), while the full search space is O(2nn2) or worse (Knight, 1999). As one of the very few exceptions to the “search-agnostic” majority, Yu et al. (2013) and Zhao et al. (2014) propose a variant of the perceptron algorithm that learns to keep the reference translations in the beam or chart. However, there are several obstacles that prevent their method from becoming popular: First of all, they rely on “forced decoding” to track gold derivations that lead to the reference translation, but in practice only a small portion</context>
<context position="3197" citStr="Koehn, 2004" startWordPosition="522" endWordPosition="523"> is that, besides caring about the rankings of the complete translations, we also promote potentially promising partial translations so that they are more likely to survive throughout the search, see Figure 1 for illustration. We make the following contributions: • Our idea of search-aware tuning can be applied (as a patch) to all of the three most popular tuning methods (MERT, PRO, and MIRA) by defining a modified objective function (Section 4). • To measure the “promise” or “potential” of a partial translation, we define a new concept “potential BLEU” inspired by future cost in MT decoding (Koehn, 2004) and heuristics in A* search (Hart et al., 1968) (Section 3.2). This work is the first study of evaluating metrics for partial translations. • Our method obtains substantial and consistent 1942 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1942–1952, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics {d o r |dEBi_j(x), |c(r)|=j}) improvements on both the large-scale NIST Chinese-to-English and English-to-Chinese translation tasks on top of MERT, MIRA, and PRO baselines. This is the first time that consisten</context>
<context position="8895" citStr="Koehn, 2004" startWordPosition="1484" endWordPosition="1485">se the former has 2 unigram mathces while the latter only 1, even though the latter is almost identical to the reference and will eventually lead to a complete translation with substantially higher Bleu+1 score (matching a 4-gram “from Shanghai to Beijing”). Similarly, it will prefer “I from Shanghai” to “I fly from” in bin 3, without knowing that the former will eventually pay the price of word-order difference. This example suggests that we need a more “global” or less greedy metric (see below). 3.2 Solution 2: Potential BLEU via Extension Inspired by future cost computation in MT decoding (Koehn, 2004), we define a very simple future string by simply concatenating the best modelscore translation (with no reorderings) in each uncovered span. Let bestw(x[i:j]) denote the best monotonic derivation for span [i : j], then future(d, x) = o[i:j]Euncov(d,x) e(bestw(x[i:j])) where o is the concatenation operator and uncov(d, x) returns an ordered list of uncovered Figure 3: Example of the extension function ¯ex(·) (and future string) on an incomplete derivation d. spans of x. See Figure 3 for an example. This future string resembles (inadmissible) heuristic function (Hart et al., 1968). Now the “ext</context>
</contexts>
<marker>Koehn, 2004</marker>
<rawString>Philipp Koehn. 2004. Pharaoh: a beam search decoder for phrase-based statistical machine translation models. In Proceedings of AMTA, pages 115–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shankar Kumar</author>
<author>Wolfgang Macherey</author>
<author>Chris Dyer</author>
<author>Franz Och</author>
</authors>
<title>Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP,</booktitle>
<location>Suntec, Singapore,</location>
<contexts>
<context position="33548" citStr="Kumar et al., 2009" startWordPosition="5785" endWordPosition="5789"> evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea is to update on prefix or partial hypotheses when the correct solution falls out of the be</context>
</contexts>
<marker>Kumar, Macherey, Dyer, Och, 2009</marker>
<rawString>Shankar Kumar, Wolfgang Macherey, Chris Dyer, and Franz Och. 2009. Efficient minimum error rate training and minimum bayes-risk decoding for translation hypergraphs and lattices. In Proceedings of ACL-IJCNLP, Suntec, Singapore, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhifei Li</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Efficient extraction of oracle-best translations from hypergraphs.</title>
<date>2009</date>
<booktitle>In Proceedings of HLT-NAACL Short Papers.</booktitle>
<contexts>
<context position="6570" citStr="Li and Khudanpur, 2009" startWordPosition="1086" endWordPosition="1089">” aims to promote not only the accurate translations in the final bin, but more importantly those potentially promising partial derivations in non-final bins. The key challenge, however, is how to evaluate the “promise” or “potential” of a partial derivation. In this Section, we develop two such measures, a simple “partial BLEU” (Section 3.1) and a more principled “potential BLEU” (Section 3.2). In Section 4, we will then adapt traditional tuning methods to their search-aware versions using these partial evaluation metrics. 3.1 Solution 1: Simple and Naive Partial BLEU Inspired by a trick in (Li and Khudanpur, 2009) and (Chiang, 2012) for oracle or hope extraction, we use a very simple metric to evaluate partial translations for tuning. For a given derivation d, the basic idea is to evaluate the (short) partial translation e(d) against the (full) reference y, but using a “prorated” reference length proportional to c(d) which is the number of Chinese words covered so far in d: |y |· |c(d)|/|x| For example, if d has covered 2 words on a 8- word Chinese sentence with a 12-word English reference, then the “effective reference length” is 12 x 2/8 = 3. We call this method “partial BLEU” since it does not compl</context>
</contexts>
<marker>Li, Khudanpur, 2009</marker>
<rawString>Zhifei Li and Sanjeev Khudanpur. 2009. Efficient extraction of oracle-best translations from hypergraphs. In Proceedings of HLT-NAACL Short Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
</authors>
<title>Statistical machine translation.</title>
<date>2008</date>
<journal>ACM Comput. Surv.,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="12879" citStr="Lopez (2008)" startWordPosition="2226" endWordPosition="2227"> we expect w · Φ(d1) &gt; w · Φ(d2) to hold after tuning. 4.1 From MERT to Search-Aware MERT Suppose D is a tuning set of (x, y) pairs. Traditional MERT learns the weight by iteratively reranking the complete translations towards those with higher BLEU in the final bin B|x|(x) for each x in D. Formally, it tries to minimize the document-level error of 1-best translations: � ) Sy top1 w(B|x|(x)) , (x,y)ED where top1w(5) is the best derivation in 5 under model w, and S·(·) is the full derivation metric as defined in Table 1; in this paper we use Sy(y&apos;) = −BLEU(y, y&apos;). Here we follow Och (2003) and Lopez (2008) to simplify the notations, where the ® operator (similar to E) is an over-simplification for BLEU which, as a document-level metric, is actually not factorizable across sentences. Besides reranking the complete translations as traditional MERT, our search-aware MERT (SAMERT) also reranks the partial translations such that potential translations may survive in the middle bins during search. Formally, its objective function is defined as follows: �ESA-MERT(D, w)= (x,y)ED where top1w(·) is defined in Eq. (4), and Sxy(d), defined in Table 1, is the generic metric for evaluating a partial derivati</context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>Adam Lopez. 2008. Statistical machine translation. ACM Comput. Surv., 40(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Francisco Guzmn</author>
<author>Stephan Voge</author>
</authors>
<title>A tale about pro and monsters.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL Short Papers.</booktitle>
<contexts>
<context position="21093" citStr="Nakov et al., 2013" startWordPosition="3666" endWordPosition="3669">ss, all scores reported are average of three runs, as suggested by Clark et al. (2011) for fairer comparisons. 5.2 Main Results on CH-EN Task Table 2 depicts the main results of our methods on CH-EN translation task. On all five test sets, our methods consistently achieve substantial improvements with two pruning options: SA-MERT pot gains +1.2 BLEU points over MERT on average; and SA-MIRApot gains +1.8 BLEU points over MIRA on average as well. SA-PROpot, however, does not work out of the box when we use the entire nist02 as the tuning set, which might be attributed to the “Monster” behavior (Nakov et al., 2013). To alleviate this problem, we only use the 109 short sentences with less than 10 words from nist02 as our new tuning data. To our supurise, this trick works really well (despite using much less data), and also made SA-PROpot an order of magnitude faster. This further confirms that our search-aware tuning is consistent across all tuning methods and datasets. As discussed in Section 3, evaluation metrics of partial derivations are crucial for search-aware tuning. Besides the principled “potential BLEU” version of search-aware tuning (i.e. SA-MERTpot, SA-MIRApot, and SA-PROpot), we also run the</context>
</contexts>
<marker>Nakov, Guzmn, Voge, 2013</marker>
<rawString>Preslav Nakov, Francisco Guzmn, and Stephan Voge. 2013. A tale about pro and monsters. In Proceedings of ACL Short Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Comput. Linguist.,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="19795" citStr="Och and Ney, 2003" startWordPosition="3447" endWordPosition="3450">for both CH-EN and EN-CH tasks is the same, and it is collected from the NIST2008 Open Machine Translation Campaign. It consists of about 1.8M sentence pairs, including about 40M/48M words in Chinese/English sides. For CH-EN task, the tuning set is nist02 (878 sents), and test sets are nist03 (919 sents), nist04 (1788 sents), nist05 (1082 sents), nist06 (616 sents from news portion) and nist08 (691 from news portion). For EN-CH task, the tuning set is ssmt07 (995 sents)3, and the test set is nist08 (1859 sents). For both tasks, all the tuning and test sets contain 4 references. We use GIZA++ (Och and Ney, 2003) for word alignment, and SRILM (Stolcke, 2002) for 4-gram language models with the Kneser-Ney smoothing 3On EN-CH task, there is only one test set available for us, and thus we use ssmt07 as the tuning set, which is provided at the Third Symposium on Statistical Machine Translation (http://mitlab.hit.edu.cn/ssmt2007.html). option. The LM for EN-CH is trained on its target side; and that for CH-EN is trained on the Xinhua portion of Gigaword. We use BLEU-4 (Papineni et al., 2002) with “average ref-len” to evaluate the translation performance for all experiments. In particular, the character-bas</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Comput. Linguist., 29(1):19–51, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Joseph Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="958" citStr="Och, 2003" startWordPosition="141" endWordPosition="142">n quality. We propose a searchaware framework to promote promising partial translations, preventing them from being pruned. To do so we develop two metrics to evaluate partial derivations. Our technique can be applied to all of the three above-mentioned tuning methods, and extensive experiments on Chinese-to-English and English-to-Chinese translation show up to +2.6 BLEU gains over search-agnostic baselines. 1 Introduction Parameter tuning has been a key problem for machine translation since the statistical revolution. However, most existing tuning algorithms treat the decoder as a black box (Och, 2003; Hopkins and May, 2011; Chiang, 2012), ignoring the fact that many potentially promising partial translations are pruned by the decoder due to the prohibitively large search space. For example, the popular beam-search decoding algorithm for phrase-based MT (Koehn, 2004) only explores O(nb) items for a sentence of n words (with a beam width of b), while the full search space is O(2nn2) or worse (Knight, 1999). As one of the very few exceptions to the “search-agnostic” majority, Yu et al. (2013) and Zhao et al. (2014) propose a variant of the perceptron algorithm that learns to keep the referen</context>
<context position="12862" citStr="Och (2003)" startWordPosition="2223" endWordPosition="2224">EU(y, y2), then we expect w · Φ(d1) &gt; w · Φ(d2) to hold after tuning. 4.1 From MERT to Search-Aware MERT Suppose D is a tuning set of (x, y) pairs. Traditional MERT learns the weight by iteratively reranking the complete translations towards those with higher BLEU in the final bin B|x|(x) for each x in D. Formally, it tries to minimize the document-level error of 1-best translations: � ) Sy top1 w(B|x|(x)) , (x,y)ED where top1w(5) is the best derivation in 5 under model w, and S·(·) is the full derivation metric as defined in Table 1; in this paper we use Sy(y&apos;) = −BLEU(y, y&apos;). Here we follow Och (2003) and Lopez (2008) to simplify the notations, where the ® operator (similar to E) is an over-simplification for BLEU which, as a document-level metric, is actually not factorizable across sentences. Besides reranking the complete translations as traditional MERT, our search-aware MERT (SAMERT) also reranks the partial translations such that potential translations may survive in the middle bins during search. Formally, its objective function is defined as follows: �ESA-MERT(D, w)= (x,y)ED where top1w(·) is defined in Eq. (4), and Sxy(d), defined in Table 1, is the generic metric for evaluating a</context>
<context position="17352" citStr="Och, 2003" startWordPosition="3039" endWordPosition="3040">., δxy (d1) &lt; δxy (d2)), we add one positive example Φ(d1) − Φ(d2) and one We evaluate our new tuning methods on two large scale NIST translation tasks: Chinese-to-English (CH-EN) and English-to-Chinese (EN-CH) tasks. 5.1 System Preparation and Data We base our experiments on Cubit2 (Huang and Chiang, 2007), a state-of-art phrase-based system in Python. We set phrase-limit to 7, beam size to 30 and distortion limit 6. We use the 11 dense features from Moses (Koehn et al., 2007), which can lead to good performance and are widely used in almost all SMT systems. The baseline tuning methods MERT (Och, 2003), MIRA (Cherry and Foster, 2012), and PRO (Hopkins and May, 2011) are from the Moses toolkit, which are batch tuning methods based on k-best translations. The searchaware tuning methods are called SA-MERT, SAMIRA, and SA-PRO, respectively. Their partial BLEU versions are marked with superscript 1 and their potential BLEU versions are marked with superscript 2, as explained in Section 3. All these search-aware tuning methods are implemented on the basis of Moses toolkit. They employ the de2http://www.cis.upenn.edu/˜lhuang3/cubit/ 1946 Methods nist03 nist04 nist05 nist06 nist08 avg MERT 33.6 35.</context>
<context position="32541" citStr="Och, 2003" startWordPosition="5619" endWordPosition="5620"> respectively. Then, for traditional tuning its number of training examples is 2; but for search-aware tuning, the total number is 40. More training examples makes our search-aware tuning slower than the traditional tuning. Table 8 shows the training time comparisons between search-aware tuning and the traditional tuning. From this Table, one can see that both SA-MIRA and SA-PRO are with the same order of magtitude as MIRA and PRO; but SA-MERT is much slower than MERT. The main reason is that, as the training examples increase dramatically, the envelope calculation for exact line search (see (Och, 2003)) in MERT is less efficient than the update based on (sub-)gradient with inexact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopki</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Joseph Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of ACL, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings ofACL,</booktitle>
<pages>311--318</pages>
<location>Philadephia, USA,</location>
<contexts>
<context position="7665" citStr="Papineni et al., 2002" startWordPosition="1280" endWordPosition="1283">sh reference, then the “effective reference length” is 12 x 2/8 = 3. We call this method “partial BLEU” since it does not complete the translation, and denote it by ¯δ|x| y (d) = −δ(y, e(d); reflen = |y |· |c(d)|/|x|). (1) 1943 S(y, y&apos;) = −Bleu+1(y, y&apos;) string distance metric Sy(d) = S(y, e(d)) full derivations eval Sxy (d) = S|x| y (d) partial bleu (Sec. 3.1) S(y, ¯ex(d)) potential Table 1: Notations for evaluating full and partial derivations. Functions ¯S|x| y (·) and ¯ex(·) are defined by Equations 1 and 3, respectively. where reflen is the effective length of reference translations, see (Papineni et al., 2002) for details. 3.1.1 Problem with Partial BLEU Simple as it is, this method does not work well in practice because comparison of partial derivations might be unfair for different derivations covering different set of Chinese words, as it will naturally favor those covering “easier” portions of the input sentence (which we do observe empirically). For instance, consider the following Chinese-toEnglish example which involves a reordering of the Chinese PP: d`ao Bˇeijing to Beijing “I flew from Shanghai to Beijing” Partial BLEU will prefer subtranslation “I from” to “I fly” in bin 2 (covering 2 Ch</context>
<context position="12114" citStr="Papineni et al., 2002" startWordPosition="2077" endWordPosition="2081">)) for all spans [i : j]. 1: for l in (0..|x|) do 2: for i in (0..|x |− l) do 3: j = i + l + 1 4: best score = −oo 5: if R[i : j] =� 0 then &gt; R[i : j] is a subset of rules R for span [i : j]. 6: bestw(x[i : j]) = argmaxr∈�[i:j] w · Φ({r}) &gt; {r} is a derivation consisting of one rule r. 7: best score = w · Φ(bestw(x[i : j])) 8: for k in (i + 1 .. i + p) do &gt; p is the phrase length limit 9: if best score &lt; w · Φ (bestw (x [i : k]) o bestw(x[k : j])) then w 10: best(x[i : j]) = bestw (x [i : k]) o bestw(x[k : j]) / 11: best score = w · Φ(bestw(x[i : j])) on some translation metric (such as BLEU (Papineni et al., 2002)). In other words, for a training sentence pair (x, y), if a pair of its translations y1 = e(d1) and y2 = e(d2) satisfies BLEU(y, y1) &gt; BLEU(y, y2), then we expect w · Φ(d1) &gt; w · Φ(d2) to hold after tuning. 4.1 From MERT to Search-Aware MERT Suppose D is a tuning set of (x, y) pairs. Traditional MERT learns the weight by iteratively reranking the complete translations towards those with higher BLEU in the final bin B|x|(x) for each x in D. Formally, it tries to minimize the document-level error of 1-best translations: � ) Sy top1 w(B|x|(x)) , (x,y)ED where top1w(5) is the best derivation in 5</context>
<context position="20278" citStr="Papineni et al., 2002" startWordPosition="3526" endWordPosition="3530">d the test set is nist08 (1859 sents). For both tasks, all the tuning and test sets contain 4 references. We use GIZA++ (Och and Ney, 2003) for word alignment, and SRILM (Stolcke, 2002) for 4-gram language models with the Kneser-Ney smoothing 3On EN-CH task, there is only one test set available for us, and thus we use ssmt07 as the tuning set, which is provided at the Third Symposium on Statistical Machine Translation (http://mitlab.hit.edu.cn/ssmt2007.html). option. The LM for EN-CH is trained on its target side; and that for CH-EN is trained on the Xinhua portion of Gigaword. We use BLEU-4 (Papineni et al., 2002) with “average ref-len” to evaluate the translation performance for all experiments. In particular, the character-based BLEU-4 is employed for EN-CH task. Since all tuning methods involve randomness, all scores reported are average of three runs, as suggested by Clark et al. (2011) for fairer comparisons. 5.2 Main Results on CH-EN Task Table 2 depicts the main results of our methods on CH-EN translation task. On all five test sets, our methods consistently achieve substantial improvements with two pruning options: SA-MERT pot gains +1.2 BLEU points over MERT on average; and SA-MIRApot gains +1</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In Proceedings ofACL, pages 311–318, Philadephia, USA, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Simianer</author>
<author>Stefan Riezler</author>
<author>Chris Dyer</author>
</authors>
<title>Joint feature selection in distributed stochastic learning for large-scale discriminative training in smt.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL,</booktitle>
<pages>11--21</pages>
<location>Jeju Island, Korea,</location>
<contexts>
<context position="33237" citStr="Simianer et al., 2012" startWordPosition="5735" endWordPosition="5738">exact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard trai</context>
</contexts>
<marker>Simianer, Riezler, Dyer, 2012</marker>
<rawString>Patrick Simianer, Stefan Riezler, and Chris Dyer. 2012. Joint feature selection in distributed stochastic learning for large-scale discriminative training in smt. In Proceedings of ACL, pages 11–21, Jeju Island, Korea, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>Srilm - an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of ICSLP,</booktitle>
<volume>30</volume>
<pages>901--904</pages>
<contexts>
<context position="19841" citStr="Stolcke, 2002" startWordPosition="3456" endWordPosition="3457"> is collected from the NIST2008 Open Machine Translation Campaign. It consists of about 1.8M sentence pairs, including about 40M/48M words in Chinese/English sides. For CH-EN task, the tuning set is nist02 (878 sents), and test sets are nist03 (919 sents), nist04 (1788 sents), nist05 (1082 sents), nist06 (616 sents from news portion) and nist08 (691 from news portion). For EN-CH task, the tuning set is ssmt07 (995 sents)3, and the test set is nist08 (1859 sents). For both tasks, all the tuning and test sets contain 4 references. We use GIZA++ (Och and Ney, 2003) for word alignment, and SRILM (Stolcke, 2002) for 4-gram language models with the Kneser-Ney smoothing 3On EN-CH task, there is only one test set available for us, and thus we use ssmt07 as the tuning set, which is provided at the Third Symposium on Statistical Machine Translation (http://mitlab.hit.edu.cn/ssmt2007.html). option. The LM for EN-CH is trained on its target side; and that for CH-EN is trained on the Xinhua portion of Gigaword. We use BLEU-4 (Papineni et al., 2002) with “average ref-len” to evaluate the translation performance for all experiments. In particular, the character-based BLEU-4 is employed for EN-CH task. Since al</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. Srilm - an extensible language modeling toolkit. In Proceedings of ICSLP, volume 30, pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy Tromble</author>
<author>Shankar Kumar</author>
<author>Franz Och</author>
<author>Wolfgang Macherey</author>
</authors>
<title>Lattice Minimum BayesRisk decoding for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP,</booktitle>
<pages>620--629</pages>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="33527" citStr="Tromble et al., 2008" startWordPosition="5781" endWordPosition="5784">ns are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea is to update on prefix or partial hypotheses when the correct solutio</context>
</contexts>
<marker>Tromble, Kumar, Och, Macherey, 2008</marker>
<rawString>Roy Tromble, Shankar Kumar, Franz Och, and Wolfgang Macherey. 2008. Lattice Minimum BayesRisk decoding for statistical machine translation. In Proceedings of EMNLP, pages 620–629, Honolulu, Hawaii, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
<author>Jun Suzuki</author>
<author>Hajime Tsukada</author>
<author>Hideki Isozaki</author>
</authors>
<title>Online large-margin training for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of EMNLP-CoNLL.</booktitle>
<contexts>
<context position="13871" citStr="Watanabe et al., 2007" startWordPosition="2383" endWordPosition="2386">dle bins during search. Formally, its objective function is defined as follows: �ESA-MERT(D, w)= (x,y)ED where top1w(·) is defined in Eq. (4), and Sxy(d), defined in Table 1, is the generic metric for evaluating a partial derivation d which has two implementations (partial bleu or potential bleu). In order words we can obtain two implementations of search-aware MERT methods, SA-MERTpar and SA-MERTpot. Notice that the traditional MERT is a special case of SA-MERT where i is fixed to |x|. 4.2 From MIRA to Search-Aware MIRA MIRA is another popular tuning method for SMT. It firstly introduced in (Watanabe et al., 2007), and then was improved in (Chiang et al., 2008; Chiang, 2012; Cherry and Foster, 2012). Its main idea is to optimize a weight such that the model score difference of a pair of derivations is greater than their loss difference. In this paper, we follow the objective function in (Chiang, 2012; Cherry and Foster, 2012), where only the violation between hope and fear derivations is concerned. Formally, we define d+(x, y) and d−(x, y) as the hope and fear derivations in the final bin (i.e., complete derivations): d+(x, y) = argmax w0 · Φ(d) − Sy(d) (10) dEB|x|(x) d−(x, y) = argmax w0 · Φ(d) + Sy(d</context>
<context position="33459" citStr="Watanabe et al., 2007" startWordPosition="5770" endWordPosition="5773">r by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea i</context>
</contexts>
<marker>Watanabe, Suzuki, Tsukada, Isozaki, 2007</marker>
<rawString>Taro Watanabe, Jun Suzuki, Hajime Tsukada, and Hideki Isozaki. 2007. Online large-margin training for statistical machine translation. In Proceedings of EMNLP-CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taro Watanabe</author>
</authors>
<title>Optimized online rank learning for machine translation.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACLHLT,</booktitle>
<pages>253--262</pages>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="33214" citStr="Watanabe, 2012" startWordPosition="5733" endWordPosition="5734">gradient with inexact line search in MIRA and PRO. One possible solution to speed up SA-MERT is the parallelization but we leave it for future work. 6 Related Work Many tuning methods have been proposed for SMT so far. These methods differ by the objective function or training mode: their objective functions are based on either evaluation-directed loss (Och, 2003; Galley and Quirk, 2011; Galley et al., 2013) or surrogate loss (Hopkins and May, 2011; Gimpel and Smith, 2012; Eidelman et al., 2013); they are either batch (Och, 2003; Hopkins and May, 2011; Cherry and Foster, 2012) or online mode (Watanabe, 2012; Simianer et al., 2012; Flanigan et al., 2013; Green et al., 2013). These methods share a common characteristic: they learn a weight by iteratively reranking a set of complete translations represented by k-best (Och, 2003; Watanabe et al., 2007; Chiang et al., 2008) or lattice (hypergraph) (Tromble et al., 2008; Kumar et al., 2009), and they do not care about search errors that potential partial translations may be pruned during decoding, even if they agree with 1950 that their decoders are built on the beam pruning based search. On the other hand, it is well-known that search errors can unde</context>
</contexts>
<marker>Watanabe, 2012</marker>
<rawString>Taro Watanabe. 2012. Optimized online rank learning for machine translation. In Proceedings of NAACLHLT, pages 253–262, Montr´eal, Canada, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Yu</author>
<author>Liang Huang</author>
<author>Haitao Mi</author>
<author>Kai Zhao</author>
</authors>
<title>Max-violation perceptron and forced decoding for scalable mt training.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="1457" citStr="Yu et al. (2013)" startWordPosition="220" endWordPosition="223">ince the statistical revolution. However, most existing tuning algorithms treat the decoder as a black box (Och, 2003; Hopkins and May, 2011; Chiang, 2012), ignoring the fact that many potentially promising partial translations are pruned by the decoder due to the prohibitively large search space. For example, the popular beam-search decoding algorithm for phrase-based MT (Koehn, 2004) only explores O(nb) items for a sentence of n words (with a beam width of b), while the full search space is O(2nn2) or worse (Knight, 1999). As one of the very few exceptions to the “search-agnostic” majority, Yu et al. (2013) and Zhao et al. (2014) propose a variant of the perceptron algorithm that learns to keep the reference translations in the beam or chart. However, there are several obstacles that prevent their method from becoming popular: First of all, they rely on “forced decoding” to track gold derivations that lead to the reference translation, but in practice only a small portion of (mostly very short) senLiang Huang Queens College and Graduate Center City University of New York liang.huang.sh@gmail.com 0 1 2 3 4 Figure 1: (a) Some potentially promising partial translations (in red) fall out of the beam</context>
<context position="4253" citStr="Yu et al. (2013)" startWordPosition="681" endWordPosition="684"> the large-scale NIST Chinese-to-English and English-to-Chinese translation tasks on top of MERT, MIRA, and PRO baselines. This is the first time that consistent improvements can be achieved with a new learning algorithm under dense feature settings (Section 5). For simplicity reasons, in this paper we use phrase-based translation, but our work has the potential to be applied to other translation paradigms. 2 Review: Beam Search for PBMT Decoding We review beam search for phrase-based decoding in our notations which will facilitate the discussion of search-aware tuning in Section 4. Following Yu et al. (2013), let (x, y) be a Chinese-English sentence pair in the tuning set D, and d = r1 o r2 o ... o r|d| be a (partial) derivation, where each ri = (c(ri), e(ri)) is a rule, i.e., a phrase-pair. Let |c(r)| be the number of Chinese words in rule r, and e(d) Δ = e(r1) o e(r2) ... o e(r|d|) be the English prefix (i.e., partial translation) generated so far. In beam search, each bin Bi(x) contains the best k derivations covering exactly i Chinese words, based on items in previous bins (see Figures 1 and 2): B0(x) = {E} � Bi(x) = topk w0 ( j=1..i where r is a rule covering j Chinese words, and topkw0(·) r</context>
<context position="28065" citStr="Yu et al., 2013" startWordPosition="4864" endWordPosition="4867">ngf¯ang j¯ıb`ı police killed the gunman the gunman was shot dead ⇓ B`ush´ı yˇu Sh¯al´ong jˇux´ıng hu`ıt´an Bush and Sharon held a meeting B`ush´ı yˇu Sh¯al´ong jˇux´ıng hu`ıt´an Bush held talks with Sharon qi¯angshˇou b`ei jˇıngf¯ang j¯ıb`ı police killed the gunman qi¯angshˇou b`ei jˇıngf¯ang j¯ıb`ı the gunman was shot dead Figure 6: Transformation of a tuning set in forced decoding for MAXFORCE: the original tuning set (on the top) contains 2 source sentences with 2 references for each; while the transformed set (on the bottom) contains 4 source sentences with one reference for each. method (Yu et al., 2013), and thus we reimplement MAXFORCE method. Since the nist02 tuning set contains 4 references and forced decoding is performed for only one reference, we enlarge the nist02 set to a variant set following the transformation in Figure 6, and obtain a variant tuning set denoted as nist02-px, which consists of 4- times sentence-pairs. On nist02-px, the non-trivial reachable prefix-data only accounts for 12% sentences and 7% words. Both these sentence-level and the word-level percentages are much lower than those on the training data as shown in Table 3 from (Yu et al., 2013). This is because there </context>
<context position="31173" citStr="Yu et al., 2013" startWordPosition="5388" endWordPosition="5391">t achieves 0.4 BLEU improvements over MERT. Finally, comparison between SA-MERTpot and SA-MERTpar shows that the potential BLEU is better for evaluation of partial derivations. 5.6 Discussions on Tuning Efficiency As shown in Figure 2, search-aware tuning considers all partial translations in the middle bins beside all complete translations in the last bin, and thus its total number of training examples is much greater than that of the traditional tuning. In details, sup4Under the dense feature setting, MAXFORCE is worse than standard MERT. This result is consistent with that in Figure 12 of (Yu et al., 2013). 5We run MAXFORCE on train-r-part, i.e. a part of reachable data instead of the entire reachable data, as we found that more tuning data does not necessarily lead to better testing performance under dense feature setting in our internal experiments. Optimization time MERT MIRA PRO basline 3 2 2 search-aware 50 7 6 Table 8: Search-aware tuning slows down MERT significantly, and MIRA and PRO moderately. The time (in minutes) is for optimization only (excluding decoding) and measured at the last iteration during the entire tuning (search aware tuning does not increase the number of iterations in</context>
</contexts>
<marker>Yu, Huang, Mi, Zhao, 2013</marker>
<rawString>Heng Yu, Liang Huang, Haitao Mi, and Kai Zhao. 2013. Max-violation perceptron and forced decoding for scalable mt training. In Proceedings of EMNLP 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Liang Huang</author>
<author>Kai Zhao</author>
<author>Ryan McDonald</author>
</authors>
<title>Online learning with inexact hypergraph search.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<contexts>
<context position="34333" citStr="Zhang et al., 2013" startWordPosition="5922" endWordPosition="5925">lt on the beam pruning based search. On the other hand, it is well-known that search errors can undermine the standard training for many beam search based NLP systems (Huang et al., 2012). As a result, Collins and Roark (2004) and Huang et al. (2012) propose the early-update and max-violation update to deal with the search errors. Their idea is to update on prefix or partial hypotheses when the correct solution falls out of the beam. This idea has been successfully used in many NLP tasks and improves the performance over the state-of-art NLP systems (Huang and Sagae, 2010; Huang et al., 2012; Zhang et al., 2013). Goldberg and Nivre (2012) propose the concept of “dynamic oracle” which is the absolute best potential of a partial derivation, and is more akin to a strictly admissible heuristic. This idea inspired and is closely related to our potential BLEU, except that in our case, computing an admissible heuristic is too costly, so our potential BLEU is more like an average potential. Gesmundo and Henderson (2014) also consider the rankings between partial translation pairs as well. However, they evaluate a partial translation through extending it to a complete translation by re-decoding, and thus they</context>
</contexts>
<marker>Zhang, Huang, Zhao, McDonald, 2013</marker>
<rawString>Hao Zhang, Liang Huang, Kai Zhao, and Ryan McDonald. 2013. Online learning with inexact hypergraph search. In Proceedings of EMNLP 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Zhao</author>
<author>Liang Huang</author>
<author>Haitao Mi</author>
<author>Abe Ittycheriah</author>
</authors>
<title>Hierarchical mt training using maxviolation perceptron.</title>
<date>2014</date>
<booktitle>In Proceedings of ACL,</booktitle>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="1480" citStr="Zhao et al. (2014)" startWordPosition="225" endWordPosition="228">revolution. However, most existing tuning algorithms treat the decoder as a black box (Och, 2003; Hopkins and May, 2011; Chiang, 2012), ignoring the fact that many potentially promising partial translations are pruned by the decoder due to the prohibitively large search space. For example, the popular beam-search decoding algorithm for phrase-based MT (Koehn, 2004) only explores O(nb) items for a sentence of n words (with a beam width of b), while the full search space is O(2nn2) or worse (Knight, 1999). As one of the very few exceptions to the “search-agnostic” majority, Yu et al. (2013) and Zhao et al. (2014) propose a variant of the perceptron algorithm that learns to keep the reference translations in the beam or chart. However, there are several obstacles that prevent their method from becoming popular: First of all, they rely on “forced decoding” to track gold derivations that lead to the reference translation, but in practice only a small portion of (mostly very short) senLiang Huang Queens College and Graduate Center City University of New York liang.huang.sh@gmail.com 0 1 2 3 4 Figure 1: (a) Some potentially promising partial translations (in red) fall out of the beam (bin 2); (b) We identi</context>
</contexts>
<marker>Zhao, Huang, Mi, Ittycheriah, 2014</marker>
<rawString>Kai Zhao, Liang Huang, Haitao Mi, and Abe Ittycheriah. 2014. Hierarchical mt training using maxviolation perceptron. In Proceedings of ACL, Baltimore, Maryland, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>