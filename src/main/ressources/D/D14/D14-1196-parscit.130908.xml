<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000826">
<title confidence="0.98999">
Dependency-based Discourse Parser for Single-Document Summarization
</title>
<author confidence="0.903067">
Yasuhisa Yoshida, Jun Suzuki, Tsutomu Hirao, and Masaaki Nagata
</author>
<affiliation confidence="0.823517">
NTT Communication Science Laboratories, NTT Corporation
</affiliation>
<address confidence="0.935032">
2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237 Japan
</address>
<email confidence="0.997724">
{yoshida.y,suzuki.jun,hirao.tsutomu,nagata.masaaki}@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.997373" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999954090909091">
The current state-of-the-art single-
document summarization method gen-
erates a summary by solving a Tree
Knapsack Problem (TKP), which is the
problem of finding the optimal rooted sub-
tree of the dependency-based discourse
tree (DEP-DT) of a document. We can
obtain a gold DEP-DT by transforming a
gold Rhetorical Structure Theory-based
discourse tree (RST-DT). However, there
is still a large difference between the
ROUGE scores of a system with a gold
DEP-DT and a system with a DEP-DT
obtained from an automatically parsed
RST-DT. To improve the ROUGE score,
we propose a novel discourse parser
that directly generates the DEP-DT. The
evaluation results showed that the TKP
with our parser outperformed that with
the state-of-the-art RST-DT parser, and
achieved almost equivalent ROUGE
scores to the TKP with the gold DEP-DT.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970212765957">
Discourse structures of documents are believed
to be highly beneficial for generating informa-
tive and coherent summaries. Several discourse-
based summarization methods have been devel-
oped, such as (Marcu, 1998; Daum´e III and
Marcu, 2002; Hirao et al., 2013; Kikuchi et al.,
2014). Moreover, the current best ROUGE score
for the summarization benchmark data of the RST-
discourse Treebank (Carlson et al., 2002) has been
provided by (Hirao et al., 2013), whose method
also utilizes discourse trees. Thus, the discourse-
based summarization approach is one promising
way to obtain high-quality summaries.
One possible weakness of discourse-based sum-
marization techniques is that they rely greatly on
the accuracy of the discourse parser they use.
For example, the above discourse-based summa-
rization methods utilize discourse trees based on
the Rhetorical Structure Theory (RST) (Mann and
Thompson, 1988) for their discourse information.
Unfortunately, the current state-of-the-art RST
parser, as described in (Hernault et al., 2010),
is insufficient as an off-the-shelf discourse parser.
In fact, there is empirical evidence that the qual-
ity (i.e., ROUGE score) of summaries from auto-
parsed discourse trees is significantly degraded
compared with those generated from gold dis-
course trees (Marcu, 1998; Hirao et al., 2013).
From this background, the goal of this paper
is to develop an appropriate discourse parser for
discourse-based summarization. We first focus on
one of the best discourse-based single document
summarization methods as proposed in (Hirao et
al., 2013). Their method formulates a single doc-
ument summarization problem as a Tree Knap-
sack Problem (TKP) over a dependency-based dis-
course tree (DEP-DT). In their method, DEP-DTs
are automatically transformed from (auto-parsed)
RST-discourse trees (RST-DTs) by heuristic rules.
Instead, we develop a DEP-DT parser, that di-
rectly provides DEP-DTs for their state-of-the-art
discourse-based summarization method. We show
that summaries generated by our parser improve
the ROUGE scores to almost the same level as
those generated by gold DEP-DTs. We also inves-
tigate the way in which the parsing accuracy helps
to improve the ROUGE scores.
</bodyText>
<sectionHeader confidence="0.9841985" genericHeader="method">
2 Single-Document Summarization as a
Tree Knapsack Problem
</sectionHeader>
<bodyText confidence="0.999497166666667">
Hirao et al. (2013) formulated single-document
summarization as a TKP that is run on the DEP-
DT. They obtained a summary by trimming the
DEP-DT, i.e. the summary is a rooted subtree of
the DEP-DT.
Suppose that we have N EDUs in a document,
</bodyText>
<page confidence="0.933167">
1834
</page>
<note confidence="0.4845265">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1834–1839,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<figure confidence="0.999773928571429">
Root
Elaboration
N S
Elaboration
Example
N S N S
Elaboration
Concession Antithesis
S N N S S N S
Contrast Contrast
N N
Evidence
N S
(a)
Background
Elabora.on
Background Elabora.on Elabora.on
Example
Concession
Concession Example
Background Elabora.on
An.thesis
Elabora.on Elabora.on
Evidence
(b)
Elabora.on Elabora.on
Evidence An.thesis
(c)
</figure>
<figureCaption confidence="0.9581005">
Figure 1: Examples of RST-DT and DEP-DT. e1, · · · , e10 are EDUs. (a) Example of an RST-DT from
(Marcu, 1998). n1, · · · , n19 are the non-terminal nodes. (b) Example of the DEP-DT obtained from the
incorrect RST-DT that is made by swapping the Nucleus-Satellite relationship of the node n2 and the
node n3. (c) The correct DEP-DT obtained from the RST-DT in (a).
</figureCaption>
<bodyText confidence="0.996517">
and the i-th EDU ei has li words. L is the maxi-
mum number of words allowed in a summary. In
the TKP, if we select ei, we need to select its par-
ent EDU in the DEP-DT. We denote parent(i) as
the index of the parent of ei in the DEP-DT. x is
an N-dimensional binary vector that represents a
summary, i.e. xi = 1 denotes that ei is included in
the summary. The TKP is defined as the following
ILP problem:
</bodyText>
<equation confidence="0.9996726">
�N
i=1 F (ei)xi
s.t. ENi=1 lixi G L
Vi : xparent(i) &gt; xi
Vi : xi E 10, 11,
</equation>
<bodyText confidence="0.9991135">
where F(ei) is the score of ei. We define F(ei) as
follows:
where W (ei) is the set of words contained in ei.
tf(w, D) is the term frequency of word w in a doc-
ument D. Depth(ei) is the depth of ei in the DEP-
DT.
</bodyText>
<sectionHeader confidence="0.9707415" genericHeader="method">
3 Tree Knapsack Problem with
Dependency-based Discourse Parser
</sectionHeader>
<subsectionHeader confidence="0.999874">
3.1 Motivation
</subsectionHeader>
<bodyText confidence="0.996121189189189">
In (Hirao et al., 2013), they automatically ob-
tain the DEP-DT by transforming from the parsed
RST-DT. We simply followed their method for ob-
taining the DEP-DTs 1. The transformation algo-
rithm can be found in detail in (Hirao et al., 2013).
Figure 1(a) shows an example of the RST-DT. Ac-
cording to RST, a document is represented as a tree
whose terminal nodes correspond to elementary
discourse units (EDUs) and whose non-terminal
nodes indicate the role of the contiguous EDUs,
namely, ‘nucleus (N)’ or ‘satellite (S)’. Since a nu-
cleus is more important than a satellite in terms of
the writer’s purpose, a satellite is always a child of
a nucleus in the RST-DT. Some discourse relations
between a nucleus and a satellite or two nuclei are
defined.
Since the TKP of (Hirao et al., 2013) employs
a DEP-DT obtained from an automatically parsed
RST-DT, their method strongly relies on the ac-
curacy of the RST parser. For example, in Fig-
ure 1(a), if the RST-DT parser incorrectly sets
the node n2 as Satellite and the node n3 as Nu-
cleus, we obtain an incorrect DEP-DT in Figure
1(b) because the transformation algorithm uses
the Nucleus-Satellite relationships in the RST-DT.
The dependency relationships in Figure 1(b) are
quite different from that of the correct DEP-DT in
Figure 1(c). In this example, the parser failed to
determine the most salient EDU e2, that is the root
EDU of the gold DEP-DT. Thus, the summary ex-
tracted from this DEP-DT will have a low ROUGE
score.
The results motivated us to design a new dis-
course parser fully trained on the DEP-DTs and
&apos;Li et al. also defined a similar transformation algorithm
(Li et al., 2014). In this paper, we follow the transformation
algorithm defined in (Hirao et al., 2013).
</bodyText>
<equation confidence="0.878399">
maximize
X
F(ei) = Depth(ei) ,
EwEW(ei) tf(w, D)
</equation>
<page confidence="0.97447">
1835
</page>
<figure confidence="0.99991764556962">
(a)
Parser Training Phase
Document
Summarization Phase
�� ��
RST=DTs
�
Example
�����
����������
��
� � �� � �� �
�
Background
Contrast
� � �
� Concession
� ���������
�
�
����������
��
� � � �
� � � �
Contrast
��
�
�
�
�� 6 Evidence
��
� �
��
�� �� �� �� e10
Discourse Dependency Parser
�
�
����������
Root
Root
���
DEP=DTs
��
Background
��
DEP=DT
�� �� �� e10
Transformation Algorithm
�� �� ��
4 Concession
��
���������� ����������
����������
����������
Evidence
����
�� �� ��
��
��
Concession
����������
���������
���������
�� �
Evidence
��
�� �
Example
��
���������
Tree Knapsack Problem
10 Example
e10
��
���������
Discourse
Dependency
Parser
Summary
Summarization Phase
RST Parser
Root
��
����������
����������
����������
�
�
Example
����������
� � �
�
Background
Concession ���������
����������
� � � �
� � � �
Background
�� �� ��
Summary
Document
Example
Concession
���������� ����������
�� �� �� e10
Contrast
�
�
Evidence
� �
���������
Evidence
��
�
DEP&gt;DT
RST&gt;DT
Transformation Algorithm
Tree Knapsack Problem
(b)
Parser Training Phase
��
�
RST&gt;DTs
��
�
Example
�����
����������
�� �
� �� � �� �
Background
Contrast
� � � Concession
� � ���������
�
�
����������
�
� � �� � �
� � �
�
Contrast
���
�
�
�
6 Evidence
��
� �
�� �� �� �� �� �� �� �� �� e10
�
�
Root
����������
Root
Root
���
RST Parser
</figure>
<figureCaption confidence="0.8527705">
Figure 2: (a) Overview of our proposed method. In the parser training phase, the parser is trained on
the DEP-DTs, and in the summarization phase, the document is directly parsed into the DEP-DT. (b)
</figureCaption>
<bodyText confidence="0.959663818181818">
Overview of (Hirao et al., 2013). In the parser training phase, the parser is trained on RST-DTs, and
in the summarization phase, the document is parsed into the RST-DT, and then transformed into the
DEP-DT.
that could directly generate the DEP-DT. Figure
2(a) shows an overview of the TKP combined with
our DEP-DT parser. In the parser training phase,
we transform RST-DTs into DEP-DTs, and di-
rectly train our parser with the DEP-DTs. In the
summarization phase, our method parses a raw
document directly into a DEP-DT, and generates
a summary with the TKP.
</bodyText>
<subsectionHeader confidence="0.994663">
3.2 Description of Discourse Dependency
Parser
</subsectionHeader>
<bodyText confidence="0.960707606060606">
Our parser is based on the first-order Maximum
Spanning Tree (MST) algorithm (McDonald et al.,
2005b). Our parser extracts the features from the
EDU ei and the EDU ej. We use almost the fea-
tures as those shown in (Hernault et al., 2010).
Lexical N-gram features use the beginning (or
end) lexical N-grams (N E 11, 2,31) in ei and
ej. We also include POS tags for the beginning
(or end) lexical N-grams (N E 11, 2,31) in ei and
ej. Organizational features include the distance
between ei and ej. They also include the num-
ber of tokens, and features for identifying whether
or not ei and ej belong to the same sentence (or
paragraph). Soricut et al. (2003) introduced dom-
inance set features. They include syntactic labels
and the lexical heads of head and attachment nodes
along with their dominance relationship. We can-
not use the strong compositionality features and
rhetorical structure features described in (Her-
nault et al., 2010) because we have to know the
subtree structures in advance when using these
features.
To train the parser, we choose the Margin In-
fused Relaxed Algorithm (MIRA) (McDonald et
al., 2005a; Crammer et al., 2006). We denote
s(w,y) = wTfy as a score function given a
weight vector w and a DEP-DT y. L(y, y*) is
a loss function, and we define it as the number of
EDUs that have an incorrect parent EDU in a pre-
dicted DEP-DT y* = arg max s(w, y). Then, we
y
solve the following optimization problem:
min ��w w(t)��
</bodyText>
<equation confidence="0.8230555">
W (1)
s.t. s(w, y) s(w, y*) ? L(y, y*),
</equation>
<bodyText confidence="0.966341">
where w(t) is a weight vector in the t-th iteration.
</bodyText>
<subsectionHeader confidence="0.997364">
3.3 Redesign of Loss Function for Tree
Knapsack Problem
</subsectionHeader>
<bodyText confidence="0.999998363636364">
When we make a summary by solving a TKP, we
do not necessarily need a DEP-DT where all of the
parent-child relationships are correct. This is be-
cause we rarely select the EDUs around the leaves
in the DEP-DT. On the other hand, the parent-
child relationships around the root EDU in the
DEP-DT are important because we often select the
EDUs around the root EDU. Incorporating these
intuitions enables us to develop a DEP-DT parser
optimized for the TKP. To incorporate this infor-
mation, we define the following loss function:
</bodyText>
<equation confidence="0.9963275">
LDepth(y, y*) =
(i,r,j)Ey
� 11 I(y*, i, A, (2)
Depth(ei)
</equation>
<bodyText confidence="0.9218385">
where I(y*, i, j) is an indicator function that
equals 1 if EDU ej is the parent of EDU ei in the
</bodyText>
<page confidence="0.984763">
1836
</page>
<bodyText confidence="0.997365">
DEP-DT y? and 0 otherwise. In Section 4, we re-
port results with the original loss function L(·, ·)
and with the modified loss function LDepth(·, ·).
</bodyText>
<sectionHeader confidence="0.989613" genericHeader="method">
4 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.996453">
4.1 Corpus
</subsectionHeader>
<bodyText confidence="0.999988">
We used the RST-DT corpus (Carlson et al., 2002)
for our experimental evaluations. The corpus con-
sists of 385 Wall Street Journal articles with RST
annotation, and 30 of these documents also have
one human-made reference summary. We used
these 30 documents as the test documents for the
summarization evaluation, and used the remaining
355 RST annotated documents as the training data
for the parser. Note that we did not use the 30 test
documents for the summarization evaluation when
we trained the parser.
</bodyText>
<subsectionHeader confidence="0.998207">
4.2 Summarization Evaluation
</subsectionHeader>
<bodyText confidence="0.999302142857143">
We compared the following three systems that dif-
fer in the way they obtain the DEP-DT.
TKP-GOLD Used a DEP-DT converted from a
gold RST-DT.
TKP-DIS-DEP Used a DEP-DT automatically
parsed by our discourse dependency-based
parser (DIS-DEP). Figure 2(a) shows an
overview of this system.
TKP-DIS-DEP-LOSS Used a DEP-DT automat-
ically parsed by our discourse dependency-
based parser (DIS-DEP). Figure 2(a) shows
an overview of this system. It is trained with
the loss function defined in equation (2).
TKP-HILDA Used a DEP-DT obtained by trans-
forming a RST-DT parsed by HILDA, a state-
of-the-art RST-DT parser (Hernault et al.,
2010). Figure 2(b) shows an overview of this
system.
Hirao et al. (2013) proved that TKP-HILDA
outperformed other methods including Marcu’s
method (Marcu, 1998), a simple knapsack model,
a maximum coverage model and LEAD method
that simply takes the first L tokens (L = summary
length). Thus, we only employed TKP-HILDA as
our baseline.
We follow the evaluation conditions described
in (Hirao et al., 2013). The number of tokens in
each summary is determined by the number in the
</bodyText>
<table confidence="0.995315">
ROUGE-1 ROUGE-2
TKP-GOLD 0.321 0.112
TKP-DIS-DEP 0.319 0.109
TKP-DIS-DEP-LOSS 0.323 0.121
TKP-HILDA 0.284 0.093
</table>
<tableCaption confidence="0.999568">
Table 1: ROUGE Recall scores
</tableCaption>
<bodyText confidence="0.999822860465116">
human-annotated reference summary. The aver-
age length of the reference summaries corresponds
to about 10% of the words in the source document.
This is also the commonly used evaluation con-
dition for single-document summarization evalu-
ation on the RST-DT corpus. We employed the
recall of ROUGE-1, 2 as the evaluation measures.
Table 1 shows ROUGE scores on the RST-DT
corpus. We can see TKP-DIS-DEP and TKP-
DIS-DEP-LOSS outperformed TKP-HILDA, and
achieved almost the same ROUGE scores as TKP-
GOLD. Wilcoxon’s signed rank test in terms
of ROUGE rejected the null hypothesis, “there
is a difference between TKP-HILDA and TKP-
DIS-DEP (or TKP-DIS-DEP-LOSS)” (Wilcoxon,
1945). This would be because test documents are
relatively small.
We analyzed the differences between the pro-
posed systems (TKP-DIS-DEP and TKP-DIS-
DEP-LOSS) and TKP-HILDA. First, we evaluated
the overlaps between the EDUs in summaries gen-
erated by the system and the EDUs in summaries
generated by TKP-GOLD. To see the overlaps, we
calculated the average F-value using Recall and
Precision defined as follows: Recall = |Ss ∩
Sg|/|Sg|, Precision = |Ss ∩ Sg|/|Ss|, where Ss
is a set of EDUs in a summary generated by a sys-
tem, and Sg a set of EDUs in a summary generated
by TKP-GOLD. The first line in Table 2 shows the
results. TKP-DIS-DEP and TKP-DIS-DEP-LOSS
outperformed TKP-HILDA as regards the aver-
age F-values. The result revealed that TKP-DIS-
DEP and TKP-DIS-DEP-LOSS have more EDUs
in common with TKP-GOLD than TKP-HILDA.
This result is evidence that TKP-DIS-DEP and
TKP-DIS-DEP-LOSS outperformed TKP-HILDA
in terms of ROUGE score.
Second, we evaluated the root accuracy (RA),
the rate at which a parser can find the root of DEP-
DTs. Since the root of a gold DEP-DT is the most
salient EDU in a document, it should be included
in the summary. The second line in Table 2 shows
that our methods succeeded in extracting the root
</bodyText>
<page confidence="0.971881">
1837
</page>
<table confidence="0.9951874">
TKP-DIS-DEP TKP-DIS-DEP-LOSS TKP-HILDA
Avg F-value 0.532? 0.532? 0.415
RA 0.933? 0.933? 0.733
Avg DAS 0.847? 0.843? 0.596
*: significantly better than TKP-HILDA (p &lt; .05)
</table>
<tableCaption confidence="0.620466875">
Table 2: Average F-value, Root Accuracy (RA), and average Dependency Accuracy in Summary (DAS).
Wilcoxon’s signed rank test in terms of average F-value, RA and DAS accepted the null hypothesis.
TKP-GOLD:
Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results. Elcotel, a telecommunications company, had net
income of $272,000, or five cents a share, in its year-earlier second quarter. The lower results, Mr. Pierce said. Elcotel will
also benefit from moving into other areas. Elcotel has also developed an automatic call processor. Automatic call processors
will provide that system for virtually any telephone, Mr. Pierce said, not just phones.
TKP-DIS-DEP, TKP-DIS-DEP-LOSS:
</tableCaption>
<bodyText confidence="0.923496777777778">
Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results. Elcotel, a telecommunications company, had net
income of $272,000, or five cents a share, in its year-earlier second quarter. George Pierce, chairman and chief executive officer,
said in an interview. Although Mr. Pierce expects that line of business to strengthen in the next year. Elcotel will also benefit
from moving into other areas. Elcotel has also developed an automatic call processor.
TKP-HILDA:
Elcotel Inc. expects fiscal second-quarter earnings to trail 1988 results. That several new products will lead to a “much
stronger” performance in its second half. George Pierce, chairman and chief executive officer, said in an interview. Mr.
Pierce said Elcotel should realize a minimum of $10 of recurring net earnings for each machine each month. Elcotel has also
developed an automatic call processor. Automatic call processors will provide that system for virtually any telephone.
</bodyText>
<figureCaption confidence="0.979231">
Figure 3: Summaries of wsj 2317. The sentences shown in bold-face are the root EDUs in each DEP-DT
of the summary.
</figureCaption>
<bodyText confidence="0.977693">
of DEP-DT with high accuracy.
Third, to evaluate the coherency of the gener-
ated summaries, we compared the average Depen-
dency Accuracy in Summary (DAS), which is de-
fined as follows:
</bodyText>
<equation confidence="0.9989126">
1 �
DAS(S) =
|S |eES
� 1 (if parent(e) � S)
�(e) = 0 (otherwise),
</equation>
<bodyText confidence="0.999891368421053">
where S is a set of EDUs contained in the sum-
mary and parent(e) returns the parent EDU of e
in the gold DEP-DT. DAS(S) measures the rate of
the correct parent-child relationships in S. When
DAS equals 1, the summary is a rooted subtree of
the gold DEP-DT. The third line in Table 2 shows
the results. The results demonstrate that the sum-
maries generated by TKP-DIS-DEP or TKP-DIS-
DEP-LOSS tend to preserve the upper level depen-
dency relationships between the EDUs within the
gold DEP-DT.
Figure 3 shows summaries of wsj 2317 gener-
ated by the three systems. The EDUs correspond-
ing to the root of the DEP-DT are used in each
system shown in boldface. We can see that the
root EDU in the gold DEP-DT is found in the
summaries generated by TKP-DIS-DEP and TKP-
DIS-DEP-LOSS, but not in the summary gener-
ated by TKP-HILDA.
</bodyText>
<sectionHeader confidence="0.999656" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999635">
In this paper, we proposed a novel dependency-
based discourse parser for single-document sum-
marization. The parser enables us to obtain the
DEP-DT without transforming the RST-DT. The
evaluation results showed that the TKP with our
parser outperformed that with the state-of-the-art
RST-DT parser, and achieved almost equivalent
ROUGE scores to the TKP with the gold DEP-DT.
</bodyText>
<sectionHeader confidence="0.999622" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.982109333333333">
Lynn Carlson, Daniel Marcu, and Mary Ellen
Okurowski. 2002. Rst discourse treebank,
ldc2002t07.
Koby Crammer, Ofer Dekel, Joseph Keshet, Shai
Shalev-Shwartz, and Yoram Singer. 2006. Online
passive-aggressive algorithms. The Journal of Ma-
chine Learning Research, 7:551–585.
6(e),
1838
Hal Daum´e III and Daniel Marcu. 2002. A noisy-
channel model for document compression. In Pro-
ceedings of the 40th Annual Meeting of the Associa-
tion for Computational Linguistics (ACL), pages 449
– 456, Philadelphia, PA, July 6 – 12.
Hugo Hernault, Helmut Prendinger, Mitsuru Ishizuka,
et al. 2010. Hilda: a discourse parser using support
vector machine classification. Dialogue and Dis-
course, 1(3).
Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino,
Norihito Yasuda, and Masaaki Nagata. 2013.
Single-document summarization as a tree knapsack
problem. In Proceedings of the 2013 Conference on
EMNLP, pages 1515–1520.
Yuta Kikuchi, Tsutomu Hirao, Hiroya Takamura, Man-
abu Okumura, and Masaaki Nagata. 2014. Single
document summarization based on nested tree struc-
ture. In Proceedings of the 52nd Annual Meeting of
the Association for Computational Linguistics (Vol-
ume 2: Short Papers), pages 315–320, Baltimore,
Maryland, June. Association for Computational Lin-
guistics.
Sujian Li, Liang Wang, Ziqiang Cao, and Wenjie Li.
2014. Text-level discourse dependency parsing. In
Proceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics (Volume 1:
Long Papers), pages 25–35, Baltimore, Maryland,
June. Association for Computational Linguistics.
William C. Mann and Sandra A. Thompson. 1988.
Rhetorical structure theory: Toward a functional the-
ory of text organization. Text, 8(3):243–281.
Daniel Marcu. 1998. Improving summarization
through rhetorical parsing tuning. In Proc. of The
6th Workshop on VLC, pages 206–215.
Ryan McDonald, Koby Crammer, and Fernando
Pereira. 2005a. Online large-margin training of de-
pendency parsers. In Proceedings of the 43rd An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’05, pages 91–98, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005b. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceed-
ings of Human Language Technology Conference
and Conference on Empirical Methods in Natural
Language Processing, pages 523–530, Vancouver,
British Columbia, Canada, October. Association for
Computational Linguistics.
Radu Soricut and Daniel Marcu. 2003. Sentence level
discourse parsing using syntactic and lexical infor-
mation. In Proceedings of the 2003 Human Lan-
guage Technology Conference of the North Ameri-
can Chapter of the Association for Computational
Linguistics.
Frank Wilcoxon. 1945. Individual Comparisons by
Ranking Methods. Biometrics Bulletin, 1(6):80–83,
December.
</reference>
<page confidence="0.996164">
1839
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.822635">
<title confidence="0.999119">Dependency-based Discourse Parser for Single-Document Summarization</title>
<author confidence="0.955919">Yasuhisa Yoshida</author>
<author confidence="0.955919">Jun Suzuki</author>
<author confidence="0.955919">Tsutomu Hirao</author>
<author confidence="0.955919">Masaaki</author>
<affiliation confidence="0.969467">NTT Communication Science Laboratories, NTT</affiliation>
<address confidence="0.943326">2-4 Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237</address>
<abstract confidence="0.995912695652174">The current state-of-the-art singledocument summarization method generates a summary by solving a Tree Knapsack Problem (TKP), which is the problem of finding the optimal rooted subtree of the dependency-based discourse tree (DEP-DT) of a document. We can obtain a gold DEP-DT by transforming a gold Rhetorical Structure Theory-based discourse tree (RST-DT). However, there is still a large difference between the ROUGE scores of a system with a gold DEP-DT and a system with a DEP-DT obtained from an automatically parsed RST-DT. To improve the ROUGE score, we propose a novel discourse parser that directly generates the DEP-DT. The evaluation results showed that the TKP with our parser outperformed that with the state-of-the-art RST-DT parser, and achieved almost equivalent ROUGE scores to the TKP with the gold DEP-DT.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lynn Carlson</author>
<author>Daniel Marcu</author>
<author>Mary Ellen Okurowski</author>
</authors>
<date>2002</date>
<note>Rst discourse treebank, ldc2002t07.</note>
<contexts>
<context position="1572" citStr="Carlson et al., 2002" startWordPosition="221" endWordPosition="224">T. The evaluation results showed that the TKP with our parser outperformed that with the state-of-the-art RST-DT parser, and achieved almost equivalent ROUGE scores to the TKP with the gold DEP-DT. 1 Introduction Discourse structures of documents are believed to be highly beneficial for generating informative and coherent summaries. Several discoursebased summarization methods have been developed, such as (Marcu, 1998; Daum´e III and Marcu, 2002; Hirao et al., 2013; Kikuchi et al., 2014). Moreover, the current best ROUGE score for the summarization benchmark data of the RSTdiscourse Treebank (Carlson et al., 2002) has been provided by (Hirao et al., 2013), whose method also utilizes discourse trees. Thus, the discoursebased summarization approach is one promising way to obtain high-quality summaries. One possible weakness of discourse-based summarization techniques is that they rely greatly on the accuracy of the discourse parser they use. For example, the above discourse-based summarization methods utilize discourse trees based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) for their discourse information. Unfortunately, the current state-of-the-art RST parser, as described in (Her</context>
<context position="11733" citStr="Carlson et al., 2002" startWordPosition="1991" endWordPosition="1994">mportant because we often select the EDUs around the root EDU. Incorporating these intuitions enables us to develop a DEP-DT parser optimized for the TKP. To incorporate this information, we define the following loss function: LDepth(y, y*) = (i,r,j)Ey � 11 I(y*, i, A, (2) Depth(ei) where I(y*, i, j) is an indicator function that equals 1 if EDU ej is the parent of EDU ei in the 1836 DEP-DT y? and 0 otherwise. In Section 4, we report results with the original loss function L(·, ·) and with the modified loss function LDepth(·, ·). 4 Experimental Evaluation 4.1 Corpus We used the RST-DT corpus (Carlson et al., 2002) for our experimental evaluations. The corpus consists of 385 Wall Street Journal articles with RST annotation, and 30 of these documents also have one human-made reference summary. We used these 30 documents as the test documents for the summarization evaluation, and used the remaining 355 RST annotated documents as the training data for the parser. Note that we did not use the 30 test documents for the summarization evaluation when we trained the parser. 4.2 Summarization Evaluation We compared the following three systems that differ in the way they obtain the DEP-DT. TKP-GOLD Used a DEP-DT </context>
</contexts>
<marker>Carlson, Marcu, Okurowski, 2002</marker>
<rawString>Lynn Carlson, Daniel Marcu, and Mary Ellen Okurowski. 2002. Rst discourse treebank, ldc2002t07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Koby Crammer</author>
<author>Ofer Dekel</author>
<author>Joseph Keshet</author>
<author>Shai Shalev-Shwartz</author>
<author>Yoram Singer</author>
</authors>
<title>Online passive-aggressive algorithms.</title>
<date>2006</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>7--551</pages>
<contexts>
<context position="10366" citStr="Crammer et al., 2006" startWordPosition="1735" endWordPosition="1738">mber of tokens, and features for identifying whether or not ei and ej belong to the same sentence (or paragraph). Soricut et al. (2003) introduced dominance set features. They include syntactic labels and the lexical heads of head and attachment nodes along with their dominance relationship. We cannot use the strong compositionality features and rhetorical structure features described in (Hernault et al., 2010) because we have to know the subtree structures in advance when using these features. To train the parser, we choose the Margin Infused Relaxed Algorithm (MIRA) (McDonald et al., 2005a; Crammer et al., 2006). We denote s(w,y) = wTfy as a score function given a weight vector w and a DEP-DT y. L(y, y*) is a loss function, and we define it as the number of EDUs that have an incorrect parent EDU in a predicted DEP-DT y* = arg max s(w, y). Then, we y solve the following optimization problem: min ��w w(t)�� W (1) s.t. s(w, y) s(w, y*) ? L(y, y*), where w(t) is a weight vector in the t-th iteration. 3.3 Redesign of Loss Function for Tree Knapsack Problem When we make a summary by solving a TKP, we do not necessarily need a DEP-DT where all of the parent-child relationships are correct. This is because w</context>
</contexts>
<marker>Crammer, Dekel, Keshet, Shalev-Shwartz, Singer, 2006</marker>
<rawString>Koby Crammer, Ofer Dekel, Joseph Keshet, Shai Shalev-Shwartz, and Yoram Singer. 2006. Online passive-aggressive algorithms. The Journal of Machine Learning Research, 7:551–585.</rawString>
</citation>
<citation valid="false">
<volume>6</volume>
<pages>1838</pages>
<marker></marker>
<rawString>6(e), 1838</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daum´e</author>
<author>Daniel Marcu</author>
</authors>
<title>A noisychannel model for document compression.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 449 – 456,</booktitle>
<volume>6</volume>
<location>Philadelphia, PA,</location>
<marker>Daum´e, Marcu, 2002</marker>
<rawString>Hal Daum´e III and Daniel Marcu. 2002. A noisychannel model for document compression. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL), pages 449 – 456, Philadelphia, PA, July 6 – 12.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hugo Hernault</author>
<author>Helmut Prendinger</author>
<author>Mitsuru Ishizuka</author>
</authors>
<title>Hilda: a discourse parser using support vector machine classification. Dialogue and Discourse,</title>
<date>2010</date>
<contexts>
<context position="2191" citStr="Hernault et al., 2010" startWordPosition="310" endWordPosition="313">02) has been provided by (Hirao et al., 2013), whose method also utilizes discourse trees. Thus, the discoursebased summarization approach is one promising way to obtain high-quality summaries. One possible weakness of discourse-based summarization techniques is that they rely greatly on the accuracy of the discourse parser they use. For example, the above discourse-based summarization methods utilize discourse trees based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) for their discourse information. Unfortunately, the current state-of-the-art RST parser, as described in (Hernault et al., 2010), is insufficient as an off-the-shelf discourse parser. In fact, there is empirical evidence that the quality (i.e., ROUGE score) of summaries from autoparsed discourse trees is significantly degraded compared with those generated from gold discourse trees (Marcu, 1998; Hirao et al., 2013). From this background, the goal of this paper is to develop an appropriate discourse parser for discourse-based summarization. We first focus on one of the best discourse-based single document summarization methods as proposed in (Hirao et al., 2013). Their method formulates a single document summarization p</context>
<context position="9462" citStr="Hernault et al., 2010" startWordPosition="1582" endWordPosition="1585">irectly generate the DEP-DT. Figure 2(a) shows an overview of the TKP combined with our DEP-DT parser. In the parser training phase, we transform RST-DTs into DEP-DTs, and directly train our parser with the DEP-DTs. In the summarization phase, our method parses a raw document directly into a DEP-DT, and generates a summary with the TKP. 3.2 Description of Discourse Dependency Parser Our parser is based on the first-order Maximum Spanning Tree (MST) algorithm (McDonald et al., 2005b). Our parser extracts the features from the EDU ei and the EDU ej. We use almost the features as those shown in (Hernault et al., 2010). Lexical N-gram features use the beginning (or end) lexical N-grams (N E 11, 2,31) in ei and ej. We also include POS tags for the beginning (or end) lexical N-grams (N E 11, 2,31) in ei and ej. Organizational features include the distance between ei and ej. They also include the number of tokens, and features for identifying whether or not ei and ej belong to the same sentence (or paragraph). Soricut et al. (2003) introduced dominance set features. They include syntactic labels and the lexical heads of head and attachment nodes along with their dominance relationship. We cannot use the strong</context>
<context position="12849" citStr="Hernault et al., 2010" startWordPosition="2169" endWordPosition="2172">ompared the following three systems that differ in the way they obtain the DEP-DT. TKP-GOLD Used a DEP-DT converted from a gold RST-DT. TKP-DIS-DEP Used a DEP-DT automatically parsed by our discourse dependency-based parser (DIS-DEP). Figure 2(a) shows an overview of this system. TKP-DIS-DEP-LOSS Used a DEP-DT automatically parsed by our discourse dependencybased parser (DIS-DEP). Figure 2(a) shows an overview of this system. It is trained with the loss function defined in equation (2). TKP-HILDA Used a DEP-DT obtained by transforming a RST-DT parsed by HILDA, a stateof-the-art RST-DT parser (Hernault et al., 2010). Figure 2(b) shows an overview of this system. Hirao et al. (2013) proved that TKP-HILDA outperformed other methods including Marcu’s method (Marcu, 1998), a simple knapsack model, a maximum coverage model and LEAD method that simply takes the first L tokens (L = summary length). Thus, we only employed TKP-HILDA as our baseline. We follow the evaluation conditions described in (Hirao et al., 2013). The number of tokens in each summary is determined by the number in the ROUGE-1 ROUGE-2 TKP-GOLD 0.321 0.112 TKP-DIS-DEP 0.319 0.109 TKP-DIS-DEP-LOSS 0.323 0.121 TKP-HILDA 0.284 0.093 Table 1: ROUG</context>
</contexts>
<marker>Hernault, Prendinger, Ishizuka, 2010</marker>
<rawString>Hugo Hernault, Helmut Prendinger, Mitsuru Ishizuka, et al. 2010. Hilda: a discourse parser using support vector machine classification. Dialogue and Discourse, 1(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tsutomu Hirao</author>
<author>Yasuhisa Yoshida</author>
<author>Masaaki Nishino</author>
<author>Norihito Yasuda</author>
<author>Masaaki Nagata</author>
</authors>
<title>Single-document summarization as a tree knapsack problem.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on EMNLP,</booktitle>
<pages>1515--1520</pages>
<contexts>
<context position="1420" citStr="Hirao et al., 2013" startWordPosition="197" endWordPosition="200">EP-DT obtained from an automatically parsed RST-DT. To improve the ROUGE score, we propose a novel discourse parser that directly generates the DEP-DT. The evaluation results showed that the TKP with our parser outperformed that with the state-of-the-art RST-DT parser, and achieved almost equivalent ROUGE scores to the TKP with the gold DEP-DT. 1 Introduction Discourse structures of documents are believed to be highly beneficial for generating informative and coherent summaries. Several discoursebased summarization methods have been developed, such as (Marcu, 1998; Daum´e III and Marcu, 2002; Hirao et al., 2013; Kikuchi et al., 2014). Moreover, the current best ROUGE score for the summarization benchmark data of the RSTdiscourse Treebank (Carlson et al., 2002) has been provided by (Hirao et al., 2013), whose method also utilizes discourse trees. Thus, the discoursebased summarization approach is one promising way to obtain high-quality summaries. One possible weakness of discourse-based summarization techniques is that they rely greatly on the accuracy of the discourse parser they use. For example, the above discourse-based summarization methods utilize discourse trees based on the Rhetorical Struct</context>
<context position="2732" citStr="Hirao et al., 2013" startWordPosition="393" endWordPosition="396">e current state-of-the-art RST parser, as described in (Hernault et al., 2010), is insufficient as an off-the-shelf discourse parser. In fact, there is empirical evidence that the quality (i.e., ROUGE score) of summaries from autoparsed discourse trees is significantly degraded compared with those generated from gold discourse trees (Marcu, 1998; Hirao et al., 2013). From this background, the goal of this paper is to develop an appropriate discourse parser for discourse-based summarization. We first focus on one of the best discourse-based single document summarization methods as proposed in (Hirao et al., 2013). Their method formulates a single document summarization problem as a Tree Knapsack Problem (TKP) over a dependency-based discourse tree (DEP-DT). In their method, DEP-DTs are automatically transformed from (auto-parsed) RST-discourse trees (RST-DTs) by heuristic rules. Instead, we develop a DEP-DT parser, that directly provides DEP-DTs for their state-of-the-art discourse-based summarization method. We show that summaries generated by our parser improve the ROUGE scores to almost the same level as those generated by gold DEP-DTs. We also investigate the way in which the parsing accuracy help</context>
<context position="5357" citStr="Hirao et al., 2013" startWordPosition="849" endWordPosition="852">enote parent(i) as the index of the parent of ei in the DEP-DT. x is an N-dimensional binary vector that represents a summary, i.e. xi = 1 denotes that ei is included in the summary. The TKP is defined as the following ILP problem: �N i=1 F (ei)xi s.t. ENi=1 lixi G L Vi : xparent(i) &gt; xi Vi : xi E 10, 11, where F(ei) is the score of ei. We define F(ei) as follows: where W (ei) is the set of words contained in ei. tf(w, D) is the term frequency of word w in a document D. Depth(ei) is the depth of ei in the DEPDT. 3 Tree Knapsack Problem with Dependency-based Discourse Parser 3.1 Motivation In (Hirao et al., 2013), they automatically obtain the DEP-DT by transforming from the parsed RST-DT. We simply followed their method for obtaining the DEP-DTs 1. The transformation algorithm can be found in detail in (Hirao et al., 2013). Figure 1(a) shows an example of the RST-DT. According to RST, a document is represented as a tree whose terminal nodes correspond to elementary discourse units (EDUs) and whose non-terminal nodes indicate the role of the contiguous EDUs, namely, ‘nucleus (N)’ or ‘satellite (S)’. Since a nucleus is more important than a satellite in terms of the writer’s purpose, a satellite is alw</context>
<context position="7060" citStr="Hirao et al., 2013" startWordPosition="1143" endWordPosition="1146">lgorithm uses the Nucleus-Satellite relationships in the RST-DT. The dependency relationships in Figure 1(b) are quite different from that of the correct DEP-DT in Figure 1(c). In this example, the parser failed to determine the most salient EDU e2, that is the root EDU of the gold DEP-DT. Thus, the summary extracted from this DEP-DT will have a low ROUGE score. The results motivated us to design a new discourse parser fully trained on the DEP-DTs and &apos;Li et al. also defined a similar transformation algorithm (Li et al., 2014). In this paper, we follow the transformation algorithm defined in (Hirao et al., 2013). maximize X F(ei) = Depth(ei) , EwEW(ei) tf(w, D) 1835 (a) Parser Training Phase Document Summarization Phase �� �� RST=DTs � Example ����� ���������� �� � � �� � �� � � Background Contrast � � � � Concession � ��������� � � ���������� �� � � � � � � � � Contrast �� � � � �� 6 Evidence �� � � �� �� �� �� �� e10 Discourse Dependency Parser � � ���������� Root Root ��� DEP=DTs �� Background �� DEP=DT �� �� �� e10 Transformation Algorithm �� �� �� 4 Concession �� ���������� ���������� ���������� ���������� Evidence ���� �� �� �� �� �� Concession ���������� ��������� ��������� �� � Evidence �� ��</context>
<context position="8652" citStr="Hirao et al., 2013" startWordPosition="1445" endWordPosition="1448"> � Evidence � � ��������� Evidence �� � DEP&gt;DT RST&gt;DT Transformation Algorithm Tree Knapsack Problem (b) Parser Training Phase �� � RST&gt;DTs �� � Example ����� ���������� �� � � �� � �� � Background Contrast � � � Concession � � ��������� � � ���������� � � � �� � � � � � � Contrast ��� � � � 6 Evidence �� � � �� �� �� �� �� �� �� �� �� e10 � � Root ���������� Root Root ��� RST Parser Figure 2: (a) Overview of our proposed method. In the parser training phase, the parser is trained on the DEP-DTs, and in the summarization phase, the document is directly parsed into the DEP-DT. (b) Overview of (Hirao et al., 2013). In the parser training phase, the parser is trained on RST-DTs, and in the summarization phase, the document is parsed into the RST-DT, and then transformed into the DEP-DT. that could directly generate the DEP-DT. Figure 2(a) shows an overview of the TKP combined with our DEP-DT parser. In the parser training phase, we transform RST-DTs into DEP-DTs, and directly train our parser with the DEP-DTs. In the summarization phase, our method parses a raw document directly into a DEP-DT, and generates a summary with the TKP. 3.2 Description of Discourse Dependency Parser Our parser is based on the</context>
<context position="12916" citStr="Hirao et al. (2013)" startWordPosition="2181" endWordPosition="2184"> the DEP-DT. TKP-GOLD Used a DEP-DT converted from a gold RST-DT. TKP-DIS-DEP Used a DEP-DT automatically parsed by our discourse dependency-based parser (DIS-DEP). Figure 2(a) shows an overview of this system. TKP-DIS-DEP-LOSS Used a DEP-DT automatically parsed by our discourse dependencybased parser (DIS-DEP). Figure 2(a) shows an overview of this system. It is trained with the loss function defined in equation (2). TKP-HILDA Used a DEP-DT obtained by transforming a RST-DT parsed by HILDA, a stateof-the-art RST-DT parser (Hernault et al., 2010). Figure 2(b) shows an overview of this system. Hirao et al. (2013) proved that TKP-HILDA outperformed other methods including Marcu’s method (Marcu, 1998), a simple knapsack model, a maximum coverage model and LEAD method that simply takes the first L tokens (L = summary length). Thus, we only employed TKP-HILDA as our baseline. We follow the evaluation conditions described in (Hirao et al., 2013). The number of tokens in each summary is determined by the number in the ROUGE-1 ROUGE-2 TKP-GOLD 0.321 0.112 TKP-DIS-DEP 0.319 0.109 TKP-DIS-DEP-LOSS 0.323 0.121 TKP-HILDA 0.284 0.093 Table 1: ROUGE Recall scores human-annotated reference summary. The average leng</context>
</contexts>
<marker>Hirao, Yoshida, Nishino, Yasuda, Nagata, 2013</marker>
<rawString>Tsutomu Hirao, Yasuhisa Yoshida, Masaaki Nishino, Norihito Yasuda, and Masaaki Nagata. 2013. Single-document summarization as a tree knapsack problem. In Proceedings of the 2013 Conference on EMNLP, pages 1515–1520.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuta Kikuchi</author>
<author>Tsutomu Hirao</author>
<author>Hiroya Takamura</author>
<author>Manabu Okumura</author>
<author>Masaaki Nagata</author>
</authors>
<title>Single document summarization based on nested tree structure.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>315--320</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="1443" citStr="Kikuchi et al., 2014" startWordPosition="201" endWordPosition="204">an automatically parsed RST-DT. To improve the ROUGE score, we propose a novel discourse parser that directly generates the DEP-DT. The evaluation results showed that the TKP with our parser outperformed that with the state-of-the-art RST-DT parser, and achieved almost equivalent ROUGE scores to the TKP with the gold DEP-DT. 1 Introduction Discourse structures of documents are believed to be highly beneficial for generating informative and coherent summaries. Several discoursebased summarization methods have been developed, such as (Marcu, 1998; Daum´e III and Marcu, 2002; Hirao et al., 2013; Kikuchi et al., 2014). Moreover, the current best ROUGE score for the summarization benchmark data of the RSTdiscourse Treebank (Carlson et al., 2002) has been provided by (Hirao et al., 2013), whose method also utilizes discourse trees. Thus, the discoursebased summarization approach is one promising way to obtain high-quality summaries. One possible weakness of discourse-based summarization techniques is that they rely greatly on the accuracy of the discourse parser they use. For example, the above discourse-based summarization methods utilize discourse trees based on the Rhetorical Structure Theory (RST) (Mann </context>
</contexts>
<marker>Kikuchi, Hirao, Takamura, Okumura, Nagata, 2014</marker>
<rawString>Yuta Kikuchi, Tsutomu Hirao, Hiroya Takamura, Manabu Okumura, and Masaaki Nagata. 2014. Single document summarization based on nested tree structure. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 315–320, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujian Li</author>
<author>Liang Wang</author>
<author>Ziqiang Cao</author>
<author>Wenjie Li</author>
</authors>
<title>Text-level discourse dependency parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>25--35</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="6973" citStr="Li et al., 2014" startWordPosition="1129" endWordPosition="1132">s Nucleus, we obtain an incorrect DEP-DT in Figure 1(b) because the transformation algorithm uses the Nucleus-Satellite relationships in the RST-DT. The dependency relationships in Figure 1(b) are quite different from that of the correct DEP-DT in Figure 1(c). In this example, the parser failed to determine the most salient EDU e2, that is the root EDU of the gold DEP-DT. Thus, the summary extracted from this DEP-DT will have a low ROUGE score. The results motivated us to design a new discourse parser fully trained on the DEP-DTs and &apos;Li et al. also defined a similar transformation algorithm (Li et al., 2014). In this paper, we follow the transformation algorithm defined in (Hirao et al., 2013). maximize X F(ei) = Depth(ei) , EwEW(ei) tf(w, D) 1835 (a) Parser Training Phase Document Summarization Phase �� �� RST=DTs � Example ����� ���������� �� � � �� � �� � � Background Contrast � � � � Concession � ��������� � � ���������� �� � � � � � � � � Contrast �� � � � �� 6 Evidence �� � � �� �� �� �� �� e10 Discourse Dependency Parser � � ���������� Root Root ��� DEP=DTs �� Background �� DEP=DT �� �� �� e10 Transformation Algorithm �� �� �� 4 Concession �� ���������� ���������� ���������� ���������� Evi</context>
</contexts>
<marker>Li, Wang, Cao, Li, 2014</marker>
<rawString>Sujian Li, Liang Wang, Ziqiang Cao, and Wenjie Li. 2014. Text-level discourse dependency parsing. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 25–35, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="2062" citStr="Mann and Thompson, 1988" startWordPosition="293" endWordPosition="296">2014). Moreover, the current best ROUGE score for the summarization benchmark data of the RSTdiscourse Treebank (Carlson et al., 2002) has been provided by (Hirao et al., 2013), whose method also utilizes discourse trees. Thus, the discoursebased summarization approach is one promising way to obtain high-quality summaries. One possible weakness of discourse-based summarization techniques is that they rely greatly on the accuracy of the discourse parser they use. For example, the above discourse-based summarization methods utilize discourse trees based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) for their discourse information. Unfortunately, the current state-of-the-art RST parser, as described in (Hernault et al., 2010), is insufficient as an off-the-shelf discourse parser. In fact, there is empirical evidence that the quality (i.e., ROUGE score) of summaries from autoparsed discourse trees is significantly degraded compared with those generated from gold discourse trees (Marcu, 1998; Hirao et al., 2013). From this background, the goal of this paper is to develop an appropriate discourse parser for discourse-based summarization. We first focus on one of the best discourse-based sin</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C. Mann and Sandra A. Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>Improving summarization through rhetorical parsing tuning.</title>
<date>1998</date>
<booktitle>In Proc. of The 6th Workshop on VLC,</booktitle>
<pages>206--215</pages>
<contexts>
<context position="1372" citStr="Marcu, 1998" startWordPosition="190" endWordPosition="191"> with a gold DEP-DT and a system with a DEP-DT obtained from an automatically parsed RST-DT. To improve the ROUGE score, we propose a novel discourse parser that directly generates the DEP-DT. The evaluation results showed that the TKP with our parser outperformed that with the state-of-the-art RST-DT parser, and achieved almost equivalent ROUGE scores to the TKP with the gold DEP-DT. 1 Introduction Discourse structures of documents are believed to be highly beneficial for generating informative and coherent summaries. Several discoursebased summarization methods have been developed, such as (Marcu, 1998; Daum´e III and Marcu, 2002; Hirao et al., 2013; Kikuchi et al., 2014). Moreover, the current best ROUGE score for the summarization benchmark data of the RSTdiscourse Treebank (Carlson et al., 2002) has been provided by (Hirao et al., 2013), whose method also utilizes discourse trees. Thus, the discoursebased summarization approach is one promising way to obtain high-quality summaries. One possible weakness of discourse-based summarization techniques is that they rely greatly on the accuracy of the discourse parser they use. For example, the above discourse-based summarization methods utiliz</context>
<context position="4313" citStr="Marcu, 1998" startWordPosition="640" endWordPosition="641">on Empirical Methods in Natural Language Processing (EMNLP), pages 1834–1839, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics Root Elaboration N S Elaboration Example N S N S Elaboration Concession Antithesis S N N S S N S Contrast Contrast N N Evidence N S (a) Background Elabora.on Background Elabora.on Elabora.on Example Concession Concession Example Background Elabora.on An.thesis Elabora.on Elabora.on Evidence (b) Elabora.on Elabora.on Evidence An.thesis (c) Figure 1: Examples of RST-DT and DEP-DT. e1, · · · , e10 are EDUs. (a) Example of an RST-DT from (Marcu, 1998). n1, · · · , n19 are the non-terminal nodes. (b) Example of the DEP-DT obtained from the incorrect RST-DT that is made by swapping the Nucleus-Satellite relationship of the node n2 and the node n3. (c) The correct DEP-DT obtained from the RST-DT in (a). and the i-th EDU ei has li words. L is the maximum number of words allowed in a summary. In the TKP, if we select ei, we need to select its parent EDU in the DEP-DT. We denote parent(i) as the index of the parent of ei in the DEP-DT. x is an N-dimensional binary vector that represents a summary, i.e. xi = 1 denotes that ei is included in the s</context>
<context position="13004" citStr="Marcu, 1998" startWordPosition="2194" endWordPosition="2195">omatically parsed by our discourse dependency-based parser (DIS-DEP). Figure 2(a) shows an overview of this system. TKP-DIS-DEP-LOSS Used a DEP-DT automatically parsed by our discourse dependencybased parser (DIS-DEP). Figure 2(a) shows an overview of this system. It is trained with the loss function defined in equation (2). TKP-HILDA Used a DEP-DT obtained by transforming a RST-DT parsed by HILDA, a stateof-the-art RST-DT parser (Hernault et al., 2010). Figure 2(b) shows an overview of this system. Hirao et al. (2013) proved that TKP-HILDA outperformed other methods including Marcu’s method (Marcu, 1998), a simple knapsack model, a maximum coverage model and LEAD method that simply takes the first L tokens (L = summary length). Thus, we only employed TKP-HILDA as our baseline. We follow the evaluation conditions described in (Hirao et al., 2013). The number of tokens in each summary is determined by the number in the ROUGE-1 ROUGE-2 TKP-GOLD 0.321 0.112 TKP-DIS-DEP 0.319 0.109 TKP-DIS-DEP-LOSS 0.323 0.121 TKP-HILDA 0.284 0.093 Table 1: ROUGE Recall scores human-annotated reference summary. The average length of the reference summaries corresponds to about 10% of the words in the source docume</context>
</contexts>
<marker>Marcu, 1998</marker>
<rawString>Daniel Marcu. 1998. Improving summarization through rhetorical parsing tuning. In Proc. of The 6th Workshop on VLC, pages 206–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Koby Crammer</author>
<author>Fernando Pereira</author>
</authors>
<title>Online large-margin training of dependency parsers.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05,</booktitle>
<pages>91--98</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="9325" citStr="McDonald et al., 2005" startWordPosition="1555" endWordPosition="1558">d on RST-DTs, and in the summarization phase, the document is parsed into the RST-DT, and then transformed into the DEP-DT. that could directly generate the DEP-DT. Figure 2(a) shows an overview of the TKP combined with our DEP-DT parser. In the parser training phase, we transform RST-DTs into DEP-DTs, and directly train our parser with the DEP-DTs. In the summarization phase, our method parses a raw document directly into a DEP-DT, and generates a summary with the TKP. 3.2 Description of Discourse Dependency Parser Our parser is based on the first-order Maximum Spanning Tree (MST) algorithm (McDonald et al., 2005b). Our parser extracts the features from the EDU ei and the EDU ej. We use almost the features as those shown in (Hernault et al., 2010). Lexical N-gram features use the beginning (or end) lexical N-grams (N E 11, 2,31) in ei and ej. We also include POS tags for the beginning (or end) lexical N-grams (N E 11, 2,31) in ei and ej. Organizational features include the distance between ei and ej. They also include the number of tokens, and features for identifying whether or not ei and ej belong to the same sentence (or paragraph). Soricut et al. (2003) introduced dominance set features. They incl</context>
</contexts>
<marker>McDonald, Crammer, Pereira, 2005</marker>
<rawString>Ryan McDonald, Koby Crammer, and Fernando Pereira. 2005a. Online large-margin training of dependency parsers. In Proceedings of the 43rd Annual Meeting on Association for Computational Linguistics, ACL ’05, pages 91–98, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>523--530</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Vancouver, British Columbia, Canada,</location>
<contexts>
<context position="9325" citStr="McDonald et al., 2005" startWordPosition="1555" endWordPosition="1558">d on RST-DTs, and in the summarization phase, the document is parsed into the RST-DT, and then transformed into the DEP-DT. that could directly generate the DEP-DT. Figure 2(a) shows an overview of the TKP combined with our DEP-DT parser. In the parser training phase, we transform RST-DTs into DEP-DTs, and directly train our parser with the DEP-DTs. In the summarization phase, our method parses a raw document directly into a DEP-DT, and generates a summary with the TKP. 3.2 Description of Discourse Dependency Parser Our parser is based on the first-order Maximum Spanning Tree (MST) algorithm (McDonald et al., 2005b). Our parser extracts the features from the EDU ei and the EDU ej. We use almost the features as those shown in (Hernault et al., 2010). Lexical N-gram features use the beginning (or end) lexical N-grams (N E 11, 2,31) in ei and ej. We also include POS tags for the beginning (or end) lexical N-grams (N E 11, 2,31) in ei and ej. Organizational features include the distance between ei and ej. They also include the number of tokens, and features for identifying whether or not ei and ej belong to the same sentence (or paragraph). Soricut et al. (2003) introduced dominance set features. They incl</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. 2005b. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 523–530, Vancouver, British Columbia, Canada, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<marker>Soricut, Marcu, 2003</marker>
<rawString>Radu Soricut and Daniel Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frank Wilcoxon</author>
</authors>
<title>Individual Comparisons by Ranking Methods.</title>
<date>1945</date>
<journal>Biometrics Bulletin,</journal>
<volume>1</volume>
<issue>6</issue>
<contexts>
<context position="14133" citStr="Wilcoxon, 1945" startWordPosition="2372" endWordPosition="2373"> of the reference summaries corresponds to about 10% of the words in the source document. This is also the commonly used evaluation condition for single-document summarization evaluation on the RST-DT corpus. We employed the recall of ROUGE-1, 2 as the evaluation measures. Table 1 shows ROUGE scores on the RST-DT corpus. We can see TKP-DIS-DEP and TKPDIS-DEP-LOSS outperformed TKP-HILDA, and achieved almost the same ROUGE scores as TKPGOLD. Wilcoxon’s signed rank test in terms of ROUGE rejected the null hypothesis, “there is a difference between TKP-HILDA and TKPDIS-DEP (or TKP-DIS-DEP-LOSS)” (Wilcoxon, 1945). This would be because test documents are relatively small. We analyzed the differences between the proposed systems (TKP-DIS-DEP and TKP-DISDEP-LOSS) and TKP-HILDA. First, we evaluated the overlaps between the EDUs in summaries generated by the system and the EDUs in summaries generated by TKP-GOLD. To see the overlaps, we calculated the average F-value using Recall and Precision defined as follows: Recall = |Ss ∩ Sg|/|Sg|, Precision = |Ss ∩ Sg|/|Ss|, where Ss is a set of EDUs in a summary generated by a system, and Sg a set of EDUs in a summary generated by TKP-GOLD. The first line in Table</context>
</contexts>
<marker>Wilcoxon, 1945</marker>
<rawString>Frank Wilcoxon. 1945. Individual Comparisons by Ranking Methods. Biometrics Bulletin, 1(6):80–83, December.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>