<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001307">
<title confidence="0.955299">
Improved Decipherment of Homophonic Ciphers
</title>
<author confidence="0.895447">
Malte Nuhn and Julian Schamper and Hermann Ney
</author>
<affiliation confidence="0.8813075">
Human Language Technology and Pattern Recognition
Computer Science Department, RWTH Aachen University, Aachen, Germany
</affiliation>
<email confidence="0.973336">
&lt;surname&gt;@cs.rwth-aachen.de
</email>
<sectionHeader confidence="0.993311" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99985176">
In this paper, we present two improve-
ments to the beam search approach for
solving homophonic substitution ciphers
presented in Nuhn et al. (2013): An im-
proved rest cost estimation together with
an optimized strategy for obtaining the or-
der in which the symbols of the cipher are
deciphered reduces the beam size needed
to successfully decipher the Zodiac-408
cipher from several million down to less
than one hundred: The search effort is re-
duced from several hours of computation
time to just a few seconds on a single CPU.
These improvements allow us to success-
fully decipher the second part of the fa-
mous Beale cipher (see (Ward et al., 1885)
and e.g. (King, 1993)): Having 182 differ-
ent cipher symbols while having a length
of just 762 symbols, the decipherment is
way more challenging than the decipher-
ment of the previously deciphered Zodiac-
408 cipher (length 408, 54 different sym-
bols). To the best of our knowledge, this
cipher has not been deciphered automati-
cally before.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999741">
State-of-the-art statistical machine translation sys-
tems use large amounts of parallel data to estimate
translation models. However, parallel corpora are
expensive and not available for every domain.
Decipherment uses only monolingual data to
train a translation model: Improving the core deci-
pherment algorithms is an important step for mak-
ing decipherment techniques useful for training
practical machine translation systems.
In this paper we present improvements to the
beam search algorithm for deciphering homo-
phonic substitution ciphers as presented in Nuhn
et al. (2013). We show significant improvements
in computation time on the Zodiac-408 cipher and
show the first decipherment of part two of the
Beale ciphers.
</bodyText>
<sectionHeader confidence="0.999814" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99998644">
Regarding the decipherment of 1:1 substitution ci-
phers, various works have been published: Most
older papers do not use a statistical approach and
instead define some heuristic measures for scoring
candidate decipherments. Approaches like Hart
(1994) and Olson (2007) use a dictionary to check
if a decipherment is useful. Clark (1998) defines
other suitability measures based on n-gram counts
and presents a variety of optimization techniques
like simulated annealing, genetic algorithms and
tabu search. On the other hand, statistical ap-
proaches for 1:1 substitution ciphers are published
in the natural language processing community:
Ravi and Knight (2008) solve 1:1 substitution ci-
phers optimally by formulating the decipherment
problem as an integer linear program (ILP) while
Corlett and Penn (2010) solve the problem using
A∗ search. Ravi and Knight (2011) report the
first automatic decipherment of the Zodiac-408 ci-
pher. They use a combination of a 3-gram lan-
guage model and a word dictionary. As stated in
the previous section, this work can be seen as an
extension of Nuhn et al. (2013). We will there-
fore make heavy use of their definitions and ap-
proaches, which we will summarize in Section 3.
</bodyText>
<sectionHeader confidence="0.99889" genericHeader="method">
3 General Framework
</sectionHeader>
<bodyText confidence="0.9908275">
In this Section we recap the beam search frame-
work introduced in Nuhn et al. (2013).
</bodyText>
<subsectionHeader confidence="0.985348">
3.1 Notation
</subsectionHeader>
<bodyText confidence="0.998946">
We denote the ciphertext with fN =
</bodyText>
<page confidence="0.67368">
1
</page>
<bodyText confidence="0.424587">
fi ... fj ... fN which consists of cipher
</bodyText>
<page confidence="0.862592">
1764
</page>
<bodyText confidence="0.858196">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1764–1768,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
tokens fj E Vf. We denote the plain-
text with eN1 = e1 ... ei ... eN (and its
vocabulary Ve respectively). We define
</bodyText>
<equation confidence="0.623207">
e0 = f0 = eN+1 = fN+1 = $ with “$”
</equation>
<bodyText confidence="0.998729272727273">
being a special sentence boundary token. Homo-
phonic substitutions are formalized with a general
function 0 : Vf —* Ve. Following (Corlett and
Penn, 2010), cipher functions 0, for which not all
0(f)’s are fixed, are called partial cipher func-
tions. Further, 0&apos; is said to extend 0, if for all
f E Vf that are fixed in 0, it holds that f is also
fixed in 0&apos; with 0&apos;(f) = 0(f). The cardinality
of 0 counts the number of fixed f’s in 0. When
talking about partial cipher functions we use the
notation for relations, in which 0 C Vf x Ve.
</bodyText>
<subsectionHeader confidence="0.999046">
3.2 Beam Search
</subsectionHeader>
<bodyText confidence="0.999997714285714">
The main idea of (Nuhn et al., 2013) is to struc-
ture all partial 0’s into a search tree: If a cipher
contains N unique symbols, then the search tree is
of height N. At each level a decision about the n-
th symbol is made. The leaves of the tree form full
hypotheses. Instead of traversing the whole search
tree, beam search descents the tree top to bottom
and only keeps the most promising candidates at
each level. Practically, this is done by keeping
track of all partial hypotheses in two arrays H3 and
Ht. During search all allowed extensions of the
partial hypotheses in H3 are generated, scored and
put into Ht. Here, the function EXT ORDER (see
Section 5) chooses which cipher symbol is used
next for extension, EXT LIMITS decides which ex-
tensions are allowed, and SCORE (see Section 4)
scores the new partial hypotheses. PRUNE then
selects a subset of these hypotheses. Afterwards
the array Ht is copied to H3 and the search pro-
cess continues with the updated array H3. Figure 1
shows the general algorithm.
</bodyText>
<sectionHeader confidence="0.9781" genericHeader="method">
4 Score Estimation
</sectionHeader>
<bodyText confidence="0.999627125">
The score estimation function is crucial to the
search procedure: It predicts how good or bad a
partial cipher function 0 might become, and there-
fore, whether it’s worth to keep it or not.
To illustrate how we can calculate these scores,
we will use the following example with vocabular-
ies Vf = {A, B, C, D}, Ve = {a, b, c, d}, exten-
sion order (B, C, A, D), and cipher text1
</bodyText>
<footnote confidence="0.410158">
fN1 _ $ ABDD CABC DADC ABDC $
1We include blanks only for clarity reasons.
</footnote>
<listItem confidence="0.984962523809524">
1: function BEAM SEARCH(EXT ORDER)
2: init sets H3, Ht
3: CARDINALITY = 0
4: H3.ADD((O, 0))
5: while CARDINALITY &lt; |Vf |do
6: f = EXT ORDER[CARDINALITY]
7: for all 0 E H3 do
8: for all e E Ve do
9: 0&apos; :_ 0 U {(e, f)}
10: if EXT LIMITS(0&apos;) then
11: Ht.ADD(0&apos;,SCORE (0&apos;))
12: end if
13: end for
14: end for
15: PRUNE(Ht)
16: CARDINALITY = CARDINALITY + 1
17: H3 = Ht
18: Ht.CLEAR()
19: end while
20: return best scoring cipher function in H3
21: end function
</listItem>
<figureCaption confidence="0.966124">
Figure 1: The general structure of the beam search
</figureCaption>
<bodyText confidence="0.9730308">
algorithm for decipherment of substitution ciphers
as presented in Nuhn et al. (2013). This paper im-
proves the functions SCORE and EXT ORDER.
and partial hypothesis 0 = {(A, a), (B, b)}. This
yields the following partial decipherment
0(fN1 ) _ $ ab.. .ab. .a.. ab.. $
The score estimation function can only use this
partial decipherment to calculate the hypothesis’
score, since there are not yet any decisions made
about the other positions.
</bodyText>
<subsectionHeader confidence="0.936235">
4.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999951357142857">
Nuhn et al. (2013) present a very simple rest
cost estimator, which calculates the hypothesis’
score based only on fully deciphered n-grams, i.e.
those parts of the partial decipherment that form a
contiguous chunk of n deciphered symbols. For
all other n-grams containing not yet deciphered
symbols, a trivial estimate of probability 1 is as-
sumed, making it an admissible heuristic. For the
above example, this baseline yields the probability
p(a|$) · p(b|a) · 14 · p(b|a) · 16 · p(b|a) · 12. The
more symbols are fixed, the more contiguous n-
grams become available. While being easy and ef-
ficient to compute, it can be seen that for example
the single ”a” is not involved in the computation of
</bodyText>
<page confidence="0.955633">
1765
</page>
<bodyText confidence="0.999946818181818">
the score at all. In practical decipherment, like e.g.
the Zodiac-408 cipher, this forms a real problem:
While making the first decisions—i.e. traversing
the first levels of the search tree—only very few
terms actually contribute to the score estimation,
and thus only give a very coarse score. This makes
the beam search ”blind” when not many symbols
are deciphered yet. This is the reason, why Nuhn
et al. (2013) need a large beam size of several mil-
lion hypotheses in order to not lose the right hy-
pothesis during the first steps of the search.
</bodyText>
<subsectionHeader confidence="0.961537">
4.2 Improved Rest Cost Estimation
</subsectionHeader>
<bodyText confidence="0.999988571428571">
The rest cost estimator we present in this paper
solves the problem mentioned in the previous sec-
tion by also including lower order n-grams: In the
example mentioned before, we would also include
unigram scores into the rest cost estimate, yielding
a score of p(a|$)·p(b|a)·13·p(a)·p(b|a)·12·p(a)12·
p(a) · p(b|a) · 12. Note that this is not a simple lin-
ear interpolation of different n-gram trivial scores:
Each symbol is scored only using the maximum
amount of context available. This heuristic is non-
admissible, since an increased amount of context
can always lower the probabilty of some symbols.
However, experiments show that this score estima-
tion function works great.
</bodyText>
<sectionHeader confidence="0.992438" genericHeader="method">
5 Extension Order
</sectionHeader>
<bodyText confidence="0.999853928571429">
Besides having a generally good scoring function,
also the order in which decisions about the cipher
symbols are made is important for obtaining reli-
able cost estimates. Generally speaking we want
an extension order that produces partial decipher-
ments that contain useful information to decide
whether a hypothesis is worth being kept or not
as early as possible.
It is also clear that the choice of a good ex-
tension order is dependent on the score estima-
tion function SCORE. After presenting the previ-
ous state of the art, we introduce a new extension
order optimized to work together with our previ-
ously introduced rest cost estimator.
</bodyText>
<subsectionHeader confidence="0.898735">
5.1 Baseline
</subsectionHeader>
<bodyText confidence="0.999937166666667">
In (Nuhn et al., 2013), two strategies are pre-
sented: One which at each step chooses the most
frequent remaining cipher symbol, and another,
which greedily chooses the next symbol to max-
imize the number of contiguously fixed n-grams
in the ciphertext.
</bodyText>
<figure confidence="0.7346905">
LM order Perplexity
Zodiac-408 Beale Pt. 2
1 19.49 18.35
2 14.09 13.96
3 12.62 11.81
4 11.38 10.76
5 11.19 9.33
6 10.13 8.49
7 10.15 8.27
8 9.98 8.27
</figure>
<figureCaption confidence="0.7695018">
Table 1: Perplexities of the correct decipherment
of Zodiac-408 and part two of the Beale ciphers
using the character based language model used in
beam search. The language model was trained on
the English Gigaword corpus.
</figureCaption>
<subsectionHeader confidence="0.991433">
5.2 Improved Extension Order
</subsectionHeader>
<bodyText confidence="0.999765923076923">
Each partial mapping φ defines a partial decipher-
ment. We want to choose an extension order such
that all possible partial decipherments following
this extension order are as informative as possible:
Due to that, we can only use information about
which symbols will be deciphered, not their actual
decipherment. Since our heuristic is based on n-
grams of different orders, it seems natural to evalu-
ate an extension order by counting how many con-
tiguously deciphered n-grams are available: Our
new strategy tries to find an extension order op-
timizing the weighted sum of contiguously deci-
phered n-gram counts2
</bodyText>
<equation confidence="0.878163">
N
wn · #n.
n=1
</equation>
<bodyText confidence="0.998357076923077">
Here n is the n-gram order, wn the weight for or-
der n, and #n the number of positions whose max-
imum context is of size n.
We perform a beam search over all possible
enumerations of the cipher vocabulary: We start
with fixing only the first symbol to decipher. We
then continue with the second symbol and evalu-
ate all resulting extension orders of length 2. In
our experiments, we prune these candidates to the
100 best ones and continue with length 3, and so
on.
Suitable values for the weights wn have to be
chosen. We try different weights for the different
</bodyText>
<footnote confidence="0.99329825">
2If two partial extension orders have the same score after
fixing n symbols, we fall back to comparing the scores of
the partial extension orders after fixing only the first n − 1
symbols.
</footnote>
<page confidence="0.915294">
1766
</page>
<equation confidence="0.976034888888889">
i02 h08 a03 v01 e05 d09 e07 P03 o07 s10 i11 t03 e14 d03 i03 n05 t06 h01 e13 c04 o10 u01 n01 t04 y01
o12 f04 b04 e15 d09 f03 o04 r06 d04 a07 b07 o09 u03 t13 f01 o01 u08 r05 m03 i08 l09 e14 s06 f01 r05
o07 m04 b06 u02 f04 o10 r07 d01 s11 i03 n02 a06 n03 e05 x01 c03 a01 v01 a03 t10 i13 o03 n05 o08 r06
v01 a08 u03 l01 t11 s12 i04 x01 f01 e01 e03 t02 b06 e07 l02 o11 w06 t08 h08 e15 s06 u04 r06 f04 a10
...
P04 a14 P01 e07 r05 n02 u02 m02 b01 e14 r05 o03 n05 e15 d10 e01 s01 c01 r01 i03 b05 e06 s08 t01 h08
c04 e10 x01 a14 c07 t02 l09 o12 c02 a04 l09 i13 t02 y01 o02 f03 t07 h02 e11 v01 a10 r07 l07 t11 s09
o04 t01 h03 a06 t04 n03 o06 d05 i13 f02 f03 i03 c04 u07 l09 t02 y01 w04 i12 l01 l02 b03 e01 h02 a09
d10 i07 n06 f01 i13 n01 d10 i03 n05 g04 i03 t05
</equation>
<bodyText confidence="0.975477428571429">
Table 2: Beginning and end of part two of the Beale cipher. Here we show a relabeled version of the ci-
pher, which encodes knowledge of the gold decipherment to assign reasonable names to all homophones.
The original cipher just consists of numbers.
orders on the Zodiac-408 cipher with just a beam
size of 26. With such a small beam size, the exten-
sion order plays a crucial role for a successful de-
cipherment: Depending on the choice of the differ-
ent weights wn we can observe decipherment runs
with 3 out of 54 correct mappings, up to 52 out
of 54 mappings correct. Even though the choice
of weights is somewhat arbitrary, we can see that
generally giving higher weights to higher n-gram
orders yields better results.
We use the weights w8 =
</bodyText>
<equation confidence="0.6018315">
1
(0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0, 3.0) for the
</equation>
<bodyText confidence="0.999966142857143">
following experiments. It is interesting to com-
pare these weights to the perplexities of the
correct decipherment measured using different
n-gram orders (Table 5). However, at this point
we do not see any obvious connection between
perplexities and weights wn, and leave this as a
further research direction.
</bodyText>
<sectionHeader confidence="0.991346" genericHeader="method">
6 Experimental Evaluation
</sectionHeader>
<subsectionHeader confidence="0.999175">
6.1 Zodiac Cipher
</subsectionHeader>
<bodyText confidence="0.999986">
Using our new algorithm we are able to decipher
the Zodiac-408 with just a beam size of 26 and a
language model order of size 8. By keeping track
of the gold hypothesis while performing the beam
search, we can see that the gold decipherment in-
deed always remains within the top 26 scoring hy-
potheses. Our new algorithm is able to decipher
the Zodiac-408 cipher in less than 10s on a sin-
gle CPU, as compared to 48h of CPU time using
the previously published heuristic, which required
a beam size of several million. Solving a cipher
with such a small beam size can be seen as “read-
ing off the solution”.
</bodyText>
<subsectionHeader confidence="0.999835">
6.2 Beale Cipher
</subsectionHeader>
<bodyText confidence="0.999992413793103">
We apply our algorithm to the second part of the
Beale ciphers with a 8-gram language model.
Compared to the Zodiac-408, which has length
408 while having 54 different symbols (7.55 ob-
servations per symbol), part two of the Beale ci-
phers has length 762 while having 182 different
symbols (4.18 observations per symbol). Com-
pared to the Zodiac-408, this is both, in terms of
redundancy, as well as in size of search space, a
way more difficult cipher to break.
Here we run our algorithm with a beam size of
10M and achieve a decipherment accuracy of 157
out of 185 symbols correct yielding a symbol error
rate of less than 5.4%. The gold decipherment is
pruned out of the beam after 35 symbols have been
fixed.
We also ran our algorithm on the other parts
of the Beale ciphers: The first part has a length
520 and contains 299 different cipher symbols
(1.74 observations per symbol), while part three
has length 618 and has 264 symbols which is
2.34 observations per mapping. However, our al-
gorithm does not yield any reasonable decipher-
ments. Since length and number of symbols indi-
cate that deciphering these ciphers is again more
difficult than for part two, it is not clear whether
the other parts are not a homophonic substitution
cipher at all, or whether our algorithm is still not
good enough to find the correct decipherment.
</bodyText>
<sectionHeader confidence="0.998933" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999949">
We presented two extensions to the beam search
method presented in (Nuhn et al., 2012), that re-
duce the search effort to decipher the Zodiac-408
enormously. These improvements allow us to au-
tomatically decipher part two of the Beale ciphers.
To the best of our knowledge, this has not been
</bodyText>
<page confidence="0.978131">
1767
</page>
<bodyText confidence="0.974558333333333">
done before. This algorithm might prove useful
when applied to word substitution ciphers and to
learning translations from monolingual data.
</bodyText>
<note confidence="0.6570755">
James B Ward, Thomas Jefferson Beale, and Robert
Morriss. 1885. The Beale Papers.
</note>
<sectionHeader confidence="0.995132" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999364">
The authors thank Mark Kozek from the Depart-
ment of Mathematics at Whittier College for chal-
lenging us with a homophonic cipher he created.
Working on his cipher led to developing the meth-
ods presented in this paper.
</bodyText>
<sectionHeader confidence="0.999192" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999850904761905">
Andrew J. Clark. 1998. Optimisation heuristics for
cryptology. Ph.D. thesis, Faculty of Information
Technology, Queensland University of Technology.
Eric Corlett and Gerald Penn. 2010. An exact A*
method for deciphering letter-substitution ciphers.
In Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics (ACL),
pages 1040–1047, Uppsala, Sweden, July. The As-
sociation for Computer Linguistics.
George W. Hart. 1994. To decode short cryptograms.
Communications of the Association for Computing
Machinery (CACM), 37(9):102–108, September.
John C. King. 1993. A reconstruction of the key to
beale cipher number two. Cryptologia, 17(3):305–
317.
Malte Nuhn, Arne Mauser, and Hermann Ney. 2012.
Deciphering foreign language by combining lan-
guage models and context vectors. In Proceedings
of the 50th Annual Meeting of the Association for
Computational Linguistics (ACL), pages 156–164,
Jeju, Republic of Korea, July. Association for Com-
putational Linguistics.
Malte Nuhn, Julian Schamper, and Hermann Ney.
2013. Beam search for solving substitution ciphers.
In Annual Meeting of the Assoc. for Computational
Linguistics, pages 1569–1576, Sofia, Bulgaria, Au-
gust.
Edwin Olson. 2007. Robust dictionary attack of
short simple substitution ciphers. Cryptologia,
31(4):332–342, October.
Sujith Ravi and Kevin Knight. 2008. Attacking de-
cipherment problems optimally with low-order n-
gram models. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP), pages 812–819, Honolulu, Hawaii. Asso-
ciation for Computational Linguistics.
Sujith Ravi and Kevin Knight. 2011. Bayesian infer-
ence for Zodiac and other homophonic ciphers. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
239–247, Portland, Oregon, June. Association for
Computational Linguistics.
</reference>
<page confidence="0.993596">
1768
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.375159">
<title confidence="0.7958815">Improved Decipherment of Homophonic Ciphers Nuhn Schamper</title>
<author confidence="0.600407">Human Language Technology</author>
<author confidence="0.600407">Pattern</author>
<affiliation confidence="0.990602">Computer Science Department, RWTH Aachen University, Aachen,</affiliation>
<email confidence="0.99568">&lt;surname&gt;@cs.rwth-aachen.de</email>
<abstract confidence="0.996137730769231">In this paper, we present two improvements to the beam search approach for solving homophonic substitution ciphers presented in Nuhn et al. (2013): An improved rest cost estimation together with an optimized strategy for obtaining the order in which the symbols of the cipher are deciphered reduces the beam size needed to successfully decipher the Zodiac-408 cipher from several million down to less than one hundred: The search effort is reduced from several hours of computation time to just a few seconds on a single CPU. These improvements allow us to successfully decipher the second part of the famous Beale cipher (see (Ward et al., 1885) and e.g. (King, 1993)): Having 182 different cipher symbols while having a length of just 762 symbols, the decipherment is way more challenging than the decipherment of the previously deciphered Zodiac- 408 cipher (length 408, 54 different symbols). To the best of our knowledge, this cipher has not been deciphered automatically before.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Andrew J Clark</author>
</authors>
<title>Optimisation heuristics for cryptology.</title>
<date>1998</date>
<tech>Ph.D. thesis,</tech>
<institution>Faculty of Information Technology, Queensland University of Technology.</institution>
<contexts>
<context position="2318" citStr="Clark (1998)" startWordPosition="357" endWordPosition="358">ents to the beam search algorithm for deciphering homophonic substitution ciphers as presented in Nuhn et al. (2013). We show significant improvements in computation time on the Zodiac-408 cipher and show the first decipherment of part two of the Beale ciphers. 2 Related Work Regarding the decipherment of 1:1 substitution ciphers, various works have been published: Most older papers do not use a statistical approach and instead define some heuristic measures for scoring candidate decipherments. Approaches like Hart (1994) and Olson (2007) use a dictionary to check if a decipherment is useful. Clark (1998) defines other suitability measures based on n-gram counts and presents a variety of optimization techniques like simulated annealing, genetic algorithms and tabu search. On the other hand, statistical approaches for 1:1 substitution ciphers are published in the natural language processing community: Ravi and Knight (2008) solve 1:1 substitution ciphers optimally by formulating the decipherment problem as an integer linear program (ILP) while Corlett and Penn (2010) solve the problem using A∗ search. Ravi and Knight (2011) report the first automatic decipherment of the Zodiac-408 cipher. They </context>
</contexts>
<marker>Clark, 1998</marker>
<rawString>Andrew J. Clark. 1998. Optimisation heuristics for cryptology. Ph.D. thesis, Faculty of Information Technology, Queensland University of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Corlett</author>
<author>Gerald Penn</author>
</authors>
<title>An exact A* method for deciphering letter-substitution ciphers.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>1040--1047</pages>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="2788" citStr="Corlett and Penn (2010)" startWordPosition="423" endWordPosition="426">res for scoring candidate decipherments. Approaches like Hart (1994) and Olson (2007) use a dictionary to check if a decipherment is useful. Clark (1998) defines other suitability measures based on n-gram counts and presents a variety of optimization techniques like simulated annealing, genetic algorithms and tabu search. On the other hand, statistical approaches for 1:1 substitution ciphers are published in the natural language processing community: Ravi and Knight (2008) solve 1:1 substitution ciphers optimally by formulating the decipherment problem as an integer linear program (ILP) while Corlett and Penn (2010) solve the problem using A∗ search. Ravi and Knight (2011) report the first automatic decipherment of the Zodiac-408 cipher. They use a combination of a 3-gram language model and a word dictionary. As stated in the previous section, this work can be seen as an extension of Nuhn et al. (2013). We will therefore make heavy use of their definitions and approaches, which we will summarize in Section 3. 3 General Framework In this Section we recap the beam search framework introduced in Nuhn et al. (2013). 3.1 Notation We denote the ciphertext with fN = 1 fi ... fj ... fN which consists of cipher 1</context>
</contexts>
<marker>Corlett, Penn, 2010</marker>
<rawString>Eric Corlett and Gerald Penn. 2010. An exact A* method for deciphering letter-substitution ciphers. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics (ACL), pages 1040–1047, Uppsala, Sweden, July. The Association for Computer Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George W Hart</author>
</authors>
<title>To decode short cryptograms.</title>
<date>1994</date>
<journal>Communications of the Association for Computing Machinery (CACM),</journal>
<volume>37</volume>
<issue>9</issue>
<contexts>
<context position="2233" citStr="Hart (1994)" startWordPosition="342" endWordPosition="343">or training practical machine translation systems. In this paper we present improvements to the beam search algorithm for deciphering homophonic substitution ciphers as presented in Nuhn et al. (2013). We show significant improvements in computation time on the Zodiac-408 cipher and show the first decipherment of part two of the Beale ciphers. 2 Related Work Regarding the decipherment of 1:1 substitution ciphers, various works have been published: Most older papers do not use a statistical approach and instead define some heuristic measures for scoring candidate decipherments. Approaches like Hart (1994) and Olson (2007) use a dictionary to check if a decipherment is useful. Clark (1998) defines other suitability measures based on n-gram counts and presents a variety of optimization techniques like simulated annealing, genetic algorithms and tabu search. On the other hand, statistical approaches for 1:1 substitution ciphers are published in the natural language processing community: Ravi and Knight (2008) solve 1:1 substitution ciphers optimally by formulating the decipherment problem as an integer linear program (ILP) while Corlett and Penn (2010) solve the problem using A∗ search. Ravi and </context>
</contexts>
<marker>Hart, 1994</marker>
<rawString>George W. Hart. 1994. To decode short cryptograms. Communications of the Association for Computing Machinery (CACM), 37(9):102–108, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C King</author>
</authors>
<title>A reconstruction of the key to beale cipher number two.</title>
<date>1993</date>
<journal>Cryptologia,</journal>
<volume>17</volume>
<issue>3</issue>
<pages>317</pages>
<contexts>
<context position="915" citStr="King, 1993" startWordPosition="143" endWordPosition="144">arch approach for solving homophonic substitution ciphers presented in Nuhn et al. (2013): An improved rest cost estimation together with an optimized strategy for obtaining the order in which the symbols of the cipher are deciphered reduces the beam size needed to successfully decipher the Zodiac-408 cipher from several million down to less than one hundred: The search effort is reduced from several hours of computation time to just a few seconds on a single CPU. These improvements allow us to successfully decipher the second part of the famous Beale cipher (see (Ward et al., 1885) and e.g. (King, 1993)): Having 182 different cipher symbols while having a length of just 762 symbols, the decipherment is way more challenging than the decipherment of the previously deciphered Zodiac408 cipher (length 408, 54 different symbols). To the best of our knowledge, this cipher has not been deciphered automatically before. 1 Introduction State-of-the-art statistical machine translation systems use large amounts of parallel data to estimate translation models. However, parallel corpora are expensive and not available for every domain. Decipherment uses only monolingual data to train a translation model: </context>
</contexts>
<marker>King, 1993</marker>
<rawString>John C. King. 1993. A reconstruction of the key to beale cipher number two. Cryptologia, 17(3):305– 317.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malte Nuhn</author>
<author>Arne Mauser</author>
<author>Hermann Ney</author>
</authors>
<title>Deciphering foreign language by combining language models and context vectors.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>156--164</pages>
<institution>Korea, July. Association for Computational Linguistics.</institution>
<location>Jeju, Republic of</location>
<contexts>
<context position="15347" citStr="Nuhn et al., 2012" startWordPosition="2704" endWordPosition="2707">ntains 299 different cipher symbols (1.74 observations per symbol), while part three has length 618 and has 264 symbols which is 2.34 observations per mapping. However, our algorithm does not yield any reasonable decipherments. Since length and number of symbols indicate that deciphering these ciphers is again more difficult than for part two, it is not clear whether the other parts are not a homophonic substitution cipher at all, or whether our algorithm is still not good enough to find the correct decipherment. 7 Conclusion We presented two extensions to the beam search method presented in (Nuhn et al., 2012), that reduce the search effort to decipher the Zodiac-408 enormously. These improvements allow us to automatically decipher part two of the Beale ciphers. To the best of our knowledge, this has not been 1767 done before. This algorithm might prove useful when applied to word substitution ciphers and to learning translations from monolingual data. James B Ward, Thomas Jefferson Beale, and Robert Morriss. 1885. The Beale Papers. Acknowledgements The authors thank Mark Kozek from the Department of Mathematics at Whittier College for challenging us with a homophonic cipher he created. Working on </context>
</contexts>
<marker>Nuhn, Mauser, Ney, 2012</marker>
<rawString>Malte Nuhn, Arne Mauser, and Hermann Ney. 2012. Deciphering foreign language by combining language models and context vectors. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (ACL), pages 156–164, Jeju, Republic of Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malte Nuhn</author>
<author>Julian Schamper</author>
<author>Hermann Ney</author>
</authors>
<title>Beam search for solving substitution ciphers.</title>
<date>2013</date>
<booktitle>In Annual Meeting of the Assoc. for Computational Linguistics,</booktitle>
<pages>1569--1576</pages>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="1822" citStr="Nuhn et al. (2013)" startWordPosition="278" endWordPosition="281">red automatically before. 1 Introduction State-of-the-art statistical machine translation systems use large amounts of parallel data to estimate translation models. However, parallel corpora are expensive and not available for every domain. Decipherment uses only monolingual data to train a translation model: Improving the core decipherment algorithms is an important step for making decipherment techniques useful for training practical machine translation systems. In this paper we present improvements to the beam search algorithm for deciphering homophonic substitution ciphers as presented in Nuhn et al. (2013). We show significant improvements in computation time on the Zodiac-408 cipher and show the first decipherment of part two of the Beale ciphers. 2 Related Work Regarding the decipherment of 1:1 substitution ciphers, various works have been published: Most older papers do not use a statistical approach and instead define some heuristic measures for scoring candidate decipherments. Approaches like Hart (1994) and Olson (2007) use a dictionary to check if a decipherment is useful. Clark (1998) defines other suitability measures based on n-gram counts and presents a variety of optimization techni</context>
<context position="3080" citStr="Nuhn et al. (2013)" startWordPosition="476" endWordPosition="479">lgorithms and tabu search. On the other hand, statistical approaches for 1:1 substitution ciphers are published in the natural language processing community: Ravi and Knight (2008) solve 1:1 substitution ciphers optimally by formulating the decipherment problem as an integer linear program (ILP) while Corlett and Penn (2010) solve the problem using A∗ search. Ravi and Knight (2011) report the first automatic decipherment of the Zodiac-408 cipher. They use a combination of a 3-gram language model and a word dictionary. As stated in the previous section, this work can be seen as an extension of Nuhn et al. (2013). We will therefore make heavy use of their definitions and approaches, which we will summarize in Section 3. 3 General Framework In this Section we recap the beam search framework introduced in Nuhn et al. (2013). 3.1 Notation We denote the ciphertext with fN = 1 fi ... fj ... fN which consists of cipher 1764 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1764–1768, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics tokens fj E Vf. We denote the plaintext with eN1 = e1 ... ei ... eN (and its vocabulary Ve r</context>
<context position="4325" citStr="Nuhn et al., 2013" startWordPosition="709" endWordPosition="712">= f0 = eN+1 = fN+1 = $ with “$” being a special sentence boundary token. Homophonic substitutions are formalized with a general function 0 : Vf —* Ve. Following (Corlett and Penn, 2010), cipher functions 0, for which not all 0(f)’s are fixed, are called partial cipher functions. Further, 0&apos; is said to extend 0, if for all f E Vf that are fixed in 0, it holds that f is also fixed in 0&apos; with 0&apos;(f) = 0(f). The cardinality of 0 counts the number of fixed f’s in 0. When talking about partial cipher functions we use the notation for relations, in which 0 C Vf x Ve. 3.2 Beam Search The main idea of (Nuhn et al., 2013) is to structure all partial 0’s into a search tree: If a cipher contains N unique symbols, then the search tree is of height N. At each level a decision about the nth symbol is made. The leaves of the tree form full hypotheses. Instead of traversing the whole search tree, beam search descents the tree top to bottom and only keeps the most promising candidates at each level. Practically, this is done by keeping track of all partial hypotheses in two arrays H3 and Ht. During search all allowed extensions of the partial hypotheses in H3 are generated, scored and put into Ht. Here, the function E</context>
<context position="6365" citStr="Nuhn et al. (2013)" startWordPosition="1090" endWordPosition="1093">nly for clarity reasons. 1: function BEAM SEARCH(EXT ORDER) 2: init sets H3, Ht 3: CARDINALITY = 0 4: H3.ADD((O, 0)) 5: while CARDINALITY &lt; |Vf |do 6: f = EXT ORDER[CARDINALITY] 7: for all 0 E H3 do 8: for all e E Ve do 9: 0&apos; :_ 0 U {(e, f)} 10: if EXT LIMITS(0&apos;) then 11: Ht.ADD(0&apos;,SCORE (0&apos;)) 12: end if 13: end for 14: end for 15: PRUNE(Ht) 16: CARDINALITY = CARDINALITY + 1 17: H3 = Ht 18: Ht.CLEAR() 19: end while 20: return best scoring cipher function in H3 21: end function Figure 1: The general structure of the beam search algorithm for decipherment of substitution ciphers as presented in Nuhn et al. (2013). This paper improves the functions SCORE and EXT ORDER. and partial hypothesis 0 = {(A, a), (B, b)}. This yields the following partial decipherment 0(fN1 ) _ $ ab.. .ab. .a.. ab.. $ The score estimation function can only use this partial decipherment to calculate the hypothesis’ score, since there are not yet any decisions made about the other positions. 4.1 Baseline Nuhn et al. (2013) present a very simple rest cost estimator, which calculates the hypothesis’ score based only on fully deciphered n-grams, i.e. those parts of the partial decipherment that form a contiguous chunk of n deciphere</context>
<context position="7850" citStr="Nuhn et al. (2013)" startWordPosition="1343" endWordPosition="1346">e more symbols are fixed, the more contiguous ngrams become available. While being easy and efficient to compute, it can be seen that for example the single ”a” is not involved in the computation of 1765 the score at all. In practical decipherment, like e.g. the Zodiac-408 cipher, this forms a real problem: While making the first decisions—i.e. traversing the first levels of the search tree—only very few terms actually contribute to the score estimation, and thus only give a very coarse score. This makes the beam search ”blind” when not many symbols are deciphered yet. This is the reason, why Nuhn et al. (2013) need a large beam size of several million hypotheses in order to not lose the right hypothesis during the first steps of the search. 4.2 Improved Rest Cost Estimation The rest cost estimator we present in this paper solves the problem mentioned in the previous section by also including lower order n-grams: In the example mentioned before, we would also include unigram scores into the rest cost estimate, yielding a score of p(a|$)·p(b|a)·13·p(a)·p(b|a)·12·p(a)12· p(a) · p(b|a) · 12. Note that this is not a simple linear interpolation of different n-gram trivial scores: Each symbol is scored on</context>
<context position="9385" citStr="Nuhn et al., 2013" startWordPosition="1598" endWordPosition="1601">the order in which decisions about the cipher symbols are made is important for obtaining reliable cost estimates. Generally speaking we want an extension order that produces partial decipherments that contain useful information to decide whether a hypothesis is worth being kept or not as early as possible. It is also clear that the choice of a good extension order is dependent on the score estimation function SCORE. After presenting the previous state of the art, we introduce a new extension order optimized to work together with our previously introduced rest cost estimator. 5.1 Baseline In (Nuhn et al., 2013), two strategies are presented: One which at each step chooses the most frequent remaining cipher symbol, and another, which greedily chooses the next symbol to maximize the number of contiguously fixed n-grams in the ciphertext. LM order Perplexity Zodiac-408 Beale Pt. 2 1 19.49 18.35 2 14.09 13.96 3 12.62 11.81 4 11.38 10.76 5 11.19 9.33 6 10.13 8.49 7 10.15 8.27 8 9.98 8.27 Table 1: Perplexities of the correct decipherment of Zodiac-408 and part two of the Beale ciphers using the character based language model used in beam search. The language model was trained on the English Gigaword corpu</context>
</contexts>
<marker>Nuhn, Schamper, Ney, 2013</marker>
<rawString>Malte Nuhn, Julian Schamper, and Hermann Ney. 2013. Beam search for solving substitution ciphers. In Annual Meeting of the Assoc. for Computational Linguistics, pages 1569–1576, Sofia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edwin Olson</author>
</authors>
<title>Robust dictionary attack of short simple substitution ciphers.</title>
<date>2007</date>
<journal>Cryptologia,</journal>
<volume>31</volume>
<issue>4</issue>
<contexts>
<context position="2250" citStr="Olson (2007)" startWordPosition="345" endWordPosition="346">tical machine translation systems. In this paper we present improvements to the beam search algorithm for deciphering homophonic substitution ciphers as presented in Nuhn et al. (2013). We show significant improvements in computation time on the Zodiac-408 cipher and show the first decipherment of part two of the Beale ciphers. 2 Related Work Regarding the decipherment of 1:1 substitution ciphers, various works have been published: Most older papers do not use a statistical approach and instead define some heuristic measures for scoring candidate decipherments. Approaches like Hart (1994) and Olson (2007) use a dictionary to check if a decipherment is useful. Clark (1998) defines other suitability measures based on n-gram counts and presents a variety of optimization techniques like simulated annealing, genetic algorithms and tabu search. On the other hand, statistical approaches for 1:1 substitution ciphers are published in the natural language processing community: Ravi and Knight (2008) solve 1:1 substitution ciphers optimally by formulating the decipherment problem as an integer linear program (ILP) while Corlett and Penn (2010) solve the problem using A∗ search. Ravi and Knight (2011) rep</context>
</contexts>
<marker>Olson, 2007</marker>
<rawString>Edwin Olson. 2007. Robust dictionary attack of short simple substitution ciphers. Cryptologia, 31(4):332–342, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Attacking decipherment problems optimally with low-order ngram models.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<pages>812--819</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii.</location>
<contexts>
<context position="2642" citStr="Ravi and Knight (2008)" startWordPosition="401" endWordPosition="404">stitution ciphers, various works have been published: Most older papers do not use a statistical approach and instead define some heuristic measures for scoring candidate decipherments. Approaches like Hart (1994) and Olson (2007) use a dictionary to check if a decipherment is useful. Clark (1998) defines other suitability measures based on n-gram counts and presents a variety of optimization techniques like simulated annealing, genetic algorithms and tabu search. On the other hand, statistical approaches for 1:1 substitution ciphers are published in the natural language processing community: Ravi and Knight (2008) solve 1:1 substitution ciphers optimally by formulating the decipherment problem as an integer linear program (ILP) while Corlett and Penn (2010) solve the problem using A∗ search. Ravi and Knight (2011) report the first automatic decipherment of the Zodiac-408 cipher. They use a combination of a 3-gram language model and a word dictionary. As stated in the previous section, this work can be seen as an extension of Nuhn et al. (2013). We will therefore make heavy use of their definitions and approaches, which we will summarize in Section 3. 3 General Framework In this Section we recap the bea</context>
</contexts>
<marker>Ravi, Knight, 2008</marker>
<rawString>Sujith Ravi and Kevin Knight. 2008. Attacking decipherment problems optimally with low-order ngram models. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 812–819, Honolulu, Hawaii. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Bayesian inference for Zodiac and other homophonic ciphers.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>239--247</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon,</location>
<contexts>
<context position="2846" citStr="Ravi and Knight (2011)" startWordPosition="433" endWordPosition="436">rt (1994) and Olson (2007) use a dictionary to check if a decipherment is useful. Clark (1998) defines other suitability measures based on n-gram counts and presents a variety of optimization techniques like simulated annealing, genetic algorithms and tabu search. On the other hand, statistical approaches for 1:1 substitution ciphers are published in the natural language processing community: Ravi and Knight (2008) solve 1:1 substitution ciphers optimally by formulating the decipherment problem as an integer linear program (ILP) while Corlett and Penn (2010) solve the problem using A∗ search. Ravi and Knight (2011) report the first automatic decipherment of the Zodiac-408 cipher. They use a combination of a 3-gram language model and a word dictionary. As stated in the previous section, this work can be seen as an extension of Nuhn et al. (2013). We will therefore make heavy use of their definitions and approaches, which we will summarize in Section 3. 3 General Framework In this Section we recap the beam search framework introduced in Nuhn et al. (2013). 3.1 Notation We denote the ciphertext with fN = 1 fi ... fj ... fN which consists of cipher 1764 Proceedings of the 2014 Conference on Empirical Method</context>
</contexts>
<marker>Ravi, Knight, 2011</marker>
<rawString>Sujith Ravi and Kevin Knight. 2011. Bayesian inference for Zodiac and other homophonic ciphers. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 239–247, Portland, Oregon, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>