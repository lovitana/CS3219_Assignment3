<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013352">
<title confidence="0.998463">
Lexical Substitution for the Medical Domain
</title>
<author confidence="0.989533">
Martin Riedl1 Michael R. Glass2 Alfio Gliozzo2
</author>
<listItem confidence="0.5059975">
(1) FG Language Technology, CS Dept., TU Darmstadt, 64289 Darmstadt, Germany
(2) IBM T.J. Watson Research, Yorktown Heights, NY 10598, USA
</listItem>
<email confidence="0.971597">
riedl@cs.tu-darmstadt.de, {mrglass,gliozzo}@us.ibm.com
</email>
<sectionHeader confidence="0.993031" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998975384615385">
In this paper we examine the lexical substitu-
tion task for the medical domain. We adapt
the current best system from the open domain,
which trains a single classifier for all instances
using delexicalized features. We show sig-
nificant improvements over a strong baseline
coming from a distributional thesaurus (DT).
Whereas in the open domain system, features
derived from WordNet show only slight im-
provements, we show that its counterpart for
the medical domain (UMLS) shows a signif-
icant additional benefit when used for feature
generation.
</bodyText>
<sectionHeader confidence="0.998798" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99979125">
The task of lexical substitution (McCarthy and Navigli,
2009) deals with the substitution of a target term within
a sentence with words having the same meaning. Thus,
the task divides into two subtasks:
</bodyText>
<listItem confidence="0.9915316">
• Identification of substitution candidates, i.e.
terms that are, for some contexts, substitutable for
a given target term.
• Ranking the substitution candidates according to
their context
</listItem>
<bodyText confidence="0.983999238095238">
Such a substitution system can help for semantic text
similarity (B¨ar et al., 2012), textual entailment (Dagan
et al., 2013) or plagiarism detection (Chong and Specia,
2011).
Datasets provided by McCarthy and Navigli (2009)
and Biemann (2012) offer manually annotated substi-
tutes for a given set of target words within a context
(sentence). Contrary to these two datasets in Kremer et
al. (2014) a dataset is offered where all words have are
annotated with substitutes. All the datasets are suited
for the open domain.
But a system performing lexical substitution is not
only of interest for the open domain, but also for the
medical domain. Such a system could then be applied
to medical word sense disambiguation, entailment or
question answering tasks. Here we introduce a new
dataset and adapt the lexical substitution system, pro-
vided by Szarvas et al. (2013), to the medical domain.
Additionally, we do not make use of WordNet (Miller,
1995) to provide similar terms, but rather employ a Dis-
tributional Thesaurus (DT), computed on medical texts.
</bodyText>
<sectionHeader confidence="0.999778" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999834">
For the general domain, the lexical substitution task
was initiated by a Semeval-2007 Task (McCarthy and
Navigli, 2009). This task was won by an unsupervised
method (Giuliano et al., 2007), which uses WordNet for
the substitution candidate generation and then relies on
the Google Web1T n-grams (Brants and Franz, 2006)1
to rank the substitutes.
The currently best system, to our knowledge, is pro-
posed by Szarvas et al. (2013). This is a supervised ap-
proach, where a single classifier is trained using delex-
icalized features for all substitutes and can thus be ap-
plied even to previously unseen substitutes. Although
there have been many approaches for solving the task
for the general domain, only slight effort has been done
in adapting it to different domains.
</bodyText>
<sectionHeader confidence="0.985484" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.999965454545455">
To perform lexical substitution, we follow the delex-
icalization framework of Szarvas et al. (2013). We
automatically build Distributional Thesauri (DTs) for
the medical domain and use features from the Uni-
fied Medical Language System (UMLS) ontology. The
dataset for supervised lexical substitution consists of
sentences, containing an annotated target word t. Con-
sidering the sentence being the context for the target
word, the target word might have different meanings.
Thus annotated substitute candidates sg1 ... sgn E sg,
need to be provided for each context. The negative ex-
amples are substitute candidates that either are incor-
rect for the target word, do not fit into the context or
both. We will refer to these substitutes as false substi-
tute candidates sf1 ... sfm E sf with sf n sg = ∅.
For the generation of substitute candidates we do not
use WordNet, as done in previous works (Szarvas et al.,
2013), but use only substitutes from a DT. To train a
single classifier, features that distinguishing the mean-
ing of words in different context need to be considered.
Such features could be e.g. n-grams, features from dis-
tributional semantics or features which are extracted
</bodyText>
<footnote confidence="0.9967145">
1http://catalog.ldc.upenn.edu/
LDC2006T13
</footnote>
<page confidence="0.928438">
610
</page>
<bodyText confidence="0.906277666666667">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 610–614,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
relative to the target word, such as the ratio between
frequencies of the substitute candidate and the target
word. After training, we apply the algorithm to un-
seen substitute candidates and rank them according to
their positive probabilities, given by the classifier. Con-
trary to Szarvas et al. (2013), we do not use any weight-
ing in the training if a substitute has been supplied by
many annotators, as we could not observe any improve-
ments. Additionally, we use logistic regression (Fan et
al., 2008) as classifier2.
</bodyText>
<sectionHeader confidence="0.998917" genericHeader="method">
4 Resources
</sectionHeader>
<bodyText confidence="0.999239666666667">
For the substitutes and for the generation of delexical-
ized features, we rely on DTs, the UMLS and Google
Web1T.
</bodyText>
<subsectionHeader confidence="0.986159">
4.1 Distributional thesauri (DTs)
</subsectionHeader>
<bodyText confidence="0.999988333333333">
We computed two different DTs using the framework
proposed in Biemann and Riedl (2013)3.
The first DT is computed based on Medline4 ab-
stracts. This thesaurus uses the left and the right word
as context features. To include multi-word expressions,
we allow the number of tokens that form a term to be
up to the length of three.
The second DT is based on dependencies as context
features from a English Slot Grammar (ESG) parser
(McCord et al., 2012) modified to handle medical data.
The ESG parser is also capable of finding multi-word
expressions. As input data we use 3.3 GB of texts
from medical textbooks, encyclopedias and clinical ref-
erence material as well as selected journals. This DT is
also used for the generation of candidates supplied to
annotators when creating the gold standard and there-
fore is the main resource to provide substitute candi-
dates.
</bodyText>
<subsectionHeader confidence="0.785664">
4.2 UMLS
</subsectionHeader>
<bodyText confidence="0.9999982">
The Unified Medical Language System (UMLS) is an
ontology for the medical domain. In contrast to Szarvas
et al. (2013), which uses WordNet (Miller, 1995) to
generate substitute candidates and also for generating
features, we use UMLS solely for feature generation.
</bodyText>
<subsectionHeader confidence="0.997025">
4.3 Google Web1T
</subsectionHeader>
<bodyText confidence="0.9994006">
We use the Google Web1T to generate n-gram features
as we expect this open domain resource to have consid-
erable coverage for most specific domains as well. For
accessing the resource, we use JWeb1T5 (Giuliano et
al., 2007).
</bodyText>
<footnote confidence="0.994866">
2We use a Java port of LIBLINEAR (http://www.
csie.ntu.edu.tw/˜cjlin/liblinear/) available
from http://liblinear.bwaldvogel.de/
3We use Lexicographer’s Mutual Information (LMI) (Ev-
ert, 2005) as significance measure and consider only the top
1000 (p = 1000) features per term.
4http://www.nlm.nih.gov/bsd/licensee/
2014_stats/baseline_med_filecount.html
5https://code.google.com/p/jweb1t/
</footnote>
<sectionHeader confidence="0.957621" genericHeader="method">
5 Lexical Substitution dataset
</sectionHeader>
<bodyText confidence="0.999967571428571">
Besides the lexical substitution data sets for the open
domain (McCarthy and Navigli, 2009; Biemann, 2012;
Kremer et al., 2014) there is no dataset available that
can be used for the medical domain. Therefore, we
constructed an annotation task for the medical domain
using a medical corpus and domain experts.
In order to provide the annotators with a clear task,
we presented a question, and a passage that contains
the correct answer to the question. We restricted this to
a subset of passages that were previously annotated as
justifying the answer to the question. This is related to
a textual entailment task, essentially the passage entails
the question with the answer substituted for the focus of
the question. We instructed the annotators to first iden-
tify the terms that were relevant for the entailment rela-
tion. For each relevant term we randomly extracted 10
terms from the ESG-based DT within the top 100 most
similar terms. Using this list of distributionally similar
terms, the annotators selected those terms that would
preserve the entailment relation if substituted. This re-
sulted in a dataset of 699 target terms with substitutes.
On average from the 10 terms 0.846 are annotated as
correct substitutes. Thus, the remaining terms can be
used as false substitute candidates.
The agreement on this task by Fleiss Kappa was
0.551 indicating “moderate agreement” (Landis and
Koch, 1977). On the metric of pairwise agreement,
as defined in the SemEval lexical substitution task, we
achieve 0.627. This number is not directly comparable
to the pairwise agreement score of 0.277 for the Se-
mEval lexical substitution task (McCarthy and Navigli,
2009) since in our task the candidates are given. How-
ever, it shows promise that subjectivity may be reduced
by casting lexical substitution into a task of maintain-
ing entailment.
</bodyText>
<sectionHeader confidence="0.999187" genericHeader="method">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999720714285714">
For the evaluation we use a ten-fold cross validation
and report P@1 (also called Average Precision (AP) at
1) and Mean Average Precision (MAP) (Buckley and
Voorhees, 2004) scores. The P@1 score indicates how
often the first substitute of the system matches the gold
standard. The MAP score is the mean of all AP from 1
to the number of all substitutes.
</bodyText>
<listItem confidence="0.976492">
• Google Web 1T:
</listItem>
<bodyText confidence="0.999987636363636">
We use the same Google n-gram features, as
used in Giuliano et al. (2007) and Szarvas et al.
(2013). These are frequencies of n-grams formed
by the substitute candidate si and the left and right
words, taken from the context sentence, normal-
ized by the frequency of the same context n-gram
with the target term t. Additionally, we add the
same features, normalized by the frequency sum
of all n-grams of the substitute candidates. An-
other feature is generated using the frequencies
where t and s are listed together using the words
</bodyText>
<page confidence="0.993787">
611
</page>
<bodyText confidence="0.99931975">
and, or and ”,” as separator and also add the left
and right words of that phrase as context. Then we
normalize this frequency by the frequency of the
context occurring only with t.
</bodyText>
<listItem confidence="0.989803">
• DT features:
</listItem>
<bodyText confidence="0.999119181818182">
To characterize if t and si have similar words
in common, and therefore are similar, we com-
pute the percentage of words their thesauri en-
tries share, considering the top n words in each
entry with n = 1, 5, 20, 50,100, 200. During
the DT calculation we also calculate the signif-
icances between each word and its context fea-
tures (see Section 4.1). Using this information,
we compute if the words in the sentences also
occur as context features for the substitute can-
didate. A third feature group relying on DTs
is created by the overlapping context features
for the top m entries of t and si with m =
1, 5, 20, 50,100,1000, which are ranked regard-
ing their significance score. Whereas, the simi-
larities between the trigram-based and the ESG-
based DT are similar, the context features are dif-
ferent. Both feature types can be applied to the
two DTs. Additionally, we extract the thesaurus
entry for the target word t and generate a feature
indicating whether the substitute si is within the
top k entries with k = 1, 5, 10, 20,100 entries6.
</bodyText>
<listItem confidence="0.989623">
• Part-of-speech n-grams:
</listItem>
<bodyText confidence="0.9996145">
To identify the context of the word we use the
POS-tag (only the first letter) of si and t as feature
and POS-tag combinations of up to three neigh-
boring words.
</bodyText>
<listItem confidence="0.991707">
• UMLS:
</listItem>
<bodyText confidence="0.999778">
Considering UMLS we look up all concept unique
identifiers (CUIs) for si and t. The first two fea-
tures are the number of CUIs for si and t. The next
features compute the number of CUIs that si and t
share, starting from the minimal to the maximum
number of CUIs. Additionally, we use a feature
indicating that si and t do not share any CUI.
</bodyText>
<subsectionHeader confidence="0.99905">
6.1 Substitute candidates
</subsectionHeader>
<bodyText confidence="0.999975">
The candidates for the substitution are taken from the
ESG based DT. For each target term we use the gold
substitute candidates as correct instances and add all
possible substitutes for the same target term occurring
in a different context and do not have been annotated
as valid in the present context as false instances.
</bodyText>
<sectionHeader confidence="0.999923" genericHeader="evaluation">
7 Results
</sectionHeader>
<bodyText confidence="0.9989845">
Running the experiment, we get the results as shown
in Table 1. As baseline system we use the ranking of
</bodyText>
<footnote confidence="0.650581666666667">
6Whereas in Szarvas et al. (2013) only k = 100 is used,
we gained an improvement in performance when also adding
smaller values of k.
</footnote>
<bodyText confidence="0.999797625">
the ESG-based DT. As can be seen, the baseline is al-
ready quite high, which can be attributed to the fact
that this resource was used to generate substitutes und
thus contains all positive instances. Using the super-
vised approach, we can beat the baseline by 0.10 for
the MAP score and by 0.176 for the P@1 score, which
is a significant improvement (p &lt; 0.0001, using a two
tailed permutation test). To get insights of the contri-
</bodyText>
<table confidence="0.999514285714286">
System MAP P@1
Baseline 0.6408 0.5365
ALL 0.7048 0.6366
w/o DT 0.5798 0.4835
w/o UMLS 0.6618 0.5651
w/o Ngrams 0.7009 0.6252
w/o POS 0.7027 0.6323
</table>
<tableCaption confidence="0.9306135">
Table 1: Results for the evaluation using substitute can-
didates from the DT.
</tableCaption>
<bodyText confidence="0.999343714285714">
bution of individual feature types, we perform an abla-
tion test. We observe that the most prominent features
are coming from the two DTs as we only achieve re-
sults below the baseline, when removing DT features.
We still obtain significant improvements over the base-
line when removing other feature groups. The second
most important feature comes from the UMLS. Fea-
tures coming from the Google n-grams improve the
system only slightly. The lowest improvement is de-
rived from the part-of-speech features. This leads us
to summarize that a hybrid approach for feature gen-
eration using manually created resources (UMLS) and
unsupervised features (DTs) leads to the best result for
lexical substitution for the medical domain.
</bodyText>
<sectionHeader confidence="0.953964" genericHeader="evaluation">
8 Analysis
</sectionHeader>
<bodyText confidence="0.994922333333333">
For a better insight into the lexical substitution we ana-
lyzed how often we outperform the baseline, get equal
results or get decreased scores. According to Table 2 in
</bodyText>
<table confidence="0.971706">
performance # of instances Avg. A MAP
decline 180 -0.16
equal 244 0
improvements 275 0.26
</table>
<tableCaption confidence="0.9591285">
Table 2: Error analysis for the task respectively to the
MAP score.
</tableCaption>
<bodyText confidence="0.972502538461538">
around 26% of the cases we observe a decreased MAP
score, which is on average 0.16 smaller then the scores
achieved with the baseline. On the other hand, we see
improvements in around 39% of the cases: an average
improvements of 0.26, which is much higher then the
loss. For the remaining 25% of cases we observe the
same score.
Looking inside the data, the largest error class is
caused by antonyms. A sub-class of this error are
multi-word expressions having an adjective modifier.
This problems might be solved by additional features
using the UMLS resource. An example is shown in
Figure 1.
</bodyText>
<page confidence="0.992288">
612
</page>
<figureCaption confidence="0.996413">
Figure 1: Example sentence for the target term mild
</figureCaption>
<bodyText confidence="0.9739961">
thrombocytopenia. The system returns a wrong rank-
ing, as the adjective changes the meaning and turns the
first ranked term into an antonym.
For feature generation, we currently lookup multi-
word expressions as one term, both in the DT and the
UMLS resource and do not split them into their sin-
gle tokens. This error also suggests considering the
single words inside the multi-word expression, espe-
cially adjectives, and looking them up in a resource
(e.g. UMLS) to detect synonymy and antonymy.
Figure 2 shows the case, where the ranking is per-
formed correctly, but the precise substitute is not an-
notated as a correct one. The term nail plate might be
even more precise in the context as the manual anno-
tated term nail bed. Due to the missing annotation the
Figure 2: Example sentence for the target term nails.
Here the ranking from the system is correct, but the first
substitute from the system was not annotated as such.
baseline gets better scores then the result from the sys-
tem.
</bodyText>
<sectionHeader confidence="0.997395" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999984727272727">
In summary, we have examined the lexical substitution
task for the medical domain and could show that a sys-
tem for open domain text data can be applied to the
medical domain. We can show that following a hybrid
approach using features from UMLS and distributional
semantics leads to the best results. In future work, we
will work on integrating DTs using other context fea-
tures, as we could see an impact of using two different
DTs. Furthermore, we want to incorporate features us-
ing n-grams computed on a corpus from the domain
and include co-occurrence features.
</bodyText>
<sectionHeader confidence="0.997396" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.994892333333333">
We thank Adam Lally, Eric Brown, Edward A. Epstein,
Chris Biemann and Faisal Chowdhury for their helpful
comments.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999528815789474">
Daniel B¨ar, Chris Biemann, Iryna Gurevych, and
Torsten Zesch. 2012. UKP: Computing Semantic
Textual Similarity by Combining Multiple Content
Similarity Measures. In Proceedings of the 6th In-
ternational Workshop on Semantic Evaluation, held
in conjunction with the 1st Joint Conference on Lex-
ical and Computational Semantics, pages 435–440,
Montreal, Canada.
Chris Biemann and Martin Riedl. 2013. Text: Now in
2D! A Framework for Lexical Expansion with Con-
textual Similarity. Journal of Language Modelling,
1(1):55–95.
Chris Biemann. 2012. Turk bootstrap word sense in-
ventory 2.0: A large-scale resource for lexical sub-
stitution. In Proceedings of the Eight International
Conference on Language Resources and Evaluation
(LREC’12), Istanbul, Turkey.
Thorsten Brants and Alex Franz. 2006. Web 1t 5-
gram corpus version 1. Technical report, Google Re-
search.
Chris Buckley and Ellen M. Voorhees. 2004. Re-
trieval evaluation with incomplete information. In
Proceedings of the 27th Annual International ACM
SIGIR Conference on Research and Development
in Information Retrieval, SIGIR ’04, pages 25–32,
Sheffield, United Kingdom.
Miranda Chong and Lucia Specia. 2011. Lexical gen-
eralisation for word-level matching in plagiarism de-
tection. In Recent Advances in Natural Language
Processing, pages 704–709, Hissar, Bulgaria.
Ido Dagan, Dan Roth, Mark Sammons, and Fabio M.
Zanzotto. 2013. Recognizing Textual Entailment:
Models and Applications. Synthesis Lectures on Hu-
man Language Technologies, 6(4):1–220.
Stefan Evert. 2005. The Statistics of Word Cooccur-
rences: Word Pairs and Collocations. Ph.D. thesis,
Institut f¨ur maschinelle Sprachverarbeitung, Univer-
sity of Stuttgart.
</reference>
<page confidence="0.988326">
613
</page>
<reference confidence="0.999691916666667">
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A
library for large linear classification. Journal of Ma-
chine Learning Research, 9:1871–1874.
Claudio Giuliano, Alfio Gliozzo, and Carlo Strappar-
ava. 2007. Fbk-irst: Lexical substitution task ex-
ploiting domain and syntagmatic coherence. In Pro-
ceedings of the 4th International Workshop on Se-
mantic Evaluations, SemEval ’07, pages 145–148,
Prague, Czech Republic.
Gerhard Kremer, Katrin Erk, Sebastian Pad´o, and Ste-
fan Thater. 2014. What Substitutes Tell Us - Anal-
ysis of an ”All-Words” Lexical Substitution Corpus.
In Proceedings of the 14th Conference of the Euro-
pean Chapter of the Association for Computational
Linguistics (EACL 2014), pages 540–549, Gothen-
burg, Sweden.
J. Richard Landis and Gary G. Koch. 1977. The mea-
surement of observer agreement for categorical data.
Biometrics, 33:159–174.
Diana McCarthy and Roberto Navigli. 2009. The En-
glish lexical substitution task. Language Resources
and Evaluation, 43(2):139–159.
Michael C. McCord, J. William Murdock, and Bran-
imir K. Boguraev. 2012. Deep Parsing in Watson.
IBM J. Res. Dev., 56(3):264–278.
George A. Miller. 1995. WordNet: A Lexical
Database for English. Communications of the ACM,
38:39–41.
Gy¨orgy Szarvas, Chris Biemann, and Iryna Gurevych.
2013. Supervised All-Words Lexical Substitution
using Delexicalized Features. In Proceedings of the
2013 Conference of the North American Chapter of
the Association for Computational Linguistics: Hu-
man Language Technologies (NAACL-HLT 2013),
pages 1131–1141, Atlanta, GA, USA.
</reference>
<page confidence="0.998156">
614
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.435691">
<title confidence="0.998906">Lexical Substitution for the Medical Domain</title>
<author confidence="0.999951">Michael R Alfio</author>
<affiliation confidence="0.821482">(1) FG Language Technology, CS Dept., TU Darmstadt, 64289 Darmstadt,</affiliation>
<address confidence="0.514206">(2) IBM T.J. Watson Research, Yorktown Heights, NY 10598,</address>
<abstract confidence="0.993088785714286">In this paper we examine the lexical substitution task for the medical domain. We adapt the current best system from the open domain, which trains a single classifier for all instances using delexicalized features. We show significant improvements over a strong baseline coming from a distributional thesaurus (DT). Whereas in the open domain system, features derived from WordNet show only slight improvements, we show that its counterpart for the medical domain (UMLS) shows a significant additional benefit when used for feature generation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Daniel B¨ar</author>
<author>Chris Biemann</author>
<author>Iryna Gurevych</author>
<author>Torsten Zesch</author>
</authors>
<title>UKP: Computing Semantic Textual Similarity by Combining Multiple Content Similarity Measures.</title>
<date>2012</date>
<booktitle>In Proceedings of the 6th International Workshop on Semantic Evaluation, held in conjunction with the 1st Joint Conference on Lexical and Computational Semantics,</booktitle>
<pages>435--440</pages>
<location>Montreal, Canada.</location>
<marker>B¨ar, Biemann, Gurevych, Zesch, 2012</marker>
<rawString>Daniel B¨ar, Chris Biemann, Iryna Gurevych, and Torsten Zesch. 2012. UKP: Computing Semantic Textual Similarity by Combining Multiple Content Similarity Measures. In Proceedings of the 6th International Workshop on Semantic Evaluation, held in conjunction with the 1st Joint Conference on Lexical and Computational Semantics, pages 435–440, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Biemann</author>
<author>Martin Riedl</author>
</authors>
<title>Text: Now in 2D! A Framework for Lexical Expansion with Contextual Similarity.</title>
<date>2013</date>
<journal>Journal of Language Modelling,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="5275" citStr="Biemann and Riedl (2013)" startWordPosition="832" endWordPosition="835">the algorithm to unseen substitute candidates and rank them according to their positive probabilities, given by the classifier. Contrary to Szarvas et al. (2013), we do not use any weighting in the training if a substitute has been supplied by many annotators, as we could not observe any improvements. Additionally, we use logistic regression (Fan et al., 2008) as classifier2. 4 Resources For the substitutes and for the generation of delexicalized features, we rely on DTs, the UMLS and Google Web1T. 4.1 Distributional thesauri (DTs) We computed two different DTs using the framework proposed in Biemann and Riedl (2013)3. The first DT is computed based on Medline4 abstracts. This thesaurus uses the left and the right word as context features. To include multi-word expressions, we allow the number of tokens that form a term to be up to the length of three. The second DT is based on dependencies as context features from a English Slot Grammar (ESG) parser (McCord et al., 2012) modified to handle medical data. The ESG parser is also capable of finding multi-word expressions. As input data we use 3.3 GB of texts from medical textbooks, encyclopedias and clinical reference material as well as selected journals. T</context>
</contexts>
<marker>Biemann, Riedl, 2013</marker>
<rawString>Chris Biemann and Martin Riedl. 2013. Text: Now in 2D! A Framework for Lexical Expansion with Contextual Similarity. Journal of Language Modelling, 1(1):55–95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Biemann</author>
</authors>
<title>Turk bootstrap word sense inventory 2.0: A large-scale resource for lexical substitution.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="1488" citStr="Biemann (2012)" startWordPosition="220" endWordPosition="221">ubstitution (McCarthy and Navigli, 2009) deals with the substitution of a target term within a sentence with words having the same meaning. Thus, the task divides into two subtasks: • Identification of substitution candidates, i.e. terms that are, for some contexts, substitutable for a given target term. • Ranking the substitution candidates according to their context Such a substitution system can help for semantic text similarity (B¨ar et al., 2012), textual entailment (Dagan et al., 2013) or plagiarism detection (Chong and Specia, 2011). Datasets provided by McCarthy and Navigli (2009) and Biemann (2012) offer manually annotated substitutes for a given set of target words within a context (sentence). Contrary to these two datasets in Kremer et al. (2014) a dataset is offered where all words have are annotated with substitutes. All the datasets are suited for the open domain. But a system performing lexical substitution is not only of interest for the open domain, but also for the medical domain. Such a system could then be applied to medical word sense disambiguation, entailment or question answering tasks. Here we introduce a new dataset and adapt the lexical substitution system, provided by</context>
<context position="7091" citStr="Biemann, 2012" startWordPosition="1110" endWordPosition="1111">fic domains as well. For accessing the resource, we use JWeb1T5 (Giuliano et al., 2007). 2We use a Java port of LIBLINEAR (http://www. csie.ntu.edu.tw/˜cjlin/liblinear/) available from http://liblinear.bwaldvogel.de/ 3We use Lexicographer’s Mutual Information (LMI) (Evert, 2005) as significance measure and consider only the top 1000 (p = 1000) features per term. 4http://www.nlm.nih.gov/bsd/licensee/ 2014_stats/baseline_med_filecount.html 5https://code.google.com/p/jweb1t/ 5 Lexical Substitution dataset Besides the lexical substitution data sets for the open domain (McCarthy and Navigli, 2009; Biemann, 2012; Kremer et al., 2014) there is no dataset available that can be used for the medical domain. Therefore, we constructed an annotation task for the medical domain using a medical corpus and domain experts. In order to provide the annotators with a clear task, we presented a question, and a passage that contains the correct answer to the question. We restricted this to a subset of passages that were previously annotated as justifying the answer to the question. This is related to a textual entailment task, essentially the passage entails the question with the answer substituted for the focus of </context>
</contexts>
<marker>Biemann, 2012</marker>
<rawString>Chris Biemann. 2012. Turk bootstrap word sense inventory 2.0: A large-scale resource for lexical substitution. In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
<author>Alex Franz</author>
</authors>
<title>Web 1t 5-gram corpus version 1.</title>
<date>2006</date>
<tech>Technical report, Google Research.</tech>
<contexts>
<context position="2632" citStr="Brants and Franz, 2006" startWordPosition="405" endWordPosition="408"> introduce a new dataset and adapt the lexical substitution system, provided by Szarvas et al. (2013), to the medical domain. Additionally, we do not make use of WordNet (Miller, 1995) to provide similar terms, but rather employ a Distributional Thesaurus (DT), computed on medical texts. 2 Related Work For the general domain, the lexical substitution task was initiated by a Semeval-2007 Task (McCarthy and Navigli, 2009). This task was won by an unsupervised method (Giuliano et al., 2007), which uses WordNet for the substitution candidate generation and then relies on the Google Web1T n-grams (Brants and Franz, 2006)1 to rank the substitutes. The currently best system, to our knowledge, is proposed by Szarvas et al. (2013). This is a supervised approach, where a single classifier is trained using delexicalized features for all substitutes and can thus be applied even to previously unseen substitutes. Although there have been many approaches for solving the task for the general domain, only slight effort has been done in adapting it to different domains. 3 Method To perform lexical substitution, we follow the delexicalization framework of Szarvas et al. (2013). We automatically build Distributional Thesaur</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>Thorsten Brants and Alex Franz. 2006. Web 1t 5-gram corpus version 1. Technical report, Google Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Buckley</author>
<author>Ellen M Voorhees</author>
</authors>
<title>Retrieval evaluation with incomplete information.</title>
<date>2004</date>
<booktitle>In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’04,</booktitle>
<pages>25--32</pages>
<location>Sheffield, United Kingdom.</location>
<contexts>
<context position="9008" citStr="Buckley and Voorhees, 2004" startWordPosition="1420" endWordPosition="1423">, 1977). On the metric of pairwise agreement, as defined in the SemEval lexical substitution task, we achieve 0.627. This number is not directly comparable to the pairwise agreement score of 0.277 for the SemEval lexical substitution task (McCarthy and Navigli, 2009) since in our task the candidates are given. However, it shows promise that subjectivity may be reduced by casting lexical substitution into a task of maintaining entailment. 6 Evaluation For the evaluation we use a ten-fold cross validation and report P@1 (also called Average Precision (AP) at 1) and Mean Average Precision (MAP) (Buckley and Voorhees, 2004) scores. The P@1 score indicates how often the first substitute of the system matches the gold standard. The MAP score is the mean of all AP from 1 to the number of all substitutes. • Google Web 1T: We use the same Google n-gram features, as used in Giuliano et al. (2007) and Szarvas et al. (2013). These are frequencies of n-grams formed by the substitute candidate si and the left and right words, taken from the context sentence, normalized by the frequency of the same context n-gram with the target term t. Additionally, we add the same features, normalized by the frequency sum of all n-grams </context>
</contexts>
<marker>Buckley, Voorhees, 2004</marker>
<rawString>Chris Buckley and Ellen M. Voorhees. 2004. Retrieval evaluation with incomplete information. In Proceedings of the 27th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’04, pages 25–32, Sheffield, United Kingdom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miranda Chong</author>
<author>Lucia Specia</author>
</authors>
<title>Lexical generalisation for word-level matching in plagiarism detection.</title>
<date>2011</date>
<booktitle>In Recent Advances in Natural Language Processing,</booktitle>
<pages>704--709</pages>
<location>Hissar, Bulgaria.</location>
<contexts>
<context position="1419" citStr="Chong and Specia, 2011" startWordPosition="208" endWordPosition="211">benefit when used for feature generation. 1 Introduction The task of lexical substitution (McCarthy and Navigli, 2009) deals with the substitution of a target term within a sentence with words having the same meaning. Thus, the task divides into two subtasks: • Identification of substitution candidates, i.e. terms that are, for some contexts, substitutable for a given target term. • Ranking the substitution candidates according to their context Such a substitution system can help for semantic text similarity (B¨ar et al., 2012), textual entailment (Dagan et al., 2013) or plagiarism detection (Chong and Specia, 2011). Datasets provided by McCarthy and Navigli (2009) and Biemann (2012) offer manually annotated substitutes for a given set of target words within a context (sentence). Contrary to these two datasets in Kremer et al. (2014) a dataset is offered where all words have are annotated with substitutes. All the datasets are suited for the open domain. But a system performing lexical substitution is not only of interest for the open domain, but also for the medical domain. Such a system could then be applied to medical word sense disambiguation, entailment or question answering tasks. Here we introduce</context>
</contexts>
<marker>Chong, Specia, 2011</marker>
<rawString>Miranda Chong and Lucia Specia. 2011. Lexical generalisation for word-level matching in plagiarism detection. In Recent Advances in Natural Language Processing, pages 704–709, Hissar, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ido Dagan</author>
<author>Dan Roth</author>
<author>Mark Sammons</author>
<author>Fabio M Zanzotto</author>
</authors>
<title>Recognizing Textual Entailment: Models and Applications. Synthesis Lectures on Human Language Technologies,</title>
<date>2013</date>
<pages>6--4</pages>
<contexts>
<context position="1370" citStr="Dagan et al., 2013" startWordPosition="201" endWordPosition="204">domain (UMLS) shows a significant additional benefit when used for feature generation. 1 Introduction The task of lexical substitution (McCarthy and Navigli, 2009) deals with the substitution of a target term within a sentence with words having the same meaning. Thus, the task divides into two subtasks: • Identification of substitution candidates, i.e. terms that are, for some contexts, substitutable for a given target term. • Ranking the substitution candidates according to their context Such a substitution system can help for semantic text similarity (B¨ar et al., 2012), textual entailment (Dagan et al., 2013) or plagiarism detection (Chong and Specia, 2011). Datasets provided by McCarthy and Navigli (2009) and Biemann (2012) offer manually annotated substitutes for a given set of target words within a context (sentence). Contrary to these two datasets in Kremer et al. (2014) a dataset is offered where all words have are annotated with substitutes. All the datasets are suited for the open domain. But a system performing lexical substitution is not only of interest for the open domain, but also for the medical domain. Such a system could then be applied to medical word sense disambiguation, entailme</context>
</contexts>
<marker>Dagan, Roth, Sammons, Zanzotto, 2013</marker>
<rawString>Ido Dagan, Dan Roth, Mark Sammons, and Fabio M. Zanzotto. 2013. Recognizing Textual Entailment: Models and Applications. Synthesis Lectures on Human Language Technologies, 6(4):1–220.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stefan Evert</author>
</authors>
<title>The Statistics of Word Cooccurrences: Word Pairs and Collocations.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>Institut f¨ur maschinelle Sprachverarbeitung, University of Stuttgart.</institution>
<contexts>
<context position="6757" citStr="Evert, 2005" startWordPosition="1071" endWordPosition="1073"> contrast to Szarvas et al. (2013), which uses WordNet (Miller, 1995) to generate substitute candidates and also for generating features, we use UMLS solely for feature generation. 4.3 Google Web1T We use the Google Web1T to generate n-gram features as we expect this open domain resource to have considerable coverage for most specific domains as well. For accessing the resource, we use JWeb1T5 (Giuliano et al., 2007). 2We use a Java port of LIBLINEAR (http://www. csie.ntu.edu.tw/˜cjlin/liblinear/) available from http://liblinear.bwaldvogel.de/ 3We use Lexicographer’s Mutual Information (LMI) (Evert, 2005) as significance measure and consider only the top 1000 (p = 1000) features per term. 4http://www.nlm.nih.gov/bsd/licensee/ 2014_stats/baseline_med_filecount.html 5https://code.google.com/p/jweb1t/ 5 Lexical Substitution dataset Besides the lexical substitution data sets for the open domain (McCarthy and Navigli, 2009; Biemann, 2012; Kremer et al., 2014) there is no dataset available that can be used for the medical domain. Therefore, we constructed an annotation task for the medical domain using a medical corpus and domain experts. In order to provide the annotators with a clear task, we pres</context>
</contexts>
<marker>Evert, 2005</marker>
<rawString>Stefan Evert. 2005. The Statistics of Word Cooccurrences: Word Pairs and Collocations. Ph.D. thesis, Institut f¨ur maschinelle Sprachverarbeitung, University of Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Liblinear: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="5013" citStr="Fan et al., 2008" startWordPosition="790" endWordPosition="793">essing (EMNLP), pages 610–614, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics relative to the target word, such as the ratio between frequencies of the substitute candidate and the target word. After training, we apply the algorithm to unseen substitute candidates and rank them according to their positive probabilities, given by the classifier. Contrary to Szarvas et al. (2013), we do not use any weighting in the training if a substitute has been supplied by many annotators, as we could not observe any improvements. Additionally, we use logistic regression (Fan et al., 2008) as classifier2. 4 Resources For the substitutes and for the generation of delexicalized features, we rely on DTs, the UMLS and Google Web1T. 4.1 Distributional thesauri (DTs) We computed two different DTs using the framework proposed in Biemann and Riedl (2013)3. The first DT is computed based on Medline4 abstracts. This thesaurus uses the left and the right word as context features. To include multi-word expressions, we allow the number of tokens that form a term to be up to the length of three. The second DT is based on dependencies as context features from a English Slot Grammar (ESG) pars</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claudio Giuliano</author>
<author>Alfio Gliozzo</author>
<author>Carlo Strapparava</author>
</authors>
<title>Fbk-irst: Lexical substitution task exploiting domain and syntagmatic coherence.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07,</booktitle>
<pages>145--148</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="2501" citStr="Giuliano et al., 2007" startWordPosition="385" endWordPosition="388"> domain. Such a system could then be applied to medical word sense disambiguation, entailment or question answering tasks. Here we introduce a new dataset and adapt the lexical substitution system, provided by Szarvas et al. (2013), to the medical domain. Additionally, we do not make use of WordNet (Miller, 1995) to provide similar terms, but rather employ a Distributional Thesaurus (DT), computed on medical texts. 2 Related Work For the general domain, the lexical substitution task was initiated by a Semeval-2007 Task (McCarthy and Navigli, 2009). This task was won by an unsupervised method (Giuliano et al., 2007), which uses WordNet for the substitution candidate generation and then relies on the Google Web1T n-grams (Brants and Franz, 2006)1 to rank the substitutes. The currently best system, to our knowledge, is proposed by Szarvas et al. (2013). This is a supervised approach, where a single classifier is trained using delexicalized features for all substitutes and can thus be applied even to previously unseen substitutes. Although there have been many approaches for solving the task for the general domain, only slight effort has been done in adapting it to different domains. 3 Method To perform lex</context>
<context position="6565" citStr="Giuliano et al., 2007" startWordPosition="1049" endWordPosition="1052">otators when creating the gold standard and therefore is the main resource to provide substitute candidates. 4.2 UMLS The Unified Medical Language System (UMLS) is an ontology for the medical domain. In contrast to Szarvas et al. (2013), which uses WordNet (Miller, 1995) to generate substitute candidates and also for generating features, we use UMLS solely for feature generation. 4.3 Google Web1T We use the Google Web1T to generate n-gram features as we expect this open domain resource to have considerable coverage for most specific domains as well. For accessing the resource, we use JWeb1T5 (Giuliano et al., 2007). 2We use a Java port of LIBLINEAR (http://www. csie.ntu.edu.tw/˜cjlin/liblinear/) available from http://liblinear.bwaldvogel.de/ 3We use Lexicographer’s Mutual Information (LMI) (Evert, 2005) as significance measure and consider only the top 1000 (p = 1000) features per term. 4http://www.nlm.nih.gov/bsd/licensee/ 2014_stats/baseline_med_filecount.html 5https://code.google.com/p/jweb1t/ 5 Lexical Substitution dataset Besides the lexical substitution data sets for the open domain (McCarthy and Navigli, 2009; Biemann, 2012; Kremer et al., 2014) there is no dataset available that can be used for </context>
<context position="9280" citStr="Giuliano et al. (2007)" startWordPosition="1472" endWordPosition="1475">our task the candidates are given. However, it shows promise that subjectivity may be reduced by casting lexical substitution into a task of maintaining entailment. 6 Evaluation For the evaluation we use a ten-fold cross validation and report P@1 (also called Average Precision (AP) at 1) and Mean Average Precision (MAP) (Buckley and Voorhees, 2004) scores. The P@1 score indicates how often the first substitute of the system matches the gold standard. The MAP score is the mean of all AP from 1 to the number of all substitutes. • Google Web 1T: We use the same Google n-gram features, as used in Giuliano et al. (2007) and Szarvas et al. (2013). These are frequencies of n-grams formed by the substitute candidate si and the left and right words, taken from the context sentence, normalized by the frequency of the same context n-gram with the target term t. Additionally, we add the same features, normalized by the frequency sum of all n-grams of the substitute candidates. Another feature is generated using the frequencies where t and s are listed together using the words 611 and, or and ”,” as separator and also add the left and right words of that phrase as context. Then we normalize this frequency by the fre</context>
</contexts>
<marker>Giuliano, Gliozzo, Strapparava, 2007</marker>
<rawString>Claudio Giuliano, Alfio Gliozzo, and Carlo Strapparava. 2007. Fbk-irst: Lexical substitution task exploiting domain and syntagmatic coherence. In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07, pages 145–148, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerhard Kremer</author>
<author>Katrin Erk</author>
<author>Sebastian Pad´o</author>
<author>Stefan Thater</author>
</authors>
<title>What Substitutes Tell Us - Analysis of an ”All-Words” Lexical Substitution Corpus.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014),</booktitle>
<pages>540--549</pages>
<location>Gothenburg,</location>
<marker>Kremer, Erk, Pad´o, Thater, 2014</marker>
<rawString>Gerhard Kremer, Katrin Erk, Sebastian Pad´o, and Stefan Thater. 2014. What Substitutes Tell Us - Analysis of an ”All-Words” Lexical Substitution Corpus. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2014), pages 540–549, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Richard Landis</author>
<author>Gary G Koch</author>
</authors>
<title>The measurement of observer agreement for categorical data.</title>
<date>1977</date>
<journal>Biometrics,</journal>
<pages>33--159</pages>
<contexts>
<context position="8388" citStr="Landis and Koch, 1977" startWordPosition="1320" endWordPosition="1323"> were relevant for the entailment relation. For each relevant term we randomly extracted 10 terms from the ESG-based DT within the top 100 most similar terms. Using this list of distributionally similar terms, the annotators selected those terms that would preserve the entailment relation if substituted. This resulted in a dataset of 699 target terms with substitutes. On average from the 10 terms 0.846 are annotated as correct substitutes. Thus, the remaining terms can be used as false substitute candidates. The agreement on this task by Fleiss Kappa was 0.551 indicating “moderate agreement” (Landis and Koch, 1977). On the metric of pairwise agreement, as defined in the SemEval lexical substitution task, we achieve 0.627. This number is not directly comparable to the pairwise agreement score of 0.277 for the SemEval lexical substitution task (McCarthy and Navigli, 2009) since in our task the candidates are given. However, it shows promise that subjectivity may be reduced by casting lexical substitution into a task of maintaining entailment. 6 Evaluation For the evaluation we use a ten-fold cross validation and report P@1 (also called Average Precision (AP) at 1) and Mean Average Precision (MAP) (Buckley</context>
</contexts>
<marker>Landis, Koch, 1977</marker>
<rawString>J. Richard Landis and Gary G. Koch. 1977. The measurement of observer agreement for categorical data. Biometrics, 33:159–174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Roberto Navigli</author>
</authors>
<title>The English lexical substitution task.</title>
<date>2009</date>
<journal>Language Resources and Evaluation,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="914" citStr="McCarthy and Navigli, 2009" startWordPosition="130" endWordPosition="133">stract In this paper we examine the lexical substitution task for the medical domain. We adapt the current best system from the open domain, which trains a single classifier for all instances using delexicalized features. We show significant improvements over a strong baseline coming from a distributional thesaurus (DT). Whereas in the open domain system, features derived from WordNet show only slight improvements, we show that its counterpart for the medical domain (UMLS) shows a significant additional benefit when used for feature generation. 1 Introduction The task of lexical substitution (McCarthy and Navigli, 2009) deals with the substitution of a target term within a sentence with words having the same meaning. Thus, the task divides into two subtasks: • Identification of substitution candidates, i.e. terms that are, for some contexts, substitutable for a given target term. • Ranking the substitution candidates according to their context Such a substitution system can help for semantic text similarity (B¨ar et al., 2012), textual entailment (Dagan et al., 2013) or plagiarism detection (Chong and Specia, 2011). Datasets provided by McCarthy and Navigli (2009) and Biemann (2012) offer manually annotated </context>
<context position="2432" citStr="McCarthy and Navigli, 2009" startWordPosition="373" endWordPosition="376">tion is not only of interest for the open domain, but also for the medical domain. Such a system could then be applied to medical word sense disambiguation, entailment or question answering tasks. Here we introduce a new dataset and adapt the lexical substitution system, provided by Szarvas et al. (2013), to the medical domain. Additionally, we do not make use of WordNet (Miller, 1995) to provide similar terms, but rather employ a Distributional Thesaurus (DT), computed on medical texts. 2 Related Work For the general domain, the lexical substitution task was initiated by a Semeval-2007 Task (McCarthy and Navigli, 2009). This task was won by an unsupervised method (Giuliano et al., 2007), which uses WordNet for the substitution candidate generation and then relies on the Google Web1T n-grams (Brants and Franz, 2006)1 to rank the substitutes. The currently best system, to our knowledge, is proposed by Szarvas et al. (2013). This is a supervised approach, where a single classifier is trained using delexicalized features for all substitutes and can thus be applied even to previously unseen substitutes. Although there have been many approaches for solving the task for the general domain, only slight effort has b</context>
<context position="7076" citStr="McCarthy and Navigli, 2009" startWordPosition="1106" endWordPosition="1109">able coverage for most specific domains as well. For accessing the resource, we use JWeb1T5 (Giuliano et al., 2007). 2We use a Java port of LIBLINEAR (http://www. csie.ntu.edu.tw/˜cjlin/liblinear/) available from http://liblinear.bwaldvogel.de/ 3We use Lexicographer’s Mutual Information (LMI) (Evert, 2005) as significance measure and consider only the top 1000 (p = 1000) features per term. 4http://www.nlm.nih.gov/bsd/licensee/ 2014_stats/baseline_med_filecount.html 5https://code.google.com/p/jweb1t/ 5 Lexical Substitution dataset Besides the lexical substitution data sets for the open domain (McCarthy and Navigli, 2009; Biemann, 2012; Kremer et al., 2014) there is no dataset available that can be used for the medical domain. Therefore, we constructed an annotation task for the medical domain using a medical corpus and domain experts. In order to provide the annotators with a clear task, we presented a question, and a passage that contains the correct answer to the question. We restricted this to a subset of passages that were previously annotated as justifying the answer to the question. This is related to a textual entailment task, essentially the passage entails the question with the answer substituted fo</context>
<context position="8648" citStr="McCarthy and Navigli, 2009" startWordPosition="1361" endWordPosition="1364">d preserve the entailment relation if substituted. This resulted in a dataset of 699 target terms with substitutes. On average from the 10 terms 0.846 are annotated as correct substitutes. Thus, the remaining terms can be used as false substitute candidates. The agreement on this task by Fleiss Kappa was 0.551 indicating “moderate agreement” (Landis and Koch, 1977). On the metric of pairwise agreement, as defined in the SemEval lexical substitution task, we achieve 0.627. This number is not directly comparable to the pairwise agreement score of 0.277 for the SemEval lexical substitution task (McCarthy and Navigli, 2009) since in our task the candidates are given. However, it shows promise that subjectivity may be reduced by casting lexical substitution into a task of maintaining entailment. 6 Evaluation For the evaluation we use a ten-fold cross validation and report P@1 (also called Average Precision (AP) at 1) and Mean Average Precision (MAP) (Buckley and Voorhees, 2004) scores. The P@1 score indicates how often the first substitute of the system matches the gold standard. The MAP score is the mean of all AP from 1 to the number of all substitutes. • Google Web 1T: We use the same Google n-gram features, a</context>
</contexts>
<marker>McCarthy, Navigli, 2009</marker>
<rawString>Diana McCarthy and Roberto Navigli. 2009. The English lexical substitution task. Language Resources and Evaluation, 43(2):139–159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael C McCord</author>
<author>J William Murdock</author>
<author>Branimir K Boguraev</author>
</authors>
<title>Deep Parsing in Watson.</title>
<date>2012</date>
<journal>IBM J. Res. Dev.,</journal>
<volume>56</volume>
<issue>3</issue>
<contexts>
<context position="5637" citStr="McCord et al., 2012" startWordPosition="897" endWordPosition="900">classifier2. 4 Resources For the substitutes and for the generation of delexicalized features, we rely on DTs, the UMLS and Google Web1T. 4.1 Distributional thesauri (DTs) We computed two different DTs using the framework proposed in Biemann and Riedl (2013)3. The first DT is computed based on Medline4 abstracts. This thesaurus uses the left and the right word as context features. To include multi-word expressions, we allow the number of tokens that form a term to be up to the length of three. The second DT is based on dependencies as context features from a English Slot Grammar (ESG) parser (McCord et al., 2012) modified to handle medical data. The ESG parser is also capable of finding multi-word expressions. As input data we use 3.3 GB of texts from medical textbooks, encyclopedias and clinical reference material as well as selected journals. This DT is also used for the generation of candidates supplied to annotators when creating the gold standard and therefore is the main resource to provide substitute candidates. 4.2 UMLS The Unified Medical Language System (UMLS) is an ontology for the medical domain. In contrast to Szarvas et al. (2013), which uses WordNet (Miller, 1995) to generate substitute</context>
</contexts>
<marker>McCord, Murdock, Boguraev, 2012</marker>
<rawString>Michael C. McCord, J. William Murdock, and Branimir K. Boguraev. 2012. Deep Parsing in Watson. IBM J. Res. Dev., 56(3):264–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>WordNet: A Lexical Database for English.</title>
<date>1995</date>
<journal>Communications of the ACM,</journal>
<pages>38--39</pages>
<contexts>
<context position="2193" citStr="Miller, 1995" startWordPosition="338" endWordPosition="339">ence). Contrary to these two datasets in Kremer et al. (2014) a dataset is offered where all words have are annotated with substitutes. All the datasets are suited for the open domain. But a system performing lexical substitution is not only of interest for the open domain, but also for the medical domain. Such a system could then be applied to medical word sense disambiguation, entailment or question answering tasks. Here we introduce a new dataset and adapt the lexical substitution system, provided by Szarvas et al. (2013), to the medical domain. Additionally, we do not make use of WordNet (Miller, 1995) to provide similar terms, but rather employ a Distributional Thesaurus (DT), computed on medical texts. 2 Related Work For the general domain, the lexical substitution task was initiated by a Semeval-2007 Task (McCarthy and Navigli, 2009). This task was won by an unsupervised method (Giuliano et al., 2007), which uses WordNet for the substitution candidate generation and then relies on the Google Web1T n-grams (Brants and Franz, 2006)1 to rank the substitutes. The currently best system, to our knowledge, is proposed by Szarvas et al. (2013). This is a supervised approach, where a single class</context>
<context position="6214" citStr="Miller, 1995" startWordPosition="994" endWordPosition="995">r (ESG) parser (McCord et al., 2012) modified to handle medical data. The ESG parser is also capable of finding multi-word expressions. As input data we use 3.3 GB of texts from medical textbooks, encyclopedias and clinical reference material as well as selected journals. This DT is also used for the generation of candidates supplied to annotators when creating the gold standard and therefore is the main resource to provide substitute candidates. 4.2 UMLS The Unified Medical Language System (UMLS) is an ontology for the medical domain. In contrast to Szarvas et al. (2013), which uses WordNet (Miller, 1995) to generate substitute candidates and also for generating features, we use UMLS solely for feature generation. 4.3 Google Web1T We use the Google Web1T to generate n-gram features as we expect this open domain resource to have considerable coverage for most specific domains as well. For accessing the resource, we use JWeb1T5 (Giuliano et al., 2007). 2We use a Java port of LIBLINEAR (http://www. csie.ntu.edu.tw/˜cjlin/liblinear/) available from http://liblinear.bwaldvogel.de/ 3We use Lexicographer’s Mutual Information (LMI) (Evert, 2005) as significance measure and consider only the top 1000 (</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. WordNet: A Lexical Database for English. Communications of the ACM, 38:39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gy¨orgy Szarvas</author>
<author>Chris Biemann</author>
<author>Iryna Gurevych</author>
</authors>
<title>Supervised All-Words Lexical Substitution using Delexicalized Features.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT</booktitle>
<pages>1131--1141</pages>
<location>Atlanta, GA, USA.</location>
<contexts>
<context position="2110" citStr="Szarvas et al. (2013)" startWordPosition="322" endWordPosition="325">offer manually annotated substitutes for a given set of target words within a context (sentence). Contrary to these two datasets in Kremer et al. (2014) a dataset is offered where all words have are annotated with substitutes. All the datasets are suited for the open domain. But a system performing lexical substitution is not only of interest for the open domain, but also for the medical domain. Such a system could then be applied to medical word sense disambiguation, entailment or question answering tasks. Here we introduce a new dataset and adapt the lexical substitution system, provided by Szarvas et al. (2013), to the medical domain. Additionally, we do not make use of WordNet (Miller, 1995) to provide similar terms, but rather employ a Distributional Thesaurus (DT), computed on medical texts. 2 Related Work For the general domain, the lexical substitution task was initiated by a Semeval-2007 Task (McCarthy and Navigli, 2009). This task was won by an unsupervised method (Giuliano et al., 2007), which uses WordNet for the substitution candidate generation and then relies on the Google Web1T n-grams (Brants and Franz, 2006)1 to rank the substitutes. The currently best system, to our knowledge, is pro</context>
<context position="4000" citStr="Szarvas et al., 2013" startWordPosition="634" endWordPosition="637">tution consists of sentences, containing an annotated target word t. Considering the sentence being the context for the target word, the target word might have different meanings. Thus annotated substitute candidates sg1 ... sgn E sg, need to be provided for each context. The negative examples are substitute candidates that either are incorrect for the target word, do not fit into the context or both. We will refer to these substitutes as false substitute candidates sf1 ... sfm E sf with sf n sg = ∅. For the generation of substitute candidates we do not use WordNet, as done in previous works (Szarvas et al., 2013), but use only substitutes from a DT. To train a single classifier, features that distinguishing the meaning of words in different context need to be considered. Such features could be e.g. n-grams, features from distributional semantics or features which are extracted 1http://catalog.ldc.upenn.edu/ LDC2006T13 610 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 610–614, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics relative to the target word, such as the ratio between frequencies of the substitute candi</context>
<context position="6179" citStr="Szarvas et al. (2013)" startWordPosition="987" endWordPosition="990">context features from a English Slot Grammar (ESG) parser (McCord et al., 2012) modified to handle medical data. The ESG parser is also capable of finding multi-word expressions. As input data we use 3.3 GB of texts from medical textbooks, encyclopedias and clinical reference material as well as selected journals. This DT is also used for the generation of candidates supplied to annotators when creating the gold standard and therefore is the main resource to provide substitute candidates. 4.2 UMLS The Unified Medical Language System (UMLS) is an ontology for the medical domain. In contrast to Szarvas et al. (2013), which uses WordNet (Miller, 1995) to generate substitute candidates and also for generating features, we use UMLS solely for feature generation. 4.3 Google Web1T We use the Google Web1T to generate n-gram features as we expect this open domain resource to have considerable coverage for most specific domains as well. For accessing the resource, we use JWeb1T5 (Giuliano et al., 2007). 2We use a Java port of LIBLINEAR (http://www. csie.ntu.edu.tw/˜cjlin/liblinear/) available from http://liblinear.bwaldvogel.de/ 3We use Lexicographer’s Mutual Information (LMI) (Evert, 2005) as significance measu</context>
<context position="9306" citStr="Szarvas et al. (2013)" startWordPosition="1477" endWordPosition="1480"> given. However, it shows promise that subjectivity may be reduced by casting lexical substitution into a task of maintaining entailment. 6 Evaluation For the evaluation we use a ten-fold cross validation and report P@1 (also called Average Precision (AP) at 1) and Mean Average Precision (MAP) (Buckley and Voorhees, 2004) scores. The P@1 score indicates how often the first substitute of the system matches the gold standard. The MAP score is the mean of all AP from 1 to the number of all substitutes. • Google Web 1T: We use the same Google n-gram features, as used in Giuliano et al. (2007) and Szarvas et al. (2013). These are frequencies of n-grams formed by the substitute candidate si and the left and right words, taken from the context sentence, normalized by the frequency of the same context n-gram with the target term t. Additionally, we add the same features, normalized by the frequency sum of all n-grams of the substitute candidates. Another feature is generated using the frequencies where t and s are listed together using the words 611 and, or and ”,” as separator and also add the left and right words of that phrase as context. Then we normalize this frequency by the frequency of the context occu</context>
<context position="12012" citStr="Szarvas et al. (2013)" startWordPosition="1963" endWordPosition="1966">om the minimal to the maximum number of CUIs. Additionally, we use a feature indicating that si and t do not share any CUI. 6.1 Substitute candidates The candidates for the substitution are taken from the ESG based DT. For each target term we use the gold substitute candidates as correct instances and add all possible substitutes for the same target term occurring in a different context and do not have been annotated as valid in the present context as false instances. 7 Results Running the experiment, we get the results as shown in Table 1. As baseline system we use the ranking of 6Whereas in Szarvas et al. (2013) only k = 100 is used, we gained an improvement in performance when also adding smaller values of k. the ESG-based DT. As can be seen, the baseline is already quite high, which can be attributed to the fact that this resource was used to generate substitutes und thus contains all positive instances. Using the supervised approach, we can beat the baseline by 0.10 for the MAP score and by 0.176 for the P@1 score, which is a significant improvement (p &lt; 0.0001, using a two tailed permutation test). To get insights of the contriSystem MAP P@1 Baseline 0.6408 0.5365 ALL 0.7048 0.6366 w/o DT 0.5798 </context>
</contexts>
<marker>Szarvas, Biemann, Gurevych, 2013</marker>
<rawString>Gy¨orgy Szarvas, Chris Biemann, and Iryna Gurevych. 2013. Supervised All-Words Lexical Substitution using Delexicalized Features. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT 2013), pages 1131–1141, Atlanta, GA, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>