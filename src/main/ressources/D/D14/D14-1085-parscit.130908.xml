<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000016">
<title confidence="0.996236">
Unsupervised Sentence Enhancement for Automatic Summarization
</title>
<author confidence="0.999549">
Jackie Chi Kit Cheung
</author>
<affiliation confidence="0.999436">
University of Toronto
</affiliation>
<address confidence="0.9964845">
10 King’s College Rd., Room 3302
Toronto, ON, Canada M5S 3G4
</address>
<email confidence="0.999598">
jcheung@cs.toronto.edu
</email>
<author confidence="0.995117">
Gerald Penn
</author>
<affiliation confidence="0.998775">
University of Toronto
</affiliation>
<address confidence="0.9964735">
10 King’s College Rd., Room 3302
Toronto, ON, Canada M5S 3G4
</address>
<email confidence="0.99965">
gpenn@cs.toronto.edu
</email>
<sectionHeader confidence="0.993917" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999825">
We present sentence enhancement as a
novel technique for text-to-text genera-
tion in abstractive summarization. Com-
pared to extraction or previous approaches
to sentence fusion, sentence enhancement
increases the range of possible summary
sentences by allowing the combination of
dependency subtrees from any sentence
from the source text. Our experiments in-
dicate that our approach yields summary
sentences that are competitive with a sen-
tence fusion baseline in terms of con-
tent quality, but better in terms of gram-
maticality, and that the benefit of sen-
tence enhancement relies crucially on an
event coreference resolution algorithm us-
ing distributional semantics. We also
consider how text-to-text generation ap-
proaches to summarization can be ex-
tended beyond the source text by exam-
ining how human summary writers incor-
porate source-text-external elements into
their summary sentences.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.92540845">
Sentence fusion is the technique of merging sev-
eral input sentences into one output sentence
while retaining the important content (Barzilay
and McKeown, 2005; Filippova and Strube, 2008;
Thadani and McKeown, 2013). For example, the
input sentences in Figure 1 may be fused into one
output sentence.
As a text-to-text generation technique, sentence
fusion is attractive because it provides an avenue
for moving beyond sentence extraction in auto-
matic summarization, while not requiring deep se-
Input: Bil Mar Foods Co., a meat processor
owned by Sara Lee, announced a recall of
certain lots of hot dogs and packaged meat.
Input: The outbreak led to the recall on Tues-
day of 15 million pounds of hot dogs and cold
cuts produced at the Bil Mar Foods plant.
Output: The outbreak led to the recall on Tues-
day of lots of hot dogs and packaged meats
produced at the Bil Mar Foods plant.
</bodyText>
<figureCaption confidence="0.886171">
Figure 1: An example of fusing two input sen-
</figureCaption>
<bodyText confidence="0.973338166666667">
tences into an output sentence. The sections of the
input sentences that are retained in the output are
shown in bold.
mantic analysis beyond, say, a dependency parser
and lexical semantic resources.
The overall trajectory pursued in the field can
be characterized as a move away from local con-
texts relying heavily on the original source text to-
wards more global contexts involving reformula-
tion of the text. Whereas sentence extraction and
sentence compression (Knight and Marcu, 2000,
for example) involve taking one sentence and per-
haps removing parts of it, traditional sentence fu-
sion involves reformulating a small number of rel-
atively similar sentences in order to take the union
or intersection of the information present therein.
In this paper, we move further along this path
in the following ways. First, we present sen-
tence enhancement as a novel technique which
extends sentence fusion by combining the subtrees
of many sentences into the output sentence, rather
than just a few. Doing so allows relevant informa-
tion from sentences that are not similar to the orig-
inal input sentences to be added during fusion. As
</bodyText>
<page confidence="0.975922">
775
</page>
<note confidence="0.770291333333333">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 775–786,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
Source text: This fact has been underscored in
the last few months by two unexpected out-
breaks offood-borne illness.
Output: The outbreak of food-borne illness led
to the recall on Tuesday of lots of hot dogs
and meats produced at the Bil Mar Foods
plant.
</note>
<figureCaption confidence="0.857806">
Figure 2: An example of sentence enhancement,
</figureCaption>
<bodyText confidence="0.983629477272727">
in which parts of dissimilar sentences are incorpo-
rated into the output sentence.
shown in Figure 2, the phrase offood-borne illness
can be added to the previous output sentence, de-
spite originating in a source text sentence that is
quite different overall.
Elsner and Santhanam (2011) proposed a super-
vised method to fuse disparate sentences, which
takes as input a small number of sentences with
compatible information that have been manually
identified by editors of articles. By contrast, our
algorithm is unsupervised, and tackles the prob-
lem of identifying compatible event mergers in the
entire source text using an event coreference mod-
ule. Our method outperforms a previous syntax-
based sentence fusion baseline on measures of
summary content quality and grammaticality.
Second, we analyze how text-to-text genera-
tion systems may make use of text that is not in
the source text itself, but in articles on a related
topic in the same domain. By examining the parts
of human-written summaries that are not found
in the source text, we find that using in-domain
text allows summary writers to more precisely ex-
press some target semantic content, but that more
sophisticated computational semantic techniques
will be required to enable automatic systems to
likewise do so.
A more general argument of this paper is that
the apparent dichotomy between text-to-text gen-
eration and semantics-to-text generation can be
resolved by viewing them simply as having dif-
ferent starting points towards the same end goal
of precise and wide-coverage NLG. The statisti-
cal generation techniques developed by the text-
to-text generation community have been success-
ful in many domains. Yet the results of our ex-
periments and studies demonstrate the following:
as text-to-text generation techniques move beyond
using local contexts towards more dramatic refor-
mulations of the kind that human writers perform,
more semantic analysis will be needed in order to
ensure that the reformulations preserve the infer-
ences that can be drawn from the input text.
</bodyText>
<sectionHeader confidence="0.999297" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999920766666667">
A relatively large body of work exists in sentence
compression (Knight and Marcu, 2000; McDon-
ald, 2006; Galley and McKeown, 2007; Cohn
and Lapata, 2008; Clarke and Lapata, 2008, in-
ter alia), and sentence fusion (Barzilay and McK-
eown, 2005; Marsi and Krahmer, 2005; Filippova
and Strube, 2008; Filippova, 2010; Thadani and
McKeown, 2013). Unlike this work, our sentence
enhancement algorithm considers the entire source
text and is not limited to the initial input sentences.
Few previous papers focus on combining the con-
tent of diverse sentences into one output sentence.
Wan et al. (2008) propose sentence augmentation
by identifying “seed” words in a single original
sentence, then adding information from auxiliary
sentences based on word co-occurrence counts.
Elsner and Santhanam (2011) investigate the idea
of fusing disparate sentences with a supervised al-
gorithm, as discussed above.
Previous studies on cut-and-paste summariza-
tion (Jing and McKeown, 2000; Saggion and La-
palme, 2002) investigate the operations that hu-
man summarizers perform on the source text in
order to produce the summary text. Our previ-
ous work argued that current extractive systems
rely too heavily on notions of information central-
ity (Cheung and Penn, 2013). This paper extends
this work by identifying specific linguistic factors
correlated with the use of source-text-external ele-
ments.
</bodyText>
<sectionHeader confidence="0.99454" genericHeader="method">
3 A Sentence Enhancement Algorithm
</sectionHeader>
<bodyText confidence="0.999853">
The basic steps in our sentence expansion algo-
rithm are as follows: (1) clustering to identify ini-
tial input sentences, (2) sentence graph creation,
(3) sentence graph expansion, (4) tree generation,
and (5) linearization.
At a high level, our method for sentence en-
hancement is inspired by the syntactic sentence
fusion approach of Filippova and Strube (2008)
(henceforth, F&amp;S) originally developed for Ger-
man, in that it operates over the dependency parses
of a small number of input sentences to produce
an output sentence which fuses parts of the in-
</bodyText>
<page confidence="0.978196">
776
</page>
<bodyText confidence="0.986650724137931">
prep_of
put sentences. We adopt the same assumption as
F&amp;S that these initial core sentences have a high
degree of similarity with each other, and should
form the core of a new sentence to be generated
(Step 1). While fusion from highly disparate in-
put sentences is possible, Elsner and Santhanam
(2011) showed how difficult it is to do so cor-
rectly, even where such cases are manually iden-
tified. We thus aim for a more targeted type of
fusion initially. Next, the dependency trees of
the core sentences are fused into an intermediate
sentence graph (Step 2), a directed acyclic graph
from which the final sentence will be generated
(Steps 4 and 5). We will compare against our im-
plementation of F&amp;S, adapted to English.
However, unlike F&amp;S or other previous ap-
proaches to sentence fusion, the sentence enhance-
ment algorithm may also avail itself of the de-
pendency parses of all of the other sentences in
the source text, which expands the range of pos-
sible sentences that may be produced. This is ac-
complished by expanding the sentence graph with
parts of these sentences (Step 3). One important
issue here is that the expansion must be modulated
by an event coreference component to ensure that
the merging of information from different points
in the source text is valid and does not result in
incorrect or nonsensical inferences.
</bodyText>
<subsectionHeader confidence="0.999642">
3.1 Core sentence identification
</subsectionHeader>
<bodyText confidence="0.999755428571429">
To generate the core sentence clusters, we first
identify clusters of similar sentences, then rank the
clusters according to their salience. The top clus-
ter in the source text is then selected to be the input
to the sentence fusion algorithms.
Sentence alignment is performed by complete-
link agglomerative clustering, which requires a
measure of similarity between sentences and a
stopping criterion. We define the similarity be-
tween two sentences to be the standard cosine
similarity between the lemmata of the sentences,
weighted by IDF and excluding stopwords, and
clustering is run until a similarity threshold of
0.5 is reached. Since complete-link clustering
prefers small coherent clusters and we select the
top-scoring cluster in each document collection,
the method is somewhat robust to different choices
of the stopping threshold.
The clusters are scored according to the signa-
ture term method of Lin and Hovy (2000), which
assigns an importance score to each term accord-
</bodyText>
<figure confidence="0.795905">
BMFoods announce recall certain lots...
nsubj dobj
outbreak led recall Tuesday 15M pounds...
(a) Abbreviated dependency trees.
food-borne illness
(b) Sentence graph after merging the nodes with lemma recall
(in bold), and expanding the node outbreak (dashed outgoing
edge).
</figure>
<figureCaption confidence="0.929658666666667">
Figure 3: An example of the input dependency
trees for sentence graph creation and expansion,
using the input sentences of Figure 1.
</figureCaption>
<bodyText confidence="0.999615833333333">
ing to how much more often it appears in the
source text compared to some irrelevant back-
ground text using a log likelihood ratio. Specifi-
cally, the score of a cluster is equal to the sum of
the importance scores of the set of lemmata in the
cluster.
</bodyText>
<subsectionHeader confidence="0.99991">
3.2 Sentence graph creation
</subsectionHeader>
<bodyText confidence="0.999962">
After core sentence identification, the next step
is to align the nodes of the dependency trees of
the core input sentences in order to create the ini-
tial sentence graph. The input to this step is the
collapsed dependency tree representations of the
core sentences produced by the Stanford parser1.
In this representation, preposition nodes are col-
lapsed into the label of the dependency edge be-
tween the functor of the prepositional phrase and
the prepositional object. Chains of conjuncts are
also split, and each argument is attached to the
parent. In addition, auxiliary verbs, negation par-
ticles, and noun-phrase-internal elements2 are col-
lapsed into their parent nodes. Figure 3a shows
the abbreviated dependency representations of the
input sentences from Figure 1.
Then, a sentence graph is created by merging
nodes that share a common lemma and part-of-
</bodyText>
<footnote confidence="0.999616">
1As part of the CoreNLP suite: http://nlp.
stanford.edu/software/corenlp.shtml
2As indicated by the dependency edge label nn.
</footnote>
<figure confidence="0.996313846153846">
nsubj dobj
prep_of
BMFoods announce certain lots...
prep_on
nsubj
prep_of
recall
outbreak led Tuesday 15M pounds...
dobj
prep_of
nsubj dobj
prep_on
prep_of
</figure>
<page confidence="0.980256">
777
</page>
<bodyText confidence="0.999888555555555">
speech tag. In addition, we allow synonyms to
be merged, defined as being in the same Word-
Net synset. Merging is blocked if the word is a
stop word, which includes function words as well
as a number of very common verbs (e.g., be, have,
do). Throughout the sentence graph creation and
expansion process, the algorithm disallows the ad-
dition of edges that would result in a cycle in the
graph.
</bodyText>
<subsectionHeader confidence="0.999886">
3.3 Sentence graph expansion
</subsectionHeader>
<bodyText confidence="0.99998844">
The initial sentence graph is expanded by merg-
ing in subtrees from dependency parses of non-
core sentences drawn from the source text. First,
expansion candidates are identified for each node
in the sentence graph by finding all of the depen-
dency edges in the source text from non-core sen-
tences in which the governor of the edge shares
the same lemma and POS tag as the node in the
sentence graph.
Then, these candidate edges are pruned accord-
ing to two heuristics. The first is to keep only one
candidate edge of each dependency relation type
according to the edge that has the highest informa-
tiveness score (Section 3.4.1), with ties being bro-
ken according to which edge has a subtree with a
fewer number of nodes. The second is to perform
event coreference in order to prune away those
candidate edges which are unlikely to be describ-
ing the same event as the core sentences, as ex-
plained in the next section. Finally, any remaining
candidate edges are fused into the sentence graph,
and the subtree rooted at the dependent of the can-
didate edge is added to the sentence graph as well.
See Figure 3b for an example of sentence graph
creation and expansion.
</bodyText>
<subsectionHeader confidence="0.962408">
3.3.1 Event coreference
</subsectionHeader>
<bodyText confidence="0.9942276">
One problem of sentence fusion is that the differ-
ent inputs of the fusion may not refer to the same
event, resulting in an incorrect merging of infor-
mation, as would be the case in the following ex-
ample:
</bodyText>
<listItem confidence="0.84534175">
S1: Officers pled not guilty but risked 25 years to
life.
S2: Officers recklessly engaged in conduct which
seriously risked the lives of others.
</listItem>
<bodyText confidence="0.99996575">
Here, the first usage of risk refers to the potential
sentence imposed if the officers are convicted in
a trial, whereas the second refers to the potential
harm caused by the officer.
</bodyText>
<equation confidence="0.885565875">
Context 1: Officers ... risked 25 years to life...
(nsubj, officers) (dobj, life)
sim1((risk, dobj), (risk, dobj))
X sim2(life, life) = 1.0
sim1((risk, nsubj), (risk, nsubj))
X sim2(officer, conduct) = 0.38
(nsubj, conduct) (advmod, seriously) (dobj, life)
Context 2:...conduct seriously risked the lives...
</equation>
<figureCaption confidence="0.992005666666667">
Figure 4: Event coreference resolution as a
maximum-weight bipartite graph matching prob-
lem. All the nodes share the predicate risk.
</figureCaption>
<bodyText confidence="0.999968558823529">
In order to ensure that sentence enhancement
does not lead to the merging of such incompati-
ble events, we designed a simple method to ap-
proximate event coreference resolution that does
not require event coreference labels. This method
is based on the intuition that different mentions of
an event should contain many of the same partic-
ipants. Thus, by measuring the similarity of the
arguments and the syntactic contexts between the
node in the sentence graph and the candidate edge,
we can have a measure of the likelihood that they
refer to the same event.
We would be interested in integrating existing
event coreference resolution systems into this step
in the future, such as the unsupervised method
of Bejan and Harabagiu (2010). Existing event
coreference systems tend to focus on cases with
different heads (e.g., X kicked Y, then Y was in-
jured), which could increase the possibilities for
sentence enhancement, if the event coreference
module is sufficiently accurate. However, since
our method currently only merges identical heads,
we require a more fine-grained method based on
distributional measures of similarity.
We measure the similarity of these syntactic
contexts by aligning the arguments in the syn-
tactic contexts and computing the similarity of
the aligned arguments. These problems can be
jointly solved as a maximum-weight bipartite
graph matching problem (Figure 4). Formally, let
a syntactic context be a list of dependency triples
(h, r, a), consisting of a governor or head node h
and a dependent argument a in the dependency re-
lation r, where head node h is fixed across each
</bodyText>
<page confidence="0.988043">
778
</page>
<bodyText confidence="0.99962375">
element of the list. Then, each of the two in-
put syntactic contexts forms one of the two dis-
joint sets in a complete weighted bipartite graph
where each node corresponds to one dependency
triple. We define the edge weights according to
the similarities of the edge’s incident nodes; i.e.,
between two dependency triples (h1, r1, a1) and
(h2, r2, a2). We also decompose the similarity
into the similarities between the head and relation
types ((h1, r1) and (h2, r2)), and between the ar-
guments (a1 and a2). The edge weight function is
thus:
</bodyText>
<equation confidence="0.960839">
sim((h1, r1, a1), (h2, r2, a2)) = (1)
sim1((h1, r1), (h2, r2)) x sim2(a1, a2),
</equation>
<bodyText confidence="0.999970529411764">
where sim1 and sim2 are binary functions that rep-
resent the similarities between governor-relation
pairs and dependents, respectively. We train mod-
els of distributional semantics using a large back-
ground corpus; namely, the Annotated Gigaword
corpus (Napoles et al., 2012). For sim1, we cre-
ate a vector of counts of the arguments that are
seen filling each (h, r) pair, and define the similar-
ity between two such pairs to be the cosine simi-
larity between their argument vectors. For sim2,
we create a basic vector-space representation of
a word d according to words that are found in
the context of word d within a five-word context
window, and likewise compute the cosine simi-
larity between the word vectors. These methods
of computing distributional similarity are well at-
tested in lexical semantics for measuring the re-
latedness of words and syntactic structures (Tur-
ney and Pantel, 2010), and similar methods have
been applied in text-to-text generation by Ganitke-
vitch et al. (2012), though the focus of that work is
to use paraphrase information thus learned to im-
prove sentence compression.
The resulting graph matching problem is solved
using the NetworkX package for Python3. The fi-
nal similarity score is an average of the similarity
scores from Equation 1 that participate in the se-
lected matching, weighted by the product of the
IDF scores of the dependent nodes of each edge.
This final score is used as a threshold that candi-
date contexts from the source text must meet in
order to be eligible for being merged into the sen-
tence graph. This threshold was tuned by cross-
validation, and can remain constant, although re-
</bodyText>
<footnote confidence="0.797935">
3http://networkx.github.io/
</footnote>
<bodyText confidence="0.9916675">
tuning to different domains (a weakly supervised
alternative) is likely to be beneficial.
</bodyText>
<subsectionHeader confidence="0.978542">
3.4 Tree generation
</subsectionHeader>
<bodyText confidence="0.999968642857143">
The next major step of the algorithm is to extract
an output dependency tree from the expanded sen-
tence graph. We formulate this as an integer linear
program, in which variables correspond to edges
of the sentence graph, and a solution to the linear
program determines the structure of an output de-
pendency tree. We use ILOG CPLEX to solve all
of the integer linear programs in our experiments.
A good dependency tree must at once express
the salient or important information present in the
input text as well as be grammatically correct and
of a manageable length. These desiderata are en-
coded into the linear program as constraints or as
part of the objective function.
</bodyText>
<subsectionHeader confidence="0.424447">
3.4.1 Objective function
</subsectionHeader>
<bodyText confidence="0.9999581">
We designed an objective function that considers
the importance of the words and syntactic rela-
tions that are selected as well as accounts for re-
dundancy in the output sentence. Let X be the set
of variables in the program, and let each variable
in X take the form xh,r,a, a binary variable that
represents whether an edge in the sentence graph
from a head node with lemma h to an argument
with lemma a in relation r is selected. For a lexi-
con E, our objective function is:
</bodyText>
<equation confidence="0.605982333333333">
xh r a max
s t.a—w(xh,r,w · P(r |h) · I (w)),
(2)
</equation>
<bodyText confidence="0.999904066666667">
where P(r|h) is the probability that head h
projects the dependency relation r, and I(w) is
the informativeness score for word w as defined
by Clarke and Lapata (2008). This formulation
encourages the selection of words that are infor-
mative according to I(w) and syntactic relations
that are probable. The inner max function for each
w in the lexicon encourages non-redundancy, as
each word may only contribute once to the objec-
tive value. This function can be rewritten into a
form compatible with a standard linear program by
the addition of auxiliary variables and constraints.
For more details of how this and other aspects of
the linear program are implemented, see the sup-
plementary document.
</bodyText>
<sectionHeader confidence="0.498151" genericHeader="method">
3.4.2 Constraints
</sectionHeader>
<bodyText confidence="0.966257">
Well-formedness constraints, taken directly from
F&amp;S, ensure that the set of selected edges pro-
</bodyText>
<equation confidence="0.601835">
�max
w∈E
</equation>
<page confidence="0.977608">
779
</page>
<bodyText confidence="0.999916235294118">
duces a tree. Another constraint limits the number
of content nodes in the tree to 11, which corre-
sponds to the average number of content nodes in
human-written summary sentences in the data set.
Syntactic constraints aim to ensure grammatical-
ity of the output sentence. In addition to the con-
straint proposed by F&amp;S regarding subordinating
conjunctions, we propose two other ones. The first
ensures that a nominal or adjectival predicate must
be selected with a copular construction at the top
level of a non-finite clause. The second ensures
that transitive verbs retain both of their comple-
ments in the output4. Semantic constraints ensure
that only noun phrases of sufficiently high simi-
larity which are not in a hyperonym-hyponym or
holonym-meronym relation with each other may
be joined by coordination.
</bodyText>
<subsectionHeader confidence="0.811617">
3.5 Linearization
</subsectionHeader>
<bodyText confidence="0.999992310344827">
The final step of our method is to linearize the de-
pendency tree from the previous step into the final
sequence of words. We implemented our own lin-
earization method to take advantage of the order-
ing information can be inferred from the original
source text sentences.
Our linearization algorithm proceeds top-down
from the root of the dependency tree to the leaves.
At each node of the tree, linearization consists of
realizing the previously collapsed elements such
as prepositions, determiners and noun compound
elements, then ordering the dependent nodes with
respect to the root node and each other. Restoring
the collapsed elements is accomplished by simple
heuristics. For example, prepositions and deter-
miners precede their accompanying noun phrase.
The dependent nodes are ordered by a sort-
ing algorithm, where the order between two syn-
tactic relations and dependent nodes (r1, a1) and
(r2, a2) is determined as follows. First, if a1 and
a2 originated from the same source text sentence,
then they are ordered according to their order of
appearance in the source text. Otherwise, we con-
sider the probability P(r1 precedes r2), and order
a1 before a2 iff P(r1 precedes r2) &gt; 0.5. This
distribution, P(r1 precedes r2), is estimated by
counting and normalizing the order of the relation
types in the source text corpus. For the purposes
of ordering, the governor node is treated as if it
</bodyText>
<footnote confidence="0.507286">
4We did not experiment with changing the grammatical
voice in the output tree, such as introducing a passive con-
struction if only a direct object is selected, but this is one
possible extension of the algorithm.
</footnote>
<bodyText confidence="0.99988075">
were a dependent node with a special syntactic re-
lation label self. This algorithm always produces
an output ordering with a projective dependency
tree, which is a reasonable assumption for English.
</bodyText>
<sectionHeader confidence="0.99925" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.992226">
4.1 Method
</subsectionHeader>
<bodyText confidence="0.999970139534884">
Recent approaches to sentence fusion have of-
ten been evaluated as isolated components. For
example, F&amp;S evaluate the output sentences by
asking human judges to rate the sentences’ in-
formativeness and grammaticality according to a
1–5 Likert scale rating. Thadani and McKe-
own (2013) combine grammaticality ratings with
an automatic evaluation which compares the sys-
tem output against gold-standard sentences drawn
from summarization data sets. However, this eval-
uation setting still does not reflect the utility of
sentence fusion in summarization, because the
input sentences come from human-written sum-
maries rather than the original source text.
We adopt a more realistic setting of using sen-
tence fusion in automatic summarization by draw-
ing the input or core sentences automatically from
the source text, then evaluating the output of the
fusion and expansion algorithm directly as one-
sentence summaries according to standard sum-
marization evaluation measures of content quality.
Data preparation. Our experiments are con-
ducted on the TAC 2010 and TAC 2011 Guided
Summarization corpus (Owczarzak and Dang,
2010), on the initial summarization task. Each
document cluster is summarized by one sentence,
generated from an initial cluster of core sentences
as described in Section 3.1.
Evaluation measures. We evaluate summary
content quality using the word-overlap measures
ROUGE-1 and ROUGE-2, as is standard in the
summarization community. We also measure the
quality of sentences at a syntactic or shallow se-
mantic level that operates at the level of depen-
dency triples by a measure that we call Pyra-
mid BE. Specifically, we extract all of the depen-
dency triples of the form t = (h, r, a) from the
sentence under evaluation and the gold-standard
summaries, where h and a are the lemmata of
the head and the argument, and r is the syntac-
tic relation, normalized for grammatical voice and
excluding the collapsed edges which are mostly
noun-phrase-internal elements and grammatical
</bodyText>
<page confidence="0.991981">
780
</page>
<table confidence="0.9997535">
Method Pyramid BE ROUGE-1 ROUGE-2 Log Likelihood Oracle Pyramid BE
Fusion (F&amp;S) 10.61 10.07 2.15 -159.31 28.00
Expansion 8.82 9.41 1.82 -157.46 52.97
+Event coref 11.00 9.76 1.93 -156.20 40.30
</table>
<tableCaption confidence="0.999945">
Table 1: Results of the sentence enhancement and fusion experiments.
</tableCaption>
<bodyText confidence="0.9999831">
particles. Then, we perform a matching between
the set of triples in the sentence under evalua-
tion and in a reference summary following the
Transformed BE method of Tratz and Hovy (2008)
with the total weighting scheme. This match-
ing is performed between the sentence and ev-
ery gold-standard summary, and the maximum of
these scores is taken. This score is then divided
by the maximum score that is achievable using the
number of triples present in the input sentence, as
inspired by the Pyramid method. This denom-
inator is more appropriate than the one used in
Transformed BE, which is designed for the case
where the evaluated summary and the reference
summaries are of comparable length.
For grammaticality, we parse the output sen-
tences using the Stanford parser5, and use the log
likelihood of the most likely parse of the sentence
as a coarse estimate of grammaticality. Parse log
likelihoods have been shown to be useful in deter-
mining grammaticality (Wagner et al., 2009), and
many of the problems associated with using it do
not apply in our evaluation, because our sentences
have a fixed number of content nodes, and contain
similar content. While we could have conducted
a user study to elicit Likert-scale grammaticality
judgements, such results are difficult to interpret
and the scores depend heavily on the set of judges
and the precise evaluation setting, as is the case for
sentence compression (Napoles et al., 2011).
</bodyText>
<subsectionHeader confidence="0.842148">
4.2 Results and discussion
</subsectionHeader>
<bodyText confidence="0.999552833333333">
As shown in Table 1, sentence enhancement with
coreference outperforms the sentence fusion algo-
rithm of F&amp;S in terms of the Pyramid BE measure
and the baseline expansion algorithm, though only
the latter difference is statistically significant (p =
0.0196). In terms of the ROUGE word overlap
</bodyText>
<footnote confidence="0.885719375">
5The likelihoods are obtained by the PCFG model of
CoreNLP version 1.3.2. We experimented with the Berke-
ley parser (Petrov et al., 2006) as well, with similar results
that favour the sentence enhancement with event coreference
method, but because the parser failed to parse a number of
cases, we do not report those results here.
6All statistical significance results in this section are for
Wilcoxon signed-rank tests.
</footnote>
<bodyText confidence="0.9999034">
measures, fusion achieves a better performance,
but it only outperforms the expansion baseline
significantly (ROUGE-1: p = 0.021, ROUGE-
2: p = 0.012). Note that the ROUGE scores
are low because they involve comparing a one-
sentence summary against a paragraph-long gold
standard. The average log likelihood result sug-
gests that sentence enhancement with event coref-
erence produces sentences that are more grammat-
ical than traditional fusion does, and this differ-
ence is statistically significant (p = 0.044). These
results show that sentence enhancement with event
coreference is competitive with a strong previous
sentence fusion method in terms of content, de-
spite having to combine information from more
diverse sentences. This does not come at the ex-
pense of grammaticality; in fact, it seems that hav-
ing a greater possible range of output sentences
may even improve the grammaticality of the out-
put sentences.
Oracle score. To examine the potential of sen-
tence enhancement, we computed an oracle score
that provides an upper bound to the best possi-
ble sentence that may be extracted from the sen-
tence graph. First, we ranked all of dependency
triples found in each gold-standard summary by
their score (i.e., the number of gold-standard sum-
maries they appear in). Then, we took the high-
est scoring triples from this ranking that are found
in the sentence graph until the length limit was
reached, and divided by the Pyramid-based de-
nominator as above7. The oracle score is the max-
imum of these scores over the gold-standard sum-
maries. The resulting oracle scores are shown
in the rightmost column of Table 1. While it
is no surprise that the oracle score improves af-
ter the sentence graph is expanded, the large in-
crease in the oracle score indicates the potential of
sentence enhancement for generating high-quality
summary sentences.
</bodyText>
<footnote confidence="0.9695235">
7There is no guarantee that these dependency triples form
a tree structure. Hence, this is an upper bound.
</footnote>
<page confidence="0.997505">
781
</page>
<bodyText confidence="0.999479375">
Grammaticality. There is still room for im-
provement in the grammaticality of the generated
sentences, which will require modelling contexts
larger than individual predicates and their argu-
ments. Consider the following output of the sen-
tence enhancement with event coreference system:
(3) The government has launched an
investigation into Soeharto’s wealth by the
Attorney General’s office on the wealth of
former government officials.
This sentence suffers from coherence problems
because two pieces of information are duplicated.
The first is the subject of the investigation, which
is expressed by two prepositional objects of in-
vestigation with the prepositions into and on.
The second, more subtle incoherence concerns
the body that is responsible for the investigation,
which is expressed both by the subject of launch
(The government has launched an investigation),
and the by-prepositional object of investigation (an
investigation ... by the Attorney General’s office).
Clearly, a model that makes fewer independence
assumptions about the relation between different
edges in the sentence graph is needed.
</bodyText>
<sectionHeader confidence="0.947625" genericHeader="method">
5 A Study of Source-External Elements
</sectionHeader>
<bodyText confidence="0.9999848125">
The sentence enhancement algorithm presented
above demonstrates that it is possible to use the
entire source text to produce an informative sen-
tence. Yet it is still limited by the particular pred-
icates and dependency relations that are found
in the source. The next step towards develop-
ing abstractive systems that exhibit human-like be-
haviour is to try to incorporate elements into the
summary that are not found in the source text at
all.
Despite its apparent difficulty, there is reason to
be hopeful for text-to-text generation techniques
even in such a scenario. In particular, we showed
in earlier work that almost all of the caseframes,
or pairs of governors and relations, in human-
written summaries can be found in the source text
or in a small set of additional related articles that
belong to the same domain as the source text (e.g.,
natural disasters) (Cheung and Penn, 2013). What
that study lacks, however, is a detailed analysis
of the factors surrounding why human summary
writers use non-source-text elements in their sum-
maries, and how these may be automatically iden-
tified in the in-domain text. In this section, we
supply such an analysis and provide evidence that
human summary writers actually do incorporate
elements external to the source text for a reason,
namely, that these elements are more specific to
the semantic content that they wish to convey. We
also identify a number of features that may be use-
ful for automatically determining the appropriate-
ness of these in-domain elements in a summary.
</bodyText>
<subsectionHeader confidence="0.998966">
5.1 Method
</subsectionHeader>
<bodyText confidence="0.999997045454545">
We performed our analysis on the predicates
present in text, such as kill and computer. We also
analyzed predicate-relation pairs (PR pairs) such
as (kill, nsubj) or (computer, amod). This choice
is similar to the caseframes used by Cheung and
Penn (2013), and we similarly apply transforma-
tions to normalize for grammatical voice and other
syntactic alternations, but we consider PR pairs of
all relation types, unlike caseframes, which only
consider verb complements and prepositional ob-
jects. PR pairs are extracted from the prepro-
cessed corpus. We use the TAC 2010 Guided
Summarization data set for our analyses, which
we organize into two sub-studies. In the prove-
nance study, we divide the PR pairs in human-
written summaries according to whether they are
found in the source text (source-internal) or not
(source-external). In the domain study, we divide
in-domain but source-external predicate-relation
pairs according to whether they are used in a
human-written summary (gold-standard) or not
(non-gold-standard).
</bodyText>
<subsectionHeader confidence="0.999902">
5.2 Provenance Study
</subsectionHeader>
<bodyText confidence="0.998392705882353">
In the first study, we compare the characteristics
of gold-standard predicates and PR pairs accord-
ing to their provenance; that is, are they found in
the source text itself? The question that we try to
answer is why human summarizers need to look
beyond the source text at all when writing their
summaries. We will provide evidence that they do
so because they can find predicates that are more
appropriate to the content that is being expressed
according to two quantitative measures.
Predicate provenance. Source-external PR
pairs may be external to the source text for two
reasons. Either the predicate (i.e., the actual word)
is found in the source text, but the dependency
relation (i.e., the semantic predication that holds
between the predicate and its arguments) is
not found with that particular predicate, or the
</bodyText>
<page confidence="0.991072">
782
</page>
<table confidence="0.989137625">
Average freq (millions)
Source-internal 1.77 (1.57, 2.08)
Source-external 1.15 (0.99, 1.50)
(a) The average predicate frequency of source-internal vs.
source-external gold-standard predicates in an external corpus.
Arg entropy
Source-internal 7.94 (7.90, 7.97)
Source-external 7.42 (7.37, 7.48)
</table>
<tableCaption confidence="0.8658402">
(b) The average argument entropy of source-internal vs. source-
external PR pairs in bits.
Table 2: Results of the provenance study. 95%
confidence intervals are estimated by the bootstrap
method and indicated in parentheses.
</tableCaption>
<bodyText confidence="0.9997232">
predicate itself may be external to the source text
altogether. If the former is true, then a generalized
version of the sentence enhancement algorithm
presented in this paper could in principle capture
these PR-pairs. We thus compute the proportion
of source-external PR pairs where the predicate
already exists in the source text.
We find that 2413 of the 4745 source-external
PR pairs, or 51% have a predicate that can be
found in the source text. This indicates that an
extension of the sentence enhancement with event
coreference approach presented in this paper could
capture a substantial portion of the source-external
PR pairs in its hypothesis space already.
Predicate frequency. What factors then can ac-
count for the remaining predicates that are not
found in the source text at all? The first such fac-
tor we identify is the frequency of the predicates.
Here, we take frequency to be the number of oc-
currences of the predicate in an external corpus;
namely the Annotated Gigaword, which gives us
a proxy for the specificity or informativeness of a
word. In this comparison, we take the set of pred-
icates in human-written summaries, divide them
according to whether they are found in the source
text or not, and then look up their frequency of ap-
pearance in the Annotated Gigaword corpus.
As Table 2a shows, the predicates that are not
found in the source text consist of significantly less
frequent words on average (Wilcoxon rank-sums
test, p &lt; 10−17). This suggests that human sum-
mary writers are motivated to use source-external
predicates, because they are able to find a more in-
formative or apposite predicate than the ones that
are available in the source text.
Entropy of argument distribution. Another
measure of the informativeness or appropriateness
of a predicate is to examine the range of arguments
that it tends to take. A more generic word would
be expected to take a wider range of arguments,
whereas a more particular word would take a nar-
rower range of arguments, for example those of
a specific entity type. We formalize this notion
by measuring the entropy of the distribution of ar-
guments that a predicate-relation pair takes as ob-
served in Annotated Gigaword. Given frequency
statistics f(h, r, a) of predicate head h taking an
argument word a in relation r, we define the argu-
ment distribution of predicate-relation pair (h, r)
as:
</bodyText>
<equation confidence="0.9889535">
P(alh, r) = f(h, r, a)/ � f(h, r, a&apos;) (4)
a/
</equation>
<bodyText confidence="0.999970846153846">
We then compute the entropy of P(aIh, r) for the
gold-standard predicate-relation pairs, and com-
pare the average argument entropies of the source-
internal and the source-external subsets.
Table 2b shows the result of this comparison.
Source-external PR pairs exhibit a lower average
argument entropy, taking a narrower range of pos-
sible arguments. Together these two findings indi-
cate that human summary writers look beyond the
source text not just for the sake of diversity or to
avoid copying the source text; they do so because
they can find predicates that more specifically con-
vey some desired semantic content.
</bodyText>
<subsectionHeader confidence="0.992315">
5.3 Domain study
</subsectionHeader>
<bodyText confidence="0.9999896875">
The second study examines how to distinguish
those source-external predicates and PR pairs in
in-domain articles that are used in a summary from
those that are not. For this study, we rely on the
topic category divisions in the TAC 2010 data set,
and define the in-domain text to be the documents
that belong to the same topic category as the target
document cluster (but not including the target doc-
ument cluster itself). This study demonstrates the
importance of better semantic understanding for
developing a text-to-text generation system that
uses in-domain text, and identifies potentially use-
ful features for training such a system.
Nearest neighbour similarity. In the event-
coreference step of the sentence enhancement al-
gorithm, we relied on distributional semantics to
</bodyText>
<page confidence="0.995639">
783
</page>
<table confidence="0.974282333333333">
N NN sim N Freq. (millions) Fecundity
GS 2202 0.493 (0.486, 0.501) GS 1568 2.44 (2.05, 2.94) 21.6 (20.8, 22.5)
Non-GS 789K 0.443 (0.442, 0.443) non-GS 268K 0.85 (0.83, 0.87) 6.43 (6.41, 6.47)
(a) Average similarity of gold-standard (GS) and
non-gold-standard (non-GS) PR pairs to the near-
est neighbour in the source text.
(b) Average frequency and fecundity of GS and non-GS predicates in
an external corpus. The differences are statistically significant (p &lt;
10−10).
</table>
<tableCaption confidence="0.999865">
Table 3: Results of the domain study. 95% confidence intervals are given in parentheses.
</tableCaption>
<bodyText confidence="0.999968771929825">
measure the similarity of arguments. Here, we
examine how well distributional similarity deter-
mines the appropriateness of a source-external PR
pair in a summary. Specifically, we measure its
similarity to the nearest PR pair in the source text.
To determine the similarity between two PR pairs,
we compute the cosine similarity between their
vector representations. The vector representation
of a PR pair is the concatenation of a context vec-
tor for the predicate itself and a selectional pref-
erences vector for the PR pair; that is, the vector
of counts with elements f(h, r, a) for fixed h and
r. These vectors are trained from the Annotated
Gigaword corpus.
The average nearest-neighbour similarities of
PR pairs are shown in Table 3a. While the dif-
ference between the gold-standard and non-gold-
standard PR pairs is indeed statistically signifi-
cant, the magnitude of the difference is not large.
This illustrates the challenge of mining source-
external text for abstractive summarization, and
demonstrates the need for a more structured or
detailed semantic representation in order to deter-
mine the PR pairs that would be appropriate. In
other words, the kind of simple event coreference
method based solely on distributional semantics
that we used in Section 3.3.1 is unlikely to be suf-
ficient when moving beyond the source text.
Frequency and fecundity. We also explore sev-
eral features that would be relevant to identifying
predicates in in-domain text that are used in the
automatic summary. This is a difficult problem, as
less than 0.6% of such predicates are actually used
in the source text. As a first step, we consider sev-
eral simple measures of the frequency and charac-
teristics of the predicates.
The first measure that we compute is the aver-
age predicate frequency of the gold-standard and
non-gold-standard predicates in an external cor-
pus, as in Section 5.2. A second, related mea-
sure is to compute the number of possible relations
that may occur with a given predicate. We call
this measure the fecundity of a predicate. Both
of these are computed with respect to the external
Annotated Gigaword corpus, as before.
As shown in Table 3b, there is a dramatic dif-
ference in both measures between gold-standard
and non-gold-standard predicates in in-domain ar-
ticles. Gold-standard predicates tend to be more
common words compared to non-gold-standard
ones. This result is not in conflict with the re-
sult in the provenance study that source-external
predicates are less common words. Rather, it is
a reminder that the background frequencies of the
predicates matter, and must be considered together
with the semantic appropriateness of the candidate
word.
</bodyText>
<sectionHeader confidence="0.999533" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999856">
This paper introduced sentence enhancement as
a method to incorporate information from multi-
ple points in the source text into one output sen-
tence in a fashion that is more flexible than previ-
ous sentence fusion algorithms. Our results show
that sentence enhancement improves the content
and grammaticality of summary sentences com-
pared to previous syntax-based sentence fusion ap-
proaches. Then, we presented studies on the com-
ponents of human-written summaries that are ex-
ternal to the source text. Our analyses suggest that
human summary writers look beyond the source
text to find predicates and relations that more pre-
cisely express some target semantic content, and
that more sophisticated semantic techniques are
needed in order to exploit in-domain articles for
text-to-text generation in summarization.
</bodyText>
<sectionHeader confidence="0.998844" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99953125">
We would like to thank the anonymous reviewers
for valuable suggestions. The first author was sup-
ported by a Facebook PhD Fellowship during the
completion of this research.
</bodyText>
<page confidence="0.997096">
784
</page>
<sectionHeader confidence="0.995879" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9995733125">
Regina Barzilay and Kathleen R. McKeown. 2005.
Sentence fusion for multidocument news summa-
rization. Computational Linguistics, 31(3):297–
328.
Cosmin A. Bejan and Sanda Harabagiu. 2010. Unsu-
pervised event coreference resolution with rich lin-
guistic features. In Proceedings of the 48th Annual
Meeting of the Association for Computational Lin-
guistics, pages 1412–1422. Association for Compu-
tational Linguistics.
Jackie Chi Kit Cheung and Gerald Penn. 2013. To-
wards robust abstractive multi-document summa-
rization: A caseframe analysis of centrality and do-
main. In Proceedings of the 51st Annual Meeting
of the Association for Computational Linguistics,
pages 1233–1242, August.
James Clarke and Mirella Lapata. 2008. Global in-
ference for sentence compression: An integer linear
programming approach. Journal ofArtificialIntelli-
gence Research(JAIR), 31:399–429.
Trevor Cohn and Mirella Lapata. 2008. Sentence
compression beyond word deletion. In Proceedings
of the 22nd International Conference on Compu-
tational Linguistics (Coling 2008), pages 137–144,
Manchester, UK, August. Coling 2008 Organizing
Committee.
Micha Elsner and Deepak Santhanam. 2011. Learn-
ing to fuse disparate sentences. In Proceedings of
the Workshop on Monolingual Text-To-Text Gener-
ation, pages 54–63. Association for Computational
Linguistics.
Katja Filippova and Michael Strube. 2008. Sentence
fusion via dependency graph compression. In Pro-
ceedings of the 2008 Conference on Empirical Meth-
ods in Natural Language Processing, pages 177–
185, Honolulu, Hawaii, October. Association for
Computational Linguistics.
Katja Filippova. 2010. Multi-sentence compression:
Finding shortest paths in word graphs. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics (Coling 2010), pages 322–
330, Beijing, China, August. Coling 2010 Organiz-
ing Committee.
Michel Galley and Kathleen McKeown. 2007. Lex-
icalized Markov grammars for sentence compres-
sion. In Human Language Technologies 2007:
The Conference of the North American Chapter of
the Association for Computational Linguistics; Pro-
ceedings of the Main Conference, pages 180–187.
Juri Ganitkevitch, Benjamin Van Durme, and Chris
Callison-Burch. 2012. Monolingual distributional
similarity for text-to-text generation. In Proceedings
of *SEM 2012: The First Joint Conference on Lex-
ical and Computational Semantics, pages 256–264,
Montr´eal, Canada, June. Association for Computa-
tional Linguistics.
Hongyan Jing and Kathleen R. McKeown. 2000. Cut
and paste based text summarization. In Proceed-
ings of the 1st North American Chapter of the As-
sociation for Computational Linguistics Conference,
pages 178–185.
Kevin Knight and Daniel Marcu. 2000. Statistics-
based summarization—step one: Sentence compres-
sion. In Proceedings of the National Conference on
Artificial Intelligence, pages 703–710.
Chin-Yew Lin and Eduard Hovy. 2000. The automated
acquisition of topic signatures for text summariza-
tion. In COLING 2000 Volume 1: The 18th In-
ternational Conference on Computational Linguis-
tics, COLING ’00, pages 495–501, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Erwin Marsi and Emiel Krahmer. 2005. Explorations
in sentence fusion. In Proceedings of the European
Workshop on Natural Language Generation, pages
109–117.
Ryan T. McDonald. 2006. Discriminative sentence
compression with soft syntactic evidence. In 11th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics.
Courtney Napoles, Benjamin Van Durme, and Chris
Callison-Burch. 2011. Evaluating sentence com-
pression: Pitfalls and suggested remedies. In Pro-
ceedings of the Workshop on Monolingual Text-To-
Text Generation, pages 91–97. Association for Com-
putational Linguistics.
Courtney Napoles, Matthew Gormley, and Benjamin
Van Durme. 2012. Annotated Gigaword. In Pro-
ceedings of the NAACL-HLT Joint Workshop on Au-
tomatic Knowledge Base Construction &amp; Web-scale
Knowledge Extraction (AKBC-WEKEX), pages 95–
100.
Karolina Owczarzak and Hoa T. Dang. 2010. TAC
2010 guided summarization task guidelines.
Slav Petrov, Leon Barrett, Romain Thibaux, and Dan
Klein. 2006. Learning accurate, compact, and
interpretable tree annotation. In Proceedings of
the 21st International Conference on Computational
Linguistics and 44th Annual Meeting of the Associ-
ation for Computational Linguistics.
Horacio Saggion and Guy Lapalme. 2002. Generat-
ing indicative-informative summaries with SumUM.
Computational Linguistics, 28(4):497–526.
Kapil Thadani and Kathleen McKeown. 2013. Super-
vised sentence fusion with single-stage inference. In
Proceedings of the Sixth International Joint Confer-
ence on Natural Language Processing, pages 1410–
1418, Nagoya, Japan, October. Asian Federation of
Natural Language Processing.
Stephen Tratz and Eduard Hovy. 2008. Summariza-
tion evaluation using transformed Basic Elements.
In Proceedings of the First Text Analysis Conference
(TAC).
</reference>
<page confidence="0.980472">
785
</page>
<reference confidence="0.998962533333333">
Peter D. Turney and Patrick Pantel. 2010. From
frequency to meaning: Vector space models of se-
mantics. Journal of Artificial Intelligence Research,
37:141–188.
Joachim Wagner, Jennifer Foster, and Josef van Gen-
abith. 2009. Judging grammaticality: Experi-
ments in sentence classification. CALICO Journal,
26(3):474–490.
Stephen Wan, Robert Dale, Mark Dras, and Cecile
Paris. 2008. Seed and grow: Augmenting statisti-
cally generated summary sentences using schematic
word patterns. In Proceedings of the 2008 Con-
ference on Empirical Methods in Natural Language
Processing, pages 543–552, Honolulu, Hawaii, Oc-
tober. Association for Computational Linguistics.
</reference>
<page confidence="0.998414">
786
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.822127">
<title confidence="0.999312">Unsupervised Sentence Enhancement for Automatic Summarization</title>
<author confidence="0.999672">Jackie Chi Kit</author>
<affiliation confidence="0.999157">University of</affiliation>
<address confidence="0.967898">10 King’s College Rd., Room Toronto, ON, Canada M5S</address>
<email confidence="0.998998">jcheung@cs.toronto.edu</email>
<author confidence="0.956374">Gerald</author>
<affiliation confidence="0.999196">University of</affiliation>
<address confidence="0.9583025">10 King’s College Rd., Room Toronto, ON, Canada M5S</address>
<email confidence="0.99876">gpenn@cs.toronto.edu</email>
<abstract confidence="0.999657">present enhancement a novel technique for text-to-text generation in abstractive summarization. Compared to extraction or previous approaches to sentence fusion, sentence enhancement increases the range of possible summary sentences by allowing the combination of dependency subtrees from any sentence from the source text. Our experiments indicate that our approach yields summary sentences that are competitive with a sentence fusion baseline in terms of content quality, but better in terms of grammaticality, and that the benefit of sentence enhancement relies crucially on an event coreference resolution algorithm using distributional semantics. We also consider how text-to-text generation approaches to summarization can be extended beyond the source text by examining how human summary writers incorporate source-text-external elements into their summary sentences.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Sentence fusion for multidocument news summarization.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>3</issue>
<pages>328</pages>
<contexts>
<context position="1378" citStr="Barzilay and McKeown, 2005" startWordPosition="198" endWordPosition="201">ntence fusion baseline in terms of content quality, but better in terms of grammaticality, and that the benefit of sentence enhancement relies crucially on an event coreference resolution algorithm using distributional semantics. We also consider how text-to-text generation approaches to summarization can be extended beyond the source text by examining how human summary writers incorporate source-text-external elements into their summary sentences. 1 Introduction Sentence fusion is the technique of merging several input sentences into one output sentence while retaining the important content (Barzilay and McKeown, 2005; Filippova and Strube, 2008; Thadani and McKeown, 2013). For example, the input sentences in Figure 1 may be fused into one output sentence. As a text-to-text generation technique, sentence fusion is attractive because it provides an avenue for moving beyond sentence extraction in automatic summarization, while not requiring deep seInput: Bil Mar Foods Co., a meat processor owned by Sara Lee, announced a recall of certain lots of hot dogs and packaged meat. Input: The outbreak led to the recall on Tuesday of 15 million pounds of hot dogs and cold cuts produced at the Bil Mar Foods plant. Outp</context>
<context position="6064" citStr="Barzilay and McKeown, 2005" startWordPosition="962" endWordPosition="966">mains. Yet the results of our experiments and studies demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sent</context>
</contexts>
<marker>Barzilay, McKeown, 2005</marker>
<rawString>Regina Barzilay and Kathleen R. McKeown. 2005. Sentence fusion for multidocument news summarization. Computational Linguistics, 31(3):297– 328.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cosmin A Bejan</author>
<author>Sanda Harabagiu</author>
</authors>
<title>Unsupervised event coreference resolution with rich linguistic features.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1412--1422</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="15289" citStr="Bejan and Harabagiu (2010)" startWordPosition="2473" endWordPosition="2476">signed a simple method to approximate event coreference resolution that does not require event coreference labels. This method is based on the intuition that different mentions of an event should contain many of the same participants. Thus, by measuring the similarity of the arguments and the syntactic contexts between the node in the sentence graph and the candidate edge, we can have a measure of the likelihood that they refer to the same event. We would be interested in integrating existing event coreference resolution systems into this step in the future, such as the unsupervised method of Bejan and Harabagiu (2010). Existing event coreference systems tend to focus on cases with different heads (e.g., X kicked Y, then Y was injured), which could increase the possibilities for sentence enhancement, if the event coreference module is sufficiently accurate. However, since our method currently only merges identical heads, we require a more fine-grained method based on distributional measures of similarity. We measure the similarity of these syntactic contexts by aligning the arguments in the syntactic contexts and computing the similarity of the aligned arguments. These problems can be jointly solved as a ma</context>
</contexts>
<marker>Bejan, Harabagiu, 2010</marker>
<rawString>Cosmin A. Bejan and Sanda Harabagiu. 2010. Unsupervised event coreference resolution with rich linguistic features. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1412–1422. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jackie Chi Kit Cheung</author>
<author>Gerald Penn</author>
</authors>
<title>Towards robust abstractive multi-document summarization: A caseframe analysis of centrality and domain.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1233--1242</pages>
<contexts>
<context position="7068" citStr="Cheung and Penn, 2013" startWordPosition="1116" endWordPosition="1119"> by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised algorithm, as discussed above. Previous studies on cut-and-paste summarization (Jing and McKeown, 2000; Saggion and Lapalme, 2002) investigate the operations that human summarizers perform on the source text in order to produce the summary text. Our previous work argued that current extractive systems rely too heavily on notions of information centrality (Cheung and Penn, 2013). This paper extends this work by identifying specific linguistic factors correlated with the use of source-text-external elements. 3 A Sentence Enhancement Algorithm The basic steps in our sentence expansion algorithm are as follows: (1) clustering to identify initial input sentences, (2) sentence graph creation, (3) sentence graph expansion, (4) tree generation, and (5) linearization. At a high level, our method for sentence enhancement is inspired by the syntactic sentence fusion approach of Filippova and Strube (2008) (henceforth, F&amp;S) originally developed for German, in that it operates o</context>
<context position="31671" citStr="Cheung and Penn, 2013" startWordPosition="5147" endWordPosition="5150"> step towards developing abstractive systems that exhibit human-like behaviour is to try to incorporate elements into the summary that are not found in the source text at all. Despite its apparent difficulty, there is reason to be hopeful for text-to-text generation techniques even in such a scenario. In particular, we showed in earlier work that almost all of the caseframes, or pairs of governors and relations, in humanwritten summaries can be found in the source text or in a small set of additional related articles that belong to the same domain as the source text (e.g., natural disasters) (Cheung and Penn, 2013). What that study lacks, however, is a detailed analysis of the factors surrounding why human summary writers use non-source-text elements in their summaries, and how these may be automatically identified in the in-domain text. In this section, we supply such an analysis and provide evidence that human summary writers actually do incorporate elements external to the source text for a reason, namely, that these elements are more specific to the semantic content that they wish to convey. We also identify a number of features that may be useful for automatically determining the appropriateness of</context>
</contexts>
<marker>Cheung, Penn, 2013</marker>
<rawString>Jackie Chi Kit Cheung and Gerald Penn. 2013. Towards robust abstractive multi-document summarization: A caseframe analysis of centrality and domain. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1233–1242, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Clarke</author>
<author>Mirella Lapata</author>
</authors>
<title>Global inference for sentence compression: An integer linear programming approach.</title>
<date>2008</date>
<journal>Journal ofArtificialIntelligence Research(JAIR),</journal>
<pages>31--399</pages>
<contexts>
<context position="6002" citStr="Clarke and Lapata, 2008" startWordPosition="952" endWordPosition="955">o-text generation community have been successful in many domains. Yet the results of our experiments and studies demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and </context>
<context position="19940" citStr="Clarke and Lapata (2008)" startWordPosition="3263" endWordPosition="3266">the words and syntactic relations that are selected as well as accounts for redundancy in the output sentence. Let X be the set of variables in the program, and let each variable in X take the form xh,r,a, a binary variable that represents whether an edge in the sentence graph from a head node with lemma h to an argument with lemma a in relation r is selected. For a lexicon E, our objective function is: xh r a max s t.a—w(xh,r,w · P(r |h) · I (w)), (2) where P(r|h) is the probability that head h projects the dependency relation r, and I(w) is the informativeness score for word w as defined by Clarke and Lapata (2008). This formulation encourages the selection of words that are informative according to I(w) and syntactic relations that are probable. The inner max function for each w in the lexicon encourages non-redundancy, as each word may only contribute once to the objective value. This function can be rewritten into a form compatible with a standard linear program by the addition of auxiliary variables and constraints. For more details of how this and other aspects of the linear program are implemented, see the supplementary document. 3.4.2 Constraints Well-formedness constraints, taken directly from F</context>
</contexts>
<marker>Clarke, Lapata, 2008</marker>
<rawString>James Clarke and Mirella Lapata. 2008. Global inference for sentence compression: An integer linear programming approach. Journal ofArtificialIntelligence Research(JAIR), 31:399–429.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Trevor Cohn</author>
<author>Mirella Lapata</author>
</authors>
<title>Sentence compression beyond word deletion.</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>137--144</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="5977" citStr="Cohn and Lapata, 2008" startWordPosition="948" endWordPosition="951"> developed by the textto-text generation community have been successful in many domains. Yet the results of our experiments and studies demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occur</context>
</contexts>
<marker>Cohn, Lapata, 2008</marker>
<rawString>Trevor Cohn and Mirella Lapata. 2008. Sentence compression beyond word deletion. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 137–144, Manchester, UK, August. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
<author>Deepak Santhanam</author>
</authors>
<title>Learning to fuse disparate sentences.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Monolingual Text-To-Text Generation,</booktitle>
<pages>54--63</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4058" citStr="Elsner and Santhanam (2011)" startWordPosition="643" endWordPosition="646">sociation for Computational Linguistics Source text: This fact has been underscored in the last few months by two unexpected outbreaks offood-borne illness. Output: The outbreak of food-borne illness led to the recall on Tuesday of lots of hot dogs and meats produced at the Bil Mar Foods plant. Figure 2: An example of sentence enhancement, in which parts of dissimilar sentences are incorporated into the output sentence. shown in Figure 2, the phrase offood-borne illness can be added to the previous output sentence, despite originating in a source text sentence that is quite different overall. Elsner and Santhanam (2011) proposed a supervised method to fuse disparate sentences, which takes as input a small number of sentences with compatible information that have been manually identified by editors of articles. By contrast, our algorithm is unsupervised, and tackles the problem of identifying compatible event mergers in the entire source text using an event coreference module. Our method outperforms a previous syntaxbased sentence fusion baseline on measures of summary content quality and grammaticality. Second, we analyze how text-to-text generation systems may make use of text that is not in the source text</context>
<context position="6618" citStr="Elsner and Santhanam (2011)" startWordPosition="1045" endWordPosition="1048">apata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised algorithm, as discussed above. Previous studies on cut-and-paste summarization (Jing and McKeown, 2000; Saggion and Lapalme, 2002) investigate the operations that human summarizers perform on the source text in order to produce the summary text. Our previous work argued that current extractive systems rely too heavily on notions of information centrality (Cheung and Penn, 2013). This paper extends this work by identifying specific linguistic factors correlated with the use of source-text-external elements. 3 A Sentence Enhan</context>
<context position="8095" citStr="Elsner and Santhanam (2011)" startWordPosition="1282" endWordPosition="1285">level, our method for sentence enhancement is inspired by the syntactic sentence fusion approach of Filippova and Strube (2008) (henceforth, F&amp;S) originally developed for German, in that it operates over the dependency parses of a small number of input sentences to produce an output sentence which fuses parts of the in776 prep_of put sentences. We adopt the same assumption as F&amp;S that these initial core sentences have a high degree of similarity with each other, and should form the core of a new sentence to be generated (Step 1). While fusion from highly disparate input sentences is possible, Elsner and Santhanam (2011) showed how difficult it is to do so correctly, even where such cases are manually identified. We thus aim for a more targeted type of fusion initially. Next, the dependency trees of the core sentences are fused into an intermediate sentence graph (Step 2), a directed acyclic graph from which the final sentence will be generated (Steps 4 and 5). We will compare against our implementation of F&amp;S, adapted to English. However, unlike F&amp;S or other previous approaches to sentence fusion, the sentence enhancement algorithm may also avail itself of the dependency parses of all of the other sentences </context>
</contexts>
<marker>Elsner, Santhanam, 2011</marker>
<rawString>Micha Elsner and Deepak Santhanam. 2011. Learning to fuse disparate sentences. In Proceedings of the Workshop on Monolingual Text-To-Text Generation, pages 54–63. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Filippova</author>
<author>Michael Strube</author>
</authors>
<title>Sentence fusion via dependency graph compression.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>177--185</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="1406" citStr="Filippova and Strube, 2008" startWordPosition="202" endWordPosition="205">rms of content quality, but better in terms of grammaticality, and that the benefit of sentence enhancement relies crucially on an event coreference resolution algorithm using distributional semantics. We also consider how text-to-text generation approaches to summarization can be extended beyond the source text by examining how human summary writers incorporate source-text-external elements into their summary sentences. 1 Introduction Sentence fusion is the technique of merging several input sentences into one output sentence while retaining the important content (Barzilay and McKeown, 2005; Filippova and Strube, 2008; Thadani and McKeown, 2013). For example, the input sentences in Figure 1 may be fused into one output sentence. As a text-to-text generation technique, sentence fusion is attractive because it provides an avenue for moving beyond sentence extraction in automatic summarization, while not requiring deep seInput: Bil Mar Foods Co., a meat processor owned by Sara Lee, announced a recall of certain lots of hot dogs and packaged meat. Input: The outbreak led to the recall on Tuesday of 15 million pounds of hot dogs and cold cuts produced at the Bil Mar Foods plant. Output: The outbreak led to the </context>
<context position="6117" citStr="Filippova and Strube, 2008" startWordPosition="971" endWordPosition="974"> demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised algorithm, as discussed above</context>
<context position="7595" citStr="Filippova and Strube (2008)" startWordPosition="1196" endWordPosition="1199">ent extractive systems rely too heavily on notions of information centrality (Cheung and Penn, 2013). This paper extends this work by identifying specific linguistic factors correlated with the use of source-text-external elements. 3 A Sentence Enhancement Algorithm The basic steps in our sentence expansion algorithm are as follows: (1) clustering to identify initial input sentences, (2) sentence graph creation, (3) sentence graph expansion, (4) tree generation, and (5) linearization. At a high level, our method for sentence enhancement is inspired by the syntactic sentence fusion approach of Filippova and Strube (2008) (henceforth, F&amp;S) originally developed for German, in that it operates over the dependency parses of a small number of input sentences to produce an output sentence which fuses parts of the in776 prep_of put sentences. We adopt the same assumption as F&amp;S that these initial core sentences have a high degree of similarity with each other, and should form the core of a new sentence to be generated (Step 1). While fusion from highly disparate input sentences is possible, Elsner and Santhanam (2011) showed how difficult it is to do so correctly, even where such cases are manually identified. We th</context>
</contexts>
<marker>Filippova, Strube, 2008</marker>
<rawString>Katja Filippova and Michael Strube. 2008. Sentence fusion via dependency graph compression. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 177– 185, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katja Filippova</author>
</authors>
<title>Multi-sentence compression: Finding shortest paths in word graphs.</title>
<date>2010</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (Coling</booktitle>
<pages>322--330</pages>
<location>Beijing, China,</location>
<contexts>
<context position="6134" citStr="Filippova, 2010" startWordPosition="975" endWordPosition="976">as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised algorithm, as discussed above. Previous studie</context>
</contexts>
<marker>Filippova, 2010</marker>
<rawString>Katja Filippova. 2010. Multi-sentence compression: Finding shortest paths in word graphs. In Proceedings of the 23rd International Conference on Computational Linguistics (Coling 2010), pages 322– 330, Beijing, China, August. Coling 2010 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michel Galley</author>
<author>Kathleen McKeown</author>
</authors>
<title>Lexicalized Markov grammars for sentence compression.</title>
<date>2007</date>
<booktitle>In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>180--187</pages>
<contexts>
<context position="5954" citStr="Galley and McKeown, 2007" startWordPosition="944" endWordPosition="947">ical generation techniques developed by the textto-text generation community have been successful in many domains. Yet the results of our experiments and studies demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences</context>
</contexts>
<marker>Galley, McKeown, 2007</marker>
<rawString>Michel Galley and Kathleen McKeown. 2007. Lexicalized Markov grammars for sentence compression. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 180–187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Juri Ganitkevitch</author>
<author>Benjamin Van Durme</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Monolingual distributional similarity for text-to-text generation.</title>
<date>2012</date>
<booktitle>In Proceedings of *SEM 2012: The First Joint Conference on Lexical and Computational Semantics,</booktitle>
<pages>256--264</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<marker>Ganitkevitch, Van Durme, Callison-Burch, 2012</marker>
<rawString>Juri Ganitkevitch, Benjamin Van Durme, and Chris Callison-Burch. 2012. Monolingual distributional similarity for text-to-text generation. In Proceedings of *SEM 2012: The First Joint Conference on Lexical and Computational Semantics, pages 256–264, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongyan Jing</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Cut and paste based text summarization.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference,</booktitle>
<pages>178--185</pages>
<contexts>
<context position="6790" citStr="Jing and McKeown, 2000" startWordPosition="1070" endWordPosition="1073">ke this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised algorithm, as discussed above. Previous studies on cut-and-paste summarization (Jing and McKeown, 2000; Saggion and Lapalme, 2002) investigate the operations that human summarizers perform on the source text in order to produce the summary text. Our previous work argued that current extractive systems rely too heavily on notions of information centrality (Cheung and Penn, 2013). This paper extends this work by identifying specific linguistic factors correlated with the use of source-text-external elements. 3 A Sentence Enhancement Algorithm The basic steps in our sentence expansion algorithm are as follows: (1) clustering to identify initial input sentences, (2) sentence graph creation, (3) se</context>
</contexts>
<marker>Jing, McKeown, 2000</marker>
<rawString>Hongyan Jing and Kathleen R. McKeown. 2000. Cut and paste based text summarization. In Proceedings of the 1st North American Chapter of the Association for Computational Linguistics Conference, pages 178–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Daniel Marcu</author>
</authors>
<title>Statisticsbased summarization—step one: Sentence compression.</title>
<date>2000</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<pages>703--710</pages>
<contexts>
<context position="2630" citStr="Knight and Marcu, 2000" startWordPosition="412" endWordPosition="415">call on Tuesday of lots of hot dogs and packaged meats produced at the Bil Mar Foods plant. Figure 1: An example of fusing two input sentences into an output sentence. The sections of the input sentences that are retained in the output are shown in bold. mantic analysis beyond, say, a dependency parser and lexical semantic resources. The overall trajectory pursued in the field can be characterized as a move away from local contexts relying heavily on the original source text towards more global contexts involving reformulation of the text. Whereas sentence extraction and sentence compression (Knight and Marcu, 2000, for example) involve taking one sentence and perhaps removing parts of it, traditional sentence fusion involves reformulating a small number of relatively similar sentences in order to take the union or intersection of the information present therein. In this paper, we move further along this path in the following ways. First, we present sentence enhancement as a novel technique which extends sentence fusion by combining the subtrees of many sentences into the output sentence, rather than just a few. Doing so allows relevant information from sentences that are not similar to the original inp</context>
<context position="5912" citStr="Knight and Marcu, 2000" startWordPosition="937" endWordPosition="940">ecise and wide-coverage NLG. The statistical generation techniques developed by the textto-text generation community have been successful in many domains. Yet the results of our experiments and studies demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then a</context>
</contexts>
<marker>Knight, Marcu, 2000</marker>
<rawString>Kevin Knight and Daniel Marcu. 2000. Statisticsbased summarization—step one: Sentence compression. In Proceedings of the National Conference on Artificial Intelligence, pages 703–710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>The automated acquisition of topic signatures for text summarization.</title>
<date>2000</date>
<booktitle>In COLING 2000 Volume 1: The 18th International Conference on Computational Linguistics, COLING ’00,</booktitle>
<pages>495--501</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10087" citStr="Lin and Hovy (2000)" startWordPosition="1609" endWordPosition="1612">ustering, which requires a measure of similarity between sentences and a stopping criterion. We define the similarity between two sentences to be the standard cosine similarity between the lemmata of the sentences, weighted by IDF and excluding stopwords, and clustering is run until a similarity threshold of 0.5 is reached. Since complete-link clustering prefers small coherent clusters and we select the top-scoring cluster in each document collection, the method is somewhat robust to different choices of the stopping threshold. The clusters are scored according to the signature term method of Lin and Hovy (2000), which assigns an importance score to each term accordBMFoods announce recall certain lots... nsubj dobj outbreak led recall Tuesday 15M pounds... (a) Abbreviated dependency trees. food-borne illness (b) Sentence graph after merging the nodes with lemma recall (in bold), and expanding the node outbreak (dashed outgoing edge). Figure 3: An example of the input dependency trees for sentence graph creation and expansion, using the input sentences of Figure 1. ing to how much more often it appears in the source text compared to some irrelevant background text using a log likelihood ratio. Specifi</context>
</contexts>
<marker>Lin, Hovy, 2000</marker>
<rawString>Chin-Yew Lin and Eduard Hovy. 2000. The automated acquisition of topic signatures for text summarization. In COLING 2000 Volume 1: The 18th International Conference on Computational Linguistics, COLING ’00, pages 495–501, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erwin Marsi</author>
<author>Emiel Krahmer</author>
</authors>
<title>Explorations in sentence fusion.</title>
<date>2005</date>
<booktitle>In Proceedings of the European Workshop on Natural Language Generation,</booktitle>
<pages>109--117</pages>
<contexts>
<context position="6089" citStr="Marsi and Krahmer, 2005" startWordPosition="967" endWordPosition="970">r experiments and studies demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised a</context>
</contexts>
<marker>Marsi, Krahmer, 2005</marker>
<rawString>Erwin Marsi and Emiel Krahmer. 2005. Explorations in sentence fusion. In Proceedings of the European Workshop on Natural Language Generation, pages 109–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan T McDonald</author>
</authors>
<title>Discriminative sentence compression with soft syntactic evidence.</title>
<date>2006</date>
<booktitle>In 11th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5928" citStr="McDonald, 2006" startWordPosition="941" endWordPosition="943">NLG. The statistical generation techniques developed by the textto-text generation community have been successful in many domains. Yet the results of our experiments and studies demonstrate the following: as text-to-text generation techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding informatio</context>
</contexts>
<marker>McDonald, 2006</marker>
<rawString>Ryan T. McDonald. 2006. Discriminative sentence compression with soft syntactic evidence. In 11th Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Courtney Napoles</author>
<author>Benjamin Van Durme</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Evaluating sentence compression: Pitfalls and suggested remedies.</title>
<date>2011</date>
<booktitle>In Proceedings of the Workshop on Monolingual Text-ToText Generation,</booktitle>
<pages>91--97</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>Napoles, Van Durme, Callison-Burch, 2011</marker>
<rawString>Courtney Napoles, Benjamin Van Durme, and Chris Callison-Burch. 2011. Evaluating sentence compression: Pitfalls and suggested remedies. In Proceedings of the Workshop on Monolingual Text-ToText Generation, pages 91–97. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Courtney Napoles</author>
<author>Matthew Gormley</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Annotated Gigaword.</title>
<date>2012</date>
<booktitle>In Proceedings of the NAACL-HLT Joint Workshop on Automatic Knowledge Base Construction &amp; Web-scale Knowledge Extraction (AKBC-WEKEX),</booktitle>
<pages>95--100</pages>
<marker>Napoles, Gormley, Van Durme, 2012</marker>
<rawString>Courtney Napoles, Matthew Gormley, and Benjamin Van Durme. 2012. Annotated Gigaword. In Proceedings of the NAACL-HLT Joint Workshop on Automatic Knowledge Base Construction &amp; Web-scale Knowledge Extraction (AKBC-WEKEX), pages 95– 100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karolina Owczarzak</author>
<author>Hoa T Dang</author>
</authors>
<title>guided summarization task guidelines.</title>
<date>2010</date>
<journal>TAC</journal>
<contexts>
<context position="24371" citStr="Owczarzak and Dang, 2010" startWordPosition="3969" endWordPosition="3972"> reflect the utility of sentence fusion in summarization, because the input sentences come from human-written summaries rather than the original source text. We adopt a more realistic setting of using sentence fusion in automatic summarization by drawing the input or core sentences automatically from the source text, then evaluating the output of the fusion and expansion algorithm directly as onesentence summaries according to standard summarization evaluation measures of content quality. Data preparation. Our experiments are conducted on the TAC 2010 and TAC 2011 Guided Summarization corpus (Owczarzak and Dang, 2010), on the initial summarization task. Each document cluster is summarized by one sentence, generated from an initial cluster of core sentences as described in Section 3.1. Evaluation measures. We evaluate summary content quality using the word-overlap measures ROUGE-1 and ROUGE-2, as is standard in the summarization community. We also measure the quality of sentences at a syntactic or shallow semantic level that operates at the level of dependency triples by a measure that we call Pyramid BE. Specifically, we extract all of the dependency triples of the form t = (h, r, a) from the sentence unde</context>
</contexts>
<marker>Owczarzak, Dang, 2010</marker>
<rawString>Karolina Owczarzak and Hoa T. Dang. 2010. TAC 2010 guided summarization task guidelines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Leon Barrett</author>
<author>Romain Thibaux</author>
<author>Dan Klein</author>
</authors>
<title>Learning accurate, compact, and interpretable tree annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="27398" citStr="Petrov et al., 2006" startWordPosition="4465" endWordPosition="4468">to interpret and the scores depend heavily on the set of judges and the precise evaluation setting, as is the case for sentence compression (Napoles et al., 2011). 4.2 Results and discussion As shown in Table 1, sentence enhancement with coreference outperforms the sentence fusion algorithm of F&amp;S in terms of the Pyramid BE measure and the baseline expansion algorithm, though only the latter difference is statistically significant (p = 0.0196). In terms of the ROUGE word overlap 5The likelihoods are obtained by the PCFG model of CoreNLP version 1.3.2. We experimented with the Berkeley parser (Petrov et al., 2006) as well, with similar results that favour the sentence enhancement with event coreference method, but because the parser failed to parse a number of cases, we do not report those results here. 6All statistical significance results in this section are for Wilcoxon signed-rank tests. measures, fusion achieves a better performance, but it only outperforms the expansion baseline significantly (ROUGE-1: p = 0.021, ROUGE2: p = 0.012). Note that the ROUGE scores are low because they involve comparing a onesentence summary against a paragraph-long gold standard. The average log likelihood result sugg</context>
</contexts>
<marker>Petrov, Barrett, Thibaux, Klein, 2006</marker>
<rawString>Slav Petrov, Leon Barrett, Romain Thibaux, and Dan Klein. 2006. Learning accurate, compact, and interpretable tree annotation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Horacio Saggion</author>
<author>Guy Lapalme</author>
</authors>
<title>Generating indicative-informative summaries with SumUM.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>4</issue>
<contexts>
<context position="6818" citStr="Saggion and Lapalme, 2002" startWordPosition="1074" endWordPosition="1078">ce enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised algorithm, as discussed above. Previous studies on cut-and-paste summarization (Jing and McKeown, 2000; Saggion and Lapalme, 2002) investigate the operations that human summarizers perform on the source text in order to produce the summary text. Our previous work argued that current extractive systems rely too heavily on notions of information centrality (Cheung and Penn, 2013). This paper extends this work by identifying specific linguistic factors correlated with the use of source-text-external elements. 3 A Sentence Enhancement Algorithm The basic steps in our sentence expansion algorithm are as follows: (1) clustering to identify initial input sentences, (2) sentence graph creation, (3) sentence graph expansion, (4) </context>
</contexts>
<marker>Saggion, Lapalme, 2002</marker>
<rawString>Horacio Saggion and Guy Lapalme. 2002. Generating indicative-informative summaries with SumUM. Computational Linguistics, 28(4):497–526.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kapil Thadani</author>
<author>Kathleen McKeown</author>
</authors>
<title>Supervised sentence fusion with single-stage inference.</title>
<date>2013</date>
<journal>Asian Federation of Natural Language Processing.</journal>
<booktitle>In Proceedings of the Sixth International Joint Conference on Natural Language Processing,</booktitle>
<pages>1410--1418</pages>
<location>Nagoya, Japan,</location>
<contexts>
<context position="1434" citStr="Thadani and McKeown, 2013" startWordPosition="206" endWordPosition="209">better in terms of grammaticality, and that the benefit of sentence enhancement relies crucially on an event coreference resolution algorithm using distributional semantics. We also consider how text-to-text generation approaches to summarization can be extended beyond the source text by examining how human summary writers incorporate source-text-external elements into their summary sentences. 1 Introduction Sentence fusion is the technique of merging several input sentences into one output sentence while retaining the important content (Barzilay and McKeown, 2005; Filippova and Strube, 2008; Thadani and McKeown, 2013). For example, the input sentences in Figure 1 may be fused into one output sentence. As a text-to-text generation technique, sentence fusion is attractive because it provides an avenue for moving beyond sentence extraction in automatic summarization, while not requiring deep seInput: Bil Mar Foods Co., a meat processor owned by Sara Lee, announced a recall of certain lots of hot dogs and packaged meat. Input: The outbreak led to the recall on Tuesday of 15 million pounds of hot dogs and cold cuts produced at the Bil Mar Foods plant. Output: The outbreak led to the recall on Tuesday of lots of</context>
<context position="6162" citStr="Thadani and McKeown, 2013" startWordPosition="977" endWordPosition="980">eneration techniques move beyond using local contexts towards more dramatic reformulations of the kind that human writers perform, more semantic analysis will be needed in order to ensure that the reformulations preserve the inferences that can be drawn from the input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised algorithm, as discussed above. Previous studies on cut-and-paste summariza</context>
<context position="23537" citStr="Thadani and McKeown (2013)" startWordPosition="3843" endWordPosition="3847">oducing a passive construction if only a direct object is selected, but this is one possible extension of the algorithm. were a dependent node with a special syntactic relation label self. This algorithm always produces an output ordering with a projective dependency tree, which is a reasonable assumption for English. 4 Experiments 4.1 Method Recent approaches to sentence fusion have often been evaluated as isolated components. For example, F&amp;S evaluate the output sentences by asking human judges to rate the sentences’ informativeness and grammaticality according to a 1–5 Likert scale rating. Thadani and McKeown (2013) combine grammaticality ratings with an automatic evaluation which compares the system output against gold-standard sentences drawn from summarization data sets. However, this evaluation setting still does not reflect the utility of sentence fusion in summarization, because the input sentences come from human-written summaries rather than the original source text. We adopt a more realistic setting of using sentence fusion in automatic summarization by drawing the input or core sentences automatically from the source text, then evaluating the output of the fusion and expansion algorithm directl</context>
</contexts>
<marker>Thadani, McKeown, 2013</marker>
<rawString>Kapil Thadani and Kathleen McKeown. 2013. Supervised sentence fusion with single-stage inference. In Proceedings of the Sixth International Joint Conference on Natural Language Processing, pages 1410– 1418, Nagoya, Japan, October. Asian Federation of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Tratz</author>
<author>Eduard Hovy</author>
</authors>
<title>Summarization evaluation using transformed Basic Elements.</title>
<date>2008</date>
<booktitle>In Proceedings of the First Text Analysis Conference (TAC).</booktitle>
<contexts>
<context position="25692" citStr="Tratz and Hovy (2008)" startWordPosition="4184" endWordPosition="4187">ment, and r is the syntactic relation, normalized for grammatical voice and excluding the collapsed edges which are mostly noun-phrase-internal elements and grammatical 780 Method Pyramid BE ROUGE-1 ROUGE-2 Log Likelihood Oracle Pyramid BE Fusion (F&amp;S) 10.61 10.07 2.15 -159.31 28.00 Expansion 8.82 9.41 1.82 -157.46 52.97 +Event coref 11.00 9.76 1.93 -156.20 40.30 Table 1: Results of the sentence enhancement and fusion experiments. particles. Then, we perform a matching between the set of triples in the sentence under evaluation and in a reference summary following the Transformed BE method of Tratz and Hovy (2008) with the total weighting scheme. This matching is performed between the sentence and every gold-standard summary, and the maximum of these scores is taken. This score is then divided by the maximum score that is achievable using the number of triples present in the input sentence, as inspired by the Pyramid method. This denominator is more appropriate than the one used in Transformed BE, which is designed for the case where the evaluated summary and the reference summaries are of comparable length. For grammaticality, we parse the output sentences using the Stanford parser5, and use the log l</context>
</contexts>
<marker>Tratz, Hovy, 2008</marker>
<rawString>Stephen Tratz and Eduard Hovy. 2008. Summarization evaluation using transformed Basic Elements. In Proceedings of the First Text Analysis Conference (TAC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Patrick Pantel</author>
</authors>
<title>From frequency to meaning: Vector space models of semantics.</title>
<date>2010</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>37--141</pages>
<contexts>
<context position="17674" citStr="Turney and Pantel, 2010" startWordPosition="2868" endWordPosition="2872">2012). For sim1, we create a vector of counts of the arguments that are seen filling each (h, r) pair, and define the similarity between two such pairs to be the cosine similarity between their argument vectors. For sim2, we create a basic vector-space representation of a word d according to words that are found in the context of word d within a five-word context window, and likewise compute the cosine similarity between the word vectors. These methods of computing distributional similarity are well attested in lexical semantics for measuring the relatedness of words and syntactic structures (Turney and Pantel, 2010), and similar methods have been applied in text-to-text generation by Ganitkevitch et al. (2012), though the focus of that work is to use paraphrase information thus learned to improve sentence compression. The resulting graph matching problem is solved using the NetworkX package for Python3. The final similarity score is an average of the similarity scores from Equation 1 that participate in the selected matching, weighted by the product of the IDF scores of the dependent nodes of each edge. This final score is used as a threshold that candidate contexts from the source text must meet in orde</context>
</contexts>
<marker>Turney, Pantel, 2010</marker>
<rawString>Peter D. Turney and Patrick Pantel. 2010. From frequency to meaning: Vector space models of semantics. Journal of Artificial Intelligence Research, 37:141–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wagner</author>
<author>Jennifer Foster</author>
<author>Josef van Genabith</author>
</authors>
<title>Judging grammaticality: Experiments in sentence classification.</title>
<date>2009</date>
<journal>CALICO Journal,</journal>
<volume>26</volume>
<issue>3</issue>
<marker>Wagner, Foster, van Genabith, 2009</marker>
<rawString>Joachim Wagner, Jennifer Foster, and Josef van Genabith. 2009. Judging grammaticality: Experiments in sentence classification. CALICO Journal, 26(3):474–490.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Wan</author>
<author>Robert Dale</author>
<author>Mark Dras</author>
<author>Cecile Paris</author>
</authors>
<title>Seed and grow: Augmenting statistically generated summary sentences using schematic word patterns.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>543--552</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="6416" citStr="Wan et al. (2008)" startWordPosition="1018" endWordPosition="1021">input text. 2 Related Work A relatively large body of work exists in sentence compression (Knight and Marcu, 2000; McDonald, 2006; Galley and McKeown, 2007; Cohn and Lapata, 2008; Clarke and Lapata, 2008, inter alia), and sentence fusion (Barzilay and McKeown, 2005; Marsi and Krahmer, 2005; Filippova and Strube, 2008; Filippova, 2010; Thadani and McKeown, 2013). Unlike this work, our sentence enhancement algorithm considers the entire source text and is not limited to the initial input sentences. Few previous papers focus on combining the content of diverse sentences into one output sentence. Wan et al. (2008) propose sentence augmentation by identifying “seed” words in a single original sentence, then adding information from auxiliary sentences based on word co-occurrence counts. Elsner and Santhanam (2011) investigate the idea of fusing disparate sentences with a supervised algorithm, as discussed above. Previous studies on cut-and-paste summarization (Jing and McKeown, 2000; Saggion and Lapalme, 2002) investigate the operations that human summarizers perform on the source text in order to produce the summary text. Our previous work argued that current extractive systems rely too heavily on notio</context>
</contexts>
<marker>Wan, Dale, Dras, Paris, 2008</marker>
<rawString>Stephen Wan, Robert Dale, Mark Dras, and Cecile Paris. 2008. Seed and grow: Augmenting statistically generated summary sentences using schematic word patterns. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 543–552, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>