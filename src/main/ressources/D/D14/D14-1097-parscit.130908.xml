<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000031">
<title confidence="0.999541">
An Experimental Comparison of Active Learning Strategies for
Partially Labeled Sequences
</title>
<author confidence="0.787548">
Diego Marcheggiani Thierry Arti`eres
</author>
<affiliation confidence="0.319486">
Istituto di Scienza e Tecnologie dell’Informazione LIP6
</affiliation>
<author confidence="0.559943">
Consiglio Nazionale delle Ricerche Pierre et Marie Curie University
</author>
<affiliation confidence="0.807158">
Pisa, Italy Paris, France
</affiliation>
<email confidence="0.991548">
diego.marcheggiani@isti.cnr.it thierry.artieres@lip6.fr
</email>
<sectionHeader confidence="0.993625" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999445411764706">
Active learning (AL) consists of asking human
annotators to annotate automatically selected
data that are assumed to bring the most bene-
fit in the creation of a classifier. AL allows to
learn accurate systems with much less anno-
tated data than what is required by pure super-
vised learning algorithms, hence limiting the
tedious effort of annotating a large collection
of data.
We experimentally investigate the behav-
ior of several AL strategies for sequence
labeling tasks (in a partially-labeled sce-
nario) tailored on Partially-Labeled Condi-
tional Random Fields, on four sequence la-
beling tasks: phrase chunking, part-of-speech
tagging, named-entity recognition, and bio-
entity recognition.
</bodyText>
<sectionHeader confidence="0.998995" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999931">
Today, the state-of-the-art methods in most natural lan-
guage processing tasks are supervised machine learn-
ing approaches. Their main problem lies in their need
of large human-annotated training corpus, which re-
quires a tedious and expensive work from domain ex-
perts. The process of active learning (AL) employs one
or more human annotators by asking them to label new
samples which are supposed to be the most informa-
tive in the creation of a new classifier. A classifier is
incrementally retrained with all the data labeled by the
annotator. AL has been demonstrated to work well and
to produce accurate classifiers while saving much hu-
man annotation effort. One critical issue is to define
a measure of the informativeness which should reflect
how much new information a new example would give
in the learning of a new classifier once annotated.
A lot of work has been done on the AL field in
the past years (see (Settles, 2012) for an exhaustive
overview). In particular, AL proved its usefulness in se-
quence labeling tasks (Settles and Craven, 2008). Yet,
researchers have always adopted as annotation unit an
entire sequence (i.e., the annotator is asked to anno-
tate the whole sequence) while it looks like it could be
much more relevant to ask for labeling only small parts
of it (e.g., the ones with highest ambiguity). A few
works have investigated this idea. For instance, Wan-
varie et al. (2011) proposed to use Partially-Labeled
Conditional Random Fields (PL-CRFs) (Tsuboi et al.,
2008), a semi-supervised variation of Conditional Ran-
dom Fields (CRFs) (Lafferty et al., 2001) able to deal
with partially-labeled sequences, thus enabling to adopt
as annotation unit single tokens and still learning from
full sequences. AL with partially labeled sequences
has proven to be effective in substantially reducing the
amount of annotated data with respect to common AL
approaches (see (Wanvarie et al., 2011)).
In this work we focus on AL strategies for partially
labeled sequences adopting the single token as annota-
tion unit and PL-CRFs as learning algorithm given its
nature in dealing with partially labeled sequences. We
propose several AL strategies based on measures of un-
certainty adapted for the AL with partially labeled se-
quences scenario and tailored on PL-CRFs. We further
propose two strategies that exploit the finer granularity
given by the partially-labeled scenario. We also show
that the choice of single-token annotation can bring
to unpredictable results on sequence labeling tasks in
which the structure of the sequences is not regular, e.g.,
named-entity recognition. We propose a first solution
to the problem of unpredictability. The aim of this
work is thoroughly compare the effectiveness and the
behavior of all the proposed AL strategies on four stan-
dard sequence labeling tasks, phrase chunking, part-
of-speech tagging, named-entity recognition and bio-
entity recognition.
The remainder of this paper is as follows. In Sec-
tion 2 we summarize the related work in AL, in Sec-
tion 3 we describe PL-CRFs, the semi-supervised al-
gorithm we adopt in this work. Section 4 describes
in details the AL framework and the AL strategies we
propose. Section 5 provides a description of the experi-
mental setting, the datasets, and discusses the empirical
results. Section 6 summarizes our findings.
</bodyText>
<sectionHeader confidence="0.999853" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999788333333333">
Our work belongs to the pool-based AL framework. It
considers the case in which a large amount (pool) of
unlabeled examples is available, from which samples
to be labeled must be chosen. This framework fits all
the sequence labeling problems we consider here. For
a more exhaustive survey on other AL frameworks see
</bodyText>
<page confidence="0.970144">
898
</page>
<note confidence="0.928137">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 898–906,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9887804375">
(Settles, 2012).
Most of the AL works on sequence labeling adopted
the entire sequence as annotation unit (Settles and
Craven, 2008) which was demonstrated by Wanvarie
et al. (2011) to be less effective than using the single
token as annotation unit. The main AL works in this
latter line of work are (Shen et al., 2004), (Tomanek
and Hahn, 2009) and (Wanvarie et al., 2011). Shen
et al. (2004) adopted SVMs as learning algorithm and
proposed two strategies that combine three criteria, in-
formativeness, representativeness and diversity. SVMs
allowed them to use as annotation unit a subset of the
tokens in a sequence, without annotating, in any way,
the rest of the tokens in the sequence. In (Tomanek and
Hahn, 2009), the most uncertain tokens of the sequence
are singularly annotated, but the rest of the labels in the
sequence are then chosen by the classifier in a semi-
supervised fashion. Wanvarie et al. (2011) is the clos-
est work to ours, they adopt a minimum confidence se-
lection strategy with re-estimation using the PL-CRFs.
Differently from our work, Wanvarie et al. (2011) show
that adopting the AL with partially labeled sequences
using re-estimation, the annotation cost can be dramat-
ically reduced (by annotating from 8% to 10% of the
tokens of the entire training set), obtaining the same
level of performance of the classifier trained on the en-
tire, fully-labeled, training set. We started our work
from this conclusion and we focused on AL with par-
tially labeled sequences using re-estimation by compar-
ing several AL strategies in order to find the strategy
that allows to create the best classifier with the mini-
mum annotation effort.
</bodyText>
<sectionHeader confidence="0.74967" genericHeader="method">
3 Partially-Labeled
Conditional Random Fields
</sectionHeader>
<bodyText confidence="0.998888583333333">
PL-CRFs introduced by Tsuboi et al. (2008) allow to
learn a CRF model using partially-labeled sequences,
marginalizing on those tokens that do not have an as-
signed label. In PL-CRFs, L denotes a partially labeled
information about a sequence. It consists of a sequence
of sets Lt in which Lt = Y (where Y is the set of all
the possible labels) if there is no label information for
token at time t. Lt is a singleton containing yt if the
label of the token at time t is known, and YL is the set
of label sequences that fits the partial label information
L. Then the probability of a partial labeling may be
computed as:
</bodyText>
<equation confidence="0.9898545">
p(YL|x) = X p(y|x) (4)
YEYL
</equation>
<bodyText confidence="0.999809666666667">
In order to perform inference and parameter learning
on PL-CRFs, some modifications on traditional CRFs
inference algorithms are required.
</bodyText>
<subsectionHeader confidence="0.975926">
3.1 Forward-Backward Algorithm
</subsectionHeader>
<bodyText confidence="0.997100333333333">
Differently from traditional CRFs, the forward and
backward scores (respectively α and β), are calculated
as follows:
</bodyText>
<equation confidence="0.967001833333333">
0 if j E� Lt
T1(j, y0, x1) else if t = 1
and j ELt
SA(j) otherwise
0 if j E� Lt
1 else if t = T
</equation>
<bodyText confidence="0.595723333333333">
and j ELt
SB(j) otherwise
where
</bodyText>
<equation confidence="0.974139">
⎧
⎨⎪⎪
⎪⎪⎩
αt,L(j) =
βt,L(i) =
⎧
⎨⎪⎪
⎪⎪⎩
</equation>
<bodyText confidence="0.9993408">
Nowadays, CRFs are the de-facto standard for the so-
lution of sequence labeling tasks (Sarawagi, 2008). In
traditional CRFs (Lafferty et al., 2001) the conditional
probability of a sequence of labels y given a sequence
of observed feature vectors x is given by:
</bodyText>
<equation confidence="0.999885875">
SA(j) = X αt−1,L(i)Tt(j, i, xt) (7)
iELt−1
SB(j) = X βt+1,L(j)Tt+1(j, i, xt+1) (8)
jELt+1
p(y|x) = Z(x) YTt(y,x) (1)
1
t=1
T
</equation>
<bodyText confidence="0.9876335">
where a standard choice for sequence labeling tasks are
the so called Linear-chain CRFs:
</bodyText>
<equation confidence="0.990687714285714">
YT
1
p(y|x) = Tt(yt, yt−1, xt) (2)
Z(x)
t=1
with:
Tt(yt,yt−1,xt) = Tu(yt,xt)Tb(yt,yt−1) (3)
</equation>
<bodyText confidence="0.991122333333333">
where Tu(yt,xt) models the co-occurrence between
features xt, and label yt at time t, and Tb(yt, yt−1)
models the co-occurrence between two adjacent labels
yt and yt−1.
and y0 is a special label that encodes the beginning of
a sequence.
</bodyText>
<subsectionHeader confidence="0.99933">
3.2 Marginal Probability
</subsectionHeader>
<bodyText confidence="0.958368">
The marginal probability p(yt = j|x, L) is calculated
as:
</bodyText>
<equation confidence="0.9879272">
p(yt = j |) — αt,L(j) - βt,L(j) (9)
x, L _ ZL(x)
with:
dt, ZL(x) = X αt,L(j) - βt,L(j) (10)
jELt
</equation>
<bodyText confidence="0.9999615">
In case there is no label information, the formulas for
forward and backward scores (Equations (5) and (6))
and for the marginal probabilities (Equation (9)) yield
the standard results of CRFs.
</bodyText>
<page confidence="0.997802">
899
</page>
<subsectionHeader confidence="0.996496">
3.3 Viterbi Algorithm
</subsectionHeader>
<bodyText confidence="0.999628666666667">
The most probable sequence assignment may be de-
rived with a Viterbi algorithm by recursively comput-
ing the following quantities:
</bodyText>
<equation confidence="0.7413795">
0 if j E� Lt (11)
Ψ1(j, y0, x1) else if t = 1
and j ELt
M(j) otherwise
</equation>
<bodyText confidence="0.756001">
where
</bodyText>
<equation confidence="0.959823818181818">
M(j) = max
i∈Lt−1 6t−1,L(i)Ψt(j,i,xt) (12)
The most probable assignment is then calculated as:
y∗ = argmaxyp(y|x, L)
3.4 Log-Likelihood
PL-CRFs’s parameters 0 are learnt through maximum
log-likelihood estimation, that is to maximize the log-
likelihood function LL(0):
log p(YL(i)|x(i))
(13)
log ZYL(i) (x(i)) − log ZY(x(i))
</equation>
<bodyText confidence="0.998962666666667">
The parameters 0 that maximize Equation (13) are
computed via the LBFGS optimization method (Byrd
et al., 1994).
</bodyText>
<sectionHeader confidence="0.983701" genericHeader="method">
4 Active Learning Strategies
</sectionHeader>
<bodyText confidence="0.9989254375">
Pool-based AL (see (Lewis and Catlett, 1994)) is prob-
ably the most common scenario in AL, where one has
a large amount (pool) of unlabeled examples U1 and a
small amount of labeled examples T1. In this scenario,
the process of AL consists in a series of n iterations
where a classifier Φi is trained with labeled examples
Ti, and then is used to classify the unlabeled examples
Ui. At this point an AL strategy S will select a number
of examples B that once labeled will hopefully improve
the performance of the next classifier Φi+1.
Algorithm 1 shows the pool-based AL framework
for partially annotated sequences as introduced in
(Wanvarie et al., 2011). Differently from AL for fully
labeled sequences (Esuli et al., 2010), thanks to the
finer granularity of the partially labeled model, we use
the token as basic annotation unit, instead of the entire
sequence.
The point of using the partial labeling is in saving the
request for human annotations on tokens whose labels
are already known (inferred) by the classifier and con-
centrate on those tokens that the classifier finds hard to
label. Using the semi-supervised approach of the PL-
CRFs we can take advantage of single-labeled tokens
instead of an entire labeled sequence.
The entire pool-based AL process with partially la-
beled sequences is summarized in Algorithm 1. The
Algorithm 1 Pool-based active learning framework
Require: T1, the initial training set
U1, the initial unlabeled set
S, the selected AL strategy
n, the number of iterations
B, the dimension of the update batch
</bodyText>
<listItem confidence="0.998670307692308">
1: for i ← 1 to n do
2: Φi ← train(Ti)
3: Li ← Φi(Ui)
4: for b ← 1 to B do
x(b)
5: ∗ ← arg minxt∈x,x∈Li S(t, x)
6: Li ← Li − x(b) ∪ Φi(x(b), y∗)
∗ ∪ (x(b)
7: Ui ← Ui − x(b) ∗ , y∗)
∗ ∪ (x(b)
8: Ti ← Ti − x(b) ∗ , y∗)
9: Ui+1 ← Ui
10: Ti+1 ← Ti
</listItem>
<bodyText confidence="0.997388365853658">
function S(t, x) is what, hereafter, we call an AL strat-
egy. S(t,x) takes as input an automatically annotated
sequence x and an element t of this sequence, from the
set of sequences Li annotated by the PL-CRF classi-
fier Φi, and returns a measure of informativeness as a
function of the classifier decision.
For each iteration through the update batch B, the
most informative element x(b)
∗ , according to the AL
strategy, is chosen. The subscript ∗, in this case, repre-
sents the most informative token, while the superscript
(b) represents the sequence in which the token appears.
After the choice of the most informative token the sets
Li, Ui and Ti are updated. Li is updated by remov-
ing the annotated sequence x(b) and all the informa-
tion given by the classifier, and by adding the same se-
quence with the new manually labeled token (y∗) and
all the re-estimated annotation given by the classifier
Φi(x(b), y∗). In the unlabeled set Ui and the training
set Ti the most informative token x(b)
∗ is updated with
its manually labeled version (x(b)
∗ ,y∗)1. After B token
annotations, the unlabeled set and the training set for
the next iteration, respectively Ui+1 and Ti+1, are up-
dated.
The inference methods of Section 3 allow not only
to train a CRF model with partially labeled sequences,
but give the possibility of classifying partially labeled
sequences, using the known labels as support for the
prediction of the other ones. Thus, in this AL scenario,
each time a token is chosen it is immediately labeled,
and this new information, as we can see from line 6 of
Algorithm 1, is promptly used to re-estimate the infor-
mativeness of the other tokens in the sequence in which
the chosen token appears.
One may argue that, for a human annotator, anno-
1In order to have a light notation we omit the fact that
when the most informative token is the first annotated token
of a sentence, the whole sentence, with just one annotated
token, is added to the training set Ti
</bodyText>
<equation confidence="0.999186285714286">
6t,L(j) = I
N
LL(0) =
i=1
N
=
i=1
</equation>
<page confidence="0.884824">
900
</page>
<bodyText confidence="0.999973818181818">
tating only one or few tokens, instead of the entire se-
quence, is a difficult task. This would be correct in
the scenario in which the text is presented to the hu-
man annotator without any visual clue about the an-
notations. However, in (Culotta and McCallum, 2005)
it is shown that presenting to the human annotator the
highlighted sequence to be annotated along with the as-
sociated sequence of labels obtained by the classifier
requires much less effort from the annotator than per-
forming the annotation without any visual and contex-
tual clue.
</bodyText>
<subsectionHeader confidence="0.998491">
4.1 Greedy Strategies
</subsectionHeader>
<bodyText confidence="0.999987333333333">
In this section we present three AL strategies that select
the most informative tokens, regardless of the assign-
ment performed by the Viterbi algorithm. The ratio-
nale behind these strategies is that, even though we are
looking for the most probable sequence assignment, we
also want to annotate the most informative tokens sin-
gularly.
The Minimum Token Probability (MTP) strategy
employs as measure of informativeness the probability
of the most probable assignment at time t. This strategy
greedily samples the tokens whose highest probability
among the labels is lowest.
</bodyText>
<equation confidence="0.9902225">
SMTP(t, x) = max p(yt = j|x, L) (14)
j∈Y
</equation>
<bodyText confidence="0.9997366">
The Maximum Token Entropy (MTE) strategy relies
on the entropy measure to evaluate the ambiguity about
the label of a token. The rationale of it is that, if more
than one label have the same assigned marginal proba-
bility, the entropy will be high, that is,
</bodyText>
<equation confidence="0.988408333333333">
SMTE(t, x) =
11 p(yt = j|x, L) · logp(yt = j|x, L) (15)
j∈Y
</equation>
<bodyText confidence="0.9997485">
In order to directly plug the SMT E strategy into the AL
framework of Algorithm 1, we removed the minus sign
at the beginning of the entropy formula. This allow
us to use the min operator with a maximum entropy
approach.
The Minimum Token Margin (MTM) strategy is
a variant of the margin sampling strategy introduced
in (Scheffer et al., 2001). It calculates the informative-
ness by considering the two most probable assignments
and by subtracting the highest probability by the low-
est. With max0 that calculates the second maximum
value, MTM is defined as:
</bodyText>
<equation confidence="0.939932">
SMTM(t, x) =
16)
max p(yt =j |x, L) − max0p(yt = j |x, L) (
j∈Y j∈Y
</equation>
<subsectionHeader confidence="0.982555">
4.2 Viterbi Strategies
</subsectionHeader>
<bodyText confidence="0.999961">
The following AL strategies take into consideration the
most probable sequence assignments obtained from the
Viterbi algorithm computed on already known labels in
the sequence.
The rationale is that, with these strategies, the mea-
sure of uncertainty is chosen according to the informa-
tion obtained from the outcome of the Viterbi algorithm
(i.e., the most probable sequence assignment).
The Minimum Viterbi Probability (MVP) is the
base strategy adopted in (Wanvarie et al., 2011). It
takes as measure of informativeness the probability of
the label chosen by the Viterbi algorithm.
</bodyText>
<equation confidence="0.943529">
SMV P(t, x) = p(y∗t |x, L) (17)
</equation>
<bodyText confidence="0.995673714285714">
where y∗t is the label assignment chosen by the Viterbi
algorithm. In general, the token assignments that max-
imize the probability of the sequence assignment y∗t
are different from the token assignments that maxi-
mize the probability of the individual token assign-
ments argmaxj∈Yp(yt = j).
The Maximum Viterbi Pseudo-Entropy (MVPE)
strategy calculates for each token the “pseudo” entropy
of the most probable sequences at the variation of the
label at position t. The prefix pseudo is used because
even though it is calculated as an entropy, the summa-
tion is over all the possible labels that can be associated
to a token, and not all the possible sequence assign-
ments.
</bodyText>
<equation confidence="0.998408333333333">
SMV PE(t, x) =
E p(y∗yt=j|x, L) · log p(y∗yt=j|x, L) (18)
j∈Y
</equation>
<bodyText confidence="0.999657583333333">
where y∗yt=j represents the most probable assignment
with the label at time t constrained to the value j. As
in the MTE strategy the minus sign is removed in order
to plug the functions directly into the AL framework of
Algorithm 1.
The Minimum Viterbi Margin (MVM) strategy
calculates the difference of the sequence probabili-
ties of the two most probable sequence assignments
at the variation of the label at time t. When the dif-
ference at time t is low, the Viterbi algorithm, in that
time, chooses between two almost equally probable, se-
quence assignments. Formally:
</bodyText>
<equation confidence="0.9975795">
SMV M(t, x) = p(y∗ t |x, L) (19)
y∗ t |x, L) − p(y0∗ y�∗
</equation>
<bodyText confidence="0.9948698">
where y0∗ is the second most probable assignment.
PL-CRFs allow us to inspect one token at time in or-
der to decide if it is worth to annotate. This fact give
us the possibility of exploit two quantities in order to
estimate the informativeness of a token, the sequence
probability, usually adopted in the traditional AL for
sequence labeling, and the marginal probabilities of the
single tokens as in Section 4.1. The Minimum Expec-
tation (ME) strategy combines the marginal probabili-
ties, p(yt = j|x, L) and p(y∗yt=j|x, L).
</bodyText>
<equation confidence="0.990352">
�SME(t,x) = p(yt = j|x, L) · p(y∗yt=j|x, L)
j∈Y
(20)
</equation>
<page confidence="0.945183">
901
</page>
<bodyText confidence="0.999519888888889">
Here the maximum sequence probability is seen as a
function, and what we calculate is the expected value of
this very function. The rationale of this strategy is pick-
ing those tokens in which both, the sequence probabil-
ity returned by the Viterbi algorithm, and the marginal
probability of the considered labels are low.
Given that the ME strategy gives a high weight to
the sequence probability, one might expect that tokens
that belongs to longer sequences are selected more fre-
quently, given that, the sequence probability of longer
sequences is usually lower than shorter ones. One way
to normalize this difference is subtracting the current
maximum sequence probability, that is, the maximum
sequence probability calculated without any new label
estimation, to the expected value obtained from the es-
timation of the label assignment of the token. This is
the Minimum Expectation Difference (MED) strat-
egy.
</bodyText>
<equation confidence="0.900105">
SMED(t, x) = SME(t, x) − p(y∗|x, L) (21)
</equation>
<bodyText confidence="0.999901416666667">
The rationale of this strategy is that when the expected
value is far from the maximum value, that is the value
returned by the Viterbi algorithm, it means that we have
uncertainty on the token taken into consideration.
The Random (RAND) strategy samples random to-
kens without any external information. It is used as
baseline to compare the real effectiveness of the pro-
posed strategy.
At the best of our knowledge the strategies presented
in this section (with the exception of the MVP strategy)
have never been applied in the context of AL with par-
tially labeled sequences scenario.
</bodyText>
<sectionHeader confidence="0.999488" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.775107">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999841777777778">
We have experimented and evaluated the AL strate-
gies of Section 4 on four sequence labeling tasks,
part-of-speech tagging, phrase chunking, named-entity
recognition and bio-entity recognition. We used the
CoNLL2000 dataset (Tjong Kim Sang and Buchholz,
2000) for the phrase chunking task, the CoNLL2003
dataset (Tjong Kim Sang and De Meulder, 2003),
for the named-entity recognition task, the NLPBA2004
dataset (Kim et al., 2004), for the biomedical entity
recognition task and the CoNLL2000POS dataset2 for
the part-of-speech labeling task. All the datasets are
publicly available and are standard benchmarks in se-
quence labeling tasks. Table 1 shows some statistics of
the datasets in terms of dimensions, number of labels,
distribution of the labels, etc. The data heterogeneity of
the different datasets allowed us to test the AL strate-
gies on different “experimental settings”, thus to have
a more robust empirical evaluation.
</bodyText>
<footnote confidence="0.9429525">
2This is the CoNLL2000 dataset annotated with part-of-
speech labels instead of chunking labels.
</footnote>
<subsectionHeader confidence="0.994033">
5.2 Experimental Setting
</subsectionHeader>
<bodyText confidence="0.999989166666667">
We tested the AL strategies described in Section 4
on test sets composed by 2012 sequences and 47377
tokens for the CoNLL2000 and CoNLL2000POS
datasets, by 3452 sequences and 46394 tokens for
the CoNLL2003 dataset and by 3856 sequences and
101039 tokens for the NLPBA2004 dataset. We
chose an initial training set T1 of —5 sequences on
CoNLL2000 and CoNLL2000POS datasets, —7 se-
quences on CoNLL2003 dataset and —4 sequences on
NLPBA2004 dataset, for a total of —100 labeled tokens
for each dataset. The dimension of the batch update B
has been chosen as a trade-off between an ideal case in
which the system is retrained after every single anno-
tation (i.e., B = 1) and a practical case with higher B
to limit the algorithmic complexity (since the PL-CRF
classifier must be retrained every iteration). We used in
our experiments B = 50. We fixed the number of AL
iterations n at 40 because what matters here is how the
strategies behave in the beginning of AL process when
the annotation effort remains low. For each strategy
and for each dataset, we report averaged results of three
runs with a different randomly sampled initial training
set T1.
For each dataset we adopted a standard set of fea-
tures. For the CoNLL2000 dataset we adopted the same
standard features used in (Wanvarie et al., 2011) for the
same dataset, for the CoNLL2003 and the NLPBA2004
dataset we adopted the features used in (Wanvarie et
al., 2011) for the CoNLL2003 dataset, while for the
CoNLL2000POS dataset we used the features pre-
sented in (Ratnaparkhi, 1996). As evaluation measure
we adopted the token variant of the F1 measure, intro-
duced by Esuli and Sebastiani (2010). This variant, in-
stead of the entire annotation (chunk/entity), calculates
TPs, FPs, and FNs, singularly for each token that
compose the annotation, bringing to a finer evaluation.
</bodyText>
<subsectionHeader confidence="0.558285">
5.3 Results
</subsectionHeader>
<bodyText confidence="0.999975684210526">
From the learning curves of Figure 1 and Figure 2 it
is clear that most of the strategies have the same trend
throughout the different datasets. This results is some-
what different from the results obtained in (Settles and
Craven, 2008) in which there is not a clear winner
among the strategies they proposed in a fully-labeled
scenario. The strategies that perform particularly bad
(worse than the RAND strategy in CoNLL2000POS
and in CoNLL2003 dataset) in all the datasets are the
MTE and MTP. This is expected, because the choice
of the measure of informativeness related to the token
without taking in consideration the Viterbi path is sub-
optimal in this task. Surprisingly, the MTM strategy
even though based on the same principle of MTE and
MTP, is very effective in most of the datasets. The
most effective strategies, that is, the ones that are the
faster at helping the classifier to reach a better accu-
racy are the MTM, MVM, and MVP, in particular the
margin-based strategies perform very good in all the
</bodyText>
<page confidence="0.997517">
902
</page>
<tableCaption confidence="0.983188">
Table 1: Training Data Statistics. #S is the number of total sequences in the dataset, #T is the number of tokens
</tableCaption>
<bodyText confidence="0.9952526">
in the dataset, #L is the number of positive labels (labels different from the negative label 0), AAL is the average
length, in tokens, of annotations (sequence of tokens that refer to the same instance of a label), APT is the average
number of token in a sequence annotated with a positive label, ASL is the average length of a sequence, AA is the
average number of annotations in a sequence, %AC is the percentage of sequences with more than one positive
annotation, %DAC is the percentage of sequences that have two or more annotations with different labels.
</bodyText>
<table confidence="0.8193382">
Dataset #S #T #L AAL APT ASL AA %AC %DAC
CoNLL2000 8936 211727 11 1.6 20.6 24 12.0 98% 98%
CoNLL2000POS 8936 211727 35 1.0 20.8 24 20.8 100% 99%
CoNLL2003 17290 254979 4 1.4 2.5 15 2.2 45% 32%
NLPBA2004 18546 492551 5 2.5 5.9 27 3.1 72% 47%
</table>
<figureCaption confidence="0.995492">
Figure 1: Fl results on CoNLL2000 dataset (left) and CoNLL2000POS dataset (right). For both datasets the
maximum number of annotated tokens used (2100) represents ∼1% of the entire training set.
</figureCaption>
<figure confidence="0.999467757575757">
0 500 1000 1500 2000
number annotated tokens
0 500 1000 1500 2000
number annotated tokens
0.95
0.90
0.85
0.80
0.75
MTP
MTE
MTM
MVP
MVPE
MVM
ME
MED
RAND
F1
0.9
0.8
0.6
0.7
0.5
MTP
MTE
MTM
MVP
MVPE
MVM
ME
MED
RAND
</figure>
<bodyText confidence="0.999865552631579">
datasets. The MVPE strategy performs particularly bad
in the CoNLL2003 dataset but it performs better than
the RAND strategy in the other datasets. The perfor-
mance of the ME strategy is always above the aver-
age, in particular it is the best performing strategy in
the NLPBA2004 dataset. However, in the CoNLL2003
dataset its performance is similar to the RAND’s per-
formance. Looking at the data, as expected, ME tends
to choose tokens belonging to the longest sequences,
regardless if the sequence is already partially anno-
tated, that is, it tends to choose tokens from the same
sequences. This behavior is not particularly relevant on
the CoNLL2003 dataset given that the average num-
ber of positive tokens per sentence is not high (2.5,
see Table 1). For the other datasets, the average num-
ber of positive tokens per sentence is high, and so
the ME strategy is particularly effective. The MED
strategy has the most heterogeneous behavior among
the datasets. It shows average performances in the
CoNLL2000 dataset and NLPBA2004 dataset, but is
slower than the RAND strategy in the CoNLL2003 and
CoNLL2000POS datasets.
In Figure 2 (left) we can notice that there are some
strategies that are consistently worse than the RAND
strategy. The difference between the strategies below
the RAND strategy and the RAND strategy itself might
be due to the fact that those strategies ask to label to-
kens that are “outliers” (if we imagine tokens as points
of the features space) that rarely appear in the training
and test set, and on which the classifier is very uncer-
tain. Given that we are in a semi-supervised setting,
with very few training examples, these “outliers” can
introduce a lot of noise in the created models and so
yielding poor results. This phenomenon does not hap-
pen in the RAND strategy given that it samples uni-
formly from the unlabeled set and given that the “out-
liers” (special cases) are not many, the probability of
randomly selecting an “outlier” is low.
</bodyText>
<subsubsectionHeader confidence="0.504197">
5.3.1 Performance Drop
</subsubsectionHeader>
<bodyText confidence="0.9999469">
The AL strategies applied on the CoNLL2003 dataset
(Figure 2 (left)) suffer of some “random” drop of per-
formance. We believe that the first reason that yield
such a behavior is that named entities often appear once
in a sentence, and have heterogeneous structures with
respect to some homogenous structures as the chunk
and POS. The second reason is that, it may happen that
the strategies are not accurate enough to localize pre-
cisely the best token to label or that getting the label
of an isolated token does not help the classifier much
</bodyText>
<page confidence="0.996916">
903
</page>
<figure confidence="0.999022666666667">
F1
0.7
0.6
0.5
0.4
0.3
0.2
MTP
MTE
MTM
MVP
MVPE
MVM
ME
MED
RAND
F1
MTP
MTE
MTM
MVP
MVPE
MVM
ME
MED
RAND
0 500 1000 1500 2000
number annotated tokens
0.1
0 500 1000 1500 2000
number annotated tokens
0.6
0.5
0.4
0.3
0.2
</figure>
<figureCaption confidence="0.940541428571429">
Figure 2: Fl results on CoNLL2003 dataset (left) and NLPBA2004 dataset (right). 2100 annotated tokens repre-
sent the —0.8% and —0.4% respectively of the CoNLL2003 training set and the NLPBA2004 training set.
for the remaining of the (unlabeled) tokens in the se-
quence.
Figure 3: Fl results on CoNLL2003 dataset, three to-
kens annotation. 6100 annotated tokens represent the
—2.4% of the CoNLL2003 training set.
</figureCaption>
<bodyText confidence="0.999781681818182">
A similar phenomenon, called missed class effect
(Tomanek et al., 2009), happens in AL when the strate-
gies inspect regions of the example space around the
decision boundaries, bringing to a slow AL process. In
(Tomanek et al., 2009) the missed class effect prob-
lem is solved by helping the AL strategies to inspect
regions far from the decision boundaries, that is, by
choosing an entire sequence instead of a single to-
ken. This solution is not suitable in this context given
that we will loose all the advantages we have in the
partially-labeled scenario, thus, we decided to anno-
tate for each chosen token the previous token and the
next token. The learning curves of the AL strategies
adopting this method (Figure 3) show a monotonically
increasing performance in function of the number of
annotated tokens.
By annotating three tokens at time, the tokens that
were considered “outliers” in the scenario with a single
token annotation are now supported by other tokens of
the sequence. This fact helps to decrease the noise in-
troduced in the semi-supervised model yielding better
results.
</bodyText>
<subsectionHeader confidence="0.900025">
5.3.2 Statistical Analysis
</subsectionHeader>
<bodyText confidence="0.999987952380952">
Figure 4 reports a few statistics that highlight the be-
havior of the methods on one of the datasets. One may
see for instance that the MVM and ME strategies are
very different from the other methods in that they se-
lect tokens that belong to significantly longer sentences
on average. Also it may be seen that MVM in partic-
ular selects tokens that are far from already annotated
tokens in the sentence. This strategy probably yields a
particular behavior with respect to exploration and ex-
ploitation that seems to suit the two tasks well. The
other strategies do exhibit different behaviors that intu-
itively should not work well. For instance the MED and
the MVPE strategies select tokens from new fully unla-
beled sentences (not shown statistics), preferably short,
so that the distance from selected tokens to already la-
beled tokens in the sentence (when any) is low. These
curves look like relevant indicators of the behavior of
the methods, and it would probably be worth monitor-
ing these all along the AL process to make sure the
learning exhibit a suitable behavior. This will be a fu-
ture study that is out of the scope of this work.
</bodyText>
<sectionHeader confidence="0.999255" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9988529">
In this paper we have presented several AL strategies
tailored for the PL-CRFs in a pool-based scenario. We
have tested the proposed strategies on four different
datasets for four different sequence labeling tasks. Dif-
ferently from other similar work in the field of AL,
in this study we have shown that margin-based strate-
gies constantly achieve good performance on four tasks
with very different data characteristics. Furthermore,
we have found that on datasets with certain character-
istics a particular phenomenon that makes the entire
</bodyText>
<figure confidence="0.991487617021277">
0 500 1000 1500 2000
number annotated tokens
F1
0.6
0.4
0.7
0.5
0.3
MTP
MTE
MTM
MVP
MVPE
MVM
ME
MED
RAND
904
MTP
MTE
MTM
MVP
MVPE
MVM
ME
MED
RAND
Distance
14
10
12
8
MTP
MTE
MTM
MVP
MVPE
MVM
ME
MED
RAND
6
4
2
0
0 5 10 15 20 25 30 35 40
Iterations
</figure>
<figureCaption confidence="0.946225">
Figure 4: Behavior of the methods on CoNLL2000 dataset as a function of the number of the iterations (x-axis,
from 1 to 40). Average length of the sentence the tokens that are selected by the AL strategy belong to (left) and
average distance from a token that is selected to the closest already labeled token in the sentence, if any (right).
</figureCaption>
<figure confidence="0.987001625">
Length 60
50
40
30
20
10
0 5 10 15 20 25 30 35 40
Iterations
</figure>
<bodyText confidence="0.9956088">
AL process highly unpredictable shows up. This phe-
nomenon consists in random drops of accuracy of the
classifiers learnt during the AL process. We have pro-
posed a first solution for this problem that does not have
a relevant impact on the human annotation effort.
</bodyText>
<sectionHeader confidence="0.9982" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999835">
We kindly thank Fabrizio Sebastiani and Andrea Esuli
for their help and valuable comments, and Dittaya
Wanvarie for providing us her implementation of
partially-labeled CRFs.
</bodyText>
<sectionHeader confidence="0.99922" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999645275862069">
Richard H. Byrd, Jorge Nocedal, and Robert B. Schn-
abel. 1994. Representations of quasi-Newton matri-
ces and their use in limited memory methods. Math-
emathical Programming, 63:129–156.
Aron Culotta and Andrew McCallum. 2005. Reduc-
ing labeling effort for structured prediction tasks. In
Proceedings of the Twentieth National Conference
on Artificial Intelligence and the Seventeenth Inno-
vative Applications of Artificial Intelligence Confer-
ence, (AAAI 2005), pages 746–751, Pittsburgh, US.
Andrea Esuli and Fabrizio Sebastiani. 2010. Evalu-
ating information extraction. In Proceedings of the
Conference on Multilingual and Multimodal Infor-
mation Access Evaluation (CLEF 2010), pages 100–
111, Padova, IT.
Andrea Esuli, Diego Marcheggiani, and Fabrizio Se-
bastiani. 2010. Sentence-based active learning
strategies for information extraction. In Proceedings
of the First Italian Information Retrieval Workshop
(IIR 2010), pages 41–45, Padua, Italy.
Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka,
Yuka Tateisi, and Nigel Collier. 2004. Introduc-
tion to the bio-entity recognition task at JNLPBA. In
Proceedings of the International Joint Workshop on
Natural Language Processing in Biomedicine and its
Applications, pages 70–75, Geneva, CH.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Proba-
bilistic models for segmenting and labeling sequence
data. In Proceedings of the 18th International Con-
ference on Machine Learning (ICML 2001), pages
282–289, Williamstown, US.
David D. Lewis and Jason Catlett. 1994. Hetero-
geneous uncertainty sampling for supervised learn-
ing. In Proceedings of 11th International Confer-
ence on Machine Learning (ICML 1994), pages 148–
156, New Brunswick, US.
Adwait Ratnaparkhi. 1996. A maximum entropy
model for part-of-speech tagging. In Proceedings of
the conference on empirical methods in natural lan-
guage processing, volume 1, pages 133–142.
Sunita Sarawagi. 2008. Information extraction. Foun-
dations and Trends in Databases, 1(3):261—377.
Tobias Scheffer, Christian Decomain, and Stefan Wro-
bel. 2001. Active hidden Markov models for infor-
mation extraction. In Proceedings of the 4th Inter-
national Conference on Advances in Intelligent Data
Analysis (IDA 2001), pages 309–318, Cascais, PT.
Burr Settles and Mark Craven. 2008. An analy-
sis of active learning strategies for sequence label-
ing tasks. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP 2008), pages 1070–1079, Honolulu, US.
Burr Settles. 2012. Active learning. Synthesis Lec-
tures on Artificial Intelligence and Machine Learn-
ing. Morgan &amp; Claypool Publishers.
Dan Shen, Jie Zhang, Jian Su, Guodong Zhou, and
Chew-Lim Tan. 2004. Multi-criteria-based active
</reference>
<page confidence="0.987392">
905
</page>
<reference confidence="0.990168051282051">
learning for named entity recognition. In Proceed-
ings of the 42nd Meeting of the Association for Com-
putational Linguistics (ACL 2004), pages 589–596,
Barcelona, ES.
Erik F. Tjong Kim Sang and Sabine Buchholz.
2000. Introduction to the CoNLL-2000 shared task:
Chunking. In Proceedings of the 2nd Workshop
on Learning Language in Logic and 4th Confer-
ence on Computational Natural Language Learning
(LLL/CoNLL 2000), pages 127–132. Lisbon, PT.
Erik F. Tjong Kim Sang and Fien De Meulder.
2003. Introduction to the CoNLL-2003 shared task:
Language-independent named entity recognition. In
Proceedings of the 7th Conference on Natural Lan-
guage Learning (CONLL 2003), pages 142–147, Ed-
monton, CA.
Katrin Tomanek and Udo Hahn. 2009. Semi-
supervised active learning for sequence labeling. In
Proceedings of the 47th Annual Meeting of the As-
sociation for Computational Linguistics and the 4th
International Joint Conference on Natural Language
Processing of the AFNLP (ACL-IJCNLP 2009),
pages 1039–1047, Singapore.
Katrin Tomanek, Florian Laws, Udo Hahn, and Hin-
rich Sch¨utze. 2009. On proper unit selection in
active learning: co-selection effects for named en-
tity recognition. In Proceedings of the NAACL HLT
2009 Workshop on Active Learning for Natural Lan-
guage Processing, pages 9–17, Boulder, US.
Yuta Tsuboi, Hisashi Kashima, Hiroki Oda, Shinsuke
Mori, and Yuji Matsumoto. 2008. Training condi-
tional random fields using incomplete annotations.
In Proceedings of the 22nd International Confer-
ence on Computational Linguistics (COLING 2008),
pages 897–904, Manchester, UK.
Dittaya Wanvarie, Hiroya Takamura, and Manabu Oku-
mura. 2011. Active learning with subsequence sam-
pling strategy for sequence labeling tasks. Informa-
tion and Media Technologies, 6(3):680–700.
</reference>
<page confidence="0.998507">
906
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.561972">
<title confidence="0.999468">An Experimental Comparison of Active Learning Strategies Partially Labeled Sequences</title>
<author confidence="0.935897">Diego Marcheggiani Thierry Arti`eres</author>
<affiliation confidence="0.9295085">Istituto di Scienza e Tecnologie dell’Informazione LIP6 Consiglio Nazionale delle Ricerche Pierre et Marie Curie University</affiliation>
<address confidence="0.787631">Pisa, Italy Paris,</address>
<email confidence="0.94903">diego.marcheggiani@isti.cnr.itthierry.artieres@lip6.fr</email>
<abstract confidence="0.993254333333333">learning consists of asking human annotators to annotate automatically selected data that are assumed to bring the most benefit in the creation of a classifier. AL allows to learn accurate systems with much less annotated data than what is required by pure supervised learning algorithms, hence limiting the tedious effort of annotating a large collection of data. We experimentally investigate the behavior of several AL strategies for sequence tasks (in a scenario) tailored on Partially-Labeled Conditional Random Fields, on four sequence labeling tasks: phrase chunking, part-of-speech tagging, named-entity recognition, and bioentity recognition.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Richard H Byrd</author>
<author>Jorge Nocedal</author>
<author>Robert B Schnabel</author>
</authors>
<title>Representations of quasi-Newton matrices and their use in limited memory methods.</title>
<date>1994</date>
<booktitle>Mathemathical Programming,</booktitle>
<pages>63--129</pages>
<contexts>
<context position="9539" citStr="Byrd et al., 1994" startWordPosition="1558" endWordPosition="1561">ence assignment may be derived with a Viterbi algorithm by recursively computing the following quantities: 0 if j E� Lt (11) Ψ1(j, y0, x1) else if t = 1 and j ELt M(j) otherwise where M(j) = max i∈Lt−1 6t−1,L(i)Ψt(j,i,xt) (12) The most probable assignment is then calculated as: y∗ = argmaxyp(y|x, L) 3.4 Log-Likelihood PL-CRFs’s parameters 0 are learnt through maximum log-likelihood estimation, that is to maximize the loglikelihood function LL(0): log p(YL(i)|x(i)) (13) log ZYL(i) (x(i)) − log ZY(x(i)) The parameters 0 that maximize Equation (13) are computed via the LBFGS optimization method (Byrd et al., 1994). 4 Active Learning Strategies Pool-based AL (see (Lewis and Catlett, 1994)) is probably the most common scenario in AL, where one has a large amount (pool) of unlabeled examples U1 and a small amount of labeled examples T1. In this scenario, the process of AL consists in a series of n iterations where a classifier Φi is trained with labeled examples Ti, and then is used to classify the unlabeled examples Ui. At this point an AL strategy S will select a number of examples B that once labeled will hopefully improve the performance of the next classifier Φi+1. Algorithm 1 shows the pool-based AL</context>
</contexts>
<marker>Byrd, Nocedal, Schnabel, 1994</marker>
<rawString>Richard H. Byrd, Jorge Nocedal, and Robert B. Schnabel. 1994. Representations of quasi-Newton matrices and their use in limited memory methods. Mathemathical Programming, 63:129–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aron Culotta</author>
<author>Andrew McCallum</author>
</authors>
<title>Reducing labeling effort for structured prediction tasks.</title>
<date>2005</date>
<booktitle>In Proceedings of the Twentieth National Conference on Artificial Intelligence and the Seventeenth Innovative Applications of Artificial Intelligence Conference, (AAAI</booktitle>
<pages>746--751</pages>
<location>Pittsburgh, US.</location>
<contexts>
<context position="13624" citStr="Culotta and McCallum, 2005" startWordPosition="2299" endWordPosition="2302">ther tokens in the sequence in which the chosen token appears. One may argue that, for a human annotator, anno1In order to have a light notation we omit the fact that when the most informative token is the first annotated token of a sentence, the whole sentence, with just one annotated token, is added to the training set Ti 6t,L(j) = I N LL(0) = i=1 N = i=1 900 tating only one or few tokens, instead of the entire sequence, is a difficult task. This would be correct in the scenario in which the text is presented to the human annotator without any visual clue about the annotations. However, in (Culotta and McCallum, 2005) it is shown that presenting to the human annotator the highlighted sequence to be annotated along with the associated sequence of labels obtained by the classifier requires much less effort from the annotator than performing the annotation without any visual and contextual clue. 4.1 Greedy Strategies In this section we present three AL strategies that select the most informative tokens, regardless of the assignment performed by the Viterbi algorithm. The rationale behind these strategies is that, even though we are looking for the most probable sequence assignment, we also want to annotate th</context>
</contexts>
<marker>Culotta, McCallum, 2005</marker>
<rawString>Aron Culotta and Andrew McCallum. 2005. Reducing labeling effort for structured prediction tasks. In Proceedings of the Twentieth National Conference on Artificial Intelligence and the Seventeenth Innovative Applications of Artificial Intelligence Conference, (AAAI 2005), pages 746–751, Pittsburgh, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Evaluating information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010),</booktitle>
<pages>100--111</pages>
<location>Padova, IT.</location>
<contexts>
<context position="22325" citStr="Esuli and Sebastiani (2010)" startWordPosition="3758" endWordPosition="3761">gy and for each dataset, we report averaged results of three runs with a different randomly sampled initial training set T1. For each dataset we adopted a standard set of features. For the CoNLL2000 dataset we adopted the same standard features used in (Wanvarie et al., 2011) for the same dataset, for the CoNLL2003 and the NLPBA2004 dataset we adopted the features used in (Wanvarie et al., 2011) for the CoNLL2003 dataset, while for the CoNLL2000POS dataset we used the features presented in (Ratnaparkhi, 1996). As evaluation measure we adopted the token variant of the F1 measure, introduced by Esuli and Sebastiani (2010). This variant, instead of the entire annotation (chunk/entity), calculates TPs, FPs, and FNs, singularly for each token that compose the annotation, bringing to a finer evaluation. 5.3 Results From the learning curves of Figure 1 and Figure 2 it is clear that most of the strategies have the same trend throughout the different datasets. This results is somewhat different from the results obtained in (Settles and Craven, 2008) in which there is not a clear winner among the strategies they proposed in a fully-labeled scenario. The strategies that perform particularly bad (worse than the RAND str</context>
</contexts>
<marker>Esuli, Sebastiani, 2010</marker>
<rawString>Andrea Esuli and Fabrizio Sebastiani. 2010. Evaluating information extraction. In Proceedings of the Conference on Multilingual and Multimodal Information Access Evaluation (CLEF 2010), pages 100– 111, Padova, IT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Esuli</author>
<author>Diego Marcheggiani</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Sentence-based active learning strategies for information extraction.</title>
<date>2010</date>
<booktitle>In Proceedings of the First Italian Information Retrieval Workshop (IIR 2010),</booktitle>
<pages>41--45</pages>
<location>Padua, Italy.</location>
<contexts>
<context position="10294" citStr="Esuli et al., 2010" startWordPosition="1687" endWordPosition="1690"> large amount (pool) of unlabeled examples U1 and a small amount of labeled examples T1. In this scenario, the process of AL consists in a series of n iterations where a classifier Φi is trained with labeled examples Ti, and then is used to classify the unlabeled examples Ui. At this point an AL strategy S will select a number of examples B that once labeled will hopefully improve the performance of the next classifier Φi+1. Algorithm 1 shows the pool-based AL framework for partially annotated sequences as introduced in (Wanvarie et al., 2011). Differently from AL for fully labeled sequences (Esuli et al., 2010), thanks to the finer granularity of the partially labeled model, we use the token as basic annotation unit, instead of the entire sequence. The point of using the partial labeling is in saving the request for human annotations on tokens whose labels are already known (inferred) by the classifier and concentrate on those tokens that the classifier finds hard to label. Using the semi-supervised approach of the PLCRFs we can take advantage of single-labeled tokens instead of an entire labeled sequence. The entire pool-based AL process with partially labeled sequences is summarized in Algorithm 1</context>
</contexts>
<marker>Esuli, Marcheggiani, Sebastiani, 2010</marker>
<rawString>Andrea Esuli, Diego Marcheggiani, and Fabrizio Sebastiani. 2010. Sentence-based active learning strategies for information extraction. In Proceedings of the First Italian Information Retrieval Workshop (IIR 2010), pages 41–45, Padua, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>Yoshimasa Tsuruoka</author>
<author>Yuka Tateisi</author>
<author>Nigel Collier</author>
</authors>
<title>Introduction to the bio-entity recognition task at JNLPBA.</title>
<date>2004</date>
<booktitle>In Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications,</booktitle>
<pages>70--75</pages>
<location>Geneva, CH.</location>
<contexts>
<context position="20053" citStr="Kim et al., 2004" startWordPosition="3381" endWordPosition="3384">egies presented in this section (with the exception of the MVP strategy) have never been applied in the context of AL with partially labeled sequences scenario. 5 Experiments 5.1 Datasets We have experimented and evaluated the AL strategies of Section 4 on four sequence labeling tasks, part-of-speech tagging, phrase chunking, named-entity recognition and bio-entity recognition. We used the CoNLL2000 dataset (Tjong Kim Sang and Buchholz, 2000) for the phrase chunking task, the CoNLL2003 dataset (Tjong Kim Sang and De Meulder, 2003), for the named-entity recognition task, the NLPBA2004 dataset (Kim et al., 2004), for the biomedical entity recognition task and the CoNLL2000POS dataset2 for the part-of-speech labeling task. All the datasets are publicly available and are standard benchmarks in sequence labeling tasks. Table 1 shows some statistics of the datasets in terms of dimensions, number of labels, distribution of the labels, etc. The data heterogeneity of the different datasets allowed us to test the AL strategies on different “experimental settings”, thus to have a more robust empirical evaluation. 2This is the CoNLL2000 dataset annotated with part-ofspeech labels instead of chunking labels. 5.</context>
</contexts>
<marker>Kim, Ohta, Tsuruoka, Tateisi, Collier, 2004</marker>
<rawString>Jin-Dong Kim, Tomoko Ohta, Yoshimasa Tsuruoka, Yuka Tateisi, and Nigel Collier. 2004. Introduction to the bio-entity recognition task at JNLPBA. In Proceedings of the International Joint Workshop on Natural Language Processing in Biomedicine and its Applications, pages 70–75, Geneva, CH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning (ICML</booktitle>
<pages>282--289</pages>
<location>Williamstown, US.</location>
<contexts>
<context position="2632" citStr="Lafferty et al., 2001" startWordPosition="403" endWordPosition="406">particular, AL proved its usefulness in sequence labeling tasks (Settles and Craven, 2008). Yet, researchers have always adopted as annotation unit an entire sequence (i.e., the annotator is asked to annotate the whole sequence) while it looks like it could be much more relevant to ask for labeling only small parts of it (e.g., the ones with highest ambiguity). A few works have investigated this idea. For instance, Wanvarie et al. (2011) proposed to use Partially-Labeled Conditional Random Fields (PL-CRFs) (Tsuboi et al., 2008), a semi-supervised variation of Conditional Random Fields (CRFs) (Lafferty et al., 2001) able to deal with partially-labeled sequences, thus enabling to adopt as annotation unit single tokens and still learning from full sequences. AL with partially labeled sequences has proven to be effective in substantially reducing the amount of annotated data with respect to common AL approaches (see (Wanvarie et al., 2011)). In this work we focus on AL strategies for partially labeled sequences adopting the single token as annotation unit and PL-CRFs as learning algorithm given its nature in dealing with partially labeled sequences. We propose several AL strategies based on measures of unce</context>
<context position="7841" citStr="Lafferty et al., 2001" startWordPosition="1269" endWordPosition="1272">= X p(y|x) (4) YEYL In order to perform inference and parameter learning on PL-CRFs, some modifications on traditional CRFs inference algorithms are required. 3.1 Forward-Backward Algorithm Differently from traditional CRFs, the forward and backward scores (respectively α and β), are calculated as follows: 0 if j E� Lt T1(j, y0, x1) else if t = 1 and j ELt SA(j) otherwise 0 if j E� Lt 1 else if t = T and j ELt SB(j) otherwise where ⎧ ⎨⎪⎪ ⎪⎪⎩ αt,L(j) = βt,L(i) = ⎧ ⎨⎪⎪ ⎪⎪⎩ Nowadays, CRFs are the de-facto standard for the solution of sequence labeling tasks (Sarawagi, 2008). In traditional CRFs (Lafferty et al., 2001) the conditional probability of a sequence of labels y given a sequence of observed feature vectors x is given by: SA(j) = X αt−1,L(i)Tt(j, i, xt) (7) iELt−1 SB(j) = X βt+1,L(j)Tt+1(j, i, xt+1) (8) jELt+1 p(y|x) = Z(x) YTt(y,x) (1) 1 t=1 T where a standard choice for sequence labeling tasks are the so called Linear-chain CRFs: YT 1 p(y|x) = Tt(yt, yt−1, xt) (2) Z(x) t=1 with: Tt(yt,yt−1,xt) = Tu(yt,xt)Tb(yt,yt−1) (3) where Tu(yt,xt) models the co-occurrence between features xt, and label yt at time t, and Tb(yt, yt−1) models the co-occurrence between two adjacent labels yt and yt−1. and y0 is </context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning (ICML 2001), pages 282–289, Williamstown, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
<author>Jason Catlett</author>
</authors>
<title>Heterogeneous uncertainty sampling for supervised learning.</title>
<date>1994</date>
<booktitle>In Proceedings of 11th International Conference on Machine Learning (ICML 1994),</booktitle>
<pages>148--156</pages>
<location>New Brunswick, US.</location>
<contexts>
<context position="9614" citStr="Lewis and Catlett, 1994" startWordPosition="1569" endWordPosition="1572">y computing the following quantities: 0 if j E� Lt (11) Ψ1(j, y0, x1) else if t = 1 and j ELt M(j) otherwise where M(j) = max i∈Lt−1 6t−1,L(i)Ψt(j,i,xt) (12) The most probable assignment is then calculated as: y∗ = argmaxyp(y|x, L) 3.4 Log-Likelihood PL-CRFs’s parameters 0 are learnt through maximum log-likelihood estimation, that is to maximize the loglikelihood function LL(0): log p(YL(i)|x(i)) (13) log ZYL(i) (x(i)) − log ZY(x(i)) The parameters 0 that maximize Equation (13) are computed via the LBFGS optimization method (Byrd et al., 1994). 4 Active Learning Strategies Pool-based AL (see (Lewis and Catlett, 1994)) is probably the most common scenario in AL, where one has a large amount (pool) of unlabeled examples U1 and a small amount of labeled examples T1. In this scenario, the process of AL consists in a series of n iterations where a classifier Φi is trained with labeled examples Ti, and then is used to classify the unlabeled examples Ui. At this point an AL strategy S will select a number of examples B that once labeled will hopefully improve the performance of the next classifier Φi+1. Algorithm 1 shows the pool-based AL framework for partially annotated sequences as introduced in (Wanvarie et </context>
</contexts>
<marker>Lewis, Catlett, 1994</marker>
<rawString>David D. Lewis and Jason Catlett. 1994. Heterogeneous uncertainty sampling for supervised learning. In Proceedings of 11th International Conference on Machine Learning (ICML 1994), pages 148– 156, New Brunswick, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of the conference on empirical methods in natural language processing,</booktitle>
<volume>1</volume>
<pages>133--142</pages>
<contexts>
<context position="22212" citStr="Ratnaparkhi, 1996" startWordPosition="3741" endWordPosition="3742">strategies behave in the beginning of AL process when the annotation effort remains low. For each strategy and for each dataset, we report averaged results of three runs with a different randomly sampled initial training set T1. For each dataset we adopted a standard set of features. For the CoNLL2000 dataset we adopted the same standard features used in (Wanvarie et al., 2011) for the same dataset, for the CoNLL2003 and the NLPBA2004 dataset we adopted the features used in (Wanvarie et al., 2011) for the CoNLL2003 dataset, while for the CoNLL2000POS dataset we used the features presented in (Ratnaparkhi, 1996). As evaluation measure we adopted the token variant of the F1 measure, introduced by Esuli and Sebastiani (2010). This variant, instead of the entire annotation (chunk/entity), calculates TPs, FPs, and FNs, singularly for each token that compose the annotation, bringing to a finer evaluation. 5.3 Results From the learning curves of Figure 1 and Figure 2 it is clear that most of the strategies have the same trend throughout the different datasets. This results is somewhat different from the results obtained in (Settles and Craven, 2008) in which there is not a clear winner among the strategies</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>Adwait Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings of the conference on empirical methods in natural language processing, volume 1, pages 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sunita Sarawagi</author>
</authors>
<date>2008</date>
<booktitle>Information extraction. Foundations and Trends in Databases,</booktitle>
<volume>1</volume>
<issue>3</issue>
<contexts>
<context position="7796" citStr="Sarawagi, 2008" startWordPosition="1264" endWordPosition="1265"> labeling may be computed as: p(YL|x) = X p(y|x) (4) YEYL In order to perform inference and parameter learning on PL-CRFs, some modifications on traditional CRFs inference algorithms are required. 3.1 Forward-Backward Algorithm Differently from traditional CRFs, the forward and backward scores (respectively α and β), are calculated as follows: 0 if j E� Lt T1(j, y0, x1) else if t = 1 and j ELt SA(j) otherwise 0 if j E� Lt 1 else if t = T and j ELt SB(j) otherwise where ⎧ ⎨⎪⎪ ⎪⎪⎩ αt,L(j) = βt,L(i) = ⎧ ⎨⎪⎪ ⎪⎪⎩ Nowadays, CRFs are the de-facto standard for the solution of sequence labeling tasks (Sarawagi, 2008). In traditional CRFs (Lafferty et al., 2001) the conditional probability of a sequence of labels y given a sequence of observed feature vectors x is given by: SA(j) = X αt−1,L(i)Tt(j, i, xt) (7) iELt−1 SB(j) = X βt+1,L(j)Tt+1(j, i, xt+1) (8) jELt+1 p(y|x) = Z(x) YTt(y,x) (1) 1 t=1 T where a standard choice for sequence labeling tasks are the so called Linear-chain CRFs: YT 1 p(y|x) = Tt(yt, yt−1, xt) (2) Z(x) t=1 with: Tt(yt,yt−1,xt) = Tu(yt,xt)Tb(yt,yt−1) (3) where Tu(yt,xt) models the co-occurrence between features xt, and label yt at time t, and Tb(yt, yt−1) models the co-occurrence betwee</context>
</contexts>
<marker>Sarawagi, 2008</marker>
<rawString>Sunita Sarawagi. 2008. Information extraction. Foundations and Trends in Databases, 1(3):261—377.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tobias Scheffer</author>
<author>Christian Decomain</author>
<author>Stefan Wrobel</author>
</authors>
<title>Active hidden Markov models for information extraction.</title>
<date>2001</date>
<booktitle>In Proceedings of the 4th International Conference on Advances in Intelligent Data Analysis</booktitle>
<pages>309--318</pages>
<location>Cascais, PT.</location>
<contexts>
<context position="15201" citStr="Scheffer et al., 2001" startWordPosition="2569" endWordPosition="2572">gy relies on the entropy measure to evaluate the ambiguity about the label of a token. The rationale of it is that, if more than one label have the same assigned marginal probability, the entropy will be high, that is, SMTE(t, x) = 11 p(yt = j|x, L) · logp(yt = j|x, L) (15) j∈Y In order to directly plug the SMT E strategy into the AL framework of Algorithm 1, we removed the minus sign at the beginning of the entropy formula. This allow us to use the min operator with a maximum entropy approach. The Minimum Token Margin (MTM) strategy is a variant of the margin sampling strategy introduced in (Scheffer et al., 2001). It calculates the informativeness by considering the two most probable assignments and by subtracting the highest probability by the lowest. With max0 that calculates the second maximum value, MTM is defined as: SMTM(t, x) = 16) max p(yt =j |x, L) − max0p(yt = j |x, L) ( j∈Y j∈Y 4.2 Viterbi Strategies The following AL strategies take into consideration the most probable sequence assignments obtained from the Viterbi algorithm computed on already known labels in the sequence. The rationale is that, with these strategies, the measure of uncertainty is chosen according to the information obtain</context>
</contexts>
<marker>Scheffer, Decomain, Wrobel, 2001</marker>
<rawString>Tobias Scheffer, Christian Decomain, and Stefan Wrobel. 2001. Active hidden Markov models for information extraction. In Proceedings of the 4th International Conference on Advances in Intelligent Data Analysis (IDA 2001), pages 309–318, Cascais, PT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
<author>Mark Craven</author>
</authors>
<title>An analysis of active learning strategies for sequence labeling tasks.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>1070--1079</pages>
<location>Honolulu, US.</location>
<contexts>
<context position="2100" citStr="Settles and Craven, 2008" startWordPosition="317" endWordPosition="320"> creation of a new classifier. A classifier is incrementally retrained with all the data labeled by the annotator. AL has been demonstrated to work well and to produce accurate classifiers while saving much human annotation effort. One critical issue is to define a measure of the informativeness which should reflect how much new information a new example would give in the learning of a new classifier once annotated. A lot of work has been done on the AL field in the past years (see (Settles, 2012) for an exhaustive overview). In particular, AL proved its usefulness in sequence labeling tasks (Settles and Craven, 2008). Yet, researchers have always adopted as annotation unit an entire sequence (i.e., the annotator is asked to annotate the whole sequence) while it looks like it could be much more relevant to ask for labeling only small parts of it (e.g., the ones with highest ambiguity). A few works have investigated this idea. For instance, Wanvarie et al. (2011) proposed to use Partially-Labeled Conditional Random Fields (PL-CRFs) (Tsuboi et al., 2008), a semi-supervised variation of Conditional Random Fields (CRFs) (Lafferty et al., 2001) able to deal with partially-labeled sequences, thus enabling to ado</context>
<context position="5023" citStr="Settles and Craven, 2008" startWordPosition="779" endWordPosition="782">he pool-based AL framework. It considers the case in which a large amount (pool) of unlabeled examples is available, from which samples to be labeled must be chosen. This framework fits all the sequence labeling problems we consider here. For a more exhaustive survey on other AL frameworks see 898 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 898–906, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (Settles, 2012). Most of the AL works on sequence labeling adopted the entire sequence as annotation unit (Settles and Craven, 2008) which was demonstrated by Wanvarie et al. (2011) to be less effective than using the single token as annotation unit. The main AL works in this latter line of work are (Shen et al., 2004), (Tomanek and Hahn, 2009) and (Wanvarie et al., 2011). Shen et al. (2004) adopted SVMs as learning algorithm and proposed two strategies that combine three criteria, informativeness, representativeness and diversity. SVMs allowed them to use as annotation unit a subset of the tokens in a sequence, without annotating, in any way, the rest of the tokens in the sequence. In (Tomanek and Hahn, 2009), the most un</context>
<context position="22754" citStr="Settles and Craven, 2008" startWordPosition="3828" endWordPosition="3831"> for the CoNLL2000POS dataset we used the features presented in (Ratnaparkhi, 1996). As evaluation measure we adopted the token variant of the F1 measure, introduced by Esuli and Sebastiani (2010). This variant, instead of the entire annotation (chunk/entity), calculates TPs, FPs, and FNs, singularly for each token that compose the annotation, bringing to a finer evaluation. 5.3 Results From the learning curves of Figure 1 and Figure 2 it is clear that most of the strategies have the same trend throughout the different datasets. This results is somewhat different from the results obtained in (Settles and Craven, 2008) in which there is not a clear winner among the strategies they proposed in a fully-labeled scenario. The strategies that perform particularly bad (worse than the RAND strategy in CoNLL2000POS and in CoNLL2003 dataset) in all the datasets are the MTE and MTP. This is expected, because the choice of the measure of informativeness related to the token without taking in consideration the Viterbi path is suboptimal in this task. Surprisingly, the MTM strategy even though based on the same principle of MTE and MTP, is very effective in most of the datasets. The most effective strategies, that is, t</context>
</contexts>
<marker>Settles, Craven, 2008</marker>
<rawString>Burr Settles and Mark Craven. 2008. An analysis of active learning strategies for sequence labeling tasks. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP 2008), pages 1070–1079, Honolulu, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Burr Settles</author>
</authors>
<title>Active learning.</title>
<date>2012</date>
<booktitle>Synthesis Lectures on Artificial Intelligence and Machine Learning.</booktitle>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="1977" citStr="Settles, 2012" startWordPosition="300" endWordPosition="301">r more human annotators by asking them to label new samples which are supposed to be the most informative in the creation of a new classifier. A classifier is incrementally retrained with all the data labeled by the annotator. AL has been demonstrated to work well and to produce accurate classifiers while saving much human annotation effort. One critical issue is to define a measure of the informativeness which should reflect how much new information a new example would give in the learning of a new classifier once annotated. A lot of work has been done on the AL field in the past years (see (Settles, 2012) for an exhaustive overview). In particular, AL proved its usefulness in sequence labeling tasks (Settles and Craven, 2008). Yet, researchers have always adopted as annotation unit an entire sequence (i.e., the annotator is asked to annotate the whole sequence) while it looks like it could be much more relevant to ask for labeling only small parts of it (e.g., the ones with highest ambiguity). A few works have investigated this idea. For instance, Wanvarie et al. (2011) proposed to use Partially-Labeled Conditional Random Fields (PL-CRFs) (Tsuboi et al., 2008), a semi-supervised variation of C</context>
<context position="4906" citStr="Settles, 2012" startWordPosition="762" endWordPosition="763">d discusses the empirical results. Section 6 summarizes our findings. 2 Related Work Our work belongs to the pool-based AL framework. It considers the case in which a large amount (pool) of unlabeled examples is available, from which samples to be labeled must be chosen. This framework fits all the sequence labeling problems we consider here. For a more exhaustive survey on other AL frameworks see 898 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 898–906, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (Settles, 2012). Most of the AL works on sequence labeling adopted the entire sequence as annotation unit (Settles and Craven, 2008) which was demonstrated by Wanvarie et al. (2011) to be less effective than using the single token as annotation unit. The main AL works in this latter line of work are (Shen et al., 2004), (Tomanek and Hahn, 2009) and (Wanvarie et al., 2011). Shen et al. (2004) adopted SVMs as learning algorithm and proposed two strategies that combine three criteria, informativeness, representativeness and diversity. SVMs allowed them to use as annotation unit a subset of the tokens in a seque</context>
</contexts>
<marker>Settles, 2012</marker>
<rawString>Burr Settles. 2012. Active learning. Synthesis Lectures on Artificial Intelligence and Machine Learning. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Shen</author>
<author>Jie Zhang</author>
<author>Jian Su</author>
<author>Guodong Zhou</author>
<author>Chew-Lim Tan</author>
</authors>
<title>Multi-criteria-based active learning for named entity recognition.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL 2004),</booktitle>
<pages>589--596</pages>
<location>Barcelona, ES.</location>
<contexts>
<context position="5211" citStr="Shen et al., 2004" startWordPosition="814" endWordPosition="817">equence labeling problems we consider here. For a more exhaustive survey on other AL frameworks see 898 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 898–906, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (Settles, 2012). Most of the AL works on sequence labeling adopted the entire sequence as annotation unit (Settles and Craven, 2008) which was demonstrated by Wanvarie et al. (2011) to be less effective than using the single token as annotation unit. The main AL works in this latter line of work are (Shen et al., 2004), (Tomanek and Hahn, 2009) and (Wanvarie et al., 2011). Shen et al. (2004) adopted SVMs as learning algorithm and proposed two strategies that combine three criteria, informativeness, representativeness and diversity. SVMs allowed them to use as annotation unit a subset of the tokens in a sequence, without annotating, in any way, the rest of the tokens in the sequence. In (Tomanek and Hahn, 2009), the most uncertain tokens of the sequence are singularly annotated, but the rest of the labels in the sequence are then chosen by the classifier in a semisupervised fashion. Wanvarie et al. (2011) is</context>
</contexts>
<marker>Shen, Zhang, Su, Zhou, Tan, 2004</marker>
<rawString>Dan Shen, Jie Zhang, Jian Su, Guodong Zhou, and Chew-Lim Tan. 2004. Multi-criteria-based active learning for named entity recognition. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL 2004), pages 589–596, Barcelona, ES.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Sabine Buchholz</author>
</authors>
<title>Introduction to the CoNLL-2000 shared task: Chunking.</title>
<date>2000</date>
<booktitle>In Proceedings of the 2nd Workshop on Learning Language in Logic and 4th Conference on Computational Natural Language Learning</booktitle>
<pages>127--132</pages>
<location>Lisbon, PT.</location>
<contexts>
<context position="19882" citStr="Sang and Buchholz, 2000" startWordPosition="3354" endWordPosition="3357"> samples random tokens without any external information. It is used as baseline to compare the real effectiveness of the proposed strategy. At the best of our knowledge the strategies presented in this section (with the exception of the MVP strategy) have never been applied in the context of AL with partially labeled sequences scenario. 5 Experiments 5.1 Datasets We have experimented and evaluated the AL strategies of Section 4 on four sequence labeling tasks, part-of-speech tagging, phrase chunking, named-entity recognition and bio-entity recognition. We used the CoNLL2000 dataset (Tjong Kim Sang and Buchholz, 2000) for the phrase chunking task, the CoNLL2003 dataset (Tjong Kim Sang and De Meulder, 2003), for the named-entity recognition task, the NLPBA2004 dataset (Kim et al., 2004), for the biomedical entity recognition task and the CoNLL2000POS dataset2 for the part-of-speech labeling task. All the datasets are publicly available and are standard benchmarks in sequence labeling tasks. Table 1 shows some statistics of the datasets in terms of dimensions, number of labels, distribution of the labels, etc. The data heterogeneity of the different datasets allowed us to test the AL strategies on different </context>
</contexts>
<marker>Sang, Buchholz, 2000</marker>
<rawString>Erik F. Tjong Kim Sang and Sabine Buchholz. 2000. Introduction to the CoNLL-2000 shared task: Chunking. In Proceedings of the 2nd Workshop on Learning Language in Logic and 4th Conference on Computational Natural Language Learning (LLL/CoNLL 2000), pages 127–132. Lisbon, PT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erik F Tjong Kim Sang</author>
<author>Fien De Meulder</author>
</authors>
<title>Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th Conference on Natural Language Learning (CONLL</booktitle>
<pages>142--147</pages>
<location>Edmonton, CA.</location>
<marker>Sang, De Meulder, 2003</marker>
<rawString>Erik F. Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. In Proceedings of the 7th Conference on Natural Language Learning (CONLL 2003), pages 142–147, Edmonton, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Tomanek</author>
<author>Udo Hahn</author>
</authors>
<title>Semisupervised active learning for sequence labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP</booktitle>
<pages>1039--1047</pages>
<contexts>
<context position="5237" citStr="Tomanek and Hahn, 2009" startWordPosition="818" endWordPosition="821">lems we consider here. For a more exhaustive survey on other AL frameworks see 898 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 898–906, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (Settles, 2012). Most of the AL works on sequence labeling adopted the entire sequence as annotation unit (Settles and Craven, 2008) which was demonstrated by Wanvarie et al. (2011) to be less effective than using the single token as annotation unit. The main AL works in this latter line of work are (Shen et al., 2004), (Tomanek and Hahn, 2009) and (Wanvarie et al., 2011). Shen et al. (2004) adopted SVMs as learning algorithm and proposed two strategies that combine three criteria, informativeness, representativeness and diversity. SVMs allowed them to use as annotation unit a subset of the tokens in a sequence, without annotating, in any way, the rest of the tokens in the sequence. In (Tomanek and Hahn, 2009), the most uncertain tokens of the sequence are singularly annotated, but the rest of the labels in the sequence are then chosen by the classifier in a semisupervised fashion. Wanvarie et al. (2011) is the closest work to ours,</context>
</contexts>
<marker>Tomanek, Hahn, 2009</marker>
<rawString>Katrin Tomanek and Udo Hahn. 2009. Semisupervised active learning for sequence labeling. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and the 4th International Joint Conference on Natural Language Processing of the AFNLP (ACL-IJCNLP 2009), pages 1039–1047, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Tomanek</author>
<author>Florian Laws</author>
<author>Udo Hahn</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>On proper unit selection in active learning: co-selection effects for named entity recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing,</booktitle>
<pages>9--17</pages>
<location>Boulder, US.</location>
<marker>Tomanek, Laws, Hahn, Sch¨utze, 2009</marker>
<rawString>Katrin Tomanek, Florian Laws, Udo Hahn, and Hinrich Sch¨utze. 2009. On proper unit selection in active learning: co-selection effects for named entity recognition. In Proceedings of the NAACL HLT 2009 Workshop on Active Learning for Natural Language Processing, pages 9–17, Boulder, US.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yuta Tsuboi</author>
<author>Hisashi Kashima</author>
<author>Hiroki Oda</author>
<author>Shinsuke Mori</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Training conditional random fields using incomplete annotations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING</booktitle>
<pages>897--904</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="2543" citStr="Tsuboi et al., 2008" startWordPosition="390" endWordPosition="393">on the AL field in the past years (see (Settles, 2012) for an exhaustive overview). In particular, AL proved its usefulness in sequence labeling tasks (Settles and Craven, 2008). Yet, researchers have always adopted as annotation unit an entire sequence (i.e., the annotator is asked to annotate the whole sequence) while it looks like it could be much more relevant to ask for labeling only small parts of it (e.g., the ones with highest ambiguity). A few works have investigated this idea. For instance, Wanvarie et al. (2011) proposed to use Partially-Labeled Conditional Random Fields (PL-CRFs) (Tsuboi et al., 2008), a semi-supervised variation of Conditional Random Fields (CRFs) (Lafferty et al., 2001) able to deal with partially-labeled sequences, thus enabling to adopt as annotation unit single tokens and still learning from full sequences. AL with partially labeled sequences has proven to be effective in substantially reducing the amount of annotated data with respect to common AL approaches (see (Wanvarie et al., 2011)). In this work we focus on AL strategies for partially labeled sequences adopting the single token as annotation unit and PL-CRFs as learning algorithm given its nature in dealing wit</context>
<context position="6634" citStr="Tsuboi et al. (2008)" startWordPosition="1047" endWordPosition="1050">lly labeled sequences using re-estimation, the annotation cost can be dramatically reduced (by annotating from 8% to 10% of the tokens of the entire training set), obtaining the same level of performance of the classifier trained on the entire, fully-labeled, training set. We started our work from this conclusion and we focused on AL with partially labeled sequences using re-estimation by comparing several AL strategies in order to find the strategy that allows to create the best classifier with the minimum annotation effort. 3 Partially-Labeled Conditional Random Fields PL-CRFs introduced by Tsuboi et al. (2008) allow to learn a CRF model using partially-labeled sequences, marginalizing on those tokens that do not have an assigned label. In PL-CRFs, L denotes a partially labeled information about a sequence. It consists of a sequence of sets Lt in which Lt = Y (where Y is the set of all the possible labels) if there is no label information for token at time t. Lt is a singleton containing yt if the label of the token at time t is known, and YL is the set of label sequences that fits the partial label information L. Then the probability of a partial labeling may be computed as: p(YL|x) = X p(y|x) (4) </context>
</contexts>
<marker>Tsuboi, Kashima, Oda, Mori, Matsumoto, 2008</marker>
<rawString>Yuta Tsuboi, Hisashi Kashima, Hiroki Oda, Shinsuke Mori, and Yuji Matsumoto. 2008. Training conditional random fields using incomplete annotations. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), pages 897–904, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dittaya Wanvarie</author>
<author>Hiroya Takamura</author>
<author>Manabu Okumura</author>
</authors>
<title>Active learning with subsequence sampling strategy for sequence labeling tasks. Information and Media Technologies,</title>
<date>2011</date>
<pages>6--3</pages>
<contexts>
<context position="2451" citStr="Wanvarie et al. (2011)" startWordPosition="377" endWordPosition="381">le would give in the learning of a new classifier once annotated. A lot of work has been done on the AL field in the past years (see (Settles, 2012) for an exhaustive overview). In particular, AL proved its usefulness in sequence labeling tasks (Settles and Craven, 2008). Yet, researchers have always adopted as annotation unit an entire sequence (i.e., the annotator is asked to annotate the whole sequence) while it looks like it could be much more relevant to ask for labeling only small parts of it (e.g., the ones with highest ambiguity). A few works have investigated this idea. For instance, Wanvarie et al. (2011) proposed to use Partially-Labeled Conditional Random Fields (PL-CRFs) (Tsuboi et al., 2008), a semi-supervised variation of Conditional Random Fields (CRFs) (Lafferty et al., 2001) able to deal with partially-labeled sequences, thus enabling to adopt as annotation unit single tokens and still learning from full sequences. AL with partially labeled sequences has proven to be effective in substantially reducing the amount of annotated data with respect to common AL approaches (see (Wanvarie et al., 2011)). In this work we focus on AL strategies for partially labeled sequences adopting the singl</context>
<context position="5072" citStr="Wanvarie et al. (2011)" startWordPosition="787" endWordPosition="790"> which a large amount (pool) of unlabeled examples is available, from which samples to be labeled must be chosen. This framework fits all the sequence labeling problems we consider here. For a more exhaustive survey on other AL frameworks see 898 Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 898–906, October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics (Settles, 2012). Most of the AL works on sequence labeling adopted the entire sequence as annotation unit (Settles and Craven, 2008) which was demonstrated by Wanvarie et al. (2011) to be less effective than using the single token as annotation unit. The main AL works in this latter line of work are (Shen et al., 2004), (Tomanek and Hahn, 2009) and (Wanvarie et al., 2011). Shen et al. (2004) adopted SVMs as learning algorithm and proposed two strategies that combine three criteria, informativeness, representativeness and diversity. SVMs allowed them to use as annotation unit a subset of the tokens in a sequence, without annotating, in any way, the rest of the tokens in the sequence. In (Tomanek and Hahn, 2009), the most uncertain tokens of the sequence are singularly ann</context>
<context position="10224" citStr="Wanvarie et al., 2011" startWordPosition="1676" endWordPosition="1679">tlett, 1994)) is probably the most common scenario in AL, where one has a large amount (pool) of unlabeled examples U1 and a small amount of labeled examples T1. In this scenario, the process of AL consists in a series of n iterations where a classifier Φi is trained with labeled examples Ti, and then is used to classify the unlabeled examples Ui. At this point an AL strategy S will select a number of examples B that once labeled will hopefully improve the performance of the next classifier Φi+1. Algorithm 1 shows the pool-based AL framework for partially annotated sequences as introduced in (Wanvarie et al., 2011). Differently from AL for fully labeled sequences (Esuli et al., 2010), thanks to the finer granularity of the partially labeled model, we use the token as basic annotation unit, instead of the entire sequence. The point of using the partial labeling is in saving the request for human annotations on tokens whose labels are already known (inferred) by the classifier and concentrate on those tokens that the classifier finds hard to label. Using the semi-supervised approach of the PLCRFs we can take advantage of single-labeled tokens instead of an entire labeled sequence. The entire pool-based AL</context>
<context position="15986" citStr="Wanvarie et al., 2011" startWordPosition="2697" endWordPosition="2700">lates the second maximum value, MTM is defined as: SMTM(t, x) = 16) max p(yt =j |x, L) − max0p(yt = j |x, L) ( j∈Y j∈Y 4.2 Viterbi Strategies The following AL strategies take into consideration the most probable sequence assignments obtained from the Viterbi algorithm computed on already known labels in the sequence. The rationale is that, with these strategies, the measure of uncertainty is chosen according to the information obtained from the outcome of the Viterbi algorithm (i.e., the most probable sequence assignment). The Minimum Viterbi Probability (MVP) is the base strategy adopted in (Wanvarie et al., 2011). It takes as measure of informativeness the probability of the label chosen by the Viterbi algorithm. SMV P(t, x) = p(y∗t |x, L) (17) where y∗t is the label assignment chosen by the Viterbi algorithm. In general, the token assignments that maximize the probability of the sequence assignment y∗t are different from the token assignments that maximize the probability of the individual token assignments argmaxj∈Yp(yt = j). The Maximum Viterbi Pseudo-Entropy (MVPE) strategy calculates for each token the “pseudo” entropy of the most probable sequences at the variation of the label at position t. Th</context>
<context position="21974" citStr="Wanvarie et al., 2011" startWordPosition="3700" endWordPosition="3703">ical case with higher B to limit the algorithmic complexity (since the PL-CRF classifier must be retrained every iteration). We used in our experiments B = 50. We fixed the number of AL iterations n at 40 because what matters here is how the strategies behave in the beginning of AL process when the annotation effort remains low. For each strategy and for each dataset, we report averaged results of three runs with a different randomly sampled initial training set T1. For each dataset we adopted a standard set of features. For the CoNLL2000 dataset we adopted the same standard features used in (Wanvarie et al., 2011) for the same dataset, for the CoNLL2003 and the NLPBA2004 dataset we adopted the features used in (Wanvarie et al., 2011) for the CoNLL2003 dataset, while for the CoNLL2000POS dataset we used the features presented in (Ratnaparkhi, 1996). As evaluation measure we adopted the token variant of the F1 measure, introduced by Esuli and Sebastiani (2010). This variant, instead of the entire annotation (chunk/entity), calculates TPs, FPs, and FNs, singularly for each token that compose the annotation, bringing to a finer evaluation. 5.3 Results From the learning curves of Figure 1 and Figure 2 it is</context>
</contexts>
<marker>Wanvarie, Takamura, Okumura, 2011</marker>
<rawString>Dittaya Wanvarie, Hiroya Takamura, and Manabu Okumura. 2011. Active learning with subsequence sampling strategy for sequence labeling tasks. Information and Media Technologies, 6(3):680–700.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>