<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001953">
<title confidence="0.984148">
Cipher Type Detection
</title>
<author confidence="0.929768">
Malte Nuhn
</author>
<affiliation confidence="0.9628585">
Human Language Technology
and Pattern Recognition Group
Computer Science Department
RWTH Aachen University
</affiliation>
<email confidence="0.986155">
nuhn@cs.rwth-aachen.de
</email>
<author confidence="0.997929">
Kevin Knight
</author>
<affiliation confidence="0.997323">
Information Sciences Institute
University of Southern California
</affiliation>
<email confidence="0.995831">
knight@isi.edu
</email>
<sectionHeader confidence="0.99384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99988625">
Manual analysis and decryption of enci-
phered documents is a tedious and error
prone work. Often—even after spend-
ing large amounts of time on a par-
ticular cipher—no decipherment can be
found. Automating the decryption of var-
ious types of ciphers makes it possible
to sift through the large number of en-
crypted messages found in libraries and
archives, and to focus human effort only
on a small but potentially interesting sub-
set of them. In this work, we train a clas-
sifier that is able to predict which enci-
pherment method has been used to gener-
ate a given ciphertext. We are able to dis-
tinguish 50 different cipher types (speci-
fied by the American Cryptogram Associ-
ation) with an accuracy of 58.5%. This is a
11.2% absolute improvement over the best
previously published classifier.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.988550871794872">
Libraries and archives contain a large number of
encrypted messages created throughout the cen-
turies using various encryption methods. For the
great majority of the ciphers an analysis has not
yet been conducted, simply because it takes too
much time to analyze each cipher individually, or
because it is too hard to decipher them. Automatic
methods for analyzing and classifying given ci-
phers makes it possible to sift interesting messages
and by that focus the limited amount of human re-
sources to a promising subset of ciphers.
For specific types of ciphers, there exist au-
tomated tools to decipher encrypted messages.
However, the publicly available tools often de-
pend on a more or less educated guess which
type of encipherment has been used. Furthermore,
they often still need human interaction and are
only restricted to analyzing very few types of ci-
phers. In practice however, there are many differ-
ent types of ciphers which we would like to an-
alyze in a fully automatic fashion: Bauer (2010)
gives a good overview over historical methods that
have been used to encipher messages in the past.
Similarly, the American Cryptogram Association
(ACA) specifies a set of 56 different methods for
enciphering a given plaintext:
Each encipherment method Mi can be seen as
a function that transforms a given plaintext into a
ciphertext using a given key, or short:
cipher = Mi(plain, key)
When analyzing an unknown ciphertext, we are
interested in the original plaintext that was used to
generate the ciphertext, i.e. the opposite direction:
plain = M−&apos;
i (cipher, key)
Obtaining the plaintext from an enciphered mes-
sage is a difficult problem. We assume that the
decipherment of a message can be separated into
solving three different subproblems:
</bodyText>
<listItem confidence="0.999282428571428">
1. Find the encipherment method Mi that was
used to create the cipher
cipher → Mi
2. Find the key that was used together with the
.method Mi to encipher the plaintext to obtain
cipher = Mi(plain, key).
3. Decode the message using Mi and key
</listItem>
<equation confidence="0.5126985">
cipher → M−&apos;
i (cipher, key)
</equation>
<bodyText confidence="0.999621666666667">
Thus, an intermediate step to deciphering an un-
known ciphertext is to find out which encryption
method was used. In this paper, we present a clas-
sifier that is able to predict just that: Given an un-
known ciphertext, it can predict what kind of en-
cryption method was most likely used to generate
</bodyText>
<page confidence="0.929832">
1769
</page>
<bodyText confidence="0.3515985">
Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1769–1773,
October 25-29, 2014, Doha, Qatar. c�2014 Association for Computational Linguistics
</bodyText>
<figure confidence="0.9880972">
type
plaintext key
encipher
ciphertext
classifier training
</figure>
<figureCaption confidence="0.985453">
Figure 2: Overview over the data generation and
training of the classifier presented in this work.
</figureCaption>
<sectionHeader confidence="0.799497" genericHeader="introduction">
3 General Approach
</sectionHeader>
<bodyText confidence="0.9997645">
Given a ciphertext, the task is to find the right en-
cryption method. Our test set covers 50 out of 56
cipher types specified by ACA, as listed in Fig-
ure 3. We are going to take a machine learning ap-
proach which is based on the observation that we
can generate an infinite amount of training data.
</bodyText>
<listItem confidence="0.962292636363636">
• Type: CMBIFID
• Plaintext:
WOMEN NSFOO TBALL ISGAI
NINGI NPOPU LARIT YANDT
HETOU RNAME
• Key:
LEFTKEY=’IACERATIONS’
RIGHTKEY=’KNORKOPPING’
PERIOD=3, LROUTE=1
RROUTE=1, USE6X6=0
• Ciphertext:
</listItem>
<sectionHeader confidence="0.715159" genericHeader="method">
WTQNG GEEBQ BPNQP VANEN
KDAOD GAHQS PKNVI PTAAP
DGMGR PCSGN
</sectionHeader>
<figureCaption confidence="0.884313">
Figure 1: Example “CMBIFID” cipher: Text is
grouped in five character chunks for readability.
</figureCaption>
<bodyText confidence="0.999826333333333">
it. The results of our classifier are a valuable input
to human decipherers to make a first categoriza-
tion of an unknown ciphertext.
</bodyText>
<sectionHeader confidence="0.999806" genericHeader="method">
2 Related Work
</sectionHeader>
<subsectionHeader confidence="0.999873">
3.1 Data Flow
</subsectionHeader>
<bodyText confidence="0.999847125">
Central to this work is the list of encryption meth-
ods provided by the American Cipher Associa-
tion1. This list contains detailed descriptions and
examples of each of the cipher types, allowing us
to implement them. Figure 3 lists these methods.
We compare our work to the only previously
published cipher type classifier for classical ci-
phers2. This classifier is trained on 16, 800 cipher-
texts and is implemented in javascript to run in the
web browser: The user can provide the ciphertext
as input to a web page that returns the classifier’s
predictions. The source code of the classifier is
available online. Our work includes a reimple-
mentation of the features used in that classifier.
As examples for work that deals with the auto-
mated decipherment of cipher texts, we point to
(Ravi and Knight, 2011), and (Nuhn et al., 2013).
These publications develop specialized algorithms
for solving simple and homophonic substitution
ciphers, which are just two out of the 56 cipher
types defined by the ACA. We also want to men-
tion (de Souza et al., 2013), which presents a ci-
pher type classifier for the finalist algorithms of
the Advanced Encryption Standard (AES) contest.
</bodyText>
<footnote confidence="0.978401">
1http://cryptogram.org/cipher_types.html
2See http://bionsgadgets.appspot.com/gadget_forms/
refscore_extended.html and https://sites.google.com/site/
bionspot/cipher-id-tests
</footnote>
<bodyText confidence="0.999945227272727">
The training procedure is depicted in Figure 2:
Based upon a large English corpus, we first choose
possible plaintext messages. Then, for each enci-
pherment method, we choose a random key and
encipher each of the plaintext messages using the
encipherment method and key. By doing this, we
can obtain (a theoretically infinite) amount of la-
beled data of the form (type, ciphertext). We can
then train a classifier on this data and evaluate it
on some held out data.
Figure 1 shows that in general the key can con-
sist of more than just a codeword: In this case,
the method uses two codewords, a period length,
two different permutation parameters, and a gen-
eral decision whether to use a special “6 x 6” vari-
ant of the cipher or not. If not defined otherwise,
we choose random settings for these parameters.
If the parameters are integers, we choose random
values from a uniform distribution (in a sensible
range). In case of codewords, we choose the 450k
most frequent words from an English dictionary.
We train on cipher texts of random length.
</bodyText>
<subsectionHeader confidence="0.993432">
3.2 Classifiers
</subsectionHeader>
<bodyText confidence="0.999810666666667">
The previous state-of-the-art classifier by BION
uses a random forest classifier (Breiman, 2001).
The version that is available online, uses 50 ran-
</bodyText>
<page confidence="0.879008">
1770
</page>
<listItem confidence="0.999893833333333">
• 6x6bifid • four square • (nihilisttransp) fort • swagman
• 6x6playfair • fracmorse • patristocrat • progressivekey • tridigital
• amsco • grandpre • period 7 vig. • quagmire2 • trifid
• bazeries • (grille) • periodic gro- • quagmire3 • trisquare
• beaufort • gromark mark • quagmire4 • trisquare hr
• bifid6 • gronsfeld • phillips • ragbaby • two square
• bifid7 • homophonic • plaintext • randomdigit • two sq. spiral
• (cadenus) • mnmedinome • playfair • randomtext • vigautokey
• cmbifid • morbit • pollux • redefence • (vigenere)
• columnar • myszkowski • porta • (route transp) • (vigslidefair)
• digrafid • nicodemus • portax • runningkey
• dbl chckrbrd • nihilistsub • progkey beau- • seriatedpfair
</listItem>
<figureCaption confidence="0.868589">
Figure 3: Cipher types specified by ACA. Our classifier is able to recognize 50 out of these 56 ciphers.
The braced cipher types are not covered in this work.
</figureCaption>
<bodyText confidence="0.995597565217391">
dom decision trees. The features used by this clas-
sifier are described in Section 4.
Further, we train a support vector machine using
the libSVM toolkit (Chang and Lin, 2011). This
is feasible for up to 100k training examples. Be-
yond this point, training times become too large.
We perform multi class classification using v-SVC
and a polynomial kernel. Multi class classification
is performed using one-against-one binary classifi-
cation. We select the SVM’s free parameters using
a small development set of 1k training examples.
We also use Vowpal Wabbit (Langford et al.,
2007) to train a linear classifier using stochastic
gradient descent. Compared to training SVMs,
Vowpal Wabbit is extremely fast and allows using
a lot of training examples. We use a squared loss
function, adaptive learning rates and don’t employ
any regularization. We train our classifier with up
to 1M training examples. The best performing set-
tings use one-against-all classification, 20 passes
over the training data and the default learning rate.
Quadratic features resulted in much slower train-
ing, while not providing any gains in accuracy.
</bodyText>
<sectionHeader confidence="0.999691" genericHeader="method">
4 Features
</sectionHeader>
<bodyText confidence="0.999974642857143">
We reimplemented all of the features used in the
BION classifier, and add three newly developed
sets of features, resulting in a total of 58 features.
In order to further structure these features, we
group these features as follows: We call the set
of features that relate to the length of the cipher
LEN. This set contains binary features firing when
the cipher length is a multiple of 2, 3, 5, 25, any
of 4-15, and any of 4-30. We call the set of fea-
tures that are based on the fact that the cipher-
text contains a specific symbol HAS. This set con-
tains binary features firing when the cipher con-
tains a digit, a letter (A-Z), the “#” symbol, the
letter “j”, the digit “0”. We also introduce an-
other set of features called DGT that contains two
features, firing when the cipher is starting or end-
ing with a digit. The set VIG contains 5 features:
The feature score is based on the best possible bi-
gram LM perplexity of a decipherment compatible
with the decipherment process of the cipher types
Autokey, Beaufort, Porta, Slidefair and Vigenere.
Further, we also include the features IC, MIC,
MKA, DIC, EDI, LR, ROD and LDI, DBL, NOMOR,
RDI, PTX, NIC, PHIC, BDI, CDD, SSTD, MPIC,
SERP, which were introduced in the BION classi-
fier3. Thus, the first 22 data points in Figure 4 are
based on previously known features by BION. We
further present the following additional features.
</bodyText>
<subsectionHeader confidence="0.99835">
4.1 Repetition Feature (REP)
</subsectionHeader>
<bodyText confidence="0.999646888888889">
This set of features is based on how often the ci-
phertext contains symbols that are repeated ex-
actly n times in a row: For example the cipher-
text shown in Figure 1 contains two positions with
repetitions of length n = 2, because the cipher-
text contains EE, as well as AA. Beyond length
2, there are no repeats. These numbers are then
normalized by dividing them by the total number
of repeats of length 2 &lt; n &lt; 5.
</bodyText>
<subsectionHeader confidence="0.997297">
4.2 Amsco Feature (AMSC)
</subsectionHeader>
<bodyText confidence="0.999953285714286">
The idea of the AMSCO cipher is to fill consec-
utive chunks of one and two plaintext characters
into n columns of a grid (see Table 1). Then a
permutation of the columns is performed, and the
resulting permuted plaintext is read of line by line
and forms the final ciphertext. This feature reads
the ciphertext into a similar grid of up to 5 columns
</bodyText>
<footnote confidence="0.997792">
3See http://home.comcast.net/˜acabion/acarefstats.html
</footnote>
<page confidence="0.978999">
1771
</page>
<table confidence="0.359676">
Plaintext w om e ns f
oo t ba l li
Permutation 3 5 1 4 2
</table>
<tableCaption confidence="0.995121">
Table 1: Example grid used for AMSCO ciphers.
</tableCaption>
<bodyText confidence="0.999469833333333">
and then tries all possible permutations to retain
the original plaintext. The result of this opera-
tion is then scored with a bigram language model.
Depending on whether the difference in perplexity
between ciphertext and deciphered text exceeds a
given threshold, this binary feature fires.
</bodyText>
<subsectionHeader confidence="0.9991">
4.3 Variant Feature (VAR)
</subsectionHeader>
<bodyText confidence="0.999992666666667">
In the variant cipher, the plaintext is written into
a block under a key word. All letters in the first
column are enciphered by shifting them using the
first key letter of the key word, the second column
uses the second key letter, etc. For different pe-
riods (i.e. lengths of key words), the ciphertext
is structured into n columns and unigram statis-
tics for each column are calculated. The frequency
profile of each column is compared to the unigram
frequency profile using a perplexity measure. This
binary feature fires when the resulting perplexities
are lower than a specific threshold.
</bodyText>
<sectionHeader confidence="0.999964" genericHeader="evaluation">
5 Results
</sectionHeader>
<bodyText confidence="0.999622769230769">
Figure 4 shows the classification accuracy for the
BION baseline, as well as our SVM and VW based
classifiers for a test set of 305 ciphers that have
been published in the ACA. The classifiers shown
in this figure are trained on cipher texts of ran-
dom length. We show the contribution of all the
features we used in the classifier on the x-axis.
Furthermore we also vary the amount of training
data we use to train the classifiers from 10k to 1M
training examples. It can be seen that when using
the same features as BION, our prediction accu-
racy is compatible with the BION classifier. The
main improvement of our classifier stems from the
REP, AMSC and VAR features. Our best classi-
fier is more than 11% more accurate than previous
state-of-the-art BION classifier.
We identified the best classifier on a held-out
set of 1000 ciphers, i.e. 20 ciphers for each ci-
pher type. Here the three new features improve the
VW-1M classifier from 50.9% accuracy to 56.0%
accuracy, and the VW-100k classifier from 48.9%
to 54.6%. Note that this held-out set is based on
the exact same generator that we used to create the
training data with. However, we also report the
results of our method on the completely indepen-
dently created ACA test set in Figure 4.
</bodyText>
<sectionHeader confidence="0.999232" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999857">
We presented a state-of-the art classifier for cipher
type detection. The approach we present is easily
extensible to cover more cipher types and allows
incorporating new features.
</bodyText>
<sectionHeader confidence="0.994965" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9928372">
We thank Taylor Berg-Kirkpatrick, Shu Cai, Bill
Mason, Be´ata Megyesi, Julian Schamper, and
Megha Srivastava for their support and ideas. This
work was supported by ARL/ARO (W911NF-10-
1-0533) and DARPA (HR0011-12-C-0014).
</bodyText>
<figure confidence="0.995322692307692">
Accuracy (%)
60
50
40
30
20
10
BION
SVM 10k
SVM100k
VW 100k
VW 1M
Features
</figure>
<figureCaption confidence="0.994774">
Figure 4: Classifier accuracy vs. training data and set of features used. From left to right more and
</figureCaption>
<bodyText confidence="0.860106333333333">
more features are used, the x-axis shows which features are added. The feature names are described in
Section 4. The features right of the vertical line are presented in this paper. The horizontal line shows
the previous state-of-the art accuracy (BION) of 47.3%, we achieve 58.49%.
</bodyText>
<page confidence="0.990263">
1772
</page>
<sectionHeader confidence="0.995871" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999851791666667">
F.L. Bauer. 2010. Decrypted Secrets: Methods and
Maxims of Cryptology. Springer.
Leo Breiman. 2001. Random forests. Machine Learn-
ing, 45(1):5–32, October.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technol-
ogy, 2:27:1–27:27. Software available at http://
www.csie.ntu.edu.tw/˜cjlin/libsvm.
William AR de Souza, Allan Tomlinson, and Luiz MS
de Figueiredo. 2013. Cipher identification with a
neural network.
John Langford, Lihong Li, and Alex Strehl. 2007.
Vowpal Wabbit. https://github.com/
JohnLangford/vowpal_wabbit/wiki.
Malte Nuhn, Julian Schamper, and Hermann Ney.
2013. Beam search for solving substitution ciphers.
In ACL (1), pages 1568–1576.
Sujith Ravi and Kevin Knight. 2011. Bayesian Infer-
ence for Zodiac and Other Homophonic Ciphers. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics (ACL), pages
239–247, Stroudsburg, PA, USA, June. Association
for Computational Linguistics.
</reference>
<page confidence="0.984053">
1773
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.194182">
<title confidence="0.878626666666667">Cipher Type Detection Malte Human Language</title>
<author confidence="0.523657">Pattern Recognition</author>
<affiliation confidence="0.7258495">Computer Science RWTH Aachen</affiliation>
<email confidence="0.971261">nuhn@cs.rwth-aachen.de</email>
<author confidence="0.930346">Kevin</author>
<affiliation confidence="0.999703">Information Sciences University of Southern</affiliation>
<email confidence="0.999799">knight@isi.edu</email>
<abstract confidence="0.998108333333333">Manual analysis and decryption of enciphered documents is a tedious and error prone work. Often—even after spending large amounts of time on a particular cipher—no decipherment can be found. Automating the decryption of various types of ciphers makes it possible to sift through the large number of encrypted messages found in libraries and archives, and to focus human effort only on a small but potentially interesting subset of them. In this work, we train a classifier that is able to predict which encipherment method has been used to generate a given ciphertext. We are able to distinguish 50 different cipher types (specified by the American Cryptogram Associwith an accuracy of This is a absolute improvement over the best previously published classifier.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>F L Bauer</author>
</authors>
<title>Decrypted Secrets: Methods and Maxims of Cryptology.</title>
<date>2010</date>
<publisher>Springer.</publisher>
<contexts>
<context position="2065" citStr="Bauer (2010)" startWordPosition="333" endWordPosition="334">hers makes it possible to sift interesting messages and by that focus the limited amount of human resources to a promising subset of ciphers. For specific types of ciphers, there exist automated tools to decipher encrypted messages. However, the publicly available tools often depend on a more or less educated guess which type of encipherment has been used. Furthermore, they often still need human interaction and are only restricted to analyzing very few types of ciphers. In practice however, there are many different types of ciphers which we would like to analyze in a fully automatic fashion: Bauer (2010) gives a good overview over historical methods that have been used to encipher messages in the past. Similarly, the American Cryptogram Association (ACA) specifies a set of 56 different methods for enciphering a given plaintext: Each encipherment method Mi can be seen as a function that transforms a given plaintext into a ciphertext using a given key, or short: cipher = Mi(plain, key) When analyzing an unknown ciphertext, we are interested in the original plaintext that was used to generate the ciphertext, i.e. the opposite direction: plain = M−&apos; i (cipher, key) Obtaining the plaintext from an</context>
</contexts>
<marker>Bauer, 2010</marker>
<rawString>F.L. Bauer. 2010. Decrypted Secrets: Methods and Maxims of Cryptology. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Breiman</author>
</authors>
<title>Random forests.</title>
<date>2001</date>
<booktitle>Machine Learning,</booktitle>
<volume>45</volume>
<issue>1</issue>
<contexts>
<context position="7066" citStr="Breiman, 2001" startWordPosition="1149" endWordPosition="1150">d: In this case, the method uses two codewords, a period length, two different permutation parameters, and a general decision whether to use a special “6 x 6” variant of the cipher or not. If not defined otherwise, we choose random settings for these parameters. If the parameters are integers, we choose random values from a uniform distribution (in a sensible range). In case of codewords, we choose the 450k most frequent words from an English dictionary. We train on cipher texts of random length. 3.2 Classifiers The previous state-of-the-art classifier by BION uses a random forest classifier (Breiman, 2001). The version that is available online, uses 50 ran1770 • 6x6bifid • four square • (nihilisttransp) fort • swagman • 6x6playfair • fracmorse • patristocrat • progressivekey • tridigital • amsco • grandpre • period 7 vig. • quagmire2 • trifid • bazeries • (grille) • periodic gro- • quagmire3 • trisquare • beaufort • gromark mark • quagmire4 • trisquare hr • bifid6 • gronsfeld • phillips • ragbaby • two square • bifid7 • homophonic • plaintext • randomdigit • two sq. spiral • (cadenus) • mnmedinome • playfair • randomtext • vigautokey • cmbifid • morbit • pollux • redefence • (vigenere) • column</context>
</contexts>
<marker>Breiman, 2001</marker>
<rawString>Leo Breiman. 2001. Random forests. Machine Learning, 45(1):5–32, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<pages>2--27</pages>
<note>Software available at http:// www.csie.ntu.edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="8163" citStr="Chang and Lin, 2011" startWordPosition="1341" endWordPosition="1344">• (cadenus) • mnmedinome • playfair • randomtext • vigautokey • cmbifid • morbit • pollux • redefence • (vigenere) • columnar • myszkowski • porta • (route transp) • (vigslidefair) • digrafid • nicodemus • portax • runningkey • dbl chckrbrd • nihilistsub • progkey beau- • seriatedpfair Figure 3: Cipher types specified by ACA. Our classifier is able to recognize 50 out of these 56 ciphers. The braced cipher types are not covered in this work. dom decision trees. The features used by this classifier are described in Section 4. Further, we train a support vector machine using the libSVM toolkit (Chang and Lin, 2011). This is feasible for up to 100k training examples. Beyond this point, training times become too large. We perform multi class classification using v-SVC and a polynomial kernel. Multi class classification is performed using one-against-one binary classification. We select the SVM’s free parameters using a small development set of 1k training examples. We also use Vowpal Wabbit (Langford et al., 2007) to train a linear classifier using stochastic gradient descent. Compared to training SVMs, Vowpal Wabbit is extremely fast and allows using a lot of training examples. We use a squared loss func</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2:27:1–27:27. Software available at http:// www.csie.ntu.edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William AR de Souza</author>
<author>Allan Tomlinson</author>
<author>Luiz MS de Figueiredo</author>
</authors>
<title>Cipher identification with a neural network.</title>
<date>2013</date>
<marker>de Souza, Tomlinson, de Figueiredo, 2013</marker>
<rawString>William AR de Souza, Allan Tomlinson, and Luiz MS de Figueiredo. 2013. Cipher identification with a neural network.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Langford</author>
<author>Lihong Li</author>
<author>Alex Strehl</author>
</authors>
<date>2007</date>
<note>Vowpal Wabbit. https://github.com/ JohnLangford/vowpal_wabbit/wiki.</note>
<contexts>
<context position="8568" citStr="Langford et al., 2007" startWordPosition="1404" endWordPosition="1407">cipher types are not covered in this work. dom decision trees. The features used by this classifier are described in Section 4. Further, we train a support vector machine using the libSVM toolkit (Chang and Lin, 2011). This is feasible for up to 100k training examples. Beyond this point, training times become too large. We perform multi class classification using v-SVC and a polynomial kernel. Multi class classification is performed using one-against-one binary classification. We select the SVM’s free parameters using a small development set of 1k training examples. We also use Vowpal Wabbit (Langford et al., 2007) to train a linear classifier using stochastic gradient descent. Compared to training SVMs, Vowpal Wabbit is extremely fast and allows using a lot of training examples. We use a squared loss function, adaptive learning rates and don’t employ any regularization. We train our classifier with up to 1M training examples. The best performing settings use one-against-all classification, 20 passes over the training data and the default learning rate. Quadratic features resulted in much slower training, while not providing any gains in accuracy. 4 Features We reimplemented all of the features used in </context>
</contexts>
<marker>Langford, Li, Strehl, 2007</marker>
<rawString>John Langford, Lihong Li, and Alex Strehl. 2007. Vowpal Wabbit. https://github.com/ JohnLangford/vowpal_wabbit/wiki.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Malte Nuhn</author>
<author>Julian Schamper</author>
<author>Hermann Ney</author>
</authors>
<title>Beam search for solving substitution ciphers.</title>
<date>2013</date>
<booktitle>In ACL (1),</booktitle>
<pages>1568--1576</pages>
<contexts>
<context position="5393" citStr="Nuhn et al., 2013" startWordPosition="887" endWordPosition="890">. Figure 3 lists these methods. We compare our work to the only previously published cipher type classifier for classical ciphers2. This classifier is trained on 16, 800 ciphertexts and is implemented in javascript to run in the web browser: The user can provide the ciphertext as input to a web page that returns the classifier’s predictions. The source code of the classifier is available online. Our work includes a reimplementation of the features used in that classifier. As examples for work that deals with the automated decipherment of cipher texts, we point to (Ravi and Knight, 2011), and (Nuhn et al., 2013). These publications develop specialized algorithms for solving simple and homophonic substitution ciphers, which are just two out of the 56 cipher types defined by the ACA. We also want to mention (de Souza et al., 2013), which presents a cipher type classifier for the finalist algorithms of the Advanced Encryption Standard (AES) contest. 1http://cryptogram.org/cipher_types.html 2See http://bionsgadgets.appspot.com/gadget_forms/ refscore_extended.html and https://sites.google.com/site/ bionspot/cipher-id-tests The training procedure is depicted in Figure 2: Based upon a large English corpus, </context>
</contexts>
<marker>Nuhn, Schamper, Ney, 2013</marker>
<rawString>Malte Nuhn, Julian Schamper, and Hermann Ney. 2013. Beam search for solving substitution ciphers. In ACL (1), pages 1568–1576.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sujith Ravi</author>
<author>Kevin Knight</author>
</authors>
<title>Bayesian Inference for Zodiac and Other Homophonic Ciphers.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>239--247</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA,</location>
<contexts>
<context position="5368" citStr="Ravi and Knight, 2011" startWordPosition="882" endWordPosition="885">allowing us to implement them. Figure 3 lists these methods. We compare our work to the only previously published cipher type classifier for classical ciphers2. This classifier is trained on 16, 800 ciphertexts and is implemented in javascript to run in the web browser: The user can provide the ciphertext as input to a web page that returns the classifier’s predictions. The source code of the classifier is available online. Our work includes a reimplementation of the features used in that classifier. As examples for work that deals with the automated decipherment of cipher texts, we point to (Ravi and Knight, 2011), and (Nuhn et al., 2013). These publications develop specialized algorithms for solving simple and homophonic substitution ciphers, which are just two out of the 56 cipher types defined by the ACA. We also want to mention (de Souza et al., 2013), which presents a cipher type classifier for the finalist algorithms of the Advanced Encryption Standard (AES) contest. 1http://cryptogram.org/cipher_types.html 2See http://bionsgadgets.appspot.com/gadget_forms/ refscore_extended.html and https://sites.google.com/site/ bionspot/cipher-id-tests The training procedure is depicted in Figure 2: Based upon</context>
</contexts>
<marker>Ravi, Knight, 2011</marker>
<rawString>Sujith Ravi and Kevin Knight. 2011. Bayesian Inference for Zodiac and Other Homophonic Ciphers. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics (ACL), pages 239–247, Stroudsburg, PA, USA, June. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>